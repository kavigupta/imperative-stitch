{"igor.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Helper for building, testing, and linting coverage.py.\n\nTo get portability, all these operations are written in Python here instead\nof in shell scripts, batch files, or Makefiles.\n\n\"\"\"\n\nimport contextlib\nimport datetime\nimport glob\nimport inspect\nimport itertools\nimport os\nimport platform\nimport pprint\nimport re\nimport subprocess\nimport sys\nimport sysconfig\nimport textwrap\nimport types\nimport warnings\nimport zipfile\n\ntry:\n    import pytest\nexcept ImportError:\n    # We want to be able to run this for some tasks that don't need pytest.\n    pytest = None\n\n# Constants derived the same as in coverage/env.py.  We can't import\n# that file here, it would be evaluated too early and not get the\n# settings we make in this file.\n\nCPYTHON = platform.python_implementation() == \"CPython\"\nPYPY = platform.python_implementation() == \"PyPy\"\n\n\n@contextlib.contextmanager\ndef ignore_warnings():\n    \"\"\"Context manager to ignore warning within the with statement.\"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        yield\n\n\nVERBOSITY = int(os.getenv(\"COVERAGE_IGOR_VERBOSE\", \"0\"))\n\n# Functions named do_* are executable from the command line: do_blah is run\n# by \"python igor.py blah\".\n\n\ndef do_show_env():\n    \"\"\"Show the environment variables.\"\"\"\n    print(\"Environment:\")\n    for env in sorted(os.environ):\n        print(f\"  {env} = {os.environ[env]!r}\")\n\n\ndef do_remove_extension(*args):\n    \"\"\"Remove the compiled C extension, no matter what its name.\"\"\"\n\n    so_patterns = \"\"\"\n        tracer.so\n        tracer.*.so\n        tracer.pyd\n        tracer.*.pyd\n        \"\"\".split()\n\n    if \"--from-install\" in args:\n        # Get the install location using a subprocess to avoid\n        # locking the file we are about to delete\n        root = os.path.dirname(\n            subprocess.check_output(\n                [\n                    sys.executable,\n                    \"-Xutf8\",\n                    \"-c\",\n                    \"import coverage; print(coverage.__file__)\",\n                ],\n                encoding=\"utf-8\",\n            ).strip(),\n        )\n        roots = [root]\n    else:\n        roots = [\"coverage\", \"build/*/coverage\"]\n\n    for root, pattern in itertools.product(roots, so_patterns):\n        pattern = os.path.join(root, pattern.strip())\n        if VERBOSITY:\n            print(f\"Searching for {pattern}\")\n        for filename in glob.glob(pattern):\n            if os.path.exists(filename):\n                if VERBOSITY:\n                    print(f\"Removing {filename}\")\n                try:\n                    os.remove(filename)\n                except OSError as exc:\n                    if VERBOSITY:\n                        print(f\"Couldn't remove {filename}: {exc}\")\n\n\ndef label_for_core(core):\n    \"\"\"Get the label for these tests.\"\"\"\n    if core == \"pytrace\":\n        return \"with Python tracer\"\n    elif core == \"ctrace\":\n        return \"with C tracer\"\n    elif core == \"sysmon\":\n        return \"with sys.monitoring\"\n    else:\n        raise ValueError(f\"Bad core: {core!r}\")\n\n\ndef should_skip(core):\n    \"\"\"Is there a reason to skip these tests?\n\n    Return empty string to run tests, or a message about why we are skipping\n    the tests.\n    \"\"\"\n    skipper = \"\"\n\n    # $set_env.py: COVERAGE_TEST_CORES - List of cores to run\n    test_cores = os.getenv(\"COVERAGE_TEST_CORES\")\n    if test_cores:\n        if core not in test_cores:\n            skipper = f\"core {core} not in COVERAGE_TEST_CORES={test_cores}\"\n    else:\n        # $set_env.py: COVERAGE_ONE_CORE - Only run tests for one core.\n        only_one = os.getenv(\"COVERAGE_ONE_CORE\")\n        if only_one:\n            if CPYTHON:\n                if sys.version_info >= (3, 12):\n                    if core != \"sysmon\":\n                        skipper = f\"Only one core: not running {core}\"\n                elif core != \"ctrace\":\n                    skipper = f\"Only one core: not running {core}\"\n            else:\n                if core != \"pytrace\":\n                    skipper = f\"No C core for {platform.python_implementation()}\"\n\n    if skipper:\n        msg = \"Skipping tests \" + label_for_core(core)\n        if len(skipper) > 1:\n            msg += \": \" + skipper\n    else:\n        msg = \"\"\n\n    return msg\n\n\ndef make_env_id(core):\n    \"\"\"An environment id that will keep all the test runs distinct.\"\"\"\n    impl = platform.python_implementation().lower()\n    version = \"{}{}\".format(*sys.version_info[:2])\n    if PYPY:\n        version += \"_{}{}\".format(*sys.pypy_version_info[:2])\n    env_id = f\"{impl}{version}_{core}\"\n    return env_id\n\n\ndef run_tests(core, *runner_args):\n    \"\"\"The actual running of tests.\"\"\"\n    if \"COVERAGE_TESTING\" not in os.environ:\n        os.environ[\"COVERAGE_TESTING\"] = \"True\"\n    print_banner(label_for_core(core))\n\n    return pytest.main(list(runner_args))\n\n\ndef run_tests_with_coverage(core, *runner_args):\n    \"\"\"Run tests, but with coverage.\"\"\"\n    # Need to define this early enough that the first import of env.py sees it.\n    os.environ[\"COVERAGE_TESTING\"] = \"True\"\n    os.environ[\"COVERAGE_PROCESS_START\"] = os.path.abspath(\"metacov.ini\")\n    os.environ[\"COVERAGE_HOME\"] = os.getcwd()\n    context = os.getenv(\"COVERAGE_CONTEXT\")\n    if context:\n        if context[0] == \"$\":\n            context = os.environ[context[1:]]\n        os.environ[\"COVERAGE_CONTEXT\"] = context + \".\" + core\n\n    # Create the .pth file that will let us measure coverage in sub-processes.\n    # The .pth file seems to have to be alphabetically after easy-install.pth\n    # or the sys.path entries aren't created right?\n    # There's an entry in \"make clean\" to get rid of this file.\n    pth_dir = sysconfig.get_path(\"purelib\")\n    pth_path = os.path.join(pth_dir, \"zzz_metacov.pth\")\n    with open(pth_path, \"w\") as pth_file:\n        pth_file.write(\"import coverage; coverage.process_startup()\\n\")\n\n    suffix = f\"{make_env_id(core)}_{platform.platform()}\"\n    os.environ[\"COVERAGE_METAFILE\"] = os.path.abspath(\".metacov.\" + suffix)\n\n    import coverage\n\n    cov = coverage.Coverage(config_file=\"metacov.ini\")\n    cov._warn_unimported_source = False\n    cov._warn_preimported_source = False\n    cov._metacov = True\n    cov.start()\n\n    try:\n        # Re-import coverage to get it coverage tested!  I don't understand all\n        # the mechanics here, but if I don't carry over the imported modules\n        # (in covmods), then things go haywire (os is None, eventually).\n        covmods = {}\n        covdir = os.path.split(coverage.__file__)[0]\n        # We have to make a list since we'll be deleting in the loop.\n        modules = list(sys.modules.items())\n        for name, mod in modules:\n            if name.startswith(\"coverage\"):\n                if getattr(mod, \"__file__\", \"??\").startswith(covdir):\n                    covmods[name] = mod\n                    del sys.modules[name]\n        import coverage  # pylint: disable=reimported\n\n        sys.modules.update(covmods)\n\n        # Run tests, with the arguments from our command line.\n        status = run_tests(core, *runner_args)\n\n    finally:\n        cov.stop()\n        os.remove(pth_path)\n\n    cov.save()\n    return status\n\n\ndef do_combine_html():\n    \"\"\"Combine data from a meta-coverage run, and make the HTML report.\"\"\"\n    import coverage\n\n    os.environ[\"COVERAGE_HOME\"] = os.getcwd()\n    cov = coverage.Coverage(config_file=\"metacov.ini\")\n    cov.load()\n    cov.combine()\n    cov.save()\n    # A new Coverage to turn on messages. Better would be to have tighter\n    # control over message verbosity...\n    cov = coverage.Coverage(config_file=\"metacov.ini\", messages=True)\n    cov.load()\n    show_contexts = bool(\n        os.getenv(\"COVERAGE_DYNCTX\") or os.getenv(\"COVERAGE_CONTEXT\"),\n    )\n    cov.html_report(show_contexts=show_contexts)\n    cov.json_report(show_contexts=show_contexts, pretty_print=True)\n\n\ndef do_test_with_core(core, *runner_args):\n    \"\"\"Run tests with a particular core.\"\"\"\n    # If we should skip these tests, skip them.\n    skip_msg = should_skip(core)\n    if skip_msg:\n        print(skip_msg)\n        return None\n\n    os.environ[\"COVERAGE_CORE\"] = core\n    if os.getenv(\"COVERAGE_COVERAGE\", \"no\") == \"yes\":\n        return run_tests_with_coverage(core, *runner_args)\n    else:\n        return run_tests(core, *runner_args)\n\n\ndef do_zip_mods():\n    \"\"\"Build the zip files needed for tests.\"\"\"\n    with zipfile.ZipFile(\"tests/zipmods.zip\", \"w\") as zf:\n        # Take some files from disk.\n        zf.write(\"tests/covmodzip1.py\", \"covmodzip1.py\")\n\n        # The others will be various encodings.\n        source = textwrap.dedent(\n            \"\"\"\\\n            # coding: {encoding}\n            text = u\"{text}\"\n            ords = {ords}\n            assert [ord(c) for c in text] == ords\n            print(u\"All OK with {encoding}\")\n            encoding = \"{encoding}\"\n            \"\"\",\n        )\n        # These encodings should match the list in tests/test_python.py\n        details = [\n            (\"utf-8\", \"\u24d7\u24d4\u24db\u24db\u24de, \u24e6\u24de\u24e1\u24db\u24d3\"),\n            (\"gb2312\", \"\u4f60\u597d\uff0c\u4e16\u754c\"),\n            (\"hebrew\", \"\u05e9\u05dc\u05d5\u05dd, \u05e2\u05d5\u05dc\u05dd\"),\n            (\"shift_jis\", \"\u3053\u3093\u306b\u3061\u306f\u4e16\u754c\"),\n            (\"cp1252\", \"\u201chi\u201d\"),\n        ]\n        for encoding, text in details:\n            filename = f\"encoded_{encoding}.py\"\n            ords = [ord(c) for c in text]\n            source_text = source.format(encoding=encoding, text=text, ords=ords)\n            zf.writestr(filename, source_text.encode(encoding))\n\n    with zipfile.ZipFile(\"tests/zip1.zip\", \"w\") as zf:\n        zf.write(\"tests/zipsrc/zip1/__init__.py\", \"zip1/__init__.py\")\n        zf.write(\"tests/zipsrc/zip1/zip1.py\", \"zip1/zip1.py\")\n\n    with zipfile.ZipFile(\"tests/covmain.zip\", \"w\") as zf:\n        zf.write(\"coverage/__main__.py\", \"__main__.py\")\n\n\ndef print_banner(label):\n    \"\"\"Print the version of Python.\"\"\"\n    try:\n        impl = platform.python_implementation()\n    except AttributeError:\n        impl = \"Python\"\n\n    version = platform.python_version()\n\n    if PYPY:\n        version += \" (pypy %s)\" % \".\".join(str(v) for v in sys.pypy_version_info)\n\n    rev = platform.python_revision()\n    if rev:\n        version += f\" (rev {rev})\"\n\n    try:\n        which_python = os.path.relpath(sys.executable)\n    except ValueError:\n        # On Windows having a python executable on a different drive\n        # than the sources cannot be relative.\n        which_python = sys.executable\n    print(f\"=== {impl} {version} {label} ({which_python}) ===\")\n    sys.stdout.flush()\n\n\ndef do_quietly(command):\n    \"\"\"Run a command in a shell, and suppress all output.\"\"\"\n    proc = subprocess.run(\n        command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL,\n    )\n    return proc.returncode\n\n\ndef get_release_facts():\n    \"\"\"Return an object with facts about the current release.\"\"\"\n    import coverage\n    import coverage.version\n\n    facts = types.SimpleNamespace()\n    facts.ver = coverage.__version__\n    mjr, mnr, mcr, rel, ser = facts.vi = coverage.version_info\n    facts.dev = coverage.version._dev\n    facts.shortver = f\"{mjr}.{mnr}.{mcr}\"\n    facts.anchor = facts.shortver.replace(\".\", \"-\")\n    if rel == \"final\":\n        facts.next_vi = (mjr, mnr, mcr + 1, \"alpha\", 0)\n    else:\n        facts.anchor += f\"{rel[0]}{ser}\"\n        facts.next_vi = (mjr, mnr, mcr, rel, ser + 1)\n\n    facts.now = datetime.datetime.now()\n    facts.branch = subprocess.getoutput(\"git rev-parse --abbrev-ref @\")\n    facts.sha = subprocess.getoutput(\"git rev-parse @\")\n    return facts\n\n\ndef update_file(fname, pattern, replacement):\n    \"\"\"Update the contents of a file, replacing pattern with replacement.\"\"\"\n    with open(fname) as fobj:\n        old_text = fobj.read()\n\n    new_text = re.sub(pattern, replacement, old_text, count=1)\n\n    if new_text != old_text:\n        print(f\"Updating {fname}\")\n        with open(fname, \"w\") as fobj:\n            fobj.write(new_text)\n\n\nUNRELEASED = \"Unreleased\\n----------\"\nSCRIV_START = \".. scriv-start-here\\n\\n\"\n\n\ndef do_edit_for_release():\n    \"\"\"Edit a few files in preparation for a release.\"\"\"\n    facts = get_release_facts()\n\n    if facts.dev:\n        print(f\"**\\n** This is a dev release: {facts.ver}\\n**\\n\\nNo edits\")\n        return\n\n    # NOTICE.txt\n    update_file(\n        \"NOTICE.txt\", r\"Copyright 2004.*? Ned\", f\"Copyright 2004-{facts.now:%Y} Ned\",\n    )\n\n    # CHANGES.rst\n    title = f\"Version {facts.ver} \u2014 {facts.now:%Y-%m-%d}\"\n    rule = \"-\" * len(title)\n    new_head = f\".. _changes_{facts.anchor}:\\n\\n{title}\\n{rule}\"\n\n    update_file(\"CHANGES.rst\", re.escape(SCRIV_START), \"\")\n    update_file(\"CHANGES.rst\", re.escape(UNRELEASED), SCRIV_START + new_head)\n\n    # doc/conf.py\n    new_conf = textwrap.dedent(\n        f\"\"\"\\\n        # @@@ editable\n        copyright = \"2009\\N{EN DASH}{facts.now:%Y}, Ned Batchelder\" # pylint: disable=redefined-builtin\n        # The short X.Y.Z version.\n        version = \"{facts.shortver}\"\n        # The full version, including alpha/beta/rc tags.\n        release = \"{facts.ver}\"\n        # The date of release, in \"monthname day, year\" format.\n        release_date = \"{facts.now:%B %-d, %Y}\"\n        # @@@ end\n        \"\"\",\n    )\n    update_file(\"doc/conf.py\", r\"(?s)# @@@ editable\\n.*# @@@ end\\n\", new_conf)\n\n\ndef do_bump_version():\n    \"\"\"Edit a few files right after a release to bump the version.\"\"\"\n    facts = get_release_facts()\n\n    # CHANGES.rst\n    update_file(\n        \"CHANGES.rst\",\n        re.escape(SCRIV_START),\n        f\"{UNRELEASED}\\n\\nNothing yet.\\n\\n\\n\" + SCRIV_START,\n    )\n\n    # coverage/version.py\n    next_version = f\"version_info = {facts.next_vi}\\n_dev = 1\".replace(\"'\", '\"')\n    update_file(\n        \"coverage/version.py\", r\"(?m)^version_info = .*\\n_dev = \\d+$\", next_version,\n    )\n\n\ndef do_cheats():\n    \"\"\"Show a cheatsheet of useful things during releasing.\"\"\"\n    facts = get_release_facts()\n    pprint.pprint(facts.__dict__)\n    print()\n    print(f\"Coverage version is {facts.ver}\")\n\n    repo = \"nedbat/coveragepy\"\n    github = f\"https://github.com/{repo}\"\n    egg = \"egg=coverage==0.0\"  # to force a re-install\n    print(\n        f\"https://coverage.readthedocs.io/en/{facts.ver}/changes.html#changes-{facts.anchor}\",\n    )\n\n    print(\n        \"\\n## For GitHub commenting:\\n\"\n        + \"This is now released as part of \"\n        + f\"[coverage {facts.ver}](https://pypi.org/project/coverage/{facts.ver}).\",\n    )\n\n    print(\"\\n## To install this code:\")\n    if facts.branch == \"master\":\n        print(f\"python3 -m pip install git+{github}#{egg}\")\n    else:\n        print(f\"python3 -m pip install git+{github}@{facts.branch}#{egg}\")\n    print(f\"python3 -m pip install git+{github}@{facts.sha[:20]}#{egg}\")\n\n    print(\"\\n## To read this code on GitHub:\")\n    print(f\"https://github.com/nedbat/coveragepy/commit/{facts.sha}\")\n    print(f\"https://github.com/nedbat/coveragepy/commits/{facts.sha}\")\n    print(f\"https://github.com/nedbat/coveragepy/tree/{facts.branch}\")\n\n    print(\n        \"\\n## For other collaborators to get this code:\\n\"\n        + f\"git clone {github}\\n\"\n        + f\"cd {repo.partition('/')[-1]}\\n\"\n        + f\"git checkout {facts.sha}\",\n    )\n\n\ndef do_help():\n    \"\"\"List the available commands\"\"\"\n    items = list(globals().items())\n    items.sort()\n    for name, value in items:\n        if name.startswith(\"do_\"):\n            print(f\"{name[3:]:<20}{value.__doc__}\")\n\n\ndef analyze_args(function):\n    \"\"\"What kind of args does `function` expect?\n\n    Returns:\n        star, num_pos:\n            star(boolean): Does `function` accept *args?\n            num_args(int): How many positional arguments does `function` have?\n    \"\"\"\n    argspec = inspect.getfullargspec(function)\n    return bool(argspec.varargs), len(argspec.args)\n\n\ndef main(args):\n    \"\"\"Main command-line execution for igor.\n\n    Verbs are taken from the command line, and extra words taken as directed\n    by the arguments needed by the handler.\n\n    \"\"\"\n    while args:\n        verb = args.pop(0)\n        handler = globals().get(\"do_\" + verb)\n        if handler is None:\n            print(f\"*** No handler for {verb!r}\")\n            return 1\n        star, num_args = analyze_args(handler)\n        if star:\n            # Handler has *args, give it all the rest of the command line.\n            handler_args = args\n            args = []\n        else:\n            # Handler has specific arguments, give it only what it needs.\n            handler_args = args[:num_args]\n            args = args[num_args:]\n        ret = handler(*handler_args)\n        # If a handler returns a failure-like value, stop.\n        if ret:\n            return ret\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main(sys.argv[1:]))\n", "setup.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Code coverage measurement for Python\"\"\"\n\n# Distutils setup for coverage.py\n# This file is used unchanged under all versions of Python.\n\nimport os\nimport sys\n\n# Setuptools has to be imported before distutils, or things break.\nfrom setuptools import setup\nfrom distutils.core import Extension  # pylint: disable=wrong-import-order\nfrom setuptools.command.build_ext import build_ext  # pylint: disable=wrong-import-order\nfrom distutils import errors  # pylint: disable=wrong-import-order\n\n# Get or massage our metadata.  We exec coverage/version.py so we can avoid\n# importing the product code into setup.py.\n\n# PYVERSIONS\nclassifiers = \"\"\"\\\nEnvironment :: Console\nIntended Audience :: Developers\nLicense :: OSI Approved :: Apache Software License\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.8\nProgramming Language :: Python :: 3.9\nProgramming Language :: Python :: 3.10\nProgramming Language :: Python :: 3.11\nProgramming Language :: Python :: 3.12\nProgramming Language :: Python :: 3.13\nProgramming Language :: Python :: Implementation :: CPython\nProgramming Language :: Python :: Implementation :: PyPy\nTopic :: Software Development :: Quality Assurance\nTopic :: Software Development :: Testing\n\"\"\"\n\ncov_ver_py = os.path.join(os.path.split(__file__)[0], \"coverage/version.py\")\nwith open(cov_ver_py) as version_file:\n    # __doc__ will be overwritten by version.py.\n    doc = __doc__\n    # Keep pylint happy.\n    __version__ = __url__ = version_info = \"\"\n    # Execute the code in version.py.\n    exec(compile(version_file.read(), cov_ver_py, \"exec\", dont_inherit=True))\n\nwith open(\"README.rst\") as readme:\n    readme_text = readme.read()\n\ntemp_url = __url__.replace(\"readthedocs\", \"@@\")\nassert \"@@\" not in readme_text\nlong_description = (\n    readme_text.replace(\"https://coverage.readthedocs.io/en/latest\", temp_url)\n    .replace(\"https://coverage.readthedocs.io\", temp_url)\n    .replace(\"@@\", \"readthedocs\")\n)\n\nwith open(\"CONTRIBUTORS.txt\", \"rb\") as contributors:\n    paras = contributors.read().split(b\"\\n\\n\")\n    num_others = len(paras[-1].splitlines())\n    num_others += 1  # Count Gareth Rees, who is mentioned in the top paragraph.\n\nclassifier_list = classifiers.splitlines()\n\nif version_info[3] == \"alpha\":\n    devstat = \"3 - Alpha\"\nelif version_info[3] in [\"beta\", \"candidate\"]:\n    devstat = \"4 - Beta\"\nelse:\n    assert version_info[3] == \"final\"\n    devstat = \"5 - Production/Stable\"\nclassifier_list.append(f\"Development Status :: {devstat}\")\n\n# Create the keyword arguments for setup()\n\nsetup_args = dict(\n    name=\"coverage\",\n    version=__version__,\n    packages=[\n        \"coverage\",\n    ],\n    package_data={\n        \"coverage\": [\n            \"htmlfiles/*.*\",\n            \"py.typed\",\n        ],\n    },\n    entry_points={\n        # Install a script as \"coverage\", and as \"coverage3\", and as\n        # \"coverage-3.7\" (or whatever).\n        \"console_scripts\": [\n            \"coverage = coverage.cmdline:main\",\n            \"coverage%d = coverage.cmdline:main\" % sys.version_info[:1],\n            \"coverage-%d.%d = coverage.cmdline:main\" % sys.version_info[:2],\n        ],\n    },\n    extras_require={\n        # Enable pyproject.toml support.\n        \"toml\": ['tomli; python_full_version<=\"3.11.0a6\"'],\n    },\n    # We need to get HTML assets from our htmlfiles directory.\n    zip_safe=False,\n    author=f\"Ned Batchelder and {num_others} others\",\n    author_email=\"ned@nedbatchelder.com\",\n    description=doc,\n    long_description=long_description,\n    long_description_content_type=\"text/x-rst\",\n    keywords=\"code coverage testing\",\n    license=\"Apache-2.0\",\n    license_files=[\"LICENSE.txt\"],\n    classifiers=classifier_list,\n    url=\"https://github.com/nedbat/coveragepy\",\n    project_urls={\n        \"Documentation\": __url__,\n        \"Funding\": (\n            \"https://tidelift.com/subscription/pkg/pypi-coverage\"\n            + \"?utm_source=pypi-coverage&utm_medium=referral&utm_campaign=pypi\"\n        ),\n        \"Issues\": \"https://github.com/nedbat/coveragepy/issues\",\n        \"Mastodon\": \"https://hachyderm.io/@coveragepy\",\n        \"Mastodon (nedbat)\": \"https://hachyderm.io/@nedbat\",\n    },\n    python_requires=\">=3.8\",  # minimum of PYVERSIONS\n)\n\n# A replacement for the build_ext command which raises a single exception\n# if the build fails, so we can fallback nicely.\n\next_errors = (\n    errors.CCompilerError,\n    errors.DistutilsExecError,\n    errors.DistutilsPlatformError,\n)\nif sys.platform == \"win32\":\n    # distutils.msvc9compiler can raise an IOError when failing to\n    # find the compiler\n    ext_errors += (IOError,)\n\n\nclass BuildFailed(Exception):\n    \"\"\"Raise this to indicate the C extension wouldn't build.\"\"\"\n\n    def __init__(self):\n        Exception.__init__(self)\n        self.cause = sys.exc_info()[1]  # work around py 2/3 different syntax\n\n\nclass ve_build_ext(build_ext):\n    \"\"\"Build C extensions, but fail with a straightforward exception.\"\"\"\n\n    def run(self):\n        \"\"\"Wrap `run` with `BuildFailed`.\"\"\"\n        try:\n            build_ext.run(self)\n        except errors.DistutilsPlatformError as exc:\n            raise BuildFailed() from exc\n\n    def build_extension(self, ext):\n        \"\"\"Wrap `build_extension` with `BuildFailed`.\"\"\"\n        try:\n            # Uncomment to test compile failure handling:\n            #   raise errors.CCompilerError(\"OOPS\")\n            build_ext.build_extension(self, ext)\n        except ext_errors as exc:\n            raise BuildFailed() from exc\n        except ValueError as err:\n            # this can happen on Windows 64 bit, see Python issue 7511\n            if \"'path'\" in str(err):  # works with both py 2/3\n                raise BuildFailed() from err\n            raise\n\n\n# There are a few reasons we might not be able to compile the C extension.\n# Figure out if we should attempt the C extension or not.\n\ncompile_extension = True\n\nif \"__pypy__\" in sys.builtin_module_names:\n    # Pypy can't compile C extensions\n    compile_extension = False\n\nif compile_extension:\n    setup_args.update(\n        dict(\n            ext_modules=[\n                Extension(\n                    \"coverage.tracer\",\n                    sources=[\n                        \"coverage/ctracer/datastack.c\",\n                        \"coverage/ctracer/filedisp.c\",\n                        \"coverage/ctracer/module.c\",\n                        \"coverage/ctracer/tracer.c\",\n                    ],\n                ),\n            ],\n            cmdclass={\n                \"build_ext\": ve_build_ext,\n            },\n        ),\n    )\n\n\ndef main():\n    \"\"\"Actually invoke setup() with the arguments we built above.\"\"\"\n    # For a variety of reasons, it might not be possible to install the C\n    # extension.  Try it with, and if it fails, try it without.\n    try:\n        setup(**setup_args)\n    except BuildFailed as exc:\n        msg = \"Couldn't install with extension module, trying without it...\"\n        exc_msg = f\"{exc.__class__.__name__}: {exc.cause}\"\n        print(f\"**\\n** {msg}\\n** {exc_msg}\\n**\")\n\n        del setup_args[\"ext_modules\"]\n        setup(**setup_args)\n\n\nif __name__ == \"__main__\":\n    main()\n", "__main__.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Be able to execute coverage.py by pointing Python at a working tree.\"\"\"\n\nimport runpy\nimport os\n\nPKG = \"coverage\"\n\nrun_globals = runpy.run_module(PKG, run_name=\"__main__\", alter_sys=True)\nexecuted = os.path.splitext(os.path.basename(run_globals[\"__file__\"]))[0]\n", "doc/cog_helpers.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nFunctions for use with cog in the documentation.\n\"\"\"\n\n# For help text in doc/cmd.rst:\n# optparse wraps help to the COLUMNS value.  Set it here to be sure it's\n# consistent regardless of the environment.  Has to be set before we\n# import cmdline.py, which creates the optparse objects.\n\n# pylint: disable=wrong-import-position\nimport os\nos.environ[\"COLUMNS\"] = \"80\"\n\nimport contextlib\nimport io\nimport re\nimport textwrap\n\nimport cog              # pylint: disable=import-error\n\nfrom coverage.cmdline import CoverageScript\nfrom coverage.config import read_coverage_config\n\n\ndef show_help(cmd):\n    \"\"\"\n    Insert the help output from a command.\n    \"\"\"\n    with contextlib.redirect_stdout(io.StringIO()) as stdout:\n        CoverageScript().command_line([cmd, \"--help\"])\n    help_text = stdout.getvalue()\n    help_text = help_text.replace(\"__main__.py\", \"coverage\")\n    help_text = re.sub(r\"(?m)^Full doc.*$\", \"\", help_text)\n    help_text = help_text.rstrip()\n\n    print(\".. code::\\n\")\n    print(f\"    $ coverage {cmd} --help\")\n    print(textwrap.indent(help_text, \"    \"))\n\n\ndef _read_config(text, fname):\n    \"\"\"\n    Prep and read configuration text.\n\n    Returns the prepared text, and a dict of the settings.\n    \"\"\"\n    # Text will be triple-quoted with an initial ignored newline.\n    assert text[0] == \"\\n\"\n    text = textwrap.dedent(text[1:])\n\n    os.makedirs(\"tmp\", exist_ok=True)\n    with open(f\"tmp/{fname}\", \"w\") as f:\n        f.write(text)\n\n    config = read_coverage_config(f\"tmp/{fname}\", warn=cog.error)\n\n    values = {}\n    for name, val in vars(config).items():\n        if name.startswith(\"_\"):\n            continue\n        if \"config_file\" in name:\n            continue\n        values[name] = val\n    return text, values\n\n\ndef show_configs(ini, toml):\n    \"\"\"\n    Show configuration text in a tabbed box.\n\n    `ini` is the ini-file syntax, `toml` is the equivalent TOML syntax.\n    The equivalence is checked for accuracy, and the process fails if there's\n    a mismtach.\n\n    A three-tabbed box will be produced.\n    \"\"\"\n    ini, ini_vals = _read_config(ini, \"covrc\")\n    toml, toml_vals = _read_config(toml, \"covrc.toml\")\n    for key, val in ini_vals.items():\n        if val != toml_vals[key]:\n            cog.error(f\"Mismatch! {key}: {val!r} vs {toml_vals[key]!r}\")\n\n    ini2 = re.sub(r\"(?m)^\\[\", \"[coverage:\", ini)\n    print()\n    print(\".. tabs::\\n\")\n    for name, syntax, text in [\n        (\".coveragerc\", \"ini\", ini),\n        (\"pyproject.toml\", \"toml\", toml),\n        (\"setup.cfg, tox.ini\", \"ini\", ini2),\n    ]:\n        print(f\"    .. code-tab:: {syntax}\")\n        print(f\"        :caption: {name}\")\n        print()\n        print(textwrap.indent(text, \" \" * 8))\n", "doc/conf.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Sphinx configuration.\"\"\"\n\n# coverage.py documentation build configuration file, created by\n# sphinx-quickstart on Wed May 13 22:18:33 2009.\n#\n# This file is execfile()d with the current directory set to its containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport atexit\nimport os\nimport re\nimport sys\nimport tempfile\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#sys.path.append(os.path.abspath('.'))\n\n# on_rtd is whether we are on readthedocs.org\non_rtd = os.getenv('READTHEDOCS') == 'True'\n\n# -- General configuration -----------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.\nextensions = [\n    'sphinx.ext.autodoc',\n    'sphinx.ext.todo',\n    'sphinx.ext.ifconfig',\n    'sphinx.ext.intersphinx',\n    'sphinxcontrib.restbuilder',\n    'sphinx.ext.napoleon',\n    'sphinx_code_tabs',\n    'sphinx_rtd_theme',\n]\n\nautodoc_typehints = \"description\"\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = []\n\n# The suffix of source filenames.\nsource_suffix = '.rst'\n\n# The encoding of source files.\n#source_encoding = 'utf-8'\n\n# The master toctree document.\nmaster_doc = 'index'\n\n# General information about the project.\nproject = 'Coverage.py'\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n\n# @@@ editable\ncopyright = \"2009\u20132024, Ned Batchelder\" # pylint: disable=redefined-builtin\n# The short X.Y.Z version.\nversion = \"7.5.4\"\n# The full version, including alpha/beta/rc tags.\nrelease = \"7.5.4\"\n# The date of release, in \"monthname day, year\" format.\nrelease_date = \"June 22, 2024\"\n# @@@ end\n\nrst_epilog = f\"\"\"\n.. |release_date| replace:: {release_date}\n.. |coverage-equals-release| replace:: coverage=={release}\n.. |doc-url| replace:: https://coverage.readthedocs.io/en/{release}\n.. |br| raw:: html\n\n  <br/>\n\n\"\"\"\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = ''\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = '%B %d, %Y'\n\n# List of documents that shouldn't be included in the build.\n#unused_docs = []\n\n# List of directories, relative to source directory, that shouldn't be searched\n# for source files.\nexclude_patterns = [\"_build\", \"help/*\"]\n\n# The reST default role (used for this markup: `text`) to use for all documents.\n#default_role = None\n\n# If true, '()' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = 'sphinx'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\nintersphinx_mapping = {\n    'python': ('https://docs.python.org/3', None),\n}\n\nnitpick_ignore = [\n    (\"py:class\", \"DefaultValue\"),\n    (\"py:class\", \"FilePath\"),\n    (\"py:class\", \"types.FrameType\"),\n    (\"py:class\", \"TWarnFn\"),\n    (\"py:class\", \"TDebugCtl\"),\n]\n\nnitpick_ignore_regex = [\n    (r\"py:class\", r\"coverage\\..*\\..*\"),\n]\n\n# -- Options for HTML output ---------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  Major themes that come with\n# Sphinx are currently 'default' and 'sphinxdoc'.\nhtml_theme = 'sphinx_rtd_theme'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n#html_style = \"neds.css\"\n#html_add_permalinks = \"\"\n\n# Add any paths that contain custom themes here, relative to this directory.\n#html_theme_path = ['_templates']\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\nhtml_logo = 'media/sleepy-snake-circle-150.png'\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = ['_static']\n\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = '%b %d, %Y'\n\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\nhtml_use_modindex = False\n\n# If false, no index is generated.\nhtml_use_index = False\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\nhtml_show_sourcelink = False\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = ''\n\n# If nonempty, this is the file name suffix for HTML files (e.g. \".xhtml\").\n#html_file_suffix = '.htm'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'coveragepydoc'\n\n# -- Spelling ---\n\nif any(\"spell\" in arg for arg in sys.argv):\n    # sphinxcontrib.spelling needs the native \"enchant\" library, which often is\n    # missing, so only use the extension if we are specifically spell-checking.\n    extensions += ['sphinxcontrib.spelling']\n    names_file = tempfile.NamedTemporaryFile(mode='w', prefix=\"coverage_names_\", suffix=\".txt\")\n    with open(\"../CONTRIBUTORS.txt\") as contributors:\n        names = set(re.split(r\"[^\\w']\", contributors.read()))\n        names = [n for n in names if len(n) >= 2 and n[0].isupper()]\n        names_file.write(\"\\n\".join(names))\n        names_file.flush()\n    atexit.register(os.remove, names_file.name)\n\n    spelling_word_list_filename = ['dict.txt', names_file.name]\n    spelling_show_suggestions = False\n\n\n# Regexes for URLs that linkcheck should skip.\nlinkcheck_ignore = [\n    # We have lots of links to GitHub, and they start refusing to serve them to linkcheck,\n    # so don't bother checking them.\n    r\"https://github.com/nedbat/coveragepy/(issues|pull)/\\d+\",\n    # When publishing a new version, the docs will refer to the version before\n    # the docs have been published.  So don't check those links.\n    fr\"https://coverage.readthedocs.io/en/{release}$\",\n]\n\n# https://github.com/executablebooks/sphinx-tabs/pull/54\nsphinx_tabs_valid_builders = ['linkcheck']\n\n# When auto-doc'ing a class, only write the class' docstring into the class docs,\n# don't automatically include the __init__ docstring.\nautoclass_content = \"class\"\n\nprerelease = bool(max(release).isalpha())\n\ndef setup(app):\n    \"\"\"Configure Sphinx\"\"\"\n    app.add_css_file('coverage.css')\n    app.add_config_value('prerelease', False, 'env')\n    print(\"** Prerelease = %r\" % prerelease)\n", "coverage/debug.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Control of and utilities for debugging.\"\"\"\n\nfrom __future__ import annotations\n\nimport atexit\nimport contextlib\nimport functools\nimport inspect\nimport itertools\nimport os\nimport pprint\nimport re\nimport reprlib\nimport sys\nimport traceback\nimport types\nimport _thread\n\nfrom typing import (\n    overload,\n    Any, Callable, IO, Iterable, Iterator, Mapping,\n)\n\nfrom coverage.misc import human_sorted_items, isolate_module\nfrom coverage.types import AnyCallable, TWritable\n\nos = isolate_module(os)\n\n\n# When debugging, it can be helpful to force some options, especially when\n# debugging the configuration mechanisms you usually use to control debugging!\n# This is a list of forced debugging options.\nFORCED_DEBUG: list[str] = []\nFORCED_DEBUG_FILE = None\n\n\nclass DebugControl:\n    \"\"\"Control and output for debugging.\"\"\"\n\n    show_repr_attr = False      # For auto_repr\n\n    def __init__(\n        self,\n        options: Iterable[str],\n        output: IO[str] | None,\n        file_name: str | None = None,\n    ) -> None:\n        \"\"\"Configure the options and output file for debugging.\"\"\"\n        self.options = list(options) + FORCED_DEBUG\n        self.suppress_callers = False\n\n        filters = []\n        if self.should(\"process\"):\n            filters.append(CwdTracker().filter)\n            filters.append(ProcessTracker().filter)\n        if self.should(\"pytest\"):\n            filters.append(PytestTracker().filter)\n        if self.should(\"pid\"):\n            filters.append(add_pid_and_tid)\n\n        self.output = DebugOutputFile.get_one(\n            output,\n            file_name=file_name,\n            filters=filters,\n        )\n        self.raw_output = self.output.outfile\n\n    def __repr__(self) -> str:\n        return f\"<DebugControl options={self.options!r} raw_output={self.raw_output!r}>\"\n\n    def should(self, option: str) -> bool:\n        \"\"\"Decide whether to output debug information in category `option`.\"\"\"\n        if option == \"callers\" and self.suppress_callers:\n            return False\n        return (option in self.options)\n\n    @contextlib.contextmanager\n    def without_callers(self) -> Iterator[None]:\n        \"\"\"A context manager to prevent call stacks from being logged.\"\"\"\n        old = self.suppress_callers\n        self.suppress_callers = True\n        try:\n            yield\n        finally:\n            self.suppress_callers = old\n\n    def write(self, msg: str, *, exc: BaseException | None = None) -> None:\n        \"\"\"Write a line of debug output.\n\n        `msg` is the line to write. A newline will be appended.\n\n        If `exc` is provided, a stack trace of the exception will be written\n        after the message.\n\n        \"\"\"\n        self.output.write(msg + \"\\n\")\n        if exc is not None:\n            self.output.write(\"\".join(traceback.format_exception(None, exc, exc.__traceback__)))\n        if self.should(\"self\"):\n            caller_self = inspect.stack()[1][0].f_locals.get(\"self\")\n            if caller_self is not None:\n                self.output.write(f\"self: {caller_self!r}\\n\")\n        if self.should(\"callers\"):\n            dump_stack_frames(out=self.output, skip=1)\n        self.output.flush()\n\n\nclass NoDebugging(DebugControl):\n    \"\"\"A replacement for DebugControl that will never try to do anything.\"\"\"\n    def __init__(self) -> None:\n        # pylint: disable=super-init-not-called\n        ...\n\n    def should(self, option: str) -> bool:\n        \"\"\"Should we write debug messages?  Never.\"\"\"\n        return False\n\n    def write(self, msg: str, *, exc: BaseException | None = None) -> None:\n        \"\"\"This will never be called.\"\"\"\n        raise AssertionError(\"NoDebugging.write should never be called.\")\n\n\ndef info_header(label: str) -> str:\n    \"\"\"Make a nice header string.\"\"\"\n    return \"--{:-<60s}\".format(\" \"+label+\" \")\n\n\ndef info_formatter(info: Iterable[tuple[str, Any]]) -> Iterator[str]:\n    \"\"\"Produce a sequence of formatted lines from info.\n\n    `info` is a sequence of pairs (label, data).  The produced lines are\n    nicely formatted, ready to print.\n\n    \"\"\"\n    info = list(info)\n    if not info:\n        return\n    label_len = 30\n    assert all(len(l) < label_len for l, _ in info)\n    for label, data in info:\n        if data == []:\n            data = \"-none-\"\n        if isinstance(data, tuple) and len(repr(tuple(data))) < 30:\n            # Convert to tuple to scrub namedtuples.\n            yield \"%*s: %r\" % (label_len, label, tuple(data))\n        elif isinstance(data, (list, set, tuple)):\n            prefix = \"%*s:\" % (label_len, label)\n            for e in data:\n                yield \"%*s %s\" % (label_len+1, prefix, e)\n                prefix = \"\"\n        else:\n            yield \"%*s: %s\" % (label_len, label, data)\n\n\ndef write_formatted_info(\n    write: Callable[[str], None],\n    header: str,\n    info: Iterable[tuple[str, Any]],\n) -> None:\n    \"\"\"Write a sequence of (label,data) pairs nicely.\n\n    `write` is a function write(str) that accepts each line of output.\n    `header` is a string to start the section.  `info` is a sequence of\n    (label, data) pairs, where label is a str, and data can be a single\n    value, or a list/set/tuple.\n\n    \"\"\"\n    write(info_header(header))\n    for line in info_formatter(info):\n        write(f\" {line}\")\n\n\ndef exc_one_line(exc: Exception) -> str:\n    \"\"\"Get a one-line summary of an exception, including class name and message.\"\"\"\n    lines = traceback.format_exception_only(type(exc), exc)\n    return \"|\".join(l.rstrip() for l in lines)\n\n\n_FILENAME_REGEXES: list[tuple[str, str]] = [\n    (r\".*[/\\\\]pytest-of-.*[/\\\\]pytest-\\d+([/\\\\]popen-gw\\d+)?\", \"tmp:\"),\n]\n_FILENAME_SUBS: list[tuple[str, str]] = []\n\n@overload\ndef short_filename(filename: str) -> str:\n    pass\n\n@overload\ndef short_filename(filename: None) -> None:\n    pass\n\ndef short_filename(filename: str | None) -> str | None:\n    \"\"\"Shorten a file name. Directories are replaced by prefixes like 'syspath:'\"\"\"\n    if not _FILENAME_SUBS:\n        for pathdir in sys.path:\n            _FILENAME_SUBS.append((pathdir, \"syspath:\"))\n        import coverage\n        _FILENAME_SUBS.append((os.path.dirname(coverage.__file__), \"cov:\"))\n        _FILENAME_SUBS.sort(key=(lambda pair: len(pair[0])), reverse=True)\n    if filename is not None:\n        for pat, sub in _FILENAME_REGEXES:\n            filename = re.sub(pat, sub, filename)\n        for before, after in _FILENAME_SUBS:\n            filename = filename.replace(before, after)\n    return filename\n\n\ndef short_stack(\n    skip: int = 0,\n    full: bool = False,\n    frame_ids: bool = False,\n    short_filenames: bool = False,\n) -> str:\n    \"\"\"Return a string summarizing the call stack.\n\n    The string is multi-line, with one line per stack frame. Each line shows\n    the function name, the file name, and the line number:\n\n        ...\n        start_import_stop : /Users/ned/coverage/trunk/tests/coveragetest.py:95\n        import_local_file : /Users/ned/coverage/trunk/tests/coveragetest.py:81\n        import_local_file : /Users/ned/coverage/trunk/coverage/backward.py:159\n        ...\n\n    `skip` is the number of closest immediate frames to skip, so that debugging\n    functions can call this and not be included in the result.\n\n    If `full` is true, then include all frames.  Otherwise, initial \"boring\"\n    frames (ones in site-packages and earlier) are omitted.\n\n    `short_filenames` will shorten filenames using `short_filename`, to reduce\n    the amount of repetitive noise in stack traces.\n\n    \"\"\"\n    # Regexes in initial frames that we don't care about.\n    BORING_PRELUDE = [\n        \"<string>\",             # pytest-xdist has string execution.\n        r\"\\bigor.py$\",          # Our test runner.\n        r\"\\bsite-packages\\b\",   # pytest etc getting to our tests.\n    ]\n\n    stack: Iterable[inspect.FrameInfo] = inspect.stack()[:skip:-1]\n    if not full:\n        for pat in BORING_PRELUDE:\n            stack = itertools.dropwhile(\n                (lambda fi, pat=pat: re.search(pat, fi.filename)),  # type: ignore[misc]\n                stack,\n            )\n    lines = []\n    for frame_info in stack:\n        line = f\"{frame_info.function:>30s} : \"\n        if frame_ids:\n            line += f\"{id(frame_info.frame):#x} \"\n        filename = frame_info.filename\n        if short_filenames:\n            filename = short_filename(filename)\n        line += f\"{filename}:{frame_info.lineno}\"\n        lines.append(line)\n    return \"\\n\".join(lines)\n\n\ndef dump_stack_frames(out: TWritable, skip: int = 0) -> None:\n    \"\"\"Print a summary of the stack to `out`.\"\"\"\n    out.write(short_stack(skip=skip+1) + \"\\n\")\n\n\ndef clipped_repr(text: str, numchars: int = 50) -> str:\n    \"\"\"`repr(text)`, but limited to `numchars`.\"\"\"\n    r = reprlib.Repr()\n    r.maxstring = numchars\n    return r.repr(text)\n\n\ndef short_id(id64: int) -> int:\n    \"\"\"Given a 64-bit id, make a shorter 16-bit one.\"\"\"\n    id16 = 0\n    for offset in range(0, 64, 16):\n        id16 ^= id64 >> offset\n    return id16 & 0xFFFF\n\n\ndef add_pid_and_tid(text: str) -> str:\n    \"\"\"A filter to add pid and tid to debug messages.\"\"\"\n    # Thread ids are useful, but too long. Make a shorter one.\n    tid = f\"{short_id(_thread.get_ident()):04x}\"\n    text = f\"{os.getpid():5d}.{tid}: {text}\"\n    return text\n\n\nAUTO_REPR_IGNORE = {\"$coverage.object_id\"}\n\ndef auto_repr(self: Any) -> str:\n    \"\"\"A function implementing an automatic __repr__ for debugging.\"\"\"\n    show_attrs = (\n        (k, v) for k, v in self.__dict__.items()\n        if getattr(v, \"show_repr_attr\", True)\n        and not inspect.ismethod(v)\n        and k not in AUTO_REPR_IGNORE\n    )\n    return \"<{klass} @{id:#x}{attrs}>\".format(\n        klass=self.__class__.__name__,\n        id=id(self),\n        attrs=\"\".join(f\" {k}={v!r}\" for k, v in show_attrs),\n    )\n\n\ndef simplify(v: Any) -> Any:                                # pragma: debugging\n    \"\"\"Turn things which are nearly dict/list/etc into dict/list/etc.\"\"\"\n    if isinstance(v, dict):\n        return {k:simplify(vv) for k, vv in v.items()}\n    elif isinstance(v, (list, tuple)):\n        return type(v)(simplify(vv) for vv in v)\n    elif hasattr(v, \"__dict__\"):\n        return simplify({\".\"+k: v for k, v in v.__dict__.items()})\n    else:\n        return v\n\n\ndef pp(v: Any) -> None:                                     # pragma: debugging\n    \"\"\"Debug helper to pretty-print data, including SimpleNamespace objects.\"\"\"\n    # Might not be needed in 3.9+\n    pprint.pprint(simplify(v))\n\n\ndef filter_text(text: str, filters: Iterable[Callable[[str], str]]) -> str:\n    \"\"\"Run `text` through a series of filters.\n\n    `filters` is a list of functions. Each takes a string and returns a\n    string.  Each is run in turn. After each filter, the text is split into\n    lines, and each line is passed through the next filter.\n\n    Returns: the final string that results after all of the filters have\n    run.\n\n    \"\"\"\n    clean_text = text.rstrip()\n    ending = text[len(clean_text):]\n    text = clean_text\n    for filter_fn in filters:\n        lines = []\n        for line in text.splitlines():\n            lines.extend(filter_fn(line).splitlines())\n        text = \"\\n\".join(lines)\n    return text + ending\n\n\nclass CwdTracker:\n    \"\"\"A class to add cwd info to debug messages.\"\"\"\n    def __init__(self) -> None:\n        self.cwd: str | None = None\n\n    def filter(self, text: str) -> str:\n        \"\"\"Add a cwd message for each new cwd.\"\"\"\n        cwd = os.getcwd()\n        if cwd != self.cwd:\n            text = f\"cwd is now {cwd!r}\\n\" + text\n            self.cwd = cwd\n        return text\n\n\nclass ProcessTracker:\n    \"\"\"Track process creation for debug logging.\"\"\"\n    def __init__(self) -> None:\n        self.pid: int = os.getpid()\n        self.did_welcome = False\n\n    def filter(self, text: str) -> str:\n        \"\"\"Add a message about how new processes came to be.\"\"\"\n        welcome = \"\"\n        pid = os.getpid()\n        if self.pid != pid:\n            welcome = f\"New process: forked {self.pid} -> {pid}\\n\"\n            self.pid = pid\n        elif not self.did_welcome:\n            argv = getattr(sys, \"argv\", None)\n            welcome = (\n                f\"New process: {pid=}, executable: {sys.executable!r}\\n\"\n                + f\"New process: cmd: {argv!r}\\n\"\n            )\n            if hasattr(os, \"getppid\"):\n                welcome += f\"New process parent pid: {os.getppid()!r}\\n\"\n\n        if welcome:\n            self.did_welcome = True\n            return welcome + text\n        else:\n            return text\n\n\nclass PytestTracker:\n    \"\"\"Track the current pytest test name to add to debug messages.\"\"\"\n    def __init__(self) -> None:\n        self.test_name: str | None = None\n\n    def filter(self, text: str) -> str:\n        \"\"\"Add a message when the pytest test changes.\"\"\"\n        test_name = os.getenv(\"PYTEST_CURRENT_TEST\")\n        if test_name != self.test_name:\n            text = f\"Pytest context: {test_name}\\n\" + text\n            self.test_name = test_name\n        return text\n\n\nclass DebugOutputFile:\n    \"\"\"A file-like object that includes pid and cwd information.\"\"\"\n    def __init__(\n        self,\n        outfile: IO[str] | None,\n        filters: Iterable[Callable[[str], str]],\n    ):\n        self.outfile = outfile\n        self.filters = list(filters)\n        self.pid = os.getpid()\n\n    @classmethod\n    def get_one(\n        cls,\n        fileobj: IO[str] | None = None,\n        file_name: str | None = None,\n        filters: Iterable[Callable[[str], str]] = (),\n        interim: bool = False,\n    ) -> DebugOutputFile:\n        \"\"\"Get a DebugOutputFile.\n\n        If `fileobj` is provided, then a new DebugOutputFile is made with it.\n\n        If `fileobj` isn't provided, then a file is chosen (`file_name` if\n        provided, or COVERAGE_DEBUG_FILE, or stderr), and a process-wide\n        singleton DebugOutputFile is made.\n\n        `filters` are the text filters to apply to the stream to annotate with\n        pids, etc.\n\n        If `interim` is true, then a future `get_one` can replace this one.\n\n        \"\"\"\n        if fileobj is not None:\n            # Make DebugOutputFile around the fileobj passed.\n            return cls(fileobj, filters)\n\n        the_one, is_interim = cls._get_singleton_data()\n        if the_one is None or is_interim:\n            if file_name is not None:\n                fileobj = open(file_name, \"a\", encoding=\"utf-8\")\n            else:\n                # $set_env.py: COVERAGE_DEBUG_FILE - Where to write debug output\n                file_name = os.getenv(\"COVERAGE_DEBUG_FILE\", FORCED_DEBUG_FILE)\n                if file_name in (\"stdout\", \"stderr\"):\n                    fileobj = getattr(sys, file_name)\n                elif file_name:\n                    fileobj = open(file_name, \"a\", encoding=\"utf-8\")\n                    atexit.register(fileobj.close)\n                else:\n                    fileobj = sys.stderr\n            the_one = cls(fileobj, filters)\n            cls._set_singleton_data(the_one, interim)\n\n        if not(the_one.filters):\n            the_one.filters = list(filters)\n        return the_one\n\n    # Because of the way igor.py deletes and re-imports modules,\n    # this class can be defined more than once. But we really want\n    # a process-wide singleton. So stash it in sys.modules instead of\n    # on a class attribute. Yes, this is aggressively gross.\n\n    SYS_MOD_NAME = \"$coverage.debug.DebugOutputFile.the_one\"\n    SINGLETON_ATTR = \"the_one_and_is_interim\"\n\n    @classmethod\n    def _set_singleton_data(cls, the_one: DebugOutputFile, interim: bool) -> None:\n        \"\"\"Set the one DebugOutputFile to rule them all.\"\"\"\n        singleton_module = types.ModuleType(cls.SYS_MOD_NAME)\n        setattr(singleton_module, cls.SINGLETON_ATTR, (the_one, interim))\n        sys.modules[cls.SYS_MOD_NAME] = singleton_module\n\n    @classmethod\n    def _get_singleton_data(cls) -> tuple[DebugOutputFile | None, bool]:\n        \"\"\"Get the one DebugOutputFile.\"\"\"\n        singleton_module = sys.modules.get(cls.SYS_MOD_NAME)\n        return getattr(singleton_module, cls.SINGLETON_ATTR, (None, True))\n\n    @classmethod\n    def _del_singleton_data(cls) -> None:\n        \"\"\"Delete the one DebugOutputFile, just for tests to use.\"\"\"\n        if cls.SYS_MOD_NAME in sys.modules:\n            del sys.modules[cls.SYS_MOD_NAME]\n\n    def write(self, text: str) -> None:\n        \"\"\"Just like file.write, but filter through all our filters.\"\"\"\n        assert self.outfile is not None\n        self.outfile.write(filter_text(text, self.filters))\n        self.outfile.flush()\n\n    def flush(self) -> None:\n        \"\"\"Flush our file.\"\"\"\n        assert self.outfile is not None\n        self.outfile.flush()\n\n\ndef log(msg: str, stack: bool = False) -> None:             # pragma: debugging\n    \"\"\"Write a log message as forcefully as possible.\"\"\"\n    out = DebugOutputFile.get_one(interim=True)\n    out.write(msg+\"\\n\")\n    if stack:\n        dump_stack_frames(out=out, skip=1)\n\n\ndef decorate_methods(\n    decorator: Callable[..., Any],\n    butnot: Iterable[str] = (),\n    private: bool = False,\n) -> Callable[..., Any]:                                    # pragma: debugging\n    \"\"\"A class decorator to apply a decorator to methods.\"\"\"\n    def _decorator(cls):                                    # type: ignore[no-untyped-def]\n        for name, meth in inspect.getmembers(cls, inspect.isroutine):\n            if name not in cls.__dict__:\n                continue\n            if name != \"__init__\":\n                if not private and name.startswith(\"_\"):\n                    continue\n            if name in butnot:\n                continue\n            setattr(cls, name, decorator(meth))\n        return cls\n    return _decorator\n\n\ndef break_in_pudb(func: AnyCallable) -> AnyCallable:  # pragma: debugging\n    \"\"\"A function decorator to stop in the debugger for each call.\"\"\"\n    @functools.wraps(func)\n    def _wrapper(*args: Any, **kwargs: Any) -> Any:\n        import pudb\n        sys.stdout = sys.__stdout__\n        pudb.set_trace()\n        return func(*args, **kwargs)\n    return _wrapper\n\n\nOBJ_IDS = itertools.count()\nCALLS = itertools.count()\nOBJ_ID_ATTR = \"$coverage.object_id\"\n\ndef show_calls(\n    show_args: bool = True,\n    show_stack: bool = False,\n    show_return: bool = False,\n) -> Callable[..., Any]:                                    # pragma: debugging\n    \"\"\"A method decorator to debug-log each call to the function.\"\"\"\n    def _decorator(func: AnyCallable) -> AnyCallable:\n        @functools.wraps(func)\n        def _wrapper(self: Any, *args: Any, **kwargs: Any) -> Any:\n            oid = getattr(self, OBJ_ID_ATTR, None)\n            if oid is None:\n                oid = f\"{os.getpid():08d} {next(OBJ_IDS):04d}\"\n                setattr(self, OBJ_ID_ATTR, oid)\n            extra = \"\"\n            if show_args:\n                eargs = \", \".join(map(repr, args))\n                ekwargs = \", \".join(\"{}={!r}\".format(*item) for item in kwargs.items())\n                extra += \"(\"\n                extra += eargs\n                if eargs and ekwargs:\n                    extra += \", \"\n                extra += ekwargs\n                extra += \")\"\n            if show_stack:\n                extra += \" @ \"\n                extra += \"; \".join(short_stack(short_filenames=True).splitlines())\n            callid = next(CALLS)\n            msg = f\"{oid} {callid:04d} {func.__name__}{extra}\\n\"\n            DebugOutputFile.get_one(interim=True).write(msg)\n            ret = func(self, *args, **kwargs)\n            if show_return:\n                msg = f\"{oid} {callid:04d} {func.__name__} return {ret!r}\\n\"\n                DebugOutputFile.get_one(interim=True).write(msg)\n            return ret\n        return _wrapper\n    return _decorator\n\n\ndef relevant_environment_display(env: Mapping[str, str]) -> list[tuple[str, str]]:\n    \"\"\"Filter environment variables for a debug display.\n\n    Select variables to display (with COV or PY in the name, or HOME, TEMP, or\n    TMP), and also cloak sensitive values with asterisks.\n\n    Arguments:\n        env: a dict of environment variable names and values.\n\n    Returns:\n        A list of pairs (name, value) to show.\n\n    \"\"\"\n    slugs = {\"COV\", \"PY\"}\n    include = {\"HOME\", \"TEMP\", \"TMP\"}\n    cloak = {\"API\", \"TOKEN\", \"KEY\", \"SECRET\", \"PASS\", \"SIGNATURE\"}\n\n    to_show = []\n    for name, val in env.items():\n        keep = False\n        if name in include:\n            keep = True\n        elif any(slug in name for slug in slugs):\n            keep = True\n        if keep:\n            if any(slug in name for slug in cloak):\n                val = re.sub(r\"\\w\", \"*\", val)\n            to_show.append((name, val))\n    return human_sorted_items(to_show)\n", "coverage/plugin.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\n.. versionadded:: 4.0\n\nPlug-in interfaces for coverage.py.\n\nCoverage.py supports a few different kinds of plug-ins that change its\nbehavior:\n\n* File tracers implement tracing of non-Python file types.\n\n* Configurers add custom configuration, using Python code to change the\n  configuration.\n\n* Dynamic context switchers decide when the dynamic context has changed, for\n  example, to record what test function produced the coverage.\n\nTo write a coverage.py plug-in, create a module with a subclass of\n:class:`~coverage.CoveragePlugin`.  You will override methods in your class to\nparticipate in various aspects of coverage.py's processing.\nDifferent types of plug-ins have to override different methods.\n\nAny plug-in can optionally implement :meth:`~coverage.CoveragePlugin.sys_info`\nto provide debugging information about their operation.\n\nYour module must also contain a ``coverage_init`` function that registers an\ninstance of your plug-in class::\n\n    import coverage\n\n    class MyPlugin(coverage.CoveragePlugin):\n        ...\n\n    def coverage_init(reg, options):\n        reg.add_file_tracer(MyPlugin())\n\nYou use the `reg` parameter passed to your ``coverage_init`` function to\nregister your plug-in object.  The registration method you call depends on\nwhat kind of plug-in it is.\n\nIf your plug-in takes options, the `options` parameter is a dictionary of your\nplug-in's options from the coverage.py configuration file.  Use them however\nyou want to configure your object before registering it.\n\nCoverage.py will store its own information on your plug-in object, using\nattributes whose names start with ``_coverage_``.  Don't be startled.\n\n.. warning::\n    Plug-ins are imported by coverage.py before it begins measuring code.\n    If you write a plugin in your own project, it might import your product\n    code before coverage.py can start measuring.  This can result in your\n    own code being reported as missing.\n\n    One solution is to put your plugins in your project tree, but not in\n    your importable Python package.\n\n\n.. _file_tracer_plugins:\n\nFile Tracers\n============\n\nFile tracers implement measurement support for non-Python files.  File tracers\nimplement the :meth:`~coverage.CoveragePlugin.file_tracer` method to claim\nfiles and the :meth:`~coverage.CoveragePlugin.file_reporter` method to report\non those files.\n\nIn your ``coverage_init`` function, use the ``add_file_tracer`` method to\nregister your file tracer.\n\n\n.. _configurer_plugins:\n\nConfigurers\n===========\n\n.. versionadded:: 4.5\n\nConfigurers modify the configuration of coverage.py during start-up.\nConfigurers implement the :meth:`~coverage.CoveragePlugin.configure` method to\nchange the configuration.\n\nIn your ``coverage_init`` function, use the ``add_configurer`` method to\nregister your configurer.\n\n\n.. _dynamic_context_plugins:\n\nDynamic Context Switchers\n=========================\n\n.. versionadded:: 5.0\n\nDynamic context switcher plugins implement the\n:meth:`~coverage.CoveragePlugin.dynamic_context` method to dynamically compute\nthe context label for each measured frame.\n\nComputed context labels are useful when you want to group measured data without\nmodifying the source code.\n\nFor example, you could write a plugin that checks `frame.f_code` to inspect\nthe currently executed method, and set the context label to a fully qualified\nmethod name if it's an instance method of `unittest.TestCase` and the method\nname starts with 'test'.  Such a plugin would provide basic coverage grouping\nby test and could be used with test runners that have no built-in coveragepy\nsupport.\n\nIn your ``coverage_init`` function, use the ``add_dynamic_context`` method to\nregister your dynamic context switcher.\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport dataclasses\nimport functools\n\nfrom types import FrameType\nfrom typing import Any, Iterable\n\nfrom coverage import files\nfrom coverage.misc import _needs_to_implement\nfrom coverage.types import TArc, TConfigurable, TLineNo, TSourceTokenLines\n\n\nclass CoveragePlugin:\n    \"\"\"Base class for coverage.py plug-ins.\"\"\"\n\n    _coverage_plugin_name: str\n    _coverage_enabled: bool\n\n    def file_tracer(self, filename: str) -> FileTracer | None: # pylint: disable=unused-argument\n        \"\"\"Get a :class:`FileTracer` object for a file.\n\n        Plug-in type: file tracer.\n\n        Every Python source file is offered to your plug-in to give it a chance\n        to take responsibility for tracing the file.  If your plug-in can\n        handle the file, it should return a :class:`FileTracer` object.\n        Otherwise return None.\n\n        There is no way to register your plug-in for particular files.\n        Instead, this method is invoked for all  files as they are executed,\n        and the plug-in decides whether it can trace the file or not.\n        Be prepared for `filename` to refer to all kinds of files that have\n        nothing to do with your plug-in.\n\n        The file name will be a Python file being executed.  There are two\n        broad categories of behavior for a plug-in, depending on the kind of\n        files your plug-in supports:\n\n        * Static file names: each of your original source files has been\n          converted into a distinct Python file.  Your plug-in is invoked with\n          the Python file name, and it maps it back to its original source\n          file.\n\n        * Dynamic file names: all of your source files are executed by the same\n          Python file.  In this case, your plug-in implements\n          :meth:`FileTracer.dynamic_source_filename` to provide the actual\n          source file for each execution frame.\n\n        `filename` is a string, the path to the file being considered.  This is\n        the absolute real path to the file.  If you are comparing to other\n        paths, be sure to take this into account.\n\n        Returns a :class:`FileTracer` object to use to trace `filename`, or\n        None if this plug-in cannot trace this file.\n\n        \"\"\"\n        return None\n\n    def file_reporter(\n        self,\n        filename: str,                  # pylint: disable=unused-argument\n    ) -> FileReporter | str:      # str should be Literal[\"python\"]\n        \"\"\"Get the :class:`FileReporter` class to use for a file.\n\n        Plug-in type: file tracer.\n\n        This will only be invoked if `filename` returns non-None from\n        :meth:`file_tracer`.  It's an error to return None from this method.\n\n        Returns a :class:`FileReporter` object to use to report on `filename`,\n        or the string `\"python\"` to have coverage.py treat the file as Python.\n\n        \"\"\"\n        _needs_to_implement(self, \"file_reporter\")\n\n    def dynamic_context(\n        self,\n        frame: FrameType,               # pylint: disable=unused-argument\n    ) -> str | None:\n        \"\"\"Get the dynamically computed context label for `frame`.\n\n        Plug-in type: dynamic context.\n\n        This method is invoked for each frame when outside of a dynamic\n        context, to see if a new dynamic context should be started.  If it\n        returns a string, a new context label is set for this and deeper\n        frames.  The dynamic context ends when this frame returns.\n\n        Returns a string to start a new dynamic context, or None if no new\n        context should be started.\n\n        \"\"\"\n        return None\n\n    def find_executable_files(\n        self,\n        src_dir: str,                   # pylint: disable=unused-argument\n    ) -> Iterable[str]:\n        \"\"\"Yield all of the executable files in `src_dir`, recursively.\n\n        Plug-in type: file tracer.\n\n        Executability is a plug-in-specific property, but generally means files\n        which would have been considered for coverage analysis, had they been\n        included automatically.\n\n        Returns or yields a sequence of strings, the paths to files that could\n        have been executed, including files that had been executed.\n\n        \"\"\"\n        return []\n\n    def configure(self, config: TConfigurable) -> None:\n        \"\"\"Modify the configuration of coverage.py.\n\n        Plug-in type: configurer.\n\n        This method is called during coverage.py start-up, to give your plug-in\n        a chance to change the configuration.  The `config` parameter is an\n        object with :meth:`~coverage.Coverage.get_option` and\n        :meth:`~coverage.Coverage.set_option` methods.  Do not call any other\n        methods on the `config` object.\n\n        \"\"\"\n        pass\n\n    def sys_info(self) -> Iterable[tuple[str, Any]]:\n        \"\"\"Get a list of information useful for debugging.\n\n        Plug-in type: any.\n\n        This method will be invoked for ``--debug=sys``.  Your\n        plug-in can return any information it wants to be displayed.\n\n        Returns a list of pairs: `[(name, value), ...]`.\n\n        \"\"\"\n        return []\n\n\nclass CoveragePluginBase:\n    \"\"\"Plugins produce specialized objects, which point back to the original plugin.\"\"\"\n    _coverage_plugin: CoveragePlugin\n\n\nclass FileTracer(CoveragePluginBase):\n    \"\"\"Support needed for files during the execution phase.\n\n    File tracer plug-ins implement subclasses of FileTracer to return from\n    their :meth:`~CoveragePlugin.file_tracer` method.\n\n    You may construct this object from :meth:`CoveragePlugin.file_tracer` any\n    way you like.  A natural choice would be to pass the file name given to\n    `file_tracer`.\n\n    `FileTracer` objects should only be created in the\n    :meth:`CoveragePlugin.file_tracer` method.\n\n    See :ref:`howitworks` for details of the different coverage.py phases.\n\n    \"\"\"\n\n    def source_filename(self) -> str:\n        \"\"\"The source file name for this file.\n\n        This may be any file name you like.  A key responsibility of a plug-in\n        is to own the mapping from Python execution back to whatever source\n        file name was originally the source of the code.\n\n        See :meth:`CoveragePlugin.file_tracer` for details about static and\n        dynamic file names.\n\n        Returns the file name to credit with this execution.\n\n        \"\"\"\n        _needs_to_implement(self, \"source_filename\")\n\n    def has_dynamic_source_filename(self) -> bool:\n        \"\"\"Does this FileTracer have dynamic source file names?\n\n        FileTracers can provide dynamically determined file names by\n        implementing :meth:`dynamic_source_filename`.  Invoking that function\n        is expensive. To determine whether to invoke it, coverage.py uses the\n        result of this function to know if it needs to bother invoking\n        :meth:`dynamic_source_filename`.\n\n        See :meth:`CoveragePlugin.file_tracer` for details about static and\n        dynamic file names.\n\n        Returns True if :meth:`dynamic_source_filename` should be called to get\n        dynamic source file names.\n\n        \"\"\"\n        return False\n\n    def dynamic_source_filename(\n        self,\n        filename: str,                  # pylint: disable=unused-argument\n        frame: FrameType,               # pylint: disable=unused-argument\n    ) -> str | None:\n        \"\"\"Get a dynamically computed source file name.\n\n        Some plug-ins need to compute the source file name dynamically for each\n        frame.\n\n        This function will not be invoked if\n        :meth:`has_dynamic_source_filename` returns False.\n\n        Returns the source file name for this frame, or None if this frame\n        shouldn't be measured.\n\n        \"\"\"\n        return None\n\n    def line_number_range(self, frame: FrameType) -> tuple[TLineNo, TLineNo]:\n        \"\"\"Get the range of source line numbers for a given a call frame.\n\n        The call frame is examined, and the source line number in the original\n        file is returned.  The return value is a pair of numbers, the starting\n        line number and the ending line number, both inclusive.  For example,\n        returning (5, 7) means that lines 5, 6, and 7 should be considered\n        executed.\n\n        This function might decide that the frame doesn't indicate any lines\n        from the source file were executed.  Return (-1, -1) in this case to\n        tell coverage.py that no lines should be recorded for this frame.\n\n        \"\"\"\n        lineno = frame.f_lineno\n        return lineno, lineno\n\n\n@dataclasses.dataclass\nclass CodeRegion:\n    \"\"\"Data for a region of code found by :meth:`FileReporter.code_regions`.\"\"\"\n\n    #: The kind of region, like `\"function\"` or `\"class\"`. Must be one of the\n    #: singular values returned by :meth:`FileReporter.code_region_kinds`.\n    kind: str\n\n    #: The name of the region. For example, a function or class name.\n    name: str\n\n    #: The line in the source file to link to when navigating to the region.\n    #: Can be a line not mentioned in `lines`.\n    start: int\n\n    #: The lines in the region. Should be lines that could be executed in the\n    #: region.  For example, a class region includes all of the lines in the\n    #: methods of the class, but not the lines defining class attributes, since\n    #: they are executed on import, not as part of exercising the class.  The\n    #: set can include non-executable lines like blanks and comments.\n    lines: set[int]\n\n    def __lt__(self, other: CodeRegion) -> bool:\n        \"\"\"To support sorting to make test-writing easier.\"\"\"\n        if self.name == other.name:\n            return min(self.lines) < min(other.lines)\n        return self.name < other.name\n\n\n@functools.total_ordering\nclass FileReporter(CoveragePluginBase):\n    \"\"\"Support needed for files during the analysis and reporting phases.\n\n    File tracer plug-ins implement a subclass of `FileReporter`, and return\n    instances from their :meth:`CoveragePlugin.file_reporter` method.\n\n    There are many methods here, but only :meth:`lines` is required, to provide\n    the set of executable lines in the file.\n\n    See :ref:`howitworks` for details of the different coverage.py phases.\n\n    \"\"\"\n\n    def __init__(self, filename: str) -> None:\n        \"\"\"Simple initialization of a `FileReporter`.\n\n        The `filename` argument is the path to the file being reported.  This\n        will be available as the `.filename` attribute on the object.  Other\n        method implementations on this base class rely on this attribute.\n\n        \"\"\"\n        self.filename = filename\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__.__name__} filename={self.filename!r}>\"\n\n    def relative_filename(self) -> str:\n        \"\"\"Get the relative file name for this file.\n\n        This file path will be displayed in reports.  The default\n        implementation will supply the actual project-relative file path.  You\n        only need to supply this method if you have an unusual syntax for file\n        paths.\n\n        \"\"\"\n        return files.relative_filename(self.filename)\n\n    def source(self) -> str:\n        \"\"\"Get the source for the file.\n\n        Returns a Unicode string.\n\n        The base implementation simply reads the `self.filename` file and\n        decodes it as UTF-8.  Override this method if your file isn't readable\n        as a text file, or if you need other encoding support.\n\n        \"\"\"\n        with open(self.filename, encoding=\"utf-8\") as f:\n            return f.read()\n\n    def lines(self) -> set[TLineNo]:\n        \"\"\"Get the executable lines in this file.\n\n        Your plug-in must determine which lines in the file were possibly\n        executable.  This method returns a set of those line numbers.\n\n        Returns a set of line numbers.\n\n        \"\"\"\n        _needs_to_implement(self, \"lines\")\n\n    def excluded_lines(self) -> set[TLineNo]:\n        \"\"\"Get the excluded executable lines in this file.\n\n        Your plug-in can use any method it likes to allow the user to exclude\n        executable lines from consideration.\n\n        Returns a set of line numbers.\n\n        The base implementation returns the empty set.\n\n        \"\"\"\n        return set()\n\n    def translate_lines(self, lines: Iterable[TLineNo]) -> set[TLineNo]:\n        \"\"\"Translate recorded lines into reported lines.\n\n        Some file formats will want to report lines slightly differently than\n        they are recorded.  For example, Python records the last line of a\n        multi-line statement, but reports are nicer if they mention the first\n        line.\n\n        Your plug-in can optionally define this method to perform these kinds\n        of adjustment.\n\n        `lines` is a sequence of integers, the recorded line numbers.\n\n        Returns a set of integers, the adjusted line numbers.\n\n        The base implementation returns the numbers unchanged.\n\n        \"\"\"\n        return set(lines)\n\n    def arcs(self) -> set[TArc]:\n        \"\"\"Get the executable arcs in this file.\n\n        To support branch coverage, your plug-in needs to be able to indicate\n        possible execution paths, as a set of line number pairs.  Each pair is\n        a `(prev, next)` pair indicating that execution can transition from the\n        `prev` line number to the `next` line number.\n\n        Returns a set of pairs of line numbers.  The default implementation\n        returns an empty set.\n\n        \"\"\"\n        return set()\n\n    def no_branch_lines(self) -> set[TLineNo]:\n        \"\"\"Get the lines excused from branch coverage in this file.\n\n        Your plug-in can use any method it likes to allow the user to exclude\n        lines from consideration of branch coverage.\n\n        Returns a set of line numbers.\n\n        The base implementation returns the empty set.\n\n        \"\"\"\n        return set()\n\n    def translate_arcs(self, arcs: Iterable[TArc]) -> set[TArc]:\n        \"\"\"Translate recorded arcs into reported arcs.\n\n        Similar to :meth:`translate_lines`, but for arcs.  `arcs` is a set of\n        line number pairs.\n\n        Returns a set of line number pairs.\n\n        The default implementation returns `arcs` unchanged.\n\n        \"\"\"\n        return set(arcs)\n\n    def exit_counts(self) -> dict[TLineNo, int]:\n        \"\"\"Get a count of exits from that each line.\n\n        To determine which lines are branches, coverage.py looks for lines that\n        have more than one exit.  This function creates a dict mapping each\n        executable line number to a count of how many exits it has.\n\n        To be honest, this feels wrong, and should be refactored.  Let me know\n        if you attempt to implement this method in your plug-in...\n\n        \"\"\"\n        return {}\n\n    def missing_arc_description(\n        self,\n        start: TLineNo,\n        end: TLineNo,\n        executed_arcs: Iterable[TArc] | None = None,     # pylint: disable=unused-argument\n    ) -> str:\n        \"\"\"Provide an English sentence describing a missing arc.\n\n        The `start` and `end` arguments are the line numbers of the missing\n        arc. Negative numbers indicate entering or exiting code objects.\n\n        The `executed_arcs` argument is a set of line number pairs, the arcs\n        that were executed in this file.\n\n        By default, this simply returns the string \"Line {start} didn't jump\n        to {end}\".\n\n        \"\"\"\n        return f\"Line {start} didn't jump to line {end}\"\n\n    def source_token_lines(self) -> TSourceTokenLines:\n        \"\"\"Generate a series of tokenized lines, one for each line in `source`.\n\n        These tokens are used for syntax-colored reports.\n\n        Each line is a list of pairs, each pair is a token::\n\n            [(\"key\", \"def\"), (\"ws\", \" \"), (\"nam\", \"hello\"), (\"op\", \"(\"), ... ]\n\n        Each pair has a token class, and the token text.  The token classes\n        are:\n\n        * ``\"com\"``: a comment\n        * ``\"key\"``: a keyword\n        * ``\"nam\"``: a name, or identifier\n        * ``\"num\"``: a number\n        * ``\"op\"``: an operator\n        * ``\"str\"``: a string literal\n        * ``\"ws\"``: some white space\n        * ``\"txt\"``: some other kind of text\n\n        If you concatenate all the token texts, and then join them with\n        newlines, you should have your original source back.\n\n        The default implementation simply returns each line tagged as\n        ``\"txt\"``.\n\n        \"\"\"\n        for line in self.source().splitlines():\n            yield [(\"txt\", line)]\n\n    def code_regions(self) -> Iterable[CodeRegion]:\n        \"\"\"Identify regions in the source file for finer reporting than by file.\n\n        Returns an iterable of :class:`CodeRegion` objects.  The kinds reported\n        should be in the possibilities returned by :meth:`code_region_kinds`.\n\n        \"\"\"\n        return []\n\n    def code_region_kinds(self) -> Iterable[tuple[str, str]]:\n        \"\"\"Return the kinds of code regions this plugin can find.\n\n        The returned pairs are the singular and plural forms of the kinds::\n\n            [\n                (\"function\", \"functions\"),\n                (\"class\", \"classes\"),\n            ]\n\n        This will usually be hard-coded, but could also differ by the specific\n        source file involved.\n\n        \"\"\"\n        return []\n\n    def __eq__(self, other: Any) -> bool:\n        return isinstance(other, FileReporter) and self.filename == other.filename\n\n    def __lt__(self, other: Any) -> bool:\n        return isinstance(other, FileReporter) and self.filename < other.filename\n\n    # This object doesn't need to be hashed.\n    __hash__ = None         # type: ignore[assignment]\n", "coverage/sqlitedb.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"SQLite abstraction for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nimport contextlib\nimport re\nimport sqlite3\n\nfrom typing import cast, Any, Iterable, Iterator, Tuple\n\nfrom coverage.debug import auto_repr, clipped_repr, exc_one_line\nfrom coverage.exceptions import DataError\nfrom coverage.types import TDebugCtl\n\n\nclass SqliteDb:\n    \"\"\"A simple abstraction over a SQLite database.\n\n    Use as a context manager, then you can use it like a\n    :class:`python:sqlite3.Connection` object::\n\n        with SqliteDb(filename, debug_control) as db:\n            with db.execute(\"select a, b from some_table\") as cur:\n                for a, b in cur:\n                    etc(a, b)\n\n    \"\"\"\n    def __init__(self, filename: str, debug: TDebugCtl) -> None:\n        self.debug = debug\n        self.filename = filename\n        self.nest = 0\n        self.con: sqlite3.Connection | None = None\n\n    __repr__ = auto_repr\n\n    def _connect(self) -> None:\n        \"\"\"Connect to the db and do universal initialization.\"\"\"\n        if self.con is not None:\n            return\n\n        # It can happen that Python switches threads while the tracer writes\n        # data. The second thread will also try to write to the data,\n        # effectively causing a nested context. However, given the idempotent\n        # nature of the tracer operations, sharing a connection among threads\n        # is not a problem.\n        if self.debug.should(\"sql\"):\n            self.debug.write(f\"Connecting to {self.filename!r}\")\n        try:\n            self.con = sqlite3.connect(self.filename, check_same_thread=False)\n        except sqlite3.Error as exc:\n            raise DataError(f\"Couldn't use data file {self.filename!r}: {exc}\") from exc\n\n        if self.debug.should(\"sql\"):\n            self.debug.write(f\"Connected to {self.filename!r} as {self.con!r}\")\n\n        self.con.create_function(\"REGEXP\", 2, lambda txt, pat: re.search(txt, pat) is not None)\n\n        # Turning off journal_mode can speed up writing. It can't always be\n        # disabled, so we have to be prepared for *-journal files elsewhere.\n        # In Python 3.12+, we can change the config to allow journal_mode=off.\n        if hasattr(sqlite3, \"SQLITE_DBCONFIG_DEFENSIVE\"):\n            # Turn off defensive mode, so that journal_mode=off can succeed.\n            self.con.setconfig(                     # type: ignore[attr-defined, unused-ignore]\n                sqlite3.SQLITE_DBCONFIG_DEFENSIVE, False,\n            )\n\n        # This pragma makes writing faster. It disables rollbacks, but we never need them.\n        self.execute_void(\"pragma journal_mode=off\")\n\n        # This pragma makes writing faster. It can fail in unusual situations\n        # (https://github.com/nedbat/coveragepy/issues/1646), so use fail_ok=True\n        # to keep things going.\n        self.execute_void(\"pragma synchronous=off\", fail_ok=True)\n\n    def close(self) -> None:\n        \"\"\"If needed, close the connection.\"\"\"\n        if self.con is not None and self.filename != \":memory:\":\n            if self.debug.should(\"sql\"):\n                self.debug.write(f\"Closing {self.con!r} on {self.filename!r}\")\n            self.con.close()\n            self.con = None\n\n    def __enter__(self) -> SqliteDb:\n        if self.nest == 0:\n            self._connect()\n            assert self.con is not None\n            self.con.__enter__()\n        self.nest += 1\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback) -> None:     # type: ignore[no-untyped-def]\n        self.nest -= 1\n        if self.nest == 0:\n            try:\n                assert self.con is not None\n                self.con.__exit__(exc_type, exc_value, traceback)\n                self.close()\n            except Exception as exc:\n                if self.debug.should(\"sql\"):\n                    self.debug.write(f\"EXCEPTION from __exit__: {exc_one_line(exc)}\")\n                raise DataError(f\"Couldn't end data file {self.filename!r}: {exc}\") from exc\n\n    def _execute(self, sql: str, parameters: Iterable[Any]) -> sqlite3.Cursor:\n        \"\"\"Same as :meth:`python:sqlite3.Connection.execute`.\"\"\"\n        if self.debug.should(\"sql\"):\n            tail = f\" with {parameters!r}\" if parameters else \"\"\n            self.debug.write(f\"Executing {sql!r}{tail}\")\n        try:\n            assert self.con is not None\n            try:\n                return self.con.execute(sql, parameters)    # type: ignore[arg-type]\n            except Exception:\n                # In some cases, an error might happen that isn't really an\n                # error.  Try again immediately.\n                # https://github.com/nedbat/coveragepy/issues/1010\n                return self.con.execute(sql, parameters)    # type: ignore[arg-type]\n        except sqlite3.Error as exc:\n            msg = str(exc)\n            if self.filename != \":memory:\":\n                try:\n                    # `execute` is the first thing we do with the database, so try\n                    # hard to provide useful hints if something goes wrong now.\n                    with open(self.filename, \"rb\") as bad_file:\n                        cov4_sig = b\"!coverage.py: This is a private format\"\n                        if bad_file.read(len(cov4_sig)) == cov4_sig:\n                            msg = (\n                                \"Looks like a coverage 4.x data file. \" +\n                                \"Are you mixing versions of coverage?\"\n                            )\n                except Exception:\n                    pass\n            if self.debug.should(\"sql\"):\n                self.debug.write(f\"EXCEPTION from execute: {exc_one_line(exc)}\")\n            raise DataError(f\"Couldn't use data file {self.filename!r}: {msg}\") from exc\n\n    @contextlib.contextmanager\n    def execute(\n        self,\n        sql: str,\n        parameters: Iterable[Any] = (),\n    ) -> Iterator[sqlite3.Cursor]:\n        \"\"\"Context managed :meth:`python:sqlite3.Connection.execute`.\n\n        Use with a ``with`` statement to auto-close the returned cursor.\n        \"\"\"\n        cur = self._execute(sql, parameters)\n        try:\n            yield cur\n        finally:\n            cur.close()\n\n    def execute_void(self, sql: str, parameters: Iterable[Any] = (), fail_ok: bool = False) -> None:\n        \"\"\"Same as :meth:`python:sqlite3.Connection.execute` when you don't need the cursor.\n\n        If `fail_ok` is True, then SQLite errors are ignored.\n        \"\"\"\n        try:\n            # PyPy needs the .close() calls here, or sqlite gets twisted up:\n            # https://bitbucket.org/pypy/pypy/issues/2872/default-isolation-mode-is-different-on\n            self._execute(sql, parameters).close()\n        except DataError:\n            if not fail_ok:\n                raise\n\n    def execute_for_rowid(self, sql: str, parameters: Iterable[Any] = ()) -> int:\n        \"\"\"Like execute, but returns the lastrowid.\"\"\"\n        with self.execute(sql, parameters) as cur:\n            assert cur.lastrowid is not None\n            rowid: int = cur.lastrowid\n        if self.debug.should(\"sqldata\"):\n            self.debug.write(f\"Row id result: {rowid!r}\")\n        return rowid\n\n    def execute_one(self, sql: str, parameters: Iterable[Any] = ()) -> tuple[Any, ...] | None:\n        \"\"\"Execute a statement and return the one row that results.\n\n        This is like execute(sql, parameters).fetchone(), except it is\n        correct in reading the entire result set.  This will raise an\n        exception if more than one row results.\n\n        Returns a row, or None if there were no rows.\n        \"\"\"\n        with self.execute(sql, parameters) as cur:\n            rows = list(cur)\n        if len(rows) == 0:\n            return None\n        elif len(rows) == 1:\n            return cast(Tuple[Any, ...], rows[0])\n        else:\n            raise AssertionError(f\"SQL {sql!r} shouldn't return {len(rows)} rows\")\n\n    def _executemany(self, sql: str, data: list[Any]) -> sqlite3.Cursor:\n        \"\"\"Same as :meth:`python:sqlite3.Connection.executemany`.\"\"\"\n        if self.debug.should(\"sql\"):\n            final = \":\" if self.debug.should(\"sqldata\") else \"\"\n            self.debug.write(f\"Executing many {sql!r} with {len(data)} rows{final}\")\n            if self.debug.should(\"sqldata\"):\n                for i, row in enumerate(data):\n                    self.debug.write(f\"{i:4d}: {row!r}\")\n        assert self.con is not None\n        try:\n            return self.con.executemany(sql, data)\n        except Exception:\n            # In some cases, an error might happen that isn't really an\n            # error.  Try again immediately.\n            # https://github.com/nedbat/coveragepy/issues/1010\n            return self.con.executemany(sql, data)\n\n    def executemany_void(self, sql: str, data: Iterable[Any]) -> None:\n        \"\"\"Same as :meth:`python:sqlite3.Connection.executemany` when you don't need the cursor.\"\"\"\n        data = list(data)\n        if data:\n            self._executemany(sql, data).close()\n\n    def executescript(self, script: str) -> None:\n        \"\"\"Same as :meth:`python:sqlite3.Connection.executescript`.\"\"\"\n        if self.debug.should(\"sql\"):\n            self.debug.write(\"Executing script with {} chars: {}\".format(\n                len(script), clipped_repr(script, 100),\n            ))\n        assert self.con is not None\n        self.con.executescript(script).close()\n\n    def dump(self) -> str:\n        \"\"\"Return a multi-line string, the SQL dump of the database.\"\"\"\n        assert self.con is not None\n        return \"\\n\".join(self.con.iterdump())\n", "coverage/html.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"HTML reporting for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport dataclasses\nimport datetime\nimport functools\nimport json\nimport os\nimport re\nimport string\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Iterable, TYPE_CHECKING\n\nimport coverage\nfrom coverage.data import CoverageData, add_data_to_hash\nfrom coverage.exceptions import NoDataError\nfrom coverage.files import flat_rootname\nfrom coverage.misc import (\n    ensure_dir, file_be_gone, Hasher, isolate_module, format_local_datetime,\n    human_sorted, plural, stdout_link,\n)\nfrom coverage.report_core import get_analysis_to_report\nfrom coverage.results import Analysis, Numbers\nfrom coverage.templite import Templite\nfrom coverage.types import TLineNo, TMorf\nfrom coverage.version import __url__\n\n\nif TYPE_CHECKING:\n    from coverage import Coverage\n    from coverage.plugins import FileReporter\n\n\nos = isolate_module(os)\n\n\ndef data_filename(fname: str) -> str:\n    \"\"\"Return the path to an \"htmlfiles\" data file of ours.\n    \"\"\"\n    static_dir = os.path.join(os.path.dirname(__file__), \"htmlfiles\")\n    static_filename = os.path.join(static_dir, fname)\n    return static_filename\n\n\ndef read_data(fname: str) -> str:\n    \"\"\"Return the contents of a data file of ours.\"\"\"\n    with open(data_filename(fname)) as data_file:\n        return data_file.read()\n\n\ndef write_html(fname: str, html: str) -> None:\n    \"\"\"Write `html` to `fname`, properly encoded.\"\"\"\n    html = re.sub(r\"(\\A\\s+)|(\\s+$)\", \"\", html, flags=re.MULTILINE) + \"\\n\"\n    with open(fname, \"wb\") as fout:\n        fout.write(html.encode(\"ascii\", \"xmlcharrefreplace\"))\n\n\n@dataclass\nclass LineData:\n    \"\"\"The data for each source line of HTML output.\"\"\"\n    tokens: list[tuple[str, str]]\n    number: TLineNo\n    category: str\n    contexts: list[str]\n    contexts_label: str\n    context_list: list[str]\n    short_annotations: list[str]\n    long_annotations: list[str]\n    html: str = \"\"\n    context_str: str | None = None\n    annotate: str | None = None\n    annotate_long: str | None = None\n    css_class: str = \"\"\n\n\n@dataclass\nclass FileData:\n    \"\"\"The data for each source file of HTML output.\"\"\"\n    relative_filename: str\n    nums: Numbers\n    lines: list[LineData]\n\n\n@dataclass\nclass IndexItem:\n    \"\"\"Information for each index entry, to render an index page.\"\"\"\n    url: str = \"\"\n    file: str = \"\"\n    description: str = \"\"\n    nums: Numbers = field(default_factory=Numbers)\n\n\n@dataclass\nclass IndexPage:\n    \"\"\"Data for each index page.\"\"\"\n    noun: str\n    plural: str\n    filename: str\n    summaries: list[IndexItem]\n    totals: Numbers\n    skipped_covered_count: int\n    skipped_empty_count: int\n\n\nclass HtmlDataGeneration:\n    \"\"\"Generate structured data to be turned into HTML reports.\"\"\"\n\n    EMPTY = \"(empty)\"\n\n    def __init__(self, cov: Coverage) -> None:\n        self.coverage = cov\n        self.config = self.coverage.config\n        self.data = self.coverage.get_data()\n        self.has_arcs = self.data.has_arcs()\n        if self.config.show_contexts:\n            if self.data.measured_contexts() == {\"\"}:\n                self.coverage._warn(\"No contexts were measured\")\n        self.data.set_query_contexts(self.config.report_contexts)\n\n    def data_for_file(self, fr: FileReporter, analysis: Analysis) -> FileData:\n        \"\"\"Produce the data needed for one file's report.\"\"\"\n        if self.has_arcs:\n            missing_branch_arcs = analysis.missing_branch_arcs()\n            arcs_executed = analysis.arcs_executed\n        else:\n            missing_branch_arcs = {}\n            arcs_executed = []\n\n        if self.config.show_contexts:\n            contexts_by_lineno = self.data.contexts_by_lineno(analysis.filename)\n\n        lines = []\n\n        for lineno, tokens in enumerate(fr.source_token_lines(), start=1):\n            # Figure out how to mark this line.\n            category = \"\"\n            short_annotations = []\n            long_annotations = []\n\n            if lineno in analysis.excluded:\n                category = \"exc\"\n            elif lineno in analysis.missing:\n                category = \"mis\"\n            elif self.has_arcs and lineno in missing_branch_arcs:\n                category = \"par\"\n                for b in missing_branch_arcs[lineno]:\n                    if b < 0:\n                        short_annotations.append(\"exit\")\n                    else:\n                        short_annotations.append(str(b))\n                    long_annotations.append(fr.missing_arc_description(lineno, b, arcs_executed))\n            elif lineno in analysis.statements:\n                category = \"run\"\n\n            contexts = []\n            contexts_label = \"\"\n            context_list = []\n            if category and self.config.show_contexts:\n                contexts = human_sorted(c or self.EMPTY for c in contexts_by_lineno.get(lineno, ()))\n                if contexts == [self.EMPTY]:\n                    contexts_label = self.EMPTY\n                else:\n                    contexts_label = f\"{len(contexts)} ctx\"\n                    context_list = contexts\n\n            lines.append(LineData(\n                tokens=tokens,\n                number=lineno,\n                category=category,\n                contexts=contexts,\n                contexts_label=contexts_label,\n                context_list=context_list,\n                short_annotations=short_annotations,\n                long_annotations=long_annotations,\n            ))\n\n        file_data = FileData(\n            relative_filename=fr.relative_filename(),\n            nums=analysis.numbers,\n            lines=lines,\n        )\n\n        return file_data\n\n\nclass FileToReport:\n    \"\"\"A file we're considering reporting.\"\"\"\n    def __init__(self, fr: FileReporter, analysis: Analysis) -> None:\n        self.fr = fr\n        self.analysis = analysis\n        self.rootname = flat_rootname(fr.relative_filename())\n        self.html_filename = self.rootname + \".html\"\n        self.prev_html = self.next_html = \"\"\n\n\nHTML_SAFE = string.ascii_letters + string.digits + \"!#$%'()*+,-./:;=?@[]^_`{|}~\"\n\n@functools.lru_cache(maxsize=None)\ndef encode_int(n: int) -> str:\n    \"\"\"Create a short HTML-safe string from an integer, using HTML_SAFE.\"\"\"\n    if n == 0:\n        return HTML_SAFE[0]\n\n    r = []\n    while n:\n        n, t = divmod(n, len(HTML_SAFE))\n        r.append(HTML_SAFE[t])\n    return \"\".join(r)\n\n\nclass HtmlReporter:\n    \"\"\"HTML reporting.\"\"\"\n\n    # These files will be copied from the htmlfiles directory to the output\n    # directory.\n    STATIC_FILES = [\n        \"style.css\",\n        \"coverage_html.js\",\n        \"keybd_closed.png\",\n        \"favicon_32.png\",\n    ]\n\n    def __init__(self, cov: Coverage) -> None:\n        self.coverage = cov\n        self.config = self.coverage.config\n        self.directory = self.config.html_dir\n\n        self.skip_covered = self.config.html_skip_covered\n        if self.skip_covered is None:\n            self.skip_covered = self.config.skip_covered\n        self.skip_empty = self.config.html_skip_empty\n        if self.skip_empty is None:\n            self.skip_empty = self.config.skip_empty\n\n        title = self.config.html_title\n\n        self.extra_css = bool(self.config.extra_css)\n\n        self.data = self.coverage.get_data()\n        self.has_arcs = self.data.has_arcs()\n\n        self.index_pages: dict[str, IndexPage] = {\n            \"file\": self.new_index_page(\"file\", \"files\"),\n        }\n        self.incr = IncrementalChecker(self.directory)\n        self.datagen = HtmlDataGeneration(self.coverage)\n        self.directory_was_empty = False\n        self.first_fr = None\n        self.final_fr = None\n\n        self.template_globals = {\n            # Functions available in the templates.\n            \"escape\": escape,\n            \"pair\": pair,\n            \"len\": len,\n\n            # Constants for this report.\n            \"__url__\": __url__,\n            \"__version__\": coverage.__version__,\n            \"title\": title,\n            \"time_stamp\": format_local_datetime(datetime.datetime.now()),\n            \"extra_css\": self.extra_css,\n            \"has_arcs\": self.has_arcs,\n            \"show_contexts\": self.config.show_contexts,\n            \"statics\": {},\n\n            # Constants for all reports.\n            # These css classes determine which lines are highlighted by default.\n            \"category\": {\n                \"exc\": \"exc show_exc\",\n                \"mis\": \"mis show_mis\",\n                \"par\": \"par run show_par\",\n                \"run\": \"run\",\n            },\n        }\n        self.index_tmpl = Templite(read_data(\"index.html\"), self.template_globals)\n        self.pyfile_html_source = read_data(\"pyfile.html\")\n        self.source_tmpl = Templite(self.pyfile_html_source, self.template_globals)\n\n    def new_index_page(self, noun: str, plural_noun: str) -> IndexPage:\n        \"\"\"Create an IndexPage for a kind of region.\"\"\"\n        return IndexPage(\n            noun=noun,\n            plural=plural_noun,\n            filename=\"index.html\" if noun == \"file\" else f\"{noun}_index.html\",\n            summaries=[],\n            totals=Numbers(precision=self.config.precision),\n            skipped_covered_count=0,\n            skipped_empty_count=0,\n        )\n\n    def report(self, morfs: Iterable[TMorf] | None) -> float:\n        \"\"\"Generate an HTML report for `morfs`.\n\n        `morfs` is a list of modules or file names.\n\n        \"\"\"\n        # Read the status data and check that this run used the same\n        # global data as the last run.\n        self.incr.read()\n        self.incr.check_global_data(self.config, self.pyfile_html_source)\n\n        # Process all the files. For each page we need to supply a link\n        # to the next and previous page.\n        files_to_report = []\n\n        have_data = False\n        for fr, analysis in get_analysis_to_report(self.coverage, morfs):\n            have_data = True\n            ftr = FileToReport(fr, analysis)\n            if self.should_report(analysis, self.index_pages[\"file\"]):\n                files_to_report.append(ftr)\n            else:\n                file_be_gone(os.path.join(self.directory, ftr.html_filename))\n\n        if not have_data:\n            raise NoDataError(\"No data to report.\")\n\n        self.make_directory()\n        self.make_local_static_report_files()\n\n        if files_to_report:\n            for ftr1, ftr2 in zip(files_to_report[:-1], files_to_report[1:]):\n                ftr1.next_html = ftr2.html_filename\n                ftr2.prev_html = ftr1.html_filename\n            files_to_report[0].prev_html = \"index.html\"\n            files_to_report[-1].next_html = \"index.html\"\n\n        for ftr in files_to_report:\n            self.write_html_page(ftr)\n            for noun, plural_noun in ftr.fr.code_region_kinds():\n                if noun not in self.index_pages:\n                    self.index_pages[noun] = self.new_index_page(noun, plural_noun)\n\n        # Write the index page.\n        if files_to_report:\n            first_html = files_to_report[0].html_filename\n            final_html = files_to_report[-1].html_filename\n        else:\n            first_html = final_html = \"index.html\"\n        self.write_file_index_page(first_html, final_html)\n\n        # Write function and class index pages.\n        self.write_region_index_pages(files_to_report)\n\n        return (\n            self.index_pages[\"file\"].totals.n_statements\n            and self.index_pages[\"file\"].totals.pc_covered\n        )\n\n    def make_directory(self) -> None:\n        \"\"\"Make sure our htmlcov directory exists.\"\"\"\n        ensure_dir(self.directory)\n        if not os.listdir(self.directory):\n            self.directory_was_empty = True\n\n    def copy_static_file(self, src: str, slug: str = \"\") -> None:\n        \"\"\"Copy a static file into the output directory with cache busting.\"\"\"\n        with open(src, \"rb\") as f:\n            text = f.read()\n        h = Hasher()\n        h.update(text)\n        cache_bust = h.hexdigest()[:8]\n        src_base = os.path.basename(src)\n        dest = src_base.replace(\".\", f\"_cb_{cache_bust}.\")\n        if not slug:\n            slug = src_base.replace(\".\", \"_\")\n        self.template_globals[\"statics\"][slug] = dest # type: ignore\n        with open(os.path.join(self.directory, dest), \"wb\") as f:\n            f.write(text)\n\n    def make_local_static_report_files(self) -> None:\n        \"\"\"Make local instances of static files for HTML report.\"\"\"\n\n        # The files we provide must always be copied.\n        for static in self.STATIC_FILES:\n            self.copy_static_file(data_filename(static))\n\n        # The user may have extra CSS they want copied.\n        if self.extra_css:\n            assert self.config.extra_css is not None\n            self.copy_static_file(self.config.extra_css, slug=\"extra_css\")\n\n        # Only write the .gitignore file if the directory was originally empty.\n        # .gitignore can't be copied from the source tree because if it was in\n        # the source tree, it would stop the static files from being checked in.\n        if self.directory_was_empty:\n            with open(os.path.join(self.directory, \".gitignore\"), \"w\") as fgi:\n                fgi.write(\"# Created by coverage.py\\n*\\n\")\n\n    def should_report(self, analysis: Analysis, index_page: IndexPage) -> bool:\n        \"\"\"Determine if we'll report this file or region.\"\"\"\n        # Get the numbers for this file.\n        nums = analysis.numbers\n        index_page.totals += nums\n\n        if self.skip_covered:\n            # Don't report on 100% files.\n            no_missing_lines = (nums.n_missing == 0)\n            no_missing_branches = (nums.n_partial_branches == 0)\n            if no_missing_lines and no_missing_branches:\n                index_page.skipped_covered_count += 1\n                return False\n\n        if self.skip_empty:\n            # Don't report on empty files.\n            if nums.n_statements == 0:\n                index_page.skipped_empty_count += 1\n                return False\n\n        return True\n\n    def write_html_page(self, ftr: FileToReport) -> None:\n        \"\"\"Generate an HTML page for one source file.\n\n        If the page on disk is already correct based on our incremental status\n        checking, then the page doesn't have to be generated, and this function\n        only does page summary bookkeeping.\n\n        \"\"\"\n        # Find out if the page on disk is already correct.\n        if self.incr.can_skip_file(self.data, ftr.fr, ftr.rootname):\n            self.index_pages[\"file\"].summaries.append(self.incr.index_info(ftr.rootname))\n            return\n\n        # Write the HTML page for this source file.\n        file_data = self.datagen.data_for_file(ftr.fr, ftr.analysis)\n\n        contexts = collections.Counter(c for cline in file_data.lines for c in cline.contexts)\n        context_codes = {y: i for (i, y) in enumerate(x[0] for x in contexts.most_common())}\n        if context_codes:\n            contexts_json = json.dumps(\n                {encode_int(v): k for (k, v) in context_codes.items()},\n                indent=2,\n            )\n        else:\n            contexts_json = None\n\n        for ldata in file_data.lines:\n            # Build the HTML for the line.\n            html_parts = []\n            for tok_type, tok_text in ldata.tokens:\n                if tok_type == \"ws\":\n                    html_parts.append(escape(tok_text))\n                else:\n                    tok_html = escape(tok_text) or \"&nbsp;\"\n                    html_parts.append(f'<span class=\"{tok_type}\">{tok_html}</span>')\n            ldata.html = \"\".join(html_parts)\n            if ldata.context_list:\n                encoded_contexts = [\n                    encode_int(context_codes[c_context]) for c_context in ldata.context_list\n                ]\n                code_width = max(len(ec) for ec in encoded_contexts)\n                ldata.context_str = (\n                    str(code_width)\n                    + \"\".join(ec.ljust(code_width) for ec in encoded_contexts)\n                )\n            else:\n                ldata.context_str = \"\"\n\n            if ldata.short_annotations:\n                # 202F is NARROW NO-BREAK SPACE.\n                # 219B is RIGHTWARDS ARROW WITH STROKE.\n                ldata.annotate = \",&nbsp;&nbsp; \".join(\n                    f\"{ldata.number}&#x202F;&#x219B;&#x202F;{d}\"\n                    for d in ldata.short_annotations\n                )\n            else:\n                ldata.annotate = None\n\n            if ldata.long_annotations:\n                longs = ldata.long_annotations\n                if len(longs) == 1:\n                    ldata.annotate_long = longs[0]\n                else:\n                    ldata.annotate_long = \"{:d} missed branches: {}\".format(\n                        len(longs),\n                        \", \".join(\n                            f\"{num:d}) {ann_long}\"\n                            for num, ann_long in enumerate(longs, start=1)\n                        ),\n                    )\n            else:\n                ldata.annotate_long = None\n\n            css_classes = []\n            if ldata.category:\n                css_classes.append(\n                    self.template_globals[\"category\"][ldata.category],   # type: ignore[index]\n                )\n            ldata.css_class = \" \".join(css_classes) or \"pln\"\n\n        html_path = os.path.join(self.directory, ftr.html_filename)\n        html = self.source_tmpl.render({\n            **file_data.__dict__,\n            \"contexts_json\": contexts_json,\n            \"prev_html\": ftr.prev_html,\n            \"next_html\": ftr.next_html,\n        })\n        write_html(html_path, html)\n\n        # Save this file's information for the index page.\n        index_info = IndexItem(\n            url = ftr.html_filename,\n            file = escape(ftr.fr.relative_filename()),\n            nums = ftr.analysis.numbers,\n        )\n        self.index_pages[\"file\"].summaries.append(index_info)\n        self.incr.set_index_info(ftr.rootname, index_info)\n\n    def write_file_index_page(self, first_html: str, final_html: str) -> None:\n        \"\"\"Write the file index page for this report.\"\"\"\n        index_file = self.write_index_page(\n            self.index_pages[\"file\"],\n            first_html=first_html,\n            final_html=final_html,\n        )\n\n        print_href = stdout_link(index_file, f\"file://{os.path.abspath(index_file)}\")\n        self.coverage._message(f\"Wrote HTML report to {print_href}\")\n\n        # Write the latest hashes for next time.\n        self.incr.write()\n\n    def write_region_index_pages(self, files_to_report: Iterable[FileToReport]) -> None:\n        \"\"\"Write the other index pages for this report.\"\"\"\n        for ftr in files_to_report:\n            region_nouns = [pair[0] for pair in ftr.fr.code_region_kinds()]\n            num_lines = len(ftr.fr.source().splitlines())\n            outside_lines = set(range(1, num_lines + 1))\n            regions = ftr.fr.code_regions()\n\n            for noun in region_nouns:\n                page_data = self.index_pages[noun]\n\n                for region in regions:\n                    if region.kind != noun:\n                        continue\n                    outside_lines -= region.lines\n                    analysis = ftr.analysis.narrow(region.lines)\n                    if not self.should_report(analysis, page_data):\n                        continue\n                    sorting_name = region.name.rpartition(\".\")[-1].lstrip(\"_\")\n                    page_data.summaries.append(IndexItem(\n                        url=f\"{ftr.html_filename}#t{region.start}\",\n                        file=escape(ftr.fr.relative_filename()),\n                        description=(\n                            f\"<data value='{escape(sorting_name)}'>\"\n                            + escape(region.name)\n                            + \"</data>\"\n                        ),\n                        nums=analysis.numbers,\n                    ))\n\n                analysis = ftr.analysis.narrow(outside_lines)\n                if self.should_report(analysis, page_data):\n                    page_data.summaries.append(IndexItem(\n                        url=ftr.html_filename,\n                        file=escape(ftr.fr.relative_filename()),\n                        description=(\n                            \"<data value=''>\"\n                            + f\"<span class='no-noun'>(no {escape(noun)})</span>\"\n                            + \"</data>\"\n                        ),\n                        nums=analysis.numbers,\n                    ))\n\n        for noun, index_page in self.index_pages.items():\n            if noun != \"file\":\n                self.write_index_page(index_page)\n\n    def write_index_page(self, index_page: IndexPage, **kwargs: str) -> str:\n        \"\"\"Write an index page specified by `index_page`.\n\n        Returns the filename created.\n        \"\"\"\n        skipped_covered_msg = skipped_empty_msg = \"\"\n        if n := index_page.skipped_covered_count:\n            word = plural(n, index_page.noun, index_page.plural)\n            skipped_covered_msg = f\"{n} {word} skipped due to complete coverage.\"\n        if n := index_page.skipped_empty_count:\n            word = plural(n, index_page.noun, index_page.plural)\n            skipped_empty_msg = f\"{n} empty {word} skipped.\"\n\n        index_buttons = [\n            {\n                \"label\": ip.plural.title(),\n                \"url\": ip.filename if ip.noun != index_page.noun else \"\",\n                \"current\": ip.noun == index_page.noun,\n            }\n            for ip in self.index_pages.values()\n        ]\n        render_data = {\n            \"regions\": index_page.summaries,\n            \"totals\": index_page.totals,\n            \"noun\": index_page.noun,\n            \"region_noun\": index_page.noun if index_page.noun != \"file\" else \"\",\n            \"skip_covered\": self.skip_covered,\n            \"skipped_covered_msg\": skipped_covered_msg,\n            \"skipped_empty_msg\": skipped_empty_msg,\n            \"first_html\": \"\",\n            \"final_html\": \"\",\n            \"index_buttons\": index_buttons,\n        }\n        render_data.update(kwargs)\n        html = self.index_tmpl.render(render_data)\n\n        index_file = os.path.join(self.directory, index_page.filename)\n        write_html(index_file, html)\n        return index_file\n\n\n@dataclass\nclass FileInfo:\n    \"\"\"Summary of the information from last rendering, to avoid duplicate work.\"\"\"\n    hash: str = \"\"\n    index: IndexItem = field(default_factory=IndexItem)\n\n\nclass IncrementalChecker:\n    \"\"\"Logic and data to support incremental reporting.\n\n    When generating an HTML report, often only a few of the source files have\n    changed since the last time we made the HTML report.  This means previously\n    created HTML pages can be reused without generating them again, speeding\n    the command.\n\n    This class manages a JSON data file that captures enough information to\n    know whether an HTML page for a .py file needs to be regenerated or not.\n    The data file also needs to store all the information needed to create the\n    entry for the file on the index page so that if the HTML page is reused,\n    the index page can still be created to refer to it.\n\n    The data looks like::\n\n        {\n            \"note\": \"This file is an internal implementation detail ...\",\n            // A fixed number indicating the data format.  STATUS_FORMAT\n            \"format\": 5,\n            // The version of coverage.py\n            \"version\": \"7.4.4\",\n            // A hash of a number of global things, including the configuration\n            // settings and the pyfile.html template itself.\n            \"globals\": \"540ee119c15d52a68a53fe6f0897346d\",\n            \"files\": {\n                // An entry for each source file keyed by the flat_rootname().\n                \"z_7b071bdc2a35fa80___init___py\": {\n                    // Hash of the source, the text of the .py file.\n                    \"hash\": \"e45581a5b48f879f301c0f30bf77a50c\",\n                    // Information for the index.html file.\n                    \"index\": {\n                        \"url\": \"z_7b071bdc2a35fa80___init___py.html\",\n                        \"file\": \"cogapp/__init__.py\",\n                        \"description\": \"\",\n                        // The Numbers for this file.\n                        \"nums\": { \"precision\": 2, \"n_files\": 1, \"n_statements\": 43, ... }\n                    }\n                },\n                ...\n            }\n        }\n\n    \"\"\"\n\n    STATUS_FILE = \"status.json\"\n    STATUS_FORMAT = 5\n    NOTE = (\n        \"This file is an internal implementation detail to speed up HTML report\"\n        + \" generation. Its format can change at any time. You might be looking\"\n        + \" for the JSON report: https://coverage.rtfd.io/cmd.html#cmd-json\"\n    )\n\n    def __init__(self, directory: str) -> None:\n        self.directory = directory\n        self._reset()\n\n    def _reset(self) -> None:\n        \"\"\"Initialize to empty. Causes all files to be reported.\"\"\"\n        self.globals = \"\"\n        self.files: dict[str, FileInfo] = {}\n\n    def read(self) -> None:\n        \"\"\"Read the information we stored last time.\"\"\"\n        try:\n            status_file = os.path.join(self.directory, self.STATUS_FILE)\n            with open(status_file) as fstatus:\n                status = json.load(fstatus)\n        except (OSError, ValueError):\n            # Status file is missing or malformed.\n            usable = False\n        else:\n            if status[\"format\"] != self.STATUS_FORMAT:\n                usable = False\n            elif status[\"version\"] != coverage.__version__:\n                usable = False\n            else:\n                usable = True\n\n        if usable:\n            self.files = {}\n            for filename, filedict in status[\"files\"].items():\n                indexdict = filedict[\"index\"]\n                index_item = IndexItem(**indexdict)\n                index_item.nums = Numbers(**indexdict[\"nums\"])\n                fileinfo = FileInfo(\n                    hash=filedict[\"hash\"],\n                    index=index_item,\n                )\n                self.files[filename] = fileinfo\n            self.globals = status[\"globals\"]\n        else:\n            self._reset()\n\n    def write(self) -> None:\n        \"\"\"Write the current status.\"\"\"\n        status_file = os.path.join(self.directory, self.STATUS_FILE)\n        status_data = {\n            \"note\": self.NOTE,\n            \"format\": self.STATUS_FORMAT,\n            \"version\": coverage.__version__,\n            \"globals\": self.globals,\n            \"files\": {\n                fname: dataclasses.asdict(finfo)\n                for fname, finfo in self.files.items()\n            },\n        }\n        with open(status_file, \"w\") as fout:\n            json.dump(status_data, fout, separators=(\",\", \":\"))\n\n    def check_global_data(self, *data: Any) -> None:\n        \"\"\"Check the global data that can affect incremental reporting.\n\n        Pass in whatever global information could affect the content of the\n        HTML pages.  If the global data has changed since last time, this will\n        clear the data so that all files are regenerated.\n\n        \"\"\"\n        m = Hasher()\n        for d in data:\n            m.update(d)\n        these_globals = m.hexdigest()\n        if self.globals != these_globals:\n            self._reset()\n            self.globals = these_globals\n\n    def can_skip_file(self, data: CoverageData, fr: FileReporter, rootname: str) -> bool:\n        \"\"\"Can we skip reporting this file?\n\n        `data` is a CoverageData object, `fr` is a `FileReporter`, and\n        `rootname` is the name being used for the file.\n\n        Returns True if the HTML page is fine as-is, False if we need to recreate\n        the HTML page.\n\n        \"\"\"\n        m = Hasher()\n        m.update(fr.source().encode(\"utf-8\"))\n        add_data_to_hash(data, fr.filename, m)\n        this_hash = m.hexdigest()\n\n        file_info = self.files.setdefault(rootname, FileInfo())\n\n        if this_hash == file_info.hash:\n            # Nothing has changed to require the file to be reported again.\n            return True\n        else:\n            # File has changed, record the latest hash and force regeneration.\n            file_info.hash = this_hash\n            return False\n\n    def index_info(self, fname: str) -> IndexItem:\n        \"\"\"Get the information for index.html for `fname`.\"\"\"\n        return self.files.get(fname, FileInfo()).index\n\n    def set_index_info(self, fname: str, info: IndexItem) -> None:\n        \"\"\"Set the information for index.html for `fname`.\"\"\"\n        self.files.setdefault(fname, FileInfo()).index = info\n\n\n# Helpers for templates and generating HTML\n\ndef escape(t: str) -> str:\n    \"\"\"HTML-escape the text in `t`.\n\n    This is only suitable for HTML text, not attributes.\n\n    \"\"\"\n    # Convert HTML special chars into HTML entities.\n    return t.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\")\n\n\ndef pair(ratio: tuple[int, int]) -> str:\n    \"\"\"Format a pair of numbers so JavaScript can read them in an attribute.\"\"\"\n    return \"{} {}\".format(*ratio)\n", "coverage/bytecode.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Bytecode manipulation for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nfrom types import CodeType\nfrom typing import Iterator\n\n\ndef code_objects(code: CodeType) -> Iterator[CodeType]:\n    \"\"\"Iterate over all the code objects in `code`.\"\"\"\n    stack = [code]\n    while stack:\n        # We're going to return the code object on the stack, but first\n        # push its children for later returning.\n        code = stack.pop()\n        for c in code.co_consts:\n            if isinstance(c, CodeType):\n                stack.append(c)\n        yield code\n", "coverage/plugin_support.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Support for plugins.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport os.path\nimport sys\n\nfrom types import FrameType\nfrom typing import Any, Iterable, Iterator\n\nfrom coverage.exceptions import PluginError\nfrom coverage.misc import isolate_module\nfrom coverage.plugin import CoveragePlugin, FileTracer, FileReporter\nfrom coverage.types import (\n    TArc, TConfigurable, TDebugCtl, TLineNo, TPluginConfig, TSourceTokenLines,\n)\n\nos = isolate_module(os)\n\n\nclass Plugins:\n    \"\"\"The currently loaded collection of coverage.py plugins.\"\"\"\n\n    def __init__(self) -> None:\n        self.order: list[CoveragePlugin] = []\n        self.names: dict[str, CoveragePlugin] = {}\n        self.file_tracers: list[CoveragePlugin] = []\n        self.configurers: list[CoveragePlugin] = []\n        self.context_switchers: list[CoveragePlugin] = []\n\n        self.current_module: str | None = None\n        self.debug: TDebugCtl | None\n\n    @classmethod\n    def load_plugins(\n        cls,\n        modules: Iterable[str],\n        config: TPluginConfig,\n        debug: TDebugCtl | None = None,\n    ) -> Plugins:\n        \"\"\"Load plugins from `modules`.\n\n        Returns a Plugins object with the loaded and configured plugins.\n\n        \"\"\"\n        plugins = cls()\n        plugins.debug = debug\n\n        for module in modules:\n            plugins.current_module = module\n            __import__(module)\n            mod = sys.modules[module]\n\n            coverage_init = getattr(mod, \"coverage_init\", None)\n            if not coverage_init:\n                raise PluginError(\n                    f\"Plugin module {module!r} didn't define a coverage_init function\",\n                )\n\n            options = config.get_plugin_options(module)\n            coverage_init(plugins, options)\n\n        plugins.current_module = None\n        return plugins\n\n    def add_file_tracer(self, plugin: CoveragePlugin) -> None:\n        \"\"\"Add a file tracer plugin.\n\n        `plugin` is an instance of a third-party plugin class.  It must\n        implement the :meth:`CoveragePlugin.file_tracer` method.\n\n        \"\"\"\n        self._add_plugin(plugin, self.file_tracers)\n\n    def add_configurer(self, plugin: CoveragePlugin) -> None:\n        \"\"\"Add a configuring plugin.\n\n        `plugin` is an instance of a third-party plugin class. It must\n        implement the :meth:`CoveragePlugin.configure` method.\n\n        \"\"\"\n        self._add_plugin(plugin, self.configurers)\n\n    def add_dynamic_context(self, plugin: CoveragePlugin) -> None:\n        \"\"\"Add a dynamic context plugin.\n\n        `plugin` is an instance of a third-party plugin class.  It must\n        implement the :meth:`CoveragePlugin.dynamic_context` method.\n\n        \"\"\"\n        self._add_plugin(plugin, self.context_switchers)\n\n    def add_noop(self, plugin: CoveragePlugin) -> None:\n        \"\"\"Add a plugin that does nothing.\n\n        This is only useful for testing the plugin support.\n\n        \"\"\"\n        self._add_plugin(plugin, None)\n\n    def _add_plugin(\n        self,\n        plugin: CoveragePlugin,\n        specialized: list[CoveragePlugin] | None,\n    ) -> None:\n        \"\"\"Add a plugin object.\n\n        `plugin` is a :class:`CoveragePlugin` instance to add.  `specialized`\n        is a list to append the plugin to.\n\n        \"\"\"\n        plugin_name = f\"{self.current_module}.{plugin.__class__.__name__}\"\n        if self.debug and self.debug.should(\"plugin\"):\n            self.debug.write(f\"Loaded plugin {self.current_module!r}: {plugin!r}\")\n            labelled = LabelledDebug(f\"plugin {self.current_module!r}\", self.debug)\n            plugin = DebugPluginWrapper(plugin, labelled)\n\n        plugin._coverage_plugin_name = plugin_name\n        plugin._coverage_enabled = True\n        self.order.append(plugin)\n        self.names[plugin_name] = plugin\n        if specialized is not None:\n            specialized.append(plugin)\n\n    def __bool__(self) -> bool:\n        return bool(self.order)\n\n    def __iter__(self) -> Iterator[CoveragePlugin]:\n        return iter(self.order)\n\n    def get(self, plugin_name: str) -> CoveragePlugin:\n        \"\"\"Return a plugin by name.\"\"\"\n        return self.names[plugin_name]\n\n\nclass LabelledDebug:\n    \"\"\"A Debug writer, but with labels for prepending to the messages.\"\"\"\n\n    def __init__(self, label: str, debug: TDebugCtl, prev_labels: Iterable[str] = ()):\n        self.labels = list(prev_labels) + [label]\n        self.debug = debug\n\n    def add_label(self, label: str) -> LabelledDebug:\n        \"\"\"Add a label to the writer, and return a new `LabelledDebug`.\"\"\"\n        return LabelledDebug(label, self.debug, self.labels)\n\n    def message_prefix(self) -> str:\n        \"\"\"The prefix to use on messages, combining the labels.\"\"\"\n        prefixes = self.labels + [\"\"]\n        return \":\\n\".join(\"  \"*i+label for i, label in enumerate(prefixes))\n\n    def write(self, message: str) -> None:\n        \"\"\"Write `message`, but with the labels prepended.\"\"\"\n        self.debug.write(f\"{self.message_prefix()}{message}\")\n\n\nclass DebugPluginWrapper(CoveragePlugin):\n    \"\"\"Wrap a plugin, and use debug to report on what it's doing.\"\"\"\n\n    def __init__(self, plugin: CoveragePlugin, debug: LabelledDebug) -> None:\n        super().__init__()\n        self.plugin = plugin\n        self.debug = debug\n\n    def file_tracer(self, filename: str) -> FileTracer | None:\n        tracer = self.plugin.file_tracer(filename)\n        self.debug.write(f\"file_tracer({filename!r}) --> {tracer!r}\")\n        if tracer:\n            debug = self.debug.add_label(f\"file {filename!r}\")\n            tracer = DebugFileTracerWrapper(tracer, debug)\n        return tracer\n\n    def file_reporter(self, filename: str) -> FileReporter | str:\n        reporter = self.plugin.file_reporter(filename)\n        assert isinstance(reporter, FileReporter)\n        self.debug.write(f\"file_reporter({filename!r}) --> {reporter!r}\")\n        if reporter:\n            debug = self.debug.add_label(f\"file {filename!r}\")\n            reporter = DebugFileReporterWrapper(filename, reporter, debug)\n        return reporter\n\n    def dynamic_context(self, frame: FrameType) -> str | None:\n        context = self.plugin.dynamic_context(frame)\n        self.debug.write(f\"dynamic_context({frame!r}) --> {context!r}\")\n        return context\n\n    def find_executable_files(self, src_dir: str) -> Iterable[str]:\n        executable_files = self.plugin.find_executable_files(src_dir)\n        self.debug.write(f\"find_executable_files({src_dir!r}) --> {executable_files!r}\")\n        return executable_files\n\n    def configure(self, config: TConfigurable) -> None:\n        self.debug.write(f\"configure({config!r})\")\n        self.plugin.configure(config)\n\n    def sys_info(self) -> Iterable[tuple[str, Any]]:\n        return self.plugin.sys_info()\n\n\nclass DebugFileTracerWrapper(FileTracer):\n    \"\"\"A debugging `FileTracer`.\"\"\"\n\n    def __init__(self, tracer: FileTracer, debug: LabelledDebug) -> None:\n        self.tracer = tracer\n        self.debug = debug\n\n    def _show_frame(self, frame: FrameType) -> str:\n        \"\"\"A short string identifying a frame, for debug messages.\"\"\"\n        return \"%s@%d\" % (\n            os.path.basename(frame.f_code.co_filename),\n            frame.f_lineno,\n        )\n\n    def source_filename(self) -> str:\n        sfilename = self.tracer.source_filename()\n        self.debug.write(f\"source_filename() --> {sfilename!r}\")\n        return sfilename\n\n    def has_dynamic_source_filename(self) -> bool:\n        has = self.tracer.has_dynamic_source_filename()\n        self.debug.write(f\"has_dynamic_source_filename() --> {has!r}\")\n        return has\n\n    def dynamic_source_filename(self, filename: str, frame: FrameType) -> str | None:\n        dyn = self.tracer.dynamic_source_filename(filename, frame)\n        self.debug.write(\"dynamic_source_filename({!r}, {}) --> {!r}\".format(\n            filename, self._show_frame(frame), dyn,\n        ))\n        return dyn\n\n    def line_number_range(self, frame: FrameType) -> tuple[TLineNo, TLineNo]:\n        pair = self.tracer.line_number_range(frame)\n        self.debug.write(f\"line_number_range({self._show_frame(frame)}) --> {pair!r}\")\n        return pair\n\n\nclass DebugFileReporterWrapper(FileReporter):\n    \"\"\"A debugging `FileReporter`.\"\"\"\n\n    def __init__(self, filename: str, reporter: FileReporter, debug: LabelledDebug) -> None:\n        super().__init__(filename)\n        self.reporter = reporter\n        self.debug = debug\n\n    def relative_filename(self) -> str:\n        ret = self.reporter.relative_filename()\n        self.debug.write(f\"relative_filename() --> {ret!r}\")\n        return ret\n\n    def lines(self) -> set[TLineNo]:\n        ret = self.reporter.lines()\n        self.debug.write(f\"lines() --> {ret!r}\")\n        return ret\n\n    def excluded_lines(self) -> set[TLineNo]:\n        ret = self.reporter.excluded_lines()\n        self.debug.write(f\"excluded_lines() --> {ret!r}\")\n        return ret\n\n    def translate_lines(self, lines: Iterable[TLineNo]) -> set[TLineNo]:\n        ret = self.reporter.translate_lines(lines)\n        self.debug.write(f\"translate_lines({lines!r}) --> {ret!r}\")\n        return ret\n\n    def translate_arcs(self, arcs: Iterable[TArc]) -> set[TArc]:\n        ret = self.reporter.translate_arcs(arcs)\n        self.debug.write(f\"translate_arcs({arcs!r}) --> {ret!r}\")\n        return ret\n\n    def no_branch_lines(self) -> set[TLineNo]:\n        ret = self.reporter.no_branch_lines()\n        self.debug.write(f\"no_branch_lines() --> {ret!r}\")\n        return ret\n\n    def exit_counts(self) -> dict[TLineNo, int]:\n        ret = self.reporter.exit_counts()\n        self.debug.write(f\"exit_counts() --> {ret!r}\")\n        return ret\n\n    def arcs(self) -> set[TArc]:\n        ret = self.reporter.arcs()\n        self.debug.write(f\"arcs() --> {ret!r}\")\n        return ret\n\n    def source(self) -> str:\n        ret = self.reporter.source()\n        self.debug.write(\"source() --> %d chars\" % (len(ret),))\n        return ret\n\n    def source_token_lines(self) -> TSourceTokenLines:\n        ret = list(self.reporter.source_token_lines())\n        self.debug.write(\"source_token_lines() --> %d tokens\" % (len(ret),))\n        return ret\n", "coverage/templite.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"A simple Python template renderer, for a nano-subset of Django syntax.\n\nFor a detailed discussion of this code, see this chapter from 500 Lines:\nhttp://aosabook.org/en/500L/a-template-engine.html\n\n\"\"\"\n\n# Coincidentally named the same as http://code.activestate.com/recipes/496702/\n\nfrom __future__ import annotations\n\nimport re\n\nfrom typing import (\n    Any, Callable, Dict, NoReturn, cast,\n)\n\n\nclass TempliteSyntaxError(ValueError):\n    \"\"\"Raised when a template has a syntax error.\"\"\"\n    pass\n\n\nclass TempliteValueError(ValueError):\n    \"\"\"Raised when an expression won't evaluate in a template.\"\"\"\n    pass\n\n\nclass CodeBuilder:\n    \"\"\"Build source code conveniently.\"\"\"\n\n    def __init__(self, indent: int = 0) -> None:\n        self.code: list[str | CodeBuilder] = []\n        self.indent_level = indent\n\n    def __str__(self) -> str:\n        return \"\".join(str(c) for c in self.code)\n\n    def add_line(self, line: str) -> None:\n        \"\"\"Add a line of source to the code.\n\n        Indentation and newline will be added for you, don't provide them.\n\n        \"\"\"\n        self.code.extend([\" \" * self.indent_level, line, \"\\n\"])\n\n    def add_section(self) -> CodeBuilder:\n        \"\"\"Add a section, a sub-CodeBuilder.\"\"\"\n        section = CodeBuilder(self.indent_level)\n        self.code.append(section)\n        return section\n\n    INDENT_STEP = 4      # PEP8 says so!\n\n    def indent(self) -> None:\n        \"\"\"Increase the current indent for following lines.\"\"\"\n        self.indent_level += self.INDENT_STEP\n\n    def dedent(self) -> None:\n        \"\"\"Decrease the current indent for following lines.\"\"\"\n        self.indent_level -= self.INDENT_STEP\n\n    def get_globals(self) -> dict[str, Any]:\n        \"\"\"Execute the code, and return a dict of globals it defines.\"\"\"\n        # A check that the caller really finished all the blocks they started.\n        assert self.indent_level == 0\n        # Get the Python source as a single string.\n        python_source = str(self)\n        # Execute the source, defining globals, and return them.\n        global_namespace: dict[str, Any] = {}\n        exec(python_source, global_namespace)\n        return global_namespace\n\n\nclass Templite:\n    \"\"\"A simple template renderer, for a nano-subset of Django syntax.\n\n    Supported constructs are extended variable access::\n\n        {{var.modifier.modifier|filter|filter}}\n\n    loops::\n\n        {% for var in list %}...{% endfor %}\n\n    and ifs::\n\n        {% if var %}...{% endif %}\n\n    Comments are within curly-hash markers::\n\n        {# This will be ignored #}\n\n    Lines between `{% joined %}` and `{% endjoined %}` will have lines stripped\n    and joined.  Be careful, this could join words together!\n\n    Any of these constructs can have a hyphen at the end (`-}}`, `-%}`, `-#}`),\n    which will collapse the white space following the tag.\n\n    Construct a Templite with the template text, then use `render` against a\n    dictionary context to create a finished string::\n\n        templite = Templite('''\n            <h1>Hello {{name|upper}}!</h1>\n            {% for topic in topics %}\n                <p>You are interested in {{topic}}.</p>\n            {% endif %}\n            ''',\n            {\"upper\": str.upper},\n        )\n        text = templite.render({\n            \"name\": \"Ned\",\n            \"topics\": [\"Python\", \"Geometry\", \"Juggling\"],\n        })\n\n    \"\"\"\n    def __init__(self, text: str, *contexts: dict[str, Any]) -> None:\n        \"\"\"Construct a Templite with the given `text`.\n\n        `contexts` are dictionaries of values to use for future renderings.\n        These are good for filters and global values.\n\n        \"\"\"\n        self.context = {}\n        for context in contexts:\n            self.context.update(context)\n\n        self.all_vars: set[str] = set()\n        self.loop_vars: set[str] = set()\n\n        # We construct a function in source form, then compile it and hold onto\n        # it, and execute it to render the template.\n        code = CodeBuilder()\n\n        code.add_line(\"def render_function(context, do_dots):\")\n        code.indent()\n        vars_code = code.add_section()\n        code.add_line(\"result = []\")\n        code.add_line(\"append_result = result.append\")\n        code.add_line(\"extend_result = result.extend\")\n        code.add_line(\"to_str = str\")\n\n        buffered: list[str] = []\n\n        def flush_output() -> None:\n            \"\"\"Force `buffered` to the code builder.\"\"\"\n            if len(buffered) == 1:\n                code.add_line(\"append_result(%s)\" % buffered[0])\n            elif len(buffered) > 1:\n                code.add_line(\"extend_result([%s])\" % \", \".join(buffered))\n            del buffered[:]\n\n        ops_stack = []\n\n        # Split the text to form a list of tokens.\n        tokens = re.split(r\"(?s)({{.*?}}|{%.*?%}|{#.*?#})\", text)\n\n        squash = in_joined = False\n\n        for token in tokens:\n            if token.startswith(\"{\"):\n                start, end = 2, -2\n                squash = (token[-3] == \"-\")\n                if squash:\n                    end = -3\n\n                if token.startswith(\"{#\"):\n                    # Comment: ignore it and move on.\n                    continue\n                elif token.startswith(\"{{\"):\n                    # An expression to evaluate.\n                    expr = self._expr_code(token[start:end].strip())\n                    buffered.append(\"to_str(%s)\" % expr)\n                else:\n                    # token.startswith(\"{%\")\n                    # Action tag: split into words and parse further.\n                    flush_output()\n\n                    words = token[start:end].strip().split()\n                    if words[0] == \"if\":\n                        # An if statement: evaluate the expression to determine if.\n                        if len(words) != 2:\n                            self._syntax_error(\"Don't understand if\", token)\n                        ops_stack.append(\"if\")\n                        code.add_line(\"if %s:\" % self._expr_code(words[1]))\n                        code.indent()\n                    elif words[0] == \"for\":\n                        # A loop: iterate over expression result.\n                        if len(words) != 4 or words[2] != \"in\":\n                            self._syntax_error(\"Don't understand for\", token)\n                        ops_stack.append(\"for\")\n                        self._variable(words[1], self.loop_vars)\n                        code.add_line(\n                            f\"for c_{words[1]} in {self._expr_code(words[3])}:\",\n                        )\n                        code.indent()\n                    elif words[0] == \"joined\":\n                        ops_stack.append(\"joined\")\n                        in_joined = True\n                    elif words[0].startswith(\"end\"):\n                        # Endsomething.  Pop the ops stack.\n                        if len(words) != 1:\n                            self._syntax_error(\"Don't understand end\", token)\n                        end_what = words[0][3:]\n                        if not ops_stack:\n                            self._syntax_error(\"Too many ends\", token)\n                        start_what = ops_stack.pop()\n                        if start_what != end_what:\n                            self._syntax_error(\"Mismatched end tag\", end_what)\n                        if end_what == \"joined\":\n                            in_joined = False\n                        else:\n                            code.dedent()\n                    else:\n                        self._syntax_error(\"Don't understand tag\", words[0])\n            else:\n                # Literal content.  If it isn't empty, output it.\n                if in_joined:\n                    token = re.sub(r\"\\s*\\n\\s*\", \"\", token.strip())\n                elif squash:\n                    token = token.lstrip()\n                if token:\n                    buffered.append(repr(token))\n\n        if ops_stack:\n            self._syntax_error(\"Unmatched action tag\", ops_stack[-1])\n\n        flush_output()\n\n        for var_name in self.all_vars - self.loop_vars:\n            vars_code.add_line(f\"c_{var_name} = context[{var_name!r}]\")\n\n        code.add_line(\"return ''.join(result)\")\n        code.dedent()\n        self._render_function = cast(\n            Callable[\n                [Dict[str, Any], Callable[..., Any]],\n                str,\n            ],\n            code.get_globals()[\"render_function\"],\n        )\n\n    def _expr_code(self, expr: str) -> str:\n        \"\"\"Generate a Python expression for `expr`.\"\"\"\n        if \"|\" in expr:\n            pipes = expr.split(\"|\")\n            code = self._expr_code(pipes[0])\n            for func in pipes[1:]:\n                self._variable(func, self.all_vars)\n                code = f\"c_{func}({code})\"\n        elif \".\" in expr:\n            dots = expr.split(\".\")\n            code = self._expr_code(dots[0])\n            args = \", \".join(repr(d) for d in dots[1:])\n            code = f\"do_dots({code}, {args})\"\n        else:\n            self._variable(expr, self.all_vars)\n            code = \"c_%s\" % expr\n        return code\n\n    def _syntax_error(self, msg: str, thing: Any) -> NoReturn:\n        \"\"\"Raise a syntax error using `msg`, and showing `thing`.\"\"\"\n        raise TempliteSyntaxError(f\"{msg}: {thing!r}\")\n\n    def _variable(self, name: str, vars_set: set[str]) -> None:\n        \"\"\"Track that `name` is used as a variable.\n\n        Adds the name to `vars_set`, a set of variable names.\n\n        Raises an syntax error if `name` is not a valid name.\n\n        \"\"\"\n        if not re.match(r\"[_a-zA-Z][_a-zA-Z0-9]*$\", name):\n            self._syntax_error(\"Not a valid name\", name)\n        vars_set.add(name)\n\n    def render(self, context: dict[str, Any] | None = None) -> str:\n        \"\"\"Render this template by applying it to `context`.\n\n        `context` is a dictionary of values to use in this rendering.\n\n        \"\"\"\n        # Make the complete context we'll use.\n        render_context = dict(self.context)\n        if context:\n            render_context.update(context)\n        return self._render_function(render_context, self._do_dots)\n\n    def _do_dots(self, value: Any, *dots: str) -> Any:\n        \"\"\"Evaluate dotted expressions at run-time.\"\"\"\n        for dot in dots:\n            try:\n                value = getattr(value, dot)\n            except AttributeError:\n                try:\n                    value = value[dot]\n                except (TypeError, KeyError) as exc:\n                    raise TempliteValueError(\n                        f\"Couldn't evaluate {value!r}.{dot}\",\n                    ) from exc\n            if callable(value):\n                value = value()\n        return value\n", "coverage/config.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Config file for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport configparser\nimport copy\nimport os\nimport os.path\nimport re\n\nfrom typing import (\n    Any, Callable, Iterable, Union,\n)\n\nfrom coverage.exceptions import ConfigError\nfrom coverage.misc import isolate_module, human_sorted_items, substitute_variables\nfrom coverage.tomlconfig import TomlConfigParser, TomlDecodeError\nfrom coverage.types import (\n    TConfigurable, TConfigSectionIn, TConfigValueIn, TConfigSectionOut,\n    TConfigValueOut, TPluginConfig,\n)\n\nos = isolate_module(os)\n\n\nclass HandyConfigParser(configparser.ConfigParser):\n    \"\"\"Our specialization of ConfigParser.\"\"\"\n\n    def __init__(self, our_file: bool) -> None:\n        \"\"\"Create the HandyConfigParser.\n\n        `our_file` is True if this config file is specifically for coverage,\n        False if we are examining another config file (tox.ini, setup.cfg)\n        for possible settings.\n        \"\"\"\n\n        super().__init__(interpolation=None)\n        self.section_prefixes = [\"coverage:\"]\n        if our_file:\n            self.section_prefixes.append(\"\")\n\n    def read( # type: ignore[override]\n        self,\n        filenames: Iterable[str],\n        encoding_unused: str | None = None,\n    ) -> list[str]:\n        \"\"\"Read a file name as UTF-8 configuration data.\"\"\"\n        return super().read(filenames, encoding=\"utf-8\")\n\n    def real_section(self, section: str) -> str | None:\n        \"\"\"Get the actual name of a section.\"\"\"\n        for section_prefix in self.section_prefixes:\n            real_section = section_prefix + section\n            has = super().has_section(real_section)\n            if has:\n                return real_section\n        return None\n\n    def has_option(self, section: str, option: str) -> bool:\n        real_section = self.real_section(section)\n        if real_section is not None:\n            return super().has_option(real_section, option)\n        return False\n\n    def has_section(self, section: str) -> bool:\n        return bool(self.real_section(section))\n\n    def options(self, section: str) -> list[str]:\n        real_section = self.real_section(section)\n        if real_section is not None:\n            return super().options(real_section)\n        raise ConfigError(f\"No section: {section!r}\")\n\n    def get_section(self, section: str) -> TConfigSectionOut:\n        \"\"\"Get the contents of a section, as a dictionary.\"\"\"\n        d: dict[str, TConfigValueOut] = {}\n        for opt in self.options(section):\n            d[opt] = self.get(section, opt)\n        return d\n\n    def get(self, section: str, option: str, *args: Any, **kwargs: Any) -> str: # type: ignore\n        \"\"\"Get a value, replacing environment variables also.\n\n        The arguments are the same as `ConfigParser.get`, but in the found\n        value, ``$WORD`` or ``${WORD}`` are replaced by the value of the\n        environment variable ``WORD``.\n\n        Returns the finished value.\n\n        \"\"\"\n        for section_prefix in self.section_prefixes:\n            real_section = section_prefix + section\n            if super().has_option(real_section, option):\n                break\n        else:\n            raise ConfigError(f\"No option {option!r} in section: {section!r}\")\n\n        v: str = super().get(real_section, option, *args, **kwargs)\n        v = substitute_variables(v, os.environ)\n        return v\n\n    def getlist(self, section: str, option: str) -> list[str]:\n        \"\"\"Read a list of strings.\n\n        The value of `section` and `option` is treated as a comma- and newline-\n        separated list of strings.  Each value is stripped of white space.\n\n        Returns the list of strings.\n\n        \"\"\"\n        value_list = self.get(section, option)\n        values = []\n        for value_line in value_list.split(\"\\n\"):\n            for value in value_line.split(\",\"):\n                value = value.strip()\n                if value:\n                    values.append(value)\n        return values\n\n    def getregexlist(self, section: str, option: str) -> list[str]:\n        \"\"\"Read a list of full-line regexes.\n\n        The value of `section` and `option` is treated as a newline-separated\n        list of regexes.  Each value is stripped of white space.\n\n        Returns the list of strings.\n\n        \"\"\"\n        line_list = self.get(section, option)\n        value_list = []\n        for value in line_list.splitlines():\n            value = value.strip()\n            try:\n                re.compile(value)\n            except re.error as e:\n                raise ConfigError(\n                    f\"Invalid [{section}].{option} value {value!r}: {e}\",\n                ) from e\n            if value:\n                value_list.append(value)\n        return value_list\n\n\nTConfigParser = Union[HandyConfigParser, TomlConfigParser]\n\n\n# The default line exclusion regexes.\nDEFAULT_EXCLUDE = [\n    r\"#\\s*(pragma|PRAGMA)[:\\s]?\\s*(no|NO)\\s*(cover|COVER)\",\n]\n\n# The default partial branch regexes, to be modified by the user.\nDEFAULT_PARTIAL = [\n    r\"#\\s*(pragma|PRAGMA)[:\\s]?\\s*(no|NO)\\s*(branch|BRANCH)\",\n]\n\n# The default partial branch regexes, based on Python semantics.\n# These are any Python branching constructs that can't actually execute all\n# their branches.\nDEFAULT_PARTIAL_ALWAYS = [\n    \"while (True|1|False|0):\",\n    \"if (True|1|False|0):\",\n]\n\n\nclass CoverageConfig(TConfigurable, TPluginConfig):\n    \"\"\"Coverage.py configuration.\n\n    The attributes of this class are the various settings that control the\n    operation of coverage.py.\n\n    \"\"\"\n    # pylint: disable=too-many-instance-attributes\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the configuration attributes to their defaults.\"\"\"\n        # Metadata about the config.\n        # We tried to read these config files.\n        self.config_files_attempted: list[str] = []\n        # We did read these config files, but maybe didn't find any content for us.\n        self.config_files_read: list[str] = []\n        # The file that gave us our configuration.\n        self.config_file: str | None = None\n        self._config_contents: bytes | None = None\n\n        # Defaults for [run] and [report]\n        self._include = None\n        self._omit = None\n\n        # Defaults for [run]\n        self.branch = False\n        self.command_line: str | None = None\n        self.concurrency: list[str] = []\n        self.context: str | None = None\n        self.cover_pylib = False\n        self.data_file = \".coverage\"\n        self.debug: list[str] = []\n        self.debug_file: str | None = None\n        self.disable_warnings: list[str] = []\n        self.dynamic_context: str | None = None\n        self.parallel = False\n        self.plugins: list[str] = []\n        self.relative_files = False\n        self.run_include: list[str] = []\n        self.run_omit: list[str] = []\n        self.sigterm = False\n        self.source: list[str] | None = None\n        self.source_pkgs: list[str] = []\n        self.timid = False\n        self._crash: str | None = None\n\n        # Defaults for [report]\n        self.exclude_list = DEFAULT_EXCLUDE[:]\n        self.exclude_also: list[str] = []\n        self.fail_under = 0.0\n        self.format: str | None = None\n        self.ignore_errors = False\n        self.include_namespace_packages = False\n        self.report_include: list[str] | None = None\n        self.report_omit: list[str] | None = None\n        self.partial_always_list = DEFAULT_PARTIAL_ALWAYS[:]\n        self.partial_list = DEFAULT_PARTIAL[:]\n        self.precision = 0\n        self.report_contexts: list[str] | None = None\n        self.show_missing = False\n        self.skip_covered = False\n        self.skip_empty = False\n        self.sort: str | None = None\n\n        # Defaults for [html]\n        self.extra_css: str | None = None\n        self.html_dir = \"htmlcov\"\n        self.html_skip_covered: bool | None = None\n        self.html_skip_empty: bool | None = None\n        self.html_title = \"Coverage report\"\n        self.show_contexts = False\n\n        # Defaults for [xml]\n        self.xml_output = \"coverage.xml\"\n        self.xml_package_depth = 99\n\n        # Defaults for [json]\n        self.json_output = \"coverage.json\"\n        self.json_pretty_print = False\n        self.json_show_contexts = False\n\n        # Defaults for [lcov]\n        self.lcov_output = \"coverage.lcov\"\n\n        # Defaults for [paths]\n        self.paths: dict[str, list[str]] = {}\n\n        # Options for plugins\n        self.plugin_options: dict[str, TConfigSectionOut] = {}\n\n    MUST_BE_LIST = {\n        \"debug\", \"concurrency\", \"plugins\",\n        \"report_omit\", \"report_include\",\n        \"run_omit\", \"run_include\",\n    }\n\n    def from_args(self, **kwargs: TConfigValueIn) -> None:\n        \"\"\"Read config values from `kwargs`.\"\"\"\n        for k, v in kwargs.items():\n            if v is not None:\n                if k in self.MUST_BE_LIST and isinstance(v, str):\n                    v = [v]\n                setattr(self, k, v)\n\n    def from_file(self, filename: str, warn: Callable[[str], None], our_file: bool) -> bool:\n        \"\"\"Read configuration from a .rc file.\n\n        `filename` is a file name to read.\n\n        `our_file` is True if this config file is specifically for coverage,\n        False if we are examining another config file (tox.ini, setup.cfg)\n        for possible settings.\n\n        Returns True or False, whether the file could be read, and it had some\n        coverage.py settings in it.\n\n        \"\"\"\n        _, ext = os.path.splitext(filename)\n        cp: TConfigParser\n        if ext == \".toml\":\n            cp = TomlConfigParser(our_file)\n        else:\n            cp = HandyConfigParser(our_file)\n\n        self.config_files_attempted.append(os.path.abspath(filename))\n\n        try:\n            files_read = cp.read(filename)\n        except (configparser.Error, TomlDecodeError) as err:\n            raise ConfigError(f\"Couldn't read config file {filename}: {err}\") from err\n        if not files_read:\n            return False\n\n        self.config_files_read.extend(map(os.path.abspath, files_read))\n\n        any_set = False\n        try:\n            for option_spec in self.CONFIG_FILE_OPTIONS:\n                was_set = self._set_attr_from_config_option(cp, *option_spec)\n                if was_set:\n                    any_set = True\n        except ValueError as err:\n            raise ConfigError(f\"Couldn't read config file {filename}: {err}\") from err\n\n        # Check that there are no unrecognized options.\n        all_options = collections.defaultdict(set)\n        for option_spec in self.CONFIG_FILE_OPTIONS:\n            section, option = option_spec[1].split(\":\")\n            all_options[section].add(option)\n\n        for section, options in all_options.items():\n            real_section = cp.real_section(section)\n            if real_section:\n                for unknown in set(cp.options(section)) - options:\n                    warn(\n                        \"Unrecognized option '[{}] {}=' in config file {}\".format(\n                            real_section, unknown, filename,\n                        ),\n                    )\n\n        # [paths] is special\n        if cp.has_section(\"paths\"):\n            for option in cp.options(\"paths\"):\n                self.paths[option] = cp.getlist(\"paths\", option)\n                any_set = True\n\n        # plugins can have options\n        for plugin in self.plugins:\n            if cp.has_section(plugin):\n                self.plugin_options[plugin] = cp.get_section(plugin)\n                any_set = True\n\n        # Was this file used as a config file? If it's specifically our file,\n        # then it was used.  If we're piggybacking on someone else's file,\n        # then it was only used if we found some settings in it.\n        if our_file:\n            used = True\n        else:\n            used = any_set\n\n        if used:\n            self.config_file = os.path.abspath(filename)\n            with open(filename, \"rb\") as f:\n                self._config_contents = f.read()\n\n        return used\n\n    def copy(self) -> CoverageConfig:\n        \"\"\"Return a copy of the configuration.\"\"\"\n        return copy.deepcopy(self)\n\n    CONCURRENCY_CHOICES = {\"thread\", \"gevent\", \"greenlet\", \"eventlet\", \"multiprocessing\"}\n\n    CONFIG_FILE_OPTIONS = [\n        # These are *args for _set_attr_from_config_option:\n        #   (attr, where, type_=\"\")\n        #\n        #   attr is the attribute to set on the CoverageConfig object.\n        #   where is the section:name to read from the configuration file.\n        #   type_ is the optional type to apply, by using .getTYPE to read the\n        #       configuration value from the file.\n\n        # [run]\n        (\"branch\", \"run:branch\", \"boolean\"),\n        (\"command_line\", \"run:command_line\"),\n        (\"concurrency\", \"run:concurrency\", \"list\"),\n        (\"context\", \"run:context\"),\n        (\"cover_pylib\", \"run:cover_pylib\", \"boolean\"),\n        (\"data_file\", \"run:data_file\"),\n        (\"debug\", \"run:debug\", \"list\"),\n        (\"debug_file\", \"run:debug_file\"),\n        (\"disable_warnings\", \"run:disable_warnings\", \"list\"),\n        (\"dynamic_context\", \"run:dynamic_context\"),\n        (\"parallel\", \"run:parallel\", \"boolean\"),\n        (\"plugins\", \"run:plugins\", \"list\"),\n        (\"relative_files\", \"run:relative_files\", \"boolean\"),\n        (\"run_include\", \"run:include\", \"list\"),\n        (\"run_omit\", \"run:omit\", \"list\"),\n        (\"sigterm\", \"run:sigterm\", \"boolean\"),\n        (\"source\", \"run:source\", \"list\"),\n        (\"source_pkgs\", \"run:source_pkgs\", \"list\"),\n        (\"timid\", \"run:timid\", \"boolean\"),\n        (\"_crash\", \"run:_crash\"),\n\n        # [report]\n        (\"exclude_list\", \"report:exclude_lines\", \"regexlist\"),\n        (\"exclude_also\", \"report:exclude_also\", \"regexlist\"),\n        (\"fail_under\", \"report:fail_under\", \"float\"),\n        (\"format\", \"report:format\"),\n        (\"ignore_errors\", \"report:ignore_errors\", \"boolean\"),\n        (\"include_namespace_packages\", \"report:include_namespace_packages\", \"boolean\"),\n        (\"partial_always_list\", \"report:partial_branches_always\", \"regexlist\"),\n        (\"partial_list\", \"report:partial_branches\", \"regexlist\"),\n        (\"precision\", \"report:precision\", \"int\"),\n        (\"report_contexts\", \"report:contexts\", \"list\"),\n        (\"report_include\", \"report:include\", \"list\"),\n        (\"report_omit\", \"report:omit\", \"list\"),\n        (\"show_missing\", \"report:show_missing\", \"boolean\"),\n        (\"skip_covered\", \"report:skip_covered\", \"boolean\"),\n        (\"skip_empty\", \"report:skip_empty\", \"boolean\"),\n        (\"sort\", \"report:sort\"),\n\n        # [html]\n        (\"extra_css\", \"html:extra_css\"),\n        (\"html_dir\", \"html:directory\"),\n        (\"html_skip_covered\", \"html:skip_covered\", \"boolean\"),\n        (\"html_skip_empty\", \"html:skip_empty\", \"boolean\"),\n        (\"html_title\", \"html:title\"),\n        (\"show_contexts\", \"html:show_contexts\", \"boolean\"),\n\n        # [xml]\n        (\"xml_output\", \"xml:output\"),\n        (\"xml_package_depth\", \"xml:package_depth\", \"int\"),\n\n        # [json]\n        (\"json_output\", \"json:output\"),\n        (\"json_pretty_print\", \"json:pretty_print\", \"boolean\"),\n        (\"json_show_contexts\", \"json:show_contexts\", \"boolean\"),\n\n        # [lcov]\n        (\"lcov_output\", \"lcov:output\"),\n    ]\n\n    def _set_attr_from_config_option(\n        self,\n        cp: TConfigParser,\n        attr: str,\n        where: str,\n        type_: str = \"\",\n    ) -> bool:\n        \"\"\"Set an attribute on self if it exists in the ConfigParser.\n\n        Returns True if the attribute was set.\n\n        \"\"\"\n        section, option = where.split(\":\")\n        if cp.has_option(section, option):\n            method = getattr(cp, \"get\" + type_)\n            setattr(self, attr, method(section, option))\n            return True\n        return False\n\n    def get_plugin_options(self, plugin: str) -> TConfigSectionOut:\n        \"\"\"Get a dictionary of options for the plugin named `plugin`.\"\"\"\n        return self.plugin_options.get(plugin, {})\n\n    def set_option(self, option_name: str, value: TConfigValueIn | TConfigSectionIn) -> None:\n        \"\"\"Set an option in the configuration.\n\n        `option_name` is a colon-separated string indicating the section and\n        option name.  For example, the ``branch`` option in the ``[run]``\n        section of the config file would be indicated with `\"run:branch\"`.\n\n        `value` is the new value for the option.\n\n        \"\"\"\n        # Special-cased options.\n        if option_name == \"paths\":\n            self.paths = value  # type: ignore[assignment]\n            return\n\n        # Check all the hard-coded options.\n        for option_spec in self.CONFIG_FILE_OPTIONS:\n            attr, where = option_spec[:2]\n            if where == option_name:\n                setattr(self, attr, value)\n                return\n\n        # See if it's a plugin option.\n        plugin_name, _, key = option_name.partition(\":\")\n        if key and plugin_name in self.plugins:\n            self.plugin_options.setdefault(plugin_name, {})[key] = value # type: ignore[index]\n            return\n\n        # If we get here, we didn't find the option.\n        raise ConfigError(f\"No such option: {option_name!r}\")\n\n    def get_option(self, option_name: str) -> TConfigValueOut | None:\n        \"\"\"Get an option from the configuration.\n\n        `option_name` is a colon-separated string indicating the section and\n        option name.  For example, the ``branch`` option in the ``[run]``\n        section of the config file would be indicated with `\"run:branch\"`.\n\n        Returns the value of the option.\n\n        \"\"\"\n        # Special-cased options.\n        if option_name == \"paths\":\n            return self.paths  # type: ignore[return-value]\n\n        # Check all the hard-coded options.\n        for option_spec in self.CONFIG_FILE_OPTIONS:\n            attr, where = option_spec[:2]\n            if where == option_name:\n                return getattr(self, attr)  # type: ignore[no-any-return]\n\n        # See if it's a plugin option.\n        plugin_name, _, key = option_name.partition(\":\")\n        if key and plugin_name in self.plugins:\n            return self.plugin_options.get(plugin_name, {}).get(key)\n\n        # If we get here, we didn't find the option.\n        raise ConfigError(f\"No such option: {option_name!r}\")\n\n    def post_process_file(self, path: str) -> str:\n        \"\"\"Make final adjustments to a file path to make it usable.\"\"\"\n        return os.path.expanduser(path)\n\n    def post_process(self) -> None:\n        \"\"\"Make final adjustments to settings to make them usable.\"\"\"\n        self.data_file = self.post_process_file(self.data_file)\n        self.html_dir = self.post_process_file(self.html_dir)\n        self.xml_output = self.post_process_file(self.xml_output)\n        self.paths = {\n            k: [self.post_process_file(f) for f in v]\n            for k, v in self.paths.items()\n        }\n        self.exclude_list += self.exclude_also\n\n    def debug_info(self) -> list[tuple[str, Any]]:\n        \"\"\"Make a list of (name, value) pairs for writing debug info.\"\"\"\n        return human_sorted_items(\n            (k, v) for k, v in self.__dict__.items() if not k.startswith(\"_\")\n        )\n\n\ndef config_files_to_try(config_file: bool | str) -> list[tuple[str, bool, bool]]:\n    \"\"\"What config files should we try to read?\n\n    Returns a list of tuples:\n        (filename, is_our_file, was_file_specified)\n    \"\"\"\n\n    # Some API users were specifying \".coveragerc\" to mean the same as\n    # True, so make it so.\n    if config_file == \".coveragerc\":\n        config_file = True\n    specified_file = (config_file is not True)\n    if not specified_file:\n        # No file was specified. Check COVERAGE_RCFILE.\n        rcfile = os.getenv(\"COVERAGE_RCFILE\")\n        if rcfile:\n            config_file = rcfile\n            specified_file = True\n    if not specified_file:\n        # Still no file specified. Default to .coveragerc\n        config_file = \".coveragerc\"\n    assert isinstance(config_file, str)\n    files_to_try = [\n        (config_file, True, specified_file),\n        (\"setup.cfg\", False, False),\n        (\"tox.ini\", False, False),\n        (\"pyproject.toml\", False, False),\n    ]\n    return files_to_try\n\n\ndef read_coverage_config(\n    config_file: bool | str,\n    warn: Callable[[str], None],\n    **kwargs: TConfigValueIn,\n) -> CoverageConfig:\n    \"\"\"Read the coverage.py configuration.\n\n    Arguments:\n        config_file: a boolean or string, see the `Coverage` class for the\n            tricky details.\n        warn: a function to issue warnings.\n        all others: keyword arguments from the `Coverage` class, used for\n            setting values in the configuration.\n\n    Returns:\n        config:\n            config is a CoverageConfig object read from the appropriate\n            configuration file.\n\n    \"\"\"\n    # Build the configuration from a number of sources:\n    # 1) defaults:\n    config = CoverageConfig()\n\n    # 2) from a file:\n    if config_file:\n        files_to_try = config_files_to_try(config_file)\n\n        for fname, our_file, specified_file in files_to_try:\n            config_read = config.from_file(fname, warn, our_file=our_file)\n            if config_read:\n                break\n            if specified_file:\n                raise ConfigError(f\"Couldn't read {fname!r} as a config file\")\n\n    # 3) from environment variables:\n    env_data_file = os.getenv(\"COVERAGE_FILE\")\n    if env_data_file:\n        config.data_file = env_data_file\n    # $set_env.py: COVERAGE_DEBUG - Debug options: https://coverage.rtfd.io/cmd.html#debug\n    debugs = os.getenv(\"COVERAGE_DEBUG\")\n    if debugs:\n        config.debug.extend(d.strip() for d in debugs.split(\",\"))\n\n    # 4) from constructor arguments:\n    config.from_args(**kwargs)\n\n    # 5) for our benchmark, force settings using a secret environment variable:\n    force_file = os.getenv(\"COVERAGE_FORCE_CONFIG\")\n    if force_file:\n        config.from_file(force_file, warn, our_file=True)\n\n    # Once all the config has been collected, there's a little post-processing\n    # to do.\n    config.post_process()\n\n    return config\n", "coverage/regions.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Find functions and classes in Python code.\"\"\"\n\nfrom __future__ import annotations\n\nimport ast\nimport dataclasses\n\nfrom typing import cast\n\nfrom coverage.plugin import CodeRegion\n\n\n@dataclasses.dataclass\nclass Context:\n    \"\"\"The nested named context of a function or class.\"\"\"\n    name: str\n    kind: str\n    lines: set[int]\n\n\nclass RegionFinder:\n    \"\"\"An ast visitor that will find and track regions of code.\n\n    Functions and classes are tracked by name. Results are in the .regions\n    attribute.\n\n    \"\"\"\n    def __init__(self) -> None:\n        self.regions: list[CodeRegion] = []\n        self.context: list[Context] = []\n\n    def parse_source(self, source: str) -> None:\n        \"\"\"Parse `source` and walk the ast to populate the .regions attribute.\"\"\"\n        self.handle_node(ast.parse(source))\n\n    def fq_node_name(self) -> str:\n        \"\"\"Get the current fully qualified name we're processing.\"\"\"\n        return \".\".join(c.name for c in self.context)\n\n    def handle_node(self, node: ast.AST) -> None:\n        \"\"\"Recursively handle any node.\"\"\"\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            self.handle_FunctionDef(node)\n        elif isinstance(node, ast.ClassDef):\n            self.handle_ClassDef(node)\n        else:\n            self.handle_node_body(node)\n\n    def handle_node_body(self, node: ast.AST) -> None:\n        \"\"\"Recursively handle the nodes in this node's body, if any.\"\"\"\n        for body_node in getattr(node, \"body\", ()):\n            self.handle_node(body_node)\n\n    def handle_FunctionDef(self, node: ast.FunctionDef | ast.AsyncFunctionDef) -> None:\n        \"\"\"Called for `def` or `async def`.\"\"\"\n        lines = set(range(node.body[0].lineno, cast(int, node.body[-1].end_lineno) + 1))\n        if self.context and self.context[-1].kind == \"class\":\n            # Function bodies are part of their enclosing class.\n            self.context[-1].lines |= lines\n        # Function bodies should be excluded from the nearest enclosing function.\n        for ancestor in reversed(self.context):\n            if ancestor.kind == \"function\":\n                ancestor.lines -= lines\n                break\n        self.context.append(Context(node.name, \"function\", lines))\n        self.regions.append(\n            CodeRegion(\n                kind=\"function\",\n                name=self.fq_node_name(),\n                start=node.lineno,\n                lines=lines,\n            )\n        )\n        self.handle_node_body(node)\n        self.context.pop()\n\n    def handle_ClassDef(self, node: ast.ClassDef) -> None:\n        \"\"\"Called for `class`.\"\"\"\n        # The lines for a class are the lines in the methods of the class.\n        # We start empty, and count on visit_FunctionDef to add the lines it\n        # finds.\n        lines: set[int] = set()\n        self.context.append(Context(node.name, \"class\", lines))\n        self.regions.append(\n            CodeRegion(\n                kind=\"class\",\n                name=self.fq_node_name(),\n                start=node.lineno,\n                lines=lines,\n            )\n        )\n        self.handle_node_body(node)\n        self.context.pop()\n        # Class bodies should be excluded from the enclosing classes.\n        for ancestor in reversed(self.context):\n            if ancestor.kind == \"class\":\n                ancestor.lines -= lines\n\n\ndef code_regions(source: str) -> list[CodeRegion]:\n    \"\"\"Find function and class regions in source code.\n\n    Analyzes the code in `source`, and returns a list of :class:`CodeRegion`\n    objects describing functions and classes as regions of the code::\n\n        [\n            CodeRegion(kind=\"function\", name=\"func1\", start=8, lines={10, 11, 12}),\n            CodeRegion(kind=\"function\", name=\"MyClass.method\", start=30, lines={34, 35, 36}),\n            CodeRegion(kind=\"class\", name=\"MyClass\", start=25, lines={34, 35, 36}),\n        ]\n\n    The line numbers will include comments and blank lines.  Later processing\n    will need to ignore those lines as needed.\n\n    Nested functions and classes are excluded from their enclosing region.  No\n    line should be reported as being part of more than one function, or more\n    than one class.  Lines in methods are reported as being in a function and\n    in a class.\n\n    \"\"\"\n    rf = RegionFinder()\n    rf.parse_source(source)\n    return rf.regions\n", "coverage/exceptions.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Exceptions coverage.py can raise.\"\"\"\n\nfrom __future__ import annotations\n\nclass _BaseCoverageException(Exception):\n    \"\"\"The base-base of all Coverage exceptions.\"\"\"\n    pass\n\n\nclass CoverageException(_BaseCoverageException):\n    \"\"\"The base class of all exceptions raised by Coverage.py.\"\"\"\n    pass\n\n\nclass ConfigError(_BaseCoverageException):\n    \"\"\"A problem with a config file, or a value in one.\"\"\"\n    pass\n\n\nclass DataError(CoverageException):\n    \"\"\"An error in using a data file.\"\"\"\n    pass\n\nclass NoDataError(CoverageException):\n    \"\"\"We didn't have data to work with.\"\"\"\n    pass\n\n\nclass NoSource(CoverageException):\n    \"\"\"We couldn't find the source for a module.\"\"\"\n    pass\n\n\nclass NoCode(NoSource):\n    \"\"\"We couldn't find any code at all.\"\"\"\n    pass\n\n\nclass NotPython(CoverageException):\n    \"\"\"A source file turned out not to be parsable Python.\"\"\"\n    pass\n\n\nclass PluginError(CoverageException):\n    \"\"\"A plugin misbehaved.\"\"\"\n    pass\n\n\nclass _ExceptionDuringRun(CoverageException):\n    \"\"\"An exception happened while running customer code.\n\n    Construct it with three arguments, the values from `sys.exc_info`.\n\n    \"\"\"\n    pass\n\n\nclass CoverageWarning(Warning):\n    \"\"\"A warning from Coverage.py.\"\"\"\n    pass\n", "coverage/inorout.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Determining whether files are being measured/reported or not.\"\"\"\n\nfrom __future__ import annotations\n\nimport importlib.util\nimport inspect\nimport itertools\nimport os\nimport platform\nimport re\nimport sys\nimport sysconfig\nimport traceback\n\nfrom types import FrameType, ModuleType\nfrom typing import (\n    cast, Any, Iterable, TYPE_CHECKING,\n)\n\nfrom coverage import env\nfrom coverage.disposition import FileDisposition, disposition_init\nfrom coverage.exceptions import CoverageException, PluginError\nfrom coverage.files import TreeMatcher, GlobMatcher, ModuleMatcher\nfrom coverage.files import prep_patterns, find_python_files, canonical_filename\nfrom coverage.misc import sys_modules_saved\nfrom coverage.python import source_for_file, source_for_morf\nfrom coverage.types import TFileDisposition, TMorf, TWarnFn, TDebugCtl\n\nif TYPE_CHECKING:\n    from coverage.config import CoverageConfig\n    from coverage.plugin_support import Plugins\n\n\n# Pypy has some unusual stuff in the \"stdlib\".  Consider those locations\n# when deciding where the stdlib is.  These modules are not used for anything,\n# they are modules importable from the pypy lib directories, so that we can\n# find those directories.\nmodules_we_happen_to_have: list[ModuleType] = [\n    inspect, itertools, os, platform, re, sysconfig, traceback,\n]\n\nif env.PYPY:\n    try:\n        import _structseq\n        modules_we_happen_to_have.append(_structseq)\n    except ImportError:\n        pass\n\n    try:\n        import _pypy_irc_topic\n        modules_we_happen_to_have.append(_pypy_irc_topic)\n    except ImportError:\n        pass\n\n\ndef canonical_path(morf: TMorf, directory: bool = False) -> str:\n    \"\"\"Return the canonical path of the module or file `morf`.\n\n    If the module is a package, then return its directory. If it is a\n    module, then return its file, unless `directory` is True, in which\n    case return its enclosing directory.\n\n    \"\"\"\n    morf_path = canonical_filename(source_for_morf(morf))\n    if morf_path.endswith(\"__init__.py\") or directory:\n        morf_path = os.path.split(morf_path)[0]\n    return morf_path\n\n\ndef name_for_module(filename: str, frame: FrameType | None) -> str:\n    \"\"\"Get the name of the module for a filename and frame.\n\n    For configurability's sake, we allow __main__ modules to be matched by\n    their importable name.\n\n    If loaded via runpy (aka -m), we can usually recover the \"original\"\n    full dotted module name, otherwise, we resort to interpreting the\n    file name to get the module's name.  In the case that the module name\n    can't be determined, None is returned.\n\n    \"\"\"\n    module_globals = frame.f_globals if frame is not None else {}\n    dunder_name: str = module_globals.get(\"__name__\", None)\n\n    if isinstance(dunder_name, str) and dunder_name != \"__main__\":\n        # This is the usual case: an imported module.\n        return dunder_name\n\n    spec = module_globals.get(\"__spec__\", None)\n    if spec:\n        fullname = spec.name\n        if isinstance(fullname, str) and fullname != \"__main__\":\n            # Module loaded via: runpy -m\n            return fullname\n\n    # Script as first argument to Python command line.\n    inspectedname = inspect.getmodulename(filename)\n    if inspectedname is not None:\n        return inspectedname\n    else:\n        return dunder_name\n\n\ndef module_is_namespace(mod: ModuleType) -> bool:\n    \"\"\"Is the module object `mod` a PEP420 namespace module?\"\"\"\n    return hasattr(mod, \"__path__\") and getattr(mod, \"__file__\", None) is None\n\n\ndef module_has_file(mod: ModuleType) -> bool:\n    \"\"\"Does the module object `mod` have an existing __file__ ?\"\"\"\n    mod__file__ = getattr(mod, \"__file__\", None)\n    if mod__file__ is None:\n        return False\n    return os.path.exists(mod__file__)\n\n\ndef file_and_path_for_module(modulename: str) -> tuple[str | None, list[str]]:\n    \"\"\"Find the file and search path for `modulename`.\n\n    Returns:\n        filename: The filename of the module, or None.\n        path: A list (possibly empty) of directories to find submodules in.\n\n    \"\"\"\n    filename = None\n    path = []\n    try:\n        spec = importlib.util.find_spec(modulename)\n    except Exception:\n        pass\n    else:\n        if spec is not None:\n            filename = spec.origin\n            path = list(spec.submodule_search_locations or ())\n    return filename, path\n\n\ndef add_stdlib_paths(paths: set[str]) -> None:\n    \"\"\"Add paths where the stdlib can be found to the set `paths`.\"\"\"\n    # Look at where some standard modules are located. That's the\n    # indication for \"installed with the interpreter\". In some\n    # environments (virtualenv, for example), these modules may be\n    # spread across a few locations. Look at all the candidate modules\n    # we've imported, and take all the different ones.\n    for m in modules_we_happen_to_have:\n        if hasattr(m, \"__file__\"):\n            paths.add(canonical_path(m, directory=True))\n\n\ndef add_third_party_paths(paths: set[str]) -> None:\n    \"\"\"Add locations for third-party packages to the set `paths`.\"\"\"\n    # Get the paths that sysconfig knows about.\n    scheme_names = set(sysconfig.get_scheme_names())\n\n    for scheme in scheme_names:\n        # https://foss.heptapod.net/pypy/pypy/-/issues/3433\n        better_scheme = \"pypy_posix\" if scheme == \"pypy\" else scheme\n        if os.name in better_scheme.split(\"_\"):\n            config_paths = sysconfig.get_paths(scheme)\n            for path_name in [\"platlib\", \"purelib\", \"scripts\"]:\n                paths.add(config_paths[path_name])\n\n\ndef add_coverage_paths(paths: set[str]) -> None:\n    \"\"\"Add paths where coverage.py code can be found to the set `paths`.\"\"\"\n    cover_path = canonical_path(__file__, directory=True)\n    paths.add(cover_path)\n    if env.TESTING:\n        # Don't include our own test code.\n        paths.add(os.path.join(cover_path, \"tests\"))\n\n\nclass InOrOut:\n    \"\"\"Machinery for determining what files to measure.\"\"\"\n\n    def __init__(\n        self,\n        config: CoverageConfig,\n        warn: TWarnFn,\n        debug: TDebugCtl | None,\n        include_namespace_packages: bool,\n    ) -> None:\n        self.warn = warn\n        self.debug = debug\n        self.include_namespace_packages = include_namespace_packages\n\n        self.source: list[str] = []\n        self.source_pkgs: list[str] = []\n        self.source_pkgs.extend(config.source_pkgs)\n        for src in config.source or []:\n            if os.path.isdir(src):\n                self.source.append(canonical_filename(src))\n            else:\n                self.source_pkgs.append(src)\n        self.source_pkgs_unmatched = self.source_pkgs[:]\n\n        self.include = prep_patterns(config.run_include)\n        self.omit = prep_patterns(config.run_omit)\n\n        # The directories for files considered \"installed with the interpreter\".\n        self.pylib_paths: set[str] = set()\n        if not config.cover_pylib:\n            add_stdlib_paths(self.pylib_paths)\n\n        # To avoid tracing the coverage.py code itself, we skip anything\n        # located where we are.\n        self.cover_paths: set[str] = set()\n        add_coverage_paths(self.cover_paths)\n\n        # Find where third-party packages are installed.\n        self.third_paths: set[str] = set()\n        add_third_party_paths(self.third_paths)\n\n        def _debug(msg: str) -> None:\n            if self.debug:\n                self.debug.write(msg)\n\n        # The matchers for should_trace.\n\n        # Generally useful information\n        _debug(\"sys.path:\" + \"\".join(f\"\\n    {p}\" for p in sys.path))\n\n        # Create the matchers we need for should_trace\n        self.source_match = None\n        self.source_pkgs_match = None\n        self.pylib_match = None\n        self.include_match = self.omit_match = None\n\n        if self.source or self.source_pkgs:\n            against = []\n            if self.source:\n                self.source_match = TreeMatcher(self.source, \"source\")\n                against.append(f\"trees {self.source_match!r}\")\n            if self.source_pkgs:\n                self.source_pkgs_match = ModuleMatcher(self.source_pkgs, \"source_pkgs\")\n                against.append(f\"modules {self.source_pkgs_match!r}\")\n            _debug(\"Source matching against \" + \" and \".join(against))\n        else:\n            if self.pylib_paths:\n                self.pylib_match = TreeMatcher(self.pylib_paths, \"pylib\")\n                _debug(f\"Python stdlib matching: {self.pylib_match!r}\")\n        if self.include:\n            self.include_match = GlobMatcher(self.include, \"include\")\n            _debug(f\"Include matching: {self.include_match!r}\")\n        if self.omit:\n            self.omit_match = GlobMatcher(self.omit, \"omit\")\n            _debug(f\"Omit matching: {self.omit_match!r}\")\n\n        self.cover_match = TreeMatcher(self.cover_paths, \"coverage\")\n        _debug(f\"Coverage code matching: {self.cover_match!r}\")\n\n        self.third_match = TreeMatcher(self.third_paths, \"third\")\n        _debug(f\"Third-party lib matching: {self.third_match!r}\")\n\n        # Check if the source we want to measure has been installed as a\n        # third-party package.\n        # Is the source inside a third-party area?\n        self.source_in_third_paths = set()\n        with sys_modules_saved():\n            for pkg in self.source_pkgs:\n                try:\n                    modfile, path = file_and_path_for_module(pkg)\n                    _debug(f\"Imported source package {pkg!r} as {modfile!r}\")\n                except CoverageException as exc:\n                    _debug(f\"Couldn't import source package {pkg!r}: {exc}\")\n                    continue\n                if modfile:\n                    if self.third_match.match(modfile):\n                        _debug(\n                            f\"Source in third-party: source_pkg {pkg!r} at {modfile!r}\",\n                        )\n                        self.source_in_third_paths.add(canonical_path(source_for_file(modfile)))\n                else:\n                    for pathdir in path:\n                        if self.third_match.match(pathdir):\n                            _debug(\n                                f\"Source in third-party: {pkg!r} path directory at {pathdir!r}\",\n                            )\n                            self.source_in_third_paths.add(pathdir)\n\n        for src in self.source:\n            if self.third_match.match(src):\n                _debug(f\"Source in third-party: source directory {src!r}\")\n                self.source_in_third_paths.add(src)\n        self.source_in_third_match = TreeMatcher(self.source_in_third_paths, \"source_in_third\")\n        _debug(f\"Source in third-party matching: {self.source_in_third_match}\")\n\n        self.plugins: Plugins\n        self.disp_class: type[TFileDisposition] = FileDisposition\n\n    def should_trace(self, filename: str, frame: FrameType | None = None) -> TFileDisposition:\n        \"\"\"Decide whether to trace execution in `filename`, with a reason.\n\n        This function is called from the trace function.  As each new file name\n        is encountered, this function determines whether it is traced or not.\n\n        Returns a FileDisposition object.\n\n        \"\"\"\n        original_filename = filename\n        disp = disposition_init(self.disp_class, filename)\n\n        def nope(disp: TFileDisposition, reason: str) -> TFileDisposition:\n            \"\"\"Simple helper to make it easy to return NO.\"\"\"\n            disp.trace = False\n            disp.reason = reason\n            return disp\n\n        if original_filename.startswith(\"<\"):\n            return nope(disp, \"original file name is not real\")\n\n        if frame is not None:\n            # Compiled Python files have two file names: frame.f_code.co_filename is\n            # the file name at the time the .pyc was compiled.  The second name is\n            # __file__, which is where the .pyc was actually loaded from.  Since\n            # .pyc files can be moved after compilation (for example, by being\n            # installed), we look for __file__ in the frame and prefer it to the\n            # co_filename value.\n            dunder_file = frame.f_globals and frame.f_globals.get(\"__file__\")\n            if dunder_file:\n                filename = source_for_file(dunder_file)\n                if original_filename and not original_filename.startswith(\"<\"):\n                    orig = os.path.basename(original_filename)\n                    if orig != os.path.basename(filename):\n                        # Files shouldn't be renamed when moved. This happens when\n                        # exec'ing code.  If it seems like something is wrong with\n                        # the frame's file name, then just use the original.\n                        filename = original_filename\n\n        if not filename:\n            # Empty string is pretty useless.\n            return nope(disp, \"empty string isn't a file name\")\n\n        if filename.startswith(\"memory:\"):\n            return nope(disp, \"memory isn't traceable\")\n\n        if filename.startswith(\"<\"):\n            # Lots of non-file execution is represented with artificial\n            # file names like \"<string>\", \"<doctest readme.txt[0]>\", or\n            # \"<exec_function>\".  Don't ever trace these executions, since we\n            # can't do anything with the data later anyway.\n            return nope(disp, \"file name is not real\")\n\n        canonical = canonical_filename(filename)\n        disp.canonical_filename = canonical\n\n        # Try the plugins, see if they have an opinion about the file.\n        plugin = None\n        for plugin in self.plugins.file_tracers:\n            if not plugin._coverage_enabled:\n                continue\n\n            try:\n                file_tracer = plugin.file_tracer(canonical)\n                if file_tracer is not None:\n                    file_tracer._coverage_plugin = plugin\n                    disp.trace = True\n                    disp.file_tracer = file_tracer\n                    if file_tracer.has_dynamic_source_filename():\n                        disp.has_dynamic_filename = True\n                    else:\n                        disp.source_filename = canonical_filename(\n                            file_tracer.source_filename(),\n                        )\n                    break\n            except Exception:\n                plugin_name = plugin._coverage_plugin_name\n                tb = traceback.format_exc()\n                self.warn(f\"Disabling plug-in {plugin_name!r} due to an exception:\\n{tb}\")\n                plugin._coverage_enabled = False\n                continue\n        else:\n            # No plugin wanted it: it's Python.\n            disp.trace = True\n            disp.source_filename = canonical\n\n        if not disp.has_dynamic_filename:\n            if not disp.source_filename:\n                raise PluginError(\n                    f\"Plugin {plugin!r} didn't set source_filename for '{disp.original_filename}'\",\n                )\n            reason = self.check_include_omit_etc(disp.source_filename, frame)\n            if reason:\n                nope(disp, reason)\n\n        return disp\n\n    def check_include_omit_etc(self, filename: str, frame: FrameType | None) -> str | None:\n        \"\"\"Check a file name against the include, omit, etc, rules.\n\n        Returns a string or None.  String means, don't trace, and is the reason\n        why.  None means no reason found to not trace.\n\n        \"\"\"\n        modulename = name_for_module(filename, frame)\n\n        # If the user specified source or include, then that's authoritative\n        # about the outer bound of what to measure and we don't have to apply\n        # any canned exclusions. If they didn't, then we have to exclude the\n        # stdlib and coverage.py directories.\n        if self.source_match or self.source_pkgs_match:\n            extra = \"\"\n            ok = False\n            if self.source_pkgs_match:\n                if self.source_pkgs_match.match(modulename):\n                    ok = True\n                    if modulename in self.source_pkgs_unmatched:\n                        self.source_pkgs_unmatched.remove(modulename)\n                else:\n                    extra = f\"module {modulename!r} \"\n            if not ok and self.source_match:\n                if self.source_match.match(filename):\n                    ok = True\n            if not ok:\n                return extra + \"falls outside the --source spec\"\n            if self.third_match.match(filename) and not self.source_in_third_match.match(filename):\n                return \"inside --source, but is third-party\"\n        elif self.include_match:\n            if not self.include_match.match(filename):\n                return \"falls outside the --include trees\"\n        else:\n            # We exclude the coverage.py code itself, since a little of it\n            # will be measured otherwise.\n            if self.cover_match.match(filename):\n                return \"is part of coverage.py\"\n\n            # If we aren't supposed to trace installed code, then check if this\n            # is near the Python standard library and skip it if so.\n            if self.pylib_match and self.pylib_match.match(filename):\n                return \"is in the stdlib\"\n\n            # Exclude anything in the third-party installation areas.\n            if self.third_match.match(filename):\n                return \"is a third-party module\"\n\n        # Check the file against the omit pattern.\n        if self.omit_match and self.omit_match.match(filename):\n            return \"is inside an --omit pattern\"\n\n        # No point tracing a file we can't later write to SQLite.\n        try:\n            filename.encode(\"utf-8\")\n        except UnicodeEncodeError:\n            return \"non-encodable filename\"\n\n        # No reason found to skip this file.\n        return None\n\n    def warn_conflicting_settings(self) -> None:\n        \"\"\"Warn if there are settings that conflict.\"\"\"\n        if self.include:\n            if self.source or self.source_pkgs:\n                self.warn(\"--include is ignored because --source is set\", slug=\"include-ignored\")\n\n    def warn_already_imported_files(self) -> None:\n        \"\"\"Warn if files have already been imported that we will be measuring.\"\"\"\n        if self.include or self.source or self.source_pkgs:\n            warned = set()\n            for mod in list(sys.modules.values()):\n                filename = getattr(mod, \"__file__\", None)\n                if filename is None:\n                    continue\n                if filename in warned:\n                    continue\n\n                if len(getattr(mod, \"__path__\", ())) > 1:\n                    # A namespace package, which confuses this code, so ignore it.\n                    continue\n\n                disp = self.should_trace(filename)\n                if disp.has_dynamic_filename:\n                    # A plugin with dynamic filenames: the Python file\n                    # shouldn't cause a warning, since it won't be the subject\n                    # of tracing anyway.\n                    continue\n                if disp.trace:\n                    msg = f\"Already imported a file that will be measured: {filename}\"\n                    self.warn(msg, slug=\"already-imported\")\n                    warned.add(filename)\n                elif self.debug and self.debug.should(\"trace\"):\n                    self.debug.write(\n                        \"Didn't trace already imported file {!r}: {}\".format(\n                            disp.original_filename, disp.reason,\n                        ),\n                    )\n\n    def warn_unimported_source(self) -> None:\n        \"\"\"Warn about source packages that were of interest, but never traced.\"\"\"\n        for pkg in self.source_pkgs_unmatched:\n            self._warn_about_unmeasured_code(pkg)\n\n    def _warn_about_unmeasured_code(self, pkg: str) -> None:\n        \"\"\"Warn about a package or module that we never traced.\n\n        `pkg` is a string, the name of the package or module.\n\n        \"\"\"\n        mod = sys.modules.get(pkg)\n        if mod is None:\n            self.warn(f\"Module {pkg} was never imported.\", slug=\"module-not-imported\")\n            return\n\n        if module_is_namespace(mod):\n            # A namespace package. It's OK for this not to have been traced,\n            # since there is no code directly in it.\n            return\n\n        if not module_has_file(mod):\n            self.warn(f\"Module {pkg} has no Python source.\", slug=\"module-not-python\")\n            return\n\n        # The module was in sys.modules, and seems like a module with code, but\n        # we never measured it. I guess that means it was imported before\n        # coverage even started.\n        msg = f\"Module {pkg} was previously imported, but not measured\"\n        self.warn(msg, slug=\"module-not-measured\")\n\n    def find_possibly_unexecuted_files(self) -> Iterable[tuple[str, str | None]]:\n        \"\"\"Find files in the areas of interest that might be untraced.\n\n        Yields pairs: file path, and responsible plug-in name.\n        \"\"\"\n        for pkg in self.source_pkgs:\n            if (pkg not in sys.modules or\n                not module_has_file(sys.modules[pkg])):\n                continue\n            pkg_file = source_for_file(cast(str, sys.modules[pkg].__file__))\n            yield from self._find_executable_files(canonical_path(pkg_file))\n\n        for src in self.source:\n            yield from self._find_executable_files(src)\n\n    def _find_plugin_files(self, src_dir: str) -> Iterable[tuple[str, str]]:\n        \"\"\"Get executable files from the plugins.\"\"\"\n        for plugin in self.plugins.file_tracers:\n            for x_file in plugin.find_executable_files(src_dir):\n                yield x_file, plugin._coverage_plugin_name\n\n    def _find_executable_files(self, src_dir: str) -> Iterable[tuple[str, str | None]]:\n        \"\"\"Find executable files in `src_dir`.\n\n        Search for files in `src_dir` that can be executed because they\n        are probably importable. Don't include ones that have been omitted\n        by the configuration.\n\n        Yield the file path, and the plugin name that handles the file.\n\n        \"\"\"\n        py_files = (\n            (py_file, None) for py_file in\n            find_python_files(src_dir, self.include_namespace_packages)\n        )\n        plugin_files = self._find_plugin_files(src_dir)\n\n        for file_path, plugin_name in itertools.chain(py_files, plugin_files):\n            file_path = canonical_filename(file_path)\n            if self.omit_match and self.omit_match.match(file_path):\n                # Turns out this file was omitted, so don't pull it back\n                # in as un-executed.\n                continue\n            yield file_path, plugin_name\n\n    def sys_info(self) -> Iterable[tuple[str, Any]]:\n        \"\"\"Our information for Coverage.sys_info.\n\n        Returns a list of (key, value) pairs.\n        \"\"\"\n        info = [\n            (\"coverage_paths\", self.cover_paths),\n            (\"stdlib_paths\", self.pylib_paths),\n            (\"third_party_paths\", self.third_paths),\n            (\"source_in_third_party_paths\", self.source_in_third_paths),\n        ]\n\n        matcher_names = [\n            \"source_match\", \"source_pkgs_match\",\n            \"include_match\", \"omit_match\",\n            \"cover_match\", \"pylib_match\", \"third_match\", \"source_in_third_match\",\n        ]\n\n        for matcher_name in matcher_names:\n            matcher = getattr(self, matcher_name)\n            if matcher:\n                matcher_info = matcher.info()\n            else:\n                matcher_info = \"-none-\"\n            info.append((matcher_name, matcher_info))\n\n        return info\n", "coverage/pytracer.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Raw data collector for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport atexit\nimport dis\nimport itertools\nimport sys\nimport threading\n\nfrom types import FrameType, ModuleType\nfrom typing import Any, Callable, Set, cast\n\nfrom coverage import env\nfrom coverage.types import (\n    TArc, TFileDisposition, TLineNo, TTraceData, TTraceFileData, TTraceFn,\n    TracerCore, TWarnFn,\n)\n\n# We need the YIELD_VALUE opcode below, in a comparison-friendly form.\n# PYVERSIONS: RESUME is new in Python3.11\nRESUME = dis.opmap.get(\"RESUME\")\nRETURN_VALUE = dis.opmap[\"RETURN_VALUE\"]\nif RESUME is None:\n    YIELD_VALUE = dis.opmap[\"YIELD_VALUE\"]\n    YIELD_FROM = dis.opmap[\"YIELD_FROM\"]\n    YIELD_FROM_OFFSET = 0 if env.PYPY else 2\nelse:\n    YIELD_VALUE = YIELD_FROM = YIELD_FROM_OFFSET = -1\n\n# When running meta-coverage, this file can try to trace itself, which confuses\n# everything.  Don't trace ourselves.\n\nTHIS_FILE = __file__.rstrip(\"co\")\n\nclass PyTracer(TracerCore):\n    \"\"\"Python implementation of the raw data tracer.\"\"\"\n\n    # Because of poor implementations of trace-function-manipulating tools,\n    # the Python trace function must be kept very simple.  In particular, there\n    # must be only one function ever set as the trace function, both through\n    # sys.settrace, and as the return value from the trace function.  Put\n    # another way, the trace function must always return itself.  It cannot\n    # swap in other functions, or return None to avoid tracing a particular\n    # frame.\n    #\n    # The trace manipulator that introduced this restriction is DecoratorTools,\n    # which sets a trace function, and then later restores the pre-existing one\n    # by calling sys.settrace with a function it found in the current frame.\n    #\n    # Systems that use DecoratorTools (or similar trace manipulations) must use\n    # PyTracer to get accurate results.  The command-line --timid argument is\n    # used to force the use of this tracer.\n\n    tracer_ids = itertools.count()\n\n    def __init__(self) -> None:\n        # Which tracer are we?\n        self.id = next(self.tracer_ids)\n\n        # Attributes set from the collector:\n        self.data: TTraceData\n        self.trace_arcs = False\n        self.should_trace: Callable[[str, FrameType], TFileDisposition]\n        self.should_trace_cache: dict[str, TFileDisposition | None]\n        self.should_start_context: Callable[[FrameType], str | None] | None = None\n        self.switch_context: Callable[[str | None], None] | None = None\n        self.lock_data: Callable[[], None]\n        self.unlock_data: Callable[[], None]\n        self.warn: TWarnFn\n\n        # The threading module to use, if any.\n        self.threading: ModuleType | None = None\n\n        self.cur_file_data: TTraceFileData | None = None\n        self.last_line: TLineNo = 0\n        self.cur_file_name: str | None = None\n        self.context: str | None = None\n        self.started_context = False\n\n        # The data_stack parallels the Python call stack. Each entry is\n        # information about an active frame, a four-element tuple:\n        #   [0] The TTraceData for this frame's file. Could be None if we\n        #           aren't tracing this frame.\n        #   [1] The current file name for the frame. None if we aren't tracing\n        #           this frame.\n        #   [2] The last line number executed in this frame.\n        #   [3] Boolean: did this frame start a new context?\n        self.data_stack: list[tuple[TTraceFileData | None, str | None, TLineNo, bool]] = []\n        self.thread: threading.Thread | None = None\n        self.stopped = False\n        self._activity = False\n\n        self.in_atexit = False\n        # On exit, self.in_atexit = True\n        atexit.register(setattr, self, \"in_atexit\", True)\n\n        # Cache a bound method on the instance, so that we don't have to\n        # re-create a bound method object all the time.\n        self._cached_bound_method_trace: TTraceFn = self._trace\n\n    def __repr__(self) -> str:\n        points = sum(len(v) for v in self.data.values())\n        files = len(self.data)\n        return f\"<PyTracer at {id(self):#x}: {points} data points in {files} files>\"\n\n    def log(self, marker: str, *args: Any) -> None:\n        \"\"\"For hard-core logging of what this tracer is doing.\"\"\"\n        with open(\"/tmp/debug_trace.txt\", \"a\") as f:\n            f.write(f\"{marker} {self.id}[{len(self.data_stack)}]\")\n            if 0:   # if you want thread ids..\n                f.write(\".{:x}.{:x}\".format(                    # type: ignore[unreachable]\n                    self.thread.ident,\n                    self.threading.current_thread().ident,\n                ))\n            f.write(\" {}\".format(\" \".join(map(str, args))))\n            if 0:   # if you want callers..\n                f.write(\" | \")                                  # type: ignore[unreachable]\n                stack = \" / \".join(\n                    (fname or \"???\").rpartition(\"/\")[-1]\n                    for _, fname, _, _ in self.data_stack\n                )\n                f.write(stack)\n            f.write(\"\\n\")\n\n    def _trace(\n        self,\n        frame: FrameType,\n        event: str,\n        arg: Any,                               # pylint: disable=unused-argument\n        lineno: TLineNo | None = None,       # pylint: disable=unused-argument\n    ) -> TTraceFn | None:\n        \"\"\"The trace function passed to sys.settrace.\"\"\"\n\n        if THIS_FILE in frame.f_code.co_filename:\n            return None\n\n        # f = frame; code = f.f_code\n        # self.log(\":\", f\"{code.co_filename} {f.f_lineno} {code.co_name}()\", event)\n\n        if (self.stopped and sys.gettrace() == self._cached_bound_method_trace):    # pylint: disable=comparison-with-callable\n            # The PyTrace.stop() method has been called, possibly by another\n            # thread, let's deactivate ourselves now.\n            if 0:\n                f = frame                           # type: ignore[unreachable]\n                self.log(\"---\\nX\", f.f_code.co_filename, f.f_lineno)\n                while f:\n                    self.log(\">\", f.f_code.co_filename, f.f_lineno, f.f_code.co_name, f.f_trace)\n                    f = f.f_back\n            sys.settrace(None)\n            try:\n                self.cur_file_data, self.cur_file_name, self.last_line, self.started_context = (\n                    self.data_stack.pop()\n                )\n            except IndexError:\n                self.log(\n                    \"Empty stack!\",\n                    frame.f_code.co_filename,\n                    frame.f_lineno,\n                    frame.f_code.co_name,\n                )\n            return None\n\n        # if event != \"call\" and frame.f_code.co_filename != self.cur_file_name:\n        #     self.log(\"---\\n*\", frame.f_code.co_filename, self.cur_file_name, frame.f_lineno)\n\n        if event == \"call\":\n            # Should we start a new context?\n            if self.should_start_context and self.context is None:\n                context_maybe = self.should_start_context(frame)    # pylint: disable=not-callable\n                if context_maybe is not None:\n                    self.context = context_maybe\n                    started_context = True\n                    assert self.switch_context is not None\n                    self.switch_context(self.context)   # pylint: disable=not-callable\n                else:\n                    started_context = False\n            else:\n                started_context = False\n            self.started_context = started_context\n\n            # Entering a new frame.  Decide if we should trace in this file.\n            self._activity = True\n            self.data_stack.append(\n                (\n                    self.cur_file_data,\n                    self.cur_file_name,\n                    self.last_line,\n                    started_context,\n                ),\n            )\n\n            # Improve tracing performance: when calling a function, both caller\n            # and callee are often within the same file. if that's the case, we\n            # don't have to re-check whether to trace the corresponding\n            # function (which is a little bit expensive since it involves\n            # dictionary lookups). This optimization is only correct if we\n            # didn't start a context.\n            filename = frame.f_code.co_filename\n            if filename != self.cur_file_name or started_context:\n                self.cur_file_name = filename\n                disp = self.should_trace_cache.get(filename)\n                if disp is None:\n                    disp = self.should_trace(filename, frame)\n                    self.should_trace_cache[filename] = disp\n\n                self.cur_file_data = None\n                if disp.trace:\n                    tracename = disp.source_filename\n                    assert tracename is not None\n                    self.lock_data()\n                    try:\n                        if tracename not in self.data:\n                            self.data[tracename] = set()\n                    finally:\n                        self.unlock_data()\n                    self.cur_file_data = self.data[tracename]\n                else:\n                    frame.f_trace_lines = False\n            elif not self.cur_file_data:\n                frame.f_trace_lines = False\n\n            # The call event is really a \"start frame\" event, and happens for\n            # function calls and re-entering generators.  The f_lasti field is\n            # -1 for calls, and a real offset for generators.  Use <0 as the\n            # line number for calls, and the real line number for generators.\n            if RESUME is not None:\n                # The current opcode is guaranteed to be RESUME. The argument\n                # determines what kind of resume it is.\n                oparg = frame.f_code.co_code[frame.f_lasti + 1]\n                real_call = (oparg == 0)\n            else:\n                real_call = (getattr(frame, \"f_lasti\", -1) < 0)\n            if real_call:\n                self.last_line = -frame.f_code.co_firstlineno\n            else:\n                self.last_line = frame.f_lineno\n\n        elif event == \"line\":\n            # Record an executed line.\n            if self.cur_file_data is not None:\n                flineno: TLineNo = frame.f_lineno\n\n                if self.trace_arcs:\n                    cast(Set[TArc], self.cur_file_data).add((self.last_line, flineno))\n                else:\n                    cast(Set[TLineNo], self.cur_file_data).add(flineno)\n                self.last_line = flineno\n\n        elif event == \"return\":\n            if self.trace_arcs and self.cur_file_data:\n                # Record an arc leaving the function, but beware that a\n                # \"return\" event might just mean yielding from a generator.\n                code = frame.f_code.co_code\n                lasti = frame.f_lasti\n                if RESUME is not None:\n                    if len(code) == lasti + 2:\n                        # A return from the end of a code object is a real return.\n                        real_return = True\n                    else:\n                        # It is a real return if we aren't going to resume next.\n                        if env.PYBEHAVIOR.lasti_is_yield:\n                            lasti += 2\n                        real_return = (code[lasti] != RESUME)\n                else:\n                    if code[lasti] == RETURN_VALUE:\n                        real_return = True\n                    elif code[lasti] == YIELD_VALUE:\n                        real_return = False\n                    elif len(code) <= lasti + YIELD_FROM_OFFSET:\n                        real_return = True\n                    elif code[lasti + YIELD_FROM_OFFSET] == YIELD_FROM:\n                        real_return = False\n                    else:\n                        real_return = True\n                if real_return:\n                    first = frame.f_code.co_firstlineno\n                    cast(Set[TArc], self.cur_file_data).add((self.last_line, -first))\n\n            # Leaving this function, pop the filename stack.\n            self.cur_file_data, self.cur_file_name, self.last_line, self.started_context = (\n                self.data_stack.pop()\n            )\n            # Leaving a context?\n            if self.started_context:\n                assert self.switch_context is not None\n                self.context = None\n                self.switch_context(None)   # pylint: disable=not-callable\n        return self._cached_bound_method_trace\n\n    def start(self) -> TTraceFn:\n        \"\"\"Start this Tracer.\n\n        Return a Python function suitable for use with sys.settrace().\n\n        \"\"\"\n        self.stopped = False\n        if self.threading:\n            if self.thread is None:\n                self.thread = self.threading.current_thread()\n\n        sys.settrace(self._cached_bound_method_trace)\n        return self._cached_bound_method_trace\n\n    def stop(self) -> None:\n        \"\"\"Stop this Tracer.\"\"\"\n        # Get the active tracer callback before setting the stop flag to be\n        # able to detect if the tracer was changed prior to stopping it.\n        tf = sys.gettrace()\n\n        # Set the stop flag. The actual call to sys.settrace(None) will happen\n        # in the self._trace callback itself to make sure to call it from the\n        # right thread.\n        self.stopped = True\n\n        if self.threading:\n            assert self.thread is not None\n            if self.thread.ident != self.threading.current_thread().ident:\n                # Called on a different thread than started us: we can't unhook\n                # ourselves, but we've set the flag that we should stop, so we\n                # won't do any more tracing.\n                #self.log(\"~\", \"stopping on different threads\")\n                return\n\n        # PyPy clears the trace function before running atexit functions,\n        # so don't warn if we are in atexit on PyPy and the trace function\n        # has changed to None.  Metacoverage also messes this up, so don't\n        # warn if we are measuring ourselves.\n        suppress_warning = (\n            (env.PYPY and self.in_atexit and tf is None)\n            or env.METACOV\n        )\n        if self.warn and not suppress_warning:\n            if tf != self._cached_bound_method_trace:   # pylint: disable=comparison-with-callable\n                self.warn(\n                    \"Trace function changed, data is likely wrong: \" +\n                    f\"{tf!r} != {self._cached_bound_method_trace!r}\",\n                    slug=\"trace-changed\",\n                )\n\n    def activity(self) -> bool:\n        \"\"\"Has there been any activity?\"\"\"\n        return self._activity\n\n    def reset_activity(self) -> None:\n        \"\"\"Reset the activity() flag.\"\"\"\n        self._activity = False\n\n    def get_stats(self) -> dict[str, int] | None:\n        \"\"\"Return a dictionary of statistics, or None.\"\"\"\n        return None\n", "coverage/numbits.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nFunctions to manipulate packed binary representations of number sets.\n\nTo save space, coverage stores sets of line numbers in SQLite using a packed\nbinary representation called a numbits.  A numbits is a set of positive\nintegers.\n\nA numbits is stored as a blob in the database.  The exact meaning of the bytes\nin the blobs should be considered an implementation detail that might change in\nthe future.  Use these functions to work with those binary blobs of data.\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport sqlite3\n\nfrom itertools import zip_longest\nfrom typing import Iterable\n\n\ndef nums_to_numbits(nums: Iterable[int]) -> bytes:\n    \"\"\"Convert `nums` into a numbits.\n\n    Arguments:\n        nums: a reusable iterable of integers, the line numbers to store.\n\n    Returns:\n        A binary blob.\n    \"\"\"\n    try:\n        nbytes = max(nums) // 8 + 1\n    except ValueError:\n        # nums was empty.\n        return b\"\"\n    b = bytearray(nbytes)\n    for num in nums:\n        b[num//8] |= 1 << num % 8\n    return bytes(b)\n\n\ndef numbits_to_nums(numbits: bytes) -> list[int]:\n    \"\"\"Convert a numbits into a list of numbers.\n\n    Arguments:\n        numbits: a binary blob, the packed number set.\n\n    Returns:\n        A list of ints.\n\n    When registered as a SQLite function by :func:`register_sqlite_functions`,\n    this returns a string, a JSON-encoded list of ints.\n\n    \"\"\"\n    nums = []\n    for byte_i, byte in enumerate(numbits):\n        for bit_i in range(8):\n            if (byte & (1 << bit_i)):\n                nums.append(byte_i * 8 + bit_i)\n    return nums\n\n\ndef numbits_union(numbits1: bytes, numbits2: bytes) -> bytes:\n    \"\"\"Compute the union of two numbits.\n\n    Returns:\n        A new numbits, the union of `numbits1` and `numbits2`.\n    \"\"\"\n    byte_pairs = zip_longest(numbits1, numbits2, fillvalue=0)\n    return bytes(b1 | b2 for b1, b2 in byte_pairs)\n\n\ndef numbits_intersection(numbits1: bytes, numbits2: bytes) -> bytes:\n    \"\"\"Compute the intersection of two numbits.\n\n    Returns:\n        A new numbits, the intersection `numbits1` and `numbits2`.\n    \"\"\"\n    byte_pairs = zip_longest(numbits1, numbits2, fillvalue=0)\n    intersection_bytes = bytes(b1 & b2 for b1, b2 in byte_pairs)\n    return intersection_bytes.rstrip(b\"\\0\")\n\n\ndef numbits_any_intersection(numbits1: bytes, numbits2: bytes) -> bool:\n    \"\"\"Is there any number that appears in both numbits?\n\n    Determine whether two number sets have a non-empty intersection. This is\n    faster than computing the intersection.\n\n    Returns:\n        A bool, True if there is any number in both `numbits1` and `numbits2`.\n    \"\"\"\n    byte_pairs = zip_longest(numbits1, numbits2, fillvalue=0)\n    return any(b1 & b2 for b1, b2 in byte_pairs)\n\n\ndef num_in_numbits(num: int, numbits: bytes) -> bool:\n    \"\"\"Does the integer `num` appear in `numbits`?\n\n    Returns:\n        A bool, True if `num` is a member of `numbits`.\n    \"\"\"\n    nbyte, nbit = divmod(num, 8)\n    if nbyte >= len(numbits):\n        return False\n    return bool(numbits[nbyte] & (1 << nbit))\n\n\ndef register_sqlite_functions(connection: sqlite3.Connection) -> None:\n    \"\"\"\n    Define numbits functions in a SQLite connection.\n\n    This defines these functions for use in SQLite statements:\n\n    * :func:`numbits_union`\n    * :func:`numbits_intersection`\n    * :func:`numbits_any_intersection`\n    * :func:`num_in_numbits`\n    * :func:`numbits_to_nums`\n\n    `connection` is a :class:`sqlite3.Connection <python:sqlite3.Connection>`\n    object.  After creating the connection, pass it to this function to\n    register the numbits functions.  Then you can use numbits functions in your\n    queries::\n\n        import sqlite3\n        from coverage.numbits import register_sqlite_functions\n\n        conn = sqlite3.connect(\"example.db\")\n        register_sqlite_functions(conn)\n        c = conn.cursor()\n        # Kind of a nonsense query:\n        # Find all the files and contexts that executed line 47 in any file:\n        c.execute(\n            \"select file_id, context_id from line_bits where num_in_numbits(?, numbits)\",\n            (47,)\n        )\n    \"\"\"\n    connection.create_function(\"numbits_union\", 2, numbits_union)\n    connection.create_function(\"numbits_intersection\", 2, numbits_intersection)\n    connection.create_function(\"numbits_any_intersection\", 2, numbits_any_intersection)\n    connection.create_function(\"num_in_numbits\", 2, num_in_numbits)\n    connection.create_function(\"numbits_to_nums\", 1, lambda b: json.dumps(numbits_to_nums(b)))\n", "coverage/xmlreport.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"XML reporting for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport os.path\nimport sys\nimport time\nimport xml.dom.minidom\n\nfrom dataclasses import dataclass\nfrom typing import Any, IO, Iterable, TYPE_CHECKING\n\nfrom coverage import __version__, files\nfrom coverage.misc import isolate_module, human_sorted, human_sorted_items\nfrom coverage.plugin import FileReporter\nfrom coverage.report_core import get_analysis_to_report\nfrom coverage.results import Analysis\nfrom coverage.types import TMorf\nfrom coverage.version import __url__\n\nif TYPE_CHECKING:\n    from coverage import Coverage\n\nos = isolate_module(os)\n\n\nDTD_URL = \"https://raw.githubusercontent.com/cobertura/web/master/htdocs/xml/coverage-04.dtd\"\n\n\ndef rate(hit: int, num: int) -> str:\n    \"\"\"Return the fraction of `hit`/`num`, as a string.\"\"\"\n    if num == 0:\n        return \"1\"\n    else:\n        return \"%.4g\" % (hit / num)\n\n\n@dataclass\nclass PackageData:\n    \"\"\"Data we keep about each \"package\" (in Java terms).\"\"\"\n    elements: dict[str, xml.dom.minidom.Element]\n    hits: int\n    lines: int\n    br_hits: int\n    branches: int\n\n\ndef appendChild(parent: Any, child: Any) -> None:\n    \"\"\"Append a child to a parent, in a way mypy will shut up about.\"\"\"\n    parent.appendChild(child)\n\n\nclass XmlReporter:\n    \"\"\"A reporter for writing Cobertura-style XML coverage results.\"\"\"\n\n    report_type = \"XML report\"\n\n    def __init__(self, coverage: Coverage) -> None:\n        self.coverage = coverage\n        self.config = self.coverage.config\n\n        self.source_paths = set()\n        if self.config.source:\n            for src in self.config.source:\n                if os.path.exists(src):\n                    if self.config.relative_files:\n                        src = src.rstrip(r\"\\/\")\n                    else:\n                        src = files.canonical_filename(src)\n                    self.source_paths.add(src)\n        self.packages: dict[str, PackageData] = {}\n        self.xml_out: xml.dom.minidom.Document\n\n    def report(self, morfs: Iterable[TMorf] | None, outfile: IO[str] | None = None) -> float:\n        \"\"\"Generate a Cobertura-compatible XML report for `morfs`.\n\n        `morfs` is a list of modules or file names.\n\n        `outfile` is a file object to write the XML to.\n\n        \"\"\"\n        # Initial setup.\n        outfile = outfile or sys.stdout\n        has_arcs = self.coverage.get_data().has_arcs()\n\n        # Create the DOM that will store the data.\n        impl = xml.dom.minidom.getDOMImplementation()\n        assert impl is not None\n        self.xml_out = impl.createDocument(None, \"coverage\", None)\n\n        # Write header stuff.\n        xcoverage = self.xml_out.documentElement\n        xcoverage.setAttribute(\"version\", __version__)\n        xcoverage.setAttribute(\"timestamp\", str(int(time.time()*1000)))\n        xcoverage.appendChild(self.xml_out.createComment(\n            f\" Generated by coverage.py: {__url__} \",\n        ))\n        xcoverage.appendChild(self.xml_out.createComment(f\" Based on {DTD_URL} \"))\n\n        # Call xml_file for each file in the data.\n        for fr, analysis in get_analysis_to_report(self.coverage, morfs):\n            self.xml_file(fr, analysis, has_arcs)\n\n        xsources = self.xml_out.createElement(\"sources\")\n        xcoverage.appendChild(xsources)\n\n        # Populate the XML DOM with the source info.\n        for path in human_sorted(self.source_paths):\n            xsource = self.xml_out.createElement(\"source\")\n            appendChild(xsources, xsource)\n            txt = self.xml_out.createTextNode(path)\n            appendChild(xsource, txt)\n\n        lnum_tot, lhits_tot = 0, 0\n        bnum_tot, bhits_tot = 0, 0\n\n        xpackages = self.xml_out.createElement(\"packages\")\n        xcoverage.appendChild(xpackages)\n\n        # Populate the XML DOM with the package info.\n        for pkg_name, pkg_data in human_sorted_items(self.packages.items()):\n            xpackage = self.xml_out.createElement(\"package\")\n            appendChild(xpackages, xpackage)\n            xclasses = self.xml_out.createElement(\"classes\")\n            appendChild(xpackage, xclasses)\n            for _, class_elt in human_sorted_items(pkg_data.elements.items()):\n                appendChild(xclasses, class_elt)\n            xpackage.setAttribute(\"name\", pkg_name.replace(os.sep, \".\"))\n            xpackage.setAttribute(\"line-rate\", rate(pkg_data.hits, pkg_data.lines))\n            if has_arcs:\n                branch_rate = rate(pkg_data.br_hits, pkg_data.branches)\n            else:\n                branch_rate = \"0\"\n            xpackage.setAttribute(\"branch-rate\", branch_rate)\n            xpackage.setAttribute(\"complexity\", \"0\")\n\n            lhits_tot += pkg_data.hits\n            lnum_tot += pkg_data.lines\n            bhits_tot += pkg_data.br_hits\n            bnum_tot += pkg_data.branches\n\n        xcoverage.setAttribute(\"lines-valid\", str(lnum_tot))\n        xcoverage.setAttribute(\"lines-covered\", str(lhits_tot))\n        xcoverage.setAttribute(\"line-rate\", rate(lhits_tot, lnum_tot))\n        if has_arcs:\n            xcoverage.setAttribute(\"branches-valid\", str(bnum_tot))\n            xcoverage.setAttribute(\"branches-covered\", str(bhits_tot))\n            xcoverage.setAttribute(\"branch-rate\", rate(bhits_tot, bnum_tot))\n        else:\n            xcoverage.setAttribute(\"branches-covered\", \"0\")\n            xcoverage.setAttribute(\"branches-valid\", \"0\")\n            xcoverage.setAttribute(\"branch-rate\", \"0\")\n        xcoverage.setAttribute(\"complexity\", \"0\")\n\n        # Write the output file.\n        outfile.write(serialize_xml(self.xml_out))\n\n        # Return the total percentage.\n        denom = lnum_tot + bnum_tot\n        if denom == 0:\n            pct = 0.0\n        else:\n            pct = 100.0 * (lhits_tot + bhits_tot) / denom\n        return pct\n\n    def xml_file(self, fr: FileReporter, analysis: Analysis, has_arcs: bool) -> None:\n        \"\"\"Add to the XML report for a single file.\"\"\"\n\n        if self.config.skip_empty:\n            if analysis.numbers.n_statements == 0:\n                return\n\n        # Create the \"lines\" and \"package\" XML elements, which\n        # are populated later.  Note that a package == a directory.\n        filename = fr.filename.replace(\"\\\\\", \"/\")\n        for source_path in self.source_paths:\n            if not self.config.relative_files:\n                source_path = files.canonical_filename(source_path)\n            if filename.startswith(source_path.replace(\"\\\\\", \"/\") + \"/\"):\n                rel_name = filename[len(source_path)+1:]\n                break\n        else:\n            rel_name = fr.relative_filename().replace(\"\\\\\", \"/\")\n            self.source_paths.add(fr.filename[:-len(rel_name)].rstrip(r\"\\/\"))\n\n        dirname = os.path.dirname(rel_name) or \".\"\n        dirname = \"/\".join(dirname.split(\"/\")[:self.config.xml_package_depth])\n        package_name = dirname.replace(\"/\", \".\")\n\n        package = self.packages.setdefault(package_name, PackageData({}, 0, 0, 0, 0))\n\n        xclass: xml.dom.minidom.Element = self.xml_out.createElement(\"class\")\n\n        appendChild(xclass, self.xml_out.createElement(\"methods\"))\n\n        xlines = self.xml_out.createElement(\"lines\")\n        appendChild(xclass, xlines)\n\n        xclass.setAttribute(\"name\", os.path.relpath(rel_name, dirname))\n        xclass.setAttribute(\"filename\", rel_name.replace(\"\\\\\", \"/\"))\n        xclass.setAttribute(\"complexity\", \"0\")\n\n        branch_stats = analysis.branch_stats()\n        missing_branch_arcs = analysis.missing_branch_arcs()\n\n        # For each statement, create an XML \"line\" element.\n        for line in sorted(analysis.statements):\n            xline = self.xml_out.createElement(\"line\")\n            xline.setAttribute(\"number\", str(line))\n\n            # Q: can we get info about the number of times a statement is\n            # executed?  If so, that should be recorded here.\n            xline.setAttribute(\"hits\", str(int(line not in analysis.missing)))\n\n            if has_arcs:\n                if line in branch_stats:\n                    total, taken = branch_stats[line]\n                    xline.setAttribute(\"branch\", \"true\")\n                    xline.setAttribute(\n                        \"condition-coverage\",\n                        \"%d%% (%d/%d)\" % (100*taken//total, taken, total),\n                    )\n                if line in missing_branch_arcs:\n                    annlines = [\"exit\" if b < 0 else str(b) for b in missing_branch_arcs[line]]\n                    xline.setAttribute(\"missing-branches\", \",\".join(annlines))\n            appendChild(xlines, xline)\n\n        class_lines = len(analysis.statements)\n        class_hits = class_lines - len(analysis.missing)\n\n        if has_arcs:\n            class_branches = sum(t for t, k in branch_stats.values())\n            missing_branches = sum(t - k for t, k in branch_stats.values())\n            class_br_hits = class_branches - missing_branches\n        else:\n            class_branches = 0\n            class_br_hits = 0\n\n        # Finalize the statistics that are collected in the XML DOM.\n        xclass.setAttribute(\"line-rate\", rate(class_hits, class_lines))\n        if has_arcs:\n            branch_rate = rate(class_br_hits, class_branches)\n        else:\n            branch_rate = \"0\"\n        xclass.setAttribute(\"branch-rate\", branch_rate)\n\n        package.elements[rel_name] = xclass\n        package.hits += class_hits\n        package.lines += class_lines\n        package.br_hits += class_br_hits\n        package.branches += class_branches\n\n\ndef serialize_xml(dom: xml.dom.minidom.Document) -> str:\n    \"\"\"Serialize a minidom node to XML.\"\"\"\n    return dom.toprettyxml()\n", "coverage/annotate.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Source file annotation for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport re\n\nfrom typing import Iterable, TYPE_CHECKING\n\nfrom coverage.files import flat_rootname\nfrom coverage.misc import ensure_dir, isolate_module\nfrom coverage.plugin import FileReporter\nfrom coverage.report_core import get_analysis_to_report\nfrom coverage.results import Analysis\nfrom coverage.types import TMorf\n\nif TYPE_CHECKING:\n    from coverage import Coverage\n\nos = isolate_module(os)\n\n\nclass AnnotateReporter:\n    \"\"\"Generate annotated source files showing line coverage.\n\n    This reporter creates annotated copies of the measured source files. Each\n    .py file is copied as a .py,cover file, with a left-hand margin annotating\n    each line::\n\n        > def h(x):\n        -     if 0:   #pragma: no cover\n        -         pass\n        >     if x == 1:\n        !         a = 1\n        >     else:\n        >         a = 2\n\n        > h(2)\n\n    Executed lines use \">\", lines not executed use \"!\", lines excluded from\n    consideration use \"-\".\n\n    \"\"\"\n\n    def __init__(self, coverage: Coverage) -> None:\n        self.coverage = coverage\n        self.config = self.coverage.config\n        self.directory: str | None = None\n\n    blank_re = re.compile(r\"\\s*(#|$)\")\n    else_re = re.compile(r\"\\s*else\\s*:\\s*(#|$)\")\n\n    def report(self, morfs: Iterable[TMorf] | None, directory: str | None = None) -> None:\n        \"\"\"Run the report.\n\n        See `coverage.report()` for arguments.\n\n        \"\"\"\n        self.directory = directory\n        self.coverage.get_data()\n        for fr, analysis in get_analysis_to_report(self.coverage, morfs):\n            self.annotate_file(fr, analysis)\n\n    def annotate_file(self, fr: FileReporter, analysis: Analysis) -> None:\n        \"\"\"Annotate a single file.\n\n        `fr` is the FileReporter for the file to annotate.\n\n        \"\"\"\n        statements = sorted(analysis.statements)\n        missing = sorted(analysis.missing)\n        excluded = sorted(analysis.excluded)\n\n        if self.directory:\n            ensure_dir(self.directory)\n            dest_file = os.path.join(self.directory, flat_rootname(fr.relative_filename()))\n            if dest_file.endswith(\"_py\"):\n                dest_file = dest_file[:-3] + \".py\"\n            dest_file += \",cover\"\n        else:\n            dest_file = fr.filename + \",cover\"\n\n        with open(dest_file, \"w\", encoding=\"utf-8\") as dest:\n            i = j = 0\n            covered = True\n            source = fr.source()\n            for lineno, line in enumerate(source.splitlines(True), start=1):\n                while i < len(statements) and statements[i] < lineno:\n                    i += 1\n                while j < len(missing) and missing[j] < lineno:\n                    j += 1\n                if i < len(statements) and statements[i] == lineno:\n                    covered = j >= len(missing) or missing[j] > lineno\n                if self.blank_re.match(line):\n                    dest.write(\"  \")\n                elif self.else_re.match(line):\n                    # Special logic for lines containing only \"else:\".\n                    if j >= len(missing):\n                        dest.write(\"> \")\n                    elif statements[i] == missing[j]:\n                        dest.write(\"! \")\n                    else:\n                        dest.write(\"> \")\n                elif lineno in excluded:\n                    dest.write(\"- \")\n                elif covered:\n                    dest.write(\"> \")\n                else:\n                    dest.write(\"! \")\n\n                dest.write(line)\n", "coverage/report.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Summary reporting\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\n\nfrom typing import Any, IO, Iterable, TYPE_CHECKING\n\nfrom coverage.exceptions import ConfigError, NoDataError\nfrom coverage.misc import human_sorted_items\nfrom coverage.plugin import FileReporter\nfrom coverage.report_core import get_analysis_to_report\nfrom coverage.results import Analysis, Numbers\nfrom coverage.types import TMorf\n\nif TYPE_CHECKING:\n    from coverage import Coverage\n\n\nclass SummaryReporter:\n    \"\"\"A reporter for writing the summary report.\"\"\"\n\n    def __init__(self, coverage: Coverage) -> None:\n        self.coverage = coverage\n        self.config = self.coverage.config\n        self.branches = coverage.get_data().has_arcs()\n        self.outfile: IO[str] | None = None\n        self.output_format = self.config.format or \"text\"\n        if self.output_format not in {\"text\", \"markdown\", \"total\"}:\n            raise ConfigError(f\"Unknown report format choice: {self.output_format!r}\")\n        self.fr_analysis: list[tuple[FileReporter, Analysis]] = []\n        self.skipped_count = 0\n        self.empty_count = 0\n        self.total = Numbers(precision=self.config.precision)\n\n    def write(self, line: str) -> None:\n        \"\"\"Write a line to the output, adding a newline.\"\"\"\n        assert self.outfile is not None\n        self.outfile.write(line.rstrip())\n        self.outfile.write(\"\\n\")\n\n    def write_items(self, items: Iterable[str]) -> None:\n        \"\"\"Write a list of strings, joined together.\"\"\"\n        self.write(\"\".join(items))\n\n    def _report_text(\n        self,\n        header: list[str],\n        lines_values: list[list[Any]],\n        total_line: list[Any],\n        end_lines: list[str],\n    ) -> None:\n        \"\"\"Internal method that prints report data in text format.\n\n        `header` is a list with captions.\n        `lines_values` is list of lists of sortable values.\n        `total_line` is a list with values of the total line.\n        `end_lines` is a list of ending lines with information about skipped files.\n\n        \"\"\"\n        # Prepare the formatting strings, header, and column sorting.\n        max_name = max([len(line[0]) for line in lines_values] + [5]) + 1\n        max_n = max(len(total_line[header.index(\"Cover\")]) + 2, len(\" Cover\")) + 1\n        max_n = max([max_n] + [len(line[header.index(\"Cover\")]) + 2 for line in lines_values])\n        formats = dict(\n            Name=\"{:{name_len}}\",\n            Stmts=\"{:>7}\",\n            Miss=\"{:>7}\",\n            Branch=\"{:>7}\",\n            BrPart=\"{:>7}\",\n            Cover=\"{:>{n}}\",\n            Missing=\"{:>10}\",\n        )\n        header_items = [\n            formats[item].format(item, name_len=max_name, n=max_n)\n            for item in header\n        ]\n        header_str = \"\".join(header_items)\n        rule = \"-\" * len(header_str)\n\n        # Write the header\n        self.write(header_str)\n        self.write(rule)\n\n        formats.update(dict(Cover=\"{:>{n}}%\"), Missing=\"   {:9}\")\n        for values in lines_values:\n            # build string with line values\n            line_items = [\n                formats[item].format(str(value),\n                name_len=max_name, n=max_n-1) for item, value in zip(header, values)\n            ]\n            self.write_items(line_items)\n\n        # Write a TOTAL line\n        if lines_values:\n            self.write(rule)\n\n        line_items = [\n            formats[item].format(str(value),\n            name_len=max_name, n=max_n-1) for item, value in zip(header, total_line)\n        ]\n        self.write_items(line_items)\n\n        for end_line in end_lines:\n            self.write(end_line)\n\n    def _report_markdown(\n        self,\n        header: list[str],\n        lines_values: list[list[Any]],\n        total_line: list[Any],\n        end_lines: list[str],\n    ) -> None:\n        \"\"\"Internal method that prints report data in markdown format.\n\n        `header` is a list with captions.\n        `lines_values` is a sorted list of lists containing coverage information.\n        `total_line` is a list with values of the total line.\n        `end_lines` is a list of ending lines with information about skipped files.\n\n        \"\"\"\n        # Prepare the formatting strings, header, and column sorting.\n        max_name = max((len(line[0].replace(\"_\", \"\\\\_\")) for line in lines_values), default=0)\n        max_name = max(max_name, len(\"**TOTAL**\")) + 1\n        formats = dict(\n            Name=\"| {:{name_len}}|\",\n            Stmts=\"{:>9} |\",\n            Miss=\"{:>9} |\",\n            Branch=\"{:>9} |\",\n            BrPart=\"{:>9} |\",\n            Cover=\"{:>{n}} |\",\n            Missing=\"{:>10} |\",\n        )\n        max_n = max(len(total_line[header.index(\"Cover\")]) + 6, len(\" Cover \"))\n        header_items = [formats[item].format(item, name_len=max_name, n=max_n) for item in header]\n        header_str = \"\".join(header_items)\n        rule_str = \"|\" + \" \".join([\"- |\".rjust(len(header_items[0])-1, \"-\")] +\n            [\"-: |\".rjust(len(item)-1, \"-\") for item in header_items[1:]],\n        )\n\n        # Write the header\n        self.write(header_str)\n        self.write(rule_str)\n\n        for values in lines_values:\n            # build string with line values\n            formats.update(dict(Cover=\"{:>{n}}% |\"))\n            line_items = [\n                formats[item].format(str(value).replace(\"_\", \"\\\\_\"), name_len=max_name, n=max_n-1)\n                for item, value in zip(header, values)\n            ]\n            self.write_items(line_items)\n\n        # Write the TOTAL line\n        formats.update(dict(Name=\"|{:>{name_len}} |\", Cover=\"{:>{n}} |\"))\n        total_line_items: list[str] = []\n        for item, value in zip(header, total_line):\n            if value == \"\":\n                insert = value\n            elif item == \"Cover\":\n                insert = f\" **{value}%**\"\n            else:\n                insert = f\" **{value}**\"\n            total_line_items += formats[item].format(insert, name_len=max_name, n=max_n)\n        self.write_items(total_line_items)\n        for end_line in end_lines:\n            self.write(end_line)\n\n    def report(self, morfs: Iterable[TMorf] | None, outfile: IO[str] | None = None) -> float:\n        \"\"\"Writes a report summarizing coverage statistics per module.\n\n        `outfile` is a text-mode file object to write the summary to.\n\n        \"\"\"\n        self.outfile = outfile or sys.stdout\n\n        self.coverage.get_data().set_query_contexts(self.config.report_contexts)\n        for fr, analysis in get_analysis_to_report(self.coverage, morfs):\n            self.report_one_file(fr, analysis)\n\n        if not self.total.n_files and not self.skipped_count:\n            raise NoDataError(\"No data to report.\")\n\n        if self.output_format == \"total\":\n            self.write(self.total.pc_covered_str)\n        else:\n            self.tabular_report()\n\n        return self.total.pc_covered\n\n    def tabular_report(self) -> None:\n        \"\"\"Writes tabular report formats.\"\"\"\n        # Prepare the header line and column sorting.\n        header = [\"Name\", \"Stmts\", \"Miss\"]\n        if self.branches:\n            header += [\"Branch\", \"BrPart\"]\n        header += [\"Cover\"]\n        if self.config.show_missing:\n            header += [\"Missing\"]\n\n        column_order = dict(name=0, stmts=1, miss=2, cover=-1)\n        if self.branches:\n            column_order.update(dict(branch=3, brpart=4))\n\n        # `lines_values` is list of lists of sortable values.\n        lines_values = []\n\n        for (fr, analysis) in self.fr_analysis:\n            nums = analysis.numbers\n\n            args = [fr.relative_filename(), nums.n_statements, nums.n_missing]\n            if self.branches:\n                args += [nums.n_branches, nums.n_partial_branches]\n            args += [nums.pc_covered_str]\n            if self.config.show_missing:\n                args += [analysis.missing_formatted(branches=True)]\n            args += [nums.pc_covered]\n            lines_values.append(args)\n\n        # Line sorting.\n        sort_option = (self.config.sort or \"name\").lower()\n        reverse = False\n        if sort_option[0] == \"-\":\n            reverse = True\n            sort_option = sort_option[1:]\n        elif sort_option[0] == \"+\":\n            sort_option = sort_option[1:]\n        sort_idx = column_order.get(sort_option)\n        if sort_idx is None:\n            raise ConfigError(f\"Invalid sorting option: {self.config.sort!r}\")\n        if sort_option == \"name\":\n            lines_values = human_sorted_items(lines_values, reverse=reverse)\n        else:\n            lines_values.sort(\n                key=lambda line: (line[sort_idx], line[0]),\n                reverse=reverse,\n            )\n\n        # Calculate total if we had at least one file.\n        total_line = [\"TOTAL\", self.total.n_statements, self.total.n_missing]\n        if self.branches:\n            total_line += [self.total.n_branches, self.total.n_partial_branches]\n        total_line += [self.total.pc_covered_str]\n        if self.config.show_missing:\n            total_line += [\"\"]\n\n        # Create other final lines.\n        end_lines = []\n        if self.config.skip_covered and self.skipped_count:\n            file_suffix = \"s\" if self.skipped_count>1 else \"\"\n            end_lines.append(\n                f\"\\n{self.skipped_count} file{file_suffix} skipped due to complete coverage.\",\n            )\n        if self.config.skip_empty and self.empty_count:\n            file_suffix = \"s\" if self.empty_count > 1 else \"\"\n            end_lines.append(f\"\\n{self.empty_count} empty file{file_suffix} skipped.\")\n\n        if self.output_format == \"markdown\":\n            formatter = self._report_markdown\n        else:\n            formatter = self._report_text\n        formatter(header, lines_values, total_line, end_lines)\n\n    def report_one_file(self, fr: FileReporter, analysis: Analysis) -> None:\n        \"\"\"Report on just one file, the callback from report().\"\"\"\n        nums = analysis.numbers\n        self.total += nums\n\n        no_missing_lines = (nums.n_missing == 0)\n        no_missing_branches = (nums.n_partial_branches == 0)\n        if self.config.skip_covered and no_missing_lines and no_missing_branches:\n            # Don't report on 100% files.\n            self.skipped_count += 1\n        elif self.config.skip_empty and nums.n_statements == 0:\n            # Don't report on empty files.\n            self.empty_count += 1\n        else:\n            self.fr_analysis.append((fr, analysis))\n", "coverage/jsonreport.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Json reporting for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nimport datetime\nimport json\nimport sys\n\nfrom typing import Any, IO, Iterable, TYPE_CHECKING\n\nfrom coverage import __version__\nfrom coverage.report_core import get_analysis_to_report\nfrom coverage.results import Analysis, Numbers\nfrom coverage.types import TMorf, TLineNo\n\nif TYPE_CHECKING:\n    from coverage import Coverage\n    from coverage.data import CoverageData\n\n\n# \"Version 1\" had no format number at all.\n# 2: add the meta.format field.\nFORMAT_VERSION = 2\n\nclass JsonReporter:\n    \"\"\"A reporter for writing JSON coverage results.\"\"\"\n\n    report_type = \"JSON report\"\n\n    def __init__(self, coverage: Coverage) -> None:\n        self.coverage = coverage\n        self.config = self.coverage.config\n        self.total = Numbers(self.config.precision)\n        self.report_data: dict[str, Any] = {}\n\n    def report(self, morfs: Iterable[TMorf] | None, outfile: IO[str]) -> float:\n        \"\"\"Generate a json report for `morfs`.\n\n        `morfs` is a list of modules or file names.\n\n        `outfile` is a file object to write the json to.\n\n        \"\"\"\n        outfile = outfile or sys.stdout\n        coverage_data = self.coverage.get_data()\n        coverage_data.set_query_contexts(self.config.report_contexts)\n        self.report_data[\"meta\"] = {\n            \"format\": FORMAT_VERSION,\n            \"version\": __version__,\n            \"timestamp\": datetime.datetime.now().isoformat(),\n            \"branch_coverage\": coverage_data.has_arcs(),\n            \"show_contexts\": self.config.json_show_contexts,\n        }\n\n        measured_files = {}\n        for file_reporter, analysis in get_analysis_to_report(self.coverage, morfs):\n            measured_files[file_reporter.relative_filename()] = self.report_one_file(\n                coverage_data,\n                analysis,\n            )\n\n        self.report_data[\"files\"] = measured_files\n\n        self.report_data[\"totals\"] = {\n            \"covered_lines\": self.total.n_executed,\n            \"num_statements\": self.total.n_statements,\n            \"percent_covered\": self.total.pc_covered,\n            \"percent_covered_display\": self.total.pc_covered_str,\n            \"missing_lines\": self.total.n_missing,\n            \"excluded_lines\": self.total.n_excluded,\n        }\n\n        if coverage_data.has_arcs():\n            self.report_data[\"totals\"].update({\n                \"num_branches\": self.total.n_branches,\n                \"num_partial_branches\": self.total.n_partial_branches,\n                \"covered_branches\": self.total.n_executed_branches,\n                \"missing_branches\": self.total.n_missing_branches,\n            })\n\n        json.dump(\n            self.report_data,\n            outfile,\n            indent=(4 if self.config.json_pretty_print else None),\n        )\n\n        return self.total.n_statements and self.total.pc_covered\n\n    def report_one_file(self, coverage_data: CoverageData, analysis: Analysis) -> dict[str, Any]:\n        \"\"\"Extract the relevant report data for a single file.\"\"\"\n        nums = analysis.numbers\n        self.total += nums\n        summary = {\n            \"covered_lines\": nums.n_executed,\n            \"num_statements\": nums.n_statements,\n            \"percent_covered\": nums.pc_covered,\n            \"percent_covered_display\": nums.pc_covered_str,\n            \"missing_lines\": nums.n_missing,\n            \"excluded_lines\": nums.n_excluded,\n        }\n        reported_file = {\n            \"executed_lines\": sorted(analysis.executed),\n            \"summary\": summary,\n            \"missing_lines\": sorted(analysis.missing),\n            \"excluded_lines\": sorted(analysis.excluded),\n        }\n        if self.config.json_show_contexts:\n            reported_file[\"contexts\"] = coverage_data.contexts_by_lineno(analysis.filename)\n        if coverage_data.has_arcs():\n            summary.update({\n                \"num_branches\": nums.n_branches,\n                \"num_partial_branches\": nums.n_partial_branches,\n                \"covered_branches\": nums.n_executed_branches,\n                \"missing_branches\": nums.n_missing_branches,\n            })\n            reported_file[\"executed_branches\"] = list(\n                _convert_branch_arcs(analysis.executed_branch_arcs()),\n            )\n            reported_file[\"missing_branches\"] = list(\n                _convert_branch_arcs(analysis.missing_branch_arcs()),\n            )\n        return reported_file\n\n\ndef _convert_branch_arcs(\n    branch_arcs: dict[TLineNo, list[TLineNo]],\n) -> Iterable[tuple[TLineNo, TLineNo]]:\n    \"\"\"Convert branch arcs to a list of two-element tuples.\"\"\"\n    for source, targets in branch_arcs.items():\n        for target in targets:\n            yield source, target\n", "coverage/version.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"The version and URL for coverage.py\"\"\"\n# This file is exec'ed in setup.py, don't import anything!\n\nfrom __future__ import annotations\n\n# version_info: same semantics as sys.version_info.\n# _dev: the .devN suffix if any.\nversion_info = (7, 5, 5, \"alpha\", 0)\n_dev = 1\n\n\ndef _make_version(\n    major: int,\n    minor: int,\n    micro: int,\n    releaselevel: str = \"final\",\n    serial: int = 0,\n    dev: int = 0,\n) -> str:\n    \"\"\"Create a readable version string from version_info tuple components.\"\"\"\n    assert releaselevel in [\"alpha\", \"beta\", \"candidate\", \"final\"]\n    version = \"%d.%d.%d\" % (major, minor, micro)\n    if releaselevel != \"final\":\n        short = {\"alpha\": \"a\", \"beta\": \"b\", \"candidate\": \"rc\"}[releaselevel]\n        version += f\"{short}{serial}\"\n    if dev != 0:\n        version += f\".dev{dev}\"\n    return version\n\n\ndef _make_url(\n    major: int,\n    minor: int,\n    micro: int,\n    releaselevel: str,\n    serial: int = 0,\n    dev: int = 0,\n) -> str:\n    \"\"\"Make the URL people should start at for this version of coverage.py.\"\"\"\n    return (\n        \"https://coverage.readthedocs.io/en/\"\n        + _make_version(major, minor, micro, releaselevel, serial, dev)\n    )\n\n\n__version__ = _make_version(*version_info, _dev)\n__url__ = _make_url(*version_info, _dev)\n", "coverage/cmdline.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Command-line support for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport glob\nimport optparse     # pylint: disable=deprecated-module\nimport os\nimport os.path\nimport shlex\nimport sys\nimport textwrap\nimport traceback\n\nfrom typing import cast, Any, NoReturn\n\nimport coverage\nfrom coverage import Coverage\nfrom coverage import env\nfrom coverage.collector import HAS_CTRACER\nfrom coverage.config import CoverageConfig\nfrom coverage.control import DEFAULT_DATAFILE\nfrom coverage.data import combinable_files, debug_data_file\nfrom coverage.debug import info_header, short_stack, write_formatted_info\nfrom coverage.exceptions import _BaseCoverageException, _ExceptionDuringRun, NoSource\nfrom coverage.execfile import PyRunner\nfrom coverage.results import display_covered, should_fail_under\nfrom coverage.version import __url__\n\n# When adding to this file, alphabetization is important.  Look for\n# \"alphabetize\" comments throughout.\n\nclass Opts:\n    \"\"\"A namespace class for individual options we'll build parsers from.\"\"\"\n\n    # Keep these entries alphabetized (roughly) by the option name as it\n    # appears on the command line.\n\n    append = optparse.make_option(\n        \"-a\", \"--append\", action=\"store_true\",\n        help=\"Append coverage data to .coverage, otherwise it starts clean each time.\",\n    )\n    branch = optparse.make_option(\n        \"\", \"--branch\", action=\"store_true\",\n        help=\"Measure branch coverage in addition to statement coverage.\",\n    )\n    concurrency = optparse.make_option(\n        \"\", \"--concurrency\", action=\"store\", metavar=\"LIBS\",\n        help=(\n            \"Properly measure code using a concurrency library. \" +\n            \"Valid values are: {}, or a comma-list of them.\"\n        ).format(\", \".join(sorted(CoverageConfig.CONCURRENCY_CHOICES))),\n    )\n    context = optparse.make_option(\n        \"\", \"--context\", action=\"store\", metavar=\"LABEL\",\n        help=\"The context label to record for this coverage run.\",\n    )\n    contexts = optparse.make_option(\n        \"\", \"--contexts\", action=\"store\", metavar=\"REGEX1,REGEX2,...\",\n        help=(\n            \"Only display data from lines covered in the given contexts. \" +\n            \"Accepts Python regexes, which must be quoted.\"\n        ),\n    )\n    datafile = optparse.make_option(\n        \"\", \"--data-file\", action=\"store\", metavar=\"DATAFILE\",\n        help=(\n            \"Base name of the data files to operate on. \" +\n            \"Defaults to '.coverage'. [env: COVERAGE_FILE]\"\n        ),\n    )\n    datafle_input = optparse.make_option(\n        \"\", \"--data-file\", action=\"store\", metavar=\"INFILE\",\n        help=(\n            \"Read coverage data for report generation from this file. \" +\n            \"Defaults to '.coverage'. [env: COVERAGE_FILE]\"\n        ),\n    )\n    datafile_output = optparse.make_option(\n        \"\", \"--data-file\", action=\"store\", metavar=\"OUTFILE\",\n        help=(\n            \"Write the recorded coverage data to this file. \" +\n            \"Defaults to '.coverage'. [env: COVERAGE_FILE]\"\n        ),\n    )\n    debug = optparse.make_option(\n        \"\", \"--debug\", action=\"store\", metavar=\"OPTS\",\n        help=\"Debug options, separated by commas. [env: COVERAGE_DEBUG]\",\n    )\n    directory = optparse.make_option(\n        \"-d\", \"--directory\", action=\"store\", metavar=\"DIR\",\n        help=\"Write the output files to DIR.\",\n    )\n    fail_under = optparse.make_option(\n        \"\", \"--fail-under\", action=\"store\", metavar=\"MIN\", type=\"float\",\n        help=\"Exit with a status of 2 if the total coverage is less than MIN.\",\n    )\n    format = optparse.make_option(\n        \"\", \"--format\", action=\"store\", metavar=\"FORMAT\",\n        help=\"Output format, either text (default), markdown, or total.\",\n    )\n    help = optparse.make_option(\n        \"-h\", \"--help\", action=\"store_true\",\n        help=\"Get help on this command.\",\n    )\n    ignore_errors = optparse.make_option(\n        \"-i\", \"--ignore-errors\", action=\"store_true\",\n        help=\"Ignore errors while reading source files.\",\n    )\n    include = optparse.make_option(\n        \"\", \"--include\", action=\"store\", metavar=\"PAT1,PAT2,...\",\n        help=(\n            \"Include only files whose paths match one of these patterns. \" +\n            \"Accepts shell-style wildcards, which must be quoted.\"\n        ),\n    )\n    keep = optparse.make_option(\n        \"\", \"--keep\", action=\"store_true\",\n        help=\"Keep original coverage files, otherwise they are deleted.\",\n    )\n    pylib = optparse.make_option(\n        \"-L\", \"--pylib\", action=\"store_true\",\n        help=(\n            \"Measure coverage even inside the Python installed library, \" +\n            \"which isn't done by default.\"\n        ),\n    )\n    show_missing = optparse.make_option(\n        \"-m\", \"--show-missing\", action=\"store_true\",\n        help=\"Show line numbers of statements in each module that weren't executed.\",\n    )\n    module = optparse.make_option(\n        \"-m\", \"--module\", action=\"store_true\",\n        help=(\n            \"<pyfile> is an importable Python module, not a script path, \" +\n            \"to be run as 'python -m' would run it.\"\n        ),\n    )\n    omit = optparse.make_option(\n        \"\", \"--omit\", action=\"store\", metavar=\"PAT1,PAT2,...\",\n        help=(\n            \"Omit files whose paths match one of these patterns. \" +\n            \"Accepts shell-style wildcards, which must be quoted.\"\n        ),\n    )\n    output_xml = optparse.make_option(\n        \"-o\", \"\", action=\"store\", dest=\"outfile\", metavar=\"OUTFILE\",\n        help=\"Write the XML report to this file. Defaults to 'coverage.xml'\",\n    )\n    output_json = optparse.make_option(\n        \"-o\", \"\", action=\"store\", dest=\"outfile\", metavar=\"OUTFILE\",\n        help=\"Write the JSON report to this file. Defaults to 'coverage.json'\",\n    )\n    output_lcov = optparse.make_option(\n        \"-o\", \"\", action=\"store\", dest=\"outfile\", metavar=\"OUTFILE\",\n        help=\"Write the LCOV report to this file. Defaults to 'coverage.lcov'\",\n    )\n    json_pretty_print = optparse.make_option(\n        \"\", \"--pretty-print\", action=\"store_true\",\n        help=\"Format the JSON for human readers.\",\n    )\n    parallel_mode = optparse.make_option(\n        \"-p\", \"--parallel-mode\", action=\"store_true\",\n        help=(\n            \"Append the machine name, process id and random number to the \" +\n            \"data file name to simplify collecting data from \" +\n            \"many processes.\"\n        ),\n    )\n    precision = optparse.make_option(\n        \"\", \"--precision\", action=\"store\", metavar=\"N\", type=int,\n        help=(\n            \"Number of digits after the decimal point to display for \" +\n            \"reported coverage percentages.\"\n        ),\n    )\n    quiet = optparse.make_option(\n        \"-q\", \"--quiet\", action=\"store_true\",\n        help=\"Don't print messages about what is happening.\",\n    )\n    rcfile = optparse.make_option(\n        \"\", \"--rcfile\", action=\"store\",\n        help=(\n            \"Specify configuration file. \" +\n            \"By default '.coveragerc', 'setup.cfg', 'tox.ini', and \" +\n            \"'pyproject.toml' are tried. [env: COVERAGE_RCFILE]\"\n        ),\n    )\n    show_contexts = optparse.make_option(\n        \"--show-contexts\", action=\"store_true\",\n        help=\"Show contexts for covered lines.\",\n    )\n    skip_covered = optparse.make_option(\n        \"--skip-covered\", action=\"store_true\",\n        help=\"Skip files with 100% coverage.\",\n    )\n    no_skip_covered = optparse.make_option(\n        \"--no-skip-covered\", action=\"store_false\", dest=\"skip_covered\",\n        help=\"Disable --skip-covered.\",\n    )\n    skip_empty = optparse.make_option(\n        \"--skip-empty\", action=\"store_true\",\n        help=\"Skip files with no code.\",\n    )\n    sort = optparse.make_option(\n        \"--sort\", action=\"store\", metavar=\"COLUMN\",\n        help=(\n            \"Sort the report by the named column: name, stmts, miss, branch, brpart, or cover. \" +\n             \"Default is name.\"\n        ),\n    )\n    source = optparse.make_option(\n        \"\", \"--source\", action=\"store\", metavar=\"SRC1,SRC2,...\",\n        help=\"A list of directories or importable names of code to measure.\",\n    )\n    timid = optparse.make_option(\n        \"\", \"--timid\", action=\"store_true\",\n        help=\"Use the slower Python trace function core.\",\n    )\n    title = optparse.make_option(\n        \"\", \"--title\", action=\"store\", metavar=\"TITLE\",\n        help=\"A text string to use as the title on the HTML.\",\n    )\n    version = optparse.make_option(\n        \"\", \"--version\", action=\"store_true\",\n        help=\"Display version information and exit.\",\n    )\n\n\nclass CoverageOptionParser(optparse.OptionParser):\n    \"\"\"Base OptionParser for coverage.py.\n\n    Problems don't exit the program.\n    Defaults are initialized for all options.\n\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        kwargs[\"add_help_option\"] = False\n        super().__init__(*args, **kwargs)\n        self.set_defaults(\n            # Keep these arguments alphabetized by their names.\n            action=None,\n            append=None,\n            branch=None,\n            concurrency=None,\n            context=None,\n            contexts=None,\n            data_file=None,\n            debug=None,\n            directory=None,\n            fail_under=None,\n            format=None,\n            help=None,\n            ignore_errors=None,\n            include=None,\n            keep=None,\n            module=None,\n            omit=None,\n            parallel_mode=None,\n            precision=None,\n            pylib=None,\n            quiet=None,\n            rcfile=True,\n            show_contexts=None,\n            show_missing=None,\n            skip_covered=None,\n            skip_empty=None,\n            sort=None,\n            source=None,\n            timid=None,\n            title=None,\n            version=None,\n        )\n\n        self.disable_interspersed_args()\n\n    class OptionParserError(Exception):\n        \"\"\"Used to stop the optparse error handler ending the process.\"\"\"\n        pass\n\n    def parse_args_ok(self, args: list[str]) -> tuple[bool, optparse.Values | None, list[str]]:\n        \"\"\"Call optparse.parse_args, but return a triple:\n\n        (ok, options, args)\n\n        \"\"\"\n        try:\n            options, args = super().parse_args(args)\n        except self.OptionParserError:\n            return False, None, []\n        return True, options, args\n\n    def error(self, msg: str) -> NoReturn:\n        \"\"\"Override optparse.error so sys.exit doesn't get called.\"\"\"\n        show_help(msg)\n        raise self.OptionParserError\n\n\nclass GlobalOptionParser(CoverageOptionParser):\n    \"\"\"Command-line parser for coverage.py global option arguments.\"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n\n        self.add_options([\n            Opts.help,\n            Opts.version,\n        ])\n\n\nclass CmdOptionParser(CoverageOptionParser):\n    \"\"\"Parse one of the new-style commands for coverage.py.\"\"\"\n\n    def __init__(\n        self,\n        action: str,\n        options: list[optparse.Option],\n        description: str,\n        usage: str | None = None,\n    ):\n        \"\"\"Create an OptionParser for a coverage.py command.\n\n        `action` is the slug to put into `options.action`.\n        `options` is a list of Option's for the command.\n        `description` is the description of the command, for the help text.\n        `usage` is the usage string to display in help.\n\n        \"\"\"\n        if usage:\n            usage = \"%prog \" + usage\n        super().__init__(\n            usage=usage,\n            description=description,\n        )\n        self.set_defaults(action=action)\n        self.add_options(options)\n        self.cmd = action\n\n    def __eq__(self, other: str) -> bool:       # type: ignore[override]\n        # A convenience equality, so that I can put strings in unit test\n        # results, and they will compare equal to objects.\n        return (other == f\"<CmdOptionParser:{self.cmd}>\")\n\n    __hash__ = None         # type: ignore[assignment]\n\n    def get_prog_name(self) -> str:\n        \"\"\"Override of an undocumented function in optparse.OptionParser.\"\"\"\n        program_name = super().get_prog_name()\n\n        # Include the sub-command for this parser as part of the command.\n        return f\"{program_name} {self.cmd}\"\n\n# In lists of Opts, keep them alphabetized by the option names as they appear\n# on the command line, since these lists determine the order of the options in\n# the help output.\n#\n# In COMMANDS, keep the keys (command names) alphabetized.\n\nGLOBAL_ARGS = [\n    Opts.debug,\n    Opts.help,\n    Opts.rcfile,\n]\n\nCOMMANDS = {\n    \"annotate\": CmdOptionParser(\n        \"annotate\",\n        [\n            Opts.directory,\n            Opts.datafle_input,\n            Opts.ignore_errors,\n            Opts.include,\n            Opts.omit,\n            ] + GLOBAL_ARGS,\n        usage=\"[options] [modules]\",\n        description=(\n            \"Make annotated copies of the given files, marking statements that are executed \" +\n            \"with > and statements that are missed with !.\"\n        ),\n    ),\n\n    \"combine\": CmdOptionParser(\n        \"combine\",\n        [\n            Opts.append,\n            Opts.datafile,\n            Opts.keep,\n            Opts.quiet,\n            ] + GLOBAL_ARGS,\n        usage=\"[options] <path1> <path2> ... <pathN>\",\n        description=(\n            \"Combine data from multiple coverage files. \" +\n            \"The combined results are written to a single \" +\n            \"file representing the union of the data. The positional \" +\n            \"arguments are data files or directories containing data files. \" +\n            \"If no paths are provided, data files in the default data file's \" +\n            \"directory are combined.\"\n        ),\n    ),\n\n    \"debug\": CmdOptionParser(\n        \"debug\", GLOBAL_ARGS,\n        usage=\"<topic>\",\n        description=(\n            \"Display information about the internals of coverage.py, \" +\n            \"for diagnosing problems. \" +\n            \"Topics are: \" +\n                \"'data' to show a summary of the collected data; \" +\n                \"'sys' to show installation information; \" +\n                \"'config' to show the configuration; \" +\n                \"'premain' to show what is calling coverage; \" +\n                \"'pybehave' to show internal flags describing Python behavior.\"\n        ),\n    ),\n\n    \"erase\": CmdOptionParser(\n        \"erase\",\n        [\n            Opts.datafile,\n            ] + GLOBAL_ARGS,\n        description=\"Erase previously collected coverage data.\",\n    ),\n\n    \"help\": CmdOptionParser(\n        \"help\", GLOBAL_ARGS,\n        usage=\"[command]\",\n        description=\"Describe how to use coverage.py\",\n    ),\n\n    \"html\": CmdOptionParser(\n        \"html\",\n        [\n            Opts.contexts,\n            Opts.directory,\n            Opts.datafle_input,\n            Opts.fail_under,\n            Opts.ignore_errors,\n            Opts.include,\n            Opts.omit,\n            Opts.precision,\n            Opts.quiet,\n            Opts.show_contexts,\n            Opts.skip_covered,\n            Opts.no_skip_covered,\n            Opts.skip_empty,\n            Opts.title,\n            ] + GLOBAL_ARGS,\n        usage=\"[options] [modules]\",\n        description=(\n            \"Create an HTML report of the coverage of the files.  \" +\n            \"Each file gets its own page, with the source decorated to show \" +\n            \"executed, excluded, and missed lines.\"\n        ),\n    ),\n\n    \"json\": CmdOptionParser(\n        \"json\",\n        [\n            Opts.contexts,\n            Opts.datafle_input,\n            Opts.fail_under,\n            Opts.ignore_errors,\n            Opts.include,\n            Opts.omit,\n            Opts.output_json,\n            Opts.json_pretty_print,\n            Opts.quiet,\n            Opts.show_contexts,\n            ] + GLOBAL_ARGS,\n        usage=\"[options] [modules]\",\n        description=\"Generate a JSON report of coverage results.\",\n    ),\n\n    \"lcov\": CmdOptionParser(\n        \"lcov\",\n        [\n            Opts.datafle_input,\n            Opts.fail_under,\n            Opts.ignore_errors,\n            Opts.include,\n            Opts.output_lcov,\n            Opts.omit,\n            Opts.quiet,\n            ] + GLOBAL_ARGS,\n        usage=\"[options] [modules]\",\n        description=\"Generate an LCOV report of coverage results.\",\n    ),\n\n    \"report\": CmdOptionParser(\n        \"report\",\n        [\n            Opts.contexts,\n            Opts.datafle_input,\n            Opts.fail_under,\n            Opts.format,\n            Opts.ignore_errors,\n            Opts.include,\n            Opts.omit,\n            Opts.precision,\n            Opts.sort,\n            Opts.show_missing,\n            Opts.skip_covered,\n            Opts.no_skip_covered,\n            Opts.skip_empty,\n            ] + GLOBAL_ARGS,\n        usage=\"[options] [modules]\",\n        description=\"Report coverage statistics on modules.\",\n    ),\n\n    \"run\": CmdOptionParser(\n        \"run\",\n        [\n            Opts.append,\n            Opts.branch,\n            Opts.concurrency,\n            Opts.context,\n            Opts.datafile_output,\n            Opts.include,\n            Opts.module,\n            Opts.omit,\n            Opts.pylib,\n            Opts.parallel_mode,\n            Opts.source,\n            Opts.timid,\n            ] + GLOBAL_ARGS,\n        usage=\"[options] <pyfile> [program options]\",\n        description=\"Run a Python program, measuring code execution.\",\n    ),\n\n    \"xml\": CmdOptionParser(\n        \"xml\",\n        [\n            Opts.datafle_input,\n            Opts.fail_under,\n            Opts.ignore_errors,\n            Opts.include,\n            Opts.omit,\n            Opts.output_xml,\n            Opts.quiet,\n            Opts.skip_empty,\n            ] + GLOBAL_ARGS,\n        usage=\"[options] [modules]\",\n        description=\"Generate an XML report of coverage results.\",\n    ),\n}\n\n\ndef show_help(\n    error: str | None = None,\n    topic: str | None = None,\n    parser: optparse.OptionParser | None = None,\n) -> None:\n    \"\"\"Display an error message, or the named topic.\"\"\"\n    assert error or topic or parser\n\n    program_path = sys.argv[0]\n    if program_path.endswith(os.path.sep + \"__main__.py\"):\n        # The path is the main module of a package; get that path instead.\n        program_path = os.path.dirname(program_path)\n    program_name = os.path.basename(program_path)\n    if env.WINDOWS:\n        # entry_points={\"console_scripts\":...} on Windows makes files\n        # called coverage.exe, coverage3.exe, and coverage-3.5.exe. These\n        # invoke coverage-script.py, coverage3-script.py, and\n        # coverage-3.5-script.py.  argv[0] is the .py file, but we want to\n        # get back to the original form.\n        auto_suffix = \"-script.py\"\n        if program_name.endswith(auto_suffix):\n            program_name = program_name[:-len(auto_suffix)]\n\n    help_params = dict(coverage.__dict__)\n    help_params[\"__url__\"] = __url__\n    help_params[\"program_name\"] = program_name\n    if HAS_CTRACER:\n        help_params[\"extension_modifier\"] = \"with C extension\"\n    else:\n        help_params[\"extension_modifier\"] = \"without C extension\"\n\n    if error:\n        print(error, file=sys.stderr)\n        print(f\"Use '{program_name} help' for help.\", file=sys.stderr)\n    elif parser:\n        print(parser.format_help().strip())\n        print()\n    else:\n        assert topic is not None\n        help_msg = textwrap.dedent(HELP_TOPICS.get(topic, \"\")).strip()\n        if help_msg:\n            print(help_msg.format(**help_params))\n        else:\n            print(f\"Don't know topic {topic!r}\")\n    print(\"Full documentation is at {__url__}\".format(**help_params))\n\n\nOK, ERR, FAIL_UNDER = 0, 1, 2\n\n\nclass CoverageScript:\n    \"\"\"The command-line interface to coverage.py.\"\"\"\n\n    def __init__(self) -> None:\n        self.global_option = False\n        self.coverage: Coverage\n\n    def command_line(self, argv: list[str]) -> int:\n        \"\"\"The bulk of the command line interface to coverage.py.\n\n        `argv` is the argument list to process.\n\n        Returns 0 if all is well, 1 if something went wrong.\n\n        \"\"\"\n        # Collect the command-line options.\n        if not argv:\n            show_help(topic=\"minimum_help\")\n            return OK\n\n        # The command syntax we parse depends on the first argument.  Global\n        # switch syntax always starts with an option.\n        parser: optparse.OptionParser | None\n        self.global_option = argv[0].startswith(\"-\")\n        if self.global_option:\n            parser = GlobalOptionParser()\n        else:\n            parser = COMMANDS.get(argv[0])\n            if not parser:\n                show_help(f\"Unknown command: {argv[0]!r}\")\n                return ERR\n            argv = argv[1:]\n\n        ok, options, args = parser.parse_args_ok(argv)\n        if not ok:\n            return ERR\n        assert options is not None\n\n        # Handle help and version.\n        if self.do_help(options, args, parser):\n            return OK\n\n        # Listify the list options.\n        source = unshell_list(options.source)\n        omit = unshell_list(options.omit)\n        include = unshell_list(options.include)\n        debug = unshell_list(options.debug)\n        contexts = unshell_list(options.contexts)\n\n        if options.concurrency is not None:\n            concurrency = options.concurrency.split(\",\")\n        else:\n            concurrency = None\n\n        # Do something.\n        self.coverage = Coverage(\n            data_file=options.data_file or DEFAULT_DATAFILE,\n            data_suffix=options.parallel_mode,\n            cover_pylib=options.pylib,\n            timid=options.timid,\n            branch=options.branch,\n            config_file=options.rcfile,\n            source=source,\n            omit=omit,\n            include=include,\n            debug=debug,\n            concurrency=concurrency,\n            check_preimported=True,\n            context=options.context,\n            messages=not options.quiet,\n        )\n\n        if options.action == \"debug\":\n            return self.do_debug(args)\n\n        elif options.action == \"erase\":\n            self.coverage.erase()\n            return OK\n\n        elif options.action == \"run\":\n            return self.do_run(options, args)\n\n        elif options.action == \"combine\":\n            if options.append:\n                self.coverage.load()\n            data_paths = args or None\n            self.coverage.combine(data_paths, strict=True, keep=bool(options.keep))\n            self.coverage.save()\n            return OK\n\n        # Remaining actions are reporting, with some common options.\n        report_args = dict(\n            morfs=unglob_args(args),\n            ignore_errors=options.ignore_errors,\n            omit=omit,\n            include=include,\n            contexts=contexts,\n        )\n\n        # We need to be able to import from the current directory, because\n        # plugins may try to, for example, to read Django settings.\n        sys.path.insert(0, \"\")\n\n        self.coverage.load()\n\n        total = None\n        if options.action == \"report\":\n            total = self.coverage.report(\n                precision=options.precision,\n                show_missing=options.show_missing,\n                skip_covered=options.skip_covered,\n                skip_empty=options.skip_empty,\n                sort=options.sort,\n                output_format=options.format,\n                **report_args,\n            )\n        elif options.action == \"annotate\":\n            self.coverage.annotate(directory=options.directory, **report_args)\n        elif options.action == \"html\":\n            total = self.coverage.html_report(\n                directory=options.directory,\n                precision=options.precision,\n                skip_covered=options.skip_covered,\n                skip_empty=options.skip_empty,\n                show_contexts=options.show_contexts,\n                title=options.title,\n                **report_args,\n            )\n        elif options.action == \"xml\":\n            total = self.coverage.xml_report(\n                outfile=options.outfile,\n                skip_empty=options.skip_empty,\n                **report_args,\n            )\n        elif options.action == \"json\":\n            total = self.coverage.json_report(\n                outfile=options.outfile,\n                pretty_print=options.pretty_print,\n                show_contexts=options.show_contexts,\n                **report_args,\n            )\n        elif options.action == \"lcov\":\n            total = self.coverage.lcov_report(\n                outfile=options.outfile,\n                **report_args,\n            )\n        else:\n            # There are no other possible actions.\n            raise AssertionError\n\n        if total is not None:\n            # Apply the command line fail-under options, and then use the config\n            # value, so we can get fail_under from the config file.\n            if options.fail_under is not None:\n                self.coverage.set_option(\"report:fail_under\", options.fail_under)\n            if options.precision is not None:\n                self.coverage.set_option(\"report:precision\", options.precision)\n\n            fail_under = cast(float, self.coverage.get_option(\"report:fail_under\"))\n            precision = cast(int, self.coverage.get_option(\"report:precision\"))\n            if should_fail_under(total, fail_under, precision):\n                msg = \"total of {total} is less than fail-under={fail_under:.{p}f}\".format(\n                    total=display_covered(total, precision),\n                    fail_under=fail_under,\n                    p=precision,\n                )\n                print(\"Coverage failure:\", msg)\n                return FAIL_UNDER\n\n        return OK\n\n    def do_help(\n        self,\n        options: optparse.Values,\n        args: list[str],\n        parser: optparse.OptionParser,\n    ) -> bool:\n        \"\"\"Deal with help requests.\n\n        Return True if it handled the request, False if not.\n\n        \"\"\"\n        # Handle help.\n        if options.help:\n            if self.global_option:\n                show_help(topic=\"help\")\n            else:\n                show_help(parser=parser)\n            return True\n\n        if options.action == \"help\":\n            if args:\n                for a in args:\n                    parser_maybe = COMMANDS.get(a)\n                    if parser_maybe is not None:\n                        show_help(parser=parser_maybe)\n                    else:\n                        show_help(topic=a)\n            else:\n                show_help(topic=\"help\")\n            return True\n\n        # Handle version.\n        if options.version:\n            show_help(topic=\"version\")\n            return True\n\n        return False\n\n    def do_run(self, options: optparse.Values, args: list[str]) -> int:\n        \"\"\"Implementation of 'coverage run'.\"\"\"\n\n        if not args:\n            if options.module:\n                # Specified -m with nothing else.\n                show_help(\"No module specified for -m\")\n                return ERR\n            command_line = cast(str, self.coverage.get_option(\"run:command_line\"))\n            if command_line is not None:\n                args = shlex.split(command_line)\n                if args and args[0] in {\"-m\", \"--module\"}:\n                    options.module = True\n                    args = args[1:]\n        if not args:\n            show_help(\"Nothing to do.\")\n            return ERR\n\n        if options.append and self.coverage.get_option(\"run:parallel\"):\n            show_help(\"Can't append to data files in parallel mode.\")\n            return ERR\n\n        if options.concurrency == \"multiprocessing\":\n            # Can't set other run-affecting command line options with\n            # multiprocessing.\n            for opt_name in [\"branch\", \"include\", \"omit\", \"pylib\", \"source\", \"timid\"]:\n                # As it happens, all of these options have no default, meaning\n                # they will be None if they have not been specified.\n                if getattr(options, opt_name) is not None:\n                    show_help(\n                        \"Options affecting multiprocessing must only be specified \" +\n                        \"in a configuration file.\\n\" +\n                        f\"Remove --{opt_name} from the command line.\",\n                    )\n                    return ERR\n\n        os.environ[\"COVERAGE_RUN\"] = \"true\"\n\n        runner = PyRunner(args, as_module=bool(options.module))\n        runner.prepare()\n\n        if options.append:\n            self.coverage.load()\n\n        # Run the script.\n        self.coverage.start()\n        code_ran = True\n        try:\n            runner.run()\n        except NoSource:\n            code_ran = False\n            raise\n        finally:\n            self.coverage.stop()\n            if code_ran:\n                self.coverage.save()\n\n        return OK\n\n    def do_debug(self, args: list[str]) -> int:\n        \"\"\"Implementation of 'coverage debug'.\"\"\"\n\n        if not args:\n            show_help(\"What information would you like: config, data, sys, premain, pybehave?\")\n            return ERR\n        if args[1:]:\n            show_help(\"Only one topic at a time, please\")\n            return ERR\n\n        if args[0] == \"sys\":\n            write_formatted_info(print, \"sys\", self.coverage.sys_info())\n        elif args[0] == \"data\":\n            print(info_header(\"data\"))\n            data_file = self.coverage.config.data_file\n            debug_data_file(data_file)\n            for filename in combinable_files(data_file):\n                print(\"-----\")\n                debug_data_file(filename)\n        elif args[0] == \"config\":\n            write_formatted_info(print, \"config\", self.coverage.config.debug_info())\n        elif args[0] == \"premain\":\n            print(info_header(\"premain\"))\n            print(short_stack(full=True))\n        elif args[0] == \"pybehave\":\n            write_formatted_info(print, \"pybehave\", env.debug_info())\n        else:\n            show_help(f\"Don't know what you mean by {args[0]!r}\")\n            return ERR\n\n        return OK\n\n\ndef unshell_list(s: str) -> list[str] | None:\n    \"\"\"Turn a command-line argument into a list.\"\"\"\n    if not s:\n        return None\n    if env.WINDOWS:\n        # When running coverage.py as coverage.exe, some of the behavior\n        # of the shell is emulated: wildcards are expanded into a list of\n        # file names.  So you have to single-quote patterns on the command\n        # line, but (not) helpfully, the single quotes are included in the\n        # argument, so we have to strip them off here.\n        s = s.strip(\"'\")\n    return s.split(\",\")\n\n\ndef unglob_args(args: list[str]) -> list[str]:\n    \"\"\"Interpret shell wildcards for platforms that need it.\"\"\"\n    if env.WINDOWS:\n        globbed = []\n        for arg in args:\n            if \"?\" in arg or \"*\" in arg:\n                globbed.extend(glob.glob(arg))\n            else:\n                globbed.append(arg)\n        args = globbed\n    return args\n\n\nHELP_TOPICS = {\n    \"help\": \"\"\"\\\n        Coverage.py, version {__version__} {extension_modifier}\n        Measure, collect, and report on code coverage in Python programs.\n\n        usage: {program_name} <command> [options] [args]\n\n        Commands:\n            annotate    Annotate source files with execution information.\n            combine     Combine a number of data files.\n            debug       Display information about the internals of coverage.py\n            erase       Erase previously collected coverage data.\n            help        Get help on using coverage.py.\n            html        Create an HTML report.\n            json        Create a JSON report of coverage results.\n            lcov        Create an LCOV report of coverage results.\n            report      Report coverage stats on modules.\n            run         Run a Python program and measure code execution.\n            xml         Create an XML report of coverage results.\n\n        Use \"{program_name} help <command>\" for detailed help on any command.\n    \"\"\",\n\n    \"minimum_help\": (\n        \"Code coverage for Python, version {__version__} {extension_modifier}.  \" +\n        \"Use '{program_name} help' for help.\"\n    ),\n\n    \"version\": \"Coverage.py, version {__version__} {extension_modifier}\",\n}\n\n\ndef main(argv: list[str] | None = None) -> int | None:\n    \"\"\"The main entry point to coverage.py.\n\n    This is installed as the script entry point.\n\n    \"\"\"\n    if argv is None:\n        argv = sys.argv[1:]\n    try:\n        status = CoverageScript().command_line(argv)\n    except _ExceptionDuringRun as err:\n        # An exception was caught while running the product code.  The\n        # sys.exc_info() return tuple is packed into an _ExceptionDuringRun\n        # exception.\n        traceback.print_exception(*err.args)    # pylint: disable=no-value-for-parameter\n        status = ERR\n    except _BaseCoverageException as err:\n        # A controlled error inside coverage.py: print the message to the user.\n        msg = err.args[0]\n        print(msg)\n        status = ERR\n    except SystemExit as err:\n        # The user called `sys.exit()`.  Exit with their argument, if any.\n        if err.args:\n            status = err.args[0]\n        else:\n            status = None\n    return status\n\n# Profiling using ox_profile.  Install it from GitHub:\n#   pip install git+https://github.com/emin63/ox_profile.git\n#\n# $set_env.py: COVERAGE_PROFILE - Set to use ox_profile.\n_profile = os.getenv(\"COVERAGE_PROFILE\")\nif _profile:                                                # pragma: debugging\n    from ox_profile.core.launchers import SimpleLauncher    # pylint: disable=import-error\n    original_main = main\n\n    def main(                                               # pylint: disable=function-redefined\n        argv: list[str] | None = None,\n    ) -> int | None:\n        \"\"\"A wrapper around main that profiles.\"\"\"\n        profiler = SimpleLauncher.launch()\n        try:\n            return original_main(argv)\n        finally:\n            data, _ = profiler.query(re_filter=\"coverage\", max_records=100)\n            print(profiler.show(query=data, limit=100, sep=\"\", col=\"\"))\n            profiler.cancel()\n", "coverage/lcovreport.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"LCOV reporting for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport base64\nimport hashlib\nimport sys\n\nfrom typing import IO, Iterable, TYPE_CHECKING\n\nfrom coverage.plugin import FileReporter\nfrom coverage.report_core import get_analysis_to_report\nfrom coverage.results import Analysis, Numbers\nfrom coverage.types import TMorf\n\nif TYPE_CHECKING:\n    from coverage import Coverage\n\n\ndef line_hash(line: str) -> str:\n    \"\"\"Produce a hash of a source line for use in the LCOV file.\"\"\"\n    # The LCOV file format requires MD5 as a fingerprint of the file. This is\n    # not a security use.  Some security scanners raise alarms about the use of\n    # MD5 here, but it is a false positive. This is not a security concern.\n    hashed = hashlib.md5(line.encode(\"utf-8\")).digest()\n    return base64.b64encode(hashed).decode(\"ascii\").rstrip(\"=\")\n\n\nclass LcovReporter:\n    \"\"\"A reporter for writing LCOV coverage reports.\"\"\"\n\n    report_type = \"LCOV report\"\n\n    def __init__(self, coverage: Coverage) -> None:\n        self.coverage = coverage\n        self.total = Numbers(self.coverage.config.precision)\n\n    def report(self, morfs: Iterable[TMorf] | None, outfile: IO[str]) -> float:\n        \"\"\"Renders the full lcov report.\n\n        `morfs` is a list of modules or filenames\n\n        outfile is the file object to write the file into.\n        \"\"\"\n\n        self.coverage.get_data()\n        outfile = outfile or sys.stdout\n\n        for fr, analysis in get_analysis_to_report(self.coverage, morfs):\n            self.get_lcov(fr, analysis, outfile)\n\n        return self.total.n_statements and self.total.pc_covered\n\n    def get_lcov(self, fr: FileReporter, analysis: Analysis, outfile: IO[str]) -> None:\n        \"\"\"Produces the lcov data for a single file.\n\n        This currently supports both line and branch coverage,\n        however function coverage is not supported.\n        \"\"\"\n        self.total += analysis.numbers\n\n        outfile.write(\"TN:\\n\")\n        outfile.write(f\"SF:{fr.relative_filename()}\\n\")\n        source_lines = fr.source().splitlines()\n        for covered in sorted(analysis.executed):\n            if covered in analysis.excluded:\n                # Do not report excluded as executed\n                continue\n            # Note: Coverage.py currently only supports checking *if* a line\n            # has been executed, not how many times, so we set this to 1 for\n            # nice output even if it's technically incorrect.\n\n            # The lines below calculate a 64-bit encoded md5 hash of the line\n            # corresponding to the DA lines in the lcov file, for either case\n            # of the line being covered or missed in coverage.py. The final two\n            # characters of the encoding (\"==\") are removed from the hash to\n            # allow genhtml to run on the resulting lcov file.\n            if source_lines:\n                if covered-1 >= len(source_lines):\n                    break\n                line = source_lines[covered-1]\n            else:\n                line = \"\"\n            outfile.write(f\"DA:{covered},1,{line_hash(line)}\\n\")\n\n        for missed in sorted(analysis.missing):\n            # We don't have to skip excluded lines here, because `missing`\n            # already doesn't have them.\n            assert source_lines\n            line = source_lines[missed-1]\n            outfile.write(f\"DA:{missed},0,{line_hash(line)}\\n\")\n\n        outfile.write(f\"LF:{analysis.numbers.n_statements}\\n\")\n        outfile.write(f\"LH:{analysis.numbers.n_executed}\\n\")\n\n        # More information dense branch coverage data.\n        missing_arcs = analysis.missing_branch_arcs()\n        executed_arcs = analysis.executed_branch_arcs()\n        for block_number, block_line_number in enumerate(\n            sorted(analysis.branch_stats().keys()),\n        ):\n            for branch_number, line_number in enumerate(\n                sorted(missing_arcs[block_line_number]),\n            ):\n                # The exit branches have a negative line number,\n                # this will not produce valid lcov. Setting\n                # the line number of the exit branch to 0 will allow\n                # for valid lcov, while preserving the data.\n                line_number = max(line_number, 0)\n                outfile.write(f\"BRDA:{line_number},{block_number},{branch_number},-\\n\")\n\n            # The start value below allows for the block number to be\n            # preserved between these two for loops (stopping the loop from\n            # resetting the value of the block number to 0).\n            for branch_number, line_number in enumerate(\n                sorted(executed_arcs[block_line_number]),\n                start=len(missing_arcs[block_line_number]),\n            ):\n                line_number = max(line_number, 0)\n                outfile.write(f\"BRDA:{line_number},{block_number},{branch_number},1\\n\")\n\n        # Summary of the branch coverage.\n        if analysis.has_arcs:\n            branch_stats = analysis.branch_stats()\n            brf = sum(t for t, k in branch_stats.values())\n            brh = brf - sum(t - k for t, k in branch_stats.values())\n            outfile.write(f\"BRF:{brf}\\n\")\n            outfile.write(f\"BRH:{brh}\\n\")\n\n        outfile.write(\"end_of_record\\n\")\n", "coverage/results.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Results of coverage measurement.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport dataclasses\n\nfrom collections.abc import Container\nfrom typing import Iterable, TYPE_CHECKING\n\nfrom coverage.exceptions import ConfigError\nfrom coverage.misc import nice_pair\nfrom coverage.types import TArc, TLineNo\n\nif TYPE_CHECKING:\n    from coverage.data import CoverageData\n    from coverage.plugin import FileReporter\n\n\ndef analysis_from_file_reporter(\n    data: CoverageData,\n    precision: int,\n    file_reporter: FileReporter,\n    filename: str,\n) -> Analysis:\n    \"\"\"Create an Analysis from a FileReporter.\"\"\"\n    has_arcs = data.has_arcs()\n    statements = file_reporter.lines()\n    excluded = file_reporter.excluded_lines()\n    executed = file_reporter.translate_lines(data.lines(filename) or [])\n\n    if has_arcs:\n        _arc_possibilities_set = file_reporter.arcs()\n        _arcs_executed_set = file_reporter.translate_arcs(data.arcs(filename) or [])\n        exit_counts = file_reporter.exit_counts()\n        no_branch = file_reporter.no_branch_lines()\n    else:\n        _arc_possibilities_set = set()\n        _arcs_executed_set = set()\n        exit_counts = {}\n        no_branch = set()\n\n    return Analysis(\n        precision=precision,\n        filename=filename,\n        has_arcs=has_arcs,\n        statements=statements,\n        excluded=excluded,\n        executed=executed,\n        _arc_possibilities_set=_arc_possibilities_set,\n        _arcs_executed_set=_arcs_executed_set,\n        exit_counts=exit_counts,\n        no_branch=no_branch,\n    )\n\n\n@dataclasses.dataclass\nclass Analysis:\n    \"\"\"The results of analyzing a FileReporter.\"\"\"\n\n    precision: int\n    filename: str\n    has_arcs: bool\n    statements: set[TLineNo]\n    excluded: set[TLineNo]\n    executed: set[TLineNo]\n    _arc_possibilities_set: set[TArc]\n    _arcs_executed_set: set[TArc]\n    exit_counts: dict[TLineNo, int]\n    no_branch: set[TLineNo]\n\n    def __post_init__(self) -> None:\n        self.arc_possibilities = sorted(self._arc_possibilities_set)\n        self.arcs_executed = sorted(self._arcs_executed_set)\n        self.missing = self.statements - self.executed\n\n        if self.has_arcs:\n            n_branches = self._total_branches()\n            mba = self.missing_branch_arcs()\n            n_partial_branches = sum(len(v) for k,v in mba.items() if k not in self.missing)\n            n_missing_branches = sum(len(v) for k,v in mba.items())\n        else:\n            n_branches = n_partial_branches = n_missing_branches = 0\n\n        self.numbers = Numbers(\n            precision=self.precision,\n            n_files=1,\n            n_statements=len(self.statements),\n            n_excluded=len(self.excluded),\n            n_missing=len(self.missing),\n            n_branches=n_branches,\n            n_partial_branches=n_partial_branches,\n            n_missing_branches=n_missing_branches,\n        )\n\n    def narrow(self, lines: Container[TLineNo]) -> Analysis:\n        \"\"\"Create a narrowed Analysis.\n\n        The current analysis is copied to make a new one that only considers\n        the lines in `lines`.\n        \"\"\"\n\n        statements = {lno for lno in self.statements if lno in lines}\n        excluded = {lno for lno in self.excluded if lno in lines}\n        executed = {lno for lno in self.executed if lno in lines}\n\n        if self.has_arcs:\n            _arc_possibilities_set = {\n                (a, b) for a, b in self._arc_possibilities_set\n                if a in lines or b in lines\n            }\n            _arcs_executed_set = {\n                (a, b) for a, b in self._arcs_executed_set\n                if a in lines or b in lines\n            }\n            exit_counts = {\n                lno: num for lno, num in self.exit_counts.items()\n                if lno in lines\n            }\n            no_branch = {lno for lno in self.no_branch if lno in lines}\n        else:\n            _arc_possibilities_set = set()\n            _arcs_executed_set = set()\n            exit_counts = {}\n            no_branch = set()\n\n        return Analysis(\n            precision=self.precision,\n            filename=self.filename,\n            has_arcs=self.has_arcs,\n            statements=statements,\n            excluded=excluded,\n            executed=executed,\n            _arc_possibilities_set=_arc_possibilities_set,\n            _arcs_executed_set=_arcs_executed_set,\n            exit_counts=exit_counts,\n            no_branch=no_branch,\n        )\n\n    def missing_formatted(self, branches: bool = False) -> str:\n        \"\"\"The missing line numbers, formatted nicely.\n\n        Returns a string like \"1-2, 5-11, 13-14\".\n\n        If `branches` is true, includes the missing branch arcs also.\n\n        \"\"\"\n        if branches and self.has_arcs:\n            arcs = self.missing_branch_arcs().items()\n        else:\n            arcs = None\n\n        return format_lines(self.statements, self.missing, arcs=arcs)\n\n    def arcs_missing(self) -> list[TArc]:\n        \"\"\"Returns a sorted list of the un-executed arcs in the code.\"\"\"\n        missing = (\n            p for p in self.arc_possibilities\n                if p not in self.arcs_executed\n                    and p[0] not in self.no_branch\n                    and p[1] not in self.excluded\n        )\n        return sorted(missing)\n\n    def arcs_unpredicted(self) -> list[TArc]:\n        \"\"\"Returns a sorted list of the executed arcs missing from the code.\"\"\"\n        # Exclude arcs here which connect a line to itself.  They can occur\n        # in executed data in some cases.  This is where they can cause\n        # trouble, and here is where it's the least burden to remove them.\n        # Also, generators can somehow cause arcs from \"enter\" to \"exit\", so\n        # make sure we have at least one positive value.\n        unpredicted = (\n            e for e in self.arcs_executed\n                if e not in self.arc_possibilities\n                    and e[0] != e[1]\n                    and (e[0] > 0 or e[1] > 0)\n        )\n        return sorted(unpredicted)\n\n    def _branch_lines(self) -> list[TLineNo]:\n        \"\"\"Returns a list of line numbers that have more than one exit.\"\"\"\n        return [l1 for l1,count in self.exit_counts.items() if count > 1]\n\n    def _total_branches(self) -> int:\n        \"\"\"How many total branches are there?\"\"\"\n        return sum(count for count in self.exit_counts.values() if count > 1)\n\n    def missing_branch_arcs(self) -> dict[TLineNo, list[TLineNo]]:\n        \"\"\"Return arcs that weren't executed from branch lines.\n\n        Returns {l1:[l2a,l2b,...], ...}\n\n        \"\"\"\n        missing = self.arcs_missing()\n        branch_lines = set(self._branch_lines())\n        mba = collections.defaultdict(list)\n        for l1, l2 in missing:\n            if l1 in branch_lines:\n                mba[l1].append(l2)\n        return mba\n\n    def executed_branch_arcs(self) -> dict[TLineNo, list[TLineNo]]:\n        \"\"\"Return arcs that were executed from branch lines.\n\n        Returns {l1:[l2a,l2b,...], ...}\n\n        \"\"\"\n        branch_lines = set(self._branch_lines())\n        eba = collections.defaultdict(list)\n        for l1, l2 in self.arcs_executed:\n            if l1 in branch_lines:\n                eba[l1].append(l2)\n        return eba\n\n    def branch_stats(self) -> dict[TLineNo, tuple[int, int]]:\n        \"\"\"Get stats about branches.\n\n        Returns a dict mapping line numbers to a tuple:\n        (total_exits, taken_exits).\n        \"\"\"\n\n        missing_arcs = self.missing_branch_arcs()\n        stats = {}\n        for lnum in self._branch_lines():\n            exits = self.exit_counts[lnum]\n            missing = len(missing_arcs[lnum])\n            stats[lnum] = (exits, exits - missing)\n        return stats\n\n\n@dataclasses.dataclass\nclass Numbers:\n    \"\"\"The numerical results of measuring coverage.\n\n    This holds the basic statistics from `Analysis`, and is used to roll\n    up statistics across files.\n\n    \"\"\"\n\n    precision: int = 0\n    n_files: int = 0\n    n_statements: int = 0\n    n_excluded: int = 0\n    n_missing: int = 0\n    n_branches: int = 0\n    n_partial_branches: int = 0\n    n_missing_branches: int = 0\n\n    @property\n    def n_executed(self) -> int:\n        \"\"\"Returns the number of executed statements.\"\"\"\n        return self.n_statements - self.n_missing\n\n    @property\n    def n_executed_branches(self) -> int:\n        \"\"\"Returns the number of executed branches.\"\"\"\n        return self.n_branches - self.n_missing_branches\n\n    @property\n    def pc_covered(self) -> float:\n        \"\"\"Returns a single percentage value for coverage.\"\"\"\n        if self.n_statements > 0:\n            numerator, denominator = self.ratio_covered\n            pc_cov = (100.0 * numerator) / denominator\n        else:\n            pc_cov = 100.0\n        return pc_cov\n\n    @property\n    def pc_covered_str(self) -> str:\n        \"\"\"Returns the percent covered, as a string, without a percent sign.\n\n        Note that \"0\" is only returned when the value is truly zero, and \"100\"\n        is only returned when the value is truly 100.  Rounding can never\n        result in either \"0\" or \"100\".\n\n        \"\"\"\n        return display_covered(self.pc_covered, self.precision)\n\n    @property\n    def ratio_covered(self) -> tuple[int, int]:\n        \"\"\"Return a numerator and denominator for the coverage ratio.\"\"\"\n        numerator = self.n_executed + self.n_executed_branches\n        denominator = self.n_statements + self.n_branches\n        return numerator, denominator\n\n    def __add__(self, other: Numbers) -> Numbers:\n        return Numbers(\n            self.precision,\n            self.n_files + other.n_files,\n            self.n_statements + other.n_statements,\n            self.n_excluded + other.n_excluded,\n            self.n_missing + other.n_missing,\n            self.n_branches + other.n_branches,\n            self.n_partial_branches + other.n_partial_branches,\n            self.n_missing_branches + other.n_missing_branches,\n        )\n\n    def __radd__(self, other: int) -> Numbers:\n        # Implementing 0+Numbers allows us to sum() a list of Numbers.\n        assert other == 0   # we only ever call it this way.\n        return self\n\n\ndef display_covered(pc: float, precision: int) -> str:\n    \"\"\"Return a displayable total percentage, as a string.\n\n    Note that \"0\" is only returned when the value is truly zero, and \"100\"\n    is only returned when the value is truly 100.  Rounding can never\n    result in either \"0\" or \"100\".\n\n    \"\"\"\n    near0 = 1.0 / 10 ** precision\n    if 0 < pc < near0:\n        pc = near0\n    elif (100.0 - near0) < pc < 100:\n        pc = 100.0 - near0\n    else:\n        pc = round(pc, precision)\n    return \"%.*f\" % (precision, pc)\n\n\ndef _line_ranges(\n    statements: Iterable[TLineNo],\n    lines: Iterable[TLineNo],\n) -> list[tuple[TLineNo, TLineNo]]:\n    \"\"\"Produce a list of ranges for `format_lines`.\"\"\"\n    statements = sorted(statements)\n    lines = sorted(lines)\n\n    pairs = []\n    start = None\n    lidx = 0\n    for stmt in statements:\n        if lidx >= len(lines):\n            break\n        if stmt == lines[lidx]:\n            lidx += 1\n            if not start:\n                start = stmt\n            end = stmt\n        elif start:\n            pairs.append((start, end))\n            start = None\n    if start:\n        pairs.append((start, end))\n    return pairs\n\n\ndef format_lines(\n    statements: Iterable[TLineNo],\n    lines: Iterable[TLineNo],\n    arcs: Iterable[tuple[TLineNo, list[TLineNo]]] | None = None,\n) -> str:\n    \"\"\"Nicely format a list of line numbers.\n\n    Format a list of line numbers for printing by coalescing groups of lines as\n    long as the lines represent consecutive statements.  This will coalesce\n    even if there are gaps between statements.\n\n    For example, if `statements` is [1,2,3,4,5,10,11,12,13,14] and\n    `lines` is [1,2,5,10,11,13,14] then the result will be \"1-2, 5-11, 13-14\".\n\n    Both `lines` and `statements` can be any iterable. All of the elements of\n    `lines` must be in `statements`, and all of the values must be positive\n    integers.\n\n    If `arcs` is provided, they are (start,[end,end,end]) pairs that will be\n    included in the output as long as start isn't in `lines`.\n\n    \"\"\"\n    line_items = [(pair[0], nice_pair(pair)) for pair in _line_ranges(statements, lines)]\n    if arcs is not None:\n        line_exits = sorted(arcs)\n        for line, exits in line_exits:\n            for ex in sorted(exits):\n                if line not in lines and ex not in lines:\n                    dest = (ex if ex > 0 else \"exit\")\n                    line_items.append((line, f\"{line}->{dest}\"))\n\n    ret = \", \".join(t[-1] for t in sorted(line_items))\n    return ret\n\n\ndef should_fail_under(total: float, fail_under: float, precision: int) -> bool:\n    \"\"\"Determine if a total should fail due to fail-under.\n\n    `total` is a float, the coverage measurement total. `fail_under` is the\n    fail_under setting to compare with. `precision` is the number of digits\n    to consider after the decimal point.\n\n    Returns True if the total should fail.\n\n    \"\"\"\n    # We can never achieve higher than 100% coverage, or less than zero.\n    if not (0 <= fail_under <= 100.0):\n        msg = f\"fail_under={fail_under} is invalid. Must be between 0 and 100.\"\n        raise ConfigError(msg)\n\n    # Special case for fail_under=100, it must really be 100.\n    if fail_under == 100.0 and total != 100.0:\n        return True\n\n    return round(total, precision) < fail_under\n", "coverage/python.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Python source expertise for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\nimport types\nimport zipimport\n\nfrom typing import Iterable, TYPE_CHECKING\n\nfrom coverage import env\nfrom coverage.exceptions import CoverageException, NoSource\nfrom coverage.files import canonical_filename, relative_filename, zip_location\nfrom coverage.misc import isolate_module, join_regex\nfrom coverage.parser import PythonParser\nfrom coverage.phystokens import source_token_lines, source_encoding\nfrom coverage.plugin import CodeRegion, FileReporter\nfrom coverage.regions import code_regions\nfrom coverage.types import TArc, TLineNo, TMorf, TSourceTokenLines\n\nif TYPE_CHECKING:\n    from coverage import Coverage\n\nos = isolate_module(os)\n\n\ndef read_python_source(filename: str) -> bytes:\n    \"\"\"Read the Python source text from `filename`.\n\n    Returns bytes.\n\n    \"\"\"\n    with open(filename, \"rb\") as f:\n        source = f.read()\n\n    return source.replace(b\"\\r\\n\", b\"\\n\").replace(b\"\\r\", b\"\\n\")\n\n\ndef get_python_source(filename: str) -> str:\n    \"\"\"Return the source code, as unicode.\"\"\"\n    base, ext = os.path.splitext(filename)\n    if ext == \".py\" and env.WINDOWS:\n        exts = [\".py\", \".pyw\"]\n    else:\n        exts = [ext]\n\n    source_bytes: bytes | None\n    for ext in exts:\n        try_filename = base + ext\n        if os.path.exists(try_filename):\n            # A regular text file: open it.\n            source_bytes = read_python_source(try_filename)\n            break\n\n        # Maybe it's in a zip file?\n        source_bytes = get_zip_bytes(try_filename)\n        if source_bytes is not None:\n            break\n    else:\n        # Couldn't find source.\n        raise NoSource(f\"No source for code: '{filename}'.\")\n\n    # Replace \\f because of http://bugs.python.org/issue19035\n    source_bytes = source_bytes.replace(b\"\\f\", b\" \")\n    source = source_bytes.decode(source_encoding(source_bytes), \"replace\")\n\n    # Python code should always end with a line with a newline.\n    if source and source[-1] != \"\\n\":\n        source += \"\\n\"\n\n    return source\n\n\ndef get_zip_bytes(filename: str) -> bytes | None:\n    \"\"\"Get data from `filename` if it is a zip file path.\n\n    Returns the bytestring data read from the zip file, or None if no zip file\n    could be found or `filename` isn't in it.  The data returned will be\n    an empty string if the file is empty.\n\n    \"\"\"\n    zipfile_inner = zip_location(filename)\n    if zipfile_inner is not None:\n        zipfile, inner = zipfile_inner\n        try:\n            zi = zipimport.zipimporter(zipfile)\n        except zipimport.ZipImportError:\n            return None\n        try:\n            data = zi.get_data(inner)\n        except OSError:\n            return None\n        return data\n    return None\n\n\ndef source_for_file(filename: str) -> str:\n    \"\"\"Return the source filename for `filename`.\n\n    Given a file name being traced, return the best guess as to the source\n    file to attribute it to.\n\n    \"\"\"\n    if filename.endswith(\".py\"):\n        # .py files are themselves source files.\n        return filename\n\n    elif filename.endswith((\".pyc\", \".pyo\")):\n        # Bytecode files probably have source files near them.\n        py_filename = filename[:-1]\n        if os.path.exists(py_filename):\n            # Found a .py file, use that.\n            return py_filename\n        if env.WINDOWS:\n            # On Windows, it could be a .pyw file.\n            pyw_filename = py_filename + \"w\"\n            if os.path.exists(pyw_filename):\n                return pyw_filename\n        # Didn't find source, but it's probably the .py file we want.\n        return py_filename\n\n    # No idea, just use the file name as-is.\n    return filename\n\n\ndef source_for_morf(morf: TMorf) -> str:\n    \"\"\"Get the source filename for the module-or-file `morf`.\"\"\"\n    if hasattr(morf, \"__file__\") and morf.__file__:\n        filename = morf.__file__\n    elif isinstance(morf, types.ModuleType):\n        # A module should have had .__file__, otherwise we can't use it.\n        # This could be a PEP-420 namespace package.\n        raise CoverageException(f\"Module {morf} has no file\")\n    else:\n        filename = morf\n\n    filename = source_for_file(filename)\n    return filename\n\n\nclass PythonFileReporter(FileReporter):\n    \"\"\"Report support for a Python file.\"\"\"\n\n    def __init__(self, morf: TMorf, coverage: Coverage | None = None) -> None:\n        self.coverage = coverage\n\n        filename = source_for_morf(morf)\n\n        fname = filename\n        canonicalize = True\n        if self.coverage is not None:\n            if self.coverage.config.relative_files:\n                canonicalize = False\n        if canonicalize:\n            fname = canonical_filename(filename)\n        super().__init__(fname)\n\n        if hasattr(morf, \"__name__\"):\n            name = morf.__name__.replace(\".\", os.sep)\n            if os.path.basename(filename).startswith(\"__init__.\"):\n                name += os.sep + \"__init__\"\n            name += \".py\"\n        else:\n            name = relative_filename(filename)\n        self.relname = name\n\n        self._source: str | None = None\n        self._parser: PythonParser | None = None\n        self._excluded = None\n\n    def __repr__(self) -> str:\n        return f\"<PythonFileReporter {self.filename!r}>\"\n\n    def relative_filename(self) -> str:\n        return self.relname\n\n    @property\n    def parser(self) -> PythonParser:\n        \"\"\"Lazily create a :class:`PythonParser`.\"\"\"\n        assert self.coverage is not None\n        if self._parser is None:\n            self._parser = PythonParser(\n                filename=self.filename,\n                exclude=self.coverage._exclude_regex(\"exclude\"),\n            )\n            self._parser.parse_source()\n        return self._parser\n\n    def lines(self) -> set[TLineNo]:\n        \"\"\"Return the line numbers of statements in the file.\"\"\"\n        return self.parser.statements\n\n    def excluded_lines(self) -> set[TLineNo]:\n        \"\"\"Return the line numbers of statements in the file.\"\"\"\n        return self.parser.excluded\n\n    def translate_lines(self, lines: Iterable[TLineNo]) -> set[TLineNo]:\n        return self.parser.translate_lines(lines)\n\n    def translate_arcs(self, arcs: Iterable[TArc]) -> set[TArc]:\n        return self.parser.translate_arcs(arcs)\n\n    def no_branch_lines(self) -> set[TLineNo]:\n        assert self.coverage is not None\n        no_branch = self.parser.lines_matching(\n            join_regex(\n                self.coverage.config.partial_list\n                + self.coverage.config.partial_always_list\n            )\n        )\n        return no_branch\n\n    def arcs(self) -> set[TArc]:\n        return self.parser.arcs()\n\n    def exit_counts(self) -> dict[TLineNo, int]:\n        return self.parser.exit_counts()\n\n    def missing_arc_description(\n        self,\n        start: TLineNo,\n        end: TLineNo,\n        executed_arcs: Iterable[TArc] | None = None,\n    ) -> str:\n        return self.parser.missing_arc_description(start, end, executed_arcs)\n\n    def source(self) -> str:\n        if self._source is None:\n            self._source = get_python_source(self.filename)\n        return self._source\n\n    def should_be_python(self) -> bool:\n        \"\"\"Does it seem like this file should contain Python?\n\n        This is used to decide if a file reported as part of the execution of\n        a program was really likely to have contained Python in the first\n        place.\n\n        \"\"\"\n        # Get the file extension.\n        _, ext = os.path.splitext(self.filename)\n\n        # Anything named *.py* should be Python.\n        if ext.startswith(\".py\"):\n            return True\n        # A file with no extension should be Python.\n        if not ext:\n            return True\n        # Everything else is probably not Python.\n        return False\n\n    def source_token_lines(self) -> TSourceTokenLines:\n        return source_token_lines(self.source())\n\n    def code_regions(self) -> Iterable[CodeRegion]:\n        return code_regions(self.source())\n\n    def code_region_kinds(self) -> Iterable[tuple[str, str]]:\n        return [\n            (\"function\", \"functions\"),\n            (\"class\", \"classes\"),\n        ]\n", "coverage/files.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"File wrangling.\"\"\"\n\nfrom __future__ import annotations\n\nimport hashlib\nimport ntpath\nimport os\nimport os.path\nimport posixpath\nimport re\nimport sys\n\nfrom typing import Callable, Iterable\n\nfrom coverage import env\nfrom coverage.exceptions import ConfigError\nfrom coverage.misc import human_sorted, isolate_module, join_regex\n\n\nos = isolate_module(os)\n\n\nRELATIVE_DIR: str = \"\"\nCANONICAL_FILENAME_CACHE: dict[str, str] = {}\n\ndef set_relative_directory() -> None:\n    \"\"\"Set the directory that `relative_filename` will be relative to.\"\"\"\n    global RELATIVE_DIR, CANONICAL_FILENAME_CACHE\n\n    # The current directory\n    abs_curdir = abs_file(os.curdir)\n    if not abs_curdir.endswith(os.sep):\n        # Suffix with separator only if not at the system root\n        abs_curdir = abs_curdir + os.sep\n\n    # The absolute path to our current directory.\n    RELATIVE_DIR = os.path.normcase(abs_curdir)\n\n    # Cache of results of calling the canonical_filename() method, to\n    # avoid duplicating work.\n    CANONICAL_FILENAME_CACHE = {}\n\n\ndef relative_directory() -> str:\n    \"\"\"Return the directory that `relative_filename` is relative to.\"\"\"\n    return RELATIVE_DIR\n\n\ndef relative_filename(filename: str) -> str:\n    \"\"\"Return the relative form of `filename`.\n\n    The file name will be relative to the current directory when the\n    `set_relative_directory` was called.\n\n    \"\"\"\n    fnorm = os.path.normcase(filename)\n    if fnorm.startswith(RELATIVE_DIR):\n        filename = filename[len(RELATIVE_DIR):]\n    return filename\n\n\ndef canonical_filename(filename: str) -> str:\n    \"\"\"Return a canonical file name for `filename`.\n\n    An absolute path with no redundant components and normalized case.\n\n    \"\"\"\n    if filename not in CANONICAL_FILENAME_CACHE:\n        cf = filename\n        if not os.path.isabs(filename):\n            for path in [os.curdir] + sys.path:\n                if path is None:\n                    continue # type: ignore[unreachable]\n                f = os.path.join(path, filename)\n                try:\n                    exists = os.path.exists(f)\n                except UnicodeError:\n                    exists = False\n                if exists:\n                    cf = f\n                    break\n        cf = abs_file(cf)\n        CANONICAL_FILENAME_CACHE[filename] = cf\n    return CANONICAL_FILENAME_CACHE[filename]\n\n\ndef flat_rootname(filename: str) -> str:\n    \"\"\"A base for a flat file name to correspond to this file.\n\n    Useful for writing files about the code where you want all the files in\n    the same directory, but need to differentiate same-named files from\n    different directories.\n\n    For example, the file a/b/c.py will return 'z_86bbcbe134d28fd2_c_py'\n\n    \"\"\"\n    dirname, basename = ntpath.split(filename)\n    if dirname:\n        fp = hashlib.new(\"sha3_256\", dirname.encode(\"UTF-8\")).hexdigest()[:16]\n        prefix = f\"z_{fp}_\"\n    else:\n        prefix = \"\"\n    return prefix + basename.replace(\".\", \"_\")\n\n\nif env.WINDOWS:\n\n    _ACTUAL_PATH_CACHE: dict[str, str] = {}\n    _ACTUAL_PATH_LIST_CACHE: dict[str, list[str]] = {}\n\n    def actual_path(path: str) -> str:\n        \"\"\"Get the actual path of `path`, including the correct case.\"\"\"\n        if path in _ACTUAL_PATH_CACHE:\n            return _ACTUAL_PATH_CACHE[path]\n\n        head, tail = os.path.split(path)\n        if not tail:\n            # This means head is the drive spec: normalize it.\n            actpath = head.upper()\n        elif not head:\n            actpath = tail\n        else:\n            head = actual_path(head)\n            if head in _ACTUAL_PATH_LIST_CACHE:\n                files = _ACTUAL_PATH_LIST_CACHE[head]\n            else:\n                try:\n                    files = os.listdir(head)\n                except Exception:\n                    # This will raise OSError, or this bizarre TypeError:\n                    # https://bugs.python.org/issue1776160\n                    files = []\n                _ACTUAL_PATH_LIST_CACHE[head] = files\n            normtail = os.path.normcase(tail)\n            for f in files:\n                if os.path.normcase(f) == normtail:\n                    tail = f\n                    break\n            actpath = os.path.join(head, tail)\n        _ACTUAL_PATH_CACHE[path] = actpath\n        return actpath\n\nelse:\n    def actual_path(path: str) -> str:\n        \"\"\"The actual path for non-Windows platforms.\"\"\"\n        return path\n\n\ndef abs_file(path: str) -> str:\n    \"\"\"Return the absolute normalized form of `path`.\"\"\"\n    return actual_path(os.path.abspath(os.path.realpath(path)))\n\n\ndef zip_location(filename: str) -> tuple[str, str] | None:\n    \"\"\"Split a filename into a zipfile / inner name pair.\n\n    Only return a pair if the zipfile exists.  No check is made if the inner\n    name is in the zipfile.\n\n    \"\"\"\n    for ext in [\".zip\", \".whl\", \".egg\", \".pex\"]:\n        zipbase, extension, inner = filename.partition(ext + sep(filename))\n        if extension:\n            zipfile = zipbase + ext\n            if os.path.exists(zipfile):\n                return zipfile, inner\n    return None\n\n\ndef source_exists(path: str) -> bool:\n    \"\"\"Determine if a source file path exists.\"\"\"\n    if os.path.exists(path):\n        return True\n\n    if zip_location(path):\n        # If zip_location returns anything, then it's a zipfile that\n        # exists. That's good enough for us.\n        return True\n\n    return False\n\n\ndef python_reported_file(filename: str) -> str:\n    \"\"\"Return the string as Python would describe this file name.\"\"\"\n    if env.PYBEHAVIOR.report_absolute_files:\n        filename = os.path.abspath(filename)\n    return filename\n\n\ndef isabs_anywhere(filename: str) -> bool:\n    \"\"\"Is `filename` an absolute path on any OS?\"\"\"\n    return ntpath.isabs(filename) or posixpath.isabs(filename)\n\n\ndef prep_patterns(patterns: Iterable[str]) -> list[str]:\n    \"\"\"Prepare the file patterns for use in a `GlobMatcher`.\n\n    If a pattern starts with a wildcard, it is used as a pattern\n    as-is.  If it does not start with a wildcard, then it is made\n    absolute with the current directory.\n\n    If `patterns` is None, an empty list is returned.\n\n    \"\"\"\n    prepped = []\n    for p in patterns or []:\n        prepped.append(p)\n        if not p.startswith((\"*\", \"?\")):\n            prepped.append(abs_file(p))\n    return prepped\n\n\nclass TreeMatcher:\n    \"\"\"A matcher for files in a tree.\n\n    Construct with a list of paths, either files or directories. Paths match\n    with the `match` method if they are one of the files, or if they are\n    somewhere in a subtree rooted at one of the directories.\n\n    \"\"\"\n    def __init__(self, paths: Iterable[str], name: str = \"unknown\") -> None:\n        self.original_paths: list[str] = human_sorted(paths)\n        #self.paths = list(map(os.path.normcase, paths))\n        self.paths = [os.path.normcase(p) for p in paths]\n        self.name = name\n\n    def __repr__(self) -> str:\n        return f\"<TreeMatcher {self.name} {self.original_paths!r}>\"\n\n    def info(self) -> list[str]:\n        \"\"\"A list of strings for displaying when dumping state.\"\"\"\n        return self.original_paths\n\n    def match(self, fpath: str) -> bool:\n        \"\"\"Does `fpath` indicate a file in one of our trees?\"\"\"\n        fpath = os.path.normcase(fpath)\n        for p in self.paths:\n            if fpath.startswith(p):\n                if fpath == p:\n                    # This is the same file!\n                    return True\n                if fpath[len(p)] == os.sep:\n                    # This is a file in the directory\n                    return True\n        return False\n\n\nclass ModuleMatcher:\n    \"\"\"A matcher for modules in a tree.\"\"\"\n    def __init__(self, module_names: Iterable[str], name:str = \"unknown\") -> None:\n        self.modules = list(module_names)\n        self.name = name\n\n    def __repr__(self) -> str:\n        return f\"<ModuleMatcher {self.name} {self.modules!r}>\"\n\n    def info(self) -> list[str]:\n        \"\"\"A list of strings for displaying when dumping state.\"\"\"\n        return self.modules\n\n    def match(self, module_name: str) -> bool:\n        \"\"\"Does `module_name` indicate a module in one of our packages?\"\"\"\n        if not module_name:\n            return False\n\n        for m in self.modules:\n            if module_name.startswith(m):\n                if module_name == m:\n                    return True\n                if module_name[len(m)] == \".\":\n                    # This is a module in the package\n                    return True\n\n        return False\n\n\nclass GlobMatcher:\n    \"\"\"A matcher for files by file name pattern.\"\"\"\n    def __init__(self, pats: Iterable[str], name: str = \"unknown\") -> None:\n        self.pats = list(pats)\n        self.re = globs_to_regex(self.pats, case_insensitive=env.WINDOWS)\n        self.name = name\n\n    def __repr__(self) -> str:\n        return f\"<GlobMatcher {self.name} {self.pats!r}>\"\n\n    def info(self) -> list[str]:\n        \"\"\"A list of strings for displaying when dumping state.\"\"\"\n        return self.pats\n\n    def match(self, fpath: str) -> bool:\n        \"\"\"Does `fpath` match one of our file name patterns?\"\"\"\n        return self.re.match(fpath) is not None\n\n\ndef sep(s: str) -> str:\n    \"\"\"Find the path separator used in this string, or os.sep if none.\"\"\"\n    if sep_match := re.search(r\"[\\\\/]\", s):\n        the_sep = sep_match[0]\n    else:\n        the_sep = os.sep\n    return the_sep\n\n\n# Tokenizer for _glob_to_regex.\n# None as a sub means disallowed.\nG2RX_TOKENS = [(re.compile(rx), sub) for rx, sub in [\n    (r\"\\*\\*\\*+\", None),             # Can't have ***\n    (r\"[^/]+\\*\\*+\", None),          # Can't have x**\n    (r\"\\*\\*+[^/]+\", None),          # Can't have **x\n    (r\"\\*\\*/\\*\\*\", None),           # Can't have **/**\n    (r\"^\\*+/\", r\"(.*[/\\\\\\\\])?\"),    # ^*/ matches any prefix-slash, or nothing.\n    (r\"/\\*+$\", r\"[/\\\\\\\\].*\"),       # /*$ matches any slash-suffix.\n    (r\"\\*\\*/\", r\"(.*[/\\\\\\\\])?\"),    # **/ matches any subdirs, including none\n    (r\"/\", r\"[/\\\\\\\\]\"),             # / matches either slash or backslash\n    (r\"\\*\", r\"[^/\\\\\\\\]*\"),          # * matches any number of non slash-likes\n    (r\"\\?\", r\"[^/\\\\\\\\]\"),           # ? matches one non slash-like\n    (r\"\\[.*?\\]\", r\"\\g<0>\"),         # [a-f] matches [a-f]\n    (r\"[a-zA-Z0-9_-]+\", r\"\\g<0>\"),  # word chars match themselves\n    (r\"[\\[\\]]\", None),              # Can't have single square brackets\n    (r\".\", r\"\\\\\\g<0>\"),             # Anything else is escaped to be safe\n]]\n\ndef _glob_to_regex(pattern: str) -> str:\n    \"\"\"Convert a file-path glob pattern into a regex.\"\"\"\n    # Turn all backslashes into slashes to simplify the tokenizer.\n    pattern = pattern.replace(\"\\\\\", \"/\")\n    if \"/\" not in pattern:\n        pattern = \"**/\" + pattern\n    path_rx = []\n    pos = 0\n    while pos < len(pattern):\n        for rx, sub in G2RX_TOKENS:                     # pragma: always breaks\n            if m := rx.match(pattern, pos=pos):\n                if sub is None:\n                    raise ConfigError(f\"File pattern can't include {m[0]!r}\")\n                path_rx.append(m.expand(sub))\n                pos = m.end()\n                break\n    return \"\".join(path_rx)\n\n\ndef globs_to_regex(\n    patterns: Iterable[str],\n    case_insensitive: bool = False,\n    partial: bool = False,\n) -> re.Pattern[str]:\n    \"\"\"Convert glob patterns to a compiled regex that matches any of them.\n\n    Slashes are always converted to match either slash or backslash, for\n    Windows support, even when running elsewhere.\n\n    If the pattern has no slash or backslash, then it is interpreted as\n    matching a file name anywhere it appears in the tree.  Otherwise, the glob\n    pattern must match the whole file path.\n\n    If `partial` is true, then the pattern will match if the target string\n    starts with the pattern. Otherwise, it must match the entire string.\n\n    Returns: a compiled regex object.  Use the .match method to compare target\n    strings.\n\n    \"\"\"\n    flags = 0\n    if case_insensitive:\n        flags |= re.IGNORECASE\n    rx = join_regex(map(_glob_to_regex, patterns))\n    if not partial:\n        rx = fr\"(?:{rx})\\Z\"\n    compiled = re.compile(rx, flags=flags)\n    return compiled\n\n\nclass PathAliases:\n    \"\"\"A collection of aliases for paths.\n\n    When combining data files from remote machines, often the paths to source\n    code are different, for example, due to OS differences, or because of\n    serialized checkouts on continuous integration machines.\n\n    A `PathAliases` object tracks a list of pattern/result pairs, and can\n    map a path through those aliases to produce a unified path.\n\n    \"\"\"\n    def __init__(\n        self,\n        debugfn: Callable[[str], None] | None = None,\n        relative: bool = False,\n    ) -> None:\n        # A list of (original_pattern, regex, result)\n        self.aliases: list[tuple[str, re.Pattern[str], str]] = []\n        self.debugfn = debugfn or (lambda msg: 0)\n        self.relative = relative\n        self.pprinted = False\n\n    def pprint(self) -> None:\n        \"\"\"Dump the important parts of the PathAliases, for debugging.\"\"\"\n        self.debugfn(f\"Aliases (relative={self.relative}):\")\n        for original_pattern, regex, result in self.aliases:\n            self.debugfn(f\" Rule: {original_pattern!r} -> {result!r} using regex {regex.pattern!r}\")\n\n    def add(self, pattern: str, result: str) -> None:\n        \"\"\"Add the `pattern`/`result` pair to the list of aliases.\n\n        `pattern` is an `glob`-style pattern.  `result` is a simple\n        string.  When mapping paths, if a path starts with a match against\n        `pattern`, then that match is replaced with `result`.  This models\n        isomorphic source trees being rooted at different places on two\n        different machines.\n\n        `pattern` can't end with a wildcard component, since that would\n        match an entire tree, and not just its root.\n\n        \"\"\"\n        original_pattern = pattern\n        pattern_sep = sep(pattern)\n\n        if len(pattern) > 1:\n            pattern = pattern.rstrip(r\"\\/\")\n\n        # The pattern can't end with a wildcard component.\n        if pattern.endswith(\"*\"):\n            raise ConfigError(\"Pattern must not end with wildcards.\")\n\n        # The pattern is meant to match a file path.  Let's make it absolute\n        # unless it already is, or is meant to match any prefix.\n        if not self.relative:\n            if not pattern.startswith(\"*\") and not isabs_anywhere(pattern + pattern_sep):\n                pattern = abs_file(pattern)\n        if not pattern.endswith(pattern_sep):\n            pattern += pattern_sep\n\n        # Make a regex from the pattern.\n        regex = globs_to_regex([pattern], case_insensitive=True, partial=True)\n\n        # Normalize the result: it must end with a path separator.\n        result_sep = sep(result)\n        result = result.rstrip(r\"\\/\") + result_sep\n        self.aliases.append((original_pattern, regex, result))\n\n    def map(self, path: str, exists:Callable[[str], bool] = source_exists) -> str:\n        \"\"\"Map `path` through the aliases.\n\n        `path` is checked against all of the patterns.  The first pattern to\n        match is used to replace the root of the path with the result root.\n        Only one pattern is ever used.  If no patterns match, `path` is\n        returned unchanged.\n\n        The separator style in the result is made to match that of the result\n        in the alias.\n\n        `exists` is a function to determine if the resulting path actually\n        exists.\n\n        Returns the mapped path.  If a mapping has happened, this is a\n        canonical path.  If no mapping has happened, it is the original value\n        of `path` unchanged.\n\n        \"\"\"\n        if not self.pprinted:\n            self.pprint()\n            self.pprinted = True\n\n        for original_pattern, regex, result in self.aliases:\n            if m := regex.match(path):\n                new = path.replace(m[0], result)\n                new = new.replace(sep(path), sep(result))\n                if not self.relative:\n                    new = canonical_filename(new)\n                dot_start = result.startswith((\"./\", \".\\\\\")) and len(result) > 2\n                if new.startswith((\"./\", \".\\\\\")) and not dot_start:\n                    new = new[2:]\n                if not exists(new):\n                    self.debugfn(\n                        f\"Rule {original_pattern!r} changed {path!r} to {new!r} \" +\n                        \"which doesn't exist, continuing\",\n                    )\n                    continue\n                self.debugfn(\n                    f\"Matched path {path!r} to rule {original_pattern!r} -> {result!r}, \" +\n                    f\"producing {new!r}\",\n                )\n                return new\n\n        # If we get here, no pattern matched.\n\n        if self.relative:\n            path = relative_filename(path)\n\n        if self.relative and not isabs_anywhere(path):\n            # Auto-generate a pattern to implicitly match relative files\n            parts = re.split(r\"[/\\\\]\", path)\n            if len(parts) > 1:\n                dir1 = parts[0]\n                pattern = f\"*/{dir1}\"\n                regex_pat = fr\"^(.*[\\\\/])?{re.escape(dir1)}[\\\\/]\"\n                result = f\"{dir1}{os.sep}\"\n                # Only add a new pattern if we don't already have this pattern.\n                if not any(p == pattern for p, _, _ in self.aliases):\n                    self.debugfn(\n                        f\"Generating rule: {pattern!r} -> {result!r} using regex {regex_pat!r}\",\n                    )\n                    self.aliases.append((pattern, re.compile(regex_pat), result))\n                    return self.map(path, exists=exists)\n\n        self.debugfn(f\"No rules match, path {path!r} is unchanged\")\n        return path\n\n\ndef find_python_files(dirname: str, include_namespace_packages: bool) -> Iterable[str]:\n    \"\"\"Yield all of the importable Python files in `dirname`, recursively.\n\n    To be importable, the files have to be in a directory with a __init__.py,\n    except for `dirname` itself, which isn't required to have one.  The\n    assumption is that `dirname` was specified directly, so the user knows\n    best, but sub-directories are checked for a __init__.py to be sure we only\n    find the importable files.\n\n    If `include_namespace_packages` is True, then the check for __init__.py\n    files is skipped.\n\n    Files with strange characters are skipped, since they couldn't have been\n    imported, and are probably editor side-files.\n\n    \"\"\"\n    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dirname)):\n        if not include_namespace_packages:\n            if i > 0 and \"__init__.py\" not in filenames:\n                # If a directory doesn't have __init__.py, then it isn't\n                # importable and neither are its files\n                del dirnames[:]\n                continue\n        for filename in filenames:\n            # We're only interested in files that look like reasonable Python\n            # files: Must end with .py or .pyw, and must not have certain funny\n            # characters that probably mean they are editor junk.\n            if re.match(r\"^[^.#~!$@%^&*()+=,]+\\.pyw?$\", filename):\n                yield os.path.join(dirpath, filename)\n\n\n# Globally set the relative directory.\nset_relative_directory()\n", "coverage/execfile.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Execute files of Python code.\"\"\"\n\nfrom __future__ import annotations\n\nimport importlib.machinery\nimport importlib.util\nimport inspect\nimport marshal\nimport os\nimport struct\nimport sys\n\nfrom importlib.machinery import ModuleSpec\nfrom types import CodeType, ModuleType\nfrom typing import Any\n\nfrom coverage import env\nfrom coverage.exceptions import CoverageException, _ExceptionDuringRun, NoCode, NoSource\nfrom coverage.files import canonical_filename, python_reported_file\nfrom coverage.misc import isolate_module\nfrom coverage.python import get_python_source\n\nos = isolate_module(os)\n\n\nPYC_MAGIC_NUMBER = importlib.util.MAGIC_NUMBER\n\nclass DummyLoader:\n    \"\"\"A shim for the pep302 __loader__, emulating pkgutil.ImpLoader.\n\n    Currently only implements the .fullname attribute\n    \"\"\"\n    def __init__(self, fullname: str, *_args: Any) -> None:\n        self.fullname = fullname\n\n\ndef find_module(\n    modulename: str,\n) -> tuple[str | None, str, ModuleSpec]:\n    \"\"\"Find the module named `modulename`.\n\n    Returns the file path of the module, the name of the enclosing\n    package, and the spec.\n    \"\"\"\n    try:\n        spec = importlib.util.find_spec(modulename)\n    except ImportError as err:\n        raise NoSource(str(err)) from err\n    if not spec:\n        raise NoSource(f\"No module named {modulename!r}\")\n    pathname = spec.origin\n    packagename = spec.name\n    if spec.submodule_search_locations:\n        mod_main = modulename + \".__main__\"\n        spec = importlib.util.find_spec(mod_main)\n        if not spec:\n            raise NoSource(\n                f\"No module named {mod_main}; \" +\n                f\"{modulename!r} is a package and cannot be directly executed\",\n            )\n        pathname = spec.origin\n        packagename = spec.name\n    packagename = packagename.rpartition(\".\")[0]\n    return pathname, packagename, spec\n\n\nclass PyRunner:\n    \"\"\"Multi-stage execution of Python code.\n\n    This is meant to emulate real Python execution as closely as possible.\n\n    \"\"\"\n    def __init__(self, args: list[str], as_module: bool = False) -> None:\n        self.args = args\n        self.as_module = as_module\n\n        self.arg0 = args[0]\n        self.package: str | None = None\n        self.modulename: str | None = None\n        self.pathname: str | None = None\n        self.loader: DummyLoader | None = None\n        self.spec: ModuleSpec | None = None\n\n    def prepare(self) -> None:\n        \"\"\"Set sys.path properly.\n\n        This needs to happen before any importing, and without importing anything.\n        \"\"\"\n        path0: str | None\n        if self.as_module:\n            path0 = os.getcwd()\n        elif os.path.isdir(self.arg0):\n            # Running a directory means running the __main__.py file in that\n            # directory.\n            path0 = self.arg0\n        else:\n            path0 = os.path.abspath(os.path.dirname(self.arg0))\n\n        if os.path.isdir(sys.path[0]):\n            # sys.path fakery.  If we are being run as a command, then sys.path[0]\n            # is the directory of the \"coverage\" script.  If this is so, replace\n            # sys.path[0] with the directory of the file we're running, or the\n            # current directory when running modules.  If it isn't so, then we\n            # don't know what's going on, and just leave it alone.\n            top_file = inspect.stack()[-1][0].f_code.co_filename\n            sys_path_0_abs = os.path.abspath(sys.path[0])\n            top_file_dir_abs = os.path.abspath(os.path.dirname(top_file))\n            sys_path_0_abs = canonical_filename(sys_path_0_abs)\n            top_file_dir_abs = canonical_filename(top_file_dir_abs)\n            if sys_path_0_abs != top_file_dir_abs:\n                path0 = None\n\n        else:\n            # sys.path[0] is a file. Is the next entry the directory containing\n            # that file?\n            if sys.path[1] == os.path.dirname(sys.path[0]):\n                # Can it be right to always remove that?\n                del sys.path[1]\n\n        if path0 is not None:\n            sys.path[0] = python_reported_file(path0)\n\n    def _prepare2(self) -> None:\n        \"\"\"Do more preparation to run Python code.\n\n        Includes finding the module to run and adjusting sys.argv[0].\n        This method is allowed to import code.\n\n        \"\"\"\n        if self.as_module:\n            self.modulename = self.arg0\n            pathname, self.package, self.spec = find_module(self.modulename)\n            if self.spec is not None:\n                self.modulename = self.spec.name\n            self.loader = DummyLoader(self.modulename)\n            assert pathname is not None\n            self.pathname = os.path.abspath(pathname)\n            self.args[0] = self.arg0 = self.pathname\n        elif os.path.isdir(self.arg0):\n            # Running a directory means running the __main__.py file in that\n            # directory.\n            for ext in [\".py\", \".pyc\", \".pyo\"]:\n                try_filename = os.path.join(self.arg0, \"__main__\" + ext)\n                # 3.8.10 changed how files are reported when running a\n                # directory.  But I'm not sure how far this change is going to\n                # spread, so I'll just hard-code it here for now.\n                if env.PYVERSION >= (3, 8, 10):\n                    try_filename = os.path.abspath(try_filename)\n                if os.path.exists(try_filename):\n                    self.arg0 = try_filename\n                    break\n            else:\n                raise NoSource(f\"Can't find '__main__' module in '{self.arg0}'\")\n\n            # Make a spec. I don't know if this is the right way to do it.\n            try_filename = python_reported_file(try_filename)\n            self.spec = importlib.machinery.ModuleSpec(\"__main__\", None, origin=try_filename)\n            self.spec.has_location = True\n            self.package = \"\"\n            self.loader = DummyLoader(\"__main__\")\n        else:\n            self.loader = DummyLoader(\"__main__\")\n\n        self.arg0 = python_reported_file(self.arg0)\n\n    def run(self) -> None:\n        \"\"\"Run the Python code!\"\"\"\n\n        self._prepare2()\n\n        # Create a module to serve as __main__\n        main_mod = ModuleType(\"__main__\")\n\n        from_pyc = self.arg0.endswith((\".pyc\", \".pyo\"))\n        main_mod.__file__ = self.arg0\n        if from_pyc:\n            main_mod.__file__ = main_mod.__file__[:-1]\n        if self.package is not None:\n            main_mod.__package__ = self.package\n        main_mod.__loader__ = self.loader   # type: ignore[assignment]\n        if self.spec is not None:\n            main_mod.__spec__ = self.spec\n\n        main_mod.__builtins__ = sys.modules[\"builtins\"]     # type: ignore[attr-defined]\n\n        sys.modules[\"__main__\"] = main_mod\n\n        # Set sys.argv properly.\n        sys.argv = self.args\n\n        try:\n            # Make a code object somehow.\n            if from_pyc:\n                code = make_code_from_pyc(self.arg0)\n            else:\n                code = make_code_from_py(self.arg0)\n        except CoverageException:\n            raise\n        except Exception as exc:\n            msg = f\"Couldn't run '{self.arg0}' as Python code: {exc.__class__.__name__}: {exc}\"\n            raise CoverageException(msg) from exc\n\n        # Execute the code object.\n        # Return to the original directory in case the test code exits in\n        # a non-existent directory.\n        cwd = os.getcwd()\n        try:\n            exec(code, main_mod.__dict__)\n        except SystemExit:                          # pylint: disable=try-except-raise\n            # The user called sys.exit().  Just pass it along to the upper\n            # layers, where it will be handled.\n            raise\n        except Exception:\n            # Something went wrong while executing the user code.\n            # Get the exc_info, and pack them into an exception that we can\n            # throw up to the outer loop.  We peel one layer off the traceback\n            # so that the coverage.py code doesn't appear in the final printed\n            # traceback.\n            typ, err, tb = sys.exc_info()\n            assert typ is not None\n            assert err is not None\n            assert tb is not None\n\n            # PyPy3 weirdness.  If I don't access __context__, then somehow it\n            # is non-None when the exception is reported at the upper layer,\n            # and a nested exception is shown to the user.  This getattr fixes\n            # it somehow? https://bitbucket.org/pypy/pypy/issue/1903\n            getattr(err, \"__context__\", None)\n\n            # Call the excepthook.\n            try:\n                assert err.__traceback__ is not None\n                err.__traceback__ = err.__traceback__.tb_next\n                sys.excepthook(typ, err, tb.tb_next)\n            except SystemExit:                      # pylint: disable=try-except-raise\n                raise\n            except Exception as exc:\n                # Getting the output right in the case of excepthook\n                # shenanigans is kind of involved.\n                sys.stderr.write(\"Error in sys.excepthook:\\n\")\n                typ2, err2, tb2 = sys.exc_info()\n                assert typ2 is not None\n                assert err2 is not None\n                assert tb2 is not None\n                err2.__suppress_context__ = True\n                assert err2.__traceback__ is not None\n                err2.__traceback__ = err2.__traceback__.tb_next\n                sys.__excepthook__(typ2, err2, tb2.tb_next)\n                sys.stderr.write(\"\\nOriginal exception was:\\n\")\n                raise _ExceptionDuringRun(typ, err, tb.tb_next) from exc\n            else:\n                sys.exit(1)\n        finally:\n            os.chdir(cwd)\n\n\ndef run_python_module(args: list[str]) -> None:\n    \"\"\"Run a Python module, as though with ``python -m name args...``.\n\n    `args` is the argument array to present as sys.argv, including the first\n    element naming the module being executed.\n\n    This is a helper for tests, to encapsulate how to use PyRunner.\n\n    \"\"\"\n    runner = PyRunner(args, as_module=True)\n    runner.prepare()\n    runner.run()\n\n\ndef run_python_file(args: list[str]) -> None:\n    \"\"\"Run a Python file as if it were the main program on the command line.\n\n    `args` is the argument array to present as sys.argv, including the first\n    element naming the file being executed.  `package` is the name of the\n    enclosing package, if any.\n\n    This is a helper for tests, to encapsulate how to use PyRunner.\n\n    \"\"\"\n    runner = PyRunner(args, as_module=False)\n    runner.prepare()\n    runner.run()\n\n\ndef make_code_from_py(filename: str) -> CodeType:\n    \"\"\"Get source from `filename` and make a code object of it.\"\"\"\n    # Open the source file.\n    try:\n        source = get_python_source(filename)\n    except (OSError, NoSource) as exc:\n        raise NoSource(f\"No file to run: '{filename}'\") from exc\n\n    return compile(source, filename, \"exec\", dont_inherit=True)\n\n\ndef make_code_from_pyc(filename: str) -> CodeType:\n    \"\"\"Get a code object from a .pyc file.\"\"\"\n    try:\n        fpyc = open(filename, \"rb\")\n    except OSError as exc:\n        raise NoCode(f\"No file to run: '{filename}'\") from exc\n\n    with fpyc:\n        # First four bytes are a version-specific magic number.  It has to\n        # match or we won't run the file.\n        magic = fpyc.read(4)\n        if magic != PYC_MAGIC_NUMBER:\n            raise NoCode(f\"Bad magic number in .pyc file: {magic!r} != {PYC_MAGIC_NUMBER!r}\")\n\n        flags = struct.unpack(\"<L\", fpyc.read(4))[0]\n        hash_based = flags & 0x01\n        if hash_based:\n            fpyc.read(8)    # Skip the hash.\n        else:\n            # Skip the junk in the header that we don't need.\n            fpyc.read(4)    # Skip the moddate.\n            fpyc.read(4)    # Skip the size.\n\n        # The rest of the file is the code object we want.\n        code = marshal.load(fpyc)\n        assert isinstance(code, CodeType)\n\n    return code\n", "coverage/misc.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Miscellaneous stuff for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport contextlib\nimport datetime\nimport errno\nimport functools\nimport hashlib\nimport importlib\nimport importlib.util\nimport inspect\nimport os\nimport os.path\nimport re\nimport sys\nimport types\n\nfrom types import ModuleType\nfrom typing import (\n    Any, Iterable, Iterator, Mapping, NoReturn, Sequence, TypeVar,\n)\n\nfrom coverage.exceptions import CoverageException\nfrom coverage.types import TArc\n\n# In 6.0, the exceptions moved from misc.py to exceptions.py.  But a number of\n# other packages were importing the exceptions from misc, so import them here.\n# pylint: disable=unused-wildcard-import\nfrom coverage.exceptions import *   # pylint: disable=wildcard-import\n\nISOLATED_MODULES: dict[ModuleType, ModuleType] = {}\n\n\ndef isolate_module(mod: ModuleType) -> ModuleType:\n    \"\"\"Copy a module so that we are isolated from aggressive mocking.\n\n    If a test suite mocks os.path.exists (for example), and then we need to use\n    it during the test, everything will get tangled up if we use their mock.\n    Making a copy of the module when we import it will isolate coverage.py from\n    those complications.\n    \"\"\"\n    if mod not in ISOLATED_MODULES:\n        new_mod = types.ModuleType(mod.__name__)\n        ISOLATED_MODULES[mod] = new_mod\n        for name in dir(mod):\n            value = getattr(mod, name)\n            if isinstance(value, types.ModuleType):\n                value = isolate_module(value)\n            setattr(new_mod, name, value)\n    return ISOLATED_MODULES[mod]\n\nos = isolate_module(os)\n\n\nclass SysModuleSaver:\n    \"\"\"Saves the contents of sys.modules, and removes new modules later.\"\"\"\n    def __init__(self) -> None:\n        self.old_modules = set(sys.modules)\n\n    def restore(self) -> None:\n        \"\"\"Remove any modules imported since this object started.\"\"\"\n        new_modules = set(sys.modules) - self.old_modules\n        for m in new_modules:\n            del sys.modules[m]\n\n\n@contextlib.contextmanager\ndef sys_modules_saved() -> Iterator[None]:\n    \"\"\"A context manager to remove any modules imported during a block.\"\"\"\n    saver = SysModuleSaver()\n    try:\n        yield\n    finally:\n        saver.restore()\n\n\ndef import_third_party(modname: str) -> tuple[ModuleType, bool]:\n    \"\"\"Import a third-party module we need, but might not be installed.\n\n    This also cleans out the module after the import, so that coverage won't\n    appear to have imported it.  This lets the third party use coverage for\n    their own tests.\n\n    Arguments:\n        modname (str): the name of the module to import.\n\n    Returns:\n        The imported module, and a boolean indicating if the module could be imported.\n\n    If the boolean is False, the module returned is not the one you want: don't use it.\n\n    \"\"\"\n    with sys_modules_saved():\n        try:\n            return importlib.import_module(modname), True\n        except ImportError:\n            return sys, False\n\n\ndef nice_pair(pair: TArc) -> str:\n    \"\"\"Make a nice string representation of a pair of numbers.\n\n    If the numbers are equal, just return the number, otherwise return the pair\n    with a dash between them, indicating the range.\n\n    \"\"\"\n    start, end = pair\n    if start == end:\n        return \"%d\" % start\n    else:\n        return \"%d-%d\" % (start, end)\n\n\ndef bool_or_none(b: Any) -> bool | None:\n    \"\"\"Return bool(b), but preserve None.\"\"\"\n    if b is None:\n        return None\n    else:\n        return bool(b)\n\n\ndef join_regex(regexes: Iterable[str]) -> str:\n    \"\"\"Combine a series of regex strings into one that matches any of them.\"\"\"\n    regexes = list(regexes)\n    if len(regexes) == 1:\n        return regexes[0]\n    else:\n        return \"|\".join(f\"(?:{r})\" for r in regexes)\n\n\ndef file_be_gone(path: str) -> None:\n    \"\"\"Remove a file, and don't get annoyed if it doesn't exist.\"\"\"\n    try:\n        os.remove(path)\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            raise\n\n\ndef ensure_dir(directory: str) -> None:\n    \"\"\"Make sure the directory exists.\n\n    If `directory` is None or empty, do nothing.\n    \"\"\"\n    if directory:\n        os.makedirs(directory, exist_ok=True)\n\n\ndef ensure_dir_for_file(path: str) -> None:\n    \"\"\"Make sure the directory for the path exists.\"\"\"\n    ensure_dir(os.path.dirname(path))\n\n\nclass Hasher:\n    \"\"\"Hashes Python data for fingerprinting.\"\"\"\n    def __init__(self) -> None:\n        self.hash = hashlib.new(\"sha3_256\")\n\n    def update(self, v: Any) -> None:\n        \"\"\"Add `v` to the hash, recursively if needed.\"\"\"\n        self.hash.update(str(type(v)).encode(\"utf-8\"))\n        if isinstance(v, str):\n            self.hash.update(v.encode(\"utf-8\"))\n        elif isinstance(v, bytes):\n            self.hash.update(v)\n        elif v is None:\n            pass\n        elif isinstance(v, (int, float)):\n            self.hash.update(str(v).encode(\"utf-8\"))\n        elif isinstance(v, (tuple, list)):\n            for e in v:\n                self.update(e)\n        elif isinstance(v, dict):\n            keys = v.keys()\n            for k in sorted(keys):\n                self.update(k)\n                self.update(v[k])\n        else:\n            for k in dir(v):\n                if k.startswith(\"__\"):\n                    continue\n                a = getattr(v, k)\n                if inspect.isroutine(a):\n                    continue\n                self.update(k)\n                self.update(a)\n        self.hash.update(b\".\")\n\n    def hexdigest(self) -> str:\n        \"\"\"Retrieve the hex digest of the hash.\"\"\"\n        return self.hash.hexdigest()[:32]\n\n\ndef _needs_to_implement(that: Any, func_name: str) -> NoReturn:\n    \"\"\"Helper to raise NotImplementedError in interface stubs.\"\"\"\n    if hasattr(that, \"_coverage_plugin_name\"):\n        thing = \"Plugin\"\n        name = that._coverage_plugin_name\n    else:\n        thing = \"Class\"\n        klass = that.__class__\n        name = f\"{klass.__module__}.{klass.__name__}\"\n\n    raise NotImplementedError(\n        f\"{thing} {name!r} needs to implement {func_name}()\",\n    )\n\n\nclass DefaultValue:\n    \"\"\"A sentinel object to use for unusual default-value needs.\n\n    Construct with a string that will be used as the repr, for display in help\n    and Sphinx output.\n\n    \"\"\"\n    def __init__(self, display_as: str) -> None:\n        self.display_as = display_as\n\n    def __repr__(self) -> str:\n        return self.display_as\n\n\ndef substitute_variables(text: str, variables: Mapping[str, str]) -> str:\n    \"\"\"Substitute ``${VAR}`` variables in `text` with their values.\n\n    Variables in the text can take a number of shell-inspired forms::\n\n        $VAR\n        ${VAR}\n        ${VAR?}             strict: an error if VAR isn't defined.\n        ${VAR-missing}      defaulted: \"missing\" if VAR isn't defined.\n        $$                  just a dollar sign.\n\n    `variables` is a dictionary of variable values.\n\n    Returns the resulting text with values substituted.\n\n    \"\"\"\n    dollar_pattern = r\"\"\"(?x)   # Use extended regex syntax\n        \\$                      # A dollar sign,\n        (?:                     # then\n            (?P<dollar>\\$) |        # a dollar sign, or\n            (?P<word1>\\w+) |        # a plain word, or\n            {                       # a {-wrapped\n                (?P<word2>\\w+)          # word,\n                (?:\n                    (?P<strict>\\?) |        # with a strict marker\n                    -(?P<defval>[^}]*)      # or a default value\n                )?                      # maybe.\n            }\n        )\n        \"\"\"\n\n    dollar_groups = (\"dollar\", \"word1\", \"word2\")\n\n    def dollar_replace(match: re.Match[str]) -> str:\n        \"\"\"Called for each $replacement.\"\"\"\n        # Only one of the dollar_groups will have matched, just get its text.\n        word = next(g for g in match.group(*dollar_groups) if g)    # pragma: always breaks\n        if word == \"$\":\n            return \"$\"\n        elif word in variables:\n            return variables[word]\n        elif match[\"strict\"]:\n            msg = f\"Variable {word} is undefined: {text!r}\"\n            raise CoverageException(msg)\n        else:\n            return match[\"defval\"]\n\n    text = re.sub(dollar_pattern, dollar_replace, text)\n    return text\n\n\ndef format_local_datetime(dt: datetime.datetime) -> str:\n    \"\"\"Return a string with local timezone representing the date.\n    \"\"\"\n    return dt.astimezone().strftime(\"%Y-%m-%d %H:%M %z\")\n\n\ndef import_local_file(modname: str, modfile: str | None = None) -> ModuleType:\n    \"\"\"Import a local file as a module.\n\n    Opens a file in the current directory named `modname`.py, imports it\n    as `modname`, and returns the module object.  `modfile` is the file to\n    import if it isn't in the current directory.\n\n    \"\"\"\n    if modfile is None:\n        modfile = modname + \".py\"\n    spec = importlib.util.spec_from_file_location(modname, modfile)\n    assert spec is not None\n    mod = importlib.util.module_from_spec(spec)\n    sys.modules[modname] = mod\n    assert spec.loader is not None\n    spec.loader.exec_module(mod)\n\n    return mod\n\n\n@functools.lru_cache(maxsize=None)\ndef _human_key(s: str) -> tuple[list[str | int], str]:\n    \"\"\"Turn a string into a list of string and number chunks.\n\n    \"z23a\" -> ([\"z\", 23, \"a\"], \"z23a\")\n\n    The original string is appended as a last value to ensure the\n    key is unique enough so that \"x1y\" and \"x001y\" can be distinguished.\n    \"\"\"\n    def tryint(s: str) -> str | int:\n        \"\"\"If `s` is a number, return an int, else `s` unchanged.\"\"\"\n        try:\n            return int(s)\n        except ValueError:\n            return s\n\n    return ([tryint(c) for c in re.split(r\"(\\d+)\", s)], s)\n\ndef human_sorted(strings: Iterable[str]) -> list[str]:\n    \"\"\"Sort the given iterable of strings the way that humans expect.\n\n    Numeric components in the strings are sorted as numbers.\n\n    Returns the sorted list.\n\n    \"\"\"\n    return sorted(strings, key=_human_key)\n\nSortableItem = TypeVar(\"SortableItem\", bound=Sequence[Any])\n\ndef human_sorted_items(\n    items: Iterable[SortableItem],\n    reverse: bool = False,\n) -> list[SortableItem]:\n    \"\"\"Sort (string, ...) items the way humans expect.\n\n    The elements of `items` can be any tuple/list. They'll be sorted by the\n    first element (a string), with ties broken by the remaining elements.\n\n    Returns the sorted list of items.\n    \"\"\"\n    return sorted(items, key=lambda item: (_human_key(item[0]), *item[1:]), reverse=reverse)\n\n\ndef plural(n: int, thing: str = \"\", things: str = \"\") -> str:\n    \"\"\"Pluralize a word.\n\n    If n is 1, return thing.  Otherwise return things, or thing+s.\n    \"\"\"\n    if n == 1:\n        return thing\n    else:\n        return things or (thing + \"s\")\n\n\ndef stdout_link(text: str, url: str) -> str:\n    \"\"\"Format text+url as a clickable link for stdout.\n\n    If attached to a terminal, use escape sequences. Otherwise, just return\n    the text.\n    \"\"\"\n    if hasattr(sys.stdout, \"isatty\") and sys.stdout.isatty():\n        return f\"\\033]8;;{url}\\a{text}\\033]8;;\\a\"\n    else:\n        return text\n", "coverage/types.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nTypes for use throughout coverage.py.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport pathlib\n\nfrom types import FrameType, ModuleType\nfrom typing import (\n    Any, Callable, Dict, Iterable, List, Mapping, Optional, Protocol,\n    Set, Tuple, Type, Union, TYPE_CHECKING,\n)\n\nif TYPE_CHECKING:\n    from coverage.plugin import FileTracer\n\n\nAnyCallable = Callable[..., Any]\n\n## File paths\n\n# For arguments that are file paths:\nif TYPE_CHECKING:\n    FilePath = Union[str, os.PathLike[str]]\nelse:\n    # PathLike < python3.9 doesn't support subscription\n    FilePath = Union[str, os.PathLike]\n# For testing FilePath arguments\nFilePathClasses = [str, pathlib.Path]\nFilePathType = Union[Type[str], Type[pathlib.Path]]\n\n## Python tracing\n\nclass TTraceFn(Protocol):\n    \"\"\"A Python trace function.\"\"\"\n    def __call__(\n        self,\n        frame: FrameType,\n        event: str,\n        arg: Any,\n        lineno: TLineNo | None = None,  # Our own twist, see collector.py\n    ) -> TTraceFn | None:\n        ...\n\n## Coverage.py tracing\n\n# Line numbers are pervasive enough that they deserve their own type.\nTLineNo = int\n\nTArc = Tuple[TLineNo, TLineNo]\n\nclass TFileDisposition(Protocol):\n    \"\"\"A simple value type for recording what to do with a file.\"\"\"\n\n    original_filename: str\n    canonical_filename: str\n    source_filename: str | None\n    trace: bool\n    reason: str\n    file_tracer: FileTracer | None\n    has_dynamic_filename: bool\n\n\n# When collecting data, we use a dictionary with a few possible shapes. The\n# keys are always file names.\n# - If measuring line coverage, the values are sets of line numbers.\n# - If measuring arcs in the Python tracer, the values are sets of arcs (pairs\n#   of line numbers).\n# - If measuring arcs in the C tracer, the values are sets of packed arcs (two\n#   line numbers combined into one integer).\n\nTTraceFileData = Union[Set[TLineNo], Set[TArc], Set[int]]\n\nTTraceData = Dict[str, TTraceFileData]\n\nclass TracerCore(Protocol):\n    \"\"\"Anything that can report on Python execution.\"\"\"\n\n    data: TTraceData\n    trace_arcs: bool\n    should_trace: Callable[[str, FrameType], TFileDisposition]\n    should_trace_cache: Mapping[str, TFileDisposition | None]\n    should_start_context: Callable[[FrameType], str | None] | None\n    switch_context: Callable[[str | None], None] | None\n    lock_data: Callable[[], None]\n    unlock_data: Callable[[], None]\n    warn: TWarnFn\n\n    def __init__(self) -> None:\n        ...\n\n    def start(self) -> TTraceFn | None:\n        \"\"\"Start this tracer, return a trace function if based on sys.settrace.\"\"\"\n\n    def stop(self) -> None:\n        \"\"\"Stop this tracer.\"\"\"\n\n    def activity(self) -> bool:\n        \"\"\"Has there been any activity?\"\"\"\n\n    def reset_activity(self) -> None:\n        \"\"\"Reset the activity() flag.\"\"\"\n\n    def get_stats(self) -> dict[str, int] | None:\n        \"\"\"Return a dictionary of statistics, or None.\"\"\"\n\n\n## Coverage\n\n# Many places use kwargs as Coverage kwargs.\nTCovKwargs = Any\n\n\n## Configuration\n\n# One value read from a config file.\nTConfigValueIn = Optional[Union[bool, int, float, str, Iterable[str]]]\nTConfigValueOut = Optional[Union[bool, int, float, str, List[str]]]\n# An entire config section, mapping option names to values.\nTConfigSectionIn = Mapping[str, TConfigValueIn]\nTConfigSectionOut = Mapping[str, TConfigValueOut]\n\nclass TConfigurable(Protocol):\n    \"\"\"Something that can proxy to the coverage configuration settings.\"\"\"\n\n    def get_option(self, option_name: str) -> TConfigValueOut | None:\n        \"\"\"Get an option from the configuration.\n\n        `option_name` is a colon-separated string indicating the section and\n        option name.  For example, the ``branch`` option in the ``[run]``\n        section of the config file would be indicated with `\"run:branch\"`.\n\n        Returns the value of the option.\n\n        \"\"\"\n\n    def set_option(self, option_name: str, value: TConfigValueIn | TConfigSectionIn) -> None:\n        \"\"\"Set an option in the configuration.\n\n        `option_name` is a colon-separated string indicating the section and\n        option name.  For example, the ``branch`` option in the ``[run]``\n        section of the config file would be indicated with `\"run:branch\"`.\n\n        `value` is the new value for the option.\n\n        \"\"\"\n\nclass TPluginConfig(Protocol):\n    \"\"\"Something that can provide options to a plugin.\"\"\"\n\n    def get_plugin_options(self, plugin: str) -> TConfigSectionOut:\n        \"\"\"Get the options for a plugin.\"\"\"\n\n\n## Parsing\n\nTMorf = Union[ModuleType, str]\n\nTSourceTokenLines = Iterable[List[Tuple[str, str]]]\n\n\n## Plugins\n\nclass TPlugin(Protocol):\n    \"\"\"What all plugins have in common.\"\"\"\n    _coverage_plugin_name: str\n    _coverage_enabled: bool\n\n\n## Debugging\n\nclass TWarnFn(Protocol):\n    \"\"\"A callable warn() function.\"\"\"\n    def __call__(self, msg: str, slug: str | None = None, once: bool = False) -> None:\n        ...\n\n\nclass TDebugCtl(Protocol):\n    \"\"\"A DebugControl object, or something like it.\"\"\"\n\n    def should(self, option: str) -> bool:\n        \"\"\"Decide whether to output debug information in category `option`.\"\"\"\n\n    def write(self, msg: str) -> None:\n        \"\"\"Write a line of debug output.\"\"\"\n\n\nclass TWritable(Protocol):\n    \"\"\"Anything that can be written to.\"\"\"\n\n    def write(self, msg: str) -> None:\n        \"\"\"Write a message.\"\"\"\n", "coverage/disposition.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Simple value objects for tracking what to do with files.\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom coverage.types import TFileDisposition\n\nif TYPE_CHECKING:\n    from coverage.plugin import FileTracer\n\n\nclass FileDisposition:\n    \"\"\"A simple value type for recording what to do with a file.\"\"\"\n\n    original_filename: str\n    canonical_filename: str\n    source_filename: str | None\n    trace: bool\n    reason: str\n    file_tracer: FileTracer | None\n    has_dynamic_filename: bool\n\n    def __repr__(self) -> str:\n        return f\"<FileDisposition {self.canonical_filename!r}: trace={self.trace}>\"\n\n\n# FileDisposition \"methods\": FileDisposition is a pure value object, so it can\n# be implemented in either C or Python.  Acting on them is done with these\n# functions.\n\ndef disposition_init(cls: type[TFileDisposition], original_filename: str) -> TFileDisposition:\n    \"\"\"Construct and initialize a new FileDisposition object.\"\"\"\n    disp = cls()\n    disp.original_filename = original_filename\n    disp.canonical_filename = original_filename\n    disp.source_filename = None\n    disp.trace = False\n    disp.reason = \"\"\n    disp.file_tracer = None\n    disp.has_dynamic_filename = False\n    return disp\n\n\ndef disposition_debug_msg(disp: TFileDisposition) -> str:\n    \"\"\"Make a nice debug message of what the FileDisposition is doing.\"\"\"\n    if disp.trace:\n        msg = f\"Tracing {disp.original_filename!r}\"\n        if disp.original_filename != disp.source_filename:\n            msg += f\" as {disp.source_filename!r}\"\n        if disp.file_tracer:\n            msg += f\": will be traced by {disp.file_tracer!r}\"\n    else:\n        msg = f\"Not tracing {disp.original_filename!r}: {disp.reason}\"\n    return msg\n", "coverage/sysmon.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Callback functions and support for sys.monitoring data collection.\"\"\"\n\nfrom __future__ import annotations\n\nimport functools\nimport inspect\nimport os\nimport os.path\nimport sys\nimport threading\nimport traceback\n\nfrom dataclasses import dataclass\nfrom types import CodeType, FrameType\nfrom typing import (\n    Any,\n    Callable,\n    Set,\n    TYPE_CHECKING,\n    cast,\n)\n\nfrom coverage.debug import short_filename, short_stack\nfrom coverage.types import (\n    AnyCallable,\n    TArc,\n    TFileDisposition,\n    TLineNo,\n    TTraceData,\n    TTraceFileData,\n    TracerCore,\n    TWarnFn,\n)\n\n# pylint: disable=unused-argument\n\nLOG = False\n\n# This module will be imported in all versions of Python, but only used in 3.12+\n# It will be type-checked for 3.12, but not for earlier versions.\nsys_monitoring = getattr(sys, \"monitoring\", None)\n\nif TYPE_CHECKING:\n    assert sys_monitoring is not None\n    # I want to say this but it's not allowed:\n    #   MonitorReturn = Literal[sys.monitoring.DISABLE] | None\n    MonitorReturn = Any\n\n\nif LOG:  # pragma: debugging\n\n    class LoggingWrapper:\n        \"\"\"Wrap a namespace to log all its functions.\"\"\"\n\n        def __init__(self, wrapped: Any, namespace: str) -> None:\n            self.wrapped = wrapped\n            self.namespace = namespace\n\n        def __getattr__(self, name: str) -> Callable[..., Any]:\n            def _wrapped(*args: Any, **kwargs: Any) -> Any:\n                log(f\"{self.namespace}.{name}{args}{kwargs}\")\n                return getattr(self.wrapped, name)(*args, **kwargs)\n\n            return _wrapped\n\n    sys_monitoring = LoggingWrapper(sys_monitoring, \"sys.monitoring\")\n    assert sys_monitoring is not None\n\n    short_stack = functools.partial(\n        short_stack, full=True, short_filenames=True, frame_ids=True,\n    )\n    seen_threads: set[int] = set()\n\n    def log(msg: str) -> None:\n        \"\"\"Write a message to our detailed debugging log(s).\"\"\"\n        # Thread ids are reused across processes?\n        # Make a shorter number more likely to be unique.\n        pid = os.getpid()\n        tid = cast(int, threading.current_thread().ident)\n        tslug = f\"{(pid * tid) % 9_999_991:07d}\"\n        if tid not in seen_threads:\n            seen_threads.add(tid)\n            log(f\"New thread {tid} {tslug}:\\n{short_stack()}\")\n        # log_seq = int(os.getenv(\"PANSEQ\", \"0\"))\n        # root = f\"/tmp/pan.{log_seq:03d}\"\n        for filename in [\n            \"/tmp/foo.out\",\n            # f\"{root}.out\",\n            # f\"{root}-{pid}.out\",\n            # f\"{root}-{pid}-{tslug}.out\",\n        ]:\n            with open(filename, \"a\") as f:\n                print(f\"{pid}:{tslug}: {msg}\", file=f, flush=True)\n\n    def arg_repr(arg: Any) -> str:\n        \"\"\"Make a customized repr for logged values.\"\"\"\n        if isinstance(arg, CodeType):\n            return (\n                f\"<code @{id(arg):#x}\"\n                + f\" name={arg.co_name},\"\n                + f\" file={short_filename(arg.co_filename)!r}#{arg.co_firstlineno}>\"\n            )\n        return repr(arg)\n\n    def panopticon(*names: str | None) -> AnyCallable:\n        \"\"\"Decorate a function to log its calls.\"\"\"\n\n        def _decorator(method: AnyCallable) -> AnyCallable:\n            @functools.wraps(method)\n            def _wrapped(self: Any, *args: Any) -> Any:\n                try:\n                    # log(f\"{method.__name__}() stack:\\n{short_stack()}\")\n                    args_reprs = []\n                    for name, arg in zip(names, args):\n                        if name is None:\n                            continue\n                        args_reprs.append(f\"{name}={arg_repr(arg)}\")\n                    log(f\"{id(self):#x}:{method.__name__}({', '.join(args_reprs)})\")\n                    ret = method(self, *args)\n                    # log(f\" end {id(self):#x}:{method.__name__}({', '.join(args_reprs)})\")\n                    return ret\n                except Exception as exc:\n                    log(f\"!!{exc.__class__.__name__}: {exc}\")\n                    log(\"\".join(traceback.format_exception(exc))) # pylint: disable=[no-value-for-parameter]\n                    try:\n                        assert sys_monitoring is not None\n                        sys_monitoring.set_events(sys.monitoring.COVERAGE_ID, 0)\n                    except ValueError:\n                        # We might have already shut off monitoring.\n                        log(\"oops, shutting off events with disabled tool id\")\n                    raise\n\n            return _wrapped\n\n        return _decorator\n\nelse:\n\n    def log(msg: str) -> None:\n        \"\"\"Write a message to our detailed debugging log(s), but not really.\"\"\"\n\n    def panopticon(*names: str | None) -> AnyCallable:\n        \"\"\"Decorate a function to log its calls, but not really.\"\"\"\n\n        def _decorator(meth: AnyCallable) -> AnyCallable:\n            return meth\n\n        return _decorator\n\n\n@dataclass\nclass CodeInfo:\n    \"\"\"The information we want about each code object.\"\"\"\n\n    tracing: bool\n    file_data: TTraceFileData | None\n    # TODO: what is byte_to_line for?\n    byte_to_line: dict[int, int] | None\n\n\ndef bytes_to_lines(code: CodeType) -> dict[int, int]:\n    \"\"\"Make a dict mapping byte code offsets to line numbers.\"\"\"\n    b2l = {}\n    for bstart, bend, lineno in code.co_lines():\n        if lineno is not None:\n            for boffset in range(bstart, bend, 2):\n                b2l[boffset] = lineno\n    return b2l\n\n\nclass SysMonitor(TracerCore):\n    \"\"\"Python implementation of the raw data tracer for PEP669 implementations.\"\"\"\n\n    # One of these will be used across threads. Be careful.\n\n    def __init__(self, tool_id: int) -> None:\n        # Attributes set from the collector:\n        self.data: TTraceData\n        self.trace_arcs = False\n        self.should_trace: Callable[[str, FrameType], TFileDisposition]\n        self.should_trace_cache: dict[str, TFileDisposition | None]\n        # TODO: should_start_context and switch_context are unused!\n        # Change tests/testenv.py:DYN_CONTEXTS when this is updated.\n        self.should_start_context: Callable[[FrameType], str | None] | None = None\n        self.switch_context: Callable[[str | None], None] | None = None\n        self.lock_data: Callable[[], None]\n        self.unlock_data: Callable[[], None]\n        # TODO: warn is unused.\n        self.warn: TWarnFn\n\n        self.myid = tool_id\n\n        # Map id(code_object) -> CodeInfo\n        self.code_infos: dict[int, CodeInfo] = {}\n        # A list of code_objects, just to keep them alive so that id's are\n        # useful as identity.\n        self.code_objects: list[CodeType] = []\n        self.last_lines: dict[FrameType, int] = {}\n        # Map id(code_object) -> code_object\n        self.local_event_codes: dict[int, CodeType] = {}\n        self.sysmon_on = False\n        self.lock = threading.Lock()\n\n        self.stats = {\n            \"starts\": 0,\n        }\n\n        self.stopped = False\n        self._activity = False\n\n    def __repr__(self) -> str:\n        points = sum(len(v) for v in self.data.values())\n        files = len(self.data)\n        return f\"<SysMonitor at {id(self):#x}: {points} data points in {files} files>\"\n\n    @panopticon()\n    def start(self) -> None:\n        \"\"\"Start this Tracer.\"\"\"\n        self.stopped = False\n\n        assert sys_monitoring is not None\n        sys_monitoring.use_tool_id(self.myid, \"coverage.py\")\n        register = functools.partial(sys_monitoring.register_callback, self.myid)\n        events = sys_monitoring.events\n        if self.trace_arcs:\n            sys_monitoring.set_events(\n                self.myid,\n                events.PY_START | events.PY_UNWIND,\n            )\n            register(events.PY_START, self.sysmon_py_start)\n            register(events.PY_RESUME, self.sysmon_py_resume_arcs)\n            register(events.PY_RETURN, self.sysmon_py_return_arcs)\n            register(events.PY_UNWIND, self.sysmon_py_unwind_arcs)\n            register(events.LINE, self.sysmon_line_arcs)\n        else:\n            sys_monitoring.set_events(self.myid, events.PY_START)\n            register(events.PY_START, self.sysmon_py_start)\n            register(events.LINE, self.sysmon_line_lines)\n        sys_monitoring.restart_events()\n        self.sysmon_on = True\n\n    @panopticon()\n    def stop(self) -> None:\n        \"\"\"Stop this Tracer.\"\"\"\n        if not self.sysmon_on:\n            # In forking situations, we might try to stop when we are not\n            # started.  Do nothing in that case.\n            return\n        assert sys_monitoring is not None\n        sys_monitoring.set_events(self.myid, 0)\n        with self.lock:\n            self.sysmon_on = False\n            for code in self.local_event_codes.values():\n                sys_monitoring.set_local_events(self.myid, code, 0)\n            self.local_event_codes = {}\n        sys_monitoring.free_tool_id(self.myid)\n\n    @panopticon()\n    def post_fork(self) -> None:\n        \"\"\"The process has forked, clean up as needed.\"\"\"\n        self.stop()\n\n    def activity(self) -> bool:\n        \"\"\"Has there been any activity?\"\"\"\n        return self._activity\n\n    def reset_activity(self) -> None:\n        \"\"\"Reset the activity() flag.\"\"\"\n        self._activity = False\n\n    def get_stats(self) -> dict[str, int] | None:\n        \"\"\"Return a dictionary of statistics, or None.\"\"\"\n        return None\n\n    # The number of frames in callers_frame takes @panopticon into account.\n    if LOG:\n\n        def callers_frame(self) -> FrameType:\n            \"\"\"Get the frame of the Python code we're monitoring.\"\"\"\n            return (\n                inspect.currentframe().f_back.f_back.f_back  # type: ignore[union-attr,return-value]\n            )\n\n    else:\n\n        def callers_frame(self) -> FrameType:\n            \"\"\"Get the frame of the Python code we're monitoring.\"\"\"\n            return inspect.currentframe().f_back.f_back  # type: ignore[union-attr,return-value]\n\n    @panopticon(\"code\", \"@\")\n    def sysmon_py_start(self, code: CodeType, instruction_offset: int) -> MonitorReturn:\n        \"\"\"Handle sys.monitoring.events.PY_START events.\"\"\"\n        # Entering a new frame.  Decide if we should trace in this file.\n        self._activity = True\n        self.stats[\"starts\"] += 1\n\n        code_info = self.code_infos.get(id(code))\n        tracing_code: bool | None = None\n        file_data: TTraceFileData | None = None\n        if code_info is not None:\n            tracing_code = code_info.tracing\n            file_data = code_info.file_data\n\n        if tracing_code is None:\n            filename = code.co_filename\n            disp = self.should_trace_cache.get(filename)\n            if disp is None:\n                frame = inspect.currentframe().f_back  # type: ignore[union-attr]\n                if LOG:\n                    # @panopticon adds a frame.\n                    frame = frame.f_back  # type: ignore[union-attr]\n                disp = self.should_trace(filename, frame)  # type: ignore[arg-type]\n                self.should_trace_cache[filename] = disp\n\n            tracing_code = disp.trace\n            if tracing_code:\n                tracename = disp.source_filename\n                assert tracename is not None\n                self.lock_data()\n                try:\n                    if tracename not in self.data:\n                        self.data[tracename] = set()\n                finally:\n                    self.unlock_data()\n                file_data = self.data[tracename]\n                b2l = bytes_to_lines(code)\n            else:\n                file_data = None\n                b2l = None\n\n            self.code_infos[id(code)] = CodeInfo(\n                tracing=tracing_code,\n                file_data=file_data,\n                byte_to_line=b2l,\n            )\n            self.code_objects.append(code)\n\n            if tracing_code:\n                events = sys.monitoring.events\n                with self.lock:\n                    if self.sysmon_on:\n                        assert sys_monitoring is not None\n                        sys_monitoring.set_local_events(\n                            self.myid,\n                            code,\n                            events.PY_RETURN\n                            #\n                            | events.PY_RESUME\n                            # | events.PY_YIELD\n                            | events.LINE,\n                            # | events.BRANCH\n                            # | events.JUMP\n                        )\n                        self.local_event_codes[id(code)] = code\n\n        if tracing_code and self.trace_arcs:\n            frame = self.callers_frame()\n            self.last_lines[frame] = -code.co_firstlineno\n            return None\n        else:\n            return sys.monitoring.DISABLE\n\n    @panopticon(\"code\", \"@\")\n    def sysmon_py_resume_arcs(\n        self, code: CodeType, instruction_offset: int,\n    ) -> MonitorReturn:\n        \"\"\"Handle sys.monitoring.events.PY_RESUME events for branch coverage.\"\"\"\n        frame = self.callers_frame()\n        self.last_lines[frame] = frame.f_lineno\n\n    @panopticon(\"code\", \"@\", None)\n    def sysmon_py_return_arcs(\n        self, code: CodeType, instruction_offset: int, retval: object,\n    ) -> MonitorReturn:\n        \"\"\"Handle sys.monitoring.events.PY_RETURN events for branch coverage.\"\"\"\n        frame = self.callers_frame()\n        code_info = self.code_infos.get(id(code))\n        if code_info is not None and code_info.file_data is not None:\n            last_line = self.last_lines.get(frame)\n            if last_line is not None:\n                arc = (last_line, -code.co_firstlineno)\n                # log(f\"adding {arc=}\")\n                cast(Set[TArc], code_info.file_data).add(arc)\n\n        # Leaving this function, no need for the frame any more.\n        self.last_lines.pop(frame, None)\n\n    @panopticon(\"code\", \"@\", \"exc\")\n    def sysmon_py_unwind_arcs(\n        self, code: CodeType, instruction_offset: int, exception: BaseException,\n    ) -> MonitorReturn:\n        \"\"\"Handle sys.monitoring.events.PY_UNWIND events for branch coverage.\"\"\"\n        frame = self.callers_frame()\n        # Leaving this function.\n        last_line = self.last_lines.pop(frame, None)\n        if isinstance(exception, GeneratorExit):\n            # We don't want to count generator exits as arcs.\n            return\n        code_info = self.code_infos.get(id(code))\n        if code_info is not None and code_info.file_data is not None:\n            if last_line is not None:\n                arc = (last_line, -code.co_firstlineno)\n                # log(f\"adding {arc=}\")\n                cast(Set[TArc], code_info.file_data).add(arc)\n\n\n    @panopticon(\"code\", \"line\")\n    def sysmon_line_lines(self, code: CodeType, line_number: int) -> MonitorReturn:\n        \"\"\"Handle sys.monitoring.events.LINE events for line coverage.\"\"\"\n        code_info = self.code_infos[id(code)]\n        if code_info.file_data is not None:\n            cast(Set[TLineNo], code_info.file_data).add(line_number)\n            # log(f\"adding {line_number=}\")\n        return sys.monitoring.DISABLE\n\n    @panopticon(\"code\", \"line\")\n    def sysmon_line_arcs(self, code: CodeType, line_number: int) -> MonitorReturn:\n        \"\"\"Handle sys.monitoring.events.LINE events for branch coverage.\"\"\"\n        code_info = self.code_infos[id(code)]\n        ret = None\n        if code_info.file_data is not None:\n            frame = self.callers_frame()\n            last_line = self.last_lines.get(frame)\n            if last_line is not None:\n                arc = (last_line, line_number)\n                cast(Set[TArc], code_info.file_data).add(arc)\n            # log(f\"adding {arc=}\")\n            self.last_lines[frame] = line_number\n        return ret\n", "coverage/control.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Central control stuff for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport atexit\nimport collections\nimport contextlib\nimport functools\nimport os\nimport os.path\nimport platform\nimport signal\nimport sys\nimport threading\nimport time\nimport warnings\n\nfrom types import FrameType\nfrom typing import (\n    cast,\n    Any, Callable, IO, Iterable, Iterator, List,\n)\n\nfrom coverage import env\nfrom coverage.annotate import AnnotateReporter\nfrom coverage.collector import Collector, HAS_CTRACER\nfrom coverage.config import CoverageConfig, read_coverage_config\nfrom coverage.context import should_start_context_test_function, combine_context_switchers\nfrom coverage.data import CoverageData, combine_parallel_data\nfrom coverage.debug import (\n    DebugControl, NoDebugging, short_stack, write_formatted_info, relevant_environment_display,\n)\nfrom coverage.disposition import disposition_debug_msg\nfrom coverage.exceptions import ConfigError, CoverageException, CoverageWarning, PluginError\nfrom coverage.files import PathAliases, abs_file, relative_filename, set_relative_directory\nfrom coverage.html import HtmlReporter\nfrom coverage.inorout import InOrOut\nfrom coverage.jsonreport import JsonReporter\nfrom coverage.lcovreport import LcovReporter\nfrom coverage.misc import bool_or_none, join_regex\nfrom coverage.misc import DefaultValue, ensure_dir_for_file, isolate_module\nfrom coverage.multiproc import patch_multiprocessing\nfrom coverage.plugin import FileReporter\nfrom coverage.plugin_support import Plugins\nfrom coverage.python import PythonFileReporter\nfrom coverage.report import SummaryReporter\nfrom coverage.report_core import render_report\nfrom coverage.results import Analysis, analysis_from_file_reporter\nfrom coverage.types import (\n    FilePath, TConfigurable, TConfigSectionIn, TConfigValueIn, TConfigValueOut,\n    TFileDisposition, TLineNo, TMorf,\n)\nfrom coverage.xmlreport import XmlReporter\n\nos = isolate_module(os)\n\n@contextlib.contextmanager\ndef override_config(cov: Coverage, **kwargs: TConfigValueIn) -> Iterator[None]:\n    \"\"\"Temporarily tweak the configuration of `cov`.\n\n    The arguments are applied to `cov.config` with the `from_args` method.\n    At the end of the with-statement, the old configuration is restored.\n    \"\"\"\n    original_config = cov.config\n    cov.config = cov.config.copy()\n    try:\n        cov.config.from_args(**kwargs)\n        yield\n    finally:\n        cov.config = original_config\n\n\nDEFAULT_DATAFILE = DefaultValue(\"MISSING\")\n_DEFAULT_DATAFILE = DEFAULT_DATAFILE  # Just in case, for backwards compatibility\n\nclass Coverage(TConfigurable):\n    \"\"\"Programmatic access to coverage.py.\n\n    To use::\n\n        from coverage import Coverage\n\n        cov = Coverage()\n        cov.start()\n        #.. call your code ..\n        cov.stop()\n        cov.html_report(directory=\"covhtml\")\n\n    A context manager is available to do the same thing::\n\n        cov = Coverage()\n        with cov.collect():\n            #.. call your code ..\n        cov.html_report(directory=\"covhtml\")\n\n    Note: in keeping with Python custom, names starting with underscore are\n    not part of the public API. They might stop working at any point.  Please\n    limit yourself to documented methods to avoid problems.\n\n    Methods can raise any of the exceptions described in :ref:`api_exceptions`.\n\n    \"\"\"\n\n    # The stack of started Coverage instances.\n    _instances: list[Coverage] = []\n\n    @classmethod\n    def current(cls) -> Coverage | None:\n        \"\"\"Get the latest started `Coverage` instance, if any.\n\n        Returns: a `Coverage` instance, or None.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        if cls._instances:\n            return cls._instances[-1]\n        else:\n            return None\n\n    def __init__(                       # pylint: disable=too-many-arguments\n        self,\n        data_file: FilePath | DefaultValue | None = DEFAULT_DATAFILE,\n        data_suffix: str | bool | None = None,\n        cover_pylib: bool | None = None,\n        auto_data: bool = False,\n        timid: bool | None = None,\n        branch: bool | None = None,\n        config_file: FilePath | bool = True,\n        source: Iterable[str] | None = None,\n        source_pkgs: Iterable[str] | None = None,\n        omit: str | Iterable[str] | None = None,\n        include: str | Iterable[str] | None = None,\n        debug: Iterable[str] | None = None,\n        concurrency: str | Iterable[str] | None = None,\n        check_preimported: bool = False,\n        context: str | None = None,\n        messages: bool = False,\n    ) -> None:\n        \"\"\"\n        Many of these arguments duplicate and override values that can be\n        provided in a configuration file.  Parameters that are missing here\n        will use values from the config file.\n\n        `data_file` is the base name of the data file to use. The config value\n        defaults to \".coverage\".  None can be provided to prevent writing a data\n        file.  `data_suffix` is appended (with a dot) to `data_file` to create\n        the final file name.  If `data_suffix` is simply True, then a suffix is\n        created with the machine and process identity included.\n\n        `cover_pylib` is a boolean determining whether Python code installed\n        with the Python interpreter is measured.  This includes the Python\n        standard library and any packages installed with the interpreter.\n\n        If `auto_data` is true, then any existing data file will be read when\n        coverage measurement starts, and data will be saved automatically when\n        measurement stops.\n\n        If `timid` is true, then a slower and simpler trace function will be\n        used.  This is important for some environments where manipulation of\n        tracing functions breaks the faster trace function.\n\n        If `branch` is true, then branch coverage will be measured in addition\n        to the usual statement coverage.\n\n        `config_file` determines what configuration file to read:\n\n            * If it is \".coveragerc\", it is interpreted as if it were True,\n              for backward compatibility.\n\n            * If it is a string, it is the name of the file to read.  If the\n              file can't be read, it is an error.\n\n            * If it is True, then a few standard files names are tried\n              (\".coveragerc\", \"setup.cfg\", \"tox.ini\").  It is not an error for\n              these files to not be found.\n\n            * If it is False, then no configuration file is read.\n\n        `source` is a list of file paths or package names.  Only code located\n        in the trees indicated by the file paths or package names will be\n        measured.\n\n        `source_pkgs` is a list of package names. It works the same as\n        `source`, but can be used to name packages where the name can also be\n        interpreted as a file path.\n\n        `include` and `omit` are lists of file name patterns. Files that match\n        `include` will be measured, files that match `omit` will not.  Each\n        will also accept a single string argument.\n\n        `debug` is a list of strings indicating what debugging information is\n        desired.\n\n        `concurrency` is a string indicating the concurrency library being used\n        in the measured code.  Without this, coverage.py will get incorrect\n        results if these libraries are in use.  Valid strings are \"greenlet\",\n        \"eventlet\", \"gevent\", \"multiprocessing\", or \"thread\" (the default).\n        This can also be a list of these strings.\n\n        If `check_preimported` is true, then when coverage is started, the\n        already-imported files will be checked to see if they should be\n        measured by coverage.  Importing measured files before coverage is\n        started can mean that code is missed.\n\n        `context` is a string to use as the :ref:`static context\n        <static_contexts>` label for collected data.\n\n        If `messages` is true, some messages will be printed to stdout\n        indicating what is happening.\n\n        .. versionadded:: 4.0\n            The `concurrency` parameter.\n\n        .. versionadded:: 4.2\n            The `concurrency` parameter can now be a list of strings.\n\n        .. versionadded:: 5.0\n            The `check_preimported` and `context` parameters.\n\n        .. versionadded:: 5.3\n            The `source_pkgs` parameter.\n\n        .. versionadded:: 6.0\n            The `messages` parameter.\n\n        \"\"\"\n        # Start self.config as a usable default configuration. It will soon be\n        # replaced with the real configuration.\n        self.config = CoverageConfig()\n\n        # data_file=None means no disk file at all. data_file missing means\n        # use the value from the config file.\n        self._no_disk = data_file is None\n        if isinstance(data_file, DefaultValue):\n            data_file = None\n        if data_file is not None:\n            data_file = os.fspath(data_file)\n\n        # This is injectable by tests.\n        self._debug_file: IO[str] | None = None\n\n        self._auto_load = self._auto_save = auto_data\n        self._data_suffix_specified = data_suffix\n\n        # Is it ok for no data to be collected?\n        self._warn_no_data = True\n        self._warn_unimported_source = True\n        self._warn_preimported_source = check_preimported\n        self._no_warn_slugs: list[str] = []\n        self._messages = messages\n\n        # A record of all the warnings that have been issued.\n        self._warnings: list[str] = []\n\n        # Other instance attributes, set with placebos or placeholders.\n        # More useful objects will be created later.\n        self._debug: DebugControl = NoDebugging()\n        self._inorout: InOrOut | None = None\n        self._plugins: Plugins = Plugins()\n        self._data: CoverageData | None = None\n        self._collector: Collector | None = None\n        self._metacov = False\n\n        self._file_mapper: Callable[[str], str] = abs_file\n        self._data_suffix = self._run_suffix = None\n        self._exclude_re: dict[str, str] = {}\n        self._old_sigterm: Callable[[int, FrameType | None], Any] | None = None\n\n        # State machine variables:\n        # Have we initialized everything?\n        self._inited = False\n        self._inited_for_start = False\n        # Have we started collecting and not stopped it?\n        self._started = False\n        # Should we write the debug output?\n        self._should_write_debug = True\n\n        # Build our configuration from a number of sources.\n        if not isinstance(config_file, bool):\n            config_file = os.fspath(config_file)\n        self.config = read_coverage_config(\n            config_file=config_file,\n            warn=self._warn,\n            data_file=data_file,\n            cover_pylib=cover_pylib,\n            timid=timid,\n            branch=branch,\n            parallel=bool_or_none(data_suffix),\n            source=source,\n            source_pkgs=source_pkgs,\n            run_omit=omit,\n            run_include=include,\n            debug=debug,\n            report_omit=omit,\n            report_include=include,\n            concurrency=concurrency,\n            context=context,\n        )\n\n        # If we have sub-process measurement happening automatically, then we\n        # want any explicit creation of a Coverage object to mean, this process\n        # is already coverage-aware, so don't auto-measure it.  By now, the\n        # auto-creation of a Coverage object has already happened.  But we can\n        # find it and tell it not to save its data.\n        if not env.METACOV:\n            _prevent_sub_process_measurement()\n\n    def _init(self) -> None:\n        \"\"\"Set all the initial state.\n\n        This is called by the public methods to initialize state. This lets us\n        construct a :class:`Coverage` object, then tweak its state before this\n        function is called.\n\n        \"\"\"\n        if self._inited:\n            return\n\n        self._inited = True\n\n        # Create and configure the debugging controller.\n        self._debug = DebugControl(self.config.debug, self._debug_file, self.config.debug_file)\n        if self._debug.should(\"process\"):\n            self._debug.write(\"Coverage._init\")\n\n        if \"multiprocessing\" in (self.config.concurrency or ()):\n            # Multi-processing uses parallel for the subprocesses, so also use\n            # it for the main process.\n            self.config.parallel = True\n\n        # _exclude_re is a dict that maps exclusion list names to compiled regexes.\n        self._exclude_re = {}\n\n        set_relative_directory()\n        if self.config.relative_files:\n            self._file_mapper = relative_filename\n\n        # Load plugins\n        self._plugins = Plugins.load_plugins(self.config.plugins, self.config, self._debug)\n\n        # Run configuring plugins.\n        for plugin in self._plugins.configurers:\n            # We need an object with set_option and get_option. Either self or\n            # self.config will do. Choosing randomly stops people from doing\n            # other things with those objects, against the public API.  Yes,\n            # this is a bit childish. :)\n            plugin.configure([self, self.config][int(time.time()) % 2])\n\n    def _post_init(self) -> None:\n        \"\"\"Stuff to do after everything is initialized.\"\"\"\n        if self._should_write_debug:\n            self._should_write_debug = False\n            self._write_startup_debug()\n\n        # \"[run] _crash\" will raise an exception if the value is close by in\n        # the call stack, for testing error handling.\n        if self.config._crash and self.config._crash in short_stack():\n            raise RuntimeError(f\"Crashing because called by {self.config._crash}\")\n\n    def _write_startup_debug(self) -> None:\n        \"\"\"Write out debug info at startup if needed.\"\"\"\n        wrote_any = False\n        with self._debug.without_callers():\n            if self._debug.should(\"config\"):\n                config_info = self.config.debug_info()\n                write_formatted_info(self._debug.write, \"config\", config_info)\n                wrote_any = True\n\n            if self._debug.should(\"sys\"):\n                write_formatted_info(self._debug.write, \"sys\", self.sys_info())\n                for plugin in self._plugins:\n                    header = \"sys: \" + plugin._coverage_plugin_name\n                    info = plugin.sys_info()\n                    write_formatted_info(self._debug.write, header, info)\n                wrote_any = True\n\n            if self._debug.should(\"pybehave\"):\n                write_formatted_info(self._debug.write, \"pybehave\", env.debug_info())\n                wrote_any = True\n\n        if wrote_any:\n            write_formatted_info(self._debug.write, \"end\", ())\n\n    def _should_trace(self, filename: str, frame: FrameType) -> TFileDisposition:\n        \"\"\"Decide whether to trace execution in `filename`.\n\n        Calls `_should_trace_internal`, and returns the FileDisposition.\n\n        \"\"\"\n        assert self._inorout is not None\n        disp = self._inorout.should_trace(filename, frame)\n        if self._debug.should(\"trace\"):\n            self._debug.write(disposition_debug_msg(disp))\n        return disp\n\n    def _check_include_omit_etc(self, filename: str, frame: FrameType) -> bool:\n        \"\"\"Check a file name against the include/omit/etc, rules, verbosely.\n\n        Returns a boolean: True if the file should be traced, False if not.\n\n        \"\"\"\n        assert self._inorout is not None\n        reason = self._inorout.check_include_omit_etc(filename, frame)\n        if self._debug.should(\"trace\"):\n            if not reason:\n                msg = f\"Including {filename!r}\"\n            else:\n                msg = f\"Not including {filename!r}: {reason}\"\n            self._debug.write(msg)\n\n        return not reason\n\n    def _warn(self, msg: str, slug: str | None = None, once: bool = False) -> None:\n        \"\"\"Use `msg` as a warning.\n\n        For warning suppression, use `slug` as the shorthand.\n\n        If `once` is true, only show this warning once (determined by the\n        slug.)\n\n        \"\"\"\n        if not self._no_warn_slugs:\n            self._no_warn_slugs = list(self.config.disable_warnings)\n\n        if slug in self._no_warn_slugs:\n            # Don't issue the warning\n            return\n\n        self._warnings.append(msg)\n        if slug:\n            msg = f\"{msg} ({slug})\"\n        if self._debug.should(\"pid\"):\n            msg = f\"[{os.getpid()}] {msg}\"\n        warnings.warn(msg, category=CoverageWarning, stacklevel=2)\n\n        if once:\n            assert slug is not None\n            self._no_warn_slugs.append(slug)\n\n    def _message(self, msg: str) -> None:\n        \"\"\"Write a message to the user, if configured to do so.\"\"\"\n        if self._messages:\n            print(msg)\n\n    def get_option(self, option_name: str) -> TConfigValueOut | None:\n        \"\"\"Get an option from the configuration.\n\n        `option_name` is a colon-separated string indicating the section and\n        option name.  For example, the ``branch`` option in the ``[run]``\n        section of the config file would be indicated with `\"run:branch\"`.\n\n        Returns the value of the option.  The type depends on the option\n        selected.\n\n        As a special case, an `option_name` of ``\"paths\"`` will return an\n        dictionary with the entire ``[paths]`` section value.\n\n        .. versionadded:: 4.0\n\n        \"\"\"\n        return self.config.get_option(option_name)\n\n    def set_option(self, option_name: str, value: TConfigValueIn | TConfigSectionIn) -> None:\n        \"\"\"Set an option in the configuration.\n\n        `option_name` is a colon-separated string indicating the section and\n        option name.  For example, the ``branch`` option in the ``[run]``\n        section of the config file would be indicated with ``\"run:branch\"``.\n\n        `value` is the new value for the option.  This should be an\n        appropriate Python value.  For example, use True for booleans, not the\n        string ``\"True\"``.\n\n        As an example, calling:\n\n        .. code-block:: python\n\n            cov.set_option(\"run:branch\", True)\n\n        has the same effect as this configuration file:\n\n        .. code-block:: ini\n\n            [run]\n            branch = True\n\n        As a special case, an `option_name` of ``\"paths\"`` will replace the\n        entire ``[paths]`` section.  The value should be a dictionary.\n\n        .. versionadded:: 4.0\n\n        \"\"\"\n        self.config.set_option(option_name, value)\n\n    def load(self) -> None:\n        \"\"\"Load previously-collected coverage data from the data file.\"\"\"\n        self._init()\n        if self._collector is not None:\n            self._collector.reset()\n        should_skip = self.config.parallel and not os.path.exists(self.config.data_file)\n        if not should_skip:\n            self._init_data(suffix=None)\n        self._post_init()\n        if not should_skip:\n            assert self._data is not None\n            self._data.read()\n\n    def _init_for_start(self) -> None:\n        \"\"\"Initialization for start()\"\"\"\n        # Construct the collector.\n        concurrency: list[str] = self.config.concurrency or []\n        if \"multiprocessing\" in concurrency:\n            if self.config.config_file is None:\n                raise ConfigError(\"multiprocessing requires a configuration file\")\n            patch_multiprocessing(rcfile=self.config.config_file)\n\n        dycon = self.config.dynamic_context\n        if not dycon or dycon == \"none\":\n            context_switchers = []\n        elif dycon == \"test_function\":\n            context_switchers = [should_start_context_test_function]\n        else:\n            raise ConfigError(f\"Don't understand dynamic_context setting: {dycon!r}\")\n\n        context_switchers.extend(\n            plugin.dynamic_context for plugin in self._plugins.context_switchers\n        )\n\n        should_start_context = combine_context_switchers(context_switchers)\n\n        self._collector = Collector(\n            should_trace=self._should_trace,\n            check_include=self._check_include_omit_etc,\n            should_start_context=should_start_context,\n            file_mapper=self._file_mapper,\n            timid=self.config.timid,\n            branch=self.config.branch,\n            warn=self._warn,\n            concurrency=concurrency,\n            metacov=self._metacov,\n        )\n\n        suffix = self._data_suffix_specified\n        if suffix:\n            if not isinstance(suffix, str):\n                # if data_suffix=True, use .machinename.pid.random\n                suffix = True\n        elif self.config.parallel:\n            if suffix is None:\n                suffix = True\n            elif not isinstance(suffix, str):\n                suffix = bool(suffix)\n        else:\n            suffix = None\n\n        self._init_data(suffix)\n\n        assert self._data is not None\n        self._collector.use_data(self._data, self.config.context)\n\n        # Early warning if we aren't going to be able to support plugins.\n        if self._plugins.file_tracers and not self._collector.supports_plugins:\n            self._warn(\n                \"Plugin file tracers ({}) aren't supported with {}\".format(\n                    \", \".join(\n                        plugin._coverage_plugin_name\n                            for plugin in self._plugins.file_tracers\n                    ),\n                    self._collector.tracer_name(),\n                ),\n            )\n            for plugin in self._plugins.file_tracers:\n                plugin._coverage_enabled = False\n\n        # Create the file classifying substructure.\n        self._inorout = InOrOut(\n            config=self.config,\n            warn=self._warn,\n            debug=(self._debug if self._debug.should(\"trace\") else None),\n            include_namespace_packages=self.config.include_namespace_packages,\n        )\n        self._inorout.plugins = self._plugins\n        self._inorout.disp_class = self._collector.file_disposition_class\n\n        # It's useful to write debug info after initing for start.\n        self._should_write_debug = True\n\n        # Register our clean-up handlers.\n        atexit.register(self._atexit)\n        if self.config.sigterm:\n            is_main = (threading.current_thread() == threading.main_thread())\n            if is_main and not env.WINDOWS:\n                # The Python docs seem to imply that SIGTERM works uniformly even\n                # on Windows, but that's not my experience, and this agrees:\n                # https://stackoverflow.com/questions/35772001/x/35792192#35792192\n                self._old_sigterm = signal.signal(      # type: ignore[assignment]\n                    signal.SIGTERM, self._on_sigterm,\n                )\n\n    def _init_data(self, suffix: str | bool | None) -> None:\n        \"\"\"Create a data file if we don't have one yet.\"\"\"\n        if self._data is None:\n            # Create the data file.  We do this at construction time so that the\n            # data file will be written into the directory where the process\n            # started rather than wherever the process eventually chdir'd to.\n            ensure_dir_for_file(self.config.data_file)\n            self._data = CoverageData(\n                basename=self.config.data_file,\n                suffix=suffix,\n                warn=self._warn,\n                debug=self._debug,\n                no_disk=self._no_disk,\n            )\n\n    def start(self) -> None:\n        \"\"\"Start measuring code coverage.\n\n        Coverage measurement is only collected in functions called after\n        :meth:`start` is invoked.  Statements in the same scope as\n        :meth:`start` won't be measured.\n\n        Once you invoke :meth:`start`, you must also call :meth:`stop`\n        eventually, or your process might not shut down cleanly.\n\n        The :meth:`collect` method is a context manager to handle both\n        starting and stopping collection.\n\n        \"\"\"\n        self._init()\n        if not self._inited_for_start:\n            self._inited_for_start = True\n            self._init_for_start()\n        self._post_init()\n\n        assert self._collector is not None\n        assert self._inorout is not None\n\n        # Issue warnings for possible problems.\n        self._inorout.warn_conflicting_settings()\n\n        # See if we think some code that would eventually be measured has\n        # already been imported.\n        if self._warn_preimported_source:\n            self._inorout.warn_already_imported_files()\n\n        if self._auto_load:\n            self.load()\n\n        self._collector.start()\n        self._started = True\n        self._instances.append(self)\n\n    def stop(self) -> None:\n        \"\"\"Stop measuring code coverage.\"\"\"\n        if self._instances:\n            if self._instances[-1] is self:\n                self._instances.pop()\n        if self._started:\n            assert self._collector is not None\n            self._collector.stop()\n        self._started = False\n\n    @contextlib.contextmanager\n    def collect(self) -> Iterator[None]:\n        \"\"\"A context manager to start/stop coverage measurement collection.\n\n        .. versionadded:: 7.3\n\n        \"\"\"\n        self.start()\n        try:\n            yield\n        finally:\n            self.stop()\n\n    def _atexit(self, event: str = \"atexit\") -> None:\n        \"\"\"Clean up on process shutdown.\"\"\"\n        if self._debug.should(\"process\"):\n            self._debug.write(f\"{event}: pid: {os.getpid()}, instance: {self!r}\")\n        if self._started:\n            self.stop()\n        if self._auto_save or event == \"sigterm\":\n            self.save()\n\n    def _on_sigterm(self, signum_unused: int, frame_unused: FrameType | None) -> None:\n        \"\"\"A handler for signal.SIGTERM.\"\"\"\n        self._atexit(\"sigterm\")\n        # Statements after here won't be seen by metacov because we just wrote\n        # the data, and are about to kill the process.\n        signal.signal(signal.SIGTERM, self._old_sigterm)    # pragma: not covered\n        os.kill(os.getpid(), signal.SIGTERM)                # pragma: not covered\n\n    def erase(self) -> None:\n        \"\"\"Erase previously collected coverage data.\n\n        This removes the in-memory data collected in this session as well as\n        discarding the data file.\n\n        \"\"\"\n        self._init()\n        self._post_init()\n        if self._collector is not None:\n            self._collector.reset()\n        self._init_data(suffix=None)\n        assert self._data is not None\n        self._data.erase(parallel=self.config.parallel)\n        self._data = None\n        self._inited_for_start = False\n\n    def switch_context(self, new_context: str) -> None:\n        \"\"\"Switch to a new dynamic context.\n\n        `new_context` is a string to use as the :ref:`dynamic context\n        <dynamic_contexts>` label for collected data.  If a :ref:`static\n        context <static_contexts>` is in use, the static and dynamic context\n        labels will be joined together with a pipe character.\n\n        Coverage collection must be started already.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        if not self._started:                           # pragma: part started\n            raise CoverageException(\"Cannot switch context, coverage is not started\")\n\n        assert self._collector is not None\n        if self._collector.should_start_context:\n            self._warn(\"Conflicting dynamic contexts\", slug=\"dynamic-conflict\", once=True)\n\n        self._collector.switch_context(new_context)\n\n    def clear_exclude(self, which: str = \"exclude\") -> None:\n        \"\"\"Clear the exclude list.\"\"\"\n        self._init()\n        setattr(self.config, which + \"_list\", [])\n        self._exclude_regex_stale()\n\n    def exclude(self, regex: str, which: str = \"exclude\") -> None:\n        \"\"\"Exclude source lines from execution consideration.\n\n        A number of lists of regular expressions are maintained.  Each list\n        selects lines that are treated differently during reporting.\n\n        `which` determines which list is modified.  The \"exclude\" list selects\n        lines that are not considered executable at all.  The \"partial\" list\n        indicates lines with branches that are not taken.\n\n        `regex` is a regular expression.  The regex is added to the specified\n        list.  If any of the regexes in the list is found in a line, the line\n        is marked for special treatment during reporting.\n\n        \"\"\"\n        self._init()\n        excl_list = getattr(self.config, which + \"_list\")\n        excl_list.append(regex)\n        self._exclude_regex_stale()\n\n    def _exclude_regex_stale(self) -> None:\n        \"\"\"Drop all the compiled exclusion regexes, a list was modified.\"\"\"\n        self._exclude_re.clear()\n\n    def _exclude_regex(self, which: str) -> str:\n        \"\"\"Return a regex string for the given exclusion list.\"\"\"\n        if which not in self._exclude_re:\n            excl_list = getattr(self.config, which + \"_list\")\n            self._exclude_re[which] = join_regex(excl_list)\n        return self._exclude_re[which]\n\n    def get_exclude_list(self, which: str = \"exclude\") -> list[str]:\n        \"\"\"Return a list of excluded regex strings.\n\n        `which` indicates which list is desired.  See :meth:`exclude` for the\n        lists that are available, and their meaning.\n\n        \"\"\"\n        self._init()\n        return cast(List[str], getattr(self.config, which + \"_list\"))\n\n    def save(self) -> None:\n        \"\"\"Save the collected coverage data to the data file.\"\"\"\n        data = self.get_data()\n        data.write()\n\n    def _make_aliases(self) -> PathAliases:\n        \"\"\"Create a PathAliases from our configuration.\"\"\"\n        aliases = PathAliases(\n            debugfn=(self._debug.write if self._debug.should(\"pathmap\") else None),\n            relative=self.config.relative_files,\n        )\n        for paths in self.config.paths.values():\n            result = paths[0]\n            for pattern in paths[1:]:\n                aliases.add(pattern, result)\n        return aliases\n\n    def combine(\n        self,\n        data_paths: Iterable[str] | None = None,\n        strict: bool = False,\n        keep: bool = False,\n    ) -> None:\n        \"\"\"Combine together a number of similarly-named coverage data files.\n\n        All coverage data files whose name starts with `data_file` (from the\n        coverage() constructor) will be read, and combined together into the\n        current measurements.\n\n        `data_paths` is a list of files or directories from which data should\n        be combined. If no list is passed, then the data files from the\n        directory indicated by the current data file (probably the current\n        directory) will be combined.\n\n        If `strict` is true, then it is an error to attempt to combine when\n        there are no data files to combine.\n\n        If `keep` is true, then original input data files won't be deleted.\n\n        .. versionadded:: 4.0\n            The `data_paths` parameter.\n\n        .. versionadded:: 4.3\n            The `strict` parameter.\n\n        .. versionadded: 5.5\n            The `keep` parameter.\n        \"\"\"\n        self._init()\n        self._init_data(suffix=None)\n        self._post_init()\n        self.get_data()\n\n        assert self._data is not None\n        combine_parallel_data(\n            self._data,\n            aliases=self._make_aliases(),\n            data_paths=data_paths,\n            strict=strict,\n            keep=keep,\n            message=self._message,\n        )\n\n    def get_data(self) -> CoverageData:\n        \"\"\"Get the collected data.\n\n        Also warn about various problems collecting data.\n\n        Returns a :class:`coverage.CoverageData`, the collected coverage data.\n\n        .. versionadded:: 4.0\n\n        \"\"\"\n        self._init()\n        self._init_data(suffix=None)\n        self._post_init()\n\n        if self._collector is not None:\n            for plugin in self._plugins:\n                if not plugin._coverage_enabled:\n                    self._collector.plugin_was_disabled(plugin)\n\n            if self._collector.flush_data():\n                self._post_save_work()\n\n        assert self._data is not None\n        return self._data\n\n    def _post_save_work(self) -> None:\n        \"\"\"After saving data, look for warnings, post-work, etc.\n\n        Warn about things that should have happened but didn't.\n        Look for un-executed files.\n\n        \"\"\"\n        assert self._data is not None\n        assert self._inorout is not None\n\n        # If there are still entries in the source_pkgs_unmatched list,\n        # then we never encountered those packages.\n        if self._warn_unimported_source:\n            self._inorout.warn_unimported_source()\n\n        # Find out if we got any data.\n        if not self._data and self._warn_no_data:\n            self._warn(\"No data was collected.\", slug=\"no-data-collected\")\n\n        # Touch all the files that could have executed, so that we can\n        # mark completely un-executed files as 0% covered.\n        file_paths = collections.defaultdict(list)\n        for file_path, plugin_name in self._inorout.find_possibly_unexecuted_files():\n            file_path = self._file_mapper(file_path)\n            file_paths[plugin_name].append(file_path)\n        for plugin_name, paths in file_paths.items():\n            self._data.touch_files(paths, plugin_name)\n\n    # Backward compatibility with version 1.\n    def analysis(self, morf: TMorf) -> tuple[str, list[TLineNo], list[TLineNo], str]:\n        \"\"\"Like `analysis2` but doesn't return excluded line numbers.\"\"\"\n        f, s, _, m, mf = self.analysis2(morf)\n        return f, s, m, mf\n\n    def analysis2(\n        self,\n        morf: TMorf,\n    ) -> tuple[str, list[TLineNo], list[TLineNo], list[TLineNo], str]:\n        \"\"\"Analyze a module.\n\n        `morf` is a module or a file name.  It will be analyzed to determine\n        its coverage statistics.  The return value is a 5-tuple:\n\n        * The file name for the module.\n        * A list of line numbers of executable statements.\n        * A list of line numbers of excluded statements.\n        * A list of line numbers of statements not run (missing from\n          execution).\n        * A readable formatted string of the missing line numbers.\n\n        The analysis uses the source file itself and the current measured\n        coverage data.\n\n        \"\"\"\n        analysis = self._analyze(morf)\n        return (\n            analysis.filename,\n            sorted(analysis.statements),\n            sorted(analysis.excluded),\n            sorted(analysis.missing),\n            analysis.missing_formatted(),\n        )\n\n    def _analyze(self, morf: TMorf) -> Analysis:\n        \"\"\"Analyze a module or file.  Private for now.\"\"\"\n        self._init()\n        self._post_init()\n\n        data = self.get_data()\n        file_reporter = self._get_file_reporter(morf)\n        filename = self._file_mapper(file_reporter.filename)\n        return analysis_from_file_reporter(data, self.config.precision, file_reporter, filename)\n\n    @functools.lru_cache(maxsize=1)\n    def _get_file_reporter(self, morf: TMorf) -> FileReporter:\n        \"\"\"Get a FileReporter for a module or file name.\"\"\"\n        assert self._data is not None\n        plugin = None\n        file_reporter: str | FileReporter = \"python\"\n\n        if isinstance(morf, str):\n            mapped_morf = self._file_mapper(morf)\n            plugin_name = self._data.file_tracer(mapped_morf)\n            if plugin_name:\n                plugin = self._plugins.get(plugin_name)\n\n                if plugin:\n                    file_reporter = plugin.file_reporter(mapped_morf)\n                    if file_reporter is None:\n                        raise PluginError(\n                            \"Plugin {!r} did not provide a file reporter for {!r}.\".format(\n                                plugin._coverage_plugin_name, morf,\n                            ),\n                        )\n\n        if file_reporter == \"python\":\n            file_reporter = PythonFileReporter(morf, self)\n\n        assert isinstance(file_reporter, FileReporter)\n        return file_reporter\n\n    def _get_file_reporters(\n        self,\n        morfs: Iterable[TMorf] | None = None,\n    ) -> list[tuple[FileReporter, TMorf]]:\n        \"\"\"Get FileReporters for a list of modules or file names.\n\n        For each module or file name in `morfs`, find a FileReporter.  Return\n        a list pairing FileReporters with the morfs.\n\n        If `morfs` is a single module or file name, this returns a list of one\n        FileReporter.  If `morfs` is empty or None, then the list of all files\n        measured is used to find the FileReporters.\n\n        \"\"\"\n        assert self._data is not None\n        if not morfs:\n            morfs = self._data.measured_files()\n\n        # Be sure we have a collection.\n        if not isinstance(morfs, (list, tuple, set)):\n            morfs = [morfs]     # type: ignore[list-item]\n\n        return [(self._get_file_reporter(morf), morf) for morf in morfs]\n\n    def _prepare_data_for_reporting(self) -> None:\n        \"\"\"Re-map data before reporting, to get implicit \"combine\" behavior.\"\"\"\n        if self.config.paths:\n            mapped_data = CoverageData(warn=self._warn, debug=self._debug, no_disk=True)\n            if self._data is not None:\n                mapped_data.update(self._data, map_path=self._make_aliases().map)\n            self._data = mapped_data\n\n    def report(\n        self,\n        morfs: Iterable[TMorf] | None = None,\n        show_missing: bool | None = None,\n        ignore_errors: bool | None = None,\n        file: IO[str] | None = None,\n        omit: str | list[str] | None = None,\n        include: str | list[str] | None = None,\n        skip_covered: bool | None = None,\n        contexts: list[str] | None = None,\n        skip_empty: bool | None = None,\n        precision: int | None = None,\n        sort: str | None = None,\n        output_format: str | None = None,\n    ) -> float:\n        \"\"\"Write a textual summary report to `file`.\n\n        Each module in `morfs` is listed, with counts of statements, executed\n        statements, missing statements, and a list of lines missed.\n\n        If `show_missing` is true, then details of which lines or branches are\n        missing will be included in the report.  If `ignore_errors` is true,\n        then a failure while reporting a single file will not stop the entire\n        report.\n\n        `file` is a file-like object, suitable for writing.\n\n        `output_format` determines the format, either \"text\" (the default),\n        \"markdown\", or \"total\".\n\n        `include` is a list of file name patterns.  Files that match will be\n        included in the report. Files matching `omit` will not be included in\n        the report.\n\n        If `skip_covered` is true, don't report on files with 100% coverage.\n\n        If `skip_empty` is true, don't report on empty files (those that have\n        no statements).\n\n        `contexts` is a list of regular expression strings.  Only data from\n        :ref:`dynamic contexts <dynamic_contexts>` that match one of those\n        expressions (using :func:`re.search <python:re.search>`) will be\n        included in the report.\n\n        `precision` is the number of digits to display after the decimal\n        point for percentages.\n\n        All of the arguments default to the settings read from the\n        :ref:`configuration file <config>`.\n\n        Returns a float, the total percentage covered.\n\n        .. versionadded:: 4.0\n            The `skip_covered` parameter.\n\n        .. versionadded:: 5.0\n            The `contexts` and `skip_empty` parameters.\n\n        .. versionadded:: 5.2\n            The `precision` parameter.\n\n        .. versionadded:: 7.0\n            The `format` parameter.\n\n        \"\"\"\n        self._prepare_data_for_reporting()\n        with override_config(\n            self,\n            ignore_errors=ignore_errors,\n            report_omit=omit,\n            report_include=include,\n            show_missing=show_missing,\n            skip_covered=skip_covered,\n            report_contexts=contexts,\n            skip_empty=skip_empty,\n            precision=precision,\n            sort=sort,\n            format=output_format,\n        ):\n            reporter = SummaryReporter(self)\n            return reporter.report(morfs, outfile=file)\n\n    def annotate(\n        self,\n        morfs: Iterable[TMorf] | None = None,\n        directory: str | None = None,\n        ignore_errors: bool | None = None,\n        omit: str | list[str] | None = None,\n        include: str | list[str] | None = None,\n        contexts: list[str] | None = None,\n    ) -> None:\n        \"\"\"Annotate a list of modules.\n\n        Each module in `morfs` is annotated.  The source is written to a new\n        file, named with a \",cover\" suffix, with each line prefixed with a\n        marker to indicate the coverage of the line.  Covered lines have \">\",\n        excluded lines have \"-\", and missing lines have \"!\".\n\n        See :meth:`report` for other arguments.\n\n        \"\"\"\n        self._prepare_data_for_reporting()\n        with override_config(\n            self,\n            ignore_errors=ignore_errors,\n            report_omit=omit,\n            report_include=include,\n            report_contexts=contexts,\n        ):\n            reporter = AnnotateReporter(self)\n            reporter.report(morfs, directory=directory)\n\n    def html_report(\n        self,\n        morfs: Iterable[TMorf] | None = None,\n        directory: str | None = None,\n        ignore_errors: bool | None = None,\n        omit: str | list[str] | None = None,\n        include: str | list[str] | None = None,\n        extra_css: str | None = None,\n        title: str | None = None,\n        skip_covered: bool | None = None,\n        show_contexts: bool | None = None,\n        contexts: list[str] | None = None,\n        skip_empty: bool | None = None,\n        precision: int | None = None,\n    ) -> float:\n        \"\"\"Generate an HTML report.\n\n        The HTML is written to `directory`.  The file \"index.html\" is the\n        overview starting point, with links to more detailed pages for\n        individual modules.\n\n        `extra_css` is a path to a file of other CSS to apply on the page.\n        It will be copied into the HTML directory.\n\n        `title` is a text string (not HTML) to use as the title of the HTML\n        report.\n\n        See :meth:`report` for other arguments.\n\n        Returns a float, the total percentage covered.\n\n        .. note::\n\n            The HTML report files are generated incrementally based on the\n            source files and coverage results. If you modify the report files,\n            the changes will not be considered.  You should be careful about\n            changing the files in the report folder.\n\n        \"\"\"\n        self._prepare_data_for_reporting()\n        with override_config(\n            self,\n            ignore_errors=ignore_errors,\n            report_omit=omit,\n            report_include=include,\n            html_dir=directory,\n            extra_css=extra_css,\n            html_title=title,\n            html_skip_covered=skip_covered,\n            show_contexts=show_contexts,\n            report_contexts=contexts,\n            html_skip_empty=skip_empty,\n            precision=precision,\n        ):\n            reporter = HtmlReporter(self)\n            ret = reporter.report(morfs)\n            return ret\n\n    def xml_report(\n        self,\n        morfs: Iterable[TMorf] | None = None,\n        outfile: str | None = None,\n        ignore_errors: bool | None = None,\n        omit: str | list[str] | None = None,\n        include: str | list[str] | None = None,\n        contexts: list[str] | None = None,\n        skip_empty: bool | None = None,\n    ) -> float:\n        \"\"\"Generate an XML report of coverage results.\n\n        The report is compatible with Cobertura reports.\n\n        Each module in `morfs` is included in the report.  `outfile` is the\n        path to write the file to, \"-\" will write to stdout.\n\n        See :meth:`report` for other arguments.\n\n        Returns a float, the total percentage covered.\n\n        \"\"\"\n        self._prepare_data_for_reporting()\n        with override_config(\n            self,\n            ignore_errors=ignore_errors,\n            report_omit=omit,\n            report_include=include,\n            xml_output=outfile,\n            report_contexts=contexts,\n            skip_empty=skip_empty,\n        ):\n            return render_report(self.config.xml_output, XmlReporter(self), morfs, self._message)\n\n    def json_report(\n        self,\n        morfs: Iterable[TMorf] | None = None,\n        outfile: str | None = None,\n        ignore_errors: bool | None = None,\n        omit: str | list[str] | None = None,\n        include: str | list[str] | None = None,\n        contexts: list[str] | None = None,\n        pretty_print: bool | None = None,\n        show_contexts: bool | None = None,\n    ) -> float:\n        \"\"\"Generate a JSON report of coverage results.\n\n        Each module in `morfs` is included in the report.  `outfile` is the\n        path to write the file to, \"-\" will write to stdout.\n\n        `pretty_print` is a boolean, whether to pretty-print the JSON output or not.\n\n        See :meth:`report` for other arguments.\n\n        Returns a float, the total percentage covered.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        self._prepare_data_for_reporting()\n        with override_config(\n            self,\n            ignore_errors=ignore_errors,\n            report_omit=omit,\n            report_include=include,\n            json_output=outfile,\n            report_contexts=contexts,\n            json_pretty_print=pretty_print,\n            json_show_contexts=show_contexts,\n        ):\n            return render_report(self.config.json_output, JsonReporter(self), morfs, self._message)\n\n    def lcov_report(\n        self,\n        morfs: Iterable[TMorf] | None = None,\n        outfile: str | None = None,\n        ignore_errors: bool | None = None,\n        omit: str | list[str] | None = None,\n        include: str | list[str] | None = None,\n        contexts: list[str] | None = None,\n    ) -> float:\n        \"\"\"Generate an LCOV report of coverage results.\n\n        Each module in `morfs` is included in the report. `outfile` is the\n        path to write the file to, \"-\" will write to stdout.\n\n        See :meth:`report` for other arguments.\n\n        .. versionadded:: 6.3\n        \"\"\"\n        self._prepare_data_for_reporting()\n        with override_config(\n            self,\n            ignore_errors=ignore_errors,\n            report_omit=omit,\n            report_include=include,\n            lcov_output=outfile,\n            report_contexts=contexts,\n        ):\n            return render_report(self.config.lcov_output, LcovReporter(self), morfs, self._message)\n\n    def sys_info(self) -> Iterable[tuple[str, Any]]:\n        \"\"\"Return a list of (key, value) pairs showing internal information.\"\"\"\n\n        import coverage as covmod\n\n        self._init()\n        self._post_init()\n\n        def plugin_info(plugins: list[Any]) -> list[str]:\n            \"\"\"Make an entry for the sys_info from a list of plug-ins.\"\"\"\n            entries = []\n            for plugin in plugins:\n                entry = plugin._coverage_plugin_name\n                if not plugin._coverage_enabled:\n                    entry += \" (disabled)\"\n                entries.append(entry)\n            return entries\n\n        info = [\n            (\"coverage_version\", covmod.__version__),\n            (\"coverage_module\", covmod.__file__),\n            (\"core\", self._collector.tracer_name() if self._collector is not None else \"-none-\"),\n            (\"CTracer\", \"available\" if HAS_CTRACER else \"unavailable\"),\n            (\"plugins.file_tracers\", plugin_info(self._plugins.file_tracers)),\n            (\"plugins.configurers\", plugin_info(self._plugins.configurers)),\n            (\"plugins.context_switchers\", plugin_info(self._plugins.context_switchers)),\n            (\"configs_attempted\", self.config.config_files_attempted),\n            (\"configs_read\", self.config.config_files_read),\n            (\"config_file\", self.config.config_file),\n            (\"config_contents\",\n                repr(self.config._config_contents) if self.config._config_contents else \"-none-\",\n            ),\n            (\"data_file\", self._data.data_filename() if self._data is not None else \"-none-\"),\n            (\"python\", sys.version.replace(\"\\n\", \"\")),\n            (\"platform\", platform.platform()),\n            (\"implementation\", platform.python_implementation()),\n            (\"gil_enabled\", getattr(sys, '_is_gil_enabled', lambda: True)()),\n            (\"executable\", sys.executable),\n            (\"def_encoding\", sys.getdefaultencoding()),\n            (\"fs_encoding\", sys.getfilesystemencoding()),\n            (\"pid\", os.getpid()),\n            (\"cwd\", os.getcwd()),\n            (\"path\", sys.path),\n            (\"environment\", [f\"{k} = {v}\" for k, v in relevant_environment_display(os.environ)]),\n            (\"command_line\", \" \".join(getattr(sys, \"argv\", [\"-none-\"]))),\n        ]\n\n        if self._inorout is not None:\n            info.extend(self._inorout.sys_info())\n\n        info.extend(CoverageData.sys_info())\n\n        return info\n\n\n# Mega debugging...\n# $set_env.py: COVERAGE_DEBUG_CALLS - Lots and lots of output about calls to Coverage.\nif int(os.getenv(\"COVERAGE_DEBUG_CALLS\", 0)):               # pragma: debugging\n    from coverage.debug import decorate_methods, show_calls\n\n    Coverage = decorate_methods(        # type: ignore[misc]\n        show_calls(show_args=True),\n        butnot=[\"get_data\"],\n    )(Coverage)\n\n\ndef process_startup() -> Coverage | None:\n    \"\"\"Call this at Python start-up to perhaps measure coverage.\n\n    If the environment variable COVERAGE_PROCESS_START is defined, coverage\n    measurement is started.  The value of the variable is the config file\n    to use.\n\n    There are two ways to configure your Python installation to invoke this\n    function when Python starts:\n\n    #. Create or append to sitecustomize.py to add these lines::\n\n        import coverage\n        coverage.process_startup()\n\n    #. Create a .pth file in your Python installation containing::\n\n        import coverage; coverage.process_startup()\n\n    Returns the :class:`Coverage` instance that was started, or None if it was\n    not started by this call.\n\n    \"\"\"\n    cps = os.getenv(\"COVERAGE_PROCESS_START\")\n    if not cps:\n        # No request for coverage, nothing to do.\n        return None\n\n    # This function can be called more than once in a process. This happens\n    # because some virtualenv configurations make the same directory visible\n    # twice in sys.path.  This means that the .pth file will be found twice,\n    # and executed twice, executing this function twice.  We set a global\n    # flag (an attribute on this function) to indicate that coverage.py has\n    # already been started, so we can avoid doing it twice.\n    #\n    # https://github.com/nedbat/coveragepy/issues/340 has more details.\n\n    if hasattr(process_startup, \"coverage\"):\n        # We've annotated this function before, so we must have already\n        # started coverage.py in this process.  Nothing to do.\n        return None\n\n    cov = Coverage(config_file=cps)\n    process_startup.coverage = cov      # type: ignore[attr-defined]\n    cov._warn_no_data = False\n    cov._warn_unimported_source = False\n    cov._warn_preimported_source = False\n    cov._auto_save = True\n    cov.start()\n\n    return cov\n\n\ndef _prevent_sub_process_measurement() -> None:\n    \"\"\"Stop any subprocess auto-measurement from writing data.\"\"\"\n    auto_created_coverage = getattr(process_startup, \"coverage\", None)\n    if auto_created_coverage is not None:\n        auto_created_coverage._auto_save = False\n", "coverage/__main__.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Coverage.py's main entry point.\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\nfrom coverage.cmdline import main\nsys.exit(main())\n", "coverage/multiproc.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Monkey-patching to add multiprocessing support for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nimport multiprocessing\nimport multiprocessing.process\nimport os\nimport os.path\nimport sys\nimport traceback\n\nfrom typing import Any\n\nfrom coverage.debug import DebugControl\n\n# An attribute that will be set on the module to indicate that it has been\n# monkey-patched.\nPATCHED_MARKER = \"_coverage$patched\"\n\n\nOriginalProcess = multiprocessing.process.BaseProcess\noriginal_bootstrap = OriginalProcess._bootstrap     # type: ignore[attr-defined]\n\nclass ProcessWithCoverage(OriginalProcess):         # pylint: disable=abstract-method\n    \"\"\"A replacement for multiprocess.Process that starts coverage.\"\"\"\n\n    def _bootstrap(self, *args, **kwargs):          # type: ignore[no-untyped-def]\n        \"\"\"Wrapper around _bootstrap to start coverage.\"\"\"\n        debug: DebugControl | None = None\n        try:\n            from coverage import Coverage       # avoid circular import\n            cov = Coverage(data_suffix=True, auto_data=True)\n            cov._warn_preimported_source = False\n            cov.start()\n            _debug = cov._debug\n            assert _debug is not None\n            if _debug.should(\"multiproc\"):\n                debug = _debug\n            if debug:\n                debug.write(\"Calling multiprocessing bootstrap\")\n        except Exception:\n            print(\"Exception during multiprocessing bootstrap init:\", file=sys.stderr)\n            traceback.print_exc(file=sys.stderr)\n            sys.stderr.flush()\n            raise\n        try:\n            return original_bootstrap(self, *args, **kwargs)\n        finally:\n            if debug:\n                debug.write(\"Finished multiprocessing bootstrap\")\n            try:\n                cov.stop()\n                cov.save()\n            except Exception as exc:\n                if debug:\n                    debug.write(\"Exception during multiprocessing bootstrap cleanup\", exc=exc)\n                raise\n            if debug:\n                debug.write(\"Saved multiprocessing data\")\n\nclass Stowaway:\n    \"\"\"An object to pickle, so when it is unpickled, it can apply the monkey-patch.\"\"\"\n    def __init__(self, rcfile: str) -> None:\n        self.rcfile = rcfile\n\n    def __getstate__(self) -> dict[str, str]:\n        return {\"rcfile\": self.rcfile}\n\n    def __setstate__(self, state: dict[str, str]) -> None:\n        patch_multiprocessing(state[\"rcfile\"])\n\n\ndef patch_multiprocessing(rcfile: str) -> None:\n    \"\"\"Monkey-patch the multiprocessing module.\n\n    This enables coverage measurement of processes started by multiprocessing.\n    This involves aggressive monkey-patching.\n\n    `rcfile` is the path to the rcfile being used.\n\n    \"\"\"\n\n    if hasattr(multiprocessing, PATCHED_MARKER):\n        return\n\n    OriginalProcess._bootstrap = ProcessWithCoverage._bootstrap     # type: ignore[attr-defined]\n\n    # Set the value in ProcessWithCoverage that will be pickled into the child\n    # process.\n    os.environ[\"COVERAGE_RCFILE\"] = os.path.abspath(rcfile)\n\n    # When spawning processes rather than forking them, we have no state in the\n    # new process.  We sneak in there with a Stowaway: we stuff one of our own\n    # objects into the data that gets pickled and sent to the sub-process. When\n    # the Stowaway is unpickled, its __setstate__ method is called, which\n    # re-applies the monkey-patch.\n    # Windows only spawns, so this is needed to keep Windows working.\n    try:\n        from multiprocessing import spawn\n        original_get_preparation_data = spawn.get_preparation_data\n    except (ImportError, AttributeError):\n        pass\n    else:\n        def get_preparation_data_with_stowaway(name: str) -> dict[str, Any]:\n            \"\"\"Get the original preparation data, and also insert our stowaway.\"\"\"\n            d = original_get_preparation_data(name)\n            d[\"stowaway\"] = Stowaway(rcfile)\n            return d\n\n        spawn.get_preparation_data = get_preparation_data_with_stowaway\n\n    setattr(multiprocessing, PATCHED_MARKER, True)\n", "coverage/env.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Determine facts about the environment.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport platform\nimport sys\n\nfrom typing import Any, Iterable\n\n# debug_info() at the bottom wants to show all the globals, but not imports.\n# Grab the global names here to know which names to not show. Nothing defined\n# above this line will be in the output.\n_UNINTERESTING_GLOBALS = list(globals())\n# These names also shouldn't be shown.\n_UNINTERESTING_GLOBALS += [\"PYBEHAVIOR\", \"debug_info\"]\n\n# Operating systems.\nWINDOWS = sys.platform == \"win32\"\nLINUX = sys.platform.startswith(\"linux\")\nOSX = sys.platform == \"darwin\"\n\n# Python implementations.\nCPYTHON = (platform.python_implementation() == \"CPython\")\nPYPY = (platform.python_implementation() == \"PyPy\")\n\n# Python versions. We amend version_info with one more value, a zero if an\n# official version, or 1 if built from source beyond an official version.\n# Only use sys.version_info directly where tools like mypy need it to understand\n# version-specfic code, otherwise use PYVERSION.\nPYVERSION = sys.version_info + (int(platform.python_version()[-1] == \"+\"),)\n\nif PYPY:\n    PYPYVERSION = sys.pypy_version_info         # type: ignore[attr-defined]\nelse:\n    PYPYVERSION = (0,)\n\n# Python behavior.\nclass PYBEHAVIOR:\n    \"\"\"Flags indicating this Python's behavior.\"\"\"\n\n    # Does Python conform to PEP626, Precise line numbers for debugging and other tools.\n    # https://www.python.org/dev/peps/pep-0626\n    pep626 = (PYVERSION > (3, 10, 0, \"alpha\", 4))\n\n    # Is \"if __debug__\" optimized away?\n    optimize_if_debug = not pep626\n\n    # Is \"if not __debug__\" optimized away? The exact details have changed\n    # across versions.\n    if pep626:\n        optimize_if_not_debug = 1\n    elif PYPY:\n        if PYVERSION >= (3, 9):\n            optimize_if_not_debug = 2\n        else:\n            optimize_if_not_debug = 3\n    else:\n        optimize_if_not_debug = 2\n\n    # 3.7 changed how functions with only docstrings are numbered.\n    docstring_only_function = (not PYPY) and (PYVERSION <= (3, 10))\n\n    # When a break/continue/return statement in a try block jumps to a finally\n    # block, does the finally jump back to the break/continue/return (pre-3.10)\n    # to do the work?\n    finally_jumps_back = (PYVERSION < (3, 10))\n\n    # CPython 3.11 now jumps to the decorator line again while executing\n    # the decorator.\n    trace_decorator_line_again = (CPYTHON and PYVERSION > (3, 11, 0, \"alpha\", 3, 0))\n\n    # CPython 3.9a1 made sys.argv[0] and other reported files absolute paths.\n    report_absolute_files = (\n        (CPYTHON or (PYPY and PYPYVERSION >= (7, 3, 10)))\n        and PYVERSION >= (3, 9)\n    )\n\n    # Lines after break/continue/return/raise are no longer compiled into the\n    # bytecode.  They used to be marked as missing, now they aren't executable.\n    omit_after_jump = (\n        pep626\n        or (PYPY and PYVERSION >= (3, 9) and PYPYVERSION >= (7, 3, 12))\n    )\n\n    # PyPy has always omitted statements after return.\n    omit_after_return = omit_after_jump or PYPY\n\n    # Optimize away unreachable try-else clauses.\n    optimize_unreachable_try_else = pep626\n\n    # Modules used to have firstlineno equal to the line number of the first\n    # real line of code.  Now they always start at 1.\n    module_firstline_1 = pep626\n\n    # Are \"if 0:\" lines (and similar) kept in the compiled code?\n    keep_constant_test = pep626\n\n    # When leaving a with-block, do we visit the with-line again for the exit?\n    exit_through_with = (PYVERSION >= (3, 10, 0, \"beta\"))\n\n    # Match-case construct.\n    match_case = (PYVERSION >= (3, 10))\n\n    # Some words are keywords in some places, identifiers in other places.\n    soft_keywords = (PYVERSION >= (3, 10))\n\n    # Modules start with a line numbered zero. This means empty modules have\n    # only a 0-number line, which is ignored, giving a truly empty module.\n    empty_is_empty = (PYVERSION >= (3, 11, 0, \"beta\", 4))\n\n    # Are comprehensions inlined (new) or compiled as called functions (old)?\n    # Changed in https://github.com/python/cpython/pull/101441\n    comprehensions_are_functions = (PYVERSION <= (3, 12, 0, \"alpha\", 7, 0))\n\n    # PEP669 Low Impact Monitoring: https://peps.python.org/pep-0669/\n    pep669 = bool(getattr(sys, \"monitoring\", None))\n\n    # Where does frame.f_lasti point when yielding from a generator?\n    # It used to point at the YIELD, now it points at the RESUME.\n    # https://github.com/python/cpython/issues/113728\n    lasti_is_yield = (PYVERSION < (3, 13))\n\n\n# Coverage.py specifics, about testing scenarios. See tests/testenv.py also.\n\n# Are we coverage-measuring ourselves?\nMETACOV = os.getenv(\"COVERAGE_COVERAGE\") is not None\n\n# Are we running our test suite?\n# Even when running tests, you can use COVERAGE_TESTING=0 to disable the\n# test-specific behavior like AST checking.\nTESTING = os.getenv(\"COVERAGE_TESTING\") == \"True\"\n\n\ndef debug_info() -> Iterable[tuple[str, Any]]:\n    \"\"\"Return a list of (name, value) pairs for printing debug information.\"\"\"\n    info = [\n        (name, value) for name, value in globals().items()\n        if not name.startswith(\"_\") and name not in _UNINTERESTING_GLOBALS\n    ]\n    info += [\n        (name, value) for name, value in PYBEHAVIOR.__dict__.items()\n        if not name.startswith(\"_\")\n    ]\n    return sorted(info)\n", "coverage/__init__.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nCode coverage measurement for Python.\n\nNed Batchelder\nhttps://coverage.readthedocs.io\n\n\"\"\"\n\nfrom __future__ import annotations\n\n# mypy's convention is that \"import as\" names are public from the module.\n# We import names as themselves to indicate that. Pylint sees it as pointless,\n# so disable its warning.\n# pylint: disable=useless-import-alias\n\nfrom coverage.version import (\n    __version__ as __version__,\n    version_info as version_info,\n)\n\nfrom coverage.control import (\n    Coverage as Coverage,\n    process_startup as process_startup,\n)\nfrom coverage.data import CoverageData as CoverageData\nfrom coverage.exceptions import CoverageException as CoverageException\nfrom coverage.plugin import (\n    CodeRegion as CodeRegion,\n    CoveragePlugin as CoveragePlugin,\n    FileReporter as FileReporter,\n    FileTracer as FileTracer,\n)\n\n# Backward compatibility.\ncoverage = Coverage\n", "coverage/context.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Determine contexts for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nfrom types import FrameType\nfrom typing import cast, Callable, Sequence\n\n\ndef combine_context_switchers(\n    context_switchers: Sequence[Callable[[FrameType], str | None]],\n) -> Callable[[FrameType], str | None] | None:\n    \"\"\"Create a single context switcher from multiple switchers.\n\n    `context_switchers` is a list of functions that take a frame as an\n    argument and return a string to use as the new context label.\n\n    Returns a function that composites `context_switchers` functions, or None\n    if `context_switchers` is an empty list.\n\n    When invoked, the combined switcher calls `context_switchers` one-by-one\n    until a string is returned.  The combined switcher returns None if all\n    `context_switchers` return None.\n    \"\"\"\n    if not context_switchers:\n        return None\n\n    if len(context_switchers) == 1:\n        return context_switchers[0]\n\n    def should_start_context(frame: FrameType) -> str | None:\n        \"\"\"The combiner for multiple context switchers.\"\"\"\n        for switcher in context_switchers:\n            new_context = switcher(frame)\n            if new_context is not None:\n                return new_context\n        return None\n\n    return should_start_context\n\n\ndef should_start_context_test_function(frame: FrameType) -> str | None:\n    \"\"\"Is this frame calling a test_* function?\"\"\"\n    co_name = frame.f_code.co_name\n    if co_name.startswith(\"test\") or co_name == \"runTest\":\n        return qualname_from_frame(frame)\n    return None\n\n\ndef qualname_from_frame(frame: FrameType) -> str | None:\n    \"\"\"Get a qualified name for the code running in `frame`.\"\"\"\n    co = frame.f_code\n    fname = co.co_name\n    method = None\n    if co.co_argcount and co.co_varnames[0] == \"self\":\n        self = frame.f_locals.get(\"self\", None)\n        method = getattr(self, fname, None)\n\n    if method is None:\n        func = frame.f_globals.get(fname)\n        if func is None:\n            return None\n        return cast(str, func.__module__ + \".\" + fname)\n\n    func = getattr(method, \"__func__\", None)\n    if func is None:\n        cls = self.__class__\n        return cast(str, cls.__module__ + \".\" + cls.__name__ + \".\" + fname)\n\n    return cast(str, func.__module__ + \".\" + func.__qualname__)\n", "coverage/parser.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Code parsing for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport ast\nimport functools\nimport collections\nimport os\nimport re\nimport sys\nimport token\nimport tokenize\n\nfrom dataclasses import dataclass\nfrom types import CodeType\nfrom typing import (\n    cast, Any, Callable, Dict, Iterable, List, Optional, Protocol, Sequence,\n    Set, Tuple,\n)\n\nfrom coverage import env\nfrom coverage.bytecode import code_objects\nfrom coverage.debug import short_stack\nfrom coverage.exceptions import NoSource, NotPython\nfrom coverage.misc import nice_pair\nfrom coverage.phystokens import generate_tokens\nfrom coverage.types import TArc, TLineNo\n\n\nclass PythonParser:\n    \"\"\"Parse code to find executable lines, excluded lines, etc.\n\n    This information is all based on static analysis: no code execution is\n    involved.\n\n    \"\"\"\n    def __init__(\n        self,\n        text: str | None = None,\n        filename: str | None = None,\n        exclude: str | None = None,\n    ) -> None:\n        \"\"\"\n        Source can be provided as `text`, the text itself, or `filename`, from\n        which the text will be read.  Excluded lines are those that match\n        `exclude`, a regex string.\n\n        \"\"\"\n        assert text or filename, \"PythonParser needs either text or filename\"\n        self.filename = filename or \"<code>\"\n        if text is not None:\n            self.text: str = text\n        else:\n            from coverage.python import get_python_source\n            try:\n                self.text = get_python_source(self.filename)\n            except OSError as err:\n                raise NoSource(f\"No source for code: '{self.filename}': {err}\") from err\n\n        self.exclude = exclude\n\n        # The parsed AST of the text.\n        self._ast_root: ast.AST | None = None\n\n        # The normalized line numbers of the statements in the code. Exclusions\n        # are taken into account, and statements are adjusted to their first\n        # lines.\n        self.statements: set[TLineNo] = set()\n\n        # The normalized line numbers of the excluded lines in the code,\n        # adjusted to their first lines.\n        self.excluded: set[TLineNo] = set()\n\n        # The raw_* attributes are only used in this class, and in\n        # lab/parser.py to show how this class is working.\n\n        # The line numbers that start statements, as reported by the line\n        # number table in the bytecode.\n        self.raw_statements: set[TLineNo] = set()\n\n        # The raw line numbers of excluded lines of code, as marked by pragmas.\n        self.raw_excluded: set[TLineNo] = set()\n\n        # The line numbers of class definitions.\n        self.raw_classdefs: set[TLineNo] = set()\n\n        # The line numbers of docstring lines.\n        self.raw_docstrings: set[TLineNo] = set()\n\n        # Internal detail, used by lab/parser.py.\n        self.show_tokens = False\n\n        # A dict mapping line numbers to lexical statement starts for\n        # multi-line statements.\n        self._multiline: dict[TLineNo, TLineNo] = {}\n\n        # Lazily-created arc data, and missing arc descriptions.\n        self._all_arcs: set[TArc] | None = None\n        self._missing_arc_fragments: TArcFragments | None = None\n\n    def lines_matching(self, regex: str) -> set[TLineNo]:\n        \"\"\"Find the lines matching a regex.\n\n        Returns a set of line numbers, the lines that contain a match for\n        `regex`.  The entire line needn't match, just a part of it.\n\n        \"\"\"\n        regex_c = re.compile(regex)\n        matches = set()\n        for i, ltext in enumerate(self.text.split(\"\\n\"), start=1):\n            if regex_c.search(ltext):\n                matches.add(self._multiline.get(i, i))\n        return matches\n\n    def _raw_parse(self) -> None:\n        \"\"\"Parse the source to find the interesting facts about its lines.\n\n        A handful of attributes are updated.\n\n        \"\"\"\n        # Find lines which match an exclusion pattern.\n        if self.exclude:\n            self.raw_excluded = self.lines_matching(self.exclude)\n            self.excluded = set(self.raw_excluded)\n\n        # The current number of indents.\n        indent: int = 0\n        # An exclusion comment will exclude an entire clause at this indent.\n        exclude_indent: int = 0\n        # Are we currently excluding lines?\n        excluding: bool = False\n        # The line number of the first line in a multi-line statement.\n        first_line: int = 0\n        # Is the file empty?\n        empty: bool = True\n        # Parenthesis (and bracket) nesting level.\n        nesting: int = 0\n\n        assert self.text is not None\n        tokgen = generate_tokens(self.text)\n        for toktype, ttext, (slineno, _), (elineno, _), ltext in tokgen:\n            if self.show_tokens:                # pragma: debugging\n                print(\"%10s %5s %-20r %r\" % (\n                    tokenize.tok_name.get(toktype, toktype),\n                    nice_pair((slineno, elineno)), ttext, ltext,\n                ))\n            if toktype == token.INDENT:\n                indent += 1\n            elif toktype == token.DEDENT:\n                indent -= 1\n            elif toktype == token.OP:\n                if ttext == \":\" and nesting == 0:\n                    should_exclude = (\n                        self.excluded.intersection(range(first_line, elineno + 1))\n                    )\n                    if not excluding and should_exclude:\n                        # Start excluding a suite.  We trigger off of the colon\n                        # token so that the #pragma comment will be recognized on\n                        # the same line as the colon.\n                        self.excluded.add(elineno)\n                        exclude_indent = indent\n                        excluding = True\n                elif ttext in \"([{\":\n                    nesting += 1\n                elif ttext in \")]}\":\n                    nesting -= 1\n            elif toktype == token.NEWLINE:\n                if first_line and elineno != first_line:\n                    # We're at the end of a line, and we've ended on a\n                    # different line than the first line of the statement,\n                    # so record a multi-line range.\n                    for l in range(first_line, elineno+1):\n                        self._multiline[l] = first_line\n                first_line = 0\n\n            if ttext.strip() and toktype != tokenize.COMMENT:\n                # A non-white-space token.\n                empty = False\n                if not first_line:\n                    # The token is not white space, and is the first in a statement.\n                    first_line = slineno\n                    # Check whether to end an excluded suite.\n                    if excluding and indent <= exclude_indent:\n                        excluding = False\n                    if excluding:\n                        self.excluded.add(elineno)\n\n        # Find the starts of the executable statements.\n        if not empty:\n            byte_parser = ByteParser(self.text, filename=self.filename)\n            self.raw_statements.update(byte_parser._find_statements())\n\n        # The first line of modules can lie and say 1 always, even if the first\n        # line of code is later. If so, map 1 to the actual first line of the\n        # module.\n        if env.PYBEHAVIOR.module_firstline_1 and self._multiline:\n            self._multiline[1] = min(self.raw_statements)\n\n        self.excluded = self.first_lines(self.excluded)\n\n        # AST lets us find classes, docstrings, and decorator-affected\n        # functions and classes.\n        assert self._ast_root is not None\n        for node in ast.walk(self._ast_root):\n            # Find class definitions.\n            if isinstance(node, ast.ClassDef):\n                self.raw_classdefs.add(node.lineno)\n            # Find docstrings.\n            if isinstance(node, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef, ast.Module)):\n                if node.body:\n                    first = node.body[0]\n                    if (\n                        isinstance(first, ast.Expr)\n                        and isinstance(first.value, ast.Constant)\n                        and isinstance(first.value.value, str)\n                    ):\n                        self.raw_docstrings.update(\n                            range(first.lineno, cast(int, first.end_lineno) + 1)\n                        )\n            # Exclusions carry from decorators and signatures to the bodies of\n            # functions and classes.\n            if isinstance(node, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):\n                first_line = min((d.lineno for d in node.decorator_list), default=node.lineno)\n                if self.excluded.intersection(range(first_line, node.lineno + 1)):\n                    self.excluded.update(range(first_line, cast(int, node.end_lineno) + 1))\n\n    @functools.lru_cache(maxsize=1000)\n    def first_line(self, lineno: TLineNo) -> TLineNo:\n        \"\"\"Return the first line number of the statement including `lineno`.\"\"\"\n        if lineno < 0:\n            lineno = -self._multiline.get(-lineno, -lineno)\n        else:\n            lineno = self._multiline.get(lineno, lineno)\n        return lineno\n\n    def first_lines(self, linenos: Iterable[TLineNo]) -> set[TLineNo]:\n        \"\"\"Map the line numbers in `linenos` to the correct first line of the\n        statement.\n\n        Returns a set of the first lines.\n\n        \"\"\"\n        return {self.first_line(l) for l in linenos}\n\n    def translate_lines(self, lines: Iterable[TLineNo]) -> set[TLineNo]:\n        \"\"\"Implement `FileReporter.translate_lines`.\"\"\"\n        return self.first_lines(lines)\n\n    def translate_arcs(self, arcs: Iterable[TArc]) -> set[TArc]:\n        \"\"\"Implement `FileReporter.translate_arcs`.\"\"\"\n        return {(self.first_line(a), self.first_line(b)) for (a, b) in arcs}\n\n    def parse_source(self) -> None:\n        \"\"\"Parse source text to find executable lines, excluded lines, etc.\n\n        Sets the .excluded and .statements attributes, normalized to the first\n        line of multi-line statements.\n\n        \"\"\"\n        try:\n            self._ast_root = ast.parse(self.text)\n            self._raw_parse()\n        except (tokenize.TokenError, IndentationError, SyntaxError) as err:\n            if hasattr(err, \"lineno\"):\n                lineno = err.lineno         # IndentationError\n            else:\n                lineno = err.args[1][0]     # TokenError\n            raise NotPython(\n                f\"Couldn't parse '{self.filename}' as Python source: \" +\n                f\"{err.args[0]!r} at line {lineno}\",\n            ) from err\n\n        ignore = self.excluded | self.raw_docstrings\n        starts = self.raw_statements - ignore\n        self.statements = self.first_lines(starts) - ignore\n\n    def arcs(self) -> set[TArc]:\n        \"\"\"Get information about the arcs available in the code.\n\n        Returns a set of line number pairs.  Line numbers have been normalized\n        to the first line of multi-line statements.\n\n        \"\"\"\n        if self._all_arcs is None:\n            self._analyze_ast()\n        assert self._all_arcs is not None\n        return self._all_arcs\n\n    def _analyze_ast(self) -> None:\n        \"\"\"Run the AstArcAnalyzer and save its results.\n\n        `_all_arcs` is the set of arcs in the code.\n\n        \"\"\"\n        assert self._ast_root is not None\n        aaa = AstArcAnalyzer(self._ast_root, self.raw_statements, self._multiline)\n        aaa.analyze()\n\n        self._all_arcs = set()\n        for l1, l2 in aaa.arcs:\n            fl1 = self.first_line(l1)\n            fl2 = self.first_line(l2)\n            if fl1 != fl2:\n                self._all_arcs.add((fl1, fl2))\n\n        self._missing_arc_fragments = aaa.missing_arc_fragments\n\n    @functools.lru_cache()\n    def exit_counts(self) -> dict[TLineNo, int]:\n        \"\"\"Get a count of exits from that each line.\n\n        Excluded lines are excluded.\n\n        \"\"\"\n        exit_counts: dict[TLineNo, int] = collections.defaultdict(int)\n        for l1, l2 in self.arcs():\n            if l1 < 0:\n                # Don't ever report -1 as a line number\n                continue\n            if l1 in self.excluded:\n                # Don't report excluded lines as line numbers.\n                continue\n            if l2 in self.excluded:\n                # Arcs to excluded lines shouldn't count.\n                continue\n            exit_counts[l1] += 1\n\n        # Class definitions have one extra exit, so remove one for each:\n        for l in self.raw_classdefs:\n            # Ensure key is there: class definitions can include excluded lines.\n            if l in exit_counts:\n                exit_counts[l] -= 1\n\n        return exit_counts\n\n    def missing_arc_description(\n        self,\n        start: TLineNo,\n        end: TLineNo,\n        executed_arcs: Iterable[TArc] | None = None,\n    ) -> str:\n        \"\"\"Provide an English sentence describing a missing arc.\"\"\"\n        if self._missing_arc_fragments is None:\n            self._analyze_ast()\n            assert self._missing_arc_fragments is not None\n\n        actual_start = start\n\n        if (\n            executed_arcs and\n            end < 0 and end == -start and\n            (end, start) not in executed_arcs and\n            (end, start) in self._missing_arc_fragments\n        ):\n            # It's a one-line callable, and we never even started it,\n            # and we have a message about not starting it.\n            start, end = end, start\n\n        fragment_pairs = self._missing_arc_fragments.get((start, end), [(None, None)])\n\n        msgs = []\n        for smsg, emsg in fragment_pairs:\n            if emsg is None:\n                if end < 0:\n                    # Hmm, maybe we have a one-line callable, let's check.\n                    if (-end, end) in self._missing_arc_fragments:\n                        return self.missing_arc_description(-end, end)\n                    emsg = \"didn't jump to the function exit\"\n                else:\n                    emsg = \"didn't jump to line {lineno}\"\n            emsg = emsg.format(lineno=end)\n\n            msg = f\"line {actual_start} {emsg}\"\n            if smsg is not None:\n                msg += f\" because {smsg.format(lineno=actual_start)}\"\n\n            msgs.append(msg)\n\n        return \" or \".join(msgs)\n\n\nclass ByteParser:\n    \"\"\"Parse bytecode to understand the structure of code.\"\"\"\n\n    def __init__(\n        self,\n        text: str,\n        code: CodeType | None = None,\n        filename: str | None = None,\n    ) -> None:\n        self.text = text\n        if code is not None:\n            self.code = code\n        else:\n            assert filename is not None\n            # We only get here if earlier ast parsing succeeded, so no need to\n            # catch errors.\n            self.code = compile(text, filename, \"exec\", dont_inherit=True)\n\n    def child_parsers(self) -> Iterable[ByteParser]:\n        \"\"\"Iterate over all the code objects nested within this one.\n\n        The iteration includes `self` as its first value.\n\n        \"\"\"\n        return (ByteParser(self.text, code=c) for c in code_objects(self.code))\n\n    def _line_numbers(self) -> Iterable[TLineNo]:\n        \"\"\"Yield the line numbers possible in this code object.\n\n        Uses co_lnotab described in Python/compile.c to find the\n        line numbers.  Produces a sequence: l0, l1, ...\n        \"\"\"\n        if hasattr(self.code, \"co_lines\"):\n            # PYVERSIONS: new in 3.10\n            for _, _, line in self.code.co_lines():\n                if line:\n                    yield line\n        else:\n            # Adapted from dis.py in the standard library.\n            byte_increments = self.code.co_lnotab[0::2]\n            line_increments = self.code.co_lnotab[1::2]\n\n            last_line_num = None\n            line_num = self.code.co_firstlineno\n            byte_num = 0\n            for byte_incr, line_incr in zip(byte_increments, line_increments):\n                if byte_incr:\n                    if line_num != last_line_num:\n                        yield line_num\n                        last_line_num = line_num\n                    byte_num += byte_incr\n                if line_incr >= 0x80:\n                    line_incr -= 0x100\n                line_num += line_incr\n            if line_num != last_line_num:\n                yield line_num\n\n    def _find_statements(self) -> Iterable[TLineNo]:\n        \"\"\"Find the statements in `self.code`.\n\n        Produce a sequence of line numbers that start statements.  Recurses\n        into all code objects reachable from `self.code`.\n\n        \"\"\"\n        for bp in self.child_parsers():\n            # Get all of the lineno information from this code.\n            yield from bp._line_numbers()\n\n\n#\n# AST analysis\n#\n\n@dataclass(frozen=True, order=True)\nclass ArcStart:\n    \"\"\"The information needed to start an arc.\n\n    `lineno` is the line number the arc starts from.\n\n    `cause` is an English text fragment used as the `startmsg` for\n    AstArcAnalyzer.missing_arc_fragments.  It will be used to describe why an\n    arc wasn't executed, so should fit well into a sentence of the form,\n    \"Line 17 didn't run because {cause}.\"  The fragment can include \"{lineno}\"\n    to have `lineno` interpolated into it.\n\n    As an example, this code::\n\n        if something(x):        # line 1\n            func(x)             # line 2\n        more_stuff()            # line 3\n\n    would have two ArcStarts:\n\n    - ArcStart(1, \"the condition on line 1 was always true\")\n    - ArcStart(1, \"the condition on line 1 was never true\")\n\n    The first would be used to create an arc from 1 to 3, creating a message like\n    \"line 1 didn't jump to line 3 because the condition on line 1 was always true.\"\n\n    The second would be used for the arc from 1 to 2, creating a message like\n    \"line 1 didn't jump to line 2 because the condition on line 1 was never true.\"\n\n    \"\"\"\n    lineno: TLineNo\n    cause: str = \"\"\n\n\nclass TAddArcFn(Protocol):\n    \"\"\"The type for AstArcAnalyzer.add_arc().\"\"\"\n    def __call__(\n        self,\n        start: TLineNo,\n        end: TLineNo,\n        smsg: str | None = None,\n        emsg: str | None = None,\n    ) -> None:\n        ...\n\nTArcFragments = Dict[TArc, List[Tuple[Optional[str], Optional[str]]]]\n\nclass Block:\n    \"\"\"\n    Blocks need to handle various exiting statements in their own ways.\n\n    All of these methods take a list of exits, and a callable `add_arc`\n    function that they can use to add arcs if needed.  They return True if the\n    exits are handled, or False if the search should continue up the block\n    stack.\n    \"\"\"\n    # pylint: disable=unused-argument\n    def process_break_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        \"\"\"Process break exits.\"\"\"\n        # Because break can only appear in loops, and most subclasses\n        # implement process_break_exits, this function is never reached.\n        raise AssertionError\n\n    def process_continue_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        \"\"\"Process continue exits.\"\"\"\n        # Because continue can only appear in loops, and most subclasses\n        # implement process_continue_exits, this function is never reached.\n        raise AssertionError\n\n    def process_raise_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        \"\"\"Process raise exits.\"\"\"\n        return False\n\n    def process_return_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        \"\"\"Process return exits.\"\"\"\n        return False\n\n\nclass LoopBlock(Block):\n    \"\"\"A block on the block stack representing a `for` or `while` loop.\"\"\"\n    def __init__(self, start: TLineNo) -> None:\n        # The line number where the loop starts.\n        self.start = start\n        # A set of ArcStarts, the arcs from break statements exiting this loop.\n        self.break_exits: set[ArcStart] = set()\n\n    def process_break_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        self.break_exits.update(exits)\n        return True\n\n    def process_continue_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        for xit in exits:\n            add_arc(xit.lineno, self.start, xit.cause)\n        return True\n\n\nclass FunctionBlock(Block):\n    \"\"\"A block on the block stack representing a function definition.\"\"\"\n    def __init__(self, start: TLineNo, name: str) -> None:\n        # The line number where the function starts.\n        self.start = start\n        # The name of the function.\n        self.name = name\n\n    def process_raise_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        for xit in exits:\n            add_arc(\n                xit.lineno, -self.start, xit.cause,\n                f\"didn't except from function {self.name!r}\",\n            )\n        return True\n\n    def process_return_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        for xit in exits:\n            add_arc(\n                xit.lineno, -self.start, xit.cause,\n                f\"didn't return from function {self.name!r}\",\n            )\n        return True\n\n\nclass TryBlock(Block):\n    \"\"\"A block on the block stack representing a `try` block.\"\"\"\n    def __init__(self, handler_start: TLineNo | None, final_start: TLineNo | None) -> None:\n        # The line number of the first \"except\" handler, if any.\n        self.handler_start = handler_start\n        # The line number of the \"finally:\" clause, if any.\n        self.final_start = final_start\n\n        # The ArcStarts for breaks/continues/returns/raises inside the \"try:\"\n        # that need to route through the \"finally:\" clause.\n        self.break_from: set[ArcStart] = set()\n        self.continue_from: set[ArcStart] = set()\n        self.raise_from: set[ArcStart] = set()\n        self.return_from: set[ArcStart] = set()\n\n    def process_break_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        if self.final_start is not None:\n            self.break_from.update(exits)\n            return True\n        return False\n\n    def process_continue_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        if self.final_start is not None:\n            self.continue_from.update(exits)\n            return True\n        return False\n\n    def process_raise_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        if self.handler_start is not None:\n            for xit in exits:\n                add_arc(xit.lineno, self.handler_start, xit.cause)\n        else:\n            assert self.final_start is not None\n            self.raise_from.update(exits)\n        return True\n\n    def process_return_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        if self.final_start is not None:\n            self.return_from.update(exits)\n            return True\n        return False\n\n\nclass WithBlock(Block):\n    \"\"\"A block on the block stack representing a `with` block.\"\"\"\n    def __init__(self, start: TLineNo) -> None:\n        # We only ever use this block if it is needed, so that we don't have to\n        # check this setting in all the methods.\n        assert env.PYBEHAVIOR.exit_through_with\n\n        # The line number of the with statement.\n        self.start = start\n\n        # The ArcStarts for breaks/continues/returns/raises inside the \"with:\"\n        # that need to go through the with-statement while exiting.\n        self.break_from: set[ArcStart] = set()\n        self.continue_from: set[ArcStart] = set()\n        self.return_from: set[ArcStart] = set()\n\n    def _process_exits(\n        self,\n        exits: set[ArcStart],\n        add_arc: TAddArcFn,\n        from_set: set[ArcStart] | None = None,\n    ) -> bool:\n        \"\"\"Helper to process the four kinds of exits.\"\"\"\n        for xit in exits:\n            add_arc(xit.lineno, self.start, xit.cause)\n        if from_set is not None:\n            from_set.update(exits)\n        return True\n\n    def process_break_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        return self._process_exits(exits, add_arc, self.break_from)\n\n    def process_continue_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        return self._process_exits(exits, add_arc, self.continue_from)\n\n    def process_raise_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        return self._process_exits(exits, add_arc)\n\n    def process_return_exits(self, exits: set[ArcStart], add_arc: TAddArcFn) -> bool:\n        return self._process_exits(exits, add_arc, self.return_from)\n\n\nclass NodeList(ast.AST):\n    \"\"\"A synthetic fictitious node, containing a sequence of nodes.\n\n    This is used when collapsing optimized if-statements, to represent the\n    unconditional execution of one of the clauses.\n\n    \"\"\"\n    def __init__(self, body: Sequence[ast.AST]) -> None:\n        self.body = body\n        self.lineno = body[0].lineno\n\n# TODO: Shouldn't the cause messages join with \"and\" instead of \"or\"?\n\ndef _make_expression_code_method(noun: str) -> Callable[[AstArcAnalyzer, ast.AST], None]:\n    \"\"\"A function to make methods for expression-based callable _code_object__ methods.\"\"\"\n    def _code_object__expression_callable(self: AstArcAnalyzer, node: ast.AST) -> None:\n        start = self.line_for_node(node)\n        self.add_arc(-start, start, None, f\"didn't run the {noun} on line {start}\")\n        self.add_arc(start, -start, None, f\"didn't finish the {noun} on line {start}\")\n    return _code_object__expression_callable\n\n\nclass AstArcAnalyzer:\n    \"\"\"Analyze source text with an AST to find executable code paths.\n\n    The .analyze() method does the work, and populates these attributes:\n\n    `arcs`: a set of (from, to) pairs of the the arcs possible in the code.\n\n    `missing_arc_fragments`: a dict mapping (from, to) arcs to lists of\n    message fragments explaining why the arc is missing from execution::\n\n        { (start, end): [(startmsg, endmsg), ...], }\n\n    For an arc starting from line 17, they should be usable to form complete\n    sentences like: \"Line 17 {endmsg} because {startmsg}\".\n\n    \"\"\"\n\n    def __init__(\n        self,\n        root_node: ast.AST,\n        statements: set[TLineNo],\n        multiline: dict[TLineNo, TLineNo],\n    ) -> None:\n        self.root_node = root_node\n        # TODO: I think this is happening in too many places.\n        self.statements = {multiline.get(l, l) for l in statements}\n        self.multiline = multiline\n\n        # Turn on AST dumps with an environment variable.\n        # $set_env.py: COVERAGE_AST_DUMP - Dump the AST nodes when parsing code.\n        dump_ast = bool(int(os.getenv(\"COVERAGE_AST_DUMP\", \"0\")))\n\n        if dump_ast:                                # pragma: debugging\n            # Dump the AST so that failing tests have helpful output.\n            print(f\"Statements: {self.statements}\")\n            print(f\"Multiline map: {self.multiline}\")\n            dumpkw: dict[str, Any] = {}\n            if sys.version_info >= (3, 9):\n                dumpkw[\"indent\"] = 4\n            print(ast.dump(self.root_node, include_attributes=True, **dumpkw))\n\n        self.arcs: set[TArc] = set()\n        self.missing_arc_fragments: TArcFragments = collections.defaultdict(list)\n        self.block_stack: list[Block] = []\n\n        # $set_env.py: COVERAGE_TRACK_ARCS - Trace possible arcs added while parsing code.\n        self.debug = bool(int(os.getenv(\"COVERAGE_TRACK_ARCS\", \"0\")))\n\n    def analyze(self) -> None:\n        \"\"\"Examine the AST tree from `self.root_node` to determine possible arcs.\"\"\"\n        for node in ast.walk(self.root_node):\n            node_name = node.__class__.__name__\n            code_object_handler = getattr(self, \"_code_object__\" + node_name, None)\n            if code_object_handler is not None:\n                code_object_handler(node)\n\n    # Code object dispatchers: _code_object__*\n    #\n    # These methods are used by analyze() as the start of the analysis.\n    # There is one for each construct with a code object.\n\n    def _code_object__Module(self, node: ast.Module) -> None:\n        start = self.line_for_node(node)\n        if node.body:\n            exits = self.body_exits(node.body, from_start=ArcStart(-start))\n            for xit in exits:\n                self.add_arc(xit.lineno, -start, xit.cause, \"didn't exit the module\")\n        else:\n            # Empty module.\n            self.add_arc(-start, start)\n            self.add_arc(start, -start)\n\n    def _code_object__FunctionDef(self, node: ast.FunctionDef) -> None:\n        start = self.line_for_node(node)\n        self.block_stack.append(FunctionBlock(start=start, name=node.name))\n        exits = self.body_exits(node.body, from_start=ArcStart(-start))\n        self.process_return_exits(exits)\n        self.block_stack.pop()\n\n    _code_object__AsyncFunctionDef = _code_object__FunctionDef\n\n    def _code_object__ClassDef(self, node: ast.ClassDef) -> None:\n        start = self.line_for_node(node)\n        self.add_arc(-start, start)\n        exits = self.body_exits(node.body, from_start=ArcStart(start))\n        for xit in exits:\n            self.add_arc(\n                xit.lineno, -start, xit.cause,\n                f\"didn't exit the body of class {node.name!r}\",\n            )\n\n    _code_object__Lambda = _make_expression_code_method(\"lambda\")\n    _code_object__GeneratorExp = _make_expression_code_method(\"generator expression\")\n    if env.PYBEHAVIOR.comprehensions_are_functions:\n        _code_object__DictComp = _make_expression_code_method(\"dictionary comprehension\")\n        _code_object__SetComp = _make_expression_code_method(\"set comprehension\")\n        _code_object__ListComp = _make_expression_code_method(\"list comprehension\")\n\n\n    def add_arc(\n        self,\n        start: TLineNo,\n        end: TLineNo,\n        smsg: str | None = None,\n        emsg: str | None = None,\n    ) -> None:\n        \"\"\"Add an arc, including message fragments to use if it is missing.\"\"\"\n        if self.debug:                      # pragma: debugging\n            print(f\"\\nAdding possible arc: ({start}, {end}): {smsg!r}, {emsg!r}\")\n            print(short_stack())\n        self.arcs.add((start, end))\n\n        if smsg is not None or emsg is not None:\n            self.missing_arc_fragments[(start, end)].append((smsg, emsg))\n\n    def nearest_blocks(self) -> Iterable[Block]:\n        \"\"\"Yield the blocks in nearest-to-farthest order.\"\"\"\n        return reversed(self.block_stack)\n\n    def line_for_node(self, node: ast.AST) -> TLineNo:\n        \"\"\"What is the right line number to use for this node?\n\n        This dispatches to _line__Node functions where needed.\n\n        \"\"\"\n        node_name = node.__class__.__name__\n        handler = cast(\n            Optional[Callable[[ast.AST], TLineNo]],\n            getattr(self, \"_line__\" + node_name, None),\n        )\n        if handler is not None:\n            return handler(node)\n        else:\n            return node.lineno\n\n    # First lines: _line__*\n    #\n    # Dispatched by line_for_node, each method knows how to identify the first\n    # line number in the node, as Python will report it.\n\n    def _line_decorated(self, node: ast.FunctionDef) -> TLineNo:\n        \"\"\"Compute first line number for things that can be decorated (classes and functions).\"\"\"\n        if node.decorator_list:\n            lineno = node.decorator_list[0].lineno\n        else:\n            lineno = node.lineno\n        return lineno\n\n    def _line__Assign(self, node: ast.Assign) -> TLineNo:\n        return self.line_for_node(node.value)\n\n    _line__ClassDef = _line_decorated\n\n    def _line__Dict(self, node: ast.Dict) -> TLineNo:\n        if node.keys:\n            if node.keys[0] is not None:\n                return node.keys[0].lineno\n            else:\n                # Unpacked dict literals `{**{\"a\":1}}` have None as the key,\n                # use the value in that case.\n                return node.values[0].lineno\n        else:\n            return node.lineno\n\n    _line__FunctionDef = _line_decorated\n    _line__AsyncFunctionDef = _line_decorated\n\n    def _line__List(self, node: ast.List) -> TLineNo:\n        if node.elts:\n            return self.line_for_node(node.elts[0])\n        else:\n            return node.lineno\n\n    def _line__Module(self, node: ast.Module) -> TLineNo:\n        if env.PYBEHAVIOR.module_firstline_1:\n            return 1\n        elif node.body:\n            return self.line_for_node(node.body[0])\n        else:\n            # Empty modules have no line number, they always start at 1.\n            return 1\n\n    # The node types that just flow to the next node with no complications.\n    OK_TO_DEFAULT = {\n        \"AnnAssign\", \"Assign\", \"Assert\", \"AugAssign\", \"Delete\", \"Expr\", \"Global\",\n        \"Import\", \"ImportFrom\", \"Nonlocal\", \"Pass\",\n    }\n\n    def node_exits(self, node: ast.AST) -> set[ArcStart]:\n        \"\"\"Find the set of arc starts that exit this node.\n\n        Return a set of ArcStarts, exits from this node to the next. Because a\n        node represents an entire sub-tree (including its children), the exits\n        from a node can be arbitrarily complex::\n\n            if something(1):\n                if other(2):\n                    doit(3)\n                else:\n                    doit(5)\n\n        There are three exits from line 1: they start at lines 1, 3 and 5.\n        There are two exits from line 2: lines 3 and 5.\n\n        \"\"\"\n        node_name = node.__class__.__name__\n        handler = cast(\n            Optional[Callable[[ast.AST], Set[ArcStart]]],\n            getattr(self, \"_handle__\" + node_name, None),\n        )\n        if handler is not None:\n            arc_starts = handler(node)\n        else:\n            # No handler: either it's something that's ok to default (a simple\n            # statement), or it's something we overlooked.\n            if env.TESTING:\n                if node_name not in self.OK_TO_DEFAULT:\n                    raise RuntimeError(f\"*** Unhandled: {node}\")        # pragma: only failure\n\n            # Default for simple statements: one exit from this node.\n            arc_starts = {ArcStart(self.line_for_node(node))}\n        return arc_starts\n\n    def body_exits(\n        self,\n        body: Sequence[ast.AST],\n        from_start: ArcStart | None = None,\n        prev_starts: set[ArcStart] | None = None,\n    ) -> set[ArcStart]:\n        \"\"\"Find arc starts that exit the body of a compound statement.\n\n        `body` is the body node.  `from_start` is a single `ArcStart` that can\n        be the previous line in flow before this body.  `prev_starts` is a set\n        of ArcStarts that can be the previous line.  Only one of them should be\n        given.\n\n        Also records arcs (using `add_arc`) within the body.\n\n        Returns a set of ArcStarts, the exits from this body.\n\n        \"\"\"\n        if prev_starts is None:\n            assert from_start is not None\n            prev_starts = {from_start}\n        else:\n            assert from_start is None\n\n        # Loop over the nodes in the body, making arcs from each one's exits to\n        # the next node.\n        for body_node in body:\n            lineno = self.line_for_node(body_node)\n            first_line = self.multiline.get(lineno, lineno)\n            if first_line not in self.statements:\n                maybe_body_node = self.find_non_missing_node(body_node)\n                if maybe_body_node is None:\n                    continue\n                body_node = maybe_body_node\n                lineno = self.line_for_node(body_node)\n            for prev_start in prev_starts:\n                self.add_arc(prev_start.lineno, lineno, prev_start.cause)\n            prev_starts = self.node_exits(body_node)\n        return prev_starts\n\n    def find_non_missing_node(self, node: ast.AST) -> ast.AST | None:\n        \"\"\"Search `node` looking for a child that has not been optimized away.\n\n        This might return the node you started with, or it will work recursively\n        to find a child node in self.statements.\n\n        Returns a node, or None if none of the node remains.\n\n        \"\"\"\n        # This repeats work just done in body_exits, but this duplication\n        # means we can avoid a function call in the 99.9999% case of not\n        # optimizing away statements.\n        lineno = self.line_for_node(node)\n        first_line = self.multiline.get(lineno, lineno)\n        if first_line in self.statements:\n            return node\n\n        missing_fn = cast(\n            Optional[Callable[[ast.AST], Optional[ast.AST]]],\n            getattr(self, \"_missing__\" + node.__class__.__name__, None),\n        )\n        if missing_fn is not None:\n            ret_node = missing_fn(node)\n        else:\n            ret_node = None\n        return ret_node\n\n    # Missing nodes: _missing__*\n    #\n    # Entire statements can be optimized away by Python. They will appear in\n    # the AST, but not the bytecode.  These functions are called (by\n    # find_non_missing_node) to find a node to use instead of the missing\n    # node.  They can return None if the node should truly be gone.\n\n    def _missing__If(self, node: ast.If) -> ast.AST | None:\n        # If the if-node is missing, then one of its children might still be\n        # here, but not both. So return the first of the two that isn't missing.\n        # Use a NodeList to hold the clauses as a single node.\n        non_missing = self.find_non_missing_node(NodeList(node.body))\n        if non_missing:\n            return non_missing\n        if node.orelse:\n            return self.find_non_missing_node(NodeList(node.orelse))\n        return None\n\n    def _missing__NodeList(self, node: NodeList) -> ast.AST | None:\n        # A NodeList might be a mixture of missing and present nodes. Find the\n        # ones that are present.\n        non_missing_children = []\n        for child in node.body:\n            maybe_child = self.find_non_missing_node(child)\n            if maybe_child is not None:\n                non_missing_children.append(maybe_child)\n\n        # Return the simplest representation of the present children.\n        if not non_missing_children:\n            return None\n        if len(non_missing_children) == 1:\n            return non_missing_children[0]\n        return NodeList(non_missing_children)\n\n    def _missing__While(self, node: ast.While) -> ast.AST | None:\n        body_nodes = self.find_non_missing_node(NodeList(node.body))\n        if not body_nodes:\n            return None\n        # Make a synthetic While-true node.\n        new_while = ast.While()\n        new_while.lineno = body_nodes.lineno\n        new_while.test = ast.Name()\n        new_while.test.lineno = body_nodes.lineno\n        new_while.test.id = \"True\"\n        assert hasattr(body_nodes, \"body\")\n        new_while.body = body_nodes.body\n        new_while.orelse = []\n        return new_while\n\n    def is_constant_expr(self, node: ast.AST) -> str | None:\n        \"\"\"Is this a compile-time constant?\"\"\"\n        node_name = node.__class__.__name__\n        if node_name in [\"Constant\", \"NameConstant\", \"Num\"]:\n            return \"Num\"\n        elif isinstance(node, ast.Name):\n            if node.id in [\"True\", \"False\", \"None\", \"__debug__\"]:\n                return \"Name\"\n        return None\n\n    # In the fullness of time, these might be good tests to write:\n    #   while EXPR:\n    #   while False:\n    #   listcomps hidden deep in other expressions\n    #   listcomps hidden in lists: x = [[i for i in range(10)]]\n    #   nested function definitions\n\n    # Exit processing: process_*_exits\n    #\n    # These functions process the four kinds of jump exits: break, continue,\n    # raise, and return.  To figure out where an exit goes, we have to look at\n    # the block stack context.  For example, a break will jump to the nearest\n    # enclosing loop block, or the nearest enclosing finally block, whichever\n    # is nearer.\n\n    def process_break_exits(self, exits: set[ArcStart]) -> None:\n        \"\"\"Add arcs due to jumps from `exits` being breaks.\"\"\"\n        for block in self.nearest_blocks():                         # pragma: always breaks\n            if block.process_break_exits(exits, self.add_arc):\n                break\n\n    def process_continue_exits(self, exits: set[ArcStart]) -> None:\n        \"\"\"Add arcs due to jumps from `exits` being continues.\"\"\"\n        for block in self.nearest_blocks():                         # pragma: always breaks\n            if block.process_continue_exits(exits, self.add_arc):\n                break\n\n    def process_raise_exits(self, exits: set[ArcStart]) -> None:\n        \"\"\"Add arcs due to jumps from `exits` being raises.\"\"\"\n        for block in self.nearest_blocks():\n            if block.process_raise_exits(exits, self.add_arc):\n                break\n\n    def process_return_exits(self, exits: set[ArcStart]) -> None:\n        \"\"\"Add arcs due to jumps from `exits` being returns.\"\"\"\n        for block in self.nearest_blocks():                         # pragma: always breaks\n            if block.process_return_exits(exits, self.add_arc):\n                break\n\n    # Node handlers: _handle__*\n    #\n    # Each handler deals with a specific AST node type, dispatched from\n    # node_exits.  Handlers return the set of exits from that node, and can\n    # also call self.add_arc to record arcs they find.  These functions mirror\n    # the Python semantics of each syntactic construct.  See the docstring\n    # for node_exits to understand the concept of exits from a node.\n    #\n    # Every node type that represents a statement should have a handler, or it\n    # should be listed in OK_TO_DEFAULT.\n\n    def _handle__Break(self, node: ast.Break) -> set[ArcStart]:\n        here = self.line_for_node(node)\n        break_start = ArcStart(here, cause=\"the break on line {lineno} wasn't executed\")\n        self.process_break_exits({break_start})\n        return set()\n\n    def _handle_decorated(self, node: ast.FunctionDef) -> set[ArcStart]:\n        \"\"\"Add arcs for things that can be decorated (classes and functions).\"\"\"\n        main_line: TLineNo = node.lineno\n        last: TLineNo | None = node.lineno\n        decs = node.decorator_list\n        if decs:\n            last = None\n            for dec_node in decs:\n                dec_start = self.line_for_node(dec_node)\n                if last is not None and dec_start != last:  # type: ignore[unreachable]\n                    self.add_arc(last, dec_start)           # type: ignore[unreachable]\n                last = dec_start\n            assert last is not None\n            self.add_arc(last, main_line)\n            last = main_line\n            if env.PYBEHAVIOR.trace_decorator_line_again:\n                for top, bot in zip(decs, decs[1:]):\n                    self.add_arc(self.line_for_node(bot), self.line_for_node(top))\n                self.add_arc(self.line_for_node(decs[0]), main_line)\n                self.add_arc(main_line, self.line_for_node(decs[-1]))\n            # The definition line may have been missed, but we should have it\n            # in `self.statements`.  For some constructs, `line_for_node` is\n            # not what we'd think of as the first line in the statement, so map\n            # it to the first one.\n            if node.body:\n                body_start = self.line_for_node(node.body[0])\n                body_start = self.multiline.get(body_start, body_start)\n        # The body is handled in collect_arcs.\n        assert last is not None\n        return {ArcStart(last)}\n\n    _handle__ClassDef = _handle_decorated\n\n    def _handle__Continue(self, node: ast.Continue) -> set[ArcStart]:\n        here = self.line_for_node(node)\n        continue_start = ArcStart(here, cause=\"the continue on line {lineno} wasn't executed\")\n        self.process_continue_exits({continue_start})\n        return set()\n\n    def _handle__For(self, node: ast.For) -> set[ArcStart]:\n        start = self.line_for_node(node.iter)\n        self.block_stack.append(LoopBlock(start=start))\n        from_start = ArcStart(start, cause=\"the loop on line {lineno} never started\")\n        exits = self.body_exits(node.body, from_start=from_start)\n        # Any exit from the body will go back to the top of the loop.\n        for xit in exits:\n            self.add_arc(xit.lineno, start, xit.cause)\n        my_block = self.block_stack.pop()\n        assert isinstance(my_block, LoopBlock)\n        exits = my_block.break_exits\n        from_start = ArcStart(start, cause=\"the loop on line {lineno} didn't complete\")\n        if node.orelse:\n            else_exits = self.body_exits(node.orelse, from_start=from_start)\n            exits |= else_exits\n        else:\n            # No else clause: exit from the for line.\n            exits.add(from_start)\n        return exits\n\n    _handle__AsyncFor = _handle__For\n\n    _handle__FunctionDef = _handle_decorated\n    _handle__AsyncFunctionDef = _handle_decorated\n\n    def _handle__If(self, node: ast.If) -> set[ArcStart]:\n        start = self.line_for_node(node.test)\n        from_start = ArcStart(start, cause=\"the condition on line {lineno} was never true\")\n        exits = self.body_exits(node.body, from_start=from_start)\n        from_start = ArcStart(start, cause=\"the condition on line {lineno} was always true\")\n        exits |= self.body_exits(node.orelse, from_start=from_start)\n        return exits\n\n    if sys.version_info >= (3, 10):\n        def _handle__Match(self, node: ast.Match) -> set[ArcStart]:\n            start = self.line_for_node(node)\n            last_start = start\n            exits = set()\n            for case in node.cases:\n                case_start = self.line_for_node(case.pattern)\n                self.add_arc(last_start, case_start, \"the pattern on line {lineno} always matched\")\n                from_start = ArcStart(\n                    case_start,\n                    cause=\"the pattern on line {lineno} never matched\",\n                )\n                exits |= self.body_exits(case.body, from_start=from_start)\n                last_start = case_start\n\n            # case is now the last case, check for wildcard match.\n            pattern = case.pattern      # pylint: disable=undefined-loop-variable\n            while isinstance(pattern, ast.MatchOr):\n                pattern = pattern.patterns[-1]\n            had_wildcard = (\n                isinstance(pattern, ast.MatchAs)\n                and pattern.pattern is None\n                and case.guard is None  # pylint: disable=undefined-loop-variable\n            )\n\n            if not had_wildcard:\n                exits.add(\n                    ArcStart(case_start, cause=\"the pattern on line {lineno} always matched\"),\n                )\n            return exits\n\n    def _handle__NodeList(self, node: NodeList) -> set[ArcStart]:\n        start = self.line_for_node(node)\n        exits = self.body_exits(node.body, from_start=ArcStart(start))\n        return exits\n\n    def _handle__Raise(self, node: ast.Raise) -> set[ArcStart]:\n        here = self.line_for_node(node)\n        raise_start = ArcStart(here, cause=\"the raise on line {lineno} wasn't executed\")\n        self.process_raise_exits({raise_start})\n        # `raise` statement jumps away, no exits from here.\n        return set()\n\n    def _handle__Return(self, node: ast.Return) -> set[ArcStart]:\n        here = self.line_for_node(node)\n        return_start = ArcStart(here, cause=\"the return on line {lineno} wasn't executed\")\n        self.process_return_exits({return_start})\n        # `return` statement jumps away, no exits from here.\n        return set()\n\n    def _handle__Try(self, node: ast.Try) -> set[ArcStart]:\n        if node.handlers:\n            handler_start = self.line_for_node(node.handlers[0])\n        else:\n            handler_start = None\n\n        if node.finalbody:\n            final_start = self.line_for_node(node.finalbody[0])\n        else:\n            final_start = None\n\n        # This is true by virtue of Python syntax: have to have either except\n        # or finally, or both.\n        assert handler_start is not None or final_start is not None\n        try_block = TryBlock(handler_start, final_start)\n        self.block_stack.append(try_block)\n\n        start = self.line_for_node(node)\n        exits = self.body_exits(node.body, from_start=ArcStart(start))\n\n        # We're done with the `try` body, so this block no longer handles\n        # exceptions. We keep the block so the `finally` clause can pick up\n        # flows from the handlers and `else` clause.\n        if node.finalbody:\n            try_block.handler_start = None\n            if node.handlers:\n                # If there are `except` clauses, then raises in the try body\n                # will already jump to them.  Start this set over for raises in\n                # `except` and `else`.\n                try_block.raise_from = set()\n        else:\n            self.block_stack.pop()\n\n        handler_exits: set[ArcStart] = set()\n\n        if node.handlers:\n            last_handler_start: TLineNo | None = None\n            for handler_node in node.handlers:\n                handler_start = self.line_for_node(handler_node)\n                if last_handler_start is not None:\n                    self.add_arc(last_handler_start, handler_start)\n                last_handler_start = handler_start\n                from_cause = \"the exception caught by line {lineno} didn't happen\"\n                from_start = ArcStart(handler_start, cause=from_cause)\n                handler_exits |= self.body_exits(handler_node.body, from_start=from_start)\n\n        if node.orelse:\n            exits = self.body_exits(node.orelse, prev_starts=exits)\n\n        exits |= handler_exits\n\n        if node.finalbody:\n            self.block_stack.pop()\n            final_from = (                  # You can get to the `finally` clause from:\n                exits |                         # the exits of the body or `else` clause,\n                try_block.break_from |          # or a `break`,\n                try_block.continue_from |       # or a `continue`,\n                try_block.raise_from |          # or a `raise`,\n                try_block.return_from           # or a `return`.\n            )\n\n            final_exits = self.body_exits(node.finalbody, prev_starts=final_from)\n\n            if try_block.break_from:\n                if env.PYBEHAVIOR.finally_jumps_back:\n                    for break_line in try_block.break_from:\n                        lineno = break_line.lineno\n                        cause = break_line.cause.format(lineno=lineno)\n                        for final_exit in final_exits:\n                            self.add_arc(final_exit.lineno, lineno, cause)\n                    breaks = try_block.break_from\n                else:\n                    breaks = self._combine_finally_starts(try_block.break_from, final_exits)\n                self.process_break_exits(breaks)\n\n            if try_block.continue_from:\n                if env.PYBEHAVIOR.finally_jumps_back:\n                    for continue_line in try_block.continue_from:\n                        lineno = continue_line.lineno\n                        cause = continue_line.cause.format(lineno=lineno)\n                        for final_exit in final_exits:\n                            self.add_arc(final_exit.lineno, lineno, cause)\n                    continues = try_block.continue_from\n                else:\n                    continues = self._combine_finally_starts(try_block.continue_from, final_exits)\n                self.process_continue_exits(continues)\n\n            if try_block.raise_from:\n                self.process_raise_exits(\n                    self._combine_finally_starts(try_block.raise_from, final_exits),\n                )\n\n            if try_block.return_from:\n                if env.PYBEHAVIOR.finally_jumps_back:\n                    for return_line in try_block.return_from:\n                        lineno = return_line.lineno\n                        cause = return_line.cause.format(lineno=lineno)\n                        for final_exit in final_exits:\n                            self.add_arc(final_exit.lineno, lineno, cause)\n                    returns = try_block.return_from\n                else:\n                    returns = self._combine_finally_starts(try_block.return_from, final_exits)\n                self.process_return_exits(returns)\n\n            if exits:\n                # The finally clause's exits are only exits for the try block\n                # as a whole if the try block had some exits to begin with.\n                exits = final_exits\n\n        return exits\n\n    def _combine_finally_starts(self, starts: set[ArcStart], exits: set[ArcStart]) -> set[ArcStart]:\n        \"\"\"Helper for building the cause of `finally` branches.\n\n        \"finally\" clauses might not execute their exits, and the causes could\n        be due to a failure to execute any of the exits in the try block. So\n        we use the causes from `starts` as the causes for `exits`.\n        \"\"\"\n        causes = []\n        for start in sorted(starts):\n            if start.cause:\n                causes.append(start.cause.format(lineno=start.lineno))\n        cause = \" or \".join(causes)\n        exits = {ArcStart(xit.lineno, cause) for xit in exits}\n        return exits\n\n    def _handle__While(self, node: ast.While) -> set[ArcStart]:\n        start = to_top = self.line_for_node(node.test)\n        constant_test = self.is_constant_expr(node.test)\n        top_is_body0 = False\n        if constant_test:\n            top_is_body0 = True\n        if env.PYBEHAVIOR.keep_constant_test:\n            top_is_body0 = False\n        if top_is_body0:\n            to_top = self.line_for_node(node.body[0])\n        self.block_stack.append(LoopBlock(start=to_top))\n        from_start = ArcStart(start, cause=\"the condition on line {lineno} was never true\")\n        exits = self.body_exits(node.body, from_start=from_start)\n        for xit in exits:\n            self.add_arc(xit.lineno, to_top, xit.cause)\n        exits = set()\n        my_block = self.block_stack.pop()\n        assert isinstance(my_block, LoopBlock)\n        exits.update(my_block.break_exits)\n        from_start = ArcStart(start, cause=\"the condition on line {lineno} was always true\")\n        if node.orelse:\n            else_exits = self.body_exits(node.orelse, from_start=from_start)\n            exits |= else_exits\n        else:\n            # No `else` clause: you can exit from the start.\n            if not constant_test:\n                exits.add(from_start)\n        return exits\n\n    def _handle__With(self, node: ast.With) -> set[ArcStart]:\n        start = self.line_for_node(node)\n        if env.PYBEHAVIOR.exit_through_with:\n            self.block_stack.append(WithBlock(start=start))\n        exits = self.body_exits(node.body, from_start=ArcStart(start))\n        if env.PYBEHAVIOR.exit_through_with:\n            with_block = self.block_stack.pop()\n            assert isinstance(with_block, WithBlock)\n            with_exit = {ArcStart(start)}\n            if exits:\n                for xit in exits:\n                    self.add_arc(xit.lineno, start)\n                exits = with_exit\n            if with_block.break_from:\n                self.process_break_exits(\n                    self._combine_finally_starts(with_block.break_from, with_exit),\n                )\n            if with_block.continue_from:\n                self.process_continue_exits(\n                    self._combine_finally_starts(with_block.continue_from, with_exit),\n                )\n            if with_block.return_from:\n                self.process_return_exits(\n                    self._combine_finally_starts(with_block.return_from, with_exit),\n                )\n        return exits\n\n    _handle__AsyncWith = _handle__With\n", "coverage/sqldata.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"SQLite coverage data.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport datetime\nimport functools\nimport glob\nimport itertools\nimport os\nimport random\nimport socket\nimport sqlite3\nimport string\nimport sys\nimport textwrap\nimport threading\nimport zlib\n\nfrom typing import (\n    cast, Any, Callable, Collection, Mapping,\n    Sequence,\n)\n\nfrom coverage.debug import NoDebugging, auto_repr\nfrom coverage.exceptions import CoverageException, DataError\nfrom coverage.misc import file_be_gone, isolate_module\nfrom coverage.numbits import numbits_to_nums, numbits_union, nums_to_numbits\nfrom coverage.sqlitedb import SqliteDb\nfrom coverage.types import AnyCallable, FilePath, TArc, TDebugCtl, TLineNo, TWarnFn\nfrom coverage.version import __version__\n\nos = isolate_module(os)\n\n# If you change the schema: increment the SCHEMA_VERSION and update the\n# docs in docs/dbschema.rst by running \"make cogdoc\".\n\nSCHEMA_VERSION = 7\n\n# Schema versions:\n# 1: Released in 5.0a2\n# 2: Added contexts in 5.0a3.\n# 3: Replaced line table with line_map table.\n# 4: Changed line_map.bitmap to line_map.numbits.\n# 5: Added foreign key declarations.\n# 6: Key-value in meta.\n# 7: line_map -> line_bits\n\nSCHEMA = \"\"\"\\\nCREATE TABLE coverage_schema (\n    -- One row, to record the version of the schema in this db.\n    version integer\n);\n\nCREATE TABLE meta (\n    -- Key-value pairs, to record metadata about the data\n    key text,\n    value text,\n    unique (key)\n    -- Possible keys:\n    --  'has_arcs' boolean      -- Is this data recording branches?\n    --  'sys_argv' text         -- The coverage command line that recorded the data.\n    --  'version' text          -- The version of coverage.py that made the file.\n    --  'when' text             -- Datetime when the file was created.\n);\n\nCREATE TABLE file (\n    -- A row per file measured.\n    id integer primary key,\n    path text,\n    unique (path)\n);\n\nCREATE TABLE context (\n    -- A row per context measured.\n    id integer primary key,\n    context text,\n    unique (context)\n);\n\nCREATE TABLE line_bits (\n    -- If recording lines, a row per context per file executed.\n    -- All of the line numbers for that file/context are in one numbits.\n    file_id integer,            -- foreign key to `file`.\n    context_id integer,         -- foreign key to `context`.\n    numbits blob,               -- see the numbits functions in coverage.numbits\n    foreign key (file_id) references file (id),\n    foreign key (context_id) references context (id),\n    unique (file_id, context_id)\n);\n\nCREATE TABLE arc (\n    -- If recording branches, a row per context per from/to line transition executed.\n    file_id integer,            -- foreign key to `file`.\n    context_id integer,         -- foreign key to `context`.\n    fromno integer,             -- line number jumped from.\n    tono integer,               -- line number jumped to.\n    foreign key (file_id) references file (id),\n    foreign key (context_id) references context (id),\n    unique (file_id, context_id, fromno, tono)\n);\n\nCREATE TABLE tracer (\n    -- A row per file indicating the tracer used for that file.\n    file_id integer primary key,\n    tracer text,\n    foreign key (file_id) references file (id)\n);\n\"\"\"\n\ndef _locked(method: AnyCallable) -> AnyCallable:\n    \"\"\"A decorator for methods that should hold self._lock.\"\"\"\n    @functools.wraps(method)\n    def _wrapped(self: CoverageData, *args: Any, **kwargs: Any) -> Any:\n        if self._debug.should(\"lock\"):\n            self._debug.write(f\"Locking {self._lock!r} for {method.__name__}\")\n        with self._lock:\n            if self._debug.should(\"lock\"):\n                self._debug.write(f\"Locked  {self._lock!r} for {method.__name__}\")\n            return method(self, *args, **kwargs)\n    return _wrapped\n\n\nclass CoverageData:\n    \"\"\"Manages collected coverage data, including file storage.\n\n    This class is the public supported API to the data that coverage.py\n    collects during program execution.  It includes information about what code\n    was executed. It does not include information from the analysis phase, to\n    determine what lines could have been executed, or what lines were not\n    executed.\n\n    .. note::\n\n        The data file is currently a SQLite database file, with a\n        :ref:`documented schema <dbschema>`. The schema is subject to change\n        though, so be careful about querying it directly. Use this API if you\n        can to isolate yourself from changes.\n\n    There are a number of kinds of data that can be collected:\n\n    * **lines**: the line numbers of source lines that were executed.\n      These are always available.\n\n    * **arcs**: pairs of source and destination line numbers for transitions\n      between source lines.  These are only available if branch coverage was\n      used.\n\n    * **file tracer names**: the module names of the file tracer plugins that\n      handled each file in the data.\n\n    Lines, arcs, and file tracer names are stored for each source file. File\n    names in this API are case-sensitive, even on platforms with\n    case-insensitive file systems.\n\n    A data file either stores lines, or arcs, but not both.\n\n    A data file is associated with the data when the :class:`CoverageData`\n    is created, using the parameters `basename`, `suffix`, and `no_disk`. The\n    base name can be queried with :meth:`base_filename`, and the actual file\n    name being used is available from :meth:`data_filename`.\n\n    To read an existing coverage.py data file, use :meth:`read`.  You can then\n    access the line, arc, or file tracer data with :meth:`lines`, :meth:`arcs`,\n    or :meth:`file_tracer`.\n\n    The :meth:`has_arcs` method indicates whether arc data is available.  You\n    can get a set of the files in the data with :meth:`measured_files`.  As\n    with most Python containers, you can determine if there is any data at all\n    by using this object as a boolean value.\n\n    The contexts for each line in a file can be read with\n    :meth:`contexts_by_lineno`.\n\n    To limit querying to certain contexts, use :meth:`set_query_context` or\n    :meth:`set_query_contexts`. These will narrow the focus of subsequent\n    :meth:`lines`, :meth:`arcs`, and :meth:`contexts_by_lineno` calls. The set\n    of all measured context names can be retrieved with\n    :meth:`measured_contexts`.\n\n    Most data files will be created by coverage.py itself, but you can use\n    methods here to create data files if you like.  The :meth:`add_lines`,\n    :meth:`add_arcs`, and :meth:`add_file_tracers` methods add data, in ways\n    that are convenient for coverage.py.\n\n    To record data for contexts, use :meth:`set_context` to set a context to\n    be used for subsequent :meth:`add_lines` and :meth:`add_arcs` calls.\n\n    To add a source file without any measured data, use :meth:`touch_file`,\n    or :meth:`touch_files` for a list of such files.\n\n    Write the data to its file with :meth:`write`.\n\n    You can clear the data in memory with :meth:`erase`.  Data for specific\n    files can be removed from the database with :meth:`purge_files`.\n\n    Two data collections can be combined by using :meth:`update` on one\n    :class:`CoverageData`, passing it the other.\n\n    Data in a :class:`CoverageData` can be serialized and deserialized with\n    :meth:`dumps` and :meth:`loads`.\n\n    The methods used during the coverage.py collection phase\n    (:meth:`add_lines`, :meth:`add_arcs`, :meth:`set_context`, and\n    :meth:`add_file_tracers`) are thread-safe.  Other methods may not be.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        basename: FilePath | None = None,\n        suffix: str | bool | None = None,\n        no_disk: bool = False,\n        warn: TWarnFn | None = None,\n        debug: TDebugCtl | None = None,\n    ) -> None:\n        \"\"\"Create a :class:`CoverageData` object to hold coverage-measured data.\n\n        Arguments:\n            basename (str): the base name of the data file, defaulting to\n                \".coverage\". This can be a path to a file in another directory.\n            suffix (str or bool): has the same meaning as the `data_suffix`\n                argument to :class:`coverage.Coverage`.\n            no_disk (bool): if True, keep all data in memory, and don't\n                write any disk file.\n            warn: a warning callback function, accepting a warning message\n                argument.\n            debug: a `DebugControl` object (optional)\n\n        \"\"\"\n        self._no_disk = no_disk\n        self._basename = os.path.abspath(basename or \".coverage\")\n        self._suffix = suffix\n        self._warn = warn\n        self._debug = debug or NoDebugging()\n\n        self._choose_filename()\n        # Maps filenames to row ids.\n        self._file_map: dict[str, int] = {}\n        # Maps thread ids to SqliteDb objects.\n        self._dbs: dict[int, SqliteDb] = {}\n        self._pid = os.getpid()\n        # Synchronize the operations used during collection.\n        self._lock = threading.RLock()\n\n        # Are we in sync with the data file?\n        self._have_used = False\n\n        self._has_lines = False\n        self._has_arcs = False\n\n        self._current_context: str | None = None\n        self._current_context_id: int | None = None\n        self._query_context_ids: list[int] | None = None\n\n    __repr__ = auto_repr\n\n    def _choose_filename(self) -> None:\n        \"\"\"Set self._filename based on inited attributes.\"\"\"\n        if self._no_disk:\n            self._filename = \":memory:\"\n        else:\n            self._filename = self._basename\n            suffix = filename_suffix(self._suffix)\n            if suffix:\n                self._filename += \".\" + suffix\n\n    def _reset(self) -> None:\n        \"\"\"Reset our attributes.\"\"\"\n        if not self._no_disk:\n            for db in self._dbs.values():\n                db.close()\n            self._dbs = {}\n        self._file_map = {}\n        self._have_used = False\n        self._current_context_id = None\n\n    def _open_db(self) -> None:\n        \"\"\"Open an existing db file, and read its metadata.\"\"\"\n        if self._debug.should(\"dataio\"):\n            self._debug.write(f\"Opening data file {self._filename!r}\")\n        self._dbs[threading.get_ident()] = SqliteDb(self._filename, self._debug)\n        self._read_db()\n\n    def _read_db(self) -> None:\n        \"\"\"Read the metadata from a database so that we are ready to use it.\"\"\"\n        with self._dbs[threading.get_ident()] as db:\n            try:\n                row = db.execute_one(\"select version from coverage_schema\")\n                assert row is not None\n            except Exception as exc:\n                if \"no such table: coverage_schema\" in str(exc):\n                    self._init_db(db)\n                else:\n                    raise DataError(\n                        \"Data file {!r} doesn't seem to be a coverage data file: {}\".format(\n                            self._filename, exc,\n                        ),\n                    ) from exc\n            else:\n                schema_version = row[0]\n                if schema_version != SCHEMA_VERSION:\n                    raise DataError(\n                        \"Couldn't use data file {!r}: wrong schema: {} instead of {}\".format(\n                            self._filename, schema_version, SCHEMA_VERSION,\n                        ),\n                    )\n\n            row = db.execute_one(\"select value from meta where key = 'has_arcs'\")\n            if row is not None:\n                self._has_arcs = bool(int(row[0]))\n                self._has_lines = not self._has_arcs\n\n            with db.execute(\"select id, path from file\") as cur:\n                for file_id, path in cur:\n                    self._file_map[path] = file_id\n\n    def _init_db(self, db: SqliteDb) -> None:\n        \"\"\"Write the initial contents of the database.\"\"\"\n        if self._debug.should(\"dataio\"):\n            self._debug.write(f\"Initing data file {self._filename!r}\")\n        db.executescript(SCHEMA)\n        db.execute_void(\"insert into coverage_schema (version) values (?)\", (SCHEMA_VERSION,))\n\n        # When writing metadata, avoid information that will needlessly change\n        # the hash of the data file, unless we're debugging processes.\n        meta_data = [\n            (\"version\", __version__),\n        ]\n        if self._debug.should(\"process\"):\n            meta_data.extend([\n                (\"sys_argv\", str(getattr(sys, \"argv\", None))),\n                (\"when\", datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")),\n            ])\n        db.executemany_void(\"insert or ignore into meta (key, value) values (?, ?)\", meta_data)\n\n    def _connect(self) -> SqliteDb:\n        \"\"\"Get the SqliteDb object to use.\"\"\"\n        if threading.get_ident() not in self._dbs:\n            self._open_db()\n        return self._dbs[threading.get_ident()]\n\n    def __bool__(self) -> bool:\n        if (threading.get_ident() not in self._dbs and not os.path.exists(self._filename)):\n            return False\n        try:\n            with self._connect() as con:\n                with con.execute(\"select * from file limit 1\") as cur:\n                    return bool(list(cur))\n        except CoverageException:\n            return False\n\n    def dumps(self) -> bytes:\n        \"\"\"Serialize the current data to a byte string.\n\n        The format of the serialized data is not documented. It is only\n        suitable for use with :meth:`loads` in the same version of\n        coverage.py.\n\n        Note that this serialization is not what gets stored in coverage data\n        files.  This method is meant to produce bytes that can be transmitted\n        elsewhere and then deserialized with :meth:`loads`.\n\n        Returns:\n            A byte string of serialized data.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        if self._debug.should(\"dataio\"):\n            self._debug.write(f\"Dumping data from data file {self._filename!r}\")\n        with self._connect() as con:\n            script = con.dump()\n            return b\"z\" + zlib.compress(script.encode(\"utf-8\"))\n\n    def loads(self, data: bytes) -> None:\n        \"\"\"Deserialize data from :meth:`dumps`.\n\n        Use with a newly-created empty :class:`CoverageData` object.  It's\n        undefined what happens if the object already has data in it.\n\n        Note that this is not for reading data from a coverage data file.  It\n        is only for use on data you produced with :meth:`dumps`.\n\n        Arguments:\n            data: A byte string of serialized data produced by :meth:`dumps`.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        if self._debug.should(\"dataio\"):\n            self._debug.write(f\"Loading data into data file {self._filename!r}\")\n        if data[:1] != b\"z\":\n            raise DataError(\n                f\"Unrecognized serialization: {data[:40]!r} (head of {len(data)} bytes)\",\n            )\n        script = zlib.decompress(data[1:]).decode(\"utf-8\")\n        self._dbs[threading.get_ident()] = db = SqliteDb(self._filename, self._debug)\n        with db:\n            db.executescript(script)\n        self._read_db()\n        self._have_used = True\n\n    def _file_id(self, filename: str, add: bool = False) -> int | None:\n        \"\"\"Get the file id for `filename`.\n\n        If filename is not in the database yet, add it if `add` is True.\n        If `add` is not True, return None.\n        \"\"\"\n        if filename not in self._file_map:\n            if add:\n                with self._connect() as con:\n                    self._file_map[filename] = con.execute_for_rowid(\n                        \"insert or replace into file (path) values (?)\",\n                        (filename,),\n                    )\n        return self._file_map.get(filename)\n\n    def _context_id(self, context: str) -> int | None:\n        \"\"\"Get the id for a context.\"\"\"\n        assert context is not None\n        self._start_using()\n        with self._connect() as con:\n            row = con.execute_one(\"select id from context where context = ?\", (context,))\n            if row is not None:\n                return cast(int, row[0])\n            else:\n                return None\n\n    @_locked\n    def set_context(self, context: str | None) -> None:\n        \"\"\"Set the current context for future :meth:`add_lines` etc.\n\n        `context` is a str, the name of the context to use for the next data\n        additions.  The context persists until the next :meth:`set_context`.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        if self._debug.should(\"dataop\"):\n            self._debug.write(f\"Setting coverage context: {context!r}\")\n        self._current_context = context\n        self._current_context_id = None\n\n    def _set_context_id(self) -> None:\n        \"\"\"Use the _current_context to set _current_context_id.\"\"\"\n        context = self._current_context or \"\"\n        context_id = self._context_id(context)\n        if context_id is not None:\n            self._current_context_id = context_id\n        else:\n            with self._connect() as con:\n                self._current_context_id = con.execute_for_rowid(\n                    \"insert into context (context) values (?)\",\n                    (context,),\n                )\n\n    def base_filename(self) -> str:\n        \"\"\"The base filename for storing data.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        return self._basename\n\n    def data_filename(self) -> str:\n        \"\"\"Where is the data stored?\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        return self._filename\n\n    @_locked\n    def add_lines(self, line_data: Mapping[str, Collection[TLineNo]]) -> None:\n        \"\"\"Add measured line data.\n\n        `line_data` is a dictionary mapping file names to iterables of ints::\n\n            { filename: { line1, line2, ... }, ...}\n\n        \"\"\"\n        if self._debug.should(\"dataop\"):\n            self._debug.write(\"Adding lines: %d files, %d lines total\" % (\n                len(line_data), sum(len(lines) for lines in line_data.values()),\n            ))\n            if self._debug.should(\"dataop2\"):\n                for filename, linenos in sorted(line_data.items()):\n                    self._debug.write(f\"  {filename}: {linenos}\")\n        self._start_using()\n        self._choose_lines_or_arcs(lines=True)\n        if not line_data:\n            return\n        with self._connect() as con:\n            self._set_context_id()\n            for filename, linenos in line_data.items():\n                line_bits = nums_to_numbits(linenos)\n                file_id = self._file_id(filename, add=True)\n                query = \"select numbits from line_bits where file_id = ? and context_id = ?\"\n                with con.execute(query, (file_id, self._current_context_id)) as cur:\n                    existing = list(cur)\n                if existing:\n                    line_bits = numbits_union(line_bits, existing[0][0])\n\n                con.execute_void(\n                    \"insert or replace into line_bits \" +\n                    \" (file_id, context_id, numbits) values (?, ?, ?)\",\n                    (file_id, self._current_context_id, line_bits),\n                )\n\n    @_locked\n    def add_arcs(self, arc_data: Mapping[str, Collection[TArc]]) -> None:\n        \"\"\"Add measured arc data.\n\n        `arc_data` is a dictionary mapping file names to iterables of pairs of\n        ints::\n\n            { filename: { (l1,l2), (l1,l2), ... }, ...}\n\n        \"\"\"\n        if self._debug.should(\"dataop\"):\n            self._debug.write(\"Adding arcs: %d files, %d arcs total\" % (\n                len(arc_data), sum(len(arcs) for arcs in arc_data.values()),\n            ))\n            if self._debug.should(\"dataop2\"):\n                for filename, arcs in sorted(arc_data.items()):\n                    self._debug.write(f\"  {filename}: {arcs}\")\n        self._start_using()\n        self._choose_lines_or_arcs(arcs=True)\n        if not arc_data:\n            return\n        with self._connect() as con:\n            self._set_context_id()\n            for filename, arcs in arc_data.items():\n                if not arcs:\n                    continue\n                file_id = self._file_id(filename, add=True)\n                data = [(file_id, self._current_context_id, fromno, tono) for fromno, tono in arcs]\n                con.executemany_void(\n                    \"insert or ignore into arc \" +\n                    \"(file_id, context_id, fromno, tono) values (?, ?, ?, ?)\",\n                    data,\n                )\n\n    def _choose_lines_or_arcs(self, lines: bool = False, arcs: bool = False) -> None:\n        \"\"\"Force the data file to choose between lines and arcs.\"\"\"\n        assert lines or arcs\n        assert not (lines and arcs)\n        if lines and self._has_arcs:\n            if self._debug.should(\"dataop\"):\n                self._debug.write(\"Error: Can't add line measurements to existing branch data\")\n            raise DataError(\"Can't add line measurements to existing branch data\")\n        if arcs and self._has_lines:\n            if self._debug.should(\"dataop\"):\n                self._debug.write(\"Error: Can't add branch measurements to existing line data\")\n            raise DataError(\"Can't add branch measurements to existing line data\")\n        if not self._has_arcs and not self._has_lines:\n            self._has_lines = lines\n            self._has_arcs = arcs\n            with self._connect() as con:\n                con.execute_void(\n                    \"insert or ignore into meta (key, value) values (?, ?)\",\n                    (\"has_arcs\", str(int(arcs))),\n                )\n\n    @_locked\n    def add_file_tracers(self, file_tracers: Mapping[str, str]) -> None:\n        \"\"\"Add per-file plugin information.\n\n        `file_tracers` is { filename: plugin_name, ... }\n\n        \"\"\"\n        if self._debug.should(\"dataop\"):\n            self._debug.write(\"Adding file tracers: %d files\" % (len(file_tracers),))\n        if not file_tracers:\n            return\n        self._start_using()\n        with self._connect() as con:\n            for filename, plugin_name in file_tracers.items():\n                file_id = self._file_id(filename, add=True)\n                existing_plugin = self.file_tracer(filename)\n                if existing_plugin:\n                    if existing_plugin != plugin_name:\n                        raise DataError(\n                            \"Conflicting file tracer name for '{}': {!r} vs {!r}\".format(\n                                filename, existing_plugin, plugin_name,\n                            ),\n                        )\n                elif plugin_name:\n                    con.execute_void(\n                        \"insert into tracer (file_id, tracer) values (?, ?)\",\n                        (file_id, plugin_name),\n                    )\n\n    def touch_file(self, filename: str, plugin_name: str = \"\") -> None:\n        \"\"\"Ensure that `filename` appears in the data, empty if needed.\n\n        `plugin_name` is the name of the plugin responsible for this file.\n        It is used to associate the right filereporter, etc.\n        \"\"\"\n        self.touch_files([filename], plugin_name)\n\n    def touch_files(self, filenames: Collection[str], plugin_name: str | None = None) -> None:\n        \"\"\"Ensure that `filenames` appear in the data, empty if needed.\n\n        `plugin_name` is the name of the plugin responsible for these files.\n        It is used to associate the right filereporter, etc.\n        \"\"\"\n        if self._debug.should(\"dataop\"):\n            self._debug.write(f\"Touching {filenames!r}\")\n        self._start_using()\n        with self._connect(): # Use this to get one transaction.\n            if not self._has_arcs and not self._has_lines:\n                raise DataError(\"Can't touch files in an empty CoverageData\")\n\n            for filename in filenames:\n                self._file_id(filename, add=True)\n                if plugin_name:\n                    # Set the tracer for this file\n                    self.add_file_tracers({filename: plugin_name})\n\n    def purge_files(self, filenames: Collection[str]) -> None:\n        \"\"\"Purge any existing coverage data for the given `filenames`.\n\n        .. versionadded:: 7.2\n\n        \"\"\"\n        if self._debug.should(\"dataop\"):\n            self._debug.write(f\"Purging data for {filenames!r}\")\n        self._start_using()\n        with self._connect() as con:\n\n            if self._has_lines:\n                sql = \"delete from line_bits where file_id=?\"\n            elif self._has_arcs:\n                sql = \"delete from arc where file_id=?\"\n            else:\n                raise DataError(\"Can't purge files in an empty CoverageData\")\n\n            for filename in filenames:\n                file_id = self._file_id(filename, add=False)\n                if file_id is None:\n                    continue\n                con.execute_void(sql, (file_id,))\n\n    def update(\n        self,\n        other_data: CoverageData,\n        map_path: Callable[[str], str] | None = None,\n    ) -> None:\n        \"\"\"Update this data with data from another :class:`CoverageData`.\n\n        If `map_path` is provided, it's a function that re-map paths to match\n        the local machine's.  Note: `map_path` is None only when called\n        directly from the test suite.\n\n        \"\"\"\n        if self._debug.should(\"dataop\"):\n            self._debug.write(\"Updating with data from {!r}\".format(\n                getattr(other_data, \"_filename\", \"???\"),\n            ))\n        if self._has_lines and other_data._has_arcs:\n            raise DataError(\"Can't combine branch coverage data with statement data\")\n        if self._has_arcs and other_data._has_lines:\n            raise DataError(\"Can't combine statement coverage data with branch data\")\n\n        map_path = map_path or (lambda p: p)\n\n        # Force the database we're writing to to exist before we start nesting contexts.\n        self._start_using()\n\n        # Collector for all arcs, lines and tracers\n        other_data.read()\n        with other_data._connect() as con:\n            # Get files data.\n            with con.execute(\"select path from file\") as cur:\n                files = {path: map_path(path) for (path,) in cur}\n\n            # Get contexts data.\n            with con.execute(\"select context from context\") as cur:\n                contexts = [context for (context,) in cur]\n\n            # Get arc data.\n            with con.execute(\n                \"select file.path, context.context, arc.fromno, arc.tono \" +\n                \"from arc \" +\n                \"inner join file on file.id = arc.file_id \" +\n                \"inner join context on context.id = arc.context_id\",\n            ) as cur:\n                arcs = [\n                    (files[path], context, fromno, tono)\n                    for (path, context, fromno, tono) in cur\n                ]\n\n            # Get line data.\n            with con.execute(\n                \"select file.path, context.context, line_bits.numbits \" +\n                \"from line_bits \" +\n                \"inner join file on file.id = line_bits.file_id \" +\n                \"inner join context on context.id = line_bits.context_id\",\n            ) as cur:\n                lines: dict[tuple[str, str], bytes] = {}\n                for path, context, numbits in cur:\n                    key = (files[path], context)\n                    if key in lines:\n                        numbits = numbits_union(lines[key], numbits)\n                    lines[key] = numbits\n\n            # Get tracer data.\n            with con.execute(\n                \"select file.path, tracer \" +\n                \"from tracer \" +\n                \"inner join file on file.id = tracer.file_id\",\n            ) as cur:\n                tracers = {files[path]: tracer for (path, tracer) in cur}\n\n        with self._connect() as con:\n            assert con.con is not None\n            con.con.isolation_level = \"IMMEDIATE\"\n\n            # Get all tracers in the DB. Files not in the tracers are assumed\n            # to have an empty string tracer. Since Sqlite does not support\n            # full outer joins, we have to make two queries to fill the\n            # dictionary.\n            with con.execute(\"select path from file\") as cur:\n                this_tracers = {path: \"\" for path, in cur}\n            with con.execute(\n                \"select file.path, tracer from tracer \" +\n                \"inner join file on file.id = tracer.file_id\",\n            ) as cur:\n                this_tracers.update({\n                    map_path(path): tracer\n                    for path, tracer in cur\n                })\n\n            # Create all file and context rows in the DB.\n            con.executemany_void(\n                \"insert or ignore into file (path) values (?)\",\n                ((file,) for file in files.values()),\n            )\n            with con.execute(\"select id, path from file\") as cur:\n                file_ids = {path: id for id, path in cur}\n            self._file_map.update(file_ids)\n            con.executemany_void(\n                \"insert or ignore into context (context) values (?)\",\n                ((context,) for context in contexts),\n            )\n            with con.execute(\"select id, context from context\") as cur:\n                context_ids = {context: id for id, context in cur}\n\n            # Prepare tracers and fail, if a conflict is found.\n            # tracer_paths is used to ensure consistency over the tracer data\n            # and tracer_map tracks the tracers to be inserted.\n            tracer_map = {}\n            for path in files.values():\n                this_tracer = this_tracers.get(path)\n                other_tracer = tracers.get(path, \"\")\n                # If there is no tracer, there is always the None tracer.\n                if this_tracer is not None and this_tracer != other_tracer:\n                    raise DataError(\n                        \"Conflicting file tracer name for '{}': {!r} vs {!r}\".format(\n                            path, this_tracer, other_tracer,\n                        ),\n                    )\n                tracer_map[path] = other_tracer\n\n            # Prepare arc and line rows to be inserted by converting the file\n            # and context strings with integer ids. Then use the efficient\n            # `executemany()` to insert all rows at once.\n\n            if arcs:\n                self._choose_lines_or_arcs(arcs=True)\n\n                arc_rows = (\n                    (file_ids[file], context_ids[context], fromno, tono)\n                    for file, context, fromno, tono in arcs\n                )\n\n                # Write the combined data.\n                con.executemany_void(\n                    \"insert or ignore into arc \" +\n                    \"(file_id, context_id, fromno, tono) values (?, ?, ?, ?)\",\n                    arc_rows,\n                )\n\n            if lines:\n                self._choose_lines_or_arcs(lines=True)\n\n                for (file, context), numbits in lines.items():\n                    with con.execute(\n                        \"select numbits from line_bits where file_id = ? and context_id = ?\",\n                        (file_ids[file], context_ids[context]),\n                    ) as cur:\n                        existing = list(cur)\n                    if existing:\n                        lines[(file, context)] = numbits_union(numbits, existing[0][0])\n\n                con.executemany_void(\n                    \"insert or replace into line_bits \" +\n                    \"(file_id, context_id, numbits) values (?, ?, ?)\",\n                    [\n                        (file_ids[file], context_ids[context], numbits)\n                        for (file, context), numbits in lines.items()\n                    ],\n                )\n\n            con.executemany_void(\n                \"insert or ignore into tracer (file_id, tracer) values (?, ?)\",\n                ((file_ids[filename], tracer) for filename, tracer in tracer_map.items()),\n            )\n\n        if not self._no_disk:\n            # Update all internal cache data.\n            self._reset()\n            self.read()\n\n    def erase(self, parallel: bool = False) -> None:\n        \"\"\"Erase the data in this object.\n\n        If `parallel` is true, then also deletes data files created from the\n        basename by parallel-mode.\n\n        \"\"\"\n        self._reset()\n        if self._no_disk:\n            return\n        if self._debug.should(\"dataio\"):\n            self._debug.write(f\"Erasing data file {self._filename!r}\")\n        file_be_gone(self._filename)\n        if parallel:\n            data_dir, local = os.path.split(self._filename)\n            local_abs_path = os.path.join(os.path.abspath(data_dir), local)\n            pattern = glob.escape(local_abs_path) + \".*\"\n            for filename in glob.glob(pattern):\n                if self._debug.should(\"dataio\"):\n                    self._debug.write(f\"Erasing parallel data file {filename!r}\")\n                file_be_gone(filename)\n\n    def read(self) -> None:\n        \"\"\"Start using an existing data file.\"\"\"\n        if os.path.exists(self._filename):\n            with self._connect():\n                self._have_used = True\n\n    def write(self) -> None:\n        \"\"\"Ensure the data is written to the data file.\"\"\"\n        pass\n\n    def _start_using(self) -> None:\n        \"\"\"Call this before using the database at all.\"\"\"\n        if self._pid != os.getpid():\n            # Looks like we forked! Have to start a new data file.\n            self._reset()\n            self._choose_filename()\n            self._pid = os.getpid()\n        if not self._have_used:\n            self.erase()\n        self._have_used = True\n\n    def has_arcs(self) -> bool:\n        \"\"\"Does the database have arcs (True) or lines (False).\"\"\"\n        return bool(self._has_arcs)\n\n    def measured_files(self) -> set[str]:\n        \"\"\"A set of all files that have been measured.\n\n        Note that a file may be mentioned as measured even though no lines or\n        arcs for that file are present in the data.\n\n        \"\"\"\n        return set(self._file_map)\n\n    def measured_contexts(self) -> set[str]:\n        \"\"\"A set of all contexts that have been measured.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        self._start_using()\n        with self._connect() as con:\n            with con.execute(\"select distinct(context) from context\") as cur:\n                contexts = {row[0] for row in cur}\n        return contexts\n\n    def file_tracer(self, filename: str) -> str | None:\n        \"\"\"Get the plugin name of the file tracer for a file.\n\n        Returns the name of the plugin that handles this file.  If the file was\n        measured, but didn't use a plugin, then \"\" is returned.  If the file\n        was not measured, then None is returned.\n\n        \"\"\"\n        self._start_using()\n        with self._connect() as con:\n            file_id = self._file_id(filename)\n            if file_id is None:\n                return None\n            row = con.execute_one(\"select tracer from tracer where file_id = ?\", (file_id,))\n            if row is not None:\n                return row[0] or \"\"\n            return \"\"   # File was measured, but no tracer associated.\n\n    def set_query_context(self, context: str) -> None:\n        \"\"\"Set a context for subsequent querying.\n\n        The next :meth:`lines`, :meth:`arcs`, or :meth:`contexts_by_lineno`\n        calls will be limited to only one context.  `context` is a string which\n        must match a context exactly.  If it does not, no exception is raised,\n        but queries will return no data.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        self._start_using()\n        with self._connect() as con:\n            with con.execute(\"select id from context where context = ?\", (context,)) as cur:\n                self._query_context_ids = [row[0] for row in cur.fetchall()]\n\n    def set_query_contexts(self, contexts: Sequence[str] | None) -> None:\n        \"\"\"Set a number of contexts for subsequent querying.\n\n        The next :meth:`lines`, :meth:`arcs`, or :meth:`contexts_by_lineno`\n        calls will be limited to the specified contexts.  `contexts` is a list\n        of Python regular expressions.  Contexts will be matched using\n        :func:`re.search <python:re.search>`.  Data will be included in query\n        results if they are part of any of the contexts matched.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        self._start_using()\n        if contexts:\n            with self._connect() as con:\n                context_clause = \" or \".join([\"context regexp ?\"] * len(contexts))\n                with con.execute(\"select id from context where \" + context_clause, contexts) as cur:\n                    self._query_context_ids = [row[0] for row in cur.fetchall()]\n        else:\n            self._query_context_ids = None\n\n    def lines(self, filename: str) -> list[TLineNo] | None:\n        \"\"\"Get the list of lines executed for a source file.\n\n        If the file was not measured, returns None.  A file might be measured,\n        and have no lines executed, in which case an empty list is returned.\n\n        If the file was executed, returns a list of integers, the line numbers\n        executed in the file. The list is in no particular order.\n\n        \"\"\"\n        self._start_using()\n        if self.has_arcs():\n            arcs = self.arcs(filename)\n            if arcs is not None:\n                all_lines = itertools.chain.from_iterable(arcs)\n                return list({l for l in all_lines if l > 0})\n\n        with self._connect() as con:\n            file_id = self._file_id(filename)\n            if file_id is None:\n                return None\n            else:\n                query = \"select numbits from line_bits where file_id = ?\"\n                data = [file_id]\n                if self._query_context_ids is not None:\n                    ids_array = \", \".join(\"?\" * len(self._query_context_ids))\n                    query += \" and context_id in (\" + ids_array + \")\"\n                    data += self._query_context_ids\n                with con.execute(query, data) as cur:\n                    bitmaps = list(cur)\n                nums = set()\n                for row in bitmaps:\n                    nums.update(numbits_to_nums(row[0]))\n                return list(nums)\n\n    def arcs(self, filename: str) -> list[TArc] | None:\n        \"\"\"Get the list of arcs executed for a file.\n\n        If the file was not measured, returns None.  A file might be measured,\n        and have no arcs executed, in which case an empty list is returned.\n\n        If the file was executed, returns a list of 2-tuples of integers. Each\n        pair is a starting line number and an ending line number for a\n        transition from one line to another. The list is in no particular\n        order.\n\n        Negative numbers have special meaning.  If the starting line number is\n        -N, it represents an entry to the code object that starts at line N.\n        If the ending ling number is -N, it's an exit from the code object that\n        starts at line N.\n\n        \"\"\"\n        self._start_using()\n        with self._connect() as con:\n            file_id = self._file_id(filename)\n            if file_id is None:\n                return None\n            else:\n                query = \"select distinct fromno, tono from arc where file_id = ?\"\n                data = [file_id]\n                if self._query_context_ids is not None:\n                    ids_array = \", \".join(\"?\" * len(self._query_context_ids))\n                    query += \" and context_id in (\" + ids_array + \")\"\n                    data += self._query_context_ids\n                with con.execute(query, data) as cur:\n                    return list(cur)\n\n    def contexts_by_lineno(self, filename: str) -> dict[TLineNo, list[str]]:\n        \"\"\"Get the contexts for each line in a file.\n\n        Returns:\n            A dict mapping line numbers to a list of context names.\n\n        .. versionadded:: 5.0\n\n        \"\"\"\n        self._start_using()\n        with self._connect() as con:\n            file_id = self._file_id(filename)\n            if file_id is None:\n                return {}\n\n            lineno_contexts_map = collections.defaultdict(set)\n            if self.has_arcs():\n                query = (\n                    \"select arc.fromno, arc.tono, context.context \" +\n                    \"from arc, context \" +\n                    \"where arc.file_id = ? and arc.context_id = context.id\"\n                )\n                data = [file_id]\n                if self._query_context_ids is not None:\n                    ids_array = \", \".join(\"?\" * len(self._query_context_ids))\n                    query += \" and arc.context_id in (\" + ids_array + \")\"\n                    data += self._query_context_ids\n                with con.execute(query, data) as cur:\n                    for fromno, tono, context in cur:\n                        if fromno > 0:\n                            lineno_contexts_map[fromno].add(context)\n                        if tono > 0:\n                            lineno_contexts_map[tono].add(context)\n            else:\n                query = (\n                    \"select l.numbits, c.context from line_bits l, context c \" +\n                    \"where l.context_id = c.id \" +\n                    \"and file_id = ?\"\n                )\n                data = [file_id]\n                if self._query_context_ids is not None:\n                    ids_array = \", \".join(\"?\" * len(self._query_context_ids))\n                    query += \" and l.context_id in (\" + ids_array + \")\"\n                    data += self._query_context_ids\n                with con.execute(query, data) as cur:\n                    for numbits, context in cur:\n                        for lineno in numbits_to_nums(numbits):\n                            lineno_contexts_map[lineno].add(context)\n\n        return {lineno: list(contexts) for lineno, contexts in lineno_contexts_map.items()}\n\n    @classmethod\n    def sys_info(cls) -> list[tuple[str, Any]]:\n        \"\"\"Our information for `Coverage.sys_info`.\n\n        Returns a list of (key, value) pairs.\n\n        \"\"\"\n        with SqliteDb(\":memory:\", debug=NoDebugging()) as db:\n            with db.execute(\"pragma temp_store\") as cur:\n                temp_store = [row[0] for row in cur]\n            with db.execute(\"pragma compile_options\") as cur:\n                copts = [row[0] for row in cur]\n            copts = textwrap.wrap(\", \".join(copts), width=75)\n\n        return [\n            (\"sqlite3_sqlite_version\", sqlite3.sqlite_version),\n            (\"sqlite3_temp_store\", temp_store),\n            (\"sqlite3_compile_options\", copts),\n        ]\n\n\ndef filename_suffix(suffix: str | bool | None) -> str | None:\n    \"\"\"Compute a filename suffix for a data file.\n\n    If `suffix` is a string or None, simply return it. If `suffix` is True,\n    then build a suffix incorporating the hostname, process id, and a random\n    number.\n\n    Returns a string or None.\n\n    \"\"\"\n    if suffix is True:\n        # If data_suffix was a simple true value, then make a suffix with\n        # plenty of distinguishing information.  We do this here in\n        # `save()` at the last minute so that the pid will be correct even\n        # if the process forks.\n        die = random.Random(os.urandom(8))\n        letters = string.ascii_uppercase + string.ascii_lowercase\n        rolls = \"\".join(die.choice(letters) for _ in range(6))\n        suffix = f\"{socket.gethostname()}.{os.getpid()}.X{rolls}x\"\n    elif suffix is False:\n        suffix = None\n    return suffix\n", "coverage/report_core.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Reporter foundation for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\n\nfrom typing import (\n    Callable, Iterable, Iterator, IO, Protocol, TYPE_CHECKING,\n)\n\nfrom coverage.exceptions import NoDataError, NotPython\nfrom coverage.files import prep_patterns, GlobMatcher\nfrom coverage.misc import ensure_dir_for_file, file_be_gone\nfrom coverage.plugin import FileReporter\nfrom coverage.results import Analysis\nfrom coverage.types import TMorf\n\nif TYPE_CHECKING:\n    from coverage import Coverage\n\n\nclass Reporter(Protocol):\n    \"\"\"What we expect of reporters.\"\"\"\n\n    report_type: str\n\n    def report(self, morfs: Iterable[TMorf] | None, outfile: IO[str]) -> float:\n        \"\"\"Generate a report of `morfs`, written to `outfile`.\"\"\"\n\n\ndef render_report(\n    output_path: str,\n    reporter: Reporter,\n    morfs: Iterable[TMorf] | None,\n    msgfn: Callable[[str], None],\n) -> float:\n    \"\"\"Run a one-file report generator, managing the output file.\n\n    This function ensures the output file is ready to be written to. Then writes\n    the report to it. Then closes the file and cleans up.\n\n    \"\"\"\n    file_to_close = None\n    delete_file = False\n\n    if output_path == \"-\":\n        outfile = sys.stdout\n    else:\n        # Ensure that the output directory is created; done here because this\n        # report pre-opens the output file.  HtmlReporter does this on its own\n        # because its task is more complex, being multiple files.\n        ensure_dir_for_file(output_path)\n        outfile = open(output_path, \"w\", encoding=\"utf-8\")\n        file_to_close = outfile\n        delete_file = True\n\n    try:\n        ret = reporter.report(morfs, outfile=outfile)\n        if file_to_close is not None:\n            msgfn(f\"Wrote {reporter.report_type} to {output_path}\")\n        delete_file = False\n        return ret\n    finally:\n        if file_to_close is not None:\n            file_to_close.close()\n            if delete_file:\n                file_be_gone(output_path)           # pragma: part covered (doesn't return)\n\n\ndef get_analysis_to_report(\n    coverage: Coverage,\n    morfs: Iterable[TMorf] | None,\n) -> Iterator[tuple[FileReporter, Analysis]]:\n    \"\"\"Get the files to report on.\n\n    For each morf in `morfs`, if it should be reported on (based on the omit\n    and include configuration options), yield a pair, the `FileReporter` and\n    `Analysis` for the morf.\n\n    \"\"\"\n    fr_morfs = coverage._get_file_reporters(morfs)\n    config = coverage.config\n\n    if config.report_include:\n        matcher = GlobMatcher(prep_patterns(config.report_include), \"report_include\")\n        fr_morfs = [(fr, morf) for (fr, morf) in fr_morfs if matcher.match(fr.filename)]\n\n    if config.report_omit:\n        matcher = GlobMatcher(prep_patterns(config.report_omit), \"report_omit\")\n        fr_morfs = [(fr, morf) for (fr, morf) in fr_morfs if not matcher.match(fr.filename)]\n\n    if not fr_morfs:\n        raise NoDataError(\"No data to report.\")\n\n    for fr, morf in sorted(fr_morfs):\n        try:\n            analysis = coverage._analyze(morf)\n        except NotPython:\n            # Only report errors for .py files, and only if we didn't\n            # explicitly suppress those errors.\n            # NotPython is only raised by PythonFileReporter, which has a\n            # should_be_python() method.\n            if fr.should_be_python():       # type: ignore[attr-defined]\n                if config.ignore_errors:\n                    msg = f\"Couldn't parse Python file '{fr.filename}'\"\n                    coverage._warn(msg, slug=\"couldnt-parse\")\n                else:\n                    raise\n        except Exception as exc:\n            if config.ignore_errors:\n                msg = f\"Couldn't parse '{fr.filename}': {exc}\".rstrip()\n                coverage._warn(msg, slug=\"couldnt-parse\")\n            else:\n                raise\n        else:\n            yield (fr, analysis)\n", "coverage/phystokens.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Better tokenizing for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport ast\nimport io\nimport keyword\nimport re\nimport sys\nimport token\nimport tokenize\n\nfrom typing import Iterable\n\nfrom coverage import env\nfrom coverage.types import TLineNo, TSourceTokenLines\n\n\nTokenInfos = Iterable[tokenize.TokenInfo]\n\n\ndef _phys_tokens(toks: TokenInfos) -> TokenInfos:\n    \"\"\"Return all physical tokens, even line continuations.\n\n    tokenize.generate_tokens() doesn't return a token for the backslash that\n    continues lines.  This wrapper provides those tokens so that we can\n    re-create a faithful representation of the original source.\n\n    Returns the same values as generate_tokens()\n\n    \"\"\"\n    last_line: str | None = None\n    last_lineno = -1\n    last_ttext: str = \"\"\n    for ttype, ttext, (slineno, scol), (elineno, ecol), ltext in toks:\n        if last_lineno != elineno:\n            if last_line and last_line.endswith(\"\\\\\\n\"):\n                # We are at the beginning of a new line, and the last line\n                # ended with a backslash.  We probably have to inject a\n                # backslash token into the stream. Unfortunately, there's more\n                # to figure out.  This code::\n                #\n                #   usage = \"\"\"\\\n                #   HEY THERE\n                #   \"\"\"\n                #\n                # triggers this condition, but the token text is::\n                #\n                #   '\"\"\"\\\\\\nHEY THERE\\n\"\"\"'\n                #\n                # so we need to figure out if the backslash is already in the\n                # string token or not.\n                inject_backslash = True\n                if last_ttext.endswith(\"\\\\\"):\n                    inject_backslash = False\n                elif ttype == token.STRING:\n                    if \"\\n\" in ttext and ttext.split(\"\\n\", 1)[0][-1] == \"\\\\\":\n                        # It's a multi-line string and the first line ends with\n                        # a backslash, so we don't need to inject another.\n                        inject_backslash = False\n                if inject_backslash:\n                    # Figure out what column the backslash is in.\n                    ccol = len(last_line.split(\"\\n\")[-2]) - 1\n                    # Yield the token, with a fake token type.\n                    yield tokenize.TokenInfo(\n                        99999, \"\\\\\\n\",\n                        (slineno, ccol), (slineno, ccol+2),\n                        last_line,\n                    )\n            last_line = ltext\n        if ttype not in (tokenize.NEWLINE, tokenize.NL):\n            last_ttext = ttext\n        yield tokenize.TokenInfo(ttype, ttext, (slineno, scol), (elineno, ecol), ltext)\n        last_lineno = elineno\n\n\ndef find_soft_key_lines(source: str) -> set[TLineNo]:\n    \"\"\"Helper for finding lines with soft keywords, like match/case lines.\"\"\"\n    soft_key_lines: set[TLineNo] = set()\n\n    for node in ast.walk(ast.parse(source)):\n        if sys.version_info >= (3, 10) and isinstance(node, ast.Match):\n            soft_key_lines.add(node.lineno)\n            for case in node.cases:\n                soft_key_lines.add(case.pattern.lineno)\n        elif sys.version_info >= (3, 12) and isinstance(node, ast.TypeAlias):\n            soft_key_lines.add(node.lineno)\n\n    return soft_key_lines\n\n\ndef source_token_lines(source: str) -> TSourceTokenLines:\n    \"\"\"Generate a series of lines, one for each line in `source`.\n\n    Each line is a list of pairs, each pair is a token::\n\n        [('key', 'def'), ('ws', ' '), ('nam', 'hello'), ('op', '('), ... ]\n\n    Each pair has a token class, and the token text.\n\n    If you concatenate all the token texts, and then join them with newlines,\n    you should have your original `source` back, with two differences:\n    trailing white space is not preserved, and a final line with no newline\n    is indistinguishable from a final line with a newline.\n\n    \"\"\"\n\n    ws_tokens = {token.INDENT, token.DEDENT, token.NEWLINE, tokenize.NL}\n    line: list[tuple[str, str]] = []\n    col = 0\n\n    source = source.expandtabs(8).replace(\"\\r\\n\", \"\\n\")\n    tokgen = generate_tokens(source)\n\n    if env.PYBEHAVIOR.soft_keywords:\n        soft_key_lines = find_soft_key_lines(source)\n    else:\n        soft_key_lines = set()\n\n    for ttype, ttext, (sline, scol), (_, ecol), _ in _phys_tokens(tokgen):\n        mark_start = True\n        for part in re.split(\"(\\n)\", ttext):\n            if part == \"\\n\":\n                yield line\n                line = []\n                col = 0\n                mark_end = False\n            elif part == \"\":\n                mark_end = False\n            elif ttype in ws_tokens:\n                mark_end = False\n            else:\n                if mark_start and scol > col:\n                    line.append((\"ws\", \" \" * (scol - col)))\n                    mark_start = False\n                tok_class = tokenize.tok_name.get(ttype, \"xx\").lower()[:3]\n                if ttype == token.NAME:\n                    if keyword.iskeyword(ttext):\n                        # Hard keywords are always keywords.\n                        tok_class = \"key\"\n                    elif sys.version_info >= (3, 10):   # PYVERSIONS\n                        # Need the version_info check to keep mypy from borking\n                        # on issoftkeyword here.\n                        if env.PYBEHAVIOR.soft_keywords and keyword.issoftkeyword(ttext):\n                            # Soft keywords appear at the start of their line.\n                            if len(line) == 0:\n                                is_start_of_line = True\n                            elif (len(line) == 1) and line[0][0] == \"ws\":\n                                is_start_of_line = True\n                            else:\n                                is_start_of_line = False\n                            if is_start_of_line and sline in soft_key_lines:\n                                tok_class = \"key\"\n                line.append((tok_class, part))\n                mark_end = True\n            scol = 0\n        if mark_end:\n            col = ecol\n\n    if line:\n        yield line\n\n\ndef generate_tokens(text: str) -> TokenInfos:\n    \"\"\"A helper around `tokenize.generate_tokens`.\n\n    Originally this was used to cache the results, but it didn't seem to make\n    reporting go faster, and caused issues with using too much memory.\n\n    \"\"\"\n    readline = io.StringIO(text).readline\n    return tokenize.generate_tokens(readline)\n\n\ndef source_encoding(source: bytes) -> str:\n    \"\"\"Determine the encoding for `source`, according to PEP 263.\n\n    `source` is a byte string: the text of the program.\n\n    Returns a string, the name of the encoding.\n\n    \"\"\"\n    readline = iter(source.splitlines(True)).__next__\n    return tokenize.detect_encoding(readline)[0]\n", "coverage/collector.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Raw data collector for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport contextlib\nimport functools\nimport os\nimport sys\n\nfrom types import FrameType\nfrom typing import (\n    cast, Any, Callable, Dict, List, Mapping, Set, TypeVar,\n)\n\nfrom coverage import env\nfrom coverage.config import CoverageConfig\nfrom coverage.data import CoverageData\nfrom coverage.debug import short_stack\nfrom coverage.disposition import FileDisposition\nfrom coverage.exceptions import ConfigError\nfrom coverage.misc import human_sorted_items, isolate_module\nfrom coverage.plugin import CoveragePlugin\nfrom coverage.pytracer import PyTracer\nfrom coverage.sysmon import SysMonitor\nfrom coverage.types import (\n    TArc, TFileDisposition, TTraceData, TTraceFn, TracerCore, TWarnFn,\n)\n\nos = isolate_module(os)\n\n\ntry:\n    # Use the C extension code when we can, for speed.\n    from coverage.tracer import CTracer, CFileDisposition\n    HAS_CTRACER = True\nexcept ImportError:\n    # Couldn't import the C extension, maybe it isn't built.\n    if os.getenv(\"COVERAGE_CORE\") == \"ctrace\":      # pragma: part covered\n        # During testing, we use the COVERAGE_CORE environment variable\n        # to indicate that we've fiddled with the environment to test this\n        # fallback code.  If we thought we had a C tracer, but couldn't import\n        # it, then exit quickly and clearly instead of dribbling confusing\n        # errors. I'm using sys.exit here instead of an exception because an\n        # exception here causes all sorts of other noise in unittest.\n        sys.stderr.write(\"*** COVERAGE_CORE is 'ctrace' but can't import CTracer!\\n\")\n        sys.exit(1)\n    HAS_CTRACER = False\n\nT = TypeVar(\"T\")\n\n\nclass Collector:\n    \"\"\"Collects trace data.\n\n    Creates a Tracer object for each thread, since they track stack\n    information.  Each Tracer points to the same shared data, contributing\n    traced data points.\n\n    When the Collector is started, it creates a Tracer for the current thread,\n    and installs a function to create Tracers for each new thread started.\n    When the Collector is stopped, all active Tracers are stopped.\n\n    Threads started while the Collector is stopped will never have Tracers\n    associated with them.\n\n    \"\"\"\n\n    # The stack of active Collectors.  Collectors are added here when started,\n    # and popped when stopped.  Collectors on the stack are paused when not\n    # the top, and resumed when they become the top again.\n    _collectors: list[Collector] = []\n\n    # The concurrency settings we support here.\n    LIGHT_THREADS = {\"greenlet\", \"eventlet\", \"gevent\"}\n\n    def __init__(\n        self,\n        should_trace: Callable[[str, FrameType], TFileDisposition],\n        check_include: Callable[[str, FrameType], bool],\n        should_start_context: Callable[[FrameType], str | None] | None,\n        file_mapper: Callable[[str], str],\n        timid: bool,\n        branch: bool,\n        warn: TWarnFn,\n        concurrency: list[str],\n        metacov: bool,\n    ) -> None:\n        \"\"\"Create a collector.\n\n        `should_trace` is a function, taking a file name and a frame, and\n        returning a `coverage.FileDisposition object`.\n\n        `check_include` is a function taking a file name and a frame. It returns\n        a boolean: True if the file should be traced, False if not.\n\n        `should_start_context` is a function taking a frame, and returning a\n        string. If the frame should be the start of a new context, the string\n        is the new context. If the frame should not be the start of a new\n        context, return None.\n\n        `file_mapper` is a function taking a filename, and returning a Unicode\n        filename.  The result is the name that will be recorded in the data\n        file.\n\n        If `timid` is true, then a slower simpler trace function will be\n        used.  This is important for some environments where manipulation of\n        tracing functions make the faster more sophisticated trace function not\n        operate properly.\n\n        If `branch` is true, then branches will be measured.  This involves\n        collecting data on which statements followed each other (arcs).  Use\n        `get_arc_data` to get the arc data.\n\n        `warn` is a warning function, taking a single string message argument\n        and an optional slug argument which will be a string or None, to be\n        used if a warning needs to be issued.\n\n        `concurrency` is a list of strings indicating the concurrency libraries\n        in use.  Valid values are \"greenlet\", \"eventlet\", \"gevent\", or \"thread\"\n        (the default).  \"thread\" can be combined with one of the other three.\n        Other values are ignored.\n\n        \"\"\"\n        self.should_trace = should_trace\n        self.check_include = check_include\n        self.should_start_context = should_start_context\n        self.file_mapper = file_mapper\n        self.branch = branch\n        self.warn = warn\n        self.concurrency = concurrency\n        assert isinstance(self.concurrency, list), f\"Expected a list: {self.concurrency!r}\"\n\n        self.pid = os.getpid()\n\n        self.covdata: CoverageData\n        self.threading = None\n        self.static_context: str | None = None\n\n        self.origin = short_stack()\n\n        self.concur_id_func = None\n\n        self._trace_class: type[TracerCore]\n        self.file_disposition_class: type[TFileDisposition]\n\n        core: str | None\n        if timid:\n            core = \"pytrace\"\n        else:\n            core = os.getenv(\"COVERAGE_CORE\")\n\n            if core == \"sysmon\" and not env.PYBEHAVIOR.pep669:\n                self.warn(\"sys.monitoring isn't available, using default core\", slug=\"no-sysmon\")\n                core = None\n\n            if not core:\n                # Once we're comfortable with sysmon as a default:\n                # if env.PYBEHAVIOR.pep669 and self.should_start_context is None:\n                #     core = \"sysmon\"\n                if HAS_CTRACER:\n                    core = \"ctrace\"\n                else:\n                    core = \"pytrace\"\n\n        if core == \"sysmon\":\n            self._trace_class = SysMonitor\n            self._core_kwargs = {\"tool_id\": 3 if metacov else 1}\n            self.file_disposition_class = FileDisposition\n            self.supports_plugins = False\n            self.packed_arcs = False\n            self.systrace = False\n        elif core == \"ctrace\":\n            self._trace_class = CTracer\n            self._core_kwargs = {}\n            self.file_disposition_class = CFileDisposition\n            self.supports_plugins = True\n            self.packed_arcs = True\n            self.systrace = True\n        elif core == \"pytrace\":\n            self._trace_class = PyTracer\n            self._core_kwargs = {}\n            self.file_disposition_class = FileDisposition\n            self.supports_plugins = False\n            self.packed_arcs = False\n            self.systrace = True\n        else:\n            raise ConfigError(f\"Unknown core value: {core!r}\")\n\n        # We can handle a few concurrency options here, but only one at a time.\n        concurrencies = set(self.concurrency)\n        unknown = concurrencies - CoverageConfig.CONCURRENCY_CHOICES\n        if unknown:\n            show = \", \".join(sorted(unknown))\n            raise ConfigError(f\"Unknown concurrency choices: {show}\")\n        light_threads = concurrencies & self.LIGHT_THREADS\n        if len(light_threads) > 1:\n            show = \", \".join(sorted(light_threads))\n            raise ConfigError(f\"Conflicting concurrency settings: {show}\")\n        do_threading = False\n\n        tried = \"nothing\"  # to satisfy pylint\n        try:\n            if \"greenlet\" in concurrencies:\n                tried = \"greenlet\"\n                import greenlet\n                self.concur_id_func = greenlet.getcurrent\n            elif \"eventlet\" in concurrencies:\n                tried = \"eventlet\"\n                import eventlet.greenthread     # pylint: disable=import-error,useless-suppression\n                self.concur_id_func = eventlet.greenthread.getcurrent\n            elif \"gevent\" in concurrencies:\n                tried = \"gevent\"\n                import gevent                   # pylint: disable=import-error,useless-suppression\n                self.concur_id_func = gevent.getcurrent\n\n            if \"thread\" in concurrencies:\n                do_threading = True\n        except ImportError as ex:\n            msg = f\"Couldn't trace with concurrency={tried}, the module isn't installed.\"\n            raise ConfigError(msg) from ex\n\n        if self.concur_id_func and not hasattr(self._trace_class, \"concur_id_func\"):\n            raise ConfigError(\n                \"Can't support concurrency={} with {}, only threads are supported.\".format(\n                    tried, self.tracer_name(),\n                ),\n            )\n\n        if do_threading or not concurrencies:\n            # It's important to import threading only if we need it.  If\n            # it's imported early, and the program being measured uses\n            # gevent, then gevent's monkey-patching won't work properly.\n            import threading\n            self.threading = threading\n\n        self.reset()\n\n    def __repr__(self) -> str:\n        return f\"<Collector at {id(self):#x}: {self.tracer_name()}>\"\n\n    def use_data(self, covdata: CoverageData, context: str | None) -> None:\n        \"\"\"Use `covdata` for recording data.\"\"\"\n        self.covdata = covdata\n        self.static_context = context\n        self.covdata.set_context(self.static_context)\n\n    def tracer_name(self) -> str:\n        \"\"\"Return the class name of the tracer we're using.\"\"\"\n        return self._trace_class.__name__\n\n    def _clear_data(self) -> None:\n        \"\"\"Clear out existing data, but stay ready for more collection.\"\"\"\n        # We used to use self.data.clear(), but that would remove filename\n        # keys and data values that were still in use higher up the stack\n        # when we are called as part of switch_context.\n        with self.data_lock or contextlib.nullcontext():\n            for d in self.data.values():\n                d.clear()\n\n        for tracer in self.tracers:\n            tracer.reset_activity()\n\n    def reset(self) -> None:\n        \"\"\"Clear collected data, and prepare to collect more.\"\"\"\n        self.data_lock = self.threading.Lock() if self.threading else None\n\n        # The trace data we are collecting.\n        self.data: TTraceData = {}\n\n        # A dictionary mapping file names to file tracer plugin names that will\n        # handle them.\n        self.file_tracers: dict[str, str] = {}\n\n        self.disabled_plugins: set[str] = set()\n\n        # The .should_trace_cache attribute is a cache from file names to\n        # coverage.FileDisposition objects, or None.  When a file is first\n        # considered for tracing, a FileDisposition is obtained from\n        # Coverage.should_trace.  Its .trace attribute indicates whether the\n        # file should be traced or not.  If it should be, a plugin with dynamic\n        # file names can decide not to trace it based on the dynamic file name\n        # being excluded by the inclusion rules, in which case the\n        # FileDisposition will be replaced by None in the cache.\n        if env.PYPY:\n            import __pypy__                     # pylint: disable=import-error\n            # Alex Gaynor said:\n            # should_trace_cache is a strictly growing key: once a key is in\n            # it, it never changes.  Further, the keys used to access it are\n            # generally constant, given sufficient context. That is to say, at\n            # any given point _trace() is called, pypy is able to know the key.\n            # This is because the key is determined by the physical source code\n            # line, and that's invariant with the call site.\n            #\n            # This property of a dict with immutable keys, combined with\n            # call-site-constant keys is a match for PyPy's module dict,\n            # which is optimized for such workloads.\n            #\n            # This gives a 20% benefit on the workload described at\n            # https://bitbucket.org/pypy/pypy/issue/1871/10x-slower-than-cpython-under-coverage\n            self.should_trace_cache = __pypy__.newdict(\"module\")\n        else:\n            self.should_trace_cache = {}\n\n        # Our active Tracers.\n        self.tracers: list[TracerCore] = []\n\n        self._clear_data()\n\n    def lock_data(self) -> None:\n        \"\"\"Lock self.data_lock, for use by the C tracer.\"\"\"\n        if self.data_lock is not None:\n            self.data_lock.acquire()\n\n    def unlock_data(self) -> None:\n        \"\"\"Unlock self.data_lock, for use by the C tracer.\"\"\"\n        if self.data_lock is not None:\n            self.data_lock.release()\n\n    def _start_tracer(self) -> TTraceFn | None:\n        \"\"\"Start a new Tracer object, and store it in self.tracers.\"\"\"\n        tracer = self._trace_class(**self._core_kwargs)\n        tracer.data = self.data\n        tracer.lock_data = self.lock_data\n        tracer.unlock_data = self.unlock_data\n        tracer.trace_arcs = self.branch\n        tracer.should_trace = self.should_trace\n        tracer.should_trace_cache = self.should_trace_cache\n        tracer.warn = self.warn\n\n        if hasattr(tracer, 'concur_id_func'):\n            tracer.concur_id_func = self.concur_id_func\n        if hasattr(tracer, 'file_tracers'):\n            tracer.file_tracers = self.file_tracers\n        if hasattr(tracer, 'threading'):\n            tracer.threading = self.threading\n        if hasattr(tracer, 'check_include'):\n            tracer.check_include = self.check_include\n        if hasattr(tracer, 'should_start_context'):\n            tracer.should_start_context = self.should_start_context\n        if hasattr(tracer, 'switch_context'):\n            tracer.switch_context = self.switch_context\n        if hasattr(tracer, 'disable_plugin'):\n            tracer.disable_plugin = self.disable_plugin\n\n        fn = tracer.start()\n        self.tracers.append(tracer)\n\n        return fn\n\n    # The trace function has to be set individually on each thread before\n    # execution begins.  Ironically, the only support the threading module has\n    # for running code before the thread main is the tracing function.  So we\n    # install this as a trace function, and the first time it's called, it does\n    # the real trace installation.\n    #\n    # New in 3.12: threading.settrace_all_threads: https://github.com/python/cpython/pull/96681\n\n    def _installation_trace(self, frame: FrameType, event: str, arg: Any) -> TTraceFn | None:\n        \"\"\"Called on new threads, installs the real tracer.\"\"\"\n        # Remove ourselves as the trace function.\n        sys.settrace(None)\n        # Install the real tracer.\n        fn: TTraceFn | None = self._start_tracer()\n        # Invoke the real trace function with the current event, to be sure\n        # not to lose an event.\n        if fn:\n            fn = fn(frame, event, arg)\n        # Return the new trace function to continue tracing in this scope.\n        return fn\n\n    def start(self) -> None:\n        \"\"\"Start collecting trace information.\"\"\"\n        # We may be a new collector in a forked process.  The old process'\n        # collectors will be in self._collectors, but they won't be usable.\n        # Find them and discard them.\n        keep_collectors = []\n        for c in self._collectors:\n            if c.pid == self.pid:\n                keep_collectors.append(c)\n            else:\n                c.post_fork()\n        self._collectors[:] = keep_collectors\n\n        if self._collectors:\n            self._collectors[-1].pause()\n\n        self.tracers = []\n\n        try:\n            # Install the tracer on this thread.\n            self._start_tracer()\n        except:\n            if self._collectors:\n                self._collectors[-1].resume()\n            raise\n\n        # If _start_tracer succeeded, then we add ourselves to the global\n        # stack of collectors.\n        self._collectors.append(self)\n\n        # Install our installation tracer in threading, to jump-start other\n        # threads.\n        if self.systrace and self.threading:\n            self.threading.settrace(self._installation_trace)\n\n    def stop(self) -> None:\n        \"\"\"Stop collecting trace information.\"\"\"\n        assert self._collectors\n        if self._collectors[-1] is not self:\n            print(\"self._collectors:\")\n            for c in self._collectors:\n                print(f\"  {c!r}\\n{c.origin}\")\n        assert self._collectors[-1] is self, (\n            f\"Expected current collector to be {self!r}, but it's {self._collectors[-1]!r}\"\n        )\n\n        self.pause()\n\n        # Remove this Collector from the stack, and resume the one underneath (if any).\n        self._collectors.pop()\n        if self._collectors:\n            self._collectors[-1].resume()\n\n    def pause(self) -> None:\n        \"\"\"Pause tracing, but be prepared to `resume`.\"\"\"\n        for tracer in self.tracers:\n            tracer.stop()\n            stats = tracer.get_stats()\n            if stats:\n                print(\"\\nCoverage.py tracer stats:\")\n                for k, v in human_sorted_items(stats.items()):\n                    print(f\"{k:>20}: {v}\")\n        if self.threading:\n            self.threading.settrace(None)\n\n    def resume(self) -> None:\n        \"\"\"Resume tracing after a `pause`.\"\"\"\n        for tracer in self.tracers:\n            tracer.start()\n        if self.systrace:\n            if self.threading:\n                self.threading.settrace(self._installation_trace)\n            else:\n                self._start_tracer()\n\n    def post_fork(self) -> None:\n        \"\"\"After a fork, tracers might need to adjust.\"\"\"\n        for tracer in self.tracers:\n            if hasattr(tracer, \"post_fork\"):\n                tracer.post_fork()\n\n    def _activity(self) -> bool:\n        \"\"\"Has any activity been traced?\n\n        Returns a boolean, True if any trace function was invoked.\n\n        \"\"\"\n        return any(tracer.activity() for tracer in self.tracers)\n\n    def switch_context(self, new_context: str | None) -> None:\n        \"\"\"Switch to a new dynamic context.\"\"\"\n        context: str | None\n        self.flush_data()\n        if self.static_context:\n            context = self.static_context\n            if new_context:\n                context += \"|\" + new_context\n        else:\n            context = new_context\n        self.covdata.set_context(context)\n\n    def disable_plugin(self, disposition: TFileDisposition) -> None:\n        \"\"\"Disable the plugin mentioned in `disposition`.\"\"\"\n        file_tracer = disposition.file_tracer\n        assert file_tracer is not None\n        plugin = file_tracer._coverage_plugin\n        plugin_name = plugin._coverage_plugin_name\n        self.warn(f\"Disabling plug-in {plugin_name!r} due to previous exception\")\n        plugin._coverage_enabled = False\n        disposition.trace = False\n\n    @functools.lru_cache(maxsize=None)          # pylint: disable=method-cache-max-size-none\n    def cached_mapped_file(self, filename: str) -> str:\n        \"\"\"A locally cached version of file names mapped through file_mapper.\"\"\"\n        return self.file_mapper(filename)\n\n    def mapped_file_dict(self, d: Mapping[str, T]) -> dict[str, T]:\n        \"\"\"Return a dict like d, but with keys modified by file_mapper.\"\"\"\n        # The call to list(items()) ensures that the GIL protects the dictionary\n        # iterator against concurrent modifications by tracers running\n        # in other threads. We try three times in case of concurrent\n        # access, hoping to get a clean copy.\n        runtime_err = None\n        for _ in range(3):                      # pragma: part covered\n            try:\n                items = list(d.items())\n            except RuntimeError as ex:          # pragma: cant happen\n                runtime_err = ex\n            else:\n                break\n        else:                                   # pragma: cant happen\n            assert isinstance(runtime_err, Exception)\n            raise runtime_err\n\n        return {self.cached_mapped_file(k): v for k, v in items if v}\n\n    def plugin_was_disabled(self, plugin: CoveragePlugin) -> None:\n        \"\"\"Record that `plugin` was disabled during the run.\"\"\"\n        self.disabled_plugins.add(plugin._coverage_plugin_name)\n\n    def flush_data(self) -> bool:\n        \"\"\"Save the collected data to our associated `CoverageData`.\n\n        Data may have also been saved along the way. This forces the\n        last of the data to be saved.\n\n        Returns True if there was data to save, False if not.\n        \"\"\"\n        if not self._activity():\n            return False\n\n        if self.branch:\n            if self.packed_arcs:\n                # Unpack the line number pairs packed into integers.  See\n                # tracer.c:CTracer_record_pair for the C code that creates\n                # these packed ints.\n                arc_data: dict[str, list[TArc]] = {}\n                packed_data = cast(Dict[str, Set[int]], self.data)\n\n                # The list() here and in the inner loop are to get a clean copy\n                # even as tracers are continuing to add data.\n                for fname, packeds in list(packed_data.items()):\n                    tuples = []\n                    for packed in list(packeds):\n                        l1 = packed & 0xFFFFF\n                        l2 = (packed & (0xFFFFF << 20)) >> 20\n                        if packed & (1 << 40):\n                            l1 *= -1\n                        if packed & (1 << 41):\n                            l2 *= -1\n                        tuples.append((l1, l2))\n                    arc_data[fname] = tuples\n            else:\n                arc_data = cast(Dict[str, List[TArc]], self.data)\n            self.covdata.add_arcs(self.mapped_file_dict(arc_data))\n        else:\n            line_data = cast(Dict[str, Set[int]], self.data)\n            self.covdata.add_lines(self.mapped_file_dict(line_data))\n\n        file_tracers = {\n            k: v for k, v in self.file_tracers.items()\n            if v not in self.disabled_plugins\n        }\n        self.covdata.add_file_tracers(self.mapped_file_dict(file_tracers))\n\n        self._clear_data()\n        return True\n", "coverage/tomlconfig.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"TOML configuration support for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport re\n\nfrom typing import Any, Callable, Iterable, TypeVar\n\nfrom coverage import env\nfrom coverage.exceptions import ConfigError\nfrom coverage.misc import import_third_party, substitute_variables\nfrom coverage.types import TConfigSectionOut, TConfigValueOut\n\n\nif env.PYVERSION >= (3, 11, 0, \"alpha\", 7):\n    import tomllib      # pylint: disable=import-error\n    has_tomllib = True\nelse:\n    # TOML support on Python 3.10 and below is an install-time extra option.\n    tomllib, has_tomllib = import_third_party(\"tomli\")\n\n\nclass TomlDecodeError(Exception):\n    \"\"\"An exception class that exists even when toml isn't installed.\"\"\"\n    pass\n\n\nTWant = TypeVar(\"TWant\")\n\nclass TomlConfigParser:\n    \"\"\"TOML file reading with the interface of HandyConfigParser.\"\"\"\n\n    # This class has the same interface as config.HandyConfigParser, no\n    # need for docstrings.\n    # pylint: disable=missing-function-docstring\n\n    def __init__(self, our_file: bool) -> None:\n        self.our_file = our_file\n        self.data: dict[str, Any] = {}\n\n    def read(self, filenames: Iterable[str]) -> list[str]:\n        # RawConfigParser takes a filename or list of filenames, but we only\n        # ever call this with a single filename.\n        assert isinstance(filenames, (bytes, str, os.PathLike))\n        filename = os.fspath(filenames)\n\n        try:\n            with open(filename, encoding='utf-8') as fp:\n                toml_text = fp.read()\n        except OSError:\n            return []\n        if has_tomllib:\n            try:\n                self.data = tomllib.loads(toml_text)\n            except tomllib.TOMLDecodeError as err:\n                raise TomlDecodeError(str(err)) from err\n            return [filename]\n        else:\n            has_toml = re.search(r\"^\\[tool\\.coverage(\\.|])\", toml_text, flags=re.MULTILINE)\n            if self.our_file or has_toml:\n                # Looks like they meant to read TOML, but we can't read it.\n                msg = \"Can't read {!r} without TOML support. Install with [toml] extra\"\n                raise ConfigError(msg.format(filename))\n            return []\n\n    def _get_section(self, section: str) -> tuple[str | None, TConfigSectionOut | None]:\n        \"\"\"Get a section from the data.\n\n        Arguments:\n            section (str): A section name, which can be dotted.\n\n        Returns:\n            name (str): the actual name of the section that was found, if any,\n                or None.\n            data (str): the dict of data in the section, or None if not found.\n\n        \"\"\"\n        prefixes = [\"tool.coverage.\"]\n        for prefix in prefixes:\n            real_section = prefix + section\n            parts = real_section.split(\".\")\n            try:\n                data = self.data[parts[0]]\n                for part in parts[1:]:\n                    data = data[part]\n            except KeyError:\n                continue\n            break\n        else:\n            return None, None\n        return real_section, data\n\n    def _get(self, section: str, option: str) -> tuple[str, TConfigValueOut]:\n        \"\"\"Like .get, but returns the real section name and the value.\"\"\"\n        name, data = self._get_section(section)\n        if data is None:\n            raise ConfigError(f\"No section: {section!r}\")\n        assert name is not None\n        try:\n            value = data[option]\n        except KeyError:\n            raise ConfigError(f\"No option {option!r} in section: {name!r}\") from None\n        return name, value\n\n    def _get_single(self, section: str, option: str) -> Any:\n        \"\"\"Get a single-valued option.\n\n        Performs environment substitution if the value is a string. Other types\n        will be converted later as needed.\n        \"\"\"\n        name, value = self._get(section, option)\n        if isinstance(value, str):\n            value = substitute_variables(value, os.environ)\n        return name, value\n\n    def has_option(self, section: str, option: str) -> bool:\n        _, data = self._get_section(section)\n        if data is None:\n            return False\n        return option in data\n\n    def real_section(self, section: str) -> str | None:\n        name, _ = self._get_section(section)\n        return name\n\n    def has_section(self, section: str) -> bool:\n        name, _ = self._get_section(section)\n        return bool(name)\n\n    def options(self, section: str) -> list[str]:\n        _, data = self._get_section(section)\n        if data is None:\n            raise ConfigError(f\"No section: {section!r}\")\n        return list(data.keys())\n\n    def get_section(self, section: str) -> TConfigSectionOut:\n        _, data = self._get_section(section)\n        return data or {}\n\n    def get(self, section: str, option: str) -> Any:\n        _, value = self._get_single(section, option)\n        return value\n\n    def _check_type(\n        self,\n        section: str,\n        option: str,\n        value: Any,\n        type_: type[TWant],\n        converter: Callable[[Any], TWant] | None,\n        type_desc: str,\n    ) -> TWant:\n        \"\"\"Check that `value` has the type we want, converting if needed.\n\n        Returns the resulting value of the desired type.\n        \"\"\"\n        if isinstance(value, type_):\n            return value\n        if isinstance(value, str) and converter is not None:\n            try:\n                return converter(value)\n            except Exception as e:\n                raise ValueError(\n                    f\"Option [{section}]{option} couldn't convert to {type_desc}: {value!r}\",\n                ) from e\n        raise ValueError(\n            f\"Option [{section}]{option} is not {type_desc}: {value!r}\",\n        )\n\n    def getboolean(self, section: str, option: str) -> bool:\n        name, value = self._get_single(section, option)\n        bool_strings = {\"true\": True, \"false\": False}\n        return self._check_type(name, option, value, bool, bool_strings.__getitem__, \"a boolean\")\n\n    def _get_list(self, section: str, option: str) -> tuple[str, list[str]]:\n        \"\"\"Get a list of strings, substituting environment variables in the elements.\"\"\"\n        name, values = self._get(section, option)\n        values = self._check_type(name, option, values, list, None, \"a list\")\n        values = [substitute_variables(value, os.environ) for value in values]\n        return name, values\n\n    def getlist(self, section: str, option: str) -> list[str]:\n        _, values = self._get_list(section, option)\n        return values\n\n    def getregexlist(self, section: str, option: str) -> list[str]:\n        name, values = self._get_list(section, option)\n        for value in values:\n            value = value.strip()\n            try:\n                re.compile(value)\n            except re.error as e:\n                raise ConfigError(f\"Invalid [{name}].{option} value {value!r}: {e}\") from e\n        return values\n\n    def getint(self, section: str, option: str) -> int:\n        name, value = self._get_single(section, option)\n        return self._check_type(name, option, value, int, int, \"an integer\")\n\n    def getfloat(self, section: str, option: str) -> float:\n        name, value = self._get_single(section, option)\n        if isinstance(value, int):\n            value = float(value)\n        return self._check_type(name, option, value, float, float, \"a float\")\n", "coverage/data.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Coverage data for coverage.py.\n\nThis file had the 4.x JSON data support, which is now gone.  This file still\nhas storage-agnostic helpers, and is kept to avoid changing too many imports.\nCoverageData is now defined in sqldata.py, and imported here to keep the\nimports working.\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport functools\nimport glob\nimport hashlib\nimport os.path\n\nfrom typing import Callable, Iterable\n\nfrom coverage.exceptions import CoverageException, NoDataError\nfrom coverage.files import PathAliases\nfrom coverage.misc import Hasher, file_be_gone, human_sorted, plural\nfrom coverage.sqldata import CoverageData\n\n\ndef line_counts(data: CoverageData, fullpath: bool = False) -> dict[str, int]:\n    \"\"\"Return a dict summarizing the line coverage data.\n\n    Keys are based on the file names, and values are the number of executed\n    lines.  If `fullpath` is true, then the keys are the full pathnames of\n    the files, otherwise they are the basenames of the files.\n\n    Returns a dict mapping file names to counts of lines.\n\n    \"\"\"\n    summ = {}\n    filename_fn: Callable[[str], str]\n    if fullpath:\n        # pylint: disable=unnecessary-lambda-assignment\n        filename_fn = lambda f: f\n    else:\n        filename_fn = os.path.basename\n    for filename in data.measured_files():\n        lines = data.lines(filename)\n        assert lines is not None\n        summ[filename_fn(filename)] = len(lines)\n    return summ\n\n\ndef add_data_to_hash(data: CoverageData, filename: str, hasher: Hasher) -> None:\n    \"\"\"Contribute `filename`'s data to the `hasher`.\n\n    `hasher` is a `coverage.misc.Hasher` instance to be updated with\n    the file's data.  It should only get the results data, not the run\n    data.\n\n    \"\"\"\n    if data.has_arcs():\n        hasher.update(sorted(data.arcs(filename) or []))\n    else:\n        hasher.update(sorted_lines(data, filename))\n    hasher.update(data.file_tracer(filename))\n\n\ndef combinable_files(data_file: str, data_paths: Iterable[str] | None = None) -> list[str]:\n    \"\"\"Make a list of data files to be combined.\n\n    `data_file` is a path to a data file.  `data_paths` is a list of files or\n    directories of files.\n\n    Returns a list of absolute file paths.\n    \"\"\"\n    data_dir, local = os.path.split(os.path.abspath(data_file))\n\n    data_paths = data_paths or [data_dir]\n    files_to_combine = []\n    for p in data_paths:\n        if os.path.isfile(p):\n            files_to_combine.append(os.path.abspath(p))\n        elif os.path.isdir(p):\n            pattern = glob.escape(os.path.join(os.path.abspath(p), local)) +\".*\"\n            files_to_combine.extend(glob.glob(pattern))\n        else:\n            raise NoDataError(f\"Couldn't combine from non-existent path '{p}'\")\n\n    # SQLite might have made journal files alongside our database files.\n    # We never want to combine those.\n    files_to_combine = [fnm for fnm in files_to_combine if not fnm.endswith(\"-journal\")]\n\n    # Sorting isn't usually needed, since it shouldn't matter what order files\n    # are combined, but sorting makes tests more predictable, and makes\n    # debugging more understandable when things go wrong.\n    return sorted(files_to_combine)\n\n\ndef combine_parallel_data(\n    data: CoverageData,\n    aliases: PathAliases | None = None,\n    data_paths: Iterable[str] | None = None,\n    strict: bool = False,\n    keep: bool = False,\n    message: Callable[[str], None] | None = None,\n) -> None:\n    \"\"\"Combine a number of data files together.\n\n    `data` is a CoverageData.\n\n    Treat `data.filename` as a file prefix, and combine the data from all\n    of the data files starting with that prefix plus a dot.\n\n    If `aliases` is provided, it's a `PathAliases` object that is used to\n    re-map paths to match the local machine's.\n\n    If `data_paths` is provided, it is a list of directories or files to\n    combine.  Directories are searched for files that start with\n    `data.filename` plus dot as a prefix, and those files are combined.\n\n    If `data_paths` is not provided, then the directory portion of\n    `data.filename` is used as the directory to search for data files.\n\n    Unless `keep` is True every data file found and combined is then deleted\n    from disk. If a file cannot be read, a warning will be issued, and the\n    file will not be deleted.\n\n    If `strict` is true, and no files are found to combine, an error is\n    raised.\n\n    `message` is a function to use for printing messages to the user.\n\n    \"\"\"\n    files_to_combine = combinable_files(data.base_filename(), data_paths)\n\n    if strict and not files_to_combine:\n        raise NoDataError(\"No data to combine\")\n\n    if aliases is None:\n        map_path = None\n    else:\n        map_path = functools.lru_cache(maxsize=None)(aliases.map)\n\n    file_hashes = set()\n    combined_any = False\n\n    for f in files_to_combine:\n        if f == data.data_filename():\n            # Sometimes we are combining into a file which is one of the\n            # parallel files.  Skip that file.\n            if data._debug.should(\"dataio\"):\n                data._debug.write(f\"Skipping combining ourself: {f!r}\")\n            continue\n\n        try:\n            rel_file_name = os.path.relpath(f)\n        except ValueError:\n            # ValueError can be raised under Windows when os.getcwd() returns a\n            # folder from a different drive than the drive of f, in which case\n            # we print the original value of f instead of its relative path\n            rel_file_name = f\n\n        with open(f, \"rb\") as fobj:\n            hasher = hashlib.new(\"sha3_256\")\n            hasher.update(fobj.read())\n            sha = hasher.digest()\n            combine_this_one = sha not in file_hashes\n\n        delete_this_one = not keep\n        if combine_this_one:\n            if data._debug.should(\"dataio\"):\n                data._debug.write(f\"Combining data file {f!r}\")\n            file_hashes.add(sha)\n            try:\n                new_data = CoverageData(f, debug=data._debug)\n                new_data.read()\n            except CoverageException as exc:\n                if data._warn:\n                    # The CoverageException has the file name in it, so just\n                    # use the message as the warning.\n                    data._warn(str(exc))\n                if message:\n                    message(f\"Couldn't combine data file {rel_file_name}: {exc}\")\n                delete_this_one = False\n            else:\n                data.update(new_data, map_path=map_path)\n                combined_any = True\n                if message:\n                    message(f\"Combined data file {rel_file_name}\")\n        else:\n            if message:\n                message(f\"Skipping duplicate data {rel_file_name}\")\n\n        if delete_this_one:\n            if data._debug.should(\"dataio\"):\n                data._debug.write(f\"Deleting data file {f!r}\")\n            file_be_gone(f)\n\n    if strict and not combined_any:\n        raise NoDataError(\"No usable data files\")\n\n\ndef debug_data_file(filename: str) -> None:\n    \"\"\"Implementation of 'coverage debug data'.\"\"\"\n    data = CoverageData(filename)\n    filename = data.data_filename()\n    print(f\"path: {filename}\")\n    if not os.path.exists(filename):\n        print(\"No data collected: file doesn't exist\")\n        return\n    data.read()\n    print(f\"has_arcs: {data.has_arcs()!r}\")\n    summary = line_counts(data, fullpath=True)\n    filenames = human_sorted(summary.keys())\n    nfiles = len(filenames)\n    print(f\"{nfiles} file{plural(nfiles)}:\")\n    for f in filenames:\n        line = f\"{f}: {summary[f]} line{plural(summary[f])}\"\n        plugin = data.file_tracer(f)\n        if plugin:\n            line += f\" [{plugin}]\"\n        print(line)\n\n\ndef sorted_lines(data: CoverageData, filename: str) -> list[int]:\n    \"\"\"Get the sorted lines for a file, for tests.\"\"\"\n    lines = data.lines(filename)\n    return sorted(lines or [])\n", "tests/test_coverage.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport pytest\n\nimport coverage\nfrom coverage import env\nfrom coverage.exceptions import NoDataError\n\nfrom tests.coveragetest import CoverageTest\n\n\nclass TestCoverageTest(CoverageTest):\n    \"\"\"Make sure our complex self.check_coverage method works.\"\"\"\n\n    def test_successful_coverage(self) -> None:\n        # The simplest run possible.\n        self.check_coverage(\"\"\"\\\n            a = 1\n            b = 2\n            \"\"\",\n            [1,2],\n        )\n        # You can provide a list of possible statement matches.\n        self.check_coverage(\"\"\"\\\n            a = 1\n            b = 2\n            \"\"\",\n            ([100], [1,2], [1723,47]),\n        )\n        # You can specify missing lines.\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if a == 2:\n                a = 3\n            \"\"\",\n            [1,2,3],\n            missing=\"3\",\n        )\n\n    def test_failed_coverage(self) -> None:\n        # If the lines are wrong, the message shows right and wrong.\n        with pytest.raises(AssertionError, match=r\"\\[1, 2] != \\[1]\"):\n            self.check_coverage(\"\"\"\\\n                a = 1\n                b = 2\n                \"\"\",\n                [1],\n            )\n        # If the list of lines possibilities is wrong, the msg shows right.\n        msg = r\"None of the lines choices matched \\[1, 2]\"\n        with pytest.raises(AssertionError, match=msg):\n            self.check_coverage(\"\"\"\\\n                a = 1\n                b = 2\n                \"\"\",\n                ([1], [2]),\n            )\n        # If the missing lines are wrong, the message shows right and wrong.\n        with pytest.raises(AssertionError, match=r\"'3' != '37'\"):\n            self.check_coverage(\"\"\"\\\n                a = 1\n                if a == 2:\n                    a = 3\n                \"\"\",\n                [1,2,3],\n                missing=\"37\",\n            )\n\n    def test_exceptions_really_fail(self) -> None:\n        # An assert in the checked code will really raise up to us.\n        with pytest.raises(AssertionError, match=\"This is bad\"):\n            self.check_coverage(\"\"\"\\\n                a = 1\n                assert a == 99, \"This is bad\"\n                \"\"\",\n            )\n        # Other exceptions too.\n        with pytest.raises(ZeroDivisionError, match=\"division\"):\n            self.check_coverage(\"\"\"\\\n                a = 1\n                assert a == 1, \"This is good\"\n                a/0\n                \"\"\",\n            )\n\n\nclass BasicCoverageTest(CoverageTest):\n    \"\"\"The simplest tests, for quick smoke testing of fundamental changes.\"\"\"\n\n    def test_simple(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1\n            b = 2\n\n            c = 4\n            # Nothing here\n            d = 6\n            \"\"\",\n            [1,2,4,6], report=\"4 0 0 0 100%\",\n        )\n\n    def test_indentation_wackiness(self) -> None:\n        # Partial final lines are OK.\n        self.check_coverage(\"\"\"\\\n            import sys\n            if not sys.path:\n                a = 1\n                \"\"\",    # indented last line\n            [1,2,3], \"3\",\n        )\n\n    def test_multiline_initializer(self) -> None:\n        self.check_coverage(\"\"\"\\\n            d = {\n                'foo': 1+2,\n                'bar': (lambda x: x+1)(1),\n                'baz': str(1),\n            }\n\n            e = { 'foo': 1, 'bar': 2 }\n            \"\"\",\n            [1,7], \"\",\n        )\n\n    def test_list_comprehension(self) -> None:\n        self.check_coverage(\"\"\"\\\n            l = [\n                2*i for i in range(10)\n                if i > 5\n                ]\n            assert l == [12, 14, 16, 18]\n            \"\"\",\n            [1,5], \"\",\n        )\n\n\nclass SimpleStatementTest(CoverageTest):\n    \"\"\"Testing simple single-line statements.\"\"\"\n\n    def test_expression(self) -> None:\n        # Bare expressions as statements are tricky: some implementations\n        # optimize some of them away.  All implementations seem to count\n        # the implicit return at the end as executable.\n        self.check_coverage(\"\"\"\\\n            12\n            23\n            \"\"\",\n            ([1,2],[2]), \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            12\n            23\n            a = 3\n            \"\"\",\n            ([1,2,3],[3]), \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            1 + 2\n            1 + \\\\\n                2\n            \"\"\",\n            ([1,2], [2]), \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            1 + 2\n            1 + \\\\\n                2\n            a = 4\n            \"\"\",\n            ([1,2,4], [4]), \"\",\n        )\n\n    def test_assert(self) -> None:\n        self.check_coverage(\"\"\"\\\n            assert (1 + 2)\n            assert (1 +\n                2)\n            assert (1 + 2), 'the universe is broken'\n            assert (1 +\n                2), \\\\\n                'something is amiss'\n            \"\"\",\n            [1,2,4,5], \"\",\n        )\n\n    def test_assignment(self) -> None:\n        # Simple variable assignment\n        self.check_coverage(\"\"\"\\\n            a = (1 + 2)\n            b = (1 +\n                2)\n            c = \\\\\n                1\n            \"\"\",\n            [1,2,4], \"\",\n        )\n\n    def test_assign_tuple(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1\n            a,b,c = 7,8,9\n            assert a == 7 and b == 8 and c == 9\n            \"\"\",\n            [1,2,3], \"\",\n        )\n\n    def test_more_assignments(self) -> None:\n        self.check_coverage(\"\"\"\\\n            x = []\n            d = {}\n            d[\n                4 + len(x)\n                + 5\n            ] = \\\\\n            d[\n                8 ** 2\n            ] = \\\\\n                9\n            \"\"\",\n            [1, 2, 3], \"\",\n        )\n\n    def test_attribute_assignment(self) -> None:\n        # Attribute assignment\n        self.check_coverage(\"\"\"\\\n            class obj: pass\n            o = obj()\n            o.foo = (1 + 2)\n            o.foo = (1 +\n                2)\n            o.foo = \\\\\n                1\n            \"\"\",\n            [1,2,3,4,6], \"\",\n        )\n\n    def test_list_of_attribute_assignment(self) -> None:\n        self.check_coverage(\"\"\"\\\n            class obj: pass\n            o = obj()\n            o.a, o.b = (1 + 2), 3\n            o.a, o.b = (1 +\n                2), (3 +\n                4)\n            o.a, o.b = \\\\\n                1, \\\\\n                2\n            \"\"\",\n            [1,2,3,4,7], \"\",\n        )\n\n    def test_augmented_assignment(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1\n            a += 1\n            a += (1 +\n                2)\n            a += \\\\\n                1\n            \"\"\",\n            [1,2,3,5], \"\",\n        )\n\n    def test_triple_string_stuff(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = '''\n                a multiline\n                string.\n                '''\n            b = '''\n                long expression\n                ''' + '''\n                on many\n                lines.\n                '''\n            c = len('''\n                long expression\n                ''' +\n                '''\n                on many\n                lines.\n                ''')\n            \"\"\",\n            [1,5,11], \"\",\n        )\n\n    def test_pass(self) -> None:\n        # pass is tricky: if it's the only statement in a block, then it is\n        # \"executed\". But if it is not the only statement, then it is not.\n        self.check_coverage(\"\"\"\\\n            if 1==1:\n                pass\n            \"\"\",\n            [1,2], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            def foo():\n                pass\n            foo()\n            \"\"\",\n            [1,2,3], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            def foo():\n                \"doc\"\n                pass\n            foo()\n            \"\"\",\n            ([1,3,4], [1,4]), \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            class Foo:\n                def foo(self):\n                    pass\n            Foo().foo()\n            \"\"\",\n            [1,2,3,4], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            class Foo:\n                def foo(self):\n                    \"Huh?\"\n                    pass\n            Foo().foo()\n            \"\"\",\n            ([1,2,4,5], [1,2,5]), \"\",\n        )\n\n    def test_del(self) -> None:\n        self.check_coverage(\"\"\"\\\n            d = { 'a': 1, 'b': 1, 'c': 1, 'd': 1, 'e': 1 }\n            del d['a']\n            del d[\n                'b'\n                ]\n            del d['c'], \\\\\n                d['d'], \\\\\n                d['e']\n            assert(len(d.keys()) == 0)\n            \"\"\",\n            [1,2,3,6,9], \"\",\n        )\n\n    def test_raise(self) -> None:\n        self.check_coverage(\"\"\"\\\n            try:\n                raise Exception(\n                    \"hello %d\" %\n                    17)\n            except:\n                pass\n            \"\"\",\n            [1,2,5,6], \"\",\n        )\n\n    def test_raise_followed_by_statement(self) -> None:\n        if env.PYBEHAVIOR.omit_after_jump:\n            lines = [1,2,4,5]\n            missing = \"\"\n        else:\n            lines = [1,2,3,4,5]\n            missing = \"3\"\n        self.check_coverage(\"\"\"\\\n            try:\n                raise Exception(\"hello\")\n                a = 3\n            except:\n                pass\n            \"\"\",\n            lines=lines, missing=missing,\n        )\n\n    def test_return(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def fn():\n                a = 1\n                return a\n\n            x = fn()\n            assert(x == 1)\n            \"\"\",\n            [1,2,3,5,6], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            def fn():\n                a = 1\n                return (\n                    a +\n                    1)\n\n            x = fn()\n            assert(x == 2)\n            \"\"\",\n            [1,2,3,7,8], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            def fn():\n                a = 1\n                return (a,\n                    a + 1,\n                    a + 2)\n\n            x,y,z = fn()\n            assert x == 1 and y == 2 and z == 3\n            \"\"\",\n            [1,2,3,7,8], \"\",\n        )\n\n    def test_return_followed_by_statement(self) -> None:\n        if env.PYBEHAVIOR.omit_after_return:\n            lines = [1,2,3,6,7]\n            missing = \"\"\n        else:\n            lines = [1,2,3,4,6,7]\n            missing = \"4\"\n        self.check_coverage(\"\"\"\\\n            def fn():\n                a = 2\n                return a\n                a = 4\n\n            x = fn()\n            assert(x == 2)\n            \"\"\",\n            lines=lines, missing=missing,\n        )\n\n    def test_yield(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def gen():\n                yield 1\n                yield (2+\n                    3+\n                    4)\n                yield 1, \\\\\n                    2\n            a,b,c = gen()\n            assert a == 1 and b == 9 and c == (1,2)\n            \"\"\",\n            [1,2,3,6,8,9], \"\",\n        )\n\n    def test_break(self) -> None:\n        if env.PYBEHAVIOR.omit_after_jump:\n            lines = [1,2,3,5]\n            missing = \"\"\n        else:\n            lines = [1,2,3,4,5]\n            missing = \"4\"\n\n        self.check_coverage(\"\"\"\\\n            for x in range(10):\n                a = 2 + x\n                break\n                a = 4\n            assert a == 2\n            \"\"\",\n            lines=lines, missing=missing,\n        )\n\n    def test_continue(self) -> None:\n        if env.PYBEHAVIOR.omit_after_jump:\n            lines = [1,2,3,5]\n            missing = \"\"\n        else:\n            lines = [1,2,3,4,5]\n            missing = \"4\"\n\n        self.check_coverage(\"\"\"\\\n            for x in range(10):\n                a = 2 + x\n                continue\n                a = 4\n            assert a == 11\n            \"\"\",\n            lines=lines, missing=missing,\n        )\n\n    def test_strange_unexecuted_continue(self) -> None:\n        # This used to be true, but no longer is:\n        # Peephole optimization of jumps to jumps can mean that some statements\n        # never hit the line tracer.  The behavior is different in different\n        # versions of Python, so be careful when running this test.\n        self.check_coverage(\"\"\"\\\n            a = b = c = 0\n            for n in range(100):\n                if n % 2:\n                    if n % 4:\n                        a += 1\n                    continue    # <-- This line may not be hit.\n                else:\n                    b += 1\n                c += 1\n            assert a == 50 and b == 50 and c == 50\n\n            a = b = c = 0\n            for n in range(100):\n                if n % 2:\n                    if n % 3:\n                        a += 1\n                    continue    # <-- This line is always hit.\n                else:\n                    b += 1\n                c += 1\n            assert a == 33 and b == 50 and c == 50\n            \"\"\",\n            lines=[1,2,3,4,5,6,8,9,10, 12,13,14,15,16,17,19,20,21],\n            missing=\"\",\n        )\n\n    def test_import(self) -> None:\n        self.check_coverage(\"\"\"\\\n            import string\n            from sys import path\n            a = 1\n            \"\"\",\n            [1,2,3], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            import string\n            if 1 == 2:\n                from sys import path\n            a = 1\n            \"\"\",\n            [1,2,3,4], \"3\",\n        )\n        self.check_coverage(\"\"\"\\\n            import string, \\\\\n                os, \\\\\n                re\n            from sys import path, \\\\\n                stdout\n            a = 1\n            \"\"\",\n            [1,4,6], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            import sys, sys as s\n            assert s.path == sys.path\n            \"\"\",\n            [1,2], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            import sys, \\\\\n                sys as s\n            assert s.path == sys.path\n            \"\"\",\n            [1,3], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            from sys import path, \\\\\n                path as p\n            assert p == path\n            \"\"\",\n            [1,3], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            from sys import \\\\\n                *\n            assert len(path) > 0\n            \"\"\",\n            [1,3], \"\",\n        )\n\n    def test_global(self) -> None:\n        self.check_coverage(\"\"\"\\\n            g = h = i = 1\n            def fn():\n                global g\n                global h, \\\\\n                    i\n                g = h = i = 2\n            fn()\n            assert g == 2 and h == 2 and i == 2\n            \"\"\",\n            [1,2,6,7,8], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            g = h = i = 1\n            def fn():\n                global g; g = 2\n            fn()\n            assert g == 2 and h == 1 and i == 1\n            \"\"\",\n            [1,2,3,4,5], \"\",\n        )\n\n    def test_exec(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = b = c = 1\n            exec(\"a = 2\")\n            exec(\"b = \" +\n                \"c = \" +\n                \"2\")\n            assert a == 2 and b == 2 and c == 2\n            \"\"\",\n            [1,2,3,6], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            vars = {'a': 1, 'b': 1, 'c': 1}\n            exec(\"a = 2\", vars)\n            exec(\"b = \" +\n                \"c = \" +\n                \"2\", vars)\n            assert vars['a'] == 2 and vars['b'] == 2 and vars['c'] == 2\n            \"\"\",\n            [1,2,3,6], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            globs = {}\n            locs = {'a': 1, 'b': 1, 'c': 1}\n            exec(\"a = 2\", globs, locs)\n            exec(\"b = \" +\n                \"c = \" +\n                \"2\", globs, locs)\n            assert locs['a'] == 2 and locs['b'] == 2 and locs['c'] == 2\n            \"\"\",\n            [1,2,3,4,7], \"\",\n        )\n\n    def test_extra_doc_string(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1\n            \"An extra docstring, should be a comment.\"\n            b = 3\n            assert (a,b) == (1,3)\n            \"\"\",\n            ([1,3,4], [1,2,3,4]),\n            \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1\n            \"An extra docstring, should be a comment.\"\n            b = 3\n            123 # A number for some reason: ignored\n            1+1 # An expression: executed.\n            c = 6\n            assert (a,b,c) == (1,3,6)\n            \"\"\",\n            ([1,3,6,7], [1,3,5,6,7], [1,3,4,5,6,7], [1,2,3,4,5,6,7]),\n            \"\",\n        )\n\n    def test_nonascii(self) -> None:\n        self.check_coverage(\"\"\"\\\n            # coding: utf-8\n            a = 2\n            b = 3\n            \"\"\",\n            [2, 3],\n        )\n\n    def test_module_docstring(self) -> None:\n        self.check_coverage(\"\"\"\\\n            '''I am a module docstring.'''\n            a = 2\n            b = 3\n            \"\"\",\n            [2, 3],\n        )\n        self.check_coverage(\"\"\"\\\n            # Start with a comment, even though it doesn't change the behavior.\n            '''I am a module docstring.'''\n            a = 3\n            b = 4\n            \"\"\",\n            [3, 4],\n        )\n\n\nclass CompoundStatementTest(CoverageTest):\n    \"\"\"Testing coverage of multi-line compound statements.\"\"\"\n\n    def test_statement_list(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1;\n            b = 2; c = 3\n            d = 4; e = 5;\n\n            assert (a,b,c,d,e) == (1,2,3,4,5)\n            \"\"\",\n            [1,2,3,5], \"\",\n        )\n\n    def test_if(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if a == 1:\n                x = 3\n            assert x == 3\n            if (a ==\n                1):\n                x = 7\n            assert x == 7\n            \"\"\",\n            [1,2,3,4,5,7,8], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if a == 1:\n                x = 3\n            else:\n                y = 5\n            assert x == 3\n            \"\"\",\n            [1,2,3,5,6], \"5\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if a != 1:\n                x = 3\n            else:\n                y = 5\n            assert y == 5\n            \"\"\",\n            [1,2,3,5,6], \"3\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2\n            if a == 1:\n                if b == 2:\n                    x = 4\n                else:\n                    y = 6\n            else:\n                z = 8\n            assert x == 4\n            \"\"\",\n            [1,2,3,4,6,8,9], \"6-8\",\n        )\n\n    def test_elif(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if a == 1:\n                x = 3\n            elif b == 2:\n                y = 5\n            else:\n                z = 7\n            assert x == 3\n            \"\"\",\n            [1,2,3,4,5,7,8], \"4-7\", report=\"7 3 4 1 45% 4-7\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if a != 1:\n                x = 3\n            elif b == 2:\n                y = 5\n            else:\n                z = 7\n            assert y == 5\n            \"\"\",\n            [1,2,3,4,5,7,8], \"3, 7\", report=\"7 2 4 2 64% 3, 7\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if a != 1:\n                x = 3\n            elif b != 2:\n                y = 5\n            else:\n                z = 7\n            assert z == 7\n            \"\"\",\n            [1,2,3,4,5,7,8], \"3, 5\", report=\"7 2 4 2 64% 3, 5\",\n        )\n\n    def test_elif_no_else(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if a == 1:\n                x = 3\n            elif b == 2:\n                y = 5\n            assert x == 3\n            \"\"\",\n            [1,2,3,4,5,6], \"4-5\", report=\"6 2 4 1 50% 4-5\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if a != 1:\n                x = 3\n            elif b == 2:\n                y = 5\n            assert y == 5\n            \"\"\",\n            [1,2,3,4,5,6], \"3\", report=\"6 1 4 2 70% 3, 4->6\",\n        )\n\n    def test_elif_bizarre(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def f(self):\n                if self==1:\n                    x = 3\n                elif self.m('fred'):\n                    x = 5\n                elif (g==1) and (b==2):\n                    x = 7\n                elif self.m('fred')==True:\n                    x = 9\n                elif ((g==1) and (b==2))==True:\n                    x = 11\n                else:\n                    x = 13\n            \"\"\",\n            [1,2,3,4,5,6,7,8,9,10,11,13], \"2-13\",\n        )\n\n    def test_split_if(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if \\\\\n                a == 1:\n                x = 3\n            elif \\\\\n                b == 2:\n                y = 5\n            else:\n                z = 7\n            assert x == 3\n            \"\"\",\n            [1,2,4,5,7,9,10], \"5-9\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if \\\\\n                a != 1:\n                x = 3\n            elif \\\\\n                b == 2:\n                y = 5\n            else:\n                z = 7\n            assert y == 5\n            \"\"\",\n            [1,2,4,5,7,9,10], \"4, 9\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if \\\\\n                a != 1:\n                x = 3\n            elif \\\\\n                b != 2:\n                y = 5\n            else:\n                z = 7\n            assert z == 7\n            \"\"\",\n            [1,2,4,5,7,9,10], \"4, 7\",\n        )\n\n    def test_pathological_split_if(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if (\n                a == 1\n                ):\n                x = 3\n            elif (\n                b == 2\n                ):\n                y = 5\n            else:\n                z = 7\n            assert x == 3\n            \"\"\",\n            [1,2,5,6,9,11,12], \"6-11\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if (\n                a != 1\n                ):\n                x = 3\n            elif (\n                b == 2\n                ):\n                y = 5\n            else:\n                z = 7\n            assert y == 5\n            \"\"\",\n            [1,2,5,6,9,11,12], \"5, 11\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if (\n                a != 1\n                ):\n                x = 3\n            elif (\n                b != 2\n                ):\n                y = 5\n            else:\n                z = 7\n            assert z == 7\n            \"\"\",\n            [1,2,5,6,9,11,12], \"5, 9\",\n        )\n\n    def test_absurd_split_if(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if a == 1 \\\\\n                :\n                x = 3\n            elif b == 2 \\\\\n                :\n                y = 5\n            else:\n                z = 7\n            assert x == 3\n            \"\"\",\n            [1,2,4,5,7,9,10], \"5-9\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if a != 1 \\\\\n                :\n                x = 3\n            elif b == 2 \\\\\n                :\n                y = 5\n            else:\n                z = 7\n            assert y == 5\n            \"\"\",\n            [1,2,4,5,7,9,10], \"4, 9\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2; c = 3;\n            if a != 1 \\\\\n                :\n                x = 3\n            elif b != 2 \\\\\n                :\n                y = 5\n            else:\n                z = 7\n            assert z == 7\n            \"\"\",\n            [1,2,4,5,7,9,10], \"4, 7\",\n        )\n\n    def test_constant_if(self) -> None:\n        if env.PYBEHAVIOR.keep_constant_test:\n            lines = [1, 2, 3]\n        else:\n            lines = [2, 3]\n        self.check_coverage(\"\"\"\\\n            if 1:\n                a = 2\n            assert a == 2\n            \"\"\",\n            lines,\n            \"\",\n        )\n\n    def test_while(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 3; b = 0\n            while a:\n                b += 1\n                a -= 1\n            assert a == 0 and b == 3\n            \"\"\",\n            [1,2,3,4,5], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 3; b = 0\n            while a:\n                b += 1\n                break\n            assert a == 3 and b == 1\n            \"\"\",\n            [1,2,3,4,5], \"\",\n        )\n\n    def test_while_else(self) -> None:\n        # Take the else branch.\n        self.check_coverage(\"\"\"\\\n            a = 3; b = 0\n            while a:\n                b += 1\n                a -= 1\n            else:\n                b = 99\n            assert a == 0 and b == 99\n            \"\"\",\n            [1,2,3,4,6,7], \"\",\n        )\n        # Don't take the else branch.\n        self.check_coverage(\"\"\"\\\n            a = 3; b = 0\n            while a:\n                b += 1\n                a -= 1\n                break\n            else:\n                b = 99\n            assert a == 2 and b == 1\n            \"\"\",\n            [1,2,3,4,5,7,8], \"7\",\n        )\n\n    def test_split_while(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 3; b = 0\n            while \\\\\n                a:\n                b += 1\n                a -= 1\n            assert a == 0 and b == 3\n            \"\"\",\n            [1,2,4,5,6], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 3; b = 0\n            while (\n                a\n                ):\n                b += 1\n                a -= 1\n            assert a == 0 and b == 3\n            \"\"\",\n            [1,2,5,6,7], \"\",\n        )\n\n    def test_for(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 0\n            for i in [1,2,3,4,5]:\n                a += i\n            assert a == 15\n            \"\"\",\n            [1,2,3,4], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0\n            for i in [1,\n                2,3,4,\n                5]:\n                a += i\n            assert a == 15\n            \"\"\",\n            [1,2,5,6], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0\n            for i in [1,2,3,4,5]:\n                a += i\n                break\n            assert a == 1\n            \"\"\",\n            [1,2,3,4,5], \"\",\n        )\n\n    def test_for_else(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 0\n            for i in range(5):\n                a += i+1\n            else:\n                a = 99\n            assert a == 99\n            \"\"\",\n            [1,2,3,5,6], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0\n            for i in range(5):\n                a += i+1\n                break\n            else:\n                a = 123\n            assert a == 1\n            \"\"\",\n            [1,2,3,4,6,7], \"6\",\n        )\n\n    def test_split_for(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 0\n            for \\\\\n                i in [1,2,3,4,5]:\n                a += i\n            assert a == 15\n            \"\"\",\n            [1,2,4,5], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0\n            for \\\\\n                i in [1,\n                2,3,4,\n                5]:\n                a += i\n            assert a == 15\n            \"\"\",\n            [1,2,6,7], \"\",\n        )\n\n    def test_try_except(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n            except:\n                a = 99\n            assert a == 1\n            \"\"\",\n            [1,2,3,4,5,6], \"4-5\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n                raise Exception(\"foo\")\n            except:\n                a = 99\n            assert a == 99\n            \"\"\",\n            [1,2,3,4,5,6,7], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n                raise Exception(\"foo\")\n            except ImportError:\n                a = 99\n            except:\n                a = 123\n            assert a == 123\n            \"\"\",\n            [1,2,3,4,5,6,7,8,9], \"6\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n                raise IOError(\"foo\")\n            except ImportError:\n                a = 99\n            except IOError:\n                a = 17\n            except:\n                a = 123\n            assert a == 17\n            \"\"\",\n            [1,2,3,4,5,6,7,8,9,10,11], \"6, 9-10\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n            except:\n                a = 99\n            else:\n                a = 123\n            assert a == 123\n            \"\"\",\n            [1,2,3,4,5,7,8], \"4-5\",\n            arcz=\".1 12 23 45 58 37 78 8.\",\n            arcz_missing=\"45 58\",\n        )\n\n    def test_try_except_stranded_else(self) -> None:\n        if env.PYBEHAVIOR.optimize_unreachable_try_else:\n            # The else can't be reached because the try ends with a raise.\n            lines = [1,2,3,4,5,6,9]\n            missing = \"\"\n            arcz = \".1 12 23 34 45 56 69 9.\"\n            arcz_missing = \"\"\n        else:\n            lines = [1,2,3,4,5,6,8,9]\n            missing = \"8\"\n            arcz = \".1 12 23 34 45 56 69 89 9.\"\n            arcz_missing = \"89\"\n        self.check_coverage(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n                raise Exception(\"foo\")\n            except:\n                a = 99\n            else:\n                a = 123\n            assert a == 99\n            \"\"\",\n            lines=lines,\n            missing=missing,\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n        )\n\n    def test_try_finally(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n            finally:\n                a = 99\n            assert a == 99\n            \"\"\",\n            [1,2,3,5,6], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0; b = 0\n            try:\n                a = 1\n                try:\n                    raise Exception(\"foo\")\n                finally:\n                    b = 123\n            except:\n                a = 99\n            assert a == 99 and b == 123\n            \"\"\",\n            [1,2,3,4,5,7,8,9,10], \"\",\n        )\n\n    def test_function_def(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 99\n            def foo():\n                ''' docstring\n                '''\n                return 1\n\n            a = foo()\n            assert a == 1\n            \"\"\",\n            [1,2,5,7,8], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            def foo(\n                a,\n                b\n                ):\n                ''' docstring\n                '''\n                return a+b\n\n            x = foo(17, 23)\n            assert x == 40\n            \"\"\",\n            [1,7,9,10], \"\",\n        )\n        self.check_coverage(\"\"\"\\\n            def foo(\n                a = (lambda x: x*2)(10),\n                b = (\n                    lambda x:\n                        x+1\n                    )(1)\n                ):\n                ''' docstring\n                '''\n                return a+b\n\n            x = foo()\n            assert x == 22\n            \"\"\",\n            [1,10,12,13], \"\",\n        )\n\n    def test_class_def(self) -> None:\n        arcz=\"-22 2D DE E-2  23 36 6A A-2  -68 8-6   -AB B-A\"\n        self.check_coverage(\"\"\"\\\n            # A comment.\n            class theClass:\n                ''' the docstring.\n                    Don't be fooled.\n                '''\n                def __init__(self):\n                    ''' Another docstring. '''\n                    self.a = 1\n\n                def foo(self):\n                    return self.a\n\n            x = theClass().foo()\n            assert x == 1\n            \"\"\",\n            [2, 6, 8, 10, 11, 13, 14], \"\",\n            arcz=arcz,\n        )\n\n\nclass ExcludeTest(CoverageTest):\n    \"\"\"Tests of the exclusion feature to mark lines as not covered.\"\"\"\n\n    def test_default(self) -> None:\n        # A number of forms of pragma comment are accepted.\n        self.check_coverage(\"\"\"\\\n            a = 1\n            b = 2   # pragma: no cover\n            c = 3\n            d = 4   #pragma NOCOVER\n            e = 5\n            f = 6#\\tpragma:\\tno cover\n            g = 7\n            \"\"\",\n            [1,3,5,7],\n        )\n\n    def test_two_excludes(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2\n\n            if a == 99:\n                a = 4   # -cc\n                b = 5\n                c = 6   # -xx\n            assert a == 1 and b == 2\n            \"\"\",\n            [1,3,5,7], \"5\", excludes=['-cc', '-xx'],\n        )\n\n    def test_excluding_elif_suites(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1; b = 2\n\n            if 1==1:\n                a = 4\n                b = 5\n                c = 6\n            elif 1==0:          #pragma: NO COVER\n                a = 8\n                b = 9\n            else:\n                a = 11\n                b = 12\n            assert a == 4 and b == 5 and c == 6\n            \"\"\",\n            [1,3,4,5,6,11,12,13], \"11-12\", excludes=['#pragma: NO COVER'],\n        )\n\n    def test_excluding_try_except(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n            except:       #pragma: NO COVER\n                a = 99\n            else:\n                a = 123\n            assert a == 123\n            \"\"\",\n            [1,2,3,7,8], \"\", excludes=['#pragma: NO COVER'],\n            arcz=\".1 12 23 37 45 58 78 8.\",\n            arcz_missing=\"58\",\n        )\n\n    def test_excluding_try_except_stranded_else(self) -> None:\n        if env.PYBEHAVIOR.optimize_unreachable_try_else:\n            # The else can't be reached because the try ends with a raise.\n            arcz = \".1 12 23 34 45 56 69 9.\"\n            arcz_missing = \"\"\n        else:\n            arcz = \".1 12 23 34 45 56 69 89 9.\"\n            arcz_missing = \"89\"\n        self.check_coverage(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n                raise Exception(\"foo\")\n            except:\n                a = 99\n            else:              #pragma: NO COVER\n                x = 2\n            assert a == 99\n            \"\"\",\n            [1,2,3,4,5,6,9], \"\", excludes=['#pragma: NO COVER'],\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n        )\n\n    def test_excluded_comprehension_branches(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1271\n        self.check_coverage(\"\"\"\\\n            x, y = [0], [1]\n            if x == [2]:\n                raise NotImplementedError   # pragma: NO COVER\n            if all(_ == __ for _, __ in zip(x, y)):\n                raise NotImplementedError   # pragma: NO COVER\n            \"\"\",\n            [1,2,4], \"\", excludes=['#pragma: NO COVER'],\n            arcz=\".1 12 23 24 45 4.  -44 4-4\",\n            arcz_missing=\"4-4\",\n        )\n\n\nclass Py24Test(CoverageTest):\n    \"\"\"Tests of new syntax in Python 2.4.\"\"\"\n\n    def test_function_decorators(self) -> None:\n        lines = [1, 2, 3, 4, 6, 8, 9, 10, 12]\n        self.check_coverage(\"\"\"\\\n            def require_int(func):\n                def wrapper(arg):\n                    assert isinstance(arg, int)\n                    return func(arg)\n\n                return wrapper\n\n            @require_int\n            def p1(arg):\n                return arg*2\n\n            assert p1(10) == 20\n            \"\"\",\n            lines, \"\",\n        )\n\n    def test_function_decorators_with_args(self) -> None:\n        lines = [1, 2, 3, 4, 5, 6, 8, 9, 10, 12]\n        self.check_coverage(\"\"\"\\\n            def boost_by(extra):\n                def decorator(func):\n                    def wrapper(arg):\n                        return extra*func(arg)\n                    return wrapper\n                return decorator\n\n            @boost_by(10)\n            def boosted(arg):\n                return arg*2\n\n            assert boosted(10) == 200\n            \"\"\",\n            lines, \"\",\n        )\n\n    def test_double_function_decorators(self) -> None:\n        lines = [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 19, 21, 22, 23, 24, 26]\n        self.check_coverage(\"\"\"\\\n            def require_int(func):\n                def wrapper(arg):\n                    assert isinstance(arg, int)\n                    return func(arg)\n                return wrapper\n\n            def boost_by(extra):\n                def decorator(func):\n                    def wrapper(arg):\n                        return extra*func(arg)\n                    return wrapper\n                return decorator\n\n            @require_int\n            @boost_by(10)\n            def boosted1(arg):\n                return arg*2\n\n            assert boosted1(10) == 200\n\n            @boost_by(10)\n            @require_int\n            def boosted2(arg):\n                return arg*2\n\n            assert boosted2(10) == 200\n            \"\"\",\n            lines, \"\",\n        )\n\n\nclass Py25Test(CoverageTest):\n    \"\"\"Tests of new syntax in Python 2.5.\"\"\"\n\n    def test_with_statement(self) -> None:\n        self.check_coverage(\"\"\"\\\n            class Managed:\n                def __enter__(self):\n                    desc = \"enter\"\n\n                def __exit__(self, type, value, tb):\n                    desc = \"exit\"\n\n            m = Managed()\n            with m:\n                desc = \"block1a\"\n                desc = \"block1b\"\n\n            try:\n                with m:\n                    desc = \"block2\"\n                    raise Exception(\"Boo!\")\n            except:\n                desc = \"caught\"\n            \"\"\",\n            [1,2,3,5,6,8,9,10,11,13,14,15,16,17,18], \"\",\n        )\n\n    def test_try_except_finally(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 0; b = 0\n            try:\n                a = 1\n            except:\n                a = 99\n            finally:\n                b = 2\n            assert a == 1 and b == 2\n            \"\"\",\n            [1,2,3,4,5,7,8], \"4-5\",\n            arcz=\".1 12 23 37 45 57 78 8.\", arcz_missing=\"45 57\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0; b = 0\n            try:\n                a = 1\n                raise Exception(\"foo\")\n            except:\n                a = 99\n            finally:\n                b = 2\n            assert a == 99 and b == 2\n            \"\"\",\n            [1,2,3,4,5,6,8,9], \"\",\n            arcz=\".1 12 23 34 45 56 68 89 9.\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0; b = 0\n            try:\n                a = 1\n                raise Exception(\"foo\")\n            except ImportError:\n                a = 99\n            except:\n                a = 123\n            finally:\n                b = 2\n            assert a == 123 and b == 2\n            \"\"\",\n            [1,2,3,4,5,6,7,8,10,11], \"6\",\n            arcz=\".1 12 23 34 45 56 57 78 6A 8A AB B.\", arcz_missing=\"56 6A\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0; b = 0\n            try:\n                a = 1\n                raise IOError(\"foo\")\n            except ImportError:\n                a = 99\n            except IOError:\n                a = 17\n            except:\n                a = 123\n            finally:\n                b = 2\n            assert a == 17 and b == 2\n            \"\"\",\n            [1,2,3,4,5,6,7,8,9,10,12,13], \"6, 9-10\",\n            arcz=\".1 12 23 34 45 56 6C 57 78 8C 79 9A AC CD D.\",\n            arcz_missing=\"56 6C 79 9A AC\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 0; b = 0\n            try:\n                a = 1\n            except:\n                a = 99\n            else:\n                a = 123\n            finally:\n                b = 2\n            assert a == 123 and b == 2\n            \"\"\",\n            [1,2,3,4,5,7,9,10], \"4-5\",\n            arcz=\".1 12 23 37 45 59 79 9A A.\",\n            arcz_missing=\"45 59\",\n        )\n\n    def test_try_except_finally_stranded_else(self) -> None:\n        if env.PYBEHAVIOR.optimize_unreachable_try_else:\n            # The else can't be reached because the try ends with a raise.\n            lines = [1,2,3,4,5,6,10,11]\n            missing = \"\"\n            arcz = \".1 12 23 34 45 56 6A AB B.\"\n            arcz_missing = \"\"\n        else:\n            lines = [1,2,3,4,5,6,8,10,11]\n            missing = \"8\"\n            arcz = \".1 12 23 34 45 56 6A 8A AB B.\"\n            arcz_missing = \"8A\"\n        self.check_coverage(\"\"\"\\\n            a = 0; b = 0\n            try:\n                a = 1\n                raise Exception(\"foo\")\n            except:\n                a = 99\n            else:\n                a = 123\n            finally:\n                b = 2\n            assert a == 99 and b == 2\n            \"\"\",\n            lines=lines,\n            missing=missing,\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n        )\n\n\nclass ModuleTest(CoverageTest):\n    \"\"\"Tests for the module-level behavior of the `coverage` module.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_not_singleton(self) -> None:\n        # You *can* create another coverage object.\n        coverage.Coverage()\n        coverage.Coverage()\n\n    def test_old_name_and_new_name(self) -> None:\n        assert coverage.coverage is coverage.Coverage\n\n\nclass ReportingTest(CoverageTest):\n    \"\"\"Tests of some reporting behavior.\"\"\"\n\n    def test_no_data_to_report_on_annotate(self) -> None:\n        # Reporting with no data produces a nice message and no output\n        # directory.\n        with pytest.raises(NoDataError, match=\"No data to report.\"):\n            self.command_line(\"annotate -d ann\")\n        self.assert_doesnt_exist(\"ann\")\n\n    def test_no_data_to_report_on_html(self) -> None:\n        # Reporting with no data produces a nice message and no output\n        # directory.\n        with pytest.raises(NoDataError, match=\"No data to report.\"):\n            self.command_line(\"html -d htmlcov\")\n        self.assert_doesnt_exist(\"htmlcov\")\n\n    def test_no_data_to_report_on_xml(self) -> None:\n        # Reporting with no data produces a nice message.\n        with pytest.raises(NoDataError, match=\"No data to report.\"):\n            self.command_line(\"xml\")\n        self.assert_doesnt_exist(\"coverage.xml\")\n", "tests/test_annotate.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for annotation from coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport coverage\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.goldtest import compare, gold_path\n\n\nclass AnnotationGoldTest(CoverageTest):\n    \"\"\"Test the annotate feature with gold files.\"\"\"\n\n    def make_multi(self) -> None:\n        \"\"\"Make a few source files we need for the tests.\"\"\"\n        self.make_file(\"multi.py\", \"\"\"\\\n            import a.a\n            import b.b\n\n            a.a.a(1)\n            b.b.b(2)\n            \"\"\")\n        self.make_file(\"a/__init__.py\")\n        self.make_file(\"a/a.py\", \"\"\"\\\n            def a(x):\n                if x == 1:\n                    print(\"x is 1\")\n                else:\n                    print(\"x is not 1\")\n            \"\"\")\n        self.make_file(\"b/__init__.py\")\n        self.make_file(\"b/b.py\", \"\"\"\\\n            def b(x):\n                msg = f\"x is {x}\"\n                print(msg)\n            \"\"\")\n\n    def test_multi(self) -> None:\n        self.make_multi()\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"multi\")\n        cov.annotate()\n        compare(gold_path(\"annotate/multi\"), \".\", \"*,cover\")\n\n    def test_annotate_dir(self) -> None:\n        self.make_multi()\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"multi\")\n        cov.annotate(directory=\"out_anno_dir\")\n        compare(gold_path(\"annotate/anno_dir\"), \"out_anno_dir\", \"*,cover\")\n\n    def test_encoding(self) -> None:\n        self.make_file(\"utf8.py\", \"\"\"\\\n            # -*- coding: utf-8 -*-\n            # This comment has an accent: \u00e9\n\n            print(\"spam eggs\")\n            \"\"\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"utf8\")\n        cov.annotate()\n        compare(gold_path(\"annotate/encodings\"), \".\", \"*,cover\")\n\n    def test_white(self) -> None:\n        self.make_file(\"white.py\", \"\"\"\\\n            # A test case sent to me by Steve White\n\n            def f(self):\n                if self==1:\n                    pass\n                elif self.m('fred'):\n                    pass\n                elif (g==1) and (b==2):\n                    pass\n                elif self.m('fred')==True:\n                    pass\n                elif ((g==1) and (b==2))==True:\n                    pass\n                else:\n                    pass\n\n            def g(x):\n                if x == 1:\n                    a = 1\n                else:\n                    a = 2\n\n            g(1)\n\n            def h(x):\n                if 0:   #pragma: no cover\n                    pass\n                if x == 1:\n                    a = 1\n                else:\n                    a = 2\n\n            h(2)\n            \"\"\")\n\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"white\")\n        cov.annotate()\n        compare(gold_path(\"annotate/white\"), \".\", \"*,cover\")\n\n    def test_missing_after_else(self) -> None:\n        self.make_file(\"mae.py\", \"\"\"\\\n            def f(x):\n                if x == 1:\n                    print(\"1\")\n                else:\n                    print(\"2\")\n\n            if f(1):\n                print(\"nope\")\n            if f(2):\n                print(\"nope\")\n            \"\"\")\n\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"mae\")\n        cov.annotate()\n        assert self.stdout() == \"1\\n2\\n\"\n        compare(gold_path(\"annotate/mae\"), \".\", \"*,cover\")\n", "tests/test_arcs.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.py's arc measurement.\"\"\"\n\nfrom __future__ import annotations\n\nimport pytest\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import assert_count_equal, xfail_pypy38\n\nimport coverage\nfrom coverage import env\nfrom coverage.data import sorted_lines\nfrom coverage.files import abs_file\n\n\n# When a try block ends, does the finally block (incorrectly) jump to the\n# last statement, or does it go the line outside the try block that it\n# should?\nxfail_pypy_3882 = pytest.mark.xfail(\n    env.PYPY and env.PYVERSION[:2] == (3, 8) and env.PYPYVERSION >= (7, 3, 11),\n    reason=\"https://foss.heptapod.net/pypy/pypy/-/issues/3882\",\n)\n\nclass SimpleArcTest(CoverageTest):\n    \"\"\"Tests for coverage.py's arc measurement.\"\"\"\n\n    def test_simple_sequence(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1\n            b = 2\n            \"\"\",\n            arcz=\".1 12 2.\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1\n\n            b = 3\n            \"\"\",\n            arcz=\".1 13 3.\",\n        )\n        line1 = 1 if env.PYBEHAVIOR.module_firstline_1 else 2\n        self.check_coverage(\"\"\"\\\n\n            a = 2\n            b = 3\n\n            c = 5\n            \"\"\",\n            arcz=f\"-{line1}2 23 35 5-{line1}\",\n        )\n\n    def test_function_def(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def foo():\n                a = 2\n\n            foo()\n            \"\"\",\n            arcz=\".1 .2 14 2. 4.\",\n        )\n\n    def test_if(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if len([]) == 0:\n                a = 3\n            assert a == 3\n            \"\"\",\n            arcz=\".1 12 23 24 34 4.\", arcz_missing=\"24\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if len([]) == 1:\n                a = 3\n            assert a == 1\n            \"\"\",\n            arcz=\".1 12 23 24 34 4.\", arcz_missing=\"23 34\",\n        )\n\n    def test_if_else(self) -> None:\n        self.check_coverage(\"\"\"\\\n            if len([]) == 0:\n                a = 2\n            else:\n                a = 4\n            assert a == 2\n            \"\"\",\n            arcz=\".1 12 25 14 45 5.\", arcz_missing=\"14 45\",\n        )\n        self.check_coverage(\"\"\"\\\n            if len([]) == 1:\n                a = 2\n            else:\n                a = 4\n            assert a == 4\n            \"\"\",\n            arcz=\".1 12 25 14 45 5.\", arcz_missing=\"12 25\",\n        )\n\n    def test_compact_if(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if len([]) == 0: a = 2\n            assert a == 2\n            \"\"\",\n            arcz=\".1 12 23 3.\",\n        )\n        self.check_coverage(\"\"\"\\\n            def fn(x):\n                if x % 2: return True\n                return False\n            a = fn(1)\n            assert a is True\n            \"\"\",\n            arcz=\".1 14 45 5.  .2 2. 23 3.\", arcz_missing=\"23 3.\",\n        )\n\n    def test_multiline(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = (\n                2 +\n                3\n                )\n            b = \\\\\n                6\n            \"\"\",\n            arcz=\".1 15 5.\",\n        )\n\n    def test_if_return(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def if_ret(a):\n                if a:\n                    return 3\n                b = 4\n                return 5\n            x = if_ret(0) + if_ret(1)\n            assert x == 8\n            \"\"\",\n            arcz=\".1 16 67 7.   .2 23 24 3. 45 5.\",\n        )\n\n    def test_dont_confuse_exit_and_else(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def foo():\n                if foo:\n                    a = 3\n                else:\n                    a = 5\n                return a\n            assert foo() == 3 # 7\n            \"\"\",\n            arcz=\".1 17 7.  .2 23 36 25 56 6.\", arcz_missing=\"25 56\",\n        )\n        self.check_coverage(\"\"\"\\\n            def foo():\n                if foo:\n                    a = 3\n                else:\n                    a = 5\n            foo() # 6\n            \"\"\",\n            arcz=\".1 16 6.  .2 23 3. 25 5.\", arcz_missing=\"25 5.\",\n        )\n\n    def test_what_is_the_sound_of_no_lines_clapping(self) -> None:\n        if env.PYBEHAVIOR.empty_is_empty:\n            arcz_missing=\".1 1.\"\n        else:\n            arcz_missing=\"\"\n        self.check_coverage(\"\"\"\\\n            # __init__.py\n            \"\"\",\n            arcz=\".1 1.\",\n            arcz_missing=arcz_missing,\n        )\n\n    def test_bug_1184(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def foo(x):\n                if x:\n                    try:\n                        1/(x - 1)\n                    except ZeroDivisionError:\n                        pass\n                return x        # 7\n\n            for i in range(3):  # 9\n                foo(i)\n            \"\"\",\n            arcz=\".1 19 9-1  .2 23 27 34 47 56 67 7-1  9A A9\",\n            arcz_unpredicted=\"45\",\n        )\n\n\nclass WithTest(CoverageTest):\n    \"\"\"Arc-measuring tests involving context managers.\"\"\"\n\n    def test_with(self) -> None:\n        arcz = \".1 .2 23 34 4. 16 6.\"\n        if env.PYBEHAVIOR.exit_through_with:\n            arcz = arcz.replace(\"4.\", \"42 2.\")\n        self.check_coverage(\"\"\"\\\n            def example():\n                with open(\"test\", \"w\") as f:\n                    f.write(\"3\")\n                    a = 4\n\n            example()\n            \"\"\",\n            arcz=arcz,\n        )\n\n    def test_with_return(self) -> None:\n        arcz = \".1 .2 23 34 4. 16 6.\"\n        if env.PYBEHAVIOR.exit_through_with:\n            arcz = arcz.replace(\"4.\", \"42 2.\")\n        self.check_coverage(\"\"\"\\\n            def example():\n                with open(\"test\", \"w\") as f:\n                    f.write(\"3\")\n                    return 4\n\n            example()\n            \"\"\",\n            arcz=arcz,\n        )\n\n    def test_bug_146(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/146\n        arcz = \".1 12 23 34 41 15 5.\"\n        if env.PYBEHAVIOR.exit_through_with:\n            arcz = arcz.replace(\"34\", \"32 24\")\n        self.check_coverage(\"\"\"\\\n            for i in range(2):\n                with open(\"test\", \"w\") as f:\n                    print(3)\n                print(4)\n            print(5)\n            \"\"\",\n            arcz=arcz,\n        )\n\n    def test_nested_with_return(self) -> None:\n        arcz = \".1 .2 23 34 45 56 6. 18 8.\"\n        if env.PYBEHAVIOR.exit_through_with:\n            arcz = arcz.replace(\"6.\", \"64 42 2.\")\n        self.check_coverage(\"\"\"\\\n            def example(x):\n                with open(\"test\", \"w\") as f2:\n                    a = 3\n                    with open(\"test2\", \"w\") as f4:\n                        f2.write(\"5\")\n                        return 6\n\n            example(8)\n            \"\"\",\n            arcz=arcz,\n        )\n\n    def test_break_through_with(self) -> None:\n        arcz = \".1 12 23 34 45 15 5.\"\n        if env.PYBEHAVIOR.exit_through_with:\n            arcz = arcz.replace(\"45\", \"42 25\")\n        self.check_coverage(\"\"\"\\\n            for i in range(1+1):\n                with open(\"test\", \"w\") as f:\n                    print(3)\n                    break\n            print(5)\n            \"\"\",\n            arcz=arcz,\n            arcz_missing=\"15\",\n        )\n\n    def test_continue_through_with(self) -> None:\n        arcz = \".1 12 23 34 41 15 5.\"\n        if env.PYBEHAVIOR.exit_through_with:\n            arcz = arcz.replace(\"41\", \"42 21\")\n        self.check_coverage(\"\"\"\\\n            for i in range(1+1):\n                with open(\"test\", \"w\") as f:\n                    print(3)\n                    continue\n            print(5)\n            \"\"\",\n            arcz=arcz,\n        )\n\n    # https://github.com/nedbat/coveragepy/issues/1270\n    def test_raise_through_with(self) -> None:\n        if env.PYBEHAVIOR.exit_through_with:\n            arcz = \".1 12 27 78 8. 9A A.  -23 34 45 53 6-2\"\n            arcz_missing = \"6-2 8.\"\n            arcz_unpredicted = \"3-2 89\"\n        else:\n            arcz = \".1 12 27 78 8. 9A A.  -23 34 45 5-2 6-2\"\n            arcz_missing = \"6-2 8.\"\n            arcz_unpredicted = \"89\"\n        cov = self.check_coverage(\"\"\"\\\n            from contextlib import suppress\n            def f(x):\n                with suppress():    # used as a null context manager\n                    print(4)\n                    raise Exception(\"Boo6\")\n                print(6)\n            try:\n                f(8)\n            except Exception:\n                print(\"oops 10\")\n            \"\"\",\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n            arcz_unpredicted=arcz_unpredicted,\n        )\n        expected = \"line 3 didn't jump to the function exit\"\n        assert self.get_missing_arc_description(cov, 3, -2) == expected\n\n    def test_untaken_raise_through_with(self) -> None:\n        if env.PYBEHAVIOR.exit_through_with:\n            arcz = \".1 12 28 89 9. AB B.  -23 34 45 56 53 63 37 7-2\"\n            arcz_missing = \"56 63 AB B.\"\n        else:\n            arcz = \".1 12 28 89 9. AB B.  -23 34 45 56 6-2 57 7-2\"\n            arcz_missing = \"56 6-2 AB B.\"\n        cov = self.check_coverage(\"\"\"\\\n            from contextlib import suppress\n            def f(x):\n                with suppress():    # used as a null context manager\n                    print(4)\n                    if x == 5:\n                        raise Exception(\"Boo6\")\n                print(7)\n            try:\n                f(9)\n            except Exception:\n                print(\"oops 11\")\n            \"\"\",\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n        )\n        expected = \"line 3 didn't jump to the function exit\"\n        assert self.get_missing_arc_description(cov, 3, -2) == expected\n\n\nclass LoopArcTest(CoverageTest):\n    \"\"\"Arc-measuring tests involving loops.\"\"\"\n\n    def test_loop(self) -> None:\n        self.check_coverage(\"\"\"\\\n            for i in range(10):\n                a = i\n            assert a == 9\n            \"\"\",\n            arcz=\".1 12 21 13 3.\",\n        )\n        self.check_coverage(\"\"\"\\\n            a = -1\n            for i in range(0):\n                a = i\n            assert a == -1\n            \"\"\",\n            arcz=\".1 12 23 32 24 4.\", arcz_missing=\"23 32\",\n        )\n\n    def test_nested_loop(self) -> None:\n        self.check_coverage(\"\"\"\\\n            for i in range(3):\n                for j in range(3):\n                    a = i + j\n            assert a == 4\n            \"\"\",\n            arcz=\".1 12 23 32 21 14 4.\",\n        )\n\n    def test_break(self) -> None:\n        if env.PYBEHAVIOR.omit_after_jump:\n            arcz = \".1 12 23 35 15 5.\"\n            arcz_missing = \"15\"\n        else:\n            arcz = \".1 12 23 35 15 41 5.\"\n            arcz_missing = \"15 41\"\n\n        self.check_coverage(\"\"\"\\\n            for i in range(10):\n                a = i\n                break       # 3\n                a = 99\n            assert a == 0   # 5\n            \"\"\",\n            arcz=arcz, arcz_missing=arcz_missing,\n        )\n\n    def test_continue(self) -> None:\n        if env.PYBEHAVIOR.omit_after_jump:\n            arcz = \".1 12 23 31 15 5.\"\n            arcz_missing = \"\"\n        else:\n            arcz = \".1 12 23 31 15 41 5.\"\n            arcz_missing = \"41\"\n\n        self.check_coverage(\"\"\"\\\n            for i in range(10):\n                a = i\n                continue    # 3\n                a = 99\n            assert a == 9   # 5\n            \"\"\",\n            arcz=arcz, arcz_missing=arcz_missing,\n        )\n\n    def test_nested_breaks(self) -> None:\n        self.check_coverage(\"\"\"\\\n            for i in range(3):\n                for j in range(3):\n                    a = i + j\n                    break               # 4\n                if i == 2:\n                    break\n            assert a == 2 and i == 2    # 7\n            \"\"\",\n            arcz=\".1 12 23 34 45 25 56 51 67 17 7.\", arcz_missing=\"17 25\",\n        )\n\n    def test_while_1(self) -> None:\n        # With \"while 1\", the loop knows it's constant.\n        if env.PYBEHAVIOR.keep_constant_test:\n            arcz = \".1 12 23 34 45 36 62 57 7.\"\n        else:\n            arcz = \".1 13 34 45 36 63 57 7.\"\n        self.check_coverage(\"\"\"\\\n            a, i = 1, 0\n            while 1:\n                if i >= 3:\n                    a = 4\n                    break\n                i += 1\n            assert a == 4 and i == 3\n            \"\"\",\n            arcz=arcz,\n        )\n\n    def test_while_true(self) -> None:\n        # With \"while True\", 2.x thinks it's computation,\n        # 3.x thinks it's constant.\n        if env.PYBEHAVIOR.keep_constant_test:\n            arcz = \".1 12 23 34 45 36 62 57 7.\"\n        else:\n            arcz = \".1 13 34 45 36 63 57 7.\"\n        self.check_coverage(\"\"\"\\\n            a, i = 1, 0\n            while True:\n                if i >= 3:\n                    a = 4\n                    break\n                i += 1\n            assert a == 4 and i == 3\n            \"\"\",\n            arcz=arcz,\n        )\n\n    def test_zero_coverage_while_loop(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/502\n        self.make_file(\"main.py\", \"print('done')\")\n        self.make_file(\"zero.py\", \"\"\"\\\n            def method(self):\n                while True:\n                    return 1\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"], branch=True)\n        self.start_import_stop(cov, \"main\")\n        assert self.stdout() == 'done\\n'\n        if env.PYBEHAVIOR.keep_constant_test:\n            num_stmts = 3\n        else:\n            num_stmts = 2\n        expected = f\"zero.py {num_stmts} {num_stmts} 0 0 0% 1-3\"\n        report = self.get_report(cov, show_missing=True)\n        squeezed = self.squeezed_lines(report)\n        assert expected in squeezed[3]\n\n    def test_bug_496_continue_in_constant_while(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/496\n        # A continue in a while-true needs to jump to the right place.\n        if env.PYBEHAVIOR.keep_constant_test:\n            arcz = \".1 12 23 34 45 52 46 67 7.\"\n        else:\n            arcz = \".1 13 34 45 53 46 67 7.\"\n        self.check_coverage(\"\"\"\\\n            up = iter('ta')\n            while True:\n                char = next(up)\n                if char == 't':\n                    continue\n                i = \"line 6\"\n                break\n            \"\"\",\n            arcz=arcz,\n        )\n\n    def test_for_if_else_for(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def branches_2(l):\n                if l:\n                    for e in l:\n                        a = 4\n                else:\n                    a = 6\n\n            def branches_3(l):\n                for x in l:\n                    if x:\n                        for e in l:\n                            a = 12\n                    else:\n                        a = 14\n\n            branches_2([0,1])\n            branches_3([0,1])\n            \"\"\",\n            arcz=\n                \".1 18 8G GH H. \" +\n                \".2 23 34 43 26 3. 6. \" +\n                \"-89 9A 9-8 AB BC CB B9 AE E9\",\n            arcz_missing=\"26 6.\",\n        )\n\n    def test_for_else(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def forelse(seq):\n                for n in seq:\n                    if n > 5:\n                        break\n                else:\n                    print('None of the values were greater than 5')\n                print('Done')\n            forelse([1,2])\n            forelse([1,6])\n            \"\"\",\n            arcz=\".1 .2 23 32 34 47 26 67 7. 18 89 9.\",\n        )\n\n    def test_while_else(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def whileelse(seq):\n                while seq:\n                    n = seq.pop()\n                    if n > 4:\n                        break\n                else:\n                    n = 99\n                return n\n            assert whileelse([1, 2]) == 99\n            assert whileelse([1, 5]) == 5\n            \"\"\",\n            arcz=\".1 19 9A A.  .2 23 34 45 58 42 27 78 8.\",\n        )\n\n    def test_confusing_for_loop_bug_175(self) -> None:\n        if env.PYBEHAVIOR.comprehensions_are_functions:\n            extra_arcz = \" -22 2-2\"\n        else:\n            extra_arcz = \"\"\n        self.check_coverage(\"\"\"\\\n            o = [(1,2), (3,4)]\n            o = [a for a in o]\n            for tup in o:\n                x = tup[0]\n                y = tup[1]\n            \"\"\",\n            arcz=\".1 12 23 34 45 53 3.\" + extra_arcz,\n        )\n        self.check_coverage(\"\"\"\\\n            o = [(1,2), (3,4)]\n            for tup in [a for a in o]:\n                x = tup[0]\n                y = tup[1]\n            \"\"\",\n            arcz=\".1 12 23 34 42 2.\" + extra_arcz,\n        )\n\n    # https://bugs.python.org/issue44672\n    @pytest.mark.xfail(env.PYVERSION < (3, 10), reason=\"<3.10 traced final pass incorrectly\")\n    def test_incorrect_loop_exit_bug_1175(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def wrong_loop(x):\n                if x:\n                    for i in [3, 33]:\n                        print(i+4)\n                else:\n                    pass\n\n            wrong_loop(8)\n            \"\"\",\n            arcz=\".1 .2 23 26 34 43 3. 6. 18 8.\",\n            arcz_missing=\"26 6.\",\n        )\n\n    # https://bugs.python.org/issue44672\n    @pytest.mark.xfail(env.PYVERSION < (3, 10), reason=\"<3.10 traced final pass incorrectly\")\n    def test_incorrect_if_bug_1175(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def wrong_loop(x):\n                if x:\n                    if x:\n                        print(4)\n                else:\n                    pass\n\n            wrong_loop(8)\n            \"\"\",\n            arcz=\".1 .2 23 26 34 4. 3. 6. 18 8.\",\n            arcz_missing=\"26 3. 6.\",\n        )\n\n    def test_generator_expression(self) -> None:\n        # Generator expression:\n        self.check_coverage(\"\"\"\\\n            o = ((1,2), (3,4))\n            o = (a for a in o)\n            for tup in o:\n                x = tup[0]\n                y = tup[1]\n            \"\"\",\n            arcz=\".1 -22 2-2 12 23 34 45 53 3.\",\n        )\n\n    def test_generator_expression_another_way(self) -> None:\n        # https://bugs.python.org/issue44450\n        # Generator expression:\n        self.check_coverage(\"\"\"\\\n            o = ((1,2), (3,4))\n            o = (a for\n                 a in\n                 o)\n            for tup in o:\n                x = tup[0]\n                y = tup[1]\n            \"\"\",\n            arcz=\".1 -22 2-2 12 25 56 67 75 5.\",\n        )\n\n    def test_other_comprehensions(self) -> None:\n        if env.PYBEHAVIOR.comprehensions_are_functions:\n            extra_arcz = \" -22 2-2\"\n        else:\n            extra_arcz = \"\"\n        # Set comprehension:\n        self.check_coverage(\"\"\"\\\n            o = ((1,2), (3,4))\n            o = {a for a in o}\n            for tup in o:\n                x = tup[0]\n                y = tup[1]\n            \"\"\",\n            arcz=\".1 12 23 34 45 53 3.\" + extra_arcz,\n        )\n        # Dict comprehension:\n        self.check_coverage(\"\"\"\\\n            o = ((1,2), (3,4))\n            o = {a:1 for a in o}\n            for tup in o:\n                x = tup[0]\n                y = tup[1]\n            \"\"\",\n            arcz=\".1 12 23 34 45 53 3.\" + extra_arcz,\n        )\n\n    def test_multiline_dict_comp(self) -> None:\n        if env.PYBEHAVIOR.comprehensions_are_functions:\n            extra_arcz = \" 2-2\"\n        else:\n            extra_arcz = \"\"\n        # Multiline dict comp:\n        self.check_coverage(\"\"\"\\\n            # comment\n            d = \\\\\n                {\n                i:\n                    str(i)\n                for\n                    i\n                    in\n                    range(9)\n            }\n            x = 11\n            \"\"\",\n            arcz=\"-22 2B B-2\" + extra_arcz,\n        )\n        # Multi dict comp:\n        self.check_coverage(\"\"\"\\\n            # comment\n            d = \\\\\n                {\n                (i, j):\n                    str(i+j)\n                for\n                    i\n                    in\n                    range(9)\n                for\n                    j\n                    in\n                    range(13)\n            }\n            x = 15\n            \"\"\",\n            arcz=\"-22 2F F-2\" + extra_arcz,\n        )\n\n\nclass ExceptionArcTest(CoverageTest):\n    \"\"\"Arc-measuring tests involving exception handling.\"\"\"\n\n    def test_try_except(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a, b = 1, 1\n            try:\n                a = 3\n            except:\n                b = 5\n            assert a == 3 and b == 1\n            \"\"\",\n            arcz=\".1 12 23 36 45 56 6.\", arcz_missing=\"45 56\",\n        )\n\n    def test_raise_followed_by_statement(self) -> None:\n        if env.PYBEHAVIOR.omit_after_jump:\n            arcz = \".1 12 23 34 46 67 78 8.\"\n            arcz_missing = \"\"\n        else:\n            arcz = \".1 12 23 34 46 58 67 78 8.\"\n            arcz_missing = \"58\"\n        self.check_coverage(\"\"\"\\\n            a, b = 1, 1\n            try:\n                a = 3\n                raise Exception(\"Yikes!\")\n                a = 5\n            except:\n                b = 7\n            assert a == 3 and b == 7\n            \"\"\",\n            arcz=arcz, arcz_missing=arcz_missing,\n        )\n\n    def test_hidden_raise(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a, b = 1, 1\n            def oops(x):\n                if x % 2:\n                    raise Exception(\"odd\")\n            try:\n                a = 6\n                oops(1)\n                a = 8\n            except:\n                b = 10\n            assert a == 6 and b == 10\n            \"\"\",\n            arcz=\".1 12 -23 34 3-2 4-2 25 56 67 78 8B 9A AB B.\",\n            arcz_missing=\"3-2 78 8B\", arcz_unpredicted=\"79\",\n        )\n\n    def test_except_with_type(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a, b = 1, 1\n            def oops(x):\n                if x % 2:\n                    raise ValueError(\"odd\")\n            def try_it(x):\n                try:\n                    a = 7\n                    oops(x)\n                    a = 9\n                except ValueError:\n                    b = 11\n                return a\n            assert try_it(0) == 9   # C\n            assert try_it(1) == 7   # D\n            \"\"\",\n            arcz=\".1 12 -23 34 3-2 4-2 25 5D DE E. -56 67 78 89 9C AB BC C-5\",\n            arcz_unpredicted=\"8A\",\n        )\n\n    @xfail_pypy_3882\n    def test_try_finally(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a, c = 1, 1\n            try:\n                a = 3\n            finally:\n                c = 5\n            assert a == 3 and c == 5\n            \"\"\",\n            arcz=\".1 12 23 35 56 6.\",\n        )\n        self.check_coverage(\"\"\"\\\n            a, c, d = 1, 1, 1\n            try:\n                try:\n                    a = 4\n                finally:\n                    c = 6\n            except:\n                d = 8\n            assert a == 4 and c == 6 and d == 1    # 9\n            \"\"\",\n            arcz=\".1 12 23 34 46 78 89 69 9.\",\n            arcz_missing=\"78 89\",\n        )\n        self.check_coverage(\"\"\"\\\n            a, c, d = 1, 1, 1\n            try:\n                try:\n                    a = 4\n                    raise Exception(\"Yikes!\")\n                    # line 6\n                finally:\n                    c = 8\n            except:\n                d = 10                              # A\n            assert a == 4 and c == 8 and d == 10    # B\n            \"\"\",\n            arcz=\".1 12 23 34 45 58 89 9A AB B.\",\n            arcz_missing=\"\",\n        )\n\n    @xfail_pypy_3882\n    def test_finally_in_loop(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a, c, d, i = 1, 1, 1, 99\n            try:\n                for i in range(5):\n                    try:\n                        a = 5\n                        if i > 0:\n                            raise Exception(\"Yikes!\")\n                        a = 8\n                    finally:\n                        c = 10\n            except:\n                d = 12                              # C\n            assert a == 5 and c == 10 and d == 12   # D\n            \"\"\",\n            arcz=\".1 12 23 34 3D 45 56 67 68 7A 8A A3 AB BC CD D.\",\n            arcz_missing=\"3D\",\n        )\n        self.check_coverage(\"\"\"\\\n            a, c, d, i = 1, 1, 1, 99\n            try:\n                for i in range(5):\n                    try:\n                        a = 5\n                        if i > 10:\n                            raise Exception(\"Yikes!\")\n                        a = 8\n                    finally:\n                        c = 10\n            except:\n                d = 12                              # C\n            assert a == 8 and c == 10 and d == 1    # D\n            \"\"\",\n            arcz=\".1 12 23 34 3D 45 56 67 68 7A 8A A3 AB BC CD D.\",\n            arcz_missing=\"67 7A AB BC CD\",\n        )\n\n\n    @xfail_pypy_3882\n    def test_break_through_finally(self) -> None:\n        arcz = \".1 12 23 34 3D 45 56 67 68 7A    AD 8A A3 BC CD D.\"\n        if env.PYBEHAVIOR.finally_jumps_back:\n            arcz = arcz.replace(\"AD\", \"A7 7D\")\n        self.check_coverage(\"\"\"\\\n            a, c, d, i = 1, 1, 1, 99\n            try:\n                for i in range(3):\n                    try:\n                        a = 5\n                        if i > 0:\n                            break\n                        a = 8\n                    finally:\n                        c = 10\n            except:\n                d = 12                              # C\n            assert a == 5 and c == 10 and d == 1    # D\n            \"\"\",\n            arcz=arcz,\n            arcz_missing=\"3D BC CD\",\n        )\n\n    def test_break_continue_without_finally(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a, c, d, i = 1, 1, 1, 99\n            try:\n                for i in range(3):\n                    try:\n                        a = 5\n                        if i > 0:\n                            break\n                        continue\n                    except:\n                        c = 10\n            except:\n                d = 12                              # C\n            assert a == 5 and c == 1 and d == 1     # D\n            \"\"\",\n            arcz=\".1 12 23 34 3D 45 56 67 68 7D 83 9A A3 BC CD D.\",\n            arcz_missing=\"3D 9A A3 BC CD\",\n        )\n\n    @xfail_pypy_3882\n    def test_continue_through_finally(self) -> None:\n        arcz = \".1 12 23 34 3D 45 56 67 68       7A 8A A3 BC CD D.\"\n        if env.PYBEHAVIOR.finally_jumps_back:\n            arcz += \" 73 A7\"\n        self.check_coverage(\"\"\"\\\n            a, b, c, d, i = 1, 1, 1, 1, 99\n            try:\n                for i in range(3):\n                    try:\n                        a = 5\n                        if i > 0:\n                            continue\n                        b = 8\n                    finally:\n                        c = 10\n            except:\n                d = 12                              # C\n            assert (a, b, c, d) == (5, 8, 10, 1)    # D\n            \"\"\",\n            arcz=arcz,\n            arcz_missing=\"BC CD\",\n        )\n\n    def test_finally_in_loop_bug_92(self) -> None:\n        self.check_coverage(\"\"\"\\\n            for i in range(5):\n                try:\n                    j = 3\n                finally:\n                    f = 5\n                g = 6\n            h = 7\n            \"\"\",\n            arcz=\".1 12 23 35 56 61 17 7.\",\n        )\n\n    def test_bug_212(self) -> None:\n        # \"except Exception as e\" is crucial here.\n        # Bug 212 said that the \"if exc\" line was incorrectly marked as only\n        # partially covered.\n        self.check_coverage(\"\"\"\\\n            def b(exc):\n                try:\n                    while \"no peephole\".upper():\n                        raise Exception(exc)    # 4\n                except Exception as e:\n                    if exc != 'expected':\n                        raise\n                    q = 8\n\n            b('expected')\n            try:\n                b('unexpected')     # C\n            except:\n                pass\n            \"\"\",\n            arcz=\".1 .2 1A 23 34 3. 45 56 67 68 7. 8. AB BC C. DE E.\",\n            arcz_missing=\"3. C.\",\n            arcz_unpredicted=\"CD\",\n        )\n\n    def test_except_finally(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a, b, c = 1, 1, 1\n            try:\n                a = 3\n            except:\n                b = 5\n            finally:\n                c = 7\n            assert a == 3 and b == 1 and c == 7\n            \"\"\",\n            arcz=\".1 12 23 45 37 57 78 8.\", arcz_missing=\"45 57\",\n        )\n        self.check_coverage(\"\"\"\\\n            a, b, c = 1, 1, 1\n            def oops(x):\n                if x % 2: raise Exception(\"odd\")\n            try:\n                a = 5\n                oops(1)\n                a = 7\n            except:\n                b = 9\n            finally:\n                c = 11\n            assert a == 5 and b == 9 and c == 11\n            \"\"\",\n            arcz=\".1 12 -23 3-2 24 45 56 67 7B 89 9B BC C.\",\n            arcz_missing=\"67 7B\", arcz_unpredicted=\"68\",\n        )\n\n    def test_multiple_except_clauses(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a, b, c = 1, 1, 1\n            try:\n                a = 3\n            except ValueError:\n                b = 5\n            except IndexError:\n                a = 7\n            finally:\n                c = 9\n            assert a == 3 and b == 1 and c == 9\n            \"\"\",\n            arcz=\".1 12 23 45 46 39 59 67 79 9A A.\",\n            arcz_missing=\"45 59 46 67 79\",\n        )\n        self.check_coverage(\"\"\"\\\n            a, b, c = 1, 1, 1\n            try:\n                a = int(\"xyz\")  # ValueError\n            except ValueError:\n                b = 5\n            except IndexError:\n                a = 7\n            finally:\n                c = 9\n            assert a == 1 and b == 5 and c == 9\n            \"\"\",\n            arcz=\".1 12 23 45 46 39 59 67 79 9A A.\",\n            arcz_missing=\"39 46 67 79\",\n            arcz_unpredicted=\"34\",\n        )\n        self.check_coverage(\"\"\"\\\n            a, b, c = 1, 1, 1\n            try:\n                a = [1][3]      # IndexError\n            except ValueError:\n                b = 5\n            except IndexError:\n                a = 7\n            finally:\n                c = 9\n            assert a == 7 and b == 1 and c == 9\n            \"\"\",\n            arcz=\".1 12 23 45 46 39 59 67 79 9A A.\",\n            arcz_missing=\"39 45 59\",\n            arcz_unpredicted=\"34\",\n        )\n        self.check_coverage(\"\"\"\\\n            a, b, c = 1, 1, 1\n            try:\n                try:\n                    a = 4/0         # ZeroDivisionError\n                except ValueError:\n                    b = 6\n                except IndexError:\n                    a = 8\n                finally:\n                    c = 10\n            except ZeroDivisionError:\n                pass\n            assert a == 1 and b == 1 and c == 10\n            \"\"\",\n            arcz=\".1 12 23 34 4A 56 6A 57 78 8A AD BC CD D.\",\n            arcz_missing=\"4A 56 6A 78 8A AD\",\n            arcz_unpredicted=\"45 7A AB\",\n        )\n\n    def test_return_finally(self) -> None:\n        arcz = \".1 12 29 9A AB BC C-1   -23 34 45  7-2   57 38 8-2\"\n        if env.PYBEHAVIOR.finally_jumps_back:\n            arcz = arcz.replace(\"7-2\", \"75 5-2\")\n        self.check_coverage(\"\"\"\\\n            a = [1]\n            def check_token(data):\n                if data:\n                    try:\n                        return 5\n                    finally:\n                        a.append(7)\n                return 8\n            assert check_token(False) == 8\n            assert a == [1]\n            assert check_token(True) == 5\n            assert a == [1, 7]\n            \"\"\",\n            arcz=arcz,\n        )\n\n    @xfail_pypy_3882\n    def test_except_jump_finally(self) -> None:\n        arcz = (\n            \".1 1Q QR RS ST TU U. \" +\n            \".2 23 34 45 56 4O 6L \" +\n            \"78 89 9A AL   8B BC CD DL   BE EF FG GL   EH HI IJ JL  HL \" +\n            \"LO L4 L. LM \" +\n            \"MN NO O.\"\n        )\n        if env.PYBEHAVIOR.finally_jumps_back:\n            arcz = arcz.replace(\"LO\", \"LA AO\").replace(\"L4\", \"L4 LD D4\").replace(\"L.\", \"LG G.\")\n        self.check_coverage(\"\"\"\\\n            def func(x):\n                a = f = g = 2\n                try:\n                    for i in range(4):\n                        try:\n                            6/0\n                        except ZeroDivisionError:\n                            if x == 'break':\n                                a = 9\n                                break\n                            elif x == 'continue':\n                                a = 12\n                                continue\n                            elif x == 'return':\n                                a = 15                      # F\n                                return a, f, g, i           # G\n                            elif x == 'raise':              # H\n                                a = 18                      # I\n                                raise ValueError()          # J\n                        finally:\n                            f = 21                          # L\n                except ValueError:                          # M\n                    g = 23                                  # N\n                return a, f, g, i                           # O\n\n            assert func('break') == (9, 21, 2, 0)           # Q\n            assert func('continue') == (12, 21, 2, 3)       # R\n            assert func('return') == (15, 2, 2, 0)          # S\n            assert func('raise') == (18, 21, 23, 0)         # T\n            assert func('other') == (2, 21, 2, 3)           # U 30\n            \"\"\",\n            arcz=arcz,\n            arcz_missing=\"6L\",\n            arcz_unpredicted=\"67\",\n        )\n\n    @xfail_pypy_3882\n    def test_else_jump_finally(self) -> None:\n        arcz = (\n            \".1 1S ST TU UV VW W. \" +\n            \".2 23 34 45 56 6A 78 8N 4Q \" +\n            \"AB BC CN  AD DE EF FN  DG GH HI IN  GJ JK KL LN  JN \" +\n            \"N4 NQ N. NO \" +\n            \"OP PQ Q.\"\n        )\n        if env.PYBEHAVIOR.finally_jumps_back:\n            arcz = arcz.replace(\"NQ\", \"NC CQ\").replace(\"N4\", \"N4 NF F4\").replace(\"N.\", \"NI I.\")\n        self.check_coverage(\"\"\"\\\n            def func(x):\n                a = f = g = 2\n                try:\n                    for i in range(4):\n                        try:\n                            b = 6\n                        except ZeroDivisionError:\n                            pass\n                        else:\n                            if x == 'break':\n                                a = 11\n                                break\n                            elif x == 'continue':\n                                a = 14\n                                continue\n                            elif x == 'return':\n                                a = 17                      # H\n                                return a, f, g, i           # I\n                            elif x == 'raise':              # J\n                                a = 20                      # K\n                                raise ValueError()          # L\n                        finally:\n                            f = 23                          # N\n                except ValueError:                          # O\n                    g = 25                                  # P\n                return a, f, g, i                           # Q\n\n            assert func('break') == (11, 23, 2, 0)          # S\n            assert func('continue') == (14, 23, 2, 3)       # T\n            assert func('return') == (17, 2, 2, 0)          # U\n            assert func('raise') == (20, 23, 25, 0)         # V\n            assert func('other') == (2, 23, 2, 3)           # W 32\n            \"\"\",\n            arcz=arcz,\n            arcz_missing=\"78 8N\",\n            arcz_unpredicted=\"\",\n        )\n\n\nclass YieldTest(CoverageTest):\n    \"\"\"Arc tests for generators.\"\"\"\n\n    def test_yield_in_loop(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def gen(inp):\n                for n in inp:\n                    yield n\n\n            list(gen([1,2,3]))\n            \"\"\",\n            arcz=\".1 .2 23 2. 32 15 5.\",\n        )\n\n    def test_padded_yield_in_loop(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def gen(inp):\n                i = 2\n                for n in inp:\n                    i = 4\n                    yield n\n                    i = 6\n                i = 7\n\n            list(gen([1,2,3]))\n            \"\"\",\n            arcz=\".1 19 9.  .2 23 34 45 56 63 37 7.\",\n        )\n\n    def test_bug_308(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def run():\n                for i in range(10):\n                    yield lambda: i\n\n            for f in run():\n                print(f())\n            \"\"\",\n            arcz=\".1 15 56 65 5.  .2 23 32 2.  -33 3-3\",\n        )\n        self.check_coverage(\"\"\"\\\n            def run():\n                yield lambda: 100\n                for i in range(10):\n                    yield lambda: i\n\n            for f in run():\n                print(f())\n            \"\"\",\n            arcz=\".1 16 67 76 6.  .2 23 34 43 3.   -22 2-2  -44 4-4\",\n        )\n        self.check_coverage(\"\"\"\\\n            def run():\n                yield lambda: 100  # no branch miss\n\n            for f in run():\n                print(f())\n            \"\"\",\n            arcz=\".1 14 45 54 4.  .2 2.  -22 2-2\",\n        )\n\n    def test_bug_324(self) -> None:\n        # This code is tricky: the list() call pulls all the values from gen(),\n        # but each of them is a generator itself that is never iterated.  As a\n        # result, the generator expression on line 3 is never entered or run.\n        self.check_coverage(\"\"\"\\\n            def gen(inp):\n                for n in inp:\n                    yield (i * 2 for i in range(n))\n\n            list(gen([1,2,3]))\n            \"\"\",\n            arcz=\n                \".1 15 5. \"     # The module level\n                \".2 23 32 2. \"  # The gen() function\n                \"-33 3-3\",      # The generator expression\n            arcz_missing=\"-33 3-3\",\n        )\n\n    def test_coroutines(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def double_inputs():\n                while len([1]):     # avoid compiler differences\n                    x = yield\n                    x *= 2\n                    yield x\n\n            gen = double_inputs()\n            next(gen)\n            print(gen.send(10))\n            next(gen)\n            print(gen.send(6))\n            \"\"\",\n            arcz=\".1 17 78 89 9A AB B. .2 23 34 45 52 2.\",\n            arcz_missing=\"2.\",\n        )\n        assert self.stdout() == \"20\\n12\\n\"\n\n    def test_yield_from(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def gen(inp):\n                i = 2\n                for n in inp:\n                    i = 4\n                    yield from range(3)\n                    i = 6\n                i = 7\n\n            list(gen([1,2,3]))\n            \"\"\",\n            arcz=\".1 19 9.  .2 23 34 45 56 63 37 7.\",\n        )\n\n    def test_abandoned_yield(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/440\n        self.check_coverage(\"\"\"\\\n            def gen():\n                print(2)\n                yield 3\n                print(4)\n\n            print(next(gen()))\n            \"\"\",\n            lines=[1, 2, 3, 4, 6],\n            missing=\"4\",\n            arcz=\".1 16 6.  .2 23 34 4.\",\n            arcz_missing=\"34 4.\",\n        )\n        assert self.stdout() == \"2\\n3\\n\"\n\n\n@pytest.mark.skipif(not env.PYBEHAVIOR.match_case, reason=\"Match-case is new in 3.10\")\nclass MatchCaseTest(CoverageTest):\n    \"\"\"Tests of match-case.\"\"\"\n    def test_match_case_with_default(self) -> None:\n        self.check_coverage(\"\"\"\\\n            for command in [\"huh\", \"go home\", \"go n\"]:\n                match command.split():\n                    case [\"go\", direction] if direction in \"nesw\":\n                        match = f\"go: {direction}\"\n                    case [\"go\", _]:\n                        match = \"no go\"\n                    case _:\n                        match = \"default\"\n                print(match)\n            \"\"\",\n            arcz=\".1 12 23 34 49 35 56 69 57 78 89 91 1.\",\n        )\n        assert self.stdout() == \"default\\nno go\\ngo: n\\n\"\n\n    def test_match_case_with_wildcard(self) -> None:\n        self.check_coverage(\"\"\"\\\n            for command in [\"huh\", \"go home\", \"go n\"]:\n                match command.split():\n                    case [\"go\", direction] if direction in \"nesw\":\n                        match = f\"go: {direction}\"\n                    case [\"go\", _]:\n                        match = \"no go\"\n                    case x:\n                        match = f\"default: {x}\"\n                print(match)\n            \"\"\",\n            arcz=\".1 12 23 34 49 35 56 69 57 78 89 91 1.\",\n        )\n        assert self.stdout() == \"default: ['huh']\\nno go\\ngo: n\\n\"\n\n    def test_match_case_without_wildcard(self) -> None:\n        self.check_coverage(\"\"\"\\\n            match = None\n            for command in [\"huh\", \"go home\", \"go n\"]:\n                match command.split():\n                    case [\"go\", direction] if direction in \"nesw\":\n                        match = f\"go: {direction}\"\n                    case [\"go\", _]:\n                        match = \"no go\"\n                print(match)\n            \"\"\",\n            arcz=\".1 12 23 34 45 58 46 78 67 68 82 2.\",\n        )\n        assert self.stdout() == \"None\\nno go\\ngo: n\\n\"\n\n    def test_absurd_wildcards(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1421\n        self.check_coverage(\"\"\"\\\n            def absurd(x):\n                match x:\n                    case (3 | 99 | (999 | _)):\n                        print(\"default\")\n            absurd(5)\n            \"\"\",\n            # No arc from 3 to 5 because 3 always matches.\n            arcz=\".1 15 5.  .2 23 34 4.\",\n        )\n        assert self.stdout() == \"default\\n\"\n        self.check_coverage(\"\"\"\\\n            def absurd(x):\n                match x:\n                    case (3 | 99 | 999 as y):\n                        print(\"not default\")\n            absurd(5)\n            \"\"\",\n            arcz=\".1 15 5.  .2 23 34 3. 4.\",\n            arcz_missing=\"34 4.\",\n        )\n        assert self.stdout() == \"\"\n        self.check_coverage(\"\"\"\\\n            def absurd(x):\n                match x:\n                    case (3 | 17 as y):\n                        print(\"not default\")\n                    case 7: # 5\n                        print(\"also not default\")\n            absurd(7)\n            \"\"\",\n            arcz=\".1 17 7.  .2 23 34 4. 35 56 5. 6.\",\n            arcz_missing=\"34 4. 5.\",\n        )\n        assert self.stdout() == \"also not default\\n\"\n        self.check_coverage(\"\"\"\\\n            def absurd(x):\n                match x:\n                    case 3:\n                        print(\"not default\")\n                    case _ if x == 7: # 5\n                        print(\"also not default\")\n            absurd(7)\n            \"\"\",\n            arcz=\".1 17 7.  .2 23 34 4. 35 56 5. 6.\",\n            arcz_missing=\"34 4. 5.\",\n        )\n        assert self.stdout() == \"also not default\\n\"\n\n\nclass OptimizedIfTest(CoverageTest):\n    \"\"\"Tests of if statements being optimized away.\"\"\"\n\n    def test_optimized_away_if_0(self) -> None:\n        if env.PYBEHAVIOR.keep_constant_test:\n            lines = [1, 2, 3, 4, 8, 9]\n            arcz = \".1 12 23 24 34 48 49 89 9.\"\n            arcz_missing = \"24\"\n            # 49 isn't missing because line 4 is matched by the default partial\n            # exclusion regex, and no branches are considered missing if they\n            # start from an excluded line.\n        else:\n            lines = [1, 2, 3, 8, 9]\n            arcz = \".1 12 23 28 38 89 9.\"\n            arcz_missing = \"28\"\n\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if len([2]):\n                c = 3\n            if 0:\n                if len([5]):\n                    d = 6\n            else:\n                e = 8\n            f = 9\n            \"\"\",\n            lines=lines,\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n        )\n\n    def test_optimized_away_if_1(self) -> None:\n        if env.PYBEHAVIOR.keep_constant_test:\n            lines = [1, 2, 3, 4, 5, 6, 9]\n            arcz = \".1 12 23 24 34 45 49 56 69 59 9.\"\n            arcz_missing = \"24 59\"\n            # 49 isn't missing because line 4 is matched by the default partial\n            # exclusion regex, and no branches are considered missing if they\n            # start from an excluded line.\n        else:\n            lines = [1, 2, 3, 5, 6, 9]\n            arcz = \".1 12 23 25 35 56 69 59 9.\"\n            arcz_missing = \"25 59\"\n\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if len([2]):\n                c = 3\n            if 1:\n                if len([5]):\n                    d = 6\n            else:\n                e = 8\n            f = 9\n            \"\"\",\n            lines=lines,\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n        )\n\n    def test_optimized_away_if_1_no_else(self) -> None:\n        if env.PYBEHAVIOR.keep_constant_test:\n            lines = [1, 2, 3, 4, 5]\n            arcz = \".1 12 23 25 34 45 5.\"\n            arcz_missing = \"\"\n            # 25 isn't missing because line 2 is matched by the default partial\n            # exclusion regex, and no branches are considered missing if they\n            # start from an excluded line.\n        else:\n            lines = [1, 3, 4, 5]\n            arcz = \".1 13 34 45 5.\"\n            arcz_missing = \"\"\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if 1:\n                b = 3\n                c = 4\n            d = 5\n            \"\"\",\n            lines=lines,\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n        )\n\n    def test_optimized_if_nested(self) -> None:\n        if env.PYBEHAVIOR.keep_constant_test:\n            lines = [1, 2, 8, 11, 12, 13, 14, 15]\n            arcz = \".1 12 28 2F 8B 8F BC CD DE EF F.\"\n            arcz_missing = \"\"\n            # 2F and 8F aren't missing because they're matched by the default\n            # partial exclusion regex, and no branches are considered missing\n            # if they start from an excluded line.\n        else:\n            lines = [1, 12, 14, 15]\n            arcz = \".1 1C CE EF F.\"\n            arcz_missing = \"\"\n\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if 0:\n                if 0:\n                    b = 4\n                else:\n                    c = 6\n            else:\n                if 0:\n                    d = 9\n                else:\n                    if 0: e = 11\n                    f = 12\n                    if 0: g = 13\n                    h = 14\n            i = 15\n            \"\"\",\n            lines=lines,\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n        )\n\n    def test_dunder_debug(self) -> None:\n        # Since some of our tests use __debug__, let's make sure it is true as\n        # we expect\n        assert __debug__\n        # Check that executed code has __debug__\n        self.check_coverage(\"\"\"\\\n            assert __debug__, \"assert __debug__\"\n            \"\"\",\n        )\n        # Check that if it didn't have debug, it would let us know.\n        with pytest.raises(AssertionError):\n            self.check_coverage(\"\"\"\\\n                assert not __debug__, \"assert not __debug__\"\n                \"\"\",\n            )\n\n    def test_if_debug(self) -> None:\n        if env.PYBEHAVIOR.optimize_if_debug:\n            arcz = \".1 12 24 41 26 61 1.\"\n            arcz_missing = \"\"\n        else:\n            arcz = \".1 12 23 31 34 41 26 61 1.\"\n            arcz_missing = \"31\"\n        self.check_coverage(\"\"\"\\\n            for value in [True, False]:\n                if value:\n                    if __debug__:\n                        x = 4\n                else:\n                    x = 6\n            \"\"\",\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n        )\n\n    @xfail_pypy_3882\n    def test_if_not_debug(self) -> None:\n        if env.PYBEHAVIOR.optimize_if_not_debug == 1:\n            arcz = \".1 12 23 34 42 37 72 28 8.\"\n        elif env.PYBEHAVIOR.optimize_if_not_debug == 2:\n            arcz = \".1 12 23 35 52 37 72 28 8.\"\n        else:\n            assert env.PYBEHAVIOR.optimize_if_not_debug == 3\n            arcz = \".1 12 23 32 37 72 28 8.\"\n\n        self.check_coverage(\"\"\"\\\n            lines = set()\n            for value in [True, False]:\n                if value:\n                    if not __debug__:\n                        lines.add(5)\n                else:\n                    lines.add(7)\n            assert lines == set([7])\n            \"\"\",\n            arcz=arcz,\n        )\n\n\nclass MiscArcTest(CoverageTest):\n    \"\"\"Miscellaneous arc-measuring tests.\"\"\"\n\n    def test_dict_literal(self) -> None:\n        self.check_coverage(\"\"\"\\\n            d = {\n                'a': 2,\n                'b': 3,\n                'c': {\n                    'd': 5,\n                    'e': 6,\n                    }\n                }\n            assert d\n            \"\"\",\n            arcz=\".1 19 9.\",\n        )\n        self.check_coverage(\"\"\"\\\n            d = \\\\\n                { 'a': 2,\n                'b': 3,\n                'c': {\n                    'd': 5,\n                    'e': 6,\n                    }\n                }\n            assert d\n            \"\"\",\n            arcz=\".1 19 9.\",\n        )\n\n    def test_unpacked_literals(self) -> None:\n        self.check_coverage(\"\"\"\\\n            d = {\n                'a': 2,\n                'b': 3,\n            }\n            weird = {\n                **d,\n                **{'c': 7},\n                'd': 8,\n            }\n            assert weird['b'] == 3\n            \"\"\",\n            arcz=\".1 15 5A A.\",\n        )\n        self.check_coverage(\"\"\"\\\n            l = [\n                2,\n                3,\n            ]\n            weird = [\n                *l,\n                *[7],\n                8,\n            ]\n            assert weird[1] == 3\n            \"\"\",\n            arcz=\".1 15 5A A.\",\n        )\n\n    @pytest.mark.parametrize(\"n\", [10, 50, 100, 500, 1000, 2000, 10000])\n    def test_pathologically_long_code_object(self, n: int) -> None:\n        # https://github.com/nedbat/coveragepy/issues/359\n        # Long code objects sometimes cause problems. Originally, it was\n        # due to EXTENDED_ARG bytes codes.  Then it showed a mistake in\n        # line-number packing.\n        code = \"\"\"\\\n            data = [\n            \"\"\" + \"\".join(f\"\"\"\\\n                [\n                    {i}, {i}, {i}, {i}, {i}, {i}, {i}, {i}, {i}, {i}],\n            \"\"\" for i in range(n)\n            ) + \"\"\"\\\n            ]\n\n            print(len(data))\n            \"\"\"\n        self.check_coverage(code, arcs=[(-1, 1), (1, 2*n+4), (2*n+4, -1)])\n        assert self.stdout() == f\"{n}\\n\"\n\n    def test_partial_generators(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/475\n        # Line 2 is executed completely.\n        # Line 3 is started but not finished, because zip ends before it finishes.\n        # Line 4 is never started.\n        cov = self.check_coverage(\"\"\"\\\n            def f(a, b):\n                c = (i for i in a)          # 2\n                d = (j for j in b)          # 3\n                e = (k for k in b)          # 4\n                return dict(zip(c, d))\n\n            f(['a', 'b'], [1, 2, 3])\n            \"\"\",\n            arcz=\".1 17 7.  .2 23 34 45 5.  -22 2-2  -33 3-3  -44 4-4\",\n            arcz_missing=\"3-3 -44 4-4\",\n        )\n        expected = \"line 3 didn't finish the generator expression on line 3\"\n        assert self.get_missing_arc_description(cov, 3, -3) == expected\n        expected = \"line 4 didn't run the generator expression on line 4\"\n        assert self.get_missing_arc_description(cov, 4, -4) == expected\n\n\nclass DecoratorArcTest(CoverageTest):\n    \"\"\"Tests of arcs with decorators.\"\"\"\n\n    def test_function_decorator(self) -> None:\n        arcz = (\n            \".1 16 67 7A AE EF F. \"     # main line\n            \".2 24 4.   -23 3-2 \"       # decorators\n            \"-6D D-6 \"                  # my_function\n        )\n        if env.PYBEHAVIOR.trace_decorator_line_again:\n            arcz += \"A7 76 6A \"\n        self.check_coverage(\"\"\"\\\n            def decorator(arg):\n                def _dec(f):\n                    return f\n                return _dec\n\n            @decorator(6)\n            @decorator(\n                len([8]),\n            )\n            def my_function(\n                a=len([11]),\n            ):\n                x = 13\n            a = 14\n            my_function()\n            \"\"\",\n            arcz=arcz,\n        )\n\n    @xfail_pypy38\n    def test_class_decorator(self) -> None:\n        arcz = (\n            \".1 16 67 6D 7A AE E. \"     # main line\n            \".2 24 4.   -23 3-2 \"       # decorators\n            \"-66 D-6 \"                  # MyObject\n        )\n        if env.PYBEHAVIOR.trace_decorator_line_again:\n            arcz += \"A7 76 6A \"\n        self.check_coverage(\"\"\"\\\n            def decorator(arg):\n                def _dec(c):\n                    return c\n                return _dec\n\n            @decorator(6)\n            @decorator(\n                len([8]),\n            )\n            class MyObject(\n                object\n            ):\n                X = 13\n            a = 14\n            \"\"\",\n            arcz=arcz,\n        )\n\n    def test_bug_466a(self) -> None:\n        # A bad interaction between decorators and multi-line list assignments,\n        # believe it or not...!\n        arcz = \".1 1A A.  13 34 4.  -35 58 8-3 \"\n        if env.PYBEHAVIOR.trace_decorator_line_again:\n            arcz += \"43 \"\n        # This example makes more sense when considered in tandem with 466b below.\n        self.check_coverage(\"\"\"\\\n            class Parser(object):\n\n                @classmethod\n                def parse(cls):\n                    formats = [ 5 ]\n\n\n                    return None\n\n            Parser.parse()\n            \"\"\",\n            arcz=arcz,\n        )\n\n    def test_bug_466b(self) -> None:\n        # A bad interaction between decorators and multi-line list assignments,\n        # believe it or not...!\n        arcz = \".1 1A A.  13 34 4.  -35 58 8-3 \"\n        if env.PYBEHAVIOR.trace_decorator_line_again:\n            arcz += \"43 \"\n        self.check_coverage(\"\"\"\\\n            class Parser(object):\n\n                @classmethod\n                def parse(cls):\n                    formats = [\n                        6,\n                    ]\n                    return None\n\n            Parser.parse()\n            \"\"\",\n            arcz=arcz,\n        )\n\n\nclass LambdaArcTest(CoverageTest):\n    \"\"\"Tests of lambdas\"\"\"\n\n    def test_multiline_lambda(self) -> None:\n        self.check_coverage(\"\"\"\\\n            fn = (lambda x:\n                    x + 2\n            )\n            assert fn(4) == 6\n            \"\"\",\n            arcz=\".1 14 4-1   1-1\",\n        )\n        self.check_coverage(\"\"\"\\\n\n            fn = \\\\\n                (\n                lambda\n                    x:\n                    x\n                    +\n                    8\n            )\n            assert fn(10) == 18\n            \"\"\",\n            arcz=\"-22 2A A-2   2-2\",\n        )\n\n    def test_unused_lambdas_are_confusing_bug_90(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1\n            fn = lambda x: x\n            b = 3\n            \"\"\",\n            arcz=\".1 12 -22 2-2 23 3.\", arcz_missing=\"-22 2-2\",\n        )\n\n    def test_raise_with_lambda_looks_like_partial_branch(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def ouch(fn):\n                2/0\n            a = b = c = d = 3\n            try:\n                a = ouch(lambda: 5)\n                if a:\n                    b = 7\n            except ZeroDivisionError:\n                c = 9\n            d = 10\n            assert (a, b, c, d) == (3, 3, 9, 10)\n            \"\"\",\n            lines=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n            missing=\"6-7\",\n            arcz=\".1 13 34 45 56 67 6A 7A 89 9A AB B.   .2 2.  -55 5-5\",\n            arcz_missing=\"56 67 6A 7A  -55 5-5\",\n            arcz_unpredicted=\"58\",\n        )\n\n    def test_lambda_in_dict(self) -> None:\n        self.check_coverage(\"\"\"\\\n            x = 1\n            x = 2\n            d = {\n                4: lambda: [],\n                5: lambda: [],\n                6: lambda: [],\n                7: lambda: [],\n            }\n\n            for k, v in d.items():          # 10\n                if k & 1:\n                    v()\n            \"\"\",\n            arcz=\".1 12 23 3A AB BC BA CA A.  -33  3-3\",\n        )\n\n\n# This had been a failure on Mac 3.9, but it started passing on GitHub\n# actions (running macOS 12) but still failed on my laptop (macOS 14).\n# I don't understand why it failed, I don't understand why it passed,\n# so just skip the whole thing.\nskip_eventlet_670 = pytest.mark.skipif(\n    env.PYVERSION[:2] == (3, 9) and env.CPYTHON and env.OSX,\n    reason=\"Avoid an eventlet bug on Mac 3.9: eventlet#670\",\n    # https://github.com/eventlet/eventlet/issues/670\n)\n\n\nclass AsyncTest(CoverageTest):\n    \"\"\"Tests of the new async and await keywords in Python 3.5\"\"\"\n\n    @skip_eventlet_670\n    def test_async(self) -> None:\n        self.check_coverage(\"\"\"\\\n            import asyncio\n\n            async def compute(x, y):                        # 3\n                print(f\"Compute {x} + {y} ...\")\n                await asyncio.sleep(0.001)\n                return x + y                                # 6\n\n            async def print_sum(x, y):                      # 8\n                result = (0 +\n                            await compute(x, y)             # A\n                )\n                print(f\"{x} + {y} = {result}\")\n\n            loop = asyncio.new_event_loop()                 # E\n            loop.run_until_complete(print_sum(1, 2))\n            loop.close()                                    # G\n            \"\"\",\n            arcz=\n                \".1 13 38 8E EF FG G. \" +\n                \"-34 45 56 6-3 \" +\n                \"-89 9C C-8\",\n        )\n        assert self.stdout() == \"Compute 1 + 2 ...\\n1 + 2 = 3\\n\"\n\n    @skip_eventlet_670\n    def test_async_for(self) -> None:\n        self.check_coverage(\"\"\"\\\n            import asyncio\n\n            class AsyncIteratorWrapper:                 # 3\n                def __init__(self, obj):                # 4\n                    self._it = iter(obj)\n\n                def __aiter__(self):                    # 7\n                    return self\n\n                async def __anext__(self):              # A\n                    try:\n                        return next(self._it)\n                    except StopIteration:\n                        raise StopAsyncIteration\n\n            async def doit():                           # G\n                async for letter in AsyncIteratorWrapper(\"abc\"):\n                    print(letter)\n                print(\".\")\n\n            loop = asyncio.new_event_loop()             # L\n            loop.run_until_complete(doit())\n            loop.close()\n            \"\"\",\n            arcz=\n                \".1 13 3G GL LM MN N. \"     # module main line\n                \"-33 34 47 7A A-3 \"         # class definition\n                \"-GH HI IH HJ J-G \"         # doit\n                \"-45 5-4 \"                  # __init__\n                \"-78 8-7 \"                  # __aiter__\n                \"-AB BC C-A DE E-A \",       # __anext__\n            arcz_unpredicted=\"CD\",\n        )\n        assert self.stdout() == \"a\\nb\\nc\\n.\\n\"\n\n    def test_async_with(self) -> None:\n        if env.PYBEHAVIOR.exit_through_with:\n            arcz = \".1 1. .2 23 32 2.\"\n            arcz_missing = \".2 23 32 2.\"\n        else:\n            arcz = \".1 1. .2 23 3.\"\n            arcz_missing = \".2 23 3.\"\n        self.check_coverage(\"\"\"\\\n            async def go():\n                async with x:\n                    pass\n            \"\"\",\n            arcz=arcz,\n            arcz_missing=arcz_missing,\n        )\n\n    def test_async_decorator(self) -> None:\n        arcz = \".1 14 45 5.  .2 2.  -46 6-4 \"\n        if env.PYBEHAVIOR.trace_decorator_line_again:\n            arcz += \"54 \"\n        self.check_coverage(\"\"\"\\\n            def wrap(f):        # 1\n                return f\n\n            @wrap               # 4\n            async def go():\n                return\n            \"\"\",\n            arcz=arcz,\n            arcz_missing='-46 6-4',\n        )\n\n    # https://github.com/nedbat/coveragepy/issues/1158\n    # https://bugs.python.org/issue44621\n    @pytest.mark.skipif(env.PYVERSION[:2] == (3, 9), reason=\"avoid a 3.9 bug: 44621\")\n    def test_bug_1158(self) -> None:\n        self.check_coverage(\"\"\"\\\n            import asyncio\n\n            async def async_gen():\n                yield 4\n\n            async def async_test():\n                global a\n                a = 8\n                async for i in async_gen():\n                    print(i + 10)\n                else:\n                    a = 12\n\n            asyncio.run(async_test())\n            assert a == 12\n            \"\"\",\n            arcz=\".1 13 36 6E EF F.  -34 4-3  -68 89 9A 9C A9 C-6\",\n        )\n        assert self.stdout() == \"14\\n\"\n\n    # https://github.com/nedbat/coveragepy/issues/1176\n    # https://bugs.python.org/issue44622\n    @skip_eventlet_670\n    def test_bug_1176(self) -> None:\n        self.check_coverage(\"\"\"\\\n            import asyncio\n\n            async def async_gen():\n                yield 4\n\n            async def async_test():\n                async for i in async_gen():\n                    print(i + 8)\n\n            asyncio.run(async_test())\n            \"\"\",\n            arcz=\".1 13 36 6A A.  -34 4-3  -67 78 87 7-6\",\n        )\n        assert self.stdout() == \"12\\n\"\n\n    # https://github.com/nedbat/coveragepy/issues/1205\n    def test_bug_1205(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def func():\n                if T(2):\n                    if T(3):\n                        if F(4):\n                            if X(5):\n                                return 6\n                    else:\n                        return 8\n                elif X(9) and Y:\n                    return 10\n\n            T, F = (lambda _: True), (lambda _: False)\n            func()\n            \"\"\",\n            arcz=\".1 1C CD D.  .2 23 29 34 38 45 4. 56 5. 6. 8. 9. 9A A.  -CC C-C\",\n            arcz_missing=\"29 38 45 56 5. 6. 8. 9. 9A A.\",\n        )\n\n\nclass AnnotationTest(CoverageTest):\n    \"\"\"Tests using type annotations.\"\"\"\n\n    def test_annotations(self) -> None:\n        self.check_coverage(\"\"\"\\\n            def f(x:str, y:int) -> str:\n                a:int = 2\n                return f\"{x}, {y}, {a}, 3\"\n            print(f(\"x\", 4))\n            \"\"\",\n            arcz=\".1 .2 23 3.  14 4.\",\n        )\n        assert self.stdout() == \"x, 4, 2, 3\\n\"\n\n\nclass ExcludeTest(CoverageTest):\n    \"\"\"Tests of exclusions to indicate known partial branches.\"\"\"\n\n    def test_default(self) -> None:\n        # A number of forms of pragma comment are accepted.\n        self.check_coverage(\"\"\"\\\n            a = 1\n            if a:   #pragma: no branch\n                b = 3\n            c = 4\n            if c:   # pragma NOBRANCH\n                d = 6\n            e = 7\n            if e:#\\tpragma:\\tno branch\n                f = 9\n            \"\"\",\n            [1,2,3,4,5,6,7,8,9],\n            arcz=\".1 12 23 24 34 45 56 57 67 78 89 9. 8.\",\n        )\n\n    def test_custom_pragmas(self) -> None:\n        self.check_coverage(\"\"\"\\\n            a = 1\n            while a:    # [only some]\n                c = 3\n                break\n            assert c == 5-2\n            \"\"\",\n            [1,2,3,4,5],\n            partials=[\"only some\"],\n            arcz=\".1 12 23 34 45 25 5.\",\n        )\n\n\nclass LineDataTest(CoverageTest):\n    \"\"\"Tests that line_data gives us what we expect.\"\"\"\n\n    def test_branch(self) -> None:\n        cov = coverage.Coverage(branch=True)\n\n        self.make_file(\"fun1.py\", \"\"\"\\\n            def fun1(x):\n                if x == 1:\n                    return\n\n            fun1(3)\n            \"\"\")\n\n        self.start_import_stop(cov, \"fun1\")\n\n        data = cov.get_data()\n        fun1_lines = sorted_lines(data, abs_file(\"fun1.py\"))\n        assert_count_equal(fun1_lines, [1, 2, 5])\n", "tests/goldtest.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"A test base class for tests based on gold file comparison.\"\"\"\n\nfrom __future__ import annotations\n\nimport difflib\nimport filecmp\nimport fnmatch\nimport os\nimport os.path\nimport re\nimport xml.etree.ElementTree\n\nfrom typing import Iterable\n\nfrom tests.coveragetest import TESTS_DIR\nfrom tests.helpers import os_sep\n\n\ndef gold_path(path: str) -> str:\n    \"\"\"Get a path to a gold file for comparison.\"\"\"\n    return os.path.join(TESTS_DIR, \"gold\", path)\n\n\ndef compare(\n    expected_dir: str,\n    actual_dir: str,\n    file_pattern: str | None = None,\n    actual_extra: bool = False,\n    scrubs: list[tuple[str, str]] | None = None,\n) -> None:\n    \"\"\"Compare files matching `file_pattern` in `expected_dir` and `actual_dir`.\n\n    `actual_extra` true means `actual_dir` can have extra files in it\n    without triggering an assertion.\n\n    `scrubs` is a list of pairs: regexes to find and replace to scrub the\n    files of unimportant differences.\n\n    If a comparison fails, a message will be written to stdout, the original\n    unscrubbed output of the test will be written to an \"/actual/\" directory\n    alongside the \"/gold/\" directory, and an assertion will be raised.\n\n    \"\"\"\n    __tracebackhide__ = True    # pytest, please don't show me this function.\n    assert os_sep(\"/gold/\") in expected_dir\n    assert os.path.exists(actual_dir)\n    os.makedirs(expected_dir, exist_ok=True)\n\n    dc = filecmp.dircmp(expected_dir, actual_dir)\n    diff_files = _fnmatch_list(dc.diff_files, file_pattern)\n    expected_only = _fnmatch_list(dc.left_only, file_pattern)\n    actual_only = _fnmatch_list(dc.right_only, file_pattern)\n\n    def save_mismatch(f: str) -> None:\n        \"\"\"Save a mismatched result to tests/actual.\"\"\"\n        save_path = expected_dir.replace(os_sep(\"/gold/\"), os_sep(\"/actual/\"))\n        os.makedirs(save_path, exist_ok=True)\n        save_file = os.path.join(save_path, f)\n        with open(save_file, \"w\") as savef:\n            with open(os.path.join(actual_dir, f)) as readf:\n                savef.write(readf.read())\n                print(os_sep(f\"Saved actual output to '{save_file}': see tests/gold/README.rst\"))\n\n    # filecmp only compares in binary mode, but we want text mode.  So\n    # look through the list of different files, and compare them\n    # ourselves.\n    text_diff = []\n    for f in diff_files:\n        expected_file = os.path.join(expected_dir, f)\n        with open(expected_file) as fobj:\n            expected = fobj.read()\n        if expected_file.endswith(\".xml\"):\n            expected = canonicalize_xml(expected)\n\n        actual_file = os.path.join(actual_dir, f)\n        with open(actual_file) as fobj:\n            actual = fobj.read()\n        if actual_file.endswith(\".xml\"):\n            actual = canonicalize_xml(actual)\n\n        if scrubs:\n            expected = scrub(expected, scrubs)\n            actual = scrub(actual, scrubs)\n        if expected != actual:\n            text_diff.append(f'{expected_file} != {actual_file}')\n            expected_lines = expected.splitlines()\n            actual_lines = actual.splitlines()\n            print(f\":::: diff '{expected_file}' and '{actual_file}'\")\n            print(\"\\n\".join(difflib.Differ().compare(expected_lines, actual_lines)))\n            print(f\":::: end diff '{expected_file}' and '{actual_file}'\")\n            save_mismatch(f)\n\n    if not actual_extra:\n        for f in actual_only:\n            save_mismatch(f)\n\n    assert not text_diff, \"Files differ: \" + \"\\n\".join(text_diff)\n\n    assert not expected_only, f\"Files in {os.path.abspath(expected_dir)} only: {expected_only}\"\n    if not actual_extra:\n        assert not actual_only, f\"Files in {os.path.abspath(actual_dir)} only: {actual_only}\"\n\n\ndef contains(filename: str, *strlist: str) -> None:\n    \"\"\"Check that the file contains all of a list of strings.\n\n    An assert will be raised if one of the arguments in `strlist` is\n    missing in `filename`.\n\n    \"\"\"\n    __tracebackhide__ = True    # pytest, please don't show me this function.\n    with open(filename) as fobj:\n        text = fobj.read()\n    for s in strlist:\n        assert s in text, f\"Missing content in {filename}: {s!r}\"\n\n\ndef contains_rx(filename: str, *rxlist: str) -> None:\n    \"\"\"Check that the file has lines that re.search all of the regexes.\n\n    An assert will be raised if one of the regexes in `rxlist` doesn't match\n    any lines in `filename`.\n\n    \"\"\"\n    __tracebackhide__ = True    # pytest, please don't show me this function.\n    with open(filename) as fobj:\n        lines = fobj.readlines()\n    for rx in rxlist:\n        assert any(re.search(rx, line) for line in lines), (\n            f\"Missing regex in {filename}: r{rx!r}\"\n        )\n\n\ndef contains_any(filename: str, *strlist: str) -> None:\n    \"\"\"Check that the file contains at least one of a list of strings.\n\n    An assert will be raised if none of the arguments in `strlist` is in\n    `filename`.\n\n    \"\"\"\n    __tracebackhide__ = True    # pytest, please don't show me this function.\n    with open(filename) as fobj:\n        text = fobj.read()\n    for s in strlist:\n        if s in text:\n            return\n\n    assert False, f\"Missing content in {filename}: {strlist[0]!r} [1 of {len(strlist)}]\"\n\n\ndef doesnt_contain(filename: str, *strlist: str) -> None:\n    \"\"\"Check that the file contains none of a list of strings.\n\n    An assert will be raised if any of the strings in `strlist` appears in\n    `filename`.\n\n    \"\"\"\n    __tracebackhide__ = True    # pytest, please don't show me this function.\n    with open(filename) as fobj:\n        text = fobj.read()\n    for s in strlist:\n        assert s not in text, f\"Forbidden content in {filename}: {s!r}\"\n\n\n# Helpers\n\ndef canonicalize_xml(xtext: str) -> str:\n    \"\"\"Canonicalize some XML text.\"\"\"\n    root = xml.etree.ElementTree.fromstring(xtext)\n    for node in root.iter():\n        node.attrib = dict(sorted(node.items()))\n    return xml.etree.ElementTree.tostring(root).decode(\"utf-8\")\n\n\ndef _fnmatch_list(files: list[str], file_pattern: str | None) -> list[str]:\n    \"\"\"Filter the list of `files` to only those that match `file_pattern`.\n    If `file_pattern` is None, then return the entire list of files.\n    Returns a list of the filtered files.\n    \"\"\"\n    if file_pattern:\n        files = [f for f in files if fnmatch.fnmatch(f, file_pattern)]\n    return files\n\n\ndef scrub(strdata: str, scrubs: Iterable[tuple[str, str]]) -> str:\n    \"\"\"Scrub uninteresting data from the payload in `strdata`.\n    `scrubs` is a list of (find, replace) pairs of regexes that are used on\n    `strdata`.  A string is returned.\n    \"\"\"\n    for rx_find, rx_replace in scrubs:\n        strdata = re.sub(rx_find, rx_replace, strdata)\n    return strdata\n", "tests/coveragetest.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Base test case class for coverage.py testing.\"\"\"\n\nfrom __future__ import annotations\n\nimport contextlib\nimport datetime\nimport difflib\nimport glob\nimport io\nimport os\nimport os.path\nimport random\nimport re\nimport shlex\nimport sys\n\nfrom types import ModuleType\nfrom typing import (\n    Any, Collection, Iterable, Iterator, Mapping, Sequence,\n)\n\nimport coverage\nfrom coverage import Coverage\nfrom coverage.cmdline import CoverageScript\nfrom coverage.data import CoverageData\nfrom coverage.misc import import_local_file\nfrom coverage.types import TArc, TLineNo\n\nfrom tests.helpers import arcs_to_arcz_repr, arcz_to_arcs, assert_count_equal\nfrom tests.helpers import nice_file, run_command\nfrom tests.mixins import PytestBase, StdStreamCapturingMixin, RestoreModulesMixin, TempDirMixin\n\n\n# Status returns for the command line.\nOK, ERR = 0, 1\n\n# The coverage/tests directory, for all sorts of finding test helping things.\nTESTS_DIR = os.path.dirname(__file__)\n\n# Install arguments to pass to pip when reinstalling ourselves.\n# Defaults to the top of the source tree, but can be overridden if we need\n# some help on certain platforms.\nCOVERAGE_INSTALL_ARGS = os.getenv(\"COVERAGE_INSTALL_ARGS\", nice_file(TESTS_DIR, \"..\"))\n\n\nclass CoverageTest(\n    StdStreamCapturingMixin,\n    RestoreModulesMixin,\n    TempDirMixin,\n    PytestBase,\n):\n    \"\"\"A base class for coverage.py test cases.\"\"\"\n\n    # Standard unittest setting: show me diffs even if they are very long.\n    maxDiff = None\n\n    # Tell newer unittest implementations to print long helpful messages.\n    longMessage = True\n\n    # Let stderr go to stderr, pytest will capture it for us.\n    show_stderr = True\n\n    def setUp(self) -> None:\n        super().setUp()\n\n        # Attributes for getting info about what happened.\n        self.last_command_status: int | None = None\n        self.last_command_output: str | None = None\n        self.last_module_name: str | None = None\n\n    def start_import_stop(\n        self,\n        cov: Coverage,\n        modname: str,\n        modfile: str | None = None,\n    ) -> ModuleType:\n        \"\"\"Start coverage, import a file, then stop coverage.\n\n        `cov` is started and stopped, with an `import_local_file` of\n        `modname` in the middle. `modfile` is the file to import as `modname`\n        if it isn't in the current directory.\n\n        The imported module is returned.\n\n        \"\"\"\n        # Here's something I don't understand. I tried changing the code to use\n        # the handy context manager, like this:\n        #\n        #   with cov.collect():\n        #       # Import the Python file, executing it.\n        #       return import_local_file(modname, modfile)\n        #\n        # That seemed to work, until 7.4.0 when it made metacov fail after\n        # running all the tests.  The deep recursion tests in test_oddball.py\n        # seemed to cause something to be off so that a \"Trace function\n        # changed\" error would happen as pytest was cleaning up, failing the\n        # metacov runs.  Putting back the old code below fixes it, but I don't\n        # understand the difference.\n\n        cov.start()\n        try:                                    # pragma: nested\n            # Import the Python file, executing it.\n            mod = import_local_file(modname, modfile)\n        finally:                                # pragma: nested\n            # Stop coverage.py.\n            cov.stop()\n        return mod\n\n    def get_report(self, cov: Coverage, squeeze: bool = True, **kwargs: Any) -> str:\n        \"\"\"Get the report from `cov`, and canonicalize it.\"\"\"\n        repout = io.StringIO()\n        kwargs.setdefault(\"show_missing\", False)\n        cov.report(file=repout, **kwargs)\n        report = repout.getvalue().replace('\\\\', '/')\n        print(report)   # When tests fail, it's helpful to see the output\n        if squeeze:\n            report = re.sub(r\" +\", \" \", report)\n        return report\n\n    def get_module_name(self) -> str:\n        \"\"\"Return a random module name to use for this test run.\"\"\"\n        self.last_module_name = 'coverage_test_' + str(random.random())[2:]\n        return self.last_module_name\n\n    def _check_arcs(\n        self,\n        a1: Iterable[TArc] | None,\n        a2: Iterable[TArc] | None,\n        arc_type: str,\n    ) -> str:\n        \"\"\"Check that the arc lists `a1` and `a2` are equal.\n\n        If they are equal, return empty string. If they are unequal, return\n        a string explaining what is different.\n        \"\"\"\n        # Make them into multi-line strings so we can see what's going wrong.\n        s1 = arcs_to_arcz_repr(a1)\n        s2 = arcs_to_arcz_repr(a2)\n        if s1 != s2:\n            lines1 = s1.splitlines(True)\n            lines2 = s2.splitlines(True)\n            diff = \"\".join(difflib.ndiff(lines1, lines2))\n            return \"\\n\" + arc_type + \" arcs differ: minus is expected, plus is actual\\n\" + diff\n        else:\n            return \"\"\n\n    def check_coverage(\n        self,\n        text: str,\n        lines: Sequence[TLineNo] | Sequence[list[TLineNo]] | None = None,\n        missing: str = \"\",\n        report: str = \"\",\n        excludes: Iterable[str] | None = None,\n        partials: Iterable[str] = (),\n        arcz: str | None = None,\n        arcz_missing: str | None = None,\n        arcz_unpredicted: str | None = None,\n        arcs: Iterable[TArc] | None = None,\n        arcs_missing: Iterable[TArc] | None = None,\n        arcs_unpredicted: Iterable[TArc] | None = None,\n    ) -> Coverage:\n        \"\"\"Check the coverage measurement of `text`.\n\n        The source `text` is run and measured.  `lines` are the line numbers\n        that are executable, or a list of possible line numbers, any of which\n        could match. `missing` are the lines not executed, `excludes` are\n        regexes to match against for excluding lines, and `report` is the text\n        of the measurement report.\n\n        For arc measurement, `arcz` is a string that can be decoded into arcs\n        in the code (see `arcz_to_arcs` for the encoding scheme).\n        `arcz_missing` are the arcs that are not executed, and\n        `arcz_unpredicted` are the arcs executed in the code, but not deducible\n        from the code.  These last two default to \"\", meaning we explicitly\n        check that there are no missing or unpredicted arcs.\n\n        Returns the Coverage object, in case you want to poke at it some more.\n\n        \"\"\"\n        __tracebackhide__ = True    # pytest, please don't show me this function.\n\n        # We write the code into a file so that we can import it.\n        # Coverage.py wants to deal with things as modules with file names.\n        modname = self.get_module_name()\n\n        self.make_file(modname + \".py\", text)\n\n        if arcs is None and arcz is not None:\n            arcs = arcz_to_arcs(arcz)\n        if arcs_missing is None and arcz_missing is not None:\n            arcs_missing = arcz_to_arcs(arcz_missing)\n        if arcs_unpredicted is None and arcz_unpredicted is not None:\n            arcs_unpredicted = arcz_to_arcs(arcz_unpredicted)\n\n        # Start up coverage.py.\n        cov = coverage.Coverage(branch=True)\n        cov.erase()\n        for exc in excludes or []:\n            cov.exclude(exc)\n        for par in partials or []:\n            cov.exclude(par, which='partial')\n\n        mod = self.start_import_stop(cov, modname)\n\n        # Clean up our side effects\n        del sys.modules[modname]\n\n        # Get the analysis results, and check that they are right.\n        analysis = cov._analyze(mod)\n        statements = sorted(analysis.statements)\n        if lines:\n            if isinstance(lines[0], int):\n                # lines is just a list of numbers, it must match the statements\n                # found in the code.\n                assert statements == lines, f\"lines: {statements!r} != {lines!r}\"\n            else:\n                # lines is a list of possible line number lists, one of them\n                # must match.\n                for line_list in lines:\n                    if statements == line_list:\n                        break\n                else:\n                    assert False, f\"None of the lines choices matched {statements!r}\"\n\n            missing_formatted = analysis.missing_formatted()\n            msg = f\"missing: {missing_formatted!r} != {missing!r}\"\n            assert missing_formatted == missing, msg\n\n        if arcs is not None:\n            # print(\"Possible arcs:\")\n            # print(\" expected:\", arcs)\n            # print(\" actual:\", analysis.arc_possibilities)\n            # print(\"Executed:\")\n            # print(\" actual:\", sorted(set(analysis.arcs_executed)))\n            # TODO: this would be nicer with pytest-check, once we can run that.\n            msg = (\n                self._check_arcs(arcs, analysis.arc_possibilities, \"Possible\") +\n                self._check_arcs(arcs_missing, analysis.arcs_missing(), \"Missing\") +\n                self._check_arcs(arcs_unpredicted, analysis.arcs_unpredicted(), \"Unpredicted\")\n            )\n            if msg:\n                assert False, msg\n\n        if report:\n            frep = io.StringIO()\n            cov.report(mod, file=frep, show_missing=True)\n            rep = \" \".join(frep.getvalue().split(\"\\n\")[2].split()[1:])\n            assert report == rep, f\"{report!r} != {rep!r}\"\n\n        return cov\n\n    def make_data_file(\n        self,\n        basename: str | None = None,\n        *,\n        suffix: str | None = None,\n        lines: Mapping[str, Collection[TLineNo]] | None = None,\n        arcs: Mapping[str, Collection[TArc]] | None = None,\n        file_tracers: Mapping[str, str] | None = None,\n    ) -> CoverageData:\n        \"\"\"Write some data into a coverage data file.\"\"\"\n        data = coverage.CoverageData(basename=basename, suffix=suffix)\n        assert lines is None or arcs is None\n        if lines:\n            data.add_lines(lines)\n        if arcs:\n            data.add_arcs(arcs)\n        if file_tracers:\n            data.add_file_tracers(file_tracers)\n        data.write()\n        return data\n\n    @contextlib.contextmanager\n    def assert_warnings(\n        self,\n        cov: Coverage,\n        warnings: Iterable[str],\n        not_warnings: Iterable[str] = (),\n    ) -> Iterator[None]:\n        \"\"\"A context manager to check that particular warnings happened in `cov`.\n\n        `cov` is a Coverage instance.  `warnings` is a list of regexes.  Every\n        regex must match a warning that was issued by `cov`.  It is OK for\n        extra warnings to be issued by `cov` that are not matched by any regex.\n        Warnings that are disabled are still considered issued by this function.\n\n        `not_warnings` is a list of regexes that must not appear in the\n        warnings.  This is only checked if there are some positive warnings to\n        test for in `warnings`.\n\n        If `warnings` is empty, then `cov` is not allowed to issue any\n        warnings.\n\n        \"\"\"\n        __tracebackhide__ = True\n        saved_warnings = []\n        def capture_warning(\n            msg: str,\n            slug: str | None = None,\n            once: bool = False,                 # pylint: disable=unused-argument\n        ) -> None:\n            \"\"\"A fake implementation of Coverage._warn, to capture warnings.\"\"\"\n            # NOTE: we don't implement `once`.\n            if slug:\n                msg = f\"{msg} ({slug})\"\n            saved_warnings.append(msg)\n\n        original_warn = cov._warn\n        cov._warn = capture_warning             # type: ignore[method-assign]\n\n        try:\n            yield\n        except:                     # pylint: disable=try-except-raise\n            raise\n        else:\n            if warnings:\n                for warning_regex in warnings:\n                    for saved in saved_warnings:\n                        if re.search(warning_regex, saved):\n                            break\n                    else:\n                        msg = f\"Didn't find warning {warning_regex!r} in {saved_warnings!r}\"\n                        assert False, msg\n                for warning_regex in not_warnings:\n                    for saved in saved_warnings:\n                        if re.search(warning_regex, saved):\n                            msg = f\"Found warning {warning_regex!r} in {saved_warnings!r}\"\n                            assert False, msg\n            else:\n                # No warnings expected. Raise if any warnings happened.\n                if saved_warnings:\n                    assert False, f\"Unexpected warnings: {saved_warnings!r}\"\n        finally:\n            cov._warn = original_warn           # type: ignore[method-assign]\n\n    def assert_same_files(self, flist1: Iterable[str], flist2: Iterable[str]) -> None:\n        \"\"\"Assert that `flist1` and `flist2` are the same set of file names.\"\"\"\n        flist1_nice = [nice_file(f) for f in flist1]\n        flist2_nice = [nice_file(f) for f in flist2]\n        assert_count_equal(flist1_nice, flist2_nice)\n\n    def assert_exists(self, fname: str) -> None:\n        \"\"\"Assert that `fname` is a file that exists.\"\"\"\n        assert os.path.exists(fname), f\"File {fname!r} should exist\"\n\n    def assert_doesnt_exist(self, fname: str) -> None:\n        \"\"\"Assert that `fname` is a file that doesn't exist.\"\"\"\n        assert not os.path.exists(fname), f\"File {fname!r} shouldn't exist\"\n\n    def assert_file_count(self, pattern: str, count: int) -> None:\n        \"\"\"Assert that there are `count` files matching `pattern`.\"\"\"\n        files = sorted(glob.glob(pattern))\n        msg = \"There should be {} files matching {!r}, but there are these: {}\"\n        msg = msg.format(count, pattern, files)\n        assert len(files) == count, msg\n\n    def assert_recent_datetime(\n        self,\n        dt: datetime.datetime,\n        seconds: int = 10,\n        msg: str | None = None,\n    ) -> None:\n        \"\"\"Assert that `dt` marks a time at most `seconds` seconds ago.\"\"\"\n        age = datetime.datetime.now() - dt\n        assert age.total_seconds() >= 0, msg\n        assert age.total_seconds() <= seconds, msg\n\n    def command_line(self, args: str, ret: int = OK) -> None:\n        \"\"\"Run `args` through the command line.\n\n        Use this when you want to run the full coverage machinery, but in the\n        current process.  Exceptions may be thrown from deep in the code.\n        Asserts that `ret` is returned by `CoverageScript.command_line`.\n\n        Compare with `run_command`.\n\n        Returns None.\n\n        \"\"\"\n        ret_actual = command_line(args)\n        assert ret_actual == ret, f\"{ret_actual!r} != {ret!r}\"\n\n    # Some distros rename the coverage command, and need a way to indicate\n    # their new command name to the tests. This is here for them to override,\n    # for example:\n    # https://salsa.debian.org/debian/pkg-python-coverage/-/blob/master/debian/patches/02.rename-public-programs.patch\n    coverage_command = \"coverage\"\n\n    def run_command(self, cmd: str) -> str:\n        \"\"\"Run the command-line `cmd` in a sub-process.\n\n        `cmd` is the command line to invoke in a sub-process. Returns the\n        combined content of `stdout` and `stderr` output streams from the\n        sub-process.\n\n        See `run_command_status` for complete semantics.\n\n        Use this when you need to test the process behavior of coverage.\n\n        Compare with `command_line`.\n\n        \"\"\"\n        _, output = self.run_command_status(cmd)\n        return output\n\n    def run_command_status(self, cmd: str) -> tuple[int, str]:\n        \"\"\"Run the command-line `cmd` in a sub-process, and print its output.\n\n        Use this when you need to test the process behavior of coverage.\n\n        Compare with `command_line`.\n\n        Handles the following command names specially:\n\n        * \"python\" is replaced with the command name of the current\n            Python interpreter.\n\n        * \"coverage\" is replaced with the command name for the main\n            coverage.py program.\n\n        Returns a pair: the process' exit status and its stdout/stderr text,\n        which are also stored as `self.last_command_status` and\n        `self.last_command_output`.\n\n        \"\"\"\n        # Make sure \"python\" and \"coverage\" mean specifically what we want\n        # them to mean.\n        split_commandline = cmd.split()\n        command_name = split_commandline[0]\n        command_args = split_commandline[1:]\n\n        if command_name == \"python\":\n            # Running a Python interpreter in a sub-processes can be tricky.\n            # Use the real name of our own executable. So \"python foo.py\" might\n            # get executed as \"python3.3 foo.py\". This is important because\n            # Python 3.x doesn't install as \"python\", so you might get a Python\n            # 2 executable instead if you don't use the executable's basename.\n            command_words = [os.path.basename(sys.executable)]\n\n        elif command_name == \"coverage\":\n            # The invocation requests the coverage.py program.  Substitute the\n            # actual coverage.py main command name.\n            command_words = [self.coverage_command]\n\n        else:\n            command_words = [command_name]\n\n        cmd = \" \".join([shlex.quote(w) for w in command_words] + command_args)\n\n        self.last_command_status, self.last_command_output = run_command(cmd)\n        print(self.last_command_output)\n        return self.last_command_status, self.last_command_output\n\n    def add_test_modules_to_pythonpath(self) -> None:\n        \"\"\"Add our test modules directory to PYTHONPATH.\"\"\"\n        # Check that there isn't already a PYTHONPATH.\n        assert os.getenv(\"PYTHONPATH\") is None\n        testmods = nice_file(self.working_root(), \"tests/modules\")\n        zipfile = nice_file(self.working_root(), \"tests/zipmods.zip\")\n        self.set_environ(\"PYTHONPATH\", testmods + os.pathsep + zipfile)\n\n    def working_root(self) -> str:\n        \"\"\"Where is the root of the coverage.py working tree?\"\"\"\n        return os.path.dirname(nice_file(__file__, \"..\"))\n\n    def report_from_command(self, cmd: str) -> str:\n        \"\"\"Return the report from the `cmd`, with some convenience added.\"\"\"\n        report = self.run_command(cmd).replace('\\\\', '/')\n        assert \"error\" not in report.lower()\n        return report\n\n    def report_lines(self, report: str) -> list[str]:\n        \"\"\"Return the lines of the report, as a list.\"\"\"\n        lines = report.split('\\n')\n        assert lines[-1] == \"\"\n        return lines[:-1]\n\n    def line_count(self, report: str) -> int:\n        \"\"\"How many lines are in `report`?\"\"\"\n        return len(self.report_lines(report))\n\n    def squeezed_lines(self, report: str) -> list[str]:\n        \"\"\"Return a list of the lines in report, with the spaces squeezed.\"\"\"\n        lines = self.report_lines(report)\n        return [re.sub(r\"\\s+\", \" \", l.strip()) for l in lines]\n\n    def last_line_squeezed(self, report: str) -> str:\n        \"\"\"Return the last line of `report` with the spaces squeezed down.\"\"\"\n        return self.squeezed_lines(report)[-1]\n\n    def get_measured_filenames(self, coverage_data: CoverageData) -> dict[str, str]:\n        \"\"\"Get paths to measured files.\n\n        Returns a dict of {filename: absolute path to file}\n        for given CoverageData.\n        \"\"\"\n        return {os.path.basename(filename): filename\n                for filename in coverage_data.measured_files()}\n\n    def get_missing_arc_description(self, cov: Coverage, start: TLineNo, end: TLineNo) -> str:\n        \"\"\"Get the missing-arc description for a line arc in a coverage run.\"\"\"\n        # ugh, unexposed methods??\n        assert self.last_module_name is not None\n        filename = self.last_module_name + \".py\"\n        fr = cov._get_file_reporter(filename)\n        arcs_executed = cov._analyze(filename).arcs_executed\n        return fr.missing_arc_description(start, end, arcs_executed)\n\n\nclass UsingModulesMixin:\n    \"\"\"A mixin for importing modules from tests/modules and tests/moremodules.\"\"\"\n\n    def setUp(self) -> None:\n        super().setUp()             # type: ignore[misc]\n\n        # Parent class saves and restores sys.path, we can just modify it.\n        sys.path.append(nice_file(TESTS_DIR, \"modules\"))\n        sys.path.append(nice_file(TESTS_DIR, \"moremodules\"))\n        sys.path.append(nice_file(TESTS_DIR, \"zipmods.zip\"))\n\n\ndef command_line(args: str) -> int:\n    \"\"\"Run `args` through the CoverageScript command line.\n\n    Returns the return code from CoverageScript.command_line.\n\n    \"\"\"\n    script = CoverageScript()\n    ret = script.command_line(shlex.split(args))\n    return ret\n", "tests/test_mixins.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests of code in tests/mixins.py\"\"\"\n\nfrom __future__ import annotations\n\nimport pytest\n\nfrom coverage.misc import import_local_file\n\nfrom tests.mixins import TempDirMixin, RestoreModulesMixin\n\n\nclass TempDirMixinTest(TempDirMixin):\n    \"\"\"Test the methods in TempDirMixin.\"\"\"\n\n    def file_text(self, fname: str) -> str:\n        \"\"\"Return the text read from a file.\"\"\"\n        with open(fname, \"rb\") as f:\n            return f.read().decode('ascii')\n\n    def test_make_file(self) -> None:\n        # A simple file.\n        self.make_file(\"fooey.boo\", \"Hello there\")\n        assert self.file_text(\"fooey.boo\") == \"Hello there\"\n        # A file in a sub-directory\n        self.make_file(\"sub/another.txt\", \"Another\")\n        assert self.file_text(\"sub/another.txt\") == \"Another\"\n        # A second file in that sub-directory\n        self.make_file(\"sub/second.txt\", \"Second\")\n        assert self.file_text(\"sub/second.txt\") == \"Second\"\n        # A deeper directory\n        self.make_file(\"sub/deeper/evenmore/third.txt\")\n        assert self.file_text(\"sub/deeper/evenmore/third.txt\") == \"\"\n        # Dedenting\n        self.make_file(\"dedented.txt\", \"\"\"\\\n            Hello\n            Bye\n            \"\"\")\n        assert self.file_text(\"dedented.txt\") == \"Hello\\nBye\\n\"\n\n    def test_make_file_newline(self) -> None:\n        self.make_file(\"unix.txt\", \"Hello\\n\")\n        assert self.file_text(\"unix.txt\") == \"Hello\\n\"\n        self.make_file(\"dos.txt\", \"Hello\\n\", newline=\"\\r\\n\")\n        assert self.file_text(\"dos.txt\") == \"Hello\\r\\n\"\n        self.make_file(\"mac.txt\", \"Hello\\n\", newline=\"\\r\")\n        assert self.file_text(\"mac.txt\") == \"Hello\\r\"\n\n    def test_make_file_non_ascii(self) -> None:\n        self.make_file(\"unicode.txt\", \"tablo: \u00ab\u03c4\u03b1\u0411\u2113\u03c3\u00bb\")\n        with open(\"unicode.txt\", \"rb\") as f:\n            text = f.read()\n        assert text == b\"tablo: \\xc2\\xab\\xcf\\x84\\xce\\xb1\\xd0\\x91\\xe2\\x84\\x93\\xcf\\x83\\xc2\\xbb\"\n\n    def test_make_bytes_file(self) -> None:\n        self.make_file(\"binary.dat\", bytes=b\"\\x99\\x33\\x66hello\\0\")\n        with open(\"binary.dat\", \"rb\") as f:\n            data = f.read()\n        assert data == b\"\\x99\\x33\\x66hello\\0\"\n\n\nclass RestoreModulessMixinTest(TempDirMixin, RestoreModulesMixin):\n    \"\"\"Tests of SysPathModulesMixin.\"\"\"\n\n    @pytest.mark.parametrize(\"val\", [17, 42])\n    def test_module_independence(self, val: int) -> None:\n        self.make_file(\"xyzzy.py\", f\"A = {val}\")\n        import xyzzy            # pylint: disable=import-error\n        assert xyzzy.A == val\n\n    def test_cleanup_and_reimport(self) -> None:\n        self.make_file(\"xyzzy.py\", \"A = 17\")\n        xyzzy = import_local_file(\"xyzzy\")\n        assert xyzzy.A == 17\n\n        self.clean_local_file_imports()\n\n        self.make_file(\"xyzzy.py\", \"A = 42\")\n        xyzzy = import_local_file(\"xyzzy\")\n        assert xyzzy.A == 42\n", "tests/test_regions.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage/regions.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport textwrap\nfrom pathlib import Path\n\nimport pytest\n\nimport coverage\nfrom coverage import env\nfrom coverage.plugin import CodeRegion\nfrom coverage.regions import code_regions\n\n\nskip_pypy38 = pytest.mark.skipif(\n    env.PYPY and env.PYVERSION < (3, 9),\n    reason=\"PyPy 3.8 somehow gets different results from ast?\",\n    # But PyPy 3.8 is almost out of support so meh.\n)\n\n@skip_pypy38\ndef test_code_regions() -> None:\n    regions = code_regions(textwrap.dedent(\"\"\"\\\n        # Numbers in this code are the line number.\n        '''Module docstring'''\n\n        CONST = 4\n        class MyClass:\n            class_attr = 6\n\n            def __init__(self):\n                self.x = 9\n\n            def method_a(self):\n                self.x = 12\n                def inmethod():\n                    self.x = 14\n                    class DeepInside:\n                        def method_b():\n                            self.x = 17\n                        class Deeper:\n                            def bb():\n                                self.x = 20\n                self.y = 21\n\n            class InnerClass:\n                constant = 24\n                def method_c(self):\n                    self.x = 26\n\n        def func():\n            x = 29\n            y = 30\n            def inner():\n                z = 32\n                def inner_inner():\n                    w = 34\n\n            class InsideFunc:\n                def method_d(self):\n                    self.x = 38\n\n            return 40\n\n        async def afunc():\n            x = 43\n    \"\"\"))\n\n    F = \"function\"\n    C = \"class\"\n\n    assert sorted(regions) == sorted([\n        CodeRegion(F, \"MyClass.__init__\", start=8, lines={9}),\n        CodeRegion(F, \"MyClass.method_a\", start=11, lines={12, 13, 21}),\n        CodeRegion(F, \"MyClass.method_a.inmethod\", start=13, lines={14, 15, 16, 18, 19}),\n        CodeRegion(F, \"MyClass.method_a.inmethod.DeepInside.method_b\", start=16, lines={17}),\n        CodeRegion(F, \"MyClass.method_a.inmethod.DeepInside.Deeper.bb\", start=19, lines={20}),\n        CodeRegion(F, \"MyClass.InnerClass.method_c\", start=25, lines={26}),\n        CodeRegion(F, \"func\", start=28, lines={29, 30, 31, 35, 36, 37, 39, 40}),\n        CodeRegion(F, \"func.inner\", start=31, lines={32, 33}),\n        CodeRegion(F, \"func.inner.inner_inner\", start=33, lines={34}),\n        CodeRegion(F, \"func.InsideFunc.method_d\", start=37, lines={38}),\n        CodeRegion(F, \"afunc\", start=42, lines={43}),\n        CodeRegion(C, \"MyClass\", start=5, lines={9, 12, 13, 14, 15, 16, 18, 19, 21}),\n        CodeRegion(C, \"MyClass.method_a.inmethod.DeepInside\", start=15, lines={17}),\n        CodeRegion(C, \"MyClass.method_a.inmethod.DeepInside.Deeper\", start=18, lines={20}),\n        CodeRegion(C, \"MyClass.InnerClass\", start=23, lines={26}),\n        CodeRegion(C, \"func.InsideFunc\", start=36, lines={38}),\n    ])\n\n\n@skip_pypy38\ndef test_real_code_regions() -> None:\n    # Run code_regions on most of the coverage source code, checking that it\n    # succeeds and there are no overlaps.\n\n    cov_dir = Path(coverage.__file__).parent.parent\n    any_fails = False\n    # To run against all the files in the tox venvs:\n    #   for source_file in cov_dir.rglob(\"*.py\"):\n    for sub in [\".\", \"ci\", \"coverage\", \"lab\", \"tests\"]:\n        for source_file in (cov_dir / sub).glob(\"*.py\"):\n            regions = code_regions(source_file.read_text(encoding=\"utf-8\"))\n            for kind in [\"function\", \"class\"]:\n                kind_regions = [reg for reg in regions if reg.kind == kind]\n                line_counts = collections.Counter(\n                    lno for reg in kind_regions for lno in reg.lines\n                )\n                overlaps = [line for line, count in line_counts.items() if count > 1]\n                if overlaps:    # pragma: only failure\n                    print(\n                        f\"{kind.title()} overlaps in {source_file.relative_to(Path.cwd())}: \"\n                        + f\"{overlaps}\"\n                    )\n                    any_fails = True\n    if any_fails:\n        pytest.fail(\"Overlaps were found\")  # pragma: only failure\n", "tests/mixins.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nTest class mixins\n\nSome of these are transitional while working toward pure-pytest style.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport importlib\nimport os\nimport os.path\nimport sys\n\nfrom typing import Any, Callable, Iterable, Iterator, Tuple, cast\n\nimport pytest\n\nfrom coverage.misc import SysModuleSaver\nfrom tests.helpers import change_dir, make_file, remove_tree\n\n\nclass PytestBase:\n    \"\"\"A base class to connect to pytest in a test class hierarchy.\"\"\"\n\n    @pytest.fixture(autouse=True)\n    def connect_to_pytest(\n        self,\n        request: pytest.FixtureRequest,\n        monkeypatch: pytest.MonkeyPatch,\n    ) -> None:\n        \"\"\"Captures pytest facilities for use by other test helpers.\"\"\"\n        # pylint: disable=attribute-defined-outside-init\n        self._pytest_request = request\n        self._monkeypatch = monkeypatch\n        self.setUp()\n\n    def setUp(self) -> None:\n        \"\"\"Per-test initialization. Override this as you wish.\"\"\"\n        pass\n\n    def addCleanup(self, fn: Callable[..., None], *args: Any) -> None:\n        \"\"\"Like unittest's addCleanup: code to call when the test is done.\"\"\"\n        self._pytest_request.addfinalizer(lambda: fn(*args))\n\n    def set_environ(self, name: str, value: str) -> None:\n        \"\"\"Set an environment variable `name` to be `value`.\"\"\"\n        self._monkeypatch.setenv(name, value)\n\n    def del_environ(self, name: str) -> None:\n        \"\"\"Delete an environment variable, unless we set it.\"\"\"\n        self._monkeypatch.delenv(name, raising=False)\n\n\nclass TempDirMixin:\n    \"\"\"Provides temp dir and data file helpers for tests.\"\"\"\n\n    # Our own setting: most of these tests run in their own temp directory.\n    # Set this to False in your subclass if you don't want a temp directory\n    # created.\n    run_in_temp_dir = True\n\n    @pytest.fixture(autouse=True)\n    def _temp_dir(self, tmp_path_factory: pytest.TempPathFactory) -> Iterator[None]:\n        \"\"\"Create a temp dir for the tests, if they want it.\"\"\"\n        if self.run_in_temp_dir:\n            tmpdir = tmp_path_factory.mktemp(\"t\")\n            self.temp_dir = str(tmpdir)\n            with change_dir(self.temp_dir):\n                # Modules should be importable from this temp directory.  We don't\n                # use '' because we make lots of different temp directories and\n                # nose's caching importer can get confused.  The full path prevents\n                # problems.\n                sys.path.insert(0, os.getcwd())\n                yield\n        else:\n            yield\n\n    def make_file(\n        self,\n        filename: str,\n        text: str = \"\",\n        bytes: bytes = b\"\",\n        newline: str | None = None,\n    ) -> str:\n        \"\"\"Make a file. See `tests.helpers.make_file`\"\"\"\n        # pylint: disable=redefined-builtin     # bytes\n        assert self.run_in_temp_dir, \"Only use make_file when running in a temp dir\"\n        return make_file(filename, text, bytes, newline)\n\n\nclass RestoreModulesMixin:\n    \"\"\"Auto-restore the imported modules at the end of each test.\"\"\"\n\n    @pytest.fixture(autouse=True)\n    def _module_saving(self) -> Iterable[None]:\n        \"\"\"Remove modules we imported during the test.\"\"\"\n        self._sys_module_saver = SysModuleSaver()\n        try:\n            yield\n        finally:\n            self._sys_module_saver.restore()\n\n    def clean_local_file_imports(self) -> None:\n        \"\"\"Clean up the results of calls to `import_local_file`.\n\n        Use this if you need to `import_local_file` the same file twice in\n        one test.\n\n        \"\"\"\n        # So that we can re-import files, clean them out first.\n        self._sys_module_saver.restore()\n\n        # Also have to clean out the .pyc files, since the time stamp\n        # resolution is only one second, a changed file might not be\n        # picked up.\n        remove_tree(\"__pycache__\")\n        importlib.invalidate_caches()\n\n\nclass StdStreamCapturingMixin:\n    \"\"\"\n    Adapter from the pytest capsys fixture to more convenient methods.\n\n    This doesn't also output to the real stdout, so we probably want to move\n    to \"real\" capsys when we can use fixtures in test methods.\n\n    Once you've used one of these methods, the capturing is reset, so another\n    invocation will only return the delta.\n\n    \"\"\"\n    @pytest.fixture(autouse=True)\n    def _capcapsys(self, capsys: pytest.CaptureFixture[str]) -> None:\n        \"\"\"Grab the fixture so our methods can use it.\"\"\"\n        self.capsys = capsys\n\n    def stdouterr(self) -> tuple[str, str]:\n        \"\"\"Returns (out, err), two strings for stdout and stderr.\"\"\"\n        return cast(Tuple[str, str], self.capsys.readouterr())\n\n    def stdout(self) -> str:\n        \"\"\"Returns a string, the captured stdout.\"\"\"\n        return self.capsys.readouterr().out\n\n    def stderr(self) -> str:\n        \"\"\"Returns a string, the captured stderr.\"\"\"\n        return self.capsys.readouterr().err\n", "tests/test_parser.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.py's code parsing.\"\"\"\n\nfrom __future__ import annotations\n\nimport textwrap\n\nimport pytest\n\nfrom coverage import env\nfrom coverage.exceptions import NotPython\nfrom coverage.parser import PythonParser\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import arcz_to_arcs, xfail_pypy38\n\n\nclass PythonParserTestBase(CoverageTest):\n    \"\"\"Tests for coverage.py's Python code parsing.\"\"\"\n\n    run_in_temp_dir = False\n\n    def parse_text(self, text: str, exclude: str = \"nocover\") -> PythonParser:\n        \"\"\"Parse `text` as source, and return the `PythonParser` used.\"\"\"\n        text = textwrap.dedent(text)\n        parser = PythonParser(text=text, exclude=exclude)\n        parser.parse_source()\n        return parser\n\n\nclass PythonParserTest(PythonParserTestBase):\n    \"\"\"Tests of coverage.parser.\"\"\"\n\n    def test_exit_counts(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            # check some basic branch counting\n            class Foo:\n                def foo(self, a):\n                    if a:\n                        return 5\n                    else:\n                        return 7\n\n            class Bar:\n                pass\n            \"\"\")\n        assert parser.exit_counts() == {\n            2:1, 3:1, 4:2, 5:1, 7:1, 9:1, 10:1,\n        }\n\n    def test_generator_exit_counts(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/324\n        parser = self.parse_text(\"\"\"\\\n            def gen(input):\n                for n in inp:\n                    yield (i * 2 for i in range(n))\n\n            list(gen([1,2,3]))\n            \"\"\")\n        assert parser.exit_counts() == {\n            1:1,    # def -> list\n            2:2,    # for -> yield; for -> exit\n            3:2,    # yield -> for;  genexp exit\n            5:1,    # list -> exit\n        }\n\n    def test_try_except(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            try:\n                a = 2\n            except ValueError:\n                a = 4\n            except ZeroDivideError:\n                a = 6\n            except:\n                a = 8\n            b = 9\n            \"\"\")\n        assert parser.exit_counts() == {\n            1: 1, 2:1, 3:2, 4:1, 5:2, 6:1, 7:1, 8:1, 9:1,\n        }\n\n    def test_excluded_classes(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            class Foo:\n                def __init__(self):\n                    pass\n\n            if len([]):     # nocover\n                class Bar:\n                    pass\n            \"\"\")\n        assert parser.exit_counts() == {\n            1:0, 2:1, 3:1,\n        }\n\n    def test_missing_branch_to_excluded_code(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            if fooey:\n                a = 2\n            else:   # nocover\n                a = 4\n            b = 5\n            \"\"\")\n        assert parser.exit_counts() == { 1:1, 2:1, 5:1 }\n        parser = self.parse_text(\"\"\"\\\n            def foo():\n                if fooey:\n                    a = 3\n                else:\n                    a = 5\n            b = 6\n            \"\"\")\n        assert parser.exit_counts() == { 1:1, 2:2, 3:1, 5:1, 6:1 }\n        parser = self.parse_text(\"\"\"\\\n            def foo():\n                if fooey:\n                    a = 3\n                else:   # nocover\n                    a = 5\n            b = 6\n            \"\"\")\n        assert parser.exit_counts() == { 1:1, 2:1, 3:1, 6:1 }\n\n    @pytest.mark.parametrize(\"text\", [\n        pytest.param(\"0 spaces\\n  2\\n 1\", id=\"bad_indent\"),\n        pytest.param(\"'''\", id=\"string_eof\"),\n        pytest.param(\"$hello\", id=\"dollar\"),\n        # on 3.10 this passes ast.parse but fails on tokenize.generate_tokens\n        pytest.param(\n            \"\\r'\\\\\\n'''\",\n            id=\"leading_newline_eof\",\n            marks=[\n                pytest.mark.skipif(env.PYVERSION >= (3, 12), reason=\"parses fine in 3.12\"),\n            ]\n        )\n    ])\n    def test_not_python(self, text: str) -> None:\n        msg = r\"Couldn't parse '<code>' as Python source: '.*' at line \\d+\"\n        with pytest.raises(NotPython, match=msg):\n            _ = self.parse_text(text)\n\n    def test_empty_decorated_function(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            def decorator(func):\n                return func\n\n            @decorator\n            def foo(self):\n                '''Docstring'''\n\n            @decorator\n            def bar(self):\n                pass\n            \"\"\")\n\n        expected_statements = {1, 2, 4, 5, 8, 9, 10}\n        expected_arcs = set(arcz_to_arcs(\".1 14 45 58 89 9.  .2 2.  -8A A-8\"))\n        expected_exits = {1: 1, 2: 1, 4: 1, 5: 1, 8: 1, 9: 1, 10: 1}\n\n        if env.PYBEHAVIOR.docstring_only_function:\n            # 3.7 changed how functions with only docstrings are numbered.\n            expected_arcs.update(set(arcz_to_arcs(\"-46 6-4\")))\n            expected_exits.update({6: 1})\n\n        if env.PYBEHAVIOR.trace_decorator_line_again:\n            expected_arcs.update(set(arcz_to_arcs(\"54 98\")))\n            expected_exits.update({9: 2, 5: 2})\n\n        assert expected_statements == parser.statements\n        assert expected_arcs == parser.arcs()\n        assert expected_exits == parser.exit_counts()\n\n    def test_module_docstrings(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            '''The docstring on line 1'''\n            a = 2\n            \"\"\")\n        assert {2} == parser.statements\n\n        parser = self.parse_text(\"\"\"\\\n            # Docstring is not line 1\n            '''The docstring on line 2'''\n            a = 3\n            \"\"\")\n        assert {3} == parser.statements\n\n    def test_fuzzed_double_parse(self) -> None:\n        # https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=50381\n        # The second parse used to raise `TypeError: 'NoneType' object is not iterable`\n        msg = (\n            r\"(EOF in multi-line statement)\"        # before 3.12.0b1\n            + r\"|(unmatched ']')\"                   # after 3.12.0b1\n        )\n        with pytest.raises(NotPython, match=msg):\n            self.parse_text(\"]\")\n        with pytest.raises(NotPython, match=msg):\n            self.parse_text(\"]\")\n\n\nclass ExclusionParserTest(PythonParserTestBase):\n    \"\"\"Tests for the exclusion code in PythonParser.\"\"\"\n\n    def test_simple(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            a = 1; b = 2\n\n            if len([]):\n                a = 4   # nocover\n            \"\"\",\n        )\n        assert parser.statements == {1,3}\n\n    def test_excluding_if_suite(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            a = 1; b = 2\n\n            if len([]):     # nocover\n                a = 4\n                b = 5\n                c = 6\n            assert a == 1 and b == 2\n            \"\"\",\n        )\n        assert parser.statements == {1,7}\n\n    def test_excluding_if_but_not_else_suite(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            a = 1; b = 2\n\n            if len([]):     # nocover\n                a = 4\n                b = 5\n                c = 6\n            else:\n                a = 8\n                b = 9\n            assert a == 8 and b == 9\n            \"\"\",\n        )\n        assert parser.statements == {1,8,9,10}\n\n    def test_excluding_else_suite(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            a = 1; b = 2\n\n            if 1==1:\n                a = 4\n                b = 5\n                c = 6\n            else:          # nocover\n                a = 8\n                b = 9\n            assert a == 4 and b == 5 and c == 6\n            \"\"\",\n        )\n        assert parser.statements == {1,3,4,5,6,10}\n        parser = self.parse_text(\"\"\"\\\n            a = 1; b = 2\n\n            if 1==1:\n                a = 4\n                b = 5\n                c = 6\n\n            # Lots of comments to confuse the else handler.\n            # more.\n\n            else:          # nocover\n\n            # Comments here too.\n\n                a = 8\n                b = 9\n            assert a == 4 and b == 5 and c == 6\n            \"\"\",\n        )\n        assert parser.statements == {1,3,4,5,6,17}\n\n    def test_excluding_oneline_if(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            def foo():\n                a = 2\n                if len([]): x = 3       # nocover\n                b = 4\n\n            foo()\n            \"\"\",\n        )\n        assert parser.statements == {1,2,4,6}\n\n    def test_excluding_a_colon_not_a_suite(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            def foo():\n                l = list(range(10))\n                a = l[:3]   # nocover\n                b = 4\n\n            foo()\n            \"\"\",\n        )\n        assert parser.statements == {1,2,4,6}\n\n    def test_excluding_for_suite(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            a = 0\n            for i in [1,2,3,4,5]:     # nocover\n                a += i\n            assert a == 15\n            \"\"\",\n        )\n        assert parser.statements == {1,4}\n        parser = self.parse_text(\"\"\"\\\n            a = 0\n            for i in [1,\n                2,3,4,\n                5]:                # nocover\n                a += i\n            assert a == 15\n            \"\"\",\n        )\n        assert parser.statements == {1,6}\n        parser = self.parse_text(\"\"\"\\\n            a = 0\n            for i in [1,2,3,4,5\n                ]:                        # nocover\n                a += i\n                break\n                a = 99\n            assert a == 1\n            \"\"\",\n        )\n        assert parser.statements == {1,7}\n\n    def test_excluding_for_else(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            a = 0\n            for i in range(5):\n                a += i+1\n                break\n            else:               # nocover\n                a = 123\n            assert a == 1\n            \"\"\",\n        )\n        assert parser.statements == {1,2,3,4,7}\n\n    def test_excluding_while(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            a = 3; b = 0\n            while a*b:           # nocover\n                b += 1\n                break\n            assert a == 3 and b == 0\n            \"\"\",\n        )\n        assert parser.statements == {1,5}\n        parser = self.parse_text(\"\"\"\\\n            a = 3; b = 0\n            while (\n                a*b\n                ):           # nocover\n                b += 1\n                break\n            assert a == 3 and b == 0\n            \"\"\",\n        )\n        assert parser.statements == {1,7}\n\n    def test_excluding_while_else(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            a = 3; b = 0\n            while a:\n                b += 1\n                break\n            else:           # nocover\n                b = 123\n            assert a == 3 and b == 1\n            \"\"\",\n        )\n        assert parser.statements == {1,2,3,4,7}\n\n    def test_excluding_try_except(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n            except:           # nocover\n                a = 99\n            assert a == 1\n            \"\"\",\n        )\n        assert parser.statements == {1,2,3,6}\n        parser = self.parse_text(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n                raise Exception(\"foo\")\n            except:\n                a = 99\n            assert a == 99\n            \"\"\",\n        )\n        assert parser.statements == {1,2,3,4,5,6,7}\n        parser = self.parse_text(\"\"\"\\\n            a = 0\n            try:\n                a = 1\n                raise Exception(\"foo\")\n            except ImportError:    # nocover\n                a = 99\n            except:\n                a = 123\n            assert a == 123\n            \"\"\",\n        )\n        assert parser.statements == {1,2,3,4,7,8,9}\n\n    def test_excluding_if_pass(self) -> None:\n        # From a comment on the coverage.py page by Michael McNeil Forbes:\n        parser = self.parse_text(\"\"\"\\\n            def f():\n                if False:    # pragma: nocover\n                    pass     # This line still reported as missing\n                if False:    # pragma: nocover\n                    x = 1    # Now it is skipped.\n\n            f()\n            \"\"\",\n        )\n        assert parser.statements == {1,7}\n\n    def test_multiline_if_no_branch(self) -> None:\n        # From https://github.com/nedbat/coveragepy/issues/754\n        parser = self.parse_text(\"\"\"\\\n            if (this_is_a_verylong_boolean_expression == True   # pragma: no branch\n                and another_long_expression and here_another_expression):\n                do_something()\n            \"\"\",\n        )\n        parser2 = self.parse_text(\"\"\"\\\n            if this_is_a_verylong_boolean_expression == True and another_long_expression \\\\\n                and here_another_expression:  # pragma: no branch\n                do_something()\n            \"\"\",\n        )\n        assert parser.statements == parser2.statements == {1, 3}\n        pragma_re = \".*pragma: no branch.*\"\n        assert parser.lines_matching(pragma_re) == parser2.lines_matching(pragma_re)\n\n    def test_excluding_function(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            def fn(foo):      # nocover\n                a = 1\n                b = 2\n                c = 3\n\n            x = 1\n            assert x == 1\n            \"\"\",\n        )\n        assert parser.statements == {6,7}\n        parser = self.parse_text(\"\"\"\\\n            a = 0\n            def very_long_function_to_exclude_name(very_long_argument1,\n            very_long_argument2):\n                pass\n            assert a == 0\n            \"\"\",\n            exclude=\"function_to_exclude\",\n        )\n        assert parser.statements == {1,5}\n        parser = self.parse_text(\"\"\"\\\n            a = 0\n            def very_long_function_to_exclude_name(\n                very_long_argument1,\n                very_long_argument2\n            ):\n                pass\n            assert a == 0\n            \"\"\",\n            exclude=\"function_to_exclude\",\n        )\n        assert parser.statements == {1,7}\n        parser = self.parse_text(\"\"\"\\\n            def my_func(\n                super_long_input_argument_0=0,\n                super_long_input_argument_1=1,\n                super_long_input_argument_2=2):\n                pass\n\n            def my_func_2(super_long_input_argument_0=0, super_long_input_argument_1=1, super_long_input_argument_2=2):\n                pass\n            \"\"\",\n            exclude=\"my_func\",\n        )\n        assert parser.statements == set()\n        parser = self.parse_text(\"\"\"\\\n            def my_func(\n                super_long_input_argument_0=0,\n                super_long_input_argument_1=1,\n                super_long_input_argument_2=2):\n                pass\n\n            def my_func_2(super_long_input_argument_0=0, super_long_input_argument_1=1, super_long_input_argument_2=2):\n                pass\n            \"\"\",\n            exclude=\"my_func_2\",\n        )\n        assert parser.statements == {1,5}\n        parser = self.parse_text(\"\"\"\\\n            def my_func       (\n                super_long_input_argument_0=0,\n                super_long_input_argument_1=1,\n                super_long_input_argument_2=2):\n                pass\n\n            def my_func_2    (super_long_input_argument_0=0, super_long_input_argument_1=1, super_long_input_argument_2=2):\n                pass\n            \"\"\",\n            exclude=\"my_func_2\",\n        )\n        assert parser.statements == {1,5}\n        parser = self.parse_text(\"\"\"\\\n            def my_func       (\n                super_long_input_argument_0=0,\n                super_long_input_argument_1=1,\n                super_long_input_argument_2=2):\n                pass\n\n            def my_func_2    (super_long_input_argument_0=0, super_long_input_argument_1=1, super_long_input_argument_2=2):\n                pass\n            \"\"\",\n            exclude=\"my_func\",\n        )\n        assert parser.statements == set()\n        parser = self.parse_text(\"\"\"\\\n            def my_func \\\n                (\n                super_long_input_argument_0=0,\n                super_long_input_argument_1=1\n                ):\n                pass\n\n            def my_func_2(super_long_input_argument_0=0, super_long_input_argument_1=1, super_long_input_argument_2=2):\n                pass\n            \"\"\",\n            exclude=\"my_func_2\",\n        )\n        assert parser.statements == {1,5}\n        parser = self.parse_text(\"\"\"\\\n            def my_func \\\n                (\n                super_long_input_argument_0=0,\n                super_long_input_argument_1=1\n                ):\n                pass\n\n            def my_func_2(super_long_input_argument_0=0, super_long_input_argument_1=1, super_long_input_argument_2=2):\n                pass\n            \"\"\",\n            exclude=\"my_func\",\n        )\n        assert parser.statements == set()\n\n    def test_excluding_bug1713(self) -> None:\n        if env.PYVERSION >= (3, 10):\n            parser = self.parse_text(\"\"\"\\\n                print(\"1\")\n\n                def hello_3(a):  # pragma: nocover\n                    match a:\n                        case (\"5\"\n                              | \"6\"):\n                            print(\"7\")\n                        case \"8\":\n                            print(\"9\")\n\n                print(\"11\")\n                \"\"\",\n            )\n            assert parser.statements == {1, 11}\n        parser = self.parse_text(\"\"\"\\\n            print(\"1\")\n\n            def hello_3(a):  # nocover\n                if (\"4\" or\n                    \"5\"):\n                    print(\"6\")\n                else:\n                    print(\"8\")\n\n            print(\"10\")\n            \"\"\",\n        )\n        assert parser.statements == {1, 10}\n        parser = self.parse_text(\"\"\"\\\n            print(1)\n\n            def func(a, b):\n                if a == 4:      # nocover\n                    func5()\n                    if b:\n                        print(7)\n                    func8()\n\n            print(10)\n            \"\"\",\n        )\n        assert parser.statements == {1, 3, 10}\n        parser = self.parse_text(\"\"\"\\\n            class Foo:  # pragma: nocover\n                def greet(self):\n                    print(\"hello world\")\n            \"\"\",\n        )\n        assert parser.statements == set()\n\n    def test_excluding_method(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            class Fooey:\n                def __init__(self):\n                    self.a = 1\n\n                def foo(self):     # nocover\n                    return self.a\n\n            x = Fooey()\n            assert x.a == 1\n            \"\"\",\n        )\n        assert parser.statements == {1,2,3,8,9}\n        parser = self.parse_text(\"\"\"\\\n            class Fooey:\n                def __init__(self):\n                    self.a = 1\n\n                def very_long_method_to_exclude_name(\n                    very_long_argument1,\n                    very_long_argument2\n                ):\n                    pass\n\n            x = Fooey()\n            assert x.a == 1\n            \"\"\",\n            exclude=\"method_to_exclude\",\n        )\n        assert parser.statements == {1,2,3,11,12}\n\n    def test_excluding_class(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            class Fooey:            # nocover\n                def __init__(self):\n                    self.a = 1\n\n                def foo(self):\n                    return self.a\n\n            x = 1\n            assert x == 1\n            \"\"\",\n        )\n        assert parser.statements == {8,9}\n\n    def test_excludes_non_ascii(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            # coding: utf-8\n            a = 1; b = 2\n\n            if len([]):\n                a = 5   # \u2718cover\n            \"\"\",\n            exclude=\"\u2718cover\",\n        )\n        assert parser.statements == {2, 4}\n\n    def test_formfeed(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/461\n        parser = self.parse_text(\"\"\"\\\n            x = 1\n            assert len([]) == 0, (\n                \"This won't happen %s\" % (\"hello\",)\n            )\n            \\f\n            x = 6\n            assert len([]) == 0, (\n                \"This won't happen %s\" % (\"hello\",)\n            )\n            \"\"\",\n            exclude=\"assert\",\n        )\n        assert parser.statements == {1, 6}\n\n    @xfail_pypy38\n    def test_decorator_pragmas(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            # 1\n\n            @foo(3)                     # nocover\n            @bar\n            def func(x, y=5):\n                return 6\n\n            class Foo:      # this is the only statement.\n                '''9'''\n                @foo                    # nocover\n                def __init__(self):\n                    '''12'''\n                    return 13\n\n                @foo(                   # nocover\n                    16,\n                    17,\n                )\n                def meth(self):\n                    return 20\n\n            @foo(                       # nocover\n                23\n            )\n            def func(x=25):\n                return 26\n            \"\"\")\n        raw_statements = {3, 4, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 22, 23, 25, 26}\n        assert parser.raw_statements == raw_statements\n        assert parser.statements == {8}\n\n    @xfail_pypy38\n    def test_decorator_pragmas_with_colons(self) -> None:\n        # A colon in a decorator expression would confuse the parser,\n        # ending the exclusion of the decorated function.\n        parser = self.parse_text(\"\"\"\\\n            @decorate(X)        # nocover\n            @decorate(\"Hello\"[2])\n            def f():\n                x = 4\n\n            @decorate(X)        # nocover\n            @decorate(\"Hello\"[:7])\n            def g():\n                x = 9\n            \"\"\")\n        raw_statements = {1, 2, 3, 4, 6, 7, 8, 9}\n        assert parser.raw_statements == raw_statements\n        assert parser.statements == set()\n\n    @pytest.mark.xfail(\n        env.PYPY and env.PYVERSION[:2] == (3, 8),\n        reason=\"AST doesn't mark end of classes correctly\",\n    )\n    def test_class_decorator_pragmas(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            class Foo(object):\n                def __init__(self):\n                    self.x = 3\n\n            @foo                        # nocover\n            class Bar(object):\n                def __init__(self):\n                    self.x = 8\n            \"\"\")\n        assert parser.raw_statements == {1, 2, 3, 5, 6, 7, 8}\n        assert parser.statements == {1, 2, 3}\n\n    def test_over_exclusion_bug1779(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1779\n        parser = self.parse_text(\"\"\"\\\n            import abc\n\n            class MyProtocol:               # nocover 3\n                @abc.abstractmethod         # nocover 4\n                def my_method(self) -> int:\n                    ...     # 6\n\n            def function() -> int:\n                return 9\n            \"\"\")\n        assert parser.raw_statements == {1, 3, 4, 5, 6, 8, 9}\n        assert parser.statements == {1, 8, 9}\n\n\nclass ParserMissingArcDescriptionTest(PythonParserTestBase):\n    \"\"\"Tests for PythonParser.missing_arc_description.\"\"\"\n\n    def test_missing_arc_description(self) -> None:\n        # This code is never run, so the actual values don't matter.\n        parser = self.parse_text(\"\"\"\\\n            if x:\n                print(2)\n            print(3)\n\n            def func5():\n                for x in range(6):\n                    if x == 7:\n                        break\n\n            def func10():\n                while something(11):\n                    thing(12)\n                more_stuff(13)\n            \"\"\")\n        expected = \"line 1 didn't jump to line 2 because the condition on line 1 was never true\"\n        assert expected == parser.missing_arc_description(1, 2)\n        expected = \"line 1 didn't jump to line 3 because the condition on line 1 was always true\"\n        assert expected == parser.missing_arc_description(1, 3)\n        expected = (\n            \"line 6 didn't return from function 'func5' \" +\n            \"because the loop on line 6 didn't complete\"\n        )\n        assert expected == parser.missing_arc_description(6, -5)\n        expected = \"line 6 didn't jump to line 7 because the loop on line 6 never started\"\n        assert expected == parser.missing_arc_description(6, 7)\n        expected = \"line 11 didn't jump to line 12 because the condition on line 11 was never true\"\n        assert expected == parser.missing_arc_description(11, 12)\n        expected = (\n            \"line 11 didn't jump to line 13 \" +\n            \"because the condition on line 11 was always true\"\n        )\n        assert expected == parser.missing_arc_description(11, 13)\n\n    def test_missing_arc_descriptions_for_small_callables(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            callables = [\n                lambda: 2,\n                (x for x in range(3)),\n                {x:1 for x in range(4)},\n                {x for x in range(5)},\n            ]\n            x = 7\n            \"\"\")\n        expected = \"line 2 didn't finish the lambda on line 2\"\n        assert expected == parser.missing_arc_description(2, -2)\n        expected = \"line 3 didn't finish the generator expression on line 3\"\n        assert expected == parser.missing_arc_description(3, -3)\n        if env.PYBEHAVIOR.comprehensions_are_functions:\n            expected = \"line 4 didn't finish the dictionary comprehension on line 4\"\n            assert expected == parser.missing_arc_description(4, -4)\n            expected = \"line 5 didn't finish the set comprehension on line 5\"\n            assert expected == parser.missing_arc_description(5, -5)\n\n    def test_missing_arc_descriptions_for_exceptions(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            try:\n                pass\n            except ZeroDivideError:\n                print(\"whoops\")\n            except ValueError:\n                print(\"yikes\")\n            \"\"\")\n        expected = (\n            \"line 3 didn't jump to line 4 \" +\n            \"because the exception caught by line 3 didn't happen\"\n        )\n        assert expected == parser.missing_arc_description(3, 4)\n        expected = (\n            \"line 5 didn't jump to line 6 \" +\n            \"because the exception caught by line 5 didn't happen\"\n        )\n        assert expected == parser.missing_arc_description(5, 6)\n\n    def test_missing_arc_descriptions_for_finally(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            def function():\n                for i in range(2):\n                    try:\n                        if something(4):\n                            break\n                        elif something(6):\n                            x = 7\n                        else:\n                            if something(9):\n                                continue\n                            else:\n                                continue\n                        if also_this(13):\n                            return 14\n                        else:\n                            raise Exception(16)\n                    finally:\n                        this_thing(18)\n                that_thing(19)\n            \"\"\")\n        if env.PYBEHAVIOR.finally_jumps_back:\n            expected = \"line 18 didn't jump to line 5 because the break on line 5 wasn't executed\"\n            assert expected == parser.missing_arc_description(18, 5)\n            expected = \"line 5 didn't jump to line 19 because the break on line 5 wasn't executed\"\n            assert expected == parser.missing_arc_description(5, 19)\n            expected = (\n                \"line 18 didn't jump to line 10 \" +\n                \"because the continue on line 10 wasn't executed\"\n            )\n            assert expected == parser.missing_arc_description(18, 10)\n            expected = (\n                \"line 10 didn't jump to line 2 \" +\n                \"because the continue on line 10 wasn't executed\"\n            )\n            assert expected == parser.missing_arc_description(10, 2)\n            expected = (\n                \"line 18 didn't jump to line 14 \" +\n                \"because the return on line 14 wasn't executed\"\n            )\n            assert expected == parser.missing_arc_description(18, 14)\n            expected = (\n                \"line 14 didn't return from function 'function' \" +\n                \"because the return on line 14 wasn't executed\"\n            )\n            assert expected == parser.missing_arc_description(14, -1)\n            expected = (\n                \"line 18 didn't except from function 'function' \" +\n                \"because the raise on line 16 wasn't executed\"\n            )\n            assert expected == parser.missing_arc_description(18, -1)\n        else:\n            expected = (\n                \"line 18 didn't jump to line 19 \" +\n                \"because the break on line 5 wasn't executed\"\n            )\n            assert expected == parser.missing_arc_description(18, 19)\n            expected = (\n                \"line 18 didn't jump to line 2 \" +\n                    \"because the continue on line 10 wasn't executed\" +\n                \" or \" +\n                    \"the continue on line 12 wasn't executed\"\n            )\n            assert expected == parser.missing_arc_description(18, 2)\n            expected = (\n                \"line 18 didn't except from function 'function' \" +\n                    \"because the raise on line 16 wasn't executed\" +\n                \" or \" +\n                \"line 18 didn't return from function 'function' \" +\n                    \"because the return on line 14 wasn't executed\"\n            )\n            assert expected == parser.missing_arc_description(18, -1)\n\n    def test_missing_arc_descriptions_bug460(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            x = 1\n            d = {\n                3: lambda: [],\n                4: lambda: [],\n            }\n            x = 6\n            \"\"\")\n        assert parser.missing_arc_description(2, -3) == \"line 3 didn't finish the lambda on line 3\"\n\n\n@pytest.mark.skipif(not env.PYBEHAVIOR.match_case, reason=\"Match-case is new in 3.10\")\nclass MatchCaseMissingArcDescriptionTest(PythonParserTestBase):\n    \"\"\"Missing arc descriptions for match/case.\"\"\"\n\n    def test_match_case(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            match command.split():\n                case [\"go\", direction] if direction in \"nesw\":      # 2\n                    match = f\"go: {direction}\"\n                case [\"go\", _]:                                     # 4\n                    match = \"no go\"\n            print(match)                                            # 6\n            \"\"\")\n        assert parser.missing_arc_description(2, 3) == (\n            \"line 2 didn't jump to line 3 because the pattern on line 2 never matched\"\n        )\n        assert parser.missing_arc_description(2, 4) == (\n            \"line 2 didn't jump to line 4 because the pattern on line 2 always matched\"\n        )\n        assert parser.missing_arc_description(4, 6) == (\n            \"line 4 didn't jump to line 6 because the pattern on line 4 always matched\"\n        )\n\n    def test_final_wildcard(self) -> None:\n        parser = self.parse_text(\"\"\"\\\n            match command.split():\n                case [\"go\", direction] if direction in \"nesw\":      # 2\n                    match = f\"go: {direction}\"\n                case _:                                             # 4\n                    match = \"no go\"\n            print(match)                                            # 6\n            \"\"\")\n        assert parser.missing_arc_description(2, 3) == (\n            \"line 2 didn't jump to line 3 because the pattern on line 2 never matched\"\n        )\n        assert parser.missing_arc_description(2, 4) == (\n            \"line 2 didn't jump to line 4 because the pattern on line 2 always matched\"\n        )\n        # 4-6 isn't a possible arc, so the description is generic.\n        assert parser.missing_arc_description(4, 6) == \"line 4 didn't jump to line 6\"\n\n\nclass ParserFileTest(CoverageTest):\n    \"\"\"Tests for coverage.py's code parsing from files.\"\"\"\n\n    def parse_file(self, filename: str) -> PythonParser:\n        \"\"\"Parse `text` as source, and return the `PythonParser` used.\"\"\"\n        parser = PythonParser(filename=filename, exclude=\"nocover\")\n        parser.parse_source()\n        return parser\n\n    @pytest.mark.parametrize(\"slug, newline\", [\n        (\"unix\", \"\\n\"), (\"dos\", \"\\r\\n\"), (\"mac\", \"\\r\"),\n    ])\n    def test_line_endings(self, slug: str, newline: str) -> None:\n        text = \"\"\"\\\n            # check some basic branch counting\n            class Foo:\n                def foo(self, a):\n                    if a:\n                        return 5\n                    else:\n                        return 7\n\n            class Bar:\n                pass\n            \"\"\"\n        counts = { 2:1, 3:1, 4:2, 5:1, 7:1, 9:1, 10:1 }\n        fname = slug + \".py\"\n        self.make_file(fname, text, newline=newline)\n        parser = self.parse_file(fname)\n        assert parser.exit_counts() == counts, f\"Wrong for {fname!r}\"\n\n    def test_encoding(self) -> None:\n        self.make_file(\"encoded.py\", \"\"\"\\\n            coverage = \"\\xe7\\xf6v\\xear\\xe3g\\xe9\"\n            \"\"\")\n        parser = self.parse_file(\"encoded.py\")\n        assert parser.exit_counts() == {1: 1}\n\n    def test_missing_line_ending(self) -> None:\n        # Test that the set of statements is the same even if a final\n        # multi-line statement has no final newline.\n        # https://github.com/nedbat/coveragepy/issues/293\n\n        self.make_file(\"normal.py\", \"\"\"\\\n            out, err = subprocess.Popen(\n                [sys.executable, '-c', 'pass'],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE).communicate()\n            \"\"\")\n\n        parser = self.parse_file(\"normal.py\")\n        assert parser.statements == {1}\n\n        self.make_file(\"abrupt.py\", \"\"\"\\\n            out, err = subprocess.Popen(\n                [sys.executable, '-c', 'pass'],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE).communicate()\"\"\")   # no final newline.\n\n        # Double-check that some test helper wasn't being helpful.\n        with open(\"abrupt.py\") as f:\n            assert f.read()[-1] == \")\"\n\n        parser = self.parse_file(\"abrupt.py\")\n        assert parser.statements == {1}\n", "tests/test_collector.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests of coverage/collector.py and other collectors.\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\n\nimport coverage\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import CheckUniqueFilenames\n\n\nclass CollectorTest(CoverageTest):\n    \"\"\"Test specific aspects of the collection process.\"\"\"\n\n    def test_should_trace_cache(self) -> None:\n        # The tracers should only invoke should_trace once for each file name.\n\n        # Make some files that invoke each other.\n        self.make_file(\"f1.py\", \"\"\"\\\n            def f1(x, f):\n                return f(x)\n            \"\"\")\n\n        self.make_file(\"f2.py\", \"\"\"\\\n            import f1\n\n            def func(x):\n                return f1.f1(x, otherfunc)\n\n            def otherfunc(x):\n                return x*x\n\n            for i in range(10):\n                func(i)\n            \"\"\")\n\n        # Trace one file, but not the other. CheckUniqueFilenames will assert\n        # that _should_trace hasn't been called twice for the same file.\n        cov = coverage.Coverage(include=[\"f1.py\"])\n        should_trace_hook = CheckUniqueFilenames.hook(cov, '_should_trace')\n\n        # Import the Python file, executing it.\n        self.start_import_stop(cov, \"f2\")\n\n        # Double-check that our files were checked.\n        abs_files = {os.path.abspath(f) for f in should_trace_hook.filenames}\n        assert os.path.abspath(\"f1.py\") in abs_files\n        assert os.path.abspath(\"f2.py\") in abs_files\n", "tests/plugin1.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"A file tracer plugin for test_plugins.py to import.\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\n\nfrom types import FrameType\nfrom typing import Any\n\nfrom coverage import CoveragePlugin, FileReporter, FileTracer\nfrom coverage.plugin_support import Plugins\nfrom coverage.types import TLineNo\n\nclass Plugin(CoveragePlugin):\n    \"\"\"A file tracer plugin to import, so that it isn't in the test's current directory.\"\"\"\n\n    def file_tracer(self, filename: str) -> FileTracer | None:\n        \"\"\"Trace only files named xyz.py\"\"\"\n        if \"xyz.py\" in filename:\n            return MyFileTracer(filename)\n        return None\n\n    def file_reporter(self, filename: str) -> FileReporter | str:\n        return MyFileReporter(filename)\n\n\nclass MyFileTracer(FileTracer):\n    \"\"\"A FileTracer emulating a simple static plugin.\"\"\"\n\n    def __init__(self, filename: str) -> None:\n        \"\"\"Claim that */*xyz.py was actually sourced from /src/*ABC.zz\"\"\"\n        self._filename = filename\n        self._source_filename = os.path.join(\n            \"/src\",\n            os.path.basename(filename.replace(\"xyz.py\", \"ABC.zz\")),\n        )\n\n    def source_filename(self) -> str:\n        return self._source_filename\n\n    def line_number_range(self, frame: FrameType) -> tuple[TLineNo, TLineNo]:\n        \"\"\"Map the line number X to X05,X06,X07.\"\"\"\n        lineno = frame.f_lineno\n        return lineno*100+5, lineno*100+7\n\n\nclass MyFileReporter(FileReporter):\n    \"\"\"Dead-simple FileReporter.\"\"\"\n    def lines(self) -> set[TLineNo]:\n        return {105, 106, 107, 205, 206, 207}\n\n\ndef coverage_init(\n    reg: Plugins,\n    options: Any,       # pylint: disable=unused-argument\n) -> None:\n    \"\"\"Called by coverage to initialize the plugins here.\"\"\"\n    reg.add_file_tracer(Plugin())\n", "tests/test_config.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Test the config file handling for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nfrom unittest import mock\n\nimport pytest\n\nimport coverage\nfrom coverage import Coverage, env\nfrom coverage.config import HandyConfigParser\nfrom coverage.exceptions import ConfigError, CoverageWarning\nfrom coverage.tomlconfig import TomlConfigParser\nfrom coverage.types import FilePathClasses, FilePathType\n\nfrom tests.coveragetest import CoverageTest, UsingModulesMixin\n\n\nclass ConfigTest(CoverageTest):\n    \"\"\"Tests of the different sources of configuration settings.\"\"\"\n\n    def test_default_config(self) -> None:\n        # Just constructing a coverage() object gets the right defaults.\n        cov = coverage.Coverage()\n        assert not cov.config.timid\n        assert not cov.config.branch\n        assert cov.config.data_file == \".coverage\"\n\n    def test_arguments(self) -> None:\n        # Arguments to the constructor are applied to the configuration.\n        cov = coverage.Coverage(timid=True, data_file=\"fooey.dat\", concurrency=\"multiprocessing\")\n        assert cov.config.timid\n        assert not cov.config.branch\n        assert cov.config.data_file == \"fooey.dat\"\n        assert cov.config.concurrency == [\"multiprocessing\"]\n\n    def test_config_file(self) -> None:\n        # A .coveragerc file will be read into the configuration.\n        self.make_file(\".coveragerc\", \"\"\"\\\n            # This is just a bogus .rc file for testing.\n            [run]\n            timid =         True\n            data_file =     .hello_kitty.data\n            \"\"\")\n        cov = coverage.Coverage()\n        assert cov.config.timid\n        assert not cov.config.branch\n        assert cov.config.data_file == \".hello_kitty.data\"\n\n    @pytest.mark.parametrize(\"file_class\", FilePathClasses)\n    def test_named_config_file(self, file_class: FilePathType) -> None:\n        # You can name the config file what you like.\n        self.make_file(\"my_cov.ini\", \"\"\"\\\n            [run]\n            timid = True\n            ; I wouldn't really use this as a data file...\n            data_file = delete.me\n            \"\"\")\n        cov = coverage.Coverage(config_file=file_class(\"my_cov.ini\"))\n        assert cov.config.timid\n        assert not cov.config.branch\n        assert cov.config.data_file == \"delete.me\"\n\n    def test_toml_config_file(self) -> None:\n        # A pyproject.toml file will be read into the configuration.\n        self.make_file(\"pyproject.toml\", \"\"\"\\\n            # This is just a bogus toml file for testing.\n            [tool.somethingelse]\n            authors = [\"Joe D'\u00c1vila <joe@gmail.com>\"]\n            [tool.coverage.run]\n            concurrency = [\"a\", \"b\"]\n            timid = true\n            data_file = \".hello_kitty.data\"\n            plugins = [\"plugins.a_plugin\"]\n            [tool.coverage.report]\n            precision = 3\n            fail_under = 90.5\n            [tool.coverage.html]\n            title = \"tabblo & \u00ab\u03c4\u03b1\u0411\u042c\u2113\u03c3\u00bb\"\n            [tool.coverage.plugins.a_plugin]\n            hello = \"world\"\n            \"\"\")\n        cov = coverage.Coverage()\n        assert cov.config.timid\n        assert not cov.config.branch\n        assert cov.config.concurrency == [\"a\", \"b\"]\n        assert cov.config.data_file == \".hello_kitty.data\"\n        assert cov.config.plugins == [\"plugins.a_plugin\"]\n        assert cov.config.precision == 3\n        assert cov.config.html_title == \"tabblo & \u00ab\u03c4\u03b1\u0411\u042c\u2113\u03c3\u00bb\"\n        assert cov.config.fail_under == 90.5\n        assert cov.config.get_plugin_options(\"plugins.a_plugin\") == {\"hello\": \"world\"}\n\n    def test_toml_ints_can_be_floats(self) -> None:\n        # Test that our class doesn't reject integers when loading floats\n        self.make_file(\"pyproject.toml\", \"\"\"\\\n            # This is just a bogus toml file for testing.\n            [tool.coverage.report]\n            fail_under = 90\n            \"\"\")\n        cov = coverage.Coverage()\n        assert cov.config.fail_under == 90\n        assert isinstance(cov.config.fail_under, float)\n\n    def test_ignored_config_file(self) -> None:\n        # You can disable reading the .coveragerc file.\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            timid = True\n            data_file = delete.me\n            \"\"\")\n        cov = coverage.Coverage(config_file=False)\n        assert not cov.config.timid\n        assert not cov.config.branch\n        assert cov.config.data_file == \".coverage\"\n\n    def test_config_file_then_args(self) -> None:\n        # The arguments override the .coveragerc file.\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            timid = True\n            data_file = weirdo.file\n            \"\"\")\n        cov = coverage.Coverage(timid=False, data_file=\".mycov\")\n        assert not cov.config.timid\n        assert not cov.config.branch\n        assert cov.config.data_file == \".mycov\"\n\n    def test_data_file_from_environment(self) -> None:\n        # There's an environment variable for the data_file.\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            timid = True\n            data_file = weirdo.file\n            \"\"\")\n        self.set_environ(\"COVERAGE_FILE\", \"fromenv.dat\")\n        cov = coverage.Coverage()\n        assert cov.config.data_file == \"fromenv.dat\"\n        # But the constructor arguments override the environment variable.\n        cov = coverage.Coverage(data_file=\"fromarg.dat\")\n        assert cov.config.data_file == \"fromarg.dat\"\n\n    def test_debug_from_environment(self) -> None:\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            debug = dataio, pids\n            \"\"\")\n        self.set_environ(\"COVERAGE_DEBUG\", \"callers, fooey\")\n        cov = coverage.Coverage()\n        assert cov.config.debug == [\"dataio\", \"pids\", \"callers\", \"fooey\"]\n\n    def test_rcfile_from_environment(self) -> None:\n        self.make_file(\"here.ini\", \"\"\"\\\n            [run]\n            data_file = overthere.dat\n            \"\"\")\n        self.set_environ(\"COVERAGE_RCFILE\", \"here.ini\")\n        cov = coverage.Coverage()\n        assert cov.config.data_file == \"overthere.dat\"\n\n    def test_missing_rcfile_from_environment(self) -> None:\n        self.set_environ(\"COVERAGE_RCFILE\", \"nowhere.ini\")\n        msg = \"Couldn't read 'nowhere.ini' as a config file\"\n        with pytest.raises(ConfigError, match=msg):\n            coverage.Coverage()\n\n    @pytest.mark.parametrize(\"force\", [False, True])\n    def test_force_environment(self, force: bool) -> None:\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            debug = dataio, pids\n            \"\"\")\n        self.make_file(\"force.ini\", \"\"\"\\\n            [run]\n            debug = callers, fooey\n            \"\"\")\n        if force:\n            self.set_environ(\"COVERAGE_FORCE_CONFIG\", \"force.ini\")\n        cov = coverage.Coverage()\n        if force:\n            assert cov.config.debug == [\"callers\", \"fooey\"]\n        else:\n            assert cov.config.debug == [\"dataio\", \"pids\"]\n\n    @pytest.mark.parametrize(\"bad_config, msg\", [\n        (\"[run]\\ntimid = maybe?\\n\", r\"maybe[?]\"),\n        (\"timid = 1\\n\", r\"no section headers\"),\n        (\"[run\\n\", r\"\\[run\"),\n        (\"[report]\\nexclude_lines = foo(\\n\",\n            r\"Invalid \\[report\\].exclude_lines value 'foo\\(': \" +\n            r\"(unbalanced parenthesis|missing \\))\"),\n        (\"[report]\\npartial_branches = foo[\\n\",\n            r\"Invalid \\[report\\].partial_branches value 'foo\\[': \" +\n            r\"(unexpected end of regular expression|unterminated character set)\"),\n        (\"[report]\\npartial_branches_always = foo***\\n\",\n            r\"Invalid \\[report\\].partial_branches_always value \" +\n            r\"'foo\\*\\*\\*': \" +\n            r\"multiple repeat\"),\n    ])\n    def test_parse_errors(self, bad_config: str, msg: str) -> None:\n        # Im-parsable values raise ConfigError, with details.\n        self.make_file(\".coveragerc\", bad_config)\n        with pytest.raises(ConfigError, match=msg):\n            coverage.Coverage()\n\n    @pytest.mark.parametrize(\"bad_config, msg\", [\n        (\"[tool.coverage.run]\\ntimid = \\\"maybe?\\\"\\n\", r\"maybe[?]\"),\n        (\"[tool.coverage.run\\n\", None),\n        ('[tool.coverage.report]\\nexclude_lines = [\"foo(\"]\\n',\n         r\"Invalid \\[tool.coverage.report\\].exclude_lines value 'foo\\(': \" +\n         r\"(unbalanced parenthesis|missing \\))\"),\n        ('[tool.coverage.report]\\npartial_branches = [\"foo[\"]\\n',\n         r\"Invalid \\[tool.coverage.report\\].partial_branches value 'foo\\[': \" +\n         r\"(unexpected end of regular expression|unterminated character set)\"),\n        ('[tool.coverage.report]\\npartial_branches_always = [\"foo***\"]\\n',\n         r\"Invalid \\[tool.coverage.report\\].partial_branches_always value \" +\n         r\"'foo\\*\\*\\*': \" +\n         r\"multiple repeat\"),\n        ('[tool.coverage.run]\\nconcurrency=\"foo\"', \"not a list\"),\n        (\"[tool.coverage.report]\\nprecision=1.23\", \"not an integer\"),\n        ('[tool.coverage.report]\\nfail_under=\"s\"', \"couldn't convert to a float\"),\n    ])\n    def test_toml_parse_errors(self, bad_config: str, msg: str) -> None:\n        # Im-parsable values raise ConfigError, with details.\n        self.make_file(\"pyproject.toml\", bad_config)\n        with pytest.raises(ConfigError, match=msg):\n            coverage.Coverage()\n\n    def test_environment_vars_in_config(self) -> None:\n        # Config files can have $envvars in them.\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            data_file = $DATA_FILE.fooey\n            branch = $OKAY\n            [report]\n            exclude_lines =\n                the_$$one\n                another${THING}\n                x${THING}y\n                x${NOTHING}y\n                huh$${X}what\n            \"\"\")\n        self.set_environ(\"DATA_FILE\", \"hello-world\")\n        self.set_environ(\"THING\", \"ZZZ\")\n        self.set_environ(\"OKAY\", \"yes\")\n        cov = coverage.Coverage()\n        assert cov.config.data_file == \"hello-world.fooey\"\n        assert cov.config.branch is True\n        assert cov.config.exclude_list == [\"the_$one\", \"anotherZZZ\", \"xZZZy\", \"xy\", \"huh${X}what\"]\n\n    def test_environment_vars_in_toml_config(self) -> None:\n        # Config files can have $envvars in them.\n        self.make_file(\"pyproject.toml\", \"\"\"\\\n            [tool.coverage.run]\n            data_file = \"$DATA_FILE.fooey\"\n            branch = \"$BRANCH\"\n            [tool.coverage.report]\n            precision = \"$DIGITS\"\n            fail_under = \"$FAIL_UNDER\"\n            exclude_lines = [\n                \"the_$$one\",\n                \"another${THING}\",\n                \"x${THING}y\",\n                \"x${NOTHING}y\",\n                \"huh$${X}what\",\n            ]\n            [othersection]\n            # This reproduces the failure from https://github.com/nedbat/coveragepy/issues/1481\n            # When OTHER has a backslash that isn't a valid escape, like \\\\z (see below).\n            something = \"if [ $OTHER ]; then printf '%s\\\\n' 'Hi'; fi\"\n            \"\"\")\n        self.set_environ(\"BRANCH\", \"true\")\n        self.set_environ(\"DIGITS\", \"3\")\n        self.set_environ(\"FAIL_UNDER\", \"90.5\")\n        self.set_environ(\"DATA_FILE\", \"hello-world\")\n        self.set_environ(\"THING\", \"ZZZ\")\n        self.set_environ(\"OTHER\", \"hi\\\\zebra\")\n        cov = coverage.Coverage()\n        assert cov.config.branch is True\n        assert cov.config.precision == 3\n        assert cov.config.data_file == \"hello-world.fooey\"\n        assert cov.config.exclude_list == [\"the_$one\", \"anotherZZZ\", \"xZZZy\", \"xy\", \"huh${X}what\"]\n\n    def test_tilde_in_config(self) -> None:\n        # Config entries that are file paths can be tilde-expanded.\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            data_file = ~/data.file\n\n            [html]\n            directory = ~joe/html_dir\n\n            [xml]\n            output = ~/somewhere/xml.out\n\n            [report]\n            # Strings that aren't file paths are not tilde-expanded.\n            exclude_lines =\n                ~/data.file\n                ~joe/html_dir\n\n            [paths]\n            mapping =\n                ~/src\n                ~joe/source\n            \"\"\")\n        def expanduser(s: str) -> str:\n            \"\"\"Fake tilde expansion\"\"\"\n            s = s.replace(\"~/\", \"/Users/me/\")\n            s = s.replace(\"~joe/\", \"/Users/joe/\")\n            return s\n\n        with mock.patch.object(coverage.config.os.path, 'expanduser', new=expanduser):\n            cov = coverage.Coverage()\n        assert cov.config.data_file == \"/Users/me/data.file\"\n        assert cov.config.html_dir == \"/Users/joe/html_dir\"\n        assert cov.config.xml_output == \"/Users/me/somewhere/xml.out\"\n        assert cov.config.exclude_list == [\"~/data.file\", \"~joe/html_dir\"]\n        assert cov.config.paths == {'mapping': ['/Users/me/src', '/Users/joe/source']}\n\n    def test_tilde_in_toml_config(self) -> None:\n        # Config entries that are file paths can be tilde-expanded.\n        self.make_file(\"pyproject.toml\", \"\"\"\\\n            [tool.coverage.run]\n            data_file = \"~/data.file\"\n\n            [tool.coverage.html]\n            directory = \"~joe/html_dir\"\n\n            [tool.coverage.xml]\n            output = \"~/somewhere/xml.out\"\n\n            [tool.coverage.report]\n            # Strings that aren't file paths are not tilde-expanded.\n            exclude_lines = [\n                \"~/data.file\",\n                \"~joe/html_dir\",\n            ]\n\n            [tool.coverage.paths]\n            mapping = [\n                \"~/src\",\n                \"~joe/source\",\n            ]\n            \"\"\")\n        def expanduser(s: str) -> str:\n            \"\"\"Fake tilde expansion\"\"\"\n            s = s.replace(\"~/\", \"/Users/me/\")\n            s = s.replace(\"~joe/\", \"/Users/joe/\")\n            return s\n\n        with mock.patch.object(coverage.config.os.path, 'expanduser', new=expanduser):\n            cov = coverage.Coverage()\n        assert cov.config.data_file == \"/Users/me/data.file\"\n        assert cov.config.html_dir == \"/Users/joe/html_dir\"\n        assert cov.config.xml_output == \"/Users/me/somewhere/xml.out\"\n        assert cov.config.exclude_list == [\"~/data.file\", \"~joe/html_dir\"]\n        assert cov.config.paths == {'mapping': ['/Users/me/src', '/Users/joe/source']}\n\n    def test_tweaks_after_constructor(self) -> None:\n        # set_option can be used after construction to affect the config.\n        cov = coverage.Coverage(timid=True, data_file=\"fooey.dat\")\n        cov.set_option(\"run:timid\", False)\n\n        assert not cov.config.timid\n        assert not cov.config.branch\n        assert cov.config.data_file == \"fooey.dat\"\n\n        assert not cov.get_option(\"run:timid\")\n        assert not cov.get_option(\"run:branch\")\n        assert cov.get_option(\"run:data_file\") == \"fooey.dat\"\n\n    def test_tweaks_paths_after_constructor(self) -> None:\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [paths]\n            first =\n                /first/1\n                /first/2\n\n            second =\n                /second/a\n                /second/b\n            \"\"\")\n        old_paths = {\n            \"first\": [\"/first/1\", \"/first/2\"],\n            \"second\": [\"/second/a\", \"/second/b\"],\n        }\n        cov = coverage.Coverage()\n        paths = cov.get_option(\"paths\")\n        assert paths == old_paths\n\n        new_paths = {\n            \"magic\": [\"src\", \"ok\"],\n        }\n        cov.set_option(\"paths\", new_paths)\n\n        assert cov.get_option(\"paths\") == new_paths\n\n    def test_tweak_error_checking(self) -> None:\n        # Trying to set an unknown config value raises an error.\n        cov = coverage.Coverage()\n        with pytest.raises(ConfigError, match=\"No such option: 'run:xyzzy'\"):\n            cov.set_option(\"run:xyzzy\", 12)\n        with pytest.raises(ConfigError, match=\"No such option: 'xyzzy:foo'\"):\n            cov.set_option(\"xyzzy:foo\", 12)\n        with pytest.raises(ConfigError, match=\"No such option: 'run:xyzzy'\"):\n            _ = cov.get_option(\"run:xyzzy\")\n        with pytest.raises(ConfigError, match=\"No such option: 'xyzzy:foo'\"):\n            _ = cov.get_option(\"xyzzy:foo\")\n\n    def test_tweak_plugin_options(self) -> None:\n        # Plugin options have a more flexible syntax.\n        cov = coverage.Coverage()\n        cov.set_option(\"run:plugins\", [\"fooey.plugin\", \"xyzzy.coverage.plugin\"])\n        cov.set_option(\"fooey.plugin:xyzzy\", 17)\n        cov.set_option(\"xyzzy.coverage.plugin:plugh\", [\"a\", \"b\"])\n        with pytest.raises(ConfigError, match=\"No such option: 'no_such.plugin:foo'\"):\n            cov.set_option(\"no_such.plugin:foo\", 23)\n\n        assert cov.get_option(\"fooey.plugin:xyzzy\") == 17\n        assert cov.get_option(\"xyzzy.coverage.plugin:plugh\") == [\"a\", \"b\"]\n        with pytest.raises(ConfigError, match=\"No such option: 'no_such.plugin:foo'\"):\n            _ = cov.get_option(\"no_such.plugin:foo\")\n\n    def test_unknown_option(self) -> None:\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            xyzzy = 17\n            \"\"\")\n        msg = r\"Unrecognized option '\\[run\\] xyzzy=' in config file .coveragerc\"\n        with pytest.warns(CoverageWarning, match=msg):\n            _ = coverage.Coverage()\n\n    def test_unknown_option_toml(self) -> None:\n        self.make_file(\"pyproject.toml\", \"\"\"\\\n            [tool.coverage.run]\n            xyzzy = 17\n            \"\"\")\n        msg = r\"Unrecognized option '\\[tool.coverage.run\\] xyzzy=' in config file pyproject.toml\"\n        with pytest.warns(CoverageWarning, match=msg):\n            _ = coverage.Coverage()\n\n    def test_misplaced_option(self) -> None:\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [report]\n            branch = True\n            \"\"\")\n        msg = r\"Unrecognized option '\\[report\\] branch=' in config file .coveragerc\"\n        with pytest.warns(CoverageWarning, match=msg):\n            _ = coverage.Coverage()\n\n    def test_unknown_option_in_other_ini_file(self) -> None:\n        self.make_file(\"setup.cfg\", \"\"\"\\\n            [coverage:run]\n            huh = what?\n            \"\"\")\n        msg = r\"Unrecognized option '\\[coverage:run\\] huh=' in config file setup.cfg\"\n        with pytest.warns(CoverageWarning, match=msg):\n            _ = coverage.Coverage()\n\n    def test_exceptions_from_missing_things(self) -> None:\n        self.make_file(\"config.ini\", \"\"\"\\\n            [run]\n            branch = True\n            \"\"\")\n        config = HandyConfigParser(True)\n        config.read([\"config.ini\"])\n        with pytest.raises(ConfigError, match=\"No section: 'xyzzy'\"):\n            config.options(\"xyzzy\")\n        with pytest.raises(ConfigError, match=\"No option 'foo' in section: 'xyzzy'\"):\n            config.get(\"xyzzy\", \"foo\")\n\n    def test_exclude_also(self) -> None:\n        self.make_file(\"pyproject.toml\", \"\"\"\\\n            [tool.coverage.report]\n            exclude_also = [\"foobar\", \"raise .*Error\"]\n            \"\"\")\n        cov = coverage.Coverage()\n\n        expected = coverage.config.DEFAULT_EXCLUDE + [\"foobar\", \"raise .*Error\"]\n        assert cov.config.exclude_list == expected\n\n\nclass ConfigFileTest(UsingModulesMixin, CoverageTest):\n    \"\"\"Tests of the config file settings in particular.\"\"\"\n\n    # This sample file tries to use lots of variation of syntax...\n    # The {section} placeholder lets us nest these settings in another file.\n    LOTSA_SETTINGS = \"\"\"\\\n        # This is a settings file for coverage.py\n        [{section}run]\n        timid = yes\n        data_file = something_or_other.dat\n        branch = 1\n        cover_pylib = TRUE\n        parallel = on\n        concurrency = thread\n        ; this omit is overridden by the omit from [report]\n        omit = twenty\n        source = myapp\n        source_pkgs = ned\n        plugins =\n            plugins.a_plugin\n            plugins.another\n        debug = callers, pids  ,     dataio\n        disable_warnings =     abcd  ,  efgh\n\n        [{section}report]\n        ; these settings affect reporting.\n        exclude_lines =\n            if 0:\n\n            pragma:?\\\\s+no cover\n                another_tab\n\n        ignore_errors = TRUE\n        omit =\n            one, another, some_more,\n                yet_more\n        include = thirty\n        precision = 3\n\n        partial_branches =\n            pragma:?\\\\s+no branch\n        partial_branches_always =\n            if 0:\n            while True:\n\n        show_missing= TruE\n        skip_covered = TruE\n        skip_empty  =TruE\n\n        include_namespace_packages = TRUE\n\n        [{section}html]\n\n        directory    =     c:\\\\tricky\\\\dir.somewhere\n        extra_css=something/extra.css\n        title = Title & nums # nums!\n        [{section}xml]\n        output=mycov.xml\n        package_depth          =                                17\n\n        [{section}paths]\n        source =\n            .\n            /home/ned/src/\n\n        other = other, /home/ned/other, c:\\\\Ned\\\\etc\n\n        [{section}plugins.a_plugin]\n        hello = world\n        ; comments still work.\n        names = Jane/John/Jenny\n\n        [{section}json]\n        pretty_print = True\n        show_contexts = True\n        \"\"\"\n\n    # Just some sample setup.cfg text from the docs.\n    SETUP_CFG = \"\"\"\\\n        [bdist_rpm]\n        release = 1\n        packager = Jane Packager <janep@pysoft.com>\n        doc_files = CHANGES.txt\n                    README.txt\n                    USAGE.txt\n                    doc/\n                    examples/\n        \"\"\"\n\n    # Just some sample tox.ini text from the docs.\n    TOX_INI = \"\"\"\\\n        [tox]\n        envlist = py{26,27,33,34,35}-{c,py}tracer\n        skip_missing_interpreters = True\n\n        [testenv]\n        commands =\n            # Create tests/zipmods.zip\n            python igor.py zip_mods\n        \"\"\"\n\n    def assert_config_settings_are_correct(self, cov: Coverage) -> None:\n        \"\"\"Check that `cov` has all the settings from LOTSA_SETTINGS.\"\"\"\n        assert cov.config.timid\n        assert cov.config.data_file == \"something_or_other.dat\"\n        assert cov.config.branch\n        assert cov.config.cover_pylib\n        assert cov.config.debug == [\"callers\", \"pids\", \"dataio\"]\n        assert cov.config.parallel\n        assert cov.config.concurrency == [\"thread\"]\n        assert cov.config.source == [\"myapp\"]\n        assert cov.config.source_pkgs == [\"ned\"]\n        assert cov.config.disable_warnings == [\"abcd\", \"efgh\"]\n\n        assert cov.get_exclude_list() == [\"if 0:\", r\"pragma:?\\s+no cover\", \"another_tab\"]\n        assert cov.config.ignore_errors\n        assert cov.config.run_omit == [\"twenty\"]\n        assert cov.config.report_omit == [\"one\", \"another\", \"some_more\", \"yet_more\"]\n        assert cov.config.report_include == [\"thirty\"]\n        assert cov.config.precision == 3\n\n        assert cov.config.partial_list == [r\"pragma:?\\s+no branch\"]\n        assert cov.config.partial_always_list == [\"if 0:\", \"while True:\"]\n        assert cov.config.plugins == [\"plugins.a_plugin\", \"plugins.another\"]\n        assert cov.config.show_missing\n        assert cov.config.skip_covered\n        assert cov.config.skip_empty\n        assert cov.config.html_dir == r\"c:\\tricky\\dir.somewhere\"\n        assert cov.config.extra_css == \"something/extra.css\"\n        assert cov.config.html_title == \"Title & nums # nums!\"\n\n        assert cov.config.xml_output == \"mycov.xml\"\n        assert cov.config.xml_package_depth == 17\n\n        assert cov.config.paths == {\n            'source': ['.', '/home/ned/src/'],\n            'other': ['other', '/home/ned/other', 'c:\\\\Ned\\\\etc'],\n        }\n\n        assert cov.config.get_plugin_options(\"plugins.a_plugin\") == {\n            'hello': 'world',\n            'names': 'Jane/John/Jenny',\n        }\n        assert cov.config.get_plugin_options(\"plugins.another\") == {}\n        assert cov.config.json_show_contexts is True\n        assert cov.config.json_pretty_print is True\n        assert cov.config.include_namespace_packages is True\n\n    def test_config_file_settings(self) -> None:\n        self.make_file(\".coveragerc\", self.LOTSA_SETTINGS.format(section=\"\"))\n        cov = coverage.Coverage()\n        self.assert_config_settings_are_correct(cov)\n\n    def check_config_file_settings_in_other_file(self, fname: str, contents: str) -> None:\n        \"\"\"Check config will be read from another file, with prefixed sections.\"\"\"\n        nested = self.LOTSA_SETTINGS.format(section=\"coverage:\")\n        fname = self.make_file(fname, nested + \"\\n\" + contents)\n        cov = coverage.Coverage()\n        self.assert_config_settings_are_correct(cov)\n\n    def test_config_file_settings_in_setupcfg(self) -> None:\n        self.check_config_file_settings_in_other_file(\"setup.cfg\", self.SETUP_CFG)\n\n    def test_config_file_settings_in_toxini(self) -> None:\n        self.check_config_file_settings_in_other_file(\"tox.ini\", self.TOX_INI)\n\n    def check_other_config_if_coveragerc_specified(self, fname: str, contents: str) -> None:\n        \"\"\"Check that config `fname` is read if .coveragerc is missing, but specified.\"\"\"\n        nested = self.LOTSA_SETTINGS.format(section=\"coverage:\")\n        self.make_file(fname, nested + \"\\n\" + contents)\n        cov = coverage.Coverage(config_file=\".coveragerc\")\n        self.assert_config_settings_are_correct(cov)\n\n    def test_config_file_settings_in_setupcfg_if_coveragerc_specified(self) -> None:\n        self.check_other_config_if_coveragerc_specified(\"setup.cfg\", self.SETUP_CFG)\n\n    def test_config_file_settings_in_tox_if_coveragerc_specified(self) -> None:\n        self.check_other_config_if_coveragerc_specified(\"tox.ini\", self.TOX_INI)\n\n    def check_other_not_read_if_coveragerc(self, fname: str) -> None:\n        \"\"\"Check config `fname` is not read if .coveragerc exists.\"\"\"\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            include = foo\n            \"\"\")\n        self.make_file(fname, \"\"\"\\\n            [coverage:run]\n            omit = bar\n            branch = true\n            \"\"\")\n        cov = coverage.Coverage()\n        assert cov.config.run_include == [\"foo\"]\n        assert cov.config.run_omit == []\n        assert cov.config.branch is False\n\n    def test_setupcfg_only_if_not_coveragerc(self) -> None:\n        self.check_other_not_read_if_coveragerc(\"setup.cfg\")\n\n    def test_toxini_only_if_not_coveragerc(self) -> None:\n        self.check_other_not_read_if_coveragerc(\"tox.ini\")\n\n    def check_other_config_need_prefixes(self, fname: str) -> None:\n        \"\"\"Check that `fname` sections won't be read if un-prefixed.\"\"\"\n        self.make_file(fname, \"\"\"\\\n            [run]\n            omit = bar\n            branch = true\n            \"\"\")\n        cov = coverage.Coverage()\n        assert cov.config.run_omit == []\n        assert cov.config.branch is False\n\n    def test_setupcfg_only_if_prefixed(self) -> None:\n        self.check_other_config_need_prefixes(\"setup.cfg\")\n\n    def test_toxini_only_if_prefixed(self) -> None:\n        self.check_other_config_need_prefixes(\"tox.ini\")\n\n    def test_tox_ini_even_if_setup_cfg(self) -> None:\n        # There's a setup.cfg, but no coverage settings in it, so tox.ini\n        # is read.\n        nested = self.LOTSA_SETTINGS.format(section=\"coverage:\")\n        self.make_file(\"tox.ini\", self.TOX_INI + \"\\n\" + nested)\n        self.make_file(\"setup.cfg\", self.SETUP_CFG)\n        cov = coverage.Coverage()\n        self.assert_config_settings_are_correct(cov)\n\n    def test_read_prefixed_sections_from_explicit_file(self) -> None:\n        # You can point to a tox.ini, and it will find [coverage:run] sections\n        nested = self.LOTSA_SETTINGS.format(section=\"coverage:\")\n        self.make_file(\"tox.ini\", self.TOX_INI + \"\\n\" + nested)\n        cov = coverage.Coverage(config_file=\"tox.ini\")\n        self.assert_config_settings_are_correct(cov)\n\n    def test_non_ascii(self) -> None:\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [report]\n            exclude_lines =\n                first\n                \u2718${TOX_ENVNAME}\n                third\n            [html]\n            title = tabblo & \u00ab\u03c4\u03b1\u0411\u042c\u2113\u03c3\u00bb # numbers\n            \"\"\")\n        self.set_environ(\"TOX_ENVNAME\", \"weirdo\")\n        cov = coverage.Coverage()\n\n        assert cov.config.exclude_list == [\"first\", \"\u2718weirdo\", \"third\"]\n        assert cov.config.html_title == \"tabblo & \u00ab\u03c4\u03b1\u0411\u042c\u2113\u03c3\u00bb # numbers\"\n\n    @pytest.mark.parametrize(\"bad_file\", [\"nosuchfile.txt\", \".\"])\n    def test_unreadable_config(self, bad_file: str) -> None:\n        # If a config file is explicitly specified, then it is an error for it\n        # to not be readable.\n        msg = f\"Couldn't read {bad_file!r} as a config file\"\n        with pytest.raises(ConfigError, match=msg):\n            coverage.Coverage(config_file=bad_file)\n\n    def test_nocoveragerc_file_when_specified(self) -> None:\n        cov = coverage.Coverage(config_file=\".coveragerc\")\n        assert not cov.config.timid\n        assert not cov.config.branch\n        assert cov.config.data_file == \".coverage\"\n\n    def test_no_toml_installed_no_toml(self) -> None:\n        # Can't read a toml file that doesn't exist.\n        with mock.patch.object(coverage.tomlconfig, \"has_tomllib\", False):\n            msg = \"Couldn't read 'cov.toml' as a config file\"\n            with pytest.raises(ConfigError, match=msg):\n                coverage.Coverage(config_file=\"cov.toml\")\n\n    @pytest.mark.skipif(env.PYVERSION >= (3, 11), reason=\"Python 3.11 has toml in stdlib\")\n    def test_no_toml_installed_explicit_toml(self) -> None:\n        # Can't specify a toml config file if toml isn't installed.\n        self.make_file(\"cov.toml\", \"# A toml file!\")\n        with mock.patch.object(coverage.tomlconfig, \"has_tomllib\", False):\n            msg = \"Can't read 'cov.toml' without TOML support\"\n            with pytest.raises(ConfigError, match=msg):\n                coverage.Coverage(config_file=\"cov.toml\")\n\n    @pytest.mark.skipif(env.PYVERSION >= (3, 11), reason=\"Python 3.11 has toml in stdlib\")\n    def test_no_toml_installed_pyproject_toml(self) -> None:\n        # Can't have coverage config in pyproject.toml without toml installed.\n        self.make_file(\"pyproject.toml\", \"\"\"\\\n            # A toml file!\n            [tool.coverage.run]\n            xyzzy = 17\n            \"\"\")\n        with mock.patch.object(coverage.tomlconfig, \"has_tomllib\", False):\n            msg = \"Can't read 'pyproject.toml' without TOML support\"\n            with pytest.raises(ConfigError, match=msg):\n                coverage.Coverage()\n\n    @pytest.mark.skipif(env.PYVERSION >= (3, 11), reason=\"Python 3.11 has toml in stdlib\")\n    def test_no_toml_installed_pyproject_toml_shorter_syntax(self) -> None:\n        # Can't have coverage config in pyproject.toml without toml installed.\n        self.make_file(\"pyproject.toml\", \"\"\"\\\n            # A toml file!\n            [tool.coverage]\n            run.parallel = true\n            \"\"\")\n        with mock.patch.object(coverage.tomlconfig, \"has_tomllib\", False):\n            msg = \"Can't read 'pyproject.toml' without TOML support\"\n            with pytest.raises(ConfigError, match=msg):\n                coverage.Coverage()\n\n    @pytest.mark.skipif(env.PYVERSION >= (3, 11), reason=\"Python 3.11 has toml in stdlib\")\n    def test_no_toml_installed_pyproject_no_coverage(self) -> None:\n        # It's ok to have non-coverage pyproject.toml without toml installed.\n        self.make_file(\"pyproject.toml\", \"\"\"\\\n            # A toml file!\n            [tool.something]\n            xyzzy = 17\n            \"\"\")\n        with mock.patch.object(coverage.tomlconfig, \"has_tomllib\", False):\n            cov = coverage.Coverage()\n            # We get default settings:\n            assert not cov.config.timid\n            assert not cov.config.branch\n            assert cov.config.data_file == \".coverage\"\n\n    def test_exceptions_from_missing_toml_things(self) -> None:\n        self.make_file(\"pyproject.toml\", \"\"\"\\\n            [tool.coverage.run]\n            branch = true\n            \"\"\")\n        config = TomlConfigParser(False)\n        config.read(\"pyproject.toml\")\n        with pytest.raises(ConfigError, match=\"No section: 'xyzzy'\"):\n            config.options(\"xyzzy\")\n        with pytest.raises(ConfigError, match=\"No section: 'xyzzy'\"):\n            config.get(\"xyzzy\", \"foo\")\n        with pytest.raises(ConfigError, match=\"No option 'foo' in section: 'tool.coverage.run'\"):\n            config.get(\"run\", \"foo\")\n", "tests/test_data.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.data, and coverage.sqldata.\"\"\"\n\nfrom __future__ import annotations\n\nimport glob\nimport os\nimport os.path\nimport re\nimport sqlite3\nimport threading\n\nfrom typing import (\n    Any, Callable, Collection, Iterable, Mapping, TypeVar, Union,\n)\nfrom unittest import mock\n\nimport pytest\n\nfrom coverage.data import CoverageData, combine_parallel_data\nfrom coverage.data import add_data_to_hash, line_counts\nfrom coverage.exceptions import DataError, NoDataError\nfrom coverage.files import PathAliases, canonical_filename\nfrom coverage.types import FilePathClasses, FilePathType, TArc, TLineNo\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import DebugControlString, assert_count_equal\n\n\nLINES_1 = {\n    'a.py': {1, 2},\n    'b.py': {3},\n}\nSUMMARY_1 = {'a.py': 2, 'b.py': 1}\nMEASURED_FILES_1 = ['a.py', 'b.py']\nA_PY_LINES_1 = [1, 2]\nB_PY_LINES_1 = [3]\n\nLINES_2 = {\n    'a.py': {1, 5},\n    'c.py': {17},\n}\nSUMMARY_1_2 = {'a.py': 3, 'b.py': 1, 'c.py': 1}\nMEASURED_FILES_1_2 = ['a.py', 'b.py', 'c.py']\n\nARCS_3 = {\n    'x.py': {(-1, 1), (1, 2), (2, 3), (3, -1)},\n    'y.py': {(-1, 17), (17, 23), (23, -1)},\n}\nX_PY_ARCS_3 = [(-1, 1), (1, 2), (2, 3), (3, -1)]\nY_PY_ARCS_3 = [(-1, 17), (17, 23), (23, -1)]\nSUMMARY_3 = {'x.py': 3, 'y.py': 2}\nMEASURED_FILES_3 = ['x.py', 'y.py']\nX_PY_LINES_3 = [1, 2, 3]\nY_PY_LINES_3 = [17, 23]\n\nARCS_4 = {\n    'x.py': {(-1, 2), (2, 5), (5, -1)},\n    'z.py': {(-1, 1000), (1000, -1)},\n}\nSUMMARY_3_4 = {'x.py': 4, 'y.py': 2, 'z.py': 1}\nMEASURED_FILES_3_4 = ['x.py', 'y.py', 'z.py']\n\n\ndef DebugCoverageData(*args: Any, **kwargs: Any) -> CoverageData:\n    \"\"\"Factory for CovergeData instances with debugging turned on.\n\n    This lets us exercise the debugging lines in sqldata.py.  We don't make\n    any assertions about the debug output, but at least we can know that they\n    execute successfully, and they won't be marked as distracting missing\n    lines in our coverage reports.\n\n    In the tests in this file, we usually use DebugCoverageData, but sometimes\n    a plain CoverageData, and some tests are parameterized to run once with each\n    so that we have a mix of debugging or not.\n    \"\"\"\n    assert \"debug\" not in kwargs\n    options = [\"dataio\", \"dataop\", \"sql\"]\n    if kwargs:\n        # There's no logical reason kwargs should imply sqldata debugging.\n        # This is just a way to get a mix of debug options across the tests.\n        options.extend([\"dataop2\", \"sqldata\"])\n    debug = DebugControlString(options=options)\n    return CoverageData(*args, debug=debug, **kwargs)   # type: ignore[misc]\n\n\nTCoverageData = Callable[..., CoverageData]\n\ndef assert_line_counts(\n    covdata: CoverageData,\n    counts: Mapping[str, int],\n    fullpath: bool = False,\n) -> None:\n    \"\"\"Check that the line_counts of `covdata` is `counts`.\"\"\"\n    assert line_counts(covdata, fullpath) == counts\n\ndef assert_measured_files(covdata: CoverageData, measured: Iterable[str]) -> None:\n    \"\"\"Check that `covdata`'s measured files are `measured`.\"\"\"\n    assert_count_equal(covdata.measured_files(), measured)\n\ndef assert_lines1_data(covdata: CoverageData) -> None:\n    \"\"\"Check that `covdata` has the data from LINES1.\"\"\"\n    assert_line_counts(covdata, SUMMARY_1)\n    assert_measured_files(covdata, MEASURED_FILES_1)\n    assert_count_equal(covdata.lines(\"a.py\"), A_PY_LINES_1)\n    assert not covdata.has_arcs()\n\ndef assert_arcs3_data(covdata: CoverageData) -> None:\n    \"\"\"Check that `covdata` has the data from ARCS3.\"\"\"\n    assert_line_counts(covdata, SUMMARY_3)\n    assert_measured_files(covdata, MEASURED_FILES_3)\n    assert_count_equal(covdata.lines(\"x.py\"), X_PY_LINES_3)\n    assert_count_equal(covdata.arcs(\"x.py\"), X_PY_ARCS_3)\n    assert_count_equal(covdata.lines(\"y.py\"), Y_PY_LINES_3)\n    assert_count_equal(covdata.arcs(\"y.py\"), Y_PY_ARCS_3)\n    assert covdata.has_arcs()\n\n\nTData = TypeVar(\"TData\", bound=Union[TLineNo, TArc])\n\ndef dicts_from_sets(file_data: dict[str, set[TData]]) -> dict[str, dict[TData, None]]:\n    \"\"\"Convert a dict of sets into a dict of dicts.\n\n    Before 6.0, file data was a dict with None as the values.  In 6.0, file\n    data is a set.  SqlData all along only cared that it was an iterable.\n    This function helps us test that the old dict format still works.\n    \"\"\"\n    return {k: dict.fromkeys(v) for k, v in file_data.items()}\n\n\nclass CoverageDataTest(CoverageTest):\n    \"\"\"Test cases for CoverageData.\"\"\"\n\n    def test_empty_data_is_false(self) -> None:\n        covdata = DebugCoverageData()\n        assert not covdata\n        self.assert_doesnt_exist(\".coverage\")\n\n    def test_empty_data_is_false_when_read(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.read()\n        assert not covdata\n        self.assert_doesnt_exist(\".coverage\")\n\n    def test_line_data_is_true(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines(LINES_1)\n        assert covdata\n\n    def test_arc_data_is_true(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_arcs(ARCS_3)\n        assert covdata\n\n    def test_empty_line_data_is_false(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines({})\n        assert not covdata\n\n    def test_empty_arc_data_is_false(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_arcs({})\n        assert not covdata\n\n    @pytest.mark.parametrize(\"lines\", [LINES_1, dicts_from_sets(LINES_1)])\n    def test_adding_lines(self, lines: Mapping[str, Collection[TLineNo]]) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines(lines)\n        assert_lines1_data(covdata)\n\n    @pytest.mark.parametrize(\"arcs\", [ARCS_3, dicts_from_sets(ARCS_3)])\n    def test_adding_arcs(self, arcs: Mapping[str, Collection[TArc]]) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_arcs(arcs)\n        assert_arcs3_data(covdata)\n\n    def test_ok_to_add_lines_twice(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines(LINES_1)\n        covdata.add_lines(LINES_2)\n        assert_line_counts(covdata, SUMMARY_1_2)\n        assert_measured_files(covdata, MEASURED_FILES_1_2)\n\n    def test_ok_to_add_arcs_twice(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_arcs(ARCS_3)\n        covdata.add_arcs(ARCS_4)\n        assert_line_counts(covdata, SUMMARY_3_4)\n        assert_measured_files(covdata, MEASURED_FILES_3_4)\n\n    def test_ok_to_add_empty_arcs(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_arcs(ARCS_3)\n        covdata.add_arcs(ARCS_4)\n        covdata.add_arcs(dict.fromkeys(ARCS_3, set()))\n        assert_line_counts(covdata, SUMMARY_3_4)\n        assert_measured_files(covdata, MEASURED_FILES_3_4)\n\n    @pytest.mark.parametrize(\"klass\", [CoverageData, DebugCoverageData])\n    def test_cant_add_arcs_with_lines(self, klass: TCoverageData) -> None:\n        covdata = klass()\n        covdata.add_lines(LINES_1)\n        msg = \"Can't add branch measurements to existing line data\"\n        with pytest.raises(DataError, match=msg):\n            covdata.add_arcs(ARCS_3)\n\n    @pytest.mark.parametrize(\"klass\", [CoverageData, DebugCoverageData])\n    def test_cant_add_lines_with_arcs(self, klass: TCoverageData) -> None:\n        covdata = klass()\n        covdata.add_arcs(ARCS_3)\n        msg = \"Can't add line measurements to existing branch data\"\n        with pytest.raises(DataError, match=msg):\n            covdata.add_lines(LINES_1)\n\n    def test_touch_file_with_lines(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines(LINES_1)\n        covdata.touch_file('zzz.py')\n        assert_measured_files(covdata, MEASURED_FILES_1 + ['zzz.py'])\n\n    def test_touch_file_with_arcs(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_arcs(ARCS_3)\n        covdata.touch_file('zzz.py')\n        assert_measured_files(covdata, MEASURED_FILES_3 + ['zzz.py'])\n\n    def test_set_query_contexts(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.set_context('test_a')\n        covdata.add_lines(LINES_1)\n        covdata.set_query_contexts(['te.*a'])\n        assert covdata.lines('a.py') == [1, 2]\n        covdata.set_query_contexts(['other'])\n        assert covdata.lines('a.py') == []\n\n    def test_no_lines_vs_unmeasured_file(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines(LINES_1)\n        covdata.touch_file('zzz.py')\n        assert covdata.lines('zzz.py') == []\n        assert covdata.lines('no_such_file.py') is None\n\n    def test_lines_with_contexts(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.set_context('test_a')\n        covdata.add_lines(LINES_1)\n        assert covdata.lines('a.py') == [1, 2]\n        covdata.set_query_contexts(['test'])\n        assert covdata.lines('a.py') == [1, 2]\n        covdata.set_query_contexts(['other'])\n        assert covdata.lines('a.py') == []\n\n    def test_contexts_by_lineno_with_lines(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.set_context('test_a')\n        covdata.add_lines(LINES_1)\n        expected = {1: ['test_a'], 2: ['test_a']}\n        assert covdata.contexts_by_lineno('a.py') == expected\n\n    @pytest.mark.parametrize(\"lines\", [LINES_1, dicts_from_sets(LINES_1)])\n    def test_no_duplicate_lines(self, lines: Mapping[str, Collection[TLineNo]]) -> None:\n        covdata = DebugCoverageData()\n        covdata.set_context(\"context1\")\n        covdata.add_lines(lines)\n        covdata.set_context(\"context2\")\n        covdata.add_lines(lines)\n        assert covdata.lines('a.py') == A_PY_LINES_1\n\n    @pytest.mark.parametrize(\"arcs\", [ARCS_3, dicts_from_sets(ARCS_3)])\n    def test_no_duplicate_arcs(self, arcs: Mapping[str, Collection[TArc]]) -> None:\n        covdata = DebugCoverageData()\n        covdata.set_context(\"context1\")\n        covdata.add_arcs(arcs)\n        covdata.set_context(\"context2\")\n        covdata.add_arcs(arcs)\n        assert covdata.arcs('x.py') == X_PY_ARCS_3\n\n    def test_no_arcs_vs_unmeasured_file(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_arcs(ARCS_3)\n        covdata.touch_file('zzz.py')\n        assert covdata.lines('zzz.py') == []\n        assert covdata.lines('no_such_file.py') is None\n        assert covdata.arcs('zzz.py') == []\n        assert covdata.arcs('no_such_file.py') is None\n\n    def test_arcs_with_contexts(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.set_context('test_x')\n        covdata.add_arcs(ARCS_3)\n        assert covdata.arcs('x.py') == [(-1, 1), (1, 2), (2, 3), (3, -1)]\n        covdata.set_query_contexts(['test_.$'])\n        assert covdata.arcs('x.py') == [(-1, 1), (1, 2), (2, 3), (3, -1)]\n        covdata.set_query_contexts(['other'])\n        assert covdata.arcs('x.py') == []\n\n    def test_contexts_by_lineno_with_arcs(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.set_context('test_x')\n        covdata.add_arcs(ARCS_3)\n        expected = {1: ['test_x'], 2: ['test_x'], 3: ['test_x']}\n        assert covdata.contexts_by_lineno('x.py') == expected\n\n    def test_contexts_by_lineno_with_unknown_file(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.set_context('test_x')\n        covdata.add_arcs(ARCS_3)\n        assert covdata.contexts_by_lineno('xyz.py') == {}\n\n    def test_context_by_lineno_with_query_contexts_with_lines(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.set_context(\"test_1\")\n        covdata.add_lines(LINES_1)\n        covdata.set_context(\"test_2\")\n        covdata.add_lines(LINES_2)\n        covdata.set_query_context(\"test_1\")\n        assert covdata.contexts_by_lineno(\"a.py\") == dict.fromkeys([1,2], [\"test_1\"])\n\n    def test_context_by_lineno_with_query_contexts_with_arcs(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.set_context(\"test_1\")\n        covdata.add_arcs(ARCS_3)\n        covdata.set_context(\"test_2\")\n        covdata.add_arcs(ARCS_4)\n        covdata.set_query_context(\"test_1\")\n        assert covdata.contexts_by_lineno(\"x.py\") == dict.fromkeys([1,2,3], [\"test_1\"])\n\n    def test_file_tracer_name(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines({\n            \"p1.foo\": [1, 2, 3],\n            \"p2.html\": [10, 11, 12],\n            \"main.py\": [20],\n        })\n        covdata.add_file_tracers({\"p1.foo\": \"p1.plugin\", \"p2.html\": \"p2.plugin\"})\n        assert covdata.file_tracer(\"p1.foo\") == \"p1.plugin\"\n        assert covdata.file_tracer(\"p2.html\") == \"p2.plugin\"\n        assert covdata.file_tracer(\"main.py\") == \"\"\n        assert covdata.file_tracer(\"p3.not_here\") is None\n\n    def test_ok_to_repeat_file_tracer(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines({\n            \"p1.foo\": [1, 2, 3],\n            \"p2.html\": [10, 11, 12],\n        })\n        covdata.add_file_tracers({\"p1.foo\": \"p1.plugin\", \"p2.html\": \"p2.plugin\"})\n        covdata.add_file_tracers({\"p1.foo\": \"p1.plugin\"})\n        assert covdata.file_tracer(\"p1.foo\") == \"p1.plugin\"\n\n    def test_ok_to_set_empty_file_tracer(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines({\n            \"p1.foo\": [1, 2, 3],\n            \"p2.html\": [10, 11, 12],\n            \"main.py\": [20],\n        })\n        covdata.add_file_tracers({\"p1.foo\": \"p1.plugin\", \"main.py\": \"\"})\n        assert covdata.file_tracer(\"p1.foo\") == \"p1.plugin\"\n        assert covdata.file_tracer(\"main.py\") == \"\"\n\n    def test_cant_change_file_tracer_name(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines({\"p1.foo\": [1, 2, 3]})\n        covdata.add_file_tracers({\"p1.foo\": \"p1.plugin\"})\n\n        msg = \"Conflicting file tracer name for 'p1.foo': 'p1.plugin' vs 'p1.plugin.foo'\"\n        with pytest.raises(DataError, match=msg):\n            covdata.add_file_tracers({\"p1.foo\": \"p1.plugin.foo\"})\n\n    def test_update_lines(self) -> None:\n        covdata1 = DebugCoverageData(suffix='1')\n        covdata1.add_lines(LINES_1)\n\n        covdata2 = DebugCoverageData(suffix='2')\n        covdata2.add_lines(LINES_2)\n\n        covdata3 = DebugCoverageData(suffix='3')\n        covdata3.update(covdata1)\n        covdata3.update(covdata2)\n\n        assert_line_counts(covdata3, SUMMARY_1_2)\n        assert_measured_files(covdata3, MEASURED_FILES_1_2)\n\n    def test_update_arcs(self) -> None:\n        covdata1 = DebugCoverageData(suffix='1')\n        covdata1.add_arcs(ARCS_3)\n\n        covdata2 = DebugCoverageData(suffix='2')\n        covdata2.add_arcs(ARCS_4)\n\n        covdata3 = DebugCoverageData(suffix='3')\n        covdata3.update(covdata1)\n        covdata3.update(covdata2)\n\n        assert_line_counts(covdata3, SUMMARY_3_4)\n        assert_measured_files(covdata3, MEASURED_FILES_3_4)\n\n    def test_update_cant_mix_lines_and_arcs(self) -> None:\n        covdata1 = DebugCoverageData(suffix='1')\n        covdata1.add_lines(LINES_1)\n\n        covdata2 = DebugCoverageData(suffix='2')\n        covdata2.add_arcs(ARCS_3)\n\n        msg = \"Can't combine branch coverage data with statement data\"\n        with pytest.raises(DataError, match=msg):\n            covdata1.update(covdata2)\n\n        msg = \"Can't combine statement coverage data with branch data\"\n        with pytest.raises(DataError, match=msg):\n            covdata2.update(covdata1)\n\n    def test_update_file_tracers(self) -> None:\n        covdata1 = DebugCoverageData(suffix='1')\n        covdata1.add_lines({\n            \"p1.html\": [1, 2, 3, 4],\n            \"p2.html\": [5, 6, 7],\n            \"main.py\": [10, 11, 12],\n        })\n        covdata1.add_file_tracers({\n            \"p1.html\": \"html.plugin\",\n            \"p2.html\": \"html.plugin2\",\n        })\n\n        covdata2 = DebugCoverageData(suffix='2')\n        covdata2.add_lines({\n            \"p1.html\": [3, 4, 5, 6],\n            \"p2.html\": [7, 8, 9],\n            \"p3.foo\": [1000, 1001],\n            \"main.py\": [10, 11, 12],\n        })\n        covdata2.add_file_tracers({\n            \"p1.html\": \"html.plugin\",\n            \"p2.html\": \"html.plugin2\",\n            \"p3.foo\": \"foo_plugin\",\n        })\n\n        covdata3 = DebugCoverageData(suffix='3')\n        covdata3.update(covdata1)\n        covdata3.update(covdata2)\n        assert covdata3.file_tracer(\"p1.html\") == \"html.plugin\"\n        assert covdata3.file_tracer(\"p2.html\") == \"html.plugin2\"\n        assert covdata3.file_tracer(\"p3.foo\") == \"foo_plugin\"\n        assert covdata3.file_tracer(\"main.py\") == \"\"\n\n    def test_update_conflicting_file_tracers(self) -> None:\n        covdata1 = DebugCoverageData(suffix='1')\n        covdata1.add_lines({\"p1.html\": [1, 2, 3]})\n        covdata1.add_file_tracers({\"p1.html\": \"html.plugin\"})\n\n        covdata2 = DebugCoverageData(suffix='2')\n        covdata2.add_lines({\"p1.html\": [1, 2, 3]})\n        covdata2.add_file_tracers({\"p1.html\": \"html.other_plugin\"})\n\n        msg = \"Conflicting file tracer name for 'p1.html': 'html.plugin' vs 'html.other_plugin'\"\n        with pytest.raises(DataError, match=msg):\n            covdata1.update(covdata2)\n\n        msg = \"Conflicting file tracer name for 'p1.html': 'html.other_plugin' vs 'html.plugin'\"\n        with pytest.raises(DataError, match=msg):\n            covdata2.update(covdata1)\n\n    def test_update_file_tracer_vs_no_file_tracer(self) -> None:\n        covdata1 = DebugCoverageData(suffix=\"1\")\n        covdata1.add_lines({\"p1.html\": [1, 2, 3]})\n        covdata1.add_file_tracers({\"p1.html\": \"html.plugin\"})\n\n        covdata2 = DebugCoverageData(suffix=\"2\")\n        covdata2.add_lines({\"p1.html\": [1, 2, 3]})\n\n        msg = \"Conflicting file tracer name for 'p1.html': 'html.plugin' vs ''\"\n        with pytest.raises(DataError, match=msg):\n            covdata1.update(covdata2)\n\n        msg = \"Conflicting file tracer name for 'p1.html': '' vs 'html.plugin'\"\n        with pytest.raises(DataError, match=msg):\n            covdata2.update(covdata1)\n\n    def test_update_lines_empty(self) -> None:\n        covdata1 = DebugCoverageData(suffix='1')\n        covdata1.add_lines(LINES_1)\n\n        covdata2 = DebugCoverageData(suffix='2')\n        covdata1.update(covdata2)\n        assert_line_counts(covdata1, SUMMARY_1)\n\n    def test_update_arcs_empty(self) -> None:\n        covdata1 = DebugCoverageData(suffix='1')\n        covdata1.add_arcs(ARCS_3)\n\n        covdata2 = DebugCoverageData(suffix='2')\n        covdata1.update(covdata2)\n        assert_line_counts(covdata1, SUMMARY_3)\n\n    def test_asking_isnt_measuring(self) -> None:\n        # Asking about an unmeasured file shouldn't make it seem measured.\n        covdata = DebugCoverageData()\n        assert_measured_files(covdata, [])\n        assert covdata.arcs(\"missing.py\") is None\n        assert_measured_files(covdata, [])\n\n    def test_add_to_hash_with_lines(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines(LINES_1)\n        hasher = mock.Mock()\n        add_data_to_hash(covdata, \"a.py\", hasher)\n        assert hasher.method_calls == [\n            mock.call.update([1, 2]),   # lines\n            mock.call.update(\"\"),       # file_tracer name\n        ]\n\n    def test_add_to_hash_with_arcs(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_arcs(ARCS_3)\n        covdata.add_file_tracers({\"y.py\": \"hologram_plugin\"})\n        hasher = mock.Mock()\n        add_data_to_hash(covdata, \"y.py\", hasher)\n        assert hasher.method_calls == [\n            mock.call.update([(-1, 17), (17, 23), (23, -1)]),   # arcs\n            mock.call.update(\"hologram_plugin\"),                # file_tracer name\n        ]\n\n    def test_add_to_lines_hash_with_missing_file(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/403\n        covdata = DebugCoverageData()\n        covdata.add_lines(LINES_1)\n        hasher = mock.Mock()\n        add_data_to_hash(covdata, \"missing.py\", hasher)\n        assert hasher.method_calls == [\n            mock.call.update([]),\n            mock.call.update(None),\n        ]\n\n    def test_add_to_arcs_hash_with_missing_file(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/403\n        covdata = DebugCoverageData()\n        covdata.add_arcs(ARCS_3)\n        covdata.add_file_tracers({\"y.py\": \"hologram_plugin\"})\n        hasher = mock.Mock()\n        add_data_to_hash(covdata, \"missing.py\", hasher)\n        assert hasher.method_calls == [\n            mock.call.update([]),\n            mock.call.update(None),\n        ]\n\n    def test_empty_lines_are_still_lines(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines({})\n        covdata.touch_file(\"abc.py\")\n        assert not covdata.has_arcs()\n\n    def test_empty_arcs_are_still_arcs(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_arcs({})\n        covdata.touch_file(\"abc.py\")\n        assert covdata.has_arcs()\n\n    def test_cant_touch_in_empty_data(self) -> None:\n        covdata = DebugCoverageData()\n        msg = \"Can't touch files in an empty CoverageData\"\n        with pytest.raises(DataError, match=msg):\n            covdata.touch_file(\"abc.py\")\n\n    def test_read_and_write_are_opposites(self) -> None:\n        covdata1 = DebugCoverageData()\n        covdata1.add_arcs(ARCS_3)\n        covdata1.write()\n\n        covdata2 = DebugCoverageData()\n        covdata2.read()\n        assert_arcs3_data(covdata2)\n\n    def test_thread_stress(self) -> None:\n        covdata = DebugCoverageData()\n        exceptions = []\n\n        def thread_main() -> None:\n            \"\"\"Every thread will try to add the same data.\"\"\"\n            try:\n                covdata.add_lines(LINES_1)\n            except Exception as ex:         # pragma: only failure\n                exceptions.append(ex)\n\n        threads = [threading.Thread(target=thread_main) for _ in range(10)]\n        for t in threads:\n            t.start()\n        for t in threads:\n            t.join()\n\n        assert_lines1_data(covdata)\n        assert not exceptions\n\n    def test_purge_files_lines(self) -> None:\n        covdata = DebugCoverageData()\n        covdata.add_lines(LINES_1)\n        covdata.add_lines(LINES_2)\n        assert_line_counts(covdata, SUMMARY_1_2)\n        covdata.purge_files([\"a.py\", \"b.py\"])\n        assert_line_counts(covdata, {\"a.py\": 0, \"b.py\": 0, \"c.py\": 1})\n        covdata.purge_files([\"c.py\"])\n        assert_line_counts(covdata, {\"a.py\": 0, \"b.py\": 0, \"c.py\": 0})\n        # It's OK to \"purge\" a file that wasn't measured.\n        covdata.purge_files([\"xyz.py\"])\n        assert_line_counts(covdata, {\"a.py\": 0, \"b.py\": 0, \"c.py\": 0})\n\n    def test_purge_files_arcs(self) -> None:\n        covdata = CoverageData()\n        covdata.add_arcs(ARCS_3)\n        covdata.add_arcs(ARCS_4)\n        assert_line_counts(covdata, SUMMARY_3_4)\n        covdata.purge_files([\"x.py\", \"y.py\"])\n        assert_line_counts(covdata, {\"x.py\": 0, \"y.py\": 0, \"z.py\": 1})\n        covdata.purge_files([\"z.py\"])\n        assert_line_counts(covdata, {\"x.py\": 0, \"y.py\": 0, \"z.py\": 0})\n\n    def test_cant_purge_in_empty_data(self) -> None:\n        covdata = DebugCoverageData()\n        msg = \"Can't purge files in an empty CoverageData\"\n        with pytest.raises(DataError, match=msg):\n            covdata.purge_files([\"abc.py\"])\n\n\nclass CoverageDataInTempDirTest(CoverageTest):\n    \"\"\"Tests of CoverageData that need a temporary directory to make files.\"\"\"\n\n    @pytest.mark.parametrize(\"file_class\", FilePathClasses)\n    def test_read_write_lines(self, file_class: FilePathType) -> None:\n        self.assert_doesnt_exist(\"lines.dat\")\n        covdata1 = DebugCoverageData(file_class(\"lines.dat\"))\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n        self.assert_exists(\"lines.dat\")\n\n        covdata2 = DebugCoverageData(\"lines.dat\")\n        covdata2.read()\n        assert_lines1_data(covdata2)\n\n    def test_read_write_arcs(self) -> None:\n        covdata1 = DebugCoverageData(\"arcs.dat\")\n        covdata1.add_arcs(ARCS_3)\n        covdata1.write()\n\n        covdata2 = DebugCoverageData(\"arcs.dat\")\n        covdata2.read()\n        assert_arcs3_data(covdata2)\n\n    def test_read_errors(self) -> None:\n        self.make_file(\"xyzzy.dat\", \"xyzzy\")\n        with pytest.raises(DataError, match=r\"Couldn't .* '.*[/\\\\]xyzzy.dat': \\S+\"):\n            covdata = DebugCoverageData(\"xyzzy.dat\")\n            covdata.read()\n        assert not covdata\n\n    def test_hard_read_error(self) -> None:\n        self.make_file(\"noperms.dat\", \"go away\")\n        os.chmod(\"noperms.dat\", 0)\n        with pytest.raises(DataError, match=r\"Couldn't .* '.*[/\\\\]noperms.dat': \\S+\"):\n            covdata = DebugCoverageData(\"noperms.dat\")\n            covdata.read()\n\n    @pytest.mark.parametrize(\"klass\", [CoverageData, DebugCoverageData])\n    def test_error_when_closing(self, klass: TCoverageData) -> None:\n        msg = r\"Couldn't .* '.*[/\\\\]flaked.dat': \\S+\"\n        with pytest.raises(DataError, match=msg):\n            covdata = klass(\"flaked.dat\")\n            covdata.add_lines(LINES_1)\n            # I don't know how to make a real error, so let's fake one.\n            sqldb = list(covdata._dbs.values())[0]\n            sqldb.close = lambda: 1/0       # type: ignore[assignment]\n            covdata.add_lines(LINES_1)\n\n    def test_wrong_schema_version(self) -> None:\n        with sqlite3.connect(\"wrong_schema.db\") as con:\n            con.execute(\"create table coverage_schema (version integer)\")\n            con.execute(\"insert into coverage_schema (version) values (99)\")\n        msg = r\"Couldn't .* '.*[/\\\\]wrong_schema.db': wrong schema: 99 instead of \\d+\"\n        with pytest.raises(DataError, match=msg):\n            covdata = DebugCoverageData(\"wrong_schema.db\")\n            covdata.read()\n        assert not covdata\n\n    def test_wrong_schema_schema(self) -> None:\n        with sqlite3.connect(\"wrong_schema_schema.db\") as con:\n            con.execute(\"create table coverage_schema (xyzzy integer)\")\n            con.execute(\"insert into coverage_schema (xyzzy) values (99)\")\n        msg = r\"Data file .* doesn't seem to be a coverage data file: .* no such column\"\n        with pytest.raises(DataError, match=msg):\n            covdata = DebugCoverageData(\"wrong_schema_schema.db\")\n            covdata.read()\n        assert not covdata\n\n\nclass CoverageDataFilesTest(CoverageTest):\n    \"\"\"Tests of CoverageData file handling.\"\"\"\n\n    def test_reading_missing(self) -> None:\n        self.assert_doesnt_exist(\".coverage\")\n        covdata = DebugCoverageData()\n        covdata.read()\n        assert_line_counts(covdata, {})\n\n    def test_writing_and_reading(self) -> None:\n        covdata1 = DebugCoverageData()\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n\n        covdata2 = DebugCoverageData()\n        covdata2.read()\n        assert_line_counts(covdata2, SUMMARY_1)\n\n    def test_debug_output_with_debug_option(self) -> None:\n        # With debug option dataio, we get debug output about reading and\n        # writing files.\n        debug = DebugControlString(options=[\"dataio\"])\n        covdata1 = CoverageData(debug=debug)\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n\n        covdata2 = CoverageData(debug=debug)\n        covdata2.read()\n        assert_line_counts(covdata2, SUMMARY_1)\n\n        assert re.search(\n            r\"^Erasing data file '.*\\.coverage'\\n\" +\n            r\"Opening data file '.*\\.coverage'\\n\" +\n            r\"Initing data file '.*\\.coverage'\\n\" +\n            r\"Opening data file '.*\\.coverage'\\n$\",\n            debug.get_output(),\n        )\n\n    def test_debug_output_without_debug_option(self) -> None:\n        # With a debug object, but not the dataio option, we don't get debug\n        # output.\n        debug = DebugControlString(options=[])\n        covdata1 = CoverageData(debug=debug)\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n\n        covdata2 = CoverageData(debug=debug)\n        covdata2.read()\n        assert_line_counts(covdata2, SUMMARY_1)\n\n        assert debug.get_output() == \"\"\n\n    def test_explicit_suffix(self) -> None:\n        self.assert_doesnt_exist(\".coverage.SUFFIX\")\n        covdata = DebugCoverageData(suffix='SUFFIX')\n        covdata.add_lines(LINES_1)\n        covdata.write()\n        self.assert_exists(\".coverage.SUFFIX\")\n        self.assert_doesnt_exist(\".coverage\")\n\n    def test_true_suffix(self) -> None:\n        self.assert_file_count(\".coverage.*\", 0)\n\n        # suffix=True will make a randomly named data file.\n        covdata1 = DebugCoverageData(suffix=True)\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n        self.assert_doesnt_exist(\".coverage\")\n        data_files1 = glob.glob(\".coverage.*\")\n        assert len(data_files1) == 1\n\n        # Another suffix=True will choose a different name.\n        covdata2 = DebugCoverageData(suffix=True)\n        covdata2.add_lines(LINES_1)\n        covdata2.write()\n        self.assert_doesnt_exist(\".coverage\")\n        data_files2 = glob.glob(\".coverage.*\")\n        assert len(data_files2) == 2\n\n        # In addition to being different, the suffixes have the pid in them.\n        assert all(str(os.getpid()) in fn for fn in data_files2)\n\n    def test_combining(self) -> None:\n        self.assert_file_count(\".coverage.*\", 0)\n\n        covdata1 = DebugCoverageData(suffix='1')\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n        self.assert_exists(\".coverage.1\")\n        self.assert_file_count(\".coverage.*\", 1)\n\n        covdata2 = DebugCoverageData(suffix='2')\n        covdata2.add_lines(LINES_2)\n        covdata2.write()\n        self.assert_exists(\".coverage.2\")\n        self.assert_file_count(\".coverage.*\", 2)\n\n        covdata3 = DebugCoverageData()\n        combine_parallel_data(covdata3)\n        assert_line_counts(covdata3, SUMMARY_1_2)\n        assert_measured_files(covdata3, MEASURED_FILES_1_2)\n        self.assert_file_count(\".coverage.*\", 0)\n\n    def test_erasing(self) -> None:\n        covdata1 = DebugCoverageData()\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n\n        covdata1.erase()\n        assert_line_counts(covdata1, {})\n\n        covdata2 = DebugCoverageData()\n        covdata2.read()\n        assert_line_counts(covdata2, {})\n\n    def test_erasing_parallel(self) -> None:\n        self.make_file(\"datafile.1\")\n        self.make_file(\"datafile.2\")\n        self.make_file(\".coverage\")\n        data = DebugCoverageData(\"datafile\")\n        data.erase(parallel=True)\n        self.assert_file_count(\"datafile.*\", 0)\n        self.assert_exists(\".coverage\")\n\n    def test_combining_with_aliases(self) -> None:\n        covdata1 = DebugCoverageData(suffix='1')\n        covdata1.add_lines({\n            '/home/ned/proj/src/a.py': {1, 2},\n            '/home/ned/proj/src/sub/b.py': {3},\n            '/home/ned/proj/src/template.html': {10},\n        })\n        covdata1.add_file_tracers({\n            '/home/ned/proj/src/template.html': 'html.plugin',\n        })\n        covdata1.write()\n\n        covdata2 = DebugCoverageData(suffix='2')\n        covdata2.add_lines({\n            r'c:\\ned\\test\\a.py': {4, 5},\n            r'c:\\ned\\test\\sub\\b.py': {3, 6},\n        })\n        covdata2.write()\n\n        self.assert_file_count(\".coverage.*\", 2)\n\n        self.make_file(\"a.py\", \"\")\n        self.make_file(\"sub/b.py\", \"\")\n        self.make_file(\"template.html\", \"\")\n        covdata3 = DebugCoverageData()\n        aliases = PathAliases()\n        aliases.add(\"/home/ned/proj/src/\", \"./\")\n        aliases.add(r\"c:\\ned\\test\", \"./\")\n        combine_parallel_data(covdata3, aliases=aliases)\n        self.assert_file_count(\".coverage.*\", 0)\n        self.assert_exists(\".coverage\")\n\n        apy = canonical_filename('./a.py')\n        sub_bpy = canonical_filename('./sub/b.py')\n        template_html = canonical_filename('./template.html')\n\n        assert_line_counts(covdata3, {apy: 4, sub_bpy: 2, template_html: 1}, fullpath=True)\n        assert_measured_files(covdata3, [apy, sub_bpy, template_html])\n        assert covdata3.file_tracer(template_html) == 'html.plugin'\n\n    def test_combining_from_different_directories(self) -> None:\n        os.makedirs('cov1')\n        covdata1 = DebugCoverageData('cov1/.coverage.1')\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n\n        os.makedirs('cov2')\n        covdata2 = DebugCoverageData('cov2/.coverage.2')\n        covdata2.add_lines(LINES_2)\n        covdata2.write()\n\n        # This data won't be included.\n        covdata_xxx = DebugCoverageData('.coverage.xxx')\n        covdata_xxx.add_arcs(ARCS_3)\n        covdata_xxx.write()\n\n        covdata3 = DebugCoverageData()\n        combine_parallel_data(covdata3, data_paths=['cov1', 'cov2'])\n\n        assert_line_counts(covdata3, SUMMARY_1_2)\n        assert_measured_files(covdata3, MEASURED_FILES_1_2)\n        self.assert_doesnt_exist(\"cov1/.coverage.1\")\n        self.assert_doesnt_exist(\"cov2/.coverage.2\")\n        self.assert_exists(\".coverage.xxx\")\n\n    def test_combining_from_files(self) -> None:\n        os.makedirs('cov1')\n        covdata1 = DebugCoverageData('cov1/.coverage.1')\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n\n        # Journal files should never be included in the combining.\n        self.make_file(\"cov1/.coverage.1-journal\", \"xyzzy\")\n\n        os.makedirs('cov2')\n        covdata2 = DebugCoverageData('cov2/.coverage.2')\n        covdata2.add_lines(LINES_2)\n        covdata2.write()\n\n        # This data won't be included.\n        covdata_xxx = DebugCoverageData('.coverage.xxx')\n        covdata_xxx.add_arcs(ARCS_3)\n        covdata_xxx.write()\n\n        covdata_2xxx = DebugCoverageData('cov2/.coverage.xxx')\n        covdata_2xxx.add_arcs(ARCS_3)\n        covdata_2xxx.write()\n\n        covdata3 = DebugCoverageData()\n        combine_parallel_data(covdata3, data_paths=['cov1', 'cov2/.coverage.2'])\n\n        assert_line_counts(covdata3, SUMMARY_1_2)\n        assert_measured_files(covdata3, MEASURED_FILES_1_2)\n        self.assert_doesnt_exist(\"cov1/.coverage.1\")\n        self.assert_doesnt_exist(\"cov2/.coverage.2\")\n        self.assert_exists(\".coverage.xxx\")\n        self.assert_exists(\"cov2/.coverage.xxx\")\n\n    def test_combining_from_nonexistent_directories(self) -> None:\n        covdata = DebugCoverageData()\n        msg = \"Couldn't combine from non-existent path 'xyzzy'\"\n        with pytest.raises(NoDataError, match=msg):\n            combine_parallel_data(covdata, data_paths=['xyzzy'])\n\n    def test_interleaved_erasing_bug716(self) -> None:\n        # pytest-cov could produce this scenario. #716\n        covdata1 = DebugCoverageData()\n        covdata2 = DebugCoverageData()\n        # this used to create the .coverage database file..\n        covdata2.set_context(\"\")\n        # then this would erase it all..\n        covdata1.erase()\n        # then this would try to use tables that no longer exist.\n        # \"no such table: meta\"\n        covdata2.add_lines(LINES_1)\n\n    @pytest.mark.parametrize(\n        \"dpart, fpart\",\n        [\n            (\"\", \"[b-a]\"),\n            (\"[3-1]\", \"\"),\n            (\"[3-1]\", \"[b-a]\"),\n        ],\n    )\n    def test_combining_with_crazy_filename(self, dpart: str, fpart: str) -> None:\n        dirname = f\"py{dpart}\"\n        basename = f\"{dirname}/.coverage{fpart}\"\n        os.makedirs(dirname)\n\n        covdata1 = CoverageData(basename=basename, suffix=\"1\")\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n\n        covdata2 = CoverageData(basename=basename, suffix=\"2\")\n        covdata2.add_lines(LINES_2)\n        covdata2.write()\n\n        covdata3 = CoverageData(basename=basename)\n        combine_parallel_data(covdata3)\n        assert_line_counts(covdata3, SUMMARY_1_2)\n        assert_measured_files(covdata3, MEASURED_FILES_1_2)\n        self.assert_file_count(glob.escape(basename) + \".*\", 0)\n\n    def test_meta_data(self) -> None:\n        # The metadata written to the data file shouldn't interfere with\n        # hashing to remove duplicates, except for debug=process, which\n        # writes debugging info as metadata.\n        debug = DebugControlString(options=[])\n        covdata1 = CoverageData(basename=\"meta.1\", debug=debug)\n        covdata1.add_lines(LINES_1)\n        covdata1.write()\n        with sqlite3.connect(\"meta.1\") as con:\n            data = sorted(k for (k,) in con.execute(\"select key from meta\"))\n        assert data == [\"has_arcs\", \"version\"]\n\n        debug = DebugControlString(options=[\"process\"])\n        covdata2 = CoverageData(basename=\"meta.2\", debug=debug)\n        covdata2.add_lines(LINES_1)\n        covdata2.write()\n        with sqlite3.connect(\"meta.2\") as con:\n            data = sorted(k for (k,) in con.execute(\"select key from meta\"))\n        assert data == [\"has_arcs\", \"sys_argv\", \"version\", \"when\"]\n\n\nclass DumpsLoadsTest(CoverageTest):\n    \"\"\"Tests of CoverageData.dumps and loads.\"\"\"\n\n    run_in_temp_dir = False\n\n    @pytest.mark.parametrize(\"klass\", [CoverageData, DebugCoverageData])\n    def test_serialization(self, klass: TCoverageData) -> None:\n        covdata1 = klass(no_disk=True)\n        covdata1.add_lines(LINES_1)\n        covdata1.add_lines(LINES_2)\n        serial = covdata1.dumps()\n\n        covdata2 = klass(no_disk=True)\n        covdata2.loads(serial)\n        assert_line_counts(covdata2, SUMMARY_1_2)\n        assert_measured_files(covdata2, MEASURED_FILES_1_2)\n\n    def test_misfed_serialization(self) -> None:\n        covdata = CoverageData(no_disk=True)\n        bad_data = b'Hello, world!\\x07 ' + b'z' * 100\n        msg = r\"Unrecognized serialization: {} \\(head of {} bytes\\)\".format(\n            re.escape(repr(bad_data[:40])),\n            len(bad_data),\n        )\n        with pytest.raises(DataError, match=msg):\n            covdata.loads(bad_data)\n\n\nclass NoDiskTest(CoverageTest):\n    \"\"\"Tests of in-memory CoverageData.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_updating(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1323\n        a = CoverageData(no_disk=True)\n        a.add_lines({'foo.py': [10, 20, 30]})\n        assert a.measured_files() == {'foo.py'}\n\n        b = CoverageData(no_disk=True)\n        b.update(a)\n        assert b.measured_files() == {'foo.py'}\n", "tests/test_lcov.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Test LCOV-based summary reporting for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport math\nimport textwrap\n\nfrom tests.coveragetest import CoverageTest\n\nimport coverage\nfrom coverage import env\n\n\nclass LcovTest(CoverageTest):\n    \"\"\"Tests of the LCOV reports from coverage.py.\"\"\"\n\n    def create_initial_files(self) -> None:\n        \"\"\"\n        Helper for tests that handles the common ceremony so the tests can\n        show the consequences of changes in the setup.\n        \"\"\"\n        self.make_file(\"main_file.py\", \"\"\"\\\n            def cuboid_volume(l):\n                return (l*l*l)\n\n            def IsItTrue():\n                return True\n            \"\"\")\n\n        self.make_file(\"test_file.py\", \"\"\"\\\n            from main_file import cuboid_volume\n            import unittest\n\n            class TestCuboid(unittest.TestCase):\n                def test_volume(self):\n                    self.assertAlmostEqual(cuboid_volume(2),8)\n                    self.assertAlmostEqual(cuboid_volume(1),1)\n                    self.assertAlmostEqual(cuboid_volume(0),0)\n                    self.assertAlmostEqual(cuboid_volume(5.5),166.375)\n            \"\"\")\n\n    def get_lcov_report_content(self, filename: str = \"coverage.lcov\") -> str:\n        \"\"\"Return the content of an LCOV report.\"\"\"\n        with open(filename) as file:\n            return file.read()\n\n    def test_lone_file(self) -> None:\n        # For a single file with a couple of functions, the lcov should cover\n        # the function definitions themselves, but not the returns.\n        self.make_file(\"main_file.py\", \"\"\"\\\n            def cuboid_volume(l):\n                return (l*l*l)\n\n            def IsItTrue():\n                return True\n            \"\"\")\n        expected_result = textwrap.dedent(\"\"\"\\\n            TN:\n            SF:main_file.py\n            DA:1,1,7URou3io0zReBkk69lEb/Q\n            DA:4,1,ilhb4KUfytxtEuClijZPlQ\n            DA:2,0,Xqj6H1iz/nsARMCAbE90ng\n            DA:5,0,LWILTcvARcydjFFyo9qM0A\n            LF:4\n            LH:2\n            end_of_record\n            \"\"\")\n        self.assert_doesnt_exist(\".coverage\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"main_file\")\n        pct = cov.lcov_report()\n        assert pct == 50.0\n        actual_result = self.get_lcov_report_content()\n        assert expected_result == actual_result\n\n    def test_simple_line_coverage_two_files(self) -> None:\n        # Test that line coverage is created when coverage is run,\n        # and matches the output of the file below.\n        self.create_initial_files()\n        self.assert_doesnt_exist(\".coverage\")\n        self.make_file(\".coveragerc\", \"[lcov]\\noutput = data.lcov\\n\")\n        cov = coverage.Coverage(source=\".\")\n        self.start_import_stop(cov, \"test_file\")\n        pct = cov.lcov_report()\n        assert pct == 50.0\n        self.assert_exists(\"data.lcov\")\n        expected_result = textwrap.dedent(\"\"\"\\\n            TN:\n            SF:main_file.py\n            DA:1,1,7URou3io0zReBkk69lEb/Q\n            DA:4,1,ilhb4KUfytxtEuClijZPlQ\n            DA:2,0,Xqj6H1iz/nsARMCAbE90ng\n            DA:5,0,LWILTcvARcydjFFyo9qM0A\n            LF:4\n            LH:2\n            end_of_record\n            TN:\n            SF:test_file.py\n            DA:1,1,R5Rb4IzmjKRgY/vFFc1TRg\n            DA:2,1,E/tvV9JPVDhEcTCkgrwOFw\n            DA:4,1,GP08LPBYJq8EzYveHJy2qA\n            DA:5,1,MV+jSLi6PFEl+WatEAptog\n            DA:6,0,qyqd1mF289dg6oQAQHA+gQ\n            DA:7,0,nmEYd5F1KrxemgC9iVjlqg\n            DA:8,0,jodMK26WYDizOO1C7ekBbg\n            DA:9,0,LtxfKehkX8o4KvC5GnN52g\n            LF:8\n            LH:4\n            end_of_record\n            \"\"\")\n        actual_result = self.get_lcov_report_content(filename=\"data.lcov\")\n        assert expected_result == actual_result\n\n    def test_branch_coverage_one_file(self) -> None:\n        # Test that the reporter produces valid branch coverage.\n        self.make_file(\"main_file.py\", \"\"\"\\\n            def is_it_x(x):\n                if x == 3:\n                    return x\n                else:\n                    return False\n            \"\"\")\n        self.assert_doesnt_exist(\".coverage\")\n        cov = coverage.Coverage(branch=True, source=\".\")\n        self.start_import_stop(cov, \"main_file\")\n        pct = cov.lcov_report()\n        assert math.isclose(pct, 16.666666666666668)\n        self.assert_exists(\"coverage.lcov\")\n        expected_result = textwrap.dedent(\"\"\"\\\n            TN:\n            SF:main_file.py\n            DA:1,1,4MDXMbvwQ3L7va1tsphVzw\n            DA:2,0,MuERA6EYyZNpKPqoJfzwkA\n            DA:3,0,sAyiiE6iAuPMte9kyd0+3g\n            DA:5,0,W/g8GJDAYJkSSurt59Mzfw\n            LF:4\n            LH:1\n            BRDA:3,0,0,-\n            BRDA:5,0,1,-\n            BRF:2\n            BRH:0\n            end_of_record\n            \"\"\")\n        actual_result = self.get_lcov_report_content()\n        assert expected_result == actual_result\n\n    def test_branch_coverage_two_files(self) -> None:\n        # Test that valid branch coverage is generated\n        # in the case of two files.\n        self.make_file(\"main_file.py\", \"\"\"\\\n            def is_it_x(x):\n                if x == 3:\n                    return x\n                else:\n                    return False\n            \"\"\")\n\n        self.make_file(\"test_file.py\", \"\"\"\\\n            from main_file import *\n            import unittest\n\n            class TestIsItX(unittest.TestCase):\n                def test_is_it_x(self):\n                    self.assertEqual(is_it_x(3), 3)\n                    self.assertEqual(is_it_x(4), False)\n            \"\"\")\n        self.assert_doesnt_exist(\".coverage\")\n        cov = coverage.Coverage(branch=True, source=\".\")\n        self.start_import_stop(cov, \"test_file\")\n        pct = cov.lcov_report()\n        assert math.isclose(pct, 41.666666666666664)\n        self.assert_exists(\"coverage.lcov\")\n        expected_result = textwrap.dedent(\"\"\"\\\n            TN:\n            SF:main_file.py\n            DA:1,1,4MDXMbvwQ3L7va1tsphVzw\n            DA:2,0,MuERA6EYyZNpKPqoJfzwkA\n            DA:3,0,sAyiiE6iAuPMte9kyd0+3g\n            DA:5,0,W/g8GJDAYJkSSurt59Mzfw\n            LF:4\n            LH:1\n            BRDA:3,0,0,-\n            BRDA:5,0,1,-\n            BRF:2\n            BRH:0\n            end_of_record\n            TN:\n            SF:test_file.py\n            DA:1,1,9TxKIyoBtmhopmlbDNa8FQ\n            DA:2,1,E/tvV9JPVDhEcTCkgrwOFw\n            DA:4,1,C3s/c8C1Yd/zoNG1GnGexg\n            DA:5,1,9qPyWexYysgeKtB+YvuzAg\n            DA:6,0,LycuNcdqoUhPXeuXUTf5lA\n            DA:7,0,FPTWzd68bDx76HN7VHu1wA\n            LF:6\n            LH:4\n            BRF:0\n            BRH:0\n            end_of_record\n            \"\"\")\n        actual_result = self.get_lcov_report_content()\n        assert expected_result == actual_result\n\n    def test_half_covered_branch(self) -> None:\n        # Test that for a given branch that is only half covered,\n        # the block numbers remain the same, and produces valid lcov.\n        self.make_file(\"main_file.py\", \"\"\"\\\n            something = True\n\n            if something:\n                print(\"Yes, something\")\n            else:\n                print(\"No, nothing\")\n            \"\"\")\n        self.assert_doesnt_exist(\".coverage\")\n        cov = coverage.Coverage(branch=True, source=\".\")\n        self.start_import_stop(cov, \"main_file\")\n        pct = cov.lcov_report()\n        assert math.isclose(pct, 66.66666666666667)\n        self.assert_exists(\"coverage.lcov\")\n        expected_result = textwrap.dedent(\"\"\"\\\n            TN:\n            SF:main_file.py\n            DA:1,1,N4kbVOlkNI1rqOfCArBClw\n            DA:3,1,CmlqqPf0/H+R/p7/PLEXZw\n            DA:4,1,rE3mWnpoMq2W2sMETVk/uQ\n            DA:6,0,+Aov7ekIts7C96udNDVIIQ\n            LF:4\n            LH:3\n            BRDA:6,0,0,-\n            BRDA:4,0,1,1\n            BRF:2\n            BRH:1\n            end_of_record\n            \"\"\")\n        actual_result = self.get_lcov_report_content()\n        assert expected_result == actual_result\n\n    def test_empty_init_files(self) -> None:\n        # Test that in the case of an empty __init__.py file, the lcov\n        # reporter will note that the file is there, and will note the empty\n        # line. It will also note the lack of branches, and the checksum for\n        # the line.\n        #\n        # Although there are no lines found, it will note one line as hit in\n        # old Pythons, and no lines hit in newer Pythons.\n\n        self.make_file(\"__init__.py\", \"\")\n        self.assert_doesnt_exist(\".coverage\")\n        cov = coverage.Coverage(branch=True, source=\".\")\n        self.start_import_stop(cov, \"__init__\")\n        pct = cov.lcov_report()\n        assert pct == 0.0\n        self.assert_exists(\"coverage.lcov\")\n        # Newer Pythons have truly empty empty files.\n        if env.PYBEHAVIOR.empty_is_empty:\n            expected_result = textwrap.dedent(\"\"\"\\\n                TN:\n                SF:__init__.py\n                LF:0\n                LH:0\n                BRF:0\n                BRH:0\n                end_of_record\n                \"\"\")\n        else:\n            expected_result = textwrap.dedent(\"\"\"\\\n                TN:\n                SF:__init__.py\n                DA:1,1,1B2M2Y8AsgTpgAmY7PhCfg\n                LF:0\n                LH:0\n                BRF:0\n                BRH:0\n                end_of_record\n                \"\"\")\n        actual_result = self.get_lcov_report_content()\n        assert expected_result == actual_result\n\n    def test_excluded_lines(self) -> None:\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [report]\n            exclude_lines = foo\n            \"\"\")\n        self.make_file(\"runme.py\", \"\"\"\\\n            s = \"Hello 1\"\n            t = \"foo is ignored 2\"\n            if s.upper() == \"BYE 3\":\n                i_am_missing_4()\n                foo_is_missing_5()\n            print(\"Done 6\")\n            # foo 7\n            # line 8\n            \"\"\")\n        cov = coverage.Coverage(source=\".\", branch=True)\n        self.start_import_stop(cov, \"runme\")\n        cov.lcov_report()\n        expected_result = textwrap.dedent(\"\"\"\\\n            TN:\n            SF:runme.py\n            DA:1,1,nWfwsz0pRTEJrInVF+xNvQ\n            DA:3,1,uV4NoIauDo5LCti6agX9sg\n            DA:6,1,+PfQRgSChjQOGkA6MArMDg\n            DA:4,0,GR4ThLStnqpcZvm3alfRaA\n            LF:4\n            LH:3\n            BRDA:4,0,0,-\n            BRDA:6,0,1,1\n            BRF:2\n            BRH:1\n            end_of_record\n            \"\"\")\n        actual_result = self.get_lcov_report_content()\n        assert expected_result == actual_result\n", "tests/test_context.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for context support.\"\"\"\n\nfrom __future__ import annotations\n\nimport inspect\nimport os.path\n\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\n\nimport coverage\nfrom coverage.context import qualname_from_frame\nfrom coverage.data import CoverageData, sorted_lines\nfrom coverage.types import TArc, TCovKwargs, TLineNo\n\nfrom tests import testenv\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import assert_count_equal\n\n\nclass StaticContextTest(CoverageTest):\n    \"\"\"Tests of the static context.\"\"\"\n\n    def test_no_context(self) -> None:\n        self.make_file(\"main.py\", \"a = 1\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n        data = cov.get_data()\n        assert_count_equal(data.measured_contexts(), [\"\"])\n\n    def test_static_context(self) -> None:\n        self.make_file(\"main.py\", \"a = 1\")\n        cov = coverage.Coverage(context=\"gooey\")\n        self.start_import_stop(cov, \"main\")\n        data = cov.get_data()\n        assert_count_equal(data.measured_contexts(), [\"gooey\"])\n\n    SOURCE = \"\"\"\\\n        a = 1\n        if a > 2:\n            a = 3\n        assert a == 1\n        \"\"\"\n\n    LINES = [1, 2, 4]\n    ARCS = [(-1, 1), (1, 2), (2, 4), (4, -1)]\n\n    def run_red_blue(self, **options: TCovKwargs) -> tuple[CoverageData, CoverageData]:\n        \"\"\"Run red.py and blue.py, and return their CoverageData objects.\"\"\"\n        self.make_file(\"red.py\", self.SOURCE)\n        red_cov = coverage.Coverage(context=\"red\", data_suffix=\"r\", source=[\".\"], **options)\n        self.start_import_stop(red_cov, \"red\")\n        red_cov.save()\n        red_data = red_cov.get_data()\n\n        self.make_file(\"blue.py\", self.SOURCE)\n        blue_cov = coverage.Coverage(context=\"blue\", data_suffix=\"b\", source=[\".\"], **options)\n        self.start_import_stop(blue_cov, \"blue\")\n        blue_cov.save()\n        blue_data = blue_cov.get_data()\n\n        return red_data, blue_data\n\n    def test_combining_line_contexts(self) -> None:\n        red_data, blue_data = self.run_red_blue()\n        for datas in [[red_data, blue_data], [blue_data, red_data]]:\n            combined = CoverageData(suffix=\"combined\")\n            for data in datas:\n                combined.update(data)\n\n            assert combined.measured_contexts() == {'red', 'blue'}\n\n            full_names = {os.path.basename(f): f for f in combined.measured_files()}\n            assert_count_equal(full_names, ['red.py', 'blue.py'])\n\n            fred = full_names['red.py']\n            fblue = full_names['blue.py']\n\n            def assert_combined_lines(filename: str, context: str, lines: list[TLineNo]) -> None:\n                # pylint: disable=cell-var-from-loop\n                combined.set_query_context(context)\n                assert combined.lines(filename) == lines\n\n            assert_combined_lines(fred, 'red', self.LINES)\n            assert_combined_lines(fred, 'blue', [])\n            assert_combined_lines(fblue, 'red', [])\n            assert_combined_lines(fblue, 'blue', self.LINES)\n\n    def test_combining_arc_contexts(self) -> None:\n        red_data, blue_data = self.run_red_blue(branch=True)\n        for datas in [[red_data, blue_data], [blue_data, red_data]]:\n            combined = CoverageData(suffix=\"combined\")\n            for data in datas:\n                combined.update(data)\n\n            assert combined.measured_contexts() == {'red', 'blue'}\n\n            full_names = {os.path.basename(f): f for f in combined.measured_files()}\n            assert_count_equal(full_names, ['red.py', 'blue.py'])\n\n            fred = full_names['red.py']\n            fblue = full_names['blue.py']\n\n            def assert_combined_lines(filename: str, context: str, lines: list[TLineNo]) -> None:\n                # pylint: disable=cell-var-from-loop\n                combined.set_query_context(context)\n                assert combined.lines(filename) == lines\n\n            assert_combined_lines(fred, 'red', self.LINES)\n            assert_combined_lines(fred, 'blue', [])\n            assert_combined_lines(fblue, 'red', [])\n            assert_combined_lines(fblue, 'blue', self.LINES)\n\n            def assert_combined_arcs(filename: str, context: str, lines: list[TArc]) -> None:\n                # pylint: disable=cell-var-from-loop\n                combined.set_query_context(context)\n                assert combined.arcs(filename) == lines\n\n            assert_combined_arcs(fred, 'red', self.ARCS)\n            assert_combined_arcs(fred, 'blue', [])\n            assert_combined_arcs(fblue, 'red', [])\n            assert_combined_arcs(fblue, 'blue', self.ARCS)\n\n\n@pytest.mark.skipif(not testenv.DYN_CONTEXTS, reason=\"No dynamic contexts with this core\")\nclass DynamicContextTest(CoverageTest):\n    \"\"\"Tests of dynamically changing contexts.\"\"\"\n\n    SOURCE = \"\"\"\\\n        def helper(lineno):\n            x = 2\n\n        def test_one():\n            a = 5\n            helper(6)\n\n        def test_two():\n            a = 9\n            b = 10\n            if a > 11:\n                b = 12\n            assert a == (13-4)\n            assert b == (14-4)\n            helper(15)\n\n        test_one()\n        x = 18\n        helper(19)\n        test_two()\n        \"\"\"\n\n    OUTER_LINES = [1, 4, 8, 17, 18, 19, 2, 20]\n    TEST_ONE_LINES = [5, 6, 2]\n    TEST_TWO_LINES = [9, 10, 11, 13, 14, 15, 2]\n\n    def test_dynamic_alone(self) -> None:\n        self.make_file(\"two_tests.py\", self.SOURCE)\n        cov = coverage.Coverage(source=[\".\"])\n        cov.set_option(\"run:dynamic_context\", \"test_function\")\n        self.start_import_stop(cov, \"two_tests\")\n        data = cov.get_data()\n\n        full_names = {os.path.basename(f): f for f in data.measured_files()}\n        fname = full_names[\"two_tests.py\"]\n        assert_count_equal(\n            data.measured_contexts(),\n            [\"\", \"two_tests.test_one\", \"two_tests.test_two\"],\n        )\n\n        def assert_context_lines(context: str, lines: list[TLineNo]) -> None:\n            data.set_query_context(context)\n            assert_count_equal(lines, sorted_lines(data, fname))\n\n        assert_context_lines(\"\", self.OUTER_LINES)\n        assert_context_lines(\"two_tests.test_one\", self.TEST_ONE_LINES)\n        assert_context_lines(\"two_tests.test_two\", self.TEST_TWO_LINES)\n\n    def test_static_and_dynamic(self) -> None:\n        self.make_file(\"two_tests.py\", self.SOURCE)\n        cov = coverage.Coverage(context=\"stat\", source=[\".\"])\n        cov.set_option(\"run:dynamic_context\", \"test_function\")\n        self.start_import_stop(cov, \"two_tests\")\n        data = cov.get_data()\n\n        full_names = {os.path.basename(f): f for f in data.measured_files()}\n        fname = full_names[\"two_tests.py\"]\n        assert_count_equal(\n            data.measured_contexts(),\n            [\"stat\", \"stat|two_tests.test_one\", \"stat|two_tests.test_two\"],\n        )\n\n        def assert_context_lines(context: str, lines: list[TLineNo]) -> None:\n            data.set_query_context(context)\n            assert_count_equal(lines, sorted_lines(data, fname))\n\n        assert_context_lines(\"stat\", self.OUTER_LINES)\n        assert_context_lines(\"stat|two_tests.test_one\", self.TEST_ONE_LINES)\n        assert_context_lines(\"stat|two_tests.test_two\", self.TEST_TWO_LINES)\n\n\ndef get_qualname() -> str | None:\n    \"\"\"Helper to return qualname_from_frame for the caller.\"\"\"\n    stack = inspect.stack()[1:]\n    if any(sinfo[0].f_code.co_name == \"get_qualname\" for sinfo in stack):\n        # We're calling ourselves recursively, maybe because we're testing\n        # properties. Return an int to try to get back on track.\n        return 17       # type: ignore[return-value]\n    caller_frame = stack[0][0]\n    return qualname_from_frame(caller_frame)\n\n# pylint: disable=missing-class-docstring, missing-function-docstring, unused-argument\n\nclass Parent:\n    def meth(self) -> str | None:\n        return get_qualname()\n\n    @property\n    def a_property(self) -> str | None:\n        return get_qualname()\n\nclass Child(Parent):\n    pass\n\nclass SomethingElse:\n    pass\n\nclass MultiChild(SomethingElse, Child):\n    pass\n\ndef no_arguments() -> str | None:\n    return get_qualname()\n\ndef plain_old_function(a: Any, b: Any) -> str | None:\n    return get_qualname()\n\ndef fake_out(self: Any) -> str | None:\n    return get_qualname()\n\ndef patch_meth(self: Any) -> str | None:\n    return get_qualname()\n\n# pylint: enable=missing-class-docstring, missing-function-docstring, unused-argument\n\n\nclass QualnameTest(CoverageTest):\n    \"\"\"Tests of qualname_from_frame.\"\"\"\n\n    # Pylint gets confused about meth() below.\n    # pylint: disable=no-value-for-parameter\n\n    run_in_temp_dir = False\n\n    def test_method(self) -> None:\n        assert Parent().meth() == \"tests.test_context.Parent.meth\"\n\n    def test_inherited_method(self) -> None:\n        assert Child().meth() == \"tests.test_context.Parent.meth\"\n\n    def test_mi_inherited_method(self) -> None:\n        assert MultiChild().meth() == \"tests.test_context.Parent.meth\"\n\n    def test_no_arguments(self) -> None:\n        assert no_arguments() == \"tests.test_context.no_arguments\"\n\n    def test_plain_old_function(self) -> None:\n        assert plain_old_function(0, 1) == \"tests.test_context.plain_old_function\"\n\n    def test_fake_out(self) -> None:\n        assert fake_out(0) == \"tests.test_context.fake_out\"\n\n    def test_property(self) -> None:\n        assert Parent().a_property == \"tests.test_context.Parent.a_property\"\n\n    def test_changeling(self) -> None:\n        c = Child()\n        c.meth = patch_meth                                     # type: ignore[assignment]\n        assert c.meth(c) == \"tests.test_context.patch_meth\"     # type: ignore[call-arg]\n\n    def test_bug_829(self) -> None:\n        # A class with a name like a function shouldn't confuse qualname_from_frame.\n        class test_something:               # pylint: disable=unused-variable\n            assert get_qualname() is None\n\n    def test_bug_1210(self) -> None:\n        # Under pyarmor (an obfuscator), a function can have a \"self\" argument,\n        # but then not have a \"self\" local.\n        co = mock.Mock(co_name=\"a_co_name\", co_argcount=1, co_varnames=[\"self\"])\n        frame = mock.Mock(f_code=co, f_locals={})\n        assert qualname_from_frame(frame) == \"unittest.mock.a_co_name\"\n", "tests/test_goldtest.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests of the helpers in goldtest.py\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\nimport re\n\nimport pytest\n\nfrom tests.coveragetest import CoverageTest, TESTS_DIR\nfrom tests.goldtest import compare, gold_path\nfrom tests.goldtest import contains, contains_any, contains_rx, doesnt_contain\nfrom tests.helpers import os_sep, re_line, remove_tree\n\nGOOD_GETTY = \"\"\"\\\nFour score and seven years ago our fathers brought forth upon this continent, a\nnew nation, conceived in Liberty, and dedicated to the proposition that all men\nare created equal.\n11/19/9999, Gettysburg, Pennsylvania\n\"\"\"\n\nBAD_GETTY = \"\"\"\\\nFive score and seven years ago our fathers brought forth upon this continent, a\nnew nation, conceived in Liberty, and dedicated to the proposition that all men\nare created equal.\n333/4444/55555, Gabcdef, Pennsylvania\n\"\"\"\n\nSCRUBS = [\n    # Numbers don't matter when comparing.\n    (r'\\d+', 'D'),\n    (r'G\\w+', 'Gxxx'),\n]\n\ndef path_regex(path: str) -> str:\n    \"\"\"Convert a file path into a regex that will match that path on any OS.\"\"\"\n    return re.sub(r\"[/\\\\]\", r\"[/\\\\\\\\]\", path.replace(\".\", \"[.]\"))\n\nACTUAL_DIR = os.path.join(TESTS_DIR, \"actual/testing\")\nACTUAL_GETTY_FILE = os.path.join(ACTUAL_DIR, \"getty/gettysburg.txt\")\nGOLD_GETTY_FILE = os.path.join(TESTS_DIR, \"gold/testing/getty/gettysburg.txt\")\nGOLD_GETTY_FILE_RX = path_regex(GOLD_GETTY_FILE)\n\nGOLD_PATH_RX = path_regex(\"/tests/gold/testing/getty/gettysburg.txt\")\nOUT_PATH_RX = path_regex(\"out/gettysburg.txt\")\n\nclass CompareTest(CoverageTest):\n    \"\"\"Tests of goldtest.py:compare()\"\"\"\n\n    def setUp(self) -> None:\n        super().setUp()\n        self.addCleanup(remove_tree, ACTUAL_DIR)\n\n    def test_good(self) -> None:\n        self.make_file(\"out/gettysburg.txt\", GOOD_GETTY)\n        compare(gold_path(\"testing/getty\"), \"out\", scrubs=SCRUBS)\n        self.assert_doesnt_exist(ACTUAL_GETTY_FILE)\n\n    def test_bad(self) -> None:\n        self.make_file(\"out/gettysburg.txt\", BAD_GETTY)\n\n        # compare() raises an assertion.\n        msg = fr\"Files differ: .*{GOLD_PATH_RX} != {OUT_PATH_RX}\"\n        with pytest.raises(AssertionError, match=msg):\n            compare(gold_path(\"testing/getty\"), \"out\", scrubs=SCRUBS)\n\n        # Stdout has a description of the diff.  The diff shows the scrubbed content.\n        stdout = self.stdout()\n        assert \"- Four score\" in stdout\n        assert \"+ Five score\" in stdout\n        assert re_line(fr\"^:::: diff '.*{GOLD_PATH_RX}' and '{OUT_PATH_RX}'\", stdout)\n        assert re_line(fr\"^:::: end diff '.*{GOLD_PATH_RX}' and '{OUT_PATH_RX}'\", stdout)\n        assert (\n            os_sep(f\"Saved actual output to '{ACTUAL_GETTY_FILE}': see tests/gold/README.rst\")\n            in os_sep(stdout)\n        )\n        assert \"  D/D/D, Gxxx, Pennsylvania\" in stdout\n\n        # The actual file was saved.\n        with open(ACTUAL_GETTY_FILE) as f:\n            saved = f.read()\n        assert saved == BAD_GETTY\n\n    def test_good_needs_scrubs(self) -> None:\n        # Comparing the \"good\" result without scrubbing the variable parts will fail.\n        self.make_file(\"out/gettysburg.txt\", GOOD_GETTY)\n\n        # compare() raises an assertion.\n        msg = fr\"Files differ: .*{GOLD_PATH_RX} != {OUT_PATH_RX}\"\n        with pytest.raises(AssertionError, match=msg):\n            compare(gold_path(\"testing/getty\"), \"out\")\n\n        stdout = self.stdout()\n        assert \"- 11/19/1863, Gettysburg, Pennsylvania\" in stdout\n        assert \"+ 11/19/9999, Gettysburg, Pennsylvania\" in stdout\n\n    def test_actual_extra(self) -> None:\n        self.make_file(\"out/gettysburg.txt\", GOOD_GETTY)\n        self.make_file(\"out/another.more\", \"hi\")\n\n        # Extra files in the output are ok with actual_extra=True.\n        compare(gold_path(\"testing/getty\"), \"out\", scrubs=SCRUBS, actual_extra=True)\n\n        # But not without it:\n        # (test output is in files like /tmp/pytest-of-user/pytest-0/popen-gw3/t76/out)\n        msg = r\"Files in .*[/\\\\]t\\d+[/\\\\]out only: \\['another.more'\\]\"\n        with pytest.raises(AssertionError, match=msg):\n            compare(gold_path(\"testing/getty\"), \"out\", scrubs=SCRUBS)\n        self.assert_exists(os.path.join(TESTS_DIR, \"actual/testing/getty/another.more\"))\n\n        # But only the files matching the file_pattern are considered.\n        compare(gold_path(\"testing/getty\"), \"out\", file_pattern=\"*.txt\", scrubs=SCRUBS)\n\n    def test_xml_good(self) -> None:\n        self.make_file(\"out/output.xml\", \"\"\"\\\n            <?xml version=\"1.0\" ?>\n            <the_root c=\"three\" b=\"222\" a=\"one\">\n                <also z=\"nine\" x=\"seven\" y=\"888\">\n                    Goodie\n                </also>\n            </the_root>\n            \"\"\")\n        compare(gold_path(\"testing/xml\"), \"out\", scrubs=SCRUBS)\n\n    def test_xml_bad(self) -> None:\n        self.make_file(\"out/output.xml\", \"\"\"\\\n            <?xml version=\"1.0\" ?>\n            <the_root c=\"nine\" b=\"2\" a=\"one\">\n                <also z=\"three\" x=\"seven\" y=\"8\">\n                    Goodbye\n                </also>\n            </the_root>\n            \"\"\")\n\n        # compare() raises an exception.\n        gold_rx = path_regex(gold_path(\"testing/xml/output.xml\"))\n        out_rx = path_regex(\"out/output.xml\")\n        msg = fr\"Files differ: .*{gold_rx} != {out_rx}\"\n        with pytest.raises(AssertionError, match=msg):\n            compare(gold_path(\"testing/xml\"), \"out\", scrubs=SCRUBS)\n\n        # Stdout has a description of the diff.  The diff shows the\n        # canonicalized and scrubbed content.\n        stdout = self.stdout()\n        assert '- <the_root a=\"one\" b=\"D\" c=\"three\">' in stdout\n        assert '+ <the_root a=\"one\" b=\"D\" c=\"nine\">' in stdout\n\n\nclass ContainsTest(CoverageTest):\n    \"\"\"Tests of the various \"contains\" functions in goldtest.py\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_contains(self) -> None:\n        contains(GOLD_GETTY_FILE, \"Four\", \"fathers\", \"dedicated\")\n        msg = fr\"Missing content in {GOLD_GETTY_FILE_RX}: 'xyzzy'\"\n        with pytest.raises(AssertionError, match=msg):\n            contains(GOLD_GETTY_FILE, \"Four\", \"fathers\", \"xyzzy\", \"dedicated\")\n\n    def test_contains_rx(self) -> None:\n        contains_rx(GOLD_GETTY_FILE, r\"Fo.r\", r\"f[abc]thers\", \"dedi[cdef]ated\")\n        msg = fr\"Missing regex in {GOLD_GETTY_FILE_RX}: r'm\\[opq\\]thers'\"\n        with pytest.raises(AssertionError, match=msg):\n            contains_rx(GOLD_GETTY_FILE, r\"Fo.r\", r\"m[opq]thers\")\n\n    def test_contains_any(self) -> None:\n        contains_any(GOLD_GETTY_FILE, \"Five\", \"Four\", \"Three\")\n        msg = fr\"Missing content in {GOLD_GETTY_FILE_RX}: 'One' \\[1 of 3\\]\"\n        with pytest.raises(AssertionError, match=msg):\n            contains_any(GOLD_GETTY_FILE, \"One\", \"Two\", \"Three\")\n\n    def test_doesnt_contain(self) -> None:\n        doesnt_contain(GOLD_GETTY_FILE, \"One\", \"Two\", \"Three\")\n        msg = fr\"Forbidden content in {GOLD_GETTY_FILE_RX}: 'Four'\"\n        with pytest.raises(AssertionError, match=msg):\n            doesnt_contain(GOLD_GETTY_FILE, \"Three\", \"Four\", \"Five\")\n", "tests/test_execfile.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.execfile\"\"\"\n\nfrom __future__ import annotations\n\nimport compileall\nimport json\nimport os\nimport os.path\nimport pathlib\nimport py_compile\nimport re\nimport sys\n\nfrom typing import Any, Iterator\n\nimport pytest\n\nfrom coverage.exceptions import NoCode, NoSource, _ExceptionDuringRun\nfrom coverage.execfile import run_python_file, run_python_module\nfrom coverage.files import python_reported_file\n\nfrom tests.coveragetest import CoverageTest, TESTS_DIR, UsingModulesMixin\n\nTRY_EXECFILE = os.path.join(TESTS_DIR, \"modules/process_test/try_execfile.py\")\n\n\nclass RunFileTest(CoverageTest):\n    \"\"\"Test cases for `run_python_file`.\"\"\"\n\n    @pytest.fixture(autouse=True)\n    def clean_up(self) -> Iterator[None]:\n        \"\"\"These tests all run in-process. Clean up global changes.\"\"\"\n        yield\n        sys.excepthook = sys.__excepthook__\n\n    def test_run_python_file(self) -> None:\n        run_python_file([TRY_EXECFILE, \"arg1\", \"arg2\"])\n        mod_globs = json.loads(self.stdout())\n\n        # The file should think it is __main__\n        assert mod_globs['__name__'] == \"__main__\"\n\n        # It should seem to come from a file named try_execfile.py\n        dunder_file = os.path.basename(mod_globs['__file__'])\n        assert dunder_file == \"try_execfile.py\"\n\n        # It should have its correct module data.\n        assert mod_globs['__doc__'].splitlines()[0] == \"Test file for run_python_file.\"\n        assert mod_globs['DATA'] == \"xyzzy\"\n        assert mod_globs['FN_VAL'] == \"my_fn('fooey')\"\n\n        # It must be self-importable as __main__.\n        assert mod_globs['__main__.DATA'] == \"xyzzy\"\n\n        # Argv should have the proper values.\n        assert mod_globs['argv0'] == TRY_EXECFILE\n        assert mod_globs['argv1-n'] == [\"arg1\", \"arg2\"]\n\n        # __builtins__ should have the right values, like open().\n        assert mod_globs['__builtins__.has_open'] is True\n\n    def test_no_extra_file(self) -> None:\n        # Make sure that running a file doesn't create an extra compiled file.\n        self.make_file(\"xxx\", \"\"\"\\\n            desc = \"a non-.py file!\"\n            \"\"\")\n\n        assert os.listdir(\".\") == [\"xxx\"]\n        run_python_file([\"xxx\"])\n        assert os.listdir(\".\") == [\"xxx\"]\n\n    def test_universal_newlines(self) -> None:\n        # Make sure we can read any sort of line ending.\n        pylines = \"\"\"# try newlines|print('Hello, world!')|\"\"\".split('|')\n        for nl in ('\\n', '\\r\\n', '\\r'):\n            with open('nl.py', 'wb') as fpy:\n                fpy.write(nl.join(pylines).encode('utf-8'))\n            run_python_file(['nl.py'])\n        assert self.stdout() == \"Hello, world!\\n\"*3\n\n    def test_missing_final_newline(self) -> None:\n        # Make sure we can deal with a Python file with no final newline.\n        self.make_file(\"abrupt.py\", \"\"\"\\\n            if 1:\n                a = 1\n                print(f\"a is {a!r}\")\n                #\"\"\")\n        with open(\"abrupt.py\") as f:\n            abrupt = f.read()\n        assert abrupt[-1] == '#'\n        run_python_file([\"abrupt.py\"])\n        assert self.stdout() == \"a is 1\\n\"\n\n    def test_no_such_file(self) -> None:\n        path = python_reported_file('xyzzy.py')\n        msg = re.escape(f\"No file to run: '{path}'\")\n        with pytest.raises(NoSource, match=msg):\n            run_python_file([\"xyzzy.py\"])\n\n    def test_directory_with_main(self) -> None:\n        self.make_file(\"with_main/__main__.py\", \"\"\"\\\n            print(\"I am __main__\")\n            \"\"\")\n        run_python_file([\"with_main\"])\n        assert self.stdout() == \"I am __main__\\n\"\n\n    def test_directory_without_main(self) -> None:\n        self.make_file(\"without_main/__init__.py\", \"\")\n        with pytest.raises(NoSource, match=\"Can't find '__main__' module in 'without_main'\"):\n            run_python_file([\"without_main\"])\n\n    def test_code_throws(self) -> None:\n        self.make_file(\"throw.py\", \"\"\"\\\n            class MyException(Exception):\n                pass\n\n            def f1():\n                print(\"about to raise..\")\n                raise MyException(\"hey!\")\n\n            def f2():\n                f1()\n\n            f2()\n            \"\"\")\n\n        with pytest.raises(SystemExit) as exc_info:\n            run_python_file([\"throw.py\"])\n        assert exc_info.value.args == (1,)\n        assert self.stdout() == \"about to raise..\\n\"\n        assert self.stderr() == \"\"\n\n    def test_code_exits(self) -> None:\n        self.make_file(\"exit.py\", \"\"\"\\\n            import sys\n            def f1():\n                print(\"about to exit..\")\n                sys.exit(17)\n\n            def f2():\n                f1()\n\n            f2()\n            \"\"\")\n\n        with pytest.raises(SystemExit) as exc_info:\n            run_python_file([\"exit.py\"])\n        assert exc_info.value.args == (17,)\n        assert self.stdout() == \"about to exit..\\n\"\n        assert self.stderr() == \"\"\n\n    def test_excepthook_exit(self) -> None:\n        self.make_file(\"excepthook_exit.py\", \"\"\"\\\n            import sys\n\n            def excepthook(*args):\n                print('in excepthook')\n                sys.exit(0)\n\n            sys.excepthook = excepthook\n\n            raise RuntimeError('Error Outside')\n            \"\"\")\n        with pytest.raises(SystemExit):\n            run_python_file([\"excepthook_exit.py\"])\n        cov_out = self.stdout()\n        assert cov_out == \"in excepthook\\n\"\n\n    def test_excepthook_throw(self) -> None:\n        self.make_file(\"excepthook_throw.py\", \"\"\"\\\n            import sys\n\n            def excepthook(*args):\n                # Write this message to stderr so that we don't have to deal\n                # with interleaved stdout/stderr comparisons in the assertions\n                # in the test.\n                sys.stderr.write('in excepthook\\\\n')\n                raise RuntimeError('Error Inside')\n\n            sys.excepthook = excepthook\n\n            raise RuntimeError('Error Outside')\n            \"\"\")\n        with pytest.raises(_ExceptionDuringRun) as exc_info:\n            run_python_file([\"excepthook_throw.py\"])\n        # The _ExceptionDuringRun exception has the RuntimeError as its argument.\n        assert exc_info.value.args[1].args[0] == \"Error Outside\"\n        stderr = self.stderr()\n        assert \"in excepthook\\n\" in stderr\n        assert \"Error in sys.excepthook:\\n\" in stderr\n        assert \"RuntimeError: Error Inside\" in stderr\n\n\nclass RunPycFileTest(CoverageTest):\n    \"\"\"Test cases for `run_python_file`.\"\"\"\n\n    def make_pyc(self, **kwargs: Any) -> str:\n        \"\"\"Create a .pyc file, and return the path to it.\"\"\"\n        self.make_file(\"compiled.py\", \"\"\"\\\n            def doit():\n                print(\"I am here!\")\n\n            doit()\n            \"\"\")\n        compileall.compile_dir(\".\", quiet=True, **kwargs)\n        os.remove(\"compiled.py\")\n\n        # Find the .pyc file!\n        return str(next(pathlib.Path(\".\").rglob(\"compiled*.pyc\")))\n\n    def test_running_pyc(self) -> None:\n        pycfile = self.make_pyc()\n        run_python_file([pycfile])\n        assert self.stdout() == \"I am here!\\n\"\n\n    def test_running_pyo(self) -> None:\n        pycfile = self.make_pyc()\n        pyofile = re.sub(r\"[.]pyc$\", \".pyo\", pycfile)\n        assert pycfile != pyofile\n        os.rename(pycfile, pyofile)\n        run_python_file([pyofile])\n        assert self.stdout() == \"I am here!\\n\"\n\n    def test_running_pyc_from_wrong_python(self) -> None:\n        pycfile = self.make_pyc()\n\n        # Jam Python 2.1 magic number into the .pyc file.\n        with open(pycfile, \"r+b\") as fpyc:\n            fpyc.seek(0)\n            fpyc.write(bytes([0x2a, 0xeb, 0x0d, 0x0a]))\n\n        with pytest.raises(NoCode, match=\"Bad magic number in .pyc file\"):\n            run_python_file([pycfile])\n\n        # In some environments, the pycfile persists and pollutes another test.\n        os.remove(pycfile)\n\n    def test_running_hashed_pyc(self) -> None:\n        pycfile = self.make_pyc(invalidation_mode=py_compile.PycInvalidationMode.CHECKED_HASH)\n        run_python_file([pycfile])\n        assert self.stdout() == \"I am here!\\n\"\n\n    def test_no_such_pyc_file(self) -> None:\n        path = python_reported_file('xyzzy.pyc')\n        msg = re.escape(f\"No file to run: '{path}'\")\n        with pytest.raises(NoCode, match=msg):\n            run_python_file([\"xyzzy.pyc\"])\n\n    def test_running_py_from_binary(self) -> None:\n        # Use make_file to get the bookkeeping. Ideally, it would\n        # be able to write binary files.\n        bf = self.make_file(\"binary\")\n        with open(bf, \"wb\") as f:\n            f.write(b'\\x7fELF\\x02\\x01\\x01\\x00\\x00\\x00')\n\n        path = python_reported_file('binary')\n        msg = (\n            re.escape(f\"Couldn't run '{path}' as Python code: \") +\n            r\"(ValueError|SyntaxError): source code string cannot contain null bytes\"\n        )\n        with pytest.raises(Exception, match=msg):\n            run_python_file([bf])\n\n\nclass RunModuleTest(UsingModulesMixin, CoverageTest):\n    \"\"\"Test run_python_module.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_runmod1(self) -> None:\n        run_python_module([\"runmod1\", \"hello\"])\n        out, err = self.stdouterr()\n        assert out == \"runmod1: passed hello\\n\"\n        assert err == \"\"\n\n    def test_runmod2(self) -> None:\n        run_python_module([\"pkg1.runmod2\", \"hello\"])\n        out, err = self.stdouterr()\n        assert out == \"pkg1.__init__: pkg1\\nrunmod2: passed hello\\n\"\n        assert err == \"\"\n\n    def test_runmod3(self) -> None:\n        run_python_module([\"pkg1.sub.runmod3\", \"hello\"])\n        out, err = self.stdouterr()\n        assert out == \"pkg1.__init__: pkg1\\nrunmod3: passed hello\\n\"\n        assert err == \"\"\n\n    def test_pkg1_main(self) -> None:\n        run_python_module([\"pkg1\", \"hello\"])\n        out, err = self.stdouterr()\n        assert out == \"pkg1.__init__: pkg1\\npkg1.__main__: passed hello\\n\"\n        assert err == \"\"\n\n    def test_pkg1_sub_main(self) -> None:\n        run_python_module([\"pkg1.sub\", \"hello\"])\n        out, err = self.stdouterr()\n        assert out == \"pkg1.__init__: pkg1\\npkg1.sub.__main__: passed hello\\n\"\n        assert err == \"\"\n\n    def test_pkg1_init(self) -> None:\n        run_python_module([\"pkg1.__init__\", \"wut?\"])\n        out, err = self.stdouterr()\n        assert out == \"pkg1.__init__: pkg1\\npkg1.__init__: __main__\\n\"\n        assert err == \"\"\n\n    def test_no_such_module(self) -> None:\n        with pytest.raises(NoSource, match=\"No module named '?i_dont_exist'?\"):\n            run_python_module([\"i_dont_exist\"])\n        with pytest.raises(NoSource, match=\"No module named '?i'?\"):\n            run_python_module([\"i.dont_exist\"])\n        with pytest.raises(NoSource, match=\"No module named '?i'?\"):\n            run_python_module([\"i.dont.exist\"])\n\n    def test_no_main(self) -> None:\n        with pytest.raises(NoSource):\n            run_python_module([\"pkg2\", \"hi\"])\n", "tests/test_misc.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests of miscellaneous stuff.\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\nfrom unittest import mock\n\nimport pytest\n\nfrom coverage.exceptions import CoverageException\nfrom coverage.misc import file_be_gone\nfrom coverage.misc import Hasher, substitute_variables, import_third_party\nfrom coverage.misc import human_sorted, human_sorted_items, stdout_link\n\nfrom tests.coveragetest import CoverageTest\n\n\nclass HasherTest(CoverageTest):\n    \"\"\"Test our wrapper of fingerprint hashing.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_string_hashing(self) -> None:\n        h1 = Hasher()\n        h1.update(\"Hello, world!\")\n        h2 = Hasher()\n        h2.update(\"Goodbye!\")\n        h3 = Hasher()\n        h3.update(\"Hello, world!\")\n        assert h1.hexdigest() != h2.hexdigest()\n        assert h1.hexdigest() == h3.hexdigest()\n\n    def test_bytes_hashing(self) -> None:\n        h1 = Hasher()\n        h1.update(b\"Hello, world!\")\n        h2 = Hasher()\n        h2.update(b\"Goodbye!\")\n        assert h1.hexdigest() != h2.hexdigest()\n\n    def test_unicode_hashing(self) -> None:\n        h1 = Hasher()\n        h1.update(\"Hello, world! \\N{SNOWMAN}\")\n        h2 = Hasher()\n        h2.update(\"Goodbye!\")\n        assert h1.hexdigest() != h2.hexdigest()\n\n    def test_dict_hashing(self) -> None:\n        h1 = Hasher()\n        h1.update({'a': 17, 'b': 23})\n        h2 = Hasher()\n        h2.update({'b': 23, 'a': 17})\n        assert h1.hexdigest() == h2.hexdigest()\n\n    def test_dict_collision(self) -> None:\n        h1 = Hasher()\n        h1.update({'a': 17, 'b': {'c': 1, 'd': 2}})\n        h2 = Hasher()\n        h2.update({'a': 17, 'b': {'c': 1}, 'd': 2})\n        assert h1.hexdigest() != h2.hexdigest()\n\n\nclass RemoveFileTest(CoverageTest):\n    \"\"\"Tests of misc.file_be_gone.\"\"\"\n\n    def test_remove_nonexistent_file(self) -> None:\n        # It's OK to try to remove a file that doesn't exist.\n        file_be_gone(\"not_here.txt\")\n\n    def test_remove_actual_file(self) -> None:\n        # It really does remove a file that does exist.\n        self.make_file(\"here.txt\", \"We are here, we are here, we are here!\")\n        file_be_gone(\"here.txt\")\n        self.assert_doesnt_exist(\"here.txt\")\n\n    def test_actual_errors(self) -> None:\n        # Errors can still happen.\n        # \". is a directory\" on Unix, or \"Access denied\" on Windows\n        with pytest.raises(OSError):\n            file_be_gone(\".\")\n\n\nVARS = {\n    'FOO': 'fooey',\n    'BAR': 'xyzzy',\n}\n\n@pytest.mark.parametrize(\"before, after\", [\n    (\"Nothing to do\", \"Nothing to do\"),\n    (\"Dollar: $$\", \"Dollar: $\"),\n    (\"Simple: $FOO is fooey\", \"Simple: fooey is fooey\"),\n    (\"Braced: X${FOO}X.\", \"Braced: XfooeyX.\"),\n    (\"Missing: x${NOTHING}y is xy\", \"Missing: xy is xy\"),\n    (\"Multiple: $$ $FOO $BAR ${FOO}\", \"Multiple: $ fooey xyzzy fooey\"),\n    (\"Ill-formed: ${%5} ${{HI}} ${\", \"Ill-formed: ${%5} ${{HI}} ${\"),\n    (\"Strict: ${FOO?} is there\", \"Strict: fooey is there\"),\n    (\"Defaulted: ${WUT-missing}!\", \"Defaulted: missing!\"),\n    (\"Defaulted empty: ${WUT-}!\", \"Defaulted empty: !\"),\n])\ndef test_substitute_variables(before: str, after: str) -> None:\n    assert substitute_variables(before, VARS) == after\n\n@pytest.mark.parametrize(\"text\", [\n    \"Strict: ${NOTHING?} is an error\",\n])\ndef test_substitute_variables_errors(text: str) -> None:\n    with pytest.raises(CoverageException) as exc_info:\n        substitute_variables(text, VARS)\n    assert text in str(exc_info.value)\n    assert \"Variable NOTHING is undefined\" in str(exc_info.value)\n\n\nclass ImportThirdPartyTest(CoverageTest):\n    \"\"\"Test import_third_party.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_success(self) -> None:\n        # Make sure we don't have pytest in sys.modules before we start.\n        del sys.modules[\"pytest\"]\n        # Import pytest\n        mod, has = import_third_party(\"pytest\")\n        assert has\n        # Yes, it's really pytest:\n        assert mod.__name__ == \"pytest\"\n        print(dir(mod))\n        assert all(hasattr(mod, name) for name in [\"skip\", \"mark\", \"raises\", \"warns\"])\n        # But it's not in sys.modules:\n        assert \"pytest\" not in sys.modules\n\n    def test_failure(self) -> None:\n        _, has = import_third_party(\"xyzzy\")\n        assert not has\n        assert \"xyzzy\" not in sys.modules\n\n\nHUMAN_DATA = [\n    (\"z1 a2z a01 a2a a3 a1\", \"a01 a1 a2a a2z a3 z1\"),\n    (\"a10 a9 a100 a1\", \"a1 a9 a10 a100\"),\n    (\"4.0 3.10-win 3.10-mac 3.9-mac 3.9-win\", \"3.9-mac 3.9-win 3.10-mac 3.10-win 4.0\"),\n]\n\n@pytest.mark.parametrize(\"words, ordered\", HUMAN_DATA)\ndef test_human_sorted(words: str, ordered: str) -> None:\n    assert \" \".join(human_sorted(words.split())) == ordered\n\n@pytest.mark.parametrize(\"words, ordered\", HUMAN_DATA)\ndef test_human_sorted_items(words: str, ordered: str) -> None:\n    keys = words.split()\n    # Check that we never try to compare the values in the items\n    human_sorted_items([(k, object()) for k in keys])\n    items = [(k, 1) for k in keys] + [(k, 2) for k in keys]\n    okeys = ordered.split()\n    oitems = [(k, v) for k in okeys for v in [1, 2]]\n    assert human_sorted_items(items) == oitems\n    assert human_sorted_items(items, reverse=True) == oitems[::-1]\n\n\ndef test_stdout_link_tty() -> None:\n    with mock.patch.object(sys.stdout, \"isatty\", lambda:True):\n        link = stdout_link(\"some text\", \"some url\")\n    assert link == \"\\033]8;;some url\\asome text\\033]8;;\\a\"\n\n\ndef test_stdout_link_not_tty() -> None:\n    # Without mocking isatty, it reports False in a pytest suite.\n    assert stdout_link(\"some text\", \"some url\") == \"some text\"\n\n\ndef test_stdout_link_with_fake_stdout() -> None:\n    # If stdout is another object, we should still be ok.\n    with mock.patch.object(sys, \"stdout\", object()):\n        link = stdout_link(\"some text\", \"some url\")\n    assert link == \"some text\"\n", "tests/testenv.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Environment settings affecting tests.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\n\n# Are we testing the C-implemented trace function?\nC_TRACER = os.getenv(\"COVERAGE_CORE\", \"ctrace\") == \"ctrace\"\n\n# Are we testing the Python-implemented trace function?\nPY_TRACER = os.getenv(\"COVERAGE_CORE\", \"ctrace\") == \"pytrace\"\n\n# Are we testing the sys.monitoring implementation?\nSYS_MON = os.getenv(\"COVERAGE_CORE\", \"ctrace\") == \"sysmon\"\n\n# Are we using a settrace function as a core?\nSETTRACE_CORE = C_TRACER or PY_TRACER\n\n# Are plugins supported during these tests?\nPLUGINS = C_TRACER\n\n# Are dynamic contexts supported during these tests?\nDYN_CONTEXTS = C_TRACER or PY_TRACER\n", "tests/test_cmdline.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Test cmdline.py for coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport ast\nimport os\nimport pprint\nimport re\nimport sys\nimport textwrap\n\nfrom unittest import mock\nfrom typing import Any, Mapping\n\nimport pytest\n\nimport coverage\nimport coverage.cmdline\nfrom coverage.control import DEFAULT_DATAFILE\nfrom coverage.config import CoverageConfig\nfrom coverage.exceptions import _ExceptionDuringRun\nfrom coverage.types import TConfigValueIn, TConfigValueOut\nfrom coverage.version import __url__\n\nfrom tests import testenv\nfrom tests.coveragetest import CoverageTest, OK, ERR, command_line\nfrom tests.helpers import os_sep, re_line\n\n\nclass BaseCmdLineTest(CoverageTest):\n    \"\"\"Tests of execution paths through the command line interpreter.\"\"\"\n\n    run_in_temp_dir = False\n\n    # Make a dict mapping function names to the default values that cmdline.py\n    # uses when calling the function.\n    _defaults = mock.Mock()\n    _defaults.Coverage().annotate(\n        directory=None, ignore_errors=None, include=None, omit=None, morfs=[],\n        contexts=None,\n    )\n    _defaults.Coverage().html_report(\n        directory=None, ignore_errors=None, include=None, omit=None, morfs=[],\n        skip_covered=None, show_contexts=None, title=None, contexts=None,\n        skip_empty=None, precision=None,\n    )\n    _defaults.Coverage().report(\n        ignore_errors=None, include=None, omit=None, morfs=[],\n        show_missing=None, skip_covered=None, contexts=None, skip_empty=None,\n        precision=None, sort=None, output_format=None,\n    )\n    _defaults.Coverage().xml_report(\n        ignore_errors=None, include=None, omit=None, morfs=[], outfile=None,\n        contexts=None, skip_empty=None,\n    )\n    _defaults.Coverage().json_report(\n        ignore_errors=None, include=None, omit=None, morfs=[], outfile=None,\n        contexts=None, pretty_print=None, show_contexts=None,\n    )\n    _defaults.Coverage().lcov_report(\n        ignore_errors=None, include=None, omit=None, morfs=[], outfile=None,\n        contexts=None,\n    )\n    _defaults.Coverage(\n        data_file=DEFAULT_DATAFILE,\n        cover_pylib=None, data_suffix=None, timid=None, branch=None,\n        config_file=True, source=None, include=None, omit=None, debug=None,\n        concurrency=None, check_preimported=True, context=None, messages=True,\n    )\n\n    DEFAULT_KWARGS = {name: kw for name, _, kw in _defaults.mock_calls}\n\n    def model_object(self) -> mock.Mock:\n        \"\"\"Return a Mock suitable for use in CoverageScript.\"\"\"\n        mk = mock.Mock()\n\n        cov = mk.Coverage.return_value\n\n        # The mock needs options.\n        mk.config = CoverageConfig()\n        cov.get_option = mk.config.get_option\n        cov.set_option = mk.config.set_option\n\n        # Get the type right for the result of reporting.\n        cov.report.return_value = 50.0\n        cov.html_report.return_value = 50.0\n        cov.xml_report.return_value = 50.0\n        cov.json_report.return_value = 50.0\n        cov.lcov_report.return_value = 50.0\n\n        return mk\n\n    # Global names in cmdline.py that will be mocked during the tests.\n    MOCK_GLOBALS = ['Coverage', 'PyRunner', 'show_help']\n\n    def mock_command_line(\n        self,\n        args: str,\n        options: Mapping[str, TConfigValueIn] | None = None,\n    ) -> tuple[mock.Mock, int]:\n        \"\"\"Run `args` through the command line, with a Mock.\n\n        `options` is a dict of names and values to pass to `set_option`.\n\n        Returns the Mock it used and the status code returned.\n\n        \"\"\"\n        mk = self.model_object()\n\n        if options is not None:\n            for name, value in options.items():\n                mk.config.set_option(name, value)\n\n        patchers = [\n            mock.patch(\"coverage.cmdline.\"+name, getattr(mk, name))\n            for name in self.MOCK_GLOBALS\n        ]\n        for patcher in patchers:\n            patcher.start()\n        try:\n            ret = command_line(args)\n        finally:\n            for patcher in patchers:\n                patcher.stop()\n\n        return mk, ret\n\n    def cmd_executes(\n        self,\n        args: str,\n        code: str,\n        ret: int = OK,\n        options: Mapping[str, TConfigValueIn] | None = None,\n    ) -> None:\n        \"\"\"Assert that the `args` end up executing the sequence in `code`.\"\"\"\n        called, status = self.mock_command_line(args, options=options)\n        assert status == ret, f\"Wrong status: got {status!r}, wanted {ret!r}\"\n\n        # Remove all indentation, and execute with mock globals\n        code = textwrap.dedent(code)\n        expected = self.model_object()\n        globs = {n: getattr(expected, n) for n in self.MOCK_GLOBALS}\n        code_obj = compile(code, \"<code>\", \"exec\", dont_inherit=True)\n        eval(code_obj, globs, {})                           # pylint: disable=eval-used\n\n        # Many of our functions take a lot of arguments, and cmdline.py\n        # calls them with many.  But most of them are just the defaults, which\n        # we don't want to have to repeat in all tests.  For each call, apply\n        # the defaults.  This lets the tests just mention the interesting ones.\n        for name, _, kwargs in expected.mock_calls:\n            for k, v in self.DEFAULT_KWARGS.get(name, {}).items():\n                kwargs.setdefault(k, v)\n\n        self.assert_same_mock_calls(expected, called)\n\n    def cmd_executes_same(self, args1: str, args2: str) -> None:\n        \"\"\"Assert that the `args1` executes the same as `args2`.\"\"\"\n        m1, r1 = self.mock_command_line(args1)\n        m2, r2 = self.mock_command_line(args2)\n        assert r1 == r2\n        self.assert_same_mock_calls(m1, m2)\n\n    def assert_same_mock_calls(self, m1: mock.Mock, m2: mock.Mock) -> None:\n        \"\"\"Assert that `m1.mock_calls` and `m2.mock_calls` are the same.\"\"\"\n        # Use a real equality comparison, but if it fails, use a nicer assert\n        # so we can tell what's going on.  We have to use the real == first due\n        # to CmdOptionParser.__eq__\n        if m1.mock_calls != m2.mock_calls:\n            pp1 = pprint.pformat(m1.mock_calls)\n            pp2 = pprint.pformat(m2.mock_calls)\n            assert pp1+'\\n' == pp2+'\\n'\n\n    def cmd_help(\n        self,\n        args: str,\n        help_msg: str | None = None,\n        topic: str | None = None,\n        ret: int = ERR,\n    ) -> None:\n        \"\"\"Run a command line, and check that it prints the right help.\n\n        Only the last function call in the mock is checked, which should be the\n        help message that we want to see.\n\n        \"\"\"\n        mk, status = self.mock_command_line(args)\n        assert status == ret, f\"Wrong status: got {status}, wanted {ret}\"\n        if help_msg:\n            assert mk.mock_calls[-1] == ('show_help', (help_msg,), {})\n        else:\n            assert mk.mock_calls[-1] == ('show_help', (), {'topic': topic})\n\n\nclass BaseCmdLineTestTest(BaseCmdLineTest):\n    \"\"\"Tests that our BaseCmdLineTest helpers work.\"\"\"\n    def test_cmd_executes_same(self) -> None:\n        # All the other tests here use self.cmd_executes_same in successful\n        # ways, so here we just check that it fails.\n        with pytest.raises(AssertionError):\n            self.cmd_executes_same(\"run\", \"debug\")\n\n\nclass CmdLineTest(BaseCmdLineTest):\n    \"\"\"Tests of the coverage.py command line.\"\"\"\n\n    def test_annotate(self) -> None:\n        # coverage annotate [-d DIR] [-i] [--omit DIR,...] [FILE1 FILE2 ...]\n        self.cmd_executes(\"annotate\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.annotate()\n            \"\"\")\n        self.cmd_executes(\"annotate -d dir1\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.annotate(directory=\"dir1\")\n            \"\"\")\n        self.cmd_executes(\"annotate -i\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.annotate(ignore_errors=True)\n            \"\"\")\n        self.cmd_executes(\"annotate --omit fooey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\"])\n            cov.load()\n            cov.annotate(omit=[\"fooey\"])\n            \"\"\")\n        self.cmd_executes(\"annotate --omit fooey,booey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\", \"booey\"])\n            cov.load()\n            cov.annotate(omit=[\"fooey\", \"booey\"])\n            \"\"\")\n        self.cmd_executes(\"annotate mod1\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.annotate(morfs=[\"mod1\"])\n            \"\"\")\n        self.cmd_executes(\"annotate mod1 mod2 mod3\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.annotate(morfs=[\"mod1\", \"mod2\", \"mod3\"])\n            \"\"\")\n\n    def test_combine(self) -> None:\n        # coverage combine with args\n        self.cmd_executes(\"combine datadir1\", \"\"\"\\\n            cov = Coverage()\n            cov.combine([\"datadir1\"], strict=True, keep=False)\n            cov.save()\n            \"\"\")\n        # coverage combine, appending\n        self.cmd_executes(\"combine --append datadir1\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.combine([\"datadir1\"], strict=True, keep=False)\n            cov.save()\n            \"\"\")\n        # coverage combine without args\n        self.cmd_executes(\"combine\", \"\"\"\\\n            cov = Coverage()\n            cov.combine(None, strict=True, keep=False)\n            cov.save()\n            \"\"\")\n        # coverage combine quietly\n        self.cmd_executes(\"combine -q\", \"\"\"\\\n            cov = Coverage(messages=False)\n            cov.combine(None, strict=True, keep=False)\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"combine --quiet\", \"\"\"\\\n            cov = Coverage(messages=False)\n            cov.combine(None, strict=True, keep=False)\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"combine --data-file=foo.cov\", \"\"\"\\\n            cov = Coverage(data_file=\"foo.cov\")\n            cov.combine(None, strict=True, keep=False)\n            cov.save()\n            \"\"\")\n\n    def test_combine_doesnt_confuse_options_with_args(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/385\n        self.cmd_executes(\"combine --rcfile cov.ini\", \"\"\"\\\n            cov = Coverage(config_file='cov.ini')\n            cov.combine(None, strict=True, keep=False)\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"combine --rcfile cov.ini data1 data2/more\", \"\"\"\\\n            cov = Coverage(config_file='cov.ini')\n            cov.combine([\"data1\", \"data2/more\"], strict=True, keep=False)\n            cov.save()\n            \"\"\")\n\n    @pytest.mark.parametrize(\"cmd, output\", [\n        (\"debug\", \"What information would you like: config, data, sys, premain, pybehave?\"),\n        (\"debug foo\", \"Don't know what you mean by 'foo'\"),\n        (\"debug sys config\", \"Only one topic at a time, please\"),\n    ])\n    def test_debug(self, cmd: str, output: str) -> None:\n        self.cmd_help(cmd, output)\n\n    def test_debug_sys(self) -> None:\n        self.command_line(\"debug sys\")\n        out = self.stdout()\n        assert \"version:\" in out\n        assert \"data_file:\" in out\n\n    def test_debug_config(self) -> None:\n        self.command_line(\"debug config\")\n        out = self.stdout()\n        assert \"cover_pylib:\" in out\n        assert \"skip_covered:\" in out\n        assert \"skip_empty:\" in out\n\n    def test_debug_pybehave(self) -> None:\n        self.command_line(\"debug pybehave\")\n        out = self.stdout()\n        assert \" CPYTHON:\" in out\n        assert \" PYVERSION:\" in out\n        assert \" pep626:\" in out\n\n        # Some things that shouldn't appear..\n        assert \"typing.\" not in out     # import from typing\n        assert \": <\" not in out         # objects without a good repr\n\n        # It should report PYVERSION correctly.\n        pyversion = re_line(r\" PYVERSION:\", out)\n        vtuple = ast.literal_eval(pyversion.partition(\":\")[-1].strip())\n        assert vtuple[:5] == sys.version_info\n\n    def test_debug_premain(self) -> None:\n        self.command_line(\"debug premain\")\n        out = self.stdout()\n        # -- premain ---------------------------------------------------\n        #   ... many lines ...\n        #           _multicall : /Users/ned/cov/trunk/.tox/py39/site-packages/pluggy/_callers.py:77\n        #   pytest_pyfunc_call : /Users/ned/cov/trunk/.tox/py39/site-packages/_pytest/python.py:183\n        #   test_debug_premain : /Users/ned/cov/trunk/tests/test_cmdline.py:284\n        #         command_line : /Users/ned/cov/trunk/tests/coveragetest.py:309\n        #         command_line : /Users/ned/cov/trunk/tests/coveragetest.py:472\n        #         command_line : /Users/ned/cov/trunk/coverage/cmdline.py:592\n        #             do_debug : /Users/ned/cov/trunk/coverage/cmdline.py:804\n        lines = out.splitlines()\n        s = re.escape(os.sep)\n        assert lines[0].startswith(\"-- premain ----\")\n        assert len(lines) > 25\n        assert re.search(fr\"{s}site-packages{s}_pytest{s}\", out)\n        assert re.search(fr\"{s}site-packages{s}pluggy{s}\", out)\n        assert re.search(fr\"(?m)^\\s+test_debug_premain : .*{s}tests{s}test_cmdline.py:\\d+$\", out)\n        assert re.search(fr\"(?m)^\\s+command_line : .*{s}coverage{s}cmdline.py:\\d+$\", out)\n        assert re.search(fr\"(?m)^\\s+do_debug : .*{s}coverage{s}cmdline.py:\\d+$\", out)\n        assert \"do_debug : \" in lines[-1]\n\n    def test_erase(self) -> None:\n        # coverage erase\n        self.cmd_executes(\"erase\", \"\"\"\\\n            cov = Coverage()\n            cov.erase()\n            \"\"\")\n        self.cmd_executes(\"erase --data-file=foo.cov\", \"\"\"\\\n            cov = Coverage(data_file=\"foo.cov\")\n            cov.erase()\n            \"\"\")\n\n    def test_version(self) -> None:\n        # coverage --version\n        self.cmd_help(\"--version\", topic=\"version\", ret=OK)\n\n    def test_help_option(self) -> None:\n        # coverage -h\n        self.cmd_help(\"-h\", topic=\"help\", ret=OK)\n        self.cmd_help(\"--help\", topic=\"help\", ret=OK)\n\n    def test_help_command(self) -> None:\n        self.cmd_executes(\"help\", \"show_help(topic='help')\")\n\n    def test_cmd_help(self) -> None:\n        self.cmd_executes(\"run --help\", \"show_help(parser='<CmdOptionParser:run>')\")\n        self.cmd_executes_same(\"help run\", \"run --help\")\n\n    def test_html(self) -> None:\n        # coverage html -d DIR [-i] [--omit DIR,...] [FILE1 FILE2 ...]\n        self.cmd_executes(\"html\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.html_report()\n            \"\"\")\n        self.cmd_executes(\"html -d dir1\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.html_report(directory=\"dir1\")\n            \"\"\")\n        self.cmd_executes(\"html -i\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.html_report(ignore_errors=True)\n            \"\"\")\n        self.cmd_executes(\"html --omit fooey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\"])\n            cov.load()\n            cov.html_report(omit=[\"fooey\"])\n            \"\"\")\n        self.cmd_executes(\"html --omit fooey,booey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\", \"booey\"])\n            cov.load()\n            cov.html_report(omit=[\"fooey\", \"booey\"])\n            \"\"\")\n        self.cmd_executes(\"html mod1\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.html_report(morfs=[\"mod1\"])\n            \"\"\")\n        self.cmd_executes(\"html mod1 mod2 mod3\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.html_report(morfs=[\"mod1\", \"mod2\", \"mod3\"])\n            \"\"\")\n        self.cmd_executes(\"html --precision=3\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.html_report(precision=3)\n            \"\"\")\n        self.cmd_executes(\"html --title=Hello_there\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.html_report(title='Hello_there')\n            \"\"\")\n        self.cmd_executes(\"html -q\", \"\"\"\\\n            cov = Coverage(messages=False)\n            cov.load()\n            cov.html_report()\n            \"\"\")\n        self.cmd_executes(\"html --quiet\", \"\"\"\\\n            cov = Coverage(messages=False)\n            cov.load()\n            cov.html_report()\n            \"\"\")\n\n    def test_json(self) -> None:\n        # coverage json [-i] [--omit DIR,...] [FILE1 FILE2 ...]\n        self.cmd_executes(\"json\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.json_report()\n            \"\"\")\n        self.cmd_executes(\"json --pretty-print\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.json_report(pretty_print=True)\n            \"\"\")\n        self.cmd_executes(\"json --pretty-print --show-contexts\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.json_report(pretty_print=True, show_contexts=True)\n            \"\"\")\n        self.cmd_executes(\"json -i\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.json_report(ignore_errors=True)\n            \"\"\")\n        self.cmd_executes(\"json -o myjson.foo\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.json_report(outfile=\"myjson.foo\")\n            \"\"\")\n        self.cmd_executes(\"json -o -\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.json_report(outfile=\"-\")\n            \"\"\")\n        self.cmd_executes(\"json --omit fooey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\"])\n            cov.load()\n            cov.json_report(omit=[\"fooey\"])\n            \"\"\")\n        self.cmd_executes(\"json --omit fooey,booey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\", \"booey\"])\n            cov.load()\n            cov.json_report(omit=[\"fooey\", \"booey\"])\n            \"\"\")\n        self.cmd_executes(\"json mod1\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.json_report(morfs=[\"mod1\"])\n            \"\"\")\n        self.cmd_executes(\"json mod1 mod2 mod3\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.json_report(morfs=[\"mod1\", \"mod2\", \"mod3\"])\n            \"\"\")\n        self.cmd_executes(\"json -q\", \"\"\"\\\n            cov = Coverage(messages=False)\n            cov.load()\n            cov.json_report()\n            \"\"\")\n        self.cmd_executes(\"json --quiet\", \"\"\"\\\n            cov = Coverage(messages=False)\n            cov.load()\n            cov.json_report()\n            \"\"\")\n\n    def test_lcov(self) -> None:\n        # coverage lcov [-i] [--omit DIR,...] [FILE1 FILE2 ...]\n        self.cmd_executes(\"lcov\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.lcov_report()\n            \"\"\")\n        self.cmd_executes(\"lcov -i\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.lcov_report(ignore_errors=True)\n            \"\"\")\n        self.cmd_executes(\"lcov -o mylcov.foo\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.lcov_report(outfile=\"mylcov.foo\")\n            \"\"\")\n        self.cmd_executes(\"lcov -o -\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.lcov_report(outfile=\"-\")\n            \"\"\")\n        self.cmd_executes(\"lcov --omit fooey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\"])\n            cov.load()\n            cov.lcov_report(omit=[\"fooey\"])\n            \"\"\")\n        self.cmd_executes(\"lcov --omit fooey,booey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\", \"booey\"])\n            cov.load()\n            cov.lcov_report(omit=[\"fooey\", \"booey\"])\n            \"\"\")\n        self.cmd_executes(\"lcov -q\", \"\"\"\\\n            cov = Coverage(messages=False)\n            cov.load()\n            cov.lcov_report()\n            \"\"\")\n        self.cmd_executes(\"lcov --quiet\", \"\"\"\\\n            cov = Coverage(messages=False)\n            cov.load()\n            cov.lcov_report()\n            \"\"\")\n\n    def test_report(self) -> None:\n        # coverage report [-m] [-i] [-o DIR,...] [FILE1 FILE2 ...]\n        self.cmd_executes(\"report\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(show_missing=None)\n            \"\"\")\n        self.cmd_executes(\"report -i\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(ignore_errors=True)\n            \"\"\")\n        self.cmd_executes(\"report -m\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(show_missing=True)\n            \"\"\")\n        self.cmd_executes(\"report --omit fooey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\"])\n            cov.load()\n            cov.report(omit=[\"fooey\"])\n            \"\"\")\n        self.cmd_executes(\"report --omit fooey,booey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\", \"booey\"])\n            cov.load()\n            cov.report(omit=[\"fooey\", \"booey\"])\n            \"\"\")\n        self.cmd_executes(\"report mod1\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(morfs=[\"mod1\"])\n            \"\"\")\n        self.cmd_executes(\"report mod1 mod2 mod3\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(morfs=[\"mod1\", \"mod2\", \"mod3\"])\n            \"\"\")\n        self.cmd_executes(\"report --precision=7\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(precision=7)\n            \"\"\")\n        self.cmd_executes(\"report --skip-covered\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(skip_covered=True)\n            \"\"\")\n        self.cmd_executes(\"report --skip-covered --no-skip-covered\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(skip_covered=False)\n            \"\"\")\n        self.cmd_executes(\"report --no-skip-covered\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(skip_covered=False)\n            \"\"\")\n        self.cmd_executes(\"report --skip-empty\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(skip_empty=True)\n            \"\"\")\n        self.cmd_executes(\"report --contexts=foo,bar\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(contexts=[\"foo\", \"bar\"])\n            \"\"\")\n        self.cmd_executes(\"report --sort=-foo\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(sort='-foo')\n            \"\"\")\n        self.cmd_executes(\"report --data-file=foo.cov.2\", \"\"\"\\\n            cov = Coverage(data_file=\"foo.cov.2\")\n            cov.load()\n            cov.report(show_missing=None)\n            \"\"\")\n        self.cmd_executes(\"report --format=markdown\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.report(output_format=\"markdown\")\n            \"\"\")\n\n    def test_run(self) -> None:\n        # coverage run [-p] [-L] [--timid] MODULE.py [ARG1 ARG2 ...]\n\n        # run calls coverage.erase first.\n        self.cmd_executes(\"run foo.py\", \"\"\"\\\n            cov = Coverage()\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        # run -a combines with an existing data file before saving.\n        self.cmd_executes(\"run -a foo.py\", \"\"\"\\\n            cov = Coverage()\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.load()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        # --timid sets a flag, and program arguments get passed through.\n        self.cmd_executes(\"run --timid foo.py abc 123\", \"\"\"\\\n            cov = Coverage(timid=True)\n            runner = PyRunner(['foo.py', 'abc', '123'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        # -L sets a flag, and flags for the program don't confuse us.\n        self.cmd_executes(\"run -p -L foo.py -a -b\", \"\"\"\\\n            cov = Coverage(cover_pylib=True, data_suffix=True)\n            runner = PyRunner(['foo.py', '-a', '-b'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --branch foo.py\", \"\"\"\\\n            cov = Coverage(branch=True)\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --rcfile=myrc.rc foo.py\", \"\"\"\\\n            cov = Coverage(config_file=\"myrc.rc\")\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --include=pre1,pre2 foo.py\", \"\"\"\\\n            cov = Coverage(include=[\"pre1\", \"pre2\"])\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --omit=opre1,opre2 foo.py\", \"\"\"\\\n            cov = Coverage(omit=[\"opre1\", \"opre2\"])\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --include=pre1,pre2 --omit=opre1,opre2 foo.py\", \"\"\"\\\n            cov = Coverage(include=[\"pre1\", \"pre2\"], omit=[\"opre1\", \"opre2\"])\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --source=quux,hi.there,/home/bar foo.py\", \"\"\"\\\n            cov = Coverage(source=[\"quux\", \"hi.there\", \"/home/bar\"])\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --concurrency=gevent foo.py\", \"\"\"\\\n            cov = Coverage(concurrency=['gevent'])\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --concurrency=multiprocessing foo.py\", \"\"\"\\\n            cov = Coverage(concurrency=['multiprocessing'])\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --concurrency=gevent,thread foo.py\", \"\"\"\\\n            cov = Coverage(concurrency=['gevent', 'thread'])\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --data-file=output.coverage foo.py\", \"\"\"\\\n            cov = Coverage(data_file=\"output.coverage\")\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n\n    def test_multiprocessing_needs_config_file(self) -> None:\n        # You can't use command-line args to add options to multiprocessing\n        # runs, since they won't make it to the subprocesses. You need to use a\n        # config file.\n        self.command_line(\"run --concurrency=multiprocessing --branch foo.py\", ret=ERR)\n        msg = \"Options affecting multiprocessing must only be specified in a configuration file.\"\n        _, err = self.stdouterr()\n        assert msg in err\n        assert \"Remove --branch from the command line.\" in err\n\n    def test_run_debug(self) -> None:\n        self.cmd_executes(\"run --debug=opt1 foo.py\", \"\"\"\\\n            cov = Coverage(debug=[\"opt1\"])\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --debug=opt1,opt2 foo.py\", \"\"\"\\\n            cov = Coverage(debug=[\"opt1\",\"opt2\"])\n            runner = PyRunner(['foo.py'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n\n    def test_run_module(self) -> None:\n        self.cmd_executes(\"run -m mymodule\", \"\"\"\\\n            cov = Coverage()\n            runner = PyRunner(['mymodule'], as_module=True)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run -m mymodule -qq arg1 arg2\", \"\"\"\\\n            cov = Coverage()\n            runner = PyRunner(['mymodule', '-qq', 'arg1', 'arg2'], as_module=True)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes(\"run --branch -m mymodule\", \"\"\"\\\n            cov = Coverage(branch=True)\n            runner = PyRunner(['mymodule'], as_module=True)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\")\n        self.cmd_executes_same(\"run -m mymodule\", \"run --module mymodule\")\n\n    def test_run_nothing(self) -> None:\n        self.command_line(\"run\", ret=ERR)\n        assert \"Nothing to do\" in self.stderr()\n\n    def test_run_from_config(self) -> None:\n        options = {\"run:command_line\": \"myprog.py a 123 'a quoted thing' xyz\"}\n        self.cmd_executes(\"run\", \"\"\"\\\n            cov = Coverage()\n            runner = PyRunner(['myprog.py', 'a', '123', 'a quoted thing', 'xyz'], as_module=False)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\",\n            options=options,\n        )\n\n    def test_run_module_from_config(self) -> None:\n        self.cmd_executes(\"run\", \"\"\"\\\n            cov = Coverage()\n            runner = PyRunner(['mymodule', 'thing1', 'thing2'], as_module=True)\n            runner.prepare()\n            cov.start()\n            runner.run()\n            cov.stop()\n            cov.save()\n            \"\"\",\n            options={\"run:command_line\": \"-m mymodule thing1 thing2\"},\n        )\n\n    def test_run_from_config_but_empty(self) -> None:\n        self.cmd_executes(\"run\", \"\"\"\\\n            cov = Coverage()\n            show_help('Nothing to do.')\n            \"\"\",\n            ret=ERR,\n            options={\"run:command_line\": \"\"},\n        )\n\n    def test_run_dashm_only(self) -> None:\n        self.cmd_executes(\"run -m\", \"\"\"\\\n            cov = Coverage()\n            show_help('No module specified for -m')\n            \"\"\",\n            ret=ERR,\n        )\n        self.cmd_executes(\"run -m\", \"\"\"\\\n            cov = Coverage()\n            show_help('No module specified for -m')\n            \"\"\",\n            ret=ERR,\n            options={\"run:command_line\": \"myprog.py\"},\n        )\n\n    def test_cant_append_parallel(self) -> None:\n        self.command_line(\"run --append --parallel-mode foo.py\", ret=ERR)\n        assert \"Can't append to data files in parallel mode.\" in self.stderr()\n\n    def test_xml(self) -> None:\n        # coverage xml [-i] [--omit DIR,...] [FILE1 FILE2 ...]\n        self.cmd_executes(\"xml\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.xml_report()\n            \"\"\")\n        self.cmd_executes(\"xml -i\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.xml_report(ignore_errors=True)\n            \"\"\")\n        self.cmd_executes(\"xml -o myxml.foo\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.xml_report(outfile=\"myxml.foo\")\n            \"\"\")\n        self.cmd_executes(\"xml -o -\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.xml_report(outfile=\"-\")\n            \"\"\")\n        self.cmd_executes(\"xml --omit fooey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\"])\n            cov.load()\n            cov.xml_report(omit=[\"fooey\"])\n            \"\"\")\n        self.cmd_executes(\"xml --omit fooey,booey\", \"\"\"\\\n            cov = Coverage(omit=[\"fooey\", \"booey\"])\n            cov.load()\n            cov.xml_report(omit=[\"fooey\", \"booey\"])\n            \"\"\")\n        self.cmd_executes(\"xml mod1\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.xml_report(morfs=[\"mod1\"])\n            \"\"\")\n        self.cmd_executes(\"xml mod1 mod2 mod3\", \"\"\"\\\n            cov = Coverage()\n            cov.load()\n            cov.xml_report(morfs=[\"mod1\", \"mod2\", \"mod3\"])\n            \"\"\")\n        self.cmd_executes(\"xml -q\", \"\"\"\\\n            cov = Coverage(messages=False)\n            cov.load()\n            cov.xml_report()\n            \"\"\")\n        self.cmd_executes(\"xml --quiet\", \"\"\"\\\n            cov = Coverage(messages=False)\n            cov.load()\n            cov.xml_report()\n            \"\"\")\n\n    def test_no_arguments_at_all(self) -> None:\n        self.cmd_help(\"\", topic=\"minimum_help\", ret=OK)\n\n    def test_bad_command(self) -> None:\n        self.cmd_help(\"xyzzy\", \"Unknown command: 'xyzzy'\")\n\n\nclass CmdLineWithFilesTest(BaseCmdLineTest):\n    \"\"\"Test the command line in ways that need temp files.\"\"\"\n\n    run_in_temp_dir = True\n\n    def test_debug_data(self) -> None:\n        data = self.make_data_file(\n            lines={\n                \"file1.py\": range(1, 18),\n                \"file2.py\": range(1, 24),\n            },\n            file_tracers={\"file1.py\": \"a_plugin\"},\n        )\n\n        self.command_line(\"debug data\")\n        assert self.stdout() == textwrap.dedent(f\"\"\"\\\n            -- data ------------------------------------------------------\n            path: {data.data_filename()}\n            has_arcs: False\n            2 files:\n            file1.py: 17 lines [a_plugin]\n            file2.py: 23 lines\n            \"\"\")\n\n    def test_debug_data_with_no_data_file(self) -> None:\n        data = self.make_data_file()\n        self.command_line(\"debug data\")\n        assert self.stdout() == textwrap.dedent(f\"\"\"\\\n            -- data ------------------------------------------------------\n            path: {data.data_filename()}\n            No data collected: file doesn't exist\n            \"\"\")\n\n    def test_debug_combinable_data(self) -> None:\n        data1 = self.make_data_file(lines={\"file1.py\": range(1, 18), \"file2.py\": [1]})\n        data2 = self.make_data_file(suffix=\"123\", lines={\"file2.py\": range(1, 10)})\n\n        self.command_line(\"debug data\")\n        assert self.stdout() == textwrap.dedent(f\"\"\"\\\n            -- data ------------------------------------------------------\n            path: {data1.data_filename()}\n            has_arcs: False\n            2 files:\n            file1.py: 17 lines\n            file2.py: 1 line\n            -----\n            path: {data2.data_filename()}\n            has_arcs: False\n            1 file:\n            file2.py: 9 lines\n            \"\"\")\n\n\nclass CmdLineStdoutTest(BaseCmdLineTest):\n    \"\"\"Test the command line with real stdout output.\"\"\"\n\n    def test_minimum_help(self) -> None:\n        self.command_line(\"\")\n        out = self.stdout()\n        assert \"Code coverage for Python\" in out\n        assert out.count(\"\\n\") < 4\n\n    def test_version(self) -> None:\n        self.command_line(\"--version\")\n        out = self.stdout()\n        assert \"ersion \" in out\n        if testenv.C_TRACER or testenv.SYS_MON:\n            assert \"with C extension\" in out\n        else:\n            assert \"without C extension\" in out\n        assert out.count(\"\\n\") < 4\n\n    def test_help_contains_command_name(self) -> None:\n        # Command name should be present in help output.\n        fake_command_path = os_sep(\"lorem/ipsum/dolor\")\n        expected_command_name = \"dolor\"\n        fake_argv = [fake_command_path, \"sit\", \"amet\"]\n        with mock.patch.object(sys, 'argv', new=fake_argv):\n            self.command_line(\"help\")\n        out = self.stdout()\n        assert expected_command_name in out\n\n    def test_help_contains_command_name_from_package(self) -> None:\n        # Command package name should be present in help output.\n        #\n        # When the main module is actually a package's `__main__` module, the resulting command line\n        # has the `__main__.py` file's patch as the command name. Instead, the command name should\n        # be derived from the package name.\n\n        fake_command_path = os_sep(\"lorem/ipsum/dolor/__main__.py\")\n        expected_command_name = \"dolor\"\n        fake_argv = [fake_command_path, \"sit\", \"amet\"]\n        with mock.patch.object(sys, 'argv', new=fake_argv):\n            self.command_line(\"help\")\n        out = self.stdout()\n        assert expected_command_name in out\n\n    def test_help(self) -> None:\n        self.command_line(\"help\")\n        lines = self.stdout().splitlines()\n        assert len(lines) > 10\n        assert lines[-1] == f\"Full documentation is at {__url__}\"\n\n    def test_cmd_help(self) -> None:\n        self.command_line(\"help run\")\n        out = self.stdout()\n        lines = out.splitlines()\n        assert \"<pyfile>\" in lines[0]\n        assert \"--timid\" in out\n        assert len(lines) > 20\n        assert lines[-1] == f\"Full documentation is at {__url__}\"\n\n    def test_unknown_topic(self) -> None:\n        # Should probably be an ERR return, but meh.\n        self.command_line(\"help foobar\")\n        lines = self.stdout().splitlines()\n        assert lines[0] == \"Don't know topic 'foobar'\"\n        assert lines[-1] == f\"Full documentation is at {__url__}\"\n\n    def test_error(self) -> None:\n        self.command_line(\"fooey kablooey\", ret=ERR)\n        err = self.stderr()\n        assert \"fooey\" in err\n        assert \"help\" in err\n\n    def test_option_error(self) -> None:\n        self.command_line(\"run --fooey\", ret=ERR)\n        err = self.stderr()\n        assert \"fooey\" in err\n        assert \"help\" in err\n\n    def test_doc_url(self) -> None:\n        assert __url__.startswith(\"https://coverage.readthedocs.io\")\n\n\nclass CmdMainTest(CoverageTest):\n    \"\"\"Tests of coverage.cmdline.main(), using mocking for isolation.\"\"\"\n\n    run_in_temp_dir = False\n\n    class CoverageScriptStub:\n        \"\"\"A stub for coverage.cmdline.CoverageScript, used by CmdMainTest.\"\"\"\n\n        def command_line(self, argv: list[str]) -> int:\n            \"\"\"Stub for command_line, the arg determines what it will do.\"\"\"\n            if argv[0] == 'hello':\n                print(\"Hello, world!\")\n            elif argv[0] == 'raise':\n                try:\n                    raise RuntimeError(\"oh noes!\")\n                except:\n                    raise _ExceptionDuringRun(*sys.exc_info()) from None\n            elif argv[0] == 'internalraise':\n                raise ValueError(\"coverage is broken\")\n            elif argv[0] == 'exit':\n                sys.exit(23)\n            else:\n                raise AssertionError(f\"Bad CoverageScriptStub: {argv!r}\")\n            return 0\n\n    def setUp(self) -> None:\n        super().setUp()\n        old_CoverageScript = coverage.cmdline.CoverageScript\n        coverage.cmdline.CoverageScript = self.CoverageScriptStub   # type: ignore\n        self.addCleanup(setattr, coverage.cmdline, 'CoverageScript', old_CoverageScript)\n\n    def test_normal(self) -> None:\n        ret = coverage.cmdline.main(['hello'])\n        assert ret == 0\n        assert self.stdout() == \"Hello, world!\\n\"\n\n    def test_raise(self) -> None:\n        ret = coverage.cmdline.main(['raise'])\n        assert ret == 1\n        out, err = self.stdouterr()\n        assert out == \"\"\n        print(err)\n        err_parts = err.splitlines(keepends=True)\n        assert err_parts[0] == 'Traceback (most recent call last):\\n'\n        assert '    raise RuntimeError(\"oh noes!\")\\n' in err_parts\n        assert err_parts[-1] == 'RuntimeError: oh noes!\\n'\n\n    def test_internalraise(self) -> None:\n        with pytest.raises(ValueError, match=\"coverage is broken\"):\n            coverage.cmdline.main(['internalraise'])\n\n    def test_exit(self) -> None:\n        ret = coverage.cmdline.main(['exit'])\n        assert ret == 23\n\n\nclass CoverageReportingFake:\n    \"\"\"A fake Coverage.coverage test double for FailUnderTest methods.\"\"\"\n    # pylint: disable=missing-function-docstring\n    def __init__(\n        self,\n        report_result: float,\n        html_result: float = 0,\n        xml_result: float = 0,\n        json_report: float = 0,\n        lcov_result: float = 0,\n    ) -> None:\n        self.config = CoverageConfig()\n        self.report_result = report_result\n        self.html_result = html_result\n        self.xml_result = xml_result\n        self.json_result = json_report\n        self.lcov_result = lcov_result\n\n    def set_option(self, optname: str, optvalue: TConfigValueIn) -> None:\n        self.config.set_option(optname, optvalue)\n\n    def get_option(self, optname: str) -> TConfigValueOut:\n        return self.config.get_option(optname)\n\n    def load(self) -> None:\n        pass\n\n    def report(self, *args_unused: Any, **kwargs_unused: Any) -> float:\n        return self.report_result\n\n    def html_report(self, *args_unused: Any, **kwargs_unused: Any) -> float:\n        return self.html_result\n\n    def xml_report(self, *args_unused: Any, **kwargs_unused: Any) -> float:\n        return self.xml_result\n\n    def json_report(self, *args_unused: Any, **kwargs_unused: Any) -> float:\n        return self.json_result\n\n    def lcov_report(self, *args_unused: Any, **kwargs_unused: Any) -> float:\n        return self.lcov_result\n\n\nclass FailUnderTest(CoverageTest):\n    \"\"\"Tests of the --fail-under handling in cmdline.py.\"\"\"\n\n    @pytest.mark.parametrize(\"results, fail_under, cmd, ret\", [\n        # Command-line switch properly checks the result of reporting functions.\n        ((20, 30, 40, 50, 60), None, \"report --fail-under=19\", 0),\n        ((20, 30, 40, 50, 60), None, \"report --fail-under=21\", 2),\n        ((20, 30, 40, 50, 60), None, \"html --fail-under=29\", 0),\n        ((20, 30, 40, 50, 60), None, \"html --fail-under=31\", 2),\n        ((20, 30, 40, 50, 60), None, \"xml --fail-under=39\", 0),\n        ((20, 30, 40, 50, 60), None, \"xml --fail-under=41\", 2),\n        ((20, 30, 40, 50, 60), None, \"json --fail-under=49\", 0),\n        ((20, 30, 40, 50, 60), None, \"json --fail-under=51\", 2),\n        ((20, 30, 40, 50, 60), None, \"lcov --fail-under=59\", 0),\n        ((20, 30, 40, 50, 60), None, \"lcov --fail-under=61\", 2),\n        # Configuration file setting properly checks the result of reporting.\n        ((20, 30, 40, 50, 60), 19, \"report\", 0),\n        ((20, 30, 40, 50, 60), 21, \"report\", 2),\n        ((20, 30, 40, 50, 60), 29, \"html\", 0),\n        ((20, 30, 40, 50, 60), 31, \"html\", 2),\n        ((20, 30, 40, 50, 60), 39, \"xml\", 0),\n        ((20, 30, 40, 50, 60), 41, \"xml\", 2),\n        ((20, 30, 40, 50, 60), 49, \"json\", 0),\n        ((20, 30, 40, 50, 60), 51, \"json\", 2),\n        ((20, 30, 40, 50, 60), 59, \"lcov\", 0),\n        ((20, 30, 40, 50, 60), 61, \"lcov\", 2),\n        # Command-line overrides configuration.\n        ((20, 30, 40, 50, 60), 19, \"report --fail-under=21\", 2),\n    ])\n    def test_fail_under(\n        self,\n        results: tuple[float, float, float, float, float],\n        fail_under: float | None,\n        cmd: str,\n        ret: int,\n    ) -> None:\n        cov = CoverageReportingFake(*results)\n        if fail_under is not None:\n            cov.set_option(\"report:fail_under\", fail_under)\n        with mock.patch(\"coverage.cmdline.Coverage\", lambda *a,**kw: cov):\n            self.command_line(cmd, ret)\n\n    @pytest.mark.parametrize(\"result, cmd, ret, msg\", [\n        (20.5, \"report --fail-under=20.4 --precision=1\", 0, \"\"),\n        (20.5, \"report --fail-under=20.6 --precision=1\", 2,\n            \"Coverage failure: total of 20.5 is less than fail-under=20.6\\n\"),\n        (20.12345, \"report --fail-under=20.1235 --precision=5\", 2,\n            \"Coverage failure: total of 20.12345 is less than fail-under=20.12350\\n\"),\n        (20.12339, \"report --fail-under=20.1234 --precision=4\", 0, \"\"),\n    ])\n    def test_fail_under_with_precision(self, result: float, cmd: str, ret: int, msg: str) -> None:\n        cov = CoverageReportingFake(report_result=result)\n        with mock.patch(\"coverage.cmdline.Coverage\", lambda *a,**kw: cov):\n            self.command_line(cmd, ret)\n        assert self.stdout() == msg\n", "tests/test_oddball.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Oddball cases for testing coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\nimport re\nimport sys\n\nfrom flaky import flaky\nimport pytest\n\nimport coverage\nfrom coverage import env\nfrom coverage.data import sorted_lines\nfrom coverage.files import abs_file\nfrom coverage.misc import import_local_file\n\nfrom tests import osinfo, testenv\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import swallow_warnings\n\n\nclass ThreadingTest(CoverageTest):\n    \"\"\"Tests of the threading support.\"\"\"\n\n    def test_threading(self) -> None:\n        self.check_coverage(\"\"\"\\\n            import threading\n\n            def fromMainThread():\n                return \"called from main thread\"\n\n            def fromOtherThread():\n                return \"called from other thread\"\n\n            def neverCalled():\n                return \"no one calls me\"\n\n            other = threading.Thread(target=fromOtherThread)\n            other.start()\n            fromMainThread()\n            other.join()\n            \"\"\",\n            [1, 3, 4, 6, 7, 9, 10, 12, 13, 14, 15], \"10\",\n        )\n\n    def test_thread_run(self) -> None:\n        self.check_coverage(\"\"\"\\\n            import threading\n\n            class TestThread(threading.Thread):\n                def run(self):\n                    self.a = 5\n                    self.do_work()\n                    self.a = 7\n\n                def do_work(self):\n                    self.a = 10\n\n            thd = TestThread()\n            thd.start()\n            thd.join()\n            \"\"\",\n            [1, 3, 4, 5, 6, 7, 9, 10, 12, 13, 14], \"\",\n        )\n\n\nclass RecursionTest(CoverageTest):\n    \"\"\"Check what happens when recursive code gets near limits.\"\"\"\n\n    def test_short_recursion(self) -> None:\n        # We can definitely get close to 500 stack frames.\n        self.check_coverage(\"\"\"\\\n            def recur(n):\n                if n == 0:\n                    return 0\n                else:\n                    return recur(n-1)+1\n\n            recur(495)  # We can get at least this many stack frames.\n            i = 8       # and this line will be traced\n            \"\"\",\n            [1, 2, 3, 5, 7, 8], \"\",\n        )\n\n    def test_long_recursion(self) -> None:\n        # We can't finish a very deep recursion, but we don't crash.\n        with pytest.raises(RuntimeError):\n            with swallow_warnings(\"Trace function changed, data is likely wrong: None\"):\n                self.check_coverage(\"\"\"\\\n                    def recur(n):\n                        if n == 0:\n                            return 0\n                        else:\n                            return recur(n-1)+1\n\n                    recur(100000)  # This is definitely too many frames.\n                    \"\"\",\n                    [1, 2, 3, 5, 7], \"\",\n                )\n\n    def test_long_recursion_recovery(self) -> None:\n        # Test the core of bug 93: https://github.com/nedbat/coveragepy/issues/93\n        # When recovering from a stack overflow, the Python trace function is\n        # disabled, but the C trace function is not.  So if we're using a\n        # Python trace function, we won't trace anything after the stack\n        # overflow, and there should be a warning about it.  If we're using\n        # the C trace function, only line 3 will be missing, and all else\n        # will be traced.\n\n        self.make_file(\"recur.py\", \"\"\"\\\n            import sys #; sys.setrecursionlimit(70)\n            def recur(n):\n                if n == 0:\n                    return 0    # never hit\n                else:\n                    return recur(n-1)+1\n\n            try:\n                recur(100000)  # This is definitely too many frames.\n            except RuntimeError:\n                i = 11\n            i = 12\n            \"\"\")\n\n        cov = coverage.Coverage()\n        with swallow_warnings(\"Trace function changed, data is likely wrong: None\"):\n            self.start_import_stop(cov, \"recur\")\n\n        assert cov._collector is not None\n        pytrace = (cov._collector.tracer_name() == \"PyTracer\")\n        expected_missing = [4]\n        if pytrace:                                 # pragma: no metacov\n            expected_missing += [10, 11, 12]\n\n        _, statements, missing, _ = cov.analysis(\"recur.py\")\n        assert statements == [1, 2, 3, 4, 6, 8, 9, 10, 11, 12]\n        assert expected_missing == missing\n\n        # Get a warning about the stackoverflow effect on the tracing function.\n        if pytrace and not env.METACOV:                     # pragma: no metacov\n            assert len(cov._warnings) == 1\n            assert re.fullmatch(\n                r\"Trace function changed, data is likely wrong: None != \" +\n                r\"<bound method PyTracer._trace of \" +\n                \"<PyTracer at 0x[0-9a-fA-F]+: 6 data points in 1 files>>\",\n                cov._warnings[0],\n            )\n        else:\n            assert not cov._warnings\n\n\nclass MemoryLeakTest(CoverageTest):\n    \"\"\"Attempt the impossible: test that memory doesn't leak.\n\n    Note: this test is truly unusual, and has had a colorful history.  See\n    for example: https://github.com/nedbat/coveragepy/issues/186\n\n    It may still fail occasionally, especially on PyPy.\n\n    \"\"\"\n    @flaky      # type: ignore[misc]\n    @pytest.mark.skipif(not testenv.C_TRACER, reason=\"Only the C tracer has refcounting issues\")\n    def test_for_leaks(self) -> None:\n        # Our original bad memory leak only happened on line numbers > 255, so\n        # make a code object with more lines than that.  Ugly string mumbo\n        # jumbo to get 300 blank lines at the beginning..\n        code = \"\"\"\\\n            # blank line\\n\"\"\" * 300 + \"\"\"\\\n            def once(x):                                        # line 301\n                if x % 100 == 0:\n                    raise Exception(\"100!\")\n                elif x % 2:\n                    return 10\n                else:                                           # line 306\n                    return 11\n            i = 0 # Portable loop without alloc'ing memory.\n            while i < ITERS:\n                try:\n                    once(i)\n                except:\n                    pass\n                i += 1                                          # line 315\n            \"\"\"\n        lines = list(range(301, 315))\n        lines.remove(306)       # Line 306 is the \"else\".\n\n        # This is a non-deterministic test, so try it a few times, and fail it\n        # only if it predominantly fails.\n        fails = 0\n        for _ in range(10):\n            ram_0 = osinfo.process_ram()\n            self.check_coverage(code.replace(\"ITERS\", \"10\"), lines, \"\")\n            ram_10 = osinfo.process_ram()\n            self.check_coverage(code.replace(\"ITERS\", \"10000\"), lines, \"\")\n            ram_10k = osinfo.process_ram()\n            # Running the code 10k times shouldn't grow the ram much more than\n            # running it 10 times.\n            ram_growth = (ram_10k - ram_10) - (ram_10 - ram_0)\n            if ram_growth > 100000:\n                fails += 1                                  # pragma: only failure\n\n        if fails > 8:\n            pytest.fail(\"RAM grew by %d\" % (ram_growth))      # pragma: only failure\n\n\nclass MemoryFumblingTest(CoverageTest):\n    \"\"\"Test that we properly manage the None refcount.\"\"\"\n\n    @pytest.mark.skipif(not testenv.C_TRACER, reason=\"Only the C tracer has refcounting issues\")\n    def test_dropping_none(self) -> None:                     # pragma: not covered\n        # TODO: Mark this so it will only be run sometimes.\n        pytest.skip(\"This is too expensive for now (30s)\")\n        # Start and stop coverage thousands of times to flush out bad\n        # reference counting, maybe.\n        _ = \"this is just here to put a type comment on\"    # type: ignore[unreachable]\n        self.make_file(\"the_code.py\", \"\"\"\\\n            import random\n            def f():\n                if random.random() > .5:\n                    x = 1\n                else:\n                    x = 2\n            \"\"\")\n        self.make_file(\"main.py\", \"\"\"\\\n            import coverage\n            import sys\n            from the_code import f\n            for i in range(10000):\n                cov = coverage.Coverage(branch=True)\n                cov.start()\n                f()\n                cov.stop()\n                cov.erase()\n            print(\"Final None refcount: %d\" % (sys.getrefcount(None)))\n            \"\"\")\n        status, out = self.run_command_status(\"python main.py\")\n        assert status == 0\n        assert \"Final None refcount\" in out\n        assert \"Fatal\" not in out\n\n\nclass PyexpatTest(CoverageTest):\n    \"\"\"Pyexpat screws up tracing. Make sure we've counter-defended properly.\"\"\"\n\n    def test_pyexpat(self) -> None:\n        # pyexpat calls the trace function explicitly (inexplicably), and does\n        # it wrong for exceptions.  Parsing a DOCTYPE for some reason throws\n        # an exception internally, and triggers its wrong behavior.  This test\n        # checks that our fake PyTrace_RETURN hack in tracer.c works.  It will\n        # also detect if the pyexpat bug is fixed unbeknownst to us, meaning\n        # we'd see two RETURNs where there should only be one.\n\n        self.make_file(\"trydom.py\", \"\"\"\\\n            import xml.dom.minidom\n\n            XML = '''\\\\\n            <!DOCTYPE fooey SYSTEM \"http://www.example.com/example.dtd\">\n            <root><child/><child/></root>\n            '''\n\n            def foo():\n                dom = xml.dom.minidom.parseString(XML)\n                assert len(dom.getElementsByTagName('child')) == 2\n                a = 11\n\n            foo()\n            \"\"\")\n\n        self.make_file(\"outer.py\", \"\\n\"*100 + \"import trydom\\na = 102\\n\")\n\n        cov = coverage.Coverage()\n        cov.erase()\n\n        # Import the Python file, executing it.\n        self.start_import_stop(cov, \"outer\")\n\n        _, statements, missing, _ = cov.analysis(\"trydom.py\")\n        assert statements == [1, 3, 8, 9, 10, 11, 13]\n        assert missing == []\n\n        _, statements, missing, _ = cov.analysis(\"outer.py\")\n        assert statements == [101, 102]\n        assert missing == []\n\n        # Make sure pyexpat isn't recorded as a source file.\n        # https://github.com/nedbat/coveragepy/issues/419\n        files = cov.get_data().measured_files()\n        msg = f\"Pyexpat.c is in the measured files!: {files!r}:\"\n        assert not any(f.endswith(\"pyexpat.c\") for f in files), msg\n\n\nclass ExceptionTest(CoverageTest):\n    \"\"\"I suspect different versions of Python deal with exceptions differently\n    in the trace function.\n    \"\"\"\n\n    def test_exception(self) -> None:\n        # Python 2.3's trace function doesn't get called with \"return\" if the\n        # scope is exiting due to an exception.  This confounds our trace\n        # function which relies on scope announcements to track which files to\n        # trace.\n        #\n        # This test is designed to sniff this out.  Each function in the call\n        # stack is in a different file, to try to trip up the tracer.  Each\n        # file has active lines in a different range so we'll see if the lines\n        # get attributed to the wrong file.\n\n        self.make_file(\"oops.py\", \"\"\"\\\n            def oops(args):\n                a = 2\n                raise Exception(\"oops\")\n                a = 4\n            \"\"\")\n\n        self.make_file(\"fly.py\", \"\\n\"*100 + \"\"\"\\\n            def fly(calls):\n                a = 2\n                calls[0](calls[1:])\n                a = 4\n            \"\"\")\n\n        self.make_file(\"catch.py\", \"\\n\"*200 + \"\"\"\\\n            def catch(calls):\n                try:\n                    a = 3\n                    calls[0](calls[1:])\n                    a = 5\n                except:\n                    a = 7\n            \"\"\")\n\n        self.make_file(\"doit.py\", \"\\n\"*300 + \"\"\"\\\n            def doit(calls):\n                try:\n                    calls[0](calls[1:])\n                except:\n                    a = 5\n            \"\"\")\n\n        # Import all the modules before starting coverage, so the def lines\n        # won't be in all the results.\n        for mod in \"oops fly catch doit\".split():\n            import_local_file(mod)\n\n        # Each run nests the functions differently to get different\n        # combinations of catching exceptions and letting them fly.\n        runs = [\n            (\"doit fly oops\", {\n                'doit.py': [302, 303, 304, 305],\n                'fly.py': [102, 103],\n                'oops.py': [2, 3],\n            }),\n            (\"doit catch oops\", {\n                'doit.py': [302, 303],\n                'catch.py': [202, 203, 204, 206, 207],\n                'oops.py': [2, 3],\n            }),\n            (\"doit fly catch oops\", {\n                'doit.py': [302, 303],\n                'fly.py': [102, 103, 104],\n                'catch.py': [202, 203, 204, 206, 207],\n                'oops.py': [2, 3],\n            }),\n            (\"doit catch fly oops\", {\n                'doit.py': [302, 303],\n                'catch.py': [202, 203, 204, 206, 207],\n                'fly.py': [102, 103],\n                'oops.py': [2, 3],\n            }),\n        ]\n\n        for callnames, lines_expected in runs:\n\n            # Make the list of functions we'll call for this test.\n            callnames_list = callnames.split()\n            calls = [getattr(sys.modules[cn], cn) for cn in callnames_list]\n\n            cov = coverage.Coverage()\n            with cov.collect():\n                # Call our list of functions: invoke the first, with the rest as\n                # an argument.\n                calls[0](calls[1:])\n\n            # Clean the line data and compare to expected results.\n            # The file names are absolute, so keep just the base.\n            clean_lines = {}\n            data = cov.get_data()\n            for callname in callnames_list:\n                filename = callname + \".py\"\n                clean_lines[filename] = sorted_lines(data, abs_file(filename))\n\n            assert clean_lines == lines_expected\n\n\nclass DoctestTest(CoverageTest):\n    \"\"\"Tests invoked with doctest should measure properly.\"\"\"\n\n    def test_doctest(self) -> None:\n        # Doctests used to be traced, with their line numbers credited to the\n        # file they were in.  Below, one of the doctests has four lines (1-4),\n        # which would incorrectly claim that lines 1-4 of the file were\n        # executed.  In this file, line 2 is not executed.\n        self.make_file(\"the_doctest.py\", '''\\\n            if \"x\" in \"abc\":\n                print(\"hello\")\n            def return_arg_or_void(arg):\n                \"\"\"If <arg> is None, return \"Void\"; otherwise return <arg>\n\n                >>> return_arg_or_void(None)\n                'Void'\n                >>> return_arg_or_void(\"arg\")\n                'arg'\n                >>> return_arg_or_void(\"None\")\n                'None'\n                >>> if \"x\" in \"xyz\":                # line 1\n                ...   if \"a\" in \"aswed\":            # line 2\n                ...      if \"a\" in \"abc\":           # line 3\n                ...         return_arg_or_void(12)  # line 4\n                12\n                \"\"\"\n                if arg is None:\n                    return \"Void\"\n                else:\n                    return arg\n\n            import doctest, sys\n            doctest.testmod(sys.modules[__name__])  # we're not __main__ :(\n            ''')\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"the_doctest\")\n        data = cov.get_data()\n        assert len(data.measured_files()) == 1\n        lines = sorted_lines(data, data.measured_files().pop())\n        assert lines == [1, 3, 18, 19, 21, 23, 24]\n\n\nclass GettraceTest(CoverageTest):\n    \"\"\"Tests that we work properly with `sys.gettrace()`.\"\"\"\n    def test_round_trip_in_untraced_function(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/575\n        self.make_file(\"main.py\", \"\"\"import sample\"\"\")\n        self.make_file(\"sample.py\", \"\"\"\\\n            from swap import swap_it\n            def doit():\n                print(3)\n                swap_it()\n                print(5)\n            def doit_soon():\n                print(7)\n                doit()\n                print(9)\n            print(10)\n            doit_soon()\n            print(12)\n            \"\"\")\n        self.make_file(\"swap.py\", \"\"\"\\\n            import sys\n            def swap_it():\n                sys.settrace(sys.gettrace())\n            \"\"\")\n\n        # Use --source=sample to prevent measurement of swap.py.\n        cov = coverage.Coverage(source=[\"sample\"])\n        self.start_import_stop(cov, \"main\")\n\n        assert self.stdout() == \"10\\n7\\n3\\n5\\n9\\n12\\n\"\n\n        _, statements, missing, _ = cov.analysis(\"sample.py\")\n        assert statements == [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        assert missing == []\n\n    def test_setting_new_trace_function(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/436\n        if testenv.SETTRACE_CORE:\n            missing = \"5-7, 13-14\"\n        else:\n            missing = \"5-7\"\n        self.check_coverage('''\\\n            import os.path\n            import sys\n\n            def tracer(frame, event, arg):\n                filename = os.path.basename(frame.f_code.co_filename)   # 5\n                print(f\"{event}: {filename} @ {frame.f_lineno}\")        # 6\n                return tracer                                           # 7\n\n            def begin():\n                sys.settrace(tracer)\n\n            def collect():\n                t = sys.gettrace()              # 13\n                assert t is tracer, t           # 14\n\n            def test_unsets_trace() -> None:\n                begin()\n                collect()\n\n            old = sys.gettrace()\n            test_unsets_trace()\n            sys.settrace(old)\n            a = 21\n            b = 22\n            ''',\n            lines=[1, 2, 4, 5, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24],\n            missing=missing,\n        )\n\n        assert self.last_module_name is not None\n        out = self.stdout().replace(self.last_module_name, \"coverage_test\")\n        expected = (\n            \"call: coverage_test.py @ 12\\n\" +\n            \"line: coverage_test.py @ 13\\n\" +\n            \"line: coverage_test.py @ 14\\n\" +\n            \"return: coverage_test.py @ 14\\n\"\n        )\n        assert expected == out\n\n    @pytest.mark.expensive\n    @pytest.mark.skipif(env.METACOV, reason=\"Can't set trace functions during meta-coverage\")\n    def test_atexit_gettrace(self) -> None:\n        # This is not a test of coverage at all, but of our understanding\n        # of this edge-case behavior in various Pythons.\n\n        self.make_file(\"atexit_gettrace.py\", \"\"\"\\\n            import atexit, sys\n\n            def trace_function(frame, event, arg):\n                return trace_function\n            sys.settrace(trace_function)\n\n            def show_trace_function():\n                tfn = sys.gettrace()\n                if tfn is not None:\n                    tfn = tfn.__name__\n                print(tfn)\n            atexit.register(show_trace_function)\n\n            # This will show what the trace function is at the end of the program.\n            \"\"\")\n        status, out = self.run_command_status(\"python atexit_gettrace.py\")\n        assert status == 0\n        if env.PYPY and env.PYPYVERSION >= (5, 4):\n            # Newer PyPy clears the trace function before atexit runs.\n            assert out == \"None\\n\"\n        else:\n            # Other Pythons leave the trace function in place.\n            assert out == \"trace_function\\n\"\n\n\nclass ExecTest(CoverageTest):\n    \"\"\"Tests of exec.\"\"\"\n    def test_correct_filename(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/380\n        # Bug was that exec'd files would have their lines attributed to the\n        # calling file.  Make two files, both with ~30 lines, but no lines in\n        # common.  Line 30 in to_exec.py was recorded as line 30 in main.py,\n        # but now it's fixed. :)\n        self.make_file(\"to_exec.py\", \"\"\"\\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\n            print(\"var is {}\".format(var))         # line 31\n            \"\"\")\n        self.make_file(\"main.py\", \"\"\"\\\n            namespace = {'var': 17}\n            with open(\"to_exec.py\") as to_exec_py:\n                code = compile(to_exec_py.read(), 'to_exec.py', 'exec')\n                exec(code, globals(), namespace)\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\n            print(\"done\")                           # line 35\n            \"\"\")\n\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n\n        _, statements, missing, _ = cov.analysis(\"main.py\")\n        assert statements == [1, 2, 3, 4, 35]\n        assert missing == []\n        _, statements, missing, _ = cov.analysis(\"to_exec.py\")\n        assert statements == [31]\n        assert missing == []\n\n    def test_unencodable_filename(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/891\n        self.make_file(\"bug891.py\", r\"\"\"exec(compile(\"pass\", \"\\udcff.py\", \"exec\"))\"\"\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"bug891\")\n        # Saving would fail trying to encode \\udcff.py\n        cov.save()\n        files = [os.path.basename(f) for f in cov.get_data().measured_files()]\n        assert \"bug891.py\" in files\n\n\nclass MockingProtectionTest(CoverageTest):\n    \"\"\"Tests about protecting ourselves from aggressive mocking.\n\n    https://github.com/nedbat/coveragepy/issues/416\n\n    \"\"\"\n    def test_os_path_exists(self) -> None:\n        # To see if this test still detects the problem, change isolate_module\n        # in misc.py to simply return its argument.  It should fail with a\n        # StopIteration error.\n        self.make_file(\"bug416.py\", \"\"\"\\\n            import os.path\n            from unittest import mock\n\n            @mock.patch('os.path.exists')\n            def test_path_exists(mock_exists):\n                mock_exists.side_effect = [17]\n                print(\"in test\")\n                import bug416a\n                print(bug416a.foo)\n                print(os.path.exists(\".\"))\n\n            test_path_exists()\n            \"\"\")\n        self.make_file(\"bug416a.py\", \"\"\"\\\n            print(\"bug416a.py\")\n            foo = 23\n            \"\"\")\n\n        import py_compile\n        py_compile.compile(\"bug416a.py\")\n        out = self.run_command(\"coverage run bug416.py\")\n        assert out == \"in test\\nbug416a.py\\n23\\n17\\n\"\n", "tests/test_results.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.py's results analysis.\"\"\"\n\nfrom __future__ import annotations\n\nimport math\n\nfrom typing import Iterable, cast\n\nimport pytest\n\nfrom coverage.exceptions import ConfigError\nfrom coverage.results import Numbers, display_covered, format_lines, should_fail_under\nfrom coverage.types import TLineNo\n\nfrom tests.coveragetest import CoverageTest\n\n\nclass NumbersTest(CoverageTest):\n    \"\"\"Tests for coverage.py's numeric measurement summaries.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_basic(self) -> None:\n        n1 = Numbers(n_files=1, n_statements=200, n_missing=20)\n        assert n1.n_statements == 200\n        assert n1.n_executed == 180\n        assert n1.n_missing == 20\n        assert n1.pc_covered == 90\n\n    def test_addition(self) -> None:\n        n1 = Numbers(n_files=1, n_statements=200, n_missing=20)\n        n2 = Numbers(n_files=1, n_statements=10, n_missing=8)\n        n3 = n1 + n2\n        assert n3.n_files == 2\n        assert n3.n_statements == 210\n        assert n3.n_executed == 182\n        assert n3.n_missing == 28\n        assert math.isclose(n3.pc_covered, 86.666666666)\n\n    def test_sum(self) -> None:\n        n1 = Numbers(n_files=1, n_statements=200, n_missing=20)\n        n2 = Numbers(n_files=1, n_statements=10, n_missing=8)\n        n3 = cast(Numbers, sum([n1, n2]))\n        assert n3.n_files == 2\n        assert n3.n_statements == 210\n        assert n3.n_executed == 182\n        assert n3.n_missing == 28\n        assert math.isclose(n3.pc_covered, 86.666666666)\n\n    @pytest.mark.parametrize(\"kwargs, res\", [\n        (dict(n_files=1, n_statements=1000, n_missing=0), \"100\"),\n        (dict(n_files=1, n_statements=1000, n_missing=1), \"99\"),\n        (dict(n_files=1, n_statements=1000, n_missing=999), \"1\"),\n        (dict(n_files=1, n_statements=1000, n_missing=1000), \"0\"),\n        (dict(precision=1, n_files=1, n_statements=10000, n_missing=0), \"100.0\"),\n        (dict(precision=1, n_files=1, n_statements=10000, n_missing=1), \"99.9\"),\n        (dict(precision=1, n_files=1, n_statements=10000, n_missing=9999), \"0.1\"),\n        (dict(precision=1, n_files=1, n_statements=10000, n_missing=10000), \"0.0\"),\n    ])\n    def test_pc_covered_str(self, kwargs: dict[str, int], res: str) -> None:\n        assert Numbers(**kwargs).pc_covered_str == res\n\n    @pytest.mark.parametrize(\"prec, pc, res\", [\n        (0, 47.87, \"48\"),\n        (1, 47.87, \"47.9\"),\n        (0, 99.995, \"99\"),\n        (2, 99.99995, \"99.99\"),\n    ])\n    def test_display_covered(self, prec: int, pc: float, res: str) -> None:\n        assert display_covered(pc, prec) == res\n\n    def test_covered_ratio(self) -> None:\n        n = Numbers(n_files=1, n_statements=200, n_missing=47)\n        assert n.ratio_covered == (153, 200)\n\n        n = Numbers(\n            n_files=1, n_statements=200, n_missing=47,\n            n_branches=10, n_missing_branches=3, n_partial_branches=1000,\n        )\n        assert n.ratio_covered == (160, 210)\n\n\n@pytest.mark.parametrize(\"total, fail_under, precision, result\", [\n    # fail_under==0 means anything is fine!\n    (0, 0, 0, False),\n    (0.001, 0, 0, False),\n    # very small fail_under is possible to fail.\n    (0.001, 0.01, 0, True),\n    # Rounding should work properly.\n    (42.1, 42, 0, False),\n    (42.1, 43, 0, True),\n    (42.857, 42, 0, False),\n    (42.857, 43, 0, False),\n    (42.857, 44, 0, True),\n    (42.857, 42.856, 3, False),\n    (42.857, 42.858, 3, True),\n    # If you don't specify precision, your fail-under is rounded.\n    (42.857, 42.856, 0, False),\n    # Values near 100 should only be treated as 100 if they are 100.\n    (99.8, 100, 0, True),\n    (100.0, 100, 0, False),\n    (99.8, 99.7, 1, False),\n    (99.88, 99.90, 2, True),\n    (99.999, 100, 1, True),\n    (99.999, 100, 2, True),\n    (99.999, 100, 3, True),\n])\ndef test_should_fail_under(total: float, fail_under: float, precision: int, result: bool) -> None:\n    assert should_fail_under(float(total), float(fail_under), precision) == result\n\n\ndef test_should_fail_under_invalid_value() -> None:\n    with pytest.raises(ConfigError, match=r\"fail_under=101\"):\n        should_fail_under(100.0, 101, 0)\n\n\n@pytest.mark.parametrize(\"statements, lines, result\", [\n    ({1,2,3,4,5,10,11,12,13,14}, {1,2,5,10,11,13,14}, \"1-2, 5-11, 13-14\"),\n    ([1,2,3,4,5,10,11,12,13,14,98,99], [1,2,5,10,11,13,14,99], \"1-2, 5-11, 13-14, 99\"),\n    ([1,2,3,4,98,99,100,101,102,103,104], [1,2,99,102,103,104], \"1-2, 99, 102-104\"),\n    ([17], [17], \"17\"),\n    ([90,91,92,93,94,95], [90,91,92,93,94,95], \"90-95\"),\n    ([1, 2, 3, 4, 5], [], \"\"),\n    ([1, 2, 3, 4, 5], [4], \"4\"),\n])\ndef test_format_lines(\n    statements: Iterable[TLineNo],\n    lines: Iterable[TLineNo],\n    result: str,\n) -> None:\n    assert format_lines(statements, lines) == result\n\n\n@pytest.mark.parametrize(\"statements, lines, arcs, result\", [\n    (\n        {1,2,3,4,5,10,11,12,13,14},\n        {1,2,5,10,11,13,14},\n        (),\n        \"1-2, 5-11, 13-14\",\n    ),\n    (\n        [1,2,3,4,5,10,11,12,13,14,98,99],\n        [1,2,5,10,11,13,14,99],\n        [(3, [4]), (5, [10, 11]), (98, [100, -1])],\n        \"1-2, 3->4, 5-11, 13-14, 98->100, 98->exit, 99\",\n    ),\n    (\n        [1,2,3,4,98,99,100,101,102,103,104],\n        [1,2,99,102,103,104],\n        [(3, [4]), (104, [-1])],\n        \"1-2, 3->4, 99, 102-104\",\n    ),\n])\ndef test_format_lines_with_arcs(\n    statements: Iterable[TLineNo],\n    lines: Iterable[TLineNo],\n    arcs: Iterable[tuple[TLineNo, list[TLineNo]]],\n    result: str,\n) -> None:\n    assert format_lines(statements, lines, arcs) == result\n", "tests/plugin2.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"A file tracer plugin for test_plugins.py to import.\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\n\nfrom types import FrameType\nfrom typing import Any\n\nfrom coverage import CoveragePlugin, FileReporter, FileTracer\nfrom coverage.plugin_support import Plugins\nfrom coverage.types import TLineNo\n\ntry:\n    import third.render                 # pylint: disable=unused-import\nexcept ImportError:\n    # This plugin is used in a few tests. One of them has the third.render\n    # module, but most don't. We need to import it but not use it, so just\n    # try importing it and it's OK if the module doesn't exist.\n    pass\n\n\nclass Plugin(CoveragePlugin):\n    \"\"\"A file tracer plugin for testing.\"\"\"\n    def file_tracer(self, filename: str) -> FileTracer | None:\n        if \"render.py\" in filename:\n            return RenderFileTracer()\n        return None\n\n    def file_reporter(self, filename: str) -> FileReporter:\n        return MyFileReporter(filename)\n\n\nclass RenderFileTracer(FileTracer):\n    \"\"\"A FileTracer using information from the caller.\"\"\"\n\n    def has_dynamic_source_filename(self) -> bool:\n        return True\n\n    def dynamic_source_filename(\n        self,\n        filename: str,\n        frame: FrameType,\n    ) -> str | None:\n        if frame.f_code.co_name != \"render\":\n            return None\n        source_filename: str = os.path.abspath(frame.f_locals['filename'])\n        return source_filename\n\n    def line_number_range(self, frame: FrameType) -> tuple[TLineNo, TLineNo]:\n        lineno = frame.f_locals['linenum']\n        return lineno, lineno+1\n\n\nclass MyFileReporter(FileReporter):\n    \"\"\"A goofy file reporter.\"\"\"\n    def lines(self) -> set[TLineNo]:\n        # Goofy test arrangement: claim that the file has as many lines as the\n        # number in its name.\n        num = os.path.basename(self.filename).split(\".\")[0].split(\"_\")[1]\n        return set(range(1, int(num)+1))\n\n\ndef coverage_init(\n    reg: Plugins,\n    options: Any,       # pylint: disable=unused-argument\n) -> None:\n    \"\"\"Called by coverage to initialize the plugins here.\"\"\"\n    reg.add_file_tracer(Plugin())\n", "tests/test_version.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests of version.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport coverage\nfrom coverage.version import _make_url, _make_version\n\nfrom tests.coveragetest import CoverageTest\n\n\nclass VersionTest(CoverageTest):\n    \"\"\"Tests of version.py\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_version_info(self) -> None:\n        # Make sure we didn't screw up the version_info tuple.\n        assert isinstance(coverage.version_info, tuple)\n        assert [type(d) for d in coverage.version_info] == [int, int, int, str, int]\n        assert coverage.version_info[3] in {'alpha', 'beta', 'candidate', 'final'}\n\n    def test_make_version(self) -> None:\n        assert _make_version(4, 0, 0, 'alpha') == \"4.0.0a0\"\n        assert _make_version(4, 0, 0, 'alpha', 1) == \"4.0.0a1\"\n        assert _make_version(4, 0, 0, 'final') == \"4.0.0\"\n        assert _make_version(4, 1, 0) == \"4.1.0\"\n        assert _make_version(4, 1, 2, 'beta', 3) == \"4.1.2b3\"\n        assert _make_version(4, 1, 2) == \"4.1.2\"\n        assert _make_version(5, 10, 2, 'candidate', 7) == \"5.10.2rc7\"\n        assert _make_version(5, 10, 2, 'candidate', 7, 3) == \"5.10.2rc7.dev3\"\n\n    def test_make_url(self) -> None:\n        expected = \"https://coverage.readthedocs.io/en/4.1.2\"\n        assert _make_url(4, 1, 2, 'final') == expected\n        expected = \"https://coverage.readthedocs.io/en/4.1.2b3\"\n        assert _make_url(4, 1, 2, 'beta', 3) == expected\n        expected = \"https://coverage.readthedocs.io/en/4.1.2b3.dev17\"\n        assert _make_url(4, 1, 2, 'beta', 3, 17) == expected\n        expected = \"https://coverage.readthedocs.io/en/4.1.2.dev17\"\n        assert _make_url(4, 1, 2, 'final', 0, 17) == expected\n", "tests/test_debug.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests of coverage/debug.py\"\"\"\n\nfrom __future__ import annotations\n\nimport ast\nimport io\nimport os\nimport re\nimport sys\n\nfrom typing import Any, Callable, Iterable\n\nimport pytest\n\nimport coverage\nfrom coverage import env\nfrom coverage.debug import (\n    DebugControl, DebugOutputFile,\n    auto_repr, clipped_repr, exc_one_line, filter_text,\n    info_formatter, info_header,\n    relevant_environment_display, short_id, short_filename, short_stack,\n)\nfrom coverage.exceptions import DataError\n\nfrom tests import testenv\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import DebugControlString, re_line, re_lines, re_lines_text\n\n\nclass InfoFormatterTest(CoverageTest):\n    \"\"\"Tests of debug.info_formatter.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_info_formatter(self) -> None:\n        lines = list(info_formatter([\n            ('x', 'hello there'),\n            ('very long label', ['one element']),\n            ('regular', ['abc', 'def', 'ghi', 'jkl']),\n            ('nothing', []),\n        ]))\n        expected = [\n            '                             x: hello there',\n            '               very long label: one element',\n            '                       regular: abc',\n            '                                def',\n            '                                ghi',\n            '                                jkl',\n            '                       nothing: -none-',\n        ]\n        assert expected == lines\n\n    def test_info_formatter_with_generator(self) -> None:\n        lines = list(info_formatter(('info%d' % i, i) for i in range(3)))\n        expected = [\n            '                         info0: 0',\n            '                         info1: 1',\n            '                         info2: 2',\n        ]\n        assert expected == lines\n\n    def test_too_long_label(self) -> None:\n        with pytest.raises(AssertionError):\n            list(info_formatter([('this label is way too long and will not fit', 23)]))\n\n\n@pytest.mark.parametrize(\"label, header\", [\n    (\"x\",               \"-- x ---------------------------------------------------------\"),\n    (\"hello there\",     \"-- hello there -----------------------------------------------\"),\n])\ndef test_info_header(label: str, header: str) -> None:\n    assert header == info_header(label)\n\n\n@pytest.mark.parametrize(\"id64, id16\", [\n    (0x1234, 0x1234),\n    (0x12340000, 0x1234),\n    (0xA5A55A5A, 0xFFFF),\n    (0x1234cba956780fed, 0x8008),\n])\ndef test_short_id(id64: int, id16: int) -> None:\n    assert id16 == short_id(id64)\n\n\n@pytest.mark.parametrize(\"text, numchars, result\", [\n    (\"hello\", 10, \"'hello'\"),\n    (\"0123456789abcdefghijklmnopqrstuvwxyz\", 15, \"'01234...vwxyz'\"),\n])\ndef test_clipped_repr(text: str, numchars: int, result: str) -> None:\n    assert result == clipped_repr(text, numchars)\n\n\n@pytest.mark.parametrize(\"text, filters, result\", [\n    (\"hello\", [], \"hello\"),\n    (\"hello\\n\", [], \"hello\\n\"),\n    (\"hello\\nhello\\n\", [], \"hello\\nhello\\n\"),\n    (\"hello\\nbye\\n\", [lambda x: \"=\"+x], \"=hello\\n=bye\\n\"),\n    (\"hello\\nbye\\n\", [lambda x: \"=\"+x, lambda x: x+\"\\ndone\\n\"], \"=hello\\ndone\\n=bye\\ndone\\n\"),\n])\ndef test_filter_text(\n    text: str,\n    filters: Iterable[Callable[[str], str]],\n    result: str,\n) -> None:\n    assert result == filter_text(text, filters)\n\n\nclass DebugTraceTest(CoverageTest):\n    \"\"\"Tests of debug output.\"\"\"\n\n    def f1_debug_output(self, debug: Iterable[str]) -> str:\n        \"\"\"Runs some code with `debug` option, returns the debug output.\"\"\"\n        # Make code to run.\n        self.make_file(\"f1.py\", \"\"\"\\\n            def f1(x):\n                return x+1\n\n            for i in range(5):\n                f1(i)\n            \"\"\")\n\n        debug_out = io.StringIO()\n        cov = coverage.Coverage(debug=debug)\n        cov._debug_file = debug_out\n        self.start_import_stop(cov, \"f1\")\n        cov.save()\n\n        return debug_out.getvalue()\n\n    def test_debug_no_trace(self) -> None:\n        out_text = self.f1_debug_output([])\n\n        # We should have no output at all.\n        assert not out_text\n\n    def test_debug_trace(self) -> None:\n        out_text = self.f1_debug_output([\"trace\"])\n\n        # We should have a line like \"Tracing 'f1.py'\", perhaps with an\n        # absolute path.\n        assert re.search(r\"Tracing '.*f1.py'\", out_text)\n\n        # We should have lines like \"Not tracing 'collector.py'...\"\n        assert re_lines(r\"^Not tracing .*: is part of coverage.py$\", out_text)\n\n    def test_debug_trace_pid(self) -> None:\n        out_text = self.f1_debug_output([\"trace\", \"pid\"])\n\n        # Now our lines are always prefixed with the process id.\n        pid_prefix = r\"^%5d\\.[0-9a-f]{4}: \" % os.getpid()\n        pid_lines = re_lines_text(pid_prefix, out_text)\n        assert pid_lines == out_text\n\n        # We still have some tracing, and some not tracing.\n        assert re_lines(pid_prefix + \"Tracing \", out_text)\n        assert re_lines(pid_prefix + \"Not tracing \", out_text)\n\n    def test_debug_callers(self) -> None:\n        out_text = self.f1_debug_output([\"pid\", \"dataop\", \"dataio\", \"callers\", \"lock\"])\n        # For every real message, there should be a stack trace with a line like\n        #       \"f1_debug_output : /Users/ned/coverage/tests/test_debug.py @71\"\n        real_messages = re_lines(r\":\\d+\", out_text, match=False)\n        frame_pattern = r\"\\s+f1_debug_output : .*tests[/\\\\]test_debug.py:\\d+$\"\n        frames = re_lines(frame_pattern, out_text)\n        assert len(real_messages) == len(frames)\n\n        last_line = out_text.splitlines()[-1]\n\n        # The details of what to expect on the stack are empirical, and can change\n        # as the code changes. This test is here to ensure that the debug code\n        # continues working. It's ok to adjust these details over time.\n        assert re_lines(r\"^\\s*\\d+\\.\\w{4}: Adding file tracers: 0 files\", real_messages[-1])\n        assert re_lines(r\"\\s+add_file_tracers : .*coverage[/\\\\]sqldata.py:\\d+$\", last_line)\n\n    def test_debug_config(self) -> None:\n        out_text = self.f1_debug_output([\"config\"])\n\n        labels = \"\"\"\n            branch config_file config_files_attempted config_files_read cover_pylib data_file\n            debug exclude_list extra_css html_dir html_title ignore_errors\n            run_include run_omit parallel partial_always_list partial_list paths\n            precision show_missing source timid xml_output\n            report_include report_omit\n            \"\"\".split()\n        for label in labels:\n            label_pat = fr\"^\\s*{label}: \"\n            msg = f\"Incorrect lines for {label!r}\"\n            assert 1 == len(re_lines(label_pat, out_text)), msg\n\n    def test_debug_sys(self) -> None:\n        out_text = self.f1_debug_output([\"sys\"])\n        assert_good_debug_sys(out_text)\n\n    def test_debug_sys_ctracer(self) -> None:\n        out_text = self.f1_debug_output([\"sys\"])\n        tracer_line = re_line(r\"CTracer:\", out_text).strip()\n        if testenv.C_TRACER or testenv.SYS_MON:\n            expected = \"CTracer: available\"\n        else:\n            expected = \"CTracer: unavailable\"\n        assert expected == tracer_line\n\n    def test_debug_pybehave(self) -> None:\n        out_text = self.f1_debug_output([\"pybehave\"])\n        out_lines = out_text.splitlines()\n        assert 10 < len(out_lines) < 40\n        pyversion = re_line(r\" PYVERSION:\", out_text)\n        vtuple = ast.literal_eval(pyversion.partition(\":\")[-1].strip())\n        assert vtuple[:5] == sys.version_info\n\n    def test_debug_process(self) -> None:\n        out_text = self.f1_debug_output([\"trace\", \"process\"])\n        assert f\"New process: pid={os.getpid()}, executable:\" in out_text\n\n    def test_debug_pytest(self) -> None:\n        out_text = self.f1_debug_output([\"trace\", \"pytest\"])\n        ctx = \"tests/test_debug.py::DebugTraceTest::test_debug_pytest (call)\"\n        assert f\"Pytest context: {ctx}\" in out_text\n\n\ndef assert_good_debug_sys(out_text: str) -> None:\n    \"\"\"Assert that `str` is good output for debug=sys.\"\"\"\n    labels = \"\"\"\n        coverage_version coverage_module coverage_paths stdlib_paths third_party_paths\n        core configs_attempted config_file configs_read data_file\n        python platform implementation executable\n        pid cwd path environment command_line cover_match pylib_match\n        \"\"\".split()\n    for label in labels:\n        label_pat = fr\"^\\s*{label}: \"\n        msg = f\"Incorrect lines for {label!r}\"\n        assert 1 == len(re_lines(label_pat, out_text)), msg\n    tracer_line = re_line(\" core:\", out_text).strip()\n    if testenv.C_TRACER:\n        assert tracer_line == \"core: CTracer\"\n    elif testenv.PY_TRACER:\n        assert tracer_line == \"core: PyTracer\"\n    else:\n        assert testenv.SYS_MON\n        assert tracer_line == \"core: SysMonitor\"\n\n\nclass DebugOutputTest(CoverageTest):\n    \"\"\"Tests that we can direct debug output where we want.\"\"\"\n\n    def setUp(self) -> None:\n        super().setUp()\n        # DebugOutputFile aggressively tries to start just one output file. We\n        # need to manually force it to make a new one.\n        DebugOutputFile._del_singleton_data()\n\n    def debug_sys(self) -> None:\n        \"\"\"Run just enough coverage to get full debug=sys output.\"\"\"\n        cov = coverage.Coverage(debug=[\"sys\"])\n        cov.start()\n        cov.stop()\n\n    def test_stderr_default(self) -> None:\n        self.debug_sys()\n        out, err = self.stdouterr()\n        assert \"\" == out\n        assert_good_debug_sys(err)\n\n    def test_envvar(self) -> None:\n        self.set_environ(\"COVERAGE_DEBUG_FILE\", \"debug.out\")\n        self.debug_sys()\n        assert (\"\", \"\") == self.stdouterr()\n        with open(\"debug.out\") as f:\n            assert_good_debug_sys(f.read())\n\n    def test_config_file(self) -> None:\n        self.make_file(\".coveragerc\", \"[run]\\ndebug_file = lotsa_info.txt\")\n        self.debug_sys()\n        assert (\"\", \"\") == self.stdouterr()\n        with open(\"lotsa_info.txt\") as f:\n            assert_good_debug_sys(f.read())\n\n    def test_stdout_alias(self) -> None:\n        self.set_environ(\"COVERAGE_DEBUG_FILE\", \"stdout\")\n        self.debug_sys()\n        out, err = self.stdouterr()\n        assert \"\" == err\n        assert_good_debug_sys(out)\n\n\nclass DebugControlTest(CoverageTest):\n    \"\"\"Tests of DebugControl (via DebugControlString).\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_debug_control(self) -> None:\n        debug = DebugControlString([\"yes\"])\n        assert debug.should(\"yes\")\n        debug.write(\"YES\")\n        assert not debug.should(\"no\")\n        assert \"YES\\n\" == debug.get_output()\n\n    def test_debug_write_exceptions(self) -> None:\n        debug = DebugControlString([\"yes\"])\n        try:\n            raise RuntimeError('Oops') # This is in the traceback\n        except Exception as exc:\n            debug.write(\"Something happened\", exc=exc)\n        lines = debug.get_output().splitlines()\n        assert \"Something happened\" == lines[0]\n        assert \"Traceback (most recent call last):\" == lines[1]\n        assert \"    raise RuntimeError('Oops') # This is in the traceback\" in lines\n        assert \"RuntimeError: Oops\" == lines[-1]\n\n    def test_debug_write_self(self) -> None:\n        class DebugWritingClass:\n            \"\"\"A simple class to show 'self:' debug messages.\"\"\"\n            def __init__(self, debug: DebugControl) -> None:\n                # This line will have \"self:\" reported.\n                debug.write(\"Hello from me\")\n\n            def __repr__(self) -> str:\n                return \"<<DebugWritingClass object!>>\"\n\n        def run_some(debug: DebugControl) -> None:\n            # This line will have no \"self:\" because there's no local self.\n            debug.write(\"In run_some\")\n            DebugWritingClass(debug)\n\n        debug = DebugControlString([\"self\"])\n        run_some(debug)\n        lines = debug.get_output().splitlines()\n        assert lines == [\n            \"In run_some\",\n            \"Hello from me\",\n            \"self: <<DebugWritingClass object!>>\",\n        ]\n\n\ndef f_one(*args: Any, **kwargs: Any) -> str:\n    \"\"\"First of the chain of functions for testing `short_stack`.\"\"\"\n    return f_two(*args, **kwargs)\n\ndef f_two(*args: Any, **kwargs: Any) -> str:\n    \"\"\"Second of the chain of functions for testing `short_stack`.\"\"\"\n    return f_three(*args, **kwargs)\n\ndef f_three(*args: Any, **kwargs: Any) -> str:\n    \"\"\"Third of the chain of functions for testing `short_stack`.\"\"\"\n    return short_stack(*args, **kwargs)\n\n\nclass ShortStackTest(CoverageTest):\n    \"\"\"Tests of coverage.debug.short_stack.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_short_stack(self) -> None:\n        stack = f_one().splitlines()\n        assert 4 == len(stack)\n        assert \"test_short_stack\" in stack[0]\n        assert \"f_one\" in stack[1]\n        assert \"f_two\" in stack[2]\n        assert \"f_three\" in stack[3]\n\n    def test_short_stack_skip(self) -> None:\n        stack = f_one(skip=1).splitlines()\n        assert 3 == len(stack)\n        assert \"test_short_stack\" in stack[0]\n        assert \"f_one\" in stack[1]\n        assert \"f_two\" in stack[2]\n\n    def test_short_stack_full(self) -> None:\n        stack_text = f_one(full=True)\n        s = re.escape(os.sep)\n        if env.WINDOWS:\n            pylib = \"[Ll]ib\"\n        else:\n            py = \"pypy\" if env.PYPY else \"python\"\n            majv, minv = sys.version_info[:2]\n            pylib = f\"lib{s}{py}{majv}.{minv}\"\n        assert len(re_lines(fr\"{s}{pylib}{s}site-packages{s}_pytest\", stack_text)) > 3\n        assert len(re_lines(fr\"{s}{pylib}{s}site-packages{s}pluggy\", stack_text)) > 3\n        assert not re_lines(r\" 0x[0-9a-fA-F]+\", stack_text) # No frame ids\n        stack = stack_text.splitlines()\n        assert len(stack) > 25\n        assert \"test_short_stack\" in stack[-4]\n        assert \"f_one\" in stack[-3]\n        assert \"f_two\" in stack[-2]\n        assert \"f_three\" in stack[-1]\n\n    def test_short_stack_short_filenames(self) -> None:\n        stack_text = f_one(full=True, short_filenames=True)\n        s = re.escape(os.sep)\n        assert not re_lines(r\"site-packages\", stack_text)\n        assert len(re_lines(fr\"syspath:{s}_pytest\", stack_text)) > 3\n        assert len(re_lines(fr\"syspath:{s}pluggy\", stack_text)) > 3\n\n    def test_short_stack_frame_ids(self) -> None:\n        stack = f_one(full=True, frame_ids=True).splitlines()\n        assert len(stack) > 25\n        frame_ids = [m[0] for line in stack if (m := re.search(r\" 0x[0-9a-fA-F]{6,}\", line))]\n        # Every line has a frame id.\n        assert len(frame_ids) == len(stack)\n        # All the frame ids are different.\n        assert len(set(frame_ids)) == len(frame_ids)\n\n\nclass ShortFilenameTest(CoverageTest):\n    \"\"\"Tests of debug.py:short_filename.\"\"\"\n\n    def test_short_filename(self) -> None:\n        s = os.sep\n        se = re.escape(s)\n        assert short_filename(ast.__file__) == f\"syspath:{s}ast.py\"\n        assert short_filename(pytest.__file__) == f\"syspath:{s}pytest{s}__init__.py\"\n        assert short_filename(env.__file__) == f\"cov:{s}env.py\"\n        self.make_file(\"hello.txt\", \"hi\")\n        short_hello = short_filename(os.path.abspath(\"hello.txt\"))\n        assert re.match(fr\"tmp:{se}t\\d+{se}hello.txt\", short_hello)\n        oddball = f\"{s}xyzzy{s}plugh{s}foo.txt\"\n        assert short_filename(oddball) == oddball\n        assert short_filename(None) is None\n\n\ndef test_relevant_environment_display() -> None:\n    env_vars = {\n        \"HOME\": \"my home\",\n        \"HOME_DIR\": \"other place\",\n        \"XYZ_NEVER_MIND\": \"doesn't matter\",\n        \"SOME_PYOTHER\": \"xyz123\",\n        \"COVERAGE_THING\": \"abcd\",\n        \"MY_PYPI_TOKEN\": \"secret.something\",\n        \"TMP\": \"temporary\",\n    }\n    expected = [\n        (\"COVERAGE_THING\", \"abcd\"),\n        (\"HOME\", \"my home\"),\n        (\"MY_PYPI_TOKEN\", \"******.*********\"),\n        (\"SOME_PYOTHER\", \"xyz123\"),\n        (\"TMP\", \"temporary\"),\n    ]\n    assert expected == relevant_environment_display(env_vars)\n\n\ndef test_exc_one_line() -> None:\n    try:\n        raise DataError(\"wtf?\")\n    except Exception as exc:\n        assert \"coverage.exceptions.DataError: wtf?\" == exc_one_line(exc)\n\n\ndef test_auto_repr() -> None:\n    class MyStuff:\n        \"\"\"Random class to test auto_repr.\"\"\"\n        def __init__(self) -> None:\n            self.x = 17\n            self.y = \"hello\"\n        __repr__ = auto_repr\n    stuff = MyStuff()\n    setattr(stuff, \"$coverage.object_id\", 123456)\n    assert re.match(r\"<MyStuff @0x[a-f\\d]+ x=17 y='hello'>\", repr(stuff))\n", "tests/osinfo.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"OS information for testing.\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\n\n\nif sys.platform == \"win32\":\n    # Windows implementation\n    def process_ram() -> int:\n        \"\"\"How much RAM is this process using? (Windows)\"\"\"\n        import ctypes\n        from ctypes import wintypes\n        # From: http://lists.ubuntu.com/archives/bazaar-commits/2009-February/011990.html\n        # Updated from: https://stackoverflow.com/a/16204942/14343\n        class PROCESS_MEMORY_COUNTERS_EX(ctypes.Structure):\n            \"\"\"Used by GetProcessMemoryInfo\"\"\"\n            _fields_ = [\n                ('cb', wintypes.DWORD),\n                ('PageFaultCount', wintypes.DWORD),\n                ('PeakWorkingSetSize', ctypes.c_size_t),\n                ('WorkingSetSize', ctypes.c_size_t),\n                ('QuotaPeakPagedPoolUsage', ctypes.c_size_t),\n                ('QuotaPagedPoolUsage', ctypes.c_size_t),\n                ('QuotaPeakNonPagedPoolUsage', ctypes.c_size_t),\n                ('QuotaNonPagedPoolUsage', ctypes.c_size_t),\n                ('PagefileUsage', ctypes.c_size_t),\n                ('PeakPagefileUsage', ctypes.c_size_t),\n                ('PrivateUsage', ctypes.c_size_t),\n            ]\n\n        GetProcessMemoryInfo = ctypes.windll.psapi.GetProcessMemoryInfo\n        GetProcessMemoryInfo.argtypes = [\n            wintypes.HANDLE,\n            ctypes.POINTER(PROCESS_MEMORY_COUNTERS_EX),\n            wintypes.DWORD,\n        ]\n        GetProcessMemoryInfo.restype = wintypes.BOOL\n\n        GetCurrentProcess = ctypes.windll.kernel32.GetCurrentProcess\n        GetCurrentProcess.argtypes = []\n        GetCurrentProcess.restype = wintypes.HANDLE\n\n        counters = PROCESS_MEMORY_COUNTERS_EX()\n        ret = GetProcessMemoryInfo(\n            GetCurrentProcess(),\n            ctypes.byref(counters),\n            ctypes.sizeof(counters),\n        )\n        if not ret:                 # pragma: part covered\n            return 0                # pragma: cant happen\n        return counters.PrivateUsage\n\nelif sys.platform.startswith(\"linux\"):\n    # Linux implementation\n    import os\n\n    _scale = {'kb': 1024, 'mb': 1024*1024}\n\n    def _VmB(key: str) -> int:\n        \"\"\"Read the /proc/PID/status file to find memory use.\"\"\"\n        try:\n            # Get pseudo file /proc/<pid>/status\n            with open(f\"/proc/{os.getpid()}/status\") as t:\n                v = t.read()\n        except OSError:             # pragma: cant happen\n            return 0    # non-Linux?\n        # Get VmKey line e.g. 'VmRSS:  9999  kB\\n ...'\n        i = v.index(key)\n        vp = v[i:].split(None, 3)\n        if len(vp) < 3:             # pragma: part covered\n            return 0                # pragma: cant happen\n        # Convert Vm value to bytes.\n        return int(float(vp[1]) * _scale[vp[2].lower()])\n\n    def process_ram() -> int:\n        \"\"\"How much RAM is this process using? (Linux implementation)\"\"\"\n        return _VmB('VmRSS')\n\nelse:\n    # Generic implementation.\n    def process_ram() -> int:\n        \"\"\"How much RAM is this process using? (stdlib implementation)\"\"\"\n        import resource\n        return resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n", "tests/test_setup.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests of miscellaneous stuff.\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\n\nfrom typing import List, cast\n\nimport pytest\n\nimport coverage\nfrom coverage import env\n\nfrom tests.coveragetest import CoverageTest\n\n\nclass SetupPyTest(CoverageTest):\n    \"\"\"Tests of setup.py\"\"\"\n\n    run_in_temp_dir = False\n\n    def setUp(self) -> None:\n        super().setUp()\n        # Force the most restrictive interpretation.\n        self.set_environ('LC_ALL', 'C')\n\n    def test_metadata(self) -> None:\n        status, output = self.run_command_status(\n            \"python setup.py --description --version --url --author\",\n        )\n        assert status == 0\n        out = output.splitlines()\n        assert \"measurement\" in out[0]\n        assert coverage.__version__ == out[1]\n        assert \"github.com/nedbat/coveragepy\" in out[2]\n        assert \"Ned Batchelder\" in out[3]\n\n    @pytest.mark.skipif(\n        env.PYVERSION[3:5] == (\"alpha\", 0),\n        reason=\"don't expect classifiers until labelled builds\",\n    )\n    def test_more_metadata(self) -> None:\n        # Let's be sure we pick up our own setup.py\n        # CoverageTest restores the original sys.path for us.\n        sys.path.insert(0, '')\n        from setup import setup_args\n\n        classifiers = cast(List[str], setup_args['classifiers'])\n        assert len(classifiers) > 7\n        assert classifiers[-1].startswith(\"Development Status ::\")\n        assert \"Programming Language :: Python :: %d\" % sys.version_info[:1] in classifiers\n        assert \"Programming Language :: Python :: %d.%d\" % sys.version_info[:2] in classifiers\n\n        long_description = cast(str, setup_args['long_description']).splitlines()\n        assert len(long_description) > 7\n        assert long_description[0].strip() != \"\"\n        assert long_description[-1].strip() != \"\"\n", "tests/test_testing.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests that our test infrastructure is really working!\"\"\"\n\nfrom __future__ import annotations\n\nimport datetime\nimport os\nimport re\nimport sys\nimport warnings\n\n\nimport pytest\n\nimport coverage\nfrom coverage.exceptions import CoverageWarning\nfrom coverage.files import actual_path\nfrom coverage.types import TArc\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import (\n    CheckUniqueFilenames, FailingProxy,\n    arcs_to_arcz_repr, arcz_to_arcs, assert_count_equal, assert_coverage_warnings,\n    re_lines, re_lines_text, re_line,\n)\n\n\ndef test_xdist_sys_path_nuttiness_is_fixed() -> None:\n    # See conftest.py:fix_xdist_sys_path\n    assert sys.path[1] != \"\"\n    assert os.getenv(\"PYTHONPATH\") is None\n\n\ndef test_assert_count_equal() -> None:\n    assert_count_equal(set(), set())\n    assert_count_equal({\"a\": 1, \"b\": 2}, [\"b\", \"a\"])\n    with pytest.raises(AssertionError):\n        assert_count_equal({1,2,3}, set())\n    with pytest.raises(AssertionError):\n        assert_count_equal({1,2,3}, {4,5,6})\n\n\nclass CoverageTestTest(CoverageTest):\n    \"\"\"Test the methods in `CoverageTest`.\"\"\"\n\n    def test_file_exists(self) -> None:\n        self.make_file(\"whoville.txt\", \"We are here!\")\n        self.assert_exists(\"whoville.txt\")\n        self.assert_doesnt_exist(\"shadow.txt\")\n        msg = \"File 'whoville.txt' shouldn't exist\"\n        with pytest.raises(AssertionError, match=msg):\n            self.assert_doesnt_exist(\"whoville.txt\")\n        msg = \"File 'shadow.txt' should exist\"\n        with pytest.raises(AssertionError, match=msg):\n            self.assert_exists(\"shadow.txt\")\n\n    def test_file_count(self) -> None:\n        self.make_file(\"abcde.txt\", \"abcde\")\n        self.make_file(\"axczz.txt\", \"axczz\")\n        self.make_file(\"afile.txt\", \"afile\")\n        self.assert_file_count(\"a*.txt\", 3)\n        self.assert_file_count(\"*c*.txt\", 2)\n        self.assert_file_count(\"afile.*\", 1)\n        self.assert_file_count(\"*.q\", 0)\n        msg = re.escape(\n            \"There should be 13 files matching 'a*.txt', but there are these: \" +\n            \"['abcde.txt', 'afile.txt', 'axczz.txt']\",\n        )\n        with pytest.raises(AssertionError, match=msg):\n            self.assert_file_count(\"a*.txt\", 13)\n        msg = re.escape(\n            \"There should be 12 files matching '*c*.txt', but there are these: \" +\n            \"['abcde.txt', 'axczz.txt']\",\n        )\n        with pytest.raises(AssertionError, match=msg):\n            self.assert_file_count(\"*c*.txt\", 12)\n        msg = re.escape(\n            \"There should be 11 files matching 'afile.*', but there are these: ['afile.txt']\",\n        )\n        with pytest.raises(AssertionError, match=msg):\n            self.assert_file_count(\"afile.*\", 11)\n        msg = re.escape(\n            \"There should be 10 files matching '*.q', but there are these: []\",\n        )\n        with pytest.raises(AssertionError, match=msg):\n            self.assert_file_count(\"*.q\", 10)\n\n    def test_assert_recent_datetime(self) -> None:\n        def now_delta(seconds: int) -> datetime.datetime:\n            \"\"\"Make a datetime `seconds` seconds from now.\"\"\"\n            return datetime.datetime.now() + datetime.timedelta(seconds=seconds)\n\n        # Default delta is 10 seconds.\n        self.assert_recent_datetime(now_delta(0))\n        self.assert_recent_datetime(now_delta(-9))\n        with pytest.raises(AssertionError):\n            self.assert_recent_datetime(now_delta(-11))\n        with pytest.raises(AssertionError):\n            self.assert_recent_datetime(now_delta(1))\n\n        # Delta is settable.\n        self.assert_recent_datetime(now_delta(0), seconds=120)\n        self.assert_recent_datetime(now_delta(-100), seconds=120)\n        with pytest.raises(AssertionError):\n            self.assert_recent_datetime(now_delta(-1000), seconds=120)\n        with pytest.raises(AssertionError):\n            self.assert_recent_datetime(now_delta(1), seconds=120)\n\n    def test_assert_warnings(self) -> None:\n        cov = coverage.Coverage()\n\n        # Make a warning, it should catch it properly.\n        with self.assert_warnings(cov, [\"Hello there!\"]):\n            cov._warn(\"Hello there!\")\n\n        # The expected warnings are regexes.\n        with self.assert_warnings(cov, [\"Hello.*!\"]):\n            cov._warn(\"Hello there!\")\n\n        # There can be a bunch of actual warnings.\n        with self.assert_warnings(cov, [\"Hello.*!\"]):\n            cov._warn(\"You there?\")\n            cov._warn(\"Hello there!\")\n\n        # There can be a bunch of expected warnings.\n        with self.assert_warnings(cov, [\"Hello.*!\", \"You\"]):\n            cov._warn(\"You there?\")\n            cov._warn(\"Hello there!\")\n\n        # But if there are a bunch of expected warnings, they have to all happen.\n        warn_regex = r\"Didn't find warning 'You' in \\['Hello there!'\\]\"\n        with pytest.raises(AssertionError, match=warn_regex):\n            with self.assert_warnings(cov, [\"Hello.*!\", \"You\"]):\n                cov._warn(\"Hello there!\")\n\n        # Make a different warning than expected, it should raise an assertion.\n        warn_regex = r\"Didn't find warning 'Not me' in \\['Hello there!'\\]\"\n        with pytest.raises(AssertionError, match=warn_regex):\n            with self.assert_warnings(cov, [\"Not me\"]):\n                cov._warn(\"Hello there!\")\n\n        # Try checking a warning that shouldn't appear: happy case.\n        with self.assert_warnings(cov, [\"Hi\"], not_warnings=[\"Bye\"]):\n            cov._warn(\"Hi\")\n\n        # But it should fail if the unexpected warning does appear.\n        warn_regex = r\"Found warning 'Bye' in \\['Hi', 'Bye'\\]\"\n        with pytest.raises(AssertionError, match=warn_regex):\n            with self.assert_warnings(cov, [\"Hi\"], not_warnings=[\"Bye\"]):\n                cov._warn(\"Hi\")\n                cov._warn(\"Bye\")\n\n        # assert_warnings shouldn't hide a real exception.\n        with pytest.raises(ZeroDivisionError, match=\"oops\"):\n            with self.assert_warnings(cov, [\"Hello there!\"]):\n                raise ZeroDivisionError(\"oops\")\n\n    def test_assert_no_warnings(self) -> None:\n        cov = coverage.Coverage()\n\n        # Happy path: no warnings.\n        with self.assert_warnings(cov, []):\n            pass\n\n        # If you said there would be no warnings, and there were, fail!\n        warn_regex = r\"Unexpected warnings: \\['Watch out!'\\]\"\n        with pytest.raises(AssertionError, match=warn_regex):\n            with self.assert_warnings(cov, []):\n                cov._warn(\"Watch out!\")\n\n    def test_sub_python_is_this_python(self) -> None:\n        # Try it with a Python command.\n        self.set_environ('COV_FOOBAR', 'XYZZY')\n        self.make_file(\"showme.py\", \"\"\"\\\n            import os, sys\n            print(sys.executable)\n            print(os.__file__)\n            print(os.environ['COV_FOOBAR'])\n            \"\"\")\n        out_lines = self.run_command(\"python showme.py\").splitlines()\n        assert actual_path(out_lines[0]) == actual_path(sys.executable)\n        assert out_lines[1] == os.__file__\n        assert out_lines[2] == 'XYZZY'\n\n        # Try it with a \"coverage debug sys\" command.\n        out = self.run_command(\"coverage debug sys\")\n\n        executable = re_line(\"executable:\", out)\n        executable = executable.split(\":\", 1)[1].strip()\n        assert _same_python_executable(executable, sys.executable)\n\n        # \"environment: COV_FOOBAR = XYZZY\" or \"COV_FOOBAR = XYZZY\"\n        environ = re_line(\"COV_FOOBAR\", out)\n        _, _, environ = environ.rpartition(\":\")\n        assert environ.strip() == \"COV_FOOBAR = XYZZY\"\n\n    def test_run_command_stdout_stderr(self) -> None:\n        # run_command should give us both stdout and stderr.\n        self.make_file(\"outputs.py\", \"\"\"\\\n            import sys\n            sys.stderr.write(\"StdErr\\\\n\")\n            print(\"StdOut\")\n            \"\"\")\n        out = self.run_command(\"python outputs.py\")\n        assert \"StdOut\\n\" in out\n        assert \"StdErr\\n\" in out\n\n    def test_stdout(self) -> None:\n        # stdout is captured.\n        print(\"This is stdout\")\n        print(\"Line 2\")\n        assert self.stdout() == \"This is stdout\\nLine 2\\n\"\n        # When we grab stdout(), it's reset.\n        print(\"Some more\")\n        assert self.stdout() == \"Some more\\n\"\n\n\nclass CheckUniqueFilenamesTest(CoverageTest):\n    \"\"\"Tests of CheckUniqueFilenames.\"\"\"\n\n    run_in_temp_dir = False\n\n    class Stub:\n        \"\"\"A stand-in for the class we're checking.\"\"\"\n        def __init__(self, x: int) -> None:\n            self.x = x\n\n        def method(\n            self,\n            filename: str,\n            a: int = 17,\n            b: str = \"hello\",\n        ) -> tuple[int, str, int, str]:\n            \"\"\"The method we'll wrap, with args to be sure args work.\"\"\"\n            return (self.x, filename, a, b)\n\n    def test_detect_duplicate(self) -> None:\n        stub = self.Stub(23)\n        CheckUniqueFilenames.hook(stub, \"method\")\n\n        # Two method calls with different names are fine.\n        assert stub.method(\"file1\") == (23, \"file1\", 17, \"hello\")\n        assert stub.method(\"file2\", 1723, b=\"what\") == (23, \"file2\", 1723, \"what\")\n\n        # A duplicate file name trips an assertion.\n        with pytest.raises(AssertionError):\n            stub.method(\"file1\")\n\n\nclass CheckCoverageTest(CoverageTest):\n    \"\"\"Tests of the failure assertions in check_coverage.\"\"\"\n\n    CODE = \"\"\"\\\n        a, b = 1, 1\n        def oops(x):\n            if x % 2:\n                raise Exception(\"odd\")\n        try:\n            a = 6\n            oops(1)\n            a = 8\n        except:\n            b = 10\n        assert a == 6 and b == 10\n        \"\"\"\n    ARCZ = \".1 12 -23 34 3-2 4-2 25 56 67 78 8B 9A AB B.\"\n    ARCZ_MISSING = \"3-2 78 8B\"\n    ARCZ_UNPREDICTED = \"79\"\n\n    def test_check_coverage_possible(self) -> None:\n        msg = r\"(?s)Possible arcs differ: .*- \\(6, 3\\).*\\+ \\(6, 7\\)\"\n        with pytest.raises(AssertionError, match=msg):\n            self.check_coverage(\n                self.CODE,\n                arcz=self.ARCZ.replace(\"7\", \"3\"),\n                arcz_missing=self.ARCZ_MISSING,\n                arcz_unpredicted=self.ARCZ_UNPREDICTED,\n            )\n\n    def test_check_coverage_missing(self) -> None:\n        msg = r\"(?s)Missing arcs differ: .*- \\(3, 8\\).*\\+ \\(7, 8\\)\"\n        with pytest.raises(AssertionError, match=msg):\n            self.check_coverage(\n                self.CODE,\n                arcz=self.ARCZ,\n                arcz_missing=self.ARCZ_MISSING.replace(\"7\", \"3\"),\n                arcz_unpredicted=self.ARCZ_UNPREDICTED,\n            )\n\n    def test_check_coverage_unpredicted(self) -> None:\n        msg = r\"(?s)Unpredicted arcs differ: .*- \\(3, 9\\).*\\+ \\(7, 9\\)\"\n        with pytest.raises(AssertionError, match=msg):\n            self.check_coverage(\n                self.CODE,\n                arcz=self.ARCZ,\n                arcz_missing=self.ARCZ_MISSING,\n                arcz_unpredicted=self.ARCZ_UNPREDICTED.replace(\"7\", \"3\"),\n            )\n\n\nclass ReLinesTest(CoverageTest):\n    \"\"\"Tests of `re_lines`.\"\"\"\n\n    run_in_temp_dir = False\n\n    @pytest.mark.parametrize(\"pat, text, result\", [\n        (\"line\", \"line1\\nline2\\nline3\\n\", \"line1\\nline2\\nline3\\n\"),\n        (\"[13]\", \"line1\\nline2\\nline3\\n\", \"line1\\nline3\\n\"),\n        (\"X\", \"line1\\nline2\\nline3\\n\", \"\"),\n    ])\n    def test_re_lines(self, pat: str, text: str, result: str) -> None:\n        assert re_lines_text(pat, text) == result\n        assert re_lines(pat, text) == result.splitlines()\n\n    @pytest.mark.parametrize(\"pat, text, result\", [\n        (\"line\", \"line1\\nline2\\nline3\\n\", \"\"),\n        (\"[13]\", \"line1\\nline2\\nline3\\n\", \"line2\\n\"),\n        (\"X\", \"line1\\nline2\\nline3\\n\", \"line1\\nline2\\nline3\\n\"),\n    ])\n    def test_re_lines_inverted(self, pat: str, text: str, result: str) -> None:\n        assert re_lines_text(pat, text, match=False) == result\n        assert re_lines(pat, text, match=False) == result.splitlines()\n\n    @pytest.mark.parametrize(\"pat, text, result\", [\n        (\"2\", \"line1\\nline2\\nline3\\n\", \"line2\"),\n    ])\n    def test_re_line(self, pat: str, text: str, result: str) -> None:\n        assert re_line(pat, text) == result\n\n    @pytest.mark.parametrize(\"pat, text\", [\n        (\"line\", \"line1\\nline2\\nline3\\n\"),      # too many matches\n        (\"X\", \"line1\\nline2\\nline3\\n\"),         # no matches\n    ])\n    def test_re_line_bad(self, pat: str, text: str) -> None:\n        with pytest.raises(AssertionError):\n            re_line(pat, text)\n\n\ndef _same_python_executable(e1: str, e2: str) -> bool:\n    \"\"\"Determine if `e1` and `e2` refer to the same Python executable.\n\n    Either path could include symbolic links.  The two paths might not refer\n    to the exact same file, but if they are in the same directory and their\n    numeric suffixes aren't different, they are the same executable.\n\n    \"\"\"\n    e1 = os.path.abspath(os.path.realpath(e1))\n    e2 = os.path.abspath(os.path.realpath(e2))\n\n    if os.path.dirname(e1) != os.path.dirname(e2):\n        return False                                    # pragma: only failure\n\n    e1 = os.path.basename(e1)\n    e2 = os.path.basename(e2)\n\n    if e1 == \"python\" or e2 == \"python\" or e1 == e2:\n        # Python and Python2.3: OK\n        # Python2.3 and Python: OK\n        # Python and Python: OK\n        # Python2.3 and Python2.3: OK\n        return True\n\n    return False                                        # pragma: only failure\n\n\nclass ArczTest(CoverageTest):\n    \"\"\"Tests of arcz/arcs helpers.\"\"\"\n\n    run_in_temp_dir = False\n\n    @pytest.mark.parametrize(\"arcz, arcs\", [\n        (\".1 12 2.\", [(-1, 1), (1, 2), (2, -1)]),\n        (\"-11 12 2-5\", [(-1, 1), (1, 2), (2, -5)]),\n        (\"-QA CB IT Z-A\", [(-26, 10), (12, 11), (18, 29), (35, -10)]),\n    ])\n    def test_arcz_to_arcs(self, arcz: str, arcs: list[TArc]) -> None:\n        assert arcz_to_arcs(arcz) == arcs\n\n    @pytest.mark.parametrize(\"arcs, arcz_repr\", [\n        ([(-1, 1), (1, 2), (2, -1)], \"(-1, 1) # .1\\n(1, 2) # 12\\n(2, -1) # 2.\\n\"),\n        ([(-1, 1), (1, 2), (2, -5)], \"(-1, 1) # .1\\n(1, 2) # 12\\n(2, -5) # 2-5\\n\"),\n        ([(-26, 10), (12, 11), (18, 29), (35, -10), (1, 33), (100, 7)],\n            (\n            \"(-26, 10) # -QA\\n\" +\n            \"(12, 11) # CB\\n\" +\n            \"(18, 29) # IT\\n\" +\n            \"(35, -10) # Z-A\\n\" +\n            \"(1, 33) # 1X\\n\" +\n            \"(100, 7) # ?7\\n\"\n            ),\n        ),\n    ])\n    def test_arcs_to_arcz_repr(self, arcs: list[TArc], arcz_repr: str) -> None:\n        assert arcs_to_arcz_repr(arcs) == arcz_repr\n\n\nclass AssertCoverageWarningsTest(CoverageTest):\n    \"\"\"Tests of assert_coverage_warnings\"\"\"\n\n    def test_one_warning(self) -> None:\n        with pytest.warns(Warning) as warns:\n            warnings.warn(\"Hello there\", category=CoverageWarning)\n        assert_coverage_warnings(warns, \"Hello there\")\n\n    def test_many_warnings(self) -> None:\n        with pytest.warns(Warning) as warns:\n            warnings.warn(\"The first\", category=CoverageWarning)\n            warnings.warn(\"The second\", category=CoverageWarning)\n            warnings.warn(\"The third\", category=CoverageWarning)\n        assert_coverage_warnings(warns, \"The first\", \"The second\", \"The third\")\n\n    def test_wrong_type(self) -> None:\n        with pytest.warns(Warning) as warns:\n            warnings.warn(\"Not ours\", category=Warning)\n        with pytest.raises(AssertionError):\n            assert_coverage_warnings(warns, \"Not ours\")\n\n    def test_wrong_message(self) -> None:\n        with pytest.warns(Warning) as warns:\n            warnings.warn(\"Goodbye\", category=CoverageWarning)\n        with pytest.raises(AssertionError):\n            assert_coverage_warnings(warns, \"Hello there\")\n\n    def test_wrong_number_too_many(self) -> None:\n        with pytest.warns(Warning) as warns:\n            warnings.warn(\"The first\", category=CoverageWarning)\n            warnings.warn(\"The second\", category=CoverageWarning)\n        with pytest.raises(AssertionError):\n            assert_coverage_warnings(warns, \"The first\", \"The second\", \"The third\")\n\n    def test_wrong_number_too_few(self) -> None:\n        with pytest.warns(Warning) as warns:\n            warnings.warn(\"The first\", category=CoverageWarning)\n            warnings.warn(\"The second\", category=CoverageWarning)\n            warnings.warn(\"The third\", category=CoverageWarning)\n        with pytest.raises(AssertionError):\n            assert_coverage_warnings(warns, \"The first\", \"The second\")\n\n    def test_regex_matches(self) -> None:\n        with pytest.warns(Warning) as warns:\n            warnings.warn(\"The first\", category=CoverageWarning)\n        assert_coverage_warnings(warns, re.compile(\"f?rst\"))\n\n    def test_regex_doesnt_match(self) -> None:\n        with pytest.warns(Warning) as warns:\n            warnings.warn(\"The first\", category=CoverageWarning)\n        with pytest.raises(AssertionError):\n            assert_coverage_warnings(warns, re.compile(\"second\"))\n\n\ndef test_failing_proxy() -> None:\n    class Arithmetic:\n        \"\"\"Sample class to test FailingProxy.\"\"\"\n        # pylint: disable=missing-function-docstring\n        def add(self, a, b):                    # type: ignore[no-untyped-def]\n            return a + b\n\n        def subtract(self, a, b):               # type: ignore[no-untyped-def]\n            return a - b\n\n    proxy = FailingProxy(Arithmetic(), \"add\", [RuntimeError(\"First\"), RuntimeError(\"Second\")])\n    # add fails the first time\n    with pytest.raises(RuntimeError, match=\"First\"):\n        proxy.add(1, 2)\n    # subtract always works\n    assert proxy.subtract(10, 3) == 7\n    # add fails the second time\n    with pytest.raises(RuntimeError, match=\"Second\"):\n        proxy.add(3, 4)\n    # then add starts working\n    assert proxy.add(5, 6) == 11\n", "tests/helpers.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Helpers for coverage.py tests.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport contextlib\nimport dis\nimport io\nimport locale\nimport os\nimport os.path\nimport re\nimport shutil\nimport subprocess\nimport textwrap\nimport warnings\n\nfrom pathlib import Path\nfrom typing import (\n    Any, Callable, Iterable, Iterator, NoReturn, TypeVar, cast,\n)\n\nimport flaky\nimport pytest\n\nfrom coverage import env\nfrom coverage.debug import DebugControl\nfrom coverage.exceptions import CoverageWarning\nfrom coverage.types import TArc, TLineNo\n\n\ndef run_command(cmd: str) -> tuple[int, str]:\n    \"\"\"Run a command in a sub-process.\n\n    Returns the exit status code and the combined stdout and stderr.\n\n    \"\"\"\n    # Subprocesses are expensive, but convenient, and so may be over-used in\n    # the test suite.  Use these lines to get a list of the tests using them:\n    if 0:  # pragma: debugging\n        with open(\"/tmp/processes.txt\", \"a\") as proctxt:  # type: ignore[unreachable]\n            print(os.getenv(\"PYTEST_CURRENT_TEST\", \"unknown\"), file=proctxt, flush=True)\n\n    encoding = os.device_encoding(1) or locale.getpreferredencoding()\n\n    # In some strange cases (PyPy3 in a virtualenv!?) the stdout encoding of\n    # the subprocess is set incorrectly to ascii.  Use an environment variable\n    # to force the encoding to be the same as ours.\n    sub_env = dict(os.environ)\n    sub_env['PYTHONIOENCODING'] = encoding\n\n    proc = subprocess.Popen(\n        cmd,\n        shell=True,\n        env=sub_env,\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n    )\n    output, _ = proc.communicate()\n    status = proc.returncode\n\n    # Get the output, and canonicalize it to strings with newlines.\n    output_str = output.decode(encoding).replace(\"\\r\", \"\")\n    return status, output_str\n\n\n# $set_env.py: COVERAGE_DIS - Disassemble test code to /tmp/dis\nSHOW_DIS = bool(int(os.getenv(\"COVERAGE_DIS\", \"0\")))\n\ndef make_file(\n    filename: str,\n    text: str = \"\",\n    bytes: bytes = b\"\",\n    newline: str | None = None,\n) -> str:\n    \"\"\"Create a file for testing.\n\n    `filename` is the relative path to the file, including directories if\n    desired, which will be created if need be.\n\n    `text` is the text content to create in the file, or `bytes` are the\n    bytes to write.\n\n    If `newline` is provided, it is a string that will be used as the line\n    endings in the created file, otherwise the line endings are as provided\n    in `text`.\n\n    Returns `filename`.\n\n    \"\"\"\n    # pylint: disable=redefined-builtin     # bytes\n    if bytes:\n        data = bytes\n    else:\n        text = textwrap.dedent(text)\n        if newline:\n            text = text.replace(\"\\n\", newline)\n        data = text.encode(\"utf-8\")\n\n    # Make sure the directories are available.\n    dirs, basename = os.path.split(filename)\n    if dirs:\n        os.makedirs(dirs, exist_ok=True)\n\n    # Create the file.\n    with open(filename, 'wb') as f:\n        f.write(data)\n\n    if text and basename.endswith(\".py\") and SHOW_DIS:      # pragma: debugging\n        os.makedirs(\"/tmp/dis\", exist_ok=True)\n        with open(f\"/tmp/dis/{basename}.dis\", \"w\") as fdis:\n            print(f\"# {os.path.abspath(filename)}\", file=fdis)\n            cur_test = os.getenv(\"PYTEST_CURRENT_TEST\", \"unknown\")\n            print(f\"# PYTEST_CURRENT_TEST = {cur_test}\", file=fdis)\n            kwargs = {}\n            if env.PYVERSION >= (3, 13):\n                kwargs[\"show_offsets\"] = True\n            try:\n                dis.dis(text, file=fdis, **kwargs)\n            except Exception as exc:\n                # Some tests make .py files that aren't Python, so dis will\n                # fail, which is expected.\n                print(f\"#! {exc!r}\", file=fdis)\n\n    # For debugging, enable this to show the contents of files created.\n    if 0:  # pragma: debugging\n        print(f\"   \u2500\u2500\u2500\u252c\u2500\u2500\u2524 {filename} \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\")  # type: ignore[unreachable]\n        for lineno, line in enumerate(data.splitlines(), start=1):\n            print(f\"{lineno:6}\u2502 {line.rstrip().decode()}\")\n        print()\n\n    return filename\n\n\ndef nice_file(*fparts: str) -> str:\n    \"\"\"Canonicalize the file name composed of the parts in `fparts`.\"\"\"\n    fname = os.path.join(*fparts)\n    return os.path.normcase(os.path.abspath(os.path.realpath(fname)))\n\n\ndef os_sep(s: str) -> str:\n    \"\"\"Replace slashes in `s` with the correct separator for the OS.\"\"\"\n    return s.replace(\"/\", os.sep)\n\n\nclass CheckUniqueFilenames:\n    \"\"\"Asserts the uniqueness of file names passed to a function.\"\"\"\n\n    def __init__(self, wrapped: Callable[..., Any]) -> None:\n        self.filenames: set[str] = set()\n        self.wrapped = wrapped\n\n    @classmethod\n    def hook(cls, obj: Any, method_name: str) -> CheckUniqueFilenames:\n        \"\"\"Replace a method with our checking wrapper.\n\n        The method must take a string as a first argument. That argument\n        will be checked for uniqueness across all the calls to this method.\n\n        The values don't have to be file names actually, just strings, but\n        we only use it for filename arguments.\n\n        \"\"\"\n        method = getattr(obj, method_name)\n        hook = cls(method)\n        setattr(obj, method_name, hook.wrapper)\n        return hook\n\n    def wrapper(self, filename: str, *args: Any, **kwargs: Any) -> Any:\n        \"\"\"The replacement method.  Check that we don't have dupes.\"\"\"\n        assert filename not in self.filenames, (\n            f\"File name {filename!r} passed to {self.wrapped!r} twice\"\n        )\n        self.filenames.add(filename)\n        return self.wrapped(filename, *args, **kwargs)\n\n\ndef re_lines(pat: str, text: str, match: bool = True) -> list[str]:\n    \"\"\"Return a list of lines selected by `pat` in the string `text`.\n\n    If `match` is false, the selection is inverted: only the non-matching\n    lines are included.\n\n    Returns a list, the selected lines, without line endings.\n\n    \"\"\"\n    assert len(pat) < 200, \"It's super-easy to swap the arguments to re_lines\"\n    return [l for l in text.splitlines() if bool(re.search(pat, l)) == match]\n\n\ndef re_lines_text(pat: str, text: str, match: bool = True) -> str:\n    \"\"\"Return the multi-line text of lines selected by `pat`.\"\"\"\n    return \"\".join(l + \"\\n\" for l in re_lines(pat, text, match=match))\n\n\ndef re_line(pat: str, text: str) -> str:\n    \"\"\"Return the one line in `text` that matches regex `pat`.\n\n    Raises an AssertionError if more than one, or less than one, line matches.\n\n    \"\"\"\n    lines = re_lines(pat, text)\n    assert len(lines) == 1\n    return lines[0]\n\n\ndef remove_tree(dirname: str) -> None:\n    \"\"\"Remove a directory tree.\n\n    It's fine for the directory to not exist in the first place.\n    \"\"\"\n    if os.path.exists(dirname):\n        shutil.rmtree(dirname)\n\n\n# Map chars to numbers for arcz_to_arcs\n_arcz_map = {'.': -1}\n_arcz_map.update({c: ord(c) - ord('0') for c in '123456789'})\n_arcz_map.update({c: 10 + ord(c) - ord('A') for c in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'})\n\n\ndef arcz_to_arcs(arcz: str) -> list[TArc]:\n    \"\"\"Convert a compact textual representation of arcs to a list of pairs.\n\n    The text has space-separated pairs of letters.  Period is -1, 1-9 are\n    1-9, A-Z are 10 through 36.  The resulting list is sorted regardless of\n    the order of the input pairs.\n\n    \".1 12 2.\" --> [(-1,1), (1,2), (2,-1)]\n\n    Minus signs can be included in the pairs:\n\n    \"-11, 12, 2-5\" --> [(-1,1), (1,2), (2,-5)]\n\n    \"\"\"\n    # The `type: ignore[misc]` here are to suppress \"Unpacking a string is\n    # disallowed\".\n    a: str\n    b: str\n    arcs = []\n    for pair in arcz.split():\n        asgn = bsgn = 1\n        if len(pair) == 2:\n            a, b = pair                 # type: ignore[misc]\n        else:\n            assert len(pair) == 3\n            if pair[0] == \"-\":\n                _, a, b = pair          # type: ignore[misc]\n                asgn = -1\n            else:\n                assert pair[1] == \"-\"\n                a, _, b = pair          # type: ignore[misc]\n                bsgn = -1\n        arcs.append((asgn * _arcz_map[a], bsgn * _arcz_map[b]))\n    return sorted(arcs)\n\n\n_arcz_unmap = {val: ch for ch, val in _arcz_map.items()}\n\n\ndef _arcs_to_arcz_repr_one(num: TLineNo) -> str:\n    \"\"\"Return an arcz form of the number `num`, or \"?\" if there is none.\"\"\"\n    if num == -1:\n        return \".\"\n    z = \"\"\n    if num < 0:\n        z += \"-\"\n        num *= -1\n    z += _arcz_unmap.get(num, \"?\")\n    return z\n\n\ndef arcs_to_arcz_repr(arcs: Iterable[TArc] | None) -> str:\n    \"\"\"Convert a list of arcs to a readable multi-line form for asserting.\n\n    Each pair is on its own line, with a comment showing the arcz form,\n    to make it easier to decode when debugging test failures.\n\n    \"\"\"\n    repr_list = []\n    for a, b in (arcs or ()):\n        line = repr((a, b))\n        line += \" # \"\n        line += _arcs_to_arcz_repr_one(a)\n        line += _arcs_to_arcz_repr_one(b)\n        repr_list.append(line)\n    return \"\\n\".join(repr_list) + \"\\n\"\n\n\n@contextlib.contextmanager\ndef change_dir(new_dir: str | Path) -> Iterator[None]:\n    \"\"\"Change directory, and then change back.\n\n    Use as a context manager, it will return to the original\n    directory at the end of the block.\n\n    \"\"\"\n    old_dir = os.getcwd()\n    os.chdir(str(new_dir))\n    try:\n        yield\n    finally:\n        os.chdir(old_dir)\n\nT = TypeVar(\"T\")\n\ndef assert_count_equal(\n    a: Iterable[T] | None,\n    b: Iterable[T] | None,\n) -> None:\n    \"\"\"\n    A pytest-friendly implementation of assertCountEqual.\n\n    Assert that `a` and `b` have the same elements, but maybe in different order.\n    This only works for hashable elements.\n    \"\"\"\n    assert a is not None\n    assert b is not None\n    assert collections.Counter(list(a)) == collections.Counter(list(b))\n\n\ndef assert_coverage_warnings(\n    warns: Iterable[warnings.WarningMessage],\n    *msgs: str | re.Pattern[str],\n) -> None:\n    \"\"\"\n    Assert that the CoverageWarning's in `warns` have `msgs` as messages.\n\n    Each msg can be a string compared for equality, or a compiled regex used to\n    search the text.\n    \"\"\"\n    assert msgs     # don't call this without some messages.\n    warns = [w for w in warns if issubclass(w.category, CoverageWarning)]\n    actuals = [cast(Warning, w.message).args[0] for w in warns]\n    assert len(msgs) == len(actuals)\n    for expected, actual in zip(msgs, actuals):\n        if hasattr(expected, \"search\"):\n            assert expected.search(actual), f\"{actual!r} didn't match {expected!r}\"\n        else:\n            assert expected == actual\n\n\n@contextlib.contextmanager\ndef swallow_warnings(\n    message: str = r\".\",\n    category: type[Warning] = CoverageWarning,\n) -> Iterator[None]:\n    \"\"\"Swallow particular warnings.\n\n    It's OK if they happen, or if they don't happen. Just ignore them.\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=category, message=message)\n        yield\n\n\nxfail_pypy38 = pytest.mark.xfail(\n    env.PYPY and env.PYVERSION[:2] == (3, 8) and env.PYPYVERSION < (7, 3, 11),\n    reason=\"These tests fail on older PyPy 3.8\",\n)\n\n\nclass FailingProxy:\n    \"\"\"A proxy for another object, but one method will fail a few times before working.\"\"\"\n    def __init__(self, obj: Any, methname: str, fails: list[Exception]) -> None:\n        \"\"\"Create the failing proxy.\n\n        `obj` is the object to proxy.  `methname` is the method that will fail\n        a few times.  `fails` are the exceptions to fail with. Once used up,\n        the method will proxy correctly.\n\n        \"\"\"\n        self.obj = obj\n        self.methname = methname\n        self.fails = fails\n\n    def __getattr__(self, name: str) -> Any:\n        if name == self.methname and self.fails:\n            meth = self._make_failing_method(self.fails[0])\n            del self.fails[0]\n        else:\n            meth = getattr(self.obj, name)\n        return meth\n\n    def _make_failing_method(self, exc: Exception) -> Callable[..., NoReturn]:\n        \"\"\"Return a function that will raise `exc`.\"\"\"\n        def _meth(*args: Any, **kwargs: Any) -> NoReturn:\n            raise exc\n        return _meth\n\n\nclass DebugControlString(DebugControl):\n    \"\"\"A `DebugControl` that writes to a StringIO, for testing.\"\"\"\n    def __init__(self, options: Iterable[str]) -> None:\n        self.io = io.StringIO()\n        super().__init__(options, self.io)\n\n    def get_output(self) -> str:\n        \"\"\"Get the output text from the `DebugControl`.\"\"\"\n        return self.io.getvalue()\n\n\nTestMethod = Callable[[Any], None]\n\ndef flaky_method(max_runs: int) -> Callable[[TestMethod], TestMethod]:\n    \"\"\"flaky.flaky, but with type annotations.\"\"\"\n    def _decorator(fn: TestMethod) -> TestMethod:\n        return cast(TestMethod, flaky.flaky(max_runs)(fn))\n    return _decorator\n", "tests/test_venv.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests about understanding how third-party code is installed.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport os.path\nimport shutil\n\nfrom pathlib import Path\nfrom typing import Iterator, cast\n\nimport pytest\n\nfrom coverage import env\n\nfrom tests import testenv\nfrom tests.coveragetest import CoverageTest, COVERAGE_INSTALL_ARGS\nfrom tests.helpers import change_dir, make_file\nfrom tests.helpers import re_lines, run_command\n\n\ndef run_in_venv(cmd: str) -> str:\n    r\"\"\"Run `cmd` in the virtualenv at `venv`.\n\n    The first word of the command will be adjusted to run it from the\n    venv/bin or venv\\Scripts directory.\n\n    Returns the text output of the command.\n    \"\"\"\n    words = cmd.split()\n    if env.WINDOWS:\n        words[0] = fr\"venv\\Scripts\\{words[0]}.exe\"\n    else:\n        words[0] = fr\"venv/bin/{words[0]}\"\n    status, output = run_command(\" \".join(words))\n    # Print the output so if it fails, we can tell what happened.\n    print(output)\n    assert status == 0\n    return output\n\n\n@pytest.fixture(scope=\"session\", name=\"venv_world\")\ndef venv_world_fixture(tmp_path_factory: pytest.TempPathFactory) -> Path:\n    \"\"\"Create a virtualenv with a few test packages for VirtualenvTest to use.\n\n    Returns the directory containing the \"venv\" virtualenv.\n    \"\"\"\n\n    venv_world = tmp_path_factory.mktemp(\"venv_world\")\n    with change_dir(venv_world):\n        # Create a virtualenv.\n        run_command(\"python -m venv venv\")\n\n        # A third-party package that installs a few different packages.\n        make_file(\"third_pkg/third/__init__.py\", \"\"\"\\\n            import fourth\n            def third(x):\n                return 3 * x\n            \"\"\")\n        # Use plugin2.py as third.plugin\n        with open(os.path.join(os.path.dirname(__file__), \"plugin2.py\")) as f:\n            make_file(\"third_pkg/third/plugin.py\", f.read())\n        # A render function for plugin2 to use for dynamic file names.\n        make_file(\"third_pkg/third/render.py\", \"\"\"\\\n            def render(filename, linenum):\n                return \"HTML: {}@{}\".format(filename, linenum)\n            \"\"\")\n        # Another package that third can use.\n        make_file(\"third_pkg/fourth/__init__.py\", \"\"\"\\\n            def fourth(x):\n                return 4 * x\n            \"\"\")\n        # Some namespace packages.\n        make_file(\"third_pkg/nspkg/fifth/__init__.py\", \"\"\"\\\n            def fifth(x):\n                return 5 * x\n            \"\"\")\n        # The setup.py to install everything.\n        make_file(\"third_pkg/setup.py\", \"\"\"\\\n            import setuptools\n            setuptools.setup(\n                name=\"third\",\n                packages=[\"third\", \"fourth\", \"nspkg.fifth\"],\n            )\n            \"\"\")\n\n        # Some namespace packages.\n        make_file(\"another_pkg/nspkg/sixth/__init__.py\", \"\"\"\\\n            def sixth(x):\n                return 6 * x\n            \"\"\")\n        make_file(\"another_pkg/setup.py\", \"\"\"\\\n            import setuptools\n            setuptools.setup(\n                name=\"another\",\n                packages=[\"nspkg.sixth\"],\n            )\n            \"\"\")\n\n        # Bug888 code.\n        make_file(\"bug888/app/setup.py\", \"\"\"\\\n            from setuptools import setup\n            setup(\n                name='testcov',\n                packages=['testcov'],\n            )\n            \"\"\")\n        # https://packaging.python.org/en/latest/guides/packaging-namespace-packages/#pkgutil-style-namespace-packages\n        make_file(\"bug888/app/testcov/__init__.py\", \"\"\"\\\n            __path__ = __import__('pkgutil').extend_path(__path__, __name__)\n            \"\"\")\n        if env.PYVERSION < (3, 10):\n            get_plugins = \"entry_points['plugins']\"\n        else:\n            get_plugins = \"entry_points.select(group='plugins')\"\n        make_file(\"bug888/app/testcov/main.py\", f\"\"\"\\\n            import importlib.metadata\n            entry_points = importlib.metadata.entry_points()\n            for entry_point in {get_plugins}:\n                entry_point.load()()\n            \"\"\")\n        make_file(\"bug888/plugin/setup.py\", \"\"\"\\\n            from setuptools import setup\n            setup(\n                name='testcov-plugin',\n                packages=['testcov'],\n                entry_points={'plugins': ['testp = testcov.plugin:testp']},\n            )\n            \"\"\")\n        # https://packaging.python.org/en/latest/guides/packaging-namespace-packages/#pkgutil-style-namespace-packages\n        make_file(\"bug888/plugin/testcov/__init__.py\", \"\"\"\\\n            __path__ = __import__('pkgutil').extend_path(__path__, __name__)\n            \"\"\")\n        make_file(\"bug888/plugin/testcov/plugin.py\", \"\"\"\\\n            def testp():\n                print(\"Plugin here\")\n            \"\"\")\n\n        # Install everything.\n        run_in_venv(\n            \"python -m pip install \" +\n            \"./third_pkg \" +\n            \"-e ./another_pkg \" +\n            \"-e ./bug888/app -e ./bug888/plugin \" +\n            COVERAGE_INSTALL_ARGS,\n        )\n        shutil.rmtree(\"third_pkg\")\n\n    return venv_world\n\n\n@pytest.fixture(params=[\n    \"coverage\",\n    \"python -m coverage\",\n], name=\"coverage_command\")\ndef coverage_command_fixture(request: pytest.FixtureRequest) -> str:\n    \"\"\"Parametrized fixture to use multiple forms of \"coverage\" command.\"\"\"\n    return cast(str, request.param)\n\n\nclass VirtualenvTest(CoverageTest):\n    \"\"\"Tests of virtualenv considerations.\"\"\"\n\n    expected_stdout = \"33\\n110\\n198\\n1.5\\n\"\n\n    @pytest.fixture(autouse=True)\n    def in_venv_world_fixture(self, venv_world: Path) -> Iterator[None]:\n        \"\"\"For running tests inside venv_world, and cleaning up made files.\"\"\"\n        with change_dir(venv_world):\n            self.make_file(\"myproduct.py\", \"\"\"\\\n                import colorsys\n                import third\n                import nspkg.fifth\n                import nspkg.sixth\n                print(third.third(11))\n                print(nspkg.fifth.fifth(22))\n                print(nspkg.sixth.sixth(33))\n                print(sum(colorsys.rgb_to_hls(1, 0, 0)))\n                \"\"\")\n\n            self.del_environ(\"COVERAGE_TESTING\")    # To get realistic behavior\n            self.set_environ(\"COVERAGE_DEBUG_FILE\", \"debug_out.txt\")\n            self.set_environ(\"COVERAGE_DEBUG\", \"trace\")\n\n            yield\n\n            for fname in os.listdir(\".\"):\n                if fname not in {\"venv\", \"another_pkg\", \"bug888\"}:\n                    os.remove(fname)\n\n    def get_trace_output(self) -> str:\n        \"\"\"Get the debug output of coverage.py\"\"\"\n        with open(\"debug_out.txt\") as f:\n            return f.read()\n\n    @pytest.mark.parametrize('install_source_in_venv', [True, False])\n    def test_third_party_venv_isnt_measured(\n        self, coverage_command: str, install_source_in_venv: bool,\n    ) -> None:\n        if install_source_in_venv:\n            make_file(\"setup.py\", \"\"\"\\\n                import setuptools\n                setuptools.setup(\n                    name=\"myproduct\",\n                    py_modules = [\"myproduct\"],\n                )\n                \"\"\")\n            try:\n                run_in_venv(\"python -m pip install .\")\n            finally:\n                shutil.rmtree(\"build\", ignore_errors=True)\n                shutil.rmtree(\"myproduct.egg-info\", ignore_errors=True)\n            # Ensure that coverage doesn't run the non-installed module.\n            os.remove('myproduct.py')\n            out = run_in_venv(coverage_command + \" run --source=.,myproduct -m myproduct\")\n        else:\n            out = run_in_venv(coverage_command + \" run --source=. myproduct.py\")\n        # In particular, this warning doesn't appear:\n        # Already imported a file that will be measured: .../coverage/__main__.py\n        assert out == self.expected_stdout\n\n        # Check that our tracing was accurate. Files are mentioned because\n        # --source refers to a file.\n        debug_out = self.get_trace_output()\n        assert re_lines(\n            r\"^Not tracing .*\\bexecfile.py': inside --source, but is third-party\",\n            debug_out,\n        )\n        assert re_lines(r\"^Tracing .*\\bmyproduct.py\", debug_out)\n        assert re_lines(\n            r\"^Not tracing .*\\bcolorsys.py': (module 'colorsys' |)?falls outside the --source spec\",\n            debug_out,\n        )\n\n        out = run_in_venv(coverage_command + \" report\")\n        assert \"myproduct.py\" in out\n        assert \"third\" not in out\n        assert \"coverage\" not in out\n        assert \"colorsys\" not in out\n\n    def test_us_in_venv_isnt_measured(self, coverage_command: str) -> None:\n        out = run_in_venv(coverage_command + \" run --source=third myproduct.py\")\n        assert out == self.expected_stdout\n\n        # Check that our tracing was accurate. Modules are mentioned because\n        # --source refers to a module.\n        debug_out = self.get_trace_output()\n        assert re_lines(\n            r\"^Not tracing .*\\bexecfile.py': \" +\n            \"module 'coverage.execfile' falls outside the --source spec\",\n            debug_out,\n        )\n        assert re_lines(\n            r\"^Not tracing .*\\bmyproduct.py': module 'myproduct' falls outside the --source spec\",\n            debug_out,\n        )\n        assert re_lines(\n            r\"^Not tracing .*\\bcolorsys.py': module 'colorsys' falls outside the --source spec\",\n            debug_out,\n        )\n\n        out = run_in_venv(coverage_command + \" report\")\n        assert \"myproduct.py\" not in out\n        assert \"third\" in out\n        assert \"coverage\" not in out\n        assert \"colorsys\" not in out\n\n    def test_venv_isnt_measured(self, coverage_command: str) -> None:\n        out = run_in_venv(coverage_command + \" run myproduct.py\")\n        assert out == self.expected_stdout\n\n        debug_out = self.get_trace_output()\n        assert re_lines(r\"^Not tracing .*\\bexecfile.py': is part of coverage.py\", debug_out)\n        assert re_lines(r\"^Tracing .*\\bmyproduct.py\", debug_out)\n        assert re_lines(r\"^Not tracing .*\\bcolorsys.py': is in the stdlib\", debug_out)\n\n        out = run_in_venv(coverage_command + \" report\")\n        assert \"myproduct.py\" in out\n        assert \"third\" not in out\n        assert \"coverage\" not in out\n        assert \"colorsys\" not in out\n\n    @pytest.mark.skipif(not testenv.C_TRACER, reason=\"No plugins with this core.\")\n    def test_venv_with_dynamic_plugin(self, coverage_command: str) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1150\n        # Django coverage plugin was incorrectly getting warnings:\n        # \"Already imported: ... django/template/blah.py\"\n        # It happened because coverage imported the plugin, which imported\n        # Django, and then the Django files were reported as traceable.\n        self.make_file(\".coveragerc\", \"[run]\\nplugins=third.plugin\\n\")\n        self.make_file(\"myrender.py\", \"\"\"\\\n            import third.render\n            print(third.render.render(\"hello.html\", 1723))\n            \"\"\")\n        out = run_in_venv(coverage_command + \" run --source=. myrender.py\")\n        # The output should not have this warning:\n        # Already imported a file that will be measured: ...third/render.py (already-imported)\n        assert out == \"HTML: hello.html@1723\\n\"\n\n    def test_installed_namespace_packages(self, coverage_command: str) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1231\n        # When namespace packages were installed, they were considered\n        # third-party packages.  Test that isn't still happening.\n        out = run_in_venv(coverage_command + \" run --source=nspkg myproduct.py\")\n        # In particular, this warning doesn't appear:\n        # Already imported a file that will be measured: .../coverage/__main__.py\n        assert out == self.expected_stdout\n\n        # Check that our tracing was accurate. Files are mentioned because\n        # --source refers to a file.\n        debug_out = self.get_trace_output()\n        assert re_lines(\n            r\"^Not tracing .*\\bexecfile.py': \" +\n            \"module 'coverage.execfile' falls outside the --source spec\",\n            debug_out,\n        )\n        assert re_lines(\n            r\"^Not tracing .*\\bmyproduct.py': module 'myproduct' falls outside the --source spec\",\n            debug_out,\n        )\n        assert re_lines(\n            r\"^Not tracing .*\\bcolorsys.py': module 'colorsys' falls outside the --source spec\",\n            debug_out,\n        )\n\n        out = run_in_venv(coverage_command + \" report\")\n\n        # Name                                                       Stmts   Miss  Cover\n        # ------------------------------------------------------------------------------\n        # another_pkg/nspkg/sixth/__init__.py                            2      0   100%\n        # venv/lib/python3.9/site-packages/nspkg/fifth/__init__.py       2      0   100%\n        # ------------------------------------------------------------------------------\n        # TOTAL                                                          4      0   100%\n\n        assert \"myproduct.py\" not in out\n        assert \"third\" not in out\n        assert \"coverage\" not in out\n        assert \"colorsys\" not in out\n        assert \"fifth\" in out\n        assert \"sixth\" in out\n\n    def test_bug_888(self, coverage_command: str) -> None:\n        out = run_in_venv(\n            coverage_command +\n            \" run --source=bug888/app,bug888/plugin bug888/app/testcov/main.py\",\n        )\n        # When the test fails, the output includes \"Already imported a file that will be measured\"\n        assert out == \"Plugin here\\n\"\n", "tests/plugin_config.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"A configuring plugin for test_plugins.py to import.\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any, List, cast\n\nimport coverage\nfrom coverage.plugin_support import Plugins\nfrom coverage.types import TConfigurable\n\n\nclass Plugin(coverage.CoveragePlugin):\n    \"\"\"A configuring plugin for testing.\"\"\"\n    def configure(self, config: TConfigurable) -> None:\n        \"\"\"Configure all the things!\"\"\"\n        opt_name = \"report:exclude_lines\"\n        exclude_lines = cast(List[str], config.get_option(opt_name))\n        exclude_lines.append(r\"pragma: custom\")\n        exclude_lines.append(r\"pragma: or whatever\")\n        config.set_option(opt_name, exclude_lines)\n\n\ndef coverage_init(\n    reg: Plugins,\n    options: Any,           # pylint: disable=unused-argument\n) -> None:\n    \"\"\"Called by coverage to initialize the plugins here.\"\"\"\n    reg.add_configurer(Plugin())\n", "tests/select_plugin.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nA pytest plugin to select tests by running an external command.\n\nSee lab/pick.py for how to use pick.py to subset test suites.\n\nMore about this: https://nedbatchelder.com/blog/202401/randomly_subsetting_test_suites.html\n\n\"\"\"\n\nimport subprocess\n\n\ndef pytest_addoption(parser):\n    \"\"\"Add command-line options for controlling the plugin.\"\"\"\n    parser.addoption(\n        \"--select-cmd\",\n        metavar=\"CMD\",\n        action=\"store\",\n        default=\"\",\n        type=str,\n        help=\"Command to run to get test names\",\n    )\n\n\ndef pytest_collection_modifyitems(config, items):\n    \"\"\"Run an external command to get a list of tests to run.\"\"\"\n    select_cmd = config.getoption(\"--select-cmd\")\n    if select_cmd:\n        output = subprocess.check_output(select_cmd, shell=\"True\").decode(\"utf-8\")\n        test_nodeids = {\n            nodeid: seq for seq, nodeid in enumerate(output.splitlines())\n        }\n        new_items = [item for item in items if item.nodeid in test_nodeids]\n        items[:] = sorted(new_items, key=lambda item: test_nodeids[item.nodeid])\n", "tests/test_sqlitedb.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.sqlitedb\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import NoReturn\nfrom unittest import mock\n\nimport pytest\n\nimport coverage.sqlitedb\nfrom coverage.exceptions import DataError\nfrom coverage.sqlitedb import SqliteDb\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import DebugControlString, FailingProxy\n\nDB_INIT = \"\"\"\\\ncreate table name (first text, last text);\ninsert into name (first, last) values (\"pablo\", \"picasso\");\n\"\"\"\n\nclass SqliteDbTest(CoverageTest):\n    \"\"\"Tests of tricky parts of SqliteDb.\"\"\"\n\n    def test_error_reporting(self) -> None:\n        msg = \"Couldn't use data file 'test.db': no such table: bar\"\n        with SqliteDb(\"test.db\", DebugControlString(options=[\"sql\"])) as db:\n            with pytest.raises(DataError, match=msg):\n                with db.execute(\"select foo from bar\"):\n                    # Entering the context manager raises the error, this line doesn't run:\n                    pass    # pragma: not covered\n\n    def test_retry_execute(self) -> None:\n        with SqliteDb(\"test.db\", DebugControlString(options=[\"sql\"])) as db:\n            db.executescript(DB_INIT)\n            proxy = FailingProxy(db.con, \"execute\", [Exception(\"WUT\")])\n            with mock.patch.object(db, \"con\", proxy):\n                with db.execute(\"select first from name order by 1\") as cur:\n                    assert list(cur) == [(\"pablo\",)]\n\n    def test_retry_execute_failure(self) -> None:\n        with SqliteDb(\"test.db\", DebugControlString(options=[\"sql\"])) as db:\n            db.executescript(DB_INIT)\n            proxy = FailingProxy(db.con, \"execute\", [Exception(\"WUT\"), RuntimeError(\"Fake\")])\n            with mock.patch.object(db, \"con\", proxy):\n                with pytest.raises(RuntimeError, match=\"Fake\"):\n                    with db.execute(\"select first from name order by 1\"):\n                        # Entering the context manager raises the error, this line doesn't run:\n                        pass    # pragma: not covered\n\n    def test_retry_executemany_void(self) -> None:\n        with SqliteDb(\"test.db\", DebugControlString(options=[\"sql\"])) as db:\n            db.executescript(DB_INIT)\n            proxy = FailingProxy(db.con, \"executemany\", [Exception(\"WUT\")])\n            with mock.patch.object(db, \"con\", proxy):\n                db.executemany_void(\n                    \"insert into name (first, last) values (?, ?)\",\n                    [(\"vincent\", \"van gogh\")],\n                )\n            with db.execute(\"select first from name order by 1\") as cur:\n                assert list(cur) == [(\"pablo\",), (\"vincent\",)]\n\n    def test_retry_executemany_void_failure(self) -> None:\n        with SqliteDb(\"test.db\", DebugControlString(options=[\"sql\"])) as db:\n            db.executescript(DB_INIT)\n            proxy = FailingProxy(db.con, \"executemany\", [Exception(\"WUT\"), RuntimeError(\"Fake\")])\n            with mock.patch.object(db, \"con\", proxy):\n                with pytest.raises(RuntimeError, match=\"Fake\"):\n                    db.executemany_void(\n                        \"insert into name (first, last) values (?, ?)\",\n                        [(\"vincent\", \"van gogh\")],\n                    )\n\n    def test_open_fails_on_bad_db(self) -> None:\n        self.make_file(\"bad.db\", \"boogers\")\n        def fake_failing_open(filename: str, mode: str) -> NoReturn:\n            assert (filename, mode) == (\"bad.db\", \"rb\")\n            raise RuntimeError(\"No you can't!\")\n        with mock.patch.object(coverage.sqlitedb, \"open\", fake_failing_open):\n            msg = \"Couldn't use data file 'bad.db': file is not a database\"\n            with pytest.raises(DataError, match=msg):\n                with SqliteDb(\"bad.db\", DebugControlString(options=[\"sql\"])):\n                    pass    # pragma: not covered\n\n    def test_execute_void_can_allow_failure(self) -> None:\n        with SqliteDb(\"fail.db\", DebugControlString(options=[\"sql\"])) as db:\n            db.executescript(DB_INIT)\n            proxy = FailingProxy(db.con, \"execute\", [Exception(\"WUT\")])\n            with mock.patch.object(db, \"con\", proxy):\n                db.execute_void(\"select x from nosuchtable\", fail_ok=True)\n\n    def test_execute_void_can_refuse_failure(self) -> None:\n        with SqliteDb(\"fail.db\", DebugControlString(options=[\"sql\"])) as db:\n            db.executescript(DB_INIT)\n            proxy = FailingProxy(db.con, \"execute\", [Exception(\"WUT\")])\n            with mock.patch.object(db, \"con\", proxy):\n                msg = \"Couldn't use data file 'fail.db': no such table: nosuchtable\"\n                with pytest.raises(DataError, match=msg):\n                    db.execute_void(\"select x from nosuchtable\", fail_ok=False)\n", "tests/test_report_common.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests of behavior common to all reporting.\"\"\"\n\nfrom __future__ import annotations\n\nimport textwrap\n\nimport coverage\nfrom coverage.files import abs_file\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.goldtest import contains, doesnt_contain\nfrom tests.helpers import arcz_to_arcs, os_sep\n\n\nclass ReportMapsPathsTest(CoverageTest):\n    \"\"\"Check that reporting implicitly maps paths.\"\"\"\n\n    def make_files(self, data: str, settings: bool = False) -> None:\n        \"\"\"Create the test files we need for line coverage.\"\"\"\n        src = \"\"\"\\\n            if VER == 1:\n                print(\"line 2\")\n            if VER == 2:\n                print(\"line 4\")\n            if VER == 3:\n                print(\"line 6\")\n            \"\"\"\n        self.make_file(\"src/program.py\", src)\n        self.make_file(\"ver1/program.py\", src)\n        self.make_file(\"ver2/program.py\", src)\n\n        if data == \"line\":\n            self.make_data_file(\n                lines={\n                    abs_file(\"ver1/program.py\"): [1, 2, 3, 5],\n                    abs_file(\"ver2/program.py\"): [1, 3, 4, 5],\n                },\n            )\n        else:\n            self.make_data_file(\n                arcs={\n                    abs_file(\"ver1/program.py\"): arcz_to_arcs(\".1 12 23 35 5.\"),\n                    abs_file(\"ver2/program.py\"): arcz_to_arcs(\".1 13 34 45 5.\"),\n                },\n            )\n\n        if settings:\n            self.make_file(\".coveragerc\", \"\"\"\\\n                [paths]\n                source =\n                    src\n                    ver1\n                    ver2\n                \"\"\")\n\n    def test_map_paths_during_line_report_without_setting(self) -> None:\n        self.make_files(data=\"line\")\n        cov = coverage.Coverage()\n        cov.load()\n        cov.report(show_missing=True)\n        expected = textwrap.dedent(os_sep(\"\"\"\\\n            Name              Stmts   Miss  Cover   Missing\n            -----------------------------------------------\n            ver1/program.py       6      2    67%   4, 6\n            ver2/program.py       6      2    67%   2, 6\n            -----------------------------------------------\n            TOTAL                12      4    67%\n            \"\"\"))\n        assert expected == self.stdout()\n\n    def test_map_paths_during_line_report(self) -> None:\n        self.make_files(data=\"line\", settings=True)\n        cov = coverage.Coverage()\n        cov.load()\n        cov.report(show_missing=True)\n        expected = textwrap.dedent(os_sep(\"\"\"\\\n            Name             Stmts   Miss  Cover   Missing\n            ----------------------------------------------\n            src/program.py       6      1    83%   6\n            ----------------------------------------------\n            TOTAL                6      1    83%\n            \"\"\"))\n        assert expected == self.stdout()\n\n    def test_map_paths_during_branch_report_without_setting(self) -> None:\n        self.make_files(data=\"arcs\")\n        cov = coverage.Coverage(branch=True)\n        cov.load()\n        cov.report(show_missing=True)\n        expected = textwrap.dedent(os_sep(\"\"\"\\\n            Name              Stmts   Miss Branch BrPart  Cover   Missing\n            -------------------------------------------------------------\n            ver1/program.py       6      2      6      3    58%   1->3, 4, 6\n            ver2/program.py       6      2      6      3    58%   2, 3->5, 6\n            -------------------------------------------------------------\n            TOTAL                12      4     12      6    58%\n            \"\"\"))\n        assert expected == self.stdout()\n\n    def test_map_paths_during_branch_report(self) -> None:\n        self.make_files(data=\"arcs\", settings=True)\n        cov = coverage.Coverage(branch=True)\n        cov.load()\n        cov.report(show_missing=True)\n        expected = textwrap.dedent(os_sep(\"\"\"\\\n            Name             Stmts   Miss Branch BrPart  Cover   Missing\n            ------------------------------------------------------------\n            src/program.py       6      1      6      1    83%   6\n            ------------------------------------------------------------\n            TOTAL                6      1      6      1    83%\n            \"\"\"))\n        assert expected == self.stdout()\n\n    def test_map_paths_during_annotate(self) -> None:\n        self.make_files(data=\"line\", settings=True)\n        cov = coverage.Coverage()\n        cov.load()\n        cov.annotate()\n        self.assert_exists(os_sep(\"src/program.py,cover\"))\n        self.assert_doesnt_exist(os_sep(\"ver1/program.py,cover\"))\n        self.assert_doesnt_exist(os_sep(\"ver2/program.py,cover\"))\n\n    def test_map_paths_during_html_report(self) -> None:\n        self.make_files(data=\"line\", settings=True)\n        cov = coverage.Coverage()\n        cov.load()\n        cov.html_report()\n        contains(\"htmlcov/index.html\", os_sep(\"src/program.py\"))\n        doesnt_contain(\"htmlcov/index.html\", os_sep(\"ver1/program.py\"), os_sep(\"ver2/program.py\"))\n\n    def test_map_paths_during_xml_report(self) -> None:\n        self.make_files(data=\"line\", settings=True)\n        cov = coverage.Coverage()\n        cov.load()\n        cov.xml_report()\n        contains(\"coverage.xml\", \"src/program.py\")\n        doesnt_contain(\"coverage.xml\", \"ver1/program.py\", \"ver2/program.py\")\n\n    def test_map_paths_during_json_report(self) -> None:\n        self.make_files(data=\"line\", settings=True)\n        cov = coverage.Coverage()\n        cov.load()\n        cov.json_report()\n        def os_sepj(s: str) -> str:\n            return os_sep(s).replace(\"\\\\\", r\"\\\\\")\n        contains(\"coverage.json\", os_sepj(\"src/program.py\"))\n        doesnt_contain(\"coverage.json\", os_sepj(\"ver1/program.py\"), os_sepj(\"ver2/program.py\"))\n\n    def test_map_paths_during_lcov_report(self) -> None:\n        self.make_files(data=\"line\", settings=True)\n        cov = coverage.Coverage()\n        cov.load()\n        cov.lcov_report()\n        contains(\"coverage.lcov\", os_sep(\"src/program.py\"))\n        doesnt_contain(\"coverage.lcov\", os_sep(\"ver1/program.py\"), os_sep(\"ver2/program.py\"))\n\n\nclass ReportWithJinjaTest(CoverageTest):\n    \"\"\"Tests of Jinja-like behavior.\n\n    Jinja2 compiles a template into Python code, and then runs the Python code\n    to render the template.  But during rendering, it uses the template name\n    (for example, \"template.j2\") as the file name, not the Python code file\n    name.  Then during reporting, we will try to parse template.j2 as Python\n    code.\n\n    If the file can be parsed, it's included in the report (as a Python file!).\n    If it can't be parsed, then it's not included in the report.\n\n    These tests confirm that code doesn't raise an exception (as reported in\n    #1553), and that the current (incorrect) behavior remains stable.  Ideally,\n    good.j2 wouldn't be listed at all, since we can't report on it accurately.\n\n    See https://github.com/nedbat/coveragepy/issues/1553 for more detail, and\n    https://github.com/nedbat/coveragepy/issues/1623 for an issue about this\n    behavior.\n\n    \"\"\"\n\n    def make_files(self) -> None:\n        \"\"\"Create test files: two Jinja templates, and data from rendering them.\"\"\"\n        # A Jinja2 file that is syntactically acceptable Python (though it wont run).\n        self.make_file(\"good.j2\", \"\"\"\\\n            {{ data }}\n            line2\n            line3\n            \"\"\")\n        # A Jinja2 file that is a Python syntax error.\n        self.make_file(\"bad.j2\", \"\"\"\\\n            This is data: {{ data }}.\n            line 2\n            line 3\n            \"\"\")\n        self.make_data_file(\n            lines={\n                abs_file(\"good.j2\"): [1, 3, 5, 7, 9],\n                abs_file(\"bad.j2\"): [1, 3, 5, 7, 9],\n            },\n        )\n\n    def test_report(self) -> None:\n        self.make_files()\n        cov = coverage.Coverage()\n        cov.load()\n        cov.report(show_missing=True)\n        expected = textwrap.dedent(\"\"\"\\\n            Name      Stmts   Miss  Cover   Missing\n            ---------------------------------------\n            good.j2       3      1    67%   2\n            ---------------------------------------\n            TOTAL         3      1    67%\n            \"\"\")\n        assert expected == self.stdout()\n\n    def test_html(self) -> None:\n        self.make_files()\n        cov = coverage.Coverage()\n        cov.load()\n        cov.html_report()\n        contains(\"htmlcov/index.html\", \"\"\"\\\n        <tbody>\n            <tr class=\"region\">\n                <td class=\"name left\"><a href=\"good_j2.html\">good.j2</a></td>\n                <td>3</td>\n                <td>1</td>\n                <td>0</td>\n                <td class=\"right\" data-ratio=\"2 3\">67%</td>\n            </tr>\n        </tbody>\"\"\",\n        )\n        doesnt_contain(\"htmlcov/index.html\", \"bad.j2\")\n\n    def test_xml(self) -> None:\n        self.make_files()\n        cov = coverage.Coverage()\n        cov.load()\n        cov.xml_report()\n        contains(\"coverage.xml\", 'filename=\"good.j2\"')\n        contains(\"coverage.xml\",\n            '<line number=\"1\" hits=\"1\"/>',\n            '<line number=\"2\" hits=\"0\"/>',\n            '<line number=\"3\" hits=\"1\"/>',\n        )\n        doesnt_contain(\"coverage.xml\", 'filename=\"bad.j2\"')\n        doesnt_contain(\"coverage.xml\", '<line number=\"4\"')\n\n    def test_json(self) -> None:\n        self.make_files()\n        cov = coverage.Coverage()\n        cov.load()\n        cov.json_report()\n        contains(\"coverage.json\",\n            # Notice the .json report claims lines in good.j2 executed that\n            # don't even exist in good.j2...\n            '\"files\": {\"good.j2\": {\"executed_lines\": [1, 3, 5, 7, 9], ' +\n                '\"summary\": {\"covered_lines\": 2, \"num_statements\": 3',\n        )\n        doesnt_contain(\"coverage.json\", \"bad.j2\")\n\n    def test_lcov(self) -> None:\n        self.make_files()\n        cov = coverage.Coverage()\n        cov.load()\n        cov.lcov_report()\n        with open(\"coverage.lcov\") as lcov:\n            actual = lcov.read()\n        expected = textwrap.dedent(\"\"\"\\\n            TN:\n            SF:good.j2\n            DA:1,1,FHs1rDakj9p/NAzMCu3Kgw\n            DA:3,1,DGOyp8LEgI+3CcdFYw9uKQ\n            DA:2,0,5iUbzxp9w7peeTPjJbvmBQ\n            LF:3\n            LH:2\n            end_of_record\n            \"\"\")\n        assert expected == actual\n", "tests/test_python.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests of coverage/python.py\"\"\"\n\nfrom __future__ import annotations\n\nimport pathlib\nimport sys\n\nimport pytest\n\nfrom coverage import env\nfrom coverage.python import get_zip_bytes, source_for_file\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import os_sep\n\n\nclass GetZipBytesTest(CoverageTest):\n    \"\"\"Tests of `get_zip_bytes`.\"\"\"\n\n    run_in_temp_dir = False\n\n    @pytest.mark.parametrize(\n        \"encoding\",\n        [\"utf-8\", \"gb2312\", \"hebrew\", \"shift_jis\", \"cp1252\"],\n    )\n    def test_get_encoded_zip_files(self, encoding: str) -> None:\n        # See igor.py, do_zipmods, for the text of these files.\n        zip_file = \"tests/zipmods.zip\"\n        sys.path.append(zip_file)       # So we can import the files.\n        filename = zip_file + \"/encoded_\" + encoding + \".py\"\n        filename = os_sep(filename)\n        zip_data = get_zip_bytes(filename)\n        assert zip_data is not None\n        zip_text = zip_data.decode(encoding)\n        assert 'All OK' in zip_text\n        # Run the code to see that we really got it encoded properly.\n        mod = __import__(\"encoded_\"+encoding)\n        assert mod.encoding == encoding\n\n\ndef test_source_for_file(tmp_path: pathlib.Path) -> None:\n    src = str(tmp_path / \"a.py\")\n    assert source_for_file(src) == src\n    assert source_for_file(src + 'c') == src\n    assert source_for_file(src + 'o') == src\n    unknown = src + 'FOO'\n    assert source_for_file(unknown) == unknown\n\n\n@pytest.mark.skipif(not env.WINDOWS, reason=\"not windows\")\ndef test_source_for_file_windows(tmp_path: pathlib.Path) -> None:\n    a_py = tmp_path / \"a.py\"\n    src = str(a_py)\n\n    # On windows if a pyw exists, it is an acceptable source\n    path_windows = tmp_path / \"a.pyw\"\n    path_windows.write_text(\"\")\n    assert str(path_windows) == source_for_file(src + 'c')\n\n    # If both pyw and py exist, py is preferred\n    a_py.write_text(\"\")\n    assert source_for_file(src + 'c') == src\n", "tests/test_plugins.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for plugins.\"\"\"\n\nfrom __future__ import annotations\n\nimport inspect\nimport io\nimport math\nimport os.path\n\nfrom typing import Any\nfrom xml.etree import ElementTree\n\nimport pytest\n\nimport coverage\nfrom coverage import Coverage\nfrom coverage.control import Plugins\nfrom coverage.data import line_counts, sorted_lines\nfrom coverage.exceptions import CoverageWarning, NoSource, PluginError\nfrom coverage.misc import import_local_file\nfrom coverage.types import TConfigSectionOut, TLineNo, TPluginConfig\n\nimport coverage.plugin\n\nfrom tests import testenv\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import CheckUniqueFilenames, swallow_warnings\n\n\nclass NullConfig(TPluginConfig):\n    \"\"\"A plugin configure thing when we don't really need one.\"\"\"\n    def get_plugin_options(self, plugin: str) -> TConfigSectionOut:\n        return {}   # pragma: never called\n\n\nclass FakeConfig(TPluginConfig):\n    \"\"\"A fake config for use in tests.\"\"\"\n\n    def __init__(self, plugin: str, options: dict[str, Any]) -> None:\n        self.plugin = plugin\n        self.options = options\n        self.asked_for: list[str] = []\n\n    def get_plugin_options(self, plugin: str) -> TConfigSectionOut:\n        \"\"\"Just return the options for `plugin` if this is the right module.\"\"\"\n        self.asked_for.append(plugin)\n        if plugin == self.plugin:\n            return self.options\n        else:\n            return {}\n\n\nclass LoadPluginsTest(CoverageTest):\n    \"\"\"Test Plugins.load_plugins directly.\"\"\"\n\n    def test_implicit_boolean(self) -> None:\n        self.make_file(\"plugin1.py\", \"\"\"\\\n            from coverage import CoveragePlugin\n\n            class Plugin(CoveragePlugin):\n                pass\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n\n        config = FakeConfig(\"plugin1\", {})\n        plugins = Plugins.load_plugins([], config)\n        assert not plugins\n\n        plugins = Plugins.load_plugins([\"plugin1\"], config)\n        assert plugins\n\n    def test_importing_and_configuring(self) -> None:\n        self.make_file(\"plugin1.py\", \"\"\"\\\n            from coverage import CoveragePlugin\n\n            class Plugin(CoveragePlugin):\n                def __init__(self, options):\n                    self.options = options\n                    self.this_is = \"me\"\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin(options))\n            \"\"\")\n\n        config = FakeConfig(\"plugin1\", {'a': 'hello'})\n        plugins = list(Plugins.load_plugins([\"plugin1\"], config))\n\n        assert len(plugins) == 1\n        assert plugins[0].this_is == \"me\"                   # type: ignore\n        assert plugins[0].options == {'a': 'hello'}         # type: ignore\n        assert config.asked_for == ['plugin1']\n\n    def test_importing_and_configuring_more_than_one(self) -> None:\n        self.make_file(\"plugin1.py\", \"\"\"\\\n            from coverage import CoveragePlugin\n\n            class Plugin(CoveragePlugin):\n                def __init__(self, options):\n                    self.options = options\n                    self.this_is = \"me\"\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin(options))\n            \"\"\")\n        self.make_file(\"plugin2.py\", \"\"\"\\\n            from coverage import CoveragePlugin\n\n            class Plugin(CoveragePlugin):\n                def __init__(self, options):\n                    self.options = options\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin(options))\n            \"\"\")\n\n        config = FakeConfig(\"plugin1\", {'a': 'hello'})\n        plugins = list(Plugins.load_plugins([\"plugin1\", \"plugin2\"], config))\n\n        assert len(plugins) == 2\n        assert plugins[0].this_is == \"me\"                   # type: ignore\n        assert plugins[0].options == {'a': 'hello'}         # type: ignore\n        assert plugins[1].options == {}             # type: ignore\n        assert config.asked_for == ['plugin1', 'plugin2']\n\n        # The order matters...\n        config = FakeConfig(\"plugin1\", {'a': 'second'})\n        plugins = list(Plugins.load_plugins([\"plugin2\", \"plugin1\"], config))\n\n        assert len(plugins) == 2\n        assert plugins[0].options == {}                     # type: ignore\n        assert plugins[1].this_is == \"me\"                   # type: ignore\n        assert plugins[1].options == {'a': 'second'}        # type: ignore\n\n    def test_cant_import(self) -> None:\n        with pytest.raises(ImportError, match=\"No module named '?plugin_not_there'?\"):\n            _ = Plugins.load_plugins([\"plugin_not_there\"], NullConfig())\n\n    def test_plugin_must_define_coverage_init(self) -> None:\n        self.make_file(\"no_plugin.py\", \"\"\"\\\n            from coverage import CoveragePlugin\n            Nothing = 0\n            \"\"\")\n        msg_pat = \"Plugin module 'no_plugin' didn't define a coverage_init function\"\n        with pytest.raises(PluginError, match=msg_pat):\n            list(Plugins.load_plugins([\"no_plugin\"], NullConfig()))\n\n\nclass PluginTest(CoverageTest):\n    \"\"\"Test plugins through the Coverage class.\"\"\"\n\n    def test_plugin_imported(self) -> None:\n        # Prove that a plugin will be imported.\n        self.make_file(\"my_plugin.py\", \"\"\"\\\n            from coverage import CoveragePlugin\n            class Plugin(CoveragePlugin):\n                pass\n            def coverage_init(reg, options):\n                reg.add_noop(Plugin())\n            with open(\"evidence.out\", \"w\") as f:\n                f.write(\"we are here!\")\n            \"\"\")\n\n        self.assert_doesnt_exist(\"evidence.out\")\n        cov = coverage.Coverage()\n        cov.set_option(\"run:plugins\", [\"my_plugin\"])\n        cov.start()\n        cov.stop()      # pragma: nested\n\n        with open(\"evidence.out\") as f:\n            assert f.read() == \"we are here!\"\n\n    def test_missing_plugin_raises_import_error(self) -> None:\n        # Prove that a missing plugin will raise an ImportError.\n        with pytest.raises(ImportError, match=\"No module named '?does_not_exist_woijwoicweo'?\"):\n            cov = coverage.Coverage()\n            cov.set_option(\"run:plugins\", [\"does_not_exist_woijwoicweo\"])\n            cov.start()\n        cov.stop()\n\n    def test_bad_plugin_isnt_hidden(self) -> None:\n        # Prove that a plugin with an error in it will raise the error.\n        self.make_file(\"plugin_over_zero.py\", \"1/0\")\n        with pytest.raises(ZeroDivisionError):\n            cov = coverage.Coverage()\n            cov.set_option(\"run:plugins\", [\"plugin_over_zero\"])\n            cov.start()\n        cov.stop()\n\n    def test_plugin_sys_info(self) -> None:\n        self.make_file(\"plugin_sys_info.py\", \"\"\"\\\n            import coverage\n\n            class Plugin(coverage.CoveragePlugin):\n                def sys_info(self):\n                    return [(\"hello\", \"world\")]\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        debug_out = io.StringIO()\n        cov = coverage.Coverage(debug=[\"sys\"])\n        cov._debug_file = debug_out\n        cov.set_option(\"run:plugins\", [\"plugin_sys_info\"])\n        with swallow_warnings(\n            r\"Plugin file tracers \\(plugin_sys_info.Plugin\\) aren't supported with .*\",\n        ):\n            cov.start()\n        cov.stop()      # pragma: nested\n\n        out_lines = [line.strip() for line in debug_out.getvalue().splitlines()]\n        if testenv.C_TRACER:\n            assert 'plugins.file_tracers: plugin_sys_info.Plugin' in out_lines\n        else:\n            assert 'plugins.file_tracers: plugin_sys_info.Plugin (disabled)' in out_lines\n        assert 'plugins.configurers: -none-' in out_lines\n        expected_end = [\n            \"-- sys: plugin_sys_info.Plugin -------------------------------\",\n            \"hello: world\",\n            \"-- end -------------------------------------------------------\",\n        ]\n        assert expected_end == out_lines[-len(expected_end):]\n\n    def test_plugin_with_no_sys_info(self) -> None:\n        self.make_file(\"plugin_no_sys_info.py\", \"\"\"\\\n            import coverage\n\n            class Plugin(coverage.CoveragePlugin):\n                pass\n\n            def coverage_init(reg, options):\n                reg.add_configurer(Plugin())\n            \"\"\")\n        debug_out = io.StringIO()\n        cov = coverage.Coverage(debug=[\"sys\"])\n        cov._debug_file = debug_out\n        cov.set_option(\"run:plugins\", [\"plugin_no_sys_info\"])\n        cov.start()\n        cov.stop()      # pragma: nested\n\n        out_lines = [line.strip() for line in debug_out.getvalue().splitlines()]\n        assert 'plugins.file_tracers: -none-' in out_lines\n        assert 'plugins.configurers: plugin_no_sys_info.Plugin' in out_lines\n        expected_end = [\n            \"-- sys: plugin_no_sys_info.Plugin ----------------------------\",\n            \"-- end -------------------------------------------------------\",\n        ]\n        assert expected_end == out_lines[-len(expected_end):]\n\n    def test_local_files_are_importable(self) -> None:\n        self.make_file(\"importing_plugin.py\", \"\"\"\\\n            from coverage import CoveragePlugin\n            import local_module\n            class MyPlugin(CoveragePlugin):\n                pass\n            def coverage_init(reg, options):\n                reg.add_noop(MyPlugin())\n            \"\"\")\n        self.make_file(\"local_module.py\", \"CONST = 1\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            plugins = importing_plugin\n            \"\"\")\n        self.make_file(\"main_file.py\", \"print('MAIN')\")\n\n        out = self.run_command(\"coverage run main_file.py\")\n        assert out == \"MAIN\\n\"\n        out = self.run_command(\"coverage html -q\")  # sneak in a test of -q\n        assert out == \"\"\n\n\n@pytest.mark.skipif(testenv.PLUGINS, reason=\"This core doesn't support plugins.\")\nclass PluginWarningOnPyTracerTest(CoverageTest):\n    \"\"\"Test that we get a controlled exception when plugins aren't supported.\"\"\"\n    def test_exception_if_plugins_on_pytracer(self) -> None:\n        self.make_file(\"simple.py\", \"a = 1\")\n\n        cov = coverage.Coverage()\n        cov.set_option(\"run:plugins\", [\"tests.plugin1\"])\n\n        if testenv.PY_TRACER:\n            core = \"PyTracer\"\n        else:\n            assert testenv.SYS_MON\n            core = \"SysMonitor\"\n\n        expected_warnings = [\n            fr\"Plugin file tracers \\(tests.plugin1.Plugin\\) aren't supported with {core}\",\n        ]\n        with self.assert_warnings(cov, expected_warnings):\n            self.start_import_stop(cov, \"simple\")\n\n\n@pytest.mark.skipif(not testenv.PLUGINS, reason=\"Plugins are not supported with this core.\")\nclass FileTracerTest(CoverageTest):\n    \"\"\"Tests of plugins that implement file_tracer.\"\"\"\n\n\nclass GoodFileTracerTest(FileTracerTest):\n    \"\"\"Tests of file tracer plugin happy paths.\"\"\"\n\n    def test_plugin1(self) -> None:\n        self.make_file(\"simple.py\", \"\"\"\\\n            import try_xyz\n            a = 1\n            b = 2\n            \"\"\")\n        self.make_file(\"try_xyz.py\", \"\"\"\\\n            c = 3\n            d = 4\n            \"\"\")\n\n        cov = coverage.Coverage()\n        CheckUniqueFilenames.hook(cov, '_should_trace')\n        CheckUniqueFilenames.hook(cov, '_check_include_omit_etc')\n        cov.set_option(\"run:plugins\", [\"tests.plugin1\"])\n\n        # Import the Python file, executing it.\n        self.start_import_stop(cov, \"simple\")\n\n        _, statements, missing, _ = cov.analysis(\"simple.py\")\n        assert statements == [1, 2, 3]\n        assert missing == []\n        zzfile = os.path.abspath(os.path.join(\"/src\", \"try_ABC.zz\"))\n        _, statements, _, _ = cov.analysis(zzfile)\n        assert statements == [105, 106, 107, 205, 206, 207]\n\n    def make_render_and_caller(self) -> None:\n        \"\"\"Make the render.py and caller.py files we need.\"\"\"\n        # plugin2 emulates a dynamic tracing plugin: the caller's locals\n        # are examined to determine the source file and line number.\n        # The plugin is in tests/plugin2.py.\n        self.make_file(\"render.py\", \"\"\"\\\n            def render(filename, linenum):\n                # This function emulates a template renderer. The plugin\n                # will examine the `filename` and `linenum` locals to\n                # determine the source file and line number.\n                fiddle_around = 1   # not used, just chaff.\n                return \"[{} @ {}]\".format(filename, linenum)\n\n            def helper(x):\n                # This function is here just to show that not all code in\n                # this file will be part of the dynamic tracing.\n                return x+1\n            \"\"\")\n        self.make_file(\"caller.py\", \"\"\"\\\n            import sys\n            from render import helper, render\n\n            assert render(\"foo_7.html\", 4) == \"[foo_7.html @ 4]\"\n            # Render foo_7.html again to try the CheckUniqueFilenames asserts.\n            render(\"foo_7.html\", 4)\n\n            assert helper(42) == 43\n            assert render(\"bar_4.html\", 2) == \"[bar_4.html @ 2]\"\n            assert helper(76) == 77\n\n            # quux_5.html will be omitted from the results.\n            assert render(\"quux_5.html\", 3) == \"[quux_5.html @ 3]\"\n            \"\"\")\n\n        # will try to read the actual source files, so make some\n        # source files.\n        def lines(n: int) -> str:\n            \"\"\"Make a string with n lines of text.\"\"\"\n            return \"\".join(\"line %d\\n\" % i for i in range(n))\n\n        self.make_file(\"bar_4.html\", lines(4))\n        self.make_file(\"foo_7.html\", lines(7))\n\n    def test_plugin2(self) -> None:\n        self.make_render_and_caller()\n\n        cov = coverage.Coverage(omit=[\"*quux*\"])\n        CheckUniqueFilenames.hook(cov, '_should_trace')\n        CheckUniqueFilenames.hook(cov, '_check_include_omit_etc')\n        cov.set_option(\"run:plugins\", [\"tests.plugin2\"])\n\n        self.start_import_stop(cov, \"caller\")\n\n        # The way plugin2 works, a file named foo_7.html will be claimed to\n        # have 7 lines in it.  If render() was called with line number 4,\n        # then the plugin will claim that lines 4 and 5 were executed.\n        _, statements, missing, _ = cov.analysis(\"foo_7.html\")\n        assert statements == [1, 2, 3, 4, 5, 6, 7]\n        assert missing == [1, 2, 3, 6, 7]\n        assert \"foo_7.html\" in line_counts(cov.get_data())\n\n        _, statements, missing, _ = cov.analysis(\"bar_4.html\")\n        assert statements == [1, 2, 3, 4]\n        assert missing == [1, 4]\n        assert \"bar_4.html\" in line_counts(cov.get_data())\n\n        assert \"quux_5.html\" not in line_counts(cov.get_data())\n\n    def test_plugin2_with_branch(self) -> None:\n        self.make_render_and_caller()\n\n        cov = coverage.Coverage(branch=True, omit=[\"*quux*\"])\n        CheckUniqueFilenames.hook(cov, '_should_trace')\n        CheckUniqueFilenames.hook(cov, '_check_include_omit_etc')\n        cov.set_option(\"run:plugins\", [\"tests.plugin2\"])\n\n        self.start_import_stop(cov, \"caller\")\n\n        # The way plugin2 works, a file named foo_7.html will be claimed to\n        # have 7 lines in it.  If render() was called with line number 4,\n        # then the plugin will claim that lines 4 and 5 were executed.\n        analysis = cov._analyze(\"foo_7.html\")\n        assert analysis.statements == {1, 2, 3, 4, 5, 6, 7}\n        # Plugins don't do branch coverage yet.\n        assert analysis.has_arcs is True\n        assert analysis.arc_possibilities == []\n\n        assert analysis.missing == {1, 2, 3, 6, 7}\n\n    def test_plugin2_with_text_report(self) -> None:\n        self.make_render_and_caller()\n\n        cov = coverage.Coverage(branch=True, omit=[\"*quux*\"])\n        cov.set_option(\"run:plugins\", [\"tests.plugin2\"])\n\n        self.start_import_stop(cov, \"caller\")\n\n        repout = io.StringIO()\n        total = cov.report(file=repout, include=[\"*.html\"], omit=[\"uni*.html\"], show_missing=True)\n        report = repout.getvalue().splitlines()\n        expected = [\n            'Name         Stmts   Miss Branch BrPart  Cover   Missing',\n            '--------------------------------------------------------',\n            'bar_4.html       4      2      0      0    50%   1, 4',\n            'foo_7.html       7      5      0      0    29%   1-3, 6-7',\n            '--------------------------------------------------------',\n            'TOTAL           11      7      0      0    36%',\n        ]\n        assert expected == report\n        assert math.isclose(total, 4 / 11 * 100)\n\n    def test_plugin2_with_html_report(self) -> None:\n        self.make_render_and_caller()\n\n        cov = coverage.Coverage(branch=True, omit=[\"*quux*\"])\n        cov.set_option(\"run:plugins\", [\"tests.plugin2\"])\n\n        self.start_import_stop(cov, \"caller\")\n\n        total = cov.html_report(include=[\"*.html\"], omit=[\"uni*.html\"])\n        assert math.isclose(total, 4 / 11 * 100)\n\n        self.assert_exists(\"htmlcov/index.html\")\n        self.assert_exists(\"htmlcov/bar_4_html.html\")\n        self.assert_exists(\"htmlcov/foo_7_html.html\")\n\n    def test_plugin2_with_xml_report(self) -> None:\n        self.make_render_and_caller()\n\n        cov = coverage.Coverage(branch=True, omit=[\"*quux*\"])\n        cov.set_option(\"run:plugins\", [\"tests.plugin2\"])\n\n        self.start_import_stop(cov, \"caller\")\n\n        total = cov.xml_report(include=[\"*.html\"], omit=[\"uni*.html\"])\n        assert math.isclose(total, 4 / 11 * 100)\n\n        dom = ElementTree.parse(\"coverage.xml\")\n        classes = {}\n        for elt in dom.findall(\".//class\"):\n            classes[elt.get('name')] = elt\n\n        assert classes['bar_4.html'].attrib == {\n            'branch-rate': '1',\n            'complexity': '0',\n            'filename': 'bar_4.html',\n            'line-rate': '0.5',\n            'name': 'bar_4.html',\n        }\n        assert classes['foo_7.html'].attrib == {\n            'branch-rate': '1',\n            'complexity': '0',\n            'filename': 'foo_7.html',\n            'line-rate': '0.2857',\n            'name': 'foo_7.html',\n        }\n\n    def test_defer_to_python(self) -> None:\n        # A plugin that measures, but then wants built-in python reporting.\n        self.make_file(\"fairly_odd_plugin.py\", \"\"\"\\\n            # A plugin that claims all the odd lines are executed, and none of\n            # the even lines, and then punts reporting off to the built-in\n            # Python reporting.\n            import coverage.plugin\n            class Plugin(coverage.CoveragePlugin):\n                def file_tracer(self, filename):\n                    return OddTracer(filename)\n                def file_reporter(self, filename):\n                    return \"python\"\n\n            class OddTracer(coverage.plugin.FileTracer):\n                def __init__(self, filename):\n                    self.filename = filename\n                def source_filename(self):\n                    return self.filename\n                def line_number_range(self, frame):\n                    lineno = frame.f_lineno\n                    if lineno % 2:\n                        return (lineno, lineno)\n                    else:\n                        return (-1, -1)\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.make_file(\"unsuspecting.py\", \"\"\"\\\n            a = 1\n            b = 2\n            c = 3\n            d = 4\n            e = 5\n            f = 6\n            \"\"\")\n        cov = coverage.Coverage(include=[\"unsuspecting.py\"])\n        cov.set_option(\"run:plugins\", [\"fairly_odd_plugin\"])\n        self.start_import_stop(cov, \"unsuspecting\")\n\n        repout = io.StringIO()\n        total = cov.report(file=repout, show_missing=True)\n        report = repout.getvalue().splitlines()\n        expected = [\n            'Name              Stmts   Miss  Cover   Missing',\n            '-----------------------------------------------',\n            'unsuspecting.py       6      3    50%   2, 4, 6',\n            '-----------------------------------------------',\n            'TOTAL                 6      3    50%',\n        ]\n        assert expected == report\n        assert total == 50\n\n    def test_find_unexecuted(self) -> None:\n        self.make_file(\"unexecuted_plugin.py\", \"\"\"\\\n            import os\n            import coverage.plugin\n            class Plugin(coverage.CoveragePlugin):\n                def file_tracer(self, filename):\n                    if filename.endswith(\"foo.py\"):\n                        return MyTracer(filename)\n                def file_reporter(self, filename):\n                    return MyReporter(filename)\n                def find_executable_files(self, src_dir):\n                    # Check that src_dir is the right value\n                    files = os.listdir(src_dir)\n                    assert \"foo.py\" in files\n                    assert \"unexecuted_plugin.py\" in files\n                    return [\"chimera.py\"]\n\n            class MyTracer(coverage.plugin.FileTracer):\n                def __init__(self, filename):\n                    self.filename = filename\n                def source_filename(self):\n                    return self.filename\n                def line_number_range(self, frame):\n                    return (999, 999)\n\n            class MyReporter(coverage.FileReporter):\n                def lines(self):\n                    return {99, 999, 9999}\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n        \"\"\")\n        self.make_file(\"foo.py\", \"a = 1\")\n        cov = coverage.Coverage(source=['.'])\n        cov.set_option(\"run:plugins\", [\"unexecuted_plugin\"])\n        self.start_import_stop(cov, \"foo\")\n\n        # The file we executed claims to have run line 999.\n        _, statements, missing, _ = cov.analysis(\"foo.py\")\n        assert statements == [99, 999, 9999]\n        assert missing == [99, 9999]\n\n        # The completely missing file is in the results.\n        _, statements, missing, _ = cov.analysis(\"chimera.py\")\n        assert statements == [99, 999, 9999]\n        assert missing == [99, 999, 9999]\n\n        # But completely new filenames are not in the results.\n        assert len(cov.get_data().measured_files()) == 3\n        with pytest.raises(NoSource):\n            cov.analysis(\"fictional.py\")\n\n\nclass BadFileTracerTest(FileTracerTest):\n    \"\"\"Test error handling around file tracer plugins.\"\"\"\n\n    def run_plugin(self, module_name: str) -> Coverage:\n        \"\"\"Run a plugin with the given module_name.\n\n        Uses a few fixed Python files.\n\n        Returns the Coverage object.\n\n        \"\"\"\n        self.make_file(\"simple.py\", \"\"\"\\\n            import other, another\n            a = other.f(2)\n            b = other.f(3)\n            c = another.g(4)\n            d = another.g(5)\n            \"\"\")\n        # The names of these files are important: some plugins apply themselves\n        # to \"*other.py\".\n        self.make_file(\"other.py\", \"\"\"\\\n            def f(x):\n                return x+1\n            \"\"\")\n        self.make_file(\"another.py\", \"\"\"\\\n            def g(x):\n                return x-1\n            \"\"\")\n\n        cov = coverage.Coverage()\n        cov.set_option(\"run:plugins\", [module_name])\n        self.start_import_stop(cov, \"simple\")\n        cov.save()  # pytest-cov does a save after stop, so we'll do it too.\n        return cov\n\n    def run_bad_plugin(\n        self,\n        module_name: str,\n        plugin_name: str,\n        our_error: bool = True,\n        excmsg: str | None = None,\n        excmsgs: list[str] | None = None,\n    ) -> None:\n        \"\"\"Run a file, and see that the plugin failed.\n\n        `module_name` and `plugin_name` is the module and name of the plugin to\n        use.\n\n        `our_error` is True if the error reported to the user will be an\n        explicit error in our test code, marked with an '# Oh noes!' comment.\n\n        `excmsg`, if provided, is text that must appear in the stderr.\n\n        `excmsgs`, if provided, is a list of messages, one of which must\n        appear in the stderr.\n\n        The plugin will be disabled, and we check that a warning is output\n        explaining why.\n\n        \"\"\"\n        with pytest.warns(Warning) as warns:\n            self.run_plugin(module_name)\n\n        stderr = self.stderr()\n        stderr += \"\".join(str(w.message) for w in warns)\n        if our_error:\n            # The exception we're causing should only appear once.\n            assert stderr.count(\"# Oh noes!\") == 1\n\n        # There should be a warning explaining what's happening, but only one.\n        # The message can be in two forms:\n        #   Disabling plug-in '...' due to previous exception\n        # or:\n        #   Disabling plug-in '...' due to an exception:\n        print([str(w) for w in warns.list])\n        warnings = [w for w in warns.list if issubclass(w.category, CoverageWarning)]\n        assert len(warnings) == 1\n        warnmsg = str(warnings[0].message)\n        assert f\"Disabling plug-in '{module_name}.{plugin_name}' due to \" in warnmsg\n\n        if excmsg:\n            assert excmsg in stderr\n        if excmsgs:\n            found_exc = any(em in stderr for em in excmsgs)             #  pragma: part covered\n            assert found_exc, f\"expected one of {excmsgs} in stderr\"\n\n    def test_file_tracer_has_no_file_tracer_method(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            class Plugin(object):\n                pass\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\"bad_plugin\", \"Plugin\", our_error=False)\n\n    def test_file_tracer_has_inherited_sourcefilename_method(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage\n            class Plugin(coverage.CoveragePlugin):\n                def file_tracer(self, filename):\n                    # Just grab everything.\n                    return FileTracer()\n\n            class FileTracer(coverage.FileTracer):\n                pass\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\n            \"bad_plugin\", \"Plugin\", our_error=False,\n            excmsg=\"Class 'bad_plugin.FileTracer' needs to implement source_filename()\",\n        )\n\n    def test_plugin_has_inherited_filereporter_method(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage\n            class Plugin(coverage.CoveragePlugin):\n                def file_tracer(self, filename):\n                    # Just grab everything.\n                    return FileTracer()\n\n            class FileTracer(coverage.FileTracer):\n                def source_filename(self):\n                    return \"foo.xxx\"\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        cov = self.run_plugin(\"bad_plugin\")\n        expected_msg = \"Plugin 'bad_plugin.Plugin' needs to implement file_reporter()\"\n        with pytest.raises(NotImplementedError, match=expected_msg):\n            cov.report()\n\n    def test_file_tracer_fails(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def file_tracer(self, filename):\n                    17/0 # Oh noes!\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\"bad_plugin\", \"Plugin\")\n\n    def test_file_tracer_fails_eventually(self) -> None:\n        # Django coverage plugin can report on a few files and then fail.\n        # https://github.com/nedbat/coveragepy/issues/1011\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import os.path\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def __init__(self):\n                    self.calls = 0\n\n                def file_tracer(self, filename):\n                    print(filename)\n                    self.calls += 1\n                    if self.calls <= 2:\n                        return FileTracer(filename)\n                    else:\n                        17/0 # Oh noes!\n\n            class FileTracer(coverage.FileTracer):\n                def __init__(self, filename):\n                    self.filename = filename\n                def source_filename(self):\n                    return os.path.basename(self.filename).replace(\".py\", \".foo\")\n                def line_number_range(self, frame):\n                    return -1, -1\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\"bad_plugin\", \"Plugin\")\n\n    def test_file_tracer_returns_wrong(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def file_tracer(self, filename):\n                    return 3.14159\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\n            \"bad_plugin\", \"Plugin\", our_error=False, excmsg=\"'float' object has no attribute\",\n        )\n\n    def test_has_dynamic_source_filename_fails(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def file_tracer(self, filename):\n                    return BadFileTracer()\n\n            class BadFileTracer(coverage.plugin.FileTracer):\n                def has_dynamic_source_filename(self):\n                    23/0 # Oh noes!\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\"bad_plugin\", \"Plugin\")\n\n    def test_source_filename_fails(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def file_tracer(self, filename):\n                    return BadFileTracer()\n\n            class BadFileTracer(coverage.plugin.FileTracer):\n                def source_filename(self):\n                    42/0 # Oh noes!\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\"bad_plugin\", \"Plugin\")\n\n    def test_source_filename_returns_wrong(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def file_tracer(self, filename):\n                    return BadFileTracer()\n\n            class BadFileTracer(coverage.plugin.FileTracer):\n                def source_filename(self):\n                    return 17.3\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\n            \"bad_plugin\", \"Plugin\", our_error=False,\n            excmsgs=[\n                \"expected str, bytes or os.PathLike object, not float\",\n                \"'float' object has no attribute\",\n                \"object of type 'float' has no len()\",\n                \"'float' object is unsubscriptable\",\n            ],\n        )\n\n    def test_dynamic_source_filename_fails(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def file_tracer(self, filename):\n                    if filename.endswith(\"other.py\"):\n                        return BadFileTracer()\n\n            class BadFileTracer(coverage.plugin.FileTracer):\n                def has_dynamic_source_filename(self):\n                    return True\n                def dynamic_source_filename(self, filename, frame):\n                    101/0 # Oh noes!\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\"bad_plugin\", \"Plugin\")\n\n    def test_line_number_range_raises_error(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def file_tracer(self, filename):\n                    if filename.endswith(\"other.py\"):\n                        return BadFileTracer()\n\n            class BadFileTracer(coverage.plugin.FileTracer):\n                def source_filename(self):\n                    return \"something.foo\"\n\n                def line_number_range(self, frame):\n                    raise Exception(\"borked!\")\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\n            \"bad_plugin\", \"Plugin\", our_error=False, excmsg=\"borked!\",\n        )\n\n    def test_line_number_range_returns_non_tuple(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def file_tracer(self, filename):\n                    if filename.endswith(\"other.py\"):\n                        return BadFileTracer()\n\n            class BadFileTracer(coverage.plugin.FileTracer):\n                def source_filename(self):\n                    return \"something.foo\"\n\n                def line_number_range(self, frame):\n                    return 42.23\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\n            \"bad_plugin\", \"Plugin\", our_error=False, excmsg=\"line_number_range must return 2-tuple\",\n        )\n\n    def test_line_number_range_returns_triple(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def file_tracer(self, filename):\n                    if filename.endswith(\"other.py\"):\n                        return BadFileTracer()\n\n            class BadFileTracer(coverage.plugin.FileTracer):\n                def source_filename(self):\n                    return \"something.foo\"\n\n                def line_number_range(self, frame):\n                    return (1, 2, 3)\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\n            \"bad_plugin\", \"Plugin\", our_error=False, excmsg=\"line_number_range must return 2-tuple\",\n        )\n\n    def test_line_number_range_returns_pair_of_strings(self) -> None:\n        self.make_file(\"bad_plugin.py\", \"\"\"\\\n            import coverage.plugin\n            class Plugin(coverage.plugin.CoveragePlugin):\n                def file_tracer(self, filename):\n                    if filename.endswith(\"other.py\"):\n                        return BadFileTracer()\n\n            class BadFileTracer(coverage.plugin.FileTracer):\n                def source_filename(self):\n                    return \"something.foo\"\n\n                def line_number_range(self, frame):\n                    return (\"5\", \"7\")\n\n            def coverage_init(reg, options):\n                reg.add_file_tracer(Plugin())\n            \"\"\")\n        self.run_bad_plugin(\n            \"bad_plugin\", \"Plugin\", our_error=False,\n            excmsgs=[\n                \"an integer is required\",\n                \"cannot be interpreted as an integer\",\n            ],\n        )\n\n\nclass ConfigurerPluginTest(CoverageTest):\n    \"\"\"Test configuring plugins.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_configurer_plugin(self) -> None:\n        cov = coverage.Coverage()\n        cov.set_option(\"run:plugins\", [\"tests.plugin_config\"])\n        cov.start()\n        cov.stop()      # pragma: nested\n        excluded = cov.get_option(\"report:exclude_lines\")\n        assert isinstance(excluded, list)\n        assert \"pragma: custom\" in excluded\n        assert \"pragma: or whatever\" in excluded\n\n\n@pytest.mark.skipif(not testenv.DYN_CONTEXTS, reason=\"No dynamic contexts with this core\")\nclass DynamicContextPluginTest(CoverageTest):\n    \"\"\"Tests of plugins that implement `dynamic_context`.\"\"\"\n\n    def make_plugin_capitalized_testnames(self, filename: str) -> None:\n        \"\"\"Create a dynamic context plugin that capitalizes the part after 'test_'.\"\"\"\n        self.make_file(filename, \"\"\"\\\n            from coverage import CoveragePlugin\n\n            class Plugin(CoveragePlugin):\n                def dynamic_context(self, frame):\n                    name = frame.f_code.co_name\n                    if name.startswith((\"test_\", \"doctest_\")):\n                        parts = name.split(\"_\", 1)\n                        return \"%s:%s\" % (parts[0], parts[1].upper())\n                    return None\n\n            def coverage_init(reg, options):\n                reg.add_dynamic_context(Plugin())\n            \"\"\")\n\n    def make_plugin_track_render(self, filename: str) -> None:\n        \"\"\"Make a dynamic context plugin that tracks 'render_' functions.\"\"\"\n        self.make_file(filename, \"\"\"\\\n            from coverage import CoveragePlugin\n\n            class Plugin(CoveragePlugin):\n                def dynamic_context(self, frame):\n                    name = frame.f_code.co_name\n                    if name.startswith(\"render_\"):\n                        return 'renderer:' + name[7:]\n                    return None\n\n            def coverage_init(reg, options):\n                reg.add_dynamic_context(Plugin())\n            \"\"\")\n\n    def make_test_files(self) -> None:\n        \"\"\"Make some files to use while testing dynamic context plugins.\"\"\"\n        self.make_file(\"rendering.py\", \"\"\"\\\n            def html_tag(tag, content):\n                return f'<{tag}>{content}</{tag}>'\n\n            def render_paragraph(text):\n                return html_tag('p', text)\n\n            def render_span(text):\n                return html_tag('span', text)\n\n            def render_bold(text):\n                return html_tag('b', text)\n            \"\"\")\n\n        self.make_file(\"testsuite.py\", \"\"\"\\\n            import rendering\n\n            def test_html_tag() -> None:\n                assert rendering.html_tag('b', 'hello') == '<b>hello</b>'\n\n            def doctest_html_tag():\n                assert eval('''\n                    rendering.html_tag('i', 'text') == '<i>text</i>'\n                    '''.strip())\n\n            def test_renderers() -> None:\n                assert rendering.render_paragraph('hello') == '<p>hello</p>'\n                assert rendering.render_bold('wide') == '<b>wide</b>'\n                assert rendering.render_span('world') == '<span>world</span>'\n\n            def build_full_html():\n                html = '<html><body>%s</body></html>' % (\n                   rendering.render_paragraph(\n                      rendering.render_span('hello')))\n                return html\n            \"\"\")\n\n    def run_all_functions(self, cov: Coverage, suite_name: str) -> None:    # pragma: nested\n        \"\"\"Run all functions in `suite_name` under coverage.\"\"\"\n        cov.start()\n        suite = import_local_file(suite_name)\n        try:\n            # Call all functions in this module\n            for name in dir(suite):\n                variable = getattr(suite, name)\n                if inspect.isfunction(variable):\n                    variable()\n        finally:\n            cov.stop()\n\n    def test_plugin_standalone(self) -> None:\n        self.make_plugin_capitalized_testnames('plugin_tests.py')\n        self.make_test_files()\n\n        # Enable dynamic context plugin\n        cov = coverage.Coverage()\n        cov.set_option(\"run:plugins\", ['plugin_tests'])\n\n        # Run the tests\n        self.run_all_functions(cov, 'testsuite')\n\n        # Labeled coverage is collected\n        data = cov.get_data()\n        filenames = self.get_measured_filenames(data)\n        expected = ['', 'doctest:HTML_TAG', 'test:HTML_TAG', 'test:RENDERERS']\n        assert expected == sorted(data.measured_contexts())\n        data.set_query_context(\"doctest:HTML_TAG\")\n        assert [2] == sorted_lines(data, filenames['rendering.py'])\n        data.set_query_context(\"test:HTML_TAG\")\n        assert [2] == sorted_lines(data, filenames['rendering.py'])\n        data.set_query_context(\"test:RENDERERS\")\n        assert [2, 5, 8, 11] == sorted_lines(data, filenames['rendering.py'])\n\n    def test_static_context(self) -> None:\n        self.make_plugin_capitalized_testnames('plugin_tests.py')\n        self.make_test_files()\n\n        # Enable dynamic context plugin for coverage with named context\n        cov = coverage.Coverage(context='mytests')\n        cov.set_option(\"run:plugins\", ['plugin_tests'])\n\n        # Run the tests\n        self.run_all_functions(cov, 'testsuite')\n\n        # Static context prefix is preserved\n        data = cov.get_data()\n        expected = [\n            'mytests',\n            'mytests|doctest:HTML_TAG',\n            'mytests|test:HTML_TAG',\n            'mytests|test:RENDERERS',\n        ]\n        assert expected == sorted(data.measured_contexts())\n\n    def test_plugin_with_test_function(self) -> None:\n        self.make_plugin_capitalized_testnames('plugin_tests.py')\n        self.make_test_files()\n\n        # Enable both a plugin and test_function dynamic context\n        cov = coverage.Coverage()\n        cov.set_option(\"run:plugins\", ['plugin_tests'])\n        cov.set_option(\"run:dynamic_context\", \"test_function\")\n\n        # Run the tests\n        self.run_all_functions(cov, 'testsuite')\n\n        # test_function takes precedence over plugins - only\n        # functions that are not labeled by test_function are\n        # labeled by plugin_tests.\n        data = cov.get_data()\n        filenames = self.get_measured_filenames(data)\n        expected = [\n            '',\n            'doctest:HTML_TAG',\n            'testsuite.test_html_tag',\n            'testsuite.test_renderers',\n        ]\n        assert expected == sorted(data.measured_contexts())\n\n        def assert_context_lines(context: str, lines: list[TLineNo]) -> None:\n            data.set_query_context(context)\n            assert lines == sorted_lines(data, filenames['rendering.py'])\n\n        assert_context_lines(\"doctest:HTML_TAG\", [2])\n        assert_context_lines(\"testsuite.test_html_tag\", [2])\n        assert_context_lines(\"testsuite.test_renderers\", [2, 5, 8, 11])\n\n    def test_multiple_plugins(self) -> None:\n        self.make_plugin_capitalized_testnames('plugin_tests.py')\n        self.make_plugin_track_render('plugin_renderers.py')\n        self.make_test_files()\n\n        # Enable two plugins\n        cov = coverage.Coverage()\n        cov.set_option(\"run:plugins\", ['plugin_renderers', 'plugin_tests'])\n\n        self.run_all_functions(cov, 'testsuite')\n\n        # It is important to note, that line 11 (render_bold function) is never\n        # labeled as renderer:bold context, because it is only called from\n        # test_renderers function - so it already falls under test:RENDERERS\n        # context.\n        #\n        # render_paragraph and render_span (lines 5, 8) are directly called by\n        # testsuite.build_full_html, so they get labeled by renderers plugin.\n        data = cov.get_data()\n        filenames = self.get_measured_filenames(data)\n        expected = [\n            '',\n            'doctest:HTML_TAG',\n            'renderer:paragraph',\n            'renderer:span',\n            'test:HTML_TAG',\n            'test:RENDERERS',\n        ]\n        assert expected == sorted(data.measured_contexts())\n\n        def assert_context_lines(context: str, lines: list[TLineNo]) -> None:\n            data.set_query_context(context)\n            assert lines == sorted_lines(data, filenames['rendering.py'])\n\n        assert_context_lines(\"test:HTML_TAG\", [2])\n        assert_context_lines(\"test:RENDERERS\", [2, 5, 8, 11])\n        assert_context_lines(\"doctest:HTML_TAG\", [2])\n        assert_context_lines(\"renderer:paragraph\", [2, 5])\n        assert_context_lines(\"renderer:span\", [2, 8])\n", "tests/conftest.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nPytest auto configuration.\n\nThis module is run automatically by pytest, to define and enable fixtures.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport sys\nimport sysconfig\nimport warnings\n\nfrom pathlib import Path\nfrom typing import Iterator\n\nimport pytest\n\nfrom coverage import env\nfrom coverage.files import set_relative_directory\n\n# Pytest will rewrite assertions in test modules, but not elsewhere.\n# This tells pytest to also rewrite assertions in these files:\npytest.register_assert_rewrite(\"tests.coveragetest\")\npytest.register_assert_rewrite(\"tests.helpers\")\n\n# Pytest can take additional options:\n# $set_env.py: PYTEST_ADDOPTS - Extra arguments to pytest.\n\npytest_plugins = [\n    \"tests.balance_xdist_plugin\",\n    \"tests.select_plugin\",\n]\n\n\n@pytest.fixture(autouse=True)\ndef set_warnings() -> None:\n    \"\"\"Configure warnings to show while running tests.\"\"\"\n    warnings.simplefilter(\"default\")\n    warnings.simplefilter(\"once\", DeprecationWarning)\n\n    # Warnings to suppress:\n    # How come these warnings are successfully suppressed here, but not in pyproject.toml??\n\n    if env.PYPY:\n        # pypy3 warns about unclosed files a lot.\n        warnings.filterwarnings(\"ignore\", r\".*unclosed file\", category=ResourceWarning)\n\n    # Don't warn about unclosed SQLite connections.\n    # We don't close \":memory:\" databases because we don't have a way to connect\n    # to them more than once if we close them.  In real coverage.py uses, there\n    # are only a couple of them, but our test suite makes many and we get warned\n    # about them all.\n    # Python3.13 added this warning, but the behavior has been the same all along,\n    # without any reported problems, so just quiet the warning.\n    # https://github.com/python/cpython/issues/105539\n    warnings.filterwarnings(\"ignore\", r\"unclosed database\", category=ResourceWarning)\n\n\n@pytest.fixture(autouse=True)\ndef reset_sys_path() -> Iterator[None]:\n    \"\"\"Clean up sys.path changes around every test.\"\"\"\n    sys_path = list(sys.path)\n    yield\n    sys.path[:] = sys_path\n\n\n@pytest.fixture(autouse=True)\ndef reset_environment() -> Iterator[None]:\n    \"\"\"Make sure a test setting an envvar doesn't leak into another test.\"\"\"\n    old_environ = os.environ.copy()\n    yield\n    os.environ.clear()\n    os.environ.update(old_environ)\n\n\n@pytest.fixture(autouse=True)\ndef reset_filesdotpy_globals() -> Iterator[None]:\n    \"\"\"coverage/files.py has some unfortunate globals. Reset them every test.\"\"\"\n    set_relative_directory()\n    yield\n\nWORKER = os.getenv(\"PYTEST_XDIST_WORKER\", \"none\")\n\ndef pytest_sessionstart() -> None:\n    \"\"\"Run once at the start of the test session.\"\"\"\n    # Only in the main process...\n    if WORKER == \"none\":\n        # Create a .pth file for measuring subprocess coverage.\n        pth_dir = find_writable_pth_directory()\n        assert pth_dir\n        (pth_dir / \"subcover.pth\").write_text(\"import coverage; coverage.process_startup()\\n\")\n        # subcover.pth is deleted by pytest_sessionfinish below.\n\n\ndef pytest_sessionfinish() -> None:\n    \"\"\"Hook the end of a test session, to clean up.\"\"\"\n    # This is called by each of the workers and by the main process.\n    if WORKER == \"none\":\n        for pth_dir in possible_pth_dirs():             # pragma: part covered\n            pth_file = pth_dir / \"subcover.pth\"\n            if pth_file.exists():\n                pth_file.unlink()\n\n\ndef possible_pth_dirs() -> Iterator[Path]:\n    \"\"\"Produce a sequence of directories for trying to write .pth files.\"\"\"\n    # First look through sys.path, and if we find a .pth file, then it's a good\n    # place to put ours.\n    for pth_dir in map(Path, sys.path):             # pragma: part covered\n        pth_files = list(pth_dir.glob(\"*.pth\"))\n        if pth_files:\n            yield pth_dir\n\n    # If we're still looking, then try the Python library directory.\n    # https://github.com/nedbat/coveragepy/issues/339\n    yield Path(sysconfig.get_path(\"purelib\"))       # pragma: cant happen\n\n\ndef find_writable_pth_directory() -> Path | None:\n    \"\"\"Find a place to write a .pth file.\"\"\"\n    for pth_dir in possible_pth_dirs():             # pragma: part covered\n        try_it = pth_dir / f\"touch_{WORKER}.it\"\n        try:\n            try_it.write_text(\"foo\")\n        except OSError:                             # pragma: cant happen\n            continue\n\n        os.remove(try_it)\n        return pth_dir\n\n    return None                                     # pragma: cant happen\n", "tests/test_filereporter.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for FileReporters\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\n\nfrom coverage.plugin import FileReporter\nfrom coverage.python import PythonFileReporter\n\nfrom tests.coveragetest import CoverageTest, UsingModulesMixin\nfrom tests.helpers import os_sep\n\n# pylint: disable=import-error\n# Unable to import 'aa' (No module named aa)\n\n\nclass FileReporterTest(UsingModulesMixin, CoverageTest):\n    \"\"\"Tests for FileReporter classes.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_filenames(self) -> None:\n        acu = PythonFileReporter(\"aa/afile.py\")\n        bcu = PythonFileReporter(\"aa/bb/bfile.py\")\n        ccu = PythonFileReporter(\"aa/bb/cc/cfile.py\")\n        assert acu.relative_filename() == \"aa/afile.py\"\n        assert bcu.relative_filename() == \"aa/bb/bfile.py\"\n        assert ccu.relative_filename() == \"aa/bb/cc/cfile.py\"\n        assert acu.source() == \"# afile.py\\n\"\n        assert bcu.source() == \"# bfile.py\\n\"\n        assert ccu.source() == \"# cfile.py\\n\"\n\n    def test_odd_filenames(self) -> None:\n        acu = PythonFileReporter(\"aa/afile.odd.py\")\n        bcu = PythonFileReporter(\"aa/bb/bfile.odd.py\")\n        b2cu = PythonFileReporter(\"aa/bb.odd/bfile.py\")\n        assert acu.relative_filename() == \"aa/afile.odd.py\"\n        assert bcu.relative_filename() == \"aa/bb/bfile.odd.py\"\n        assert b2cu.relative_filename() == \"aa/bb.odd/bfile.py\"\n        assert acu.source() == \"# afile.odd.py\\n\"\n        assert bcu.source() == \"# bfile.odd.py\\n\"\n        assert b2cu.source() == \"# bfile.py\\n\"\n\n    def test_modules(self) -> None:\n        import aa\n        import aa.bb\n        import aa.bb.cc\n\n        acu = PythonFileReporter(aa)\n        bcu = PythonFileReporter(aa.bb)\n        ccu = PythonFileReporter(aa.bb.cc)\n        assert acu.relative_filename() == os_sep(\"aa/__init__.py\")\n        assert bcu.relative_filename() == os_sep(\"aa/bb/__init__.py\")\n        assert ccu.relative_filename() == os_sep(\"aa/bb/cc/__init__.py\")\n        assert acu.source() == \"# aa\\n\"\n        assert bcu.source() == \"# bb\\n\"\n        assert ccu.source() == \"\"  # yes, empty\n\n    def test_module_files(self) -> None:\n        import aa.afile\n        import aa.bb.bfile\n        import aa.bb.cc.cfile\n\n        acu = PythonFileReporter(aa.afile)\n        bcu = PythonFileReporter(aa.bb.bfile)\n        ccu = PythonFileReporter(aa.bb.cc.cfile)\n        assert acu.relative_filename() == os_sep(\"aa/afile.py\")\n        assert bcu.relative_filename() == os_sep(\"aa/bb/bfile.py\")\n        assert ccu.relative_filename() == os_sep(\"aa/bb/cc/cfile.py\")\n        assert acu.source() == \"# afile.py\\n\"\n        assert bcu.source() == \"# bfile.py\\n\"\n        assert ccu.source() == \"# cfile.py\\n\"\n\n    def test_comparison(self) -> None:\n        acu = FileReporter(\"aa/afile.py\")\n        acu2 = FileReporter(\"aa/afile.py\")\n        zcu = FileReporter(\"aa/zfile.py\")\n        bcu = FileReporter(\"aa/bb/bfile.py\")\n        assert acu == acu2 and acu <= acu2 and acu >= acu2      # pylint: disable=chained-comparison\n        assert acu < zcu and acu <= zcu and acu != zcu\n        assert zcu > acu and zcu >= acu and zcu != acu\n        assert acu < bcu and acu <= bcu and acu != bcu\n        assert bcu > acu and bcu >= acu and bcu != acu\n\n    def test_zipfile(self) -> None:\n        sys.path.append(\"tests/zip1.zip\")\n\n        # Test that we can get files out of zipfiles, and read their source files.\n        # The zip1 module is installed by an action in igor.py.\n        import zip1\n        import zip1.zip1\n\n        # Verify that we really imported from an zipfile.  If we did, then the\n        # __file__ won't be an actual file, because one of the \"directories\"\n        # in the path is actually the zip file.\n        self.assert_doesnt_exist(zip1.__file__)\n\n        z1 = PythonFileReporter(zip1)\n        z1z1 = PythonFileReporter(zip1.zip1)\n        assert z1.source() == \"\"\n        assert \"# My zip file!\" in z1z1.source().splitlines()\n", "tests/test_xml.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for XML reports from coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport os.path\nimport re\n\nfrom typing import Any, Iterator\nfrom xml.etree import ElementTree\n\nimport pytest\n\nimport coverage\nfrom coverage import Coverage, env\nfrom coverage.exceptions import NoDataError\nfrom coverage.files import abs_file\nfrom coverage.misc import import_local_file\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.goldtest import compare, gold_path\nfrom tests.helpers import assert_coverage_warnings, change_dir\n\n\nclass XmlTestHelpers(CoverageTest):\n    \"\"\"Methods to use from XML tests.\"\"\"\n\n    def run_doit(self) -> Coverage:\n        \"\"\"Construct a simple sub-package.\"\"\"\n        self.make_file(\"sub/__init__.py\")\n        self.make_file(\"sub/doit.py\", \"print('doit!')\")\n        self.make_file(\"main.py\", \"import sub.doit\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"main\")\n        return cov\n\n    def make_tree(self, width: int, depth: int, curdir: str = \".\") -> None:\n        \"\"\"Make a tree of packages.\n\n        Makes `width` directories, named d0 .. d{width-1}. Each directory has\n        __init__.py, and `width` files, named f0.py .. f{width-1}.py.  Each\n        directory also has `width` sub-directories, in the same fashion, until\n        a depth of `depth` is reached.\n\n        \"\"\"\n        if depth == 0:\n            return\n\n        def here(p: str) -> str:\n            \"\"\"A path for `p` in our currently interesting directory.\"\"\"\n            return os.path.join(curdir, p)\n\n        for i in range(width):\n            next_dir = here(f\"d{i}\")\n            self.make_tree(width, depth-1, next_dir)\n        if curdir != \".\":\n            self.make_file(here(\"__init__.py\"), \"\")\n            for i in range(width):\n                filename = here(f\"f{i}.py\")\n                self.make_file(filename, f\"# {filename}\\n\")\n\n    def assert_source(\n        self,\n        xmldom: ElementTree.Element | ElementTree.ElementTree,\n        src: str,\n    ) -> None:\n        \"\"\"Assert that the XML has a <source> element with `src`.\"\"\"\n        src = abs_file(src)\n        elts = xmldom.findall(\".//sources/source\")\n        assert any(elt.text == src for elt in elts)\n\n\nclass XmlTestHelpersTest(XmlTestHelpers, CoverageTest):\n    \"\"\"Tests of methods in XmlTestHelpers.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_assert_source(self) -> None:\n        dom = ElementTree.fromstring(\"\"\"\\\n            <doc>\n                <src>foo</src>\n                <sources>\n                    <source>{cwd}something</source>\n                    <source>{cwd}another</source>\n                </sources>\n            </doc>\n            \"\"\".format(cwd=abs_file(\".\")+os.sep))\n\n        self.assert_source(dom, \"something\")\n        self.assert_source(dom, \"another\")\n\n        with pytest.raises(AssertionError):\n            self.assert_source(dom, \"hello\")\n        with pytest.raises(AssertionError):\n            self.assert_source(dom, \"foo\")\n        with pytest.raises(AssertionError):\n            self.assert_source(dom, \"thing\")\n\n\nclass XmlReportTest(XmlTestHelpers, CoverageTest):\n    \"\"\"Tests of the XML reports from coverage.py.\"\"\"\n\n    def make_mycode_data(self) -> None:\n        \"\"\"Pretend that we ran mycode.py, so we can report on it.\"\"\"\n        self.make_file(\"mycode.py\", \"print('hello')\\n\")\n        self.make_data_file(lines={abs_file(\"mycode.py\"): [1]})\n\n    def run_xml_report(self, **kwargs: Any) -> None:\n        \"\"\"Run xml_report()\"\"\"\n        cov = coverage.Coverage()\n        cov.load()\n        cov.xml_report(**kwargs)\n\n    def test_default_file_placement(self) -> None:\n        self.make_mycode_data()\n        self.run_xml_report()\n        self.assert_exists(\"coverage.xml\")\n        assert self.stdout() == \"\"\n\n    def test_argument_affects_xml_placement(self) -> None:\n        self.make_mycode_data()\n        cov = coverage.Coverage(messages=True)\n        cov.load()\n        cov.xml_report(outfile=\"put_it_there.xml\")\n        assert self.stdout() == \"Wrote XML report to put_it_there.xml\\n\"\n        self.assert_doesnt_exist(\"coverage.xml\")\n        self.assert_exists(\"put_it_there.xml\")\n\n    def test_output_directory_does_not_exist(self) -> None:\n        self.make_mycode_data()\n        self.run_xml_report(outfile=\"nonexistent/put_it_there.xml\")\n        self.assert_doesnt_exist(\"coverage.xml\")\n        self.assert_doesnt_exist(\"put_it_there.xml\")\n        self.assert_exists(\"nonexistent/put_it_there.xml\")\n\n    def test_config_affects_xml_placement(self) -> None:\n        self.make_mycode_data()\n        self.make_file(\".coveragerc\", \"[xml]\\noutput = xml.out\\n\")\n        self.run_xml_report()\n        self.assert_doesnt_exist(\"coverage.xml\")\n        self.assert_exists(\"xml.out\")\n\n    def test_no_data(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/210\n        with pytest.raises(NoDataError, match=\"No data to report.\"):\n            self.run_xml_report()\n        self.assert_doesnt_exist(\"coverage.xml\")\n        self.assert_doesnt_exist(\".coverage\")\n\n    def test_no_source(self) -> None:\n        # Written while investigating a bug, might as well keep it.\n        # https://github.com/nedbat/coveragepy/issues/208\n        self.make_file(\"innocuous.py\", \"a = 4\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"innocuous\")\n        os.remove(\"innocuous.py\")\n        with pytest.warns(Warning) as warns:\n            cov.xml_report(ignore_errors=True)\n        assert_coverage_warnings(\n            warns,\n            re.compile(r\"Couldn't parse '.*innocuous.py'. \\(couldnt-parse\\)\"),\n        )\n        self.assert_exists(\"coverage.xml\")\n\n    def test_filename_format_showing_everything(self) -> None:\n        cov = self.run_doit()\n        cov.xml_report()\n        dom = ElementTree.parse(\"coverage.xml\")\n        elts = dom.findall(\".//class[@name='doit.py']\")\n        assert len(elts) == 1\n        assert elts[0].get('filename') == \"sub/doit.py\"\n\n    def test_filename_format_including_filename(self) -> None:\n        cov = self.run_doit()\n        cov.xml_report([\"sub/doit.py\"])\n        dom = ElementTree.parse(\"coverage.xml\")\n        elts = dom.findall(\".//class[@name='doit.py']\")\n        assert len(elts) == 1\n        assert elts[0].get('filename') == \"sub/doit.py\"\n\n    def test_filename_format_including_module(self) -> None:\n        cov = self.run_doit()\n        import sub.doit                         # pylint: disable=import-error\n        cov.xml_report([sub.doit])\n        dom = ElementTree.parse(\"coverage.xml\")\n        elts = dom.findall(\".//class[@name='doit.py']\")\n        assert len(elts) == 1\n        assert elts[0].get('filename') == \"sub/doit.py\"\n\n    def test_reporting_on_nothing(self) -> None:\n        # Used to raise a zero division error:\n        # https://github.com/nedbat/coveragepy/issues/250\n        self.make_file(\"empty.py\", \"\")\n        cov = coverage.Coverage()\n        empty = self.start_import_stop(cov, \"empty\")\n        cov.xml_report([empty])\n        dom = ElementTree.parse(\"coverage.xml\")\n        elts = dom.findall(\".//class[@name='empty.py']\")\n        assert len(elts) == 1\n        assert elts[0].get('filename') == \"empty.py\"\n        assert elts[0].get('line-rate') == '1'\n\n    def test_empty_file_is_100_not_0(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/345\n        cov = self.run_doit()\n        cov.xml_report()\n        dom = ElementTree.parse(\"coverage.xml\")\n        elts = dom.findall(\".//class[@name='__init__.py']\")\n        assert len(elts) == 1\n        assert elts[0].get('line-rate') == '1'\n\n    def test_empty_file_is_skipped(self) -> None:\n        cov = self.run_doit()\n        cov.xml_report(skip_empty=True)\n        dom = ElementTree.parse(\"coverage.xml\")\n        elts = dom.findall(\".//class[@name='__init__.py']\")\n        assert len(elts) == 0\n\n    def test_curdir_source(self) -> None:\n        # With no source= option, the XML report should explain that the source\n        # is in the current directory.\n        cov = self.run_doit()\n        cov.xml_report()\n        dom = ElementTree.parse(\"coverage.xml\")\n        self.assert_source(dom, \".\")\n        sources = dom.findall(\".//source\")\n        assert len(sources) == 1\n\n    def test_deep_source(self) -> None:\n        # When using source=, the XML report needs to mention those directories\n        # in the <source> elements.\n        # https://github.com/nedbat/coveragepy/issues/439\n        self.make_file(\"src/main/foo.py\", \"a = 1\")\n        self.make_file(\"also/over/there/bar.py\", \"b = 2\")\n\n        cov = coverage.Coverage(source=[\"src/main\", \"also/over/there\", \"not/really\"])\n        with cov.collect():\n            mod_foo = import_local_file(\"foo\", \"src/main/foo.py\")\n            mod_bar = import_local_file(\"bar\", \"also/over/there/bar.py\")\n\n        with pytest.warns(Warning) as warns:\n            cov.xml_report([mod_foo, mod_bar])\n        assert_coverage_warnings(\n            warns,\n            \"Module not/really was never imported. (module-not-imported)\",\n        )\n        dom = ElementTree.parse(\"coverage.xml\")\n\n        self.assert_source(dom, \"src/main\")\n        self.assert_source(dom, \"also/over/there\")\n        sources = dom.findall(\".//source\")\n        assert len(sources) == 2\n\n        foo_class = dom.findall(\".//class[@name='foo.py']\")\n        assert len(foo_class) == 1\n        assert foo_class[0].attrib == {\n            'branch-rate': '0',\n            'complexity': '0',\n            'filename': 'foo.py',\n            'line-rate': '1',\n            'name': 'foo.py',\n        }\n\n        bar_class = dom.findall(\".//class[@name='bar.py']\")\n        assert len(bar_class) == 1\n        assert bar_class[0].attrib == {\n            'branch-rate': '0',\n            'complexity': '0',\n            'filename': 'bar.py',\n            'line-rate': '1',\n            'name': 'bar.py',\n        }\n\n    def test_nonascii_directory(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/573\n        self.make_file(\"\ud14c\uc2a4\ud2b8/program.py\", \"a = 1\")\n        with change_dir(\"\ud14c\uc2a4\ud2b8\"):\n            cov = coverage.Coverage()\n            self.start_import_stop(cov, \"program\")\n            cov.xml_report()\n\n    def test_accented_dot_py(self) -> None:\n        # Make a file with a non-ascii character in the filename.\n        self.make_file(\"h\\xe2t.py\", \"print('accented')\")\n        self.make_data_file(lines={abs_file(\"h\\xe2t.py\"): [1]})\n        cov = coverage.Coverage()\n        cov.load()\n        cov.xml_report()\n        # The XML report is always UTF8-encoded.\n        with open(\"coverage.xml\", \"rb\") as xmlf:\n            xml = xmlf.read()\n        assert ' filename=\"h\\xe2t.py\"'.encode() in xml\n        assert ' name=\"h\\xe2t.py\"'.encode() in xml\n\n    def test_accented_directory(self) -> None:\n        # Make a file with a non-ascii character in the directory name.\n        self.make_file(\"\\xe2/accented.py\", \"print('accented')\")\n        self.make_data_file(lines={abs_file(\"\\xe2/accented.py\"): [1]})\n\n        # The XML report is always UTF8-encoded.\n        cov = coverage.Coverage()\n        cov.load()\n        cov.xml_report()\n        with open(\"coverage.xml\", \"rb\") as xmlf:\n            xml = xmlf.read()\n        assert b' filename=\"\\xc3\\xa2/accented.py\"' in xml\n        assert b' name=\"accented.py\"' in xml\n\n        dom = ElementTree.parse(\"coverage.xml\")\n        elts = dom.findall(\".//package[@name='\u00e2']\")\n        assert len(elts) == 1\n        assert elts[0].attrib == {\n            \"branch-rate\": \"0\",\n            \"complexity\": \"0\",\n            \"line-rate\": \"1\",\n            \"name\": \"\u00e2\",\n        }\n\n    def test_no_duplicate_packages(self) -> None:\n        self.make_file(\n            \"namespace/package/__init__.py\",\n            \"from . import sample; from . import test; from .subpackage import test\",\n        )\n        self.make_file(\"namespace/package/sample.py\", \"print('package.sample')\")\n        self.make_file(\"namespace/package/test.py\", \"print('package.test')\")\n        self.make_file(\"namespace/package/subpackage/test.py\", \"print('package.subpackage.test')\")\n\n        # no source path passed to coverage!\n        # problem occurs when they are dynamically generated during xml report\n        cov = coverage.Coverage()\n        with cov.collect():\n            import_local_file(\"foo\", \"namespace/package/__init__.py\")\n\n        cov.xml_report()\n\n        dom = ElementTree.parse(\"coverage.xml\")\n\n        # only two packages should be present\n        packages = dom.findall(\".//package\")\n        assert len(packages) == 2\n\n        # one of them is namespace.package\n        named_package = dom.findall(\".//package[@name='namespace.package']\")\n        assert len(named_package) == 1\n\n        # the other one namespace.package.subpackage\n        named_sub_package = dom.findall(\".//package[@name='namespace.package.subpackage']\")\n        assert len(named_sub_package) == 1\n\n    def test_bug_1709(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1709\n        self.make_file(\"main.py\", \"import x1y, x01y, x001y\")\n        self.make_file(\"x1y.py\", \"print('x1y')\")\n        self.make_file(\"x01y.py\", \"print('x01y')\")\n        self.make_file(\"x001y.py\", \"print('x001y')\")\n\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n        assert self.stdout() == \"x1y\\nx01y\\nx001y\\n\"\n        # This used to raise:\n        # TypeError: '<' not supported between instances of 'Element' and 'Element'\n        cov.xml_report()\n\n\ndef unbackslash(v: Any) -> Any:\n    \"\"\"Find strings in `v`, and replace backslashes with slashes throughout.\"\"\"\n    if isinstance(v, (tuple, list)):\n        return [unbackslash(vv) for vv in v]\n    elif isinstance(v, dict):\n        return {k: unbackslash(vv) for k, vv in v.items()}\n    else:\n        assert isinstance(v, str)\n        return v.replace(\"\\\\\", \"/\")\n\n\nclass XmlPackageStructureTest(XmlTestHelpers, CoverageTest):\n    \"\"\"Tests about the package structure reported in the coverage.xml file.\"\"\"\n\n    def package_and_class_tags(self, cov: Coverage) -> Iterator[tuple[str, dict[str, Any]]]:\n        \"\"\"Run an XML report on `cov`, and get the package and class tags.\"\"\"\n        cov.xml_report()\n        dom = ElementTree.parse(\"coverage.xml\")\n        for node in dom.iter():\n            if node.tag in ('package', 'class'):\n                yield (node.tag, {a:v for a,v in node.items() if a in ('name', 'filename')})\n\n    def assert_package_and_class_tags(self, cov: Coverage, result: Any) -> None:\n        \"\"\"Check the XML package and class tags from `cov` match `result`.\"\"\"\n        assert unbackslash(list(self.package_and_class_tags(cov))) == unbackslash(result)\n\n    def test_package_names(self) -> None:\n        self.make_tree(width=1, depth=3)\n        self.make_file(\"main.py\", \"\"\"\\\n            from d0.d0 import f0\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"main\")\n        self.assert_package_and_class_tags(cov, [\n            ('package', {'name': \".\"}),\n            ('class', {'filename': \"main.py\", 'name': \"main.py\"}),\n            ('package', {'name': \"d0\"}),\n            ('class', {'filename': \"d0/__init__.py\", 'name': \"__init__.py\"}),\n            ('class', {'filename': \"d0/f0.py\", 'name': \"f0.py\"}),\n            ('package', {'name': \"d0.d0\"}),\n            ('class', {'filename': \"d0/d0/__init__.py\", 'name': \"__init__.py\"}),\n            ('class', {'filename': \"d0/d0/f0.py\", 'name': \"f0.py\"}),\n        ])\n\n    def test_package_depth_1(self) -> None:\n        self.make_tree(width=1, depth=4)\n        self.make_file(\"main.py\", \"\"\"\\\n            from d0.d0 import f0\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"main\")\n\n        cov.set_option(\"xml:package_depth\", 1)\n        self.assert_package_and_class_tags(cov, [\n            ('package', {'name': \".\"}),\n            ('class', {'filename': \"main.py\", 'name': \"main.py\"}),\n            ('package', {'name': \"d0\"}),\n            ('class', {'filename': \"d0/__init__.py\", 'name': \"__init__.py\"}),\n            ('class', {'filename': \"d0/d0/__init__.py\", 'name': \"d0/__init__.py\"}),\n            ('class', {'filename': \"d0/d0/d0/__init__.py\", 'name': \"d0/d0/__init__.py\"}),\n            ('class', {'filename': \"d0/d0/d0/f0.py\", 'name': \"d0/d0/f0.py\"}),\n            ('class', {'filename': \"d0/d0/f0.py\", 'name': \"d0/f0.py\"}),\n            ('class', {'filename': \"d0/f0.py\", 'name': \"f0.py\"}),\n        ])\n\n    def test_package_depth_2(self) -> None:\n        self.make_tree(width=1, depth=4)\n        self.make_file(\"main.py\", \"\"\"\\\n            from d0.d0 import f0\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"main\")\n\n        cov.set_option(\"xml:package_depth\", 2)\n        self.assert_package_and_class_tags(cov, [\n            ('package', {'name': \".\"}),\n            ('class', {'filename': \"main.py\", 'name': \"main.py\"}),\n            ('package', {'name': \"d0\"}),\n            ('class', {'filename': \"d0/__init__.py\", 'name': \"__init__.py\"}),\n            ('class', {'filename': \"d0/f0.py\", 'name': \"f0.py\"}),\n            ('package', {'name': \"d0.d0\"}),\n            ('class', {'filename': \"d0/d0/__init__.py\", 'name': \"__init__.py\"}),\n            ('class', {'filename': \"d0/d0/d0/__init__.py\", 'name': \"d0/__init__.py\"}),\n            ('class', {'filename': \"d0/d0/d0/f0.py\", 'name': \"d0/f0.py\"}),\n            ('class', {'filename': \"d0/d0/f0.py\", 'name': \"f0.py\"}),\n        ])\n\n    def test_package_depth_3(self) -> None:\n        self.make_tree(width=1, depth=4)\n        self.make_file(\"main.py\", \"\"\"\\\n            from d0.d0 import f0\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"main\")\n\n        cov.set_option(\"xml:package_depth\", 3)\n        self.assert_package_and_class_tags(cov, [\n            ('package', {'name': \".\"}),\n            ('class', {'filename': \"main.py\", 'name': \"main.py\"}),\n            ('package', {'name': \"d0\"}),\n            ('class', {'filename': \"d0/__init__.py\", 'name': \"__init__.py\"}),\n            ('class', {'filename': \"d0/f0.py\", 'name': \"f0.py\"}),\n            ('package', {'name': \"d0.d0\"}),\n            ('class', {'filename': \"d0/d0/__init__.py\", 'name': \"__init__.py\"}),\n            ('class', {'filename': \"d0/d0/f0.py\", 'name': \"f0.py\"}),\n            ('package', {'name': \"d0.d0.d0\"}),\n            ('class', {'filename': \"d0/d0/d0/__init__.py\", 'name': \"__init__.py\"}),\n            ('class', {'filename': \"d0/d0/d0/f0.py\", 'name': \"f0.py\"}),\n        ])\n\n    def test_source_prefix(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/465\n        # https://github.com/nedbat/coveragepy/issues/526\n        self.make_file(\"src/mod.py\", \"print(17)\")\n        cov = coverage.Coverage(source=[\"src\"])\n        self.start_import_stop(cov, \"mod\", modfile=\"src/mod.py\")\n\n        self.assert_package_and_class_tags(cov, [\n            ('package', {'name': \".\"}),\n            ('class', {'filename': \"mod.py\", 'name': \"mod.py\"}),\n        ])\n        dom = ElementTree.parse(\"coverage.xml\")\n        self.assert_source(dom, \"src\")\n\n    @pytest.mark.parametrize(\"trail\", [\"\", \"/\", \"\\\\\"])\n    def test_relative_source(self, trail: str) -> None:\n        if trail == \"\\\\\" and not env.WINDOWS:\n            pytest.skip(\"trailing backslash is only for Windows\")\n        self.make_file(\"src/mod.py\", \"print(17)\")\n        cov = coverage.Coverage(source=[f\"src{trail}\"])\n        cov.set_option(\"run:relative_files\", True)\n        self.start_import_stop(cov, \"mod\", modfile=\"src/mod.py\")\n        cov.xml_report()\n\n        dom = ElementTree.parse(\"coverage.xml\")\n        elts = dom.findall(\".//sources/source\")\n        assert [elt.text for elt in elts] == [\"src\"]\n\n\ndef compare_xml(expected: str, actual: str, actual_extra: bool = False) -> None:\n    \"\"\"Specialized compare function for our XML files.\"\"\"\n    source_path = coverage.files.relative_directory().rstrip(r\"\\/\")\n\n    scrubs=[\n        (r' timestamp=\"\\d+\"', ' timestamp=\"TIMESTAMP\"'),\n        (r' version=\"[-.\\w]+\"', ' version=\"VERSION\"'),\n        (r'<source>\\s*.*?\\s*</source>', '<source>%s</source>' % re.escape(source_path)),\n        (r'/coverage\\.readthedocs\\.io/?[-.\\w/]*', '/coverage.readthedocs.io/VER'),\n    ]\n    compare(expected, actual, scrubs=scrubs, actual_extra=actual_extra)\n\n\nclass XmlGoldTest(CoverageTest):\n    \"\"\"Tests of XML reporting that use gold files.\"\"\"\n\n    def test_a_xml_1(self) -> None:\n        self.make_file(\"a.py\", \"\"\"\\\n            if 1 < 2:\n                # Needed a < to look at HTML entities.\n                a = 3\n            else:\n                a = 4\n            \"\"\")\n\n        cov = coverage.Coverage()\n        a = self.start_import_stop(cov, \"a\")\n        cov.xml_report(a, outfile=\"coverage.xml\")\n        compare_xml(gold_path(\"xml/x_xml\"), \".\", actual_extra=True)\n\n    def test_a_xml_2(self) -> None:\n        self.make_file(\"a.py\", \"\"\"\\\n            if 1 < 2:\n                # Needed a < to look at HTML entities.\n                a = 3\n            else:\n                a = 4\n            \"\"\")\n\n        self.make_file(\"run_a_xml_2.ini\", \"\"\"\\\n            # Put all the XML output in xml_2\n            [xml]\n            output = xml_2/coverage.xml\n            \"\"\")\n\n        cov = coverage.Coverage(config_file=\"run_a_xml_2.ini\")\n        a = self.start_import_stop(cov, \"a\")\n        cov.xml_report(a)\n        compare_xml(gold_path(\"xml/x_xml\"), \"xml_2\")\n\n    def test_y_xml_branch(self) -> None:\n        self.make_file(\"y.py\", \"\"\"\\\n            def choice(x):\n                if x < 2:\n                    return 3\n                else:\n                    return 4\n\n            assert choice(1) == 3\n            \"\"\")\n\n        cov = coverage.Coverage(branch=True)\n        y = self.start_import_stop(cov, \"y\")\n        cov.xml_report(y, outfile=\"y_xml_branch/coverage.xml\")\n        compare_xml(gold_path(\"xml/y_xml_branch\"), \"y_xml_branch\")\n", "tests/test_report_core.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for helpers in report.py\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import IO, Iterable\n\nimport pytest\n\nfrom coverage.exceptions import CoverageException\nfrom coverage.report_core import render_report\nfrom coverage.types import TMorf\n\nfrom tests.coveragetest import CoverageTest\n\n\nclass FakeReporter:\n    \"\"\"A fake implementation of a one-file reporter.\"\"\"\n\n    report_type = \"fake report file\"\n\n    def __init__(self, output: str = \"\", error: type[Exception] | None = None) -> None:\n        self.output = output\n        self.error = error\n        self.morfs: Iterable[TMorf] | None = None\n\n    def report(self, morfs: Iterable[TMorf] | None, outfile: IO[str]) -> float:\n        \"\"\"Fake.\"\"\"\n        self.morfs = morfs\n        outfile.write(self.output)\n        if self.error:\n            raise self.error(\"You asked for it!\")\n        return 17.25\n\n\nclass RenderReportTest(CoverageTest):\n    \"\"\"Tests of render_report.\"\"\"\n\n    def test_stdout(self) -> None:\n        fake = FakeReporter(output=\"Hello!\\n\")\n        msgs: list[str] = []\n        res = render_report(\"-\", fake, [pytest, \"coverage\"], msgs.append)\n        assert res == 17.25\n        assert fake.morfs == [pytest, \"coverage\"]\n        assert self.stdout() == \"Hello!\\n\"\n        assert not msgs\n\n    def test_file(self) -> None:\n        fake = FakeReporter(output=\"Gr\u00e9\u00e8tings!\\n\")\n        msgs: list[str] = []\n        res = render_report(\"output.txt\", fake, [], msgs.append)\n        assert res == 17.25\n        assert self.stdout() == \"\"\n        with open(\"output.txt\", \"rb\") as f:\n            assert f.read().rstrip() == b\"Gr\\xc3\\xa9\\xc3\\xa8tings!\"\n        assert msgs == [\"Wrote fake report file to output.txt\"]\n\n    @pytest.mark.parametrize(\"error\", [CoverageException, ZeroDivisionError])\n    def test_exception(self, error: type[Exception]) -> None:\n        fake = FakeReporter(error=error)\n        msgs: list[str] = []\n        with pytest.raises(error, match=\"You asked for it!\"):\n            render_report(\"output.txt\", fake, [], msgs.append)\n        assert self.stdout() == \"\"\n        self.assert_doesnt_exist(\"output.txt\")\n        assert not msgs\n", "tests/covmodzip1.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n# Module-level docstrings are counted differently in different versions of Python,\n# so don't add one here.\n# pylint: disable=missing-module-docstring\n\n# covmodzip.py: for putting into a zip file.\nj = 1\nj += 1\n", "tests/test_concurrency.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for concurrency libraries.\"\"\"\n\nfrom __future__ import annotations\n\nimport glob\nimport multiprocessing\nimport os\nimport pathlib\nimport random\nimport re\nimport sys\nimport threading\nimport time\n\nfrom types import ModuleType\nfrom typing import Iterable\n\nfrom flaky import flaky\nimport pytest\n\nimport coverage\nfrom coverage import env\nfrom coverage.data import line_counts\nfrom coverage.exceptions import ConfigError\nfrom coverage.files import abs_file\nfrom coverage.misc import import_local_file\n\nfrom tests import testenv\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import flaky_method\n\n\n# These libraries aren't always available, we'll skip tests if they aren't.\n\ntry:\n    import eventlet\nexcept ImportError:\n    eventlet = None\n\ntry:\n    import gevent\nexcept ImportError:\n    gevent = None\n\ntry:\n    import greenlet\nexcept ImportError:\n    greenlet = None\n\n\ndef measurable_line(l: str) -> bool:\n    \"\"\"Is this a line of code coverage will measure?\n\n    Not blank, not a comment, and not \"else\"\n    \"\"\"\n    l = l.strip()\n    if not l:\n        return False\n    if l.startswith('#'):\n        return False\n    if l.startswith('else:'):\n        return False\n    return True\n\n\ndef line_count(s: str) -> int:\n    \"\"\"How many measurable lines are in `s`?\"\"\"\n    return len(list(filter(measurable_line, s.splitlines())))\n\n\ndef print_simple_annotation(code: str, linenos: Iterable[int]) -> None:\n    \"\"\"Print the lines in `code` with X for each line number in `linenos`.\"\"\"\n    for lineno, line in enumerate(code.splitlines(), start=1):\n        print(\" {} {}\".format(\"X\" if lineno in linenos else \" \", line))\n\n\nclass LineCountTest(CoverageTest):\n    \"\"\"Test the helpers here.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_line_count(self) -> None:\n        CODE = \"\"\"\n            # Hey there!\n            x = 1\n            if x:\n                print(\"hello\")\n            else:\n                print(\"bye\")\n\n            print(\"done\")\n            \"\"\"\n\n        assert line_count(CODE) == 5\n\n\n# The code common to all the concurrency models.\nSUM_RANGE_Q = \"\"\"\n    # Above this will be imports defining queue and threading.\n\n    class Producer(threading.Thread):\n        def __init__(self, limit, q):\n            threading.Thread.__init__(self)\n            self.limit = limit\n            self.q = q\n\n        def run(self):\n            for i in range(self.limit):\n                self.q.put(i)\n            self.q.put(None)\n\n    class Consumer(threading.Thread):\n        def __init__(self, q, qresult):\n            threading.Thread.__init__(self)\n            self.q = q\n            self.qresult = qresult\n\n        def run(self):\n            sum = 0\n            while \"no peephole\".upper():\n                i = self.q.get()\n                if i is None:\n                    break\n                sum += i\n            self.qresult.put(sum)\n\n    def sum_range(limit):\n        q = queue.Queue()\n        qresult = queue.Queue()\n        c = Consumer(q, qresult)\n        p = Producer(limit, q)\n        c.start()\n        p.start()\n\n        p.join()\n        c.join()\n        return qresult.get()\n\n    # Below this will be something using sum_range.\n    \"\"\"\n\nPRINT_SUM_RANGE = \"\"\"\n    print(sum_range({QLIMIT}))\n    \"\"\"\n\n# Import the things to use threads.\nTHREAD = \"\"\"\n    import threading\n    import queue\n    \"\"\"\n\n# Import the things to use eventlet.\nEVENTLET = \"\"\"\n    import eventlet.green.threading as threading\n    import eventlet.queue as queue\n    \"\"\"\n\n# Import the things to use gevent.\nGEVENT = \"\"\"\n    from gevent import monkey\n    monkey.patch_thread()\n    import threading\n    import gevent.queue as queue\n    \"\"\"\n\n# Uncomplicated code that doesn't use any of the concurrency stuff, to test\n# the simple case under each of the regimes.\nSIMPLE = \"\"\"\n    total = 0\n    for i in range({QLIMIT}):\n        total += i\n    print(total)\n    \"\"\"\n\n\ndef cant_trace_msg(concurrency: str, the_module: ModuleType | None) -> str | None:\n    \"\"\"What might coverage.py say about a concurrency setting and imported module?\"\"\"\n    # In the concurrency choices, \"multiprocessing\" doesn't count, so remove it.\n    if \"multiprocessing\" in concurrency:\n        parts = concurrency.split(\",\")\n        parts.remove(\"multiprocessing\")\n        concurrency = \",\".join(parts)\n\n    if the_module is None:\n        # We don't even have the underlying module installed, we expect\n        # coverage to alert us to this fact.\n        expected_out = (\n            f\"Couldn't trace with concurrency={concurrency}, the module isn't installed.\\n\"\n        )\n    elif testenv.C_TRACER or concurrency == \"thread\" or concurrency == \"\":\n        expected_out = None\n    else:\n        expected_out = (\n            f\"Can't support concurrency={concurrency} with PyTracer, only threads are supported.\\n\"\n        )\n    return expected_out\n\n\nclass ConcurrencyTest(CoverageTest):\n    \"\"\"Tests of the concurrency support in coverage.py.\"\"\"\n\n    QLIMIT = 1000\n\n    def try_some_code(\n        self,\n        code: str,\n        concurrency: str,\n        the_module: ModuleType,\n        expected_out: str | None = None,\n    ) -> None:\n        \"\"\"Run some concurrency testing code and see that it was all covered.\n\n        `code` is the Python code to execute.  `concurrency` is the name of\n        the concurrency regime to test it under.  `the_module` is the imported\n        module that must be available for this to work at all. `expected_out`\n        is the text we expect the code to produce.\n\n        \"\"\"\n        self.make_file(\"try_it.py\", code)\n\n        cmd = f\"coverage run --concurrency={concurrency} try_it.py\"\n        out = self.run_command(cmd)\n\n        expected_cant_trace = cant_trace_msg(concurrency, the_module)\n\n        if expected_cant_trace is not None:\n            assert out == expected_cant_trace\n            pytest.skip(f\"Can't test: {expected_cant_trace}\")\n        else:\n            # We can fully measure the code if we are using the C tracer, which\n            # can support all the concurrency, or if we are using threads.\n            if expected_out is None:\n                expected_out = \"%d\\n\" % (sum(range(self.QLIMIT)))\n            print(code)\n            assert out == expected_out\n\n            # Read the coverage file and see that try_it.py has all its lines\n            # executed.\n            data = coverage.CoverageData(\".coverage\")\n            data.read()\n\n            # If the test fails, it's helpful to see this info:\n            fname = abs_file(\"try_it.py\")\n            linenos = data.lines(fname)\n            assert linenos is not None\n            print(f\"{len(linenos)}: {linenos}\")\n            print_simple_annotation(code, linenos)\n\n            lines = line_count(code)\n            assert line_counts(data)['try_it.py'] == lines\n\n    def test_threads(self) -> None:\n        code = (THREAD + SUM_RANGE_Q + PRINT_SUM_RANGE).format(QLIMIT=self.QLIMIT)\n        self.try_some_code(code, \"thread\", threading)\n\n    def test_threads_simple_code(self) -> None:\n        code = SIMPLE.format(QLIMIT=self.QLIMIT)\n        self.try_some_code(code, \"thread\", threading)\n\n    def test_eventlet(self) -> None:\n        code = (EVENTLET + SUM_RANGE_Q + PRINT_SUM_RANGE).format(QLIMIT=self.QLIMIT)\n        self.try_some_code(code, \"eventlet\", eventlet)\n\n    def test_eventlet_simple_code(self) -> None:\n        code = SIMPLE.format(QLIMIT=self.QLIMIT)\n        self.try_some_code(code, \"eventlet\", eventlet)\n\n    # https://github.com/nedbat/coveragepy/issues/663\n    @pytest.mark.skipif(env.WINDOWS, reason=\"gevent has problems on Windows: #663\")\n    def test_gevent(self) -> None:\n        code = (GEVENT + SUM_RANGE_Q + PRINT_SUM_RANGE).format(QLIMIT=self.QLIMIT)\n        self.try_some_code(code, \"gevent\", gevent)\n\n    def test_gevent_simple_code(self) -> None:\n        code = SIMPLE.format(QLIMIT=self.QLIMIT)\n        self.try_some_code(code, \"gevent\", gevent)\n\n    def test_greenlet(self) -> None:\n        GREENLET = \"\"\"\\\n            from greenlet import greenlet\n\n            def test1(x, y):\n                z = gr2.switch(x+y)\n                print(z)\n\n            def test2(u):\n                print(u)\n                gr1.switch(42)\n\n            gr1 = greenlet(test1)\n            gr2 = greenlet(test2)\n            gr1.switch(\"hello\", \" world\")\n            \"\"\"\n        self.try_some_code(GREENLET, \"greenlet\", greenlet, \"hello world\\n42\\n\")\n\n    def test_greenlet_simple_code(self) -> None:\n        code = SIMPLE.format(QLIMIT=self.QLIMIT)\n        self.try_some_code(code, \"greenlet\", greenlet)\n\n    def test_bug_330(self) -> None:\n        BUG_330 = \"\"\"\\\n            from weakref import WeakKeyDictionary\n            import eventlet\n\n            def do():\n                eventlet.sleep(.01)\n\n            gts = WeakKeyDictionary()\n            for _ in range(100):\n                gts[eventlet.spawn(do)] = True\n                eventlet.sleep(.005)\n\n            eventlet.sleep(.1)\n            print(len(gts))\n            \"\"\"\n        self.try_some_code(BUG_330, \"eventlet\", eventlet, \"0\\n\")\n\n    @flaky_method(max_runs=3)   # Sometimes a test fails due to inherent randomness. Try more times.\n    def test_threads_with_gevent(self) -> None:\n        self.make_file(\"both.py\", \"\"\"\\\n            import queue\n            import threading\n\n            import gevent\n\n            def work1(q):\n                q.put(1)\n\n            def gwork(q):\n                gevent.spawn(work1, q).join()\n                q.put(None)\n                print(\"done\")\n\n            q = queue.Queue()\n            t = threading.Thread(target=gwork, args=(q,))\n            t.start()\n            t.join()\n\n            answer = q.get()\n            assert answer == 1\n            \"\"\")\n        out = self.run_command(\"coverage run --concurrency=thread,gevent both.py\")\n        if gevent is None:\n            assert out == (\n                \"Couldn't trace with concurrency=gevent, the module isn't installed.\\n\"\n            )\n            pytest.skip(\"Can't run test without gevent installed.\")\n        if not testenv.C_TRACER:\n            assert out == (\n                \"Can't support concurrency=gevent with PyTracer, only threads are supported.\\n\"\n            )\n            pytest.skip(\"Can't run gevent with PyTracer\")\n\n        assert out == \"done\\n\"\n\n        out = self.run_command(\"coverage report -m\")\n        last_line = self.squeezed_lines(out)[-1]\n        assert re.search(r\"TOTAL \\d+ 0 100%\", last_line)\n\n    def test_bad_concurrency(self) -> None:\n        with pytest.raises(ConfigError, match=\"Unknown concurrency choices: nothing\"):\n            self.command_line(\"run --concurrency=nothing prog.py\")\n\n    def test_bad_concurrency_in_config(self) -> None:\n        self.make_file(\".coveragerc\", \"[run]\\nconcurrency = nothing\\n\")\n        with pytest.raises(ConfigError, match=\"Unknown concurrency choices: nothing\"):\n            self.command_line(\"run prog.py\")\n\n    def test_no_multiple_light_concurrency(self) -> None:\n        with pytest.raises(ConfigError, match=\"Conflicting concurrency settings: eventlet, gevent\"):\n            self.command_line(\"run --concurrency=gevent,eventlet prog.py\")\n\n    def test_no_multiple_light_concurrency_in_config(self) -> None:\n        self.make_file(\".coveragerc\", \"[run]\\nconcurrency = gevent, eventlet\\n\")\n        with pytest.raises(ConfigError, match=\"Conflicting concurrency settings: eventlet, gevent\"):\n            self.command_line(\"run prog.py\")\n\n    def test_multiprocessing_needs_config_file(self) -> None:\n        with pytest.raises(ConfigError, match=\"multiprocessing requires a configuration file\"):\n            self.command_line(\"run --concurrency=multiprocessing prog.py\")\n\n\nclass WithoutConcurrencyModuleTest(CoverageTest):\n    \"\"\"Tests of what happens if the requested concurrency isn't installed.\"\"\"\n\n    @pytest.mark.parametrize(\"module\", [\"eventlet\", \"gevent\", \"greenlet\"])\n    def test_missing_module(self, module: str) -> None:\n        self.make_file(\"prog.py\", \"a = 1\")\n        sys.modules[module] = None      # type: ignore[assignment]\n        msg = f\"Couldn't trace with concurrency={module}, the module isn't installed.\"\n        with pytest.raises(ConfigError, match=msg):\n            self.command_line(f\"run --concurrency={module} prog.py\")\n\n\nSQUARE_OR_CUBE_WORK = \"\"\"\n    def work(x):\n        # Use different lines in different subprocesses.\n        if x % 2:\n            y = x*x\n        else:\n            y = x*x*x\n        return y\n    \"\"\"\n\nSUM_RANGE_WORK = \"\"\"\n    def work(x):\n        return sum_range((x+1)*100)\n    \"\"\"\n\nMULTI_CODE = \"\"\"\n    # Above this will be a definition of work().\n    import multiprocessing\n    import os\n    import time\n    import sys\n\n    def process_worker_main(args):\n        # Need to pause, or the tasks go too quickly, and some processes\n        # in the pool don't get any work, and then don't record data.\n        ret = work(*args)\n        time.sleep(0.1)\n        return os.getpid(), ret\n\n    if __name__ == \"__main__\":      # pragma: no branch\n        # This if is on a single line so we can get 100% coverage\n        # even if we have no arguments.\n        if len(sys.argv) > 1: multiprocessing.set_start_method(sys.argv[1])\n        pool = multiprocessing.Pool({NPROCS})\n        inputs = [(x,) for x in range({UPTO})]\n        outputs = pool.imap_unordered(process_worker_main, inputs)\n        pids = set()\n        total = 0\n        for pid, sq in outputs:\n            pids.add(pid)\n            total += sq\n        print(f\"{{len(pids)}} pids, {{total = }}\")\n        pool.close()\n        pool.join()\n    \"\"\"\n\n\n@pytest.fixture(params=[\"fork\", \"spawn\"], name=\"start_method\")\ndef start_method_fixture(request: pytest.FixtureRequest) -> str:\n    \"\"\"Parameterized fixture to choose the start_method for multiprocessing.\"\"\"\n    start_method: str = request.param\n    if start_method not in multiprocessing.get_all_start_methods():\n        # Windows doesn't support \"fork\".\n        pytest.skip(f\"start_method={start_method} not supported here\")\n    return start_method\n\n\n#@flaky(max_runs=30)         # Sometimes a test fails due to inherent randomness. Try more times.\nclass MultiprocessingTest(CoverageTest):\n    \"\"\"Test support of the multiprocessing module.\"\"\"\n\n    def try_multiprocessing_code(\n        self,\n        code: str,\n        expected_out: str | None,\n        the_module: ModuleType,\n        nprocs: int,\n        start_method: str,\n        concurrency: str = \"multiprocessing\",\n        args: str = \"\",\n    ) -> None:\n        \"\"\"Run code using multiprocessing, it should produce `expected_out`.\"\"\"\n        self.make_file(\"multi.py\", code)\n        self.make_file(\".coveragerc\", f\"\"\"\\\n            [run]\n            concurrency = {concurrency}\n            source = .\n            \"\"\")\n\n        cmd = f\"coverage run {args} multi.py {start_method}\"\n        out = self.run_command(cmd)\n        expected_cant_trace = cant_trace_msg(concurrency, the_module)\n\n        if expected_cant_trace is not None:\n            print(out)\n            assert out == expected_cant_trace\n            pytest.skip(f\"Can't test: {expected_cant_trace}\")\n        else:\n            assert out.rstrip() == expected_out\n            assert len(glob.glob(\".coverage.*\")) == nprocs + 1\n\n            out = self.run_command(\"coverage combine\")\n            out_lines = out.splitlines()\n            assert len(out_lines) == nprocs + 1\n            assert all(\n                re.fullmatch(\n                    r\"(Combined data file|Skipping duplicate data) \\.coverage\\..*\\.\\d+\\.X\\w{6}x\",\n                    line,\n                )\n                for line in out_lines\n            )\n            assert len(glob.glob(\".coverage.*\")) == 0\n            out = self.run_command(\"coverage report -m\")\n\n            last_line = self.squeezed_lines(out)[-1]\n            assert re.search(r\"TOTAL \\d+ 0 100%\", last_line)\n\n    def test_multiprocessing_simple(self, start_method: str) -> None:\n        nprocs = 3\n        upto = 30\n        code = (SQUARE_OR_CUBE_WORK + MULTI_CODE).format(NPROCS=nprocs, UPTO=upto)\n        total = sum(x*x if x%2 else x*x*x for x in range(upto))\n        expected_out = f\"{nprocs} pids, {total = }\"\n        self.try_multiprocessing_code(\n            code,\n            expected_out,\n            threading,\n            nprocs,\n            start_method=start_method,\n        )\n\n    def test_multiprocessing_append(self, start_method: str) -> None:\n        nprocs = 3\n        upto = 30\n        code = (SQUARE_OR_CUBE_WORK + MULTI_CODE).format(NPROCS=nprocs, UPTO=upto)\n        total = sum(x*x if x%2 else x*x*x for x in range(upto))\n        expected_out = f\"{nprocs} pids, total = {total}\"\n        self.try_multiprocessing_code(\n            code,\n            expected_out,\n            threading,\n            nprocs,\n            args=\"--append\",\n            start_method=start_method,\n        )\n\n    def test_multiprocessing_and_gevent(self, start_method: str) -> None:\n        nprocs = 3\n        upto = 30\n        code = (\n            SUM_RANGE_WORK + EVENTLET + SUM_RANGE_Q + MULTI_CODE\n        ).format(NPROCS=nprocs, UPTO=upto)\n        total = sum(sum(range((x + 1) * 100)) for x in range(upto))\n        expected_out = f\"{nprocs} pids, total = {total}\"\n        self.try_multiprocessing_code(\n            code,\n            expected_out,\n            eventlet,\n            nprocs,\n            concurrency=\"multiprocessing,eventlet\",\n            start_method=start_method,\n        )\n\n    def test_multiprocessing_with_branching(self, start_method: str) -> None:\n        nprocs = 3\n        upto = 30\n        code = (SQUARE_OR_CUBE_WORK + MULTI_CODE).format(NPROCS=nprocs, UPTO=upto)\n        total = sum(x*x if x%2 else x*x*x for x in range(upto))\n        expected_out = f\"{nprocs} pids, total = {total}\"\n        self.make_file(\"multi.py\", code)\n        self.make_file(\"multi.rc\", \"\"\"\\\n            [run]\n            concurrency = multiprocessing\n            branch = True\n            omit = */site-packages/*\n            \"\"\")\n\n        out = self.run_command(f\"coverage run --rcfile=multi.rc multi.py {start_method}\")\n        assert out.rstrip() == expected_out\n\n        out = self.run_command(\"coverage combine -q\")   # sneak in a test of -q\n        assert out == \"\"\n        out = self.run_command(\"coverage report -m\")\n\n        last_line = self.squeezed_lines(out)[-1]\n        assert re.search(r\"TOTAL \\d+ 0 \\d+ 0 100%\", last_line)\n\n    def test_multiprocessing_bootstrap_error_handling(self) -> None:\n        # An exception during bootstrapping will be reported.\n        self.make_file(\"multi.py\", \"\"\"\\\n            import multiprocessing\n            if __name__ == \"__main__\":\n                with multiprocessing.Manager():\n                    pass\n            \"\"\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            concurrency = multiprocessing\n            _crash = _bootstrap\n            \"\"\")\n        out = self.run_command(\"coverage run multi.py\")\n        assert \"Exception during multiprocessing bootstrap init\" in out\n        assert \"RuntimeError: Crashing because called by _bootstrap\" in out\n\n    def test_bug_890(self) -> None:\n        # chdir in multiprocessing shouldn't keep us from finding the\n        # .coveragerc file.\n        self.make_file(\"multi.py\", \"\"\"\\\n            import multiprocessing, os, os.path\n            if __name__ == \"__main__\":\n                if not os.path.exists(\"./tmp\"): os.mkdir(\"./tmp\")\n                os.chdir(\"./tmp\")\n                with multiprocessing.Manager():\n                    pass\n                print(\"ok\")\n            \"\"\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            concurrency = multiprocessing\n            \"\"\")\n        out = self.run_command(\"coverage run multi.py\")\n        assert out.splitlines()[-1] == \"ok\"\n\n\n@pytest.mark.skipif(not testenv.SETTRACE_CORE, reason=\"gettrace is not supported with this core.\")\ndef test_coverage_stop_in_threads() -> None:\n    has_started_coverage = []\n    has_stopped_coverage = []\n\n    def run_thread() -> None:           # pragma: nested\n        \"\"\"Check that coverage is stopping properly in threads.\"\"\"\n        deadline = time.time() + 5\n        ident = threading.current_thread().ident\n        if sys.gettrace() is not None:\n            has_started_coverage.append(ident)\n        while sys.gettrace() is not None:\n            # Wait for coverage to stop\n            time.sleep(0.01)\n            if time.time() > deadline:\n                return\n        has_stopped_coverage.append(ident)\n\n    cov = coverage.Coverage()\n    with cov.collect():\n        t = threading.Thread(target=run_thread)\n        t.start()\n\n        time.sleep(0.1)\n    t.join()\n\n    assert has_started_coverage == [t.ident]\n    assert has_stopped_coverage == [t.ident]\n\n\ndef test_thread_safe_save_data(tmp_path: pathlib.Path) -> None:\n    # Non-regression test for: https://github.com/nedbat/coveragepy/issues/581\n\n    # Create some Python modules and put them in the path\n    modules_dir = tmp_path / \"test_modules\"\n    modules_dir.mkdir()\n    module_names = [f\"m{i:03d}\" for i in range(1000)]\n    for module_name in module_names:\n        (modules_dir / (module_name + \".py\")).write_text(\"def f(): pass\\n\")\n\n    # Shared variables for threads\n    should_run = [True]\n    imported = []\n\n    old_dir = os.getcwd()\n    os.chdir(modules_dir)\n    try:\n        # Make sure that all dummy modules can be imported.\n        for module_name in module_names:\n            import_local_file(module_name)\n\n        def random_load() -> None:                      # pragma: nested\n            \"\"\"Import modules randomly to stress coverage.\"\"\"\n            while should_run[0]:\n                module_name = random.choice(module_names)\n                mod = import_local_file(module_name)\n                mod.f()\n                imported.append(mod)\n\n        # Spawn some threads with coverage enabled and attempt to read the\n        # results right after stopping coverage collection with the threads\n        #  still running.\n        duration = 0.01\n        for _ in range(3):\n            cov = coverage.Coverage()\n            with cov.collect():\n                threads = [threading.Thread(target=random_load) for _ in range(10)]\n                should_run[0] = True\n                for t in threads:\n                    t.start()\n\n                time.sleep(duration)\n\n            # The following call used to crash with running background threads.\n            cov.get_data()\n\n            # Stop the threads\n            should_run[0] = False\n            for t in threads:\n                t.join()\n\n            if (not imported) and duration < 10:    # pragma: only failure\n                duration *= 2\n\n    finally:\n        os.chdir(old_dir)\n        should_run[0] = False\n\n\n@pytest.mark.skipif(env.WINDOWS, reason=\"SIGTERM doesn't work the same on Windows\")\n@flaky(max_runs=3)          # Sometimes a test fails due to inherent randomness. Try more times.\nclass SigtermTest(CoverageTest):\n    \"\"\"Tests of our handling of SIGTERM.\"\"\"\n\n    @pytest.mark.parametrize(\"sigterm\", [False, True])\n    def test_sigterm_multiprocessing_saves_data(self, sigterm: bool) -> None:\n        # A terminated process should save its coverage data.\n        self.make_file(\"clobbered.py\", \"\"\"\\\n            import multiprocessing\n            import time\n\n            def subproc(x):\n                if x.value == 3:\n                    print(\"THREE\", flush=True)  # line 6, missed\n                else:\n                    print(\"NOT THREE\", flush=True)\n                x.value = 0\n                time.sleep(60)\n\n            if __name__ == \"__main__\":\n                print(\"START\", flush=True)\n                x = multiprocessing.Value(\"L\", 1)\n                proc = multiprocessing.Process(target=subproc, args=(x,))\n                proc.start()\n                while x.value != 0:\n                    time.sleep(.05)\n                proc.terminate()\n                print(\"END\", flush=True)\n            \"\"\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            parallel = True\n            concurrency = multiprocessing\n            \"\"\" + (\"sigterm = true\" if sigterm else \"\"),\n            )\n        out = self.run_command(\"coverage run clobbered.py\")\n        # Under Linux, things go wrong. Does that matter?\n        if env.LINUX and \"assert self._collectors\" in out:\n            lines = out.splitlines(True)\n            out = \"\".join(lines[:3])\n        assert out == \"START\\nNOT THREE\\nEND\\n\"\n        self.run_command(\"coverage combine\")\n        out = self.run_command(\"coverage report -m\")\n        if sigterm:\n            expected = \"clobbered.py 17 1 94% 6\"\n        else:\n            expected = \"clobbered.py 17 5 71% 5-10\"\n        assert self.squeezed_lines(out)[2] == expected\n\n    def test_sigterm_threading_saves_data(self) -> None:\n        # A terminated process should save its coverage data.\n        self.make_file(\"handler.py\", \"\"\"\\\n            import os, signal\n\n            print(\"START\", flush=True)\n            print(\"SIGTERM\", flush=True)\n            os.kill(os.getpid(), signal.SIGTERM)\n            print(\"NOT HERE\", flush=True)\n            \"\"\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            # The default concurrency option.\n            concurrency = thread\n            sigterm = true\n            \"\"\")\n        out = self.run_command(\"coverage run handler.py\")\n        out_lines = out.splitlines()\n        assert len(out_lines) in [2, 3]\n        assert out_lines[:2] == [\"START\", \"SIGTERM\"]\n        if len(out_lines) == 3:\n            assert out_lines[2] == \"Terminated\"\n        out = self.run_command(\"coverage report -m\")\n        expected = \"handler.py 5 1 80% 6\"\n        assert self.squeezed_lines(out)[2] == expected\n\n    def test_sigterm_still_runs(self) -> None:\n        # A terminated process still runs its own SIGTERM handler.\n        self.make_file(\"handler.py\", \"\"\"\\\n            import multiprocessing\n            import signal\n            import time\n\n            def subproc(x):\n                print(\"START\", flush=True)\n                def on_sigterm(signum, frame):\n                    print(\"SIGTERM\", flush=True)\n\n                signal.signal(signal.SIGTERM, on_sigterm)\n                x.value = 0\n                time.sleep(.1)\n                print(\"END\", flush=True)\n\n            if __name__ == \"__main__\":\n                x = multiprocessing.Value(\"L\", 1)\n                proc = multiprocessing.Process(target=subproc, args=(x,))\n                proc.start()\n                while x.value != 0:\n                    time.sleep(.02)\n                proc.terminate()\n            \"\"\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            parallel = True\n            concurrency = multiprocessing\n            sigterm = True\n            \"\"\")\n        out = self.run_command(\"coverage run handler.py\")\n        assert out == \"START\\nSIGTERM\\nEND\\n\"\n", "tests/test_api.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.py's API.\"\"\"\n\nfrom __future__ import annotations\n\nimport fnmatch\nimport glob\nimport io\nimport os\nimport os.path\nimport re\nimport shutil\nimport sys\nimport textwrap\n\nfrom typing import cast, Callable, Iterable\n\nimport pytest\n\nimport coverage\nfrom coverage import Coverage, env\nfrom coverage.data import line_counts, sorted_lines\nfrom coverage.exceptions import CoverageException, DataError, NoDataError, NoSource\nfrom coverage.files import abs_file, relative_filename\nfrom coverage.misc import import_local_file\nfrom coverage.types import FilePathClasses, FilePathType, TCovKwargs\n\nfrom tests import testenv\nfrom tests.coveragetest import CoverageTest, TESTS_DIR, UsingModulesMixin\nfrom tests.helpers import assert_count_equal, assert_coverage_warnings\nfrom tests.helpers import change_dir, nice_file, os_sep\n\nBAD_SQLITE_REGEX = r\"file( is encrypted or)? is not a database\"\n\nclass ApiTest(CoverageTest):\n    \"\"\"Api-oriented tests for coverage.py.\"\"\"\n\n    def clean_files(self, files: list[str], pats: list[str]) -> list[str]:\n        \"\"\"Remove names matching `pats` from `files`, a list of file names.\"\"\"\n        good = []\n        for f in files:\n            for pat in pats:\n                if fnmatch.fnmatch(f, pat):\n                    break\n            else:\n                good.append(f)\n        return good\n\n    def assertFiles(self, files: list[str]) -> None:\n        \"\"\"Assert that the files here are `files`, ignoring the usual junk.\"\"\"\n        here = os.listdir(\".\")\n        here = self.clean_files(here, [\"*.pyc\", \"__pycache__\", \"*$py.class\"])\n        assert_count_equal(here, files)\n\n    def test_unexecuted_file(self) -> None:\n        cov = coverage.Coverage()\n\n        self.make_file(\"mycode.py\", \"\"\"\\\n            a = 1\n            b = 2\n            if b == 3:\n                c = 4\n            d = 5\n            \"\"\")\n\n        self.make_file(\"not_run.py\", \"\"\"\\\n            fooey = 17\n            \"\"\")\n\n        # Import the Python file, executing it.\n        self.start_import_stop(cov, \"mycode\")\n\n        _, statements, missing, _ = cov.analysis(\"not_run.py\")\n        assert statements == [1]\n        assert missing == [1]\n\n    def test_filenames(self) -> None:\n        self.make_file(\"mymain.py\", \"\"\"\\\n            import mymod\n            a = 1\n            \"\"\")\n\n        self.make_file(\"mymod.py\", \"\"\"\\\n            fooey = 17\n            \"\"\")\n\n        # Import the Python file, executing it.\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"mymain\")\n\n        filename, _, _, _ = cov.analysis(\"mymain.py\")\n        assert os.path.basename(filename) == \"mymain.py\"\n        filename, _, _, _ = cov.analysis(\"mymod.py\")\n        assert os.path.basename(filename) == \"mymod.py\"\n\n        filename, _, _, _ = cov.analysis(sys.modules[\"mymain\"])\n        assert os.path.basename(filename) == \"mymain.py\"\n        filename, _, _, _ = cov.analysis(sys.modules[\"mymod\"])\n        assert os.path.basename(filename) == \"mymod.py\"\n\n        # Import the Python file, executing it again, once it's been compiled\n        # already.\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"mymain\")\n\n        filename, _, _, _ = cov.analysis(\"mymain.py\")\n        assert os.path.basename(filename) == \"mymain.py\"\n        filename, _, _, _ = cov.analysis(\"mymod.py\")\n        assert os.path.basename(filename) == \"mymod.py\"\n\n        filename, _, _, _ = cov.analysis(sys.modules[\"mymain\"])\n        assert os.path.basename(filename) == \"mymain.py\"\n        filename, _, _, _ = cov.analysis(sys.modules[\"mymod\"])\n        assert os.path.basename(filename) == \"mymod.py\"\n\n    def test_ignore_stdlib(self) -> None:\n        self.make_file(\"mymain.py\", \"\"\"\\\n            import colorsys\n            a = 1\n            hls = colorsys.rgb_to_hls(1.0, 0.5, 0.0)\n            \"\"\")\n\n        # Measure without the stdlib.\n        cov1 = coverage.Coverage()\n        assert cov1.config.cover_pylib is False\n        self.start_import_stop(cov1, \"mymain\")\n\n        # some statements were marked executed in mymain.py\n        _, statements, missing, _ = cov1.analysis(\"mymain.py\")\n        assert statements != missing\n        # but none were in colorsys.py\n        _, statements, missing, _ = cov1.analysis(\"colorsys.py\")\n        assert statements == missing\n\n        # Measure with the stdlib.\n        cov2 = coverage.Coverage(cover_pylib=True)\n        self.start_import_stop(cov2, \"mymain\")\n\n        # some statements were marked executed in mymain.py\n        _, statements, missing, _ = cov2.analysis(\"mymain.py\")\n        assert statements != missing\n        # and some were marked executed in colorsys.py\n        _, statements, missing, _ = cov2.analysis(\"colorsys.py\")\n        assert statements != missing\n\n    def test_include_can_measure_stdlib(self) -> None:\n        self.make_file(\"mymain.py\", \"\"\"\\\n            import colorsys, random\n            a = 1\n            r, g, b = [random.random() for _ in range(3)]\n            hls = colorsys.rgb_to_hls(r, g, b)\n            \"\"\")\n\n        # Measure without the stdlib, but include colorsys.\n        cov1 = coverage.Coverage(cover_pylib=False, include=[\"*/colorsys.py\"])\n        self.start_import_stop(cov1, \"mymain\")\n\n        # some statements were marked executed in colorsys.py\n        _, statements, missing, _ = cov1.analysis(\"colorsys.py\")\n        assert statements != missing\n        # but none were in random.py\n        _, statements, missing, _ = cov1.analysis(\"random.py\")\n        assert statements == missing\n\n    def test_exclude_list(self) -> None:\n        cov = coverage.Coverage()\n        cov.clear_exclude()\n        assert cov.get_exclude_list() == []\n        cov.exclude(\"foo\")\n        assert cov.get_exclude_list() == [\"foo\"]\n        cov.exclude(\"bar\")\n        assert cov.get_exclude_list() == [\"foo\", \"bar\"]\n        assert cov._exclude_regex('exclude') == \"(?:foo)|(?:bar)\"\n        cov.clear_exclude()\n        assert cov.get_exclude_list() == []\n\n    def test_exclude_partial_list(self) -> None:\n        cov = coverage.Coverage()\n        cov.clear_exclude(which='partial')\n        assert cov.get_exclude_list(which='partial') == []\n        cov.exclude(\"foo\", which='partial')\n        assert cov.get_exclude_list(which='partial') == [\"foo\"]\n        cov.exclude(\"bar\", which='partial')\n        assert cov.get_exclude_list(which='partial') == [\"foo\", \"bar\"]\n        assert cov._exclude_regex(which='partial') == \"(?:foo)|(?:bar)\"\n        cov.clear_exclude(which='partial')\n        assert cov.get_exclude_list(which='partial') == []\n\n    def test_exclude_and_partial_are_separate_lists(self) -> None:\n        cov = coverage.Coverage()\n        cov.clear_exclude(which='partial')\n        cov.clear_exclude(which='exclude')\n        cov.exclude(\"foo\", which='partial')\n        assert cov.get_exclude_list(which='partial') == ['foo']\n        assert cov.get_exclude_list(which='exclude') == []\n        cov.exclude(\"bar\", which='exclude')\n        assert cov.get_exclude_list(which='partial') == ['foo']\n        assert cov.get_exclude_list(which='exclude') == ['bar']\n        cov.exclude(\"p2\", which='partial')\n        cov.exclude(\"e2\", which='exclude')\n        assert cov.get_exclude_list(which='partial') == ['foo', 'p2']\n        assert cov.get_exclude_list(which='exclude') == ['bar', 'e2']\n        cov.clear_exclude(which='partial')\n        assert cov.get_exclude_list(which='partial') == []\n        assert cov.get_exclude_list(which='exclude') == ['bar', 'e2']\n        cov.clear_exclude(which='exclude')\n        assert cov.get_exclude_list(which='partial') == []\n        assert cov.get_exclude_list(which='exclude') == []\n\n    def test_datafile_default(self) -> None:\n        # Default data file behavior: it's .coverage\n        self.make_file(\"datatest1.py\", \"\"\"\\\n            fooey = 17\n            \"\"\")\n\n        self.assertFiles([\"datatest1.py\"])\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"datatest1\")\n        cov.save()\n        self.assertFiles([\"datatest1.py\", \".coverage\"])\n\n    @pytest.mark.parametrize(\"file_class\", FilePathClasses)\n    def test_datafile_specified(self, file_class: FilePathType) -> None:\n        # You can specify the data file name.\n        self.make_file(\"datatest2.py\", \"\"\"\\\n            fooey = 17\n            \"\"\")\n\n        self.assertFiles([\"datatest2.py\"])\n        cov = coverage.Coverage(data_file=file_class(\"cov.data\"))\n        self.start_import_stop(cov, \"datatest2\")\n        cov.save()\n        self.assertFiles([\"datatest2.py\", \"cov.data\"])\n\n    @pytest.mark.parametrize(\"file_class\", FilePathClasses)\n    def test_datafile_and_suffix_specified(self, file_class: FilePathType) -> None:\n        # You can specify the data file name and suffix.\n        self.make_file(\"datatest3.py\", \"\"\"\\\n            fooey = 17\n            \"\"\")\n\n        self.assertFiles([\"datatest3.py\"])\n        cov = coverage.Coverage(data_file=file_class(\"cov.data\"), data_suffix=\"14\")\n        self.start_import_stop(cov, \"datatest3\")\n        cov.save()\n        self.assertFiles([\"datatest3.py\", \"cov.data.14\"])\n\n    def test_datafile_from_rcfile(self) -> None:\n        # You can specify the data file name in the .coveragerc file\n        self.make_file(\"datatest4.py\", \"\"\"\\\n            fooey = 17\n            \"\"\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            data_file = mydata.dat\n            \"\"\")\n\n        self.assertFiles([\"datatest4.py\", \".coveragerc\"])\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"datatest4\")\n        cov.save()\n        self.assertFiles([\"datatest4.py\", \".coveragerc\", \"mydata.dat\"])\n\n    def test_deep_datafile(self) -> None:\n        self.make_file(\"datatest5.py\", \"fooey = 17\")\n        self.assertFiles([\"datatest5.py\"])\n        cov = coverage.Coverage(data_file=\"deep/sub/cov.data\")\n        self.start_import_stop(cov, \"datatest5\")\n        cov.save()\n        self.assertFiles([\"datatest5.py\", \"deep\"])\n        self.assert_exists(\"deep/sub/cov.data\")\n\n    def test_datafile_none(self) -> None:\n        cov = coverage.Coverage(data_file=None)\n\n        def f1() -> None:       # pragma: nested\n            a = 1               # pylint: disable=unused-variable\n\n        one_line_number = f1.__code__.co_firstlineno + 1\n        lines = []\n\n        def run_one_function(f: Callable[[], None]) -> None:\n            cov.erase()\n            with cov.collect():\n                f()\n\n            fs = cov.get_data().measured_files()\n            lines.append(cov.get_data().lines(list(fs)[0]))\n\n        run_one_function(f1)\n        run_one_function(f1)\n        run_one_function(f1)\n        assert lines == [[one_line_number]] * 3\n        self.assert_doesnt_exist(\".coverage\")\n        assert os.listdir(\".\") == []\n\n    def test_empty_reporting(self) -> None:\n        # empty summary reports raise exception, just like the xml report\n        cov = coverage.Coverage()\n        cov.erase()\n        with pytest.raises(NoDataError, match=\"No data to report.\"):\n            cov.report()\n\n    def test_completely_zero_reporting(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/884\n        # If nothing was measured, the file-touching didn't happen properly.\n        self.make_file(\"foo/bar.py\", \"print('Never run')\")\n        self.make_file(\"test.py\", \"assert True\")\n        with pytest.warns(Warning) as warns:\n            cov = coverage.Coverage(source=[\"foo\"])\n            self.start_import_stop(cov, \"test\")\n            cov.report()\n        assert_coverage_warnings(warns, \"No data was collected. (no-data-collected)\")\n        # Name         Stmts   Miss  Cover\n        # --------------------------------\n        # foo/bar.py       1      1     0%\n        # --------------------------------\n        # TOTAL            1      1     0%\n\n        last = self.last_line_squeezed(self.stdout())\n        assert \"TOTAL 1 1 0%\" == last\n\n    def test_cov4_data_file(self) -> None:\n        cov4_data = (\n            \"!coverage.py: This is a private format, don't read it directly!\" +\n            '{\"lines\":{\"/private/tmp/foo.py\":[1,5,2,3]}}'\n        )\n        self.make_file(\".coverage\", cov4_data)\n        cov = coverage.Coverage()\n        with pytest.raises(DataError, match=\"Looks like a coverage 4.x data file\"):\n            cov.load()\n        cov.erase()\n\n    def make_code1_code2(self) -> None:\n        \"\"\"Create the code1.py and code2.py files.\"\"\"\n        self.make_file(\"code1.py\", \"\"\"\\\n            code1 = 1\n            \"\"\")\n        self.make_file(\"code2.py\", \"\"\"\\\n            code2 = 1\n            code2 = 2\n            \"\"\")\n\n    def check_code1_code2(self, cov: Coverage) -> None:\n        \"\"\"Check the analysis is correct for code1.py and code2.py.\"\"\"\n        _, statements, missing, _ = cov.analysis(\"code1.py\")\n        assert statements == [1]\n        assert missing == []\n        _, statements, missing, _ = cov.analysis(\"code2.py\")\n        assert statements == [1, 2]\n        assert missing == []\n\n    def test_start_stop_start_stop(self) -> None:\n        self.make_code1_code2()\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"code1\")\n        cov.save()\n        self.start_import_stop(cov, \"code2\")\n        self.check_code1_code2(cov)\n\n    def test_start_save_stop(self) -> None:\n        self.make_code1_code2()\n        cov = coverage.Coverage()\n        with cov.collect():\n            import_local_file(\"code1\")\n            cov.save()\n            import_local_file(\"code2\")\n        self.check_code1_code2(cov)\n\n    def test_start_save_nostop(self) -> None:\n        self.make_code1_code2()\n        cov = coverage.Coverage()\n        with cov.collect():\n            import_local_file(\"code1\")\n            cov.save()\n            import_local_file(\"code2\")\n            self.check_code1_code2(cov)\n\n    def test_two_getdata_only_warn_once(self) -> None:\n        self.make_code1_code2()\n        cov = coverage.Coverage(source=[\".\"], omit=[\"code1.py\"])\n        with cov.collect():\n            import_local_file(\"code1\")\n        # We didn't collect any data, so we should get a warning.\n        with self.assert_warnings(cov, [\"No data was collected\"]):\n            cov.get_data()\n        # But calling get_data a second time with no intervening activity\n        # won't make another warning.\n        with self.assert_warnings(cov, []):\n            cov.get_data()\n\n    def test_two_getdata_warn_twice(self) -> None:\n        self.make_code1_code2()\n        cov = coverage.Coverage(source=[\".\"], omit=[\"code1.py\", \"code2.py\"])\n        with cov.collect():\n            import_local_file(\"code1\")\n            # We didn't collect any data, so we should get a warning.\n            with self.assert_warnings(cov, [\"No data was collected\"]):\n                cov.save()\n            import_local_file(\"code2\")\n            # Calling get_data a second time after tracing some more will warn again.\n            with self.assert_warnings(cov, [\"No data was collected\"]):\n                cov.get_data()\n\n    def make_good_data_files(self) -> None:\n        \"\"\"Make some good data files.\"\"\"\n        self.make_code1_code2()\n        cov = coverage.Coverage(data_suffix=True)\n        self.start_import_stop(cov, \"code1\")\n        cov.save()\n\n        cov = coverage.Coverage(data_suffix=True)\n        self.start_import_stop(cov, \"code2\")\n        cov.save()\n        self.assert_file_count(\".coverage.*\", 2)\n\n    def test_combining_corrupt_data(self) -> None:\n        # If you combine a corrupt data file, then you will get a warning,\n        # and the file will remain.\n        self.make_good_data_files()\n        self.make_file(\".coverage.foo\", \"\"\"La la la, this isn't coverage data!\"\"\")\n        cov = coverage.Coverage()\n        warning_regex = (\n            r\"Couldn't use data file '.*\\.coverage\\.foo': \" + BAD_SQLITE_REGEX\n        )\n        with self.assert_warnings(cov, [warning_regex]):\n            cov.combine()\n\n        # We got the results from code1 and code2 properly.\n        self.check_code1_code2(cov)\n\n        # The bad file still exists, but it's the only parallel data file left.\n        self.assert_exists(\".coverage.foo\")\n        self.assert_file_count(\".coverage.*\", 1)\n\n    def test_combining_twice(self) -> None:\n        self.make_good_data_files()\n        cov1 = coverage.Coverage()\n        cov1.combine()\n        assert self.stdout() == \"\"\n        cov1.save()\n        self.check_code1_code2(cov1)\n        self.assert_file_count(\".coverage.*\", 0)\n        self.assert_exists(\".coverage\")\n\n        cov2 = coverage.Coverage()\n        with pytest.raises(NoDataError, match=r\"No data to combine\"):\n            cov2.combine(strict=True, keep=False)\n\n        cov3 = coverage.Coverage()\n        cov3.combine()\n        assert self.stdout() == \"\"\n        # Now the data is empty!\n        _, statements, missing, _ = cov3.analysis(\"code1.py\")\n        assert statements == [1]\n        assert missing == [1]\n        _, statements, missing, _ = cov3.analysis(\"code2.py\")\n        assert statements == [1, 2]\n        assert missing == [1, 2]\n\n    def test_combining_with_a_used_coverage(self) -> None:\n        # Can you use a coverage object to run one shard of a parallel suite,\n        # and then also combine the data?\n        self.make_code1_code2()\n        cov = coverage.Coverage(data_suffix=True)\n        self.start_import_stop(cov, \"code1\")\n        cov.save()\n\n        cov = coverage.Coverage(data_suffix=True)\n        self.start_import_stop(cov, \"code2\")\n        cov.save()\n\n        cov.combine()\n        assert self.stdout() == \"\"\n        self.check_code1_code2(cov)\n\n    def test_ordered_combine(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/649\n        # The order of the [paths] setting used to matter. Now the\n        # resulting path must exist, so the order doesn't matter.\n        def make_files() -> None:\n            self.make_file(\"plugins/p1.py\", \"\")\n            self.make_file(\"girder/g1.py\", \"\")\n            self.make_data_file(\n                basename=\".coverage.1\",\n                lines={\n                    abs_file('ci/girder/g1.py'): range(10),\n                    abs_file('ci/girder/plugins/p1.py'): range(10),\n                },\n            )\n\n        def get_combined_filenames() -> set[str]:\n            cov = coverage.Coverage()\n            cov.combine()\n            assert self.stdout() == \"\"\n            cov.save()\n            data = cov.get_data()\n            filenames = {relative_filename(f).replace(\"\\\\\", \"/\") for f in data.measured_files()}\n            return filenames\n\n        # Case 1: get the order right.\n        make_files()\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [paths]\n            plugins =\n                plugins/\n                ci/girder/plugins/\n            girder =\n                girder/\n                ci/girder/\n            \"\"\")\n        assert get_combined_filenames() == {'girder/g1.py', 'plugins/p1.py'}\n\n        # Case 2: get the order \"wrong\".\n        make_files()\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [paths]\n            girder =\n                girder/\n                ci/girder/\n            plugins =\n                plugins/\n                ci/girder/plugins/\n            \"\"\")\n        assert get_combined_filenames() == {'girder/g1.py', 'plugins/p1.py'}\n\n    def test_warnings(self) -> None:\n        self.make_file(\"hello.py\", \"\"\"\\\n            import sys, os\n            print(\"Hello\")\n            \"\"\")\n        with pytest.warns(Warning) as warns:\n            cov = coverage.Coverage(source=[\"sys\", \"xyzzy\", \"quux\"])\n            self.start_import_stop(cov, \"hello\")\n            cov.get_data()\n\n        assert \"Hello\\n\" == self.stdout()\n        assert_coverage_warnings(\n            warns,\n            \"Module sys has no Python source. (module-not-python)\",\n            \"Module xyzzy was never imported. (module-not-imported)\",\n            \"Module quux was never imported. (module-not-imported)\",\n            \"No data was collected. (no-data-collected)\",\n        )\n\n    def test_warnings_suppressed(self) -> None:\n        self.make_file(\"hello.py\", \"\"\"\\\n            import sys, os\n            print(\"Hello\")\n            \"\"\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            disable_warnings = no-data-collected, module-not-imported\n            \"\"\")\n        with pytest.warns(Warning) as warns:\n            cov = coverage.Coverage(source=[\"sys\", \"xyzzy\", \"quux\"])\n            self.start_import_stop(cov, \"hello\")\n            cov.get_data()\n\n        assert \"Hello\\n\" == self.stdout()\n        assert_coverage_warnings(warns, \"Module sys has no Python source. (module-not-python)\")\n        # No \"module-not-imported\" in warns\n        # No \"no-data-collected\" in warns\n\n    def test_warn_once(self) -> None:\n        with pytest.warns(Warning) as warns:\n            cov = coverage.Coverage()\n            cov.load()\n            cov._warn(\"Warning, warning 1!\", slug=\"bot\", once=True)\n            cov._warn(\"Warning, warning 2!\", slug=\"bot\", once=True)\n\n        assert_coverage_warnings(warns, \"Warning, warning 1! (bot)\")\n        # No \"Warning, warning 2!\" in warns\n\n    def test_source_and_include_dont_conflict(self) -> None:\n        # A bad fix made this case fail: https://github.com/nedbat/coveragepy/issues/541\n        self.make_file(\"a.py\", \"import b\\na = 1\")\n        self.make_file(\"b.py\", \"b = 1\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            source = .\n            \"\"\")\n\n        # Just like: coverage run a.py\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"a\")\n        cov.save()\n\n        # Run the equivalent of: coverage report --include=b.py\n        cov = coverage.Coverage(include=[\"b.py\"])\n        cov.load()\n        # There should be no exception. At one point, report() threw:\n        # CoverageException: --include and --source are mutually exclusive\n        cov.report()\n        expected = textwrap.dedent(\"\"\"\\\n            Name    Stmts   Miss  Cover\n            ---------------------------\n            b.py        1      0   100%\n            ---------------------------\n            TOTAL       1      0   100%\n            \"\"\")\n        assert expected == self.stdout()\n\n    def test_config_crash(self) -> None:\n        # The internal '[run] _crash' setting can be used to artificially raise\n        # exceptions from inside Coverage.\n        cov = coverage.Coverage()\n        cov.set_option(\"run:_crash\", \"test_config_crash\")\n        with pytest.raises(Exception, match=\"Crashing because called by test_config_crash\"):\n            cov.start()\n\n    def test_config_crash_no_crash(self) -> None:\n        # '[run] _crash' really checks the call stack.\n        cov = coverage.Coverage()\n        cov.set_option(\"run:_crash\", \"not_my_caller\")\n        cov.start()\n        cov.stop()\n\n    def test_run_debug_sys(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/907\n        cov = coverage.Coverage()\n        with cov.collect():\n            d = dict(cov.sys_info())\n        assert cast(str, d['data_file']).endswith(\".coverage\")\n\n\n@pytest.mark.skipif(not testenv.DYN_CONTEXTS, reason=\"No dynamic contexts with this core.\")\nclass SwitchContextTest(CoverageTest):\n    \"\"\"Tests of the .switch_context() method.\"\"\"\n\n    def make_test_files(self) -> None:\n        \"\"\"Create a simple file representing a method with two tests.\"\"\"\n        self.make_file(\"testsuite.py\", \"\"\"\\\n            def timestwo(x):\n                return x*2\n\n            def test_multiply_zero():\n                assert timestwo(0) == 0\n\n            def test_multiply_six():\n                assert timestwo(6) == 12\n            \"\"\")\n\n    def test_switch_context_testrunner(self) -> None:\n        # This test simulates a coverage-aware test runner,\n        # measuring labeled coverage via public API\n        self.make_test_files()\n\n        # Test runner starts\n        cov = coverage.Coverage()\n        with cov.collect():\n            # Imports the test suite\n            suite = import_local_file(\"testsuite\")\n\n            # Measures test case 1\n            cov.switch_context('multiply_zero')\n            suite.test_multiply_zero()\n\n            # Measures test case 2\n            cov.switch_context('multiply_six')\n            suite.test_multiply_six()\n\n            # Runner finishes\n            cov.save()\n\n        # Labeled data is collected\n        data = cov.get_data()\n        assert ['', 'multiply_six', 'multiply_zero'] == sorted(data.measured_contexts())\n\n        filenames = self.get_measured_filenames(data)\n        suite_filename = filenames['testsuite.py']\n\n        data.set_query_context(\"multiply_six\")\n        assert [2, 8] == sorted_lines(data, suite_filename)\n        data.set_query_context(\"multiply_zero\")\n        assert [2, 5] == sorted_lines(data, suite_filename)\n\n    def test_switch_context_with_static(self) -> None:\n        # This test simulates a coverage-aware test runner,\n        # measuring labeled coverage via public API,\n        # with static label prefix.\n        self.make_test_files()\n\n        # Test runner starts\n        cov = coverage.Coverage(context=\"mysuite\")\n        with cov.collect():\n            # Imports the test suite\n            suite = import_local_file(\"testsuite\")\n\n            # Measures test case 1\n            cov.switch_context('multiply_zero')\n            suite.test_multiply_zero()\n\n            # Measures test case 2\n            cov.switch_context('multiply_six')\n            suite.test_multiply_six()\n\n            # Runner finishes\n            cov.save()\n\n        # Labeled data is collected\n        data = cov.get_data()\n        expected = ['mysuite', 'mysuite|multiply_six', 'mysuite|multiply_zero']\n        assert expected == sorted(data.measured_contexts())\n\n        filenames = self.get_measured_filenames(data)\n        suite_filename = filenames['testsuite.py']\n\n        data.set_query_context(\"mysuite|multiply_six\")\n        assert [2, 8] == sorted_lines(data, suite_filename)\n        data.set_query_context(\"mysuite|multiply_zero\")\n        assert [2, 5] == sorted_lines(data, suite_filename)\n\n    def test_dynamic_context_conflict(self) -> None:\n        cov = coverage.Coverage(source=[\".\"])\n        cov.set_option(\"run:dynamic_context\", \"test_function\")\n        with cov.collect():\n            with pytest.warns(Warning) as warns:\n                # Switch twice, but only get one warning.\n                cov.switch_context(\"test1\")\n                cov.switch_context(\"test2\")\n        assert_coverage_warnings(warns, \"Conflicting dynamic contexts (dynamic-conflict)\")\n\n    def test_unknown_dynamic_context(self) -> None:\n        cov = coverage.Coverage()\n        cov.set_option(\"run:dynamic_context\", \"no-idea\")\n        with pytest.raises(Exception, match=\"Don't understand dynamic_context setting: 'no-idea'\"):\n            cov.start()\n\n    def test_switch_context_unstarted(self) -> None:\n        # Coverage must be started to switch context\n        msg = \"Cannot switch context, coverage is not started\"\n        cov = coverage.Coverage()\n        with pytest.raises(CoverageException, match=msg):\n            cov.switch_context(\"test1\")\n\n        with cov.collect():\n            cov.switch_context(\"test2\")\n\n        with pytest.raises(CoverageException, match=msg):\n            cov.switch_context(\"test3\")\n\n\nclass CurrentInstanceTest(CoverageTest):\n    \"\"\"Tests of Coverage.current().\"\"\"\n\n    run_in_temp_dir = False\n\n    def assert_current_is_none(self, current: Coverage | None) -> None:\n        \"\"\"Assert that a current we expect to be None is correct.\"\"\"\n        # During meta-coverage, the None answers will be wrong because the\n        # overall coverage measurement will still be on the current-stack.\n        # Since we know they will be wrong, and we have non-meta test runs\n        # also, don't assert them.\n        if not env.METACOV:\n            assert current is None\n\n    def test_current(self) -> None:\n        cur0 = coverage.Coverage.current()\n        self.assert_current_is_none(cur0)\n        # Making an instance doesn't make it current.\n        cov = coverage.Coverage()\n        cur1 = coverage.Coverage.current()\n        self.assert_current_is_none(cur1)\n        assert cur0 is cur1\n        # Starting the instance makes it current.\n        with cov.collect():\n            cur2 = coverage.Coverage.current()\n            assert cur2 is cov\n            # Stopping the instance makes current None again.\n\n        cur3 = coverage.Coverage.current()\n        self.assert_current_is_none(cur3)\n        assert cur0 is cur3\n\n\nclass NamespaceModuleTest(UsingModulesMixin, CoverageTest):\n    \"\"\"Test PEP-420 namespace modules.\"\"\"\n\n    def test_explicit_namespace_module(self) -> None:\n        self.make_file(\"main.py\", \"import namespace_420\\n\")\n\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n\n        with pytest.raises(CoverageException, match=r\"Module .* has no file\"):\n            cov.analysis(sys.modules['namespace_420'])\n\n    def test_bug_572(self) -> None:\n        self.make_file(\"main.py\", \"import namespace_420\\n\")\n\n        # Use source=namespace_420 to trigger the check that used to fail,\n        # and use source=main so that something is measured.\n        cov = coverage.Coverage(source=[\"namespace_420\", \"main\"])\n        with self.assert_warnings(cov, []):\n            self.start_import_stop(cov, \"main\")\n            cov.report()\n\n\nclass IncludeOmitTestsMixin(UsingModulesMixin, CoverageTest):\n    \"\"\"Test methods for coverage methods taking include and omit.\"\"\"\n\n    # An abstract method for subclasses to define, to appease mypy.\n    def coverage_usepkgs(self, **kwargs_unused: TCovKwargs) -> Iterable[str]:\n        \"\"\"Run coverage on usepkgs, return a line summary. kwargs are for Coverage(**kwargs).\"\"\"\n        raise NotImplementedError()     # pragma: not covered\n\n    def filenames_in(self, summary: Iterable[str], filenames: str) -> None:\n        \"\"\"Assert the `filenames` are in the `summary`.\"\"\"\n        for filename in filenames.split():\n            assert filename in summary\n\n    def filenames_not_in(self, summary: Iterable[str], filenames: str) -> None:\n        \"\"\"Assert the `filenames` are not in the `summary`.\"\"\"\n        for filename in filenames.split():\n            assert filename not in summary\n\n    def test_nothing_specified(self) -> None:\n        result = self.coverage_usepkgs()\n        self.filenames_in(result, \"p1a p1b p2a p2b othera otherb osa osb\")\n        self.filenames_not_in(result, \"p1c\")\n        # Because there was no source= specified, we don't search for\n        # un-executed files.\n\n    def test_include(self) -> None:\n        result = self.coverage_usepkgs(include=[\"*/p1a.py\"])\n        self.filenames_in(result, \"p1a\")\n        self.filenames_not_in(result, \"p1b p1c p2a p2b othera otherb osa osb\")\n\n    def test_include_2(self) -> None:\n        result = self.coverage_usepkgs(include=[\"*a.py\"])\n        self.filenames_in(result, \"p1a p2a othera osa\")\n        self.filenames_not_in(result, \"p1b p1c p2b otherb osb\")\n\n    def test_include_as_string(self) -> None:\n        result = self.coverage_usepkgs(include=\"*a.py\")\n        self.filenames_in(result, \"p1a p2a othera osa\")\n        self.filenames_not_in(result, \"p1b p1c p2b otherb osb\")\n\n    def test_omit(self) -> None:\n        result = self.coverage_usepkgs(omit=[\"*/p1a.py\"])\n        self.filenames_in(result, \"p1b p2a p2b\")\n        self.filenames_not_in(result, \"p1a p1c\")\n\n    def test_omit_2(self) -> None:\n        result = self.coverage_usepkgs(omit=[\"*a.py\"])\n        self.filenames_in(result, \"p1b p2b otherb osb\")\n        self.filenames_not_in(result, \"p1a p1c p2a othera osa\")\n\n    def test_omit_as_string(self) -> None:\n        result = self.coverage_usepkgs(omit=\"*a.py\")\n        self.filenames_in(result, \"p1b p2b otherb osb\")\n        self.filenames_not_in(result, \"p1a p1c p2a othera osa\")\n\n    def test_omit_and_include(self) -> None:\n        result = self.coverage_usepkgs(include=[\"*/p1*\"], omit=[\"*/p1a.py\"])\n        self.filenames_in(result, \"p1b\")\n        self.filenames_not_in(result, \"p1a p1c p2a p2b\")\n\n\nclass SourceIncludeOmitTest(IncludeOmitTestsMixin, CoverageTest):\n    \"\"\"Test using `source`, `include`, and `omit` when measuring code.\"\"\"\n\n    def setUp(self) -> None:\n        super().setUp()\n\n        # These tests use the TESTS_DIR/modules files, but they cd into it. To\n        # keep tests from cross-contaminating, we make a copy of the files.\n        # Since we need to import from there, we also add it to the beginning\n        # of sys.path.\n\n        shutil.copytree(\n            nice_file(TESTS_DIR, \"modules\"),\n            \"tests_dir_modules\",\n            ignore=shutil.ignore_patterns(\"__pycache__\"),\n        )\n        sys.path.insert(0, abs_file(\"tests_dir_modules\"))\n\n    def coverage_usepkgs_counts(self, **kwargs: TCovKwargs) -> dict[str, int]:\n        \"\"\"Run coverage on usepkgs and return a line summary.\n\n        Arguments are passed to the `coverage.Coverage` constructor.\n\n        \"\"\"\n        cov = coverage.Coverage(**kwargs)\n        with cov.collect():\n            import usepkgs  # pylint: disable=import-error, unused-import\n        with self.assert_warnings(cov, []):\n            data = cov.get_data()\n        summary = line_counts(data)\n        for k, v in list(summary.items()):\n            assert k.endswith(\".py\")\n            summary[k[:-3]] = v\n        return summary\n\n    def coverage_usepkgs(self, **kwargs: TCovKwargs) -> Iterable[str]:\n        summary = self.coverage_usepkgs_counts(**kwargs)\n        return list(summary)\n\n    def test_source_include_exclusive(self) -> None:\n        cov = coverage.Coverage(source=[\"pkg1\"], include=[\"pkg2\"])\n        with self.assert_warnings(cov, [\"--include is ignored because --source is set\"]):\n            cov.start()\n        cov.stop()\n\n    def test_source_package_as_package(self) -> None:\n        assert not os.path.isdir(\"pkg1\")\n        lines = self.coverage_usepkgs_counts(source=[\"pkg1\"])\n        self.filenames_in(list(lines), \"p1a p1b\")\n        self.filenames_not_in(list(lines), \"p2a p2b othera otherb osa osb\")\n        # Because source= was specified, we do search for un-executed files.\n        assert lines['p1c'] == 0\n\n    def test_source_package_as_dir(self) -> None:\n        os.chdir(\"tests_dir_modules\")\n        assert os.path.isdir(\"pkg1\")\n        lines = self.coverage_usepkgs_counts(source=[\"pkg1\"])\n        self.filenames_in(list(lines), \"p1a p1b\")\n        self.filenames_not_in(list(lines), \"p2a p2b othera otherb osa osb\")\n        # Because source= was specified, we do search for un-executed files.\n        assert lines['p1c'] == 0\n\n    def test_source_package_dotted_sub(self) -> None:\n        lines = self.coverage_usepkgs_counts(source=[\"pkg1.sub\"])\n        self.filenames_not_in(list(lines), \"p2a p2b othera otherb osa osb\")\n        # Because source= was specified, we do search for un-executed files.\n        assert lines['runmod3'] == 0\n\n    def test_source_package_dotted_p1b(self) -> None:\n        lines = self.coverage_usepkgs_counts(source=[\"pkg1.p1b\"])\n        self.filenames_in(list(lines), \"p1b\")\n        self.filenames_not_in(list(lines), \"p1a p1c p2a p2b othera otherb osa osb\")\n\n    def test_source_package_part_omitted(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/218\n        # Used to be if you omitted something executed and inside the source,\n        # then after it was executed but not recorded, it would be found in\n        # the search for un-executed files, and given a score of 0%.\n\n        # The omit arg is by path, so need to be in the modules directory.\n        os.chdir(\"tests_dir_modules\")\n        lines = self.coverage_usepkgs_counts(source=[\"pkg1\"], omit=[\"pkg1/p1b.py\"])\n        self.filenames_in(list(lines), \"p1a\")\n        self.filenames_not_in(list(lines), \"p1b\")\n        assert lines['p1c'] == 0\n\n    def test_source_package_as_package_part_omitted(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/638\n        lines = self.coverage_usepkgs_counts(source=[\"pkg1\"], omit=[\"*/p1b.py\"])\n        self.filenames_in(list(lines), \"p1a\")\n        self.filenames_not_in(list(lines), \"p1b\")\n        assert lines['p1c'] == 0\n\n    def test_ambiguous_source_package_as_dir(self) -> None:\n        # pkg1 is a directory and a pkg, since we cd into tests_dir_modules/ambiguous\n        os.chdir(\"tests_dir_modules/ambiguous\")\n        # pkg1 defaults to directory because tests_dir_modules/ambiguous/pkg1 exists\n        lines = self.coverage_usepkgs_counts(source=[\"pkg1\"])\n        self.filenames_in(list(lines), \"ambiguous\")\n        self.filenames_not_in(list(lines), \"p1a p1b p1c\")\n\n    def test_ambiguous_source_package_as_package(self) -> None:\n        # pkg1 is a directory and a pkg, since we cd into tests_dir_modules/ambiguous\n        os.chdir(\"tests_dir_modules/ambiguous\")\n        lines = self.coverage_usepkgs_counts(source_pkgs=[\"pkg1\"])\n        self.filenames_in(list(lines), \"p1a p1b\")\n        self.filenames_not_in(list(lines), \"p2a p2b othera otherb osa osb ambiguous\")\n        # Because source= was specified, we do search for un-executed files.\n        assert lines['p1c'] == 0\n\n\nclass ReportIncludeOmitTest(IncludeOmitTestsMixin, CoverageTest):\n    \"\"\"Tests of the report include/omit functionality.\"\"\"\n\n    def coverage_usepkgs(self, **kwargs: TCovKwargs) -> Iterable[str]:\n        \"\"\"Try coverage.report().\"\"\"\n        cov = coverage.Coverage()\n        with cov.collect():\n            import usepkgs  # pylint: disable=import-error, unused-import\n        report = io.StringIO()\n        cov.report(file=report, **kwargs)\n        return report.getvalue()\n\n\nclass XmlIncludeOmitTest(IncludeOmitTestsMixin, CoverageTest):\n    \"\"\"Tests of the XML include/omit functionality.\n\n    This also takes care of the HTML and annotate include/omit, by virtue\n    of the structure of the code.\n\n    \"\"\"\n\n    def coverage_usepkgs(self, **kwargs: TCovKwargs) -> Iterable[str]:\n        \"\"\"Try coverage.xml_report().\"\"\"\n        cov = coverage.Coverage()\n        with cov.collect():\n            import usepkgs  # pylint: disable=import-error, unused-import\n        cov.xml_report(outfile=\"-\", **kwargs)\n        return self.stdout()\n\n\nclass AnalysisTest(CoverageTest):\n    \"\"\"Test the numerical analysis of results.\"\"\"\n    def test_many_missing_branches(self) -> None:\n        cov = coverage.Coverage(branch=True)\n\n        self.make_file(\"missing.py\", \"\"\"\\\n            def fun1(x):\n                if x == 1:\n                    print(\"one\")\n                else:\n                    print(\"not one\")\n                print(\"done\")           # pragma: nocover\n\n            def fun2(x):\n                print(\"x\")\n\n            fun2(3)\n            \"\"\")\n\n        # Import the Python file, executing it.\n        self.start_import_stop(cov, \"missing\")\n\n        nums = cov._analyze(\"missing.py\").numbers\n        assert nums.n_files == 1\n        assert nums.n_statements == 7\n        assert nums.n_excluded == 1\n        assert nums.n_missing == 3\n        assert nums.n_branches == 2\n        assert nums.n_partial_branches == 0\n        assert nums.n_missing_branches == 2\n\n\nclass TestRunnerPluginTest(CoverageTest):\n    \"\"\"Test that the API works properly the way various third-party plugins call it.\n\n    We don't actually use the plugins, but these tests call the API the same\n    way they do.\n\n    \"\"\"\n    def pretend_to_be_nose_with_cover(self, erase: bool = False, cd: bool = False) -> None:\n        \"\"\"This is what the nose --with-cover plugin does.\"\"\"\n        self.make_file(\"no_biggie.py\", \"\"\"\\\n            a = 1\n            b = 2\n            if b == 1:\n                c = 4\n            \"\"\")\n        self.make_file(\"sub/hold.txt\", \"\")\n\n        cov = coverage.Coverage()\n        if erase:\n            cov.combine()\n            cov.erase()\n        cov.load()\n        self.start_import_stop(cov, \"no_biggie\")\n        if cd:\n            os.chdir(\"sub\")\n        cov.combine()\n        cov.save()\n        cov.report([\"no_biggie.py\"], show_missing=True)\n        assert self.stdout() == textwrap.dedent(\"\"\"\\\n            Name           Stmts   Miss  Cover   Missing\n            --------------------------------------------\n            no_biggie.py       4      1    75%   4\n            --------------------------------------------\n            TOTAL              4      1    75%\n            \"\"\")\n        if cd:\n            os.chdir(\"..\")\n\n    def test_nose_plugin(self) -> None:\n        self.pretend_to_be_nose_with_cover()\n\n    def test_nose_plugin_with_erase(self) -> None:\n        self.pretend_to_be_nose_with_cover(erase=True)\n\n    def test_nose_plugin_with_cd(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/916\n        self.pretend_to_be_nose_with_cover(cd=True)\n\n    def pretend_to_be_pytestcov(self, append: bool) -> None:\n        \"\"\"Act like pytest-cov.\"\"\"\n        self.make_file(\"prog.py\", \"\"\"\\\n            a = 1\n            b = 2\n            if b == 1:\n                c = 4\n            \"\"\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            parallel = True\n            source = .\n            \"\"\")\n\n        cov = coverage.Coverage(source=None, branch=None, config_file='.coveragerc')\n        if append:\n            cov.load()\n        else:\n            cov.erase()\n        self.start_import_stop(cov, \"prog\")\n        cov.combine()\n        cov.save()\n        report = io.StringIO()\n        cov.report(show_missing=None, ignore_errors=True, file=report, skip_covered=None,\n                   skip_empty=None)\n        assert report.getvalue() == textwrap.dedent(\"\"\"\\\n            Name      Stmts   Miss  Cover\n            -----------------------------\n            prog.py       4      1    75%\n            -----------------------------\n            TOTAL         4      1    75%\n            \"\"\")\n        self.assert_file_count(\".coverage\", 0)\n        self.assert_file_count(\".coverage.*\", 1)\n\n    def test_pytestcov_parallel(self) -> None:\n        self.pretend_to_be_pytestcov(append=False)\n\n    def test_pytestcov_parallel_append(self) -> None:\n        self.pretend_to_be_pytestcov(append=True)\n\n\nclass ImmutableConfigTest(CoverageTest):\n    \"\"\"Check that reporting methods don't permanently change the configuration.\"\"\"\n\n    def test_config_doesnt_change(self) -> None:\n        self.make_file(\"simple.py\", \"a = 1\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"simple\")\n        assert cov.get_option(\"report:show_missing\") is False\n        cov.report(show_missing=True)\n        assert cov.get_option(\"report:show_missing\") is False\n\n\nclass RelativePathTest(CoverageTest):\n    \"\"\"Tests of the relative_files setting.\"\"\"\n\n    def test_moving_stuff(self) -> None:\n        # When using absolute file names, moving the source around results in\n        # \"No source for code\" errors while reporting.\n        self.make_file(\"foo.py\", \"a = 1\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"foo\")\n        res = cov.report()\n        assert res == 100\n\n        expected = re.escape(\"No source for code: '{}'.\".format(abs_file(\"foo.py\")))\n        os.remove(\"foo.py\")\n        self.make_file(\"new/foo.py\", \"a = 1\")\n        shutil.move(\".coverage\", \"new/.coverage\")\n        with change_dir(\"new\"):\n            cov = coverage.Coverage()\n            cov.load()\n            with pytest.raises(NoSource, match=expected):\n                cov.report()\n\n    def test_moving_stuff_with_relative(self) -> None:\n        # When using relative file names, moving the source around is fine.\n        self.make_file(\"foo.py\", \"a = 1\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            relative_files = true\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"foo\")\n        res = cov.report()\n        assert res == 100\n\n        os.remove(\"foo.py\")\n        self.make_file(\"new/foo.py\", \"a = 1\")\n        shutil.move(\".coverage\", \"new/.coverage\")\n        shutil.move(\".coveragerc\", \"new/.coveragerc\")\n        with change_dir(\"new\"):\n            cov = coverage.Coverage()\n            cov.load()\n            res = cov.report()\n            assert res == 100\n\n    def test_combine_relative(self) -> None:\n        self.make_file(\"foo.py\", \"\"\"\\\n            import mod\n            a = 1\n            \"\"\")\n        self.make_file(\"lib/mod/__init__.py\", \"x = 1\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            relative_files = true\n            \"\"\")\n        sys.path.append(\"lib\")\n        cov = coverage.Coverage(source=[\".\"], data_suffix=True)\n        self.start_import_stop(cov, \"foo\")\n        cov.save()\n\n        self.make_file(\"dir2/bar.py\", \"a = 1\")\n        self.make_file(\"dir2/.coveragerc\", \"\"\"\\\n            [run]\n            relative_files = true\n            \"\"\")\n        with change_dir(\"dir2\"):\n            cov = coverage.Coverage(source=[\".\"], data_suffix=True)\n            self.start_import_stop(cov, \"bar\")\n            cov.save()\n            shutil.move(glob.glob(\".coverage.*\")[0], \"..\")\n\n        self.make_file(\"foo.py\", \"a = 1\")\n        self.make_file(\"bar.py\", \"a = 1\")\n        self.make_file(\"modsrc/__init__.py\", \"x = 1\")\n\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            relative_files = true\n            [paths]\n            source =\n                modsrc\n                */mod\n            \"\"\")\n        cov = coverage.Coverage()\n        cov.combine()\n        cov.save()\n\n        cov = coverage.Coverage()\n        cov.load()\n        files = cov.get_data().measured_files()\n        assert files == {'foo.py', 'bar.py', os_sep('modsrc/__init__.py')}\n        res = cov.report()\n        assert res == 100\n\n    def test_combine_no_suffix_multiprocessing(self) -> None:\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            branch = True\n            \"\"\")\n        cov = coverage.Coverage(\n            config_file=\".coveragerc\",\n            concurrency=\"multiprocessing\",\n            data_suffix=False,\n        )\n        cov.start()\n        cov.stop()\n        # The warning isn't the point of this test, but suppress it.\n        with pytest.warns(Warning) as warns:\n            cov.combine()\n        assert_coverage_warnings(warns, \"No data was collected. (no-data-collected)\")\n        cov.save()\n        self.assert_file_count(\".coverage.*\", 0)\n        self.assert_exists(\".coverage\")\n\n    def test_files_up_one_level(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1280\n        self.make_file(\"src/mycode.py\", \"\"\"\\\n            def foo():\n                return 17\n            \"\"\")\n        self.make_file(\"test/test_it.py\", \"\"\"\\\n            from src.mycode import foo\n            assert foo() == 17\n            \"\"\")\n        self.make_file(\"test/.coveragerc\", \"\"\"\\\n            [run]\n            parallel = True\n            relative_files = True\n\n            [paths]\n            source =\n                ../src/\n                */src\n            \"\"\")\n        os.chdir(\"test\")\n        sys.path.insert(0, \"..\")\n        cov1 = coverage.Coverage()\n        self.start_import_stop(cov1, \"test_it\")\n        cov1.save()\n        cov2 = coverage.Coverage()\n        cov2.combine()\n        cov3 = coverage.Coverage()\n        cov3.load()\n        report = self.get_report(cov3)\n        assert self.last_line_squeezed(report) == \"TOTAL 4 0 100%\"\n\n\nclass CombiningTest(CoverageTest):\n    \"\"\"More tests of combining data.\"\"\"\n\n    B_LINES = {\"b_or_c.py\": [1, 2, 3, 4, 8, 9]}\n    C_LINES = {\"b_or_c.py\": [1, 2, 3, 6, 7, 8, 9]}\n\n    def make_b_or_c_py(self) -> None:\n        \"\"\"Create b_or_c.py, used in a few of these tests.\"\"\"\n        # \"b_or_c.py b\" will run 6 lines.\n        # \"b_or_c.py c\" will run 7 lines.\n        # Together, they run 8 lines.\n        self.make_file(\"b_or_c.py\", \"\"\"\\\n            import sys\n            a = 2\n            if sys.argv[1] == 'b':\n                b = 4\n            else:\n                c = 6\n                c2 = 7\n            d = 8\n            print('done')\n            \"\"\")\n\n    def test_combine_parallel_data(self) -> None:\n        self.make_b_or_c_py()\n        self.make_data_file(\".coverage.b\", lines=self.B_LINES)\n        self.make_data_file(\".coverage.c\", lines=self.C_LINES)\n\n        # Combine the parallel coverage data files into .coverage .\n        cov = coverage.Coverage()\n        cov.combine(strict=True)\n        self.assert_exists(\".coverage\")\n\n        # After combining, there should be only the .coverage file.\n        self.assert_file_count(\".coverage.*\", 0)\n\n        # Read the coverage file and see that b_or_c.py has all 8 lines\n        # executed.\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['b_or_c.py'] == 8\n\n        # Running combine again should fail, because there are no parallel data\n        # files to combine.\n        cov = coverage.Coverage()\n        with pytest.raises(NoDataError, match=r\"No data to combine\"):\n            cov.combine(strict=True)\n\n        # And the originally combined data is still there.\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['b_or_c.py'] == 8\n\n    def test_combine_parallel_data_with_a_corrupt_file(self) -> None:\n        self.make_b_or_c_py()\n        self.make_data_file(\".coverage.b\", lines=self.B_LINES)\n        self.make_data_file(\".coverage.c\", lines=self.C_LINES)\n\n        # Make a bogus data file.\n        self.make_file(\".coverage.bad\", \"This isn't a coverage data file.\")\n\n        # Combine the parallel coverage data files into .coverage .\n        cov = coverage.Coverage()\n        with pytest.warns(Warning) as warns:\n            cov.combine(strict=True)\n        assert_coverage_warnings(\n            warns,\n            re.compile(\n                r\"Couldn't use data file '.*[/\\\\]\\.coverage\\.bad': \" + BAD_SQLITE_REGEX,\n            ),\n        )\n\n        # After combining, those two should be the only data files.\n        self.assert_exists(\".coverage\")\n        self.assert_exists(\".coverage.bad\")\n        self.assert_file_count(\".coverage.*\", 1)\n\n        # Read the coverage file and see that b_or_c.py has all 8 lines\n        # executed.\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['b_or_c.py'] == 8\n\n    def test_combine_no_usable_files(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/629\n        self.make_b_or_c_py()\n        self.make_data_file(\".coverage\", lines=self.B_LINES)\n\n        # Make bogus data files.\n        self.make_file(\".coverage.bad1\", \"This isn't a coverage data file.\")\n        self.make_file(\".coverage.bad2\", \"This isn't a coverage data file either.\")\n\n        # Combine the parallel coverage data files into .coverage, but nothing is readable.\n        cov = coverage.Coverage()\n        with pytest.warns(Warning) as warns:\n            with pytest.raises(NoDataError, match=r\"No usable data files\"):\n                cov.combine(strict=True)\n\n        warn_rx = re.compile(\n            r\"Couldn't use data file '.*[/\\\\]\\.coverage\\.bad[12]': \" + BAD_SQLITE_REGEX,\n        )\n        assert_coverage_warnings(warns, warn_rx, warn_rx)\n\n        # After combining, we should have a main file and two parallel files.\n        self.assert_exists(\".coverage\")\n        self.assert_exists(\".coverage.bad1\")\n        self.assert_exists(\".coverage.bad2\")\n        self.assert_file_count(\".coverage.*\", 2)\n\n        # Read the coverage file and see that b_or_c.py has 6 lines\n        # executed (we only did b, not c).\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['b_or_c.py'] == 6\n\n    def test_combine_parallel_data_in_two_steps(self) -> None:\n        self.make_b_or_c_py()\n        self.make_data_file(\".coverage.b\", lines=self.B_LINES)\n\n        # Combine the (one) parallel coverage data file into .coverage .\n        cov = coverage.Coverage()\n        cov.combine(strict=True)\n\n        self.assert_exists(\".coverage\")\n        self.assert_file_count(\".coverage.*\", 0)\n\n        self.make_data_file(\".coverage.c\", lines=self.C_LINES)\n        self.assert_exists(\".coverage\")\n        self.assert_file_count(\".coverage.*\", 1)\n\n        # Combine the parallel coverage data files into .coverage .\n        cov = coverage.Coverage()\n        cov.load()\n        cov.combine(strict=True)\n\n        # After combining, there should be only the .coverage file.\n        self.assert_exists(\".coverage\")\n        self.assert_file_count(\".coverage.*\", 0)\n\n        # Read the coverage file and see that b_or_c.py has all 8 lines\n        # executed.\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['b_or_c.py'] == 8\n\n    def test_combine_parallel_data_no_append(self) -> None:\n        self.make_b_or_c_py()\n        self.make_data_file(\".coverage.b\", lines=self.B_LINES)\n\n        # Combine the (one) parallel coverage data file into .coverage .\n        cov = coverage.Coverage()\n        cov.combine(strict=True)\n        self.assert_exists(\".coverage\")\n        self.assert_file_count(\".coverage.*\", 0)\n\n        self.make_data_file(\".coverage.c\", lines=self.C_LINES)\n\n        # Combine the parallel coverage data files into .coverage, but don't\n        # use the data in .coverage already.\n        cov = coverage.Coverage()\n        cov.combine(strict=True)\n\n        # After combining, there should be only the .coverage file.\n        self.assert_exists(\".coverage\")\n        self.assert_file_count(\".coverage.*\", 0)\n\n        # Read the coverage file and see that b_or_c.py has only 7 lines\n        # because we didn't keep the data from running b.\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['b_or_c.py'] == 7\n\n    def test_combine_parallel_data_keep(self) -> None:\n        self.make_b_or_c_py()\n        self.make_data_file(\".coverage.b\", lines=self.B_LINES)\n        self.make_data_file(\".coverage.c\", lines=self.C_LINES)\n\n        # Combine the parallel coverage data files into .coverage with the keep flag.\n        cov = coverage.Coverage()\n        cov.combine(strict=True, keep=True)\n\n        # After combining, the .coverage file & the original combined file should still be there.\n        self.assert_exists(\".coverage\")\n        self.assert_file_count(\".coverage.*\", 2)\n\n    @pytest.mark.parametrize(\"abs_order, rel_order\", [(1, 2), (2, 1)])\n    def test_combine_absolute_then_relative_1752(self, abs_order: int, rel_order: int) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1752\n        # If we're combining a relative data file and an absolute data file,\n        # the absolutes were made relative only if the relative file name was\n        # encountered first.  Test combining in both orders and check that the\n        # absolute file name is properly relative in either order.\n        FILE = \"sub/myprog.py\"\n        self.make_file(FILE, \"a = 1\")\n\n        self.make_data_file(suffix=f\"{abs_order}.abs\", lines={abs_file(FILE): [1]})\n        self.make_data_file(suffix=f\"{rel_order}.rel\", lines={FILE: [1]})\n\n        self.make_file(\".coveragerc\", \"[run]\\nrelative_files = True\\n\")\n        cov = coverage.Coverage()\n        cov.combine()\n        data = coverage.CoverageData()\n        data.read()\n        assert {os_sep(\"sub/myprog.py\")} == data.measured_files()\n", "tests/test_html.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests that HTML generation is awesome.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport datetime\nimport glob\nimport json\nimport os\nimport os.path\nimport re\nimport sys\n\nfrom unittest import mock\nfrom typing import Any, IO\n\nimport pytest\n\nimport coverage\nfrom coverage import env, Coverage\nfrom coverage.exceptions import NoDataError, NotPython, NoSource\nfrom coverage.files import abs_file, flat_rootname\nimport coverage.html\nfrom coverage.report_core import get_analysis_to_report\nfrom coverage.types import TLineNo, TMorf\n\nfrom tests import testenv\nfrom tests.coveragetest import CoverageTest, TESTS_DIR\nfrom tests.goldtest import gold_path\nfrom tests.goldtest import compare, contains, contains_rx, doesnt_contain, contains_any\nfrom tests.helpers import assert_coverage_warnings, change_dir\n\n\nclass HtmlTestHelpers(CoverageTest):\n    \"\"\"Methods that help with HTML tests.\"\"\"\n\n    def create_initial_files(self) -> None:\n        \"\"\"Create the source files we need to run these tests.\"\"\"\n        self.make_file(\"main_file.py\", \"\"\"\\\n            import helper1, helper2\n            helper1.func1(12)\n            helper2.func2(12)\n            \"\"\")\n        self.make_file(\"helper1.py\", \"\"\"\\\n            def func1(x):\n                if x % 2:\n                    print(\"odd\")\n            \"\"\")\n        self.make_file(\"helper2.py\", \"\"\"\\\n            def func2(x):\n                print(\"x is %d\" % x)\n            \"\"\")\n\n    def run_coverage(\n        self,\n        covargs: dict[str, Any] | None = None,\n        htmlargs: dict[str, Any] | None = None,\n    ) -> float:\n        \"\"\"Run coverage.py on main_file.py, and create an HTML report.\"\"\"\n        self.clean_local_file_imports()\n        cov = coverage.Coverage(**(covargs or {}))\n        self.start_import_stop(cov, \"main_file\")\n        ret = cov.html_report(**(htmlargs or {}))\n        self.assert_valid_hrefs()\n        return ret\n\n    def get_html_report_content(self, module: str) -> str:\n        \"\"\"Return the content of the HTML report for `module`.\"\"\"\n        filename = flat_rootname(module) + \".html\"\n        filename = os.path.join(\"htmlcov\", filename)\n        with open(filename) as f:\n            return f.read()\n\n    def get_html_index_content(self) -> str:\n        \"\"\"Return the content of index.html.\n\n        Time stamps are replaced with a placeholder so that clocks don't matter.\n\n        \"\"\"\n        with open(\"htmlcov/index.html\") as f:\n            index = f.read()\n        index = re.sub(\n            r\"created at \\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2} \\+\\d{4}\",\n            r\"created at YYYY-MM-DD HH:MM +ZZZZ\",\n            index,\n        )\n        index = re.sub(\n            r\"created at \\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}\",\n            r\"created at YYYY-MM-DD HH:MM\",\n            index,\n        )\n        return index\n\n    def assert_correct_timestamp(self, html: str) -> None:\n        \"\"\"Extract the time stamp from `html`, and assert it is recent.\"\"\"\n        timestamp_pat = r\"created at (\\d{4})-(\\d{2})-(\\d{2}) (\\d{2}):(\\d{2})\"\n        m = re.search(timestamp_pat, html)\n        assert m, \"Didn't find a time stamp!\"\n        timestamp = datetime.datetime(*[int(v) for v in m.groups()])    # type: ignore[arg-type]\n        # The time stamp only records the minute, so the delta could be from\n        # 12:00 to 12:01:59, or two minutes.\n        self.assert_recent_datetime(\n            timestamp,\n            seconds=120,\n            msg=f\"Time stamp is wrong: {timestamp}\",\n        )\n\n    def assert_valid_hrefs(self, directory: str = \"htmlcov\") -> None:\n        \"\"\"Assert that the hrefs in htmlcov/*.html are valid.\n\n        Doesn't check external links (those with a protocol).\n        \"\"\"\n        hrefs = collections.defaultdict(set)\n        for fname in glob.glob(f\"{directory}/*.html\"):\n            with open(fname) as fhtml:\n                html = fhtml.read()\n            for href in re.findall(r\"\"\" href=['\"]([^'\"]*)['\"]\"\"\", html):\n                if href.startswith(\"#\"):\n                    assert re.search(fr\"\"\" id=['\"]{href[1:]}['\"]\"\"\", html), (\n                        f\"Fragment {href!r} in {fname} has no anchor\"\n                    )\n                    continue\n                if \"://\" in href:\n                    continue\n                href = href.partition(\"#\")[0]   # ignore fragment in URLs.\n                hrefs[href].add(fname)\n        for href, sources in hrefs.items():\n            assert os.path.exists(f\"{directory}/{href}\"), (\n                f\"These files link to {href!r}, which doesn't exist: {', '.join(sources)}\"\n            )\n\n\nclass FileWriteTracker:\n    \"\"\"A fake object to track how `open` is used to write files.\"\"\"\n    def __init__(self, written: set[str]) -> None:\n        self.written = written\n\n    def open(self, filename: str, mode: str = \"r\") -> IO[str]:\n        \"\"\"Be just like `open`, but write written file names to `self.written`.\"\"\"\n        if mode.startswith(\"w\"):\n            self.written.add(filename.replace('\\\\', '/'))\n        return open(filename, mode)\n\n\nclass HtmlDeltaTest(HtmlTestHelpers, CoverageTest):\n    \"\"\"Tests of the HTML delta speed-ups.\"\"\"\n\n    def setUp(self) -> None:\n        super().setUp()\n\n        # At least one of our tests monkey-patches the version of coverage.py,\n        # so grab it here to restore it later.\n        self.real_coverage_version = coverage.__version__\n        self.addCleanup(setattr, coverage, \"__version__\", self.real_coverage_version)\n\n        self.files_written: set[str]\n\n    def run_coverage(\n        self,\n        covargs: dict[str, Any] | None = None,\n        htmlargs: dict[str, Any] | None = None,\n    ) -> float:\n        \"\"\"Run coverage in-process for the delta tests.\n\n        For the delta tests, we always want `source=.` and we want to track\n        which files are written.  `self.files_written` will be the file names\n        that were opened for writing in html.py.\n\n        \"\"\"\n        covargs = covargs or {}\n        covargs['source'] = \".\"\n        self.files_written = set()\n        mock_open = FileWriteTracker(self.files_written).open\n        with mock.patch(\"coverage.html.open\", mock_open):\n            return super().run_coverage(covargs=covargs, htmlargs=htmlargs)\n\n    def assert_htmlcov_files_exist(self) -> None:\n        \"\"\"Assert that all the expected htmlcov files exist.\"\"\"\n        self.assert_exists(\"htmlcov/index.html\")\n        self.assert_exists(\"htmlcov/function_index.html\")\n        self.assert_exists(\"htmlcov/class_index.html\")\n        self.assert_exists(\"htmlcov/main_file_py.html\")\n        self.assert_exists(\"htmlcov/helper1_py.html\")\n        self.assert_exists(\"htmlcov/helper2_py.html\")\n        self.assert_exists(\"htmlcov/.gitignore\")\n        # Cache-busted files have random data in the name, but they should all\n        # be there, and there should only be one of each.\n        statics = [\"style.css\", \"coverage_html.js\", \"keybd_closed.png\", \"favicon_32.png\"]\n        files = os.listdir(\"htmlcov\")\n        for static in statics:\n            base, ext = os.path.splitext(static)\n            busted_file_pattern = fr\"{base}_cb_\\w{{8}}{ext}\"\n            matches = [m for f in files if (m := re.fullmatch(busted_file_pattern, f))]\n            assert len(matches) == 1, f\"Found {len(matches)} files for {static}\"\n\n    def test_html_created(self) -> None:\n        # Test basic HTML generation: files should be created.\n        self.create_initial_files()\n        self.run_coverage()\n        self.assert_htmlcov_files_exist()\n\n    def test_html_delta_from_source_change(self) -> None:\n        # HTML generation can create only the files that have changed.\n        # In this case, helper1 changes because its source is different.\n        self.create_initial_files()\n        self.run_coverage()\n        index1 = self.get_html_index_content()\n\n        # Now change a file (but only in a comment) and do it again.\n        self.make_file(\"helper1.py\", \"\"\"\\\n            def func1(x):   # A nice function\n                if x % 2:\n                    print(\"odd\")\n            \"\"\")\n\n        self.run_coverage()\n\n        # Only the changed files should have been created.\n        self.assert_htmlcov_files_exist()\n        assert \"htmlcov/index.html\" in self.files_written\n        assert \"htmlcov/helper1_py.html\" in self.files_written\n        assert \"htmlcov/helper2_py.html\" not in self.files_written\n        assert \"htmlcov/main_file_py.html\" not in self.files_written\n\n        # Because the source change was only a comment, the index is the same.\n        index2 = self.get_html_index_content()\n        assert index1 == index2\n\n    def test_html_delta_from_coverage_change(self) -> None:\n        # HTML generation can create only the files that have changed.\n        # In this case, helper1 changes because its coverage is different.\n        self.create_initial_files()\n        self.run_coverage()\n\n        # Now change a file and do it again. main_file is different, and calls\n        # helper1 differently.\n        self.make_file(\"main_file.py\", \"\"\"\\\n            import helper1, helper2\n            helper1.func1(23)\n            helper2.func2(23)\n            \"\"\")\n\n        self.run_coverage()\n\n        # Only the changed files should have been created.\n        self.assert_htmlcov_files_exist()\n        assert \"htmlcov/index.html\" in self.files_written\n        assert \"htmlcov/helper1_py.html\" in self.files_written\n        assert \"htmlcov/helper2_py.html\" not in self.files_written\n        assert \"htmlcov/main_file_py.html\" in self.files_written\n\n    def test_html_delta_from_settings_change(self) -> None:\n        # HTML generation can create only the files that have changed.\n        # In this case, everything changes because the coverage.py settings\n        # have changed.\n        self.create_initial_files()\n        self.run_coverage(covargs=dict(omit=[]))\n        index1 = self.get_html_index_content()\n\n        self.run_coverage(covargs=dict(omit=['xyzzy*']))\n\n        # All the files have been reported again.\n        self.assert_htmlcov_files_exist()\n        assert \"htmlcov/index.html\" in self.files_written\n        assert \"htmlcov/helper1_py.html\" in self.files_written\n        assert \"htmlcov/helper2_py.html\" in self.files_written\n        assert \"htmlcov/main_file_py.html\" in self.files_written\n\n        index2 = self.get_html_index_content()\n        assert index1 == index2\n\n    def test_html_delta_from_coverage_version_change(self) -> None:\n        # HTML generation can create only the files that have changed.\n        # In this case, everything changes because the coverage.py version has\n        # changed.\n        self.create_initial_files()\n        self.run_coverage()\n        index1 = self.get_html_index_content()\n\n        # \"Upgrade\" coverage.py!\n        coverage.__version__ = \"XYZZY\"\n\n        self.run_coverage()\n\n        # All the files have been reported again.\n        self.assert_htmlcov_files_exist()\n        assert \"htmlcov/index.html\" in self.files_written\n        assert \"htmlcov/helper1_py.html\" in self.files_written\n        assert \"htmlcov/helper2_py.html\" in self.files_written\n        assert \"htmlcov/main_file_py.html\" in self.files_written\n\n        index2 = self.get_html_index_content()\n        fixed_index2 = index2.replace(\"XYZZY\", self.real_coverage_version)\n        assert index1 == fixed_index2\n\n    def test_file_becomes_100(self) -> None:\n        self.create_initial_files()\n        self.run_coverage()\n\n        # Now change a file and do it again\n        self.make_file(\"main_file.py\", \"\"\"\\\n            import helper1, helper2\n            # helper1 is now 100%\n            helper1.func1(12)\n            helper1.func1(23)\n            \"\"\")\n\n        self.run_coverage(htmlargs=dict(skip_covered=True))\n\n        # The 100% file, skipped, shouldn't be here.\n        self.assert_doesnt_exist(\"htmlcov/helper1_py.html\")\n\n    def test_status_format_change(self) -> None:\n        self.create_initial_files()\n        self.run_coverage()\n\n        with open(\"htmlcov/status.json\") as status_json:\n            status_data = json.load(status_json)\n\n        assert status_data['format'] == 5\n        status_data['format'] = 99\n        with open(\"htmlcov/status.json\", \"w\") as status_json:\n            json.dump(status_data, status_json)\n\n        self.run_coverage()\n\n        # All the files have been reported again.\n        self.assert_htmlcov_files_exist()\n        assert \"htmlcov/index.html\" in self.files_written\n        assert \"htmlcov/helper1_py.html\" in self.files_written\n        assert \"htmlcov/helper2_py.html\" in self.files_written\n        assert \"htmlcov/main_file_py.html\" in self.files_written\n\n    def test_dont_overwrite_gitignore(self) -> None:\n        self.create_initial_files()\n        self.make_file(\"htmlcov/.gitignore\", \"# ignore nothing\")\n        self.run_coverage()\n        with open(\"htmlcov/.gitignore\") as fgi:\n            assert fgi.read() == \"# ignore nothing\"\n\n    def test_dont_write_gitignore_into_existing_directory(self) -> None:\n        self.create_initial_files()\n        self.make_file(\"htmlcov/README\", \"My files: don't touch!\")\n        self.run_coverage()\n        self.assert_doesnt_exist(\"htmlcov/.gitignore\")\n        self.assert_exists(\"htmlcov/index.html\")\n\n\nclass HtmlTitleTest(HtmlTestHelpers, CoverageTest):\n    \"\"\"Tests of the HTML title support.\"\"\"\n\n    def test_default_title(self) -> None:\n        self.create_initial_files()\n        self.run_coverage()\n        index = self.get_html_index_content()\n        assert \"<title>Coverage report</title>\" in index\n        assert \"<h1>Coverage report:\" in index\n\n    def test_title_set_in_config_file(self) -> None:\n        self.create_initial_files()\n        self.make_file(\".coveragerc\", \"[html]\\ntitle = Metrics & stuff!\\n\")\n        self.run_coverage()\n        index = self.get_html_index_content()\n        assert \"<title>Metrics &amp; stuff!</title>\" in index\n        assert \"<h1>Metrics &amp; stuff!:\" in index\n\n    def test_non_ascii_title_set_in_config_file(self) -> None:\n        self.create_initial_files()\n        self.make_file(\".coveragerc\", \"[html]\\ntitle = \u00ab\u03c4\u03b1\u0411\u042c\u2113\u03c3\u00bb numbers\")\n        self.run_coverage()\n        index = self.get_html_index_content()\n        assert \"<title>&#171;&#964;&#945;&#1041;&#1068;&#8467;&#963;&#187; numbers\" in index\n        assert \"<h1>&#171;&#964;&#945;&#1041;&#1068;&#8467;&#963;&#187; numbers\" in index\n\n    def test_title_set_in_args(self) -> None:\n        self.create_initial_files()\n        self.make_file(\".coveragerc\", \"[html]\\ntitle = Good title\\n\")\n        self.run_coverage(htmlargs=dict(title=\"\u00ab\u03c4\u03b1\u0411\u042c\u2113\u03c3\u00bb & st\u00fcff!\"))\n        index = self.get_html_index_content()\n        expected = (\n            \"<title>&#171;&#964;&#945;&#1041;&#1068;&#8467;&#963;&#187; \" +\n            \"&amp; st&#252;ff!</title>\"\n        )\n        assert expected in index\n        assert \"<h1>&#171;&#964;&#945;&#1041;&#1068;&#8467;&#963;&#187; &amp; st&#252;ff!:\" in index\n\n\nclass HtmlWithUnparsableFilesTest(HtmlTestHelpers, CoverageTest):\n    \"\"\"Test the behavior when measuring unparsable files.\"\"\"\n\n    def test_dotpy_not_python(self) -> None:\n        self.make_file(\"main.py\", \"import innocuous\")\n        self.make_file(\"innocuous.py\", \"a = 1\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n        self.make_file(\"innocuous.py\", \"<h1>This isn't python!</h1>\")\n        msg = \"Couldn't parse '.*innocuous.py' as Python source: .* at line 1\"\n        with pytest.raises(NotPython, match=msg):\n            cov.html_report()\n\n    def test_dotpy_not_python_ignored(self) -> None:\n        self.make_file(\"main.py\", \"import innocuous\")\n        self.make_file(\"innocuous.py\", \"a = 2\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n\n        self.make_file(\"innocuous.py\", \"<h1>This isn't python!</h1>\")\n        with pytest.warns(Warning) as warns:\n            cov.html_report(ignore_errors=True)\n        assert_coverage_warnings(\n            warns,\n            re.compile(r\"Couldn't parse Python file '.*innocuous.py' \\(couldnt-parse\\)\"),\n        )\n        self.assert_exists(\"htmlcov/index.html\")\n        # This would be better as a glob, if the HTML layout changes:\n        self.assert_doesnt_exist(\"htmlcov/innocuous.html\")\n\n    def test_dothtml_not_python(self) -> None:\n        # Run an \"HTML\" file\n        self.make_file(\"innocuous.html\", \"a = 3\")\n        self.make_data_file(lines={abs_file(\"innocuous.html\"): [1]})\n        # Before reporting, change it to be an HTML file.\n        self.make_file(\"innocuous.html\", \"<h1>This isn't python at all!</h1>\")\n        cov = coverage.Coverage()\n        cov.load()\n        with pytest.raises(NoDataError, match=\"No data to report.\"):\n            cov.html_report()\n\n    def test_execed_liar_ignored(self) -> None:\n        # Jinja2 sets __file__ to be a non-Python file, and then execs code.\n        # If that file contains non-Python code, a TokenError shouldn't\n        # have been raised when writing the HTML report.\n        source = \"exec(compile('','','exec'), {'__file__': 'liar.html'})\"\n        self.make_file(\"liar.py\", source)\n        self.make_file(\"liar.html\", \"{# Whoops, not python code #}\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"liar\")\n        cov.html_report()\n        self.assert_exists(\"htmlcov/index.html\")\n\n    def test_execed_liar_ignored_indentation_error(self) -> None:\n        # Jinja2 sets __file__ to be a non-Python file, and then execs code.\n        # If that file contains untokenizable code, we shouldn't get an\n        # exception.\n        source = \"exec(compile('','','exec'), {'__file__': 'liar.html'})\"\n        self.make_file(\"liar.py\", source)\n        # Tokenize will raise an IndentationError if it can't dedent.\n        self.make_file(\"liar.html\", \"0\\n  2\\n 1\\n\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"liar\")\n        cov.html_report()\n        self.assert_exists(\"htmlcov/index.html\")\n\n    def test_decode_error(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/351\n        # imp.load_module won't load a file with an undecodable character\n        # in a comment, though Python will run them.  So we'll change the\n        # file after running.\n        self.make_file(\"main.py\", \"import sub.not_ascii\")\n        self.make_file(\"sub/__init__.py\")\n        self.make_file(\"sub/not_ascii.py\", \"\"\"\\\n            # coding: utf-8\n            a = 1  # Isn't this great?!\n            \"\"\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n\n        # Create the undecodable version of the file. make_file is too helpful,\n        # so get down and dirty with bytes.\n        with open(\"sub/not_ascii.py\", \"wb\") as f:\n            f.write(b\"# coding: utf-8\\na = 1  # Isn't this great?\\xcb!\\n\")\n\n        with open(\"sub/not_ascii.py\", \"rb\") as f:\n            undecodable = f.read()\n        assert b\"?\\xcb!\" in undecodable\n\n        cov.html_report()\n\n        html_report = self.get_html_report_content(\"sub/not_ascii.py\")\n        expected = \"# Isn't this great?&#65533;!\"\n        assert expected in html_report\n\n    def test_formfeeds(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/360\n        self.make_file(\"formfeed.py\", \"line_one = 1\\n\\f\\nline_two = 2\\n\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"formfeed\")\n        cov.html_report()\n\n        formfeed_html = self.get_html_report_content(\"formfeed.py\")\n        assert \"line_two\" in formfeed_html\n\n    def test_splitlines_special_chars(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1512\n        # See https://docs.python.org/3/library/stdtypes.html#str.splitlines for\n        # the characters splitlines treats specially that readlines does not.\n\n        # I'm not exactly sure why we need the \"a\" strings here, but the old\n        # code wasn't failing without them.\n        self.make_file(\"splitlines_is_weird.py\", \"\"\"\\\n            test = {\n                \"0b\": [\"\\x0b0\"], \"a1\": \"this is line 2\",\n                \"0c\": [\"\\x0c0\"], \"a2\": \"this is line 3\",\n                \"1c\": [\"\\x1c0\"], \"a3\": \"this is line 4\",\n                \"1d\": [\"\\x1d0\"], \"a4\": \"this is line 5\",\n                \"1e\": [\"\\x1e0\"], \"a5\": \"this is line 6\",\n                \"85\": [\"\\x850\"], \"a6\": \"this is line 7\",\n                \"2028\": [\"\\u20280\"], \"a7\": \"this is line 8\",\n                \"2029\": [\"\\u20290\"], \"a8\": \"this is line 9\",\n            }\n            DONE = 1\n            \"\"\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"splitlines_is_weird\")\n        cov.html_report()\n\n        the_html = self.get_html_report_content(\"splitlines_is_weird.py\")\n        assert \"DONE\" in the_html\n\n        # Check that the lines are properly decoded and reported...\n        html_lines = the_html.split(\"\\n\")\n        assert any(re.search(r'id=\"t2\".*\"this is line 2\"', line) for line in html_lines)\n        assert any(re.search(r'id=\"t9\".*\"this is line 9\"', line) for line in html_lines)\n\n\nclass HtmlTest(HtmlTestHelpers, CoverageTest):\n    \"\"\"Moar HTML tests.\"\"\"\n\n    def test_missing_source_file_incorrect_message(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/60\n        self.make_file(\"thefile.py\", \"import sub.another\\n\")\n        self.make_file(\"sub/__init__.py\", \"\")\n        self.make_file(\"sub/another.py\", \"print('another')\\n\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, 'thefile')\n        os.remove(\"sub/another.py\")\n\n        missing_file = os.path.join(self.temp_dir, \"sub\", \"another.py\")\n        missing_file = os.path.realpath(missing_file)\n        msg = \"(?i)No source for code: '%s'\" % re.escape(missing_file)\n        with pytest.raises(NoSource, match=msg):\n            cov.html_report()\n\n    def test_extensionless_file_collides_with_extension(self) -> None:\n        # It used to be that \"program\" and \"program.py\" would both be reported\n        # to \"program.html\".  Now they are not.\n        # https://github.com/nedbat/coveragepy/issues/69\n        self.make_file(\"program\", \"import program\\n\")\n        self.make_file(\"program.py\", \"a = 1\\n\")\n        self.make_data_file(lines={\n            abs_file(\"program\"): [1],\n            abs_file(\"program.py\"): [1],\n        })\n        cov = coverage.Coverage()\n        cov.load()\n        cov.html_report()\n        self.assert_exists(\"htmlcov/index.html\")\n        self.assert_exists(\"htmlcov/program.html\")\n        self.assert_exists(\"htmlcov/program_py.html\")\n\n    def test_has_date_stamp_in_files(self) -> None:\n        self.create_initial_files()\n        self.run_coverage()\n\n        with open(\"htmlcov/index.html\") as f:\n            self.assert_correct_timestamp(f.read())\n        with open(\"htmlcov/main_file_py.html\") as f:\n            self.assert_correct_timestamp(f.read())\n\n    def test_reporting_on_unmeasured_file(self) -> None:\n        # It should be ok to ask for an HTML report on a file that wasn't even\n        # measured at all.  https://github.com/nedbat/coveragepy/issues/403\n        self.create_initial_files()\n        self.make_file(\"other.py\", \"a = 1\\n\")\n        self.run_coverage(htmlargs=dict(morfs=['other.py']))\n        self.assert_exists(\"htmlcov/index.html\")\n        self.assert_exists(\"htmlcov/other_py.html\")\n\n    def make_main_and_not_covered(self) -> None:\n        \"\"\"Helper to create files for skip_covered scenarios.\"\"\"\n        self.make_file(\"main_file.py\", \"\"\"\\\n            import not_covered\n\n            def normal():\n                print(\"z\")\n            normal()\n        \"\"\")\n        self.make_file(\"not_covered.py\", \"\"\"\\\n            def not_covered():\n                print(\"n\")\n        \"\"\")\n\n    def test_report_skip_covered(self) -> None:\n        self.make_main_and_not_covered()\n        self.run_coverage(htmlargs=dict(skip_covered=True))\n        self.assert_exists(\"htmlcov/index.html\")\n        self.assert_doesnt_exist(\"htmlcov/main_file_py.html\")\n        self.assert_exists(\"htmlcov/not_covered_py.html\")\n\n    def test_html_skip_covered(self) -> None:\n        self.make_main_and_not_covered()\n        self.make_file(\".coveragerc\", \"[html]\\nskip_covered = True\")\n        self.run_coverage()\n        self.assert_exists(\"htmlcov/index.html\")\n        self.assert_doesnt_exist(\"htmlcov/main_file_py.html\")\n        self.assert_exists(\"htmlcov/not_covered_py.html\")\n        index = self.get_html_index_content()\n        assert \"1 file skipped due to complete coverage.\" in index\n\n    def test_report_skip_covered_branches(self) -> None:\n        self.make_main_and_not_covered()\n        self.run_coverage(covargs=dict(branch=True), htmlargs=dict(skip_covered=True))\n        self.assert_exists(\"htmlcov/index.html\")\n        self.assert_doesnt_exist(\"htmlcov/main_file_py.html\")\n        self.assert_exists(\"htmlcov/not_covered_py.html\")\n\n    def test_report_skip_covered_100(self) -> None:\n        self.make_file(\"main_file.py\", \"\"\"\\\n            def normal():\n                print(\"z\")\n            normal()\n        \"\"\")\n        res = self.run_coverage(covargs=dict(source=\".\"), htmlargs=dict(skip_covered=True))\n        assert res == 100.0\n        self.assert_doesnt_exist(\"htmlcov/main_file_py.html\")\n        # Since there are no files to report, we can't collect any region\n        # information, so there are no region-based index pages.\n        self.assert_doesnt_exist(\"htmlcov/function_index.html\")\n        self.assert_doesnt_exist(\"htmlcov/class_index.html\")\n\n    def test_report_skip_covered_100_functions(self) -> None:\n        self.make_file(\"main_file.py\", \"\"\"\\\n            def normal():\n                print(\"z\")\n            def abnormal():\n                print(\"a\")\n            normal()\n        \"\"\")\n        res = self.run_coverage(covargs=dict(source=\".\"), htmlargs=dict(skip_covered=True))\n        assert res == 80.0\n        self.assert_exists(\"htmlcov/main_file_py.html\")\n        # We have a file to report, so we get function and class index pages,\n        # even though there are no classes.\n        self.assert_exists(\"htmlcov/function_index.html\")\n        self.assert_exists(\"htmlcov/class_index.html\")\n\n    def make_init_and_main(self) -> None:\n        \"\"\"Helper to create files for skip_empty scenarios.\"\"\"\n        self.make_file(\"submodule/__init__.py\", \"\")\n        self.make_file(\"main_file.py\", \"\"\"\\\n            import submodule\n\n            def normal():\n                print(\"z\")\n            normal()\n        \"\"\")\n\n    def test_report_skip_empty(self) -> None:\n        self.make_init_and_main()\n        self.run_coverage(htmlargs=dict(skip_empty=True))\n        self.assert_exists(\"htmlcov/index.html\")\n        self.assert_exists(\"htmlcov/main_file_py.html\")\n        self.assert_doesnt_exist(\"htmlcov/submodule___init___py.html\")\n        index = self.get_html_index_content()\n        assert \"1 empty file skipped.\" in index\n\n    def test_html_skip_empty(self) -> None:\n        self.make_init_and_main()\n        self.make_file(\".coveragerc\", \"[html]\\nskip_empty = True\")\n        self.run_coverage()\n        self.assert_exists(\"htmlcov/index.html\")\n        self.assert_exists(\"htmlcov/main_file_py.html\")\n        self.assert_doesnt_exist(\"htmlcov/submodule___init___py.html\")\n\n\ndef filepath_to_regex(path: str) -> str:\n    \"\"\"Create a regex for scrubbing a file path.\"\"\"\n    regex = re.escape(path)\n    # If there's a backslash, let it match either slash.\n    regex = regex.replace(r\"\\\\\", r\"[\\\\/]\")\n    if env.WINDOWS:\n        regex = \"(?i)\" + regex\n    return regex\n\n\ndef compare_html(\n    expected: str,\n    actual: str,\n    extra_scrubs: list[tuple[str, str]] | None = None,\n) -> None:\n    \"\"\"Specialized compare function for our HTML files.\"\"\"\n    __tracebackhide__ = True    # pytest, please don't show me this function.\n    scrubs = [\n        (r'/coverage\\.readthedocs\\.io/?[-.\\w/]*', '/coverage.readthedocs.io/VER'),\n        (r'coverage\\.py v[\\d.abcdev]+', 'coverage.py vVER'),\n        (r'created at \\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d [-+]\\d\\d\\d\\d', 'created at DATE'),\n        (r'created at \\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d', 'created at DATE'),\n        # Static files have cache busting.\n        (r'_cb_\\w{8}\\.', '_CB.'),\n        # Occasionally an absolute path is in the HTML report.\n        (filepath_to_regex(TESTS_DIR), 'TESTS_DIR'),\n        (filepath_to_regex(flat_rootname(str(TESTS_DIR))), '_TESTS_DIR'),\n        # The temp dir the tests make.\n        (filepath_to_regex(os.getcwd()), 'TEST_TMPDIR'),\n        (filepath_to_regex(flat_rootname(str(os.getcwd()))), '_TEST_TMPDIR'),\n        (filepath_to_regex(abs_file(os.getcwd())), 'TEST_TMPDIR'),\n        (filepath_to_regex(flat_rootname(str(abs_file(os.getcwd())))), '_TEST_TMPDIR'),\n        (r'/private/var/[\\w/]+/pytest-of-\\w+/pytest-\\d+/(popen-gw\\d+/)?t\\d+', 'TEST_TMPDIR'),\n        # If the gold files were created on Windows, we need to scrub Windows paths also:\n        (r'[A-Z]:\\\\Users\\\\[\\w\\\\]+\\\\pytest-of-\\w+\\\\pytest-\\d+\\\\(popen-gw\\d+\\\\)?t\\d+', 'TEST_TMPDIR'),\n    ]\n    if extra_scrubs:\n        scrubs += extra_scrubs\n    compare(expected, actual, file_pattern=\"*.html\", scrubs=scrubs)\n\n\ndef unbust(directory: str) -> None:\n    \"\"\"Find files with cache busting, and rename them to simple names.\n\n    This makes it possible for us to compare gold files.\n    \"\"\"\n    with change_dir(directory):\n        for fname in os.listdir(\".\"):\n            base, ext = os.path.splitext(fname)\n            base, _, _ = base.partition(\"_cb_\")\n            if base != fname:\n                os.rename(fname, base + ext)\n\n\nclass HtmlGoldTest(HtmlTestHelpers, CoverageTest):\n    \"\"\"Tests of HTML reporting that use gold files.\"\"\"\n\n    def test_a(self) -> None:\n        self.make_file(\"a.py\", \"\"\"\\\n            if 1 < 2:\n                # Needed a < to look at HTML entities.\n                a = 3\n            else:\n                a = 4\n            \"\"\")\n\n        cov = coverage.Coverage()\n        a = self.start_import_stop(cov, \"a\")\n        cov.html_report(a, directory='out/a')\n\n        compare_html(gold_path(\"html/a\"), \"out/a\")\n        contains(\n            \"out/a/a_py.html\",\n            ('<span class=\"key\">if</span> <span class=\"num\">1</span> ' +\n             '<span class=\"op\">&lt;</span> <span class=\"num\">2</span>'),\n            ('    <span class=\"nam\">a</span> ' +\n             '<span class=\"op\">=</span> <span class=\"num\">3</span>'),\n            '<span class=\"pc_cov\">67%</span>',\n        )\n        contains(\n            \"out/a/index.html\",\n            '<a href=\"a_py.html\">a.py</a>',\n            '<span class=\"pc_cov\">67%</span>',\n            '<td class=\"right\" data-ratio=\"2 3\">67%</td>',\n        )\n\n    @pytest.mark.skipif(\n        env.PYPY and env.PYVERSION[:2] == (3, 8),\n        reason=\"PyPy 3.8 produces different results!?\",\n    )\n    def test_b_branch(self) -> None:\n        self.make_file(\"b.py\", \"\"\"\\\n            def one(x):\n                # This will be a branch that misses the else.\n                if x < 2:\n                    a = 3\n                else:\n                    a = 4\n\n            one(1)\n\n            def two(x):\n                # A missed else that branches to \"exit\"\n                if x:\n                    a = 5\n\n            two(1)\n\n            def three():\n                try:\n                    # This if has two branches, *neither* one taken.\n                    if name_error_this_variable_doesnt_exist:\n                        a = 1\n                    else:\n                        a = 2\n                except:\n                    pass\n\n            three()\n            \"\"\")\n\n        cov = coverage.Coverage(branch=True)\n        b = self.start_import_stop(cov, \"b\")\n        cov.html_report(b, directory=\"out/b_branch\")\n\n        compare_html(gold_path(\"html/b_branch\"), \"out/b_branch\")\n        contains(\n            \"out/b_branch/b_py.html\",\n            ('<span class=\"key\">if</span> <span class=\"nam\">x</span> ' +\n             '<span class=\"op\">&lt;</span> <span class=\"num\">2</span>'),\n            ('    <span class=\"nam\">a</span> <span class=\"op\">=</span> ' +\n             '<span class=\"num\">3</span>'),\n            '<span class=\"pc_cov\">70%</span>',\n\n            ('<span class=\"annotate short\">3&#x202F;&#x219B;&#x202F;6</span>' +\n             '<span class=\"annotate long\">line 3 didn\\'t jump to line 6 ' +\n                            'because the condition on line 3 was always true</span>'),\n            ('<span class=\"annotate short\">12&#x202F;&#x219B;&#x202F;exit</span>' +\n             '<span class=\"annotate long\">line 12 didn\\'t return from function \\'two\\' ' +\n                            'because the condition on line 12 was always true</span>'),\n            ('<span class=\"annotate short\">20&#x202F;&#x219B;&#x202F;21,&nbsp;&nbsp; ' +\n                            '20&#x202F;&#x219B;&#x202F;23</span>' +\n             '<span class=\"annotate long\">2 missed branches: ' +\n                            '1) line 20 didn\\'t jump to line 21 ' +\n                                'because the condition on line 20 was never true, ' +\n                            '2) line 20 didn\\'t jump to line 23 ' +\n                                'because the condition on line 20 was always true</span>'),\n        )\n        contains(\n            \"out/b_branch/index.html\",\n            '<a href=\"b_py.html\">b.py</a>',\n            '<span class=\"pc_cov\">70%</span>',\n            '<td class=\"right\" data-ratio=\"16 23\">70%</td>',\n        )\n\n    def test_bom(self) -> None:\n        self.make_file(\"bom.py\", bytes=b\"\"\"\\\n\\xef\\xbb\\xbf# A Python source file in utf-8, with BOM.\nmath = \"3\\xc3\\x974 = 12, \\xc3\\xb72 = 6\\xc2\\xb10\"\n\nassert len(math) == 18\nassert len(math.encode('utf-8')) == 21\n\"\"\".replace(b\"\\n\", b\"\\r\\n\"))\n\n        # It's important that the source file really have a BOM, which can\n        # get lost, so check that it's really there, and that we have \\r\\n\n        # line endings.\n        with open(\"bom.py\", \"rb\") as f:\n            data = f.read()\n            assert data[:3] == b\"\\xef\\xbb\\xbf\"\n            assert data.count(b\"\\r\\n\") == 5\n\n        cov = coverage.Coverage()\n        bom = self.start_import_stop(cov, \"bom\")\n        cov.html_report(bom, directory=\"out/bom\")\n\n        compare_html(gold_path(\"html/bom\"), \"out/bom\")\n        contains(\n            \"out/bom/bom_py.html\",\n            '<span class=\"str\">\"3&#215;4 = 12, &#247;2 = 6&#177;0\"</span>',\n        )\n\n    def test_isolatin1(self) -> None:\n        self.make_file(\"isolatin1.py\", bytes=b\"\"\"\\\n# -*- coding: iso8859-1 -*-\n# A Python source file in another encoding.\n\nmath = \"3\\xd74 = 12, \\xf72 = 6\\xb10\"\nassert len(math) == 18\n\"\"\")\n\n        cov = coverage.Coverage()\n        isolatin1 = self.start_import_stop(cov, \"isolatin1\")\n        cov.html_report(isolatin1, directory=\"out/isolatin1\")\n\n        compare_html(gold_path(\"html/isolatin1\"), \"out/isolatin1\")\n        contains(\n            \"out/isolatin1/isolatin1_py.html\",\n            '<span class=\"str\">\"3&#215;4 = 12, &#247;2 = 6&#177;0\"</span>',\n        )\n\n    def make_main_etc(self) -> None:\n        \"\"\"Make main.py and m1-m3.py for other tests.\"\"\"\n        self.make_file(\"main.py\", \"\"\"\\\n            import m1\n            import m2\n            import m3\n\n            a = 5\n            b = 6\n\n            assert m1.m1a == 1\n            assert m2.m2a == 1\n            assert m3.m3a == 1\n            \"\"\")\n        self.make_file(\"m1.py\", \"\"\"\\\n            m1a = 1\n            m1b = 2\n            \"\"\")\n        self.make_file(\"m2.py\", \"\"\"\\\n            m2a = 1\n            m2b = 2\n            \"\"\")\n        self.make_file(\"m3.py\", \"\"\"\\\n            m3a = 1\n            m3b = 2\n            \"\"\")\n\n    def test_omit_1(self) -> None:\n        self.make_main_etc()\n        cov = coverage.Coverage(include=[\"./*\"])\n        self.start_import_stop(cov, \"main\")\n        cov.html_report(directory=\"out/omit_1\")\n        compare_html(gold_path(\"html/omit_1\"), \"out/omit_1\")\n\n    def test_omit_2(self) -> None:\n        self.make_main_etc()\n        cov = coverage.Coverage(include=[\"./*\"])\n        self.start_import_stop(cov, \"main\")\n        cov.html_report(directory=\"out/omit_2\", omit=[\"m1.py\"])\n        compare_html(gold_path(\"html/omit_2\"), \"out/omit_2\")\n\n    def test_omit_3(self) -> None:\n        self.make_main_etc()\n        cov = coverage.Coverage(include=[\"./*\"])\n        self.start_import_stop(cov, \"main\")\n        cov.html_report(directory=\"out/omit_3\", omit=[\"m1.py\", \"m2.py\"])\n        compare_html(gold_path(\"html/omit_3\"), \"out/omit_3\")\n\n    def test_omit_4(self) -> None:\n        self.make_main_etc()\n        self.make_file(\"omit4.ini\", \"\"\"\\\n            [report]\n            omit = m2.py\n            \"\"\")\n\n        cov = coverage.Coverage(config_file=\"omit4.ini\", include=[\"./*\"])\n        self.start_import_stop(cov, \"main\")\n        cov.html_report(directory=\"out/omit_4\")\n        compare_html(gold_path(\"html/omit_4\"), \"out/omit_4\")\n\n    def test_omit_5(self) -> None:\n        self.make_main_etc()\n        self.make_file(\"omit5.ini\", \"\"\"\\\n            [report]\n            omit =\n                fooey\n                gooey, m[23]*, kablooey\n                helloworld\n\n            [html]\n            directory = out/omit_5\n            \"\"\")\n\n        cov = coverage.Coverage(config_file=\"omit5.ini\", include=[\"./*\"])\n        self.start_import_stop(cov, \"main\")\n        cov.html_report()\n        compare_html(gold_path(\"html/omit_5\"), \"out/omit_5\")\n\n    def test_other(self) -> None:\n        self.make_file(\"src/here.py\", \"\"\"\\\n            import other\n\n            if 1 < 2:\n                h = 3\n            else:\n                h = 4\n            \"\"\")\n        self.make_file(\"othersrc/other.py\", \"\"\"\\\n            # A file in another directory.  We're checking that it ends up in the\n            # HTML report.\n\n            print(\"This is the other src!\")\n            \"\"\")\n\n        with change_dir(\"src\"):\n            sys.path.insert(0, \"../othersrc\")\n            cov = coverage.Coverage(include=[\"./*\", \"../othersrc/*\"])\n            self.start_import_stop(cov, \"here\")\n            cov.html_report(directory=\"../out/other\")\n\n        # Different platforms will name the \"other\" file differently. Rename it\n        actual_file = list(glob.glob(\"out/other/*_other_py.html\"))\n        assert len(actual_file) == 1\n        os.rename(actual_file[0], \"out/other/blah_blah_other_py.html\")\n\n        compare_html(\n            gold_path(\"html/other\"), \"out/other\",\n            extra_scrubs=[\n                (r'href=\"z_[0-9a-z]{16}_other_', 'href=\"_TEST_TMPDIR_other_othersrc_'),\n                (r'TEST_TMPDIR\\\\othersrc\\\\other.py', 'TEST_TMPDIR/othersrc/other.py'),\n            ],\n        )\n        contains(\n            'out/other/index.html',\n            '<a href=\"here_py.html\">here.py</a>',\n            'other_py.html\">',\n            'other.py</a>',\n        )\n\n    def test_partial(self) -> None:\n        self.make_file(\"partial.py\", \"\"\"\\\n            # partial branches and excluded lines\n            a = 2\n\n            while \"no peephole\".upper():        # t4\n                break\n\n            while a:        # pragma: no branch\n                break\n\n            if 0:\n                never_happen()\n\n            if 13:\n                a = 14\n\n            if a == 16:\n                raise ZeroDivisionError(\"17\")\n            \"\"\")\n        self.make_file(\"partial.ini\", \"\"\"\\\n            [run]\n            branch = True\n\n            [report]\n            exclude_lines =\n                raise ZeroDivisionError\n            \"\"\")\n\n        cov = coverage.Coverage(config_file=\"partial.ini\")\n        partial = self.start_import_stop(cov, \"partial\")\n\n        if env.PYBEHAVIOR.pep626:\n            cov.html_report(partial, directory=\"out/partial_626\")\n            compare_html(gold_path(\"html/partial_626\"), \"out/partial_626\")\n            contains_rx(\n                \"out/partial_626/partial_py.html\",\n                r'<p class=\"par run show_par\">.* id=\"t4\"',\n                r'<p class=\"run\">.* id=\"t7\"',\n                # The \"if 0\" and \"if 1\" statements are marked as run.\n                r'<p class=\"run\">.* id=\"t10\"',\n                # The \"raise ZeroDivisionError\" is excluded by regex in the .ini.\n                r'<p class=\"exc show_exc\">.* id=\"t17\"',\n            )\n            contains(\n                \"out/partial_626/index.html\",\n                '<a href=\"partial_py.html\">partial.py</a>',\n                '<span class=\"pc_cov\">87%</span>',\n            )\n        else:\n            cov.html_report(partial, directory=\"out/partial\")\n            compare_html(gold_path(\"html/partial\"), \"out/partial\")\n            contains_rx(\n                \"out/partial/partial_py.html\",\n                r'<p class=\"par run show_par\">.* id=\"t4\"',\n                r'<p class=\"run\">.* id=\"t7\"',\n                # The \"if 0\" and \"if 1\" statements are optimized away.\n                r'<p class=\"pln\">.* id=\"t10\"',\n                # The \"raise ZeroDivisionError\" is excluded by regex in the .ini.\n                r'<p class=\"exc show_exc\">.* id=\"t17\"',\n            )\n            contains(\n                \"out/partial/index.html\",\n                '<a href=\"partial_py.html\">partial.py</a>',\n                '<span class=\"pc_cov\">91%</span>',\n            )\n\n    def test_styled(self) -> None:\n        self.make_file(\"a.py\", \"\"\"\\\n            if 1 < 2:\n                # Needed a < to look at HTML entities.\n                a = 3\n            else:\n                a = 4\n            \"\"\")\n\n        self.make_file(\"myfile/myextra.css\", \"/* Doesn't matter what's here, it gets copied. */\\n\")\n\n        cov = coverage.Coverage()\n        a = self.start_import_stop(cov, \"a\")\n        cov.html_report(a, directory=\"out/styled\", extra_css=\"myfile/myextra.css\")\n        self.assert_valid_hrefs(\"out/styled\")\n        compare_html(gold_path(\"html/styled\"), \"out/styled\")\n        unbust(\"out/styled\")\n        compare(gold_path(\"html/styled\"), \"out/styled\", file_pattern=\"*.css\")\n        contains_rx(\n            \"out/styled/a_py.html\",\n            r'<link rel=\"stylesheet\" href=\"myextra_cb_\\w{8}.css\" type=\"text/css\">',\n            (r'<span class=\"key\">if</span> <span class=\"num\">1</span> ' +\n             r'<span class=\"op\">&lt;</span> <span class=\"num\">2</span>'),\n            (r'    <span class=\"nam\">a</span> <span class=\"op\">=</span> ' +\n             r'<span class=\"num\">3</span>'),\n            r'<span class=\"pc_cov\">67%</span>',\n        )\n        contains_rx(\n            \"out/styled/index.html\",\n            r'<link rel=\"stylesheet\" href=\"myextra_cb_\\w{8}.css\" type=\"text/css\">',\n            r'<a href=\"a_py.html\">a.py</a>',\n            r'<span class=\"pc_cov\">67%</span>',\n        )\n\n    def test_tabbed(self) -> None:\n        # The file contents would look like this with 8-space tabs:\n        #   x = 1\n        #   if x:\n        #           a = \"tabbed\"                            # aligned comments\n        #           if x:                                   # look nice\n        #                   b = \"no spaces\"                 # when they\n        #           c = \"done\"                              # line up.\n        self.make_file(\"tabbed.py\", \"\"\"\\\n            x = 1\n            if x:\n            \\ta = \"Tabbed\"\\t\\t\\t\\t# Aligned comments\n            \\tif x:\\t\\t\\t\\t\\t# look nice\n            \\t\\tb = \"No spaces\"\\t\\t\\t# when they\n            \\tc = \"Done\"\\t\\t\\t\\t# line up.\n            \"\"\")\n\n        cov = coverage.Coverage()\n        tabbed = self.start_import_stop(cov, \"tabbed\")\n        cov.html_report(tabbed, directory=\"out\")\n\n        # Editors like to change things, make sure our source file still has tabs.\n        contains(\"tabbed.py\", \"\\tif x:\\t\\t\\t\\t\\t# look nice\")\n\n        contains(\n            \"out/tabbed_py.html\",\n            '>        <span class=\"key\">if</span> ' +\n            '<span class=\"nam\">x</span><span class=\"op\">:</span>' +\n            '                                   ' +\n            '<span class=\"com\"># look nice</span>',\n        )\n\n        doesnt_contain(\"out/tabbed_py.html\", \"\\t\")\n\n    def test_unicode(self) -> None:\n        surrogate = \"\\U000e0100\"\n\n        self.make_file(\"unicode.py\", \"\"\"\\\n            # -*- coding: utf-8 -*-\n            # A Python source file with exotic characters.\n\n            upside_down = \"\u028ed\u02d9\u01ddb\u0250\u0279\u01dd\u028co\u0254\"\n            surrogate = \"db40,dd00: x@\"\n            \"\"\".replace(\"@\", surrogate))\n\n        cov = coverage.Coverage()\n        unimod = self.start_import_stop(cov, \"unicode\")\n        cov.html_report(unimod, directory=\"out/unicode\")\n\n        compare_html(gold_path(\"html/unicode\"), \"out/unicode\")\n        contains(\n            \"out/unicode/unicode_py.html\",\n            '<span class=\"str\">\"&#654;d&#729;&#477;b&#592;&#633;&#477;&#652;o&#596;\"</span>',\n        )\n\n        contains_any(\n            \"out/unicode/unicode_py.html\",\n            '<span class=\"str\">\"db40,dd00: x&#56128;&#56576;\"</span>',\n            '<span class=\"str\">\"db40,dd00: x&#917760;\"</span>',\n        )\n\n    def test_accented_dot_py(self) -> None:\n        # Make a file with a non-ascii character in the filename.\n        self.make_file(\"h\\xe2t.py\", \"print('accented')\")\n        self.make_data_file(lines={abs_file(\"h\\xe2t.py\"): [1]})\n        cov = coverage.Coverage()\n        cov.load()\n        cov.html_report()\n        self.assert_exists(\"htmlcov/h\\xe2t_py.html\")\n        with open(\"htmlcov/index.html\") as indexf:\n            index = indexf.read()\n        assert '<a href=\"h&#226;t_py.html\">h&#226;t.py</a>' in index\n\n    def test_accented_directory(self) -> None:\n        # Make a file with a non-ascii character in the directory name.\n        self.make_file(\"\\xe2/accented.py\", \"print('accented')\")\n        self.make_data_file(lines={abs_file(\"\\xe2/accented.py\"): [1]})\n\n        # The HTML report uses ascii-encoded HTML entities.\n        cov = coverage.Coverage()\n        cov.load()\n        cov.html_report()\n        self.assert_exists(\"htmlcov/z_5786906b6f0ffeb4_accented_py.html\")\n        with open(\"htmlcov/index.html\") as indexf:\n            index = indexf.read()\n        expected = '<a href=\"z_5786906b6f0ffeb4_accented_py.html\">&#226;%saccented.py</a>'\n        assert expected % os.sep in index\n\n\n@pytest.mark.skipif(not testenv.DYN_CONTEXTS, reason=\"No dynamic contexts with this core.\")\nclass HtmlWithContextsTest(HtmlTestHelpers, CoverageTest):\n    \"\"\"Tests of the HTML reports with shown contexts.\"\"\"\n\n    EMPTY = coverage.html.HtmlDataGeneration.EMPTY\n\n    def html_data_from_cov(self, cov: Coverage, morf: TMorf) -> coverage.html.FileData:\n        \"\"\"Get HTML report data from a `Coverage` object for a morf.\"\"\"\n        with self.assert_warnings(cov, []):\n            datagen = coverage.html.HtmlDataGeneration(cov)\n            fr, analysis = next(get_analysis_to_report(cov, [morf]))\n            file_data = datagen.data_for_file(fr, analysis)\n            return file_data\n\n    SOURCE = \"\"\"\\\n        def helper(lineno):\n            x = 2\n\n        def test_one():\n            a = 5\n            helper(6)\n\n        def test_two():\n            a = 9\n            b = 10\n            if a > 11:\n                b = 12\n            assert a == (13-4)\n            assert b == (14-4)\n            helper(\n                16\n            )\n\n        test_one()\n        x = 20\n        helper(21)\n        test_two()\n        \"\"\"\n\n    OUTER_LINES = [1, 4, 8, 19, 20, 21, 2, 22]\n    TEST_ONE_LINES = [5, 6, 2]\n    TEST_TWO_LINES = [9, 10, 11, 13, 14, 15, 2]\n\n    def test_dynamic_contexts(self) -> None:\n        self.make_file(\"two_tests.py\", self.SOURCE)\n        cov = coverage.Coverage(source=[\".\"])\n        cov.set_option(\"run:dynamic_context\", \"test_function\")\n        cov.set_option(\"html:show_contexts\", True)\n        mod = self.start_import_stop(cov, \"two_tests\")\n        d = self.html_data_from_cov(cov, mod)\n        context_labels = [self.EMPTY, 'two_tests.test_one', 'two_tests.test_two']\n        expected_lines = [self.OUTER_LINES, self.TEST_ONE_LINES, self.TEST_TWO_LINES]\n        for label, expected in zip(context_labels, expected_lines):\n            actual = [\n                ld.number for ld in d.lines\n                if label == ld.contexts_label or label in (ld.contexts or ())\n            ]\n            assert sorted(expected) == sorted(actual)\n\n        cov.html_report(mod, directory=\"out/contexts\")\n        compare_html(gold_path(\"html/contexts\"), \"out/contexts\")\n\n    def test_filtered_dynamic_contexts(self) -> None:\n        self.make_file(\"two_tests.py\", self.SOURCE)\n        cov = coverage.Coverage(source=[\".\"])\n        cov.set_option(\"run:dynamic_context\", \"test_function\")\n        cov.set_option(\"html:show_contexts\", True)\n        cov.set_option(\"report:contexts\", [\"test_one\"])\n        mod = self.start_import_stop(cov, \"two_tests\")\n        d = self.html_data_from_cov(cov, mod)\n\n        context_labels = [self.EMPTY, 'two_tests.test_one', 'two_tests.test_two']\n        expected_lines: list[list[TLineNo]] = [[], self.TEST_ONE_LINES, []]\n        for label, expected in zip(context_labels, expected_lines):\n            actual = [ld.number for ld in d.lines if label in (ld.contexts or ())]\n            assert sorted(expected) == sorted(actual)\n\n    def test_no_contexts_warns_no_contexts(self) -> None:\n        # If no contexts were collected, then show_contexts emits a warning.\n        self.make_file(\"two_tests.py\", self.SOURCE)\n        cov = coverage.Coverage(source=[\".\"])\n        cov.set_option(\"html:show_contexts\", True)\n        self.start_import_stop(cov, \"two_tests\")\n        with self.assert_warnings(cov, [\"No contexts were measured\"]):\n            cov.html_report()\n\n    def test_dynamic_contexts_relative_files(self) -> None:\n        self.make_file(\"two_tests.py\", self.SOURCE)\n        self.make_file(\"config\", \"[run]\\nrelative_files = True\")\n        cov = coverage.Coverage(source=[\".\"], config_file=\"config\")\n        cov.set_option(\"run:dynamic_context\", \"test_function\")\n        cov.set_option(\"html:show_contexts\", True)\n        mod = self.start_import_stop(cov, \"two_tests\")\n        d = self.html_data_from_cov(cov, mod)\n        context_labels = [self.EMPTY, 'two_tests.test_one', 'two_tests.test_two']\n        expected_lines = [self.OUTER_LINES, self.TEST_ONE_LINES, self.TEST_TWO_LINES]\n        for label, expected in zip(context_labels, expected_lines):\n            actual = [\n                ld.number for ld in d.lines\n                if label == ld.contexts_label or label in (ld.contexts or ())\n            ]\n            assert sorted(expected) == sorted(actual)\n\n\nclass HtmlHelpersTest(HtmlTestHelpers, CoverageTest):\n    \"\"\"Tests of the helpers in HtmlTestHelpers.\"\"\"\n\n    def test_bad_link(self) -> None:\n        # Does assert_valid_hrefs detect links to non-existent files?\n        self.make_file(\"htmlcov/index.html\", \"<a href='nothing.html'>Nothing</a>\")\n        msg = \"These files link to 'nothing.html', which doesn't exist: htmlcov.index.html\"\n        with pytest.raises(AssertionError, match=msg):\n            self.assert_valid_hrefs()\n\n    def test_bad_anchor(self) -> None:\n        # Does assert_valid_hrefs detect fragments that go nowhere?\n        self.make_file(\"htmlcov/index.html\", \"<a href='#nothing'>Nothing</a>\")\n        msg = \"Fragment '#nothing' in htmlcov.index.html has no anchor\"\n        with pytest.raises(AssertionError, match=msg):\n            self.assert_valid_hrefs()\n\n\n@pytest.mark.parametrize(\"n, key\", [\n    (0, \"a\"),\n    (1, \"b\"),\n    (999999999, \"e9S_p\"),\n])\ndef test_encode_int(n: int, key: str) -> None:\n    assert coverage.html.encode_int(n) == key\n", "tests/__init__.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Automated tests. Run with pytest.\"\"\"\n", "tests/test_phystokens.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.py's improved tokenizer.\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\nimport re\nimport sys\nimport textwrap\nimport warnings\n\nimport pytest\n\nfrom coverage import env\nfrom coverage.phystokens import source_token_lines, source_encoding\nfrom coverage.python import get_python_source\n\nfrom tests.coveragetest import CoverageTest, TESTS_DIR\n\n\n# A simple program and its token stream.\nSIMPLE = \"\"\"\\\n# yay!\ndef foo():\n  say('two = %d' % 2)\n\"\"\"\n\nSIMPLE_TOKENS = [\n    [('com', \"# yay!\")],\n    [('key', 'def'), ('ws', ' '), ('nam', 'foo'), ('op', '('), ('op', ')'), ('op', ':')],\n    [('ws', '  '), ('nam', 'say'), ('op', '('),\n        ('str', \"'two = %d'\"), ('ws', ' '), ('op', '%'),\n        ('ws', ' '), ('num', '2'), ('op', ')')],\n]\n\n# Mixed-white-space program, and its token stream.\nMIXED_WS = \"\"\"\\\ndef hello():\n        a=\"Hello world!\"\n\\tb=\"indented\"\n\"\"\"\n\nMIXED_WS_TOKENS = [\n    [('key', 'def'), ('ws', ' '), ('nam', 'hello'), ('op', '('), ('op', ')'), ('op', ':')],\n    [('ws', '        '), ('nam', 'a'), ('op', '='), ('str', '\"Hello world!\"')],\n    [('ws', '        '), ('nam', 'b'), ('op', '='), ('str', '\"indented\"')],\n]\n\n# https://github.com/nedbat/coveragepy/issues/822\nBUG_822 = \"\"\"\\\nprint( \"Message 1\" )\narray = [ 1,2,3,4,       # 4 numbers \\\\\n          5,6,7 ]        # 3 numbers\nprint( \"Message 2\" )\n\"\"\"\n\nclass PhysTokensTest(CoverageTest):\n    \"\"\"Tests for coverage.py's improved tokenizer.\"\"\"\n\n    run_in_temp_dir = False\n\n    def check_tokenization(self, source: str) -> None:\n        \"\"\"Tokenize `source`, then put it back together, should be the same.\"\"\"\n        tokenized = \"\"\n        for line in source_token_lines(source):\n            text = \"\".join(t for _, t in line)\n            tokenized += text + \"\\n\"\n        # source_token_lines doesn't preserve trailing spaces, so trim all that\n        # before comparing.\n        source = source.replace('\\r\\n', '\\n')\n        source = re.sub(r\"(?m)[ \\t]+$\", \"\", source)\n        tokenized = re.sub(r\"(?m)[ \\t]+$\", \"\", tokenized)\n        assert source == tokenized\n\n    def check_file_tokenization(self, fname: str) -> None:\n        \"\"\"Use the contents of `fname` for `check_tokenization`.\"\"\"\n        self.check_tokenization(get_python_source(fname))\n\n    def test_simple(self) -> None:\n        assert list(source_token_lines(SIMPLE)) == SIMPLE_TOKENS\n        self.check_tokenization(SIMPLE)\n\n    def test_missing_final_newline(self) -> None:\n        # We can tokenize source that is missing the final newline.\n        assert list(source_token_lines(SIMPLE.rstrip())) == SIMPLE_TOKENS\n\n    def test_tab_indentation(self) -> None:\n        # Mixed tabs and spaces...\n        assert list(source_token_lines(MIXED_WS)) == MIXED_WS_TOKENS\n\n    def test_bug_822(self) -> None:\n        self.check_tokenization(BUG_822)\n\n    def test_tokenize_real_file(self) -> None:\n        # Check the tokenization of a real file (large, btw).\n        real_file = os.path.join(TESTS_DIR, \"test_coverage.py\")\n        self.check_file_tokenization(real_file)\n\n    @pytest.mark.parametrize(\"fname\", [\n        \"stress_phystoken.tok\",\n        \"stress_phystoken_dos.tok\",\n    ])\n    def test_stress(self, fname: str) -> None:\n        # Check the tokenization of the stress-test files.\n        # And check that those files haven't been incorrectly \"fixed\".\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\"ignore\", message=r\".*invalid escape sequence\")\n\n            stress = os.path.join(TESTS_DIR, fname)\n            self.check_file_tokenization(stress)\n            with open(stress) as fstress:\n                assert re.search(r\"(?m) $\", fstress.read()), f\"{stress} needs a trailing space.\"\n\n@pytest.mark.skipif(not env.PYBEHAVIOR.soft_keywords, reason=\"Soft keywords are new in Python 3.10\")\nclass SoftKeywordTest(CoverageTest):\n    \"\"\"Tests the tokenizer handling soft keywords.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_soft_keywords_match_case(self) -> None:\n        source = textwrap.dedent(\"\"\"\\\n            match re.match(something):\n                case [\"what\"]:\n                    match = case(\"hello\")\n                case [_]:\n                    match(\"hello\")\n                    match another.thing:\n                        case 1:\n                            pass\n\n            class case(): pass\n            def match():\n                global case\n            \"\"\")\n        tokens = list(source_token_lines(source))\n        print(tokens)\n        assert tokens[0][0] == (\"key\", \"match\")\n        assert tokens[0][4] == (\"nam\", \"match\")\n        assert tokens[1][1] == (\"key\", \"case\")\n        assert tokens[2][1] == (\"nam\", \"match\")\n        assert tokens[2][5] == (\"nam\", \"case\")\n        assert tokens[3][1] == (\"key\", \"case\")\n        assert tokens[4][1] == (\"nam\", \"match\")\n        assert tokens[5][1] == (\"key\", \"match\")\n        assert tokens[6][1] == (\"key\", \"case\")\n        assert tokens[9][2] == (\"nam\", \"case\")\n        assert tokens[10][2] == (\"nam\", \"match\")\n        assert tokens[11][3] == (\"nam\", \"case\")\n\n    @pytest.mark.skipif(sys.version_info < (3, 12), reason=\"type is a soft keyword in 3.12\")\n    def test_soft_keyword_type(self) -> None:\n        source = textwrap.dedent(\"\"\"\\\n            type Point = tuple[float, float]\n            type(int)\n            \"\"\")\n        tokens = list(source_token_lines(source))\n        assert tokens[0][0] == (\"key\", \"type\")\n        assert tokens[1][0] == (\"nam\", \"type\")\n\n\n# The default source file encoding.\nDEF_ENCODING = \"utf-8\"\n\n\nENCODING_DECLARATION_SOURCES = [\n    # Various forms from http://www.python.org/dev/peps/pep-0263/\n    (1, b\"# coding=cp850\\n\\n\", \"cp850\"),\n    (1, b\"# coding=latin-1\\n\", \"iso-8859-1\"),\n    (1, b\"# coding=iso-latin-1\\n\", \"iso-8859-1\"),\n    (1, b\"#!/usr/bin/python\\n# -*- coding: cp850 -*-\\n\", \"cp850\"),\n    (1, b\"#!/usr/bin/python\\n# vim: set fileencoding=cp850:\\n\", \"cp850\"),\n    (1, b\"# This Python file uses this encoding: cp850\\n\", \"cp850\"),\n    (1, b\"# This file uses a different encoding:\\n# coding: cp850\\n\", \"cp850\"),\n    (1, b\"\\n# coding=cp850\\n\\n\", \"cp850\"),\n    (2, b\"# -*-  coding:cp850 -*-\\n# vim: fileencoding=cp850\\n\", \"cp850\"),\n]\n\nclass SourceEncodingTest(CoverageTest):\n    \"\"\"Tests of source_encoding() for detecting encodings.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_detect_source_encoding(self) -> None:\n        for _, source, expected in ENCODING_DECLARATION_SOURCES:\n            assert source_encoding(source) == expected, f\"Wrong encoding in {source!r}\"\n\n    def test_detect_source_encoding_not_in_comment(self) -> None:\n        # Should not detect anything here\n        source = b'def parse(src, encoding=None):\\n    pass'\n        assert source_encoding(source) == DEF_ENCODING\n\n    def test_dont_detect_source_encoding_on_third_line(self) -> None:\n        # A coding declaration doesn't count on the third line.\n        source = b\"\\n\\n# coding=cp850\\n\\n\"\n        assert source_encoding(source) == DEF_ENCODING\n\n    def test_detect_source_encoding_of_empty_file(self) -> None:\n        # An important edge case.\n        assert source_encoding(b\"\") == DEF_ENCODING\n\n    def test_bom(self) -> None:\n        # A BOM means utf-8.\n        source = b\"\\xEF\\xBB\\xBFtext = 'hello'\\n\"\n        assert source_encoding(source) == 'utf-8-sig'\n\n    def test_bom_with_encoding(self) -> None:\n        source = b\"\\xEF\\xBB\\xBF# coding: utf-8\\ntext = 'hello'\\n\"\n        assert source_encoding(source) == 'utf-8-sig'\n\n    def test_bom_is_wrong(self) -> None:\n        # A BOM with an explicit non-utf8 encoding is an error.\n        source = b\"\\xEF\\xBB\\xBF# coding: cp850\\n\"\n        with pytest.raises(SyntaxError, match=\"encoding problem: utf-8\"):\n            source_encoding(source)\n\n    def test_unknown_encoding(self) -> None:\n        source = b\"# coding: klingon\\n\"\n        with pytest.raises(SyntaxError, match=\"unknown encoding: klingon\"):\n            source_encoding(source)\n", "tests/test_files.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for files.py\"\"\"\n\nfrom __future__ import annotations\n\nimport itertools\nimport os\nimport os.path\nimport re\n\nfrom typing import Any, Iterable, Iterator, Protocol\nfrom unittest import mock\n\nimport pytest\n\nfrom coverage import env, files\nfrom coverage.exceptions import ConfigError\nfrom coverage.files import (\n    GlobMatcher, ModuleMatcher, PathAliases, TreeMatcher, abs_file,\n    actual_path, find_python_files, flat_rootname, globs_to_regex,\n)\n\nfrom tests.coveragetest import CoverageTest\nfrom tests.helpers import os_sep\n\n\nclass FilesTest(CoverageTest):\n    \"\"\"Tests of coverage.files.\"\"\"\n\n    def abs_path(self, p: str) -> str:\n        \"\"\"Return the absolute path for `p`.\"\"\"\n        return os.path.join(abs_file(os.getcwd()), os.path.normpath(p))\n\n    def test_simple(self) -> None:\n        self.make_file(\"hello.py\")\n        files.set_relative_directory()\n        assert files.relative_filename(\"hello.py\") == \"hello.py\"\n        a = self.abs_path(\"hello.py\")\n        assert a != \"hello.py\"\n        assert files.relative_filename(a) == \"hello.py\"\n\n    def test_peer_directories(self) -> None:\n        self.make_file(\"sub/proj1/file1.py\")\n        self.make_file(\"sub/proj2/file2.py\")\n        a1 = self.abs_path(\"sub/proj1/file1.py\")\n        a2 = self.abs_path(\"sub/proj2/file2.py\")\n        d = os.path.normpath(\"sub/proj1\")\n        os.chdir(d)\n        files.set_relative_directory()\n        assert files.relative_filename(a1) == \"file1.py\"\n        assert files.relative_filename(a2) == a2\n\n    def test_filepath_contains_absolute_prefix_twice(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/194\n        # Build a path that has two pieces matching the absolute path prefix.\n        # Technically, this test doesn't do that on Windows, but drive\n        # letters make that impractical to achieve.\n        files.set_relative_directory()\n        d = abs_file(os.curdir)\n        trick = os.path.splitdrive(d)[1].lstrip(os.path.sep)\n        rel = os.path.join('sub', trick, 'file1.py')\n        assert files.relative_filename(abs_file(rel)) == rel\n\n    def test_canonical_filename_ensure_cache_hit(self) -> None:\n        self.make_file(\"sub/proj1/file1.py\")\n        d = actual_path(self.abs_path(\"sub/proj1\"))\n        os.chdir(d)\n        files.set_relative_directory()\n        canonical_path = files.canonical_filename('sub/proj1/file1.py')\n        assert canonical_path == self.abs_path('file1.py')\n        # After the filename has been converted, it should be in the cache.\n        assert 'sub/proj1/file1.py' in files.CANONICAL_FILENAME_CACHE\n        assert files.canonical_filename('sub/proj1/file1.py') == self.abs_path('file1.py')\n\n    @pytest.mark.parametrize(\n        \"curdir, sep\", [\n            (\"/\", \"/\"),\n            (\"X:\\\\\", \"\\\\\"),\n        ],\n    )\n    def test_relative_dir_for_root(self, curdir: str, sep: str) -> None:\n        with mock.patch.object(files.os, 'curdir', new=curdir):\n            with mock.patch.object(files.os, 'sep', new=sep):\n                with mock.patch('coverage.files.os.path.normcase', return_value=curdir):\n                    files.set_relative_directory()\n                    assert files.relative_directory() == curdir\n\n    @pytest.mark.parametrize(\n        \"to_make, to_check, answer\", [\n            (\"a/b/c/foo.py\", \"a/b/c/foo.py\", True),\n            (\"a/b/c/foo.py\", \"a/b/c/bar.py\", False),\n            (\"src/files.zip\", \"src/files.zip/foo.py\", True),\n            (\"src/files.whl\", \"src/files.whl/foo.py\", True),\n            (\"src/files.egg\", \"src/files.egg/foo.py\", True),\n            (\"src/files.pex\", \"src/files.pex/foo.py\", True),\n            (\"src/files.zip\", \"src/morefiles.zip/foo.py\", False),\n            (\"src/files.pex\", \"src/files.pex/zipfiles/files.zip/foo.py\", True),\n        ],\n    )\n    def test_source_exists(self, to_make: str, to_check: str, answer: bool) -> None:\n        # source_exists won't look inside the zipfile, so it's fine to make\n        # an empty file with the zipfile name.\n        self.make_file(to_make, \"\")\n        assert files.source_exists(to_check) == answer\n\n\n@pytest.mark.parametrize(\"original, flat\", [\n    (\"abc.py\", \"abc_py\"),\n    (\"hellothere\", \"hellothere\"),\n    (\"a/b/c.py\", \"z_86bbcbe134d28fd2_c_py\"),\n    (\"a/b/defghi.py\", \"z_86bbcbe134d28fd2_defghi_py\"),\n    (\"/a/b/c.py\", \"z_bb25e0ada04227c6_c_py\"),\n    (\"/a/b/defghi.py\", \"z_bb25e0ada04227c6_defghi_py\"),\n    (r\"c:\\foo\\bar.html\", \"z_e7c107482373f299_bar_html\"),\n    (r\"d:\\foo\\bar.html\", \"z_584a05dcebc67b46_bar_html\"),\n    (\"Montr\u00e9al/\u263a/conf.py\", \"z_c840497a2c647ce0_conf_py\"),\n    ( # original:\n        r\"c:\\lorem\\ipsum\\quia\\dolor\\sit\\amet\\consectetur\\adipisci\\velit\\sed\" +\n        r\"\\quia\\non\\numquam\\eius\\modi\\tempora\\incidunt\\ut\\labore\\et\\dolore\" +\n        r\"\\magnam\\aliquam\\quaerat\\voluptatem\\ut\\enim\\ad\\minima\\veniam\\quis\" +\n        r\"\\nostrum\\exercitationem\\ullam\\corporis\\suscipit\\laboriosam\" +\n        r\"\\Montr\u00e9al\\\u263a\\my_program.py\",\n        # flat:\n        \"z_e597dfacb73a23d5_my_program_py\",\n     ),\n])\ndef test_flat_rootname(original: str, flat: str) -> None:\n    assert flat_rootname(original) == flat\n\n\ndef globs_to_regex_params(\n    patterns: Iterable[str],\n    case_insensitive: bool = False,\n    partial: bool = False,\n    matches: Iterable[str] = (),\n    nomatches: Iterable[str] = (),\n) -> Iterator[Any]:\n    \"\"\"Generate parameters for `test_globs_to_regex`.\n\n    `patterns`, `case_insensitive`, and `partial` are arguments for\n    `globs_to_regex`.  `matches` is a list of strings that should match, and\n    `nomatches` is a list of strings that should not match.\n\n    Everything is yielded so that `test_globs_to_regex` can call\n    `globs_to_regex` once and check one result.\n\n    \"\"\"\n    pat_id = \"|\".join(patterns)\n    for text in matches:\n        yield pytest.param(\n            patterns, case_insensitive, partial, text, True,\n            id=f\"{pat_id}:ci{case_insensitive}:par{partial}:{text}:match\",\n        )\n    for text in nomatches:\n        yield pytest.param(\n            patterns, case_insensitive, partial, text, False,\n            id=f\"{pat_id}:ci{case_insensitive}:par{partial}:{text}:nomatch\",\n        )\n\n@pytest.mark.parametrize(\n    \"patterns, case_insensitive, partial, text, result\",\n    list(itertools.chain.from_iterable([\n        globs_to_regex_params(\n            [\"abc\", \"xyz\"],\n            matches=[\"abc\", \"xyz\", \"sub/mod/abc\"],\n            nomatches=[\n                \"ABC\", \"xYz\", \"abcx\", \"xabc\", \"axyz\", \"xyza\", \"sub/mod/abcd\", \"sub/abc/more\",\n            ],\n        ),\n        globs_to_regex_params(\n            [\"abc\", \"xyz\"], case_insensitive=True,\n            matches=[\"abc\", \"xyz\", \"Abc\", \"XYZ\", \"AbC\"],\n            nomatches=[\"abcx\", \"xabc\", \"axyz\", \"xyza\"],\n        ),\n        globs_to_regex_params(\n            [\"a*c\", \"x*z\"],\n            matches=[\"abc\", \"xyz\", \"xYz\", \"azc\", \"xaz\", \"axyzc\"],\n            nomatches=[\"ABC\", \"abcx\", \"xabc\", \"axyz\", \"xyza\", \"a/c\"],\n        ),\n        globs_to_regex_params(\n            [\"a?c\", \"x?z\"],\n            matches=[\"abc\", \"xyz\", \"xYz\", \"azc\", \"xaz\"],\n            nomatches=[\"ABC\", \"abcx\", \"xabc\", \"axyz\", \"xyza\", \"a/c\"],\n        ),\n        globs_to_regex_params(\n            [\"a??d\"],\n            matches=[\"abcd\", \"azcd\", \"a12d\"],\n            nomatches=[\"ABCD\", \"abcx\", \"axyz\", \"abcde\"],\n        ),\n        globs_to_regex_params(\n            [\"abc/hi.py\"], case_insensitive=True,\n            matches=[\"abc/hi.py\", \"ABC/hi.py\", r\"ABC\\hi.py\"],\n            nomatches=[\"abc_hi.py\", \"abc/hi.pyc\"],\n        ),\n        globs_to_regex_params(\n            [r\"abc\\hi.py\"], case_insensitive=True,\n            matches=[r\"abc\\hi.py\", r\"ABC\\hi.py\", \"abc/hi.py\", \"ABC/hi.py\"],\n            nomatches=[\"abc_hi.py\", \"abc/hi.pyc\"],\n        ),\n        globs_to_regex_params(\n            [\"abc/*/hi.py\"], case_insensitive=True,\n            matches=[\"abc/foo/hi.py\", r\"ABC\\foo/hi.py\"],\n            nomatches=[\"abc/hi.py\", \"abc/hi.pyc\", \"ABC/foo/bar/hi.py\", r\"ABC\\foo/bar/hi.py\"],\n        ),\n        globs_to_regex_params(\n            [\"abc/**/hi.py\"], case_insensitive=True,\n            matches=[\n                \"abc/foo/hi.py\", r\"ABC\\foo/hi.py\", \"abc/hi.py\", \"ABC/foo/bar/hi.py\",\n                r\"ABC\\foo/bar/hi.py\",\n            ],\n            nomatches=[\"abc/hi.pyc\"],\n        ),\n        globs_to_regex_params(\n            [\"abc/[a-f]*/hi.py\"], case_insensitive=True,\n            matches=[\"abc/foo/hi.py\", r\"ABC\\boo/hi.py\"],\n            nomatches=[\n                \"abc/zoo/hi.py\", \"abc/hi.py\", \"abc/hi.pyc\", \"abc/foo/bar/hi.py\",\n                r\"abc\\foo/bar/hi.py\",\n            ],\n        ),\n        globs_to_regex_params(\n            [\"abc/[a-f]/hi.py\"], case_insensitive=True,\n            matches=[\"abc/f/hi.py\", r\"ABC\\b/hi.py\"],\n            nomatches=[\n                \"abc/foo/hi.py\", \"abc/zoo/hi.py\", \"abc/hi.py\", \"abc/hi.pyc\", \"abc/foo/bar/hi.py\",\n                r\"abc\\foo/bar/hi.py\",\n            ],\n        ),\n        globs_to_regex_params(\n            [\"abc/\"], case_insensitive=True, partial=True,\n            matches=[\"abc/foo/hi.py\", \"ABC/foo/bar/hi.py\", r\"ABC\\foo/bar/hi.py\"],\n            nomatches=[\"abcd/foo.py\", \"xabc/hi.py\"],\n        ),\n        globs_to_regex_params(\n            [\"*/foo\"], case_insensitive=False, partial=True,\n            matches=[\"abc/foo/hi.py\", \"foo/hi.py\", \"abc/def/foo/hi.py\"],\n            nomatches=[\"abc/xfoo/hi.py\"],\n        ),\n        globs_to_regex_params(\n            [\"*c/foo\"], case_insensitive=False, partial=True,\n            matches=[\"abc/foo/hi.py\"],\n            nomatches=[\"abc/xfoo/hi.py\", \"foo/hi.py\", \"def/abc/foo/hi.py\"],\n        ),\n        globs_to_regex_params(\n            [\"foo/x*\"], case_insensitive=False, partial=True,\n            matches=[\"foo/x\", \"foo/xhi.py\", \"foo/x/hi.py\"],\n            nomatches=[],\n        ),\n        globs_to_regex_params(\n            [\"foo/x*\"], case_insensitive=False, partial=False,\n            matches=[\"foo/x\", \"foo/xhi.py\"],\n            nomatches=[\"foo/x/hi.py\"],\n        ),\n        globs_to_regex_params(\n            [\"**/foo\"],\n            matches=[\"foo\", \"hello/foo\", \"hi/there/foo\"],\n            nomatches=[\"foob\", \"hello/foob\", \"hello/Foo\"],\n        ),\n        globs_to_regex_params(\n            [\"a+b/foo*\", \"x{y}z/foo*\"],\n            matches=[\"a+b/foo\", \"a+b/foobar\", \"x{y}z/foobar\"],\n            nomatches=[\"aab/foo\", \"ab/foo\", \"xyz/foo\"],\n        ),\n    ])),\n)\ndef test_globs_to_regex(\n    patterns: Iterable[str],\n    case_insensitive: bool,\n    partial: bool,\n    text: str,\n    result: bool,\n) -> None:\n    regex = globs_to_regex(patterns, case_insensitive=case_insensitive, partial=partial)\n    assert bool(regex.match(text)) == result\n\n\n@pytest.mark.parametrize(\"pattern, bad_word\", [\n    (\"***/foo.py\", \"***\"),\n    (\"bar/***/foo.py\", \"***\"),\n    (\"*****/foo.py\", \"*****\"),\n    (\"Hello]there\", \"]\"),\n    (\"Hello[there\", \"[\"),\n    (\"x/a**/b.py\", \"a**\"),\n    (\"x/abcd**/b.py\", \"abcd**\"),\n    (\"x/**a/b.py\", \"**a\"),\n    (\"x/**/**/b.py\", \"**/**\"),\n])\ndef test_invalid_globs(pattern: str, bad_word: str) -> None:\n    msg = f\"File pattern can't include {bad_word!r}\"\n    with pytest.raises(ConfigError, match=re.escape(msg)):\n        globs_to_regex([pattern])\n\n\nclass TMatcher(Protocol):\n    \"\"\"The shape all Matchers have.\"\"\"\n\n    def match(self, s: str) -> bool:\n        \"\"\"Does this string match?\"\"\"\n\n\nclass MatcherTest(CoverageTest):\n    \"\"\"Tests of file matchers.\"\"\"\n\n    def setUp(self) -> None:\n        super().setUp()\n        files.set_relative_directory()\n\n    def assertMatches(self, matcher: TMatcher, filepath: str, matches: bool) -> None:\n        \"\"\"The `matcher` should agree with `matches` about `filepath`.\"\"\"\n        canonical = files.canonical_filename(filepath)\n        msg = f\"File {filepath} should have matched as {matches}\"\n        assert matches == matcher.match(canonical), msg\n\n    def test_tree_matcher(self) -> None:\n        case_folding = env.WINDOWS\n        matches_to_try = [\n            (self.make_file(\"sub/file1.py\"), True),\n            (self.make_file(\"sub/file2.c\"), True),\n            (self.make_file(\"sub2/file3.h\"), False),\n            (self.make_file(\"sub3/file4.py\"), True),\n            (self.make_file(\"sub3/file5.c\"), False),\n            (self.make_file(\"sub4/File5.py\"), case_folding),\n            (self.make_file(\"sub5/file6.py\"), case_folding),\n        ]\n        trees = [\n            files.canonical_filename(\"sub\"),\n            files.canonical_filename(\"sub3/file4.py\"),\n            files.canonical_filename(\"sub4/file5.py\"),\n            files.canonical_filename(\"SUB5/file6.py\"),\n        ]\n        tm = TreeMatcher(trees)\n        assert tm.info() == sorted(trees)\n        for filepath, matches in matches_to_try:\n            self.assertMatches(tm, filepath, matches)\n\n    def test_module_matcher(self) -> None:\n        matches_to_try = [\n            ('test', True),\n            ('trash', False),\n            ('testing', False),\n            ('test.x', True),\n            ('test.x.y.z', True),\n            ('py', False),\n            ('py.t', False),\n            ('py.test', True),\n            ('py.testing', False),\n            ('py.test.buz', True),\n            ('py.test.buz.baz', True),\n            ('__main__', False),\n            ('mymain', True),\n            ('yourmain', False),\n        ]\n        modules = ['test', 'py.test', 'mymain']\n        mm = ModuleMatcher(modules)\n        assert mm.info() == modules\n        for modulename, matches in matches_to_try:\n            assert mm.match(modulename) == matches, modulename\n\n    def test_glob_matcher(self) -> None:\n        matches_to_try = [\n            (self.make_file(\"sub/file1.py\"), True),\n            (self.make_file(\"sub/file2.c\"), False),\n            (self.make_file(\"sub2/file3.h\"), True),\n            (self.make_file(\"sub2/sub/file3.h\"), True),\n            (self.make_file(\"sub3/file4.py\"), True),\n            (self.make_file(\"sub3/file5.c\"), False),\n        ]\n        fnm = GlobMatcher([\"*.py\", \"*/sub2/*\"])\n        assert fnm.info() == [\"*.py\", \"*/sub2/*\"]\n        for filepath, matches in matches_to_try:\n            self.assertMatches(fnm, filepath, matches)\n\n    def test_glob_matcher_overload(self) -> None:\n        fnm = GlobMatcher([\"*x%03d*.txt\" % i for i in range(500)])\n        self.assertMatches(fnm, \"x007foo.txt\", True)\n        self.assertMatches(fnm, \"x123foo.txt\", True)\n        self.assertMatches(fnm, \"x798bar.txt\", False)\n        self.assertMatches(fnm, \"x499.txt\", True)\n        self.assertMatches(fnm, \"x500.txt\", False)\n\n    def test_glob_windows_paths(self) -> None:\n        # We should be able to match Windows paths even if we are running on\n        # a non-Windows OS.\n        fnm = GlobMatcher([\"*/foo.py\"])\n        self.assertMatches(fnm, r\"dir\\foo.py\", True)\n        fnm = GlobMatcher([r\"*\\foo.py\"])\n        self.assertMatches(fnm, r\"dir\\foo.py\", True)\n\n\n@pytest.fixture(params=[False, True], name=\"rel_yn\")\ndef relative_setting(request: pytest.FixtureRequest) -> bool:\n    \"\"\"Parameterized fixture to choose whether PathAliases is relative or not.\"\"\"\n    return request.param        # type: ignore[no-any-return]\n\n\nclass PathAliasesTest(CoverageTest):\n    \"\"\"Tests for coverage/files.py:PathAliases\"\"\"\n\n    run_in_temp_dir = False\n\n    def assert_mapped(self, aliases: PathAliases, inp: str, out: str) -> None:\n        \"\"\"Assert that `inp` mapped through `aliases` produces `out`.\n\n        If the aliases are not relative, then `out` is canonicalized first,\n        since aliases produce canonicalized paths by default.\n\n        \"\"\"\n        mapped = aliases.map(inp, exists=lambda p: True)\n        if aliases.relative:\n            expected = out\n        else:\n            expected = files.canonical_filename(out)\n        assert mapped == expected\n\n    def assert_unchanged(self, aliases: PathAliases, inp: str, exists: bool = True) -> None:\n        \"\"\"Assert that `inp` mapped through `aliases` is unchanged.\"\"\"\n        assert aliases.map(inp, exists=lambda p: exists) == inp\n\n    def test_noop(self, rel_yn: bool) -> None:\n        aliases = PathAliases(relative=rel_yn)\n        self.assert_unchanged(aliases, '/ned/home/a.py')\n\n    def test_nomatch(self, rel_yn: bool) -> None:\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('/home/*/src', './mysrc')\n        self.assert_unchanged(aliases, '/home/foo/a.py')\n\n    def test_wildcard(self, rel_yn: bool) -> None:\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('/ned/home/*/src', './mysrc')\n        self.assert_mapped(aliases, '/ned/home/foo/src/a.py', './mysrc/a.py')\n\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('/ned/home/*/src/', './mysrc')\n        self.assert_mapped(aliases, '/ned/home/foo/src/a.py', './mysrc/a.py')\n\n    def test_no_accidental_match(self, rel_yn: bool) -> None:\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('/home/*/src', './mysrc')\n        self.assert_unchanged(aliases, '/home/foo/srcetc')\n\n    def test_no_map_if_not_exist(self, rel_yn: bool) -> None:\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('/ned/home/*/src', './mysrc')\n        self.assert_unchanged(aliases, '/ned/home/foo/src/a.py', exists=False)\n        self.assert_unchanged(aliases, 'foo/src/a.py', exists=False)\n\n    def test_no_dotslash(self, rel_yn: bool) -> None:\n        # The result shouldn't start with \"./\" if the map result didn't.\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('*/project', '.')\n        self.assert_mapped(aliases, '/ned/home/project/src/a.py', os_sep('src/a.py'))\n\n    def test_relative_pattern(self) -> None:\n        aliases = PathAliases(relative=True)\n        aliases.add(\".tox/*/site-packages\", \"src\")\n        self.assert_mapped(\n            aliases,\n            \".tox/py314/site-packages/proj/a.py\",\n            os_sep(\"src/proj/a.py\"),\n        )\n\n    def test_multiple_patterns(self, rel_yn: bool) -> None:\n        # also test the debugfn...\n        msgs: list[str] = []\n        aliases = PathAliases(debugfn=msgs.append, relative=rel_yn)\n        aliases.add('/home/*/src', './mysrc')\n        aliases.add('/lib/*/libsrc', './mylib')\n        self.assert_mapped(aliases, '/home/foo/src/a.py', './mysrc/a.py')\n        self.assert_mapped(aliases, '/lib/foo/libsrc/a.py', './mylib/a.py')\n        if rel_yn:\n            assert msgs == [\n                \"Aliases (relative=True):\",\n                \" Rule: '/home/*/src' -> './mysrc/' using regex \" +\n                    \"'[/\\\\\\\\\\\\\\\\]home[/\\\\\\\\\\\\\\\\][^/\\\\\\\\\\\\\\\\]*[/\\\\\\\\\\\\\\\\]src[/\\\\\\\\\\\\\\\\]'\",\n                \" Rule: '/lib/*/libsrc' -> './mylib/' using regex \" +\n                    \"'[/\\\\\\\\\\\\\\\\]lib[/\\\\\\\\\\\\\\\\][^/\\\\\\\\\\\\\\\\]*[/\\\\\\\\\\\\\\\\]libsrc[/\\\\\\\\\\\\\\\\]'\",\n                \"Matched path '/home/foo/src/a.py' to rule '/home/*/src' -> './mysrc/', \" +\n                    \"producing './mysrc/a.py'\",\n                \"Matched path '/lib/foo/libsrc/a.py' to rule '/lib/*/libsrc' -> './mylib/', \" +\n                    \"producing './mylib/a.py'\",\n            ]\n        else:\n            assert msgs == [\n                \"Aliases (relative=False):\",\n                \" Rule: '/home/*/src' -> './mysrc/' using regex \" +\n                    \"'[/\\\\\\\\\\\\\\\\]home[/\\\\\\\\\\\\\\\\][^/\\\\\\\\\\\\\\\\]*[/\\\\\\\\\\\\\\\\]src[/\\\\\\\\\\\\\\\\]'\",\n                \" Rule: '/lib/*/libsrc' -> './mylib/' using regex \" +\n                    \"'[/\\\\\\\\\\\\\\\\]lib[/\\\\\\\\\\\\\\\\][^/\\\\\\\\\\\\\\\\]*[/\\\\\\\\\\\\\\\\]libsrc[/\\\\\\\\\\\\\\\\]'\",\n                \"Matched path '/home/foo/src/a.py' to rule '/home/*/src' -> './mysrc/', \" +\n                    f\"producing {files.canonical_filename('./mysrc/a.py')!r}\",\n                \"Matched path '/lib/foo/libsrc/a.py' to rule '/lib/*/libsrc' -> './mylib/', \" +\n                    f\"producing {files.canonical_filename('./mylib/a.py')!r}\",\n            ]\n\n    @pytest.mark.parametrize(\"badpat\", [\n        \"/ned/home/*\",\n        \"/ned/home/*/\",\n        \"/ned/home/*/*/\",\n    ])\n    def test_cant_have_wildcard_at_end(self, badpat: str) -> None:\n        aliases = PathAliases()\n        msg = \"Pattern must not end with wildcards.\"\n        with pytest.raises(ConfigError, match=msg):\n            aliases.add(badpat, \"fooey\")\n\n    def test_no_accidental_munging(self) -> None:\n        aliases = PathAliases()\n        aliases.add(r'c:\\Zoo\\boo', 'src/')\n        aliases.add('/home/ned$', 'src/')\n        self.assert_mapped(aliases, r'c:\\Zoo\\boo\\foo.py', 'src/foo.py')\n        self.assert_mapped(aliases, r'/home/ned$/foo.py', 'src/foo.py')\n\n    def test_paths_are_os_corrected(self, rel_yn: bool) -> None:\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('/home/ned/*/src', './mysrc')\n        aliases.add(r'c:\\ned\\src', './mysrc')\n        self.assert_mapped(aliases, r'C:\\Ned\\src\\sub\\a.py', './mysrc/sub/a.py')\n\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('/home/ned/*/src', r'.\\mysrc')\n        aliases.add(r'c:\\ned\\src', r'.\\mysrc')\n        self.assert_mapped(\n            aliases,\n            r'/home/ned/foo/src/sub/a.py',\n            r'.\\mysrc\\sub\\a.py',\n        )\n\n    # Try the paths in both orders.\n    lin = \"*/project/module/\"\n    win = \"*\\\\project\\\\module\\\\\"\n    lin_win_paths = [[lin, win], [win, lin]]\n\n    @pytest.mark.parametrize(\"paths\", lin_win_paths)\n    def test_windows_on_linux(self, paths: Iterable[str], rel_yn: bool) -> None:\n        # https://github.com/nedbat/coveragepy/issues/618\n        aliases = PathAliases(relative=rel_yn)\n        for path in paths:\n            aliases.add(path, \"project/module\")\n        self.assert_mapped(\n            aliases,\n            \"C:\\\\a\\\\path\\\\somewhere\\\\coveragepy_test\\\\project\\\\module\\\\tests\\\\file.py\",\n            \"project/module/tests/file.py\",\n        )\n\n    @pytest.mark.parametrize(\"paths\", lin_win_paths)\n    def test_linux_on_windows(self, paths: Iterable[str], rel_yn: bool) -> None:\n        # https://github.com/nedbat/coveragepy/issues/618\n        aliases = PathAliases(relative=rel_yn)\n        for path in paths:\n            aliases.add(path, \"project\\\\module\")\n        self.assert_mapped(\n            aliases,\n            \"C:/a/path/somewhere/coveragepy_test/project/module/tests/file.py\",\n            \"project\\\\module\\\\tests\\\\file.py\",\n        )\n\n    @pytest.mark.parametrize(\"paths\", lin_win_paths)\n    def test_relative_windows_on_linux(self, paths: Iterable[str]) -> None:\n        # https://github.com/nedbat/coveragepy/issues/991\n        aliases = PathAliases(relative=True)\n        for path in paths:\n            aliases.add(path, \"project/module\")\n        self.assert_mapped(\n            aliases,\n            r\"project\\module\\tests\\file.py\",\n            r\"project/module/tests/file.py\",\n        )\n\n    @pytest.mark.parametrize(\"paths\", lin_win_paths)\n    def test_relative_linux_on_windows(self, paths: Iterable[str]) -> None:\n        # https://github.com/nedbat/coveragepy/issues/991\n        aliases = PathAliases(relative=True)\n        for path in paths:\n            aliases.add(path, r\"project\\module\")\n        self.assert_mapped(\n            aliases,\n            r\"project/module/tests/file.py\",\n            r\"project\\module\\tests\\file.py\",\n        )\n\n    @pytest.mark.skipif(env.WINDOWS, reason=\"This test assumes Unix file system\")\n    def test_implicit_relative_windows_on_linux(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/991\n        aliases = PathAliases(relative=True)\n        self.assert_mapped(\n            aliases,\n            r\"project\\module\\tests\\file.py\",\n            r\"project/module/tests/file.py\",\n        )\n\n    @pytest.mark.skipif(not env.WINDOWS, reason=\"This test assumes Windows file system\")\n    def test_implicit_relative_linux_on_windows(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/991\n        aliases = PathAliases(relative=True)\n        self.assert_mapped(\n            aliases,\n            r\"project/module/tests/file.py\",\n            r\"project\\module\\tests\\file.py\",\n        )\n\n    def test_multiple_wildcard(self, rel_yn: bool) -> None:\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('/home/jenkins/*/a/*/b/*/django', './django')\n        self.assert_mapped(\n            aliases,\n            '/home/jenkins/xx/a/yy/b/zz/django/foo/bar.py',\n            './django/foo/bar.py',\n        )\n\n    def test_windows_root_paths(self, rel_yn: bool) -> None:\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('X:\\\\', '/tmp/src')\n        self.assert_mapped(\n            aliases,\n            \"X:\\\\a\\\\file.py\",\n            \"/tmp/src/a/file.py\",\n        )\n        self.assert_mapped(\n            aliases,\n            \"X:\\\\file.py\",\n            \"/tmp/src/file.py\",\n        )\n\n    def test_leading_wildcard(self, rel_yn: bool) -> None:\n        aliases = PathAliases(relative=rel_yn)\n        aliases.add('*/d1', './mysrc1')\n        aliases.add('*/d2', './mysrc2')\n        self.assert_mapped(aliases, '/foo/bar/d1/x.py', './mysrc1/x.py')\n        self.assert_mapped(aliases, '/foo/bar/d2/y.py', './mysrc2/y.py')\n\n    @pytest.mark.parametrize(\"dirname\", [\".\", \"..\", \"../other\", \"/\"])\n    def test_dot(self, dirname: str) -> None:\n        if env.WINDOWS and dirname == \"/\":\n            # The root test case was added for the manylinux Docker images,\n            # and I'm not sure how it should work on Windows, so skip it.\n            pytest.skip(\"Don't know how to handle root on Windows\")\n        aliases = PathAliases()\n        aliases.add(dirname, '/the/source')\n        the_file = os.path.join(dirname, 'a.py')\n        the_file = os.path.expanduser(the_file)\n        the_file = os.path.abspath(os.path.realpath(the_file))\n\n        assert '~' not in the_file  # to be sure the test is pure.\n        self.assert_mapped(aliases, the_file, '/the/source/a.py')\n\n\nclass PathAliasesRealFilesTest(CoverageTest):\n    \"\"\"Tests for coverage/files.py:PathAliases using real files.\"\"\"\n\n    def test_aliasing_zip_files(self) -> None:\n        self.make_file(\"src/zipfiles/code.zip\", \"fake zip, doesn't matter\")\n        aliases = PathAliases()\n        aliases.add(\"*/d1\", \"./src\")\n        aliases.add(\"*/d2\", \"./src\")\n\n        expected = files.canonical_filename(\"src/zipfiles/code.zip/p1.py\")\n        assert aliases.map(\"tox/d1/zipfiles/code.zip/p1.py\") == expected\n\n\nclass FindPythonFilesTest(CoverageTest):\n    \"\"\"Tests of `find_python_files`.\"\"\"\n\n    def test_find_python_files(self) -> None:\n        self.make_file(\"sub/a.py\")\n        self.make_file(\"sub/b.py\")\n        self.make_file(\"sub/x.c\")                   # nope: not .py\n        self.make_file(\"sub/ssub/__init__.py\")\n        self.make_file(\"sub/ssub/s.py\")\n        self.make_file(\"sub/ssub/~s.py\")            # nope: editor effluvia\n        self.make_file(\"sub/lab/exp.py\")            # nope: no __init__.py\n        self.make_file(\"sub/windows.pyw\")\n        py_files = set(find_python_files(\"sub\", include_namespace_packages=False))\n        self.assert_same_files(py_files, [\n            \"sub/a.py\", \"sub/b.py\",\n            \"sub/ssub/__init__.py\", \"sub/ssub/s.py\",\n            \"sub/windows.pyw\",\n        ])\n\n    def test_find_python_files_include_namespace_packages(self) -> None:\n        self.make_file(\"sub/a.py\")\n        self.make_file(\"sub/b.py\")\n        self.make_file(\"sub/x.c\")                   # nope: not .py\n        self.make_file(\"sub/ssub/__init__.py\")\n        self.make_file(\"sub/ssub/s.py\")\n        self.make_file(\"sub/ssub/~s.py\")            # nope: editor effluvia\n        self.make_file(\"sub/lab/exp.py\")\n        self.make_file(\"sub/windows.pyw\")\n        py_files = set(find_python_files(\"sub\", include_namespace_packages=True))\n        self.assert_same_files(py_files, [\n            \"sub/a.py\", \"sub/b.py\",\n            \"sub/ssub/__init__.py\", \"sub/ssub/s.py\",\n            \"sub/lab/exp.py\",\n            \"sub/windows.pyw\",\n        ])\n\n\n@pytest.mark.skipif(not env.WINDOWS, reason=\"Only need to run Windows tests on Windows.\")\nclass WindowsFileTest(CoverageTest):\n    \"\"\"Windows-specific tests of file name handling.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_actual_path(self) -> None:\n        assert actual_path(r'c:\\Windows') == actual_path(r'C:\\wINDOWS')\n", "tests/test_numbits.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.numbits\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport sqlite3\n\nfrom typing import Iterable\n\nfrom hypothesis import example, given, settings\nfrom hypothesis.strategies import sets, integers\n\nfrom coverage import env\nfrom coverage.numbits import (\n    nums_to_numbits, numbits_to_nums, numbits_union, numbits_intersection,\n    numbits_any_intersection, num_in_numbits, register_sqlite_functions,\n)\n\nfrom tests.coveragetest import CoverageTest\n\n# Hypothesis-generated line number data\nline_numbers = integers(min_value=1, max_value=9999)\nline_number_sets = sets(line_numbers)\n\n# When coverage-testing ourselves, hypothesis complains about a test being\n# flaky because the first run exceeds the deadline (and fails), and the second\n# run succeeds.  Disable the deadline if we are coverage-testing.\ndefault_settings = settings(deadline=400)   # milliseconds\nif env.METACOV:\n    default_settings = settings(default_settings, deadline=None)\n\n\ndef good_numbits(numbits: bytes) -> None:\n    \"\"\"Assert that numbits is good.\"\"\"\n    # It shouldn't end with a zero byte, that should have been trimmed off.\n    assert (not numbits) or (numbits[-1] != 0)\n\n\nclass NumbitsOpTest(CoverageTest):\n    \"\"\"Tests of the numbits operations in numbits.py.\"\"\"\n\n    run_in_temp_dir = False\n\n    @given(line_number_sets)\n    @settings(default_settings)\n    def test_conversion(self, nums: Iterable[int]) -> None:\n        numbits = nums_to_numbits(nums)\n        good_numbits(numbits)\n        nums2 = numbits_to_nums(numbits)\n        assert nums == set(nums2)\n\n    @given(line_number_sets, line_number_sets)\n    @settings(default_settings)\n    def test_union(self, nums1: set[int], nums2: set[int]) -> None:\n        nb1 = nums_to_numbits(nums1)\n        good_numbits(nb1)\n        nb2 = nums_to_numbits(nums2)\n        good_numbits(nb2)\n        nbu = numbits_union(nb1, nb2)\n        good_numbits(nbu)\n        union = numbits_to_nums(nbu)\n        assert nums1 | nums2 == set(union)\n\n    @given(line_number_sets, line_number_sets)\n    @settings(default_settings)\n    def test_intersection(self, nums1: set[int], nums2: set[int]) -> None:\n        nb1 = nums_to_numbits(nums1)\n        good_numbits(nb1)\n        nb2 = nums_to_numbits(nums2)\n        good_numbits(nb2)\n        nbi = numbits_intersection(nb1, nb2)\n        good_numbits(nbi)\n        intersection = numbits_to_nums(nbi)\n        assert nums1 & nums2 == set(intersection)\n\n    @given(line_number_sets, line_number_sets)\n    @settings(default_settings)\n    def test_any_intersection(self, nums1: set[int], nums2: set[int]) -> None:\n        nb1 = nums_to_numbits(nums1)\n        good_numbits(nb1)\n        nb2 = nums_to_numbits(nums2)\n        good_numbits(nb2)\n        inter = numbits_any_intersection(nb1, nb2)\n        expect = bool(nums1 & nums2)\n        assert expect == bool(inter)\n\n    @given(line_numbers, line_number_sets)\n    @settings(default_settings)\n    @example(152, {144})\n    def test_num_in_numbits(self, num: int, nums: Iterable[int]) -> None:\n        numbits = nums_to_numbits(nums)\n        good_numbits(numbits)\n        is_in = num_in_numbits(num, numbits)\n        assert (num in nums) == is_in\n\n\nclass NumbitsSqliteFunctionTest(CoverageTest):\n    \"\"\"Tests of the SQLite integration for numbits functions.\"\"\"\n\n    run_in_temp_dir = False\n\n    def setUp(self) -> None:\n        super().setUp()\n        conn = sqlite3.connect(\":memory:\")\n        register_sqlite_functions(conn)\n        self.cursor = conn.cursor()\n        self.cursor.execute(\"create table data (id int, numbits blob)\")\n        self.cursor.executemany(\n            \"insert into data (id, numbits) values (?, ?)\",\n            [\n                (i, nums_to_numbits(range(i, 100, i)))\n                for i in range(1, 11)\n            ],\n        )\n        self.addCleanup(self.cursor.close)\n\n    def test_numbits_union(self) -> None:\n        res = self.cursor.execute(\n            \"select numbits_union(\" +\n                \"(select numbits from data where id = 7),\" +\n                \"(select numbits from data where id = 9)\" +\n                \")\",\n        )\n        expected = [\n            7, 9, 14, 18, 21, 27, 28, 35, 36, 42, 45, 49,\n            54, 56, 63, 70, 72, 77, 81, 84, 90, 91, 98, 99,\n        ]\n        answer = numbits_to_nums(list(res)[0][0])\n        assert expected == answer\n\n    def test_numbits_intersection(self) -> None:\n        res = self.cursor.execute(\n            \"select numbits_intersection(\" +\n                \"(select numbits from data where id = 7),\" +\n                \"(select numbits from data where id = 9)\" +\n                \")\",\n        )\n        answer = numbits_to_nums(list(res)[0][0])\n        assert [63] == answer\n\n    def test_numbits_any_intersection(self) -> None:\n        res = self.cursor.execute(\n            \"select numbits_any_intersection(?, ?)\",\n            (nums_to_numbits([1, 2, 3]), nums_to_numbits([3, 4, 5])),\n        )\n        answer = [any_inter for (any_inter,) in res]\n        assert [1] == answer\n\n        res = self.cursor.execute(\n            \"select numbits_any_intersection(?, ?)\",\n            (nums_to_numbits([1, 2, 3]), nums_to_numbits([7, 8, 9])),\n        )\n        answer = [any_inter for (any_inter,) in res]\n        assert [0] == answer\n\n    def test_num_in_numbits(self) -> None:\n        res = self.cursor.execute(\"select id, num_in_numbits(12, numbits) from data order by id\")\n        answer = [is_in for (id, is_in) in res]\n        assert [1, 1, 1, 1, 0, 1, 0, 0, 0, 0] == answer\n\n    def test_numbits_to_nums(self) -> None:\n        res = self.cursor.execute(\"select numbits_to_nums(?)\", [nums_to_numbits([1, 2, 3])])\n        assert [1, 2, 3] == json.loads(res.fetchone()[0])\n", "tests/test_process.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for process behavior of coverage.py.\"\"\"\n\nfrom __future__ import annotations\n\nimport csv\nimport glob\nimport os\nimport os.path\nimport platform\nimport re\nimport stat\nimport sys\nimport textwrap\n\nfrom pathlib import Path\nfrom typing import Any\n\nimport pytest\n\nimport coverage\nfrom coverage import env\nfrom coverage.data import line_counts\nfrom coverage.files import abs_file, python_reported_file\n\nfrom tests import testenv\nfrom tests.coveragetest import CoverageTest, TESTS_DIR\nfrom tests.helpers import re_line, re_lines, re_lines_text\n\n\nclass ProcessTest(CoverageTest):\n    \"\"\"Tests of the per-process behavior of coverage.py.\"\"\"\n\n    def test_save_on_exit(self) -> None:\n        self.make_file(\"mycode.py\", \"\"\"\\\n            h = \"Hello\"\n            w = \"world\"\n            \"\"\")\n\n        self.assert_doesnt_exist(\".coverage\")\n        self.run_command(\"coverage run mycode.py\")\n        self.assert_exists(\".coverage\")\n\n    def test_tests_dir_is_importable(self) -> None:\n        # Checks that we can import modules from the tests directory at all!\n        self.make_file(\"mycode.py\", \"\"\"\\\n            import covmod1\n            import covmodzip1\n            a = 1\n            print('done')\n            \"\"\")\n\n        self.assert_doesnt_exist(\".coverage\")\n        self.add_test_modules_to_pythonpath()\n        out = self.run_command(\"coverage run mycode.py\")\n        self.assert_exists(\".coverage\")\n        assert out == 'done\\n'\n\n    def test_coverage_run_envvar_is_in_coveragerun(self) -> None:\n        # Test that we are setting COVERAGE_RUN when we run.\n        self.make_file(\"envornot.py\", \"\"\"\\\n            import os\n            print(os.getenv(\"COVERAGE_RUN\", \"nope\"))\n            \"\"\")\n        self.del_environ(\"COVERAGE_RUN\")\n        # Regular Python doesn't have the environment variable.\n        out = self.run_command(\"python envornot.py\")\n        assert out == \"nope\\n\"\n        self.del_environ(\"COVERAGE_RUN\")\n        # But `coverage run` does have it.\n        out = self.run_command(\"coverage run envornot.py\")\n        assert out == \"true\\n\"\n\n    def make_b_or_c_py(self) -> None:\n        \"\"\"Create b_or_c.py, used in a few of these tests.\"\"\"\n        # \"b_or_c.py b\" will run 6 lines.\n        # \"b_or_c.py c\" will run 7 lines.\n        # Together, they run 8 lines.\n        self.make_file(\"b_or_c.py\", \"\"\"\\\n            import sys\n            a = 2\n            if sys.argv[1] == 'b':\n                b = 4\n            else:\n                c = 6\n                c2 = 7\n            d = 8\n            print('done')\n            \"\"\")\n\n    def test_append_data(self) -> None:\n        self.make_b_or_c_py()\n\n        out = self.run_command(\"coverage run b_or_c.py b\")\n        assert out == 'done\\n'\n        self.assert_exists(\".coverage\")\n        self.assert_file_count(\".coverage.*\", 0)\n\n        out = self.run_command(\"coverage run --append b_or_c.py c\")\n        assert out == 'done\\n'\n        self.assert_exists(\".coverage\")\n        self.assert_file_count(\".coverage.*\", 0)\n\n        # Read the coverage file and see that b_or_c.py has all 8 lines\n        # executed.\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['b_or_c.py'] == 8\n\n    def test_append_data_with_different_file(self) -> None:\n        self.make_b_or_c_py()\n\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            data_file = .mycovdata\n            \"\"\")\n\n        out = self.run_command(\"coverage run b_or_c.py b\")\n        assert out == 'done\\n'\n        self.assert_doesnt_exist(\".coverage\")\n        self.assert_exists(\".mycovdata\")\n\n        out = self.run_command(\"coverage run --append b_or_c.py c\")\n        assert out == 'done\\n'\n        self.assert_doesnt_exist(\".coverage\")\n        self.assert_exists(\".mycovdata\")\n\n        # Read the coverage file and see that b_or_c.py has all 8 lines\n        # executed.\n        data = coverage.CoverageData(\".mycovdata\")\n        data.read()\n        assert line_counts(data)['b_or_c.py'] == 8\n\n    def test_append_can_create_a_data_file(self) -> None:\n        self.make_b_or_c_py()\n\n        out = self.run_command(\"coverage run --append b_or_c.py b\")\n        assert out == 'done\\n'\n        self.assert_exists(\".coverage\")\n        self.assert_file_count(\".coverage.*\", 0)\n\n        # Read the coverage file and see that b_or_c.py has only 6 lines\n        # executed.\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['b_or_c.py'] == 6\n\n    def test_combine_with_rc(self) -> None:\n        self.make_b_or_c_py()\n\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            source = .\n            parallel = true\n            \"\"\")\n\n        out = self.run_command(\"coverage run b_or_c.py b\")\n        assert out == 'done\\n'\n        self.assert_doesnt_exist(\".coverage\")\n\n        out = self.run_command(\"coverage run b_or_c.py c\")\n        assert out == 'done\\n'\n        self.assert_doesnt_exist(\".coverage\")\n\n        # After two runs, there should be two .coverage.machine.123 files.\n        self.assert_file_count(\".coverage.*\", 2)\n\n        # Combine the parallel coverage data files into .coverage .\n        self.run_command(\"coverage combine\")\n        self.assert_exists(\".coverage\")\n        self.assert_exists(\".coveragerc\")\n\n        # After combining, there should be only the .coverage file.\n        self.assert_file_count(\".coverage.*\", 0)\n\n        # Read the coverage file and see that b_or_c.py has all 8 lines\n        # executed.\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['b_or_c.py'] == 8\n\n        # Reporting should still work even with the .rc file\n        out = self.run_command(\"coverage report\")\n        assert out == textwrap.dedent(\"\"\"\\\n            Name        Stmts   Miss  Cover\n            -------------------------------\n            b_or_c.py       8      0   100%\n            -------------------------------\n            TOTAL           8      0   100%\n            \"\"\")\n\n    def test_combine_with_aliases(self) -> None:\n        self.make_file(\"d1/x.py\", \"\"\"\\\n            a = 1\n            b = 2\n            print(f\"{a} {b}\")\n            \"\"\")\n\n        self.make_file(\"d2/x.py\", \"\"\"\\\n            # 1\n            # 2\n            # 3\n            c = 4\n            d = 5\n            print(f\"{c} {d}\")\n            \"\"\")\n\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            source = .\n            parallel = True\n\n            [paths]\n            source =\n                src\n                */d1\n                */d2\n            \"\"\")\n\n        out = self.run_command(\"coverage run \" + os.path.normpath(\"d1/x.py\"))\n        assert out == '1 2\\n'\n        out = self.run_command(\"coverage run \" + os.path.normpath(\"d2/x.py\"))\n        assert out == '4 5\\n'\n\n        self.assert_file_count(\".coverage.*\", 2)\n\n        self.make_file(\"src/x.py\", \"\")\n\n        self.run_command(\"coverage combine\")\n        self.assert_exists(\".coverage\")\n\n        # After combining, there should be only the .coverage file.\n        self.assert_file_count(\".coverage.*\", 0)\n\n        # Read the coverage data file and see that the two different x.py\n        # files have been combined together.\n        data = coverage.CoverageData()\n        data.read()\n        summary = line_counts(data, fullpath=True)\n        assert len(summary) == 1\n        actual = abs_file(list(summary.keys())[0])\n        expected = abs_file('src/x.py')\n        assert expected == actual\n        assert list(summary.values())[0] == 6\n\n    def test_erase_parallel(self) -> None:\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            data_file = data.dat\n            parallel = True\n            \"\"\")\n        self.make_file(\"data.dat\")\n        self.make_file(\"data.dat.fooey\")\n        self.make_file(\"data.dat.gooey\")\n        self.make_file(\".coverage\")\n\n        self.run_command(\"coverage erase\")\n        self.assert_doesnt_exist(\"data.dat\")\n        self.assert_doesnt_exist(\"data.dat.fooey\")\n        self.assert_doesnt_exist(\"data.dat.gooey\")\n        self.assert_exists(\".coverage\")\n\n    def test_missing_source_file(self) -> None:\n        # Check what happens if the source is missing when reporting happens.\n        self.make_file(\"fleeting.py\", \"\"\"\\\n            s = 'goodbye, cruel world!'\n            \"\"\")\n\n        self.run_command(\"coverage run fleeting.py\")\n        os.remove(\"fleeting.py\")\n        out = self.run_command(\"coverage html -d htmlcov\")\n        assert re.search(\"No source for code: '.*fleeting.py'\", out)\n        assert \"Traceback\" not in out\n\n        # It happens that the code paths are different for *.py and other\n        # files, so try again with no extension.\n        self.make_file(\"fleeting\", \"\"\"\\\n            s = 'goodbye, cruel world!'\n            \"\"\")\n\n        self.run_command(\"coverage run fleeting\")\n        os.remove(\"fleeting\")\n        status, out = self.run_command_status(\"coverage html -d htmlcov\")\n        assert re.search(\"No source for code: '.*fleeting'\", out)\n        assert \"Traceback\" not in out\n        assert status == 1\n\n    def test_running_missing_file(self) -> None:\n        status, out = self.run_command_status(\"coverage run xyzzy.py\")\n        assert re.search(\"No file to run: .*xyzzy.py\", out)\n        assert \"raceback\" not in out\n        assert \"rror\" not in out\n        assert status == 1\n\n    def test_code_throws(self) -> None:\n        self.make_file(\"throw.py\", \"\"\"\\\n            class MyException(Exception):\n                pass\n\n            def f1():\n                raise MyException(\"hey!\")\n\n            def f2():\n                f1()\n\n            f2()\n            \"\"\")\n\n        # The important thing is for \"coverage run\" and \"python\" to report the\n        # same traceback.\n        status, out = self.run_command_status(\"coverage run throw.py\")\n        out2 = self.run_command(\"python throw.py\")\n        if env.PYPY:\n            # PyPy has an extra frame in the traceback for some reason\n            out2 = re_lines_text(\"toplevel\", out2, match=False)\n        assert out == out2\n\n        # But also make sure that the output is what we expect.\n        path = python_reported_file('throw.py')\n        msg = f'File \"{re.escape(path)}\", line 8, in f2'\n        assert re.search(msg, out)\n        assert 'raise MyException(\"hey!\")' in out\n        assert status == 1\n\n    def test_code_exits(self) -> None:\n        self.make_file(\"exit.py\", \"\"\"\\\n            import sys\n            def f1():\n                print(\"about to exit..\")\n                sys.exit(17)\n\n            def f2():\n                f1()\n\n            f2()\n            \"\"\")\n\n        # The important thing is for \"coverage run\" and \"python\" to have the\n        # same output.  No traceback.\n        status, out = self.run_command_status(\"coverage run exit.py\")\n        status2, out2 = self.run_command_status(\"python exit.py\")\n        assert out == out2\n        assert out == \"about to exit..\\n\"\n        assert status == status2\n        assert status == 17\n\n    def test_code_exits_no_arg(self) -> None:\n        self.make_file(\"exit_none.py\", \"\"\"\\\n            import sys\n            def f1():\n                print(\"about to exit quietly..\")\n                sys.exit()\n\n            f1()\n            \"\"\")\n        status, out = self.run_command_status(\"coverage run exit_none.py\")\n        status2, out2 = self.run_command_status(\"python exit_none.py\")\n        assert out == out2\n        assert out == \"about to exit quietly..\\n\"\n        assert status == status2\n        assert status == 0\n\n    @pytest.mark.skipif(not hasattr(os, \"fork\"), reason=\"Can't test os.fork, it doesn't exist.\")\n    def test_fork(self) -> None:\n        self.make_file(\"fork.py\", \"\"\"\\\n            import os\n\n            print(f\"parent,{os.getpid()}\", flush=True)\n            ret = os.fork()\n\n            if ret == 0:\n                print(f\"child,{os.getpid()}\", flush=True)\n            else:\n                os.waitpid(ret, 0)\n            \"\"\")\n        total_lines = 6\n\n        self.set_environ(\"COVERAGE_DEBUG_FILE\", \"debug.out\")\n        out = self.run_command(\"coverage run --debug=pid,process,trace -p fork.py\")\n        pids = {key:int(pid) for key, pid in csv.reader(out.splitlines())}\n        assert set(pids) == {\"parent\", \"child\"}\n        self.assert_doesnt_exist(\".coverage\")\n\n        # After running the forking program, there should be two\n        # .coverage.machine.pid.randomword files.  The pids should match our\n        # processes, and the files should have different random words at the\n        # end of the file name.\n        self.assert_file_count(\".coverage.*\", 2)\n        data_files = glob.glob(\".coverage.*\")\n        filepids = {int(name.split(\".\")[-2]) for name in data_files}\n        assert filepids == set(pids.values())\n        suffixes = {name.split(\".\")[-1] for name in data_files}\n        assert len(suffixes) == 2, f\"Same random suffix: {data_files}\"\n\n        # Each data file should have a subset of the lines.\n        for data_file in data_files:\n            data = coverage.CoverageData(data_file)\n            data.read()\n            assert line_counts(data)[\"fork.py\"] < total_lines\n\n        # Combine the parallel coverage data files into a .coverage file.\n        # After combining, there should be only the .coverage file.\n        self.run_command(\"coverage combine\")\n        self.assert_exists(\".coverage\")\n        self.assert_file_count(\".coverage.*\", 0)\n\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)[\"fork.py\"] == total_lines\n\n        debug_text = Path(\"debug.out\").read_text()\n        ppid = pids[\"parent\"]\n        cpid = pids[\"child\"]\n        assert ppid != cpid\n        plines = re_lines(fr\"{ppid}\\.[0-9a-f]+: New process: pid={ppid}, executable\", debug_text)\n        assert len(plines) == 1\n        clines = re_lines(fr\"{cpid}\\.[0-9a-f]+: New process: forked {ppid} -> {cpid}\", debug_text)\n        assert len(clines) == 1\n        reported_pids = {line.split(\".\")[0] for line in debug_text.splitlines()}\n        assert len(reported_pids) == 2\n\n    def test_warnings_during_reporting(self) -> None:\n        # While fixing issue #224, the warnings were being printed far too\n        # often.  Make sure they're not any more.\n        self.make_file(\"hello.py\", \"\"\"\\\n            import sys, os, the_other\n            print(\"Hello\")\n            \"\"\")\n        self.make_file(\"the_other.py\", \"\"\"\\\n            print(\"What?\")\n            \"\"\")\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            source =\n                .\n                xyzzy\n            \"\"\")\n\n        self.run_command(\"coverage run hello.py\")\n        out = self.run_command(\"coverage html\")\n        assert out.count(\"Module xyzzy was never imported.\") == 0\n\n    def test_warns_if_never_run(self) -> None:\n        # Note: the name of the function can't have \"warning\" in it, or the\n        # absolute path of the file will have \"warning\" in it, and an assertion\n        # will fail.\n        out = self.run_command(\"coverage run i_dont_exist.py\")\n        path = python_reported_file('i_dont_exist.py')\n        assert f\"No file to run: '{path}'\" in out\n        assert \"warning\" not in out\n        assert \"Exception\" not in out\n\n        out = self.run_command(\"coverage run -m no_such_module\")\n        assert (\n            (\"No module named no_such_module\" in out) or\n            (\"No module named 'no_such_module'\" in out)\n        )\n        assert \"warning\" not in out\n        assert \"Exception\" not in out\n\n    @pytest.mark.skipif(env.METACOV, reason=\"Can't test tracers changing during metacoverage\")\n    def test_warnings_trace_function_changed_with_threads(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/164\n\n        self.make_file(\"bug164.py\", \"\"\"\\\n            import threading\n            import time\n\n            class MyThread (threading.Thread):\n                def run(self):\n                    print(\"Hello\")\n\n            thr = MyThread()\n            thr.start()\n            thr.join()\n            \"\"\")\n        out = self.run_command(\"coverage run --timid bug164.py\")\n\n        assert \"Hello\\n\" in out\n        assert \"warning\" not in out\n\n    @pytest.mark.skipif(env.METACOV, reason=\"Can't test tracers changing during metacoverage\")\n    def test_warning_trace_function_changed(self) -> None:\n        self.make_file(\"settrace.py\", \"\"\"\\\n            import sys\n            print(\"Hello\")\n            sys.settrace(None)\n            print(\"Goodbye\")\n            \"\"\")\n        out = self.run_command(\"coverage run --timid settrace.py\")\n        assert \"Hello\\n\" in out\n        assert \"Goodbye\\n\" in out\n\n        assert \"Trace function changed\" in out\n\n    # When meta-coverage testing, this test doesn't work, because it finds\n    # coverage.py's own trace function.\n    @pytest.mark.skipif(env.METACOV, reason=\"Can't test timid during coverage measurement.\")\n    def test_timid(self) -> None:\n        # Test that the --timid command line argument properly swaps the tracer\n        # function for a simpler one.\n        #\n        # This is complicated by the fact that the tests are run twice for each\n        # version: once with a compiled C-based trace function, and once without\n        # it, to also test the Python trace function.  So this test has to examine\n        # an environment variable set in igor.py to know whether to expect to see\n        # the C trace function or not.\n\n        self.make_file(\"showtrace.py\", \"\"\"\\\n            # Show the current frame's trace function, so that we can test what the\n            # command-line options do to the trace function used.\n\n            import inspect\n\n            # Show what the trace function is.  If a C-based function is used, then f_trace\n            # may be None.\n            trace_fn = inspect.currentframe().f_trace\n            if trace_fn is None:\n                trace_name = \"None\"\n            else:\n                # Get the name of the tracer class.\n                try:\n                    trace_name = trace_fn.__self__.__class__.__name__\n                except AttributeError:\n                    # A C-based function could also manifest as an f_trace value\n                    # which doesn't have __self__.\n                    trace_name = trace_fn.__class__.__name__\n\n            print(trace_name)\n            \"\"\")\n\n        # When running without coverage, no trace function\n        py_out = self.run_command(\"python showtrace.py\")\n        assert py_out == \"None\\n\"\n\n        cov_out = self.run_command(\"coverage run showtrace.py\")\n        if testenv.C_TRACER:\n            # If the C trace function is being tested, then regular running should have\n            # the C function, which registers itself as f_trace.\n            assert cov_out == \"CTracer\\n\"\n        elif testenv.SYS_MON:\n            assert cov_out == \"None\\n\"\n        else:\n            # If the Python trace function is being tested, then regular running will\n            # also show the Python function.\n            assert cov_out == \"PyTracer\\n\"\n\n        # When running timidly, the trace function is always Python.\n        timid_out = self.run_command(\"coverage run --timid showtrace.py\")\n        assert timid_out == \"PyTracer\\n\"\n\n    def test_warn_preimported(self) -> None:\n        self.make_file(\"hello.py\", \"\"\"\\\n            import goodbye\n            import coverage\n            cov = coverage.Coverage(include=[\"good*\"], check_preimported=True)\n            cov.start()\n            print(goodbye.f())\n            cov.stop()\n            \"\"\")\n        self.make_file(\"goodbye.py\", \"\"\"\\\n            def f():\n                return \"Goodbye!\"\n            \"\"\")\n        goodbye_path = os.path.abspath(\"goodbye.py\")\n\n        out = self.run_command(\"python hello.py\")\n        assert \"Goodbye!\" in out\n\n        msg = (\n            f\"CoverageWarning: Already imported a file that will be measured: {goodbye_path} \" +\n            \"(already-imported)\"\n        )\n        assert msg in out\n\n    # Pypy passes locally, but fails in CI? Perhaps the version of macOS is\n    # significant?  https://foss.heptapod.net/pypy/pypy/-/issues/3074\n    @pytest.mark.skipif(env.PYPY, reason=\"PyPy is unreliable with this test\")\n    def test_lang_c(self) -> None:\n        # LANG=C forces getfilesystemencoding on Linux to 'ascii', which causes\n        # failures with non-ascii file names. We don't want to make a real file\n        # with strange characters, though, because that gets the test runners\n        # tangled up.  This will isolate the concerns to the coverage.py code.\n        # https://github.com/nedbat/coveragepy/issues/533\n        self.make_file(\"weird_file.py\", r\"\"\"\n            globs = {}\n            code = \"a = 1\\nb = 2\\n\"\n            exec(compile(code, \"wut\\xe9\\xea\\xeb\\xec\\x01\\x02.py\", 'exec'), globs)\n            print(globs['a'])\n            print(globs['b'])\n            \"\"\")\n        self.set_environ(\"LANG\", \"C\")\n        out = self.run_command(\"coverage run weird_file.py\")\n        assert out == \"1\\n2\\n\"\n\n    def test_deprecation_warnings(self) -> None:\n        # Test that coverage doesn't trigger deprecation warnings.\n        # https://github.com/nedbat/coveragepy/issues/305\n        self.make_file(\"allok.py\", \"\"\"\\\n            import warnings\n            warnings.simplefilter('default')\n            import coverage\n            print(\"No warnings!\")\n            \"\"\")\n\n        # Some of our testing infrastructure can issue warnings.\n        # Turn it all off for the sub-process.\n        self.del_environ(\"COVERAGE_TESTING\")\n\n        out = self.run_command(\"python allok.py\")\n        assert out == \"No warnings!\\n\"\n\n    def test_run_twice(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/353\n        self.make_file(\"foo.py\", \"\"\"\\\n            def foo():\n                pass\n            \"\"\")\n        self.make_file(\"run_twice.py\", \"\"\"\\\n            import sys\n            import coverage\n\n            for i in [1, 2]:\n                sys.stderr.write(f\"Run {i}\\\\n\")\n                inst = coverage.Coverage(source=['foo'])\n                inst.load()\n                inst.start()\n                import foo\n                inst.stop()\n                inst.save()\n            \"\"\")\n        out = self.run_command(\"python run_twice.py\")\n        # Remove the file location and source line from the warning.\n        out = re.sub(r\"(?m)^[\\\\/\\w.:~_-]+:\\d+: CoverageWarning: \", \"f:d: CoverageWarning: \", out)\n        out = re.sub(r\"(?m)^\\s+self.warn.*$\\n\", \"\", out)\n        expected = (\n            \"Run 1\\n\" +\n            \"Run 2\\n\" +\n            \"f:d: CoverageWarning: Module foo was previously imported, but not measured \" +\n            \"(module-not-measured)\\n\"\n        )\n        assert expected == out\n\n    def test_module_name(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/478\n        # Make sure help doesn't show a silly command name when run as a\n        # module, like it used to:\n        #   $ python -m coverage\n        #   Code coverage for Python.  Use '__main__.py help' for help.\n        out = self.run_command(\"python -m coverage\")\n        assert \"Use 'coverage help' for help\" in out\n\n\nTRY_EXECFILE = os.path.join(os.path.dirname(__file__), \"modules/process_test/try_execfile.py\")\n\nclass EnvironmentTest(CoverageTest):\n    \"\"\"Tests using try_execfile.py to test the execution environment.\"\"\"\n\n    def assert_tryexecfile_output(self, expected: str, actual: str) -> None:\n        \"\"\"Assert that the output we got is a successful run of try_execfile.py.\n\n        `expected` and `actual` must be the same.\n\n        \"\"\"\n        # First, is this even credible try_execfile.py output?\n        assert '\"DATA\": \"xyzzy\"' in actual\n        assert actual == expected\n\n    def test_coverage_run_is_like_python(self) -> None:\n        with open(TRY_EXECFILE) as f:\n            self.make_file(\"run_me.py\", f.read())\n        expected = self.run_command(\"python run_me.py\")\n        actual = self.run_command(\"coverage run run_me.py\")\n        self.assert_tryexecfile_output(expected, actual)\n\n    def test_coverage_run_far_away_is_like_python(self) -> None:\n        with open(TRY_EXECFILE) as f:\n            self.make_file(\"sub/overthere/prog.py\", f.read())\n        expected = self.run_command(\"python sub/overthere/prog.py\")\n        actual = self.run_command(\"coverage run sub/overthere/prog.py\")\n        self.assert_tryexecfile_output(expected, actual)\n\n    @pytest.mark.skipif(not env.WINDOWS, reason=\"This is about Windows paths\")\n    def test_coverage_run_far_away_is_like_python_windows(self) -> None:\n        with open(TRY_EXECFILE) as f:\n            self.make_file(\"sub/overthere/prog.py\", f.read())\n        expected = self.run_command(\"python sub\\\\overthere\\\\prog.py\")\n        actual = self.run_command(\"coverage run sub\\\\overthere\\\\prog.py\")\n        self.assert_tryexecfile_output(expected, actual)\n\n    def test_coverage_run_dashm_is_like_python_dashm(self) -> None:\n        self.add_test_modules_to_pythonpath()\n        expected = self.run_command(\"python -m process_test.try_execfile\")\n        actual = self.run_command(\"coverage run -m process_test.try_execfile\")\n        self.assert_tryexecfile_output(expected, actual)\n\n    def test_coverage_run_dir_is_like_python_dir(self) -> None:\n        with open(TRY_EXECFILE) as f:\n            self.make_file(\"with_main/__main__.py\", f.read())\n\n        expected = self.run_command(\"python with_main\")\n        actual = self.run_command(\"coverage run with_main\")\n        self.assert_tryexecfile_output(expected, actual)\n\n    def test_coverage_run_dashm_dir_no_init_is_like_python(self) -> None:\n        with open(TRY_EXECFILE) as f:\n            self.make_file(\"with_main/__main__.py\", f.read())\n\n        expected = self.run_command(\"python -m with_main\")\n        actual = self.run_command(\"coverage run -m with_main\")\n        self.assert_tryexecfile_output(expected, actual)\n\n    def test_coverage_run_dashm_dir_with_init_is_like_python(self) -> None:\n        with open(TRY_EXECFILE) as f:\n            self.make_file(\"with_main/__main__.py\", f.read())\n        self.make_file(\"with_main/__init__.py\", \"\")\n\n        expected = self.run_command(\"python -m with_main\")\n        actual = self.run_command(\"coverage run -m with_main\")\n        self.assert_tryexecfile_output(expected, actual)\n\n    def test_coverage_run_dashm_equal_to_doubledashsource(self) -> None:\n        \"\"\"regression test for #328\n\n        When imported by -m, a module's __name__ is __main__, but we need the\n        --source machinery to know and respect the original name.\n        \"\"\"\n        self.add_test_modules_to_pythonpath()\n        expected = self.run_command(\"python -m process_test.try_execfile\")\n        actual = self.run_command(\n            \"coverage run --source process_test.try_execfile -m process_test.try_execfile\",\n        )\n        self.assert_tryexecfile_output(expected, actual)\n\n    def test_coverage_run_dashm_superset_of_doubledashsource(self) -> None:\n        \"\"\"Edge case: --source foo -m foo.bar\"\"\"\n        # Ugh: without this config file, we'll get a warning about\n        #   CoverageWarning: Module process_test was previously imported,\n        #   but not measured (module-not-measured)\n        #\n        # This is because process_test/__init__.py is imported while looking\n        # for process_test.try_execfile.  That import happens while setting\n        # sys.path before start() is called.\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            disable_warnings = module-not-measured\n            \"\"\")\n        self.add_test_modules_to_pythonpath()\n        expected = self.run_command(\"python -m process_test.try_execfile\")\n        actual = self.run_command(\n            \"coverage run --source process_test -m process_test.try_execfile\",\n        )\n        self.assert_tryexecfile_output(expected, actual)\n\n        st, out = self.run_command_status(\"coverage report\")\n        assert st == 0\n        assert self.line_count(out) == 6, out\n\n    def test_coverage_run_script_imports_doubledashsource(self) -> None:\n        # This file imports try_execfile, which compiles it to .pyc, so the\n        # first run will have __file__ == \"try_execfile.py\" and the second will\n        # have __file__ == \"try_execfile.pyc\", which throws off the comparison.\n        # Setting dont_write_bytecode True stops the compilation to .pyc and\n        # keeps the test working.\n        self.make_file(\"myscript\", \"\"\"\\\n            import sys; sys.dont_write_bytecode = True\n            import process_test.try_execfile\n            \"\"\")\n\n        self.add_test_modules_to_pythonpath()\n        expected = self.run_command(\"python myscript\")\n        actual = self.run_command(\"coverage run --source process_test myscript\")\n        self.assert_tryexecfile_output(expected, actual)\n\n        st, out = self.run_command_status(\"coverage report\")\n        assert st == 0\n        assert self.line_count(out) == 6, out\n\n    def test_coverage_run_dashm_is_like_python_dashm_off_path(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/242\n        self.make_file(\"sub/__init__.py\", \"\")\n        with open(TRY_EXECFILE) as f:\n            self.make_file(\"sub/run_me.py\", f.read())\n\n        expected = self.run_command(\"python -m sub.run_me\")\n        actual = self.run_command(\"coverage run -m sub.run_me\")\n        self.assert_tryexecfile_output(expected, actual)\n\n    def test_coverage_run_dashm_is_like_python_dashm_with__main__207(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/207\n        self.make_file(\"package/__init__.py\", \"print('init')\")\n        self.make_file(\"package/__main__.py\", \"print('main')\")\n        expected = self.run_command(\"python -m package\")\n        actual = self.run_command(\"coverage run -m package\")\n        assert expected == actual\n\n    def test_coverage_zip_is_like_python(self) -> None:\n        # Test running coverage from a zip file itself.  Some environments\n        # (windows?) zip up the coverage main to be used as the coverage\n        # command.\n        with open(TRY_EXECFILE) as f:\n            self.make_file(\"run_me.py\", f.read())\n        expected = self.run_command(\"python run_me.py\")\n        cov_main = os.path.join(TESTS_DIR, \"covmain.zip\")\n        actual = self.run_command(f\"python {cov_main} run run_me.py\")\n        self.assert_tryexecfile_output(expected, actual)\n\n    def test_coverage_custom_script(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/678\n        # If sys.path[0] isn't the Python default, then coverage.py won't\n        # fiddle with it.\n        self.make_file(\"a/b/c/thing.py\", \"\"\"\\\n            SOMETHING = \"hello-xyzzy\"\n            \"\"\")\n        abc = os.path.abspath(\"a/b/c\")\n        self.make_file(\"run_coverage.py\", f\"\"\"\\\n            import sys\n            sys.path[0:0] = [\n                r'{abc}',\n                '/Users/somebody/temp/something/eggs/something-4.5.1-py2.7-xxx-10.13-x86_64.egg',\n            ]\n\n            import coverage.cmdline\n\n            if __name__ == '__main__':\n                sys.exit(coverage.cmdline.main())\n            \"\"\")\n        self.make_file(\"how_is_it.py\", \"\"\"\\\n            import pprint, sys\n            pprint.pprint(sys.path)\n            import thing\n            print(thing.SOMETHING)\n            \"\"\")\n        # If this test fails, it will be with \"can't import thing\".\n        out = self.run_command(\"python run_coverage.py run how_is_it.py\")\n        assert \"hello-xyzzy\" in out\n\n        out = self.run_command(\"python -m run_coverage run how_is_it.py\")\n        assert \"hello-xyzzy\" in out\n\n    @pytest.mark.skipif(env.WINDOWS, reason=\"Windows can't make symlinks\")\n    @pytest.mark.skipif(\n        platform.python_version().endswith(\"+\"),\n        reason=\"setuptools barfs on dev versions: https://github.com/pypa/packaging/issues/678\",\n        # https://github.com/nedbat/coveragepy/issues/1556\n    )\n    def test_bug_862(self) -> None:\n        # This used to simulate how pyenv and pyenv-virtualenv create the\n        # coverage executable.  Now the code shows how venv does it.\n        self.make_file(\"elsewhere/bin/fake-coverage\", f\"\"\"\\\n            #!{sys.executable}\n            import re\n            import sys\n            from coverage.cmdline import main\n            if __name__ == '__main__':\n                sys.argv[0] = re.sub(r'(-script\\\\.pyw|\\\\.exe)?$', '', sys.argv[0])\n                sys.exit(main())\n            \"\"\")\n        os.chmod(\"elsewhere/bin/fake-coverage\", stat.S_IREAD | stat.S_IEXEC)\n        os.symlink(\"elsewhere\", \"somewhere\")\n        self.make_file(\"foo.py\", \"print('inside foo')\")\n        self.make_file(\"bar.py\", \"import foo\")\n        out = self.run_command(\"somewhere/bin/fake-coverage run bar.py\")\n        assert \"inside foo\\n\" == out\n\n    def test_bug_909(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/909\n        # The __init__ files were being imported before measurement started,\n        # so the line in __init__.py was being marked as missed, and there were\n        # warnings about measured files being imported before start.\n        self.make_file(\"proj/__init__.py\", \"print('Init')\")\n        self.make_file(\"proj/thecode.py\", \"print('The code')\")\n        self.make_file(\"proj/tests/__init__.py\", \"\")\n        self.make_file(\"proj/tests/test_it.py\", \"import proj.thecode\")\n\n        expected = \"Init\\nThe code\\n\"\n        actual = self.run_command(\"coverage run --source=proj -m proj.tests.test_it\")\n        assert expected == actual\n\n        report = self.run_command(\"coverage report -m\")\n\n        # Name                     Stmts   Miss  Cover   Missing\n        # ------------------------------------------------------\n        # proj/__init__.py             1      0   100%\n        # proj/tests/__init__.py       0      0   100%\n        # proj/tests/test_it.py        1      0   100%\n        # proj/thecode.py              1      0   100%\n        # ------------------------------------------------------\n        # TOTAL                        3      0   100%\n\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[2].replace(\"\\\\\", \"/\") == \"proj/__init__.py 1 0 100%\"\n\n\nclass ExcepthookTest(CoverageTest):\n    \"\"\"Tests of sys.excepthook support.\"\"\"\n\n    # TODO: do we need these as process tests if we have test_execfile.py:RunFileTest?\n\n    def test_excepthook(self) -> None:\n        self.make_file(\"excepthook.py\", \"\"\"\\\n            import sys\n\n            def excepthook(*args):\n                print('in excepthook')\n                if maybe == 2:\n                    print('definitely')\n\n            sys.excepthook = excepthook\n\n            maybe = 1\n            raise RuntimeError('Error Outside')\n            \"\"\")\n        cov_st, cov_out = self.run_command_status(\"coverage run excepthook.py\")\n        py_st, py_out = self.run_command_status(\"python excepthook.py\")\n        assert cov_st == py_st\n        assert cov_st == 1\n        assert \"in excepthook\" in py_out\n        assert cov_out == py_out\n\n        # Read the coverage file and see that excepthook.py has 7 lines\n        # executed.\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['excepthook.py'] == 7\n\n    @pytest.mark.skipif(not env.CPYTHON,\n        reason=\"non-CPython handles excepthook exits differently, punt for now.\",\n    )\n    def test_excepthook_exit(self) -> None:\n        self.make_file(\"excepthook_exit.py\", \"\"\"\\\n            import sys\n\n            def excepthook(*args):\n                print('in excepthook')\n                sys.exit(0)\n\n            sys.excepthook = excepthook\n\n            raise RuntimeError('Error Outside')\n            \"\"\")\n        cov_st, cov_out = self.run_command_status(\"coverage run excepthook_exit.py\")\n        py_st, py_out = self.run_command_status(\"python excepthook_exit.py\")\n        assert cov_st == py_st\n        assert cov_st == 0\n\n        assert py_out == \"in excepthook\\n\"\n        assert cov_out == py_out\n\n    @pytest.mark.skipif(env.PYPY, reason=\"PyPy handles excepthook throws differently.\")\n    def test_excepthook_throw(self) -> None:\n        self.make_file(\"excepthook_throw.py\", \"\"\"\\\n            import sys\n\n            def excepthook(*args):\n                # Write this message to stderr so that we don't have to deal\n                # with interleaved stdout/stderr comparisons in the assertions\n                # in the test.\n                sys.stderr.write('in excepthook\\\\n')\n                raise RuntimeError('Error Inside')\n\n            sys.excepthook = excepthook\n\n            raise RuntimeError('Error Outside')\n            \"\"\")\n        cov_st, cov_out = self.run_command_status(\"coverage run excepthook_throw.py\")\n        py_st, py_out = self.run_command_status(\"python excepthook_throw.py\")\n        assert cov_st == py_st\n        assert cov_st == 1\n        assert \"in excepthook\" in py_out\n        assert cov_out == py_out\n\n\nclass AliasedCommandTest(CoverageTest):\n    \"\"\"Tests of the version-specific command aliases.\"\"\"\n\n    run_in_temp_dir = False\n\n    def test_major_version_works(self) -> None:\n        # \"coverage3\" works on py3\n        cmd = \"coverage%d\" % sys.version_info[0]\n        out = self.run_command(cmd)\n        assert \"Code coverage for Python\" in out\n\n    def test_wrong_alias_doesnt_work(self) -> None:\n        # \"coverage2\" doesn't work on py3\n        assert sys.version_info[0] == 3    # Let us know when Python 4 is out...\n        badcmd = \"coverage2\"\n        out = self.run_command(badcmd)\n        assert \"Code coverage for Python\" not in out\n\n    def test_specific_alias_works(self) -> None:\n        # \"coverage-3.9\" works on py3.9\n        cmd = \"coverage-%d.%d\" % sys.version_info[:2]\n        out = self.run_command(cmd)\n        assert \"Code coverage for Python\" in out\n\n    @pytest.mark.parametrize(\"cmd\", [\n        \"coverage\",\n        \"coverage%d\" % sys.version_info[0],\n        \"coverage-%d.%d\" % sys.version_info[:2],\n    ])\n    def test_aliases_used_in_messages(self, cmd: str) -> None:\n        out = self.run_command(f\"{cmd} foobar\")\n        assert \"Unknown command: 'foobar'\" in out\n        assert f\"Use '{cmd} help' for help\" in out\n\n\nclass PydocTest(CoverageTest):\n    \"\"\"Test that pydoc can get our information.\"\"\"\n\n    run_in_temp_dir = False\n\n    def assert_pydoc_ok(self, name: str, thing: Any) -> None:\n        \"\"\"Check that pydoc of `name` finds the docstring from `thing`.\"\"\"\n        # Run pydoc.\n        out = self.run_command(\"python -m pydoc \" + name)\n        # It should say \"Help on..\", and not have a traceback\n        assert out.startswith(\"Help on \")\n        assert \"Traceback\" not in out\n\n        # All of the lines in the docstring should be there somewhere.\n        for line in thing.__doc__.splitlines():\n            assert line.strip() in out\n\n    def test_pydoc_coverage(self) -> None:\n        self.assert_pydoc_ok(\"coverage\", coverage)\n\n    def test_pydoc_coverage_coverage(self) -> None:\n        self.assert_pydoc_ok(\"coverage.Coverage\", coverage.Coverage)\n\n\nclass FailUnderTest(CoverageTest):\n    \"\"\"Tests of the --fail-under switch.\"\"\"\n\n    def setUp(self) -> None:\n        super().setUp()\n        self.make_file(\"forty_two_plus.py\", \"\"\"\\\n            # I have 42.857% (3/7) coverage!\n            a = 1\n            b = 2\n            if a > 3:\n                b = 4\n                c = 5\n                d = 6\n                e = 7\n            \"\"\")\n        self.make_data_file(lines={abs_file(\"forty_two_plus.py\"): [2, 3, 4]})\n\n    def test_report_43_is_ok(self) -> None:\n        st, out = self.run_command_status(\"coverage report --fail-under=43\")\n        assert st == 0\n        assert self.last_line_squeezed(out) == \"TOTAL 7 4 43%\"\n\n    def test_report_43_is_not_ok(self) -> None:\n        st, out = self.run_command_status(\"coverage report --fail-under=44\")\n        assert st == 2\n        expected = \"Coverage failure: total of 43 is less than fail-under=44\"\n        assert expected == self.last_line_squeezed(out)\n\n    def test_report_42p86_is_not_ok(self) -> None:\n        self.make_file(\".coveragerc\", \"[report]\\nprecision = 2\")\n        st, out = self.run_command_status(\"coverage report --fail-under=42.88\")\n        assert st == 2\n        expected = \"Coverage failure: total of 42.86 is less than fail-under=42.88\"\n        assert expected == self.last_line_squeezed(out)\n\n    def test_report_99p9_is_not_ok(self) -> None:\n        # A file with 99.9% coverage:\n        self.make_file(\"ninety_nine_plus.py\",\n            \"a = 1\\n\" +\n            \"b = 2\\n\" * 2000 +\n            \"if a > 3:\\n\" +\n            \"    c = 4\\n\",\n        )\n        self.make_data_file(lines={abs_file(\"ninety_nine_plus.py\"): range(1, 2002)})\n        st, out = self.run_command_status(\"coverage report --fail-under=100\")\n        assert st == 2\n        expected = \"Coverage failure: total of 99 is less than fail-under=100\"\n        assert expected == self.last_line_squeezed(out)\n\n\nclass CoverageCoreTest(CoverageTest):\n    \"\"\"Test that cores are chosen correctly.\"\"\"\n    # This doesn't test failure modes, only successful requests.\n    try:\n        from coverage.tracer import CTracer\n        has_ctracer = True\n    except ImportError:\n        has_ctracer = False\n\n    def test_core_default(self) -> None:\n        self.del_environ(\"COVERAGE_TEST_CORES\")\n        self.del_environ(\"COVERAGE_CORE\")\n        self.make_file(\"numbers.py\", \"print(123, 456)\")\n        out = self.run_command(\"coverage run --debug=sys numbers.py\")\n        assert out.endswith(\"123 456\\n\")\n        core = re_line(r\" core:\", out).strip()\n        if self.has_ctracer:\n            assert core == \"core: CTracer\"\n        else:\n            assert core == \"core: PyTracer\"\n\n    @pytest.mark.skipif(not has_ctracer, reason=\"No CTracer to request\")\n    def test_core_request_ctrace(self) -> None:\n        self.del_environ(\"COVERAGE_TEST_CORES\")\n        self.set_environ(\"COVERAGE_CORE\", \"ctrace\")\n        self.make_file(\"numbers.py\", \"print(123, 456)\")\n        out = self.run_command(\"coverage run --debug=sys numbers.py\")\n        assert out.endswith(\"123 456\\n\")\n        core = re_line(r\" core:\", out).strip()\n        assert core == \"core: CTracer\"\n\n    def test_core_request_pytrace(self) -> None:\n        self.del_environ(\"COVERAGE_TEST_CORES\")\n        self.set_environ(\"COVERAGE_CORE\", \"pytrace\")\n        self.make_file(\"numbers.py\", \"print(123, 456)\")\n        out = self.run_command(\"coverage run --debug=sys numbers.py\")\n        assert out.endswith(\"123 456\\n\")\n        core = re_line(r\" core:\", out).strip()\n        assert core == \"core: PyTracer\"\n\n    def test_core_request_sysmon(self) -> None:\n        self.del_environ(\"COVERAGE_TEST_CORES\")\n        self.set_environ(\"COVERAGE_CORE\", \"sysmon\")\n        self.make_file(\"numbers.py\", \"print(123, 456)\")\n        out = self.run_command(\"coverage run --debug=sys numbers.py\")\n        assert out.endswith(\"123 456\\n\")\n        core = re_line(r\" core:\", out).strip()\n        warns = re_lines(r\"CoverageWarning: sys.monitoring isn't available\", out)\n        if env.PYBEHAVIOR.pep669:\n            assert core == \"core: SysMonitor\"\n            assert not warns\n        else:\n            assert core in (\"core: CTracer\", \"core: PyTracer\")\n            assert warns\n\n\nclass FailUnderNoFilesTest(CoverageTest):\n    \"\"\"Test that nothing to report results in an error exit status.\"\"\"\n    def test_report(self) -> None:\n        self.make_file(\".coveragerc\", \"[report]\\nfail_under = 99\\n\")\n        st, out = self.run_command_status(\"coverage report\")\n        assert 'No data to report.' in out\n        assert st == 1\n\n\nclass FailUnderEmptyFilesTest(CoverageTest):\n    \"\"\"Test that empty files produce the proper fail_under exit status.\"\"\"\n    def test_report(self) -> None:\n        self.make_file(\".coveragerc\", \"[report]\\nfail_under = 99\\n\")\n        self.make_file(\"empty.py\", \"\")\n        st, _ = self.run_command_status(\"coverage run empty.py\")\n        assert st == 0\n        st, _ = self.run_command_status(\"coverage report\")\n        # An empty file is marked as 100% covered, so this is ok.\n        assert st == 0\n\n\n@pytest.mark.skipif(env.WINDOWS, reason=\"Windows can't delete the directory in use.\")\nclass YankedDirectoryTest(CoverageTest):\n    \"\"\"Tests of what happens when the current directory is deleted.\"\"\"\n\n    BUG_806 = \"\"\"\\\n        import os\n        import sys\n        import tempfile\n\n        tmpdir = tempfile.mkdtemp()\n        os.chdir(tmpdir)\n        os.rmdir(tmpdir)\n        print(sys.argv[1])\n        \"\"\"\n\n    def test_removing_directory(self) -> None:\n        self.make_file(\"bug806.py\", self.BUG_806)\n        out = self.run_command(\"coverage run bug806.py noerror\")\n        assert out == \"noerror\\n\"\n\n    def test_removing_directory_with_error(self) -> None:\n        self.make_file(\"bug806.py\", self.BUG_806)\n        out = self.run_command(\"coverage run bug806.py\")\n        path = python_reported_file('bug806.py')\n        # Python 3.11 adds an extra line to the traceback.\n        # Check that the lines we expect are there.\n        lines = textwrap.dedent(f\"\"\"\\\n            Traceback (most recent call last):\n              File \"{path}\", line 8, in <module>\n                print(sys.argv[1])\n            IndexError: list index out of range\n            \"\"\").splitlines(keepends=True)\n        assert all(line in out for line in lines)\n\n\n@pytest.mark.skipif(env.METACOV, reason=\"Can't test sub-process pth file during metacoverage\")\nclass ProcessStartupTest(CoverageTest):\n    \"\"\"Test that we can measure coverage in sub-processes.\"\"\"\n\n    def setUp(self) -> None:\n        super().setUp()\n\n        # Main will run sub.py\n        self.make_file(\"main.py\", \"\"\"\\\n            import os, os.path, sys\n            ex = os.path.basename(sys.executable)\n            os.system(ex + \" sub.py\")\n            \"\"\")\n        # sub.py will write a few lines.\n        self.make_file(\"sub.py\", \"\"\"\\\n            f = open(\"out.txt\", \"w\")\n            f.write(\"Hello, world!\\\\n\")\n            f.close()\n            \"\"\")\n\n    def test_subprocess_with_pth_files(self) -> None:\n        # An existing data file should not be read when a subprocess gets\n        # measured automatically.  Create the data file here with bogus data in\n        # it.\n        data = coverage.CoverageData(\".mycovdata\")\n        data.add_lines({os.path.abspath('sub.py'): range(100)})\n        data.write()\n\n        self.make_file(\"coverage.ini\", \"\"\"\\\n            [run]\n            data_file = .mycovdata\n            \"\"\")\n        self.set_environ(\"COVERAGE_PROCESS_START\", \"coverage.ini\")\n        import main             # pylint: disable=unused-import, import-error\n\n        with open(\"out.txt\") as f:\n            assert f.read() == \"Hello, world!\\n\"\n\n        # Read the data from .coverage\n        self.assert_exists(\".mycovdata\")\n        data = coverage.CoverageData(\".mycovdata\")\n        data.read()\n        assert line_counts(data)['sub.py'] == 3\n\n    def test_subprocess_with_pth_files_and_parallel(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/492\n        self.make_file(\"coverage.ini\", \"\"\"\\\n            [run]\n            parallel = true\n            \"\"\")\n\n        self.set_environ(\"COVERAGE_PROCESS_START\", \"coverage.ini\")\n        self.run_command(\"coverage run main.py\")\n\n        with open(\"out.txt\") as f:\n            assert f.read() == \"Hello, world!\\n\"\n\n        self.run_command(\"coverage combine\")\n\n        # assert that the combined .coverage data file is correct\n        self.assert_exists(\".coverage\")\n        data = coverage.CoverageData()\n        data.read()\n        assert line_counts(data)['sub.py'] == 3\n\n        # assert that there are *no* extra data files left over after a combine\n        data_files = glob.glob(os.getcwd() + '/.coverage*')\n        msg = (\n            \"Expected only .coverage after combine, looks like there are \" +\n            f\"extra data files that were not cleaned up: {data_files!r}\"\n        )\n        assert len(data_files) == 1, msg\n\n\nclass ProcessStartupWithSourceTest(CoverageTest):\n    \"\"\"Show that we can configure {[run]source} during process-level coverage.\n\n    There are three interesting variables, for a total of eight tests:\n\n        1. -m versus a simple script argument (for example, `python myscript`),\n\n        2. filtering for the top-level (main.py) or second-level (sub.py)\n           module, and\n\n        3. whether the files are in a package or not.\n\n    \"\"\"\n\n    @pytest.mark.parametrize(\"dashm\", [\"-m\", \"\"])\n    @pytest.mark.parametrize(\"package\", [\"pkg\", \"\"])\n    @pytest.mark.parametrize(\"source\", [\"main\", \"sub\"])\n    def test_pth_and_source_work_together(self, dashm: str, package: str, source: str) -> None:\n        \"\"\"Run the test for a particular combination of factors.\n\n        The arguments are all strings:\n\n        * `dashm`: Either \"\" (run the program as a file) or \"-m\" (run the\n          program as a module).\n\n        * `package`: Either \"\" (put the source at the top level) or a\n          package name to use to hold the source.\n\n        * `source`: Either \"main\" or \"sub\", which file to use as the\n          ``--source`` argument.\n\n        \"\"\"\n        def fullname(modname: str) -> str:\n            \"\"\"What is the full module name for `modname` for this test?\"\"\"\n            if package and dashm:\n                return '.'.join((package, modname))\n            else:\n                return modname\n\n        def path(basename: str) -> str:\n            \"\"\"Where should `basename` be created for this test?\"\"\"\n            return os.path.join(package, basename)\n\n        # Main will run sub.py.\n        self.make_file(path(\"main.py\"), \"\"\"\\\n            import %s\n            a = 2\n            b = 3\n            \"\"\" % fullname('sub'))\n        if package:\n            self.make_file(path(\"__init__.py\"), \"\")\n        # sub.py will write a few lines.\n        self.make_file(path(\"sub.py\"), \"\"\"\\\n            f = open(\"out.txt\", \"w\")\n            f.write(\"Hello, world!\")\n            f.close()\n            \"\"\")\n        self.make_file(\"coverage.ini\", \"\"\"\\\n            [run]\n            source = %s\n            \"\"\" % fullname(source))\n\n        self.set_environ(\"COVERAGE_PROCESS_START\", \"coverage.ini\")\n\n        if dashm:\n            cmd = \"python -m %s\" % fullname('main')\n        else:\n            cmd = \"python %s\" % path('main.py')\n\n        self.run_command(cmd)\n\n        with open(\"out.txt\") as f:\n            assert f.read() == \"Hello, world!\"\n\n        # Read the data from .coverage\n        self.assert_exists(\".coverage\")\n        data = coverage.CoverageData()\n        data.read()\n        summary = line_counts(data)\n        assert summary[source + '.py'] == 3\n        assert len(summary) == 1\n", "tests/test_report.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Test text-based summary reporting for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nimport glob\nimport io\nimport math\nimport os\nimport os.path\nimport py_compile\nimport re\n\n\nimport pytest\n\nimport coverage\nfrom coverage import env\nfrom coverage.control import Coverage\nfrom coverage.data import CoverageData\nfrom coverage.exceptions import ConfigError, NoDataError, NotPython\nfrom coverage.files import abs_file\nfrom coverage.report import SummaryReporter\nfrom coverage.types import TConfigValueIn\n\nfrom tests.coveragetest import CoverageTest, TESTS_DIR, UsingModulesMixin\nfrom tests.helpers import assert_coverage_warnings\n\n\nclass SummaryTest(UsingModulesMixin, CoverageTest):\n    \"\"\"Tests of the text summary reporting for coverage.py.\"\"\"\n\n    def make_mycode(self) -> None:\n        \"\"\"Make the mycode.py file when needed.\"\"\"\n        self.make_file(\"mycode.py\", \"\"\"\\\n            import covmod1\n            import covmodzip1\n            a = 1\n            print('done')\n            \"\"\")\n\n    def test_report(self) -> None:\n        self.make_mycode()\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"mycode\")\n        assert self.stdout() == 'done\\n'\n        report = self.get_report(cov)\n\n        # Name                                           Stmts   Miss  Cover\n        # ------------------------------------------------------------------\n        # c:/ned/coverage/tests/modules/covmod1.py           2      0   100%\n        # c:/ned/coverage/tests/zipmods.zip/covmodzip1.py    2      0   100%\n        # mycode.py                                          4      0   100%\n        # ------------------------------------------------------------------\n        # TOTAL                                              8      0   100%\n\n        assert \"/coverage/__init__/\" not in report\n        assert \"/tests/modules/covmod1.py \" in report\n        assert \"/tests/zipmods.zip/covmodzip1.py \" in report\n        assert \"mycode.py \" in report\n        assert self.last_line_squeezed(report) == \"TOTAL 8 0 100%\"\n\n    def test_report_just_one(self) -> None:\n        # Try reporting just one module\n        self.make_mycode()\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"mycode\")\n        report = self.get_report(cov, morfs=[\"mycode.py\"])\n\n        # Name        Stmts   Miss  Cover\n        # -------------------------------\n        # mycode.py       4      0   100%\n        # -------------------------------\n        # TOTAL           4      0   100%\n        assert self.line_count(report) == 5\n        assert \"/coverage/\" not in report\n        assert \"/tests/modules/covmod1.py \" not in report\n        assert \"/tests/zipmods.zip/covmodzip1.py \" not in report\n        assert \"mycode.py \" in report\n        assert self.last_line_squeezed(report) == \"TOTAL 4 0 100%\"\n\n    def test_report_wildcard(self) -> None:\n        # Try reporting using wildcards to get the modules.\n        self.make_mycode()\n        self.add_test_modules_to_pythonpath()\n        # Wildcard is handled by shell or cmdline.py, so use real commands\n        self.run_command(\"coverage run mycode.py\")\n        report = self.report_from_command(\"coverage report my*.py\")\n\n        # Name        Stmts   Miss  Cover\n        # -------------------------------\n        # mycode.py       4      0   100%\n        # -------------------------------\n        # TOTAL           4      0   100%\n\n        assert self.line_count(report) == 5\n        assert \"/coverage/\" not in report\n        assert \"/tests/modules/covmod1.py \" not in report\n        assert \"/tests/zipmods.zip/covmodzip1.py \" not in report\n        assert \"mycode.py \" in report\n        assert self.last_line_squeezed(report) == \"TOTAL 4 0 100%\"\n\n    def test_report_omitting(self) -> None:\n        # Try reporting while omitting some modules\n        self.make_mycode()\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"mycode\")\n        report = self.get_report(cov, omit=[f\"{TESTS_DIR}/*\", \"*/site-packages/*\"])\n\n        # Name        Stmts   Miss  Cover\n        # -------------------------------\n        # mycode.py       4      0   100%\n        # -------------------------------\n        # TOTAL           4      0   100%\n\n        assert self.line_count(report) == 5\n        assert \"/coverage/\" not in report\n        assert \"/tests/modules/covmod1.py \" not in report\n        assert \"/tests/zipmods.zip/covmodzip1.py \" not in report\n        assert \"mycode.py \" in report\n        assert self.last_line_squeezed(report) == \"TOTAL 4 0 100%\"\n\n    def test_report_including(self) -> None:\n        # Try reporting while including some modules\n        self.make_mycode()\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"mycode\")\n        report = self.get_report(cov, include=[\"mycode*\"])\n\n        # Name        Stmts   Miss  Cover\n        # -------------------------------\n        # mycode.py       4      0   100%\n        # -------------------------------\n        # TOTAL           4      0   100%\n\n        assert self.line_count(report) == 5\n        assert \"/coverage/\" not in report\n        assert \"/tests/modules/covmod1.py \" not in report\n        assert \"/tests/zipmods.zip/covmodzip1.py \" not in report\n        assert \"mycode.py \" in report\n        assert self.last_line_squeezed(report) == \"TOTAL 4 0 100%\"\n\n    def test_report_include_relative_files_and_path(self) -> None:\n        \"\"\"\n        Test that when relative_files is True and a relative path to a module\n        is included, coverage is reported for the module.\n\n        Ref: https://github.com/nedbat/coveragepy/issues/1604\n        \"\"\"\n        self.make_mycode()\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            relative_files = true\n            \"\"\")\n        self.make_file(\"submodule/mycode.py\", \"import mycode\")\n\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"submodule/mycode\")\n        report = self.get_report(cov, include=\"submodule/mycode.py\")\n\n        # Name                Stmts   Miss  Cover\n        # ---------------------------------------\n        # submodule/mycode.py 1       0     100%\n        # ---------------------------------------\n        # TOTAL               1       0     100%\n\n        assert \"submodule/mycode.py \" in report\n        assert self.last_line_squeezed(report) == \"TOTAL 1 0 100%\"\n\n    def test_report_include_relative_files_and_wildcard_path(self) -> None:\n        self.make_mycode()\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            relative_files = true\n            \"\"\")\n        self.make_file(\"submodule/mycode.py\", \"import nested.submodule.mycode\")\n        self.make_file(\"nested/submodule/mycode.py\", \"import mycode\")\n\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"submodule/mycode\")\n        report = self.get_report(cov, include=\"*/submodule/mycode.py\")\n\n        # Name                          Stmts   Miss  Cover\n        # -------------------------------------------------\n        # nested/submodule/mycode.py    1       0     100%\n        # submodule/mycode.py           1       0     100%\n        # -------------------------------------------------\n        # TOTAL                         2       0     100%\n\n        reported_files = [line.split()[0] for line in report.splitlines()[2:4]]\n        assert reported_files == [\n            \"nested/submodule/mycode.py\",\n            \"submodule/mycode.py\",\n        ]\n\n    def test_omit_files_here(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/1407\n        self.make_file(\"foo.py\", \"\")\n        self.make_file(\"bar/bar.py\", \"\")\n        self.make_file(\"tests/test_baz.py\", \"\"\"\\\n            def test_foo():\n                assert True\n            test_foo()\n            \"\"\")\n        self.run_command(\"coverage run --source=. --omit='./*.py' -m tests.test_baz\")\n        report = self.report_from_command(\"coverage report\")\n\n        # Name                Stmts   Miss  Cover\n        # ---------------------------------------\n        # tests/test_baz.py       3      0   100%\n        # ---------------------------------------\n        # TOTAL                   3      0   100%\n\n        assert self.line_count(report) == 5\n        assert \"foo\" not in report\n        assert \"bar\" not in report\n        assert \"tests/test_baz.py\" in report\n        assert self.last_line_squeezed(report) == \"TOTAL 3 0 100%\"\n\n    def test_run_source_vs_report_include(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/621\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            source = .\n\n            [report]\n            include = mod/*,tests/*\n            \"\"\")\n        # It should be OK to use that configuration.\n        cov = coverage.Coverage()\n        with self.assert_warnings(cov, []):\n            with cov.collect():\n                pass\n\n    def test_run_omit_vs_report_omit(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/622\n        # report:omit shouldn't clobber run:omit.\n        self.make_mycode()\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [run]\n            omit = */covmodzip1.py\n\n            [report]\n            omit = */covmod1.py\n            \"\"\")\n        self.add_test_modules_to_pythonpath()\n        self.run_command(\"coverage run mycode.py\")\n\n        # Read the data written, to see that the right files have been omitted from running.\n        covdata = CoverageData()\n        covdata.read()\n        files = [os.path.basename(p) for p in covdata.measured_files()]\n        assert \"covmod1.py\" in files\n        assert \"covmodzip1.py\" not in files\n\n    def test_report_branches(self) -> None:\n        self.make_file(\"mybranch.py\", \"\"\"\\\n            def branch(x):\n                if x:\n                    print(\"x\")\n                return x\n            branch(1)\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"], branch=True)\n        self.start_import_stop(cov, \"mybranch\")\n        assert self.stdout() == 'x\\n'\n        report = self.get_report(cov)\n\n        # Name          Stmts   Miss Branch BrPart  Cover\n        # -----------------------------------------------\n        # mybranch.py       5      0      2      1    86%\n        # -----------------------------------------------\n        # TOTAL             5      0      2      1    86%\n        assert self.line_count(report) == 5\n        assert \"mybranch.py \" in report\n        assert self.last_line_squeezed(report) == \"TOTAL 5 0 2 1 86%\"\n\n    def test_report_show_missing(self) -> None:\n        self.make_file(\"mymissing.py\", \"\"\"\\\n            def missing(x, y):\n                if x:\n                    print(\"x\")\n                    return x\n                if y:\n                    print(\"y\")\n                try:\n                    print(\"z\")\n                    1/0\n                    print(\"Never!\")\n                except ZeroDivisionError:\n                    pass\n                return x\n            missing(0, 1)\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"mymissing\")\n        assert self.stdout() == 'y\\nz\\n'\n        report = self.get_report(cov, show_missing=True)\n\n        # Name           Stmts   Miss  Cover   Missing\n        # --------------------------------------------\n        # mymissing.py      14      3    79%   3-4, 10\n        # --------------------------------------------\n        # TOTAL             14      3    79%\n\n        assert self.line_count(report) == 5\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[2] == \"mymissing.py 14 3 79% 3-4, 10\"\n        assert squeezed[4] == \"TOTAL 14 3 79%\"\n\n    def test_report_show_missing_branches(self) -> None:\n        self.make_file(\"mybranch.py\", \"\"\"\\\n            def branch(x, y):\n                if x:\n                    print(\"x\")\n                if y:\n                    print(\"y\")\n            branch(1, 1)\n            \"\"\")\n        cov = coverage.Coverage(branch=True)\n        self.start_import_stop(cov, \"mybranch\")\n        assert self.stdout() == 'x\\ny\\n'\n        report = self.get_report(cov, show_missing=True)\n\n        # Name           Stmts   Miss Branch BrPart  Cover   Missing\n        # ----------------------------------------------------------\n        # mybranch.py        6      0      4      2    80%   2->4, 4->exit\n        # ----------------------------------------------------------\n        # TOTAL              6      0      4      2    80%\n\n        assert self.line_count(report) == 5\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[2] == \"mybranch.py 6 0 4 2 80% 2->4, 4->exit\"\n        assert squeezed[4] == \"TOTAL 6 0 4 2 80%\"\n\n    def test_report_show_missing_branches_and_lines(self) -> None:\n        self.make_file(\"main.py\", \"\"\"\\\n            import mybranch\n            \"\"\")\n        self.make_file(\"mybranch.py\", \"\"\"\\\n            def branch(x, y, z):\n                if x:\n                    print(\"x\")\n                if y:\n                    print(\"y\")\n                if z:\n                    if x and y:\n                        print(\"z\")\n                return x\n            branch(1, 1, 0)\n            \"\"\")\n        cov = coverage.Coverage(branch=True)\n        self.start_import_stop(cov, \"main\")\n        assert self.stdout() == 'x\\ny\\n'\n        report_lines = self.get_report(cov, squeeze=False, show_missing=True).splitlines()\n\n        expected = [\n            'Name          Stmts   Miss Branch BrPart  Cover   Missing',\n            '---------------------------------------------------------',\n            'main.py           1      0      0      0   100%',\n            'mybranch.py      10      2      8      3    61%   2->4, 4->6, 7-8',\n            '---------------------------------------------------------',\n            'TOTAL            11      2      8      3    63%',\n        ]\n        assert expected == report_lines\n\n    def test_report_skip_covered_no_branches(self) -> None:\n        self.make_file(\"main.py\", \"\"\"\\\n            import not_covered\n\n            def normal():\n                print(\"z\")\n            normal()\n            \"\"\")\n        self.make_file(\"not_covered.py\", \"\"\"\\\n            def not_covered():\n                print(\"n\")\n            \"\"\")\n        # --fail-under is handled by cmdline.py, use real commands.\n        out = self.run_command(\"coverage run main.py\")\n        assert out == \"z\\n\"\n        report = self.report_from_command(\"coverage report --skip-covered --fail-under=70\")\n\n        # Name             Stmts   Miss  Cover\n        # ------------------------------------\n        # not_covered.py       2      1    50%\n        # ------------------------------------\n        # TOTAL                6      1    83%\n        #\n        # 1 file skipped due to complete coverage.\n\n        assert self.line_count(report) == 7, report\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[2] == \"not_covered.py 2 1 50%\"\n        assert squeezed[4] == \"TOTAL 6 1 83%\"\n        assert squeezed[6] == \"1 file skipped due to complete coverage.\"\n        assert self.last_command_status == 0\n\n    def test_report_skip_covered_branches(self) -> None:\n        self.make_file(\"main.py\", \"\"\"\\\n            import not_covered, covered\n\n            def normal(z):\n                if z:\n                    print(\"z\")\n            normal(True)\n            normal(False)\n            \"\"\")\n        self.make_file(\"not_covered.py\", \"\"\"\\\n            def not_covered(n):\n                if n:\n                    print(\"n\")\n            not_covered(True)\n            \"\"\")\n        self.make_file(\"covered.py\", \"\"\"\\\n            def foo():\n                pass\n            foo()\n            \"\"\")\n        cov = coverage.Coverage(branch=True)\n        self.start_import_stop(cov, \"main\")\n        assert self.stdout() == \"n\\nz\\n\"\n        report = self.get_report(cov, skip_covered=True)\n\n        # Name             Stmts   Miss Branch BrPart  Cover\n        # --------------------------------------------------\n        # not_covered.py       4      0      2      1    83%\n        # --------------------------------------------------\n        # TOTAL               13      0      4      1    94%\n        #\n        # 2 files skipped due to complete coverage.\n\n        assert self.line_count(report) == 7, report\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[2] == \"not_covered.py 4 0 2 1 83%\"\n        assert squeezed[4] == \"TOTAL 13 0 4 1 94%\"\n        assert squeezed[6] == \"2 files skipped due to complete coverage.\"\n\n    def test_report_skip_covered_branches_with_totals(self) -> None:\n        self.make_file(\"main.py\", \"\"\"\\\n            import not_covered\n            import also_not_run\n\n            def normal(z):\n                if z:\n                    print(\"z\")\n            normal(True)\n            normal(False)\n            \"\"\")\n        self.make_file(\"not_covered.py\", \"\"\"\\\n            def not_covered(n):\n                if n:\n                    print(\"n\")\n            not_covered(True)\n            \"\"\")\n        self.make_file(\"also_not_run.py\", \"\"\"\\\n            def does_not_appear_in_this_film(ni):\n                print(\"Ni!\")\n            \"\"\")\n        cov = coverage.Coverage(branch=True)\n        self.start_import_stop(cov, \"main\")\n        assert self.stdout() == \"n\\nz\\n\"\n        report = self.get_report(cov, skip_covered=True)\n\n        # Name             Stmts   Miss Branch BrPart  Cover\n        # --------------------------------------------------\n        # also_not_run.py      2      1      0      0    50%\n        # not_covered.py       4      0      2      1    83%\n        # --------------------------------------------------\n        # TOTAL                13     1      4      1    88%\n        #\n        # 1 file skipped due to complete coverage.\n\n        assert self.line_count(report) == 8, report\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[2] == \"also_not_run.py 2 1 0 0 50%\"\n        assert squeezed[3] == \"not_covered.py 4 0 2 1 83%\"\n        assert squeezed[5] == \"TOTAL 13 1 4 1 88%\"\n        assert squeezed[7] == \"1 file skipped due to complete coverage.\"\n\n    def test_report_skip_covered_all_files_covered(self) -> None:\n        self.make_file(\"main.py\", \"\"\"\\\n            def foo():\n                pass\n            foo()\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"], branch=True)\n        self.start_import_stop(cov, \"main\")\n        assert self.stdout() == \"\"\n        report = self.get_report(cov, skip_covered=True)\n\n        # Name    Stmts   Miss Branch BrPart  Cover\n        # -----------------------------------------\n        # TOTAL       3      0      0      0   100%\n        #\n        # 1 file skipped due to complete coverage.\n\n        assert self.line_count(report) == 5, report\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[4] == \"1 file skipped due to complete coverage.\"\n\n        report = self.get_report(cov, squeeze=False, skip_covered=True, output_format=\"markdown\")\n\n        # | Name      |    Stmts |     Miss |   Branch |   BrPart |    Cover |\n        # |---------- | -------: | -------: | -------: | -------: | -------: |\n        # | **TOTAL** |    **3** |    **0** |    **0** |    **0** | **100%** |\n        #\n        # 1 file skipped due to complete coverage.\n\n        assert self.line_count(report) == 5, report\n        assert report.split(\"\\n\")[0] == (\n            '| Name      |    Stmts |     Miss |   Branch |   BrPart |    Cover |'\n        )\n        assert report.split(\"\\n\")[1] == (\n            '|---------- | -------: | -------: | -------: | -------: | -------: |'\n        )\n        assert report.split(\"\\n\")[2] == (\n            '| **TOTAL** |    **3** |    **0** |    **0** |    **0** | **100%** |'\n        )\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[4] == \"1 file skipped due to complete coverage.\"\n\n        total = self.get_report(cov, output_format=\"total\", skip_covered=True)\n        assert total == \"100\\n\"\n\n    def test_report_skip_covered_longfilename(self) -> None:\n        self.make_file(\"long_______________filename.py\", \"\"\"\\\n            def foo():\n                pass\n            foo()\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"], branch=True)\n        self.start_import_stop(cov, \"long_______________filename\")\n        assert self.stdout() == \"\"\n        report = self.get_report(cov, squeeze=False, skip_covered=True)\n\n        # Name    Stmts   Miss Branch BrPart  Cover\n        # -----------------------------------------\n        # TOTAL       3      0      0      0   100%\n        #\n        # 1 file skipped due to complete coverage.\n\n        assert self.line_count(report) == 5, report\n        lines = self.report_lines(report)\n        assert lines[0] == \"Name    Stmts   Miss Branch BrPart  Cover\"\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[4] == \"1 file skipped due to complete coverage.\"\n\n    def test_report_skip_covered_no_data(self) -> None:\n        cov = coverage.Coverage()\n        cov.load()\n        with pytest.raises(NoDataError, match=\"No data to report.\"):\n            self.get_report(cov, skip_covered=True)\n        self.assert_doesnt_exist(\".coverage\")\n\n    def test_report_skip_empty(self) -> None:\n        self.make_file(\"main.py\", \"\"\"\\\n            import submodule\n\n            def normal():\n                print(\"z\")\n            normal()\n            \"\"\")\n        self.make_file(\"submodule/__init__.py\", \"\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n        assert self.stdout() == \"z\\n\"\n        report = self.get_report(cov, skip_empty=True)\n\n        # Name             Stmts   Miss  Cover\n        # ------------------------------------\n        # main.py              4      0   100%\n        # ------------------------------------\n        # TOTAL                4      0   100%\n        #\n        # 1 empty file skipped.\n\n        assert self.line_count(report) == 7, report\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[2] == \"main.py 4 0 100%\"\n        assert squeezed[4] == \"TOTAL 4 0 100%\"\n        assert squeezed[6] == \"1 empty file skipped.\"\n\n    def test_report_skip_empty_no_data(self) -> None:\n        self.make_file(\"__init__.py\", \"\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"__init__\")\n        assert self.stdout() == \"\"\n        report = self.get_report(cov, skip_empty=True)\n\n        # Name             Stmts   Miss  Cover\n        # ------------------------------------\n        # TOTAL                0      0   100%\n        #\n        # 1 empty file skipped.\n\n        assert self.line_count(report) == 5, report\n        assert report.split(\"\\n\")[2] == \"TOTAL 0 0 100%\"\n        assert report.split(\"\\n\")[4] == \"1 empty file skipped.\"\n\n    def test_report_precision(self) -> None:\n        self.make_file(\".coveragerc\", \"\"\"\\\n            [report]\n            precision = 3\n            omit = */site-packages/*\n            \"\"\")\n        self.make_file(\"main.py\", \"\"\"\\\n            import not_covered, covered\n\n            def normal(z):\n                if z:\n                    print(\"z\")\n            normal(True)\n            normal(False)\n            \"\"\")\n        self.make_file(\"not_covered.py\", \"\"\"\\\n            def not_covered(n):\n                if n:\n                    print(\"n\")\n            not_covered(True)\n            \"\"\")\n        self.make_file(\"covered.py\", \"\"\"\\\n            def foo():\n                pass\n            foo()\n            \"\"\")\n        cov = coverage.Coverage(branch=True)\n        self.start_import_stop(cov, \"main\")\n        assert self.stdout() == \"n\\nz\\n\"\n        report = self.get_report(cov, squeeze=False)\n\n        # Name             Stmts   Miss Branch BrPart      Cover\n        # ------------------------------------------------------\n        # covered.py           3      0      0      0   100.000%\n        # main.py              6      0      2      0   100.000%\n        # not_covered.py       4      0      2      1    83.333%\n        # ------------------------------------------------------\n        # TOTAL               13      0      4      1    94.118%\n\n        assert self.line_count(report) == 7, report\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[2] == \"covered.py 3 0 0 0 100.000%\"\n        assert squeezed[4] == \"not_covered.py 4 0 2 1 83.333%\"\n        assert squeezed[6] == \"TOTAL 13 0 4 1 94.118%\"\n\n    def test_report_precision_all_zero(self) -> None:\n        self.make_file(\"not_covered.py\", \"\"\"\\\n            def not_covered(n):\n                if n:\n                    print(\"n\")\n            \"\"\")\n        self.make_file(\"empty.py\", \"\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"empty\")\n        report = self.get_report(cov, precision=6, squeeze=False)\n\n        # Name             Stmts   Miss       Cover\n        # -----------------------------------------\n        # empty.py             0      0 100.000000%\n        # not_covered.py       3      3   0.000000%\n        # -----------------------------------------\n        # TOTAL                3      3   0.000000%\n\n        assert self.line_count(report) == 6, report\n        assert \"empty.py             0      0 100.000000%\" in report\n        assert \"not_covered.py       3      3   0.000000%\" in report\n        assert \"TOTAL                3      3   0.000000%\" in report\n\n    def test_report_module_docstrings(self) -> None:\n        self.make_file(\"main.py\", \"\"\"\\\n            # Line 1\n            '''Line 2 docstring.'''\n            import other\n            a = 4\n            \"\"\")\n        self.make_file(\"other.py\", \"\"\"\\\n            '''Line 1'''\n            a = 2\n            \"\"\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n        report = self.get_report(cov)\n\n        # Name       Stmts   Miss  Cover\n        # ------------------------------\n        # main.py        2      0   100%\n        # other.py       1      0   100%\n        # ------------------------------\n        # TOTAL          3      0   100%\n\n        assert self.line_count(report) == 6, report\n        squeezed = self.squeezed_lines(report)\n        assert squeezed[2] == \"main.py 2 0 100%\"\n        assert squeezed[3] == \"other.py 1 0 100%\"\n        assert squeezed[5] == \"TOTAL 3 0 100%\"\n\n    def test_dotpy_not_python(self) -> None:\n        # We run a .py file, and when reporting, we can't parse it as Python.\n        # We should get an error message in the report.\n\n        self.make_data_file(lines={\"mycode.py\": [1]})\n        self.make_file(\"mycode.py\", \"This isn't python at all!\")\n        cov = coverage.Coverage()\n        cov.load()\n        msg = r\"Couldn't parse '.*[/\\\\]mycode.py' as Python source: '.*' at line 1\"\n        with pytest.raises(NotPython, match=msg):\n            self.get_report(cov, morfs=[\"mycode.py\"])\n\n    def test_accented_directory(self) -> None:\n        # Make a file with a non-ascii character in the directory name.\n        self.make_file(\"\\xe2/accented.py\", \"print('accented')\")\n        self.make_data_file(lines={abs_file(\"\\xe2/accented.py\"): [1]})\n        report_expected = (\n            \"Name            Stmts   Miss  Cover\\n\" +\n            \"-----------------------------------\\n\" +\n            \"\\xe2/accented.py       1      0   100%\\n\" +\n            \"-----------------------------------\\n\" +\n            \"TOTAL               1      0   100%\\n\"\n        )\n        cov = coverage.Coverage()\n        cov.load()\n        output = self.get_report(cov, squeeze=False)\n        assert output == report_expected\n\n    def test_accenteddotpy_not_python(self) -> None:\n        # We run a .py file with a non-ascii name, and when reporting, we can't\n        # parse it as Python.  We should get an error message in the report.\n\n        self.make_data_file(lines={\"accented\\xe2.py\": [1]})\n        self.make_file(\"accented\\xe2.py\", \"This isn't python at all!\")\n        cov = coverage.Coverage()\n        cov.load()\n        msg = r\"Couldn't parse '.*[/\\\\]accented\\xe2.py' as Python source: '.*' at line 1\"\n        with pytest.raises(NotPython, match=msg):\n            self.get_report(cov, morfs=[\"accented\\xe2.py\"])\n\n    def test_dotpy_not_python_ignored(self) -> None:\n        # We run a .py file, and when reporting, we can't parse it as Python,\n        # but we've said to ignore errors, so there's no error reported,\n        # though we still get a warning.\n        self.make_file(\"mycode.py\", \"This isn't python at all!\")\n        self.make_data_file(lines={\"mycode.py\": [1]})\n        cov = coverage.Coverage()\n        cov.load()\n        with pytest.raises(NoDataError, match=\"No data to report.\"):\n            with pytest.warns(Warning) as warns:\n                self.get_report(cov, morfs=[\"mycode.py\"], ignore_errors=True)\n        assert_coverage_warnings(\n            warns,\n            re.compile(r\"Couldn't parse Python file '.*[/\\\\]mycode.py' \\(couldnt-parse\\)\"),\n        )\n\n    def test_dothtml_not_python(self) -> None:\n        # We run a .html file, and when reporting, we can't parse it as\n        # Python.  Since it wasn't .py, no error is reported.\n\n        # Pretend to run an html file.\n        self.make_file(\"mycode.html\", \"<h1>This isn't python at all!</h1>\")\n        self.make_data_file(lines={\"mycode.html\": [1]})\n        cov = coverage.Coverage()\n        cov.load()\n        with pytest.raises(NoDataError, match=\"No data to report.\"):\n            self.get_report(cov, morfs=[\"mycode.html\"])\n\n    def test_report_no_extension(self) -> None:\n        self.make_file(\"xxx\", \"\"\"\\\n            # This is a python file though it doesn't look like it, like a main script.\n            a = b = c = d = 0\n            a = 3\n            b = 4\n            if not b:\n                c = 6\n            d = 7\n            print(f\"xxx: {a} {b} {c} {d}\")\n            \"\"\")\n        self.make_data_file(lines={abs_file(\"xxx\"): [2, 3, 4, 5, 7, 8]})\n        cov = coverage.Coverage()\n        cov.load()\n        report = self.get_report(cov)\n        assert self.last_line_squeezed(report) == \"TOTAL 7 1 86%\"\n\n    def test_report_with_chdir(self) -> None:\n        self.make_file(\"chdir.py\", \"\"\"\\\n            import os\n            print(\"Line One\")\n            os.chdir(\"subdir\")\n            print(\"Line Two\")\n            print(open(\"something\").read())\n            \"\"\")\n        self.make_file(\"subdir/something\", \"hello\")\n        out = self.run_command(\"coverage run --source=. chdir.py\")\n        assert out == \"Line One\\nLine Two\\nhello\\n\"\n        report = self.report_from_command(\"coverage report\")\n        assert self.last_line_squeezed(report) == \"TOTAL 5 0 100%\"\n        report = self.report_from_command(\"coverage report --format=markdown\")\n        assert self.last_line_squeezed(report) == \"| **TOTAL** | **5** | **0** | **100%** |\"\n\n    def test_bug_156_file_not_run_should_be_zero(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/156\n        self.make_file(\"mybranch.py\", \"\"\"\\\n            def branch(x):\n                if x:\n                    print(\"x\")\n                return x\n            branch(1)\n            \"\"\")\n        self.make_file(\"main.py\", \"\"\"\\\n            print(\"y\")\n            \"\"\")\n        cov = coverage.Coverage(branch=True, source=[\".\"])\n        self.start_import_stop(cov, \"main\")\n        report = self.get_report(cov).splitlines()\n        assert \"mybranch.py 5 5 2 0 0%\" in report\n\n    def run_TheCode_and_report_it(self) -> str:\n        \"\"\"A helper for the next few tests.\"\"\"\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"TheCode\")\n        return self.get_report(cov)\n\n    def test_bug_203_mixed_case_listed_twice_with_rc(self) -> None:\n        self.make_file(\"TheCode.py\", \"a = 1\\n\")\n        self.make_file(\".coveragerc\", \"[run]\\nsource = .\\n\")\n\n        report = self.run_TheCode_and_report_it()\n        assert \"TheCode\" in report\n        assert \"thecode\" not in report\n\n    def test_bug_203_mixed_case_listed_twice(self) -> None:\n        self.make_file(\"TheCode.py\", \"a = 1\\n\")\n\n        report = self.run_TheCode_and_report_it()\n\n        assert \"TheCode\" in report\n        assert \"thecode\" not in report\n\n    @pytest.mark.skipif(not env.WINDOWS, reason=\".pyw files are only on Windows.\")\n    def test_pyw_files(self) -> None:\n        # https://github.com/nedbat/coveragepy/issues/261\n        self.make_file(\"start.pyw\", \"\"\"\\\n            import mod\n            print(\"In start.pyw\")\n            \"\"\")\n        self.make_file(\"mod.pyw\", \"\"\"\\\n            print(\"In mod.pyw\")\n            \"\"\")\n        cov = coverage.Coverage()\n        # start_import_stop can't import the .pyw file, so use the long form.\n        with cov.collect():\n            import start    # pylint: disable=import-error, unused-import\n\n        report = self.get_report(cov)\n        assert \"NoSource\" not in report\n        report_lines = report.splitlines()\n        assert \"start.pyw 2 0 100%\" in report_lines\n        assert \"mod.pyw 1 0 100%\" in report_lines\n\n    def test_tracing_pyc_file(self) -> None:\n        # Create two Python files.\n        self.make_file(\"mod.py\", \"a = 1\\n\")\n        self.make_file(\"main.py\", \"import mod\\n\")\n\n        # Make one into a .pyc.\n        py_compile.compile(\"mod.py\")\n\n        # Run the program.\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n\n        report_lines = self.get_report(cov).splitlines()\n        assert \"mod.py 1 0 100%\" in report_lines\n        report = self.get_report(cov, squeeze=False, output_format=\"markdown\")\n        assert report.split(\"\\n\")[3] == \"| mod.py    |        1 |        0 |     100% |\"\n        assert report.split(\"\\n\")[4] == \"| **TOTAL** |    **2** |    **0** | **100%** |\"\n\n    def test_missing_py_file_during_run(self) -> None:\n        # Create two Python files.\n        self.make_file(\"mod.py\", \"a = 1\\n\")\n        self.make_file(\"main.py\", \"import mod\\n\")\n\n        # Make one into a .pyc, and remove the .py.\n        py_compile.compile(\"mod.py\")\n        os.remove(\"mod.py\")\n\n        # Python 3 puts the .pyc files in a __pycache__ directory, and will\n        # not import from there without source.  It will import a .pyc from\n        # the source location though.\n        pycs = glob.glob(\"__pycache__/mod.*.pyc\")\n        assert len(pycs) == 1\n        os.rename(pycs[0], \"mod.pyc\")\n\n        # Run the program.\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"main\")\n\n        # Put back the missing Python file.\n        self.make_file(\"mod.py\", \"a = 1\\n\")\n        report = self.get_report(cov).splitlines()\n        assert \"mod.py 1 0 100%\" in report\n\n    def test_empty_files(self) -> None:\n        # Shows that empty files like __init__.py are listed as having zero\n        # statements, not one statement.\n        cov = coverage.Coverage(branch=True)\n        with cov.collect():\n            import usepkgs  # pylint: disable=import-error, unused-import\n        report = self.get_report(cov)\n        assert \"tests/modules/pkg1/__init__.py 1 0 0 0 100%\" in report\n        assert \"tests/modules/pkg2/__init__.py 0 0 0 0 100%\" in report\n        report = self.get_report(cov, squeeze=False, output_format=\"markdown\")\n        # get_report() escapes backslash so we expect forward slash escaped\n        # underscore\n        assert \"tests/modules/pkg1//_/_init/_/_.py \" in report\n        assert \"|        1 |        0 |        0 |        0 |     100% |\" in report\n        assert \"tests/modules/pkg2//_/_init/_/_.py \" in report\n        assert \"|        0 |        0 |        0 |        0 |     100% |\" in report\n\n    def test_markdown_with_missing(self) -> None:\n        self.make_file(\"mymissing.py\", \"\"\"\\\n            def missing(x, y):\n                if x:\n                    print(\"x\")\n                    return x\n                if y:\n                    print(\"y\")\n                try:\n                    print(\"z\")\n                    1/0\n                    print(\"Never!\")\n                except ZeroDivisionError:\n                    pass\n                return x\n            missing(0, 1)\n            \"\"\")\n        cov = coverage.Coverage(source=[\".\"])\n        self.start_import_stop(cov, \"mymissing\")\n        assert self.stdout() == 'y\\nz\\n'\n        report = self.get_report(cov, squeeze=False, output_format=\"markdown\", show_missing=True)\n\n        # | Name         |    Stmts |     Miss |   Cover |   Missing |\n        # |------------- | -------: | -------: | ------: | --------: |\n        # | mymissing.py |       14 |        3 |     79% |   3-4, 10 |\n        # |    **TOTAL** |   **14** |    **3** | **79%** |           |\n        assert self.line_count(report) == 4\n        report_lines = report.split(\"\\n\")\n        assert report_lines[2] == \"| mymissing.py |       14 |        3 |     79% |   3-4, 10 |\"\n        assert report_lines[3] == \"|    **TOTAL** |   **14** |    **3** | **79%** |           |\"\n\n        assert self.get_report(cov, output_format=\"total\") == \"79\\n\"\n        assert self.get_report(cov, output_format=\"total\", precision=2) == \"78.57\\n\"\n        assert self.get_report(cov, output_format=\"total\", precision=4) == \"78.5714\\n\"\n\n    def test_bug_1524(self) -> None:\n        self.make_file(\"bug1524.py\", \"\"\"\\\n            class Mine:\n                @property\n                def thing(self) -> int:\n                    return 17\n\n            print(Mine().thing)\n            \"\"\")\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"bug1524\")\n        assert self.stdout() == \"17\\n\"\n        report = self.get_report(cov)\n        report_lines = report.splitlines()\n        assert report_lines[2] == \"bug1524.py 5 0 100%\"\n\n\nclass ReportingReturnValueTest(CoverageTest):\n    \"\"\"Tests of reporting functions returning values.\"\"\"\n\n    def run_coverage(self) -> Coverage:\n        \"\"\"Run coverage on doit.py and return the coverage object.\"\"\"\n        self.make_file(\"doit.py\", \"\"\"\\\n            a = 1\n            b = 2\n            c = 3\n            d = 4\n            if a > 10:\n                f = 6\n            g = 7\n            \"\"\")\n\n        cov = coverage.Coverage()\n        self.start_import_stop(cov, \"doit\")\n        return cov\n\n    def test_report(self) -> None:\n        cov = self.run_coverage()\n        val = cov.report(include=\"*/doit.py\")\n        assert math.isclose(val, 6 / 7 * 100)\n\n    def test_html(self) -> None:\n        cov = self.run_coverage()\n        val = cov.html_report(include=\"*/doit.py\")\n        assert math.isclose(val, 6 / 7 * 100)\n\n    def test_xml(self) -> None:\n        cov = self.run_coverage()\n        val = cov.xml_report(include=\"*/doit.py\")\n        assert math.isclose(val, 6 / 7 * 100)\n\n\nclass SummaryReporterConfigurationTest(CoverageTest):\n    \"\"\"Tests of SummaryReporter.\"\"\"\n\n    def make_rigged_file(self, filename: str, stmts: int, miss: int) -> None:\n        \"\"\"Create a file that will have specific results.\n\n        `stmts` and `miss` are ints, the number of statements, and\n        missed statements that should result.\n        \"\"\"\n        run = stmts - miss - 1\n        dont_run = miss\n        source = \"\"\n        source += \"a = 1\\n\" * run\n        source += \"if a == 99:\\n\"\n        source += \"    a = 2\\n\" * dont_run\n        self.make_file(filename, source)\n\n    def get_summary_text(self, *options: tuple[str, TConfigValueIn]) -> str:\n        \"\"\"Get text output from the SummaryReporter.\n\n        The arguments are tuples: (name, value) for Coverage.set_option.\n        \"\"\"\n        self.make_rigged_file(\"file1.py\", 339, 155)\n        self.make_rigged_file(\"file2.py\", 13, 3)\n        self.make_rigged_file(\"file10.py\", 234, 228)\n        self.make_file(\"doit.py\", \"import file1, file2, file10\")\n\n        cov = Coverage(source=[\".\"], omit=[\"doit.py\"])\n        self.start_import_stop(cov, \"doit\")\n        for name, value in options:\n            cov.set_option(name, value)\n        printer = SummaryReporter(cov)\n        destination = io.StringIO()\n        printer.report([], destination)\n        return destination.getvalue()\n\n    def test_test_data(self) -> None:\n        # We use our own test files as test data. Check that our assumptions\n        # about them are still valid.  We want the three columns of numbers to\n        # sort in three different orders.\n        report = self.get_summary_text()\n        # Name       Stmts   Miss  Cover\n        # ------------------------------\n        # file1.py     339    155    54%\n        # file2.py      13      3    77%\n        # file10.py    234    228     3%\n        # ------------------------------\n        # TOTAL        586    386    34%\n        lines = report.splitlines()[2:-2]\n        assert len(lines) == 3\n        nums = [list(map(int, l.replace('%', '').split()[1:])) for l in lines]\n        # [\n        #  [339, 155, 54],\n        #  [ 13,   3, 77],\n        #  [234, 228,  3]\n        # ]\n        assert nums[1][0] < nums[2][0] < nums[0][0]\n        assert nums[1][1] < nums[0][1] < nums[2][1]\n        assert nums[2][2] < nums[0][2] < nums[1][2]\n\n    def test_defaults(self) -> None:\n        \"\"\"Run the report with no configuration options.\"\"\"\n        report = self.get_summary_text()\n        assert 'Missing' not in report\n        assert 'Branch' not in report\n\n    def test_print_missing(self) -> None:\n        \"\"\"Run the report printing the missing lines.\"\"\"\n        report = self.get_summary_text(('report:show_missing', True))\n        assert 'Missing' in report\n        assert 'Branch' not in report\n\n    def assert_ordering(self, text: str, *words: str) -> None:\n        \"\"\"Assert that the `words` appear in order in `text`.\"\"\"\n        indexes = list(map(text.find, words))\n        assert -1 not in indexes\n        msg = f\"The words {words!r} don't appear in order in {text!r}\"\n        assert indexes == sorted(indexes), msg\n\n    def test_default_sort_report(self) -> None:\n        # Sort the text report by the default (Name) column.\n        report = self.get_summary_text()\n        self.assert_ordering(report, \"file1.py\", \"file2.py\", \"file10.py\")\n\n    def test_sort_report_by_name(self) -> None:\n        # Sort the text report explicitly by the Name column.\n        report = self.get_summary_text(('report:sort', 'Name'))\n        self.assert_ordering(report, \"file1.py\", \"file2.py\", \"file10.py\")\n\n    def test_sort_report_by_stmts(self) -> None:\n        # Sort the text report by the Stmts column.\n        report = self.get_summary_text(('report:sort', 'Stmts'))\n        self.assert_ordering(report, \"file2.py\", \"file10.py\", \"file1.py\")\n\n    def test_sort_report_by_missing(self) -> None:\n        # Sort the text report by the Missing column.\n        report = self.get_summary_text(('report:sort', 'Miss'))\n        self.assert_ordering(report, \"file2.py\", \"file1.py\", \"file10.py\")\n\n    def test_sort_report_by_cover(self) -> None:\n        # Sort the text report by the Cover column.\n        report = self.get_summary_text(('report:sort', 'Cover'))\n        self.assert_ordering(report, \"file10.py\", \"file1.py\", \"file2.py\")\n\n    def test_sort_report_by_cover_plus(self) -> None:\n        # Sort the text report by the Cover column, including the explicit + sign.\n        report = self.get_summary_text(('report:sort', '+Cover'))\n        self.assert_ordering(report, \"file10.py\", \"file1.py\", \"file2.py\")\n\n    def test_sort_report_by_cover_reversed(self) -> None:\n        # Sort the text report by the Cover column reversed.\n        report = self.get_summary_text(('report:sort', '-Cover'))\n        self.assert_ordering(report, \"file2.py\", \"file1.py\", \"file10.py\")\n\n    def test_sort_report_by_invalid_option(self) -> None:\n        # Sort the text report by a nonsense column.\n        msg = \"Invalid sorting option: 'Xyzzy'\"\n        with pytest.raises(ConfigError, match=msg):\n            self.get_summary_text(('report:sort', 'Xyzzy'))\n\n    def test_report_with_invalid_format(self) -> None:\n        # Ask for an invalid format.\n        msg = \"Unknown report format choice: 'xyzzy'\"\n        with pytest.raises(ConfigError, match=msg):\n            self.get_summary_text(('report:format', 'xyzzy'))\n", "tests/balance_xdist_plugin.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nA pytest plugin to record test times and then use those times to divide tests\ninto evenly balanced workloads for each xdist worker.\n\nTwo things are hard-coded here that shouldn't be:\n\n- The timing data is written to the tmp directory, but should use the pytest\n  cache (https://docs.pytest.org/en/latest/how-to/cache.html).\n\n- The number of xdist workers is hard-coded to 8 because I couldn't figure out\n  how to find the number.  Would it be crazy to read the -n argument directly?\n\nYou can force some tests to run on the same worker by setting the\n`balanced_clumps` setting in your pytest config file.  Each line is a substring\nof a test name.  All tests with that substring (like -k) will run on the\nworker:\n\n    balanced_clumps =\n        LongRunningFixture\n        some_other_test_substring\n\n\"\"\"\n\nimport collections\nimport csv\nimport os\nimport shutil\nimport time\n\nfrom pathlib import Path\n\nimport pytest\nimport xdist.scheduler\n\n\ndef pytest_addoption(parser):\n    \"\"\"Auto-called to define ini-file settings.\"\"\"\n    parser.addini(\n        \"balanced_clumps\",\n        type=\"linelist\",\n        help=\"Test substrings to assign to the same worker\",\n    )\n\n@pytest.hookimpl(tryfirst=True)\ndef pytest_configure(config):\n    \"\"\"Registers our pytest plugin.\"\"\"\n    config.pluginmanager.register(BalanceXdistPlugin(config), \"balance_xdist_plugin\")\n\n\nclass BalanceXdistPlugin:       # pragma: debugging\n    \"\"\"The plugin\"\"\"\n\n    def __init__(self, config):\n        self.config = config\n        self.running_all = (self.config.getoption(\"-k\") == \"\")\n        self.times = collections.defaultdict(float)\n        self.worker = os.getenv(\"PYTEST_XDIST_WORKER\", \"none\")\n        self.tests_csv = None\n\n    def pytest_sessionstart(self, session):\n        \"\"\"Called once before any tests are run, but in every worker.\"\"\"\n        if not self.running_all:\n            return\n\n        tests_csv_dir = session.startpath.resolve() / \"tmp/tests_csv\"\n        self.tests_csv = tests_csv_dir / f\"{self.worker}.csv\"\n\n        if self.worker == \"none\":\n            if tests_csv_dir.exists():\n                for csv_file in tests_csv_dir.iterdir():\n                    with csv_file.open(newline=\"\") as fcsv:\n                        reader = csv.reader(fcsv)\n                        for row in reader:\n                            self.times[row[1]] += float(row[3])\n                shutil.rmtree(tests_csv_dir)\n\n    def write_duration_row(self, item, phase, duration):\n        \"\"\"Helper to write a row to the tracked-test csv file.\"\"\"\n        if self.running_all:\n            self.tests_csv.parent.mkdir(parents=True, exist_ok=True)\n            with self.tests_csv.open(\"a\", newline=\"\") as fcsv:\n                csv.writer(fcsv).writerow([self.worker, item.nodeid, phase, duration])\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_setup(self, item):\n        \"\"\"Run once for each test.\"\"\"\n        start = time.time()\n        yield\n        self.write_duration_row(item, \"setup\", time.time() - start)\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_call(self, item):\n        \"\"\"Run once for each test.\"\"\"\n        start = time.time()\n        yield\n        self.write_duration_row(item, \"call\", time.time() - start)\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_teardown(self, item):\n        \"\"\"Run once for each test.\"\"\"\n        start = time.time()\n        yield\n        self.write_duration_row(item, \"teardown\", time.time() - start)\n\n    @pytest.hookimpl(trylast=True)\n    def pytest_xdist_make_scheduler(self, config, log):\n        \"\"\"Create our BalancedScheduler using time data from the last run.\"\"\"\n        # Assign tests to chunks\n        nchunks = 8\n        totals = [0] * nchunks\n        tests = collections.defaultdict(set)\n\n        # first put the difficult ones all in one worker\n        clumped = set()\n        clumps = config.getini(\"balanced_clumps\")\n        for i, clump_word in enumerate(clumps):\n            clump_nodes = {nodeid for nodeid in self.times.keys() if clump_word in nodeid}\n            i %= nchunks\n            tests[i].update(clump_nodes)\n            totals[i] += sum(self.times[nodeid] for nodeid in clump_nodes)\n            clumped.update(clump_nodes)\n\n        # Then assign the rest in descending order\n        rest = [(nodeid, t) for (nodeid, t) in self.times.items() if nodeid not in clumped]\n        rest.sort(key=lambda item: item[1], reverse=True)\n        for nodeid, t in rest:\n            lightest = min(enumerate(totals), key=lambda pair: pair[1])[0]\n            tests[lightest].add(nodeid)\n            totals[lightest] += t\n\n        test_chunks = {}\n        for chunk_id, nodeids in tests.items():\n            for nodeid in nodeids:\n                test_chunks[nodeid] = chunk_id\n\n        return BalancedScheduler(config, log, clumps, test_chunks)\n\n\nclass BalancedScheduler(xdist.scheduler.LoadScopeScheduling):   # pylint: disable=abstract-method # pragma: debugging\n    \"\"\"A balanced-chunk test scheduler for pytest-xdist.\"\"\"\n    def __init__(self, config, log, clumps, test_chunks):\n        super().__init__(config, log)\n        self.clumps = clumps\n        self.test_chunks = test_chunks\n\n    def _split_scope(self, nodeid):\n        \"\"\"Assign a chunk id to a test node.\"\"\"\n        # If we have a chunk assignment for this node, return it.\n        scope = self.test_chunks.get(nodeid)\n        if scope is not None:\n            return scope\n\n        # If this is a node that should be clumped, clump it.\n        for i, clump_word in enumerate(self.clumps):\n            if clump_word in nodeid:\n                return f\"clump{i}\"\n\n        # Otherwise every node is a separate chunk.\n        return nodeid\n\n\n# Run this with:\n#   python -c \"from tests.balance_xdist_plugin import show_worker_times as f; f()\"\ndef show_worker_times():                            # pragma: debugging\n    \"\"\"Ad-hoc utility to show data from the last tracked-test run.\"\"\"\n    times = collections.defaultdict(float)\n    tests = collections.defaultdict(int)\n    tests_csv_dir = Path(\"tmp/tests_csv\")\n\n    for csv_file in tests_csv_dir.iterdir():\n        with csv_file.open(newline=\"\") as fcsv:\n            reader = csv.reader(fcsv)\n            for row in reader:\n                worker = row[0]\n                duration = float(row[3])\n                times[worker] += duration\n                if row[2] == \"call\":\n                    tests[worker] += 1\n\n    for worker in sorted(tests.keys()):\n        print(f\"{worker}: {tests[worker]:3d} {times[worker]:.2f}\")\n\n    total = sum(times.values())\n    avg = total / len(times)\n    print(f\"total: {total:.2f}, avg: {avg:.2f}\")\n    lo = min(times.values())\n    hi = max(times.values())\n    print(f\"lo = {lo:.2f}; hi = {hi:.2f}; gap = {hi - lo:.2f}; long delta = {hi - avg:.2f}\")\n", "tests/test_templite.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Tests for coverage.templite.\"\"\"\n\nfrom __future__ import annotations\n\nimport re\n\nfrom types import SimpleNamespace\nfrom typing import Any, ContextManager\n\nimport pytest\n\nfrom coverage.templite import Templite, TempliteSyntaxError, TempliteValueError\n\nfrom tests.coveragetest import CoverageTest\n\n# pylint: disable=possibly-unused-variable\n\n\nclass TempliteTest(CoverageTest):\n    \"\"\"Tests for Templite.\"\"\"\n\n    run_in_temp_dir = False\n\n    def try_render(\n        self,\n        text: str,\n        ctx: dict[str, Any] | None = None,\n        result: str | None = None,\n    ) -> None:\n        \"\"\"Render `text` through `ctx`, and it had better be `result`.\n\n        Result defaults to None so we can shorten the calls where we expect\n        an exception and never get to the result comparison.\n\n        \"\"\"\n        actual = Templite(text).render(ctx or {})\n        # If result is None, then an exception should have prevented us getting\n        # to here.\n        assert result is not None\n        assert actual == result\n\n    def assertSynErr(self, msg: str) -> ContextManager[None]:\n        \"\"\"Assert that a `TempliteSyntaxError` will happen.\n\n        A context manager, and the message should be `msg`.\n\n        \"\"\"\n        pat = \"^\" + re.escape(msg) + \"$\"\n        return pytest.raises(TempliteSyntaxError, match=pat)    # type: ignore\n\n    def test_passthrough(self) -> None:\n        # Strings without variables are passed through unchanged.\n        assert Templite(\"Hello\").render() == \"Hello\"\n        assert Templite(\"Hello, 20% fun time!\").render() == \"Hello, 20% fun time!\"\n\n    def test_variables(self) -> None:\n        # Variables use {{var}} syntax.\n        self.try_render(\"Hello, {{name}}!\", {'name':'Ned'}, \"Hello, Ned!\")\n\n    def test_undefined_variables(self) -> None:\n        # Using undefined names is an error.\n        with pytest.raises(Exception, match=\"'name'\"):\n            self.try_render(\"Hi, {{name}}!\")\n\n    def test_pipes(self) -> None:\n        # Variables can be filtered with pipes.\n        data = {\n            'name': 'Ned',\n            'upper': lambda x: x.upper(),\n            'second': lambda x: x[1],\n        }\n        self.try_render(\"Hello, {{name|upper}}!\", data, \"Hello, NED!\")\n\n        # Pipes can be concatenated.\n        self.try_render(\"Hello, {{name|upper|second}}!\", data, \"Hello, E!\")\n\n    def test_reusability(self) -> None:\n        # A single Templite can be used more than once with different data.\n        globs = {\n            'upper': lambda x: x.upper(),\n            'punct': '!',\n        }\n\n        template = Templite(\"This is {{name|upper}}{{punct}}\", globs)\n        assert template.render({'name':'Ned'}) == \"This is NED!\"\n        assert template.render({'name':'Ben'}) == \"This is BEN!\"\n\n    def test_attribute(self) -> None:\n        # Variables' attributes can be accessed with dots.\n        obj = SimpleNamespace(a=\"Ay\")\n        self.try_render(\"{{obj.a}}\", locals(), \"Ay\")\n\n        obj2 = SimpleNamespace(obj=obj, b=\"Bee\")\n        self.try_render(\"{{obj2.obj.a}} {{obj2.b}}\", locals(), \"Ay Bee\")\n\n    def test_member_function(self) -> None:\n        # Variables' member functions can be used, as long as they are nullary.\n        class WithMemberFns(SimpleNamespace):\n            \"\"\"A class to try out member function access.\"\"\"\n            def ditto(self) -> str:\n                \"\"\"Return twice the .txt attribute.\"\"\"\n                return self.txt + self.txt          # type: ignore\n        obj = WithMemberFns(txt=\"Once\")\n        self.try_render(\"{{obj.ditto}}\", locals(), \"OnceOnce\")\n\n    def test_item_access(self) -> None:\n        # Variables' items can be used.\n        d = {'a':17, 'b':23}\n        self.try_render(\"{{d.a}} < {{d.b}}\", locals(), \"17 < 23\")\n\n    def test_loops(self) -> None:\n        # Loops work like in Django.\n        nums = [1,2,3,4]\n        self.try_render(\n            \"Look: {% for n in nums %}{{n}}, {% endfor %}done.\",\n            locals(),\n            \"Look: 1, 2, 3, 4, done.\",\n        )\n        # Loop iterables can be filtered.\n        def rev(l: list[int]) -> list[int]:\n            \"\"\"Return the reverse of `l`.\"\"\"\n            l = l[:]\n            l.reverse()\n            return l\n\n        self.try_render(\n            \"Look: {% for n in nums|rev %}{{n}}, {% endfor %}done.\",\n            locals(),\n            \"Look: 4, 3, 2, 1, done.\",\n        )\n\n    def test_empty_loops(self) -> None:\n        self.try_render(\n            \"Empty: {% for n in nums %}{{n}}, {% endfor %}done.\",\n            {'nums':[]},\n            \"Empty: done.\",\n        )\n\n    def test_multiline_loops(self) -> None:\n        self.try_render(\n            \"Look: \\n{% for n in nums %}\\n{{n}}, \\n{% endfor %}done.\",\n            {'nums':[1,2,3]},\n            \"Look: \\n\\n1, \\n\\n2, \\n\\n3, \\ndone.\",\n        )\n\n    def test_multiple_loops(self) -> None:\n        self.try_render(\n            \"{% for n in nums %}{{n}}{% endfor %} and \" +\n                                    \"{% for n in nums %}{{n}}{% endfor %}\",\n            {'nums': [1,2,3]},\n            \"123 and 123\",\n        )\n\n    def test_comments(self) -> None:\n        # Single-line comments work:\n        self.try_render(\n            \"Hello, {# Name goes here: #}{{name}}!\",\n            {'name':'Ned'}, \"Hello, Ned!\",\n        )\n        # and so do multi-line comments:\n        self.try_render(\n            \"Hello, {# Name\\ngoes\\nhere: #}{{name}}!\",\n            {'name':'Ned'}, \"Hello, Ned!\",\n        )\n\n    def test_if(self) -> None:\n        self.try_render(\n            \"Hi, {% if ned %}NED{% endif %}{% if ben %}BEN{% endif %}!\",\n            {'ned': 1, 'ben': 0},\n            \"Hi, NED!\",\n        )\n        self.try_render(\n            \"Hi, {% if ned %}NED{% endif %}{% if ben %}BEN{% endif %}!\",\n            {'ned': 0, 'ben': 1},\n            \"Hi, BEN!\",\n        )\n        self.try_render(\n            \"Hi, {% if ned %}NED{% if ben %}BEN{% endif %}{% endif %}!\",\n            {'ned': 0, 'ben': 0},\n            \"Hi, !\",\n        )\n        self.try_render(\n            \"Hi, {% if ned %}NED{% if ben %}BEN{% endif %}{% endif %}!\",\n            {'ned': 1, 'ben': 0},\n            \"Hi, NED!\",\n        )\n        self.try_render(\n            \"Hi, {% if ned %}NED{% if ben %}BEN{% endif %}{% endif %}!\",\n            {'ned': 1, 'ben': 1},\n            \"Hi, NEDBEN!\",\n        )\n\n    def test_complex_if(self) -> None:\n        class Complex(SimpleNamespace):\n            \"\"\"A class to try out complex data access.\"\"\"\n            def getit(self):            # type: ignore\n                \"\"\"Return it.\"\"\"\n                return self.it\n        obj = Complex(it={'x':\"Hello\", 'y': 0})\n        self.try_render(\n            \"@\" +\n            \"{% if obj.getit.x %}X{% endif %}\" +\n            \"{% if obj.getit.y %}Y{% endif %}\" +\n            \"{% if obj.getit.y|str %}S{% endif %}\" +\n            \"!\",\n            { 'obj': obj, 'str': str },\n            \"@XS!\",\n        )\n\n    def test_loop_if(self) -> None:\n        self.try_render(\n            \"@{% for n in nums %}{% if n %}Z{% endif %}{{n}}{% endfor %}!\",\n            {'nums': [0,1,2]},\n            \"@0Z1Z2!\",\n        )\n        self.try_render(\n            \"X{%if nums%}@{% for n in nums %}{{n}}{% endfor %}{%endif%}!\",\n            {'nums': [0,1,2]},\n            \"X@012!\",\n        )\n        self.try_render(\n            \"X{%if nums%}@{% for n in nums %}{{n}}{% endfor %}{%endif%}!\",\n            {'nums': []},\n            \"X!\",\n        )\n\n    def test_nested_loops(self) -> None:\n        self.try_render(\n            \"@\" +\n            \"{% for n in nums %}\" +\n                \"{% for a in abc %}{{a}}{{n}}{% endfor %}\" +\n            \"{% endfor %}\" +\n            \"!\",\n            {'nums': [0,1,2], 'abc': ['a', 'b', 'c']},\n            \"@a0b0c0a1b1c1a2b2c2!\",\n        )\n\n    def test_whitespace_handling(self) -> None:\n        self.try_render(\n            \"@{% for n in nums %}\\n\" +\n            \" {% for a in abc %}{{a}}{{n}}{% endfor %}\\n\" +\n            \"{% endfor %}!\\n\",\n            {'nums': [0, 1, 2], 'abc': ['a', 'b', 'c']},\n            \"@\\n a0b0c0\\n\\n a1b1c1\\n\\n a2b2c2\\n!\\n\",\n        )\n        self.try_render(\n            \"@{% for n in nums -%}\\n\" +\n            \" {% for a in abc -%}\\n\" +\n            \"  {# this disappears completely -#}\\n\" +\n            \"  {{a-}}\\n\" +\n            \"  {{n -}}\\n\" +\n            \"  {{n    -}}\\n\" +\n            \" {% endfor %}\\n\" +\n            \"{% endfor %}!\\n\",\n            {'nums': [0, 1, 2], 'abc': ['a', 'b', 'c']},\n            \"@a00b00c00\\na11b11c11\\na22b22c22\\n!\\n\",\n        )\n        self.try_render(\n            \"@{% for n in nums -%}\\n\" +\n            \"  {{n -}}\\n\" +\n            \"  x\\n\" +\n            \"{% endfor %}!\\n\",\n            {'nums': [0, 1, 2]},\n            \"@0x\\n1x\\n2x\\n!\\n\",\n        )\n        self.try_render(\"  hello  \", {}, \"  hello  \")\n\n    def test_eat_whitespace(self) -> None:\n        self.try_render(\n            \"Hey!\\n\" +\n            \"{% joined %}\\n\" +\n            \"@{% for n in nums %}\\n\" +\n            \" {% for a in abc %}\\n\" +\n            \"  {# this disappears completely #}\\n\" +\n            \"  X\\n\" +\n            \"  Y\\n\" +\n            \"  {{a}}\\n\" +\n            \"  {{n }}\\n\" +\n            \" {% endfor %}\\n\" +\n            \"{% endfor %}!\\n\" +\n            \"{% endjoined %}\\n\",\n            {'nums': [0, 1, 2], 'abc': ['a', 'b', 'c']},\n            \"Hey!\\n@XYa0XYb0XYc0XYa1XYb1XYc1XYa2XYb2XYc2!\\n\",\n        )\n\n    def test_non_ascii(self) -> None:\n        self.try_render(\n            \"{{where}} oll\u01dd\u0265\",\n            { 'where': '\u01dd\u0279\u01dd\u0265\u0287' },\n            \"\u01dd\u0279\u01dd\u0265\u0287 oll\u01dd\u0265\",\n        )\n\n    def test_exception_during_evaluation(self) -> None:\n        # TypeError: Couldn't evaluate {{ foo.bar.baz }}:\n        regex = \"^Couldn't evaluate None.bar$\"\n        with pytest.raises(TempliteValueError, match=regex):\n            self.try_render(\n                \"Hey {{foo.bar.baz}} there\", {'foo': None}, \"Hey ??? there\",\n            )\n\n    def test_bad_names(self) -> None:\n        with self.assertSynErr(\"Not a valid name: 'var%&!@'\"):\n            self.try_render(\"Wat: {{ var%&!@ }}\")\n        with self.assertSynErr(\"Not a valid name: 'filter%&!@'\"):\n            self.try_render(\"Wat: {{ foo|filter%&!@ }}\")\n        with self.assertSynErr(\"Not a valid name: '@'\"):\n            self.try_render(\"Wat: {% for @ in x %}{% endfor %}\")\n\n    def test_bogus_tag_syntax(self) -> None:\n        with self.assertSynErr(\"Don't understand tag: 'bogus'\"):\n            self.try_render(\"Huh: {% bogus %}!!{% endbogus %}??\")\n\n    def test_malformed_if(self) -> None:\n        with self.assertSynErr(\"Don't understand if: '{% if %}'\"):\n            self.try_render(\"Buh? {% if %}hi!{% endif %}\")\n        with self.assertSynErr(\"Don't understand if: '{% if this or that %}'\"):\n            self.try_render(\"Buh? {% if this or that %}hi!{% endif %}\")\n\n    def test_malformed_for(self) -> None:\n        with self.assertSynErr(\"Don't understand for: '{% for %}'\"):\n            self.try_render(\"Weird: {% for %}loop{% endfor %}\")\n        with self.assertSynErr(\"Don't understand for: '{% for x from y %}'\"):\n            self.try_render(\"Weird: {% for x from y %}loop{% endfor %}\")\n        with self.assertSynErr(\"Don't understand for: '{% for x, y in z %}'\"):\n            self.try_render(\"Weird: {% for x, y in z %}loop{% endfor %}\")\n\n    def test_bad_nesting(self) -> None:\n        with self.assertSynErr(\"Unmatched action tag: 'if'\"):\n            self.try_render(\"{% if x %}X\")\n        with self.assertSynErr(\"Mismatched end tag: 'for'\"):\n            self.try_render(\"{% if x %}X{% endfor %}\")\n        with self.assertSynErr(\"Too many ends: '{% endif %}'\"):\n            self.try_render(\"{% if x %}{% endif %}{% endif %}\")\n\n    def test_malformed_end(self) -> None:\n        with self.assertSynErr(\"Don't understand end: '{% end if %}'\"):\n            self.try_render(\"{% if x %}X{% end if %}\")\n        with self.assertSynErr(\"Don't understand end: '{% endif now %}'\"):\n            self.try_render(\"{% if x %}X{% endif now %}\")\n", "tests/test_json.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Test json-based summary reporting for coverage.py\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport os\n\nfrom datetime import datetime\nfrom typing import Any\n\nimport coverage\nfrom coverage import Coverage\nfrom coverage.jsonreport import FORMAT_VERSION\n\nfrom tests.coveragetest import UsingModulesMixin, CoverageTest\n\n\nclass JsonReportTest(UsingModulesMixin, CoverageTest):\n    \"\"\"Tests of the JSON reports from coverage.py.\"\"\"\n\n    def _assert_expected_json_report(\n        self,\n        cov: Coverage,\n        expected_result: dict[str, Any],\n    ) -> None:\n        \"\"\"\n        Helper that handles common ceremonies so tests can clearly show the\n        consequences of setting various arguments.\n        \"\"\"\n        self.make_file(\"a.py\", \"\"\"\\\n            a = {'b': 1}\n            if a.get('a'):\n                b = 1\n            elif a.get('b'):\n                b = 2\n            else:\n                b = 3\n            if not a:\n                b = 4\n            \"\"\")\n        a = self.start_import_stop(cov, \"a\")\n        output_path = os.path.join(self.temp_dir, \"a.json\")\n        cov.json_report(a, outfile=output_path)\n        with open(output_path) as result_file:\n            parsed_result = json.load(result_file)\n        self.assert_recent_datetime(\n            datetime.strptime(parsed_result['meta']['timestamp'], \"%Y-%m-%dT%H:%M:%S.%f\"),\n        )\n        del (parsed_result['meta']['timestamp'])\n        expected_result[\"meta\"].update({\n            \"format\": FORMAT_VERSION,\n            \"version\": coverage.__version__,\n        })\n        assert parsed_result == expected_result\n\n    def test_branch_coverage(self) -> None:\n        cov = coverage.Coverage(branch=True)\n        expected_result = {\n            'meta': {\n                \"branch_coverage\": True,\n                \"show_contexts\": False,\n            },\n            'files': {\n                'a.py': {\n                    'executed_lines': [1, 2, 4, 5, 8],\n                    'missing_lines': [3, 7, 9],\n                    'excluded_lines': [],\n                    'executed_branches': [\n                        [2, 4],\n                        [4, 5],\n                        [8, -1],\n                    ],\n                    'missing_branches': [\n                        [2, 3],\n                        [4, 7],\n                        [8, 9],\n                    ],\n                    'summary': {\n                        'missing_lines': 3,\n                        'covered_lines': 5,\n                        'num_statements': 8,\n                        'num_branches': 6,\n                        'excluded_lines': 0,\n                        'num_partial_branches': 3,\n                        'covered_branches': 3,\n                        'missing_branches': 3,\n                        'percent_covered': 57.142857142857146,\n                        'percent_covered_display': '57',\n                    },\n                },\n            },\n            'totals': {\n                'missing_lines': 3,\n                'covered_lines': 5,\n                'num_statements': 8,\n                'num_branches': 6,\n                'excluded_lines': 0,\n                'num_partial_branches': 3,\n                'percent_covered': 57.142857142857146,\n                'percent_covered_display': '57',\n                'covered_branches': 3,\n                'missing_branches': 3,\n            },\n        }\n        self._assert_expected_json_report(cov, expected_result)\n\n    def test_simple_line_coverage(self) -> None:\n        cov = coverage.Coverage()\n        expected_result = {\n            'meta': {\n                \"branch_coverage\": False,\n                \"show_contexts\": False,\n            },\n            'files': {\n                'a.py': {\n                    'executed_lines': [1, 2, 4, 5, 8],\n                    'missing_lines': [3, 7, 9],\n                    'excluded_lines': [],\n                    'summary': {\n                        'excluded_lines': 0,\n                        'missing_lines': 3,\n                        'covered_lines': 5,\n                        'num_statements': 8,\n                        'percent_covered': 62.5,\n                        'percent_covered_display': '62',\n                    },\n                },\n            },\n            'totals': {\n                'excluded_lines': 0,\n                'missing_lines': 3,\n                'covered_lines': 5,\n                'num_statements': 8,\n                'percent_covered': 62.5,\n                'percent_covered_display': '62',\n            },\n        }\n        self._assert_expected_json_report(cov, expected_result)\n\n    def run_context_test(self, relative_files: bool) -> None:\n        \"\"\"A helper for two tests below.\"\"\"\n        self.make_file(\"config\", f\"\"\"\\\n            [run]\n            relative_files = {relative_files}\n\n            [report]\n            precision = 2\n\n            [json]\n            show_contexts = True\n            \"\"\")\n        cov = coverage.Coverage(context=\"cool_test\", config_file=\"config\")\n        expected_result = {\n            'meta': {\n                \"branch_coverage\": False,\n                \"show_contexts\": True,\n            },\n            'files': {\n                'a.py': {\n                    'executed_lines': [1, 2, 4, 5, 8],\n                    'missing_lines': [3, 7, 9],\n                    'excluded_lines': [],\n                    \"contexts\": {\n                        \"1\": [\n                            \"cool_test\",\n                        ],\n                        \"2\": [\n                            \"cool_test\",\n                        ],\n                        \"4\": [\n                            \"cool_test\",\n                        ],\n                        \"5\": [\n                            \"cool_test\",\n                        ],\n                        \"8\": [\n                            \"cool_test\",\n                        ],\n                    },\n                    'summary': {\n                        'excluded_lines': 0,\n                        'missing_lines': 3,\n                        'covered_lines': 5,\n                        'num_statements': 8,\n                        'percent_covered': 62.5,\n                        'percent_covered_display': '62.50',\n                    },\n                },\n            },\n            'totals': {\n                'excluded_lines': 0,\n                'missing_lines': 3,\n                'covered_lines': 5,\n                'num_statements': 8,\n                'percent_covered': 62.5,\n                'percent_covered_display': '62.50',\n            },\n        }\n        self._assert_expected_json_report(cov, expected_result)\n\n    def test_context_non_relative(self) -> None:\n        self.run_context_test(relative_files=False)\n\n    def test_context_relative(self) -> None:\n        self.run_context_test(relative_files=True)\n", "tests/zipsrc/zip1/zip1.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n# My zip file!\n\nlighter = \"Zippo\"\nsays = \"coo-coo cachoo\"\n", "tests/zipsrc/zip1/__init__.py": "", "tests/moremodules/othermods/othera.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\no = 1\np = 2\n", "tests/moremodules/othermods/otherb.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nq = 3\nr = 4\n", "tests/moremodules/othermods/__init__.py": "", "tests/moremodules/othermods/sub/osa.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\ns = 5\nt = 6\n", "tests/moremodules/othermods/sub/__init__.py": "", "tests/moremodules/othermods/sub/osb.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nu = 7\nv = 8\n", "tests/moremodules/namespace_420/sub2/__init__.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nsub2 = \"namespace_420 sub2\"\n", "tests/modules/covmod1.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n# covmod1.py: Simplest module for testing.\ni = 1\ni += 1\n", "tests/modules/runmod1.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n# Used in the tests for PyRunner\nimport sys\nprint(\"runmod1: passed %s\" % sys.argv[1])\n", "tests/modules/usepkgs.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nimport pkg1.p1a, pkg1.p1b, pkg1.sub\nimport pkg2.p2a, pkg2.p2b\nimport othermods.othera, othermods.otherb\nimport othermods.sub.osa, othermods.sub.osb\nimport ambiguous, ambiguous.pkg1.ambiguous\n", "tests/modules/plugins/another.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"A plugin for tests to reference.\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any\n\nfrom coverage import CoveragePlugin\nfrom coverage.plugin_support import Plugins\n\nclass Plugin(CoveragePlugin):\n    pass\n\n\ndef coverage_init(\n    reg: Plugins,\n    options: Any,       # pylint: disable=unused-argument\n) -> None:\n    reg.add_file_tracer(Plugin())\n", "tests/modules/plugins/a_plugin.py": "\"\"\"A plugin for tests to reference.\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any\n\nfrom coverage import CoveragePlugin\nfrom coverage.plugin_support import Plugins\n\n\nclass Plugin(CoveragePlugin):\n    pass\n\n\ndef coverage_init(\n    reg: Plugins,\n    options: Any,       # pylint: disable=unused-argument\n) -> None:\n    reg.add_file_tracer(Plugin())\n", "tests/modules/plugins/__init__.py": "", "tests/modules/namespace_420/sub1/__init__.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nsub1 = \"namespace_420 sub1\"\n", "tests/modules/ambiguous/__init__.py": "", "tests/modules/ambiguous/pkg1/ambiguous.py": "amb = 1\namb = 2\n", "tests/modules/ambiguous/pkg1/__init__.py": "print(\"Ambiguous pkg1\")\n", "tests/modules/process_test/__init__.py": "", "tests/modules/process_test/try_execfile.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Test file for run_python_file.\n\nThis file is executed two ways::\n\n    $ coverage run try_execfile.py\n\nand::\n\n    $ python try_execfile.py\n\nThe output is compared to see that the program execution context is the same\nunder coverage and under Python.\n\nIt is not crucial that the execution be identical, there are some differences\nthat are OK.  This program canonicalizes the output to gloss over those\ndifferences and get a clean diff.\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport itertools\nimport json\nimport os\nimport sys\n\nfrom typing import Any, List\n\n# sys.path varies by execution environments.  Some installation libraries\n# removes duplicate entries from sys.path.  So we do that too, since the extra\n# entries don't affect the running of the program.\n\ndef same_file(p1: str, p2: str) -> bool:\n    \"\"\"Determine if `p1` and `p2` refer to the same existing file.\"\"\"\n    if not p1:\n        return not p2\n    if not os.path.exists(p1):\n        return False\n    if not os.path.exists(p2):\n        return False\n    if hasattr(os.path, \"samefile\"):\n        return os.path.samefile(p1, p2)\n    else:\n        norm1 = os.path.normcase(os.path.normpath(p1))\n        norm2 = os.path.normcase(os.path.normpath(p2))\n        return norm1 == norm2\n\ndef without_same_files(filenames: List[str]) -> List[str]:\n    \"\"\"Return the list `filenames` with duplicates (by same_file) removed.\"\"\"\n    reduced: List[str] = []\n    for filename in filenames:\n        if not any(same_file(filename, other) for other in reduced):\n            reduced.append(filename)\n    return reduced\n\ncleaned_sys_path = [os.path.normcase(p) for p in without_same_files(sys.path)]\n\nDATA = \"xyzzy\"\n\nimport __main__\n\ndef my_function(a: Any) -> str:\n    \"\"\"A function to force execution of module-level values.\"\"\"\n    return f\"my_fn({a!r})\"\n\nFN_VAL = my_function(\"fooey\")\n\nloader = globals().get('__loader__')\nspec = globals().get('__spec__')\n\n# A more compact ad-hoc grouped-by-first-letter list of builtins.\nCLUMPS = \"ABC,DEF,GHI,JKLMN,OPQR,ST,U,VWXYZ_,ab,cd,efg,hij,lmno,pqr,stuvwxyz\".split(\",\")\n\ndef word_group(w: str) -> int:\n    \"\"\"Figure out which CLUMP the first letter of w is in.\"\"\"\n    for i, clump in enumerate(CLUMPS):\n        if w[0] in clump:\n            return i\n    return 99\n\nbuiltin_dir = [\" \".join(s) for _, s in itertools.groupby(dir(__builtins__), key=word_group)]\n\nglobals_to_check = {\n    'os.getcwd': os.getcwd(),\n    '__name__': __name__,\n    '__file__': os.path.normcase(__file__),\n    '__doc__': __doc__,\n    '__builtins__.has_open': hasattr(__builtins__, 'open'),\n    '__builtins__.dir': builtin_dir,\n    '__loader__ exists': loader is not None,\n    '__package__': __package__,\n    '__spec__ exists': spec is not None,\n    'DATA': DATA,\n    'FN_VAL': FN_VAL,\n    '__main__.DATA': getattr(__main__, \"DATA\", \"nothing\"),\n    'argv0': sys.argv[0],\n    'argv1-n': sys.argv[1:],\n    'path': cleaned_sys_path,\n}\n\nif loader is not None:\n    globals_to_check.update({\n        '__loader__.fullname': getattr(loader, 'fullname', None) or getattr(loader, 'name', None),\n    })\n\nif spec is not None:\n    globals_to_check.update({\n        '__spec__.' + aname: getattr(spec, aname)\n        for aname in ['name', 'origin', 'submodule_search_locations', 'parent', 'has_location']\n    })\n\nprint(json.dumps(globals_to_check, indent=4, sort_keys=True))\n", "tests/modules/pkg2/p2b.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nt = 1\nu = 1\nv = 1\n", "tests/modules/pkg2/p2a.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nq = 1\nr = 1\ns = 1\n", "tests/modules/pkg2/__init__.py": "# This is an __init__.py file, with no executable statements in it.\n# This comment shouldn't confuse the parser.\n", "tests/modules/aa/afile.py": "# afile.py\n", "tests/modules/aa/afile.odd.py": "# afile.odd.py\n", "tests/modules/aa/zfile.py": "# zfile.py\n", "tests/modules/aa/__init__.py": "# aa\n", "tests/modules/aa/bb.odd/bfile.py": "# bfile.py\n", "tests/modules/aa/bb/bfile.odd.py": "# bfile.odd.py\n", "tests/modules/aa/bb/__init__.py": "# bb\n", "tests/modules/aa/bb/bfile.py": "# bfile.py\n", "tests/modules/aa/bb/cc/cfile.py": "# cfile.py\n", "tests/modules/aa/bb/cc/__init__.py": "", "tests/modules/pkg1/p1a.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nimport os, sys\n\n# Invoke functions in os and sys so we can see if we measure code there.\nx = sys.getfilesystemencoding()\ny = os.getcwd()\n", "tests/modules/pkg1/p1b.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nx = 1\ny = 2\nz = 3\n", "tests/modules/pkg1/runmod2.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n# Used in the tests for PyRunner\nimport sys\nprint(\"runmod2: passed %s\" % sys.argv[1])\n", "tests/modules/pkg1/__main__.py": "# Used in the tests for PyRunner\nimport sys\nprint(\"pkg1.__main__: passed %s\" % sys.argv[1])\n", "tests/modules/pkg1/p1c.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\na = 1\nb = 2\nc = 3\n", "tests/modules/pkg1/__init__.py": "# A simple package for testing with.\nprint(f\"pkg1.__init__: {__name__}\")\n", "tests/modules/pkg1/sub/runmod3.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n# Used in the tests for PyRunner\nimport sys\nprint(\"runmod3: passed %s\" % sys.argv[1])\n", "tests/modules/pkg1/sub/__main__.py": "# Used in the tests for PyRunner\nimport sys\nprint(\"pkg1.sub.__main__: passed %s\" % sys.argv[1])\n", "tests/modules/pkg1/sub/__init__.py": "", "tests/modules/pkg1/sub/ps1a.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nd = 1\ne = 2\nf = 3\n", "lab/parse_all.py": "\"\"\"Parse every Python file in a tree.\"\"\"\n\nimport os\nimport sys\n\nfrom coverage.parser import PythonParser\n\nfor root, dirnames, filenames in os.walk(sys.argv[1]):\n    for filename in filenames:\n        if filename.endswith(\".py\"):\n            filename = os.path.join(root, filename)\n            print(f\":: {filename}\")\n            try:\n                par = PythonParser(filename=filename)\n                par.parse_source()\n                par.arcs()\n            except Exception as exc:\n                print(f\"  ** {exc}\")\n", "lab/run_sysmon.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Run sys.monitoring on a file of Python code.\"\"\"\n\nimport functools\nimport sys\n\nprint(sys.version)\nthe_program = sys.argv[1]\n\ncode = open(the_program).read()\n\nmy_id = sys.monitoring.COVERAGE_ID\nsys.monitoring.use_tool_id(my_id, \"run_sysmon.py\")\nregister = functools.partial(sys.monitoring.register_callback, my_id)\nevents = sys.monitoring.events\n\n\ndef bytes_to_lines(code):\n    \"\"\"Make a dict mapping byte code offsets to line numbers.\"\"\"\n    b2l = {}\n    cur_line = 0\n    for bstart, bend, lineno in code.co_lines():\n        for boffset in range(bstart, bend, 2):\n            b2l[boffset] = lineno\n    return b2l\n\n\ndef sysmon_py_start(code, instruction_offset):\n    print(f\"PY_START: {code.co_filename}@{instruction_offset}\")\n    sys.monitoring.set_local_events(\n        my_id,\n        code,\n        events.PY_RETURN | events.PY_RESUME | events.LINE | events.BRANCH | events.JUMP,\n    )\n\n\ndef sysmon_py_resume(code, instruction_offset):\n    b2l = bytes_to_lines(code)\n    print(\n        f\"PY_RESUME: {code.co_filename}@{instruction_offset}, \"\n        + f\"{b2l[instruction_offset]}\"\n    )\n\n\ndef sysmon_py_return(code, instruction_offset, retval):\n    b2l = bytes_to_lines(code)\n    print(\n        f\"PY_RETURN: {code.co_filename}@{instruction_offset}, \"\n        + f\"{b2l[instruction_offset]}\"\n    )\n\n\ndef sysmon_line(code, line_number):\n    print(f\"LINE: {code.co_filename}@{line_number}\")\n    return sys.monitoring.DISABLE\n\n\ndef sysmon_branch(code, instruction_offset, destination_offset):\n    b2l = bytes_to_lines(code)\n    print(\n        f\"BRANCH: {code.co_filename}@{instruction_offset}->{destination_offset}, \"\n        + f\"{b2l[instruction_offset]}->{b2l[destination_offset]}\"\n    )\n\n\ndef sysmon_jump(code, instruction_offset, destination_offset):\n    b2l = bytes_to_lines(code)\n    print(\n        f\"JUMP: {code.co_filename}@{instruction_offset}->{destination_offset}, \"\n        + f\"{b2l[instruction_offset]}->{b2l[destination_offset]}\"\n    )\n\n\nsys.monitoring.set_events(\n    my_id,\n    events.PY_START | events.PY_UNWIND,\n)\nregister(events.PY_START, sysmon_py_start)\nregister(events.PY_RESUME, sysmon_py_resume)\nregister(events.PY_RETURN, sysmon_py_return)\n# register(events.PY_UNWIND, sysmon_py_unwind_arcs)\nregister(events.LINE, sysmon_line)\nregister(events.BRANCH, sysmon_branch)\nregister(events.JUMP, sysmon_jump)\n\nexec(code)\n", "lab/run_trace.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Run a simple trace function on a file of Python code.\"\"\"\n\nimport os, sys\n\nnest = 0\n\ndef trace(frame, event, arg):\n    global nest\n\n    if nest is None:\n        # This can happen when Python is shutting down.\n        return None\n\n    print(\"%s%s %s %d @%d\" % (\n        \"    \" * nest,\n        event,\n        os.path.basename(frame.f_code.co_filename),\n        frame.f_lineno,\n        frame.f_lasti,\n    ))\n\n    if event == 'call':\n        nest += 1\n    if event == 'return':\n        nest -= 1\n\n    return trace\n\nprint(sys.version)\nthe_program = sys.argv[1]\n\ncode = open(the_program).read()\nsys.settrace(trace)\nexec(code)\n", "lab/goals.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\\\nCheck coverage goals.\n\nUse `coverage json` to get a coverage.json file, then run this tool\nto check goals for subsets of files.\n\nPatterns can use '**/foo*.py' to find files anywhere in the project,\nand '!**/something.py' to exclude files matching a pattern.\n\n--file will check each file individually for the required coverage.\n--group checks the entire group collectively.\n\n\"\"\"\n\nimport argparse\nimport json\nimport sys\n\nfrom wcmatch import fnmatch as wcfnmatch    # python -m pip install wcmatch\n\nfrom coverage.results import Numbers        # Note: an internal class!\n\n\ndef select_files(files, pat):\n    flags = wcfnmatch.NEGATE | wcfnmatch.NEGATEALL\n    selected = [f for f in files if wcfnmatch.fnmatch(f, pat, flags=flags)]\n    return selected\n\ndef total_for_files(data, files):\n    total = Numbers(precision=3)\n    for f in files:\n        sel_summ = data[\"files\"][f][\"summary\"]\n        total += Numbers(\n            n_statements=sel_summ[\"num_statements\"],\n            n_excluded=sel_summ[\"excluded_lines\"],\n            n_missing=sel_summ[\"missing_lines\"],\n            n_branches=sel_summ.get(\"num_branches\", 0),\n            n_partial_branches=sel_summ.get(\"num_partial_branches\", 0),\n            n_missing_branches=sel_summ.get(\"missing_branches\", 0),\n        )\n\n    return total\n\ndef main(argv):\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"--file\", \"-f\", action=\"store_true\", help=\"Check each file individually\")\n    parser.add_argument(\"--group\", \"-g\", action=\"store_true\", help=\"Check a group of files\")\n    parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\", help=\"Be chatty about what's happening\")\n    parser.add_argument(\"goal\", type=float, help=\"Coverage goal\")\n    parser.add_argument(\"pattern\", type=str, nargs=\"+\", help=\"Patterns to check\")\n    args = parser.parse_args(argv)\n\n    print(\"** Note: this is a proof-of-concept. Support is not promised. **\")\n    print(\"Read more: https://nedbatchelder.com/blog/202111/coverage_goals.html\")\n    print(\"Feedback is appreciated: https://github.com/nedbat/coveragepy/issues/691\")\n\n    if args.file and args.group:\n        print(\"Can't use --file and --group together\")\n        return 1\n    if not (args.file or args.group):\n        print(\"Need either --file or --group\")\n        return 1\n\n    with open(\"coverage.json\") as j:\n        data = json.load(j)\n    all_files = list(data[\"files\"].keys())\n    selected = select_files(all_files, args.pattern)\n\n    ok = True\n    if args.group:\n        total = total_for_files(data, selected)\n        pat_nice = \",\".join(args.pattern)\n        result = f\"Coverage for {pat_nice} is {total.pc_covered_str}\"\n        if total.pc_covered < args.goal:\n            print(f\"{result}, below {args.goal}\")\n            ok = False\n        elif args.verbose:\n            print(result)\n    else:\n        for fname in selected:\n            total = total_for_files(data, [fname])\n            result = f\"Coverage for {fname} is {total.pc_covered_str}\"\n            if total.pc_covered < args.goal:\n                print(f\"{result}, below {args.goal}\")\n                ok = False\n            elif args.verbose:\n                print(result)\n\n    return 0 if ok else 2\n\nif __name__ == \"__main__\":\n    sys.exit(main(sys.argv[1:]))\n", "lab/genpy.py": "\"\"\"Generate random Python for testing.\"\"\"\n\nimport collections\nfrom itertools import cycle, product\nimport random\nimport re\n\nfrom coverage.parser import PythonParser\n\n\nclass PythonSpinner:\n    \"\"\"Spin Python source from a simple AST.\"\"\"\n\n    def __init__(self):\n        self.lines = []\n        self.lines.append(\"async def func():\")\n        self.indent = 4\n\n    @property\n    def lineno(self):\n        return len(self.lines) + 1\n\n    @classmethod\n    def generate_python(cls, ast):\n        spinner = cls()\n        spinner.gen_python_internal(ast)\n        return \"\\n\".join(spinner.lines)\n\n    def add_line(self, line):\n        g = f\"g{self.lineno}\"\n        self.lines.append(' ' * self.indent + line.format(g=g, lineno=self.lineno))\n\n    def add_block(self, node):\n        self.indent += 4\n        self.gen_python_internal(node)\n        self.indent -= 4\n\n    def maybe_block(self, node, nodei, keyword):\n        if len(node) > nodei and node[nodei] is not None:\n            self.add_line(keyword + \":\")\n            self.add_block(node[nodei])\n\n    def gen_python_internal(self, ast):\n        for node in ast:\n            if isinstance(node, list):\n                op = node[0]\n                if op == \"if\":\n                    self.add_line(\"if {g}:\")\n                    self.add_block(node[1])\n                    self.maybe_block(node, 2, \"else\")\n                elif op == \"for\":\n                    self.add_line(\"for x in {g}:\")\n                    self.add_block(node[1])\n                    self.maybe_block(node, 2, \"else\")\n                elif op == \"while\":\n                    self.add_line(\"while {g}:\")\n                    self.add_block(node[1])\n                    self.maybe_block(node, 2, \"else\")\n                elif op == \"try\":\n                    self.add_line(\"try:\")\n                    self.add_block(node[1])\n                    # 'except' clauses are different, because there can be any\n                    # number.\n                    if len(node) > 2 and node[2] is not None:\n                        for except_node in node[2]:\n                            self.add_line(f\"except Exception{self.lineno}:\")\n                            self.add_block(except_node)\n                    self.maybe_block(node, 3, \"else\")\n                    self.maybe_block(node, 4, \"finally\")\n                elif op == \"with\":\n                    self.add_line(\"with {g} as x:\")\n                    self.add_block(node[1])\n                else:\n                    raise Exception(f\"Bad list node: {node!r}\")\n            else:\n                op = node\n                if op == \"assign\":\n                    self.add_line(\"x = {lineno}\")\n                elif op in [\"break\", \"continue\"]:\n                    self.add_line(op)\n                elif op == \"return\":\n                    self.add_line(\"return\")\n                elif op == \"yield\":\n                    self.add_line(\"yield {lineno}\")\n                else:\n                    raise Exception(f\"Bad atom node: {node!r}\")\n\n\ndef weighted_choice(rand, choices):\n    \"\"\"Choose from a list of [(choice, weight), ...] options, randomly.\"\"\"\n    total = sum(w for c, w in choices)\n    r = rand.uniform(0, total)\n    upto = 0\n    for c, w in choices:\n        if upto + w >= r:\n            return c\n        upto += w\n    assert False, \"Shouldn't get here\"\n\n\nclass RandomAstMaker:\n    def __init__(self, seed=None):\n        self.r = random.Random()\n        if seed is not None:\n            self.r.seed(seed)\n        self.depth = 0\n        self.bc_allowed = set()\n\n    def roll(self, prob=0.5):\n        return self.r.random() <= prob\n\n    def choose(self, choices):\n        \"\"\"Roll the dice to choose an option.\"\"\"\n        return weighted_choice(self.r, choices)\n\n    STMT_CHOICES = [\n        [(\"if\", 10), (\"for\", 10), (\"try\", 10), (\"while\", 3), (\"with\", 10), (\"assign\", 20), (\"return\", 1), (\"yield\", 0)],\n        [(\"if\", 10), (\"for\", 10), (\"try\", 10), (\"while\", 3), (\"with\", 10), (\"assign\", 40), (\"return\", 1), (\"yield\", 0), (\"break\", 10), (\"continue\", 10)],\n        [(\"if\", 10), (\"for\", 10), (\"try\", 10), (\"while\", 3), (\"with\", 10), (\"assign\", 40), (\"return\", 1), (\"yield\", 0), (\"break\", 10), (\"continue\", 10)],\n        [(\"if\", 10), (\"for\", 10), (\"try\", 10), (\"while\", 3), (\"with\", 10), (\"assign\", 40), (\"return\", 1), (\"yield\", 0), (\"break\", 10), (\"continue\", 10)],\n        [(\"if\", 10), (\"for\", 10), (\"try\", 10), (\"while\", 3), (\"with\", 10), (\"assign\", 40), (\"return\", 1), (\"yield\", 0), (\"break\", 10), (\"continue\", 10)],\n        # Last element has to have no compound statements, to limit depth.\n        [(\"assign\", 10), (\"return\", 1), (\"yield\", 0), (\"break\", 10), (\"continue\", 10)],\n    ]\n\n    def make_body(self, parent):\n        body = []\n        choices = self.STMT_CHOICES[self.depth]\n\n        self.depth += 1\n        nstmts = self.choose([(1, 10), (2, 25), (3, 10), (4, 10), (5, 5)])\n        for _ in range(nstmts):\n            stmt = self.choose(choices)\n            if stmt == \"if\":\n                body.append([\"if\", self.make_body(\"if\")])\n                if self.roll():\n                    body[-1].append(self.make_body(\"ifelse\"))\n            elif stmt == \"for\":\n                old_allowed = self.bc_allowed\n                self.bc_allowed = self.bc_allowed | {\"break\", \"continue\"}\n                body.append([\"for\", self.make_body(\"for\")])\n                self.bc_allowed = old_allowed\n                if self.roll():\n                    body[-1].append(self.make_body(\"forelse\"))\n            elif stmt == \"while\":\n                old_allowed = self.bc_allowed\n                self.bc_allowed = self.bc_allowed | {\"break\", \"continue\"}\n                body.append([\"while\", self.make_body(\"while\")])\n                self.bc_allowed = old_allowed\n                if self.roll():\n                    body[-1].append(self.make_body(\"whileelse\"))\n            elif stmt == \"try\":\n                else_clause = self.make_body(\"try\") if self.roll() else None\n                old_allowed = self.bc_allowed\n                self.bc_allowed = self.bc_allowed - {\"continue\"}\n                finally_clause = self.make_body(\"finally\") if self.roll() else None\n                self.bc_allowed = old_allowed\n                if else_clause:\n                    with_exceptions = True\n                elif not else_clause and not finally_clause:\n                    with_exceptions = True\n                else:\n                    with_exceptions = self.roll()\n                if with_exceptions:\n                    num_exceptions = self.choose([(1, 50), (2, 50)])\n                    exceptions = [self.make_body(\"except\") for _ in range(num_exceptions)]\n                else:\n                    exceptions = None\n                body.append(\n                    [\"try\", self.make_body(\"tryelse\"), exceptions, else_clause, finally_clause]\n                )\n            elif stmt == \"with\":\n                body.append([\"with\", self.make_body(\"with\")])\n            elif stmt == \"return\":\n                body.append(stmt)\n                break\n            elif stmt == \"yield\":\n                body.append(\"yield\")\n            elif stmt in [\"break\", \"continue\"]:\n                if stmt in self.bc_allowed:\n                    # A break or continue immediately after a loop is not\n                    # interesting.  So if we are immediately after a loop, then\n                    # insert an assignment.\n                    if not body and (parent in [\"for\", \"while\"]):\n                        body.append(\"assign\")\n                    body.append(stmt)\n                    break\n                else:\n                    stmt = \"assign\"\n\n            if stmt == \"assign\":\n                # Don't put two assignments in a row, there's no point.\n                if not body or body[-1] != \"assign\":\n                    body.append(\"assign\")\n\n        self.depth -= 1\n        return body\n\n\ndef async_alternatives(source):\n    parts = re.split(r\"(for |with )\", source)\n    nchoices = len(parts) // 2\n    #print(\"{} choices\".format(nchoices))\n\n    def constant(s):\n        return [s]\n\n    def maybe_async(s):\n        return [s, \"async \"+s]\n\n    choices = [f(x) for f, x in zip(cycle([constant, maybe_async]), parts)]\n    for result in product(*choices):\n        source = \"\".join(result)\n        yield source\n\n\ndef compare_alternatives(source):\n    all_all_arcs = collections.defaultdict(list)\n    for i, alternate_source in enumerate(async_alternatives(source)):\n        parser = PythonParser(alternate_source)\n        arcs = parser.arcs()\n        all_all_arcs[tuple(arcs)].append((i, alternate_source))\n\n    return len(all_all_arcs)\n\n\ndef show_a_bunch():\n    longest = \"\"\n    for i in range(100):\n        maker = RandomAstMaker(i)\n        source = PythonSpinner.generate_python(maker.make_body(\"def\"))\n        try:\n            print(\"-\"*80, \"\\n\", source, sep=\"\")\n            compile(source, \"<string>\", \"exec\", dont_inherit=True)\n        except Exception as ex:\n            print(f\"Oops: {ex}\\n{source}\")\n        if len(source) > len(longest):\n            longest = source\n\n\ndef show_alternatives():\n    for i in range(1000):\n        maker = RandomAstMaker(i)\n        source = PythonSpinner.generate_python(maker.make_body(\"def\"))\n        nlines = len(source.splitlines())\n        if nlines < 15:\n            nalt = compare_alternatives(source)\n            if nalt > 1:\n                print(f\"--- {nlines:3} lines, {nalt:2} alternatives ---------\")\n                print(source)\n\n\n\ndef show_one():\n    maker = RandomAstMaker()\n    source = PythonSpinner.generate_python(maker.make_body(\"def\"))\n    print(source)\n\nif __name__ == \"__main__\":\n    show_one()\n    #show_alternatives()\n", "lab/pick.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nPick lines from the standard input.  Blank or commented lines are ignored.\n\nUsed to subset lists of tests to run.  Use with the --select-cmd pytest plugin\noption.\n\nThe first command line argument is a mode for selection. Other arguments depend\non the mode.  Only one mode is currently implemented: sample.\n\nModes:\n\n    - ``sample``: randomly sample N lines from the input.\n\n        - the first argument is N, the number of lines you want.\n\n        - the second argument is optional: a seed for the randomizer.\n          Using the same seed will produce the same output.\n\nExamples:\n\nGet a list of test nodes::\n\n    pytest --collect-only | grep :: > tests.txt\n\nUse like this::\n\n    pytest --cache-clear --select-cmd=\"python pick.py sample 10 < tests.txt\"\n\nFor coverage.py specifically::\n\n    tox -q -e py311 -- -n 0 --cache-clear --select-cmd=\"python lab/pick.py sample 10 < tests.txt\"\n\nor::\n\n    for n in $(seq 1 100); do \\\n        echo seed=$n; \\\n        tox -q -e py311 -- -n 0 --cache-clear --select-cmd=\"python lab/pick.py sample 3 $n < tests.txt\"; \\\n    done\n\nMore about this: https://nedbatchelder.com/blog/202401/randomly_subsetting_test_suites.html\n\n\"\"\"\n\nimport random\nimport sys\n\nargs = sys.argv[1:][::-1]\nnext_arg = args.pop\n\nlines = []\nfor line in sys.stdin:\n    line = line.strip()\n    if not line:\n        continue\n    if line.startswith(\"#\"):\n        continue\n    lines.append(line)\n\nmode = next_arg()\nif mode == \"sample\":\n    number = int(next_arg())\n    if args:\n        random.seed(next_arg())\n    lines = random.sample(lines, number)\nelse:\n    raise ValueError(f\"Don't know {mode=}\")\n\nfor line in lines:\n    print(line)\n", "lab/extract_code.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nUse this to copy some indented code from the coverage.py test suite into a\nstandalone file for deeper testing, or writing bug reports.\n\nGive it a file name and a line number, and it will find the indented\nmulti-line string containing that line number, and output the dedented\ncontents of the string.\n\nIf tests/test_arcs.py has this (partial) content::\n\n    1630\t    def test_partial_generators(self):\n    1631\t        # https://github.com/nedbat/coveragepy/issues/475\n    1632\t        # Line 2 is executed completely.\n    1633\t        # Line 3 is started but not finished, because zip ends before it finishes.\n    1634\t        # Line 4 is never started.\n    1635\t        cov = self.check_coverage('''\\\n    1636\t            def f(a, b):\n    1637\t                c = (i for i in a)          # 2\n    1638\t                d = (j for j in b)          # 3\n    1639\t                e = (k for k in b)          # 4\n    1640\t                return dict(zip(c, d))\n    1641\n    1642\t            f(['a', 'b'], [1, 2, 3])\n    1643\t            ''',\n    1644\t            arcz=\".1 17 7.  .2 23 34 45 5.  -22 2-2  -33 3-3  -44 4-4\",\n    1645\t            arcz_missing=\"3-3 -44 4-4\",\n    1646\t        )\n\nthen you can do::\n\n    % python lab/extract_code.py tests/test_arcs.py 1637\n    def f(a, b):\n        c = (i for i in a)          # 2\n        d = (j for j in b)          # 3\n        e = (k for k in b)          # 4\n        return dict(zip(c, d))\n\n    f(['a', 'b'], [1, 2, 3])\n    %\n\n\"\"\"\n\nimport sys\nimport textwrap\n\nif len(sys.argv) == 2:\n    fname, lineno = sys.argv[1].split(\":\")\nelse:\n    fname, lineno = sys.argv[1:]\nlineno = int(lineno)\n\nwith open(fname) as code_file:\n    lines = [\"\", *code_file]\n\n# Find opening triple-quote\nfor start in range(lineno, 0, -1):\n    line = lines[start]\n    if \"'''\" in line or '\"\"\"' in line:\n        break\n\nfor end in range(lineno+1, len(lines)):\n    line = lines[end]\n    if \"'''\" in line or '\"\"\"' in line:\n        break\n\ncode = \"\".join(lines[start+1: end])\ncode = textwrap.dedent(code)\n\nprint(code, end=\"\")\n", "lab/bpo_prelude.py": "import linecache, sys\n\ndef trace(frame, event, arg):\n    # The weird globals here is to avoid a NameError on shutdown...\n    if frame.f_code.co_filename == globals().get(\"__file__\"):\n        lineno = frame.f_lineno\n        line = linecache.getline(__file__, lineno).rstrip()\n        print(\"{} {}: {}\".format(event[:4], lineno, line))\n    return trace\n\nprint(sys.version)\nsys.settrace(trace)\n\n", "lab/show_platform.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\nimport platform\nimport types\n\nfor n in dir(platform):\n    if n.startswith(\"_\"):\n        continue\n    v = getattr(platform, n)\n    if isinstance(v, types.ModuleType):\n        continue\n    if callable(v):\n        try:\n            v = v()\n            n += \"()\"\n        except:\n            continue\n    print(f\"{n:>30}: {v!r}\")\n", "lab/hack_pyc.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\" Wicked hack to get .pyc files to do bytecode tracing instead of\n    line tracing.\n\"\"\"\n\nimport marshal, new, opcode, sys, types\n\nfrom lnotab import lnotab_numbers, lnotab_string\n\nclass PycFile:\n    def read(self, f):\n        if isinstance(f, basestring):\n            f = open(f, \"rb\")\n        self.magic = f.read(4)\n        self.modtime = f.read(4)\n        self.code = marshal.load(f)\n\n    def write(self, f):\n        if isinstance(f, basestring):\n            f = open(f, \"wb\")\n        f.write(self.magic)\n        f.write(self.modtime)\n        marshal.dump(self.code, f)\n\n    def hack_line_numbers(self):\n        self.code = hack_line_numbers(self.code)\n\ndef hack_line_numbers(code):\n    \"\"\" Replace a code object's line number information to claim that every\n        byte of the bytecode is a new source line.  Returns a new code\n        object.  Also recurses to hack the line numbers in nested code objects.\n    \"\"\"\n\n    # Create a new lnotab table.  Each opcode is claimed to be at\n    # 1000*lineno + (opcode number within line), so for example, the opcodes on\n    # source line 12 will be given new line numbers 12000, 12001, 12002, etc.\n    old_num = list(lnotab_numbers(code.co_lnotab, code.co_firstlineno))\n    n_bytes = len(code.co_code)\n    new_num = []\n    line = 0\n    opnum_in_line = 0\n    i_byte = 0\n    while i_byte < n_bytes:\n        if old_num and i_byte == old_num[0][0]:\n            line = old_num.pop(0)[1]\n            opnum_in_line = 0\n        new_num.append((i_byte, 100000000 + 1000*line + opnum_in_line))\n        if ord(code.co_code[i_byte]) >= opcode.HAVE_ARGUMENT:\n            i_byte += 3\n        else:\n            i_byte += 1\n        opnum_in_line += 1\n\n    # new_num is a list of pairs, (byteoff, lineoff).  Turn it into an lnotab.\n    new_firstlineno = new_num[0][1]-1\n    new_lnotab = lnotab_string(new_num, new_firstlineno)\n\n    # Recurse into code constants in this code object.\n    new_consts = []\n    for const in code.co_consts:\n        if type(const) == types.CodeType:\n            new_consts.append(hack_line_numbers(const))\n        else:\n            new_consts.append(const)\n\n    # Create a new code object, just like the old one, except with new\n    # line numbers.\n    new_code = new.code(\n        code.co_argcount, code.co_nlocals, code.co_stacksize, code.co_flags,\n        code.co_code, tuple(new_consts), code.co_names, code.co_varnames,\n        code.co_filename, code.co_name, new_firstlineno, new_lnotab\n    )\n\n    return new_code\n\ndef hack_file(f):\n    pyc = PycFile()\n    pyc.read(f)\n    pyc.hack_line_numbers()\n    pyc.write(f)\n\nif __name__ == '__main__':\n    hack_file(sys.argv[1])\n", "lab/find_class.py": "class Parent:\n    def meth(self):\n        print(\"METH\")\n\nclass Child(Parent):\n    pass\n\ndef trace(frame, event, args):\n    # Thanks to Aleksi Torhamo for code and idea.\n    co = frame.f_code\n    fname = co.co_name\n    if not co.co_varnames:\n        return\n    locs = frame.f_locals\n    first_arg = co.co_varnames[0]\n    if co.co_argcount:\n        self = locs[first_arg]\n    elif co.co_flags & 0x04:    # *args syntax\n        self = locs[first_arg][0]\n    else:\n        return\n\n    func = getattr(self, fname).__func__\n    if hasattr(func, '__qualname__'):\n        qname = func.__qualname__\n    else:\n        for cls in self.__class__.__mro__:\n            f = cls.__dict__.get(fname, None)\n            if f is None:\n                continue\n            if f is func:\n                qname = cls.__name__ + \".\" + fname\n                break\n    print(f\"{event}: {self}.{fname} {qname}\")\n    return trace\n\nimport sys\nsys.settrace(trace)\n\nChild().meth()\n", "lab/branches.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n# Demonstrate some issues with coverage.py branch testing.\n\ndef my_function(x):\n    \"\"\"This isn't real code, just snippets...\"\"\"\n\n    # An infinite loop is structurally still a branch: it can next execute the\n    # first line of the loop, or the first line after the loop.  But\n    # \"while True\" will never jump to the line after the loop, so the line\n    # is shown as a partial branch:\n\n    i = 0\n    while True:\n        print(\"In while True\")\n        if i > 0:\n            break\n        i += 1\n    print(\"Left the True loop\")\n\n    # Notice that \"while 1\" also has this problem.  Even though the compiler\n    # knows there's no computation at the top of the loop, it's still expressed\n    # in bytecode as a branch with two possibilities.\n\n    i = 0\n    while 1:\n        print(\"In while 1\")\n        if i > 0:\n            break\n        i += 1\n    print(\"Left the 1 loop\")\n\n    # Coverage.py lets developers exclude lines that they know will not be\n    # executed.  So far, the branch coverage doesn't use all that information\n    # when deciding which lines are partially executed.\n    #\n    # Here, even though the else line is explicitly marked as never executed,\n    # the if line complains that it never branched to the else:\n\n    if x < 1000:\n        # This branch is always taken\n        print(\"x is reasonable\")\n    else:   # pragma: nocover\n        print(\"this never happens\")\n\n    # try-except structures are complex branches.  An except clause with a\n    # type is a three-way branch: there could be no exception, there could be\n    # a matching exception, and there could be a non-matching exception.\n    #\n    # Here we run the code twice: once with no exception, and once with a\n    # matching exception.  The \"except\" line is marked as partial because we\n    # never executed its third case: a non-matching exception.\n\n    for y in (1, 2):\n        try:\n            if y % 2:\n                raise ValueError(\"y is odd!\")\n        except ValueError:\n            print(\"y must have been odd\")\n        print(\"done with y\")\n    print(\"done with 1, 2\")\n\n    # Another except clause, but this time all three cases are executed.  No\n    # partial lines are shown:\n\n    for y in (0, 1, 2):\n        try:\n            if y % 2:\n                raise ValueError(\"y is odd!\")\n            if y == 0:\n                raise Exception(\"zero!\")\n        except ValueError:\n            print(\"y must have been odd\")\n        except:\n            print(\"y is something else\")\n        print(\"done with y\")\n    print(\"done with 0, 1, 2\")\n\n\nmy_function(1)\n", "lab/parser.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Parser.py: a main for invoking code in coverage/parser.py\"\"\"\n\n\nimport collections\nimport dis\nimport glob\nimport optparse\nimport os\nimport re\nimport sys\nimport textwrap\nimport types\n\nfrom coverage.parser import PythonParser\nfrom coverage.python import get_python_source\n\n\nclass ParserMain:\n    \"\"\"A main for code parsing experiments.\"\"\"\n\n    def main(self, args):\n        \"\"\"A main function for trying the code from the command line.\"\"\"\n\n        parser = optparse.OptionParser()\n        parser.add_option(\n            \"-d\", action=\"store_true\", dest=\"dis\",\n            help=\"Disassemble\"\n        )\n        parser.add_option(\n            \"-R\", action=\"store_true\", dest=\"recursive\",\n            help=\"Recurse to find source files\"\n        )\n        parser.add_option(\n            \"-s\", action=\"store_true\", dest=\"source\",\n            help=\"Show analyzed source\"\n        )\n        parser.add_option(\n            \"-t\", action=\"store_true\", dest=\"tokens\",\n            help=\"Show tokens\"\n        )\n\n        options, args = parser.parse_args()\n        if options.recursive:\n            if args:\n                root = args[0]\n            else:\n                root = \".\"\n            for root, _, _ in os.walk(root):\n                for f in glob.glob(root + \"/*.py\"):\n                    self.one_file(options, f)\n        elif not args:\n            parser.print_help()\n        else:\n            self.one_file(options, args[0])\n\n    def one_file(self, options, filename):\n        \"\"\"Process just one file.\"\"\"\n        # `filename` can have a line number suffix. In that case, extract those\n        # lines, dedent them, and use that.  This is for trying test cases\n        # embedded in the test files.\n        if match := re.search(r\"^(.*):(\\d+)-(\\d+)$\", filename):\n            filename, start, end = match.groups()\n            start, end = int(start), int(end)\n        else:\n            start = end = None\n\n        try:\n            text = get_python_source(filename)\n            if start is not None:\n                lines = text.splitlines(True)\n                text = textwrap.dedent(\"\".join(lines[start-1:end]).replace(\"\\\\\\\\\", \"\\\\\"))\n            pyparser = PythonParser(text, filename=filename, exclude=r\"no\\s*cover\")\n            pyparser.parse_source()\n        except Exception as err:\n            print(f\"{err}\")\n            return\n\n        if options.dis:\n            print(\"Main code:\")\n            disassemble(pyparser.text)\n\n        arcs = pyparser.arcs()\n\n        if options.source or options.tokens:\n            pyparser.show_tokens = options.tokens\n            pyparser.parse_source()\n\n            if options.source:\n                arc_chars = self.arc_ascii_art(arcs)\n                if arc_chars:\n                    arc_width = max(len(a) for a in arc_chars.values())\n\n                exit_counts = pyparser.exit_counts()\n\n                for lineno, ltext in enumerate(pyparser.text.splitlines(), start=1):\n                    marks = [' '] * 6\n                    a = ' '\n                    if lineno in pyparser.raw_statements:\n                        marks[0] = '-'\n                    if lineno in pyparser.statements:\n                        marks[1] = '='\n                    exits = exit_counts.get(lineno, 0)\n                    if exits > 1:\n                        marks[2] = str(exits)\n                    if lineno in pyparser.raw_docstrings:\n                        marks[3] = '\"'\n                    if lineno in pyparser.raw_classdefs:\n                        marks[3] = 'C'\n                    if lineno in pyparser.raw_excluded:\n                        marks[4] = 'X'\n                    elif lineno in pyparser.excluded:\n                        marks[4] = '\u00d7'\n                    if lineno in pyparser._multiline.values():\n                        marks[5] = 'o'\n                    elif lineno in pyparser._multiline.keys():\n                        marks[5] = '.'\n\n                    if arc_chars:\n                        a = arc_chars[lineno].ljust(arc_width)\n                    else:\n                        a = \"\"\n\n                    print(\"%4d %s%s %s\" % (lineno, \"\".join(marks), a, ltext))\n\n    def arc_ascii_art(self, arcs):\n        \"\"\"Draw arcs as ascii art.\n\n        Returns a dictionary mapping line numbers to ascii strings to draw for\n        that line.\n\n        \"\"\"\n        plus_ones = set()\n        arc_chars = collections.defaultdict(str)\n        for lfrom, lto in sorted(arcs):\n            if lfrom < 0:\n                arc_chars[lto] += 'v'\n            elif lto < 0:\n                arc_chars[lfrom] += '^'\n            else:\n                if lfrom == lto - 1:\n                    plus_ones.add(lfrom)\n                    arc_chars[lfrom] += \"\"      # ensure this line is in arc_chars\n                    continue\n                if lfrom < lto:\n                    l1, l2 = lfrom, lto\n                else:\n                    l1, l2 = lto, lfrom\n                w = first_all_blanks(arc_chars[l] for l in range(l1, l2+1))\n                for l in range(l1, l2+1):\n                    if l == lfrom:\n                        ch = '<'\n                    elif l == lto:\n                        ch = '>'\n                    else:\n                        ch = '|'\n                    arc_chars[l] = set_char(arc_chars[l], w, ch)\n\n        # Add the plusses as the first character\n        for lineno, arcs in arc_chars.items():\n            arc_chars[lineno] = (\n                (\"+\" if lineno in plus_ones else \" \") +\n                arcs\n            )\n\n        return arc_chars\n\n\ndef all_code_objects(code):\n    \"\"\"Iterate over all the code objects in `code`.\"\"\"\n    stack = [code]\n    while stack:\n        # We're going to return the code object on the stack, but first\n        # push its children for later returning.\n        code = stack.pop()\n        stack.extend(c for c in code.co_consts if isinstance(c, types.CodeType))\n        yield code\n\n\ndef disassemble(text):\n    \"\"\"Disassemble code, for ad-hoc experimenting.\"\"\"\n\n    code = compile(text, \"\", \"exec\", dont_inherit=True)\n    for code_obj in all_code_objects(code):\n        if text:\n            srclines = text.splitlines()\n        else:\n            srclines = None\n        print(\"\\n%s: \" % code_obj)\n        upto = None\n        for inst in dis.get_instructions(code_obj):\n            if inst.starts_line is not None:\n                if srclines:\n                    upto = upto or inst.starts_line - 1\n                    while upto <= inst.starts_line - 1:\n                        print(\"{:>100}{}\".format(\"\", srclines[upto]))\n                        upto += 1\n                elif inst.offset > 0:\n                    print(\"\")\n            line = inst._disassemble()\n            print(f\"{line:<70}\")\n\n    print(\"\")\n\n\ndef set_char(s, n, c):\n    \"\"\"Set the nth char of s to be c, extending s if needed.\"\"\"\n    s = s.ljust(n)\n    return s[:n] + c + s[n+1:]\n\n\ndef blanks(s):\n    \"\"\"Return the set of positions where s is blank.\"\"\"\n    return {i for i, c in enumerate(s) if c == \" \"}\n\n\ndef first_all_blanks(ss):\n    \"\"\"Find the first position that is all blank in the strings ss.\"\"\"\n    ss = list(ss)\n    blankss = blanks(ss[0])\n    for s in ss[1:]:\n        blankss &= blanks(s)\n    if blankss:\n        return min(blankss)\n    else:\n        return max(len(s) for s in ss)\n\n\nif __name__ == '__main__':\n    ParserMain().main(sys.argv[1:])\n", "lab/branch_trace.py": "import sys\n\npairs = set()\nlast = -1\n\ndef trace(frame, event, arg):\n    global last\n    if event == \"line\":\n        this = frame.f_lineno\n        pairs.add((last, this))\n        last = this\n    return trace\n\ncode = open(sys.argv[1]).read()\nsys.settrace(trace)\nexec(code)\nprint(sorted(pairs))\n", "lab/show_pyc.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nDump the contents of a .pyc file.\n\nThe output will only be correct if run with the same version of Python that\nproduced the .pyc.\n\n\"\"\"\n\nimport binascii\nimport dis\nimport marshal\nimport struct\nimport sys\nimport time\nimport types\n\n\ndef show_pyc_file(fname):\n    f = open(fname, \"rb\")\n    magic = f.read(4)\n    print(\"magic %s\" % (binascii.hexlify(magic)))\n    read_date_and_size = True\n    flags = struct.unpack('<L', f.read(4))[0]\n    hash_based = bool(flags & 0x01)\n    check_source = bool(flags & 0x02)\n    print(f\"flags {flags:#08x}\")\n    if hash_based:\n        source_hash = f.read(8)\n        read_date_and_size = False\n        print(f\"hash {binascii.hexlify(source_hash)}\")\n        print(f\"check_source {check_source}\")\n    if read_date_and_size:\n        moddate = f.read(4)\n        modtime = time.asctime(time.localtime(struct.unpack('<L', moddate)[0]))\n        print(f\"moddate {binascii.hexlify(moddate)} ({modtime})\")\n        size = f.read(4)\n        print(\"pysize %s (%d)\" % (binascii.hexlify(size), struct.unpack('<L', size)[0]))\n    code = marshal.load(f)\n    show_code(code)\n\ndef show_py_file(fname):\n    text = open(fname).read().replace('\\r\\n', '\\n')\n    show_py_text(text, fname=fname)\n\ndef show_py_text(text, fname=\"<string>\"):\n    code = compile(text, fname, \"exec\", dont_inherit=True)\n    show_code(code)\n\nCO_FLAGS = [\n    ('CO_OPTIMIZED',                0x00001),\n    ('CO_NEWLOCALS',                0x00002),\n    ('CO_VARARGS',                  0x00004),\n    ('CO_VARKEYWORDS',              0x00008),\n    ('CO_NESTED',                   0x00010),\n    ('CO_GENERATOR',                0x00020),\n    ('CO_NOFREE',                   0x00040),\n    ('CO_COROUTINE',                0x00080),\n    ('CO_ITERABLE_COROUTINE',       0x00100),\n    ('CO_ASYNC_GENERATOR',          0x00200),\n    ('CO_GENERATOR_ALLOWED',        0x01000),\n]\n\nif sys.version_info < (3, 9):\n    CO_FLAGS += [\n        ('CO_FUTURE_DIVISION',          0x02000),\n        ('CO_FUTURE_ABSOLUTE_IMPORT',   0x04000),\n        ('CO_FUTURE_WITH_STATEMENT',    0x08000),\n        ('CO_FUTURE_PRINT_FUNCTION',    0x10000),\n        ('CO_FUTURE_UNICODE_LITERALS',  0x20000),\n        ('CO_FUTURE_BARRY_AS_BDFL',     0x40000),\n        ('CO_FUTURE_GENERATOR_STOP',    0x80000),\n    ]\nelse:\n    CO_FLAGS += [\n        ('CO_FUTURE_DIVISION',          0x0020000),\n        ('CO_FUTURE_ABSOLUTE_IMPORT',   0x0040000),\n        ('CO_FUTURE_WITH_STATEMENT',    0x0080000),\n        ('CO_FUTURE_PRINT_FUNCTION',    0x0100000),\n        ('CO_FUTURE_UNICODE_LITERALS',  0x0200000),\n        ('CO_FUTURE_BARRY_AS_BDFL',     0x0400000),\n        ('CO_FUTURE_GENERATOR_STOP',    0x0800000),\n        ('CO_FUTURE_ANNOTATIONS',       0x1000000),\n    ]\n\n\ndef show_code(code, indent='', number=None):\n    label = \"\"\n    if number is not None:\n        label = \"%d: \" % number\n    print(f\"{indent}{label}code\")\n    indent += \"    \"\n    print(f\"{indent}name {code.co_name!r}\")\n    print(\"%sargcount %d\" % (indent, code.co_argcount))\n    print(\"%snlocals %d\" % (indent, code.co_nlocals))\n    print(\"%sstacksize %d\" % (indent, code.co_stacksize))\n    print(f\"{indent}flags {code.co_flags:04x}: {flag_words(code.co_flags, CO_FLAGS)}\")\n    show_hex(\"code\", code.co_code, indent=indent)\n    dis.disassemble(code)\n    print(\"%sconsts\" % indent)\n    for i, const in enumerate(code.co_consts):\n        if type(const) == types.CodeType:\n            show_code(const, indent+\"    \", number=i)\n        else:\n            print(\"    %s%d: %r\" % (indent, i, const))\n    print(f\"{indent}names {code.co_names!r}\")\n    print(f\"{indent}varnames {code.co_varnames!r}\")\n    print(f\"{indent}freevars {code.co_freevars!r}\")\n    print(f\"{indent}cellvars {code.co_cellvars!r}\")\n    print(f\"{indent}filename {code.co_filename!r}\")\n    print(\"%sfirstlineno %d\" % (indent, code.co_firstlineno))\n    show_hex(\"lnotab\", code.co_lnotab, indent=indent)\n    print(\"    {}{}\".format(indent, \", \".join(f\"{line!r}:{byte!r}\" for byte, line in lnotab_interpreted(code))))\n    if hasattr(code, \"co_linetable\"):\n        show_hex(\"linetable\", code.co_linetable, indent=indent)\n    if hasattr(code, \"co_lines\"):\n        print(\"    {}co_lines {}\".format(\n            indent,\n            \", \".join(f\"{line!r}:{start!r}-{end!r}\" for start, end, line in code.co_lines())\n        ))\n\ndef show_hex(label, h, indent):\n    h = binascii.hexlify(h)\n    if len(h) < 60:\n        print(\"{}{} {}\".format(indent, label, h.decode('ascii')))\n    else:\n        print(f\"{indent}{label}\")\n        for i in range(0, len(h), 60):\n            print(\"{}   {}\".format(indent, h[i:i+60].decode('ascii')))\n\n\ndef lnotab_interpreted(code):\n    # Adapted from dis.py in the standard library.\n    byte_increments = code.co_lnotab[0::2]\n    line_increments = code.co_lnotab[1::2]\n\n    last_line_num = None\n    line_num = code.co_firstlineno\n    byte_num = 0\n    for byte_incr, line_incr in zip(byte_increments, line_increments):\n        if byte_incr:\n            if line_num != last_line_num:\n                yield (byte_num, line_num)\n                last_line_num = line_num\n            byte_num += byte_incr\n        if line_incr >= 0x80:\n            line_incr -= 0x100\n        line_num += line_incr\n    if line_num != last_line_num:\n        yield (byte_num, line_num)\n\ndef flag_words(flags, flag_defs):\n    words = []\n    for word, flag in flag_defs:\n        if flag & flags:\n            words.append(word)\n    return \", \".join(words)\n\ndef show_file(fname):\n    if fname.endswith('pyc'):\n        show_pyc_file(fname)\n    elif fname.endswith('py'):\n        show_py_file(fname)\n    else:\n        print(\"Odd file:\", fname)\n\ndef main(args):\n    if args[0] == '-c':\n        show_py_text(\" \".join(args[1:]).replace(\";\", \"\\n\"))\n    else:\n        for a in args:\n            show_file(a)\n\nif __name__ == '__main__':\n    main(sys.argv[1:])\n", "lab/platform_info.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Dump information so we can get a quick look at what's available.\"\"\"\n\nimport platform\nimport sys\n\n\ndef whatever(f):\n    try:\n        return f()\n    except:\n        return f\n\n\ndef dump_module(mod):\n    print(f\"\\n###  {mod.__name__} ---------------------------\")\n    for name in dir(mod):\n        if name.startswith(\"_\"):\n            continue\n        print(f\"{name:30s}: {whatever(getattr(mod, name))!r:.100}\")\n\n\nfor mod in [platform, sys]:\n    dump_module(mod)\n", "lab/select_contexts.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\\\nSelect certain contexts from a coverage.py data file.\n\"\"\"\n\nimport argparse\nimport re\nimport sys\n\nimport coverage\n\n\ndef main(argv):\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"--include\", type=str, help=\"Regex for contexts to keep\")\n    parser.add_argument(\"--exclude\", type=str, help=\"Regex for contexts to discard\")\n    args = parser.parse_args(argv)\n\n    print(\"** Note: this is a proof-of-concept. Support is not promised. **\")\n    print(\"Feedback is appreciated: https://github.com/nedbat/coveragepy/issues/668\")\n\n    cov_in = coverage.Coverage()\n    cov_in.load()\n    data_in = cov_in.get_data()\n    print(f\"Contexts in {data_in.data_filename()}:\")\n    for ctx in sorted(data_in.measured_contexts()):\n        print(f\"    {ctx}\")\n\n    if args.include is None and args.exclude is None:\n        print(\"Nothing to do, no output written.\")\n        return\n\n    out_file = \"output.data\"\n    file_names = data_in.measured_files()\n    print(f\"{len(file_names)} measured files\")\n    print(f\"Writing to {out_file}\")\n    cov_out = coverage.Coverage(data_file=out_file)\n    data_out = cov_out.get_data()\n\n    for ctx in sorted(data_in.measured_contexts()):\n        if args.include is not None:\n            if not re.search(args.include, ctx):\n                print(f\"Skipping context {ctx}, not included\")\n                continue\n        if args.exclude is not None:\n            if re.search(args.exclude, ctx):\n                print(f\"Skipping context {ctx}, excluded\")\n                continue\n        print(f\"Keeping context {ctx}\")\n        data_in.set_query_context(ctx)\n        data_out.set_context(ctx)\n        if data_in.has_arcs():\n            data_out.add_arcs({f: data_in.arcs(f) for f in file_names})\n        else:\n            data_out.add_lines({f: data_in.lines(f) for f in file_names})\n\n    for fname in file_names:\n        data_out.touch_file(fname, data_in.file_tracer(fname))\n\n    cov_out.save()\n\n\nif __name__ == \"__main__\":\n    sys.exit(main(sys.argv[1:]))\n", "benchmark/run.py": "import optparse\nfrom pathlib import Path\n\nfrom benchmark import *\n\nparser = optparse.OptionParser()\nparser.add_option(\n    \"--clean\",\n    action=\"store_true\",\n    dest=\"clean\",\n    default=False,\n    help=\"Delete the results.json file before running benchmarks\"\n)\noptions, args = parser.parse_args()\n\nif options.clean:\n    results_file = Path(\"results.json\")\n    if results_file.exists():\n        results_file.unlink()\n        print(\"Deleted results.json\")\n\nif 0:\n    run_experiment(\n        py_versions=[\n            # Python(3, 11),\n            AdHocPython(\"/usr/local/cpython/v3.10.5\", \"v3.10.5\"),\n            AdHocPython(\"/usr/local/cpython/v3.11.0b3\", \"v3.11.0b3\"),\n            AdHocPython(\"/usr/local/cpython/94231\", \"94231\"),\n        ],\n        cov_versions=[\n            Coverage(\"6.4.1\", \"coverage==6.4.1\"),\n        ],\n        projects=[\n            AdHocProject(\"/src/bugs/bug1339/bug1339.py\"),\n            SlipcoverBenchmark(\"bm_sudoku.py\"),\n            SlipcoverBenchmark(\"bm_spectral_norm.py\"),\n        ],\n        rows=[\"cov\", \"proj\"],\n        column=\"pyver\",\n        ratios=[\n            (\"3.11b3 vs 3.10\", \"v3.11.0b3\", \"v3.10.5\"),\n            (\"94231 vs 3.10\", \"94231\", \"v3.10.5\"),\n        ],\n    )\n\n\nif 0:\n    run_experiment(\n        py_versions=[\n            Python(3, 9),\n            Python(3, 11),\n        ],\n        cov_versions=[\n            Coverage(\"701\", \"coverage==7.0.1\"),\n            Coverage(\n                \"701.dynctx\", \"coverage==7.0.1\", [(\"dynamic_context\", \"test_function\")]\n            ),\n            Coverage(\"702\", \"coverage==7.0.2\"),\n            Coverage(\n                \"702.dynctx\", \"coverage==7.0.2\", [(\"dynamic_context\", \"test_function\")]\n            ),\n        ],\n        projects=[\n            ProjectAttrs(),\n        ],\n        rows=[\"proj\", \"pyver\"],\n        column=\"cov\",\n        ratios=[\n            (\".2 vs .1\", \"702\", \"701\"),\n            (\".1 dynctx cost\", \"701.dynctx\", \"701\"),\n            (\".2 dynctx cost\", \"702.dynctx\", \"702\"),\n        ],\n    )\n\n\nif 0:\n    # Compare two Python versions\n    v1 = 10\n    v2 = 11\n    run_experiment(\n        py_versions=[\n            Python(3, v1),\n            Python(3, v2),\n        ],\n        cov_versions=[\n            Coverage(\"753\", \"coverage==7.5.3\"),\n        ],\n        projects=[\n            ProjectMashumaro(),\n        ],\n        rows=[\"cov\", \"proj\"],\n        column=\"pyver\",\n        ratios=[\n            (f\"3.{v2} vs 3.{v1}\", f\"python3.{v2}\", f\"python3.{v1}\"),\n        ],\n    )\n\nif 1:\n    # Compare sysmon on many projects\n\n    run_experiment(\n        py_versions=[\n            Python(3, 12),\n        ],\n        cov_versions=[\n            NoCoverage(\"nocov\"),\n            CoverageSource(slug=\"ctrace\", env_vars={\"COVERAGE_CORE\": \"ctrace\"}),\n            CoverageSource(slug=\"sysmon\", env_vars={\"COVERAGE_CORE\": \"sysmon\"}),\n        ],\n        projects=[\n            # ProjectSphinx(),  # Works, slow\n            ProjectPygments(),  # Works\n            # ProjectRich(),  # Doesn't work\n            # ProjectTornado(),  # Works, tests fail\n            # ProjectDulwich(),  # Works\n            # ProjectBlack(),  # Works, slow\n            # ProjectMpmath(),  # Works, slow\n            ProjectMypy(),  # Works, slow\n            # ProjectHtml5lib(),  # Works\n            # ProjectUrllib3(),  # Works\n        ],\n        rows=[\"pyver\", \"proj\"],\n        column=\"cov\",\n        ratios=[\n            (f\"ctrace%\", \"ctrace\", \"nocov\"),\n            (f\"sysmon%\", \"sysmon\", \"nocov\"),\n        ],\n        load=True,\n    )\n\nif 0:\n    # Compare current Coverage source against shipped version\n    run_experiment(\n        py_versions=[\n            Python(3, 11),\n        ],\n        cov_versions=[\n            Coverage(\"pip\", \"coverage\"),\n            CoverageSource(slug=\"latest\"),\n        ],\n        projects=[\n            ProjectMashumaro(),\n            ProjectOperator(),\n        ],\n        rows=[\"pyver\", \"proj\"],\n        column=\"cov\",\n        ratios=[\n            (f\"Latest vs shipped\", \"latest\", \"pip\"),\n        ],\n    )\n\nif 0:\n    # Compare 3.12 coverage vs no coverage\n    run_experiment(\n        py_versions=[\n            Python(3, 12),\n        ],\n        cov_versions=[\n            NoCoverage(\"nocov\"),\n            Coverage(\"732\", \"coverage==7.3.2\"),\n            CoverageSource(\n                slug=\"sysmon\",\n                env_vars={\"COVERAGE_CORE\": \"sysmon\"},\n            ),\n        ],\n        projects=[\n            ProjectMashumaro(),     # small: \"-k ck\"\n            ProjectOperator(),      # small: \"-k irk\"\n        ],\n        rows=[\"pyver\", \"proj\"],\n        column=\"cov\",\n        ratios=[\n            (f\"732%\", \"732\", \"nocov\"),\n            (f\"sysmon%\", \"sysmon\", \"nocov\"),\n        ],\n    )\n\nif 0:\n    # Compare 3.12 coverage vs no coverage\n    run_experiment(\n        py_versions=[\n            Python(3, 12),\n        ],\n        cov_versions=[\n            NoCoverage(\"nocov\"),\n            Coverage(\"732\", \"coverage==7.3.2\"),\n            CoverageSource(\n                slug=\"sysmon\",\n                env_vars={\"COVERAGE_CORE\": \"sysmon\"},\n            ),\n        ],\n        projects=[\n            ProjectMashumaro(),         # small: \"-k ck\"\n            ProjectMashumaroBranch(),   # small: \"-k ck\"\n        ],\n        rows=[\"pyver\", \"proj\"],\n        column=\"cov\",\n        ratios=[\n            (f\"732%\", \"732\", \"nocov\"),\n            (f\"sysmon%\", \"sysmon\", \"nocov\"),\n        ],\n    )\n", "benchmark/benchmark.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Run performance comparisons for versions of coverage\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport contextlib\nimport itertools\nimport json\nimport os\nimport random\nimport shutil\nimport statistics\nimport subprocess\nimport sys\nimport time\nimport traceback\n\nfrom pathlib import Path\n\nfrom dataclasses import dataclass\nfrom io import TextIOWrapper\nfrom types import TracebackType\nfrom typing import Any, Dict, Iterable, Iterator, Mapping, Optional, Tuple, Type, cast\n\nimport requests\nimport tabulate\n\nTweaksType = Optional[Iterable[Tuple[str, Any]]]\nEnv_VarsType = Optional[Dict[str, str]]\n\n\nclass ShellSession:\n    \"\"\"A logged shell session.\n\n    The duration of the last command is available as .last_duration.\n    \"\"\"\n\n    def __init__(self, output_filename: str):\n        self.output_filename = output_filename\n        self.last_duration: float = 0\n        self.foutput: TextIOWrapper | None = None\n        self.env_vars = {\"PATH\": os.getenv(\"PATH\")}\n\n    def __enter__(self) -> ShellSession:\n        self.foutput = open(self.output_filename, \"a\", encoding=\"utf-8\")\n        print(f\"Logging output to {os.path.abspath(self.output_filename)}\")\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Type[BaseException] | None,\n        exc_value: BaseException | None,\n        traceback: TracebackType | None,\n    ) -> None:\n        if self.foutput is not None:\n            self.foutput.close()\n\n    @contextlib.contextmanager\n    def set_env(self, *env_varss: dict[str, str] | None) -> Iterator[None]:\n        \"\"\"Set environment variables.\n\n        All the arguments are dicts of name:value, or None.  All are applied\n        to the environment variables.\n        \"\"\"\n        old_env_vars = self.env_vars\n        self.env_vars = dict(old_env_vars)\n        for env_vars in env_varss:\n            self.env_vars.update(env_vars or {})\n        try:\n            yield\n        finally:\n            self.env_vars = old_env_vars\n\n    def print(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Print a message to this shell's log.\"\"\"\n        print(*args, **kwargs, file=self.foutput)\n\n    def print_banner(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Print a distinguished banner to the log.\"\"\"\n        self.print(\"\\n######> \", end=\"\")\n        self.print(*args, **kwargs)\n\n    def run_command(self, cmd: str) -> str:\n        \"\"\"\n        Run a command line (with a shell).\n\n        Returns:\n            str: the output of the command.\n\n        \"\"\"\n        self.print(f\"\\n### ========================\\n$ {cmd}\")\n        start = time.perf_counter()\n        proc = subprocess.run(\n            cmd,\n            shell=True,\n            check=False,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            env=cast(Mapping[str, str], self.env_vars),\n        )\n        output = proc.stdout.decode(\"utf-8\")\n        self.last_duration = time.perf_counter() - start\n        self.print(output, end=\"\")\n        self.print(f\"(was: {cmd})\")\n        self.print(f\"(in {os.getcwd()}, duration: {self.last_duration:.3f}s)\")\n\n        if proc.returncode != 0:\n            self.print(f\"ERROR: command returned {proc.returncode}\")\n            raise Exception(\n                f\"Command failed ({proc.returncode}): {cmd!r}, output was:\\n{output}\"\n            )\n\n        return output.strip()\n\n\ndef rmrf(path: Path) -> None:\n    \"\"\"\n    Remove a directory tree.  It's OK if it doesn't exist.\n    \"\"\"\n    if path.exists():\n        shutil.rmtree(path)\n\n\n@contextlib.contextmanager\ndef change_dir(newdir: Path) -> Iterator[Path]:\n    \"\"\"\n    Change to a new directory, and then change back.\n\n    Will make the directory if needed.\n    \"\"\"\n    old_dir = os.getcwd()\n    newdir.mkdir(parents=True, exist_ok=True)\n    os.chdir(newdir)\n    try:\n        yield newdir\n    finally:\n        os.chdir(old_dir)\n\n\n@contextlib.contextmanager\ndef file_replace(file_name: Path, old_text: str, new_text: str) -> Iterator[None]:\n    \"\"\"\n    Replace some text in `file_name`, and change it back.\n    \"\"\"\n    file_text = \"\"\n    if old_text:\n        file_text = file_name.read_text()\n        if old_text not in file_text:\n            raise Exception(\"Old text {old_text!r} not found in {file_name}\")\n        updated_text = file_text.replace(old_text, new_text)\n        file_name.write_text(updated_text)\n    try:\n        yield\n    finally:\n        if old_text:\n            file_name.write_text(file_text)\n\n\ndef file_must_exist(file_name: str, kind: str = \"file\") -> Path:\n    \"\"\"\n    Check that a file exists, for early validation of pip (etc) arguments.\n\n    Raises an exception if it doesn't exist.  Returns the resolved path if it\n    does exist so we can use relative paths and they'll still work once we've\n    cd'd to the temporary workspace.\n    \"\"\"\n    path = Path(file_name).expanduser().resolve()\n    if not path.exists():\n        kind = kind[0].upper() + kind[1:]\n        raise RuntimeError(f\"{kind} {file_name!r} doesn't exist\")\n    return path\n\n\ndef url_must_exist(url: str) -> bool:\n    \"\"\"\n    Check that a URL exists, for early validation of pip (etc) arguments.\n\n    Raises an exception if it doesn't exist.\n    \"\"\"\n    resp = requests.head(url)\n    resp.raise_for_status()\n    return True\n\n\nclass ProjectToTest:\n    \"\"\"Information about a project to use as a test case.\"\"\"\n\n    # Where can we clone the project from?\n    git_url: str = \"\"\n    slug: str = \"\"\n    env_vars: Env_VarsType = {}\n\n    def __init__(self) -> None:\n        url_must_exist(self.git_url)\n        if not self.slug:\n            if self.git_url:\n                self.slug = self.git_url.split(\"/\")[-1]\n\n    def shell(self) -> ShellSession:\n        return ShellSession(f\"output_{self.slug}.log\")\n\n    def make_dir(self) -> None:\n        self.dir = Path(f\"work_{self.slug}\")\n        if self.dir.exists():\n            rmrf(self.dir)\n\n    def get_source(self, shell: ShellSession, retries: int = 5) -> None:\n        \"\"\"Get the source of the project.\"\"\"\n        for retry in range(retries):\n            try:\n                shell.run_command(f\"git clone {self.git_url} {self.dir}\")\n                return\n            except Exception as e:\n                print(f\"Retrying to clone {self.git_url} due to error:\\n{e}\")\n                if retry == retries - 1:\n                    raise e\n\n    def prep_environment(self, env: Env) -> None:\n        \"\"\"Prepare the environment to run the test suite.\n\n        This is not timed.\n        \"\"\"\n\n    @contextlib.contextmanager\n    def tweak_coverage_settings(self, settings: TweaksType) -> Iterator[None]:\n        \"\"\"Tweak the coverage settings.\n\n        NOTE: This is not properly factored, and is only used by ToxProject now!!!\n        \"\"\"\n        yield\n\n    def pre_check(self, env: Env) -> None:\n        pass\n\n    def post_check(self, env: Env) -> None:\n        pass\n\n    def run_no_coverage(self, env: Env) -> float:\n        \"\"\"Run the test suite with no coverage measurement.\n\n        Returns the duration of the run.\n        \"\"\"\n        return 0.0\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        \"\"\"Run the test suite with coverage measurement.\n\n        Must install a particular version of coverage using `cov_ver.pip_args`.\n\n        Returns the duration of the run.\n        \"\"\"\n        return 0.0\n\n\nclass EmptyProject(ProjectToTest):\n    \"\"\"A dummy project for testing other parts of this code.\"\"\"\n\n    def __init__(self, slug: str = \"empty\", fake_durations: Iterable[float] = (1.23,)):\n        self.slug = slug\n        self.durations = iter(itertools.cycle(fake_durations))\n\n    def get_source(self, shell: ShellSession, retries: int = 5) -> None:\n        pass\n\n    def run_no_coverage(self, env: Env) -> float:\n        \"\"\"Run the test suite with coverage measurement.\"\"\"\n        return next(self.durations)\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        \"\"\"Run the test suite with coverage measurement.\"\"\"\n        return next(self.durations)\n\n\nclass ToxProject(ProjectToTest):\n    \"\"\"A project using tox to run the test suite.\"\"\"\n\n    env_vars: Env_VarsType = {\n        **(ProjectToTest.env_vars or {}),\n        # Allow some environment variables into the tox execution.\n        \"TOX_OVERRIDE\": \"testenv.pass_env+=COVERAGE_DEBUG,COVERAGE_CORE,COVERAGE_FORCE_CONFIG\",\n        \"COVERAGE_DEBUG\": \"config,sys\",\n    }\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install tox\")\n        self.run_tox(env, env.pyver.toxenv, \"--notest\")\n\n    def run_tox(self, env: Env, toxenv: str, toxargs: str = \"\") -> float:\n        \"\"\"Run a tox command. Return the duration.\"\"\"\n        env.shell.run_command(f\"{env.python} -m tox -v -e {toxenv} {toxargs}\")\n        return env.shell.last_duration\n\n    def run_no_coverage(self, env: Env) -> float:\n        return self.run_tox(env, env.pyver.toxenv, \"--skip-pkg-install\")\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        self.run_tox(env, env.pyver.toxenv, \"--notest\")\n        env.shell.run_command(\n            f\".tox/{env.pyver.toxenv}/bin/python -m pip install {cov_ver.pip_args}\"\n        )\n        with self.tweak_coverage_settings(cov_ver.tweaks):\n            self.pre_check(env)  # NOTE: Not properly factored, and only used from here.\n            duration = self.run_tox(env, env.pyver.toxenv, \"--skip-pkg-install\")\n            self.post_check(\n                env\n            )  # NOTE: Not properly factored, and only used from here.\n        return duration\n\n\nclass ProjectPytestHtml(ToxProject):\n    \"\"\"pytest-dev/pytest-html\"\"\"\n\n    git_url = \"https://github.com/pytest-dev/pytest-html\"\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        raise Exception(\"This doesn't work because options changed to tweaks\")\n        covenv = env.pyver.toxenv + \"-cov\"  # type: ignore[unreachable]\n        self.run_tox(env, covenv, \"--notest\")\n        env.shell.run_command(\n            f\".tox/{covenv}/bin/python -m pip install {cov_ver.pip_args}\"\n        )\n        if cov_ver.tweaks:\n            replace = (\"# reference: https\", f\"[run]\\n{cov_ver.tweaks}\\n#\")\n        else:\n            replace = (\"\", \"\")\n        with file_replace(Path(\".coveragerc\"), *replace):\n            env.shell.run_command(\"cat .coveragerc\")\n            env.shell.run_command(f\".tox/{covenv}/bin/python -m coverage debug sys\")\n            return self.run_tox(env, covenv, \"--skip-pkg-install\")\n\n\nclass ProjectDateutil(ToxProject):\n    \"\"\"dateutil/dateutil\"\"\"\n\n    git_url = \"https://github.com/dateutil/dateutil\"\n\n    def prep_environment(self, env: Env) -> None:\n        super().prep_environment(env)\n        env.shell.run_command(f\"{env.python} updatezinfo.py\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(\"echo No option to run without coverage\")\n        return 0\n\n\nclass ProjectAttrs(ToxProject):\n    \"\"\"python-attrs/attrs\"\"\"\n\n    git_url = \"https://github.com/python-attrs/attrs\"\n\n    @contextlib.contextmanager\n    def tweak_coverage_settings(self, tweaks: TweaksType) -> Iterator[None]:\n        return tweak_toml_coverage_settings(\"pyproject.toml\", tweaks)\n\n    def pre_check(self, env: Env) -> None:\n        env.shell.run_command(\"cat pyproject.toml\")\n\n    def post_check(self, env: Env) -> None:\n        env.shell.run_command(\"ls -al\")\n\n\nclass ProjectDjangoAuthToolkit(ToxProject):\n    \"\"\"jazzband/django-oauth-toolkit\"\"\"\n\n    git_url = \"https://github.com/jazzband/django-oauth-toolkit\"\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(\"echo No option to run without coverage\")\n        return 0\n\n\nclass ProjectDjango(ToxProject):\n    \"\"\"django/django\"\"\"\n\n    # brew install libmemcached\n    # pip install -e .\n    # coverage run tests/runtests.py --settings=test_sqlite\n    # coverage report --format=total --precision=6\n    # 32.848540\n\n\nclass ProjectMashumaro(ProjectToTest):\n    git_url = \"https://github.com/Fatal1ty/mashumaro\"\n\n    def __init__(self, more_pytest_args: str = \"\"):\n        super().__init__()\n        self.more_pytest_args = more_pytest_args\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install .\")\n        env.shell.run_command(f\"{env.python} -m pip install -r requirements-dev.txt\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(f\"{env.python} -m pytest {self.more_pytest_args}\")\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        env.shell.run_command(\n            f\"{env.python} -m pytest --cov=mashumaro --cov=tests {self.more_pytest_args}\"\n        )\n        duration = env.shell.last_duration\n        report = env.shell.run_command(f\"{env.python} -m coverage report --precision=6\")\n        print(\"Results:\", report.splitlines()[-1])\n        return duration\n\n\nclass ProjectMashumaroBranch(ProjectMashumaro):\n    def __init__(self, more_pytest_args: str = \"\"):\n        super().__init__(more_pytest_args=\"--cov-branch \" + more_pytest_args)\n        self.slug = \"mashbranch\"\n\n\nclass ProjectOperator(ProjectToTest):\n    git_url = \"https://github.com/nedbat/operator\"\n\n    def __init__(self, more_pytest_args: str = \"\"):\n        super().__init__()\n        self.more_pytest_args = more_pytest_args\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install tox\")\n        Path(\"/tmp/operator_tmp\").mkdir(exist_ok=True)\n        env.shell.run_command(f\"{env.python} -m tox -e unit --notest\")\n        env.shell.run_command(f\"{env.python} -m tox -e unitnocov --notest\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(\n            f\"TMPDIR=/tmp/operator_tmp {env.python} -m tox -e unitnocov --skip-pkg-install\"\n            + f\" -- {self.more_pytest_args}\"\n        )\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        env.shell.run_command(\n            f\"TMPDIR=/tmp/operator_tmp {env.python} -m tox -e unit --skip-pkg-install\"\n            + f\" -- {self.more_pytest_args}\"\n        )\n        duration = env.shell.last_duration\n        report = env.shell.run_command(f\"{env.python} -m coverage report --precision=6\")\n        print(\"Results:\", report.splitlines()[-1])\n        return duration\n\n\nclass ProjectPygments(ToxProject):\n    git_url = \"https://github.com/pygments/pygments\"\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        self.run_tox(env, env.pyver.toxenv, \"--notest\")\n        env.shell.run_command(\n            f\".tox/{env.pyver.toxenv}/bin/python -m pip install {cov_ver.pip_args}\"\n        )\n        with self.tweak_coverage_settings(cov_ver.tweaks):\n            self.pre_check(env)  # NOTE: Not properly factored, and only used here.\n            duration = self.run_tox(\n                env, env.pyver.toxenv, \"--skip-pkg-install -- --cov\"\n            )\n            self.post_check(env)  # NOTE: Not properly factored, and only used here.\n        return duration\n\n\nclass ProjectRich(ToxProject):\n    git_url = \"https://github.com/Textualize/rich\"\n\n    def prep_environment(self, env: Env) -> None:\n        raise Exception(\"Doesn't work due to poetry install error.\")\n\n\nclass ProjectTornado(ToxProject):\n    git_url = \"https://github.com/tornadoweb/tornado\"\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(f\"{env.python} -m tornado.test\")\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        env.shell.run_command(f\"{env.python} -m coverage run -m tornado.test\")\n        duration = env.shell.last_duration\n        report = env.shell.run_command(f\"{env.python} -m coverage report --precision=6\")\n        print(\"Results:\", report.splitlines()[-1])\n        return duration\n\n\nclass ProjectDulwich(ToxProject):\n    git_url = \"https://github.com/jelmer/dulwich\"\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install -r requirements.txt\")\n        env.shell.run_command(f\"{env.python} -m pip install .\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(f\"{env.python} -m unittest tests.test_suite\")\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        env.shell.run_command(\n            f\"{env.python} -m coverage run -m unittest tests.test_suite\"\n        )\n        duration = env.shell.last_duration\n        report = env.shell.run_command(f\"{env.python} -m coverage report --precision=6\")\n        print(\"Results:\", report.splitlines()[-1])\n        return duration\n\n\nclass ProjectBlack(ToxProject):\n    git_url = \"https://github.com/psf/black\"\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install -r test_requirements.txt\")\n        env.shell.run_command(f\"{env.python} -m pip install -e .[d]\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(\n            f\"{env.python} -m pytest tests --run-optional no_jupyter --no-cov --numprocesses 1\"\n        )\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        env.shell.run_command(\n            f\"{env.python} -m pytest tests --run-optional no_jupyter --cov --numprocesses 1\"\n        )\n        duration = env.shell.last_duration\n        report = env.shell.run_command(f\"{env.python} -m coverage report --precision=6\")\n        print(\"Results:\", report.splitlines()[-1])\n        return duration\n\n\nclass ProjectMpmath(ProjectToTest):\n    git_url = \"https://github.com/mpmath/mpmath\"\n    select = \"-k 'not (torture or extra or functions2 or calculus or cli or elliptic or quad)'\"\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install .[develop]\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(f\"{env.python} -m pytest {self.select} --no-cov\")\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        env.shell.run_command(f\"{env.python} -m pytest {self.select} --cov=mpmath\")\n        duration = env.shell.last_duration\n        report = env.shell.run_command(f\"{env.python} -m coverage report --precision=6\")\n        print(\"Results:\", report.splitlines()[-1])\n        return duration\n\n\nclass ProjectMypy(ToxProject):\n    git_url = \"https://github.com/python/mypy\"\n\n    SLOW_TESTS = \" or \".join([\n        \"PythonCmdline\",\n        \"PEP561Suite\",\n        \"PythonEvaluation\",\n        \"testdaemon\",\n        \"StubgenCmdLine\",\n        \"StubgenPythonSuite\",\n        \"TestRun\",\n        \"TestRunMultiFile\",\n        \"TestExternal\",\n        \"TestCommandLine\",\n        \"ErrorStreamSuite\",\n    ])\n\n    FAST = f\"-k 'not ({SLOW_TESTS})'\"\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install -r test-requirements.txt\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(f\"{env.python} -m pytest {self.FAST} --no-cov\")\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        pforce = Path(\"force.ini\")\n        pforce.write_text(\"[run]\\nbranch=false\\n\")\n        with env.shell.set_env({\"COVERAGE_FORCE_CONFIG\": str(pforce.resolve())}):\n            env.shell.run_command(f\"{env.python} -m pytest {self.FAST} --cov\")\n            duration = env.shell.last_duration\n            report = env.shell.run_command(f\"{env.python} -m coverage report --precision=6\")\n        print(\"Results:\", report.splitlines()[-1])\n        return duration\n\n\nclass ProjectHtml5lib(ToxProject):\n    git_url = \"https://github.com/html5lib/html5lib-python\"\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install -r requirements-test.txt\")\n        env.shell.run_command(f\"{env.python} -m pip install .\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(f\"{env.python} -m pytest\")\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        env.shell.run_command(f\"{env.python} -m coverage run -m pytest\")\n        duration = env.shell.last_duration\n        report = env.shell.run_command(f\"{env.python} -m coverage report --precision=6\")\n        print(\"Results:\", report.splitlines()[-1])\n        return duration\n\n\nclass ProjectSphinx(ToxProject):\n    git_url = \"https://github.com/sphinx-doc/sphinx\"\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install .[test]\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(f\"{env.python} -m pytest\")\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        env.shell.run_command(f\"{env.python} -m coverage run -m pytest\")\n        duration = env.shell.last_duration\n        env.shell.run_command(f\"{env.python} -m coverage combine\")\n        report = env.shell.run_command(f\"{env.python} -m coverage report --precision=6\")\n        print(\"Results:\", report.splitlines()[-1])\n        return duration\n\n\nclass ProjectUrllib3(ProjectToTest):\n    git_url = \"https://github.com/urllib3/urllib3\"\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install -r dev-requirements.txt\")\n        env.shell.run_command(f\"{env.python} -m pip install .\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        env.shell.run_command(f\"{env.python} -m pytest\")\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        env.shell.run_command(f\"{env.python} -m coverage run -m pytest\")\n        duration = env.shell.last_duration\n        report = env.shell.run_command(f\"{env.python} -m coverage report --precision=6\")\n        print(\"Results:\", report.splitlines()[-1])\n        return duration\n\n\ndef tweak_toml_coverage_settings(toml_file: str, tweaks: TweaksType) -> Iterator[None]:\n    if tweaks:\n        toml_inserts = []\n        for name, value in tweaks:\n            if isinstance(value, bool):\n                toml_inserts.append(f\"{name} = {str(value).lower()}\")\n            elif isinstance(value, str):\n                toml_inserts.append(f\"{name} = '{value}'\")\n            else:\n                raise Exception(f\"Can't tweak toml setting: {name} = {value!r}\")\n        header = \"[tool.coverage.run]\\n\"\n        insert = header + \"\\n\".join(toml_inserts) + \"\\n\"\n    else:\n        header = insert = \"\"\n    return file_replace(Path(toml_file), header, insert)  # type: ignore\n\n\nclass AdHocProject(ProjectToTest):\n    \"\"\"A standalone program to run locally.\"\"\"\n\n    def __init__(\n        self, python_file: str, cur_dir: str | None = None, pip_args: str = \"\"\n    ):\n        super().__init__()\n        self.python_file = Path(python_file)\n        if not self.python_file.exists():\n            raise ValueError(f\"Couldn't find {self.python_file} to run ad-hoc.\")\n        self.cur_dir = Path(cur_dir or self.python_file.parent)\n        if not self.cur_dir.exists():\n            raise ValueError(f\"Couldn't find {self.cur_dir} to run in.\")\n        self.pip_args = pip_args\n        self.slug = self.python_file.name\n\n    def get_source(self, shell: ShellSession, retries: int = 5) -> None:\n        pass\n\n    def prep_environment(self, env: Env) -> None:\n        env.shell.run_command(f\"{env.python} -m pip install {self.pip_args}\")\n\n    def run_no_coverage(self, env: Env) -> float:\n        with change_dir(self.cur_dir):\n            env.shell.run_command(f\"{env.python} {self.python_file}\")\n        return env.shell.last_duration\n\n    def run_with_coverage(self, env: Env, cov_ver: Coverage) -> float:\n        env.shell.run_command(f\"{env.python} -m pip install {cov_ver.pip_args}\")\n        with change_dir(self.cur_dir):\n            env.shell.run_command(f\"{env.python} -m coverage run {self.python_file}\")\n        return env.shell.last_duration\n\n\nclass SlipcoverBenchmark(AdHocProject):\n    \"\"\"\n    For running code from the Slipcover benchmarks.\n\n    Clone https://github.com/plasma-umass/slipcover to /src/slipcover\n\n    \"\"\"\n\n    def __init__(self, python_file: str):\n        super().__init__(\n            python_file=f\"/src/slipcover/benchmarks/{python_file}\",\n            cur_dir=\"/src/slipcover\",\n            pip_args=\"six pyperf\",\n        )\n\n\nclass PyVersion:\n    \"\"\"A version of Python to use.\"\"\"\n\n    # The command to run this Python\n    command: str\n    # Short word for messages, directories, etc\n    slug: str\n    # The tox environment to run this Python\n    toxenv: str\n\n\nclass Python(PyVersion):\n    \"\"\"A version of CPython to use.\"\"\"\n\n    def __init__(self, major: int, minor: int):\n        self.command = self.slug = f\"python{major}.{minor}\"\n        self.toxenv = f\"py{major}{minor}\"\n\n\nclass PyPy(PyVersion):\n    \"\"\"A version of PyPy to use.\"\"\"\n\n    def __init__(self, major: int, minor: int):\n        self.command = self.slug = f\"pypy{major}.{minor}\"\n        self.toxenv = f\"pypy{major}{minor}\"\n\n\nclass AdHocPython(PyVersion):\n    \"\"\"A custom build of Python to use.\"\"\"\n\n    def __init__(self, path: str, slug: str):\n        self.command = f\"{path}/bin/python3\"\n        file_must_exist(self.command, \"python command\")\n        self.slug = slug\n        self.toxenv = \"\"\n\n\n@dataclass\nclass Coverage:\n    \"\"\"A version of coverage.py to use, maybe None.\"\"\"\n\n    # Short word for messages, directories, etc\n    slug: str\n    # Arguments for \"pip install ...\"\n    pip_args: str | None = None\n    # Tweaks to the .coveragerc file\n    tweaks: TweaksType = None\n    # Environment variables to set\n    env_vars: Env_VarsType = None\n\n\nclass NoCoverage(Coverage):\n    \"\"\"Run without coverage at all.\"\"\"\n\n    def __init__(self, slug: str = \"nocov\"):\n        super().__init__(slug=slug, pip_args=None)\n\n\nclass CoveragePR(Coverage):\n    \"\"\"A version of coverage.py from a pull request.\"\"\"\n\n    def __init__(\n        self, number: int, tweaks: TweaksType = None, env_vars: Env_VarsType = None\n    ):\n        url = f\"https://github.com/nedbat/coveragepy.git@refs/pull/{number}/merge\"\n        url_must_exist(url)\n        super().__init__(\n            slug=f\"#{number}\",\n            pip_args=f\"git+{url}\",\n            tweaks=tweaks,\n            env_vars=env_vars,\n        )\n\n\nclass CoverageCommit(Coverage):\n    \"\"\"A version of coverage.py from a specific commit.\"\"\"\n\n    def __init__(\n        self, sha: str, tweaks: TweaksType = None, env_vars: Env_VarsType = None\n    ):\n        url = f\"https://github.com/nedbat/coveragepy.git@{sha}\"\n        url_must_exist(url)\n        super().__init__(\n            slug=sha,\n            pip_args=f\"git+{url}\",\n            tweaks=tweaks,\n            env_vars=env_vars,\n        )\n\n\nclass CoverageSource(Coverage):\n    \"\"\"The coverage.py in a working tree.\"\"\"\n\n    def __init__(\n        self,\n        directory_name: str = \"..\",\n        slug: str = \"source\",\n        tweaks: TweaksType = None,\n        env_vars: Env_VarsType = None,\n    ):\n        directory = file_must_exist(directory_name, \"coverage directory\")\n        super().__init__(\n            slug=slug,\n            pip_args=str(directory),\n            tweaks=tweaks,\n            env_vars=env_vars,\n        )\n\n\n@dataclass\nclass Env:\n    \"\"\"An environment to run a test suite in.\"\"\"\n\n    pyver: PyVersion\n    python: Path\n    shell: ShellSession\n\n\nResultKey = Tuple[str, str, str]\n\nDIMENSION_NAMES = [\"proj\", \"pyver\", \"cov\"]\n\n\nclass Experiment:\n    \"\"\"A particular time experiment to run.\"\"\"\n\n    def __init__(\n        self,\n        py_versions: list[PyVersion],\n        cov_versions: list[Coverage],\n        projects: list[ProjectToTest],\n        results_file: str = \"results.json\",\n        load: bool = False,\n        cwd: str = \"\",\n    ):\n        self.py_versions = py_versions\n        self.cov_versions = cov_versions\n        self.projects = projects\n        self.results_file = Path(cwd) / Path(results_file)\n        self.result_data: dict[ResultKey, list[float]] = (\n            self.load_results() if load else {}\n        )\n        self.summary_data: dict[ResultKey, float] = {}\n\n    def save_results(self) -> None:\n        \"\"\"Save current results to the JSON file.\"\"\"\n        with self.results_file.open(\"w\") as f:\n            json.dump({\" \".join(k): v for k, v in self.result_data.items()}, f)\n\n    def load_results(self) -> dict[ResultKey, list[float]]:\n        \"\"\"Load results from the JSON file if it exists.\"\"\"\n        if self.results_file.exists():\n            with self.results_file.open(\"r\") as f:\n                data: dict[str, list[float]] = json.load(f)\n            return {\n                (k.split()[0], k.split()[1], k.split()[2]): v for k, v in data.items()\n            }\n        return {}\n\n    def run(self, num_runs: int = 3) -> None:\n        total_runs = (\n            len(self.projects)\n            * len(self.py_versions)\n            * len(self.cov_versions)\n            * num_runs\n        )\n        total_run_nums = iter(itertools.count(start=1))\n\n        all_runs = []\n\n        for proj in self.projects:\n            with proj.shell() as shell:\n                print(f\"Prepping project {proj.slug}\")\n                shell.print_banner(f\"Prepping project {proj.slug}\")\n                proj.make_dir()\n                proj.get_source(shell)\n\n                for pyver in self.py_versions:\n                    print(f\"Making venv for {proj.slug} {pyver.slug}\")\n                    venv_dir = f\"venv_{proj.slug}_{pyver.slug}\"\n                    shell.run_command(f\"{pyver.command} -m venv {venv_dir}\")\n                    python = Path.cwd() / f\"{venv_dir}/bin/python\"\n                    shell.run_command(f\"{python} -V\")\n                    shell.run_command(f\"{python} -m pip install -U pip\")\n                    env = Env(pyver, python, shell)\n\n                    with change_dir(proj.dir):\n                        print(f\"Prepping for {proj.slug} {pyver.slug}\")\n                        proj.prep_environment(env)\n                        for cov_ver in self.cov_versions:\n                            all_runs.append((proj, pyver, cov_ver, env))\n\n        all_runs *= num_runs\n        random.shuffle(all_runs)\n\n        run_data: dict[ResultKey, list[float]] = collections.defaultdict(list)\n        run_data.update(self.result_data)\n\n        for proj, pyver, cov_ver, env in all_runs:\n            result_key = (proj.slug, pyver.slug, cov_ver.slug)\n            total_run_num = next(total_run_nums)\n            if (\n                result_key in self.result_data\n                and len(self.result_data[result_key]) >= num_runs\n            ):\n                print(f\"Skipping {result_key} as results already exist.\")\n                continue\n\n            with env.shell:\n                banner = (\n                    \"Running tests: \"\n                    + f\"proj={proj.slug}, py={pyver.slug}, cov={cov_ver.slug}, \"\n                    + f\"{total_run_num} of {total_runs}\"\n                )\n                print(banner)\n                env.shell.print_banner(banner)\n                with change_dir(proj.dir):\n                    with env.shell.set_env(proj.env_vars, cov_ver.env_vars):\n                        try:\n                            if cov_ver.pip_args is None:\n                                dur = proj.run_no_coverage(env)\n                            else:\n                                dur = proj.run_with_coverage(env, cov_ver)\n                        except Exception as exc:\n                            print(f\"!!! {exc = }\")\n                            traceback.print_exc(file=env.shell.foutput)\n                            dur = float(\"NaN\")\n            print(f\"Tests took {dur:.3f}s\")\n            if result_key not in self.result_data:\n                self.result_data[result_key] = []\n            self.result_data[result_key].append(dur)\n            run_data[result_key].append(dur)\n            self.save_results()\n\n        # Summarize and collect the data.\n        print(\"# Results\")\n        for proj in self.projects:\n            for pyver in self.py_versions:\n                for cov_ver in self.cov_versions:\n                    result_key = (proj.slug, pyver.slug, cov_ver.slug)\n                    data = run_data[result_key]\n                    med = statistics.median(data)\n                    self.summary_data[result_key] = med\n                    stdev = statistics.stdev(data) if len(data) > 1 else 0.0\n                    summary = (\n                        f\"Median for {proj.slug}, {pyver.slug}, {cov_ver.slug}: \"\n                        + f\"{med:.3f}s, \"\n                        + f\"stdev={stdev:.3f}\"\n                    )\n                    if 1:\n                        data_sum = \", \".join(f\"{d:.3f}\" for d in data)\n                        summary += f\", data={data_sum}\"\n                    print(summary)\n\n    def show_results(\n        self,\n        rows: list[str],\n        column: str,\n        ratios: Iterable[tuple[str, str, str]] = (),\n    ) -> None:\n        dimensions = {\n            \"cov\": [cov_ver.slug for cov_ver in self.cov_versions],\n            \"pyver\": [pyver.slug for pyver in self.py_versions],\n            \"proj\": [proj.slug for proj in self.projects],\n        }\n\n        table_axes = [dimensions[rowname] for rowname in rows]\n        data_order = [*rows, column]\n        remap = [data_order.index(datum) for datum in DIMENSION_NAMES]\n\n        header = []\n        header.extend(rows)\n        header.extend(dimensions[column])\n        header.extend(slug for slug, _, _ in ratios)\n\n        aligns = [\"left\"] * len(rows) + [\"right\"] * (len(header) - len(rows))\n        data = []\n\n        for tup in itertools.product(*table_axes):\n            row: list[str] = []\n            row.extend(tup)\n            col_data = {}\n            for col in dimensions[column]:\n                key = (*tup, col)\n                key = tuple(key[i] for i in remap)\n                key = cast(ResultKey, key)\n                result_time = self.summary_data[key]\n                row.append(f\"{result_time:.1f}s\")\n                col_data[col] = result_time\n            for _, num, denom in ratios:\n                ratio = col_data[num] / col_data[denom]\n                row.append(f\"{ratio * 100:.0f}%\")\n            data.append(row)\n\n        print()\n        print(tabulate.tabulate(data, headers=header, colalign=aligns, tablefmt=\"pipe\"))\n\n\nPERF_DIR = Path(\"/tmp/covperf\")\n\n\ndef run_experiment(\n    py_versions: list[PyVersion],\n    cov_versions: list[Coverage],\n    projects: list[ProjectToTest],\n    rows: list[str],\n    column: str,\n    ratios: Iterable[tuple[str, str, str]] = (),\n    num_runs: int = int(sys.argv[1]),\n    load: bool = False,\n) -> None:\n    \"\"\"\n    Run a benchmarking experiment and print a table of results.\n\n    Arguments:\n\n        py_versions: The Python versions to test.\n        cov_versions: The coverage versions to test.\n        projects: The projects to run.\n        rows: A list of strings chosen from `\"pyver\"`, `\"cov\"`, and `\"proj\"`.\n        column: The remaining dimension not used in `rows`.\n        ratios: A list of triples: (title, slug1, slug2).\n        num_runs: The number of times to run each matrix element.\n\n    \"\"\"\n    slugs = [v.slug for v in py_versions + cov_versions + projects]\n    if len(set(slugs)) != len(slugs):\n        raise Exception(f\"Slugs must be unique: {slugs}\")\n    if any(\" \" in slug for slug in slugs):\n        raise Exception(f\"No spaces in slugs please: {slugs}\")\n    ratio_slugs = [rslug for ratio in ratios for rslug in ratio[1:]]\n    if any(rslug not in slugs for rslug in ratio_slugs):\n        raise Exception(f\"Ratio slug doesn't match a slug: {ratio_slugs}, {slugs}\")\n    if set(rows + [column]) != set(DIMENSION_NAMES):\n        raise Exception(\n            f\"All of these must be in rows or column: {', '.join(DIMENSION_NAMES)}\"\n        )\n\n    print(f\"Removing and re-making {PERF_DIR}\")\n    rmrf(PERF_DIR)\n\n    cwd = str(Path.cwd())\n    with change_dir(PERF_DIR):\n        exp = Experiment(\n            py_versions=py_versions,\n            cov_versions=cov_versions,\n            projects=projects,\n            load=load,\n            cwd=cwd,\n        )\n        exp.run(num_runs=int(num_runs))\n        exp.show_results(rows=rows, column=column, ratios=ratios)\n", "benchmark/empty.py": "from benchmark import *\n\nrun_experiment(\n    py_versions=[\n        Python(3, 9),\n        Python(3, 11),\n    ],\n    cov_versions=[\n        Coverage(\"701\", \"coverage==7.0.1\"),\n        Coverage(\n            \"701.dynctx\", \"coverage==7.0.1\", [(\"dynamic_context\", \"test_function\")]\n        ),\n        Coverage(\"702\", \"coverage==7.0.2\"),\n        Coverage(\n            \"702.dynctx\", \"coverage==7.0.2\", [(\"dynamic_context\", \"test_function\")]\n        ),\n    ],\n    projects=[\n        EmptyProject(\"empty\", [1.2, 3.4]),\n        EmptyProject(\"dummy\", [6.9, 7.1]),\n    ],\n    rows=[\"proj\", \"pyver\"],\n    column=\"cov\",\n    ratios=[\n        (\".2 vs .1\", \"702\", \"701\"),\n        (\".1 dynctx cost\", \"701.dynctx\", \"701\"),\n        (\".2 dynctx cost\", \"702.dynctx\", \"702\"),\n    ],\n)\n", "benchmark/fake.py": "from benchmark import *\n\nclass ProjectSlow(EmptyProject):\n    def __init__(self):\n        super().__init__(slug=\"slow\", fake_durations=[23.9, 24.2])\n\nclass ProjectOdd(EmptyProject):\n    def __init__(self):\n        super().__init__(slug=\"odd\", fake_durations=[10.1, 10.5, 9.9])\n\n\nrun_experiment(\n    py_versions=[\n        Python(3, 10),\n        Python(3, 11),\n    #    Python(3, 12),\n    ],\n    cov_versions=[\n        Coverage(\"753\", \"coverage==7.5.3\"),\n        CoverageSource(\"~/coverage\"),\n    ],\n    projects=[\n        ProjectSlow(),\n        ProjectOdd(),\n    ],\n    rows=[\"cov\", \"proj\"],\n    column=\"pyver\",\n    ratios=[\n        (\"11 vs 10\", \"python3.11\", \"python3.10\"),\n    #    (\"12 vs 11\", \"python3.12\", \"python3.11\"),\n    ],\n)\n", "ci/parse_relnotes.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"\nParse CHANGES.md into a JSON structure.\n\nRun with two arguments: the .md file to parse, and the JSON file to write:\n\n\tpython parse_relnotes.py CHANGES.md relnotes.json\n\nEvery section that has something that looks like a version number in it will\nbe recorded as the release notes for that version.\n\n\"\"\"\n\nimport json\nimport re\nimport sys\n\n\nclass TextChunkBuffer:\n    \"\"\"Hold onto text chunks until needed.\"\"\"\n    def __init__(self):\n        self.buffer = []\n\n    def append(self, text):\n        \"\"\"Add `text` to the buffer.\"\"\"\n        self.buffer.append(text)\n\n    def clear(self):\n        \"\"\"Clear the buffer.\"\"\"\n        self.buffer = []\n\n    def flush(self):\n        \"\"\"Produce a (\"text\", text) tuple if there's anything here.\"\"\"\n        buffered = \"\".join(self.buffer).strip()\n        if buffered:\n            yield (\"text\", buffered)\n        self.clear()\n\n\ndef parse_md(lines):\n    \"\"\"Parse markdown lines, producing (type, text) chunks.\"\"\"\n    buffer = TextChunkBuffer()\n\n    for line in lines:\n        if header_match := re.search(r\"^(#+) (.+)$\", line):\n            yield from buffer.flush()\n            hashes, text = header_match.groups()\n            yield (f\"h{len(hashes)}\", text)\n        else:\n            buffer.append(line)\n\n    yield from buffer.flush()\n\n\ndef sections(parsed_data):\n    \"\"\"Convert a stream of parsed tokens into sections with text and notes.\n\n    Yields a stream of:\n        ('h-level', 'header text', 'text')\n\n    \"\"\"\n    header = None\n    text = []\n    for ttype, ttext in parsed_data:\n        if ttype.startswith('h'):\n            if header:\n                yield (*header, \"\\n\".join(text))\n            text = []\n            header = (ttype, ttext)\n        elif ttype == \"text\":\n            text.append(ttext)\n        else:\n            raise RuntimeError(f\"Don't know ttype {ttype!r}\")\n    yield (*header, \"\\n\".join(text))\n\n\ndef refind(regex, text):\n    \"\"\"Find a regex in some text, and return the matched text, or None.\"\"\"\n    if m := re.search(regex, text):\n        return m.group()\n    else:\n        return None\n\n\ndef fix_ref_links(text, version):\n    \"\"\"Find links to .rst files, and make them full RTFD links.\"\"\"\n    def new_link(m):\n        return f\"](https://coverage.readthedocs.io/en/{version}/{m[1]}.html{m[2]})\"\n    return re.sub(r\"\\]\\((\\w+)\\.rst(#.*?)\\)\", new_link, text)\n\n\ndef relnotes(mdlines):\n    r\"\"\"Yield (version, text) pairs from markdown lines.\n\n    Each tuple is a separate version mentioned in the release notes.\n\n    A version is any section with \\d\\.\\d in the header text.\n\n    \"\"\"\n    for _, htext, text in sections(parse_md(mdlines)):\n        version = refind(r\"\\d+\\.\\d[^ ]*\", htext)\n        if version:\n            prerelease = any(c in version for c in \"abc\")\n            when = refind(r\"\\d+-\\d+-\\d+\", htext)\n            text = fix_ref_links(text, version)\n            yield {\n                \"version\": version,\n                \"text\": text,\n                \"prerelease\": prerelease,\n                \"when\": when,\n            }\n\ndef parse(md_filename, json_filename):\n    \"\"\"Main function: parse markdown and write JSON.\"\"\"\n    with open(md_filename) as mf:\n        markdown = mf.read()\n    with open(json_filename, \"w\") as jf:\n        json.dump(list(relnotes(markdown.splitlines(True))), jf, indent=4)\n\nif __name__ == \"__main__\":\n    parse(*sys.argv[1:3])\n", "ci/trigger_action.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Trigger a repository_dispatch GitHub action.\"\"\"\n\nimport sys\n\nfrom session import get_session\n\nrepo_owner, event_type = sys.argv[1:]\n\n# The GitHub URL makes no mention of which workflow to use. It's found based on\n# the event_type, which matches the types in the workflow:\n#\n#   on:\n#     repository_dispatch:\n#       types:\n#         - build-kits\n#\n\nurl = f\"https://api.github.com/repos/{repo_owner}/dispatches\"\ndata = {\"event_type\": event_type}\n\nresp = get_session().post(url, json=data)\nif resp.status_code // 100 == 2:\n    print(\"Success\")\nelse:\n    print(f\"Status: {resp.status_code}\")\n    print(resp.text)\n", "ci/comment_on_fixes.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Add a release comment to all the issues mentioned in the latest release.\"\"\"\n\nimport json\nimport re\nimport sys\n\nfrom session import get_session\n\nwith open(\"tmp/relnotes.json\") as frn:\n    relnotes = json.load(frn)\n\nlatest = relnotes[0]\nversion = latest[\"version\"]\ncomment = (\n    f\"This is now released as part of [coverage {version}]\" +\n    f\"(https://pypi.org/project/coverage/{version}).\"\n)\nprint(f\"Comment will be:\\n\\n{comment}\\n\")\n\nrepo_owner = sys.argv[1]\nfor m in re.finditer(fr\"https://github.com/{repo_owner}/(issues|pull)/(\\d+)\", latest[\"text\"]):\n    kind, number = m.groups()\n    do_comment = False\n\n    if kind == \"issues\":\n        url = f\"https://api.github.com/repos/{repo_owner}/issues/{number}\"\n        issue_data = get_session().get(url).json()\n        if issue_data[\"state\"] == \"closed\":\n            do_comment = True\n        else:\n            print(f\"Still open, comment manually: {m[0]}\")\n    else:\n        url = f\"https://api.github.com/repos/{repo_owner}/pulls/{number}\"\n        pull_data = get_session().get(url).json()\n        if pull_data[\"state\"] == \"closed\":\n            if pull_data[\"merged\"]:\n                do_comment = True\n            else:\n                print(f\"Not merged, comment manually: {m[0]}\")\n        else:\n            print(f\"Still open, comment manually: {m[0]}\")\n\n    if do_comment:\n        print(f\"Commenting on {m[0]}\")\n        url = f\"https://api.github.com/repos/{repo_owner}/issues/{number}/comments\"\n        resp = get_session().post(url, json={\"body\": comment})\n        print(resp)\n", "ci/session.py": "# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0\n# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt\n\n\"\"\"Help make a requests Session with proper authentication.\"\"\"\n\nimport os\nimport sys\n\nimport requests\n\n_SESSION = None\n\ndef get_session():\n    \"\"\"Get a properly authenticated requests Session.\"\"\"\n\n    global _SESSION\n\n    if _SESSION is None:\n        # If GITHUB_TOKEN is in the environment, use it.\n        token = os.environ.get(\"GITHUB_TOKEN\")\n        if token is None:\n            sys.exit(\"!! Must have a GITHUB_TOKEN\")\n\n        _SESSION = requests.session()\n        _SESSION.headers[\"Authorization\"] = f\"token {token}\"\n        # requests.get() will always prefer the .netrc file even if a header\n        # is already set.  This tells it to ignore the .netrc file.\n        _SESSION.trust_env = False\n\n    return _SESSION\n"}