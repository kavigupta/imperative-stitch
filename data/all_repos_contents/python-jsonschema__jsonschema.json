{"noxfile.py": "from pathlib import Path\nfrom tempfile import TemporaryDirectory\nimport os\n\nimport nox\n\nROOT = Path(__file__).parent\nPACKAGE = ROOT / \"jsonschema\"\nBENCHMARKS = PACKAGE / \"benchmarks\"\nPYPROJECT = ROOT / \"pyproject.toml\"\nCHANGELOG = ROOT / \"CHANGELOG.rst\"\nDOCS = ROOT / \"docs\"\n\nINSTALLABLE = [\n    nox.param(value, id=name) for name, value in [\n        (\"no-extras\", str(ROOT)),\n        (\"format\", f\"{ROOT}[format]\"),\n        (\"format-nongpl\", f\"{ROOT}[format-nongpl]\"),\n    ]\n]\nREQUIREMENTS = dict(\n    docs=DOCS / \"requirements.txt\",\n)\nREQUIREMENTS_IN = [  # this is actually ordered, as files depend on each other\n    path.parent / f\"{path.stem}.in\" for path in REQUIREMENTS.values()\n]\n\nNONGPL_LICENSES = [\n    \"Apache Software License\",\n    \"BSD License\",\n    \"ISC License (ISCL)\",\n    \"MIT License\",\n    \"Mozilla Public License 2.0 (MPL 2.0)\",\n    \"Python Software Foundation License\",\n    \"The Unlicense (Unlicense)\",\n]\n\nSUPPORTED = [\"3.8\", \"3.9\", \"3.10\", \"pypy3.10\", \"3.11\", \"3.12\"]\nLATEST = SUPPORTED[-1]\n\nnox.options.sessions = []\n\n\ndef session(default=True, python=LATEST, **kwargs):  # noqa: D103\n    def _session(fn):\n        if default:\n            nox.options.sessions.append(kwargs.get(\"name\", fn.__name__))\n        return nox.session(python=python, **kwargs)(fn)\n\n    return _session\n\n\n@session(python=SUPPORTED)\n@nox.parametrize(\"installable\", INSTALLABLE)\ndef tests(session, installable):\n    \"\"\"\n    Run the test suite with a corresponding Python version.\n    \"\"\"\n    env = dict(JSON_SCHEMA_TEST_SUITE=str(ROOT / \"json\"))\n\n    session.install(\"virtue\", installable)\n\n    if session.posargs and session.posargs[0] == \"coverage\":\n        if len(session.posargs) > 1 and session.posargs[1] == \"github\":\n            posargs = session.posargs[2:]\n            github = Path(os.environ[\"GITHUB_STEP_SUMMARY\"])\n        else:\n            posargs, github = session.posargs[1:], None\n\n        session.install(\"coverage[toml]\")\n        session.run(\n            \"coverage\",\n            \"run\",\n            *posargs,\n            \"-m\",\n            \"virtue\",\n            PACKAGE,\n            env=env,\n        )\n\n        if github is None:\n            session.run(\"coverage\", \"report\")\n        else:\n            with github.open(\"a\") as summary:\n                summary.write(\"### Coverage\\n\\n\")\n                summary.flush()  # without a flush, output seems out of order.\n                session.run(\n                    \"coverage\",\n                    \"report\",\n                    \"--format=markdown\",\n                    stdout=summary,\n                )\n    else:\n        session.run(\"virtue\", *session.posargs, PACKAGE, env=env)\n\n\n@session()\n@nox.parametrize(\"installable\", INSTALLABLE)\ndef audit(session, installable):\n    \"\"\"\n    Audit dependencies for vulnerabilities.\n    \"\"\"\n    session.install(\"pip-audit\", installable)\n    session.run(\"python\", \"-m\", \"pip_audit\")\n\n\n@session()\ndef license_check(session):\n    \"\"\"\n    Check that the non-GPL extra does not allow arbitrary licenses.\n    \"\"\"\n    session.install(\"pip-licenses\", f\"{ROOT}[format-nongpl]\")\n    session.run(\n        \"python\",\n        \"-m\",\n        \"piplicenses\",\n        \"--ignore-packages\",\n        \"pip-requirements-parser\",\n        \"pip_audit\",\n        \"pip-api\",\n        \"--allow-only\",\n        \";\".join(NONGPL_LICENSES),\n    )\n\n\n@session(tags=[\"build\"])\ndef build(session):\n    \"\"\"\n    Build a distribution suitable for PyPI and check its validity.\n    \"\"\"\n    session.install(\"build\", \"docutils\", \"twine\")\n    with TemporaryDirectory() as tmpdir:\n        session.run(\"python\", \"-m\", \"build\", ROOT, \"--outdir\", tmpdir)\n        session.run(\"twine\", \"check\", \"--strict\", tmpdir + \"/*\")\n        session.run(\n            \"python\", \"-m\", \"docutils\", \"--strict\", CHANGELOG, os.devnull,\n        )\n\n\n@session()\ndef secrets(session):\n    \"\"\"\n    Check for accidentally committed secrets.\n    \"\"\"\n    session.install(\"detect-secrets\")\n    session.run(\"detect-secrets\", \"scan\", ROOT)\n\n\n@session(tags=[\"style\"])\ndef style(session):\n    \"\"\"\n    Check Python code style.\n    \"\"\"\n    session.install(\"ruff\")\n    session.run(\"ruff\", \"check\", ROOT)\n\n\n@session()\ndef typing(session):\n    \"\"\"\n    Check static typing.\n    \"\"\"\n    session.install(\"mypy\", \"types-requests\", ROOT)\n    session.run(\"mypy\", \"--config\", PYPROJECT, PACKAGE)\n\n\n@session(tags=[\"docs\"])\n@nox.parametrize(\n    \"builder\",\n    [\n        nox.param(name, id=name)\n        for name in [\n            \"dirhtml\",\n            \"doctest\",\n            \"linkcheck\",\n            \"man\",\n            \"spelling\",\n        ]\n    ],\n)\ndef docs(session, builder):\n    \"\"\"\n    Build the documentation using a specific Sphinx builder.\n    \"\"\"\n    session.install(\"-r\", REQUIREMENTS[\"docs\"])\n    with TemporaryDirectory() as tmpdir_str:\n        tmpdir = Path(tmpdir_str)\n        argv = [\"-n\", \"-T\", \"-W\"]\n        if builder != \"spelling\":\n            argv += [\"-q\"]\n        posargs = session.posargs or [tmpdir / builder]\n        session.run(\n            \"python\",\n            \"-m\",\n            \"sphinx\",\n            \"-b\",\n            builder,\n            DOCS,\n            *argv,\n            *posargs,\n        )\n\n\n@session(tags=[\"docs\", \"style\"], name=\"docs(style)\")\ndef docs_style(session):\n    \"\"\"\n    Check the documentation style.\n    \"\"\"\n    session.install(\n        \"doc8\",\n        \"pygments\",\n        \"pygments-github-lexers\",\n    )\n    session.run(\"python\", \"-m\", \"doc8\", \"--config\", PYPROJECT, DOCS)\n\n\n@session(default=False)\n@nox.parametrize(\n    \"benchmark\",\n    [\n        nox.param(each.stem, id=each.stem)\n        for each in BENCHMARKS.glob(\"[!_]*.py\")\n    ],\n)\ndef bench(session, benchmark):\n    \"\"\"\n    Run a performance benchmark.\n    \"\"\"\n    session.install(\"pyperf\", f\"{ROOT}[format]\")\n    tmpdir = Path(session.create_tmp())\n    output = tmpdir / f\"bench-{benchmark}.json\"\n    session.run(\"python\", BENCHMARKS / f\"{benchmark}.py\", \"--output\", output)\n\n\n@session(default=False)\ndef requirements(session):\n    \"\"\"\n    Update the project's pinned requirements.\n\n    You should commit the result afterwards.\n    \"\"\"\n    session.install(\"pip-tools\")\n    for each in REQUIREMENTS_IN:\n        session.run(\n            \"pip-compile\",\n            \"--resolver\",\n            \"backtracking\",\n            \"--strip-extras\",\n            \"-U\",\n            each.relative_to(ROOT),\n        )\n", "jsonschema/protocols.py": "\"\"\"\ntyping.Protocol classes for jsonschema interfaces.\n\"\"\"\n\n# for reference material on Protocols, see\n#   https://www.python.org/dev/peps/pep-0544/\n\nfrom __future__ import annotations\n\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    ClassVar,\n    Iterable,\n    Protocol,\n    runtime_checkable,\n)\n\n# in order for Sphinx to resolve references accurately from type annotations,\n# it needs to see names like `jsonschema.TypeChecker`\n# therefore, only import at type-checking time (to avoid circular references),\n# but use `jsonschema` for any types which will otherwise not be resolvable\nif TYPE_CHECKING:\n    from collections.abc import Mapping\n\n    import referencing.jsonschema\n\n    from jsonschema import _typing\n    from jsonschema.exceptions import ValidationError\n    import jsonschema\n    import jsonschema.validators\n\n# For code authors working on the validator protocol, these are the three\n# use-cases which should be kept in mind:\n#\n# 1. As a protocol class, it can be used in type annotations to describe the\n#    available methods and attributes of a validator\n# 2. It is the source of autodoc for the validator documentation\n# 3. It is runtime_checkable, meaning that it can be used in isinstance()\n#    checks.\n#\n# Since protocols are not base classes, isinstance() checking is limited in\n# its capabilities. See docs on runtime_checkable for detail\n\n\n@runtime_checkable\nclass Validator(Protocol):\n    \"\"\"\n    The protocol to which all validator classes adhere.\n\n    Arguments:\n\n        schema:\n\n            The schema that the validator object will validate with.\n            It is assumed to be valid, and providing\n            an invalid schema can lead to undefined behavior. See\n            `Validator.check_schema` to validate a schema first.\n\n        registry:\n\n            a schema registry that will be used for looking up JSON references\n\n        resolver:\n\n            a resolver that will be used to resolve :kw:`$ref`\n            properties (JSON references). If unprovided, one will be created.\n\n            .. deprecated:: v4.18.0\n\n                `RefResolver <_RefResolver>` has been deprecated in favor of\n                `referencing`, and with it, this argument.\n\n        format_checker:\n\n            if provided, a checker which will be used to assert about\n            :kw:`format` properties present in the schema. If unprovided,\n            *no* format validation is done, and the presence of format\n            within schemas is strictly informational. Certain formats\n            require additional packages to be installed in order to assert\n            against instances. Ensure you've installed `jsonschema` with\n            its `extra (optional) dependencies <index:extras>` when\n            invoking ``pip``.\n\n    .. deprecated:: v4.12.0\n\n        Subclassing validator classes now explicitly warns this is not part of\n        their public API.\n\n    \"\"\"\n\n    #: An object representing the validator's meta schema (the schema that\n    #: describes valid schemas in the given version).\n    META_SCHEMA: ClassVar[Mapping]\n\n    #: A mapping of validation keywords (`str`\\s) to functions that\n    #: validate the keyword with that name. For more information see\n    #: `creating-validators`.\n    VALIDATORS: ClassVar[Mapping]\n\n    #: A `jsonschema.TypeChecker` that will be used when validating\n    #: :kw:`type` keywords in JSON schemas.\n    TYPE_CHECKER: ClassVar[jsonschema.TypeChecker]\n\n    #: A `jsonschema.FormatChecker` that will be used when validating\n    #: :kw:`format` keywords in JSON schemas.\n    FORMAT_CHECKER: ClassVar[jsonschema.FormatChecker]\n\n    #: A function which given a schema returns its ID.\n    ID_OF: _typing.id_of\n\n    #: The schema that will be used to validate instances\n    schema: Mapping | bool\n\n    def __init__(\n        self,\n        schema: Mapping | bool,\n        registry: referencing.jsonschema.SchemaRegistry,\n        format_checker: jsonschema.FormatChecker | None = None,\n    ) -> None:\n        ...\n\n    @classmethod\n    def check_schema(cls, schema: Mapping | bool) -> None:\n        \"\"\"\n        Validate the given schema against the validator's `META_SCHEMA`.\n\n        Raises:\n\n            `jsonschema.exceptions.SchemaError`:\n\n                if the schema is invalid\n\n        \"\"\"\n\n    def is_type(self, instance: Any, type: str) -> bool:\n        \"\"\"\n        Check if the instance is of the given (JSON Schema) type.\n\n        Arguments:\n\n            instance:\n\n                the value to check\n\n            type:\n\n                the name of a known (JSON Schema) type\n\n        Returns:\n\n            whether the instance is of the given type\n\n        Raises:\n\n            `jsonschema.exceptions.UnknownType`:\n\n                if ``type`` is not a known type\n\n        \"\"\"\n\n    def is_valid(self, instance: Any) -> bool:\n        \"\"\"\n        Check if the instance is valid under the current `schema`.\n\n        Returns:\n\n            whether the instance is valid or not\n\n        >>> schema = {\"maxItems\" : 2}\n        >>> Draft202012Validator(schema).is_valid([2, 3, 4])\n        False\n\n        \"\"\"\n\n    def iter_errors(self, instance: Any) -> Iterable[ValidationError]:\n        r\"\"\"\n        Lazily yield each of the validation errors in the given instance.\n\n        >>> schema = {\n        ...     \"type\" : \"array\",\n        ...     \"items\" : {\"enum\" : [1, 2, 3]},\n        ...     \"maxItems\" : 2,\n        ... }\n        >>> v = Draft202012Validator(schema)\n        >>> for error in sorted(v.iter_errors([2, 3, 4]), key=str):\n        ...     print(error.message)\n        4 is not one of [1, 2, 3]\n        [2, 3, 4] is too long\n\n        .. deprecated:: v4.0.0\n\n            Calling this function with a second schema argument is deprecated.\n            Use `Validator.evolve` instead.\n        \"\"\"\n\n    def validate(self, instance: Any) -> None:\n        \"\"\"\n        Check if the instance is valid under the current `schema`.\n\n        Raises:\n\n            `jsonschema.exceptions.ValidationError`:\n\n                if the instance is invalid\n\n        >>> schema = {\"maxItems\" : 2}\n        >>> Draft202012Validator(schema).validate([2, 3, 4])\n        Traceback (most recent call last):\n            ...\n        ValidationError: [2, 3, 4] is too long\n\n        \"\"\"\n\n    def evolve(self, **kwargs) -> Validator:\n        \"\"\"\n        Create a new validator like this one, but with given changes.\n\n        Preserves all other attributes, so can be used to e.g. create a\n        validator with a different schema but with the same :kw:`$ref`\n        resolution behavior.\n\n        >>> validator = Draft202012Validator({})\n        >>> validator.evolve(schema={\"type\": \"number\"})\n        Draft202012Validator(schema={'type': 'number'}, format_checker=None)\n\n        The returned object satisfies the validator protocol, but may not\n        be of the same concrete class! In particular this occurs\n        when a :kw:`$ref` occurs to a schema with a different\n        :kw:`$schema` than this one (i.e. for a different draft).\n\n        >>> validator.evolve(\n        ...     schema={\"$schema\": Draft7Validator.META_SCHEMA[\"$id\"]}\n        ... )\n        Draft7Validator(schema=..., format_checker=None)\n        \"\"\"\n", "jsonschema/cli.py": "\"\"\"\nThe ``jsonschema`` command line.\n\"\"\"\n\nfrom importlib import metadata\nfrom json import JSONDecodeError\nfrom textwrap import dedent\nimport argparse\nimport json\nimport sys\nimport traceback\nimport warnings\n\ntry:\n    from pkgutil import resolve_name\nexcept ImportError:\n    from pkgutil_resolve_name import resolve_name  # type: ignore[no-redef]\n\nfrom attrs import define, field\n\nfrom jsonschema.exceptions import SchemaError\nfrom jsonschema.validators import _RefResolver, validator_for\n\nwarnings.warn(\n    (\n        \"The jsonschema CLI is deprecated and will be removed in a future \"\n        \"version. Please use check-jsonschema instead, which can be installed \"\n        \"from https://pypi.org/project/check-jsonschema/\"\n    ),\n    DeprecationWarning,\n    stacklevel=2,\n)\n\n\nclass _CannotLoadFile(Exception):\n    pass\n\n\n@define\nclass _Outputter:\n\n    _formatter = field()\n    _stdout = field()\n    _stderr = field()\n\n    @classmethod\n    def from_arguments(cls, arguments, stdout, stderr):\n        if arguments[\"output\"] == \"plain\":\n            formatter = _PlainFormatter(arguments[\"error_format\"])\n        elif arguments[\"output\"] == \"pretty\":\n            formatter = _PrettyFormatter()\n        return cls(formatter=formatter, stdout=stdout, stderr=stderr)\n\n    def load(self, path):\n        try:\n            file = open(path)  # noqa: SIM115, PTH123\n        except FileNotFoundError as error:\n            self.filenotfound_error(path=path, exc_info=sys.exc_info())\n            raise _CannotLoadFile() from error\n\n        with file:\n            try:\n                return json.load(file)\n            except JSONDecodeError as error:\n                self.parsing_error(path=path, exc_info=sys.exc_info())\n                raise _CannotLoadFile() from error\n\n    def filenotfound_error(self, **kwargs):\n        self._stderr.write(self._formatter.filenotfound_error(**kwargs))\n\n    def parsing_error(self, **kwargs):\n        self._stderr.write(self._formatter.parsing_error(**kwargs))\n\n    def validation_error(self, **kwargs):\n        self._stderr.write(self._formatter.validation_error(**kwargs))\n\n    def validation_success(self, **kwargs):\n        self._stdout.write(self._formatter.validation_success(**kwargs))\n\n\n@define\nclass _PrettyFormatter:\n\n    _ERROR_MSG = dedent(\n        \"\"\"\\\n        ===[{type}]===({path})===\n\n        {body}\n        -----------------------------\n        \"\"\",\n    )\n    _SUCCESS_MSG = \"===[SUCCESS]===({path})===\\n\"\n\n    def filenotfound_error(self, path, exc_info):\n        return self._ERROR_MSG.format(\n            path=path,\n            type=\"FileNotFoundError\",\n            body=f\"{path!r} does not exist.\",\n        )\n\n    def parsing_error(self, path, exc_info):\n        exc_type, exc_value, exc_traceback = exc_info\n        exc_lines = \"\".join(\n            traceback.format_exception(exc_type, exc_value, exc_traceback),\n        )\n        return self._ERROR_MSG.format(\n            path=path,\n            type=exc_type.__name__,\n            body=exc_lines,\n        )\n\n    def validation_error(self, instance_path, error):\n        return self._ERROR_MSG.format(\n            path=instance_path,\n            type=error.__class__.__name__,\n            body=error,\n        )\n\n    def validation_success(self, instance_path):\n        return self._SUCCESS_MSG.format(path=instance_path)\n\n\n@define\nclass _PlainFormatter:\n\n    _error_format = field()\n\n    def filenotfound_error(self, path, exc_info):\n        return f\"{path!r} does not exist.\\n\"\n\n    def parsing_error(self, path, exc_info):\n        return \"Failed to parse {}: {}\\n\".format(\n            \"<stdin>\" if path == \"<stdin>\" else repr(path),\n            exc_info[1],\n        )\n\n    def validation_error(self, instance_path, error):\n        return self._error_format.format(file_name=instance_path, error=error)\n\n    def validation_success(self, instance_path):\n        return \"\"\n\n\ndef _resolve_name_with_default(name):\n    if \".\" not in name:\n        name = \"jsonschema.\" + name\n    return resolve_name(name)\n\n\nparser = argparse.ArgumentParser(\n    description=\"JSON Schema Validation CLI\",\n)\nparser.add_argument(\n    \"-i\", \"--instance\",\n    action=\"append\",\n    dest=\"instances\",\n    help=\"\"\"\n        a path to a JSON instance (i.e. filename.json) to validate (may\n        be specified multiple times). If no instances are provided via this\n        option, one will be expected on standard input.\n    \"\"\",\n)\nparser.add_argument(\n    \"-F\", \"--error-format\",\n    help=\"\"\"\n        the format to use for each validation error message, specified\n        in a form suitable for str.format. This string will be passed\n        one formatted object named 'error' for each ValidationError.\n        Only provide this option when using --output=plain, which is the\n        default. If this argument is unprovided and --output=plain is\n        used, a simple default representation will be used.\n    \"\"\",\n)\nparser.add_argument(\n    \"-o\", \"--output\",\n    choices=[\"plain\", \"pretty\"],\n    default=\"plain\",\n    help=\"\"\"\n        an output format to use. 'plain' (default) will produce minimal\n        text with one line for each error, while 'pretty' will produce\n        more detailed human-readable output on multiple lines.\n    \"\"\",\n)\nparser.add_argument(\n    \"-V\", \"--validator\",\n    type=_resolve_name_with_default,\n    help=\"\"\"\n        the fully qualified object name of a validator to use, or, for\n        validators that are registered with jsonschema, simply the name\n        of the class.\n    \"\"\",\n)\nparser.add_argument(\n    \"--base-uri\",\n    help=\"\"\"\n        a base URI to assign to the provided schema, even if it does not\n        declare one (via e.g. $id). This option can be used if you wish to\n        resolve relative references to a particular URI (or local path)\n    \"\"\",\n)\nparser.add_argument(\n    \"--version\",\n    action=\"version\",\n    version=metadata.version(\"jsonschema\"),\n)\nparser.add_argument(\n    \"schema\",\n    help=\"the path to a JSON Schema to validate with (i.e. schema.json)\",\n)\n\n\ndef parse_args(args):  # noqa: D103\n    arguments = vars(parser.parse_args(args=args or [\"--help\"]))\n    if arguments[\"output\"] != \"plain\" and arguments[\"error_format\"]:\n        raise parser.error(\n            \"--error-format can only be used with --output plain\",\n        )\n    if arguments[\"output\"] == \"plain\" and arguments[\"error_format\"] is None:\n        arguments[\"error_format\"] = \"{error.instance}: {error.message}\\n\"\n    return arguments\n\n\ndef _validate_instance(instance_path, instance, validator, outputter):\n    invalid = False\n    for error in validator.iter_errors(instance):\n        invalid = True\n        outputter.validation_error(instance_path=instance_path, error=error)\n\n    if not invalid:\n        outputter.validation_success(instance_path=instance_path)\n    return invalid\n\n\ndef main(args=sys.argv[1:]):  # noqa: D103\n    sys.exit(run(arguments=parse_args(args=args)))\n\n\ndef run(arguments, stdout=sys.stdout, stderr=sys.stderr, stdin=sys.stdin):  # noqa: D103\n    outputter = _Outputter.from_arguments(\n        arguments=arguments,\n        stdout=stdout,\n        stderr=stderr,\n    )\n\n    try:\n        schema = outputter.load(arguments[\"schema\"])\n    except _CannotLoadFile:\n        return 1\n\n    Validator = arguments[\"validator\"]\n    if Validator is None:\n        Validator = validator_for(schema)\n\n    try:\n        Validator.check_schema(schema)\n    except SchemaError as error:\n        outputter.validation_error(\n            instance_path=arguments[\"schema\"],\n            error=error,\n        )\n        return 1\n\n    if arguments[\"instances\"]:\n        load, instances = outputter.load, arguments[\"instances\"]\n    else:\n        def load(_):\n            try:\n                return json.load(stdin)\n            except JSONDecodeError as error:\n                outputter.parsing_error(\n                    path=\"<stdin>\", exc_info=sys.exc_info(),\n                )\n                raise _CannotLoadFile() from error\n        instances = [\"<stdin>\"]\n\n    resolver = _RefResolver(\n        base_uri=arguments[\"base_uri\"],\n        referrer=schema,\n    ) if arguments[\"base_uri\"] is not None else None\n\n    validator = Validator(schema, resolver=resolver)\n    exit_code = 0\n    for each in instances:\n        try:\n            instance = load(each)\n        except _CannotLoadFile:\n            exit_code = 1\n        else:\n            exit_code |= _validate_instance(\n                instance_path=each,\n                instance=instance,\n                validator=validator,\n                outputter=outputter,\n            )\n\n    return exit_code\n", "jsonschema/exceptions.py": "\"\"\"\nValidation errors, and some surrounding helpers.\n\"\"\"\nfrom __future__ import annotations\n\nfrom collections import defaultdict, deque\nfrom pprint import pformat\nfrom textwrap import dedent, indent\nfrom typing import TYPE_CHECKING, Any, ClassVar\nimport heapq\nimport itertools\nimport warnings\n\nfrom attrs import define\nfrom referencing.exceptions import Unresolvable as _Unresolvable\n\nfrom jsonschema import _utils\n\nif TYPE_CHECKING:\n    from collections.abc import Iterable, Mapping, MutableMapping, Sequence\n\n    from jsonschema import _types\n\nWEAK_MATCHES: frozenset[str] = frozenset([\"anyOf\", \"oneOf\"])\nSTRONG_MATCHES: frozenset[str] = frozenset()\n\n_unset = _utils.Unset()\n\n\ndef _pretty(thing: Any, prefix: str):\n    \"\"\"\n    Format something for an error message as prettily as we currently can.\n    \"\"\"\n    return indent(pformat(thing, width=72, sort_dicts=False), prefix).lstrip()\n\n\ndef __getattr__(name):\n    if name == \"RefResolutionError\":\n        warnings.warn(\n            _RefResolutionError._DEPRECATION_MESSAGE,\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _RefResolutionError\n    raise AttributeError(f\"module {__name__} has no attribute {name}\")\n\n\nclass _Error(Exception):\n\n    _word_for_schema_in_error_message: ClassVar[str]\n    _word_for_instance_in_error_message: ClassVar[str]\n\n    def __init__(\n        self,\n        message: str,\n        validator: str = _unset,  # type: ignore[assignment]\n        path: Iterable[str | int] = (),\n        cause: Exception | None = None,\n        context=(),\n        validator_value: Any = _unset,\n        instance: Any = _unset,\n        schema: Mapping[str, Any] | bool = _unset,  # type: ignore[assignment]\n        schema_path: Iterable[str | int] = (),\n        parent: _Error | None = None,\n        type_checker: _types.TypeChecker = _unset,  # type: ignore[assignment]\n    ) -> None:\n        super().__init__(\n            message,\n            validator,\n            path,\n            cause,\n            context,\n            validator_value,\n            instance,\n            schema,\n            schema_path,\n            parent,\n        )\n        self.message = message\n        self.path = self.relative_path = deque(path)\n        self.schema_path = self.relative_schema_path = deque(schema_path)\n        self.context = list(context)\n        self.cause = self.__cause__ = cause\n        self.validator = validator\n        self.validator_value = validator_value\n        self.instance = instance\n        self.schema = schema\n        self.parent = parent\n        self._type_checker = type_checker\n\n        for error in context:\n            error.parent = self\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__.__name__}: {self.message!r}>\"\n\n    def __str__(self) -> str:\n        essential_for_verbose = (\n            self.validator, self.validator_value, self.instance, self.schema,\n        )\n        if any(m is _unset for m in essential_for_verbose):\n            return self.message\n\n        schema_path = _utils.format_as_index(\n            container=self._word_for_schema_in_error_message,\n            indices=list(self.relative_schema_path)[:-1],\n        )\n        instance_path = _utils.format_as_index(\n            container=self._word_for_instance_in_error_message,\n            indices=self.relative_path,\n        )\n        prefix = 16 * \" \"\n\n        return dedent(\n            f\"\"\"\\\n            {self.message}\n\n            Failed validating {self.validator!r} in {schema_path}:\n                {_pretty(self.schema, prefix=prefix)}\n\n            On {instance_path}:\n                {_pretty(self.instance, prefix=prefix)}\n            \"\"\".rstrip(),\n        )\n\n    @classmethod\n    def create_from(cls, other: _Error):\n        return cls(**other._contents())\n\n    @property\n    def absolute_path(self) -> Sequence[str | int]:\n        parent = self.parent\n        if parent is None:\n            return self.relative_path\n\n        path = deque(self.relative_path)\n        path.extendleft(reversed(parent.absolute_path))\n        return path\n\n    @property\n    def absolute_schema_path(self) -> Sequence[str | int]:\n        parent = self.parent\n        if parent is None:\n            return self.relative_schema_path\n\n        path = deque(self.relative_schema_path)\n        path.extendleft(reversed(parent.absolute_schema_path))\n        return path\n\n    @property\n    def json_path(self) -> str:\n        path = \"$\"\n        for elem in self.absolute_path:\n            if isinstance(elem, int):\n                path += \"[\" + str(elem) + \"]\"\n            else:\n                path += \".\" + elem\n        return path\n\n    def _set(\n        self,\n        type_checker: _types.TypeChecker | None = None,\n        **kwargs: Any,\n    ) -> None:\n        if type_checker is not None and self._type_checker is _unset:\n            self._type_checker = type_checker\n\n        for k, v in kwargs.items():\n            if getattr(self, k) is _unset:\n                setattr(self, k, v)\n\n    def _contents(self):\n        attrs = (\n            \"message\", \"cause\", \"context\", \"validator\", \"validator_value\",\n            \"path\", \"schema_path\", \"instance\", \"schema\", \"parent\",\n        )\n        return {attr: getattr(self, attr) for attr in attrs}\n\n    def _matches_type(self) -> bool:\n        try:\n            # We ignore this as we want to simply crash if this happens\n            expected = self.schema[\"type\"]  # type: ignore[index]\n        except (KeyError, TypeError):\n            return False\n\n        if isinstance(expected, str):\n            return self._type_checker.is_type(self.instance, expected)\n\n        return any(\n            self._type_checker.is_type(self.instance, expected_type)\n            for expected_type in expected\n        )\n\n\nclass ValidationError(_Error):\n    \"\"\"\n    An instance was invalid under a provided schema.\n    \"\"\"\n\n    _word_for_schema_in_error_message = \"schema\"\n    _word_for_instance_in_error_message = \"instance\"\n\n\nclass SchemaError(_Error):\n    \"\"\"\n    A schema was invalid under its corresponding metaschema.\n    \"\"\"\n\n    _word_for_schema_in_error_message = \"metaschema\"\n    _word_for_instance_in_error_message = \"schema\"\n\n\n@define(slots=False)\nclass _RefResolutionError(Exception):\n    \"\"\"\n    A ref could not be resolved.\n    \"\"\"\n\n    _DEPRECATION_MESSAGE = (\n        \"jsonschema.exceptions.RefResolutionError is deprecated as of version \"\n        \"4.18.0. If you wish to catch potential reference resolution errors, \"\n        \"directly catch referencing.exceptions.Unresolvable.\"\n    )\n\n    _cause: Exception\n\n    def __eq__(self, other):\n        if self.__class__ is not other.__class__:\n            return NotImplemented  # pragma: no cover -- uncovered but deprecated  # noqa: E501\n        return self._cause == other._cause\n\n    def __str__(self) -> str:\n        return str(self._cause)\n\n\nclass _WrappedReferencingError(_RefResolutionError, _Unresolvable):  # pragma: no cover -- partially uncovered but to be removed  # noqa: E501\n    def __init__(self, cause: _Unresolvable):\n        object.__setattr__(self, \"_wrapped\", cause)\n\n    def __eq__(self, other):\n        if other.__class__ is self.__class__:\n            return self._wrapped == other._wrapped\n        elif other.__class__ is self._wrapped.__class__:\n            return self._wrapped == other\n        return NotImplemented\n\n    def __getattr__(self, attr):\n        return getattr(self._wrapped, attr)\n\n    def __hash__(self):\n        return hash(self._wrapped)\n\n    def __repr__(self):\n        return f\"<WrappedReferencingError {self._wrapped!r}>\"\n\n    def __str__(self):\n        return f\"{self._wrapped.__class__.__name__}: {self._wrapped}\"\n\n\nclass UndefinedTypeCheck(Exception):\n    \"\"\"\n    A type checker was asked to check a type it did not have registered.\n    \"\"\"\n\n    def __init__(self, type: str) -> None:\n        self.type = type\n\n    def __str__(self) -> str:\n        return f\"Type {self.type!r} is unknown to this type checker\"\n\n\nclass UnknownType(Exception):\n    \"\"\"\n    A validator was asked to validate an instance against an unknown type.\n    \"\"\"\n\n    def __init__(self, type, instance, schema):\n        self.type = type\n        self.instance = instance\n        self.schema = schema\n\n    def __str__(self):\n        prefix = 16 * \" \"\n\n        return dedent(\n            f\"\"\"\\\n            Unknown type {self.type!r} for validator with schema:\n                {_pretty(self.schema, prefix=prefix)}\n\n            While checking instance:\n                {_pretty(self.instance, prefix=prefix)}\n            \"\"\".rstrip(),\n        )\n\n\nclass FormatError(Exception):\n    \"\"\"\n    Validating a format failed.\n    \"\"\"\n\n    def __init__(self, message, cause=None):\n        super().__init__(message, cause)\n        self.message = message\n        self.cause = self.__cause__ = cause\n\n    def __str__(self):\n        return self.message\n\n\nclass ErrorTree:\n    \"\"\"\n    ErrorTrees make it easier to check which validations failed.\n    \"\"\"\n\n    _instance = _unset\n\n    def __init__(self, errors: Iterable[ValidationError] = ()):\n        self.errors: MutableMapping[str, ValidationError] = {}\n        self._contents: Mapping[str, ErrorTree] = defaultdict(self.__class__)\n\n        for error in errors:\n            container = self\n            for element in error.path:\n                container = container[element]\n            container.errors[error.validator] = error\n\n            container._instance = error.instance\n\n    def __contains__(self, index: str | int):\n        \"\"\"\n        Check whether ``instance[index]`` has any errors.\n        \"\"\"\n        return index in self._contents\n\n    def __getitem__(self, index):\n        \"\"\"\n        Retrieve the child tree one level down at the given ``index``.\n\n        If the index is not in the instance that this tree corresponds\n        to and is not known by this tree, whatever error would be raised\n        by ``instance.__getitem__`` will be propagated (usually this is\n        some subclass of `LookupError`.\n        \"\"\"\n        if self._instance is not _unset and index not in self:\n            self._instance[index]\n        return self._contents[index]\n\n    def __setitem__(self, index: str | int, value: ErrorTree):\n        \"\"\"\n        Add an error to the tree at the given ``index``.\n\n        .. deprecated:: v4.20.0\n\n            Setting items on an `ErrorTree` is deprecated without replacement.\n            To populate a tree, provide all of its sub-errors when you\n            construct the tree.\n        \"\"\"\n        warnings.warn(\n            \"ErrorTree.__setitem__ is deprecated without replacement.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        self._contents[index] = value  # type: ignore[index]\n\n    def __iter__(self):\n        \"\"\"\n        Iterate (non-recursively) over the indices in the instance with errors.\n        \"\"\"\n        return iter(self._contents)\n\n    def __len__(self):\n        \"\"\"\n        Return the `total_errors`.\n        \"\"\"\n        return self.total_errors\n\n    def __repr__(self):\n        total = len(self)\n        errors = \"error\" if total == 1 else \"errors\"\n        return f\"<{self.__class__.__name__} ({total} total {errors})>\"\n\n    @property\n    def total_errors(self):\n        \"\"\"\n        The total number of errors in the entire tree, including children.\n        \"\"\"\n        child_errors = sum(len(tree) for _, tree in self._contents.items())\n        return len(self.errors) + child_errors\n\n\ndef by_relevance(weak=WEAK_MATCHES, strong=STRONG_MATCHES):\n    \"\"\"\n    Create a key function that can be used to sort errors by relevance.\n\n    Arguments:\n        weak (set):\n            a collection of validation keywords to consider to be\n            \"weak\".  If there are two errors at the same level of the\n            instance and one is in the set of weak validation keywords,\n            the other error will take priority. By default, :kw:`anyOf`\n            and :kw:`oneOf` are considered weak keywords and will be\n            superseded by other same-level validation errors.\n\n        strong (set):\n            a collection of validation keywords to consider to be\n            \"strong\"\n\n    \"\"\"\n\n    def relevance(error):\n        validator = error.validator\n        return (                        # prefer errors which are ...\n            -len(error.path),           # 'deeper' and thereby more specific\n            error.path,                 # earlier (for sibling errors)\n            validator not in weak,      # for a non-low-priority keyword\n            validator in strong,        # for a high priority keyword\n            not error._matches_type(),  # at least match the instance's type\n        )                               # otherwise we'll treat them the same\n\n    return relevance\n\n\nrelevance = by_relevance()\n\"\"\"\nA key function (e.g. to use with `sorted`) which sorts errors by relevance.\n\nExample:\n\n.. code:: python\n\n    sorted(validator.iter_errors(12), key=jsonschema.exceptions.relevance)\n\"\"\"\n\n\ndef best_match(errors, key=relevance):\n    \"\"\"\n    Try to find an error that appears to be the best match among given errors.\n\n    In general, errors that are higher up in the instance (i.e. for which\n    `ValidationError.path` is shorter) are considered better matches,\n    since they indicate \"more\" is wrong with the instance.\n\n    If the resulting match is either :kw:`oneOf` or :kw:`anyOf`, the\n    *opposite* assumption is made -- i.e. the deepest error is picked,\n    since these keywords only need to match once, and any other errors\n    may not be relevant.\n\n    Arguments:\n        errors (collections.abc.Iterable):\n\n            the errors to select from. Do not provide a mixture of\n            errors from different validation attempts (i.e. from\n            different instances or schemas), since it won't produce\n            sensical output.\n\n        key (collections.abc.Callable):\n\n            the key to use when sorting errors. See `relevance` and\n            transitively `by_relevance` for more details (the default is\n            to sort with the defaults of that function). Changing the\n            default is only useful if you want to change the function\n            that rates errors but still want the error context descent\n            done by this function.\n\n    Returns:\n        the best matching error, or ``None`` if the iterable was empty\n\n    .. note::\n\n        This function is a heuristic. Its return value may change for a given\n        set of inputs from version to version if better heuristics are added.\n\n    \"\"\"\n    errors = iter(errors)\n    best = next(errors, None)\n    if best is None:\n        return\n    best = max(itertools.chain([best], errors), key=key)\n\n    while best.context:\n        # Calculate the minimum via nsmallest, because we don't recurse if\n        # all nested errors have the same relevance (i.e. if min == max == all)\n        smallest = heapq.nsmallest(2, best.context, key=key)\n        if len(smallest) == 2 and key(smallest[0]) == key(smallest[1]):  # noqa: PLR2004\n            return best\n        best = smallest[0]\n    return best\n", "jsonschema/_format.py": "from __future__ import annotations\n\nfrom contextlib import suppress\nfrom datetime import date, datetime\nfrom uuid import UUID\nimport ipaddress\nimport re\nimport typing\nimport warnings\n\nfrom jsonschema.exceptions import FormatError\n\n_FormatCheckCallable = typing.Callable[[object], bool]\n#: A format checker callable.\n_F = typing.TypeVar(\"_F\", bound=_FormatCheckCallable)\n_RaisesType = typing.Union[\n    typing.Type[Exception], typing.Tuple[typing.Type[Exception], ...],\n]\n\n_RE_DATE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}$\", re.ASCII)\n\n\nclass FormatChecker:\n    \"\"\"\n    A ``format`` property checker.\n\n    JSON Schema does not mandate that the ``format`` property actually do any\n    validation. If validation is desired however, instances of this class can\n    be hooked into validators to enable format validation.\n\n    `FormatChecker` objects always return ``True`` when asked about\n    formats that they do not know how to validate.\n\n    To add a check for a custom format use the `FormatChecker.checks`\n    decorator.\n\n    Arguments:\n\n        formats:\n\n            The known formats to validate. This argument can be used to\n            limit which formats will be used during validation.\n\n    \"\"\"\n\n    checkers: dict[\n        str,\n        tuple[_FormatCheckCallable, _RaisesType],\n    ] = {}  # noqa: RUF012\n\n    def __init__(self, formats: typing.Iterable[str] | None = None):\n        if formats is None:\n            formats = self.checkers.keys()\n        self.checkers = {k: self.checkers[k] for k in formats}\n\n    def __repr__(self):\n        return f\"<FormatChecker checkers={sorted(self.checkers)}>\"\n\n    def checks(\n        self, format: str, raises: _RaisesType = (),\n    ) -> typing.Callable[[_F], _F]:\n        \"\"\"\n        Register a decorated function as validating a new format.\n\n        Arguments:\n\n            format:\n\n                The format that the decorated function will check.\n\n            raises:\n\n                The exception(s) raised by the decorated function when an\n                invalid instance is found.\n\n                The exception object will be accessible as the\n                `jsonschema.exceptions.ValidationError.cause` attribute of the\n                resulting validation error.\n\n        \"\"\"\n\n        def _checks(func: _F) -> _F:\n            self.checkers[format] = (func, raises)\n            return func\n\n        return _checks\n\n    @classmethod\n    def cls_checks(\n        cls, format: str, raises: _RaisesType = (),\n    ) -> typing.Callable[[_F], _F]:\n        warnings.warn(\n            (\n                \"FormatChecker.cls_checks is deprecated. Call \"\n                \"FormatChecker.checks on a specific FormatChecker instance \"\n                \"instead.\"\n            ),\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return cls._cls_checks(format=format, raises=raises)\n\n    @classmethod\n    def _cls_checks(\n        cls, format: str, raises: _RaisesType = (),\n    ) -> typing.Callable[[_F], _F]:\n        def _checks(func: _F) -> _F:\n            cls.checkers[format] = (func, raises)\n            return func\n\n        return _checks\n\n    def check(self, instance: object, format: str) -> None:\n        \"\"\"\n        Check whether the instance conforms to the given format.\n\n        Arguments:\n\n            instance (*any primitive type*, i.e. str, number, bool):\n\n                The instance to check\n\n            format:\n\n                The format that instance should conform to\n\n        Raises:\n\n            FormatError:\n\n                if the instance does not conform to ``format``\n\n        \"\"\"\n        if format not in self.checkers:\n            return\n\n        func, raises = self.checkers[format]\n        result, cause = None, None\n        try:\n            result = func(instance)\n        except raises as e:\n            cause = e\n        if not result:\n            raise FormatError(f\"{instance!r} is not a {format!r}\", cause=cause)\n\n    def conforms(self, instance: object, format: str) -> bool:\n        \"\"\"\n        Check whether the instance conforms to the given format.\n\n        Arguments:\n\n            instance (*any primitive type*, i.e. str, number, bool):\n\n                The instance to check\n\n            format:\n\n                The format that instance should conform to\n\n        Returns:\n\n            bool: whether it conformed\n\n        \"\"\"\n        try:\n            self.check(instance, format)\n        except FormatError:\n            return False\n        else:\n            return True\n\n\ndraft3_format_checker = FormatChecker()\ndraft4_format_checker = FormatChecker()\ndraft6_format_checker = FormatChecker()\ndraft7_format_checker = FormatChecker()\ndraft201909_format_checker = FormatChecker()\ndraft202012_format_checker = FormatChecker()\n\n_draft_checkers: dict[str, FormatChecker] = dict(\n    draft3=draft3_format_checker,\n    draft4=draft4_format_checker,\n    draft6=draft6_format_checker,\n    draft7=draft7_format_checker,\n    draft201909=draft201909_format_checker,\n    draft202012=draft202012_format_checker,\n)\n\n\ndef _checks_drafts(\n    name=None,\n    draft3=None,\n    draft4=None,\n    draft6=None,\n    draft7=None,\n    draft201909=None,\n    draft202012=None,\n    raises=(),\n) -> typing.Callable[[_F], _F]:\n    draft3 = draft3 or name\n    draft4 = draft4 or name\n    draft6 = draft6 or name\n    draft7 = draft7 or name\n    draft201909 = draft201909 or name\n    draft202012 = draft202012 or name\n\n    def wrap(func: _F) -> _F:\n        if draft3:\n            func = _draft_checkers[\"draft3\"].checks(draft3, raises)(func)\n        if draft4:\n            func = _draft_checkers[\"draft4\"].checks(draft4, raises)(func)\n        if draft6:\n            func = _draft_checkers[\"draft6\"].checks(draft6, raises)(func)\n        if draft7:\n            func = _draft_checkers[\"draft7\"].checks(draft7, raises)(func)\n        if draft201909:\n            func = _draft_checkers[\"draft201909\"].checks(draft201909, raises)(\n                func,\n            )\n        if draft202012:\n            func = _draft_checkers[\"draft202012\"].checks(draft202012, raises)(\n                func,\n            )\n\n        # Oy. This is bad global state, but relied upon for now, until\n        # deprecation. See #519 and test_format_checkers_come_with_defaults\n        FormatChecker._cls_checks(\n            draft202012 or draft201909 or draft7 or draft6 or draft4 or draft3,\n            raises,\n        )(func)\n        return func\n\n    return wrap\n\n\n@_checks_drafts(name=\"idn-email\")\n@_checks_drafts(name=\"email\")\ndef is_email(instance: object) -> bool:\n    if not isinstance(instance, str):\n        return True\n    return \"@\" in instance\n\n\n@_checks_drafts(\n    draft3=\"ip-address\",\n    draft4=\"ipv4\",\n    draft6=\"ipv4\",\n    draft7=\"ipv4\",\n    draft201909=\"ipv4\",\n    draft202012=\"ipv4\",\n    raises=ipaddress.AddressValueError,\n)\ndef is_ipv4(instance: object) -> bool:\n    if not isinstance(instance, str):\n        return True\n    return bool(ipaddress.IPv4Address(instance))\n\n\n@_checks_drafts(name=\"ipv6\", raises=ipaddress.AddressValueError)\ndef is_ipv6(instance: object) -> bool:\n    if not isinstance(instance, str):\n        return True\n    address = ipaddress.IPv6Address(instance)\n    return not getattr(address, \"scope_id\", \"\")\n\n\nwith suppress(ImportError):\n    from fqdn import FQDN\n\n    @_checks_drafts(\n        draft3=\"host-name\",\n        draft4=\"hostname\",\n        draft6=\"hostname\",\n        draft7=\"hostname\",\n        draft201909=\"hostname\",\n        draft202012=\"hostname\",\n    )\n    def is_host_name(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        return FQDN(instance, min_labels=1).is_valid\n\n\nwith suppress(ImportError):\n    # The built-in `idna` codec only implements RFC 3890, so we go elsewhere.\n    import idna\n\n    @_checks_drafts(\n        draft7=\"idn-hostname\",\n        draft201909=\"idn-hostname\",\n        draft202012=\"idn-hostname\",\n        raises=(idna.IDNAError, UnicodeError),\n    )\n    def is_idn_host_name(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        idna.encode(instance)\n        return True\n\n\ntry:\n    import rfc3987\nexcept ImportError:\n    with suppress(ImportError):\n        from rfc3986_validator import validate_rfc3986\n\n        @_checks_drafts(name=\"uri\")\n        def is_uri(instance: object) -> bool:\n            if not isinstance(instance, str):\n                return True\n            return validate_rfc3986(instance, rule=\"URI\")\n\n        @_checks_drafts(\n            draft6=\"uri-reference\",\n            draft7=\"uri-reference\",\n            draft201909=\"uri-reference\",\n            draft202012=\"uri-reference\",\n            raises=ValueError,\n        )\n        def is_uri_reference(instance: object) -> bool:\n            if not isinstance(instance, str):\n                return True\n            return validate_rfc3986(instance, rule=\"URI_reference\")\n\nelse:\n\n    @_checks_drafts(\n        draft7=\"iri\",\n        draft201909=\"iri\",\n        draft202012=\"iri\",\n        raises=ValueError,\n    )\n    def is_iri(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        return rfc3987.parse(instance, rule=\"IRI\")\n\n    @_checks_drafts(\n        draft7=\"iri-reference\",\n        draft201909=\"iri-reference\",\n        draft202012=\"iri-reference\",\n        raises=ValueError,\n    )\n    def is_iri_reference(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        return rfc3987.parse(instance, rule=\"IRI_reference\")\n\n    @_checks_drafts(name=\"uri\", raises=ValueError)\n    def is_uri(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        return rfc3987.parse(instance, rule=\"URI\")\n\n    @_checks_drafts(\n        draft6=\"uri-reference\",\n        draft7=\"uri-reference\",\n        draft201909=\"uri-reference\",\n        draft202012=\"uri-reference\",\n        raises=ValueError,\n    )\n    def is_uri_reference(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        return rfc3987.parse(instance, rule=\"URI_reference\")\n\n\nwith suppress(ImportError):\n    from rfc3339_validator import validate_rfc3339\n\n    @_checks_drafts(name=\"date-time\")\n    def is_datetime(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        return validate_rfc3339(instance.upper())\n\n    @_checks_drafts(\n        draft7=\"time\",\n        draft201909=\"time\",\n        draft202012=\"time\",\n    )\n    def is_time(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        return is_datetime(\"1970-01-01T\" + instance)\n\n\n@_checks_drafts(name=\"regex\", raises=re.error)\ndef is_regex(instance: object) -> bool:\n    if not isinstance(instance, str):\n        return True\n    return bool(re.compile(instance))\n\n\n@_checks_drafts(\n    draft3=\"date\",\n    draft7=\"date\",\n    draft201909=\"date\",\n    draft202012=\"date\",\n    raises=ValueError,\n)\ndef is_date(instance: object) -> bool:\n    if not isinstance(instance, str):\n        return True\n    return bool(_RE_DATE.fullmatch(instance) and date.fromisoformat(instance))\n\n\n@_checks_drafts(draft3=\"time\", raises=ValueError)\ndef is_draft3_time(instance: object) -> bool:\n    if not isinstance(instance, str):\n        return True\n    return bool(datetime.strptime(instance, \"%H:%M:%S\"))  # noqa: DTZ007\n\n\nwith suppress(ImportError):\n    import webcolors\n\n    @_checks_drafts(draft3=\"color\", raises=(ValueError, TypeError))\n    def is_css21_color(instance: object) -> bool:\n        if isinstance(instance, str):\n            try:\n                webcolors.name_to_hex(instance)\n            except ValueError:\n                webcolors.normalize_hex(instance.lower())\n        return True\n\n\nwith suppress(ImportError):\n    import jsonpointer\n\n    @_checks_drafts(\n        draft6=\"json-pointer\",\n        draft7=\"json-pointer\",\n        draft201909=\"json-pointer\",\n        draft202012=\"json-pointer\",\n        raises=jsonpointer.JsonPointerException,\n    )\n    def is_json_pointer(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        return bool(jsonpointer.JsonPointer(instance))\n\n    # TODO: I don't want to maintain this, so it\n    #       needs to go either into jsonpointer (pending\n    #       https://github.com/stefankoegl/python-json-pointer/issues/34) or\n    #       into a new external library.\n    @_checks_drafts(\n        draft7=\"relative-json-pointer\",\n        draft201909=\"relative-json-pointer\",\n        draft202012=\"relative-json-pointer\",\n        raises=jsonpointer.JsonPointerException,\n    )\n    def is_relative_json_pointer(instance: object) -> bool:\n        # Definition taken from:\n        # https://tools.ietf.org/html/draft-handrews-relative-json-pointer-01#section-3\n        if not isinstance(instance, str):\n            return True\n        if not instance:\n            return False\n\n        non_negative_integer, rest = [], \"\"\n        for i, character in enumerate(instance):\n            if character.isdigit():\n                # digits with a leading \"0\" are not allowed\n                if i > 0 and int(instance[i - 1]) == 0:\n                    return False\n\n                non_negative_integer.append(character)\n                continue\n\n            if not non_negative_integer:\n                return False\n\n            rest = instance[i:]\n            break\n        return (rest == \"#\") or bool(jsonpointer.JsonPointer(rest))\n\n\nwith suppress(ImportError):\n    import uri_template\n\n    @_checks_drafts(\n        draft6=\"uri-template\",\n        draft7=\"uri-template\",\n        draft201909=\"uri-template\",\n        draft202012=\"uri-template\",\n    )\n    def is_uri_template(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        return uri_template.validate(instance)\n\n\nwith suppress(ImportError):\n    import isoduration\n\n    @_checks_drafts(\n        draft201909=\"duration\",\n        draft202012=\"duration\",\n        raises=isoduration.DurationParsingException,\n    )\n    def is_duration(instance: object) -> bool:\n        if not isinstance(instance, str):\n            return True\n        isoduration.parse_duration(instance)\n        # FIXME: See bolsote/isoduration#25 and bolsote/isoduration#21\n        return instance.endswith(tuple(\"DMYWHMS\"))\n\n\n@_checks_drafts(\n    draft201909=\"uuid\",\n    draft202012=\"uuid\",\n    raises=ValueError,\n)\ndef is_uuid(instance: object) -> bool:\n    if not isinstance(instance, str):\n        return True\n    UUID(instance)\n    return all(instance[position] == \"-\" for position in (8, 13, 18, 23))\n", "jsonschema/_utils.py": "from collections.abc import Mapping, MutableMapping, Sequence\nfrom urllib.parse import urlsplit\nimport itertools\nimport re\n\n\nclass URIDict(MutableMapping):\n    \"\"\"\n    Dictionary which uses normalized URIs as keys.\n    \"\"\"\n\n    def normalize(self, uri):\n        return urlsplit(uri).geturl()\n\n    def __init__(self, *args, **kwargs):\n        self.store = dict()\n        self.store.update(*args, **kwargs)\n\n    def __getitem__(self, uri):\n        return self.store[self.normalize(uri)]\n\n    def __setitem__(self, uri, value):\n        self.store[self.normalize(uri)] = value\n\n    def __delitem__(self, uri):\n        del self.store[self.normalize(uri)]\n\n    def __iter__(self):\n        return iter(self.store)\n\n    def __len__(self):  # pragma: no cover -- untested, but to be removed\n        return len(self.store)\n\n    def __repr__(self):  # pragma: no cover -- untested, but to be removed\n        return repr(self.store)\n\n\nclass Unset:\n    \"\"\"\n    An as-of-yet unset attribute or unprovided default parameter.\n    \"\"\"\n\n    def __repr__(self):  # pragma: no cover\n        return \"<unset>\"\n\n\ndef format_as_index(container, indices):\n    \"\"\"\n    Construct a single string containing indexing operations for the indices.\n\n    For example for a container ``bar``, [1, 2, \"foo\"] -> bar[1][2][\"foo\"]\n\n    Arguments:\n\n        container (str):\n\n            A word to use for the thing being indexed\n\n        indices (sequence):\n\n            The indices to format.\n\n    \"\"\"\n    if not indices:\n        return container\n    return f\"{container}[{']['.join(repr(index) for index in indices)}]\"\n\n\ndef find_additional_properties(instance, schema):\n    \"\"\"\n    Return the set of additional properties for the given ``instance``.\n\n    Weeds out properties that should have been validated by ``properties`` and\n    / or ``patternProperties``.\n\n    Assumes ``instance`` is dict-like already.\n    \"\"\"\n    properties = schema.get(\"properties\", {})\n    patterns = \"|\".join(schema.get(\"patternProperties\", {}))\n    for property in instance:\n        if property not in properties:\n            if patterns and re.search(patterns, property):\n                continue\n            yield property\n\n\ndef extras_msg(extras):\n    \"\"\"\n    Create an error message for extra items or properties.\n    \"\"\"\n    verb = \"was\" if len(extras) == 1 else \"were\"\n    return \", \".join(repr(extra) for extra in extras), verb\n\n\ndef ensure_list(thing):\n    \"\"\"\n    Wrap ``thing`` in a list if it's a single str.\n\n    Otherwise, return it unchanged.\n    \"\"\"\n    if isinstance(thing, str):\n        return [thing]\n    return thing\n\n\ndef _mapping_equal(one, two):\n    \"\"\"\n    Check if two mappings are equal using the semantics of `equal`.\n    \"\"\"\n    if len(one) != len(two):\n        return False\n    return all(\n        key in two and equal(value, two[key])\n        for key, value in one.items()\n    )\n\n\ndef _sequence_equal(one, two):\n    \"\"\"\n    Check if two sequences are equal using the semantics of `equal`.\n    \"\"\"\n    if len(one) != len(two):\n        return False\n    return all(equal(i, j) for i, j in zip(one, two))\n\n\ndef equal(one, two):\n    \"\"\"\n    Check if two things are equal evading some Python type hierarchy semantics.\n\n    Specifically in JSON Schema, evade `bool` inheriting from `int`,\n    recursing into sequences to do the same.\n    \"\"\"\n    if one is two:\n        return True\n    if isinstance(one, str) or isinstance(two, str):\n        return one == two\n    if isinstance(one, Sequence) and isinstance(two, Sequence):\n        return _sequence_equal(one, two)\n    if isinstance(one, Mapping) and isinstance(two, Mapping):\n        return _mapping_equal(one, two)\n    return unbool(one) == unbool(two)\n\n\ndef unbool(element, true=object(), false=object()):\n    \"\"\"\n    A hack to make True and 1 and False and 0 unique for ``uniq``.\n    \"\"\"\n    if element is True:\n        return true\n    elif element is False:\n        return false\n    return element\n\n\ndef uniq(container):\n    \"\"\"\n    Check if all of a container's elements are unique.\n\n    Tries to rely on the container being recursively sortable, or otherwise\n    falls back on (slow) brute force.\n    \"\"\"\n    try:\n        sort = sorted(unbool(i) for i in container)\n        sliced = itertools.islice(sort, 1, None)\n\n        for i, j in zip(sort, sliced):\n            if equal(i, j):\n                return False\n\n    except (NotImplementedError, TypeError):\n        seen = []\n        for e in container:\n            e = unbool(e)\n\n            for i in seen:\n                if equal(i, e):\n                    return False\n\n            seen.append(e)\n    return True\n\n\ndef find_evaluated_item_indexes_by_schema(validator, instance, schema):\n    \"\"\"\n    Get all indexes of items that get evaluated under the current schema.\n\n    Covers all keywords related to unevaluatedItems: items, prefixItems, if,\n    then, else, contains, unevaluatedItems, allOf, oneOf, anyOf\n    \"\"\"\n    if validator.is_type(schema, \"boolean\"):\n        return []\n    evaluated_indexes = []\n\n    if \"items\" in schema:\n        return list(range(len(instance)))\n\n    ref = schema.get(\"$ref\")\n    if ref is not None:\n        resolved = validator._resolver.lookup(ref)\n        evaluated_indexes.extend(\n            find_evaluated_item_indexes_by_schema(\n                validator.evolve(\n                    schema=resolved.contents,\n                    _resolver=resolved.resolver,\n                ),\n                instance,\n                resolved.contents,\n            ),\n        )\n\n    dynamicRef = schema.get(\"$dynamicRef\")\n    if dynamicRef is not None:\n        resolved = validator._resolver.lookup(dynamicRef)\n        evaluated_indexes.extend(\n            find_evaluated_item_indexes_by_schema(\n                validator.evolve(\n                    schema=resolved.contents,\n                    _resolver=resolved.resolver,\n                ),\n                instance,\n                resolved.contents,\n            ),\n        )\n\n    if \"prefixItems\" in schema:\n        evaluated_indexes += list(range(len(schema[\"prefixItems\"])))\n\n    if \"if\" in schema:\n        if validator.evolve(schema=schema[\"if\"]).is_valid(instance):\n            evaluated_indexes += find_evaluated_item_indexes_by_schema(\n                validator, instance, schema[\"if\"],\n            )\n            if \"then\" in schema:\n                evaluated_indexes += find_evaluated_item_indexes_by_schema(\n                    validator, instance, schema[\"then\"],\n                )\n        elif \"else\" in schema:\n            evaluated_indexes += find_evaluated_item_indexes_by_schema(\n                validator, instance, schema[\"else\"],\n            )\n\n    for keyword in [\"contains\", \"unevaluatedItems\"]:\n        if keyword in schema:\n            for k, v in enumerate(instance):\n                if validator.evolve(schema=schema[keyword]).is_valid(v):\n                    evaluated_indexes.append(k)\n\n    for keyword in [\"allOf\", \"oneOf\", \"anyOf\"]:\n        if keyword in schema:\n            for subschema in schema[keyword]:\n                errs = next(validator.descend(instance, subschema), None)\n                if errs is None:\n                    evaluated_indexes += find_evaluated_item_indexes_by_schema(\n                        validator, instance, subschema,\n                    )\n\n    return evaluated_indexes\n\n\ndef find_evaluated_property_keys_by_schema(validator, instance, schema):\n    \"\"\"\n    Get all keys of items that get evaluated under the current schema.\n\n    Covers all keywords related to unevaluatedProperties: properties,\n    additionalProperties, unevaluatedProperties, patternProperties,\n    dependentSchemas, allOf, oneOf, anyOf, if, then, else\n    \"\"\"\n    if validator.is_type(schema, \"boolean\"):\n        return []\n    evaluated_keys = []\n\n    ref = schema.get(\"$ref\")\n    if ref is not None:\n        resolved = validator._resolver.lookup(ref)\n        evaluated_keys.extend(\n            find_evaluated_property_keys_by_schema(\n                validator.evolve(\n                    schema=resolved.contents,\n                    _resolver=resolved.resolver,\n                ),\n                instance,\n                resolved.contents,\n            ),\n        )\n\n    dynamicRef = schema.get(\"$dynamicRef\")\n    if dynamicRef is not None:\n        resolved = validator._resolver.lookup(dynamicRef)\n        evaluated_keys.extend(\n            find_evaluated_property_keys_by_schema(\n                validator.evolve(\n                    schema=resolved.contents,\n                    _resolver=resolved.resolver,\n                ),\n                instance,\n                resolved.contents,\n            ),\n        )\n\n    for keyword in [\n        \"properties\", \"additionalProperties\", \"unevaluatedProperties\",\n    ]:\n        if keyword in schema:\n            schema_value = schema[keyword]\n            if validator.is_type(schema_value, \"boolean\") and schema_value:\n                evaluated_keys += instance.keys()\n\n            elif validator.is_type(schema_value, \"object\"):\n                for property in schema_value:\n                    if property in instance:\n                        evaluated_keys.append(property)\n\n    if \"patternProperties\" in schema:\n        for property in instance:\n            for pattern in schema[\"patternProperties\"]:\n                if re.search(pattern, property):\n                    evaluated_keys.append(property)\n\n    if \"dependentSchemas\" in schema:\n        for property, subschema in schema[\"dependentSchemas\"].items():\n            if property not in instance:\n                continue\n            evaluated_keys += find_evaluated_property_keys_by_schema(\n                validator, instance, subschema,\n            )\n\n    for keyword in [\"allOf\", \"oneOf\", \"anyOf\"]:\n        if keyword in schema:\n            for subschema in schema[keyword]:\n                errs = next(validator.descend(instance, subschema), None)\n                if errs is None:\n                    evaluated_keys += find_evaluated_property_keys_by_schema(\n                        validator, instance, subschema,\n                    )\n\n    if \"if\" in schema:\n        if validator.evolve(schema=schema[\"if\"]).is_valid(instance):\n            evaluated_keys += find_evaluated_property_keys_by_schema(\n                validator, instance, schema[\"if\"],\n            )\n            if \"then\" in schema:\n                evaluated_keys += find_evaluated_property_keys_by_schema(\n                    validator, instance, schema[\"then\"],\n                )\n        elif \"else\" in schema:\n            evaluated_keys += find_evaluated_property_keys_by_schema(\n                validator, instance, schema[\"else\"],\n            )\n\n    return evaluated_keys\n", "jsonschema/_types.py": "from __future__ import annotations\n\nfrom typing import Any, Callable, Mapping\nimport numbers\n\nfrom attrs import evolve, field, frozen\nfrom rpds import HashTrieMap\n\nfrom jsonschema.exceptions import UndefinedTypeCheck\n\n\n# unfortunately, the type of HashTrieMap is generic, and if used as an attrs\n# converter, the generic type is presented to mypy, which then fails to match\n# the concrete type of a type checker mapping\n# this \"do nothing\" wrapper presents the correct information to mypy\ndef _typed_map_converter(\n    init_val: Mapping[str, Callable[[TypeChecker, Any], bool]],\n) -> HashTrieMap[str, Callable[[TypeChecker, Any], bool]]:\n    return HashTrieMap.convert(init_val)\n\n\ndef is_array(checker, instance):\n    return isinstance(instance, list)\n\n\ndef is_bool(checker, instance):\n    return isinstance(instance, bool)\n\n\ndef is_integer(checker, instance):\n    # bool inherits from int, so ensure bools aren't reported as ints\n    if isinstance(instance, bool):\n        return False\n    return isinstance(instance, int)\n\n\ndef is_null(checker, instance):\n    return instance is None\n\n\ndef is_number(checker, instance):\n    # bool inherits from int, so ensure bools aren't reported as ints\n    if isinstance(instance, bool):\n        return False\n    return isinstance(instance, numbers.Number)\n\n\ndef is_object(checker, instance):\n    return isinstance(instance, dict)\n\n\ndef is_string(checker, instance):\n    return isinstance(instance, str)\n\n\ndef is_any(checker, instance):\n    return True\n\n\n@frozen(repr=False)\nclass TypeChecker:\n    \"\"\"\n    A :kw:`type` property checker.\n\n    A `TypeChecker` performs type checking for a `Validator`, converting\n    between the defined JSON Schema types and some associated Python types or\n    objects.\n\n    Modifying the behavior just mentioned by redefining which Python objects\n    are considered to be of which JSON Schema types can be done using\n    `TypeChecker.redefine` or `TypeChecker.redefine_many`, and types can be\n    removed via `TypeChecker.remove`. Each of these return a new `TypeChecker`.\n\n    Arguments:\n\n        type_checkers:\n\n            The initial mapping of types to their checking functions.\n\n    \"\"\"\n\n    _type_checkers: HashTrieMap[\n        str, Callable[[TypeChecker, Any], bool],\n    ] = field(default=HashTrieMap(), converter=_typed_map_converter)\n\n    def __repr__(self):\n        types = \", \".join(repr(k) for k in sorted(self._type_checkers))\n        return f\"<{self.__class__.__name__} types={{{types}}}>\"\n\n    def is_type(self, instance, type: str) -> bool:\n        \"\"\"\n        Check if the instance is of the appropriate type.\n\n        Arguments:\n\n            instance:\n\n                The instance to check\n\n            type:\n\n                The name of the type that is expected.\n\n        Raises:\n\n            `jsonschema.exceptions.UndefinedTypeCheck`:\n\n                if ``type`` is unknown to this object.\n\n        \"\"\"\n        try:\n            fn = self._type_checkers[type]\n        except KeyError:\n            raise UndefinedTypeCheck(type) from None\n\n        return fn(self, instance)\n\n    def redefine(self, type: str, fn) -> TypeChecker:\n        \"\"\"\n        Produce a new checker with the given type redefined.\n\n        Arguments:\n\n            type:\n\n                The name of the type to check.\n\n            fn (collections.abc.Callable):\n\n                A callable taking exactly two parameters - the type\n                checker calling the function and the instance to check.\n                The function should return true if instance is of this\n                type and false otherwise.\n\n        \"\"\"\n        return self.redefine_many({type: fn})\n\n    def redefine_many(self, definitions=()) -> TypeChecker:\n        \"\"\"\n        Produce a new checker with the given types redefined.\n\n        Arguments:\n\n            definitions (dict):\n\n                A dictionary mapping types to their checking functions.\n\n        \"\"\"\n        type_checkers = self._type_checkers.update(definitions)\n        return evolve(self, type_checkers=type_checkers)\n\n    def remove(self, *types) -> TypeChecker:\n        \"\"\"\n        Produce a new checker with the given types forgotten.\n\n        Arguments:\n\n            types:\n\n                the names of the types to remove.\n\n        Raises:\n\n            `jsonschema.exceptions.UndefinedTypeCheck`:\n\n                if any given type is unknown to this object\n\n        \"\"\"\n        type_checkers = self._type_checkers\n        for each in types:\n            try:\n                type_checkers = type_checkers.remove(each)\n            except KeyError:\n                raise UndefinedTypeCheck(each) from None\n        return evolve(self, type_checkers=type_checkers)\n\n\ndraft3_type_checker = TypeChecker(\n    {\n        \"any\": is_any,\n        \"array\": is_array,\n        \"boolean\": is_bool,\n        \"integer\": is_integer,\n        \"object\": is_object,\n        \"null\": is_null,\n        \"number\": is_number,\n        \"string\": is_string,\n    },\n)\ndraft4_type_checker = draft3_type_checker.remove(\"any\")\ndraft6_type_checker = draft4_type_checker.redefine(\n    \"integer\",\n    lambda checker, instance: (\n        is_integer(checker, instance)\n        or isinstance(instance, float) and instance.is_integer()\n    ),\n)\ndraft7_type_checker = draft6_type_checker\ndraft201909_type_checker = draft7_type_checker\ndraft202012_type_checker = draft201909_type_checker\n", "jsonschema/validators.py": "\"\"\"\nCreation and extension of validators, with implementations for existing drafts.\n\"\"\"\nfrom __future__ import annotations\n\nfrom collections import deque\nfrom collections.abc import Iterable, Mapping, Sequence\nfrom functools import lru_cache\nfrom operator import methodcaller\nfrom typing import TYPE_CHECKING\nfrom urllib.parse import unquote, urldefrag, urljoin, urlsplit\nfrom urllib.request import urlopen\nfrom warnings import warn\nimport contextlib\nimport json\nimport reprlib\nimport warnings\n\nfrom attrs import define, field, fields\nfrom jsonschema_specifications import REGISTRY as SPECIFICATIONS\nfrom rpds import HashTrieMap\nimport referencing.exceptions\nimport referencing.jsonschema\n\nfrom jsonschema import (\n    _format,\n    _keywords,\n    _legacy_keywords,\n    _types,\n    _typing,\n    _utils,\n    exceptions,\n)\n\nif TYPE_CHECKING:\n    from jsonschema.protocols import Validator\n\n_UNSET = _utils.Unset()\n\n_VALIDATORS: dict[str, Validator] = {}\n_META_SCHEMAS = _utils.URIDict()\n\n\ndef __getattr__(name):\n    if name == \"ErrorTree\":\n        warnings.warn(\n            \"Importing ErrorTree from jsonschema.validators is deprecated. \"\n            \"Instead import it from jsonschema.exceptions.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        from jsonschema.exceptions import ErrorTree\n        return ErrorTree\n    elif name == \"validators\":\n        warnings.warn(\n            \"Accessing jsonschema.validators.validators is deprecated. \"\n            \"Use jsonschema.validators.validator_for with a given schema.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _VALIDATORS\n    elif name == \"meta_schemas\":\n        warnings.warn(\n            \"Accessing jsonschema.validators.meta_schemas is deprecated. \"\n            \"Use jsonschema.validators.validator_for with a given schema.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _META_SCHEMAS\n    elif name == \"RefResolver\":\n        warnings.warn(\n            _RefResolver._DEPRECATION_MESSAGE,\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _RefResolver\n    raise AttributeError(f\"module {__name__} has no attribute {name}\")\n\n\ndef validates(version):\n    \"\"\"\n    Register the decorated validator for a ``version`` of the specification.\n\n    Registered validators and their meta schemas will be considered when\n    parsing :kw:`$schema` keywords' URIs.\n\n    Arguments:\n\n        version (str):\n\n            An identifier to use as the version's name\n\n    Returns:\n\n        collections.abc.Callable:\n\n            a class decorator to decorate the validator with the version\n\n    \"\"\"\n\n    def _validates(cls):\n        _VALIDATORS[version] = cls\n        meta_schema_id = cls.ID_OF(cls.META_SCHEMA)\n        _META_SCHEMAS[meta_schema_id] = cls\n        return cls\n    return _validates\n\n\ndef _warn_for_remote_retrieve(uri: str):\n    from urllib.request import Request, urlopen\n    headers = {\"User-Agent\": \"python-jsonschema (deprecated $ref resolution)\"}\n    request = Request(uri, headers=headers)  # noqa: S310\n    with urlopen(request) as response:  # noqa: S310\n        warnings.warn(\n            \"Automatically retrieving remote references can be a security \"\n            \"vulnerability and is discouraged by the JSON Schema \"\n            \"specifications. Relying on this behavior is deprecated \"\n            \"and will shortly become an error. If you are sure you want to \"\n            \"remotely retrieve your reference and that it is safe to do so, \"\n            \"you can find instructions for doing so via referencing.Registry \"\n            \"in the referencing documentation \"\n            \"(https://referencing.readthedocs.org).\",\n            DeprecationWarning,\n            stacklevel=9,  # Ha ha ha ha magic numbers :/\n        )\n        return referencing.Resource.from_contents(\n            json.load(response),\n            default_specification=referencing.jsonschema.DRAFT202012,\n        )\n\n\n_REMOTE_WARNING_REGISTRY = SPECIFICATIONS.combine(\n    referencing.Registry(retrieve=_warn_for_remote_retrieve),  # type: ignore[call-arg]\n)\n\n\ndef create(\n    meta_schema: referencing.jsonschema.ObjectSchema,\n    validators: (\n        Mapping[str, _typing.SchemaKeywordValidator]\n        | Iterable[tuple[str, _typing.SchemaKeywordValidator]]\n    ) = (),\n    version: str | None = None,\n    type_checker: _types.TypeChecker = _types.draft202012_type_checker,\n    format_checker: _format.FormatChecker = _format.draft202012_format_checker,\n    id_of: _typing.id_of = referencing.jsonschema.DRAFT202012.id_of,\n    applicable_validators: _typing.ApplicableValidators = methodcaller(\n        \"items\",\n    ),\n):\n    \"\"\"\n    Create a new validator class.\n\n    Arguments:\n\n        meta_schema:\n\n            the meta schema for the new validator class\n\n        validators:\n\n            a mapping from names to callables, where each callable will\n            validate the schema property with the given name.\n\n            Each callable should take 4 arguments:\n\n                1. a validator instance,\n                2. the value of the property being validated within the\n                   instance\n                3. the instance\n                4. the schema\n\n        version:\n\n            an identifier for the version that this validator class will\n            validate. If provided, the returned validator class will\n            have its ``__name__`` set to include the version, and also\n            will have `jsonschema.validators.validates` automatically\n            called for the given version.\n\n        type_checker:\n\n            a type checker, used when applying the :kw:`type` keyword.\n\n            If unprovided, a `jsonschema.TypeChecker` will be created\n            with a set of default types typical of JSON Schema drafts.\n\n        format_checker:\n\n            a format checker, used when applying the :kw:`format` keyword.\n\n            If unprovided, a `jsonschema.FormatChecker` will be created\n            with a set of default formats typical of JSON Schema drafts.\n\n        id_of:\n\n            A function that given a schema, returns its ID.\n\n        applicable_validators:\n\n            A function that, given a schema, returns the list of\n            applicable schema keywords and associated values\n            which will be used to validate the instance.\n            This is mostly used to support pre-draft 7 versions of JSON Schema\n            which specified behavior around ignoring keywords if they were\n            siblings of a ``$ref`` keyword. If you're not attempting to\n            implement similar behavior, you can typically ignore this argument\n            and leave it at its default.\n\n    Returns:\n\n        a new `jsonschema.protocols.Validator` class\n\n    \"\"\"\n    # preemptively don't shadow the `Validator.format_checker` local\n    format_checker_arg = format_checker\n\n    specification = referencing.jsonschema.specification_with(\n        dialect_id=id_of(meta_schema) or \"urn:unknown-dialect\",\n        default=referencing.Specification.OPAQUE,\n    )\n\n    @define\n    class Validator:\n\n        VALIDATORS = dict(validators)  # noqa: RUF012\n        META_SCHEMA = dict(meta_schema)  # noqa: RUF012\n        TYPE_CHECKER = type_checker\n        FORMAT_CHECKER = format_checker_arg\n        ID_OF = staticmethod(id_of)\n\n        _APPLICABLE_VALIDATORS = applicable_validators\n        _validators = field(init=False, repr=False, eq=False)\n\n        schema: referencing.jsonschema.Schema = field(repr=reprlib.repr)\n        _ref_resolver = field(default=None, repr=False, alias=\"resolver\")\n        format_checker: _format.FormatChecker | None = field(default=None)\n        # TODO: include new meta-schemas added at runtime\n        _registry: referencing.jsonschema.SchemaRegistry = field(\n            default=_REMOTE_WARNING_REGISTRY,\n            kw_only=True,\n            repr=False,\n        )\n        _resolver = field(\n            alias=\"_resolver\",\n            default=None,\n            kw_only=True,\n            repr=False,\n        )\n\n        def __init_subclass__(cls):\n            warnings.warn(\n                (\n                    \"Subclassing validator classes is not intended to \"\n                    \"be part of their public API. A future version \"\n                    \"will make doing so an error, as the behavior of \"\n                    \"subclasses isn't guaranteed to stay the same \"\n                    \"between releases of jsonschema. Instead, prefer \"\n                    \"composition of validators, wrapping them in an object \"\n                    \"owned entirely by the downstream library.\"\n                ),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n\n            def evolve(self, **changes):\n                cls = self.__class__\n                schema = changes.setdefault(\"schema\", self.schema)\n                NewValidator = validator_for(schema, default=cls)\n\n                for field in fields(cls):  # noqa: F402\n                    if not field.init:\n                        continue\n                    attr_name = field.name\n                    init_name = field.alias\n                    if init_name not in changes:\n                        changes[init_name] = getattr(self, attr_name)\n\n                return NewValidator(**changes)\n\n            cls.evolve = evolve\n\n        def __attrs_post_init__(self):\n            if self._resolver is None:\n                registry = self._registry\n                if registry is not _REMOTE_WARNING_REGISTRY:\n                    registry = SPECIFICATIONS.combine(registry)\n                resource = specification.create_resource(self.schema)\n                self._resolver = registry.resolver_with_root(resource)\n\n            if self.schema is True or self.schema is False:\n                self._validators = []\n            else:\n                self._validators = [\n                    (self.VALIDATORS[k], k, v)\n                    for k, v in applicable_validators(self.schema)\n                    if k in self.VALIDATORS\n                ]\n\n            # REMOVEME: Legacy ref resolution state management.\n            push_scope = getattr(self._ref_resolver, \"push_scope\", None)\n            if push_scope is not None:\n                id = id_of(self.schema)\n                if id is not None:\n                    push_scope(id)\n\n        @classmethod\n        def check_schema(cls, schema, format_checker=_UNSET):\n            Validator = validator_for(cls.META_SCHEMA, default=cls)\n            if format_checker is _UNSET:\n                format_checker = Validator.FORMAT_CHECKER\n            validator = Validator(\n                schema=cls.META_SCHEMA,\n                format_checker=format_checker,\n            )\n            for error in validator.iter_errors(schema):\n                raise exceptions.SchemaError.create_from(error)\n\n        @property\n        def resolver(self):\n            warnings.warn(\n                (\n                    f\"Accessing {self.__class__.__name__}.resolver is \"\n                    \"deprecated as of v4.18.0, in favor of the \"\n                    \"https://github.com/python-jsonschema/referencing \"\n                    \"library, which provides more compliant referencing \"\n                    \"behavior as well as more flexible APIs for \"\n                    \"customization.\"\n                ),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            if self._ref_resolver is None:\n                self._ref_resolver = _RefResolver.from_schema(\n                    self.schema,\n                    id_of=id_of,\n                )\n            return self._ref_resolver\n\n        def evolve(self, **changes):\n            schema = changes.setdefault(\"schema\", self.schema)\n            NewValidator = validator_for(schema, default=self.__class__)\n\n            for (attr_name, init_name) in evolve_fields:\n                if init_name not in changes:\n                    changes[init_name] = getattr(self, attr_name)\n\n            return NewValidator(**changes)\n\n        def iter_errors(self, instance, _schema=None):\n            if _schema is not None:\n                warnings.warn(\n                    (\n                        \"Passing a schema to Validator.iter_errors \"\n                        \"is deprecated and will be removed in a future \"\n                        \"release. Call validator.evolve(schema=new_schema).\"\n                        \"iter_errors(...) instead.\"\n                    ),\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n                validators = [\n                    (self.VALIDATORS[k], k, v)\n                    for k, v in applicable_validators(_schema)\n                    if k in self.VALIDATORS\n                ]\n            else:\n                _schema, validators = self.schema, self._validators\n\n            if _schema is True:\n                return\n            elif _schema is False:\n                yield exceptions.ValidationError(\n                    f\"False schema does not allow {instance!r}\",\n                    validator=None,\n                    validator_value=None,\n                    instance=instance,\n                    schema=_schema,\n                )\n                return\n\n            for validator, k, v in validators:\n                errors = validator(self, v, instance, _schema) or ()\n                for error in errors:\n                    # set details if not already set by the called fn\n                    error._set(\n                        validator=k,\n                        validator_value=v,\n                        instance=instance,\n                        schema=_schema,\n                        type_checker=self.TYPE_CHECKER,\n                    )\n                    if k not in {\"if\", \"$ref\"}:\n                        error.schema_path.appendleft(k)\n                    yield error\n\n        def descend(\n            self,\n            instance,\n            schema,\n            path=None,\n            schema_path=None,\n            resolver=None,\n        ):\n            if schema is True:\n                return\n            elif schema is False:\n                yield exceptions.ValidationError(\n                    f\"False schema does not allow {instance!r}\",\n                    validator=None,\n                    validator_value=None,\n                    instance=instance,\n                    schema=schema,\n                )\n                return\n\n            if self._ref_resolver is not None:\n                evolved = self.evolve(schema=schema)\n            else:\n                if resolver is None:\n                    resolver = self._resolver.in_subresource(\n                        specification.create_resource(schema),\n                    )\n                evolved = self.evolve(schema=schema, _resolver=resolver)\n\n            for k, v in applicable_validators(schema):\n                validator = evolved.VALIDATORS.get(k)\n                if validator is None:\n                    continue\n\n                errors = validator(evolved, v, instance, schema) or ()\n                for error in errors:\n                    # set details if not already set by the called fn\n                    error._set(\n                        validator=k,\n                        validator_value=v,\n                        instance=instance,\n                        schema=schema,\n                        type_checker=evolved.TYPE_CHECKER,\n                    )\n                    if k not in {\"if\", \"$ref\"}:\n                        error.schema_path.appendleft(k)\n                    if path is not None:\n                        error.path.appendleft(path)\n                    if schema_path is not None:\n                        error.schema_path.appendleft(schema_path)\n                    yield error\n\n        def validate(self, *args, **kwargs):\n            for error in self.iter_errors(*args, **kwargs):\n                raise error\n\n        def is_type(self, instance, type):\n            try:\n                return self.TYPE_CHECKER.is_type(instance, type)\n            except exceptions.UndefinedTypeCheck:\n                exc = exceptions.UnknownType(type, instance, self.schema)\n                raise exc from None\n\n        def _validate_reference(self, ref, instance):\n            if self._ref_resolver is None:\n                try:\n                    resolved = self._resolver.lookup(ref)\n                except referencing.exceptions.Unresolvable as err:\n                    raise exceptions._WrappedReferencingError(err) from err\n\n                return self.descend(\n                    instance,\n                    resolved.contents,\n                    resolver=resolved.resolver,\n                )\n            else:\n                resolve = getattr(self._ref_resolver, \"resolve\", None)\n                if resolve is None:\n                    with self._ref_resolver.resolving(ref) as resolved:\n                        return self.descend(instance, resolved)\n                else:\n                    scope, resolved = resolve(ref)\n                    self._ref_resolver.push_scope(scope)\n\n                    try:\n                        return list(self.descend(instance, resolved))\n                    finally:\n                        self._ref_resolver.pop_scope()\n\n        def is_valid(self, instance, _schema=None):\n            if _schema is not None:\n                warnings.warn(\n                    (\n                        \"Passing a schema to Validator.is_valid is deprecated \"\n                        \"and will be removed in a future release. Call \"\n                        \"validator.evolve(schema=new_schema).is_valid(...) \"\n                        \"instead.\"\n                    ),\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n                self = self.evolve(schema=_schema)\n\n            error = next(self.iter_errors(instance), None)\n            return error is None\n\n    evolve_fields = [\n        (field.name, field.alias)\n        for field in fields(Validator)\n        if field.init\n    ]\n\n    if version is not None:\n        safe = version.title().replace(\" \", \"\").replace(\"-\", \"\")\n        Validator.__name__ = Validator.__qualname__ = f\"{safe}Validator\"\n        Validator = validates(version)(Validator)  # type: ignore[misc]\n\n    return Validator\n\n\ndef extend(\n    validator,\n    validators=(),\n    version=None,\n    type_checker=None,\n    format_checker=None,\n):\n    \"\"\"\n    Create a new validator class by extending an existing one.\n\n    Arguments:\n\n        validator (jsonschema.protocols.Validator):\n\n            an existing validator class\n\n        validators (collections.abc.Mapping):\n\n            a mapping of new validator callables to extend with, whose\n            structure is as in `create`.\n\n            .. note::\n\n                Any validator callables with the same name as an\n                existing one will (silently) replace the old validator\n                callable entirely, effectively overriding any validation\n                done in the \"parent\" validator class.\n\n                If you wish to instead extend the behavior of a parent's\n                validator callable, delegate and call it directly in\n                the new validator function by retrieving it using\n                ``OldValidator.VALIDATORS[\"validation_keyword_name\"]``.\n\n        version (str):\n\n            a version for the new validator class\n\n        type_checker (jsonschema.TypeChecker):\n\n            a type checker, used when applying the :kw:`type` keyword.\n\n            If unprovided, the type checker of the extended\n            `jsonschema.protocols.Validator` will be carried along.\n\n        format_checker (jsonschema.FormatChecker):\n\n            a format checker, used when applying the :kw:`format` keyword.\n\n            If unprovided, the format checker of the extended\n            `jsonschema.protocols.Validator` will be carried along.\n\n    Returns:\n\n        a new `jsonschema.protocols.Validator` class extending the one\n        provided\n\n    .. note:: Meta Schemas\n\n        The new validator class will have its parent's meta schema.\n\n        If you wish to change or extend the meta schema in the new\n        validator class, modify ``META_SCHEMA`` directly on the returned\n        class. Note that no implicit copying is done, so a copy should\n        likely be made before modifying it, in order to not affect the\n        old validator.\n\n    \"\"\"\n    all_validators = dict(validator.VALIDATORS)\n    all_validators.update(validators)\n\n    if type_checker is None:\n        type_checker = validator.TYPE_CHECKER\n    if format_checker is None:\n        format_checker = validator.FORMAT_CHECKER\n    return create(\n        meta_schema=validator.META_SCHEMA,\n        validators=all_validators,\n        version=version,\n        type_checker=type_checker,\n        format_checker=format_checker,\n        id_of=validator.ID_OF,\n        applicable_validators=validator._APPLICABLE_VALIDATORS,\n    )\n\n\nDraft3Validator = create(\n    meta_schema=SPECIFICATIONS.contents(\n        \"http://json-schema.org/draft-03/schema#\",\n    ),\n    validators={\n        \"$ref\": _keywords.ref,\n        \"additionalItems\": _legacy_keywords.additionalItems,\n        \"additionalProperties\": _keywords.additionalProperties,\n        \"dependencies\": _legacy_keywords.dependencies_draft3,\n        \"disallow\": _legacy_keywords.disallow_draft3,\n        \"divisibleBy\": _keywords.multipleOf,\n        \"enum\": _keywords.enum,\n        \"extends\": _legacy_keywords.extends_draft3,\n        \"format\": _keywords.format,\n        \"items\": _legacy_keywords.items_draft3_draft4,\n        \"maxItems\": _keywords.maxItems,\n        \"maxLength\": _keywords.maxLength,\n        \"maximum\": _legacy_keywords.maximum_draft3_draft4,\n        \"minItems\": _keywords.minItems,\n        \"minLength\": _keywords.minLength,\n        \"minimum\": _legacy_keywords.minimum_draft3_draft4,\n        \"pattern\": _keywords.pattern,\n        \"patternProperties\": _keywords.patternProperties,\n        \"properties\": _legacy_keywords.properties_draft3,\n        \"type\": _legacy_keywords.type_draft3,\n        \"uniqueItems\": _keywords.uniqueItems,\n    },\n    type_checker=_types.draft3_type_checker,\n    format_checker=_format.draft3_format_checker,\n    version=\"draft3\",\n    id_of=referencing.jsonschema.DRAFT3.id_of,\n    applicable_validators=_legacy_keywords.ignore_ref_siblings,\n)\n\nDraft4Validator = create(\n    meta_schema=SPECIFICATIONS.contents(\n        \"http://json-schema.org/draft-04/schema#\",\n    ),\n    validators={\n        \"$ref\": _keywords.ref,\n        \"additionalItems\": _legacy_keywords.additionalItems,\n        \"additionalProperties\": _keywords.additionalProperties,\n        \"allOf\": _keywords.allOf,\n        \"anyOf\": _keywords.anyOf,\n        \"dependencies\": _legacy_keywords.dependencies_draft4_draft6_draft7,\n        \"enum\": _keywords.enum,\n        \"format\": _keywords.format,\n        \"items\": _legacy_keywords.items_draft3_draft4,\n        \"maxItems\": _keywords.maxItems,\n        \"maxLength\": _keywords.maxLength,\n        \"maxProperties\": _keywords.maxProperties,\n        \"maximum\": _legacy_keywords.maximum_draft3_draft4,\n        \"minItems\": _keywords.minItems,\n        \"minLength\": _keywords.minLength,\n        \"minProperties\": _keywords.minProperties,\n        \"minimum\": _legacy_keywords.minimum_draft3_draft4,\n        \"multipleOf\": _keywords.multipleOf,\n        \"not\": _keywords.not_,\n        \"oneOf\": _keywords.oneOf,\n        \"pattern\": _keywords.pattern,\n        \"patternProperties\": _keywords.patternProperties,\n        \"properties\": _keywords.properties,\n        \"required\": _keywords.required,\n        \"type\": _keywords.type,\n        \"uniqueItems\": _keywords.uniqueItems,\n    },\n    type_checker=_types.draft4_type_checker,\n    format_checker=_format.draft4_format_checker,\n    version=\"draft4\",\n    id_of=referencing.jsonschema.DRAFT4.id_of,\n    applicable_validators=_legacy_keywords.ignore_ref_siblings,\n)\n\nDraft6Validator = create(\n    meta_schema=SPECIFICATIONS.contents(\n        \"http://json-schema.org/draft-06/schema#\",\n    ),\n    validators={\n        \"$ref\": _keywords.ref,\n        \"additionalItems\": _legacy_keywords.additionalItems,\n        \"additionalProperties\": _keywords.additionalProperties,\n        \"allOf\": _keywords.allOf,\n        \"anyOf\": _keywords.anyOf,\n        \"const\": _keywords.const,\n        \"contains\": _legacy_keywords.contains_draft6_draft7,\n        \"dependencies\": _legacy_keywords.dependencies_draft4_draft6_draft7,\n        \"enum\": _keywords.enum,\n        \"exclusiveMaximum\": _keywords.exclusiveMaximum,\n        \"exclusiveMinimum\": _keywords.exclusiveMinimum,\n        \"format\": _keywords.format,\n        \"items\": _legacy_keywords.items_draft6_draft7_draft201909,\n        \"maxItems\": _keywords.maxItems,\n        \"maxLength\": _keywords.maxLength,\n        \"maxProperties\": _keywords.maxProperties,\n        \"maximum\": _keywords.maximum,\n        \"minItems\": _keywords.minItems,\n        \"minLength\": _keywords.minLength,\n        \"minProperties\": _keywords.minProperties,\n        \"minimum\": _keywords.minimum,\n        \"multipleOf\": _keywords.multipleOf,\n        \"not\": _keywords.not_,\n        \"oneOf\": _keywords.oneOf,\n        \"pattern\": _keywords.pattern,\n        \"patternProperties\": _keywords.patternProperties,\n        \"properties\": _keywords.properties,\n        \"propertyNames\": _keywords.propertyNames,\n        \"required\": _keywords.required,\n        \"type\": _keywords.type,\n        \"uniqueItems\": _keywords.uniqueItems,\n    },\n    type_checker=_types.draft6_type_checker,\n    format_checker=_format.draft6_format_checker,\n    version=\"draft6\",\n    id_of=referencing.jsonschema.DRAFT6.id_of,\n    applicable_validators=_legacy_keywords.ignore_ref_siblings,\n)\n\nDraft7Validator = create(\n    meta_schema=SPECIFICATIONS.contents(\n        \"http://json-schema.org/draft-07/schema#\",\n    ),\n    validators={\n        \"$ref\": _keywords.ref,\n        \"additionalItems\": _legacy_keywords.additionalItems,\n        \"additionalProperties\": _keywords.additionalProperties,\n        \"allOf\": _keywords.allOf,\n        \"anyOf\": _keywords.anyOf,\n        \"const\": _keywords.const,\n        \"contains\": _legacy_keywords.contains_draft6_draft7,\n        \"dependencies\": _legacy_keywords.dependencies_draft4_draft6_draft7,\n        \"enum\": _keywords.enum,\n        \"exclusiveMaximum\": _keywords.exclusiveMaximum,\n        \"exclusiveMinimum\": _keywords.exclusiveMinimum,\n        \"format\": _keywords.format,\n        \"if\": _keywords.if_,\n        \"items\": _legacy_keywords.items_draft6_draft7_draft201909,\n        \"maxItems\": _keywords.maxItems,\n        \"maxLength\": _keywords.maxLength,\n        \"maxProperties\": _keywords.maxProperties,\n        \"maximum\": _keywords.maximum,\n        \"minItems\": _keywords.minItems,\n        \"minLength\": _keywords.minLength,\n        \"minProperties\": _keywords.minProperties,\n        \"minimum\": _keywords.minimum,\n        \"multipleOf\": _keywords.multipleOf,\n        \"not\": _keywords.not_,\n        \"oneOf\": _keywords.oneOf,\n        \"pattern\": _keywords.pattern,\n        \"patternProperties\": _keywords.patternProperties,\n        \"properties\": _keywords.properties,\n        \"propertyNames\": _keywords.propertyNames,\n        \"required\": _keywords.required,\n        \"type\": _keywords.type,\n        \"uniqueItems\": _keywords.uniqueItems,\n    },\n    type_checker=_types.draft7_type_checker,\n    format_checker=_format.draft7_format_checker,\n    version=\"draft7\",\n    id_of=referencing.jsonschema.DRAFT7.id_of,\n    applicable_validators=_legacy_keywords.ignore_ref_siblings,\n)\n\nDraft201909Validator = create(\n    meta_schema=SPECIFICATIONS.contents(\n        \"https://json-schema.org/draft/2019-09/schema\",\n    ),\n    validators={\n        \"$recursiveRef\": _legacy_keywords.recursiveRef,\n        \"$ref\": _keywords.ref,\n        \"additionalItems\": _legacy_keywords.additionalItems,\n        \"additionalProperties\": _keywords.additionalProperties,\n        \"allOf\": _keywords.allOf,\n        \"anyOf\": _keywords.anyOf,\n        \"const\": _keywords.const,\n        \"contains\": _keywords.contains,\n        \"dependentRequired\": _keywords.dependentRequired,\n        \"dependentSchemas\": _keywords.dependentSchemas,\n        \"enum\": _keywords.enum,\n        \"exclusiveMaximum\": _keywords.exclusiveMaximum,\n        \"exclusiveMinimum\": _keywords.exclusiveMinimum,\n        \"format\": _keywords.format,\n        \"if\": _keywords.if_,\n        \"items\": _legacy_keywords.items_draft6_draft7_draft201909,\n        \"maxItems\": _keywords.maxItems,\n        \"maxLength\": _keywords.maxLength,\n        \"maxProperties\": _keywords.maxProperties,\n        \"maximum\": _keywords.maximum,\n        \"minItems\": _keywords.minItems,\n        \"minLength\": _keywords.minLength,\n        \"minProperties\": _keywords.minProperties,\n        \"minimum\": _keywords.minimum,\n        \"multipleOf\": _keywords.multipleOf,\n        \"not\": _keywords.not_,\n        \"oneOf\": _keywords.oneOf,\n        \"pattern\": _keywords.pattern,\n        \"patternProperties\": _keywords.patternProperties,\n        \"properties\": _keywords.properties,\n        \"propertyNames\": _keywords.propertyNames,\n        \"required\": _keywords.required,\n        \"type\": _keywords.type,\n        \"unevaluatedItems\": _legacy_keywords.unevaluatedItems_draft2019,\n        \"unevaluatedProperties\": (\n            _legacy_keywords.unevaluatedProperties_draft2019\n        ),\n        \"uniqueItems\": _keywords.uniqueItems,\n    },\n    type_checker=_types.draft201909_type_checker,\n    format_checker=_format.draft201909_format_checker,\n    version=\"draft2019-09\",\n)\n\nDraft202012Validator = create(\n    meta_schema=SPECIFICATIONS.contents(\n        \"https://json-schema.org/draft/2020-12/schema\",\n    ),\n    validators={\n        \"$dynamicRef\": _keywords.dynamicRef,\n        \"$ref\": _keywords.ref,\n        \"additionalProperties\": _keywords.additionalProperties,\n        \"allOf\": _keywords.allOf,\n        \"anyOf\": _keywords.anyOf,\n        \"const\": _keywords.const,\n        \"contains\": _keywords.contains,\n        \"dependentRequired\": _keywords.dependentRequired,\n        \"dependentSchemas\": _keywords.dependentSchemas,\n        \"enum\": _keywords.enum,\n        \"exclusiveMaximum\": _keywords.exclusiveMaximum,\n        \"exclusiveMinimum\": _keywords.exclusiveMinimum,\n        \"format\": _keywords.format,\n        \"if\": _keywords.if_,\n        \"items\": _keywords.items,\n        \"maxItems\": _keywords.maxItems,\n        \"maxLength\": _keywords.maxLength,\n        \"maxProperties\": _keywords.maxProperties,\n        \"maximum\": _keywords.maximum,\n        \"minItems\": _keywords.minItems,\n        \"minLength\": _keywords.minLength,\n        \"minProperties\": _keywords.minProperties,\n        \"minimum\": _keywords.minimum,\n        \"multipleOf\": _keywords.multipleOf,\n        \"not\": _keywords.not_,\n        \"oneOf\": _keywords.oneOf,\n        \"pattern\": _keywords.pattern,\n        \"patternProperties\": _keywords.patternProperties,\n        \"prefixItems\": _keywords.prefixItems,\n        \"properties\": _keywords.properties,\n        \"propertyNames\": _keywords.propertyNames,\n        \"required\": _keywords.required,\n        \"type\": _keywords.type,\n        \"unevaluatedItems\": _keywords.unevaluatedItems,\n        \"unevaluatedProperties\": _keywords.unevaluatedProperties,\n        \"uniqueItems\": _keywords.uniqueItems,\n    },\n    type_checker=_types.draft202012_type_checker,\n    format_checker=_format.draft202012_format_checker,\n    version=\"draft2020-12\",\n)\n\n_LATEST_VERSION = Draft202012Validator\n\n\nclass _RefResolver:\n    \"\"\"\n    Resolve JSON References.\n\n    Arguments:\n\n        base_uri (str):\n\n            The URI of the referring document\n\n        referrer:\n\n            The actual referring document\n\n        store (dict):\n\n            A mapping from URIs to documents to cache\n\n        cache_remote (bool):\n\n            Whether remote refs should be cached after first resolution\n\n        handlers (dict):\n\n            A mapping from URI schemes to functions that should be used\n            to retrieve them\n\n        urljoin_cache (:func:`functools.lru_cache`):\n\n            A cache that will be used for caching the results of joining\n            the resolution scope to subscopes.\n\n        remote_cache (:func:`functools.lru_cache`):\n\n            A cache that will be used for caching the results of\n            resolved remote URLs.\n\n    Attributes:\n\n        cache_remote (bool):\n\n            Whether remote refs should be cached after first resolution\n\n    .. deprecated:: v4.18.0\n\n        ``RefResolver`` has been deprecated in favor of `referencing`.\n\n    \"\"\"\n\n    _DEPRECATION_MESSAGE = (\n        \"jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the \"\n        \"https://github.com/python-jsonschema/referencing library, which \"\n        \"provides more compliant referencing behavior as well as more \"\n        \"flexible APIs for customization. A future release will remove \"\n        \"RefResolver. Please file a feature request (on referencing) if you \"\n        \"are missing an API for the kind of customization you need.\"\n    )\n\n    def __init__(\n        self,\n        base_uri,\n        referrer,\n        store=HashTrieMap(),\n        cache_remote=True,\n        handlers=(),\n        urljoin_cache=None,\n        remote_cache=None,\n    ):\n        if urljoin_cache is None:\n            urljoin_cache = lru_cache(1024)(urljoin)\n        if remote_cache is None:\n            remote_cache = lru_cache(1024)(self.resolve_from_url)\n\n        self.referrer = referrer\n        self.cache_remote = cache_remote\n        self.handlers = dict(handlers)\n\n        self._scopes_stack = [base_uri]\n\n        self.store = _utils.URIDict(\n            (uri, each.contents) for uri, each in SPECIFICATIONS.items()\n        )\n        self.store.update(\n            (id, each.META_SCHEMA) for id, each in _META_SCHEMAS.items()\n        )\n        self.store.update(store)\n        self.store.update(\n            (schema[\"$id\"], schema)\n            for schema in store.values()\n            if isinstance(schema, Mapping) and \"$id\" in schema\n        )\n        self.store[base_uri] = referrer\n\n        self._urljoin_cache = urljoin_cache\n        self._remote_cache = remote_cache\n\n    @classmethod\n    def from_schema(  # noqa: D417\n        cls,\n        schema,\n        id_of=referencing.jsonschema.DRAFT202012.id_of,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"\n        Construct a resolver from a JSON schema object.\n\n        Arguments:\n\n            schema:\n\n                the referring schema\n\n        Returns:\n\n            `_RefResolver`\n\n        \"\"\"\n        return cls(base_uri=id_of(schema) or \"\", referrer=schema, *args, **kwargs)  # noqa: B026, E501\n\n    def push_scope(self, scope):\n        \"\"\"\n        Enter a given sub-scope.\n\n        Treats further dereferences as being performed underneath the\n        given scope.\n        \"\"\"\n        self._scopes_stack.append(\n            self._urljoin_cache(self.resolution_scope, scope),\n        )\n\n    def pop_scope(self):\n        \"\"\"\n        Exit the most recent entered scope.\n\n        Treats further dereferences as being performed underneath the\n        original scope.\n\n        Don't call this method more times than `push_scope` has been\n        called.\n        \"\"\"\n        try:\n            self._scopes_stack.pop()\n        except IndexError:\n            raise exceptions._RefResolutionError(\n                \"Failed to pop the scope from an empty stack. \"\n                \"`pop_scope()` should only be called once for every \"\n                \"`push_scope()`\",\n            ) from None\n\n    @property\n    def resolution_scope(self):\n        \"\"\"\n        Retrieve the current resolution scope.\n        \"\"\"\n        return self._scopes_stack[-1]\n\n    @property\n    def base_uri(self):\n        \"\"\"\n        Retrieve the current base URI, not including any fragment.\n        \"\"\"\n        uri, _ = urldefrag(self.resolution_scope)\n        return uri\n\n    @contextlib.contextmanager\n    def in_scope(self, scope):\n        \"\"\"\n        Temporarily enter the given scope for the duration of the context.\n\n        .. deprecated:: v4.0.0\n        \"\"\"\n        warnings.warn(\n            \"jsonschema.RefResolver.in_scope is deprecated and will be \"\n            \"removed in a future release.\",\n            DeprecationWarning,\n            stacklevel=3,\n        )\n        self.push_scope(scope)\n        try:\n            yield\n        finally:\n            self.pop_scope()\n\n    @contextlib.contextmanager\n    def resolving(self, ref):\n        \"\"\"\n        Resolve the given ``ref`` and enter its resolution scope.\n\n        Exits the scope on exit of this context manager.\n\n        Arguments:\n\n            ref (str):\n\n                The reference to resolve\n\n        \"\"\"\n        url, resolved = self.resolve(ref)\n        self.push_scope(url)\n        try:\n            yield resolved\n        finally:\n            self.pop_scope()\n\n    def _find_in_referrer(self, key):\n        return self._get_subschemas_cache()[key]\n\n    @lru_cache  # noqa: B019\n    def _get_subschemas_cache(self):\n        cache = {key: [] for key in _SUBSCHEMAS_KEYWORDS}\n        for keyword, subschema in _search_schema(\n            self.referrer, _match_subschema_keywords,\n        ):\n            cache[keyword].append(subschema)\n        return cache\n\n    @lru_cache  # noqa: B019\n    def _find_in_subschemas(self, url):\n        subschemas = self._get_subschemas_cache()[\"$id\"]\n        if not subschemas:\n            return None\n        uri, fragment = urldefrag(url)\n        for subschema in subschemas:\n            id = subschema[\"$id\"]\n            if not isinstance(id, str):\n                continue\n            target_uri = self._urljoin_cache(self.resolution_scope, id)\n            if target_uri.rstrip(\"/\") == uri.rstrip(\"/\"):\n                if fragment:\n                    subschema = self.resolve_fragment(subschema, fragment)\n                self.store[url] = subschema\n                return url, subschema\n        return None\n\n    def resolve(self, ref):\n        \"\"\"\n        Resolve the given reference.\n        \"\"\"\n        url = self._urljoin_cache(self.resolution_scope, ref).rstrip(\"/\")\n\n        match = self._find_in_subschemas(url)\n        if match is not None:\n            return match\n\n        return url, self._remote_cache(url)\n\n    def resolve_from_url(self, url):\n        \"\"\"\n        Resolve the given URL.\n        \"\"\"\n        url, fragment = urldefrag(url)\n        if not url:\n            url = self.base_uri\n\n        try:\n            document = self.store[url]\n        except KeyError:\n            try:\n                document = self.resolve_remote(url)\n            except Exception as exc:\n                raise exceptions._RefResolutionError(exc) from exc\n\n        return self.resolve_fragment(document, fragment)\n\n    def resolve_fragment(self, document, fragment):\n        \"\"\"\n        Resolve a ``fragment`` within the referenced ``document``.\n\n        Arguments:\n\n            document:\n\n                The referent document\n\n            fragment (str):\n\n                a URI fragment to resolve within it\n\n        \"\"\"\n        fragment = fragment.lstrip(\"/\")\n\n        if not fragment:\n            return document\n\n        if document is self.referrer:\n            find = self._find_in_referrer\n        else:\n\n            def find(key):\n                yield from _search_schema(document, _match_keyword(key))\n\n        for keyword in [\"$anchor\", \"$dynamicAnchor\"]:\n            for subschema in find(keyword):\n                if fragment == subschema[keyword]:\n                    return subschema\n        for keyword in [\"id\", \"$id\"]:\n            for subschema in find(keyword):\n                if \"#\" + fragment == subschema[keyword]:\n                    return subschema\n\n        # Resolve via path\n        parts = unquote(fragment).split(\"/\") if fragment else []\n        for part in parts:\n            part = part.replace(\"~1\", \"/\").replace(\"~0\", \"~\")\n\n            if isinstance(document, Sequence):\n                try:  # noqa: SIM105\n                    part = int(part)\n                except ValueError:\n                    pass\n            try:\n                document = document[part]\n            except (TypeError, LookupError) as err:\n                raise exceptions._RefResolutionError(\n                    f\"Unresolvable JSON pointer: {fragment!r}\",\n                ) from err\n\n        return document\n\n    def resolve_remote(self, uri):\n        \"\"\"\n        Resolve a remote ``uri``.\n\n        If called directly, does not check the store first, but after\n        retrieving the document at the specified URI it will be saved in\n        the store if :attr:`cache_remote` is True.\n\n        .. note::\n\n            If the requests_ library is present, ``jsonschema`` will use it to\n            request the remote ``uri``, so that the correct encoding is\n            detected and used.\n\n            If it isn't, or if the scheme of the ``uri`` is not ``http`` or\n            ``https``, UTF-8 is assumed.\n\n        Arguments:\n\n            uri (str):\n\n                The URI to resolve\n\n        Returns:\n\n            The retrieved document\n\n        .. _requests: https://pypi.org/project/requests/\n\n        \"\"\"\n        try:\n            import requests\n        except ImportError:\n            requests = None\n\n        scheme = urlsplit(uri).scheme\n\n        if scheme in self.handlers:\n            result = self.handlers[scheme](uri)\n        elif scheme in [\"http\", \"https\"] and requests:\n            # Requests has support for detecting the correct encoding of\n            # json over http\n            result = requests.get(uri).json()\n        else:\n            # Otherwise, pass off to urllib and assume utf-8\n            with urlopen(uri) as url:  # noqa: S310\n                result = json.loads(url.read().decode(\"utf-8\"))\n\n        if self.cache_remote:\n            self.store[uri] = result\n        return result\n\n\n_SUBSCHEMAS_KEYWORDS = (\"$id\", \"id\", \"$anchor\", \"$dynamicAnchor\")\n\n\ndef _match_keyword(keyword):\n\n    def matcher(value):\n        if keyword in value:\n            yield value\n\n    return matcher\n\n\ndef _match_subschema_keywords(value):\n    for keyword in _SUBSCHEMAS_KEYWORDS:\n        if keyword in value:\n            yield keyword, value\n\n\ndef _search_schema(schema, matcher):\n    \"\"\"Breadth-first search routine.\"\"\"\n    values = deque([schema])\n    while values:\n        value = values.pop()\n        if not isinstance(value, dict):\n            continue\n        yield from matcher(value)\n        values.extendleft(value.values())\n\n\ndef validate(instance, schema, cls=None, *args, **kwargs):  # noqa: D417\n    \"\"\"\n    Validate an instance under the given schema.\n\n        >>> validate([2, 3, 4], {\"maxItems\": 2})\n        Traceback (most recent call last):\n            ...\n        ValidationError: [2, 3, 4] is too long\n\n    :func:`~jsonschema.validators.validate` will first verify that the\n    provided schema is itself valid, since not doing so can lead to less\n    obvious error messages and fail in less obvious or consistent ways.\n\n    If you know you have a valid schema already, especially\n    if you intend to validate multiple instances with\n    the same schema, you likely would prefer using the\n    `jsonschema.protocols.Validator.validate` method directly on a\n    specific validator (e.g. ``Draft202012Validator.validate``).\n\n\n    Arguments:\n\n        instance:\n\n            The instance to validate\n\n        schema:\n\n            The schema to validate with\n\n        cls (jsonschema.protocols.Validator):\n\n            The class that will be used to validate the instance.\n\n    If the ``cls`` argument is not provided, two things will happen\n    in accordance with the specification. First, if the schema has a\n    :kw:`$schema` keyword containing a known meta-schema [#]_ then the\n    proper validator will be used. The specification recommends that\n    all schemas contain :kw:`$schema` properties for this reason. If no\n    :kw:`$schema` property is found, the default validator class is the\n    latest released draft.\n\n    Any other provided positional and keyword arguments will be passed\n    on when instantiating the ``cls``.\n\n    Raises:\n\n        `jsonschema.exceptions.ValidationError`:\n\n            if the instance is invalid\n\n        `jsonschema.exceptions.SchemaError`:\n\n            if the schema itself is invalid\n\n    .. rubric:: Footnotes\n    .. [#] known by a validator registered with\n        `jsonschema.validators.validates`\n\n    \"\"\"\n    if cls is None:\n        cls = validator_for(schema)\n\n    cls.check_schema(schema)\n    validator = cls(schema, *args, **kwargs)\n    error = exceptions.best_match(validator.iter_errors(instance))\n    if error is not None:\n        raise error\n\n\ndef validator_for(\n    schema,\n    default: Validator | _utils.Unset = _UNSET,\n) -> type[Validator]:\n    \"\"\"\n    Retrieve the validator class appropriate for validating the given schema.\n\n    Uses the :kw:`$schema` keyword that should be present in the given\n    schema to look up the appropriate validator class.\n\n    Arguments:\n\n        schema (collections.abc.Mapping or bool):\n\n            the schema to look at\n\n        default:\n\n            the default to return if the appropriate validator class\n            cannot be determined.\n\n            If unprovided, the default is to return the latest supported\n            draft.\n\n    Examples:\n\n        The :kw:`$schema` JSON Schema keyword will control which validator\n        class is returned:\n\n        >>> schema = {\n        ...     \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n        ...     \"type\": \"integer\",\n        ... }\n        >>> jsonschema.validators.validator_for(schema)\n        <class 'jsonschema.validators.Draft202012Validator'>\n\n\n        Here, a draft 7 schema instead will return the draft 7 validator:\n\n        >>> schema = {\n        ...     \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n        ...     \"type\": \"integer\",\n        ... }\n        >>> jsonschema.validators.validator_for(schema)\n        <class 'jsonschema.validators.Draft7Validator'>\n\n\n        Schemas with no ``$schema`` keyword will fallback to the default\n        argument:\n\n        >>> schema = {\"type\": \"integer\"}\n        >>> jsonschema.validators.validator_for(\n        ...     schema, default=Draft7Validator,\n        ... )\n        <class 'jsonschema.validators.Draft7Validator'>\n\n        or if none is provided, to the latest version supported.\n        Always including the keyword when authoring schemas is highly\n        recommended.\n\n    \"\"\"\n    DefaultValidator = _LATEST_VERSION if default is _UNSET else default\n\n    if schema is True or schema is False or \"$schema\" not in schema:\n        return DefaultValidator\n    if schema[\"$schema\"] not in _META_SCHEMAS and default is _UNSET:\n        warn(\n            (\n                \"The metaschema specified by $schema was not found. \"\n                \"Using the latest draft to validate, but this will raise \"\n                \"an error in the future.\"\n            ),\n            DeprecationWarning,\n            stacklevel=2,\n        )\n    return _META_SCHEMAS.get(schema[\"$schema\"], DefaultValidator)\n", "jsonschema/__main__.py": "\"\"\"\nThe jsonschema CLI is now deprecated in favor of check-jsonschema.\n\"\"\"\nfrom jsonschema.cli import main\n\nmain()\n", "jsonschema/_legacy_keywords.py": "import re\n\nfrom referencing.jsonschema import lookup_recursive_ref\n\nfrom jsonschema import _utils\nfrom jsonschema.exceptions import ValidationError\n\n\ndef ignore_ref_siblings(schema):\n    \"\"\"\n    Ignore siblings of ``$ref`` if it is present.\n\n    Otherwise, return all keywords.\n\n    Suitable for use with `create`'s ``applicable_validators`` argument.\n    \"\"\"\n    ref = schema.get(\"$ref\")\n    if ref is not None:\n        return [(\"$ref\", ref)]\n    else:\n        return schema.items()\n\n\ndef dependencies_draft3(validator, dependencies, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n\n    for property, dependency in dependencies.items():\n        if property not in instance:\n            continue\n\n        if validator.is_type(dependency, \"object\"):\n            yield from validator.descend(\n                instance, dependency, schema_path=property,\n            )\n        elif validator.is_type(dependency, \"string\"):\n            if dependency not in instance:\n                message = f\"{dependency!r} is a dependency of {property!r}\"\n                yield ValidationError(message)\n        else:\n            for each in dependency:\n                if each not in instance:\n                    message = f\"{each!r} is a dependency of {property!r}\"\n                    yield ValidationError(message)\n\n\ndef dependencies_draft4_draft6_draft7(\n    validator,\n    dependencies,\n    instance,\n    schema,\n):\n    \"\"\"\n    Support for the ``dependencies`` keyword from pre-draft 2019-09.\n\n    In later drafts, the keyword was split into separate\n    ``dependentRequired`` and ``dependentSchemas`` validators.\n    \"\"\"\n    if not validator.is_type(instance, \"object\"):\n        return\n\n    for property, dependency in dependencies.items():\n        if property not in instance:\n            continue\n\n        if validator.is_type(dependency, \"array\"):\n            for each in dependency:\n                if each not in instance:\n                    message = f\"{each!r} is a dependency of {property!r}\"\n                    yield ValidationError(message)\n        else:\n            yield from validator.descend(\n                instance, dependency, schema_path=property,\n            )\n\n\ndef disallow_draft3(validator, disallow, instance, schema):\n    for disallowed in _utils.ensure_list(disallow):\n        if validator.evolve(schema={\"type\": [disallowed]}).is_valid(instance):\n            message = f\"{disallowed!r} is disallowed for {instance!r}\"\n            yield ValidationError(message)\n\n\ndef extends_draft3(validator, extends, instance, schema):\n    if validator.is_type(extends, \"object\"):\n        yield from validator.descend(instance, extends)\n        return\n    for index, subschema in enumerate(extends):\n        yield from validator.descend(instance, subschema, schema_path=index)\n\n\ndef items_draft3_draft4(validator, items, instance, schema):\n    if not validator.is_type(instance, \"array\"):\n        return\n\n    if validator.is_type(items, \"object\"):\n        for index, item in enumerate(instance):\n            yield from validator.descend(item, items, path=index)\n    else:\n        for (index, item), subschema in zip(enumerate(instance), items):\n            yield from validator.descend(\n                item, subschema, path=index, schema_path=index,\n            )\n\n\ndef additionalItems(validator, aI, instance, schema):\n    if (\n        not validator.is_type(instance, \"array\")\n        or validator.is_type(schema.get(\"items\", {}), \"object\")\n    ):\n        return\n\n    len_items = len(schema.get(\"items\", []))\n    if validator.is_type(aI, \"object\"):\n        for index, item in enumerate(instance[len_items:], start=len_items):\n            yield from validator.descend(item, aI, path=index)\n    elif not aI and len(instance) > len(schema.get(\"items\", [])):\n        error = \"Additional items are not allowed (%s %s unexpected)\"\n        yield ValidationError(\n            error % _utils.extras_msg(instance[len(schema.get(\"items\", [])):]),\n        )\n\n\ndef items_draft6_draft7_draft201909(validator, items, instance, schema):\n    if not validator.is_type(instance, \"array\"):\n        return\n\n    if validator.is_type(items, \"array\"):\n        for (index, item), subschema in zip(enumerate(instance), items):\n            yield from validator.descend(\n                item, subschema, path=index, schema_path=index,\n            )\n    else:\n        for index, item in enumerate(instance):\n            yield from validator.descend(item, items, path=index)\n\n\ndef minimum_draft3_draft4(validator, minimum, instance, schema):\n    if not validator.is_type(instance, \"number\"):\n        return\n\n    if schema.get(\"exclusiveMinimum\", False):\n        failed = instance <= minimum\n        cmp = \"less than or equal to\"\n    else:\n        failed = instance < minimum\n        cmp = \"less than\"\n\n    if failed:\n        message = f\"{instance!r} is {cmp} the minimum of {minimum!r}\"\n        yield ValidationError(message)\n\n\ndef maximum_draft3_draft4(validator, maximum, instance, schema):\n    if not validator.is_type(instance, \"number\"):\n        return\n\n    if schema.get(\"exclusiveMaximum\", False):\n        failed = instance >= maximum\n        cmp = \"greater than or equal to\"\n    else:\n        failed = instance > maximum\n        cmp = \"greater than\"\n\n    if failed:\n        message = f\"{instance!r} is {cmp} the maximum of {maximum!r}\"\n        yield ValidationError(message)\n\n\ndef properties_draft3(validator, properties, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n\n    for property, subschema in properties.items():\n        if property in instance:\n            yield from validator.descend(\n                instance[property],\n                subschema,\n                path=property,\n                schema_path=property,\n            )\n        elif subschema.get(\"required\", False):\n            error = ValidationError(f\"{property!r} is a required property\")\n            error._set(\n                validator=\"required\",\n                validator_value=subschema[\"required\"],\n                instance=instance,\n                schema=schema,\n            )\n            error.path.appendleft(property)\n            error.schema_path.extend([property, \"required\"])\n            yield error\n\n\ndef type_draft3(validator, types, instance, schema):\n    types = _utils.ensure_list(types)\n\n    all_errors = []\n    for index, type in enumerate(types):\n        if validator.is_type(type, \"object\"):\n            errors = list(validator.descend(instance, type, schema_path=index))\n            if not errors:\n                return\n            all_errors.extend(errors)\n        elif validator.is_type(instance, type):\n                return\n\n    reprs = []\n    for type in types:\n        try:\n            reprs.append(repr(type[\"name\"]))\n        except Exception:  # noqa: BLE001\n            reprs.append(repr(type))\n    yield ValidationError(\n        f\"{instance!r} is not of type {', '.join(reprs)}\",\n        context=all_errors,\n    )\n\n\ndef contains_draft6_draft7(validator, contains, instance, schema):\n    if not validator.is_type(instance, \"array\"):\n        return\n\n    if not any(\n        validator.evolve(schema=contains).is_valid(element)\n        for element in instance\n    ):\n        yield ValidationError(\n            f\"None of {instance!r} are valid under the given schema\",\n        )\n\n\ndef recursiveRef(validator, recursiveRef, instance, schema):\n    resolved = lookup_recursive_ref(validator._resolver)\n    yield from validator.descend(\n        instance,\n        resolved.contents,\n        resolver=resolved.resolver,\n    )\n\n\ndef find_evaluated_item_indexes_by_schema(validator, instance, schema):\n    \"\"\"\n    Get all indexes of items that get evaluated under the current schema.\n\n    Covers all keywords related to unevaluatedItems: items, prefixItems, if,\n    then, else, contains, unevaluatedItems, allOf, oneOf, anyOf\n    \"\"\"\n    if validator.is_type(schema, \"boolean\"):\n        return []\n    evaluated_indexes = []\n\n    ref = schema.get(\"$ref\")\n    if ref is not None:\n        resolved = validator._resolver.lookup(ref)\n        evaluated_indexes.extend(\n            find_evaluated_item_indexes_by_schema(\n                validator.evolve(\n                    schema=resolved.contents,\n                    _resolver=resolved.resolver,\n                ),\n                instance,\n                resolved.contents,\n            ),\n        )\n\n    if \"$recursiveRef\" in schema:\n        resolved = lookup_recursive_ref(validator._resolver)\n        evaluated_indexes.extend(\n            find_evaluated_item_indexes_by_schema(\n                validator.evolve(\n                    schema=resolved.contents,\n                    _resolver=resolved.resolver,\n                ),\n                instance,\n                resolved.contents,\n            ),\n        )\n\n    if \"items\" in schema:\n        if \"additionalItems\" in schema:\n            return list(range(len(instance)))\n\n        if validator.is_type(schema[\"items\"], \"object\"):\n            return list(range(len(instance)))\n        evaluated_indexes += list(range(len(schema[\"items\"])))\n\n    if \"if\" in schema:\n        if validator.evolve(schema=schema[\"if\"]).is_valid(instance):\n            evaluated_indexes += find_evaluated_item_indexes_by_schema(\n                validator, instance, schema[\"if\"],\n            )\n            if \"then\" in schema:\n                evaluated_indexes += find_evaluated_item_indexes_by_schema(\n                    validator, instance, schema[\"then\"],\n                )\n        elif \"else\" in schema:\n            evaluated_indexes += find_evaluated_item_indexes_by_schema(\n                validator, instance, schema[\"else\"],\n            )\n\n    for keyword in [\"contains\", \"unevaluatedItems\"]:\n        if keyword in schema:\n            for k, v in enumerate(instance):\n                if validator.evolve(schema=schema[keyword]).is_valid(v):\n                    evaluated_indexes.append(k)\n\n    for keyword in [\"allOf\", \"oneOf\", \"anyOf\"]:\n        if keyword in schema:\n            for subschema in schema[keyword]:\n                errs = next(validator.descend(instance, subschema), None)\n                if errs is None:\n                    evaluated_indexes += find_evaluated_item_indexes_by_schema(\n                        validator, instance, subschema,\n                    )\n\n    return evaluated_indexes\n\n\ndef unevaluatedItems_draft2019(validator, unevaluatedItems, instance, schema):\n    if not validator.is_type(instance, \"array\"):\n        return\n    evaluated_item_indexes = find_evaluated_item_indexes_by_schema(\n        validator, instance, schema,\n    )\n    unevaluated_items = [\n        item for index, item in enumerate(instance)\n        if index not in evaluated_item_indexes\n    ]\n    if unevaluated_items:\n        error = \"Unevaluated items are not allowed (%s %s unexpected)\"\n        yield ValidationError(error % _utils.extras_msg(unevaluated_items))\n\n\ndef find_evaluated_property_keys_by_schema(validator, instance, schema):\n    if validator.is_type(schema, \"boolean\"):\n        return []\n    evaluated_keys = []\n\n    ref = schema.get(\"$ref\")\n    if ref is not None:\n        resolved = validator._resolver.lookup(ref)\n        evaluated_keys.extend(\n            find_evaluated_property_keys_by_schema(\n                validator.evolve(\n                    schema=resolved.contents,\n                    _resolver=resolved.resolver,\n                ),\n                instance,\n                resolved.contents,\n            ),\n        )\n\n    if \"$recursiveRef\" in schema:\n        resolved = lookup_recursive_ref(validator._resolver)\n        evaluated_keys.extend(\n            find_evaluated_property_keys_by_schema(\n                validator.evolve(\n                    schema=resolved.contents,\n                    _resolver=resolved.resolver,\n                ),\n                instance,\n                resolved.contents,\n            ),\n        )\n\n    for keyword in [\n        \"properties\", \"additionalProperties\", \"unevaluatedProperties\",\n    ]:\n        if keyword in schema:\n            schema_value = schema[keyword]\n            if validator.is_type(schema_value, \"boolean\") and schema_value:\n                evaluated_keys += instance.keys()\n\n            elif validator.is_type(schema_value, \"object\"):\n                for property in schema_value:\n                    if property in instance:\n                        evaluated_keys.append(property)\n\n    if \"patternProperties\" in schema:\n        for property in instance:\n            for pattern in schema[\"patternProperties\"]:\n                if re.search(pattern, property):\n                    evaluated_keys.append(property)\n\n    if \"dependentSchemas\" in schema:\n        for property, subschema in schema[\"dependentSchemas\"].items():\n            if property not in instance:\n                continue\n            evaluated_keys += find_evaluated_property_keys_by_schema(\n                validator, instance, subschema,\n            )\n\n    for keyword in [\"allOf\", \"oneOf\", \"anyOf\"]:\n        if keyword in schema:\n            for subschema in schema[keyword]:\n                errs = next(validator.descend(instance, subschema), None)\n                if errs is None:\n                    evaluated_keys += find_evaluated_property_keys_by_schema(\n                        validator, instance, subschema,\n                    )\n\n    if \"if\" in schema:\n        if validator.evolve(schema=schema[\"if\"]).is_valid(instance):\n            evaluated_keys += find_evaluated_property_keys_by_schema(\n                validator, instance, schema[\"if\"],\n            )\n            if \"then\" in schema:\n                evaluated_keys += find_evaluated_property_keys_by_schema(\n                    validator, instance, schema[\"then\"],\n                )\n        elif \"else\" in schema:\n            evaluated_keys += find_evaluated_property_keys_by_schema(\n                validator, instance, schema[\"else\"],\n            )\n\n    return evaluated_keys\n\n\ndef unevaluatedProperties_draft2019(validator, uP, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n    evaluated_keys = find_evaluated_property_keys_by_schema(\n        validator, instance, schema,\n    )\n    unevaluated_keys = []\n    for property in instance:\n        if property not in evaluated_keys:\n            for _ in validator.descend(\n                instance[property],\n                uP,\n                path=property,\n                schema_path=property,\n            ):\n                # FIXME: Include context for each unevaluated property\n                #        indicating why it's invalid under the subschema.\n                unevaluated_keys.append(property)  # noqa: PERF401\n\n    if unevaluated_keys:\n        if uP is False:\n            error = \"Unevaluated properties are not allowed (%s %s unexpected)\"\n            extras = sorted(unevaluated_keys, key=str)\n            yield ValidationError(error % _utils.extras_msg(extras))\n        else:\n            error = (\n                \"Unevaluated properties are not valid under \"\n                \"the given schema (%s %s unevaluated and invalid)\"\n            )\n            yield ValidationError(error % _utils.extras_msg(unevaluated_keys))\n", "jsonschema/_typing.py": "\"\"\"\nSome (initially private) typing helpers for jsonschema's types.\n\"\"\"\nfrom typing import Any, Callable, Iterable, Protocol, Tuple, Union\n\nimport referencing.jsonschema\n\nfrom jsonschema.protocols import Validator\n\n\nclass SchemaKeywordValidator(Protocol):\n    def __call__(\n        self,\n        validator: Validator,\n        value: Any,\n        instance: Any,\n        schema: referencing.jsonschema.Schema,\n    ) -> None:\n        ...\n\n\nid_of = Callable[[referencing.jsonschema.Schema], Union[str, None]]\n\n\nApplicableValidators = Callable[\n    [referencing.jsonschema.Schema],\n    Iterable[Tuple[str, Any]],\n]\n", "jsonschema/__init__.py": "\"\"\"\nAn implementation of JSON Schema for Python.\n\nThe main functionality is provided by the validator classes for each of the\nsupported JSON Schema versions.\n\nMost commonly, `jsonschema.validators.validate` is the quickest way to simply\nvalidate a given instance under a schema, and will create a validator\nfor you.\n\"\"\"\nimport warnings\n\nfrom jsonschema._format import FormatChecker\nfrom jsonschema._types import TypeChecker\nfrom jsonschema.exceptions import SchemaError, ValidationError\nfrom jsonschema.validators import (\n    Draft3Validator,\n    Draft4Validator,\n    Draft6Validator,\n    Draft7Validator,\n    Draft201909Validator,\n    Draft202012Validator,\n    validate,\n)\n\n\ndef __getattr__(name):\n    if name == \"__version__\":\n        warnings.warn(\n            \"Accessing jsonschema.__version__ is deprecated and will be \"\n            \"removed in a future release. Use importlib.metadata directly \"\n            \"to query for jsonschema's version.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n\n        from importlib import metadata\n        return metadata.version(\"jsonschema\")\n    elif name == \"RefResolver\":\n        from jsonschema.validators import _RefResolver\n        warnings.warn(\n            _RefResolver._DEPRECATION_MESSAGE,\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _RefResolver\n    elif name == \"ErrorTree\":\n        warnings.warn(\n            \"Importing ErrorTree directly from the jsonschema package \"\n            \"is deprecated and will become an ImportError. Import it from \"\n            \"jsonschema.exceptions instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        from jsonschema.exceptions import ErrorTree\n        return ErrorTree\n    elif name == \"FormatError\":\n        warnings.warn(\n            \"Importing FormatError directly from the jsonschema package \"\n            \"is deprecated and will become an ImportError. Import it from \"\n            \"jsonschema.exceptions instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        from jsonschema.exceptions import FormatError\n        return FormatError\n    elif name == \"Validator\":\n        warnings.warn(\n            \"Importing Validator directly from the jsonschema package \"\n            \"is deprecated and will become an ImportError. Import it from \"\n            \"jsonschema.protocols instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        from jsonschema.protocols import Validator\n        return Validator\n    elif name == \"RefResolutionError\":\n        from jsonschema.exceptions import _RefResolutionError\n        warnings.warn(\n            _RefResolutionError._DEPRECATION_MESSAGE,\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _RefResolutionError\n\n    format_checkers = {\n        \"draft3_format_checker\": Draft3Validator,\n        \"draft4_format_checker\": Draft4Validator,\n        \"draft6_format_checker\": Draft6Validator,\n        \"draft7_format_checker\": Draft7Validator,\n        \"draft201909_format_checker\": Draft201909Validator,\n        \"draft202012_format_checker\": Draft202012Validator,\n    }\n    ValidatorForFormat = format_checkers.get(name)\n    if ValidatorForFormat is not None:\n        warnings.warn(\n            f\"Accessing jsonschema.{name} is deprecated and will be \"\n            \"removed in a future release. Instead, use the FORMAT_CHECKER \"\n            \"attribute on the corresponding Validator.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return ValidatorForFormat.FORMAT_CHECKER\n\n    raise AttributeError(f\"module {__name__} has no attribute {name}\")\n\n\n__all__ = [\n    \"Draft201909Validator\",\n    \"Draft202012Validator\",\n    \"Draft3Validator\",\n    \"Draft4Validator\",\n    \"Draft6Validator\",\n    \"Draft7Validator\",\n    \"FormatChecker\",\n    \"SchemaError\",\n    \"TypeChecker\",\n    \"ValidationError\",\n    \"validate\",\n]\n", "jsonschema/_keywords.py": "from fractions import Fraction\nimport re\n\nfrom jsonschema._utils import (\n    ensure_list,\n    equal,\n    extras_msg,\n    find_additional_properties,\n    find_evaluated_item_indexes_by_schema,\n    find_evaluated_property_keys_by_schema,\n    uniq,\n)\nfrom jsonschema.exceptions import FormatError, ValidationError\n\n\ndef patternProperties(validator, patternProperties, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n\n    for pattern, subschema in patternProperties.items():\n        for k, v in instance.items():\n            if re.search(pattern, k):\n                yield from validator.descend(\n                    v, subschema, path=k, schema_path=pattern,\n                )\n\n\ndef propertyNames(validator, propertyNames, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n\n    for property in instance:\n        yield from validator.descend(instance=property, schema=propertyNames)\n\n\ndef additionalProperties(validator, aP, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n\n    extras = set(find_additional_properties(instance, schema))\n\n    if validator.is_type(aP, \"object\"):\n        for extra in extras:\n            yield from validator.descend(instance[extra], aP, path=extra)\n    elif not aP and extras:\n        if \"patternProperties\" in schema:\n            verb = \"does\" if len(extras) == 1 else \"do\"\n            joined = \", \".join(repr(each) for each in sorted(extras))\n            patterns = \", \".join(\n                repr(each) for each in sorted(schema[\"patternProperties\"])\n            )\n            error = f\"{joined} {verb} not match any of the regexes: {patterns}\"\n            yield ValidationError(error)\n        else:\n            error = \"Additional properties are not allowed (%s %s unexpected)\"\n            yield ValidationError(error % extras_msg(sorted(extras, key=str)))\n\n\ndef items(validator, items, instance, schema):\n    if not validator.is_type(instance, \"array\"):\n        return\n\n    prefix = len(schema.get(\"prefixItems\", []))\n    total = len(instance)\n    extra = total - prefix\n    if extra <= 0:\n        return\n\n    if items is False:\n        rest = instance[prefix:] if extra != 1 else instance[prefix]\n        item = \"items\" if prefix != 1 else \"item\"\n        yield ValidationError(\n            f\"Expected at most {prefix} {item} but found {extra} \"\n            f\"extra: {rest!r}\",\n        )\n    else:\n        for index in range(prefix, total):\n            yield from validator.descend(\n                instance=instance[index],\n                schema=items,\n                path=index,\n            )\n\n\ndef const(validator, const, instance, schema):\n    if not equal(instance, const):\n        yield ValidationError(f\"{const!r} was expected\")\n\n\ndef contains(validator, contains, instance, schema):\n    if not validator.is_type(instance, \"array\"):\n        return\n\n    matches = 0\n    min_contains = schema.get(\"minContains\", 1)\n    max_contains = schema.get(\"maxContains\", len(instance))\n\n    contains_validator = validator.evolve(schema=contains)\n\n    for each in instance:\n        if contains_validator.is_valid(each):\n            matches += 1\n            if matches > max_contains:\n                yield ValidationError(\n                    \"Too many items match the given schema \"\n                    f\"(expected at most {max_contains})\",\n                    validator=\"maxContains\",\n                    validator_value=max_contains,\n                )\n                return\n\n    if matches < min_contains:\n        if not matches:\n            yield ValidationError(\n                f\"{instance!r} does not contain items \"\n                \"matching the given schema\",\n            )\n        else:\n            yield ValidationError(\n                \"Too few items match the given schema (expected at least \"\n                f\"{min_contains} but only {matches} matched)\",\n                validator=\"minContains\",\n                validator_value=min_contains,\n            )\n\n\ndef exclusiveMinimum(validator, minimum, instance, schema):\n    if not validator.is_type(instance, \"number\"):\n        return\n\n    if instance <= minimum:\n        yield ValidationError(\n            f\"{instance!r} is less than or equal to \"\n            f\"the minimum of {minimum!r}\",\n        )\n\n\ndef exclusiveMaximum(validator, maximum, instance, schema):\n    if not validator.is_type(instance, \"number\"):\n        return\n\n    if instance >= maximum:\n        yield ValidationError(\n            f\"{instance!r} is greater than or equal \"\n            f\"to the maximum of {maximum!r}\",\n        )\n\n\ndef minimum(validator, minimum, instance, schema):\n    if not validator.is_type(instance, \"number\"):\n        return\n\n    if instance < minimum:\n        message = f\"{instance!r} is less than the minimum of {minimum!r}\"\n        yield ValidationError(message)\n\n\ndef maximum(validator, maximum, instance, schema):\n    if not validator.is_type(instance, \"number\"):\n        return\n\n    if instance > maximum:\n        message = f\"{instance!r} is greater than the maximum of {maximum!r}\"\n        yield ValidationError(message)\n\n\ndef multipleOf(validator, dB, instance, schema):\n    if not validator.is_type(instance, \"number\"):\n        return\n\n    if isinstance(dB, float):\n        quotient = instance / dB\n        try:\n            failed = int(quotient) != quotient\n        except OverflowError:\n            # When `instance` is large and `dB` is less than one,\n            # quotient can overflow to infinity; and then casting to int\n            # raises an error.\n            #\n            # In this case we fall back to Fraction logic, which is\n            # exact and cannot overflow.  The performance is also\n            # acceptable: we try the fast all-float option first, and\n            # we know that fraction(dB) can have at most a few hundred\n            # digits in each part.  The worst-case slowdown is therefore\n            # for already-slow enormous integers or Decimals.\n            failed = (Fraction(instance) / Fraction(dB)).denominator != 1\n    else:\n        failed = instance % dB\n\n    if failed:\n        yield ValidationError(f\"{instance!r} is not a multiple of {dB}\")\n\n\ndef minItems(validator, mI, instance, schema):\n    if validator.is_type(instance, \"array\") and len(instance) < mI:\n        message = \"should be non-empty\" if mI == 1 else \"is too short\"\n        yield ValidationError(f\"{instance!r} {message}\")\n\n\ndef maxItems(validator, mI, instance, schema):\n    if validator.is_type(instance, \"array\") and len(instance) > mI:\n        message = \"is expected to be empty\" if mI == 0 else \"is too long\"\n        yield ValidationError(f\"{instance!r} {message}\")\n\n\ndef uniqueItems(validator, uI, instance, schema):\n    if (\n        uI\n        and validator.is_type(instance, \"array\")\n        and not uniq(instance)\n    ):\n        yield ValidationError(f\"{instance!r} has non-unique elements\")\n\n\ndef pattern(validator, patrn, instance, schema):\n    if (\n        validator.is_type(instance, \"string\")\n        and not re.search(patrn, instance)\n    ):\n        yield ValidationError(f\"{instance!r} does not match {patrn!r}\")\n\n\ndef format(validator, format, instance, schema):\n    if validator.format_checker is not None:\n        try:\n            validator.format_checker.check(instance, format)\n        except FormatError as error:\n            yield ValidationError(error.message, cause=error.cause)\n\n\ndef minLength(validator, mL, instance, schema):\n    if validator.is_type(instance, \"string\") and len(instance) < mL:\n        message = \"should be non-empty\" if mL == 1 else \"is too short\"\n        yield ValidationError(f\"{instance!r} {message}\")\n\n\ndef maxLength(validator, mL, instance, schema):\n    if validator.is_type(instance, \"string\") and len(instance) > mL:\n        message = \"is expected to be empty\" if mL == 0 else \"is too long\"\n        yield ValidationError(f\"{instance!r} {message}\")\n\n\ndef dependentRequired(validator, dependentRequired, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n\n    for property, dependency in dependentRequired.items():\n        if property not in instance:\n            continue\n\n        for each in dependency:\n            if each not in instance:\n                message = f\"{each!r} is a dependency of {property!r}\"\n                yield ValidationError(message)\n\n\ndef dependentSchemas(validator, dependentSchemas, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n\n    for property, dependency in dependentSchemas.items():\n        if property not in instance:\n            continue\n        yield from validator.descend(\n            instance, dependency, schema_path=property,\n        )\n\n\ndef enum(validator, enums, instance, schema):\n    if all(not equal(each, instance) for each in enums):\n        yield ValidationError(f\"{instance!r} is not one of {enums!r}\")\n\n\ndef ref(validator, ref, instance, schema):\n    yield from validator._validate_reference(ref=ref, instance=instance)\n\n\ndef dynamicRef(validator, dynamicRef, instance, schema):\n    yield from validator._validate_reference(ref=dynamicRef, instance=instance)\n\n\ndef type(validator, types, instance, schema):\n    types = ensure_list(types)\n\n    if not any(validator.is_type(instance, type) for type in types):\n        reprs = \", \".join(repr(type) for type in types)\n        yield ValidationError(f\"{instance!r} is not of type {reprs}\")\n\n\ndef properties(validator, properties, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n\n    for property, subschema in properties.items():\n        if property in instance:\n            yield from validator.descend(\n                instance[property],\n                subschema,\n                path=property,\n                schema_path=property,\n            )\n\n\ndef required(validator, required, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n    for property in required:\n        if property not in instance:\n            yield ValidationError(f\"{property!r} is a required property\")\n\n\ndef minProperties(validator, mP, instance, schema):\n    if validator.is_type(instance, \"object\") and len(instance) < mP:\n        message = (\n            \"should be non-empty\" if mP == 1\n            else \"does not have enough properties\"\n        )\n        yield ValidationError(f\"{instance!r} {message}\")\n\n\ndef maxProperties(validator, mP, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n    if validator.is_type(instance, \"object\") and len(instance) > mP:\n        message = (\n            \"is expected to be empty\" if mP == 0\n            else \"has too many properties\"\n        )\n        yield ValidationError(f\"{instance!r} {message}\")\n\n\ndef allOf(validator, allOf, instance, schema):\n    for index, subschema in enumerate(allOf):\n        yield from validator.descend(instance, subschema, schema_path=index)\n\n\ndef anyOf(validator, anyOf, instance, schema):\n    all_errors = []\n    for index, subschema in enumerate(anyOf):\n        errs = list(validator.descend(instance, subschema, schema_path=index))\n        if not errs:\n            break\n        all_errors.extend(errs)\n    else:\n        yield ValidationError(\n            f\"{instance!r} is not valid under any of the given schemas\",\n            context=all_errors,\n        )\n\n\ndef oneOf(validator, oneOf, instance, schema):\n    subschemas = enumerate(oneOf)\n    all_errors = []\n    for index, subschema in subschemas:\n        errs = list(validator.descend(instance, subschema, schema_path=index))\n        if not errs:\n            first_valid = subschema\n            break\n        all_errors.extend(errs)\n    else:\n        yield ValidationError(\n            f\"{instance!r} is not valid under any of the given schemas\",\n            context=all_errors,\n        )\n\n    more_valid = [\n        each for _, each in subschemas\n        if validator.evolve(schema=each).is_valid(instance)\n    ]\n    if more_valid:\n        more_valid.append(first_valid)\n        reprs = \", \".join(repr(schema) for schema in more_valid)\n        yield ValidationError(f\"{instance!r} is valid under each of {reprs}\")\n\n\ndef not_(validator, not_schema, instance, schema):\n    if validator.evolve(schema=not_schema).is_valid(instance):\n        message = f\"{instance!r} should not be valid under {not_schema!r}\"\n        yield ValidationError(message)\n\n\ndef if_(validator, if_schema, instance, schema):\n    if validator.evolve(schema=if_schema).is_valid(instance):\n        if \"then\" in schema:\n            then = schema[\"then\"]\n            yield from validator.descend(instance, then, schema_path=\"then\")\n    elif \"else\" in schema:\n        else_ = schema[\"else\"]\n        yield from validator.descend(instance, else_, schema_path=\"else\")\n\n\ndef unevaluatedItems(validator, unevaluatedItems, instance, schema):\n    if not validator.is_type(instance, \"array\"):\n        return\n    evaluated_item_indexes = find_evaluated_item_indexes_by_schema(\n        validator, instance, schema,\n    )\n    unevaluated_items = [\n        item for index, item in enumerate(instance)\n        if index not in evaluated_item_indexes\n    ]\n    if unevaluated_items:\n        error = \"Unevaluated items are not allowed (%s %s unexpected)\"\n        yield ValidationError(error % extras_msg(unevaluated_items))\n\n\ndef unevaluatedProperties(validator, unevaluatedProperties, instance, schema):\n    if not validator.is_type(instance, \"object\"):\n        return\n    evaluated_keys = find_evaluated_property_keys_by_schema(\n        validator, instance, schema,\n    )\n    unevaluated_keys = []\n    for property in instance:\n        if property not in evaluated_keys:\n            for _ in validator.descend(\n                instance[property],\n                unevaluatedProperties,\n                path=property,\n                schema_path=property,\n            ):\n                # FIXME: Include context for each unevaluated property\n                #        indicating why it's invalid under the subschema.\n                unevaluated_keys.append(property)  # noqa: PERF401\n\n    if unevaluated_keys:\n        if unevaluatedProperties is False:\n            error = \"Unevaluated properties are not allowed (%s %s unexpected)\"\n            extras = sorted(unevaluated_keys, key=str)\n            yield ValidationError(error % extras_msg(extras))\n        else:\n            error = (\n                \"Unevaluated properties are not valid under \"\n                \"the given schema (%s %s unevaluated and invalid)\"\n            )\n            yield ValidationError(error % extras_msg(unevaluated_keys))\n\n\ndef prefixItems(validator, prefixItems, instance, schema):\n    if not validator.is_type(instance, \"array\"):\n        return\n\n    for (index, item), subschema in zip(enumerate(instance), prefixItems):\n        yield from validator.descend(\n            instance=item,\n            schema=subschema,\n            schema_path=index,\n            path=index,\n        )\n", "jsonschema/benchmarks/unused_registry.py": "\"\"\"\nAn unused schema registry should not cause slower validation.\n\n\"Unused\" here means one where no reference resolution is occurring anyhow.\n\nSee https://github.com/python-jsonschema/jsonschema/issues/1088.\n\"\"\"\nfrom pyperf import Runner\nfrom referencing import Registry\nfrom referencing.jsonschema import DRAFT201909\n\nfrom jsonschema import Draft201909Validator\n\nregistry = Registry().with_resource(\n    \"urn:example:foo\",\n    DRAFT201909.create_resource({}),\n)\n\nschema = {\"$ref\": \"https://json-schema.org/draft/2019-09/schema\"}\ninstance = {\"maxLength\": 4}\n\nno_registry = Draft201909Validator(schema)\nwith_useless_registry = Draft201909Validator(schema, registry=registry)\n\nif __name__ == \"__main__\":\n    runner = Runner()\n\n    runner.bench_func(\n        \"no registry\",\n        lambda: no_registry.is_valid(instance),\n    )\n    runner.bench_func(\n        \"useless registry\",\n        lambda: with_useless_registry.is_valid(instance),\n    )\n", "jsonschema/benchmarks/useless_keywords.py": "\"\"\"\nA benchmark for validation of schemas containing lots of useless keywords.\n\nChecks we filter them out once, ahead of time.\n\"\"\"\n\nfrom pyperf import Runner\n\nfrom jsonschema import Draft202012Validator\n\nNUM_USELESS = 100000\nschema = dict(\n    [\n        (\"not\", {\"const\": 42}),\n        *((str(i), i) for i in range(NUM_USELESS)),\n        (\"type\", \"integer\"),\n        *((str(i), i) for i in range(NUM_USELESS, NUM_USELESS)),\n        (\"minimum\", 37),\n    ],\n)\nvalidator = Draft202012Validator(schema)\n\nvalid = 3737\ninvalid = 12\n\n\nif __name__ == \"__main__\":\n    runner = Runner()\n    runner.bench_func(\"beginning of schema\", lambda: validator.is_valid(42))\n    runner.bench_func(\"middle of schema\", lambda: validator.is_valid(\"foo\"))\n    runner.bench_func(\"end of schema\", lambda: validator.is_valid(12))\n    runner.bench_func(\"valid\", lambda: validator.is_valid(3737))\n", "jsonschema/benchmarks/const_vs_enum.py": "\"\"\"\nA benchmark for comparing equivalent validation of `const` and `enum`.\n\"\"\"\n\nfrom pyperf import Runner\n\nfrom jsonschema import Draft202012Validator\n\nvalue = [37] * 100\nconst_schema = {\"const\": list(value)}\nenum_schema = {\"enum\": [list(value)]}\n\nvalid = list(value)\ninvalid = [*valid, 73]\n\nconst = Draft202012Validator(const_schema)\nenum = Draft202012Validator(enum_schema)\n\nassert const.is_valid(valid)\nassert enum.is_valid(valid)\nassert not const.is_valid(invalid)\nassert not enum.is_valid(invalid)\n\n\nif __name__ == \"__main__\":\n    runner = Runner()\n    runner.bench_func(\"const valid\", lambda: const.is_valid(valid))\n    runner.bench_func(\"const invalid\", lambda: const.is_valid(invalid))\n    runner.bench_func(\"enum valid\", lambda: enum.is_valid(valid))\n    runner.bench_func(\"enum invalid\", lambda: enum.is_valid(invalid))\n", "jsonschema/benchmarks/subcomponents.py": "\"\"\"\nA benchmark which tries to compare the possible slow subparts of validation.\n\"\"\"\nfrom referencing import Registry\nfrom referencing.jsonschema import DRAFT202012\nfrom rpds import HashTrieMap, HashTrieSet\n\nfrom jsonschema import Draft202012Validator\n\nschema = {\n    \"type\": \"array\",\n    \"minLength\": 1,\n    \"maxLength\": 1,\n    \"items\": {\"type\": \"integer\"},\n}\n\nhmap = HashTrieMap()\nhset = HashTrieSet()\n\nregistry = Registry()\n\nv = Draft202012Validator(schema)\n\n\ndef registry_data_structures():\n    return hmap.insert(\"foo\", \"bar\"), hset.insert(\"foo\")\n\n\ndef registry_add():\n    resource = DRAFT202012.create_resource(schema)\n    return registry.with_resource(uri=\"urn:example\", resource=resource)\n\n\nif __name__ == \"__main__\":\n    from pyperf import Runner\n    runner = Runner()\n\n    runner.bench_func(\"HashMap/HashSet insertion\", registry_data_structures)\n    runner.bench_func(\"Registry insertion\", registry_add)\n    runner.bench_func(\"Success\", lambda: v.is_valid([1]))\n    runner.bench_func(\"Failure\", lambda: v.is_valid([\"foo\"]))\n    runner.bench_func(\"Metaschema validation\", lambda: v.check_schema(schema))\n", "jsonschema/benchmarks/contains.py": "\"\"\"\nA benchmark for validation of the `contains` keyword.\n\"\"\"\n\nfrom pyperf import Runner\n\nfrom jsonschema import Draft202012Validator\n\nschema = {\n    \"type\": \"array\",\n    \"contains\": {\"const\": 37},\n}\nvalidator = Draft202012Validator(schema)\n\nsize = 1000\nbeginning = [37] + [0] * (size - 1)\nmiddle = [0] * (size // 2) + [37] + [0] * (size // 2)\nend = [0] * (size - 1) + [37]\ninvalid = [0] * size\n\n\nif __name__ == \"__main__\":\n    runner = Runner()\n    runner.bench_func(\"baseline\", lambda: validator.is_valid([]))\n    runner.bench_func(\"beginning\", lambda: validator.is_valid(beginning))\n    runner.bench_func(\"middle\", lambda: validator.is_valid(middle))\n    runner.bench_func(\"end\", lambda: validator.is_valid(end))\n    runner.bench_func(\"invalid\", lambda: validator.is_valid(invalid))\n", "jsonschema/benchmarks/issue232.py": "\"\"\"\nA performance benchmark using the example from issue #232.\n\nSee https://github.com/python-jsonschema/jsonschema/pull/232.\n\"\"\"\nfrom pathlib import Path\n\nfrom pyperf import Runner\nfrom referencing import Registry\n\nfrom jsonschema.tests._suite import Version\nimport jsonschema\n\nissue232 = Version(\n    path=Path(__file__).parent / \"issue232\",\n    remotes=Registry(),\n    name=\"issue232\",\n)\n\n\nif __name__ == \"__main__\":\n    issue232.benchmark(\n        runner=Runner(),\n        Validator=jsonschema.Draft4Validator,\n    )\n", "jsonschema/benchmarks/__init__.py": "\"\"\"\nBenchmarks for validation.\n\nThis package is *not* public API.\n\"\"\"\n", "jsonschema/benchmarks/nested_schemas.py": "\"\"\"\nValidating highly nested schemas shouldn't cause exponential time blowups.\n\nSee https://github.com/python-jsonschema/jsonschema/issues/1097.\n\"\"\"\nfrom itertools import cycle\n\nfrom jsonschema.validators import validator_for\n\nmetaschemaish = {\n    \"$id\": \"https://example.com/draft/2020-12/schema/strict\",\n    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n\n    \"$vocabulary\": {\n        \"https://json-schema.org/draft/2020-12/vocab/core\": True,\n        \"https://json-schema.org/draft/2020-12/vocab/applicator\": True,\n        \"https://json-schema.org/draft/2020-12/vocab/unevaluated\": True,\n        \"https://json-schema.org/draft/2020-12/vocab/validation\": True,\n        \"https://json-schema.org/draft/2020-12/vocab/meta-data\": True,\n        \"https://json-schema.org/draft/2020-12/vocab/format-annotation\": True,\n        \"https://json-schema.org/draft/2020-12/vocab/content\": True,\n    },\n    \"$dynamicAnchor\": \"meta\",\n\n    \"$ref\": \"https://json-schema.org/draft/2020-12/schema\",\n    \"unevaluatedProperties\": False,\n}\n\n\ndef nested_schema(levels):\n    \"\"\"\n    Produce a schema which validates deeply nested objects and arrays.\n    \"\"\"\n\n    names = cycle([\"foo\", \"bar\", \"baz\", \"quux\", \"spam\", \"eggs\"])\n    schema = {\"type\": \"object\", \"properties\": {\"ham\": {\"type\": \"string\"}}}\n    for _, name in zip(range(levels - 1), names):\n        schema = {\"type\": \"object\", \"properties\": {name: schema}}\n    return schema\n\n\nvalidator = validator_for(metaschemaish)(metaschemaish)\n\nif __name__ == \"__main__\":\n    from pyperf import Runner\n    runner = Runner()\n\n    not_nested = nested_schema(levels=1)\n    runner.bench_func(\"not nested\", lambda: validator.is_valid(not_nested))\n\n    for levels in range(1, 11, 3):\n        schema = nested_schema(levels=levels)\n        runner.bench_func(\n            f\"nested * {levels}\",\n            lambda schema=schema: validator.is_valid(schema),\n        )\n", "jsonschema/benchmarks/validator_creation.py": "from pyperf import Runner\n\nfrom jsonschema import Draft202012Validator\n\nschema = {\n    \"type\": \"array\",\n    \"minLength\": 1,\n    \"maxLength\": 1,\n    \"items\": {\"type\": \"integer\"},\n}\n\n\nif __name__ == \"__main__\":\n    Runner().bench_func(\"validator creation\", Draft202012Validator, schema)\n", "jsonschema/benchmarks/useless_applicator_schemas.py": "\n\"\"\"\nA benchmark for validation of applicators containing lots of useless schemas.\n\nSignals a small possible optimization to remove all such schemas ahead of time.\n\"\"\"\n\nfrom pyperf import Runner\n\nfrom jsonschema import Draft202012Validator as Validator\n\nNUM_USELESS = 100000\n\nsubschema = {\"const\": 37}\n\nvalid = 37\ninvalid = 12\n\nbaseline = Validator(subschema)\n\n\n# These should be indistinguishable from just `subschema`\nby_name = {\n    \"single subschema\": {\n        \"anyOf\": Validator({\"anyOf\": [subschema]}),\n        \"allOf\": Validator({\"allOf\": [subschema]}),\n        \"oneOf\": Validator({\"oneOf\": [subschema]}),\n    },\n    \"redundant subschemas\": {\n        \"anyOf\": Validator({\"anyOf\": [subschema] * NUM_USELESS}),\n        \"allOf\": Validator({\"allOf\": [subschema] * NUM_USELESS}),\n    },\n    \"useless successful subschemas (beginning)\": {\n        \"anyOf\": Validator({\"anyOf\": [subschema, *[True] * NUM_USELESS]}),\n        \"allOf\": Validator({\"allOf\": [subschema, *[True] * NUM_USELESS]}),\n    },\n    \"useless successful subschemas (middle)\": {\n        \"anyOf\": Validator(\n            {\n                \"anyOf\": [\n                    *[True] * (NUM_USELESS // 2),\n                    subschema,\n                    *[True] * (NUM_USELESS // 2),\n                ],\n            },\n        ),\n        \"allOf\": Validator(\n            {\n                \"allOf\": [\n                    *[True] * (NUM_USELESS // 2),\n                    subschema,\n                    *[True] * (NUM_USELESS // 2),\n                ],\n            },\n        ),\n    },\n    \"useless successful subschemas (end)\": {\n        \"anyOf\": Validator({\"anyOf\": [*[True] * NUM_USELESS, subschema]}),\n        \"allOf\": Validator({\"allOf\": [*[True] * NUM_USELESS, subschema]}),\n    },\n    \"useless failing subschemas (beginning)\": {\n        \"anyOf\": Validator({\"anyOf\": [subschema, *[False] * NUM_USELESS]}),\n        \"oneOf\": Validator({\"oneOf\": [subschema, *[False] * NUM_USELESS]}),\n    },\n    \"useless failing subschemas (middle)\": {\n        \"anyOf\": Validator(\n            {\n                \"anyOf\": [\n                    *[False] * (NUM_USELESS // 2),\n                    subschema,\n                    *[False] * (NUM_USELESS // 2),\n                ],\n            },\n        ),\n        \"oneOf\": Validator(\n            {\n                \"oneOf\": [\n                    *[False] * (NUM_USELESS // 2),\n                    subschema,\n                    *[False] * (NUM_USELESS // 2),\n                ],\n            },\n        ),\n    },\n    \"useless failing subschemas (end)\": {\n        \"anyOf\": Validator({\"anyOf\": [*[False] * NUM_USELESS, subschema]}),\n        \"oneOf\": Validator({\"oneOf\": [*[False] * NUM_USELESS, subschema]}),\n    },\n}\n\nif __name__ == \"__main__\":\n    runner = Runner()\n\n    runner.bench_func(\"baseline valid\", lambda: baseline.is_valid(valid))\n    runner.bench_func(\"baseline invalid\", lambda: baseline.is_valid(invalid))\n\n    for group, applicators in by_name.items():\n        for applicator, validator in applicators.items():\n            runner.bench_func(\n                f\"{group}: {applicator} valid\",\n                lambda validator=validator: validator.is_valid(valid),\n            )\n            runner.bench_func(\n                f\"{group}: {applicator} invalid\",\n                lambda validator=validator: validator.is_valid(invalid),\n            )\n"}