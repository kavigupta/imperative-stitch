{"setup.py": "#!/usr/bin/env python\n\nimport io\n\nfrom setuptools import setup, find_packages\n\n\nsetup(\n    name='jmespath',\n    version='1.0.1',\n    description='JSON Matching Expressions',\n    long_description=io.open('README.rst', encoding='utf-8').read(),\n    author='James Saryerwinnie',\n    author_email='js@jamesls.com',\n    url='https://github.com/jmespath/jmespath.py',\n    scripts=['bin/jp.py'],\n    packages=find_packages(exclude=['tests']),\n    license='MIT',\n    python_requires='>=3.7',\n    classifiers=[\n        'Development Status :: 5 - Production/Stable',\n        'Intended Audience :: Developers',\n        'Natural Language :: English',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.7',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: Implementation :: CPython',\n        'Programming Language :: Python :: Implementation :: PyPy',\n    ],\n)\n", "jmespath/lexer.py": "import string\nimport warnings\nfrom json import loads\n\nfrom jmespath.exceptions import LexerError, EmptyExpressionError\n\n\nclass Lexer(object):\n    START_IDENTIFIER = set(string.ascii_letters + '_')\n    VALID_IDENTIFIER = set(string.ascii_letters + string.digits + '_')\n    VALID_NUMBER = set(string.digits)\n    WHITESPACE = set(\" \\t\\n\\r\")\n    SIMPLE_TOKENS = {\n        '.': 'dot',\n        '*': 'star',\n        ']': 'rbracket',\n        ',': 'comma',\n        ':': 'colon',\n        '@': 'current',\n        '(': 'lparen',\n        ')': 'rparen',\n        '{': 'lbrace',\n        '}': 'rbrace',\n    }\n\n    def tokenize(self, expression):\n        self._initialize_for_expression(expression)\n        while self._current is not None:\n            if self._current in self.SIMPLE_TOKENS:\n                yield {'type': self.SIMPLE_TOKENS[self._current],\n                       'value': self._current,\n                       'start': self._position, 'end': self._position + 1}\n                self._next()\n            elif self._current in self.START_IDENTIFIER:\n                start = self._position\n                buff = self._current\n                while self._next() in self.VALID_IDENTIFIER:\n                    buff += self._current\n                yield {'type': 'unquoted_identifier', 'value': buff,\n                       'start': start, 'end': start + len(buff)}\n            elif self._current in self.WHITESPACE:\n                self._next()\n            elif self._current == '[':\n                start = self._position\n                next_char = self._next()\n                if next_char == ']':\n                    self._next()\n                    yield {'type': 'flatten', 'value': '[]',\n                           'start': start, 'end': start + 2}\n                elif next_char == '?':\n                    self._next()\n                    yield {'type': 'filter', 'value': '[?',\n                           'start': start, 'end': start + 2}\n                else:\n                    yield {'type': 'lbracket', 'value': '[',\n                           'start': start, 'end': start + 1}\n            elif self._current == \"'\":\n                yield self._consume_raw_string_literal()\n            elif self._current == '|':\n                yield self._match_or_else('|', 'or', 'pipe')\n            elif self._current == '&':\n                yield self._match_or_else('&', 'and', 'expref')\n            elif self._current == '`':\n                yield self._consume_literal()\n            elif self._current in self.VALID_NUMBER:\n                start = self._position\n                buff = self._consume_number()\n                yield {'type': 'number', 'value': int(buff),\n                       'start': start, 'end': start + len(buff)}\n            elif self._current == '-':\n                # Negative number.\n                start = self._position\n                buff = self._consume_number()\n                if len(buff) > 1:\n                    yield {'type': 'number', 'value': int(buff),\n                           'start': start, 'end': start + len(buff)}\n                else:\n                    raise LexerError(lexer_position=start,\n                                     lexer_value=buff,\n                                     message=\"Unknown token '%s'\" % buff)\n            elif self._current == '\"':\n                yield self._consume_quoted_identifier()\n            elif self._current == '<':\n                yield self._match_or_else('=', 'lte', 'lt')\n            elif self._current == '>':\n                yield self._match_or_else('=', 'gte', 'gt')\n            elif self._current == '!':\n                yield self._match_or_else('=', 'ne', 'not')\n            elif self._current == '=':\n                if self._next() == '=':\n                    yield {'type': 'eq', 'value': '==',\n                        'start': self._position - 1, 'end': self._position}\n                    self._next()\n                else:\n                    if self._current is None:\n                        # If we're at the EOF, we never advanced\n                        # the position so we don't need to rewind\n                        # it back one location.\n                        position = self._position\n                    else:\n                        position = self._position - 1\n                    raise LexerError(\n                        lexer_position=position,\n                        lexer_value='=',\n                        message=\"Unknown token '='\")\n            else:\n                raise LexerError(lexer_position=self._position,\n                                 lexer_value=self._current,\n                                 message=\"Unknown token %s\" % self._current)\n        yield {'type': 'eof', 'value': '',\n               'start': self._length, 'end': self._length}\n\n    def _consume_number(self):\n        start = self._position\n        buff = self._current\n        while self._next() in self.VALID_NUMBER:\n            buff += self._current\n        return buff\n\n    def _initialize_for_expression(self, expression):\n        if not expression:\n            raise EmptyExpressionError()\n        self._position = 0\n        self._expression = expression\n        self._chars = list(self._expression)\n        self._current = self._chars[self._position]\n        self._length = len(self._expression)\n\n    def _next(self):\n        if self._position == self._length - 1:\n            self._current = None\n        else:\n            self._position += 1\n            self._current = self._chars[self._position]\n        return self._current\n\n    def _consume_until(self, delimiter):\n        # Consume until the delimiter is reached,\n        # allowing for the delimiter to be escaped with \"\\\".\n        start = self._position\n        buff = ''\n        self._next()\n        while self._current != delimiter:\n            if self._current == '\\\\':\n                buff += '\\\\'\n                self._next()\n            if self._current is None:\n                # We're at the EOF.\n                raise LexerError(lexer_position=start,\n                                 lexer_value=self._expression[start:],\n                                 message=\"Unclosed %s delimiter\" % delimiter)\n            buff += self._current\n            self._next()\n        # Skip the closing delimiter.\n        self._next()\n        return buff\n\n    def _consume_literal(self):\n        start = self._position\n        lexeme = self._consume_until('`').replace('\\\\`', '`')\n        try:\n            # Assume it is valid JSON and attempt to parse.\n            parsed_json = loads(lexeme)\n        except ValueError:\n            try:\n                # Invalid JSON values should be converted to quoted\n                # JSON strings during the JEP-12 deprecation period.\n                parsed_json = loads('\"%s\"' % lexeme.lstrip())\n                warnings.warn(\"deprecated string literal syntax\",\n                              PendingDeprecationWarning)\n            except ValueError:\n                raise LexerError(lexer_position=start,\n                                 lexer_value=self._expression[start:],\n                                 message=\"Bad token %s\" % lexeme)\n        token_len = self._position - start\n        return {'type': 'literal', 'value': parsed_json,\n                'start': start, 'end': token_len}\n\n    def _consume_quoted_identifier(self):\n        start = self._position\n        lexeme = '\"' + self._consume_until('\"') + '\"'\n        try:\n            token_len = self._position - start\n            return {'type': 'quoted_identifier', 'value': loads(lexeme),\n                    'start': start, 'end': token_len}\n        except ValueError as e:\n            error_message = str(e).split(':')[0]\n            raise LexerError(lexer_position=start,\n                             lexer_value=lexeme,\n                             message=error_message)\n\n    def _consume_raw_string_literal(self):\n        start = self._position\n        lexeme = self._consume_until(\"'\").replace(\"\\\\'\", \"'\")\n        token_len = self._position - start\n        return {'type': 'literal', 'value': lexeme,\n                'start': start, 'end': token_len}\n\n    def _match_or_else(self, expected, match_type, else_type):\n        start = self._position\n        current = self._current\n        next_char = self._next()\n        if next_char == expected:\n            self._next()\n            return {'type': match_type, 'value': current + next_char,\n                    'start': start, 'end': start + 1}\n        return {'type': else_type, 'value': current,\n                'start': start, 'end': start}\n", "jmespath/ast.py": "# AST nodes have this structure:\n# {\"type\": <node type>\", children: [], \"value\": \"\"}\n\n\ndef comparator(name, first, second):\n    return {'type': 'comparator', 'children': [first, second], 'value': name}\n\n\ndef current_node():\n    return {'type': 'current', 'children': []}\n\n\ndef expref(expression):\n    return {'type': 'expref', 'children': [expression]}\n\n\ndef function_expression(name, args):\n    return {'type': 'function_expression', 'children': args, 'value': name}\n\n\ndef field(name):\n    return {\"type\": \"field\", \"children\": [], \"value\": name}\n\n\ndef filter_projection(left, right, comparator):\n    return {'type': 'filter_projection', 'children': [left, right, comparator]}\n\n\ndef flatten(node):\n    return {'type': 'flatten', 'children': [node]}\n\n\ndef identity():\n    return {\"type\": \"identity\", 'children': []}\n\n\ndef index(index):\n    return {\"type\": \"index\", \"value\": index, \"children\": []}\n\n\ndef index_expression(children):\n    return {\"type\": \"index_expression\", 'children': children}\n\n\ndef key_val_pair(key_name, node):\n    return {\"type\": \"key_val_pair\", 'children': [node], \"value\": key_name}\n\n\ndef literal(literal_value):\n    return {'type': 'literal', 'value': literal_value, 'children': []}\n\n\ndef multi_select_dict(nodes):\n    return {\"type\": \"multi_select_dict\", \"children\": nodes}\n\n\ndef multi_select_list(nodes):\n    return {\"type\": \"multi_select_list\", \"children\": nodes}\n\n\ndef or_expression(left, right):\n    return {\"type\": \"or_expression\", \"children\": [left, right]}\n\n\ndef and_expression(left, right):\n    return {\"type\": \"and_expression\", \"children\": [left, right]}\n\n\ndef not_expression(expr):\n    return {\"type\": \"not_expression\", \"children\": [expr]}\n\n\ndef pipe(left, right):\n    return {'type': 'pipe', 'children': [left, right]}\n\n\ndef projection(left, right):\n    return {'type': 'projection', 'children': [left, right]}\n\n\ndef subexpression(children):\n    return {\"type\": \"subexpression\", 'children': children}\n\n\ndef slice(start, end, step):\n    return {\"type\": \"slice\", \"children\": [start, end, step]}\n\n\ndef value_projection(left, right):\n    return {'type': 'value_projection', 'children': [left, right]}\n", "jmespath/exceptions.py": "from jmespath.compat import with_str_method\n\n\nclass JMESPathError(ValueError):\n    pass\n\n\n@with_str_method\nclass ParseError(JMESPathError):\n    _ERROR_MESSAGE = 'Invalid jmespath expression'\n    def __init__(self, lex_position, token_value, token_type,\n                 msg=_ERROR_MESSAGE):\n        super(ParseError, self).__init__(lex_position, token_value, token_type)\n        self.lex_position = lex_position\n        self.token_value = token_value\n        self.token_type = token_type.upper()\n        self.msg = msg\n        # Whatever catches the ParseError can fill in the full expression\n        self.expression = None\n\n    def __str__(self):\n        # self.lex_position +1 to account for the starting double quote char.\n        underline = ' ' * (self.lex_position + 1) + '^'\n        return (\n            '%s: Parse error at column %s, '\n            'token \"%s\" (%s), for expression:\\n\"%s\"\\n%s' % (\n                self.msg, self.lex_position, self.token_value, self.token_type,\n                self.expression, underline))\n\n\n@with_str_method\nclass IncompleteExpressionError(ParseError):\n    def set_expression(self, expression):\n        self.expression = expression\n        self.lex_position = len(expression)\n        self.token_type = None\n        self.token_value = None\n\n    def __str__(self):\n        # self.lex_position +1 to account for the starting double quote char.\n        underline = ' ' * (self.lex_position + 1) + '^'\n        return (\n            'Invalid jmespath expression: Incomplete expression:\\n'\n            '\"%s\"\\n%s' % (self.expression, underline))\n\n\n@with_str_method\nclass LexerError(ParseError):\n    def __init__(self, lexer_position, lexer_value, message, expression=None):\n        self.lexer_position = lexer_position\n        self.lexer_value = lexer_value\n        self.message = message\n        super(LexerError, self).__init__(lexer_position,\n                                         lexer_value,\n                                         message)\n        # Whatever catches LexerError can set this.\n        self.expression = expression\n\n    def __str__(self):\n        underline = ' ' * self.lexer_position + '^'\n        return 'Bad jmespath expression: %s:\\n%s\\n%s' % (\n            self.message, self.expression, underline)\n\n\n@with_str_method\nclass ArityError(ParseError):\n    def __init__(self, expected, actual, name):\n        self.expected_arity = expected\n        self.actual_arity = actual\n        self.function_name = name\n        self.expression = None\n\n    def __str__(self):\n        return (\"Expected %s %s for function %s(), \"\n                \"received %s\" % (\n                    self.expected_arity,\n                    self._pluralize('argument', self.expected_arity),\n                    self.function_name,\n                    self.actual_arity))\n\n    def _pluralize(self, word, count):\n        if count == 1:\n            return word\n        else:\n            return word + 's'\n\n\n@with_str_method\nclass VariadictArityError(ArityError):\n    def __str__(self):\n        return (\"Expected at least %s %s for function %s(), \"\n                \"received %s\" % (\n                    self.expected_arity,\n                    self._pluralize('argument', self.expected_arity),\n                    self.function_name,\n                    self.actual_arity))\n\n\n@with_str_method\nclass JMESPathTypeError(JMESPathError):\n    def __init__(self, function_name, current_value, actual_type,\n                 expected_types):\n        self.function_name = function_name\n        self.current_value = current_value\n        self.actual_type = actual_type\n        self.expected_types = expected_types\n\n    def __str__(self):\n        return ('In function %s(), invalid type for value: %s, '\n                'expected one of: %s, received: \"%s\"' % (\n                    self.function_name, self.current_value,\n                    self.expected_types, self.actual_type))\n\n\nclass EmptyExpressionError(JMESPathError):\n    def __init__(self):\n        super(EmptyExpressionError, self).__init__(\n            \"Invalid JMESPath expression: cannot be empty.\")\n\n\nclass UnknownFunctionError(JMESPathError):\n    pass\n", "jmespath/functions.py": "import math\nimport json\n\nfrom jmespath import exceptions\nfrom jmespath.compat import string_type as STRING_TYPE\nfrom jmespath.compat import get_methods\n\n\n# python types -> jmespath types\nTYPES_MAP = {\n    'bool': 'boolean',\n    'list': 'array',\n    'dict': 'object',\n    'NoneType': 'null',\n    'unicode': 'string',\n    'str': 'string',\n    'float': 'number',\n    'int': 'number',\n    'long': 'number',\n    'OrderedDict': 'object',\n    '_Projection': 'array',\n    '_Expression': 'expref',\n}\n\n\n# jmespath types -> python types\nREVERSE_TYPES_MAP = {\n    'boolean': ('bool',),\n    'array': ('list', '_Projection'),\n    'object': ('dict', 'OrderedDict',),\n    'null': ('NoneType',),\n    'string': ('unicode', 'str'),\n    'number': ('float', 'int', 'long'),\n    'expref': ('_Expression',),\n}\n\n\ndef signature(*arguments):\n    def _record_signature(func):\n        func.signature = arguments\n        return func\n    return _record_signature\n\n\nclass FunctionRegistry(type):\n    def __init__(cls, name, bases, attrs):\n        cls._populate_function_table()\n        super(FunctionRegistry, cls).__init__(name, bases, attrs)\n\n    def _populate_function_table(cls):\n        function_table = {}\n        # Any method with a @signature decorator that also\n        # starts with \"_func_\" is registered as a function.\n        # _func_max_by -> max_by function.\n        for name, method in get_methods(cls):\n            if not name.startswith('_func_'):\n                continue\n            signature = getattr(method, 'signature', None)\n            if signature is not None:\n                function_table[name[6:]] = {\n                    'function': method,\n                    'signature': signature,\n                }\n        cls.FUNCTION_TABLE = function_table\n\n\nclass Functions(metaclass=FunctionRegistry):\n\n    FUNCTION_TABLE = {\n    }\n\n    def call_function(self, function_name, resolved_args):\n        try:\n            spec = self.FUNCTION_TABLE[function_name]\n        except KeyError:\n            raise exceptions.UnknownFunctionError(\n                \"Unknown function: %s()\" % function_name)\n        function = spec['function']\n        signature = spec['signature']\n        self._validate_arguments(resolved_args, signature, function_name)\n        return function(self, *resolved_args)\n\n    def _validate_arguments(self, args, signature, function_name):\n        if signature and signature[-1].get('variadic'):\n            if len(args) < len(signature):\n                raise exceptions.VariadictArityError(\n                    len(signature), len(args), function_name)\n        elif len(args) != len(signature):\n            raise exceptions.ArityError(\n                len(signature), len(args), function_name)\n        return self._type_check(args, signature, function_name)\n\n    def _type_check(self, actual, signature, function_name):\n        for i in range(len(signature)):\n            allowed_types = signature[i]['types']\n            if allowed_types:\n                self._type_check_single(actual[i], allowed_types,\n                                        function_name)\n\n    def _type_check_single(self, current, types, function_name):\n        # Type checking involves checking the top level type,\n        # and in the case of arrays, potentially checking the types\n        # of each element.\n        allowed_types, allowed_subtypes = self._get_allowed_pytypes(types)\n        # We're not using isinstance() on purpose.\n        # The type model for jmespath does not map\n        # 1-1 with python types (booleans are considered\n        # integers in python for example).\n        actual_typename = type(current).__name__\n        if actual_typename not in allowed_types:\n            raise exceptions.JMESPathTypeError(\n                function_name, current,\n                self._convert_to_jmespath_type(actual_typename), types)\n        # If we're dealing with a list type, we can have\n        # additional restrictions on the type of the list\n        # elements (for example a function can require a\n        # list of numbers or a list of strings).\n        # Arrays are the only types that can have subtypes.\n        if allowed_subtypes:\n            self._subtype_check(current, allowed_subtypes,\n                                types, function_name)\n\n    def _get_allowed_pytypes(self, types):\n        allowed_types = []\n        allowed_subtypes = []\n        for t in types:\n            type_ = t.split('-', 1)\n            if len(type_) == 2:\n                type_, subtype = type_\n                allowed_subtypes.append(REVERSE_TYPES_MAP[subtype])\n            else:\n                type_ = type_[0]\n            allowed_types.extend(REVERSE_TYPES_MAP[type_])\n        return allowed_types, allowed_subtypes\n\n    def _subtype_check(self, current, allowed_subtypes, types, function_name):\n        if len(allowed_subtypes) == 1:\n            # The easy case, we know up front what type\n            # we need to validate.\n            allowed_subtypes = allowed_subtypes[0]\n            for element in current:\n                actual_typename = type(element).__name__\n                if actual_typename not in allowed_subtypes:\n                    raise exceptions.JMESPathTypeError(\n                        function_name, element, actual_typename, types)\n        elif len(allowed_subtypes) > 1 and current:\n            # Dynamic type validation.  Based on the first\n            # type we see, we validate that the remaining types\n            # match.\n            first = type(current[0]).__name__\n            for subtypes in allowed_subtypes:\n                if first in subtypes:\n                    allowed = subtypes\n                    break\n            else:\n                raise exceptions.JMESPathTypeError(\n                    function_name, current[0], first, types)\n            for element in current:\n                actual_typename = type(element).__name__\n                if actual_typename not in allowed:\n                    raise exceptions.JMESPathTypeError(\n                        function_name, element, actual_typename, types)\n\n    @signature({'types': ['number']})\n    def _func_abs(self, arg):\n        return abs(arg)\n\n    @signature({'types': ['array-number']})\n    def _func_avg(self, arg):\n        if arg:\n            return sum(arg) / len(arg)\n        else:\n            return None\n\n    @signature({'types': [], 'variadic': True})\n    def _func_not_null(self, *arguments):\n        for argument in arguments:\n            if argument is not None:\n                return argument\n\n    @signature({'types': []})\n    def _func_to_array(self, arg):\n        if isinstance(arg, list):\n            return arg\n        else:\n            return [arg]\n\n    @signature({'types': []})\n    def _func_to_string(self, arg):\n        if isinstance(arg, STRING_TYPE):\n            return arg\n        else:\n            return json.dumps(arg, separators=(',', ':'),\n                              default=str)\n\n    @signature({'types': []})\n    def _func_to_number(self, arg):\n        if isinstance(arg, (list, dict, bool)):\n            return None\n        elif arg is None:\n            return None\n        elif isinstance(arg, (int, float)):\n            return arg\n        else:\n            try:\n                return int(arg)\n            except ValueError:\n                try:\n                    return float(arg)\n                except ValueError:\n                    return None\n\n    @signature({'types': ['array', 'string']}, {'types': []})\n    def _func_contains(self, subject, search):\n        return search in subject\n\n    @signature({'types': ['string', 'array', 'object']})\n    def _func_length(self, arg):\n        return len(arg)\n\n    @signature({'types': ['string']}, {'types': ['string']})\n    def _func_ends_with(self, search, suffix):\n        return search.endswith(suffix)\n\n    @signature({'types': ['string']}, {'types': ['string']})\n    def _func_starts_with(self, search, suffix):\n        return search.startswith(suffix)\n\n    @signature({'types': ['array', 'string']})\n    def _func_reverse(self, arg):\n        if isinstance(arg, STRING_TYPE):\n            return arg[::-1]\n        else:\n            return list(reversed(arg))\n\n    @signature({\"types\": ['number']})\n    def _func_ceil(self, arg):\n        return math.ceil(arg)\n\n    @signature({\"types\": ['number']})\n    def _func_floor(self, arg):\n        return math.floor(arg)\n\n    @signature({\"types\": ['string']}, {\"types\": ['array-string']})\n    def _func_join(self, separator, array):\n        return separator.join(array)\n\n    @signature({'types': ['expref']}, {'types': ['array']})\n    def _func_map(self, expref, arg):\n        result = []\n        for element in arg:\n            result.append(expref.visit(expref.expression, element))\n        return result\n\n    @signature({\"types\": ['array-number', 'array-string']})\n    def _func_max(self, arg):\n        if arg:\n            return max(arg)\n        else:\n            return None\n\n    @signature({\"types\": [\"object\"], \"variadic\": True})\n    def _func_merge(self, *arguments):\n        merged = {}\n        for arg in arguments:\n            merged.update(arg)\n        return merged\n\n    @signature({\"types\": ['array-number', 'array-string']})\n    def _func_min(self, arg):\n        if arg:\n            return min(arg)\n        else:\n            return None\n\n    @signature({\"types\": ['array-string', 'array-number']})\n    def _func_sort(self, arg):\n        return list(sorted(arg))\n\n    @signature({\"types\": ['array-number']})\n    def _func_sum(self, arg):\n        return sum(arg)\n\n    @signature({\"types\": ['object']})\n    def _func_keys(self, arg):\n        # To be consistent with .values()\n        # should we also return the indices of a list?\n        return list(arg.keys())\n\n    @signature({\"types\": ['object']})\n    def _func_values(self, arg):\n        return list(arg.values())\n\n    @signature({'types': []})\n    def _func_type(self, arg):\n        if isinstance(arg, STRING_TYPE):\n            return \"string\"\n        elif isinstance(arg, bool):\n            return \"boolean\"\n        elif isinstance(arg, list):\n            return \"array\"\n        elif isinstance(arg, dict):\n            return \"object\"\n        elif isinstance(arg, (float, int)):\n            return \"number\"\n        elif arg is None:\n            return \"null\"\n\n    @signature({'types': ['array']}, {'types': ['expref']})\n    def _func_sort_by(self, array, expref):\n        if not array:\n            return array\n        # sort_by allows for the expref to be either a number of\n        # a string, so we have some special logic to handle this.\n        # We evaluate the first array element and verify that it's\n        # either a string of a number.  We then create a key function\n        # that validates that type, which requires that remaining array\n        # elements resolve to the same type as the first element.\n        required_type = self._convert_to_jmespath_type(\n            type(expref.visit(expref.expression, array[0])).__name__)\n        if required_type not in ['number', 'string']:\n            raise exceptions.JMESPathTypeError(\n                'sort_by', array[0], required_type, ['string', 'number'])\n        keyfunc = self._create_key_func(expref,\n                                        [required_type],\n                                        'sort_by')\n        return list(sorted(array, key=keyfunc))\n\n    @signature({'types': ['array']}, {'types': ['expref']})\n    def _func_min_by(self, array, expref):\n        keyfunc = self._create_key_func(expref,\n                                        ['number', 'string'],\n                                        'min_by')\n        if array:\n            return min(array, key=keyfunc)\n        else:\n            return None\n\n    @signature({'types': ['array']}, {'types': ['expref']})\n    def _func_max_by(self, array, expref):\n        keyfunc = self._create_key_func(expref,\n                                        ['number', 'string'],\n                                        'max_by')\n        if array:\n            return max(array, key=keyfunc)\n        else:\n            return None\n\n    def _create_key_func(self, expref, allowed_types, function_name):\n        def keyfunc(x):\n            result = expref.visit(expref.expression, x)\n            actual_typename = type(result).__name__\n            jmespath_type = self._convert_to_jmespath_type(actual_typename)\n            # allowed_types is in term of jmespath types, not python types.\n            if jmespath_type not in allowed_types:\n                raise exceptions.JMESPathTypeError(\n                    function_name, result, jmespath_type, allowed_types)\n            return result\n        return keyfunc\n\n    def _convert_to_jmespath_type(self, pyobject):\n        return TYPES_MAP.get(pyobject, 'unknown')\n", "jmespath/__init__.py": "from jmespath import parser\nfrom jmespath.visitor import Options\n\n__version__ = '1.0.1'\n\n\ndef compile(expression):\n    return parser.Parser().parse(expression)\n\n\ndef search(expression, data, options=None):\n    return parser.Parser().parse(expression).search(data, options=options)\n", "jmespath/parser.py": "\"\"\"Top down operator precedence parser.\n\nThis is an implementation of Vaughan R. Pratt's\n\"Top Down Operator Precedence\" parser.\n(http://dl.acm.org/citation.cfm?doid=512927.512931).\n\nThese are some additional resources that help explain the\ngeneral idea behind a Pratt parser:\n\n* http://effbot.org/zone/simple-top-down-parsing.htm\n* http://javascript.crockford.com/tdop/tdop.html\n\nA few notes on the implementation.\n\n* All the nud/led tokens are on the Parser class itself, and are dispatched\n  using getattr().  This keeps all the parsing logic contained to a single\n  class.\n* We use two passes through the data.  One to create a list of token,\n  then one pass through the tokens to create the AST.  While the lexer actually\n  yields tokens, we convert it to a list so we can easily implement two tokens\n  of lookahead.  A previous implementation used a fixed circular buffer, but it\n  was significantly slower.  Also, the average jmespath expression typically\n  does not have a large amount of token so this is not an issue.  And\n  interestingly enough, creating a token list first is actually faster than\n  consuming from the token iterator one token at a time.\n\n\"\"\"\nimport random\n\nfrom jmespath import lexer\nfrom jmespath.compat import with_repr_method\nfrom jmespath import ast\nfrom jmespath import exceptions\nfrom jmespath import visitor\n\n\nclass Parser(object):\n    BINDING_POWER = {\n        'eof': 0,\n        'unquoted_identifier': 0,\n        'quoted_identifier': 0,\n        'literal': 0,\n        'rbracket': 0,\n        'rparen': 0,\n        'comma': 0,\n        'rbrace': 0,\n        'number': 0,\n        'current': 0,\n        'expref': 0,\n        'colon': 0,\n        'pipe': 1,\n        'or': 2,\n        'and': 3,\n        'eq': 5,\n        'gt': 5,\n        'lt': 5,\n        'gte': 5,\n        'lte': 5,\n        'ne': 5,\n        'flatten': 9,\n        # Everything above stops a projection.\n        'star': 20,\n        'filter': 21,\n        'dot': 40,\n        'not': 45,\n        'lbrace': 50,\n        'lbracket': 55,\n        'lparen': 60,\n    }\n    # The maximum binding power for a token that can stop\n    # a projection.\n    _PROJECTION_STOP = 10\n    # The _MAX_SIZE most recent expressions are cached in\n    # _CACHE dict.\n    _CACHE = {}\n    _MAX_SIZE = 128\n\n    def __init__(self, lookahead=2):\n        self.tokenizer = None\n        self._tokens = [None] * lookahead\n        self._buffer_size = lookahead\n        self._index = 0\n\n    def parse(self, expression):\n        cached = self._CACHE.get(expression)\n        if cached is not None:\n            return cached\n        parsed_result = self._do_parse(expression)\n        self._CACHE[expression] = parsed_result\n        if len(self._CACHE) > self._MAX_SIZE:\n            self._free_cache_entries()\n        return parsed_result\n\n    def _do_parse(self, expression):\n        try:\n            return self._parse(expression)\n        except exceptions.LexerError as e:\n            e.expression = expression\n            raise\n        except exceptions.IncompleteExpressionError as e:\n            e.set_expression(expression)\n            raise\n        except exceptions.ParseError as e:\n            e.expression = expression\n            raise\n\n    def _parse(self, expression):\n        self.tokenizer = lexer.Lexer().tokenize(expression)\n        self._tokens = list(self.tokenizer)\n        self._index = 0\n        parsed = self._expression(binding_power=0)\n        if not self._current_token() == 'eof':\n            t = self._lookahead_token(0)\n            raise exceptions.ParseError(t['start'], t['value'], t['type'],\n                                        \"Unexpected token: %s\" % t['value'])\n        return ParsedResult(expression, parsed)\n\n    def _expression(self, binding_power=0):\n        left_token = self._lookahead_token(0)\n        self._advance()\n        nud_function = getattr(\n            self, '_token_nud_%s' % left_token['type'],\n            self._error_nud_token)\n        left = nud_function(left_token)\n        current_token = self._current_token()\n        while binding_power < self.BINDING_POWER[current_token]:\n            led = getattr(self, '_token_led_%s' % current_token, None)\n            if led is None:\n                error_token = self._lookahead_token(0)\n                self._error_led_token(error_token)\n            else:\n                self._advance()\n                left = led(left)\n                current_token = self._current_token()\n        return left\n\n    def _token_nud_literal(self, token):\n        return ast.literal(token['value'])\n\n    def _token_nud_unquoted_identifier(self, token):\n        return ast.field(token['value'])\n\n    def _token_nud_quoted_identifier(self, token):\n        field = ast.field(token['value'])\n        # You can't have a quoted identifier as a function\n        # name.\n        if self._current_token() == 'lparen':\n            t = self._lookahead_token(0)\n            raise exceptions.ParseError(\n                0, t['value'], t['type'],\n                'Quoted identifier not allowed for function names.')\n        return field\n\n    def _token_nud_star(self, token):\n        left = ast.identity()\n        if self._current_token() == 'rbracket':\n            right = ast.identity()\n        else:\n            right = self._parse_projection_rhs(self.BINDING_POWER['star'])\n        return ast.value_projection(left, right)\n\n    def _token_nud_filter(self, token):\n        return self._token_led_filter(ast.identity())\n\n    def _token_nud_lbrace(self, token):\n        return self._parse_multi_select_hash()\n\n    def _token_nud_lparen(self, token):\n        expression = self._expression()\n        self._match('rparen')\n        return expression\n\n    def _token_nud_flatten(self, token):\n        left = ast.flatten(ast.identity())\n        right = self._parse_projection_rhs(\n            self.BINDING_POWER['flatten'])\n        return ast.projection(left, right)\n\n    def _token_nud_not(self, token):\n        expr = self._expression(self.BINDING_POWER['not'])\n        return ast.not_expression(expr)\n\n    def _token_nud_lbracket(self, token):\n        if self._current_token() in ['number', 'colon']:\n            right = self._parse_index_expression()\n            # We could optimize this and remove the identity() node.\n            # We don't really need an index_expression node, we can\n            # just use emit an index node here if we're not dealing\n            # with a slice.\n            return self._project_if_slice(ast.identity(), right)\n        elif self._current_token() == 'star' and \\\n                self._lookahead(1) == 'rbracket':\n            self._advance()\n            self._advance()\n            right = self._parse_projection_rhs(self.BINDING_POWER['star'])\n            return ast.projection(ast.identity(), right)\n        else:\n            return self._parse_multi_select_list()\n\n    def _parse_index_expression(self):\n        # We're here:\n        # [<current>\n        #  ^\n        #  | current token\n        if (self._lookahead(0) == 'colon' or\n                self._lookahead(1) == 'colon'):\n            return self._parse_slice_expression()\n        else:\n            # Parse the syntax [number]\n            node = ast.index(self._lookahead_token(0)['value'])\n            self._advance()\n            self._match('rbracket')\n            return node\n\n    def _parse_slice_expression(self):\n        # [start:end:step]\n        # Where start, end, and step are optional.\n        # The last colon is optional as well.\n        parts = [None, None, None]\n        index = 0\n        current_token = self._current_token()\n        while not current_token == 'rbracket' and index < 3:\n            if current_token == 'colon':\n                index += 1\n                if index == 3:\n                    self._raise_parse_error_for_token(\n                        self._lookahead_token(0), 'syntax error')\n                self._advance()\n            elif current_token == 'number':\n                parts[index] = self._lookahead_token(0)['value']\n                self._advance()\n            else:\n                self._raise_parse_error_for_token(\n                    self._lookahead_token(0), 'syntax error')\n            current_token = self._current_token()\n        self._match('rbracket')\n        return ast.slice(*parts)\n\n    def _token_nud_current(self, token):\n        return ast.current_node()\n\n    def _token_nud_expref(self, token):\n        expression = self._expression(self.BINDING_POWER['expref'])\n        return ast.expref(expression)\n\n    def _token_led_dot(self, left):\n        if not self._current_token() == 'star':\n            right = self._parse_dot_rhs(self.BINDING_POWER['dot'])\n            if left['type'] == 'subexpression':\n                left['children'].append(right)\n                return left\n            else:\n                return ast.subexpression([left, right])\n        else:\n            # We're creating a projection.\n            self._advance()\n            right = self._parse_projection_rhs(\n                self.BINDING_POWER['dot'])\n            return ast.value_projection(left, right)\n\n    def _token_led_pipe(self, left):\n        right = self._expression(self.BINDING_POWER['pipe'])\n        return ast.pipe(left, right)\n\n    def _token_led_or(self, left):\n        right = self._expression(self.BINDING_POWER['or'])\n        return ast.or_expression(left, right)\n\n    def _token_led_and(self, left):\n        right = self._expression(self.BINDING_POWER['and'])\n        return ast.and_expression(left, right)\n\n    def _token_led_lparen(self, left):\n        if left['type'] != 'field':\n            #  0 - first func arg or closing paren.\n            # -1 - '(' token\n            # -2 - invalid function \"name\".\n            prev_t = self._lookahead_token(-2)\n            raise exceptions.ParseError(\n                prev_t['start'], prev_t['value'], prev_t['type'],\n                \"Invalid function name '%s'\" % prev_t['value'])\n        name = left['value']\n        args = []\n        while not self._current_token() == 'rparen':\n            expression = self._expression()\n            if self._current_token() == 'comma':\n                self._match('comma')\n            args.append(expression)\n        self._match('rparen')\n        function_node = ast.function_expression(name, args)\n        return function_node\n\n    def _token_led_filter(self, left):\n        # Filters are projections.\n        condition = self._expression(0)\n        self._match('rbracket')\n        if self._current_token() == 'flatten':\n            right = ast.identity()\n        else:\n            right = self._parse_projection_rhs(self.BINDING_POWER['filter'])\n        return ast.filter_projection(left, right, condition)\n\n    def _token_led_eq(self, left):\n        return self._parse_comparator(left, 'eq')\n\n    def _token_led_ne(self, left):\n        return self._parse_comparator(left, 'ne')\n\n    def _token_led_gt(self, left):\n        return self._parse_comparator(left, 'gt')\n\n    def _token_led_gte(self, left):\n        return self._parse_comparator(left, 'gte')\n\n    def _token_led_lt(self, left):\n        return self._parse_comparator(left, 'lt')\n\n    def _token_led_lte(self, left):\n        return self._parse_comparator(left, 'lte')\n\n    def _token_led_flatten(self, left):\n        left = ast.flatten(left)\n        right = self._parse_projection_rhs(\n            self.BINDING_POWER['flatten'])\n        return ast.projection(left, right)\n\n    def _token_led_lbracket(self, left):\n        token = self._lookahead_token(0)\n        if token['type'] in ['number', 'colon']:\n            right = self._parse_index_expression()\n            if left['type'] == 'index_expression':\n                # Optimization: if the left node is an index expr,\n                # we can avoid creating another node and instead just add\n                # the right node as a child of the left.\n                left['children'].append(right)\n                return left\n            else:\n                return self._project_if_slice(left, right)\n        else:\n            # We have a projection\n            self._match('star')\n            self._match('rbracket')\n            right = self._parse_projection_rhs(self.BINDING_POWER['star'])\n            return ast.projection(left, right)\n\n    def _project_if_slice(self, left, right):\n        index_expr = ast.index_expression([left, right])\n        if right['type'] == 'slice':\n            return ast.projection(\n                index_expr,\n                self._parse_projection_rhs(self.BINDING_POWER['star']))\n        else:\n            return index_expr\n\n    def _parse_comparator(self, left, comparator):\n        right = self._expression(self.BINDING_POWER[comparator])\n        return ast.comparator(comparator, left, right)\n\n    def _parse_multi_select_list(self):\n        expressions = []\n        while True:\n            expression = self._expression()\n            expressions.append(expression)\n            if self._current_token() == 'rbracket':\n                break\n            else:\n                self._match('comma')\n        self._match('rbracket')\n        return ast.multi_select_list(expressions)\n\n    def _parse_multi_select_hash(self):\n        pairs = []\n        while True:\n            key_token = self._lookahead_token(0)\n            # Before getting the token value, verify it's\n            # an identifier.\n            self._match_multiple_tokens(\n                token_types=['quoted_identifier', 'unquoted_identifier'])\n            key_name = key_token['value']\n            self._match('colon')\n            value = self._expression(0)\n            node = ast.key_val_pair(key_name=key_name, node=value)\n            pairs.append(node)\n            if self._current_token() == 'comma':\n                self._match('comma')\n            elif self._current_token() == 'rbrace':\n                self._match('rbrace')\n                break\n        return ast.multi_select_dict(nodes=pairs)\n\n    def _parse_projection_rhs(self, binding_power):\n        # Parse the right hand side of the projection.\n        if self.BINDING_POWER[self._current_token()] < self._PROJECTION_STOP:\n            # BP of 10 are all the tokens that stop a projection.\n            right = ast.identity()\n        elif self._current_token() == 'lbracket':\n            right = self._expression(binding_power)\n        elif self._current_token() == 'filter':\n            right = self._expression(binding_power)\n        elif self._current_token() == 'dot':\n            self._match('dot')\n            right = self._parse_dot_rhs(binding_power)\n        else:\n            self._raise_parse_error_for_token(self._lookahead_token(0),\n                                              'syntax error')\n        return right\n\n    def _parse_dot_rhs(self, binding_power):\n        # From the grammar:\n        # expression '.' ( identifier /\n        #                  multi-select-list /\n        #                  multi-select-hash /\n        #                  function-expression /\n        #                  *\n        # In terms of tokens that means that after a '.',\n        # you can have:\n        lookahead = self._current_token()\n        # Common case \"foo.bar\", so first check for an identifier.\n        if lookahead in ['quoted_identifier', 'unquoted_identifier', 'star']:\n            return self._expression(binding_power)\n        elif lookahead == 'lbracket':\n            self._match('lbracket')\n            return self._parse_multi_select_list()\n        elif lookahead == 'lbrace':\n            self._match('lbrace')\n            return self._parse_multi_select_hash()\n        else:\n            t = self._lookahead_token(0)\n            allowed = ['quoted_identifier', 'unquoted_identifier',\n                       'lbracket', 'lbrace']\n            msg = (\n                \"Expecting: %s, got: %s\" % (allowed, t['type'])\n            )\n            self._raise_parse_error_for_token(t, msg)\n\n    def _error_nud_token(self, token):\n        if token['type'] == 'eof':\n            raise exceptions.IncompleteExpressionError(\n                token['start'], token['value'], token['type'])\n        self._raise_parse_error_for_token(token, 'invalid token')\n\n    def _error_led_token(self, token):\n        self._raise_parse_error_for_token(token, 'invalid token')\n\n    def _match(self, token_type=None):\n        # inline'd self._current_token()\n        if self._current_token() == token_type:\n            # inline'd self._advance()\n            self._advance()\n        else:\n            self._raise_parse_error_maybe_eof(\n                token_type, self._lookahead_token(0))\n\n    def _match_multiple_tokens(self, token_types):\n        if self._current_token() not in token_types:\n            self._raise_parse_error_maybe_eof(\n                token_types, self._lookahead_token(0))\n        self._advance()\n\n    def _advance(self):\n        self._index += 1\n\n    def _current_token(self):\n        return self._tokens[self._index]['type']\n\n    def _lookahead(self, number):\n        return self._tokens[self._index + number]['type']\n\n    def _lookahead_token(self, number):\n        return self._tokens[self._index + number]\n\n    def _raise_parse_error_for_token(self, token, reason):\n        lex_position = token['start']\n        actual_value = token['value']\n        actual_type = token['type']\n        raise exceptions.ParseError(lex_position, actual_value,\n                                    actual_type, reason)\n\n    def _raise_parse_error_maybe_eof(self, expected_type, token):\n        lex_position = token['start']\n        actual_value = token['value']\n        actual_type = token['type']\n        if actual_type == 'eof':\n            raise exceptions.IncompleteExpressionError(\n                lex_position, actual_value, actual_type)\n        message = 'Expecting: %s, got: %s' % (expected_type,\n                                              actual_type)\n        raise exceptions.ParseError(\n            lex_position, actual_value, actual_type, message)\n\n    def _free_cache_entries(self):\n        for key in random.sample(list(self._CACHE.keys()), int(self._MAX_SIZE / 2)):\n            self._CACHE.pop(key, None)\n\n    @classmethod\n    def purge(cls):\n        \"\"\"Clear the expression compilation cache.\"\"\"\n        cls._CACHE.clear()\n\n\n@with_repr_method\nclass ParsedResult(object):\n    def __init__(self, expression, parsed):\n        self.expression = expression\n        self.parsed = parsed\n\n    def search(self, value, options=None):\n        interpreter = visitor.TreeInterpreter(options)\n        result = interpreter.visit(self.parsed, value)\n        return result\n\n    def _render_dot_file(self):\n        \"\"\"Render the parsed AST as a dot file.\n\n        Note that this is marked as an internal method because\n        the AST is an implementation detail and is subject\n        to change.  This method can be used to help troubleshoot\n        or for development purposes, but is not considered part\n        of the public supported API.  Use at your own risk.\n\n        \"\"\"\n        renderer = visitor.GraphvizVisitor()\n        contents = renderer.visit(self.parsed)\n        return contents\n\n    def __repr__(self):\n        return repr(self.parsed)\n", "jmespath/visitor.py": "import operator\n\nfrom jmespath import functions\nfrom jmespath.compat import string_type\nfrom numbers import Number\n\n\ndef _equals(x, y):\n    if _is_special_number_case(x, y):\n        return False\n    else:\n        return x == y\n\n\ndef _is_special_number_case(x, y):\n    # We need to special case comparing 0 or 1 to\n    # True/False.  While normally comparing any\n    # integer other than 0/1 to True/False will always\n    # return False.  However 0/1 have this:\n    # >>> 0 == True\n    # False\n    # >>> 0 == False\n    # True\n    # >>> 1 == True\n    # True\n    # >>> 1 == False\n    # False\n    #\n    # Also need to consider that:\n    # >>> 0 in [True, False]\n    # True\n    if _is_actual_number(x) and x in (0, 1):\n        return isinstance(y, bool)\n    elif _is_actual_number(y) and y in (0, 1):\n        return isinstance(x, bool)\n\n\ndef _is_comparable(x):\n    # The spec doesn't officially support string types yet,\n    # but enough people are relying on this behavior that\n    # it's been added back.  This should eventually become\n    # part of the official spec.\n    return _is_actual_number(x) or isinstance(x, string_type)\n\n\ndef _is_actual_number(x):\n    # We need to handle python's quirkiness with booleans,\n    # specifically:\n    #\n    # >>> isinstance(False, int)\n    # True\n    # >>> isinstance(True, int)\n    # True\n    if isinstance(x, bool):\n        return False\n    return isinstance(x, Number)\n\n\nclass Options(object):\n    \"\"\"Options to control how a JMESPath function is evaluated.\"\"\"\n    def __init__(self, dict_cls=None, custom_functions=None):\n        #: The class to use when creating a dict.  The interpreter\n        #  may create dictionaries during the evaluation of a JMESPath\n        #  expression.  For example, a multi-select hash will\n        #  create a dictionary.  By default we use a dict() type.\n        #  You can set this value to change what dict type is used.\n        #  The most common reason you would change this is if you\n        #  want to set a collections.OrderedDict so that you can\n        #  have predictable key ordering.\n        self.dict_cls = dict_cls\n        self.custom_functions = custom_functions\n\n\nclass _Expression(object):\n    def __init__(self, expression, interpreter):\n        self.expression = expression\n        self.interpreter = interpreter\n\n    def visit(self, node, *args, **kwargs):\n        return self.interpreter.visit(node, *args, **kwargs)\n\n\nclass Visitor(object):\n    def __init__(self):\n        self._method_cache = {}\n\n    def visit(self, node, *args, **kwargs):\n        node_type = node['type']\n        method = self._method_cache.get(node_type)\n        if method is None:\n            method = getattr(\n                self, 'visit_%s' % node['type'], self.default_visit)\n            self._method_cache[node_type] = method\n        return method(node, *args, **kwargs)\n\n    def default_visit(self, node, *args, **kwargs):\n        raise NotImplementedError(\"default_visit\")\n\n\nclass TreeInterpreter(Visitor):\n    COMPARATOR_FUNC = {\n        'eq': _equals,\n        'ne': lambda x, y: not _equals(x, y),\n        'lt': operator.lt,\n        'gt': operator.gt,\n        'lte': operator.le,\n        'gte': operator.ge\n    }\n    _EQUALITY_OPS = ['eq', 'ne']\n    MAP_TYPE = dict\n\n    def __init__(self, options=None):\n        super(TreeInterpreter, self).__init__()\n        self._dict_cls = self.MAP_TYPE\n        if options is None:\n            options = Options()\n        self._options = options\n        if options.dict_cls is not None:\n            self._dict_cls = self._options.dict_cls\n        if options.custom_functions is not None:\n            self._functions = self._options.custom_functions\n        else:\n            self._functions = functions.Functions()\n\n    def default_visit(self, node, *args, **kwargs):\n        raise NotImplementedError(node['type'])\n\n    def visit_subexpression(self, node, value):\n        result = value\n        for node in node['children']:\n            result = self.visit(node, result)\n        return result\n\n    def visit_field(self, node, value):\n        try:\n            return value.get(node['value'])\n        except AttributeError:\n            return None\n\n    def visit_comparator(self, node, value):\n        # Common case: comparator is == or !=\n        comparator_func = self.COMPARATOR_FUNC[node['value']]\n        if node['value'] in self._EQUALITY_OPS:\n            return comparator_func(\n                self.visit(node['children'][0], value),\n                self.visit(node['children'][1], value)\n            )\n        else:\n            # Ordering operators are only valid for numbers.\n            # Evaluating any other type with a comparison operator\n            # will yield a None value.\n            left = self.visit(node['children'][0], value)\n            right = self.visit(node['children'][1], value)\n            num_types = (int, float)\n            if not (_is_comparable(left) and\n                    _is_comparable(right)):\n                return None\n            return comparator_func(left, right)\n\n    def visit_current(self, node, value):\n        return value\n\n    def visit_expref(self, node, value):\n        return _Expression(node['children'][0], self)\n\n    def visit_function_expression(self, node, value):\n        resolved_args = []\n        for child in node['children']:\n            current = self.visit(child, value)\n            resolved_args.append(current)\n        return self._functions.call_function(node['value'], resolved_args)\n\n    def visit_filter_projection(self, node, value):\n        base = self.visit(node['children'][0], value)\n        if not isinstance(base, list):\n            return None\n        comparator_node = node['children'][2]\n        collected = []\n        for element in base:\n            if self._is_true(self.visit(comparator_node, element)):\n                current = self.visit(node['children'][1], element)\n                if current is not None:\n                    collected.append(current)\n        return collected\n\n    def visit_flatten(self, node, value):\n        base = self.visit(node['children'][0], value)\n        if not isinstance(base, list):\n            # Can't flatten the object if it's not a list.\n            return None\n        merged_list = []\n        for element in base:\n            if isinstance(element, list):\n                merged_list.extend(element)\n            else:\n                merged_list.append(element)\n        return merged_list\n\n    def visit_identity(self, node, value):\n        return value\n\n    def visit_index(self, node, value):\n        # Even though we can index strings, we don't\n        # want to support that.\n        if not isinstance(value, list):\n            return None\n        try:\n            return value[node['value']]\n        except IndexError:\n            return None\n\n    def visit_index_expression(self, node, value):\n        result = value\n        for node in node['children']:\n            result = self.visit(node, result)\n        return result\n\n    def visit_slice(self, node, value):\n        if not isinstance(value, list):\n            return None\n        s = slice(*node['children'])\n        return value[s]\n\n    def visit_key_val_pair(self, node, value):\n        return self.visit(node['children'][0], value)\n\n    def visit_literal(self, node, value):\n        return node['value']\n\n    def visit_multi_select_dict(self, node, value):\n        if value is None:\n            return None\n        collected = self._dict_cls()\n        for child in node['children']:\n            collected[child['value']] = self.visit(child, value)\n        return collected\n\n    def visit_multi_select_list(self, node, value):\n        if value is None:\n            return None\n        collected = []\n        for child in node['children']:\n            collected.append(self.visit(child, value))\n        return collected\n\n    def visit_or_expression(self, node, value):\n        matched = self.visit(node['children'][0], value)\n        if self._is_false(matched):\n            matched = self.visit(node['children'][1], value)\n        return matched\n\n    def visit_and_expression(self, node, value):\n        matched = self.visit(node['children'][0], value)\n        if self._is_false(matched):\n            return matched\n        return self.visit(node['children'][1], value)\n\n    def visit_not_expression(self, node, value):\n        original_result = self.visit(node['children'][0], value)\n        if _is_actual_number(original_result) and original_result == 0:\n            # Special case for 0, !0 should be false, not true.\n            # 0 is not a special cased integer in jmespath.\n            return False\n        return not original_result\n\n    def visit_pipe(self, node, value):\n        result = value\n        for node in node['children']:\n            result = self.visit(node, result)\n        return result\n\n    def visit_projection(self, node, value):\n        base = self.visit(node['children'][0], value)\n        if not isinstance(base, list):\n            return None\n        collected = []\n        for element in base:\n            current = self.visit(node['children'][1], element)\n            if current is not None:\n                collected.append(current)\n        return collected\n\n    def visit_value_projection(self, node, value):\n        base = self.visit(node['children'][0], value)\n        try:\n            base = base.values()\n        except AttributeError:\n            return None\n        collected = []\n        for element in base:\n            current = self.visit(node['children'][1], element)\n            if current is not None:\n                collected.append(current)\n        return collected\n\n    def _is_false(self, value):\n        # This looks weird, but we're explicitly using equality checks\n        # because the truth/false values are different between\n        # python and jmespath.\n        return (value == '' or value == [] or value == {} or value is None or\n                value is False)\n\n    def _is_true(self, value):\n        return not self._is_false(value)\n\n\nclass GraphvizVisitor(Visitor):\n    def __init__(self):\n        super(GraphvizVisitor, self).__init__()\n        self._lines = []\n        self._count = 1\n\n    def visit(self, node, *args, **kwargs):\n        self._lines.append('digraph AST {')\n        current = '%s%s' % (node['type'], self._count)\n        self._count += 1\n        self._visit(node, current)\n        self._lines.append('}')\n        return '\\n'.join(self._lines)\n\n    def _visit(self, node, current):\n        self._lines.append('%s [label=\"%s(%s)\"]' % (\n            current, node['type'], node.get('value', '')))\n        for child in node.get('children', []):\n            child_name = '%s%s' % (child['type'], self._count)\n            self._count += 1\n            self._lines.append('  %s -> %s' % (current, child_name))\n            self._visit(child, child_name)\n", "jmespath/compat.py": "import sys\nimport inspect\nfrom itertools import zip_longest\n\n\ntext_type = str\nstring_type = str\n\n\ndef with_str_method(cls):\n    # In python3, we don't need to do anything, we return a str type.\n    return cls\n\ndef with_repr_method(cls):\n    return cls\n\ndef get_methods(cls):\n    for name, method in inspect.getmembers(cls, predicate=inspect.isfunction):\n        yield name, method\n", "bin/jp.py": "#!/usr/bin/env python\n\nimport sys\nimport json\nimport argparse\nfrom pprint import pformat\n\nimport jmespath\nfrom jmespath import exceptions\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('expression')\n    parser.add_argument('-f', '--filename',\n                        help=('The filename containing the input data.  '\n                              'If a filename is not given then data is '\n                              'read from stdin.'))\n    parser.add_argument('--ast', action='store_true',\n                        help=('Pretty print the AST, do not search the data.'))\n    args = parser.parse_args()\n    expression = args.expression\n    if args.ast:\n        # Only print the AST\n        expression = jmespath.compile(args.expression)\n        sys.stdout.write(pformat(expression.parsed))\n        sys.stdout.write('\\n')\n        return 0\n    if args.filename:\n        with open(args.filename, 'r') as f:\n            data = json.load(f)\n    else:\n        data = sys.stdin.read()\n        data = json.loads(data)\n    try:\n        sys.stdout.write(json.dumps(\n            jmespath.search(expression, data), indent=4, ensure_ascii=False))\n        sys.stdout.write('\\n')\n    except exceptions.ArityError as e:\n        sys.stderr.write(\"invalid-arity: %s\\n\" % e)\n        return 1\n    except exceptions.JMESPathTypeError as e:\n        sys.stderr.write(\"invalid-type: %s\\n\" % e)\n        return 1\n    except exceptions.UnknownFunctionError as e:\n        sys.stderr.write(\"unknown-function: %s\\n\" % e)\n        return 1\n    except exceptions.ParseError as e:\n        sys.stderr.write(\"syntax-error: %s\\n\" % e)\n        return 1\n\n\nif __name__ == '__main__':\n    sys.exit(main())\n"}