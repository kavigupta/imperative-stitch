{"tasks/release.py": "\"\"\"Handles creating a release PR.\"\"\"\n\nfrom __future__ import annotations\n\nfrom pathlib import Path\nfrom subprocess import check_call\n\nfrom git import Commit, Head, Remote, Repo, TagReference\nfrom packaging.version import Version\n\nROOT_SRC_DIR = Path(__file__).resolve().parents[1]\n\n\ndef main(version_str: str) -> None:\n    version = Version(version_str)\n    repo = Repo(str(ROOT_SRC_DIR))\n\n    if repo.is_dirty():\n        msg = \"Current repository is dirty. Please commit any changes and try again.\"\n        raise RuntimeError(msg)\n    upstream, release_branch = create_release_branch(repo, version)\n    release_commit = release_changelog(repo, version)\n    tag = tag_release_commit(release_commit, repo, version)\n    print(\"push release commit\")  # noqa: T201\n    repo.git.push(upstream.name, release_branch)\n    print(\"push release tag\")  # noqa: T201\n    repo.git.push(upstream.name, tag)\n    print(\"All done! \u2728 \ud83c\udf70 \u2728\")  # noqa: T201\n\n\ndef create_release_branch(repo: Repo, version: Version) -> tuple[Remote, Head]:\n    print(\"create release branch from upstream main\")  # noqa: T201\n    upstream = get_upstream(repo)\n    upstream.fetch()\n    branch_name = f\"release-{version}\"\n    release_branch = repo.create_head(branch_name, upstream.refs.main, force=True)\n    upstream.push(refspec=f\"{branch_name}:{branch_name}\", force=True)\n    release_branch.set_tracking_branch(repo.refs[f\"{upstream.name}/{branch_name}\"])\n    release_branch.checkout()\n    return upstream, release_branch\n\n\ndef get_upstream(repo: Repo) -> Remote:\n    upstream_remote = \"pypa/virtualenv.git\"\n    urls = set()\n    for remote in repo.remotes:\n        for url in remote.urls:\n            if url.endswith(upstream_remote):\n                return remote\n            urls.add(url)\n    msg = f\"could not find {upstream_remote} remote, has {urls}\"\n    raise RuntimeError(msg)\n\n\ndef release_changelog(repo: Repo, version: Version) -> Commit:\n    print(\"generate release commit\")  # noqa: T201\n    check_call([\"towncrier\", \"build\", \"--yes\", \"--version\", version.public], cwd=str(ROOT_SRC_DIR))  # noqa: S603, S607\n    return repo.index.commit(f\"release {version}\")\n\n\ndef tag_release_commit(release_commit, repo, version) -> TagReference:\n    print(\"tag release commit\")  # noqa: T201\n    existing_tags = [x.name for x in repo.tags]\n    if version in existing_tags:\n        print(f\"delete existing tag {version}\")  # noqa: T201\n        repo.delete_tag(version)\n    print(f\"create tag {version}\")  # noqa: T201\n    return repo.create_tag(version, ref=release_commit, force=True)\n\n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser(prog=\"release\")\n    parser.add_argument(\"--version\", required=True)\n    options = parser.parse_args()\n    main(options.version)\n", "tasks/update_embedded.py": "\"\"\"Helper script to rebuild virtualenv.py from virtualenv_support.\"\"\"  # noqa: EXE002\n\nfrom __future__ import annotations\n\nimport codecs\nimport locale\nimport os\nimport re\nfrom zlib import crc32 as _crc32\n\n\ndef crc32(data):\n    \"\"\"Python version idempotent.\"\"\"\n    return _crc32(data.encode()) & 0xFFFFFFFF\n\n\nhere = os.path.realpath(os.path.dirname(__file__))\nscript = os.path.realpath(os.path.join(here, \"..\", \"src\", \"virtualenv.py\"))\n\ngzip = codecs.lookup(\"zlib\")\nb64 = codecs.lookup(\"base64\")\n\nfile_regex = re.compile(r'# file (.*?)\\n([a-zA-Z][a-zA-Z0-9_]+) = convert\\(\\n {4}\"\"\"\\n(.*?)\"\"\"\\n\\)', re.DOTALL)\nfile_template = '# file {filename}\\n{variable} = convert(\\n    \"\"\"\\n{data}\"\"\"\\n)'\n\n\ndef rebuild(script_path):\n    with script_path.open(encoding=locale.getpreferredencoding(False)) as current_fh:  # noqa: FBT003\n        script_content = current_fh.read()\n    script_parts = []\n    match_end = 0\n    next_match = None\n    _count, did_update = 0, False\n    for _count, next_match in enumerate(file_regex.finditer(script_content)):\n        script_parts += [script_content[match_end : next_match.start()]]\n        match_end = next_match.end()\n        filename, variable_name, previous_encoded = next_match.group(1), next_match.group(2), next_match.group(3)\n        differ, content = handle_file(next_match.group(0), filename, variable_name, previous_encoded)\n        script_parts.append(content)\n        if differ:\n            did_update = True\n\n    script_parts += [script_content[match_end:]]\n    new_content = \"\".join(script_parts)\n\n    report(1 if not _count or did_update else 0, new_content, next_match, script_content, script_path)\n\n\ndef handle_file(previous_content, filename, variable_name, previous_encoded):\n    print(f\"Found file {filename}\")  # noqa: T201\n    current_path = os.path.realpath(os.path.join(here, \"..\", \"src\", \"virtualenv_embedded\", filename))\n    _, file_type = os.path.splitext(current_path)\n    keep_line_ending = file_type == \".bat\"\n    with open(current_path, encoding=\"utf-8\", newline=\"\" if keep_line_ending else None) as current_fh:\n        current_text = current_fh.read()\n    current_crc = crc32(current_text)\n    current_encoded = b64.encode(gzip.encode(current_text.encode())[0])[0].decode()\n    if current_encoded == previous_encoded:\n        print(f\"  File up to date (crc: {current_crc:08x})\")  # noqa: T201\n        return False, previous_content\n    # Else: content has changed\n    previous_text = gzip.decode(b64.decode(previous_encoded.encode())[0])[0].decode()\n    previous_crc = crc32(previous_text)\n    print(f\"  Content changed (crc: {previous_crc:08x} -> {current_crc:08x})\")  # noqa: T201\n    new_part = file_template.format(filename=filename, variable=variable_name, data=current_encoded)\n    return True, new_part\n\n\ndef report(exit_code, new, next_match, current, script_path):\n    if new != current:\n        print(\"Content updated; overwriting... \", end=\"\")  # noqa: T201\n        script_path.write_bytes(new)\n        print(\"done.\")  # noqa: T201\n    else:\n        print(\"No changes in content\")  # noqa: T201\n    if next_match is None:\n        print(\"No variables were matched/found\")  # noqa: T201\n    raise SystemExit(exit_code)\n\n\nif __name__ == \"__main__\":\n    rebuild(script)\n", "tasks/make_zipapp.py": "\"\"\"https://docs.python.org/3/library/zipapp.html.\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nimport io\nimport json\nimport os\nimport shutil\nimport subprocess\nimport sys\nimport zipapp\nimport zipfile\nfrom collections import defaultdict, deque\nfrom email import message_from_string\nfrom pathlib import Path, PurePosixPath\nfrom shlex import quote\nfrom stat import S_IWUSR\nfrom tempfile import TemporaryDirectory\n\nfrom packaging.markers import Marker\nfrom packaging.requirements import Requirement\n\nHERE = Path(__file__).parent.absolute()\n\nVERSIONS = [f\"3.{i}\" for i in range(10, 6, -1)]\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--dest\", default=\"virtualenv.pyz\")\n    args = parser.parse_args()\n    with TemporaryDirectory() as folder:\n        packages = get_wheels_for_support_versions(Path(folder))\n        create_zipapp(os.path.abspath(args.dest), packages)\n\n\ndef create_zipapp(dest, packages):\n    bio = io.BytesIO()\n    base = PurePosixPath(\"__virtualenv__\")\n    modules = defaultdict(lambda: defaultdict(dict))\n    dist = defaultdict(lambda: defaultdict(dict))\n    with zipfile.ZipFile(bio, \"w\") as zip_app:\n        write_packages_to_zipapp(base, dist, modules, packages, zip_app)\n        modules_json = json.dumps(modules, indent=2)\n        zip_app.writestr(\"modules.json\", modules_json)\n        distributions_json = json.dumps(dist, indent=2)\n        zip_app.writestr(\"distributions.json\", distributions_json)\n        zip_app.writestr(\"__main__.py\", (HERE / \"__main__zipapp.py\").read_bytes())\n    bio.seek(0)\n    zipapp.create_archive(bio, dest)\n    print(f\"zipapp created at {dest}\")  # noqa: T201\n\n\ndef write_packages_to_zipapp(base, dist, modules, packages, zip_app):  # noqa: C901, PLR0912\n    has = set()\n    for name, p_w_v in packages.items():  # noqa: PLR1702\n        for platform, w_v in p_w_v.items():\n            for wheel_data in w_v.values():\n                wheel = wheel_data.wheel\n                with zipfile.ZipFile(str(wheel)) as wheel_zip:\n                    for filename in wheel_zip.namelist():\n                        if name == \"virtualenv\":\n                            dest = PurePosixPath(filename)\n                        else:\n                            dest = base / wheel.stem / filename\n                            if dest.suffix in {\".so\", \".pyi\"}:\n                                continue\n                            if dest.suffix == \".py\":\n                                key = filename[:-3].replace(\"/\", \".\").replace(\"__init__\", \"\").rstrip(\".\")\n                                for version in wheel_data.versions:\n                                    modules[version][platform][key] = str(dest)\n                            if dest.parent.suffix == \".dist-info\":\n                                for version in wheel_data.versions:\n                                    dist[version][platform][dest.parent.stem.split(\"-\")[0]] = str(dest.parent)\n                        dest_str = str(dest)\n                        if dest_str in has:\n                            continue\n                        has.add(dest_str)\n                        if \"/tests/\" in dest_str or \"/docs/\" in dest_str:\n                            continue\n                        print(dest_str)  # noqa: T201\n                        content = wheel_zip.read(filename)\n                        zip_app.writestr(dest_str, content)\n                        del content\n\n\nclass WheelDownloader:\n    def __init__(self, into) -> None:\n        if into.exists():\n            shutil.rmtree(into)\n        into.mkdir(parents=True)\n        self.into = into\n        self.collected = defaultdict(lambda: defaultdict(dict))\n        self.pip_cmd = [str(Path(sys.executable).parent / \"pip\")]\n        self._cmd = [*self.pip_cmd, \"download\", \"-q\", \"--no-deps\", \"--dest\", str(self.into)]\n\n    def run(self, target, versions):\n        whl = self.build_sdist(target)\n        todo = deque((version, None, whl) for version in versions)\n        wheel_store = {}\n        while todo:\n            version, platform, dep = todo.popleft()\n            dep_str = dep.name.split(\"-\")[0] if isinstance(dep, Path) else dep.name\n            if dep_str in self.collected[version] and platform in self.collected[version][dep_str]:\n                continue\n            whl = self._get_wheel(dep, platform[2:] if platform and platform.startswith(\"==\") else None, version)\n            if whl is None:\n                if dep_str not in wheel_store:\n                    msg = f\"failed to get {dep_str}, have {wheel_store}\"\n                    raise RuntimeError(msg)\n                whl = wheel_store[dep_str]\n            else:\n                wheel_store[dep_str] = whl\n            self.collected[version][dep_str][platform] = whl\n            todo.extend(self.get_dependencies(whl, version))\n\n    def _get_wheel(self, dep, platform, version):\n        if isinstance(dep, Requirement):\n            before = set(self.into.iterdir())\n            if self._download(\n                platform,\n                False,  # noqa: FBT003\n                \"--python-version\",\n                version,\n                \"--only-binary\",\n                \":all:\",\n                str(dep),\n            ):\n                self._download(platform, True, \"--python-version\", version, str(dep))  # noqa: FBT003\n            after = set(self.into.iterdir())\n            new_files = after - before\n            assert len(new_files) <= 1  # noqa: S101\n            if not len(new_files):\n                return None\n            new_file = next(iter(new_files))\n            if new_file.suffix == \".whl\":\n                return new_file\n            dep = new_file\n        new_file = self.build_sdist(dep)\n        assert new_file.suffix == \".whl\"  # noqa: S101\n        return new_file\n\n    def _download(self, platform, stop_print_on_fail, *args):\n        exe_cmd = self._cmd + list(args)\n        if platform is not None:\n            exe_cmd.extend([\"--platform\", platform])\n        return run_suppress_output(exe_cmd, stop_print_on_fail=stop_print_on_fail)\n\n    @staticmethod\n    def get_dependencies(whl, version):\n        with zipfile.ZipFile(str(whl), \"r\") as zip_file:\n            name = \"/\".join([f\"{'-'.join(whl.name.split('-')[0:2])}.dist-info\", \"METADATA\"])\n            with zip_file.open(name) as file_handler:\n                metadata = message_from_string(file_handler.read().decode(\"utf-8\"))\n        deps = metadata.get_all(\"Requires-Dist\")\n        if deps is None:\n            return\n        for dep in deps:\n            req = Requirement(dep)\n            markers = getattr(req.marker, \"_markers\", ()) or ()\n            if any(\n                m\n                for m in markers\n                if isinstance(m, tuple) and len(m) == 3 and m[0].value == \"extra\"  # noqa: PLR2004\n            ):\n                continue\n            py_versions = WheelDownloader._marker_at(markers, \"python_version\")\n            if py_versions:\n                marker = Marker('python_version < \"1\"')\n                marker._markers = [  # noqa: SLF001\n                    markers[ver] for ver in sorted(i for i in set(py_versions) | {i - 1 for i in py_versions} if i >= 0)\n                ]\n                matches_python = marker.evaluate({\"python_version\": version})\n                if not matches_python:\n                    continue\n                deleted = 0\n                for ver in py_versions:\n                    deleted += WheelDownloader._del_marker_at(markers, ver - deleted)\n            platforms = []\n            platform_positions = WheelDownloader._marker_at(markers, \"sys_platform\")\n            deleted = 0\n            for pos in platform_positions:  # can only be or meaningfully\n                platform = f\"{markers[pos][1].value}{markers[pos][2].value}\"\n                deleted += WheelDownloader._del_marker_at(markers, pos - deleted)\n                platforms.append(platform)\n            if not platforms:\n                platforms.append(None)\n            for platform in platforms:\n                yield version, platform, req\n\n    @staticmethod\n    def _marker_at(markers, key):\n        return [\n            i\n            for i, m in enumerate(markers)\n            if isinstance(m, tuple) and len(m) == 3 and m[0].value == key  # noqa: PLR2004\n        ]\n\n    @staticmethod\n    def _del_marker_at(markers, at):\n        del markers[at]\n        deleted = 1\n        op = max(at - 1, 0)\n        if markers and isinstance(markers[op], str):\n            del markers[op]\n            deleted += 1\n        return deleted\n\n    def build_sdist(self, target):\n        if target.is_dir():\n            # pip 20.1 no longer guarantees this to be parallel safe, need to copy/lock\n            with TemporaryDirectory() as temp_folder:\n                folder = Path(temp_folder) / target.name\n                shutil.copytree(\n                    str(target),\n                    str(folder),\n                    ignore=shutil.ignore_patterns(\".tox\", \".tox4\", \"venv\", \"__pycache__\", \"*.pyz\"),\n                )\n                try:\n                    return self._build_sdist(self.into, folder)\n                finally:\n                    # permission error on Windows <3.7 https://bugs.python.org/issue26660\n                    def onerror(func, path, exc_info):  # noqa: ARG001\n                        os.chmod(path, S_IWUSR)\n                        func(path)\n\n                    shutil.rmtree(str(folder), onerror=onerror)\n\n        else:\n            return self._build_sdist(target.parent / target.stem, target)\n\n    def _build_sdist(self, folder, target):\n        if not folder.exists() or not list(folder.iterdir()):\n            cmd = [*self.pip_cmd, \"wheel\", \"-w\", str(folder), \"--no-deps\", str(target), \"-q\"]\n            run_suppress_output(cmd, stop_print_on_fail=True)\n        return next(iter(folder.iterdir()))\n\n\ndef run_suppress_output(cmd, stop_print_on_fail=False):  # noqa: FBT002\n    process = subprocess.Popen(\n        cmd,  # noqa: S603\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        universal_newlines=True,\n        encoding=\"utf-8\",\n    )\n    out, err = process.communicate()\n    if stop_print_on_fail and process.returncode != 0:\n        print(f\"exit with {process.returncode} of {' '.join(quote(i) for i in cmd)}\", file=sys.stdout)  # noqa: T201\n        if out:\n            print(out, file=sys.stdout)  # noqa: T201\n        if err:\n            print(err, file=sys.stderr)  # noqa: T201\n        raise SystemExit(process.returncode)\n    return process.returncode\n\n\ndef get_wheels_for_support_versions(folder):\n    downloader = WheelDownloader(folder / \"wheel-store\")\n    downloader.run(HERE.parent, VERSIONS)\n    packages = defaultdict(lambda: defaultdict(lambda: defaultdict(WheelForVersion)))\n    for version, collected in downloader.collected.items():\n        for pkg, platform_to_wheel in collected.items():\n            name = Requirement(pkg).name\n            for platform, wheel in platform_to_wheel.items():\n                pl = platform or \"==any\"\n                wheel_versions = packages[name][pl][wheel.name]\n                wheel_versions.versions.append(version)\n                wheel_versions.wheel = wheel\n    for name, p_w_v in packages.items():\n        for platform, w_v in p_w_v.items():\n            print(f\"{name} - {platform}\")  # noqa: T201\n            for wheel, wheel_versions in w_v.items():\n                print(f\"{' '.join(wheel_versions.versions)} of {wheel} (use {wheel_versions.wheel})\")  # noqa: T201\n    return packages\n\n\nclass WheelForVersion:\n    def __init__(self, wheel=None, versions=None) -> None:\n        self.wheel = wheel\n        self.versions = versions or []\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}({self.wheel!r}, {self.versions!r})\"\n\n\nif __name__ == \"__main__\":\n    main()\n", "tasks/upgrade_wheels.py": "\"\"\"Helper script to rebuild virtualenv_support. Downloads the wheel files using pip.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport shutil\nimport subprocess\nimport sys\nfrom collections import OrderedDict, defaultdict\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom textwrap import dedent\nfrom threading import Thread\n\nSTRICT = \"UPGRADE_ADVISORY\" not in os.environ\n\nBUNDLED = [\"pip\", \"setuptools\", \"wheel\"]\nSUPPORT = [(3, i) for i in range(7, 15)]\nDEST = Path(__file__).resolve().parents[1] / \"src\" / \"virtualenv\" / \"seed\" / \"wheels\" / \"embed\"\n\n\ndef download(ver, dest, package):\n    subprocess.call(\n        [  # noqa: S603\n            sys.executable,\n            \"-m\",\n            \"pip\",\n            \"--disable-pip-version-check\",\n            \"download\",\n            \"--only-binary=:all:\",\n            \"--python-version\",\n            ver,\n            \"-d\",\n            dest,\n            package,\n        ],\n    )\n\n\ndef run():  # noqa: C901\n    old_batch = {i.name for i in DEST.iterdir() if i.suffix == \".whl\"}\n    with TemporaryDirectory() as temp:\n        temp_path = Path(temp)\n        folders = {}\n        targets = []\n        for support in SUPPORT:\n            support_ver = \".\".join(str(i) for i in support)\n            into = temp_path / support_ver\n            into.mkdir()\n            folders[into] = support_ver\n            for package in BUNDLED:\n                thread = Thread(target=download, args=(support_ver, str(into), package))\n                targets.append(thread)\n                thread.start()\n        for thread in targets:\n            thread.join()\n        new_batch = {i.name: i for f in folders for i in Path(f).iterdir()}\n\n        new_packages = new_batch.keys() - old_batch\n        remove_packages = old_batch - new_batch.keys()\n\n        for package in remove_packages:\n            (DEST / package).unlink()\n        for package in new_packages:\n            shutil.copy2(str(new_batch[package]), DEST / package)\n\n        added = collect_package_versions(new_packages)\n        removed = collect_package_versions(remove_packages)\n\n        outcome = (1 if STRICT else 0) if (added or removed) else 0\n        lines = [\"Upgrade embedded wheels:\", \"\"]\n        for key, versions in added.items():\n            text = f\"* {key} to {fmt_version(versions)}\"\n            if key in removed:\n                rem = \", \".join(f\"``{i}``\" for i in removed[key])\n                text += f\" from {rem}\"\n                del removed[key]\n            lines.append(text)\n        for key, versions in removed.items():\n            lines.append(f\"Removed {key} of {fmt_version(versions)}\")\n        lines.append(\"\")\n        changelog = \"\\n\".join(lines)\n        print(changelog)  # noqa: T201\n        if len(lines) >= 4:  # noqa: PLR2004\n            (Path(__file__).parents[1] / \"docs\" / \"changelog\" / \"u.bugfix.rst\").write_text(changelog, encoding=\"utf-8\")\n        support_table = OrderedDict((\".\".join(str(j) for j in i), []) for i in SUPPORT)\n        for package in sorted(new_batch.keys()):\n            for folder, version in sorted(folders.items()):\n                if (folder / package).exists():\n                    support_table[version].append(package)\n        support_table = {k: OrderedDict((i.split(\"-\")[0], i) for i in v) for k, v in support_table.items()}\n        bundle = \",\".join(\n            f\"{v!r}: {{ {','.join(f'{p!r}: {f!r}' for p, f in line.items())} }}\" for v, line in support_table.items()\n        )\n        msg = dedent(\n            f\"\"\"\n        from pathlib import Path\n\n        from virtualenv.seed.wheels.util import Wheel\n\n        BUNDLE_FOLDER = Path(__file__).absolute().parent\n        BUNDLE_SUPPORT = {{ {bundle} }}\n        MAX = {next(iter(support_table.keys()))!r}\n\n\n        def get_embed_wheel(distribution, for_py_version):\n            path = BUNDLE_FOLDER / (BUNDLE_SUPPORT.get(for_py_version, {{}}) or BUNDLE_SUPPORT[MAX]).get(distribution)\n            return Wheel.from_path(path)\n\n\n        __all__ = [\n            \"get_embed_wheel\",\n            \"BUNDLE_SUPPORT\",\n            \"MAX\",\n            \"BUNDLE_FOLDER\",\n        ]\n\n        \"\"\",\n        )\n        dest_target = DEST / \"__init__.py\"\n        dest_target.write_text(msg, encoding=\"utf-8\")\n\n        subprocess.run(\n            [sys.executable, \"-m\", \"ruff\", \"check\", str(dest_target), \"--fix\", \"--unsafe-fixes\"],  # noqa: S603\n            check=False,\n        )\n        subprocess.run(\n            [sys.executable, \"-m\", \"ruff\", \"format\", str(dest_target), \"--preview\"],  # noqa: S603\n            check=False,\n        )\n\n        raise SystemExit(outcome)\n\n\ndef fmt_version(versions):\n    return \", \".join(f\"``{v}``\" for v in versions)\n\n\ndef collect_package_versions(new_packages):\n    result = defaultdict(list)\n    for package in new_packages:\n        split = package.split(\"-\")\n        if len(split) < 2:  # noqa: PLR2004\n            raise ValueError(package)\n        key, version = split[0:2]\n        result[key].append(version)\n    return result\n\n\nif __name__ == \"__main__\":\n    run()\n", "tasks/__main__zipapp.py": "from __future__ import annotations\n\nimport json\nimport os\nimport sys\nimport zipfile\n\nABS_HERE = os.path.abspath(os.path.dirname(__file__))\nNEW_IMPORT_SYSTEM = sys.version_info[0] >= 3  # noqa: PLR2004\n\n\nclass VersionPlatformSelect:\n    def __init__(self) -> None:\n        self.archive = ABS_HERE\n        self._zip_file = zipfile.ZipFile(ABS_HERE, \"r\")\n        self.modules = self._load(\"modules.json\")\n        self.distributions = self._load(\"distributions.json\")\n        self.__cache = {}\n\n    def _load(self, of_file):\n        version = \".\".join(str(i) for i in sys.version_info[0:2])\n        per_version = json.loads(self.get_data(of_file).decode(\"utf-8\"))\n        all_platforms = per_version[version] if version in per_version else per_version[\"3.9\"]\n        content = all_platforms.get(\"==any\", {})  # start will all platforms\n        not_us = f\"!={sys.platform}\"\n        for key, value in all_platforms.items():  # now override that with not platform\n            if key.startswith(\"!=\") and key != not_us:\n                content.update(value)\n        content.update(all_platforms.get(f\"=={sys.platform}\", {}))  # and finish it off with our platform\n        return content\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self._zip_file.close()\n\n    def find_mod(self, fullname):\n        if fullname in self.modules:\n            return self.modules[fullname]\n        return None\n\n    def get_filename(self, fullname):\n        zip_path = self.find_mod(fullname)\n        return None if zip_path is None else os.path.join(ABS_HERE, zip_path)\n\n    def get_data(self, filename):\n        if filename.startswith(ABS_HERE):\n            # keep paths relative from the zipfile\n            filename = filename[len(ABS_HERE) + 1 :]\n            filename = filename.lstrip(os.sep)\n        if sys.platform == \"win32\":\n            # paths within the zipfile is always /, fixup on Windows to transform \\ to /\n            filename = \"/\".join(filename.split(os.sep))\n        with self._zip_file.open(filename) as file_handler:\n            return file_handler.read()\n\n    def find_distributions(self, context):\n        dist_class = versioned_distribution_class()\n        name = context.name\n        if name in self.distributions:\n            result = dist_class(file_loader=self.get_data, dist_path=self.distributions[name])\n            yield result\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}(path={ABS_HERE})\"\n\n    def _register_distutils_finder(self):\n        if \"distlib\" not in self.modules:\n            return\n\n        class DistlibFinder:\n            def __init__(self, path, loader) -> None:\n                self.path = path\n                self.loader = loader\n\n            def find(self, name):\n                class Resource:\n                    def __init__(self, content) -> None:\n                        self.bytes = content\n\n                full_path = os.path.join(self.path, name)\n                return Resource(self.loader.get_data(full_path))\n\n        from distlib.resources import register_finder  # noqa: PLC0415\n\n        register_finder(self, lambda module: DistlibFinder(os.path.dirname(module.__file__), self))\n\n\n_VER_DISTRIBUTION_CLASS = None\n\n\ndef versioned_distribution_class():\n    global _VER_DISTRIBUTION_CLASS  # noqa: PLW0603\n    if _VER_DISTRIBUTION_CLASS is None:\n        if sys.version_info >= (3, 8):\n            from importlib.metadata import Distribution  # noqa: PLC0415\n        else:\n            from importlib_metadata import Distribution  # noqa: PLC0415\n\n        class VersionedDistribution(Distribution):\n            def __init__(self, file_loader, dist_path) -> None:\n                self.file_loader = file_loader\n                self.dist_path = dist_path\n\n            def read_text(self, filename):\n                return self.file_loader(self.locate_file(filename)).decode(\"utf-8\")\n\n            def locate_file(self, path):\n                return os.path.join(self.dist_path, path)\n\n        _VER_DISTRIBUTION_CLASS = VersionedDistribution\n    return _VER_DISTRIBUTION_CLASS\n\n\nif NEW_IMPORT_SYSTEM:\n    from importlib.abc import SourceLoader\n    from importlib.util import spec_from_file_location\n\n    class VersionedFindLoad(VersionPlatformSelect, SourceLoader):\n        def find_spec(self, fullname, path, target=None):  # noqa: ARG002\n            zip_path = self.find_mod(fullname)\n            if zip_path is not None:\n                return spec_from_file_location(name=fullname, loader=self)\n            return None\n\n        def module_repr(self, module):\n            raise NotImplementedError\n\nelse:\n    from imp import new_module\n\n    class VersionedFindLoad(VersionPlatformSelect):\n        def find_module(self, fullname, path=None):  # noqa: ARG002\n            return self if self.find_mod(fullname) else None\n\n        def load_module(self, fullname):\n            filename = self.get_filename(fullname)\n            code = self.get_data(filename)\n            mod = sys.modules.setdefault(fullname, new_module(fullname))\n            mod.__file__ = filename\n            mod.__loader__ = self\n            is_package = filename.endswith(\"__init__.py\")\n            if is_package:\n                mod.__path__ = [os.path.dirname(filename)]\n                mod.__package__ = fullname\n            else:\n                mod.__package__ = fullname.rpartition(\".\")[0]\n            exec(code, mod.__dict__)  # noqa: S102\n            return mod\n\n\ndef run():\n    with VersionedFindLoad() as finder:\n        sys.meta_path.insert(0, finder)\n        finder._register_distutils_finder()  # noqa: SLF001\n        from virtualenv.__main__ import run as run_virtualenv  # noqa: PLC0415, PLC2701\n\n        run_virtualenv()\n\n\nif __name__ == \"__main__\":\n    run()\n", "docs/render_cli.py": "from __future__ import annotations\n\nfrom argparse import SUPPRESS\nfrom contextlib import contextmanager\nfrom typing import Any, ClassVar, NamedTuple\n\nfrom docutils import nodes as n\nfrom docutils.parsers.rst.directives import unchanged_required\nfrom sphinx.util.docutils import SphinxDirective\nfrom sphinxarg.parser import parse_parser\n\nfrom virtualenv.run.plugin.base import ComponentBuilder\n\n\nclass TableRow(NamedTuple):\n    names: list[str]\n    default: str\n    choices: set[str]\n    help: str\n\n\nclass TextAsDefault(NamedTuple):\n    text: str\n\n\nCUSTOM = {\n    \"discovery\": ComponentBuilder.entry_points_for(\"virtualenv.discovery\"),\n    \"creator\": ComponentBuilder.entry_points_for(\"virtualenv.create\"),\n    \"seeder\": ComponentBuilder.entry_points_for(\"virtualenv.seed\"),\n    \"activators\": ComponentBuilder.entry_points_for(\"virtualenv.activate\"),\n}\n\n\nclass CliTable(SphinxDirective):\n    name: ClassVar[str] = \"table_cli\"\n    option_spec: ClassVar[str, Any] = {\"module\": unchanged_required, \"func\": unchanged_required}\n\n    def run(self):\n        module_name, attr_name = self.options[\"module\"], self.options[\"func\"]\n        parser_creator = getattr(__import__(module_name, fromlist=[attr_name]), attr_name)\n        core_result = parse_parser(parser_creator())\n        core_result[\"action_groups\"] = [i for i in core_result[\"action_groups\"] if i[\"title\"] not in CUSTOM]\n\n        content = [self._build_table(i[\"options\"], i[\"title\"], i[\"description\"]) for i in core_result[\"action_groups\"]]\n        for key, name_to_class in CUSTOM.items():\n            section = n.section(\"\", ids=[f\"section-{key}\"])\n            title = n.title(\"\", key)\n            section += title\n            self.state.document.note_implicit_target(title)\n            content.append(section)\n            results = {}\n\n            for name, class_n in name_to_class.items():\n                with self._run_parser(class_n, key, name):\n                    cmd = [f\"--{key}\", name]\n                    parser_result = parse_parser(parser_creator(cmd))\n                    opt_group = next(i[\"options\"] for i in parser_result[\"action_groups\"] if i[\"title\"] == key)\n                    results[name] = opt_group\n            core_names = set.intersection(*[{tuple(i[\"name\"]) for i in v} for v in results.values()])\n            if core_names:\n                rows = [i for i in next(iter(results.values())) if tuple(i[\"name\"]) in core_names]\n                content.append(\n                    self._build_table(rows, title=\"core\", description=f\"options shared across all {key}\"),\n                )\n            for name, group in results.items():\n                rows = [i for i in group if tuple(i[\"name\"]) not in core_names]\n                if rows:\n                    content.append(\n                        self._build_table(rows, title=name, description=f\"options specific to {key} {name}\"),\n                    )\n        return content\n\n    @contextmanager\n    def _run_parser(self, class_n, key, name):\n        test_name = {\"creator\": \"can_create\", \"activators\": \"supports\"}\n        func_name = test_name.get(key)\n        try:\n            if func_name is not None:\n                prev = getattr(class_n, func_name)\n\n                def a(*args, **kwargs):\n                    prev(*args, **kwargs)\n                    if key == \"activators\":\n                        return True\n                    if key == \"creator\":\n                        if name == \"venv\":\n                            from virtualenv.create.via_global_ref.venv import ViaGlobalRefMeta  # noqa: PLC0415\n\n                            meta = ViaGlobalRefMeta()\n                            meta.symlink_error = None\n                            return meta\n                        from virtualenv.create.via_global_ref.builtin.via_global_self_do import (  # noqa: PLC0415\n                            BuiltinViaGlobalRefMeta,\n                        )\n\n                        meta = BuiltinViaGlobalRefMeta()\n                        meta.symlink_error = None\n                        return meta\n                    raise RuntimeError\n\n                setattr(class_n, func_name, a)\n            yield\n        finally:\n            if func_name is not None:\n                # noinspection PyUnboundLocalVariable\n                setattr(class_n, func_name, prev)\n\n    def _build_table(self, options, title, description):\n        table = n.table()\n        table[\"classes\"] += [\"colwidths-auto\"]\n\n        options_group = n.tgroup(cols=3)\n        table += options_group\n        for _ in range(3):\n            options_group += n.colspec()\n        body = self._make_table_body(self.build_rows(options), title, description)\n        options_group += body\n        return table\n\n    plugins: ClassVar[dict[str, str]] = {\n        \"creator\": \"virtualenv.create\",\n        \"seed\": \"virtualenv.seed\",\n        \"activators\": \"virtualenv.activate\",\n        \"discovery\": \"virtualenv.discovery\",\n    }\n\n    @staticmethod\n    def build_rows(options):\n        result = []\n        for option in options:\n            names = option[\"name\"]\n            default = option[\"default\"]\n            if (\n                default is not None\n                and isinstance(default, str)\n                and default\n                and default[0] == default[-1]\n                and default[0] == '\"'\n            ):\n                default = default[1:-1]\n                if default == SUPPRESS:\n                    default = None\n            choices = option.get(\"choices\")\n            key = names[0].strip(\"-\")\n            if key in CliTable.plugins:\n                choices = list(ComponentBuilder.entry_points_for(CliTable.plugins[key]).keys())\n            help_text = option[\"help\"]\n            row = TableRow(names, default, choices, help_text)\n            result.append(row)\n        return result\n\n    def _make_table_body(self, rows, title, description):\n        t_body = n.tbody()\n        header_row = n.paragraph()\n        header_row += n.strong(text=title)\n        if description:\n            header_row += n.Text(\" \u21d2 \")\n            header_row += n.Text(description)\n        t_body += n.row(\"\", n.entry(\"\", header_row, morecols=2))\n        for row in rows:\n            name_list = self._get_targeted_names(row)\n            default = CliTable._get_default(row)\n            help_text = CliTable._get_help_text(row)\n            row_node = n.row(\"\", n.entry(\"\", name_list), n.entry(\"\", default), n.entry(\"\", help_text))\n            t_body += row_node\n        return t_body\n\n    def _get_targeted_names(self, row):\n        names = [name.lstrip(\"-\") for name in row.names]\n        target = n.target(\"\", \"\", ids=names, names=names)\n        self.register_target_option(target)\n        first = True\n        for name, orig in zip(names, row.names):\n            if first:\n                first = False\n            else:\n                target += n.Text(\", \")\n            self_ref = n.reference(refid=name)\n            self_ref += n.literal(text=orig)\n            target += self_ref\n        para = n.paragraph(text=\"\")\n        para += target\n        return para\n\n    @staticmethod\n    def _get_help_text(row):\n        name = row.names[0]\n        content = row.help[: row.help.index(\"(\") - 1] if name == \"--creator\" else row.help\n        help_body = n.paragraph(\"\", \"\", n.Text(content))\n        if row.choices is not None:\n            help_body += n.Text(\"; choice of: \")\n            first = True\n            for choice in row.choices:\n                if first:\n                    first = False\n                else:\n                    help_body += n.Text(\", \")\n                help_body += n.literal(text=choice)\n        return help_body\n\n    @staticmethod\n    def _get_default(row):\n        default = row.default\n        name = row.names[0]\n        if name == \"-p\":\n            default_body = n.Text(\"the python executable virtualenv is installed into\")\n        elif name == \"--app-data\":\n            default_body = n.Text(\"platform specific application data folder\")\n        elif name == \"--activators\":\n            default_body = n.Text(\"comma separated list of activators supported\")\n        elif name == \"--creator\":\n            default_body = n.paragraph(\"\")\n            default_body += n.literal(text=\"builtin\")\n            default_body += n.Text(\" if exist, else \")\n            default_body += n.literal(text=\"venv\")\n        elif default is None:\n            default_body = n.paragraph(\"\", text=\"\")\n        else:\n            default_body = n.literal(text=default if isinstance(default, str) else str(default))\n        return default_body\n\n    def register_target_option(self, target) -> None:\n        domain = self.env.get_domain(\"std\")\n        self.state.document.note_explicit_target(target)\n        for key in target[\"ids\"]:\n            domain.add_program_option(None, key, self.env.docname, key)\n\n\ndef literal_data(rawtext, app, of_type, slug, options):  # noqa: ARG001\n    \"\"\"Create a link to a BitBucket resource.\"\"\"\n    of_class = of_type.split(\".\")\n    data = getattr(__import__(\".\".join(of_class[:-1]), fromlist=[of_class[-1]]), of_class[-1])\n    return [n.literal(\"\", text=\",\".join(data))], []\n\n\n__all__ = (\n    \"CliTable\",\n    \"literal_data\",\n)\n", "docs/conf.py": "from __future__ import annotations\n\nimport subprocess\nimport sys\nfrom datetime import datetime, timezone\nfrom pathlib import Path\n\nfrom virtualenv.version import __version__\n\ncompany = \"PyPA\"\nname = \"virtualenv\"\nversion = \".\".join(__version__.split(\".\")[:2])\nrelease = __version__\ncopyright = f\"2007-{datetime.now(tz=timezone.utc).year}, {company}, PyPA\"  # noqa: A001\n\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.autosectionlabel\",\n    \"sphinx.ext.extlinks\",\n]\n\ntemplates_path = []\nunused_docs = []\nsource_suffix = \".rst\"\nexclude_patterns = [\"_build\", \"changelog/*\", \"_draft.rst\"]\n\nmain_doc = \"index\"\npygments_style = \"default\"\nalways_document_param_types = True\nproject = name\ntoday_fmt = \"%B %d, %Y\"\n\nhtml_theme = \"furo\"\nhtml_title, html_last_updated_fmt = project, datetime.now(tz=timezone.utc).isoformat()\npygments_style, pygments_dark_style = \"sphinx\", \"monokai\"\nhtml_static_path, html_css_files = [\"_static\"], [\"custom.css\"]\n\nautoclass_content = \"both\"  # Include __init__ in class documentation\nautodoc_member_order = \"bysource\"\nautosectionlabel_prefix_document = True\n\nextlinks = {\n    \"issue\": (\"https://github.com/pypa/virtualenv/issues/%s\", \"#%s\"),\n    \"pull\": (\"https://github.com/pypa/virtualenv/pull/%s\", \"PR #%s\"),\n    \"user\": (\"https://github.com/%s\", \"@%s\"),\n    \"pypi\": (\"https://pypi.org/project/%s\", \"%s\"),\n}\n\n\ndef setup(app):\n    here = Path(__file__).parent\n    root, exe = here.parent, Path(sys.executable)\n    towncrier = exe.with_name(f\"towncrier{exe.suffix}\")\n    cmd = [str(towncrier), \"build\", \"--draft\", \"--version\", \"NEXT\"]\n    new = subprocess.check_output(cmd, cwd=root, text=True, stderr=subprocess.DEVNULL, encoding=\"UTF-8\")  # noqa: S603\n    (root / \"docs\" / \"_draft.rst\").write_text(\"\" if \"No significant changes\" in new else new, encoding=\"UTF-8\")\n\n    # the CLI arguments are dynamically generated\n    doc_tree = Path(app.doctreedir)\n    cli_interface_doctree = doc_tree / \"cli_interface.doctree\"\n    if cli_interface_doctree.exists():\n        cli_interface_doctree.unlink()\n\n    here = Path(__file__).parent\n    if str(here) not in sys.path:\n        sys.path.append(str(here))\n\n    # noinspection PyUnresolvedReferences\n    from render_cli import CliTable, literal_data  # noqa: PLC0415\n\n    app.add_css_file(\"custom.css\")\n    app.add_directive(CliTable.name, CliTable)\n    app.add_role(\"literal_data\", literal_data)\n", "tests/conftest.py": "from __future__ import annotations\n\nimport logging\nimport os\nimport shutil\nimport sys\nfrom contextlib import contextmanager\nfrom functools import partial\nfrom pathlib import Path\nfrom typing import ClassVar\n\nimport pytest\n\nfrom virtualenv.app_data import AppDataDiskFolder\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.info import IS_PYPY, IS_WIN, fs_supports_symlink\nfrom virtualenv.report import LOGGER\n\n\ndef pytest_addoption(parser):\n    parser.addoption(\"--int\", action=\"store_true\", default=False, help=\"run integration tests\")\n\n\ndef pytest_configure(config):\n    \"\"\"Ensure randomly is called before we re-order\"\"\"\n    manager = config.pluginmanager\n\n    order = manager.hook.pytest_collection_modifyitems.get_hookimpls()\n    dest = next((i for i, p in enumerate(order) if p.plugin is manager.getplugin(\"randomly\")), None)\n    if dest is not None:\n        from_pos = next(i for i, p in enumerate(order) if p.plugin is manager.getplugin(__file__))\n        temp = order[dest]\n        order[dest] = order[from_pos]\n        order[from_pos] = temp\n\n\ndef pytest_collection_modifyitems(config, items):\n    int_location = os.path.join(\"tests\", \"integration\", \"\").rstrip()\n    if len(items) == 1:\n        return\n\n    items.sort(key=lambda i: 2 if i.location[0].startswith(int_location) else (1 if \"slow\" in i.keywords else 0))\n\n    if not config.getoption(\"--int\"):\n        for item in items:\n            if item.location[0].startswith(int_location):\n                item.add_marker(pytest.mark.skip(reason=\"need --int option to run\"))\n\n\n@pytest.fixture(scope=\"session\")\ndef has_symlink_support(tmp_path_factory):  # noqa: ARG001\n    return fs_supports_symlink()\n\n\n@pytest.fixture(scope=\"session\")\ndef link_folder(has_symlink_support):\n    if has_symlink_support:\n        return os.symlink\n    if sys.platform == \"win32\":\n        # on Windows junctions may be used instead\n        import _winapi  # noqa: PLC0415\n\n        return getattr(_winapi, \"CreateJunction\", None)\n    return None\n\n\n@pytest.fixture(scope=\"session\")\ndef link_file(has_symlink_support):\n    if has_symlink_support:\n        return os.symlink\n    return None\n\n\n@pytest.fixture(scope=\"session\")\ndef link(link_folder, link_file):\n    def _link(src, dest):\n        clean = dest.unlink\n        s_dest = str(dest)\n        s_src = str(src)\n        if src.is_dir():\n            if link_folder:\n                link_folder(s_src, s_dest)\n            else:\n                shutil.copytree(s_src, s_dest)\n                clean = partial(shutil.rmtree, str(dest))\n        elif link_file:\n            link_file(s_src, s_dest)\n        else:\n            shutil.copy2(s_src, s_dest)\n        return clean\n\n    return _link\n\n\n@pytest.fixture(autouse=True)\ndef _ensure_logging_stable():\n    logger_level = LOGGER.level\n    handlers = list(LOGGER.handlers)\n    filelock_logger = logging.getLogger(\"filelock\")\n    fl_level = filelock_logger.level\n    yield\n    filelock_logger.setLevel(fl_level)\n    for handler in LOGGER.handlers:\n        LOGGER.removeHandler(handler)\n    for handler in handlers:\n        LOGGER.addHandler(handler)\n    LOGGER.setLevel(logger_level)\n\n\n@pytest.fixture(autouse=True)\ndef _check_cwd_not_changed_by_test():\n    old = os.getcwd()\n    yield\n    new = os.getcwd()\n    if old != new:\n        pytest.fail(f\"tests changed cwd: {old!r} => {new!r}\")\n\n\n@pytest.fixture(autouse=True)\ndef _ensure_py_info_cache_empty(session_app_data):\n    PythonInfo.clear_cache(session_app_data)\n    yield\n    PythonInfo.clear_cache(session_app_data)\n\n\n@contextmanager\ndef change_os_environ(key, value):\n    env_var = key\n    previous = os.environ.get(env_var, None)\n    os.environ[env_var] = value\n    try:\n        yield\n    finally:\n        if previous is not None:\n            os.environ[env_var] = previous\n\n\n@pytest.fixture(autouse=True, scope=\"session\")\ndef _ignore_global_config(tmp_path_factory):\n    filename = str(tmp_path_factory.mktemp(\"folder\") / \"virtualenv-test-suite.ini\")\n    with change_os_environ(\"VIRTUALENV_CONFIG_FILE\", filename):\n        yield\n\n\n@pytest.fixture(autouse=True)\ndef _check_os_environ_stable():\n    old = os.environ.copy()\n    # ensure we don't inherit parent env variables\n    to_clean = {k for k in os.environ if k.startswith((\"VIRTUALENV_\", \"TOX_\")) or \"VIRTUAL_ENV\" in k}\n    cleaned = {k: os.environ[k] for k, v in os.environ.items()}\n    override = {\n        \"VIRTUALENV_NO_PERIODIC_UPDATE\": \"1\",\n        \"VIRTUALENV_NO_DOWNLOAD\": \"1\",\n    }\n    for key, value in override.items():\n        os.environ[str(key)] = str(value)\n    is_exception = False\n    try:\n        yield\n    except BaseException:\n        is_exception = True\n        raise\n    finally:\n        try:\n            for key in override:\n                del os.environ[str(key)]\n            if is_exception is False:\n                new = os.environ\n                extra = {k: new[k] for k in set(new) - set(old)}\n                miss = {k: old[k] for k in set(old) - set(new) - to_clean}\n                diff = {\n                    f\"{k} = {old[k]} vs {new[k]}\"\n                    for k in set(old) & set(new)\n                    if old[k] != new[k] and not k.startswith(\"PYTEST_\")\n                }\n                if extra or miss or diff:\n                    msg = \"tests changed environ\"\n                    if extra:\n                        msg += f\" extra {extra}\"\n                    if miss:\n                        msg += f\" miss {miss}\"\n                    if diff:\n                        msg += f\" diff {diff}\"\n                    pytest.fail(msg)\n        finally:\n            os.environ.update(cleaned)\n\n\nCOV_ENV_VAR = \"COVERAGE_PROCESS_START\"\nCOVERAGE_RUN = os.environ.get(str(COV_ENV_VAR))\n\n\n@pytest.fixture(autouse=True)\ndef coverage_env(monkeypatch, link, request):\n    \"\"\"\n    Enable coverage report collection on the created virtual environments by injecting the coverage project\n    \"\"\"\n    if COVERAGE_RUN and \"_no_coverage\" not in request.fixturenames:\n        # we inject right after creation, we cannot collect coverage on site.py - used for helper scripts, such as debug\n        from virtualenv import run  # noqa: PLC0415\n\n        def _session_via_cli(args, options, setup_logging, env=None):\n            session = prev_run(args, options, setup_logging, env)\n            old_run = session.creator.run\n\n            def create_run():\n                result = old_run()\n                obj[\"cov\"] = EnableCoverage(link)\n                obj[\"cov\"].__enter__(session.creator)  # noqa: PLC2801\n                return result\n\n            monkeypatch.setattr(session.creator, \"run\", create_run)\n            return session\n\n        obj = {\"cov\": None}\n        prev_run = run.session_via_cli\n        monkeypatch.setattr(run, \"session_via_cli\", _session_via_cli)\n\n        def finish():\n            cov = obj[\"cov\"]\n            obj[\"cov\"] = None\n            cov.__exit__(None, None, None)\n\n        yield finish\n        if obj[\"cov\"]:\n            finish()\n\n    else:\n\n        def finish():\n            pass\n\n        yield finish\n\n\n# _no_coverage tells coverage_env to disable coverage injection for _no_coverage user.\n@pytest.fixture()\ndef _no_coverage():\n    pass\n\n\nif COVERAGE_RUN:\n    import coverage\n\n    class EnableCoverage:\n        _COV_FILE: ClassVar[Path] = Path(coverage.__file__)\n        _ROOT_COV_FILES_AND_FOLDERS: ClassVar[list[Path]] = [\n            i for i in _COV_FILE.parents[1].iterdir() if i.name.startswith(\"coverage\")\n        ]\n\n        def __init__(self, link) -> None:\n            self.link = link\n            self.targets = []\n\n        def __enter__(self, creator):  # noqa: PLE0302\n            site_packages = creator.purelib\n            for entry in self._ROOT_COV_FILES_AND_FOLDERS:\n                target = site_packages / entry.name\n                if not target.exists():\n                    clean = self.link(entry, target)\n                    self.targets.append((target, clean))\n            return self\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            for target, clean in self.targets:\n                if target.exists():\n                    clean()\n            assert self._COV_FILE.exists()\n\n\n@pytest.fixture(scope=\"session\")\ndef is_inside_ci():\n    return bool(os.environ.get(\"CI_RUN\"))\n\n\n@pytest.fixture(scope=\"session\")\ndef special_char_name():\n    base = \"e-$ \u00e8\u0440\u0442\ud83d\ude92\u265e\u4e2d\u7247-j\"\n    # workaround for pypy3 https://bitbucket.org/pypy/pypy/issues/3147/venv-non-ascii-support-windows\n    encoding = \"ascii\" if IS_WIN else sys.getfilesystemencoding()\n    # let's not include characters that the file system cannot encode)\n    result = \"\"\n    for char in base:\n        try:\n            trip = char.encode(encoding, errors=\"strict\").decode(encoding)\n            if char == trip:\n                result += char\n        except ValueError:  # noqa: PERF203\n            continue\n    assert result\n    return result\n\n\n@pytest.fixture()\ndef special_name_dir(tmp_path, special_char_name):\n    return Path(str(tmp_path)) / special_char_name\n\n\n@pytest.fixture(scope=\"session\")\ndef current_creators(session_app_data):\n    return PythonInfo.current_system(session_app_data).creators()\n\n\n@pytest.fixture(scope=\"session\")\ndef current_fastest(current_creators):\n    return \"builtin\" if \"builtin\" in current_creators.key_to_class else next(iter(current_creators.key_to_class))\n\n\n@pytest.fixture(scope=\"session\")\ndef session_app_data(tmp_path_factory):\n    temp_folder = tmp_path_factory.mktemp(\"session-app-data\")\n    app_data = AppDataDiskFolder(folder=str(temp_folder))\n    with change_env_var(\"VIRTUALENV_OVERRIDE_APP_DATA\", str(app_data.lock.path)):\n        yield app_data\n\n\n@contextmanager\ndef change_env_var(key, value):\n    \"\"\"Temporarily change an environment variable.\n    :param key: the key of the env var\n    :param value: the value of the env var\n    \"\"\"\n    already_set = key in os.environ\n    prev_value = os.environ.get(key)\n    os.environ[key] = value\n    try:\n        yield\n    finally:\n        if already_set:\n            os.environ[key] = prev_value\n        else:\n            del os.environ[key]  # pragma: no cover\n\n\n@pytest.fixture()\ndef temp_app_data(monkeypatch, tmp_path):\n    app_data = tmp_path / \"app-data\"\n    monkeypatch.setenv(\"VIRTUALENV_OVERRIDE_APP_DATA\", str(app_data))\n    return app_data\n\n\n@pytest.fixture(scope=\"session\")\ndef for_py_version():\n    return f\"{sys.version_info.major}.{sys.version_info.minor}\"\n\n\n@pytest.fixture()\ndef _skip_if_test_in_system(session_app_data):\n    current = PythonInfo.current(session_app_data)\n    if current.system_executable is not None:\n        pytest.skip(\"test not valid if run under system\")\n\n\nif IS_PYPY or (IS_WIN and sys.version_info[0:2] >= (3, 13)):  # https://github.com/adamchainz/time-machine/issues/456\n\n    @pytest.fixture()\n    def time_freeze(freezer):\n        return freezer.move_to\n\nelse:\n\n    @pytest.fixture()\n    def time_freeze(time_machine):\n        return lambda s: time_machine.move_to(s, tick=False)\n", "tests/integration/test_zipapp.py": "from __future__ import annotations\n\nimport shutil\nimport subprocess\nfrom contextlib import suppress\nfrom pathlib import Path\n\nimport pytest\nfrom flaky import flaky\n\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.info import fs_supports_symlink\nfrom virtualenv.run import cli_run\n\nHERE = Path(__file__).parent\nCURRENT = PythonInfo.current_system()\n\n\n@pytest.fixture(scope=\"session\")\ndef zipapp_build_env(tmp_path_factory):\n    create_env_path = None\n    if CURRENT.implementation != \"PyPy\":\n        exe = CURRENT.executable  # guaranteed to contain a recent enough pip (tox.ini)\n    else:\n        create_env_path = tmp_path_factory.mktemp(\"zipapp-create-env\")\n        exe, found = None, False\n        # prefer CPython as builder as pypy is slow\n        for impl in [\"cpython\", \"\"]:\n            for version in range(11, 6, -1):\n                with suppress(Exception):\n                    # create a virtual environment which is also guaranteed to contain a recent enough pip (bundled)\n                    session = cli_run(\n                        [\n                            \"-vvv\",\n                            \"-p\",\n                            f\"{impl}3.{version}\",\n                            \"--activators\",\n                            \"\",\n                            str(create_env_path),\n                            \"--no-download\",\n                            \"--no-periodic-update\",\n                        ],\n                    )\n                    exe = str(session.creator.exe)\n                    found = True\n                    break\n            if found:\n                break\n        else:\n            msg = \"could not find a python to build zipapp\"\n            raise RuntimeError(msg)\n        cmd = [str(Path(exe).parent / \"pip\"), \"install\", \"pip>=23\", \"packaging>=23\"]\n        subprocess.check_call(cmd)\n    yield exe\n    if create_env_path is not None:\n        shutil.rmtree(str(create_env_path))\n\n\n@pytest.fixture(scope=\"session\")\ndef zipapp(zipapp_build_env, tmp_path_factory):\n    into = tmp_path_factory.mktemp(\"zipapp\")\n    path = HERE.parent.parent / \"tasks\" / \"make_zipapp.py\"\n    filename = into / \"virtualenv.pyz\"\n    cmd = [zipapp_build_env, str(path), \"--dest\", str(filename)]\n    subprocess.check_call(cmd)\n    yield filename\n    shutil.rmtree(str(into))\n\n\n@pytest.fixture(scope=\"session\")\ndef zipapp_test_env(tmp_path_factory):\n    base_path = tmp_path_factory.mktemp(\"zipapp-test\")\n    session = cli_run([\"-v\", \"--activators\", \"\", \"--without-pip\", str(base_path / \"env\"), \"--no-periodic-update\"])\n    yield session.creator.exe\n    shutil.rmtree(str(base_path))\n\n\n@pytest.fixture()\ndef call_zipapp(zipapp, tmp_path, zipapp_test_env, temp_app_data):  # noqa: ARG001\n    def _run(*args):\n        cmd = [str(zipapp_test_env), str(zipapp), \"-vv\", str(tmp_path / \"env\"), *list(args)]\n        subprocess.check_call(cmd)\n\n    return _run\n\n\n@pytest.fixture()\ndef call_zipapp_symlink(zipapp, tmp_path, zipapp_test_env, temp_app_data):  # noqa: ARG001\n    def _run(*args):\n        symlinked = zipapp.parent / \"symlinked_virtualenv.pyz\"\n        symlinked.symlink_to(str(zipapp))\n        cmd = [str(zipapp_test_env), str(symlinked), \"-vv\", str(tmp_path / \"env\"), *list(args)]\n        subprocess.check_call(cmd)\n\n    return _run\n\n\n@pytest.mark.skipif(not fs_supports_symlink(), reason=\"symlink not supported\")\ndef test_zipapp_in_symlink(capsys, call_zipapp_symlink):\n    call_zipapp_symlink(\"--reset-app-data\")\n    _out, err = capsys.readouterr()\n    assert not err\n\n\n@flaky(max_runs=2, min_passes=1)\ndef test_zipapp_help(call_zipapp, capsys):\n    call_zipapp(\"-h\")\n    _out, err = capsys.readouterr()\n    assert not err\n\n\n@pytest.mark.parametrize(\"seeder\", [\"app-data\", \"pip\"])\ndef test_zipapp_create(call_zipapp, seeder):\n    call_zipapp(\"--seeder\", seeder)\n", "tests/integration/test_run_int.py": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nimport pytest\n\nfrom virtualenv import cli_run\nfrom virtualenv.info import IS_PYPY\nfrom virtualenv.util.subprocess import run_cmd\n\nif TYPE_CHECKING:\n    from pathlib import Path\n\n\n@pytest.mark.skipif(IS_PYPY, reason=\"setuptools distutils patching does not work\")\ndef test_app_data_pinning(tmp_path: Path) -> None:\n    version = \"23.1\"\n    result = cli_run([str(tmp_path), \"--pip\", version, \"--activators\", \"\", \"--seeder\", \"app-data\"])\n    code, out, _ = run_cmd([str(result.creator.script(\"pip\")), \"list\", \"--disable-pip-version-check\"])\n    assert not code\n    for line in out.splitlines():\n        parts = line.split()\n        if parts and parts[0] == \"pip\":\n            assert parts[1] == version\n            break\n    else:\n        assert not out\n", "tests/unit/test_run.py": "from __future__ import annotations\n\nimport logging\n\nimport pytest\n\nfrom virtualenv import __version__\nfrom virtualenv.run import cli_run, session_via_cli\n\n\ndef test_help(capsys):\n    with pytest.raises(SystemExit) as context:\n        cli_run(args=[\"-h\", \"-vvv\"])\n    assert context.value.code == 0\n\n    out, err = capsys.readouterr()\n    assert not err\n    assert out\n\n\ndef test_version(capsys):\n    with pytest.raises(SystemExit) as context:\n        cli_run(args=[\"--version\"])\n    assert context.value.code == 0\n\n    content, err = capsys.readouterr()\n    assert not err\n\n    assert __version__ in content\n    import virtualenv  # noqa: PLC0415\n\n    assert virtualenv.__file__ in content\n\n\n@pytest.mark.parametrize(\"on\", [True, False])\ndef test_logging_setup(caplog, on):\n    caplog.set_level(logging.DEBUG)\n    session_via_cli([\"env\"], setup_logging=on)\n    # DEBUG only level output is generated during this phase, default output is WARN, so if on no records should be\n    if on:\n        assert not caplog.records\n    else:\n        assert caplog.records\n", "tests/unit/test_util.py": "from __future__ import annotations\n\nimport concurrent.futures\nimport traceback\n\nimport pytest\n\nfrom virtualenv.util.lock import ReentrantFileLock\nfrom virtualenv.util.subprocess import run_cmd\n\n\ndef test_run_fail(tmp_path):\n    code, out, err = run_cmd([str(tmp_path)])\n    assert err\n    assert not out\n    assert code\n\n\ndef test_reentrant_file_lock_is_thread_safe(tmp_path):\n    lock = ReentrantFileLock(tmp_path)\n    target_file = tmp_path / \"target\"\n    target_file.touch()\n\n    def recreate_target_file():\n        with lock.lock_for_key(\"target\"):\n            target_file.unlink()\n            target_file.touch()\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        tasks = [executor.submit(recreate_target_file) for _ in range(4)]\n        concurrent.futures.wait(tasks)\n        for task in tasks:\n            try:\n                task.result()\n            except Exception:  # noqa: BLE001, PERF203\n                pytest.fail(traceback.format_exc())\n", "tests/unit/discovery/test_discovery.py": "from __future__ import annotations\n\nimport logging\nimport os\nimport sys\nfrom argparse import Namespace\nfrom pathlib import Path\nfrom uuid import uuid4\n\nimport pytest\n\nfrom virtualenv.discovery.builtin import Builtin, get_interpreter\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.info import fs_supports_symlink\n\n\n@pytest.mark.skipif(not fs_supports_symlink(), reason=\"symlink not supported\")\n@pytest.mark.parametrize(\"case\", [\"mixed\", \"lower\", \"upper\"])\n@pytest.mark.parametrize(\"specificity\", [\"more\", \"less\", \"none\"])\ndef test_discovery_via_path(monkeypatch, case, specificity, tmp_path, caplog, session_app_data):  # noqa: PLR0913\n    caplog.set_level(logging.DEBUG)\n    current = PythonInfo.current_system(session_app_data)\n    name = \"somethingVeryCryptic\"\n    if case == \"lower\":\n        name = name.lower()\n    elif case == \"upper\":\n        name = name.upper()\n    if specificity == \"more\":\n        # e.g. spec: python3, exe: /bin/python3.12\n        core_ver = current.version_info.major\n        exe_ver = \".\".join(str(i) for i in current.version_info[0:2])\n    elif specificity == \"less\":\n        # e.g. spec: python3.12.1, exe: /bin/python3\n        core_ver = \".\".join(str(i) for i in current.version_info[0:3])\n        exe_ver = current.version_info.major\n    elif specificity == \"none\":\n        # e.g. spec: python3.12.1, exe: /bin/python\n        core_ver = \".\".join(str(i) for i in current.version_info[0:3])\n        exe_ver = \"\"\n    core = \"\" if specificity == \"none\" else f\"{name}{core_ver}\"\n    exe_name = f\"{name}{exe_ver}{'.exe' if sys.platform == 'win32' else ''}\"\n    target = tmp_path / current.install_path(\"scripts\")\n    target.mkdir(parents=True)\n    executable = target / exe_name\n    os.symlink(sys.executable, str(executable))\n    pyvenv_cfg = Path(sys.executable).parents[1] / \"pyvenv.cfg\"\n    if pyvenv_cfg.exists():\n        (target / pyvenv_cfg.name).write_bytes(pyvenv_cfg.read_bytes())\n    new_path = os.pathsep.join([str(target), *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\n    monkeypatch.setenv(\"PATH\", new_path)\n    interpreter = get_interpreter(core, [])\n\n    assert interpreter is not None\n\n\ndef test_discovery_via_path_not_found(tmp_path, monkeypatch):\n    monkeypatch.setenv(\"PATH\", str(tmp_path))\n    interpreter = get_interpreter(uuid4().hex, [])\n    assert interpreter is None\n\n\ndef test_relative_path(session_app_data, monkeypatch):\n    sys_executable = Path(PythonInfo.current_system(app_data=session_app_data).system_executable)\n    cwd = sys_executable.parents[1]\n    monkeypatch.chdir(str(cwd))\n    relative = str(sys_executable.relative_to(cwd))\n    result = get_interpreter(relative, [], session_app_data)\n    assert result is not None\n\n\ndef test_discovery_fallback_fail(session_app_data, caplog):\n    caplog.set_level(logging.DEBUG)\n    builtin = Builtin(\n        Namespace(app_data=session_app_data, try_first_with=[], python=[\"magic-one\", \"magic-two\"], env=os.environ),\n    )\n\n    result = builtin.run()\n    assert result is None\n\n    assert \"accepted\" not in caplog.text\n\n\ndef test_discovery_fallback_ok(session_app_data, caplog):\n    caplog.set_level(logging.DEBUG)\n    builtin = Builtin(\n        Namespace(app_data=session_app_data, try_first_with=[], python=[\"magic-one\", sys.executable], env=os.environ),\n    )\n\n    result = builtin.run()\n    assert result is not None, caplog.text\n    assert result.executable == sys.executable, caplog.text\n\n    assert \"accepted\" in caplog.text\n", "tests/unit/discovery/test_py_spec.py": "from __future__ import annotations\n\nimport sys\nfrom copy import copy\n\nimport pytest\n\nfrom virtualenv.discovery.py_spec import PythonSpec\n\n\ndef test_bad_py_spec():\n    text = \"python2.3.4.5\"\n    spec = PythonSpec.from_string_spec(text)\n    assert text in repr(spec)\n    assert spec.str_spec == text\n    assert spec.path == text\n    content = vars(spec)\n    del content[\"str_spec\"]\n    del content[\"path\"]\n    assert all(v is None for v in content.values())\n\n\ndef test_py_spec_first_digit_only_major():\n    spec = PythonSpec.from_string_spec(\"278\")\n    assert spec.major == 2\n    assert spec.minor == 78\n\n\ndef test_spec_satisfies_path_ok():\n    spec = PythonSpec.from_string_spec(sys.executable)\n    assert spec.satisfies(spec) is True\n\n\ndef test_spec_satisfies_path_nok(tmp_path):\n    spec = PythonSpec.from_string_spec(sys.executable)\n    of = PythonSpec.from_string_spec(str(tmp_path))\n    assert spec.satisfies(of) is False\n\n\ndef test_spec_satisfies_arch():\n    spec_1 = PythonSpec.from_string_spec(\"python-32\")\n    spec_2 = PythonSpec.from_string_spec(\"python-64\")\n\n    assert spec_1.satisfies(spec_1) is True\n    assert spec_2.satisfies(spec_1) is False\n\n\n@pytest.mark.parametrize(\n    (\"req\", \"spec\"),\n    [(\"py\", \"python\"), (\"jython\", \"jython\"), (\"CPython\", \"cpython\")],\n)\ndef test_spec_satisfies_implementation_ok(req, spec):\n    spec_1 = PythonSpec.from_string_spec(req)\n    spec_2 = PythonSpec.from_string_spec(spec)\n    assert spec_1.satisfies(spec_1) is True\n    assert spec_2.satisfies(spec_1) is True\n\n\ndef test_spec_satisfies_implementation_nok():\n    spec_1 = PythonSpec.from_string_spec(\"cpython\")\n    spec_2 = PythonSpec.from_string_spec(\"jython\")\n    assert spec_2.satisfies(spec_1) is False\n    assert spec_1.satisfies(spec_2) is False\n\n\ndef _version_satisfies_pairs():\n    target = set()\n    version = tuple(str(i) for i in sys.version_info[0:3])\n    for i in range(len(version) + 1):\n        req = \".\".join(version[0:i])\n        for j in range(i + 1):\n            sat = \".\".join(version[0:j])\n            # can be satisfied in both directions\n            target.add((req, sat))\n            target.add((sat, req))\n    return sorted(target)\n\n\n@pytest.mark.parametrize((\"req\", \"spec\"), _version_satisfies_pairs())\ndef test_version_satisfies_ok(req, spec):\n    req_spec = PythonSpec.from_string_spec(f\"python{req}\")\n    sat_spec = PythonSpec.from_string_spec(f\"python{spec}\")\n    assert sat_spec.satisfies(req_spec) is True\n\n\ndef _version_not_satisfies_pairs():\n    target = set()\n    version = tuple(str(i) for i in sys.version_info[0:3])\n    for major in range(len(version)):\n        req = \".\".join(version[0 : major + 1])\n        for minor in range(major + 1):\n            sat_ver = list(sys.version_info[0 : minor + 1])\n            for patch in range(minor + 1):\n                for o in [1, -1]:\n                    temp = copy(sat_ver)\n                    temp[patch] += o\n                    if temp[patch] < 0:\n                        continue\n                    sat = \".\".join(str(i) for i in temp)\n                    target.add((req, sat))\n    return sorted(target)\n\n\n@pytest.mark.parametrize((\"req\", \"spec\"), _version_not_satisfies_pairs())\ndef test_version_satisfies_nok(req, spec):\n    req_spec = PythonSpec.from_string_spec(f\"python{req}\")\n    sat_spec = PythonSpec.from_string_spec(f\"python{spec}\")\n    assert sat_spec.satisfies(req_spec) is False\n\n\ndef test_relative_spec(tmp_path, monkeypatch):\n    monkeypatch.chdir(tmp_path)\n    a_relative_path = str((tmp_path / \"a\" / \"b\").relative_to(tmp_path))\n    spec = PythonSpec.from_string_spec(a_relative_path)\n    assert spec.path == a_relative_path\n", "tests/unit/discovery/windows/winreg-mock-values.py": "from __future__ import annotations\n\nimport winreg\n\nhive_open = {\n    (winreg.HKEY_CURRENT_USER, \"Software\\\\Python\", 0, winreg.KEY_READ): 78701856,\n    (winreg.HKEY_LOCAL_MACHINE, \"Software\\\\Python\", 0, winreg.KEY_READ | winreg.KEY_WOW64_64KEY): 78701840,\n    (winreg.HKEY_LOCAL_MACHINE, \"Software\\\\Python\", 0, winreg.KEY_READ | winreg.KEY_WOW64_32KEY): OSError(\n        2,\n        \"The system cannot find the file specified\",\n    ),\n}\nkey_open = {\n    78701152: {\n        \"Anaconda310-32\\\\InstallPath\": 78703200,\n        \"Anaconda310-32\": 78703568,\n        \"Anaconda310-64\\\\InstallPath\": 78703520,\n        \"Anaconda310-64\": 78702368,\n    },\n    78701856: {\"ContinuumAnalytics\": 78701152, \"PythonCore\": 78702656, \"CompanyA\": 88800000},\n    78702656: {\n        \"3.1\\\\InstallPath\": 78701824,\n        \"3.1\": 78700704,\n        \"3.2\\\\InstallPath\": 78704048,\n        \"3.2\": 78704368,\n        \"3.3\\\\InstallPath\": 78701936,\n        \"3.3\": 78703024,\n        \"3.8\\\\InstallPath\": 78703792,\n        \"3.8\": 78701792,\n        \"3.9\\\\InstallPath\": 78701888,\n        \"3.9\": 78703424,\n        \"3.10-32\\\\InstallPath\": 78703600,\n        \"3.10-32\": 78704512,\n        \"3.11\\\\InstallPath\": OSError(2, \"The system cannot find the file specified\"),\n        \"3.11\": 78700656,\n        \"3.12\\\\InstallPath\": 78703632,\n        \"3.12\": 78702608,\n        \"3.X\": 78703088,\n    },\n    78702960: {\"2.7\\\\InstallPath\": 78700912, \"2.7\": 78703136, \"3.7\\\\InstallPath\": 78703648, \"3.7\": 78704032},\n    78701840: {\"PythonCore\": 78702960},\n    88800000: {\n        \"3.6\\\\InstallPath\": 88810000,\n        \"3.6\": 88820000,\n    },\n}\nvalue_collect = {\n    78703568: {\"SysVersion\": (\"3.10\", 1), \"SysArchitecture\": (\"32bit\", 1)},\n    78703200: {\n        \"ExecutablePath\": (\"C:\\\\Users\\\\user\\\\Miniconda3\\\\python.exe\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78702368: {\"SysVersion\": (\"3.10\", 1), \"SysArchitecture\": (\"64bit\", 1)},\n    78703520: {\n        \"ExecutablePath\": (\"C:\\\\Users\\\\user\\\\Miniconda3-64\\\\python.exe\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78700704: {\"SysVersion\": (\"3.9\", 1), \"SysArchitecture\": (\"magic\", 1)},\n    78701824: {\n        \"ExecutablePath\": (\"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78704368: {\"SysVersion\": (\"3.9\", 1), \"SysArchitecture\": (100, 4)},\n    78704048: {\n        \"ExecutablePath\": (\"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78703024: {\"SysVersion\": (\"3.9\", 1), \"SysArchitecture\": (\"64bit\", 1)},\n    78701936: {\n        \"ExecutablePath\": OSError(2, \"The system cannot find the file specified\"),\n        None: OSError(2, \"The system cannot find the file specified\"),\n    },\n    78701792: {\n        \"SysVersion\": OSError(2, \"The system cannot find the file specified\"),\n        \"SysArchitecture\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78703792: {\n        \"ExecutablePath\": (\"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\python.exe\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78703424: {\"SysVersion\": (\"3.9\", 1), \"SysArchitecture\": (\"64bit\", 1)},\n    78701888: {\n        \"ExecutablePath\": (\"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78704512: {\"SysVersion\": (\"3.10\", 1), \"SysArchitecture\": (\"32bit\", 1)},\n    78703600: {\n        \"ExecutablePath\": (\"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310-32\\\\python.exe\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78700656: {\n        \"SysVersion\": OSError(2, \"The system cannot find the file specified\"),\n        \"SysArchitecture\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78702608: {\"SysVersion\": (\"magic\", 1), \"SysArchitecture\": (\"64bit\", 1)},\n    78703632: {\n        \"ExecutablePath\": (\"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78703088: {\"SysVersion\": (2778, 11)},\n    78703136: {\n        \"SysVersion\": OSError(2, \"The system cannot find the file specified\"),\n        \"SysArchitecture\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78700912: {\n        \"ExecutablePath\": OSError(2, \"The system cannot find the file specified\"),\n        None: (\"C:\\\\Python27\\\\\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78704032: {\n        \"SysVersion\": OSError(2, \"The system cannot find the file specified\"),\n        \"SysArchitecture\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    78703648: {\n        \"ExecutablePath\": OSError(2, \"The system cannot find the file specified\"),\n        None: (\"C:\\\\Python37\\\\\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    88810000: {\n        \"ExecutablePath\": (\"Z:\\\\CompanyA\\\\Python\\\\3.6\\\\python.exe\", 1),\n        \"ExecutableArguments\": OSError(2, \"The system cannot find the file specified\"),\n    },\n    88820000: {\"SysVersion\": (\"3.6\", 1), \"SysArchitecture\": (\"64bit\", 1)},\n}\nenum_collect = {\n    78701856: [\n        \"ContinuumAnalytics\",\n        \"PythonCore\",\n        \"CompanyA\",\n        OSError(22, \"No more data is available\", None, 259, None),\n    ],\n    78701152: [\"Anaconda310-32\", \"Anaconda310-64\", OSError(22, \"No more data is available\", None, 259, None)],\n    78702656: [\n        \"3.1\",\n        \"3.2\",\n        \"3.3\",\n        \"3.8\",\n        \"3.9\",\n        \"3.10-32\",\n        \"3.11\",\n        \"3.12\",\n        \"3.X\",\n        OSError(22, \"No more data is available\", None, 259, None),\n    ],\n    78701840: [\"PyLauncher\", \"PythonCore\", OSError(22, \"No more data is available\", None, 259, None)],\n    78702960: [\"2.7\", \"3.7\", OSError(22, \"No more data is available\", None, 259, None)],\n    88800000: [\"3.6\", OSError(22, \"No more data is available\", None, 259, None)],\n}\n", "tests/unit/discovery/windows/conftest.py": "from __future__ import annotations\n\nfrom contextlib import contextmanager\nfrom pathlib import Path\n\nimport pytest\n\n\n@pytest.fixture()\ndef _mock_registry(mocker):  # noqa: C901\n    from virtualenv.discovery.windows.pep514 import winreg  # noqa: PLC0415\n\n    loc, glob = {}, {}\n    mock_value_str = (Path(__file__).parent / \"winreg-mock-values.py\").read_text(encoding=\"utf-8\")\n    exec(mock_value_str, glob, loc)  # noqa: S102\n    enum_collect = loc[\"enum_collect\"]\n    value_collect = loc[\"value_collect\"]\n    key_open = loc[\"key_open\"]\n    hive_open = loc[\"hive_open\"]\n\n    def _enum_key(key, at):\n        key_id = key.value if isinstance(key, Key) else key\n        result = enum_collect[key_id][at]\n        if isinstance(result, OSError):\n            raise result\n        return result\n\n    mocker.patch.object(winreg, \"EnumKey\", side_effect=_enum_key)\n\n    def _query_value_ex(key, value_name):\n        key_id = key.value if isinstance(key, Key) else key\n        result = value_collect[key_id][value_name]\n        if isinstance(result, OSError):\n            raise result\n        return result\n\n    mocker.patch.object(winreg, \"QueryValueEx\", side_effect=_query_value_ex)\n\n    class Key:\n        def __init__(self, value) -> None:\n            self.value = value\n\n        def __enter__(self):\n            return self\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            return None\n\n    @contextmanager\n    def _open_key_ex(*args):\n        if len(args) == 2:\n            key, value = args\n            key_id = key.value if isinstance(key, Key) else key\n            result = Key(key_open[key_id][value])  # this needs to be something that can be with-ed, so let's wrap it\n        elif len(args) == 4:\n            result = hive_open[args]\n        else:\n            raise RuntimeError\n        value = result.value if isinstance(result, Key) else result\n        if isinstance(value, OSError):\n            raise value\n        yield result\n\n    mocker.patch.object(winreg, \"OpenKeyEx\", side_effect=_open_key_ex)\n    mocker.patch(\"os.path.exists\", return_value=True)\n\n\ndef _mock_pyinfo(major, minor, arch, exe):\n    \"\"\"Return PythonInfo objects with essential metadata set for the given args\"\"\"\n    from virtualenv.discovery.py_info import PythonInfo, VersionInfo  # noqa: PLC0415\n\n    info = PythonInfo()\n    info.base_prefix = str(Path(exe).parent)\n    info.executable = info.original_executable = info.system_executable = exe\n    info.implementation = \"CPython\"\n    info.architecture = arch\n    info.version_info = VersionInfo(major, minor, 0, \"final\", 0)\n    return info\n\n\n@pytest.fixture()\ndef _populate_pyinfo_cache(monkeypatch):\n    \"\"\"Add metadata to virtualenv.discovery.cached_py_info._CACHE for all (mocked) registry entries\"\"\"\n    import virtualenv.discovery.cached_py_info  # noqa: PLC0415\n\n    # Data matches _mock_registry fixture\n    interpreters = [\n        (\"ContinuumAnalytics\", 3, 10, 32, \"C:\\\\Users\\\\user\\\\Miniconda3\\\\python.exe\", None),\n        (\"ContinuumAnalytics\", 3, 10, 64, \"C:\\\\Users\\\\user\\\\Miniconda3-64\\\\python.exe\", None),\n        (\"PythonCore\", 3, 9, 64, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\python.exe\", None),\n        (\"PythonCore\", 3, 9, 64, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\python.exe\", None),\n        (\"PythonCore\", 3, 5, 64, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python35\\\\python.exe\", None),\n        (\"PythonCore\", 3, 9, 64, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\python.exe\", None),\n        (\"PythonCore\", 3, 7, 32, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37-32\\\\python.exe\", None),\n        (\"PythonCore\", 3, 12, 64, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe\", None),\n        (\"PythonCore\", 2, 7, 64, \"C:\\\\Python27\\\\python.exe\", None),\n        (\"PythonCore\", 3, 4, 64, \"C:\\\\Python34\\\\python.exe\", None),\n        (\"CompanyA\", 3, 6, 64, \"Z:\\\\CompanyA\\\\Python\\\\3.6\\\\python.exe\", None),\n    ]\n    for _, major, minor, arch, exe, _ in interpreters:\n        info = _mock_pyinfo(major, minor, arch, exe)\n        monkeypatch.setitem(virtualenv.discovery.cached_py_info._CACHE, Path(info.executable), info)  # noqa: SLF001\n", "tests/unit/discovery/windows/test_windows_pep514.py": "from __future__ import annotations\n\nimport sys\nimport textwrap\n\nimport pytest\n\n\n@pytest.mark.skipif(sys.platform != \"win32\", reason=\"no Windows registry\")\n@pytest.mark.usefixtures(\"_mock_registry\")\ndef test_pep514():\n    from virtualenv.discovery.windows.pep514 import discover_pythons  # noqa: PLC0415\n\n    interpreters = list(discover_pythons())\n    assert interpreters == [\n        (\"ContinuumAnalytics\", 3, 10, 32, \"C:\\\\Users\\\\user\\\\Miniconda3\\\\python.exe\", None),\n        (\"ContinuumAnalytics\", 3, 10, 64, \"C:\\\\Users\\\\user\\\\Miniconda3-64\\\\python.exe\", None),\n        (\"PythonCore\", 3, 9, 64, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe\", None),\n        (\"PythonCore\", 3, 9, 64, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe\", None),\n        (\"PythonCore\", 3, 8, 64, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\python.exe\", None),\n        (\"PythonCore\", 3, 9, 64, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe\", None),\n        (\"PythonCore\", 3, 10, 32, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310-32\\\\python.exe\", None),\n        (\"PythonCore\", 3, 12, 64, \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe\", None),\n        (\"CompanyA\", 3, 6, 64, \"Z:\\\\CompanyA\\\\Python\\\\3.6\\\\python.exe\", None),\n        (\"PythonCore\", 2, 7, 64, \"C:\\\\Python27\\\\python.exe\", None),\n        (\"PythonCore\", 3, 7, 64, \"C:\\\\Python37\\\\python.exe\", None),\n    ]\n\n\n@pytest.mark.skipif(sys.platform != \"win32\", reason=\"no Windows registry\")\n@pytest.mark.usefixtures(\"_mock_registry\")\ndef test_pep514_run(capsys, caplog):\n    from virtualenv.discovery.windows import pep514  # noqa: PLC0415\n\n    pep514._run()  # noqa: SLF001\n    out, err = capsys.readouterr()\n    expected = textwrap.dedent(\n        r\"\"\"\n    ('CompanyA', 3, 6, 64, 'Z:\\\\CompanyA\\\\Python\\\\3.6\\\\python.exe', None)\n    ('ContinuumAnalytics', 3, 10, 32, 'C:\\\\Users\\\\user\\\\Miniconda3\\\\python.exe', None)\n    ('ContinuumAnalytics', 3, 10, 64, 'C:\\\\Users\\\\user\\\\Miniconda3-64\\\\python.exe', None)\n    ('PythonCore', 2, 7, 64, 'C:\\\\Python27\\\\python.exe', None)\n    ('PythonCore', 3, 10, 32, 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310-32\\\\python.exe', None)\n    ('PythonCore', 3, 12, 64, 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', None)\n    ('PythonCore', 3, 7, 64, 'C:\\\\Python37\\\\python.exe', None)\n    ('PythonCore', 3, 8, 64, 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\python.exe', None)\n    ('PythonCore', 3, 9, 64, 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', None)\n    ('PythonCore', 3, 9, 64, 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', None)\n    ('PythonCore', 3, 9, 64, 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', None)\n    \"\"\",\n    ).strip()\n    assert out.strip() == expected\n    assert not err\n    prefix = \"PEP-514 violation in Windows Registry at \"\n    expected_logs = [\n        f\"{prefix}HKEY_CURRENT_USER/PythonCore/3.1/SysArchitecture error: invalid format magic\",\n        f\"{prefix}HKEY_CURRENT_USER/PythonCore/3.2/SysArchitecture error: arch is not string: 100\",\n        f\"{prefix}HKEY_CURRENT_USER/PythonCore/3.3 error: no ExecutablePath or default for it\",\n        f\"{prefix}HKEY_CURRENT_USER/PythonCore/3.3 error: could not load exe with value None\",\n        f\"{prefix}HKEY_CURRENT_USER/PythonCore/3.11/InstallPath error: missing\",\n        f\"{prefix}HKEY_CURRENT_USER/PythonCore/3.12/SysVersion error: invalid format magic\",\n        f\"{prefix}HKEY_CURRENT_USER/PythonCore/3.X/SysVersion error: version is not string: 2778\",\n        f\"{prefix}HKEY_CURRENT_USER/PythonCore/3.X error: invalid format 3.X\",\n    ]\n    assert caplog.messages == expected_logs\n", "tests/unit/discovery/windows/test_windows.py": "from __future__ import annotations\n\nimport sys\n\nimport pytest\n\nfrom virtualenv.discovery.py_spec import PythonSpec\n\n\n@pytest.mark.skipif(sys.platform != \"win32\", reason=\"no Windows registry\")\n@pytest.mark.usefixtures(\"_mock_registry\")\n@pytest.mark.usefixtures(\"_populate_pyinfo_cache\")\n@pytest.mark.parametrize(\n    (\"string_spec\", \"expected_exe\"),\n    [\n        # 64-bit over 32-bit\n        (\"python3.10\", \"C:\\\\Users\\\\user\\\\Miniconda3-64\\\\python.exe\"),\n        (\"cpython3.10\", \"C:\\\\Users\\\\user\\\\Miniconda3-64\\\\python.exe\"),\n        # 1 installation of 3.9 available\n        (\"python3.12\", \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe\"),\n        (\"cpython3.12\", \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe\"),\n        # resolves to highest available version\n        (\"python\", \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe\"),\n        (\"cpython\", \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe\"),\n        # Non-standard org name\n        (\"python3.6\", \"Z:\\\\CompanyA\\\\Python\\\\3.6\\\\python.exe\"),\n        (\"cpython3.6\", \"Z:\\\\CompanyA\\\\Python\\\\3.6\\\\python.exe\"),\n    ],\n)\ndef test_propose_interpreters(string_spec, expected_exe):\n    from virtualenv.discovery.windows import propose_interpreters  # noqa: PLC0415\n\n    spec = PythonSpec.from_string_spec(string_spec)\n    interpreter = next(propose_interpreters(spec=spec, cache_dir=None, env=None))\n    assert interpreter.executable == expected_exe\n", "tests/unit/discovery/py_info/test_py_info_exe_based_of.py": "from __future__ import annotations\n\nimport logging\nimport os\nfrom pathlib import Path\n\nimport pytest\n\nfrom virtualenv.discovery.py_info import EXTENSIONS, PythonInfo\nfrom virtualenv.info import IS_WIN, fs_is_case_sensitive, fs_supports_symlink\n\nCURRENT = PythonInfo.current()\n\n\ndef test_discover_empty_folder(tmp_path, session_app_data):\n    with pytest.raises(RuntimeError):\n        CURRENT.discover_exe(session_app_data, prefix=str(tmp_path))\n\n\nBASE = (CURRENT.install_path(\"scripts\"), \".\")\n\n\n@pytest.mark.skipif(not fs_supports_symlink(), reason=\"symlink is not supported\")\n@pytest.mark.parametrize(\"suffix\", sorted({\".exe\", \".cmd\", \"\"} & set(EXTENSIONS) if IS_WIN else [\"\"]))\n@pytest.mark.parametrize(\"into\", BASE)\n@pytest.mark.parametrize(\"arch\", [CURRENT.architecture, \"\"])\n@pytest.mark.parametrize(\"version\", [\".\".join(str(i) for i in CURRENT.version_info[0:i]) for i in range(3, 0, -1)])\n@pytest.mark.parametrize(\"impl\", [CURRENT.implementation, \"python\"])\ndef test_discover_ok(tmp_path, suffix, impl, version, arch, into, caplog, session_app_data):  # noqa: PLR0913\n    caplog.set_level(logging.DEBUG)\n    folder = tmp_path / into\n    folder.mkdir(parents=True, exist_ok=True)\n    name = f\"{impl}{version}\"\n    if arch:\n        name += f\"-{arch}\"\n    name += suffix\n    dest = folder / name\n    os.symlink(CURRENT.executable, str(dest))\n    pyvenv = Path(CURRENT.executable).parents[1] / \"pyvenv.cfg\"\n    if pyvenv.exists():\n        (folder / pyvenv.name).write_text(pyvenv.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n    inside_folder = str(tmp_path)\n    base = CURRENT.discover_exe(session_app_data, inside_folder)\n    found = base.executable\n    dest_str = str(dest)\n    if not fs_is_case_sensitive():\n        found = found.lower()\n        dest_str = dest_str.lower()\n    assert found == dest_str\n    assert len(caplog.messages) >= 1, caplog.text\n    assert \"get interpreter info via cmd: \" in caplog.text\n\n    dest.rename(dest.parent / (dest.name + \"-1\"))\n    CURRENT._cache_exe_discovery.clear()  # noqa: SLF001\n    with pytest.raises(RuntimeError):\n        CURRENT.discover_exe(session_app_data, inside_folder)\n", "tests/unit/discovery/py_info/test_py_info.py": "from __future__ import annotations\n\nimport copy\nimport functools\nimport itertools\nimport json\nimport logging\nimport os\nimport sys\nimport sysconfig\nfrom pathlib import Path\nfrom textwrap import dedent\nfrom typing import NamedTuple\n\nimport pytest\n\nfrom virtualenv.discovery import cached_py_info\nfrom virtualenv.discovery.py_info import PythonInfo, VersionInfo\nfrom virtualenv.discovery.py_spec import PythonSpec\nfrom virtualenv.info import IS_PYPY, IS_WIN, fs_supports_symlink\n\nCURRENT = PythonInfo.current_system()\n\n\ndef test_current_as_json():\n    result = CURRENT._to_json()  # noqa: SLF001\n    parsed = json.loads(result)\n    a, b, c, d, e = sys.version_info\n    assert parsed[\"version_info\"] == {\"major\": a, \"minor\": b, \"micro\": c, \"releaselevel\": d, \"serial\": e}\n\n\ndef test_bad_exe_py_info_raise(tmp_path, session_app_data):\n    exe = str(tmp_path)\n    with pytest.raises(RuntimeError) as context:\n        PythonInfo.from_exe(exe, session_app_data)\n    msg = str(context.value)\n    assert \"code\" in msg\n    assert exe in msg\n\n\ndef test_bad_exe_py_info_no_raise(tmp_path, caplog, capsys, session_app_data):\n    caplog.set_level(logging.NOTSET)\n    exe = str(tmp_path)\n    result = PythonInfo.from_exe(exe, session_app_data, raise_on_error=False)\n    assert result is None\n    out, _ = capsys.readouterr()\n    assert not out\n    messages = [r.message for r in caplog.records if r.name != \"filelock\"]\n    assert len(messages) == 2\n    msg = messages[0]\n    assert \"get interpreter info via cmd: \" in msg\n    msg = messages[1]\n    assert str(exe) in msg\n    assert \"code\" in msg\n\n\n@pytest.mark.parametrize(\n    \"spec\",\n    itertools.chain(\n        [sys.executable],\n        [\n            f\"{impl}{'.'.join(str(i) for i in ver)}{arch}\"\n            for impl, ver, arch in itertools.product(\n                (\n                    [CURRENT.implementation]\n                    + ([\"python\"] if CURRENT.implementation == \"CPython\" else [])\n                    + (\n                        [CURRENT.implementation.lower()]\n                        if CURRENT.implementation != CURRENT.implementation.lower()\n                        else []\n                    )\n                ),\n                [sys.version_info[0 : i + 1] for i in range(3)],\n                [\"\", f\"-{CURRENT.architecture}\"],\n            )\n        ],\n    ),\n)\ndef test_satisfy_py_info(spec):\n    parsed_spec = PythonSpec.from_string_spec(spec)\n    matches = CURRENT.satisfies(parsed_spec, True)\n    assert matches is True\n\n\ndef test_satisfy_not_arch():\n    parsed_spec = PythonSpec.from_string_spec(\n        f\"{CURRENT.implementation}-{64 if CURRENT.architecture == 32 else 32}\",\n    )\n    matches = CURRENT.satisfies(parsed_spec, True)\n    assert matches is False\n\n\ndef _generate_not_match_current_interpreter_version():\n    result = []\n    for i in range(3):\n        ver = sys.version_info[0 : i + 1]\n        for a in range(len(ver)):\n            for o in [-1, 1]:\n                temp = list(ver)\n                temp[a] += o\n                result.append(\".\".join(str(i) for i in temp))\n    return result\n\n\n_NON_MATCH_VER = _generate_not_match_current_interpreter_version()\n\n\n@pytest.mark.parametrize(\"spec\", _NON_MATCH_VER)\ndef test_satisfy_not_version(spec):\n    parsed_spec = PythonSpec.from_string_spec(f\"{CURRENT.implementation}{spec}\")\n    matches = CURRENT.satisfies(parsed_spec, True)\n    assert matches is False\n\n\ndef test_py_info_cached_error(mocker, tmp_path, session_app_data):\n    spy = mocker.spy(cached_py_info, \"_run_subprocess\")\n    with pytest.raises(RuntimeError):\n        PythonInfo.from_exe(str(tmp_path), session_app_data)\n    with pytest.raises(RuntimeError):\n        PythonInfo.from_exe(str(tmp_path), session_app_data)\n    assert spy.call_count == 1\n\n\n@pytest.mark.skipif(not fs_supports_symlink(), reason=\"symlink is not supported\")\ndef test_py_info_cached_symlink_error(mocker, tmp_path, session_app_data):\n    spy = mocker.spy(cached_py_info, \"_run_subprocess\")\n    with pytest.raises(RuntimeError):\n        PythonInfo.from_exe(str(tmp_path), session_app_data)\n    symlinked = tmp_path / \"a\"\n    symlinked.symlink_to(tmp_path)\n    with pytest.raises(RuntimeError):\n        PythonInfo.from_exe(str(symlinked), session_app_data)\n    assert spy.call_count == 2\n\n\ndef test_py_info_cache_clear(mocker, session_app_data):\n    spy = mocker.spy(cached_py_info, \"_run_subprocess\")\n    result = PythonInfo.from_exe(sys.executable, session_app_data)\n    assert result is not None\n    count = 1 if result.executable == sys.executable else 2  # at least two, one for the venv, one more for the host\n    assert spy.call_count >= count\n    PythonInfo.clear_cache(session_app_data)\n    assert PythonInfo.from_exe(sys.executable, session_app_data) is not None\n    assert spy.call_count >= 2 * count\n\n\n@pytest.mark.skipif(not fs_supports_symlink(), reason=\"symlink is not supported\")\n@pytest.mark.xfail(\n    # https://doc.pypy.org/en/latest/install.html?highlight=symlink#download-a-pre-built-pypy\n    IS_PYPY and IS_WIN and sys.version_info[0:2] >= (3, 9),\n    reason=\"symlink is not supported\",\n)\n@pytest.mark.skipif(not fs_supports_symlink(), reason=\"symlink is not supported\")\ndef test_py_info_cached_symlink(mocker, tmp_path, session_app_data):\n    spy = mocker.spy(cached_py_info, \"_run_subprocess\")\n    first_result = PythonInfo.from_exe(sys.executable, session_app_data)\n    assert first_result is not None\n    count = spy.call_count\n    # at least two, one for the venv, one more for the host\n    exp_count = 1 if first_result.executable == sys.executable else 2\n    assert count >= exp_count  # at least two, one for the venv, one more for the host\n\n    new_exe = tmp_path / \"a\"\n    new_exe.symlink_to(sys.executable)\n    pyvenv = Path(sys.executable).parents[1] / \"pyvenv.cfg\"\n    if pyvenv.exists():\n        (tmp_path / pyvenv.name).write_text(pyvenv.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n    new_exe_str = str(new_exe)\n    second_result = PythonInfo.from_exe(new_exe_str, session_app_data)\n    assert second_result.executable == new_exe_str\n    assert spy.call_count == count + 1  # no longer needed the host invocation, but the new symlink is must\n\n\nclass PyInfoMock(NamedTuple):\n    implementation: str\n    architecture: int\n    version_info: VersionInfo\n\n\n@pytest.mark.parametrize(\n    (\"target\", \"position\", \"discovered\"),\n    [\n        (\n            PyInfoMock(\"CPython\", 64, VersionInfo(3, 6, 8, \"final\", 0)),\n            0,\n            [\n                PyInfoMock(\"CPython\", 64, VersionInfo(3, 6, 9, \"final\", 0)),\n                PyInfoMock(\"PyPy\", 64, VersionInfo(3, 6, 8, \"final\", 0)),\n            ],\n        ),\n        (\n            PyInfoMock(\"CPython\", 64, VersionInfo(3, 6, 8, \"final\", 0)),\n            0,\n            [\n                PyInfoMock(\"CPython\", 64, VersionInfo(3, 6, 9, \"final\", 0)),\n                PyInfoMock(\"CPython\", 32, VersionInfo(3, 6, 9, \"final\", 0)),\n            ],\n        ),\n        (\n            PyInfoMock(\"CPython\", 64, VersionInfo(3, 8, 1, \"final\", 0)),\n            0,\n            [\n                PyInfoMock(\"CPython\", 32, VersionInfo(2, 7, 12, \"rc\", 2)),\n                PyInfoMock(\"PyPy\", 64, VersionInfo(3, 8, 1, \"final\", 0)),\n            ],\n        ),\n    ],\n)\ndef test_system_executable_no_exact_match(  # noqa: PLR0913\n    target,\n    discovered,\n    position,\n    tmp_path,\n    mocker,\n    caplog,\n    session_app_data,\n):\n    \"\"\"Here we should fallback to other compatible\"\"\"\n    caplog.set_level(logging.DEBUG)\n\n    def _make_py_info(of):\n        base = copy.deepcopy(CURRENT)\n        base.implementation = of.implementation\n        base.version_info = of.version_info\n        base.architecture = of.architecture\n        return base\n\n    discovered_with_path = {}\n    names = []\n    selected = None\n    for pos, i in enumerate(discovered):\n        path = tmp_path / str(pos)\n        path.write_text(\"\", encoding=\"utf-8\")\n        py_info = _make_py_info(i)\n        py_info.system_executable = CURRENT.system_executable\n        py_info.executable = CURRENT.system_executable\n        py_info.base_executable = str(path)\n        if pos == position:\n            selected = py_info\n        discovered_with_path[str(path)] = py_info\n        names.append(path.name)\n\n    target_py_info = _make_py_info(target)\n    mocker.patch.object(target_py_info, \"_find_possible_exe_names\", return_value=names)\n    mocker.patch.object(target_py_info, \"_find_possible_folders\", return_value=[str(tmp_path)])\n\n    def func(k, app_data, resolve_to_host, raise_on_error, env):  # noqa: ARG001\n        return discovered_with_path[k]\n\n    mocker.patch.object(target_py_info, \"from_exe\", side_effect=func)\n    target_py_info.real_prefix = str(tmp_path)\n\n    target_py_info.system_executable = None\n    target_py_info.executable = str(tmp_path)\n    mapped = target_py_info._resolve_to_system(session_app_data, target_py_info)  # noqa: SLF001\n    assert mapped.system_executable == CURRENT.system_executable\n    found = discovered_with_path[mapped.base_executable]\n    assert found is selected\n\n    assert caplog.records[0].msg == \"discover exe for %s in %s\"\n    for record in caplog.records[1:-1]:\n        assert record.message.startswith(\"refused interpreter \")\n        assert record.levelno == logging.DEBUG\n\n    warn_similar = caplog.records[-1]\n    assert warn_similar.levelno == logging.DEBUG\n    assert warn_similar.msg.startswith(\"no exact match found, chosen most similar\")\n\n\ndef test_py_info_ignores_distutils_config(monkeypatch, tmp_path):\n    raw = f\"\"\"\n    [install]\n    prefix={tmp_path}{os.sep}prefix\n    install_purelib={tmp_path}{os.sep}purelib\n    install_platlib={tmp_path}{os.sep}platlib\n    install_headers={tmp_path}{os.sep}headers\n    install_scripts={tmp_path}{os.sep}scripts\n    install_data={tmp_path}{os.sep}data\n    \"\"\"\n    (tmp_path / \"setup.cfg\").write_text(dedent(raw), encoding=\"utf-8\")\n    monkeypatch.chdir(tmp_path)\n    py_info = PythonInfo.from_exe(sys.executable)\n    distutils = py_info.distutils_install\n    for key, value in distutils.items():\n        assert not value.startswith(str(tmp_path)), f\"{key}={value}\"\n\n\ndef test_discover_exe_on_path_non_spec_name_match(mocker):\n    suffixed_name = f\"python{CURRENT.version_info.major}.{CURRENT.version_info.minor}m\"\n    if sys.platform == \"win32\":\n        suffixed_name += Path(CURRENT.original_executable).suffix\n    spec = PythonSpec.from_string_spec(suffixed_name)\n    mocker.patch.object(CURRENT, \"original_executable\", str(Path(CURRENT.executable).parent / suffixed_name))\n    assert CURRENT.satisfies(spec, impl_must_match=True) is True\n\n\ndef test_discover_exe_on_path_non_spec_name_not_match(mocker):\n    suffixed_name = f\"python{CURRENT.version_info.major}.{CURRENT.version_info.minor}m\"\n    if sys.platform == \"win32\":\n        suffixed_name += Path(CURRENT.original_executable).suffix\n    spec = PythonSpec.from_string_spec(suffixed_name)\n    mocker.patch.object(\n        CURRENT,\n        \"original_executable\",\n        str(Path(CURRENT.executable).parent / f\"e{suffixed_name}\"),\n    )\n    assert CURRENT.satisfies(spec, impl_must_match=True) is False\n\n\n@pytest.mark.skipif(IS_PYPY, reason=\"setuptools distutils patching does not work\")\ndef test_py_info_setuptools():\n    from setuptools.dist import Distribution  # noqa: PLC0415\n\n    assert Distribution\n    PythonInfo()\n\n\n@pytest.mark.usefixtures(\"_skip_if_test_in_system\")\ndef test_py_info_to_system_raises(session_app_data, mocker, caplog):\n    caplog.set_level(logging.DEBUG)\n    mocker.patch.object(PythonInfo, \"_find_possible_folders\", return_value=[])\n    result = PythonInfo.from_exe(sys.executable, app_data=session_app_data, raise_on_error=False)\n    assert result is None\n    log = caplog.records[-1]\n    assert log.levelno == logging.INFO\n    expected = f\"ignore {sys.executable} due cannot resolve system due to RuntimeError('failed to detect \"\n    assert expected in log.message\n\n\ndef _stringify_schemes_dict(schemes_dict):\n    \"\"\"\n    Since this file has from __future__ import unicode_literals, we manually cast all values of mocked install_schemes\n    to str() as the original schemes are not unicode on Python 2.\n    \"\"\"\n    return {str(n): {str(k): str(v) for k, v in s.items()} for n, s in schemes_dict.items()}\n\n\ndef test_custom_venv_install_scheme_is_prefered(mocker):\n    # The paths in this test are Fedora paths, but we set them for nt as well, so the test also works on Windows,\n    # despite the actual values are nonsense there.\n    # Values were simplified to be compatible with all the supported Python versions.\n    default_scheme = {\n        \"stdlib\": \"{base}/lib/python{py_version_short}\",\n        \"platstdlib\": \"{platbase}/lib/python{py_version_short}\",\n        \"purelib\": \"{base}/local/lib/python{py_version_short}/site-packages\",\n        \"platlib\": \"{platbase}/local/lib/python{py_version_short}/site-packages\",\n        \"include\": \"{base}/include/python{py_version_short}\",\n        \"platinclude\": \"{platbase}/include/python{py_version_short}\",\n        \"scripts\": \"{base}/local/bin\",\n        \"data\": \"{base}/local\",\n    }\n    venv_scheme = {key: path.replace(\"local\", \"\") for key, path in default_scheme.items()}\n    sysconfig_install_schemes = {\n        \"posix_prefix\": default_scheme,\n        \"nt\": default_scheme,\n        \"pypy\": default_scheme,\n        \"pypy_nt\": default_scheme,\n        \"venv\": venv_scheme,\n    }\n    if getattr(sysconfig, \"get_preferred_scheme\", None):\n        # define the prefix as sysconfig.get_preferred_scheme did before 3.11\n        sysconfig_install_schemes[\"nt\" if os.name == \"nt\" else \"posix_prefix\"] = default_scheme\n\n    # On Python < 3.10, the distutils schemes are not derived from sysconfig schemes\n    # So we mock them as well to assert the custom \"venv\" install scheme has priority\n    distutils_scheme = {\n        \"purelib\": \"$base/local/lib/python$py_version_short/site-packages\",\n        \"platlib\": \"$platbase/local/lib/python$py_version_short/site-packages\",\n        \"headers\": \"$base/include/python$py_version_short/$dist_name\",\n        \"scripts\": \"$base/local/bin\",\n        \"data\": \"$base/local\",\n    }\n    distutils_schemes = {\n        \"unix_prefix\": distutils_scheme,\n        \"nt\": distutils_scheme,\n    }\n\n    # We need to mock distutils first, so they don't see the mocked sysconfig,\n    # if imported for the first time.\n    # That can happen if the actual interpreter has the \"venv\" INSTALL_SCHEME\n    # and hence this is the first time we are touching distutils in this process.\n    # If distutils saw our mocked sysconfig INSTALL_SCHEMES, we would need\n    # to define all install schemes.\n    mocker.patch(\"distutils.command.install.INSTALL_SCHEMES\", distutils_schemes)\n    mocker.patch(\"sysconfig._INSTALL_SCHEMES\", sysconfig_install_schemes)\n\n    pyinfo = PythonInfo()\n    pyver = f\"{pyinfo.version_info.major}.{pyinfo.version_info.minor}\"\n    assert pyinfo.install_path(\"scripts\") == \"bin\"\n    assert pyinfo.install_path(\"purelib\").replace(os.sep, \"/\") == f\"lib/python{pyver}/site-packages\"\n\n\n@pytest.mark.skipif(not (os.name == \"posix\" and sys.version_info[:2] >= (3, 11)), reason=\"POSIX 3.11+ specific\")\ndef test_fallback_existent_system_executable(mocker):\n    current = PythonInfo()\n    # Posix may execute a \"python\" out of a venv but try to set the base_executable\n    # to \"python\" out of the system installation path. PEP 394 informs distributions\n    # that \"python\" is not required and the standard `make install` does not provide one\n\n    # Falsify some data to look like we're in a venv\n    current.prefix = current.exec_prefix = \"/tmp/tmp.izZNCyINRj/venv\"  # noqa: S108\n    current.executable = current.original_executable = os.path.join(current.prefix, \"bin/python\")\n\n    # Since we don't know if the distribution we're on provides python, use a binary that should not exist\n    mocker.patch.object(sys, \"_base_executable\", os.path.join(os.path.dirname(current.system_executable), \"idontexist\"))\n    mocker.patch.object(sys, \"executable\", current.executable)\n\n    # ensure it falls back to an alternate binary name that exists\n    current._fast_get_system_executable()  # noqa: SLF001\n    assert os.path.basename(current.system_executable) in [\n        f\"python{v}\" for v in (current.version_info.major, f\"{current.version_info.major}.{current.version_info.minor}\")\n    ]\n    assert os.path.exists(current.system_executable)\n\n\n@pytest.mark.skipif(sys.version_info[:2] != (3, 10), reason=\"3.10 specific\")\ndef test_uses_posix_prefix_on_debian_3_10_without_venv(mocker):\n    # this is taken from ubuntu 22.04 /usr/lib/python3.10/sysconfig.py\n    sysconfig_install_schemes = {\n        \"posix_prefix\": {\n            \"stdlib\": \"{installed_base}/{platlibdir}/python{py_version_short}\",\n            \"platstdlib\": \"{platbase}/{platlibdir}/python{py_version_short}\",\n            \"purelib\": \"{base}/lib/python{py_version_short}/site-packages\",\n            \"platlib\": \"{platbase}/{platlibdir}/python{py_version_short}/site-packages\",\n            \"include\": \"{installed_base}/include/python{py_version_short}{abiflags}\",\n            \"platinclude\": \"{installed_platbase}/include/python{py_version_short}{abiflags}\",\n            \"scripts\": \"{base}/bin\",\n            \"data\": \"{base}\",\n        },\n        \"posix_home\": {\n            \"stdlib\": \"{installed_base}/lib/python\",\n            \"platstdlib\": \"{base}/lib/python\",\n            \"purelib\": \"{base}/lib/python\",\n            \"platlib\": \"{base}/lib/python\",\n            \"include\": \"{installed_base}/include/python\",\n            \"platinclude\": \"{installed_base}/include/python\",\n            \"scripts\": \"{base}/bin\",\n            \"data\": \"{base}\",\n        },\n        \"nt\": {\n            \"stdlib\": \"{installed_base}/Lib\",\n            \"platstdlib\": \"{base}/Lib\",\n            \"purelib\": \"{base}/Lib/site-packages\",\n            \"platlib\": \"{base}/Lib/site-packages\",\n            \"include\": \"{installed_base}/Include\",\n            \"platinclude\": \"{installed_base}/Include\",\n            \"scripts\": \"{base}/Scripts\",\n            \"data\": \"{base}\",\n        },\n        \"deb_system\": {\n            \"stdlib\": \"{installed_base}/{platlibdir}/python{py_version_short}\",\n            \"platstdlib\": \"{platbase}/{platlibdir}/python{py_version_short}\",\n            \"purelib\": \"{base}/lib/python3/dist-packages\",\n            \"platlib\": \"{platbase}/{platlibdir}/python3/dist-packages\",\n            \"include\": \"{installed_base}/include/python{py_version_short}{abiflags}\",\n            \"platinclude\": \"{installed_platbase}/include/python{py_version_short}{abiflags}\",\n            \"scripts\": \"{base}/bin\",\n            \"data\": \"{base}\",\n        },\n        \"posix_local\": {\n            \"stdlib\": \"{installed_base}/{platlibdir}/python{py_version_short}\",\n            \"platstdlib\": \"{platbase}/{platlibdir}/python{py_version_short}\",\n            \"purelib\": \"{base}/local/lib/python{py_version_short}/dist-packages\",\n            \"platlib\": \"{platbase}/local/lib/python{py_version_short}/dist-packages\",\n            \"include\": \"{installed_base}/local/include/python{py_version_short}{abiflags}\",\n            \"platinclude\": \"{installed_platbase}/local/include/python{py_version_short}{abiflags}\",\n            \"scripts\": \"{base}/local/bin\",\n            \"data\": \"{base}\",\n        },\n    }\n    # reset the default in case we're on a system which doesn't have this problem\n    sysconfig_get_path = functools.partial(sysconfig.get_path, scheme=\"posix_local\")\n\n    # make it look like python3-distutils is not available\n    mocker.patch.dict(sys.modules, {\"distutils.command\": None})\n    mocker.patch(\"sysconfig._INSTALL_SCHEMES\", sysconfig_install_schemes)\n    mocker.patch(\"sysconfig.get_path\", sysconfig_get_path)\n    mocker.patch(\"sysconfig.get_default_scheme\", return_value=\"posix_local\")\n\n    pyinfo = PythonInfo()\n    pyver = f\"{pyinfo.version_info.major}.{pyinfo.version_info.minor}\"\n    assert pyinfo.install_path(\"scripts\") == \"bin\"\n    assert pyinfo.install_path(\"purelib\").replace(os.sep, \"/\") == f\"lib/python{pyver}/site-packages\"\n", "tests/unit/activation/test_fish.py": "from __future__ import annotations\n\nimport pytest\n\nfrom virtualenv.activation import FishActivator\nfrom virtualenv.info import IS_WIN\n\n\n@pytest.mark.skipif(IS_WIN, reason=\"we have not setup fish in CI yet\")\ndef test_fish(activation_tester_class, activation_tester, monkeypatch, tmp_path):\n    monkeypatch.setenv(\"HOME\", str(tmp_path))\n    fish_conf_dir = tmp_path / \".config\" / \"fish\"\n    fish_conf_dir.mkdir(parents=True)\n    (fish_conf_dir / \"config.fish\").write_text(\"\", encoding=\"utf-8\")\n\n    class Fish(activation_tester_class):\n        def __init__(self, session) -> None:\n            super().__init__(FishActivator, session, \"fish\", \"activate.fish\", \"fish\")\n\n        def print_prompt(self):\n            return \"fish_prompt\"\n\n    activation_tester(Fish)\n", "tests/unit/activation/test_activation_support.py": "from __future__ import annotations\n\nfrom argparse import Namespace\n\nimport pytest\n\nfrom virtualenv.activation import (\n    BashActivator,\n    BatchActivator,\n    CShellActivator,\n    FishActivator,\n    PowerShellActivator,\n    PythonActivator,\n)\nfrom virtualenv.discovery.py_info import PythonInfo\n\n\n@pytest.mark.parametrize(\n    \"activator_class\",\n    [BatchActivator, PowerShellActivator, PythonActivator, BashActivator, FishActivator],\n)\ndef test_activator_support_windows(mocker, activator_class):\n    activator = activator_class(Namespace(prompt=None))\n\n    interpreter = mocker.Mock(spec=PythonInfo)\n    interpreter.os = \"nt\"\n    assert activator.supports(interpreter)\n\n\n@pytest.mark.parametrize(\"activator_class\", [CShellActivator])\ndef test_activator_no_support_windows(mocker, activator_class):\n    activator = activator_class(Namespace(prompt=None))\n\n    interpreter = mocker.Mock(spec=PythonInfo)\n    interpreter.os = \"nt\"\n    assert not activator.supports(interpreter)\n\n\n@pytest.mark.parametrize(\n    \"activator_class\",\n    [BashActivator, CShellActivator, FishActivator, PowerShellActivator, PythonActivator],\n)\ndef test_activator_support_posix(mocker, activator_class):\n    activator = activator_class(Namespace(prompt=None))\n    interpreter = mocker.Mock(spec=PythonInfo)\n    interpreter.os = \"posix\"\n    assert activator.supports(interpreter)\n\n\n@pytest.mark.parametrize(\"activator_class\", [BatchActivator])\ndef test_activator_no_support_posix(mocker, activator_class):\n    activator = activator_class(Namespace(prompt=None))\n    interpreter = mocker.Mock(spec=PythonInfo)\n    interpreter.os = \"posix\"\n    assert not activator.supports(interpreter)\n", "tests/unit/activation/test_powershell.py": "from __future__ import annotations\n\nimport sys\nfrom shlex import quote\n\nimport pytest\n\nfrom virtualenv.activation import PowerShellActivator\n\n\n@pytest.mark.slow()\ndef test_powershell(activation_tester_class, activation_tester, monkeypatch):\n    monkeypatch.setenv(\"TERM\", \"xterm\")\n\n    class PowerShell(activation_tester_class):\n        def __init__(self, session) -> None:\n            cmd = \"powershell.exe\" if sys.platform == \"win32\" else \"pwsh\"\n            super().__init__(PowerShellActivator, session, cmd, \"activate.ps1\", \"ps1\")\n            self._version_cmd = [cmd, \"-c\", \"$PSVersionTable\"]\n            self._invoke_script = [cmd, \"-ExecutionPolicy\", \"ByPass\", \"-File\"]\n            self.activate_cmd = \".\"\n            self.script_encoding = \"utf-8-sig\"\n\n        def quote(self, s):\n            \"\"\"powershell double quote needed for quotes within single quotes\"\"\"\n            text = quote(s)\n            return text.replace('\"', '\"\"') if sys.platform == \"win32\" else text\n\n        def _get_test_lines(self, activate_script):\n            return super()._get_test_lines(activate_script)\n\n        def invoke_script(self):\n            return [self.cmd, \"-File\"]\n\n        def print_prompt(self):\n            return \"prompt\"\n\n    activation_tester(PowerShell)\n", "tests/unit/activation/test_bash.py": "from __future__ import annotations\n\nimport pytest\n\nfrom virtualenv.activation import BashActivator\nfrom virtualenv.info import IS_WIN\n\n\n@pytest.mark.skipif(IS_WIN, reason=\"Github Actions ships with WSL bash\")\n@pytest.mark.parametrize(\"hashing_enabled\", [True, False])\ndef test_bash(raise_on_non_source_class, hashing_enabled, activation_tester):\n    class Bash(raise_on_non_source_class):\n        def __init__(self, session) -> None:\n            super().__init__(\n                BashActivator,\n                session,\n                \"bash\",\n                \"activate\",\n                \"sh\",\n                \"You must source this script: $ source \",\n            )\n            self.deactivate += \" || exit 1\"\n            self._invoke_script.append(\"-h\" if hashing_enabled else \"+h\")\n\n        def activate_call(self, script):\n            return super().activate_call(script) + \" || exit 1\"\n\n        def print_prompt(self):\n            return self.print_os_env_var(\"PS1\")\n\n    activation_tester(Bash)\n", "tests/unit/activation/test_csh.py": "from __future__ import annotations\n\nfrom virtualenv.activation import CShellActivator\n\n\ndef test_csh(activation_tester_class, activation_tester):\n    class Csh(activation_tester_class):\n        def __init__(self, session) -> None:\n            super().__init__(CShellActivator, session, \"csh\", \"activate.csh\", \"csh\")\n\n        def print_prompt(self):\n            # Original csh doesn't print the last newline,\n            # breaking the test; hence the trailing echo.\n            return \"echo 'source \\\"$VIRTUAL_ENV/bin/activate.csh\\\"; echo $prompt' | csh -i ; echo\"\n\n    activation_tester(Csh)\n", "tests/unit/activation/test_batch.py": "from __future__ import annotations\n\nfrom shlex import quote\n\nimport pytest\n\nfrom virtualenv.activation import BatchActivator\n\n\n@pytest.mark.usefixtures(\"activation_python\")\ndef test_batch(activation_tester_class, activation_tester, tmp_path):\n    version_script = tmp_path / \"version.bat\"\n    version_script.write_text(\"ver\", encoding=\"utf-8\")\n\n    class Batch(activation_tester_class):\n        def __init__(self, session) -> None:\n            super().__init__(BatchActivator, session, None, \"activate.bat\", \"bat\")\n            self._version_cmd = [str(version_script)]\n            self._invoke_script = []\n            self.deactivate = \"call deactivate\"\n            self.activate_cmd = \"call\"\n            self.pydoc_call = f\"call {self.pydoc_call}\"\n            self.unix_line_ending = False\n\n        def _get_test_lines(self, activate_script):\n            return [\"@echo off\", *super()._get_test_lines(activate_script)]\n\n        def quote(self, s):\n            \"\"\"double quotes needs to be single, and single need to be double\"\"\"\n            return \"\".join((\"'\" if c == '\"' else ('\"' if c == \"'\" else c)) for c in quote(s))\n\n        def print_prompt(self):\n            return \"echo %PROMPT%\"\n\n    activation_tester(Batch)\n", "tests/unit/activation/conftest.py": "from __future__ import annotations\n\nimport os\nimport re\nimport subprocess\nimport sys\nfrom os.path import dirname, normcase\nfrom pathlib import Path\nfrom shlex import quote\nfrom subprocess import Popen\n\nimport pytest\n\nfrom virtualenv.run import cli_run\n\n\nclass ActivationTester:\n    def __init__(self, of_class, session, cmd, activate_script, extension) -> None:  # noqa: PLR0913\n        self.of_class = of_class\n        self._creator = session.creator\n        self._version_cmd = [cmd, \"--version\"]\n        self._invoke_script = [cmd]\n        self.activate_script = activate_script\n        self.extension = extension\n        self.activate_cmd = \"source\"\n        self.deactivate = \"deactivate\"\n        self.pydoc_call = \"pydoc -w pydoc_test\"\n        self.script_encoding = \"utf-8\"\n        self._version = None\n        self.unix_line_ending = True\n\n    def get_version(self, raise_on_fail):\n        if self._version is None:\n            # locally we disable, so that contributors don't need to have everything setup\n            try:\n                process = Popen(\n                    self._version_cmd,\n                    universal_newlines=True,\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                    encoding=\"utf-8\",\n                )\n                out, err = process.communicate()\n            except Exception as exception:\n                self._version = exception\n                if raise_on_fail:\n                    raise\n                return RuntimeError(f\"{self} is not available due {exception}\")\n            else:\n                result = out or err\n                self._version = result\n                return result\n        return self._version\n\n    def __repr__(self) -> str:\n        return (\n            f\"{self.__class__.__name__}(\\nversion={self._version!r},\\ncreator={self._creator},\\n\"\n            f\"interpreter={self._creator.interpreter})\"\n        )\n\n    def __call__(self, monkeypatch, tmp_path):\n        activate_script = self._creator.bin_dir / self.activate_script\n\n        # check line endings are correct type\n        script_content = activate_script.read_bytes()\n        for line in script_content.split(b\"\\n\")[:-1]:\n            if self.unix_line_ending:\n                assert line == b\"\" or line[-1] != 13, script_content.decode(\"utf-8\")\n            else:\n                assert line[-1] == 13, script_content.decode(\"utf-8\")\n\n        test_script = self._generate_test_script(activate_script, tmp_path)\n        monkeypatch.chdir(tmp_path)\n\n        monkeypatch.delenv(\"VIRTUAL_ENV\", raising=False)\n        invoke, env = [*self._invoke_script, str(test_script)], self.env(tmp_path)\n\n        try:\n            process = Popen(invoke, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, env=env)\n            raw_, _ = process.communicate()\n            raw = raw_.decode()\n            assert process.returncode == 0, raw\n        except subprocess.CalledProcessError as exception:\n            output = exception.output + exception.stderr\n            assert not exception.returncode, output  # noqa: PT017\n            return None\n\n        out = re.sub(r\"pydev debugger: process \\d+ is connecting\\n\\n\", \"\", raw, flags=re.MULTILINE).strip().splitlines()\n        self.assert_output(out, raw, tmp_path)\n        return env, activate_script\n\n    def non_source_activate(self, activate_script):\n        return [*self._invoke_script, str(activate_script)]\n\n    def env(self, tmp_path):  # noqa: ARG002\n        env = os.environ.copy()\n        # add the current python executable folder to the path so we already have another python on the path\n        # also keep the path so the shells (fish, bash, etc can be discovered)\n        env[\"PYTHONIOENCODING\"] = \"utf-8\"\n        env[\"PATH\"] = os.pathsep.join([dirname(sys.executable), *env.get(\"PATH\", \"\").split(os.pathsep)])\n        # clear up some environment variables so they don't affect the tests\n        for key in [k for k in env if k.startswith((\"_OLD\", \"VIRTUALENV_\"))]:\n            del env[key]\n        return env\n\n    def _generate_test_script(self, activate_script, tmp_path):\n        commands = self._get_test_lines(activate_script)\n        script = os.linesep.join(commands)\n        test_script = tmp_path / f\"script.{self.extension}\"\n        with test_script.open(\"wb\") as file_handler:\n            file_handler.write(script.encode(self.script_encoding))\n        return test_script\n\n    def _get_test_lines(self, activate_script):\n        return [\n            self.print_python_exe(),\n            self.print_os_env_var(\"VIRTUAL_ENV\"),\n            self.print_os_env_var(\"VIRTUAL_ENV_PROMPT\"),\n            self.activate_call(activate_script),\n            self.print_python_exe(),\n            self.print_os_env_var(\"VIRTUAL_ENV\"),\n            self.print_os_env_var(\"VIRTUAL_ENV_PROMPT\"),\n            self.print_prompt(),\n            # \\\\ loads documentation from the virtualenv site packages\n            self.pydoc_call,\n            self.deactivate,\n            self.print_python_exe(),\n            self.print_os_env_var(\"VIRTUAL_ENV\"),\n            self.print_os_env_var(\"VIRTUAL_ENV_PROMPT\"),\n            \"\",  # just finish with an empty new line\n        ]\n\n    def assert_output(self, out, raw, tmp_path):\n        # pre-activation\n        assert out[0], raw\n        assert out[1] == \"None\", raw\n        assert out[2] == \"None\", raw\n        # post-activation\n        expected = self._creator.exe.parent / os.path.basename(sys.executable)\n        assert self.norm_path(out[3]) == self.norm_path(expected), raw\n        assert self.norm_path(out[4]) == self.norm_path(self._creator.dest).replace(\"\\\\\\\\\", \"\\\\\"), raw\n        assert out[5] == self._creator.env_name\n        # Some attempts to test the prompt output print more than 1 line.\n        # So we need to check if the prompt exists on any of them.\n        prompt_text = f\"({self._creator.env_name}) \"\n        assert any(prompt_text in line for line in out[6:-4]), raw\n\n        assert out[-4] == \"wrote pydoc_test.html\", raw\n        content = tmp_path / \"pydoc_test.html\"\n        assert content.exists(), raw\n        # post deactivation, same as before\n        assert out[-3] == out[0], raw\n        assert out[-2] == \"None\", raw\n        assert out[-1] == \"None\", raw\n\n    def quote(self, s):\n        return quote(s)\n\n    def python_cmd(self, cmd):\n        return f\"{os.path.basename(sys.executable)} -c {self.quote(cmd)}\"\n\n    def print_python_exe(self):\n        return self.python_cmd(\"import sys; print(sys.executable)\")\n\n    def print_os_env_var(self, var):\n        val = f'\"{var}\"'\n        return self.python_cmd(f\"import os; import sys; v = os.environ.get({val}); print(v)\")\n\n    def print_prompt(self):\n        return NotImplemented\n\n    def activate_call(self, script):\n        cmd = self.quote(str(self.activate_cmd))\n        scr = self.quote(str(script))\n        return f\"{cmd} {scr}\".strip()\n\n    @staticmethod\n    def norm_path(path):\n        # python may return Windows short paths, normalize\n        if not isinstance(path, Path):\n            path = Path(path)\n        path = str(path.resolve())\n        if sys.platform != \"win32\":\n            result = path\n        else:\n            from ctypes import create_unicode_buffer, windll  # noqa: PLC0415\n\n            buffer_cont = create_unicode_buffer(256)\n            get_long_path_name = windll.kernel32.GetLongPathNameW\n            get_long_path_name(str(path), buffer_cont, 256)\n            result = buffer_cont.value or path\n        return normcase(result)\n\n\nclass RaiseOnNonSourceCall(ActivationTester):\n    def __init__(  # noqa: PLR0913\n        self,\n        of_class,\n        session,\n        cmd,\n        activate_script,\n        extension,\n        non_source_fail_message,\n    ) -> None:\n        super().__init__(of_class, session, cmd, activate_script, extension)\n        self.non_source_fail_message = non_source_fail_message\n\n    def __call__(self, monkeypatch, tmp_path):\n        env, activate_script = super().__call__(monkeypatch, tmp_path)\n        process = Popen(\n            self.non_source_activate(activate_script),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            env=env,\n        )\n        _out, _err = process.communicate()\n        err = _err.decode(\"utf-8\")\n        assert process.returncode\n        assert self.non_source_fail_message in err\n\n\n@pytest.fixture(scope=\"session\")\ndef activation_tester_class():\n    return ActivationTester\n\n\n@pytest.fixture(scope=\"session\")\ndef raise_on_non_source_class():\n    return RaiseOnNonSourceCall\n\n\n@pytest.fixture(scope=\"session\", params=[True, False], ids=[\"with_prompt\", \"no_prompt\"])\ndef activation_python(request, tmp_path_factory, special_char_name, current_fastest):\n    dest = os.path.join(str(tmp_path_factory.mktemp(\"activation-tester-env\")), special_char_name)\n    cmd = [\"--without-pip\", dest, \"--creator\", current_fastest, \"-vv\", \"--no-periodic-update\"]\n    if request.param:\n        cmd += [\"--prompt\", special_char_name]\n    session = cli_run(cmd)\n    pydoc_test = session.creator.purelib / \"pydoc_test.py\"\n    pydoc_test.write_text('\"\"\"This is pydoc_test.py\"\"\"', encoding=\"utf-8\")\n    return session\n\n\n@pytest.fixture()\ndef activation_tester(activation_python, monkeypatch, tmp_path, is_inside_ci):\n    def _tester(tester_class):\n        tester = tester_class(activation_python)\n        if not tester.of_class.supports(activation_python.creator.interpreter):\n            pytest.skip(f\"{tester.of_class.__name__} not supported\")\n        version = tester.get_version(raise_on_fail=is_inside_ci)\n        if not isinstance(version, str):\n            pytest.skip(reason=str(version))\n        return tester(monkeypatch, tmp_path)\n\n    return _tester\n", "tests/unit/activation/test_activator.py": "from __future__ import annotations\n\nfrom argparse import Namespace\n\nfrom virtualenv.activation.activator import Activator\n\n\ndef test_activator_prompt_cwd(monkeypatch, tmp_path):\n    class FakeActivator(Activator):\n        def generate(self, creator):\n            raise NotImplementedError\n\n    cwd = tmp_path / \"magic\"\n    cwd.mkdir()\n    monkeypatch.chdir(cwd)\n\n    activator = FakeActivator(Namespace(prompt=\".\"))\n    assert activator.flag_prompt == \"magic\"\n", "tests/unit/activation/test_nushell.py": "from __future__ import annotations\n\nfrom shutil import which\n\nfrom virtualenv.activation import NushellActivator\nfrom virtualenv.info import IS_WIN\n\n\ndef test_nushell(activation_tester_class, activation_tester):\n    class Nushell(activation_tester_class):\n        def __init__(self, session) -> None:\n            cmd = which(\"nu\")\n            if cmd is None and IS_WIN:\n                cmd = \"c:\\\\program files\\\\nu\\\\bin\\\\nu.exe\"\n\n            super().__init__(NushellActivator, session, cmd, \"activate.nu\", \"nu\")\n\n            self.activate_cmd = \"overlay use\"\n            self.unix_line_ending = not IS_WIN\n\n        def print_prompt(self):\n            return r\"print $env.VIRTUAL_PREFIX\"\n\n        def activate_call(self, script):\n            # Commands are called without quotes in Nushell\n            cmd = self.activate_cmd\n            scr = self.quote(str(script))\n            return f\"{cmd} {scr}\".strip()\n\n    activation_tester(Nushell)\n", "tests/unit/activation/test_python_activator.py": "from __future__ import annotations\n\nimport os\nimport sys\nfrom ast import literal_eval\nfrom textwrap import dedent\n\nfrom virtualenv.activation import PythonActivator\nfrom virtualenv.info import IS_WIN\n\n\ndef test_python(raise_on_non_source_class, activation_tester):\n    class Python(raise_on_non_source_class):\n        def __init__(self, session) -> None:\n            super().__init__(\n                PythonActivator,\n                session,\n                sys.executable,\n                activate_script=\"activate_this.py\",\n                extension=\"py\",\n                non_source_fail_message=\"You must use import runpy; runpy.run_path(this_file)\",\n            )\n            self.unix_line_ending = not IS_WIN\n\n        def env(self, tmp_path):\n            env = os.environ.copy()\n            env[\"PYTHONIOENCODING\"] = \"utf-8\"\n            for key in (\"VIRTUAL_ENV\", \"PYTHONPATH\"):\n                env.pop(str(key), None)\n            env[\"PATH\"] = os.pathsep.join([str(tmp_path), str(tmp_path / \"other\")])\n            return env\n\n        @staticmethod\n        def _get_test_lines(activate_script):\n            raw = f\"\"\"\n            import os\n            import sys\n            import platform\n            import runpy\n\n            def print_r(value):\n                print(repr(value))\n\n            print_r(os.environ.get(\"VIRTUAL_ENV\"))\n            print_r(os.environ.get(\"VIRTUAL_ENV_PROMPT\"))\n            print_r(os.environ.get(\"PATH\").split(os.pathsep))\n            print_r(sys.path)\n\n            file_at = {str(activate_script)!r}\n            # CPython 2 requires non-ascii path open to be unicode\n            runpy.run_path(file_at)\n            print_r(os.environ.get(\"VIRTUAL_ENV\"))\n            print_r(os.environ.get(\"VIRTUAL_ENV_PROMPT\"))\n            print_r(os.environ.get(\"PATH\").split(os.pathsep))\n            print_r(sys.path)\n\n            import pydoc_test\n            print_r(pydoc_test.__file__)\n            \"\"\"\n            return dedent(raw).splitlines()\n\n        def assert_output(self, out, raw, tmp_path):  # noqa: ARG002\n            out = [literal_eval(i) for i in out]\n            assert out[0] is None  # start with VIRTUAL_ENV None\n            assert out[1] is None  # likewise for VIRTUAL_ENV_PROMPT\n\n            prev_path = out[2]\n            prev_sys_path = out[3]\n            assert out[4] == str(self._creator.dest)  # VIRTUAL_ENV now points to the virtual env folder\n\n            assert out[5] == str(self._creator.env_name)  # VIRTUAL_ENV_PROMPT now has the env name\n\n            new_path = out[6]  # PATH now starts with bin path of current\n            assert ([str(self._creator.bin_dir), *prev_path]) == new_path\n\n            # sys path contains the site package at its start\n            new_sys_path = out[7]\n\n            new_lib_paths = {str(i) for i in self._creator.libs}\n            assert prev_sys_path == new_sys_path[len(new_lib_paths) :]\n            assert new_lib_paths == set(new_sys_path[: len(new_lib_paths)])\n\n            # manage to import from activate site package\n            dest = self.norm_path(self._creator.purelib / \"pydoc_test.py\")\n            found = self.norm_path(out[8])\n            assert found.startswith(dest)\n\n        def non_source_activate(self, activate_script):\n            act = str(activate_script)\n            return [*self._invoke_script, \"-c\", f\"exec(open({act!r}).read())\"]\n\n    activation_tester(Python)\n", "tests/unit/create/test_creator.py": "from __future__ import annotations\n\nimport ast\nimport difflib\nimport gc\nimport json\nimport logging\nimport os\nimport shutil\nimport site\nimport stat\nimport subprocess\nimport sys\nimport zipfile\nfrom collections import OrderedDict\nfrom itertools import product\nfrom pathlib import Path\nfrom stat import S_IREAD, S_IRGRP, S_IROTH\nfrom textwrap import dedent\nfrom threading import Thread\n\nimport pytest\n\nfrom virtualenv.__main__ import run, run_with_catch\nfrom virtualenv.create.creator import DEBUG_SCRIPT, Creator, get_env_debug_info\nfrom virtualenv.create.pyenv_cfg import PyEnvCfg\nfrom virtualenv.create.via_global_ref.builtin.cpython.common import is_macos_brew\nfrom virtualenv.create.via_global_ref.builtin.cpython.cpython3 import CPython3Posix\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.info import IS_PYPY, IS_WIN, fs_is_case_sensitive\nfrom virtualenv.run import cli_run, session_via_cli\n\nCURRENT = PythonInfo.current_system()\n\n\ndef test_os_path_sep_not_allowed(tmp_path, capsys):\n    target = str(tmp_path / f\"a{os.pathsep}b\")\n    err = _non_success_exit_code(capsys, target)\n    msg = (\n        f\"destination {target!r} must not contain the path separator ({os.pathsep})\"\n        f\" as this would break the activation scripts\"\n    )\n    assert msg in err, err\n\n\ndef _non_success_exit_code(capsys, target):\n    with pytest.raises(SystemExit) as context:\n        run_with_catch(args=[target])\n    assert context.value.code != 0\n    out, err = capsys.readouterr()\n    assert \"SystemExit: \" in out\n    return err\n\n\ndef test_destination_exists_file(tmp_path, capsys):\n    target = tmp_path / \"out\"\n    target.write_text(\"\", encoding=\"utf-8\")\n    err = _non_success_exit_code(capsys, str(target))\n    msg = f\"the destination {target!s} already exists and is a file\"\n    assert msg in err, err\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"Windows only applies R/O to files\")\ndef test_destination_not_write_able(tmp_path, capsys):\n    if hasattr(os, \"geteuid\") and os.geteuid() == 0:\n        pytest.skip(\"no way to check permission restriction when running under root\")\n\n    target = tmp_path\n    prev_mod = target.stat().st_mode\n    target.chmod(S_IREAD | S_IRGRP | S_IROTH)\n    try:\n        err = _non_success_exit_code(capsys, str(target))\n        msg = f\"the destination . is not write-able at {target!s}\"\n        assert msg in err, err\n    finally:\n        target.chmod(prev_mod)\n\n\ndef cleanup_sys_path(paths):\n    from virtualenv.create.creator import HERE  # noqa: PLC0415\n\n    paths = [p.resolve() for p in (Path(os.path.abspath(i)) for i in paths) if p.exists()]\n    to_remove = [Path(HERE)]\n    if os.environ.get(\"PYCHARM_HELPERS_DIR\"):\n        to_remove.extend((Path(os.environ[\"PYCHARM_HELPERS_DIR\"]).parent, Path(os.path.expanduser(\"~\")) / \".PyCharm\"))\n    return [i for i in paths if not any(str(i).startswith(str(t)) for t in to_remove)]\n\n\n@pytest.fixture(scope=\"session\")\ndef system(session_app_data):\n    return get_env_debug_info(Path(CURRENT.system_executable), DEBUG_SCRIPT, session_app_data, os.environ)\n\n\nCURRENT_CREATORS = [i for i in CURRENT.creators().key_to_class if i != \"builtin\"]\nCREATE_METHODS = []\nfor k, v in CURRENT.creators().key_to_meta.items():\n    if k in CURRENT_CREATORS:\n        if v.can_copy:\n            if k == \"venv\" and CURRENT.implementation == \"PyPy\" and CURRENT.pypy_version_info >= [7, 3, 13]:\n                continue  # https://foss.heptapod.net/pypy/pypy/-/issues/4019\n            CREATE_METHODS.append((k, \"copies\"))\n        if v.can_symlink:\n            CREATE_METHODS.append((k, \"symlinks\"))\n\n\n@pytest.mark.parametrize(\n    (\"creator\", \"isolated\"),\n    [pytest.param(*i, id=f\"{'-'.join(i[0])}-{i[1]}\") for i in product(CREATE_METHODS, [\"isolated\", \"global\"])],\n)\ndef test_create_no_seed(  # noqa: C901, PLR0912, PLR0913, PLR0915\n    python,\n    creator,\n    isolated,\n    system,\n    coverage_env,\n    special_name_dir,\n):\n    dest = special_name_dir\n    creator_key, method = creator\n    cmd = [\n        \"-v\",\n        \"-v\",\n        \"-p\",\n        str(python),\n        str(dest),\n        \"--without-pip\",\n        \"--activators\",\n        \"\",\n        \"--creator\",\n        creator_key,\n        f\"--{method}\",\n    ]\n    if isolated == \"global\":\n        cmd.append(\"--system-site-packages\")\n    result = cli_run(cmd)\n    creator = result.creator\n    coverage_env()\n    if IS_PYPY:\n        # pypy cleans up file descriptors periodically so our (many) subprocess calls impact file descriptor limits\n        # force a close of these on system where the limit is low-ish (e.g. MacOS 256)\n        gc.collect()\n    purelib = creator.purelib\n    patch_files = {purelib / f\"{'_virtualenv'}.{i}\" for i in (\"py\", \"pyc\", \"pth\")}\n    patch_files.add(purelib / \"__pycache__\")\n    content = set(creator.purelib.iterdir()) - patch_files\n    assert not content, \"\\n\".join(str(i) for i in content)\n    assert creator.env_name == str(dest.name)\n    debug = creator.debug\n    assert \"exception\" not in debug, f\"{debug.get('exception')}\\n{debug.get('out')}\\n{debug.get('err')}\"\n    sys_path = cleanup_sys_path(debug[\"sys\"][\"path\"])\n    system_sys_path = cleanup_sys_path(system[\"sys\"][\"path\"])\n    our_paths = set(sys_path) - set(system_sys_path)\n    our_paths_repr = \"\\n\".join(repr(i) for i in our_paths)\n\n    # ensure we have at least one extra path added\n    assert len(our_paths) >= 1, our_paths_repr\n    # ensure all additional paths are related to the virtual environment\n    for path in our_paths:\n        msg = \"\\n\".join(str(p) for p in system_sys_path)\n        msg = f\"\\n{path!s}\\ndoes not start with {dest!s}\\nhas:\\n{msg}\"\n        assert str(path).startswith(str(dest)), msg\n    # ensure there's at least a site-packages folder as part of the virtual environment added\n    assert any(p for p in our_paths if p.parts[-1] == \"site-packages\"), our_paths_repr\n\n    # ensure the global site package is added or not, depending on flag\n    global_sys_path = system_sys_path[-1]\n    if isolated == \"isolated\":\n        msg = \"\\n\".join(str(j) for j in sys_path)\n        msg = f\"global sys path {global_sys_path!s} is in virtual environment sys path:\\n{msg}\"\n        assert global_sys_path not in sys_path, msg\n    else:\n        common = []\n        for left, right in zip(reversed(system_sys_path), reversed(sys_path)):\n            if left == right:\n                common.append(left)\n            else:\n                break\n\n        def list_to_str(iterable):\n            return [str(i) for i in iterable]\n\n        assert common, \"\\n\".join(difflib.unified_diff(list_to_str(sys_path), list_to_str(system_sys_path)))\n\n    # test that the python executables in the bin directory are either:\n    # - files\n    # - absolute symlinks outside of the venv\n    # - relative symlinks inside of the venv\n    if sys.platform == \"win32\":\n        exes = (\"python.exe\",)\n    else:\n        exes = (\"python\", f\"python{sys.version_info.major}\", f\"python{sys.version_info.major}.{sys.version_info.minor}\")\n        if creator_key == \"venv\":\n            # for venv some repackaging does not includes the pythonx.y\n            exes = exes[:-1]\n    for exe in exes:\n        exe_path = creator.bin_dir / exe\n        assert exe_path.exists(), \"\\n\".join(str(i) for i in creator.bin_dir.iterdir())\n        if not exe_path.is_symlink():  # option 1: a real file\n            continue  # it was a file\n        link = os.readlink(str(exe_path))\n        if not os.path.isabs(link):  # option 2: a relative symlink\n            continue\n        # option 3: an absolute symlink, should point outside the venv\n        assert not link.startswith(str(creator.dest))\n\n    if IS_WIN and CURRENT.implementation == \"CPython\":\n        python_w = creator.exe.parent / \"pythonw.exe\"\n        assert python_w.exists()\n        assert python_w.read_bytes() != creator.exe.read_bytes()\n\n    if CPython3Posix.pyvenv_launch_patch_active(PythonInfo.from_exe(python)) and creator_key != \"venv\":\n        result = subprocess.check_output(\n            [str(creator.exe), \"-c\", 'import os; print(os.environ.get(\"__PYVENV_LAUNCHER__\"))'],\n            text=True,\n        ).strip()\n        assert result == \"None\"\n\n    git_ignore = (dest / \".gitignore\").read_text(encoding=\"utf-8\")\n    if creator_key == \"venv\" and sys.version_info >= (3, 13):\n        comment = \"# Created by venv; see https://docs.python.org/3/library/venv.html\"\n    else:\n        comment = \"# created by virtualenv automatically\"\n    assert git_ignore.splitlines() == [comment, \"*\"]\n\n\ndef test_create_vcs_ignore_exists(tmp_path):\n    git_ignore = tmp_path / \".gitignore\"\n    git_ignore.write_text(\"magic\", encoding=\"utf-8\")\n    cli_run([str(tmp_path), \"--without-pip\", \"--activators\", \"\"])\n    assert git_ignore.read_text(encoding=\"utf-8\") == \"magic\"\n\n\ndef test_create_vcs_ignore_override(tmp_path):\n    git_ignore = tmp_path / \".gitignore\"\n    cli_run([str(tmp_path), \"--without-pip\", \"--no-vcs-ignore\", \"--activators\", \"\"])\n    assert not git_ignore.exists()\n\n\ndef test_create_vcs_ignore_exists_override(tmp_path):\n    git_ignore = tmp_path / \".gitignore\"\n    git_ignore.write_text(\"magic\", encoding=\"utf-8\")\n    cli_run([str(tmp_path), \"--without-pip\", \"--no-vcs-ignore\", \"--activators\", \"\"])\n    assert git_ignore.read_text(encoding=\"utf-8\") == \"magic\"\n\n\n@pytest.mark.skipif(not CURRENT.has_venv, reason=\"requires interpreter with venv\")\ndef test_venv_fails_not_inline(tmp_path, capsys, mocker):\n    if hasattr(os, \"geteuid\") and os.geteuid() == 0:\n        pytest.skip(\"no way to check permission restriction when running under root\")\n\n    def _session_via_cli(args, options=None, setup_logging=True, env=None):\n        session = session_via_cli(args, options, setup_logging, env)\n        assert session.creator.can_be_inline is False\n        return session\n\n    mocker.patch(\"virtualenv.run.session_via_cli\", side_effect=_session_via_cli)\n    before = tmp_path.stat().st_mode\n    cfg_path = tmp_path / \"pyvenv.cfg\"\n    cfg_path.write_text(\"\", encoding=\"utf-8\")\n    cfg = str(cfg_path)\n    try:\n        os.chmod(cfg, stat.S_IREAD | stat.S_IRGRP | stat.S_IROTH)\n        cmd = [\"-p\", str(CURRENT.executable), str(tmp_path), \"--without-pip\", \"--creator\", \"venv\"]\n        with pytest.raises(SystemExit) as context:\n            run(cmd)\n        assert context.value.code != 0\n    finally:\n        os.chmod(cfg, before)\n    out, err = capsys.readouterr()\n    assert \"subprocess call failed for\" in out, out\n    assert \"Error:\" in err, err\n\n\n@pytest.mark.parametrize(\"creator\", CURRENT_CREATORS)\n@pytest.mark.parametrize(\"clear\", [True, False], ids=[\"clear\", \"no_clear\"])\ndef test_create_clear_resets(tmp_path, creator, clear, caplog):\n    caplog.set_level(logging.DEBUG)\n    if creator == \"venv\" and clear is False:\n        pytest.skip(\"venv without clear might fail\")\n    marker = tmp_path / \"magic\"\n    cmd = [str(tmp_path), \"--seeder\", \"app-data\", \"--without-pip\", \"--creator\", creator, \"-vvv\"]\n    cli_run(cmd)\n\n    marker.write_text(\"\", encoding=\"utf-8\")  # if we a marker file this should be gone on a clear run, remain otherwise\n    assert marker.exists()\n\n    cli_run(cmd + ([\"--clear\"] if clear else []))\n    assert marker.exists() is not clear\n\n\n@pytest.mark.parametrize(\"creator\", CURRENT_CREATORS)\n@pytest.mark.parametrize(\"prompt\", [None, \"magic\"])\ndef test_prompt_set(tmp_path, creator, prompt):\n    cmd = [str(tmp_path), \"--seeder\", \"app-data\", \"--without-pip\", \"--creator\", creator]\n    if prompt is not None:\n        cmd.extend([\"--prompt\", \"magic\"])\n\n    result = cli_run(cmd)\n    actual_prompt = tmp_path.name if prompt is None else prompt\n    cfg = PyEnvCfg.from_file(result.creator.pyenv_cfg.path)\n    if prompt is None:\n        assert \"prompt\" not in cfg\n    elif creator != \"venv\":\n        assert \"prompt\" in cfg, list(cfg.content.keys())\n        assert cfg[\"prompt\"] == actual_prompt\n\n\n@pytest.mark.parametrize(\"creator\", CURRENT_CREATORS)\ndef test_home_path_is_exe_parent(tmp_path, creator):\n    cmd = [str(tmp_path), \"--seeder\", \"app-data\", \"--without-pip\", \"--creator\", creator]\n\n    result = cli_run(cmd)\n    cfg = PyEnvCfg.from_file(result.creator.pyenv_cfg.path)\n\n    # Cannot assume \"home\" path is a specific value as path resolution may change\n    # between versions (symlinks, framework paths, etc) but we can check that a\n    # python executable is present from the configured path per PEP 405\n    if sys.platform == \"win32\":\n        exes = (\"python.exe\",)\n    else:\n        exes = (\n            \"python\",\n            f\"python{sys.version_info.major}\",\n            f\"python{sys.version_info.major}.{sys.version_info.minor}\",\n        )\n\n    assert any(os.path.exists(os.path.join(cfg[\"home\"], exe)) for exe in exes)\n\n\n@pytest.mark.usefixtures(\"temp_app_data\")\ndef test_create_parallel(tmp_path):\n    def create(count):\n        subprocess.check_call(\n            [sys.executable, \"-m\", \"virtualenv\", \"-vvv\", str(tmp_path / f\"venv{count}\"), \"--without-pip\"],\n        )\n\n    threads = [Thread(target=create, args=(i,)) for i in range(1, 4)]\n    for thread in threads:\n        thread.start()\n    for thread in threads:\n        thread.join()\n\n\ndef test_creator_input_passed_is_abs(tmp_path, monkeypatch):\n    monkeypatch.chdir(tmp_path)\n    result = Creator.validate_dest(\"venv\")\n    assert str(result) == str(tmp_path / \"venv\")\n\n\n@pytest.mark.skipif(os.altsep is None, reason=\"OS does not have an altsep\")\ndef test_creator_replaces_altsep_in_dest(tmp_path):\n    dest = str(tmp_path / \"venv{}foobar\")\n    result = Creator.validate_dest(dest.format(os.altsep))\n    assert str(result) == dest.format(os.sep)\n\n\n@pytest.mark.usefixtures(\"current_fastest\")\ndef test_create_long_path(tmp_path):\n    if sys.platform == \"darwin\":\n        max_shebang_length = 512\n    else:\n        max_shebang_length = 127\n    # filenames can be at most 255 long on macOS, so split to to levels\n    count = max_shebang_length - len(str(tmp_path))\n    folder = tmp_path / (\"a\" * (count // 2)) / (\"b\" * (count // 2)) / \"c\"\n    folder.mkdir(parents=True)\n\n    cmd = [str(folder)]\n    result = cli_run(cmd)\n    subprocess.check_call([str(result.creator.script(\"pip\")), \"--version\"])\n\n\n@pytest.mark.parametrize(\"creator\", sorted(set(PythonInfo.current_system().creators().key_to_class) - {\"builtin\"}))\n@pytest.mark.usefixtures(\"session_app_data\")\ndef test_create_distutils_cfg(creator, tmp_path, monkeypatch):\n    result = cli_run(\n        [\n            str(tmp_path / \"venv\"),\n            \"--activators\",\n            \"\",\n            \"--creator\",\n            creator,\n            \"--setuptools\",\n            \"bundle\",\n            \"--wheel\",\n            \"bundle\",\n        ],\n    )\n\n    app = Path(__file__).parent / \"console_app\"\n    dest = tmp_path / \"console_app\"\n    shutil.copytree(str(app), str(dest))\n\n    setup_cfg = dest / \"setup.cfg\"\n    conf = dedent(\n        f\"\"\"\n            [install]\n            prefix={tmp_path}{os.sep}prefix\n            install_purelib={tmp_path}{os.sep}purelib\n            install_platlib={tmp_path}{os.sep}platlib\n            install_headers={tmp_path}{os.sep}headers\n            install_scripts={tmp_path}{os.sep}scripts\n            install_data={tmp_path}{os.sep}data\n            \"\"\",\n    )\n    setup_cfg.write_text(setup_cfg.read_text(encoding=\"utf-8\") + conf, encoding=\"utf-8\")\n\n    monkeypatch.chdir(dest)  # distutils will read the setup.cfg from the cwd, so change to that\n\n    install_demo_cmd = [\n        str(result.creator.script(\"pip\")),\n        \"--disable-pip-version-check\",\n        \"install\",\n        str(dest),\n        \"--no-use-pep517\",\n        \"-vv\",\n    ]\n    subprocess.check_call(install_demo_cmd)\n\n    magic = result.creator.script(\"magic\")  # console scripts are created in the right location\n    assert magic.exists()\n\n    package_folder = result.creator.purelib / \"demo\"  # prefix is set to the virtualenv prefix for install\n    assert package_folder.exists(), list_files(str(tmp_path))\n\n\ndef list_files(path):\n    result = \"\"\n    for root, _, files in os.walk(path):\n        level = root.replace(path, \"\").count(os.sep)\n        indent = \" \" * 4 * level\n        result += f\"{indent}{os.path.basename(root)}/\\n\"\n        sub = \" \" * 4 * (level + 1)\n        for f in files:\n            result += f\"{sub}{f}\\n\"\n    return result\n\n\n@pytest.mark.skipif(is_macos_brew(CURRENT), reason=\"no copy on brew\")\ndef test_zip_importer_can_import_setuptools(tmp_path):\n    \"\"\"We're patching the loaders so might fail on r/o loaders, such as zipimporter on CPython<3.8\"\"\"\n    result = cli_run(\n        [str(tmp_path / \"venv\"), \"--activators\", \"\", \"--no-pip\", \"--no-wheel\", \"--copies\", \"--setuptools\", \"bundle\"],\n    )\n    zip_path = tmp_path / \"site-packages.zip\"\n    with zipfile.ZipFile(str(zip_path), \"w\", zipfile.ZIP_DEFLATED) as zip_handler:\n        lib = str(result.creator.purelib)\n        for root, _, files in os.walk(lib):\n            base = root[len(lib) :].lstrip(os.pathsep)\n            for file in files:\n                if not file.startswith(\"_virtualenv\"):\n                    zip_handler.write(filename=os.path.join(root, file), arcname=os.path.join(base, file))\n    for folder in result.creator.purelib.iterdir():\n        if not folder.name.startswith(\"_virtualenv\"):\n            if folder.is_dir():\n                shutil.rmtree(str(folder), ignore_errors=True)\n            else:\n                folder.unlink()\n    env = os.environ.copy()\n    env[\"PYTHONPATH\"] = str(zip_path)\n    subprocess.check_call([str(result.creator.exe), \"-c\", \"from setuptools.dist import Distribution\"], env=env)\n\n\n# verify that python in created virtualenv does not preimport threading.\n# https://github.com/pypa/virtualenv/issues/1895\n#\n# coverage is disabled, because when coverage is active, it imports threading in default mode.\n@pytest.mark.xfail(\n    IS_PYPY and sys.platform.startswith(\"darwin\"),\n    reason=\"https://foss.heptapod.net/pypy/pypy/-/issues/3269\",\n)\n@pytest.mark.usefixtures(\"_no_coverage\")\ndef test_no_preimport_threading(tmp_path):\n    session = cli_run([str(tmp_path)])\n    out = subprocess.check_output(\n        [str(session.creator.exe), \"-c\", r\"import sys; print('\\n'.join(sorted(sys.modules)))\"],\n        text=True,\n        encoding=\"utf-8\",\n    )\n    imported = set(out.splitlines())\n    assert \"threading\" not in imported\n\n\n# verify that .pth files in site-packages/ are always processed even if $PYTHONPATH points to it.\ndef test_pth_in_site_vs_python_path(tmp_path):\n    session = cli_run([str(tmp_path)])\n    site_packages = session.creator.purelib\n    # install test.pth that sets sys.testpth='ok'\n    (session.creator.purelib / \"test.pth\").write_text('import sys; sys.testpth=\"ok\"\\n', encoding=\"utf-8\")\n    # verify that test.pth is activated when interpreter is run\n    out = subprocess.check_output(\n        [str(session.creator.exe), \"-c\", r\"import sys; print(sys.testpth)\"],\n        text=True,\n        encoding=\"utf-8\",\n    )\n    assert out == \"ok\\n\"\n    # same with $PYTHONPATH pointing to site_packages\n    env = os.environ.copy()\n    path = [str(site_packages)]\n    if \"PYTHONPATH\" in env:\n        path.append(env[\"PYTHONPATH\"])\n    env[\"PYTHONPATH\"] = os.pathsep.join(path)\n    out = subprocess.check_output(\n        [str(session.creator.exe), \"-c\", r\"import sys; print(sys.testpth)\"],\n        text=True,\n        env=env,\n        encoding=\"utf-8\",\n    )\n    assert out == \"ok\\n\"\n\n\ndef test_getsitepackages_system_site(tmp_path):\n    # Test without --system-site-packages\n    session = cli_run([str(tmp_path)])\n\n    system_site_packages = get_expected_system_site_packages(session)\n\n    out = subprocess.check_output(\n        [str(session.creator.exe), \"-c\", r\"import site; print(site.getsitepackages())\"],\n        text=True,\n        encoding=\"utf-8\",\n    )\n    site_packages = ast.literal_eval(out)\n\n    for system_site_package in system_site_packages:\n        assert system_site_package not in site_packages\n\n    # Test with --system-site-packages\n    session = cli_run([str(tmp_path), \"--system-site-packages\"])\n\n    system_site_packages = [str(Path(i).resolve()) for i in get_expected_system_site_packages(session)]\n\n    out = subprocess.check_output(\n        [str(session.creator.exe), \"-c\", r\"import site; print(site.getsitepackages())\"],\n        text=True,\n        encoding=\"utf-8\",\n    )\n    site_packages = [str(Path(i).resolve()) for i in ast.literal_eval(out)]\n\n    for system_site_package in system_site_packages:\n        assert system_site_package in site_packages\n\n\ndef get_expected_system_site_packages(session):\n    base_prefix = session.creator.pyenv_cfg[\"base-prefix\"]\n    base_exec_prefix = session.creator.pyenv_cfg[\"base-exec-prefix\"]\n    old_prefixes = site.PREFIXES\n    site.PREFIXES = [base_prefix, base_exec_prefix]\n    system_site_packages = site.getsitepackages()\n    site.PREFIXES = old_prefixes\n\n    return system_site_packages\n\n\ndef test_get_site_packages(tmp_path):\n    case_sensitive = fs_is_case_sensitive()\n    session = cli_run([str(tmp_path)])\n    env_site_packages = [str(session.creator.purelib), str(session.creator.platlib)]\n    out = subprocess.check_output(\n        [str(session.creator.exe), \"-c\", r\"import site; print(site.getsitepackages())\"],\n        text=True,\n        encoding=\"utf-8\",\n    )\n    site_packages = ast.literal_eval(out)\n\n    if not case_sensitive:\n        env_site_packages = [x.lower() for x in env_site_packages]\n        site_packages = [x.lower() for x in site_packages]\n\n    for env_site_package in env_site_packages:\n        assert env_site_package in site_packages\n\n\ndef test_debug_bad_virtualenv(tmp_path):\n    cmd = [str(tmp_path), \"--without-pip\"]\n    result = cli_run(cmd)\n    # if the site.py is removed/altered the debug should fail as no one is around to fix the paths\n    cust = result.creator.purelib / \"_a.pth\"\n    cust.write_text(\n        'import sys; sys.stdout.write(\"std-out\"); sys.stderr.write(\"std-err\"); raise SystemExit(1)',\n        encoding=\"utf-8\",\n    )\n    debug_info = result.creator.debug\n    assert debug_info[\"returncode\"] == 1\n    assert \"std-err\" in debug_info[\"err\"]\n    assert \"std-out\" in debug_info[\"out\"]\n    assert debug_info[\"exception\"]\n\n\n@pytest.mark.parametrize(\"python_path_on\", [True, False], ids=[\"on\", \"off\"])\ndef test_python_path(monkeypatch, tmp_path, python_path_on):\n    result = cli_run([str(tmp_path), \"--without-pip\", \"--activators\", \"\"])\n    monkeypatch.chdir(tmp_path)\n    case_sensitive = fs_is_case_sensitive()\n\n    def _get_sys_path(flag=None):\n        cmd = [str(result.creator.exe)]\n        if flag:\n            cmd.append(flag)\n        cmd.extend([\"-c\", \"import json; import sys; print(json.dumps(sys.path))\"])\n        return [i if case_sensitive else i.lower() for i in json.loads(subprocess.check_output(cmd, encoding=\"utf-8\"))]\n\n    monkeypatch.delenv(\"PYTHONPATH\", raising=False)\n    base = _get_sys_path()\n\n    # note the value result.creator.interpreter.system_stdlib cannot be set, as that would disable our custom site.py\n    python_paths = [\n        str(Path(result.creator.interpreter.prefix)),\n        str(Path(result.creator.interpreter.system_stdlib) / \"b\"),\n        str(result.creator.purelib / \"a\"),\n        str(result.creator.purelib),\n        str(result.creator.bin_dir),\n        str(tmp_path / \"base\"),\n        f\"{tmp_path / 'base_sep'!s}{os.sep}\",\n        \"name\",\n        f\"name{os.sep}\",\n        f\"{tmp_path.parent}{f'{tmp_path.name}_suffix'}\",\n        \".\",\n        \"..\",\n        \"\",\n    ]\n    python_path_env = os.pathsep.join(python_paths)\n    monkeypatch.setenv(\"PYTHONPATH\", python_path_env)\n\n    extra_all = _get_sys_path(None if python_path_on else \"-E\")\n    if python_path_on:\n        assert not extra_all[0]  # the cwd is always injected at start as ''\n        extra_all = extra_all[1:]\n        assert not base[0]\n        base = base[1:]\n\n        assert not (set(base) - set(extra_all))  # all base paths are present\n        abs_python_paths = list(OrderedDict((os.path.abspath(str(i)), None) for i in python_paths).keys())\n        abs_python_paths = [i if case_sensitive else i.lower() for i in abs_python_paths]\n\n        extra_as_python_path = extra_all[: len(abs_python_paths)]\n        assert abs_python_paths == extra_as_python_path  # python paths are there at the start\n\n        non_python_path = extra_all[len(abs_python_paths) :]\n        assert non_python_path == [i for i in base if i not in extra_as_python_path]\n    else:\n        assert base == extra_all\n\n\n# Make sure that the venv creator works on systems where vendor-delivered files\n# (specifically venv scripts delivered with Python itself) are not writable.\n#\n# https://github.com/pypa/virtualenv/issues/2419\n@pytest.mark.skipif(\"venv\" not in CURRENT_CREATORS, reason=\"test needs venv creator\")\ndef test_venv_creator_without_write_perms(tmp_path, mocker):\n    from virtualenv.run.session import Session  # noqa: PLC0415\n\n    prev = Session._create  # noqa: SLF001\n\n    def func(self):\n        prev(self)\n        scripts_dir = self.creator.dest / \"bin\"\n        for script in scripts_dir.glob(\"*ctivate*\"):\n            script.chmod(stat.S_IREAD | stat.S_IRGRP | stat.S_IROTH)\n\n    mocker.patch(\"virtualenv.run.session.Session._create\", side_effect=func, autospec=True)\n\n    cmd = [str(tmp_path), \"--seeder\", \"app-data\", \"--without-pip\", \"--creator\", \"venv\"]\n    cli_run(cmd)\n", "tests/unit/create/test_interpreters.py": "from __future__ import annotations\n\nimport sys\nfrom uuid import uuid4\n\nimport pytest\n\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.run import cli_run\n\n\n@pytest.mark.slow()\ndef test_failed_to_find_bad_spec():\n    of_id = uuid4().hex\n    with pytest.raises(RuntimeError) as context:\n        cli_run([\"-p\", of_id])\n    msg = repr(RuntimeError(f\"failed to find interpreter for Builtin discover of python_spec={of_id!r}\"))\n    assert repr(context.value) == msg\n\n\nSYSTEM = PythonInfo.current_system()\n\n\n@pytest.mark.parametrize(\n    \"of_id\",\n    ({sys.executable} if sys.executable != SYSTEM.executable else set()) | {SYSTEM.implementation},\n)\ndef test_failed_to_find_implementation(of_id, mocker):\n    mocker.patch(\"virtualenv.run.plugin.creators.CreatorSelector._OPTIONS\", return_value={})\n    with pytest.raises(RuntimeError) as context:\n        cli_run([\"-p\", of_id])\n    assert repr(context.value) == repr(RuntimeError(f\"No virtualenv implementation for {PythonInfo.current_system()}\"))\n", "tests/unit/create/conftest.py": "\"\"\"\nIt's possible to use multiple types of host pythons to create virtual environments and all should work:\n\n- host installation\n- invoking from a venv (if Python 3.3+)\n- invoking from an old style virtualenv (<17.0.0)\n- invoking from our own venv\n\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\nfrom subprocess import Popen\n\nimport pytest\n\nfrom virtualenv.discovery.py_info import PythonInfo\n\nCURRENT = PythonInfo.current_system()\n\n\ndef root(tmp_path_factory, session_app_data):  # noqa: ARG001\n    return CURRENT.system_executable\n\n\ndef venv(tmp_path_factory, session_app_data):\n    if CURRENT.is_venv:\n        return sys.executable\n    root_python = root(tmp_path_factory, session_app_data)\n    dest = tmp_path_factory.mktemp(\"venv\")\n    process = Popen([str(root_python), \"-m\", \"venv\", \"--without-pip\", str(dest)])\n    process.communicate()\n    # sadly creating a virtual environment does not tell us where the executable lives in general case\n    # so discover using some heuristic\n    return CURRENT.discover_exe(prefix=str(dest)).original_executable\n\n\nPYTHON = {\n    \"root\": root,\n    \"venv\": venv,\n}\n\n\n@pytest.fixture(params=list(PYTHON.values()), ids=list(PYTHON.keys()), scope=\"session\")\ndef python(request, tmp_path_factory, session_app_data):\n    result = request.param(tmp_path_factory, session_app_data)\n    if isinstance(result, Exception):\n        pytest.skip(f\"could not resolve interpreter based on {request.param.__name__} because {result}\")\n    if result is None:\n        pytest.skip(f\"requires interpreter with {request.param.__name__}\")\n    return result\n", "tests/unit/create/via_global_ref/test_api.py": "from __future__ import annotations\n\nfrom virtualenv.create.via_global_ref import api\n\n\ndef test_can_symlink_when_symlinks_not_enabled(mocker):\n    mocker.patch.object(api, \"fs_supports_symlink\", return_value=False)\n    assert api.ViaGlobalRefMeta().can_symlink is False\n", "tests/unit/create/via_global_ref/test_build_c_ext.py": "from __future__ import annotations\n\nimport os\nimport shutil\nimport subprocess\nfrom pathlib import Path\nfrom subprocess import Popen\n\nimport pytest\n\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.run import cli_run\n\nCURRENT = PythonInfo.current_system()\nCREATOR_CLASSES = CURRENT.creators().key_to_class\n\n\ndef builtin_shows_marker_missing():\n    builtin_classs = CREATOR_CLASSES.get(\"builtin\")\n    if builtin_classs is None:\n        return False\n    host_include_marker = getattr(builtin_classs, \"host_include_marker\", None)\n    if host_include_marker is None:\n        return False\n    marker = host_include_marker(CURRENT)\n    return not marker.exists()\n\n\n@pytest.mark.xfail(\n    condition=bool(os.environ.get(\"CI_RUN\")),\n    strict=False,\n    reason=\"did not manage to setup CI to run with VC 14.1 C++ compiler, but passes locally\",\n)\n@pytest.mark.skipif(\n    not Path(CURRENT.system_include).exists() and not builtin_shows_marker_missing(),\n    reason=\"Building C-Extensions requires header files with host python\",\n)\n@pytest.mark.parametrize(\"creator\", [i for i in CREATOR_CLASSES if i != \"builtin\"])\ndef test_can_build_c_extensions(creator, tmp_path, coverage_env):\n    env, greet = tmp_path / \"env\", str(tmp_path / \"greet\")\n    shutil.copytree(str(Path(__file__).parent.resolve() / \"greet\"), greet)\n    session = cli_run([\"--creator\", creator, \"--seeder\", \"app-data\", str(env), \"-vvv\"])\n    coverage_env()\n    cmd = [\n        str(session.creator.script(\"pip\")),\n        \"install\",\n        \"--no-index\",\n        \"--no-deps\",\n        \"--disable-pip-version-check\",\n        \"-vvv\",\n        greet,\n    ]\n    process = Popen(cmd)\n    process.communicate()\n    assert process.returncode == 0\n\n    process = Popen(\n        [str(session.creator.exe), \"-c\", \"import greet; greet.greet('World')\"],\n        universal_newlines=True,\n        stdout=subprocess.PIPE,\n        encoding=\"utf-8\",\n    )\n    out, _ = process.communicate()\n    assert process.returncode == 0\n    assert out == \"Hello World!\\n\"\n", "tests/unit/create/via_global_ref/builtin/conftest.py": "from __future__ import annotations\n\nimport sys\nfrom pathlib import Path\n\nimport pytest\nfrom testing import path\nfrom testing.py_info import read_fixture\n\n# Allows to import from `testing` into test submodules.\nsys.path.append(str(Path(__file__).parent))\n\n\n@pytest.fixture()\ndef py_info(py_info_name):\n    return read_fixture(py_info_name)\n\n\n@pytest.fixture()\ndef mock_files(mocker):\n    return lambda paths, files: path.mock_files(mocker, paths, files)\n\n\n@pytest.fixture()\ndef mock_pypy_libs(mocker):\n    return lambda pypy, libs: path.mock_pypy_libs(mocker, pypy, libs)\n", "tests/unit/create/via_global_ref/builtin/cpython/test_cpython3_win.py": "from __future__ import annotations\n\nimport pytest\nfrom testing.helpers import contains_exe, contains_ref\nfrom testing.path import join as path\n\nfrom virtualenv.create.via_global_ref.builtin.cpython.cpython3 import CPython3Windows\n\nCPYTHON3_PATH = (\n    \"virtualenv.create.via_global_ref.builtin.cpython.common.Path\",\n    \"virtualenv.create.via_global_ref.builtin.cpython.cpython3.Path\",\n)\n\n\n@pytest.mark.parametrize(\"py_info_name\", [\"cpython3_win_embed\"])\ndef test_2_exe_on_default_py_host(py_info, mock_files):\n    mock_files(CPYTHON3_PATH, [py_info.system_executable])\n    sources = tuple(CPython3Windows.sources(interpreter=py_info))\n    # Default Python exe.\n    assert contains_exe(sources, py_info.system_executable)\n    # Should always exist.\n    assert contains_exe(sources, path(py_info.prefix, \"pythonw.exe\"))\n\n\n@pytest.mark.parametrize(\"py_info_name\", [\"cpython3_win_embed\"])\ndef test_3_exe_on_not_default_py_host(py_info, mock_files):\n    # Not default python host.\n    py_info.system_executable = path(py_info.prefix, \"python666.exe\")\n    mock_files(CPYTHON3_PATH, [py_info.system_executable])\n    sources = tuple(CPython3Windows.sources(interpreter=py_info))\n    # Not default Python exe linked to both the default name and origin.\n    assert contains_exe(sources, py_info.system_executable, \"python.exe\")\n    assert contains_exe(sources, py_info.system_executable, \"python666.exe\")\n    # Should always exist.\n    assert contains_exe(sources, path(py_info.prefix, \"pythonw.exe\"))\n\n\n@pytest.mark.parametrize(\"py_info_name\", [\"cpython3_win_embed\"])\ndef test_only_shim(py_info, mock_files):\n    shim = path(py_info.system_stdlib, \"venv\\\\scripts\\\\nt\\\\python.exe\")\n    py_files = (\n        path(py_info.prefix, \"libcrypto-1_1.dll\"),\n        path(py_info.prefix, \"libffi-7.dll\"),\n        path(py_info.prefix, \"_asyncio.pyd\"),\n        path(py_info.prefix, \"_bz2.pyd\"),\n    )\n    mock_files(CPYTHON3_PATH, [shim, *py_files])\n    sources = tuple(CPython3Windows.sources(interpreter=py_info))\n    assert CPython3Windows.has_shim(interpreter=py_info)\n    assert contains_exe(sources, shim)\n    assert not contains_exe(sources, py_info.system_executable)\n    for file in py_files:\n        assert not contains_ref(sources, file)\n\n\n@pytest.mark.parametrize(\"py_info_name\", [\"cpython3_win_embed\"])\ndef test_exe_dll_pyd_without_shim(py_info, mock_files):\n    py_files = (\n        path(py_info.prefix, \"libcrypto-1_1.dll\"),\n        path(py_info.prefix, \"libffi-7.dll\"),\n        path(py_info.prefix, \"_asyncio.pyd\"),\n        path(py_info.prefix, \"_bz2.pyd\"),\n    )\n    mock_files(CPYTHON3_PATH, py_files)\n    sources = tuple(CPython3Windows.sources(interpreter=py_info))\n    assert not CPython3Windows.has_shim(interpreter=py_info)\n    assert contains_exe(sources, py_info.system_executable)\n    for file in py_files:\n        assert contains_ref(sources, file)\n\n\n@pytest.mark.parametrize(\"py_info_name\", [\"cpython3_win_embed\"])\ndef test_python_zip_if_exists_and_set_in_path(py_info, mock_files):\n    python_zip_name = f\"python{py_info.version_nodot}.zip\"\n    python_zip = path(py_info.prefix, python_zip_name)\n    mock_files(CPYTHON3_PATH, [python_zip])\n    sources = tuple(CPython3Windows.sources(interpreter=py_info))\n    assert python_zip in py_info.path\n    assert contains_ref(sources, python_zip)\n\n\n@pytest.mark.parametrize(\"py_info_name\", [\"cpython3_win_embed\"])\ndef test_no_python_zip_if_exists_and_not_set_in_path(py_info, mock_files):\n    python_zip_name = f\"python{py_info.version_nodot}.zip\"\n    python_zip = path(py_info.prefix, python_zip_name)\n    py_info.path.remove(python_zip)\n    mock_files(CPYTHON3_PATH, [python_zip])\n    sources = tuple(CPython3Windows.sources(interpreter=py_info))\n    assert python_zip not in py_info.path\n    assert not contains_ref(sources, python_zip)\n\n\n@pytest.mark.parametrize(\"py_info_name\", [\"cpython3_win_embed\"])\ndef test_no_python_zip_if_not_exists(py_info, mock_files):\n    python_zip_name = f\"python{py_info.version_nodot}.zip\"\n    python_zip = path(py_info.prefix, python_zip_name)\n    # No `python_zip`, just python.exe file.\n    mock_files(CPYTHON3_PATH, [py_info.system_executable])\n    sources = tuple(CPython3Windows.sources(interpreter=py_info))\n    assert python_zip in py_info.path\n    assert not contains_ref(sources, python_zip)\n", "tests/unit/create/via_global_ref/builtin/testing/path.py": "from __future__ import annotations\n\nfrom abc import ABC, abstractmethod\nfrom itertools import chain\nfrom operator import attrgetter as attr\nfrom pathlib import Path\n\n\ndef is_name(path):\n    return str(path) == path.name\n\n\nclass FakeDataABC(ABC):\n    \"\"\"Provides data to mock the `Path`\"\"\"\n\n    @property\n    @abstractmethod\n    def filelist(self):\n        \"\"\"To mock a dir, just mock any child file.\"\"\"\n        msg = \"Collection of (str) file paths to mock\"\n        raise NotImplementedError(msg)\n\n    @property\n    def fake_files(self):\n        return map(type(self), self.filelist)\n\n    @property\n    def fake_dirs(self):\n        return set(chain(*map(attr(\"parents\"), self.fake_files)))\n\n    @property\n    def contained_fake_names(self):\n        return filter(is_name, self.fake_content)\n\n    @property\n    def fake_content(self):\n        return filter(None, map(self.fake_child, self.fake_files))\n\n    def fake_child(self, path):\n        try:\n            return path.relative_to(self)\n        except ValueError:\n            return None\n\n\nclass PathMockABC(FakeDataABC, Path):\n    \"\"\"Mocks the behavior of `Path`\"\"\"\n\n    _flavour = getattr(Path(), \"_flavour\", None)\n    if hasattr(_flavour, \"altsep\"):\n        # Allows to pass some tests for Windows via PosixPath.\n        _flavour.altsep = _flavour.altsep or \"\\\\\"\n\n    # Python 3.13 renamed _flavour to parser\n    parser = getattr(Path(), \"parser\", None)\n    if hasattr(parser, \"altsep\"):\n        parser.altsep = parser.altsep or \"\\\\\"\n\n    def exists(self):\n        return self.is_file() or self.is_dir()\n\n    def is_file(self):\n        return self in self.fake_files\n\n    def is_dir(self):\n        return self in self.fake_dirs\n\n    def resolve(self):\n        return self\n\n    def iterdir(self):\n        if not self.is_dir():\n            msg = f\"No such mocked dir: '{self}'\"\n            raise FileNotFoundError(msg)\n        yield from map(self.joinpath, self.contained_fake_names)\n\n\ndef MetaPathMock(filelist):  # noqa: N802\n    \"\"\"\n    Metaclass that creates a `PathMock` class with the `filelist` defined.\n    \"\"\"\n    return type(\"PathMock\", (PathMockABC,), {\"filelist\": filelist})\n\n\ndef mock_files(mocker, pathlist, filelist):\n    PathMock = MetaPathMock(set(filelist))  # noqa: N806\n    for path in pathlist:\n        mocker.patch(path, PathMock)\n\n\ndef mock_pypy_libs(mocker, pypy_creator_cls, libs):\n    paths = tuple(set(map(Path, libs)))\n    mocker.patch.object(pypy_creator_cls, \"_shared_libs\", return_value=paths)\n\n\ndef join(*chunks):\n    line = \"\".join(chunks)\n    sep = (\"\\\\\" in line and \"\\\\\") or (\"/\" in line and \"/\") or \"/\"\n    return sep.join(chunks)\n", "tests/unit/create/via_global_ref/builtin/testing/py_info.py": "from __future__ import annotations\n\nfrom pathlib import Path\n\nfrom virtualenv.discovery.py_info import PythonInfo\n\n\ndef fixture_file(fixture_name):\n    file_mask = f\"*{fixture_name}.json\"\n    files = Path(__file__).parent.parent.rglob(file_mask)\n    try:\n        return next(files)\n    except StopIteration as exc:\n        # Fixture file was not found in the testing root and its subdirs.\n        error = FileNotFoundError\n        raise error(file_mask) from exc\n\n\ndef read_fixture(fixture_name):\n    fixture_json = fixture_file(fixture_name).read_text(encoding=\"utf-8\")\n    return PythonInfo._from_json(fixture_json)  # noqa: SLF001\n", "tests/unit/create/via_global_ref/builtin/testing/helpers.py": "from __future__ import annotations\n\nfrom functools import reduce\nfrom pathlib import Path\n\nfrom virtualenv.create.via_global_ref.builtin.ref import ExePathRefToDest, PathRef\n\n\ndef is_ref(source):\n    return isinstance(source, PathRef)\n\n\ndef is_exe(source):\n    return type(source) is ExePathRefToDest\n\n\ndef has_src(src):\n    return lambda ref: ref.src.as_posix() == Path(src).as_posix()\n\n\ndef has_target(target):\n    return lambda ref: ref.base == target\n\n\ndef apply_filter(values, function):\n    return filter(function, values)\n\n\ndef filterby(filters, sources):\n    return reduce(apply_filter, filters, sources)\n\n\ndef contains_exe(sources, src, target=None):\n    filters = is_exe, has_src(src), target and has_target(target)\n    return any(filterby(filters, sources))\n\n\ndef contains_ref(sources, src):\n    filters = is_ref, has_src(src)\n    return any(filterby(filters, sources))\n", "tests/unit/create/via_global_ref/builtin/testing/__init__.py": "", "tests/unit/create/via_global_ref/builtin/pypy/test_pypy3.py": "from __future__ import annotations\n\nimport pytest\nfrom testing.helpers import contains_exe, contains_ref\nfrom testing.path import join as path\n\nfrom virtualenv.create.via_global_ref.builtin.pypy.pypy3 import PyPy3Posix\n\nPYPY3_PATH = (\n    \"virtualenv.create.via_global_ref.builtin.pypy.common.Path\",\n    \"virtualenv.create.via_global_ref.builtin.pypy.pypy3.Path\",\n)\n\n\n# In `PyPy3Posix.sources()` `host_lib` will be broken in Python 2 for Windows,\n# so `py_file` will not be in sources.\n@pytest.mark.parametrize(\"py_info_name\", [\"portable_pypy38\"])\ndef test_portable_pypy3_virtualenvs_get_their_libs(py_info, mock_files, mock_pypy_libs):\n    py_file = path(py_info.prefix, \"lib/libgdbm.so.4\")\n    mock_files(PYPY3_PATH, [py_info.system_executable, py_file])\n    lib_file = path(py_info.prefix, \"bin/libpypy3-c.so\")\n    mock_pypy_libs(PyPy3Posix, [lib_file])\n    sources = tuple(PyPy3Posix.sources(interpreter=py_info))\n    assert len(sources) > 2\n    assert contains_exe(sources, py_info.system_executable)\n    assert contains_ref(sources, py_file)\n    assert contains_ref(sources, lib_file)\n\n\n@pytest.mark.parametrize(\"py_info_name\", [\"deb_pypy37\"])\ndef test_debian_pypy37_virtualenvs(py_info, mock_files, mock_pypy_libs):\n    # Debian's pypy3 layout, installed to /usr, before 3.8 allowed a /usr prefix\n    mock_files(PYPY3_PATH, [py_info.system_executable])\n    lib_file = path(py_info.prefix, \"bin/libpypy3-c.so\")\n    mock_pypy_libs(PyPy3Posix, [lib_file])\n    sources = tuple(PyPy3Posix.sources(interpreter=py_info))\n    assert len(sources) == 2\n    assert contains_exe(sources, py_info.system_executable)\n    assert contains_ref(sources, lib_file)\n\n\n@pytest.mark.parametrize(\"py_info_name\", [\"deb_pypy38\"])\ndef test_debian_pypy38_virtualenvs_exclude_usr(py_info, mock_files, mock_pypy_libs):\n    mock_files(PYPY3_PATH, [py_info.system_executable, \"/usr/lib/foo\"])\n    # libpypy3-c.so lives on the ld search path\n    mock_pypy_libs(PyPy3Posix, [])\n    sources = tuple(PyPy3Posix.sources(interpreter=py_info))\n    assert len(sources) == 1\n    assert contains_exe(sources, py_info.system_executable)\n", "tests/unit/create/via_global_ref/greet/setup.py": "from __future__ import annotations\n\nimport sys\n\nfrom setuptools import Extension, setup\n\nsetup(\n    name=\"greet\",  # package name\n    version=\"1.0\",  # package version\n    ext_modules=[\n        Extension(\n            \"greet\",\n            [f\"greet{sys.version_info[0]}.c\"],  # extension to package\n        ),  # C code to compile to run as extension\n    ],\n)\n", "tests/unit/create/console_app/setup.py": "from __future__ import annotations\n\nfrom setuptools import setup\n\nsetup()\n", "tests/unit/create/console_app/demo/__main__.py": "from __future__ import annotations\n\n\ndef run():\n    print(\"magic\")  # noqa: T201\n\n\nif __name__ == \"__main__\":\n    run()\n", "tests/unit/create/console_app/demo/__init__.py": "from __future__ import annotations\n\n\ndef run():\n    print(\"magic\")  # noqa: T201\n\n\nif __name__ == \"__main__\":\n    run()\n", "tests/unit/seed/embed/test_bootstrap_link_via_app_data.py": "from __future__ import annotations\n\nimport contextlib\nimport os\nimport sys\nfrom stat import S_IWGRP, S_IWOTH, S_IWUSR\nfrom subprocess import Popen, check_call\nfrom threading import Thread\nfrom typing import TYPE_CHECKING\n\nimport pytest\n\nfrom virtualenv.discovery import cached_py_info\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.info import fs_supports_symlink\nfrom virtualenv.run import cli_run\nfrom virtualenv.seed.wheels.embed import BUNDLE_FOLDER, BUNDLE_SUPPORT\nfrom virtualenv.util.path import safe_delete\n\nif TYPE_CHECKING:\n    from pathlib import Path\n\n    from pytest_mock import MockerFixture\n\n\n@pytest.mark.slow()\n@pytest.mark.parametrize(\"copies\", [False, True] if fs_supports_symlink() else [True])\ndef test_seed_link_via_app_data(tmp_path, coverage_env, current_fastest, copies):\n    current = PythonInfo.current_system()\n    bundle_ver = BUNDLE_SUPPORT[current.version_release_str]\n    create_cmd = [\n        str(tmp_path / \"en v\"),  # space in the name to ensure generated scripts work when path has space\n        \"--no-periodic-update\",\n        \"--seeder\",\n        \"app-data\",\n        \"--extra-search-dir\",\n        str(BUNDLE_FOLDER),\n        \"--download\",\n        \"--pip\",\n        bundle_ver[\"pip\"].split(\"-\")[1],\n        \"--setuptools\",\n        bundle_ver[\"setuptools\"].split(\"-\")[1],\n        \"--reset-app-data\",\n        \"--creator\",\n        current_fastest,\n        \"-vv\",\n    ]\n    if not copies:\n        create_cmd.append(\"--symlink-app-data\")\n    result = cli_run(create_cmd)\n    coverage_env()\n    assert result\n\n    # uninstalling pip/setuptools now should leave us with a ensure_safe_to_do env\n    site_package = result.creator.purelib\n    pip = site_package / \"pip\"\n    setuptools = site_package / \"setuptools\"\n\n    files_post_first_create = set(site_package.iterdir())\n    assert pip in files_post_first_create\n    assert setuptools in files_post_first_create\n    for pip_exe in [\n        result.creator.script_dir / f\"pip{suffix}{result.creator.exe.suffix}\"\n        for suffix in (\n            \"\",\n            f\"{current.version_info.major}\",\n            f\"{current.version_info.major}.{current.version_info.minor}\",\n            f\"-{current.version_info.major}.{current.version_info.minor}\",\n        )\n    ]:\n        assert pip_exe.exists()\n        process = Popen([str(pip_exe), \"--version\", \"--disable-pip-version-check\"])\n        _, __ = process.communicate()\n        assert not process.returncode\n\n    remove_cmd = [\n        str(result.creator.script(\"pip\")),\n        \"--verbose\",\n        \"--disable-pip-version-check\",\n        \"uninstall\",\n        \"-y\",\n        \"setuptools\",\n    ]\n    process = Popen(remove_cmd)\n    _, __ = process.communicate()\n    assert not process.returncode\n    assert site_package.exists()\n\n    files_post_first_uninstall = set(site_package.iterdir())\n    assert pip in files_post_first_uninstall\n    assert setuptools not in files_post_first_uninstall\n\n    # install a different setuptools to test that virtualenv removes this before installing new\n    version = f\"setuptools<{bundle_ver['setuptools'].split('-')[1]}\"\n    install_cmd = [str(result.creator.script(\"pip\")), \"--verbose\", \"--disable-pip-version-check\", \"install\", version]\n    process = Popen(install_cmd)\n    process.communicate()\n    assert not process.returncode\n    assert site_package.exists()\n    files_post_downgrade = set(site_package.iterdir())\n    assert setuptools in files_post_downgrade\n\n    # check we can run it again and will work - checks both overwrite and reuse cache\n    result = cli_run(create_cmd)\n    coverage_env()\n    assert result\n    files_post_second_create = set(site_package.iterdir())\n    assert files_post_first_create == files_post_second_create\n\n    # Windows does not allow removing a executable while running it, so when uninstalling pip we need to do it via\n    # python -m pip\n    remove_cmd = [str(result.creator.exe), \"-m\", \"pip\"] + remove_cmd[1:]\n    process = Popen([*remove_cmd, \"pip\", \"wheel\"])\n    _, __ = process.communicate()\n    assert not process.returncode\n    # pip is greedy here, removing all packages removes the site-package too\n    if site_package.exists():\n        purelib = result.creator.purelib\n        patch_files = {purelib / f\"{'_virtualenv'}.{i}\" for i in (\"py\", \"pyc\", \"pth\")}\n        patch_files.add(purelib / \"__pycache__\")\n        post_run = set(site_package.iterdir()) - patch_files\n        assert not post_run, \"\\n\".join(str(i) for i in post_run)\n\n\n@contextlib.contextmanager\ndef read_only_dir(d):\n    write = S_IWUSR | S_IWGRP | S_IWOTH\n    for root, _, filenames in os.walk(str(d)):\n        os.chmod(root, os.stat(root).st_mode & ~write)\n        for filename in filenames:\n            name = os.path.join(root, filename)\n            os.chmod(name, os.stat(name).st_mode & ~write)\n    try:\n        yield\n    finally:\n        for root, _, filenames in os.walk(str(d)):\n            os.chmod(root, os.stat(root).st_mode | write)\n            for filename in filenames:\n                name = os.path.join(root, filename)\n                os.chmod(name, os.stat(name).st_mode | write)\n\n\n@pytest.fixture()\ndef read_only_app_data(temp_app_data):\n    temp_app_data.mkdir()\n    with read_only_dir(temp_app_data):\n        yield temp_app_data\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"Windows only applies R/O to files\")\n@pytest.mark.usefixtures(\"read_only_app_data\")\ndef test_base_bootstrap_link_via_app_data_not_writable(tmp_path, current_fastest):\n    dest = tmp_path / \"venv\"\n    result = cli_run([\"--seeder\", \"app-data\", \"--creator\", current_fastest, \"-vv\", str(dest)])\n    assert result\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"Windows only applies R/O to files\")\ndef test_populated_read_only_cache_and_symlinked_app_data(tmp_path, current_fastest, temp_app_data):\n    dest = tmp_path / \"venv\"\n    cmd = [\n        \"--seeder\",\n        \"app-data\",\n        \"--creator\",\n        current_fastest,\n        \"--symlink-app-data\",\n        \"-vv\",\n        str(dest),\n    ]\n\n    assert cli_run(cmd)\n    check_call((str(dest.joinpath(\"bin/python\")), \"-c\", \"import pip\"))\n\n    cached_py_info._CACHE.clear()  # necessary to re-trigger py info discovery  # noqa: SLF001\n    safe_delete(dest)\n\n    # should succeed with special flag when read-only\n    with read_only_dir(temp_app_data):\n        assert cli_run([\"--read-only-app-data\", *cmd])\n        check_call((str(dest.joinpath(\"bin/python\")), \"-c\", \"import pip\"))\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"Windows only applies R/O to files\")\ndef test_populated_read_only_cache_and_copied_app_data(tmp_path, current_fastest, temp_app_data):\n    dest = tmp_path / \"venv\"\n    cmd = [\n        \"--seeder\",\n        \"app-data\",\n        \"--creator\",\n        current_fastest,\n        \"-vv\",\n        \"-p\",\n        \"python\",\n        str(dest),\n    ]\n\n    assert cli_run(cmd)\n\n    cached_py_info._CACHE.clear()  # necessary to re-trigger py info discovery  # noqa: SLF001\n    safe_delete(dest)\n\n    # should succeed with special flag when read-only\n    with read_only_dir(temp_app_data):\n        assert cli_run([\"--read-only-app-data\", *cmd])\n\n\n@pytest.mark.slow()\n@pytest.mark.parametrize(\"pkg\", [\"pip\", \"setuptools\", \"wheel\"])\n@pytest.mark.usefixtures(\"session_app_data\", \"current_fastest\", \"coverage_env\")\ndef test_base_bootstrap_link_via_app_data_no(tmp_path, pkg):\n    create_cmd = [str(tmp_path), \"--seeder\", \"app-data\", f\"--no-{pkg}\", \"--wheel\", \"bundle\", \"--setuptools\", \"bundle\"]\n    result = cli_run(create_cmd)\n    assert not (result.creator.purelib / pkg).exists()\n    for key in {\"pip\", \"setuptools\", \"wheel\"} - {pkg}:\n        assert (result.creator.purelib / key).exists()\n\n\n@pytest.mark.usefixtures(\"temp_app_data\")\ndef test_app_data_parallel_ok(tmp_path):\n    exceptions = _run_parallel_threads(tmp_path)\n    assert not exceptions, \"\\n\".join(exceptions)\n\n\n@pytest.mark.usefixtures(\"temp_app_data\")\ndef test_app_data_parallel_fail(tmp_path: Path, mocker: MockerFixture) -> None:\n    mocker.patch(\"virtualenv.seed.embed.via_app_data.pip_install.base.PipInstall.build_image\", side_effect=RuntimeError)\n    exceptions = _run_parallel_threads(tmp_path)\n    assert len(exceptions) == 2\n    for exception in exceptions:\n        assert exception.startswith(\"failed to build image wheel because:\\nTraceback\")\n        assert \"RuntimeError\" in exception, exception\n\n\ndef _run_parallel_threads(tmp_path):\n    exceptions = []\n\n    def _run(name):\n        try:\n            cli_run([\"--seeder\", \"app-data\", str(tmp_path / name), \"--no-pip\", \"--no-setuptools\", \"--wheel\", \"bundle\"])\n        except Exception as exception:  # noqa: BLE001\n            as_str = str(exception)\n            exceptions.append(as_str)\n\n    threads = [Thread(target=_run, args=(f\"env{i}\",)) for i in range(1, 3)]\n    for thread in threads:\n        thread.start()\n    for thread in threads:\n        thread.join()\n    return exceptions\n", "tests/unit/seed/embed/test_pip_invoke.py": "from __future__ import annotations\n\nimport itertools\nimport sys\nfrom shutil import copy2\n\nimport pytest\n\nfrom virtualenv.run import cli_run\nfrom virtualenv.seed.embed.pip_invoke import PipInvoke\nfrom virtualenv.seed.wheels.bundle import load_embed_wheel\nfrom virtualenv.seed.wheels.embed import BUNDLE_FOLDER, BUNDLE_SUPPORT\n\n\n@pytest.mark.slow()\n@pytest.mark.parametrize(\"no\", [\"pip\", \"setuptools\", \"wheel\", \"\"])\ndef test_base_bootstrap_via_pip_invoke(tmp_path, coverage_env, mocker, current_fastest, no):  # noqa: C901\n    extra_search_dir = tmp_path / \"extra\"\n    extra_search_dir.mkdir()\n    for_py_version = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n    new = BUNDLE_SUPPORT[for_py_version]\n    for wheel_filename in BUNDLE_SUPPORT[for_py_version].values():\n        copy2(str(BUNDLE_FOLDER / wheel_filename), str(extra_search_dir))\n\n    def _load_embed_wheel(app_data, distribution, for_py_version, version):  # noqa: ARG001\n        return load_embed_wheel(app_data, distribution, old_ver, version)\n\n    old_ver = \"3.7\"\n    old = BUNDLE_SUPPORT[old_ver]\n    mocker.patch(\"virtualenv.seed.wheels.bundle.load_embed_wheel\", side_effect=_load_embed_wheel)\n\n    def _execute(cmd, env):\n        expected = set()\n        for distribution, with_version in versions.items():\n            if distribution == no:\n                continue\n            if with_version == \"embed\" or old[distribution] == new[distribution]:\n                expected.add(BUNDLE_FOLDER)\n            else:\n                expected.add(extra_search_dir)\n        expected_list = list(\n            itertools.chain.from_iterable([\"--find-links\", str(e)] for e in sorted(expected, key=str)),\n        )\n        found = cmd[-len(expected_list) :] if expected_list else []\n        assert \"--no-index\" not in cmd\n        cmd.append(\"--no-index\")\n        assert found == expected_list\n        return original(cmd, env)\n\n    original = PipInvoke._execute  # noqa: SLF001\n    run = mocker.patch.object(PipInvoke, \"_execute\", side_effect=_execute)\n    versions = {\"pip\": \"embed\", \"setuptools\": \"bundle\", \"wheel\": new[\"wheel\"].split(\"-\")[1]}\n\n    create_cmd = [\n        \"--seeder\",\n        \"pip\",\n        str(tmp_path / \"env\"),\n        \"--download\",\n        \"--creator\",\n        current_fastest,\n        \"--extra-search-dir\",\n        str(extra_search_dir),\n        \"--app-data\",\n        str(tmp_path / \"app-data\"),\n    ]\n    for dist, version in versions.items():\n        create_cmd.extend([f\"--{dist}\", version])\n    if no:\n        create_cmd.append(f\"--no-{no}\")\n    result = cli_run(create_cmd)\n    coverage_env()\n\n    assert result\n    assert run.call_count == 1\n\n    site_package = result.creator.purelib\n    pip = site_package / \"pip\"\n    setuptools = site_package / \"setuptools\"\n    wheel = site_package / \"wheel\"\n    files_post_first_create = list(site_package.iterdir())\n\n    if no:\n        no_file = locals()[no]\n        assert no not in files_post_first_create\n\n    for key in (\"pip\", \"setuptools\", \"wheel\"):\n        if key == no:\n            continue\n        assert locals()[key] in files_post_first_create\n", "tests/unit/seed/embed/test_base_embed.py": "from __future__ import annotations\n\nimport sys\nfrom typing import TYPE_CHECKING\n\nimport pytest\n\nfrom virtualenv.run import session_via_cli\n\nif TYPE_CHECKING:\n    from pathlib import Path\n\n\n@pytest.mark.parametrize(\n    (\"args\", \"download\"),\n    [([], False), ([\"--no-download\"], False), ([\"--never-download\"], False), ([\"--download\"], True)],\n)\ndef test_download_cli_flag(args, download, tmp_path):\n    session = session_via_cli([*args, str(tmp_path)])\n    assert session.seeder.download is download\n\n\ndef test_embed_wheel_versions(tmp_path: Path) -> None:\n    session = session_via_cli([str(tmp_path)])\n    expected = (\n        {\"pip\": \"bundle\"}\n        if sys.version_info[:2] >= (3, 12)\n        else {\"pip\": \"bundle\", \"setuptools\": \"bundle\", \"wheel\": \"bundle\"}\n    )\n    assert session.seeder.distribution_to_versions() == expected\n", "tests/unit/seed/wheels/test_bundle.py": "from __future__ import annotations\n\nimport os\nfrom datetime import datetime, timezone\nfrom pathlib import Path\n\nimport pytest\n\nfrom virtualenv.app_data import AppDataDiskFolder\nfrom virtualenv.seed.wheels.bundle import from_bundle\nfrom virtualenv.seed.wheels.embed import get_embed_wheel\nfrom virtualenv.seed.wheels.periodic_update import dump_datetime\nfrom virtualenv.seed.wheels.util import Version, Wheel\n\n\n@pytest.fixture(scope=\"module\")\ndef next_pip_wheel(for_py_version):\n    wheel = get_embed_wheel(\"pip\", for_py_version)\n    new_version = list(wheel.version_tuple)\n    new_version[-1] += 1\n    new_name = wheel.name.replace(wheel.version, \".\".join(str(i) for i in new_version))\n    return Wheel.from_path(Path(new_name))\n\n\n@pytest.fixture(scope=\"module\")\ndef app_data(tmp_path_factory, for_py_version, next_pip_wheel):\n    temp_folder = tmp_path_factory.mktemp(\"module-app-data\")\n    now = dump_datetime(datetime.now(tz=timezone.utc))\n    app_data_ = AppDataDiskFolder(str(temp_folder))\n    app_data_.embed_update_log(\"pip\", for_py_version).write(\n        {\n            \"completed\": now,\n            \"periodic\": True,\n            \"started\": now,\n            \"versions\": [\n                {\n                    \"filename\": next_pip_wheel.name,\n                    \"found_date\": \"2000-01-01T00:00:00.000000Z\",\n                    \"release_date\": \"2000-01-01T00:00:00.000000Z\",\n                    \"source\": \"periodic\",\n                },\n            ],\n        },\n    )\n    return app_data_\n\n\ndef test_version_embed(app_data, for_py_version):\n    wheel = from_bundle(\"pip\", Version.embed, for_py_version, [], app_data, False, os.environ)\n    assert wheel is not None\n    assert wheel.name == get_embed_wheel(\"pip\", for_py_version).name\n\n\ndef test_version_bundle(app_data, for_py_version, next_pip_wheel):\n    wheel = from_bundle(\"pip\", Version.bundle, for_py_version, [], app_data, False, os.environ)\n    assert wheel is not None\n    assert wheel.name == next_pip_wheel.name\n\n\ndef test_version_pinned_not_found(app_data, for_py_version):\n    wheel = from_bundle(\"pip\", \"0.0.0\", for_py_version, [], app_data, False, os.environ)\n    assert wheel is None\n\n\ndef test_version_pinned_is_embed(app_data, for_py_version):\n    expected_wheel = get_embed_wheel(\"pip\", for_py_version)\n    wheel = from_bundle(\"pip\", expected_wheel.version, for_py_version, [], app_data, False, os.environ)\n    assert wheel is not None\n    assert wheel.name == expected_wheel.name\n\n\ndef test_version_pinned_in_app_data(app_data, for_py_version, next_pip_wheel):\n    wheel = from_bundle(\"pip\", next_pip_wheel.version, for_py_version, [], app_data, False, os.environ)\n    assert wheel is not None\n    assert wheel.name == next_pip_wheel.name\n", "tests/unit/seed/wheels/test_periodic_update.py": "from __future__ import annotations\n\nimport json\nimport os\nimport subprocess\nimport sys\nfrom collections import defaultdict\nfrom contextlib import contextmanager\nfrom datetime import datetime, timedelta, timezone\nfrom io import StringIO\nfrom itertools import zip_longest\nfrom pathlib import Path\nfrom textwrap import dedent\nfrom urllib.error import URLError\n\nimport pytest\n\nfrom virtualenv import cli_run\nfrom virtualenv.app_data import AppDataDiskFolder\nfrom virtualenv.seed.wheels import Wheel\nfrom virtualenv.seed.wheels.embed import BUNDLE_SUPPORT, get_embed_wheel\nfrom virtualenv.seed.wheels.periodic_update import (\n    NewVersion,\n    UpdateLog,\n    do_update,\n    dump_datetime,\n    load_datetime,\n    manual_upgrade,\n    periodic_update,\n    release_date_for_wheel_path,\n    trigger_update,\n)\nfrom virtualenv.util.subprocess import CREATE_NO_WINDOW\n\n\n@pytest.fixture(autouse=True)\ndef _clear_pypi_info_cache():\n    from virtualenv.seed.wheels.periodic_update import _PYPI_CACHE  # noqa: PLC0415\n\n    _PYPI_CACHE.clear()\n\n\ndef test_manual_upgrade(session_app_data, caplog, mocker, for_py_version):\n    wheel = get_embed_wheel(\"pip\", for_py_version)\n    new_version = NewVersion(\n        wheel.path,\n        datetime.now(tz=timezone.utc),\n        datetime.now(tz=timezone.utc) - timedelta(days=20),\n        \"manual\",\n    )\n\n    def _do_update(  # noqa: PLR0913\n        distribution,\n        for_py_version,  # noqa: ARG001\n        embed_filename,  # noqa: ARG001\n        app_data,  # noqa: ARG001\n        search_dirs,  # noqa: ARG001\n        periodic,  # noqa: ARG001\n    ):\n        if distribution == \"pip\":\n            return [new_version]\n        return []\n\n    do_update_mock = mocker.patch(\"virtualenv.seed.wheels.periodic_update.do_update\", side_effect=_do_update)\n    manual_upgrade(session_app_data, os.environ)\n\n    assert \"upgrade pip\" in caplog.text\n    assert \"upgraded pip\" in caplog.text\n    assert \" no new versions found\" in caplog.text\n    assert \" new entries found:\\n\" in caplog.text\n    assert \"\\tNewVersion(\" in caplog.text\n    packages = defaultdict(list)\n    for args in do_update_mock.call_args_list:\n        packages[args[1][\"distribution\"]].append(args[1][\"for_py_version\"])\n    packages = {key: sorted(value) for key, value in packages.items()}\n    versions = sorted(BUNDLE_SUPPORT.keys())\n    expected = {\"setuptools\": versions, \"wheel\": versions, \"pip\": versions}\n    assert packages == expected\n\n\n@pytest.mark.usefixtures(\"session_app_data\")\ndef test_pick_periodic_update(tmp_path, mocker, for_py_version):\n    embed, current = get_embed_wheel(\"setuptools\", \"3.6\"), get_embed_wheel(\"setuptools\", for_py_version)\n    mocker.patch(\"virtualenv.seed.wheels.bundle.load_embed_wheel\", return_value=embed)\n    completed = datetime.now(tz=timezone.utc) - timedelta(days=29)\n    u_log = UpdateLog(\n        started=datetime.now(tz=timezone.utc) - timedelta(days=30),\n        completed=completed,\n        versions=[NewVersion(filename=current.path, found_date=completed, release_date=completed, source=\"periodic\")],\n        periodic=True,\n    )\n    read_dict = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n\n    result = cli_run(\n        [\n            str(tmp_path),\n            \"--activators\",\n            \"\",\n            \"--no-periodic-update\",\n            \"--no-wheel\",\n            \"--no-pip\",\n            \"--setuptools\",\n            \"bundle\",\n            \"--wheel\",\n            \"bundle\",\n        ],\n    )\n\n    assert read_dict.call_count == 1\n    installed = [i.name for i in result.creator.purelib.iterdir() if i.suffix == \".dist-info\"]\n    assert f\"setuptools-{current.version}.dist-info\" in installed\n\n\ndef test_periodic_update_stops_at_current(mocker, session_app_data, for_py_version):\n    current = get_embed_wheel(\"setuptools\", for_py_version)\n\n    now, completed = datetime.now(tz=timezone.utc), datetime.now(tz=timezone.utc) - timedelta(days=29)\n    u_log = UpdateLog(\n        started=completed,\n        completed=completed,\n        versions=[\n            NewVersion(wheel_path(current, (1,)), completed, now - timedelta(days=1), \"periodic\"),\n            NewVersion(current.path, completed, now - timedelta(days=2), \"periodic\"),\n            NewVersion(wheel_path(current, (-1,)), completed, now - timedelta(days=30), \"periodic\"),\n        ],\n        periodic=True,\n    )\n    mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n\n    result = periodic_update(\"setuptools\", None, for_py_version, current, [], session_app_data, False, os.environ)\n    assert result.path == current.path\n\n\ndef test_periodic_update_latest_per_patch(mocker, session_app_data, for_py_version):\n    current = get_embed_wheel(\"setuptools\", for_py_version)\n    expected_path = wheel_path(current, (0, 1, 2))\n    now = datetime.now(tz=timezone.utc)\n    completed = now - timedelta(hours=2)\n    u_log = UpdateLog(\n        started=completed,\n        completed=completed,\n        periodic=True,\n        versions=[\n            NewVersion(expected_path, completed, now - timedelta(days=1), \"periodic\"),\n            NewVersion(wheel_path(current, (0, 1, 1)), completed, now - timedelta(days=30), \"periodic\"),\n            NewVersion(str(current.path), completed, now - timedelta(days=31), \"periodic\"),\n        ],\n    )\n    mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n\n    result = periodic_update(\"setuptools\", None, for_py_version, current, [], session_app_data, False, os.environ)\n    assert str(result.path) == expected_path\n\n\ndef test_periodic_update_latest_per_patch_prev_is_manual(mocker, session_app_data, for_py_version):\n    current = get_embed_wheel(\"setuptools\", for_py_version)\n    expected_path = wheel_path(current, (0, 1, 2))\n    now = datetime.now(tz=timezone.utc)\n    completed = now - timedelta(hours=2)\n    u_log = UpdateLog(\n        started=completed,\n        completed=completed,\n        periodic=True,\n        versions=[\n            NewVersion(expected_path, completed, completed, \"periodic\"),\n            NewVersion(wheel_path(current, (0, 1, 1)), completed, now - timedelta(days=10), \"manual\"),\n            NewVersion(wheel_path(current, (0, 1, 0)), completed, now - timedelta(days=11), \"periodic\"),\n            NewVersion(str(current.path), completed, now - timedelta(days=12), \"manual\"),\n        ],\n    )\n    mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n\n    result = periodic_update(\"setuptools\", None, for_py_version, current, [], session_app_data, False, os.environ)\n    assert str(result.path) == expected_path\n\n\ndef test_manual_update_honored(mocker, session_app_data, for_py_version):\n    current = get_embed_wheel(\"setuptools\", for_py_version)\n    expected_path = wheel_path(current, (0, 1, 1))\n    now = datetime.now(tz=timezone.utc)\n    completed = now\n    u_log = UpdateLog(\n        started=completed,\n        completed=completed,\n        periodic=True,\n        versions=[\n            NewVersion(wheel_path(current, (0, 1, 2)), completed, completed, \"periodic\"),\n            NewVersion(expected_path, completed, now - timedelta(days=10), \"manual\"),\n            NewVersion(wheel_path(current, (0, 1, 0)), completed, now - timedelta(days=11), \"periodic\"),\n            NewVersion(str(current.path), completed, now - timedelta(days=12), \"manual\"),\n        ],\n    )\n    mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n\n    result = periodic_update(\"setuptools\", None, for_py_version, current, [], session_app_data, False, os.environ)\n    assert str(result.path) == expected_path\n\n\ndef wheel_path(wheel, of, pre_release=\"\"):\n    new_version = \".\".join(str(i) for i in (tuple(sum(x) for x in zip_longest(wheel.version_tuple, of, fillvalue=0))))\n    new_name = wheel.name.replace(wheel.version, new_version + pre_release)\n    return str(wheel.path.parent / new_name)\n\n\n_UP_NOW = datetime.now(tz=timezone.utc)\n_UPDATE_SKIP = {\n    \"started_just_now_no_complete\": UpdateLog(started=_UP_NOW, completed=None, versions=[], periodic=True),\n    \"started_1_hour_no_complete\": UpdateLog(\n        started=_UP_NOW - timedelta(hours=1),\n        completed=None,\n        versions=[],\n        periodic=True,\n    ),\n    \"completed_under_two_weeks\": UpdateLog(\n        started=None,\n        completed=_UP_NOW - timedelta(days=14),\n        versions=[],\n        periodic=True,\n    ),\n    \"started_just_now_completed_two_weeks\": UpdateLog(\n        started=_UP_NOW,\n        completed=_UP_NOW - timedelta(days=14, seconds=1),\n        versions=[],\n        periodic=True,\n    ),\n    \"started_1_hour_completed_two_weeks\": UpdateLog(\n        started=_UP_NOW - timedelta(hours=1),\n        completed=_UP_NOW - timedelta(days=14, seconds=1),\n        versions=[],\n        periodic=True,\n    ),\n}\n\n\n@pytest.mark.parametrize(\"u_log\", list(_UPDATE_SKIP.values()), ids=list(_UPDATE_SKIP.keys()))\ndef test_periodic_update_skip(u_log, mocker, for_py_version, session_app_data, time_freeze):\n    time_freeze(_UP_NOW)\n    mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n    mocker.patch(\"virtualenv.seed.wheels.periodic_update.trigger_update\", side_effect=RuntimeError)\n\n    result = periodic_update(\"setuptools\", None, for_py_version, None, [], session_app_data, os.environ, True)\n    assert result is None\n\n\n_UPDATE_YES = {\n    \"never_started\": UpdateLog(started=None, completed=None, versions=[], periodic=False),\n    \"started_1_hour\": UpdateLog(\n        started=_UP_NOW - timedelta(hours=1, microseconds=1),\n        completed=None,\n        versions=[],\n        periodic=False,\n    ),\n    \"completed_two_week\": UpdateLog(\n        started=_UP_NOW - timedelta(days=14, microseconds=2),\n        completed=_UP_NOW - timedelta(days=14, microseconds=1),\n        versions=[],\n        periodic=False,\n    ),\n}\n\n\n@pytest.mark.parametrize(\"u_log\", list(_UPDATE_YES.values()), ids=list(_UPDATE_YES.keys()))\ndef test_periodic_update_trigger(u_log, mocker, for_py_version, session_app_data, time_freeze):\n    time_freeze(_UP_NOW)\n    mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n    write = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.write\")\n    trigger_update_ = mocker.patch(\"virtualenv.seed.wheels.periodic_update.trigger_update\")\n\n    result = periodic_update(\"setuptools\", None, for_py_version, None, [], session_app_data, os.environ, True)\n\n    assert result is None\n    assert trigger_update_.call_count\n    assert write.call_count == 1\n    wrote_json = write.call_args[0][0]\n    assert wrote_json[\"periodic\"] is True\n    assert load_datetime(wrote_json[\"started\"]) == _UP_NOW\n\n\ndef test_trigger_update_no_debug(for_py_version, session_app_data, tmp_path, mocker, monkeypatch):\n    monkeypatch.delenv(\"_VIRTUALENV_PERIODIC_UPDATE_INLINE\", raising=False)\n    current = get_embed_wheel(\"setuptools\", for_py_version)\n    process = mocker.MagicMock()\n    process.communicate.return_value = None, None\n    Popen = mocker.patch(\"virtualenv.seed.wheels.periodic_update.Popen\", return_value=process)  # noqa: N806\n\n    trigger_update(\n        \"setuptools\",\n        for_py_version,\n        current,\n        [tmp_path / \"a\", tmp_path / \"b\"],\n        session_app_data,\n        os.environ,\n        True,\n    )\n\n    assert Popen.call_count == 1\n    args, kwargs = Popen.call_args\n    cmd = (\n        dedent(\n            \"\"\"\n        from virtualenv.report import setup_report, MAX_LEVEL\n        from virtualenv.seed.wheels.periodic_update import do_update\n        setup_report(MAX_LEVEL, show_pid=True)\n        do_update({!r}, {!r}, {!r}, {!r}, {!r}, {!r})\n        \"\"\",\n        )\n        .strip()\n        .format(\n            \"setuptools\",\n            for_py_version,\n            str(current.path),\n            str(session_app_data),\n            [str(tmp_path / \"a\"), str(tmp_path / \"b\")],\n            True,\n        )\n    )\n\n    assert args == ([sys.executable, \"-c\", cmd],)\n    expected = {\"stdout\": subprocess.DEVNULL, \"stderr\": subprocess.DEVNULL}\n    if sys.platform == \"win32\":\n        expected[\"creationflags\"] = CREATE_NO_WINDOW\n    assert kwargs == expected\n    assert process.communicate.call_count == 0\n\n\ndef test_trigger_update_debug(for_py_version, session_app_data, tmp_path, mocker, monkeypatch):\n    monkeypatch.setenv(\"_VIRTUALENV_PERIODIC_UPDATE_INLINE\", \"1\")\n    current = get_embed_wheel(\"pip\", for_py_version)\n\n    process = mocker.MagicMock()\n    process.communicate.return_value = None, None\n    Popen = mocker.patch(\"virtualenv.seed.wheels.periodic_update.Popen\", return_value=process)  # noqa: N806\n\n    trigger_update(\n        \"pip\",\n        for_py_version,\n        current,\n        [tmp_path / \"a\", tmp_path / \"b\"],\n        session_app_data,\n        os.environ,\n        False,\n    )\n\n    assert Popen.call_count == 1\n    args, kwargs = Popen.call_args\n    cmd = (\n        dedent(\n            \"\"\"\n        from virtualenv.report import setup_report, MAX_LEVEL\n        from virtualenv.seed.wheels.periodic_update import do_update\n        setup_report(MAX_LEVEL, show_pid=True)\n        do_update({!r}, {!r}, {!r}, {!r}, {!r}, {!r})\n        \"\"\",\n        )\n        .strip()\n        .format(\n            \"pip\",\n            for_py_version,\n            str(current.path),\n            str(session_app_data),\n            [str(tmp_path / \"a\"), str(tmp_path / \"b\")],\n            False,\n        )\n    )\n    assert args == ([sys.executable, \"-c\", cmd],)\n    expected = {\"stdout\": None, \"stderr\": None}\n    assert kwargs == expected\n    assert process.communicate.call_count == 1\n\n\ndef test_do_update_first(tmp_path, mocker, time_freeze):\n    time_freeze(_UP_NOW)\n    wheel = get_embed_wheel(\"pip\", \"3.9\")\n    app_data_outer = AppDataDiskFolder(str(tmp_path / \"app\"))\n    extra = tmp_path / \"extra\"\n    extra.mkdir()\n\n    pip_version_remote = [\n        (wheel_path(wheel, (1, 0, 0)), None),\n        (wheel_path(wheel, (0, 1, 0)), _UP_NOW - timedelta(days=1)),\n        (wheel_path(wheel, (0, 0, 1)), _UP_NOW - timedelta(days=2)),\n        (wheel.path, _UP_NOW - timedelta(days=3)),\n        (wheel_path(wheel, (-1, 0, 0)), _UP_NOW - timedelta(days=30)),\n    ]\n    download_wheels = (Wheel(Path(i[0])) for i in pip_version_remote)\n\n    def _download_wheel(  # noqa: PLR0913\n        distribution,\n        version_spec,  # noqa: ARG001\n        for_py_version,\n        search_dirs,\n        app_data,\n        to_folder,\n        env,  # noqa: ARG001\n    ):\n        assert distribution == \"pip\"\n        assert for_py_version == \"3.9\"\n        assert [str(i) for i in search_dirs] == [str(extra)]\n        assert isinstance(app_data, AppDataDiskFolder)\n        assert to_folder == app_data_outer.house\n        return next(download_wheels)\n\n    download_wheel = mocker.patch(\"virtualenv.seed.wheels.acquire.download_wheel\", side_effect=_download_wheel)\n    releases = {\n        Wheel(Path(wheel)).version: [\n            {\"upload_time\": datetime.strftime(release_date, \"%Y-%m-%dT%H:%M:%S\") if release_date is not None else None},\n        ]\n        for wheel, release_date in pip_version_remote\n    }\n    pypi_release = json.dumps({\"releases\": releases})\n\n    @contextmanager\n    def _release(of, context):\n        assert of == \"https://pypi.org/pypi/pip/json\"\n        assert context is None\n        yield StringIO(pypi_release)\n\n    url_o = mocker.patch(\"virtualenv.seed.wheels.periodic_update.urlopen\", side_effect=_release)\n\n    last_update = _UP_NOW - timedelta(days=14)\n    u_log = UpdateLog(started=last_update, completed=last_update, versions=[], periodic=True)\n    read_dict = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n    write = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.write\")\n    copy = mocker.patch(\"virtualenv.seed.wheels.periodic_update.copy2\")\n\n    versions = do_update(\"pip\", \"3.9\", str(pip_version_remote[-1][0]), str(app_data_outer), [str(extra)], True)\n\n    assert download_wheel.call_count == len(pip_version_remote)\n    assert url_o.call_count == 1\n    assert copy.call_count == 1\n\n    expected = [\n        NewVersion(Path(wheel).name, _UP_NOW, None if release is None else release.replace(microsecond=0), \"periodic\")\n        for wheel, release in pip_version_remote\n    ]\n    assert versions == expected\n\n    assert read_dict.call_count == 1\n    assert write.call_count == 1\n    wrote_json = write.call_args[0][0]\n    assert wrote_json == {\n        \"started\": dump_datetime(last_update),\n        \"completed\": dump_datetime(_UP_NOW),\n        \"periodic\": True,\n        \"versions\": [e.to_dict() for e in expected],\n    }\n\n\ndef test_do_update_skip_already_done(tmp_path, mocker, time_freeze):\n    time_freeze(_UP_NOW + timedelta(hours=1))\n    wheel = get_embed_wheel(\"pip\", \"3.9\")\n    app_data_outer = AppDataDiskFolder(str(tmp_path / \"app\"))\n    extra = tmp_path / \"extra\"\n    extra.mkdir()\n\n    def _download_wheel(  # noqa: PLR0913\n        distribution,  # noqa: ARG001\n        version_spec,  # noqa: ARG001\n        for_py_version,  # noqa: ARG001\n        search_dirs,  # noqa: ARG001\n        app_data,  # noqa: ARG001\n        to_folder,  # noqa: ARG001\n        env,  # noqa: ARG001\n    ):\n        return wheel.path\n\n    download_wheel = mocker.patch(\"virtualenv.seed.wheels.acquire.download_wheel\", side_effect=_download_wheel)\n    url_o = mocker.patch(\"virtualenv.seed.wheels.periodic_update.urlopen\", side_effect=RuntimeError)\n\n    released = _UP_NOW - timedelta(days=30)\n    u_log = UpdateLog(\n        started=_UP_NOW - timedelta(days=31),\n        completed=released,\n        versions=[NewVersion(filename=wheel.path.name, found_date=released, release_date=released, source=\"periodic\")],\n        periodic=True,\n    )\n    read_dict = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n    write = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.write\")\n\n    versions = do_update(\"pip\", \"3.9\", str(wheel.path), str(app_data_outer), [str(extra)], False)\n\n    assert download_wheel.call_count == 1\n    assert read_dict.call_count == 1\n    assert not url_o.call_count\n    assert versions == []\n\n    assert write.call_count == 1\n    wrote_json = write.call_args[0][0]\n    assert wrote_json == {\n        \"started\": dump_datetime(_UP_NOW + timedelta(hours=1)),\n        \"completed\": dump_datetime(_UP_NOW + timedelta(hours=1)),\n        \"periodic\": False,\n        \"versions\": [\n            {\n                \"filename\": wheel.path.name,\n                \"release_date\": dump_datetime(released),\n                \"found_date\": dump_datetime(released),\n                \"source\": \"manual\",  # changed from \"periodic\" to \"manual\"\n            },\n        ],\n    }\n\n\ndef test_new_version_eq():\n    now = datetime.now(tz=timezone.utc)\n    value = NewVersion(\"a\", now, now, \"periodic\")\n    assert value == NewVersion(\"a\", now, now, \"periodic\")\n\n\ndef test_new_version_ne():\n    assert NewVersion(\"a\", datetime.now(tz=timezone.utc), datetime.now(tz=timezone.utc), \"periodic\") != NewVersion(\n        \"a\",\n        datetime.now(tz=timezone.utc),\n        datetime.now(tz=timezone.utc) + timedelta(hours=1),\n        \"manual\",\n    )\n\n\ndef test_get_release_unsecure(mocker, caplog):\n    @contextmanager\n    def _release(of, context):\n        assert of == \"https://pypi.org/pypi/pip/json\"\n        if context is None:\n            msg = \"insecure\"\n            raise URLError(msg)\n        assert context\n        yield StringIO(json.dumps({\"releases\": {\"20.1\": [{\"upload_time\": \"2020-12-22T12:12:12\"}]}}))\n\n    url_o = mocker.patch(\"virtualenv.seed.wheels.periodic_update.urlopen\", side_effect=_release)\n\n    result = release_date_for_wheel_path(Path(\"pip-20.1.whl\"))\n\n    assert result == datetime(year=2020, month=12, day=22, hour=12, minute=12, second=12, tzinfo=timezone.utc)\n    assert url_o.call_count == 2\n    assert \"insecure\" in caplog.text\n    assert \" failed \" in caplog.text\n\n\ndef test_get_release_fails(mocker, caplog):\n    exc = RuntimeError(\"oh no\")\n    url_o = mocker.patch(\"virtualenv.seed.wheels.periodic_update.urlopen\", side_effect=exc)\n\n    result = release_date_for_wheel_path(Path(\"pip-20.1.whl\"))\n\n    assert result is None\n    assert url_o.call_count == 1\n    assert repr(exc) in caplog.text\n\n\ndef mock_download(mocker, pip_version_remote):\n    def download():\n        index = 0\n        while True:\n            path = pip_version_remote[index]\n            index += 1\n            yield Wheel(Path(path))\n\n    do = download()\n    return mocker.patch(\n        \"virtualenv.seed.wheels.acquire.download_wheel\",\n        side_effect=lambda *a, **k: next(do),  # noqa: ARG005\n    )\n\n\ndef test_download_stop_with_embed(tmp_path, mocker, time_freeze):\n    time_freeze(_UP_NOW)\n    wheel = get_embed_wheel(\"pip\", \"3.9\")\n    app_data_outer = AppDataDiskFolder(str(tmp_path / \"app\"))\n    pip_version_remote = [wheel_path(wheel, (0, 0, 2)), wheel_path(wheel, (0, 0, 1)), wheel_path(wheel, (-1, 0, 0))]\n\n    download_wheel = mock_download(mocker, pip_version_remote)\n    url_o = mocker.patch(\"virtualenv.seed.wheels.periodic_update.urlopen\", side_effect=URLError(\"unavailable\"))\n\n    last_update = _UP_NOW - timedelta(days=14)\n    u_log = UpdateLog(started=last_update, completed=last_update, versions=[], periodic=True)\n    read_dict = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n    write = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.write\")\n\n    do_update(\"pip\", \"3.9\", str(wheel.path), str(app_data_outer), [], True)\n\n    assert download_wheel.call_count == 3\n    assert url_o.call_count == 2\n\n    assert read_dict.call_count == 1\n    assert write.call_count == 1\n\n\ndef test_download_manual_stop_after_one_download(tmp_path, mocker, time_freeze):\n    time_freeze(_UP_NOW)\n    wheel = get_embed_wheel(\"pip\", \"3.9\")\n    app_data_outer = AppDataDiskFolder(str(tmp_path / \"app\"))\n    pip_version_remote = [wheel_path(wheel, (0, 1, 1))]\n\n    download_wheel = mock_download(mocker, pip_version_remote)\n    url_o = mocker.patch(\"virtualenv.seed.wheels.periodic_update.urlopen\", side_effect=URLError(\"unavailable\"))\n\n    last_update = _UP_NOW - timedelta(days=14)\n    u_log = UpdateLog(started=last_update, completed=last_update, versions=[], periodic=True)\n    read_dict = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n    write = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.write\")\n\n    do_update(\"pip\", \"3.9\", str(wheel.path), str(app_data_outer), [], False)\n\n    assert download_wheel.call_count == 1\n    assert url_o.call_count == 2\n    assert read_dict.call_count == 1\n    assert write.call_count == 1\n\n\ndef test_download_manual_ignores_pre_release(tmp_path, mocker, time_freeze):\n    time_freeze(_UP_NOW)\n    wheel = get_embed_wheel(\"pip\", \"3.9\")\n    app_data_outer = AppDataDiskFolder(str(tmp_path / \"app\"))\n    pip_version_remote = [wheel_path(wheel, (0, 0, 1))]\n    pip_version_pre = NewVersion(Path(wheel_path(wheel, (0, 1, 0), \"b1\")).name, _UP_NOW, None, \"downloaded\")\n\n    download_wheel = mock_download(mocker, pip_version_remote)\n    url_o = mocker.patch(\"virtualenv.seed.wheels.periodic_update.urlopen\", side_effect=URLError(\"unavailable\"))\n\n    last_update = _UP_NOW - timedelta(days=14)\n    u_log = UpdateLog(started=last_update, completed=last_update, versions=[pip_version_pre], periodic=True)\n    read_dict = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n    write = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.write\")\n\n    do_update(\"pip\", \"3.9\", str(wheel.path), str(app_data_outer), [], False)\n\n    assert download_wheel.call_count == 1\n    assert url_o.call_count == 2\n    assert read_dict.call_count == 1\n    assert write.call_count == 1\n    wrote_json = write.call_args[0][0]\n    assert wrote_json[\"versions\"] == [\n        {\n            \"filename\": Path(pip_version_remote[0]).name,\n            \"release_date\": None,\n            \"found_date\": dump_datetime(_UP_NOW),\n            \"source\": \"manual\",\n        },\n        pip_version_pre.to_dict(),\n    ]\n\n\ndef test_download_periodic_stop_at_first_usable(tmp_path, mocker, time_freeze):\n    time_freeze(_UP_NOW)\n    wheel = get_embed_wheel(\"pip\", \"3.9\")\n    app_data_outer = AppDataDiskFolder(str(tmp_path / \"app\"))\n    pip_version_remote = [wheel_path(wheel, (0, 1, 1)), wheel_path(wheel, (0, 1, 0))]\n    rel_date_remote = [_UP_NOW - timedelta(days=1), _UP_NOW - timedelta(days=30)]\n\n    download_wheel = mock_download(mocker, pip_version_remote)\n\n    rel_date_gen = iter(rel_date_remote)\n    release_date = mocker.patch(\n        \"virtualenv.seed.wheels.periodic_update.release_date_for_wheel_path\",\n        side_effect=lambda *a, **k: next(rel_date_gen),  # noqa: ARG005\n    )\n\n    last_update = _UP_NOW - timedelta(days=14)\n    u_log = UpdateLog(started=last_update, completed=last_update, versions=[], periodic=True)\n    read_dict = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n    write = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.write\")\n\n    do_update(\"pip\", \"3.9\", str(wheel.path), str(app_data_outer), [], True)\n\n    assert download_wheel.call_count == 2\n    assert release_date.call_count == 2\n    assert read_dict.call_count == 1\n    assert write.call_count == 1\n\n\ndef test_download_periodic_stop_at_first_usable_with_previous_minor(tmp_path, mocker, time_freeze):\n    time_freeze(_UP_NOW)\n    wheel = get_embed_wheel(\"pip\", \"3.9\")\n    app_data_outer = AppDataDiskFolder(str(tmp_path / \"app\"))\n    pip_version_remote = [wheel_path(wheel, (0, 1, 1)), wheel_path(wheel, (0, 1, 0)), wheel_path(wheel, (0, -1, 0))]\n    rel_date_remote = [_UP_NOW - timedelta(days=1), _UP_NOW - timedelta(days=30), _UP_NOW - timedelta(days=40)]\n    downloaded_versions = [\n        NewVersion(Path(pip_version_remote[2]).name, rel_date_remote[2], None, \"download\"),\n        NewVersion(Path(pip_version_remote[0]).name, rel_date_remote[0], None, \"download\"),\n    ]\n\n    download_wheel = mock_download(mocker, pip_version_remote)\n\n    rel_date_gen = iter(rel_date_remote)\n    release_date = mocker.patch(\n        \"virtualenv.seed.wheels.periodic_update.release_date_for_wheel_path\",\n        side_effect=lambda *a, **k: next(rel_date_gen),  # noqa: ARG005\n    )\n\n    last_update = _UP_NOW - timedelta(days=14)\n    u_log = UpdateLog(\n        started=last_update,\n        completed=last_update,\n        versions=downloaded_versions,\n        periodic=True,\n    )\n    read_dict = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.read\", return_value=u_log.to_dict())\n    write = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.write\")\n\n    do_update(\"pip\", \"3.9\", str(wheel.path), str(app_data_outer), [], True)\n\n    assert download_wheel.call_count == 2\n    assert release_date.call_count == 2\n    assert read_dict.call_count == 1\n    assert write.call_count == 1\n    wrote_json = write.call_args[0][0]\n    assert wrote_json[\"versions\"] == [\n        {\n            \"filename\": Path(pip_version_remote[0]).name,\n            \"release_date\": dump_datetime(rel_date_remote[0]),\n            \"found_date\": dump_datetime(_UP_NOW),\n            \"source\": \"periodic\",\n        },\n        {\n            \"filename\": Path(pip_version_remote[1]).name,\n            \"release_date\": dump_datetime(rel_date_remote[1]),\n            \"found_date\": dump_datetime(_UP_NOW),\n            \"source\": \"periodic\",\n        },\n        downloaded_versions[0].to_dict(),\n    ]\n", "tests/unit/seed/wheels/test_acquire_find_wheel.py": "from __future__ import annotations\n\nimport pytest\n\nfrom virtualenv.seed.wheels.acquire import find_compatible_in_house\nfrom virtualenv.seed.wheels.embed import BUNDLE_FOLDER, MAX, get_embed_wheel\n\n\ndef test_find_latest_none(for_py_version):\n    result = find_compatible_in_house(\"setuptools\", None, for_py_version, BUNDLE_FOLDER)\n    expected = get_embed_wheel(\"setuptools\", for_py_version)\n    assert result.path == expected.path\n\n\ndef test_find_latest_string(for_py_version):\n    result = find_compatible_in_house(\"setuptools\", \"\", for_py_version, BUNDLE_FOLDER)\n    expected = get_embed_wheel(\"setuptools\", for_py_version)\n    assert result.path == expected.path\n\n\ndef test_find_exact(for_py_version):\n    expected = get_embed_wheel(\"setuptools\", for_py_version)\n    result = find_compatible_in_house(\"setuptools\", f\"=={expected.version}\", for_py_version, BUNDLE_FOLDER)\n    assert result.path == expected.path\n\n\ndef test_find_bad_spec():\n    with pytest.raises(ValueError, match=\"bad\"):\n        find_compatible_in_house(\"setuptools\", \"bad\", MAX, BUNDLE_FOLDER)\n", "tests/unit/seed/wheels/test_wheels_util.py": "from __future__ import annotations\n\nimport pytest\n\nfrom virtualenv.seed.wheels.embed import MAX, get_embed_wheel\nfrom virtualenv.seed.wheels.util import Wheel\n\n\ndef test_wheel_support_no_python_requires(mocker):\n    wheel = get_embed_wheel(\"setuptools\", for_py_version=None)\n    zip_mock = mocker.MagicMock()\n    mocker.patch(\"virtualenv.seed.wheels.util.ZipFile\", new=zip_mock)\n    zip_mock.return_value.__enter__.return_value.read = lambda name: b\"\"  # noqa: ARG005\n\n    supports = wheel.support_py(\"3.8\")\n    assert supports is True\n\n\ndef test_bad_as_version_tuple():\n    with pytest.raises(ValueError, match=\"bad\"):\n        Wheel.as_version_tuple(\"bad\")\n\n\ndef test_wheel_not_support():\n    wheel = get_embed_wheel(\"setuptools\", MAX)\n    assert wheel.support_py(\"3.3\") is False\n\n\ndef test_wheel_repr():\n    wheel = get_embed_wheel(\"setuptools\", MAX)\n    assert str(wheel.path) in repr(wheel)\n", "tests/unit/seed/wheels/test_acquire.py": "from __future__ import annotations\n\nimport os\nimport sys\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom subprocess import CalledProcessError\nfrom typing import TYPE_CHECKING, Callable\n\nimport pytest\n\nfrom virtualenv.app_data import AppDataDiskFolder\nfrom virtualenv.seed.wheels.acquire import download_wheel, get_wheel, pip_wheel_env_run\nfrom virtualenv.seed.wheels.embed import BUNDLE_FOLDER, get_embed_wheel\nfrom virtualenv.seed.wheels.periodic_update import dump_datetime\nfrom virtualenv.seed.wheels.util import Wheel, discover_wheels\n\nif TYPE_CHECKING:\n    from unittest.mock import MagicMock\n\n    from pytest_mock import MockerFixture\n\n\n@pytest.fixture(autouse=True)\ndef _fake_release_date(mocker):\n    mocker.patch(\"virtualenv.seed.wheels.periodic_update.release_date_for_wheel_path\", return_value=None)\n\n\ndef test_pip_wheel_env_run_could_not_find(session_app_data, mocker):\n    mocker.patch(\"virtualenv.seed.wheels.acquire.from_bundle\", return_value=None)\n    with pytest.raises(RuntimeError, match=\"could not find the embedded pip\"):\n        pip_wheel_env_run([], session_app_data, os.environ)\n\n\ndef test_download_wheel_bad_output(mocker, for_py_version, session_app_data):\n    \"\"\"if the download contains no match for what wheel was downloaded, pick one that matches from target\"\"\"\n    distribution = \"setuptools\"\n    p_open = mocker.MagicMock()\n    mocker.patch(\"virtualenv.seed.wheels.acquire.Popen\", return_value=p_open)\n    p_open.communicate.return_value = \"\", \"\"\n    p_open.returncode = 0\n\n    embed = get_embed_wheel(distribution, for_py_version)\n    as_path = mocker.MagicMock()\n    available = discover_wheels(BUNDLE_FOLDER, \"setuptools\", None, for_py_version)\n    as_path.iterdir.return_value = [i.path for i in available]\n\n    result = download_wheel(\n        distribution,\n        f\"=={embed.version}\",\n        for_py_version,\n        [],\n        session_app_data,\n        as_path,\n        os.environ,\n    )\n    assert result.path == embed.path\n\n\ndef test_download_fails(mocker, for_py_version, session_app_data):\n    p_open = mocker.MagicMock()\n    mocker.patch(\"virtualenv.seed.wheels.acquire.Popen\", return_value=p_open)\n    p_open.communicate.return_value = \"out\", \"err\"\n    p_open.returncode = 1\n\n    as_path = mocker.MagicMock()\n    with pytest.raises(CalledProcessError) as context:\n        download_wheel(\"pip\", \"==1\", for_py_version, [], session_app_data, as_path, os.environ)\n    exc = context.value\n    assert exc.output == \"out\"\n    assert exc.stderr == \"err\"\n    assert exc.returncode == 1\n    assert [\n        sys.executable,\n        \"-m\",\n        \"pip\",\n        \"download\",\n        \"--progress-bar\",\n        \"off\",\n        \"--disable-pip-version-check\",\n        \"--only-binary=:all:\",\n        \"--no-deps\",\n        \"--python-version\",\n        for_py_version,\n        \"-d\",\n        str(as_path),\n        \"pip==1\",\n    ] == exc.cmd\n\n\n@pytest.fixture()\ndef downloaded_wheel(mocker):\n    wheel = Wheel.from_path(Path(\"setuptools-0.0.0-py2.py3-none-any.whl\"))\n    return wheel, mocker.patch(\"virtualenv.seed.wheels.acquire.download_wheel\", return_value=wheel)\n\n\n@pytest.mark.parametrize(\"version\", [\"bundle\", \"0.0.0\"])\ndef test_get_wheel_download_called(mocker, for_py_version, session_app_data, downloaded_wheel, version):\n    distribution = \"setuptools\"\n    write = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.write\")\n    wheel = get_wheel(distribution, version, for_py_version, [], True, session_app_data, False, os.environ)\n    assert wheel is not None\n    assert wheel.name == downloaded_wheel[0].name\n    assert downloaded_wheel[1].call_count == 1\n    assert write.call_count == 1\n\n\n@pytest.mark.parametrize(\"version\", [\"embed\", \"pinned\"])\ndef test_get_wheel_download_not_called(mocker, for_py_version, session_app_data, downloaded_wheel, version):\n    distribution = \"setuptools\"\n    expected = get_embed_wheel(distribution, for_py_version)\n    if version == \"pinned\":\n        version = expected.version\n    write = mocker.patch(\"virtualenv.app_data.via_disk_folder.JSONStoreDisk.write\")\n    wheel = get_wheel(distribution, version, for_py_version, [], True, session_app_data, False, os.environ)\n    assert wheel is not None\n    assert wheel.name == expected.name\n    assert downloaded_wheel[1].call_count == 0\n    assert write.call_count == 0\n\n\ndef test_get_wheel_download_cached(\n    tmp_path: Path,\n    mocker: MockerFixture,\n    for_py_version: str,\n    downloaded_wheel: tuple[Wheel, MagicMock],\n    time_freeze: Callable[[datetime], None],\n) -> None:\n    time_freeze(datetime.now(tz=timezone.utc))\n    from virtualenv.app_data.via_disk_folder import JSONStoreDisk  # noqa: PLC0415\n\n    app_data = AppDataDiskFolder(folder=str(tmp_path))\n    expected = downloaded_wheel[0]\n    write = mocker.spy(JSONStoreDisk, \"write\")\n    # 1st call, not cached, download is called\n    wheel = get_wheel(expected.distribution, expected.version, for_py_version, [], True, app_data, False, os.environ)\n    assert wheel is not None\n    assert wheel.name == expected.name\n    assert downloaded_wheel[1].call_count == 1\n    assert write.call_count == 1\n    # 2nd call, cached, download is not called\n    wheel = get_wheel(expected.distribution, expected.version, for_py_version, [], True, app_data, False, os.environ)\n    assert wheel is not None\n    assert wheel.name == expected.name\n    assert downloaded_wheel[1].call_count == 1\n    assert write.call_count == 1\n    wrote_json = write.call_args[0][1]\n    assert wrote_json == {\n        \"completed\": None,\n        \"periodic\": None,\n        \"started\": None,\n        \"versions\": [\n            {\n                \"filename\": expected.name,\n                \"release_date\": None,\n                \"found_date\": dump_datetime(datetime.now(tz=timezone.utc)),\n                \"source\": \"download\",\n            },\n        ],\n    }\n", "tests/unit/config/test_env_var.py": "from __future__ import annotations\n\nimport os\nfrom pathlib import Path\n\nimport pytest\n\nfrom virtualenv.config.cli.parser import VirtualEnvOptions\nfrom virtualenv.config.ini import IniConfig\nfrom virtualenv.create.via_global_ref.builtin.cpython.common import is_macos_brew\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.run import session_via_cli\n\n\n@pytest.fixture()\ndef _empty_conf(tmp_path, monkeypatch):\n    conf = tmp_path / \"conf.ini\"\n    monkeypatch.setenv(IniConfig.VIRTUALENV_CONFIG_FILE_ENV_VAR, str(conf))\n    conf.write_text(\"[virtualenv]\", encoding=\"utf-8\")\n\n\n@pytest.mark.usefixtures(\"_empty_conf\")\ndef test_value_ok(monkeypatch):\n    monkeypatch.setenv(\"VIRTUALENV_VERBOSE\", \"5\")\n    result = session_via_cli([\"venv\"])\n    assert result.verbosity == 5\n\n\n@pytest.mark.usefixtures(\"_empty_conf\")\ndef test_value_bad(monkeypatch, caplog):\n    monkeypatch.setenv(\"VIRTUALENV_VERBOSE\", \"a\")\n    result = session_via_cli([\"venv\"])\n    assert result.verbosity == 2\n    assert len(caplog.messages) == 1\n    assert \"env var VIRTUALENV_VERBOSE failed to convert\" in caplog.messages[0]\n    assert \"invalid literal\" in caplog.messages[0]\n\n\ndef test_python_via_env_var(monkeypatch):\n    options = VirtualEnvOptions()\n    monkeypatch.setenv(\"VIRTUALENV_PYTHON\", \"python3\")\n    session_via_cli([\"venv\"], options=options)\n    assert options.python == [\"python3\"]\n\n\ndef test_python_multi_value_via_env_var(monkeypatch):\n    options = VirtualEnvOptions()\n    monkeypatch.setenv(\"VIRTUALENV_PYTHON\", \"python3,python2\")\n    session_via_cli([\"venv\"], options=options)\n    assert options.python == [\"python3\", \"python2\"]\n\n\ndef test_python_multi_value_newline_via_env_var(monkeypatch):\n    options = VirtualEnvOptions()\n    monkeypatch.setenv(\"VIRTUALENV_PYTHON\", \"python3\\npython2\")\n    session_via_cli([\"venv\"], options=options)\n    assert options.python == [\"python3\", \"python2\"]\n\n\ndef test_python_multi_value_prefer_newline_via_env_var(monkeypatch):\n    options = VirtualEnvOptions()\n    monkeypatch.setenv(\"VIRTUALENV_PYTHON\", \"python3\\npython2,python27\")\n    session_via_cli([\"venv\"], options=options)\n    assert options.python == [\"python3\", \"python2,python27\"]\n\n\ndef test_extra_search_dir_via_env_var(tmp_path, monkeypatch):\n    monkeypatch.chdir(tmp_path)\n    value = f\"a{os.linesep}0{os.linesep}b{os.pathsep}c\"\n    monkeypatch.setenv(\"VIRTUALENV_EXTRA_SEARCH_DIR\", str(value))\n    (tmp_path / \"a\").mkdir()\n    (tmp_path / \"b\").mkdir()\n    (tmp_path / \"c\").mkdir()\n    result = session_via_cli([\"venv\"])\n    assert result.seeder.extra_search_dir == [Path(\"a\").resolve(), Path(\"b\").resolve(), Path(\"c\").resolve()]\n\n\n@pytest.mark.usefixtures(\"_empty_conf\")\n@pytest.mark.skipif(is_macos_brew(PythonInfo.current_system()), reason=\"no copy on brew\")\ndef test_value_alias(monkeypatch, mocker):\n    from virtualenv.config.cli.parser import VirtualEnvConfigParser  # noqa: PLC0415\n\n    prev = VirtualEnvConfigParser._fix_default  # noqa: SLF001\n\n    def func(self, action):\n        if action.dest == \"symlinks\":\n            action.default = True  # force symlink to be true\n        elif action.dest == \"copies\":\n            action.default = False  # force default copy to be False, we expect env-var to flip it\n        return prev(self, action)\n\n    mocker.patch(\"virtualenv.run.VirtualEnvConfigParser._fix_default\", side_effect=func, autospec=True)\n\n    monkeypatch.delenv(\"SYMLINKS\", raising=False)\n    monkeypatch.delenv(\"VIRTUALENV_COPIES\", raising=False)\n    monkeypatch.setenv(\"VIRTUALENV_ALWAYS_COPY\", \"1\")\n    result = session_via_cli([\"venv\"])\n    assert result.creator.symlinks is False\n", "tests/unit/config/test_ini.py": "from __future__ import annotations\n\nimport sys\nfrom textwrap import dedent\n\nimport pytest\n\nfrom virtualenv.info import IS_PYPY, IS_WIN, fs_supports_symlink\nfrom virtualenv.run import session_via_cli\n\n\n@pytest.mark.skipif(not fs_supports_symlink(), reason=\"symlink is not supported\")\n@pytest.mark.xfail(\n    # https://doc.pypy.org/en/latest/install.html?highlight=symlink#download-a-pre-built-pypy\n    IS_PYPY and IS_WIN and sys.version_info[0:2] >= (3, 9),\n    reason=\"symlink is not supported\",\n)\ndef test_ini_can_be_overwritten_by_flag(tmp_path, monkeypatch):\n    custom_ini = tmp_path / \"conf.ini\"\n    custom_ini.write_text(\n        dedent(\n            \"\"\"\n        [virtualenv]\n        copies = True\n        \"\"\",\n        ),\n        encoding=\"utf-8\",\n    )\n    monkeypatch.setenv(\"VIRTUALENV_CONFIG_FILE\", str(custom_ini))\n\n    result = session_via_cli([\"venv\", \"--symlinks\"])\n\n    symlinks = result.creator.symlinks\n    assert symlinks is True\n", "tests/unit/config/test___main__.py": "from __future__ import annotations\n\nimport re\nimport sys\nfrom subprocess import PIPE, Popen, check_output\nfrom typing import TYPE_CHECKING\n\nimport pytest\n\nfrom virtualenv.__main__ import run_with_catch\nfrom virtualenv.util.error import ProcessCallFailedError\n\nif TYPE_CHECKING:\n    from pathlib import Path\n\n\ndef test_main():\n    process = Popen(\n        [sys.executable, \"-m\", \"virtualenv\", \"--help\"],\n        universal_newlines=True,\n        stdout=PIPE,\n        encoding=\"utf-8\",\n    )\n    out, _ = process.communicate()\n    assert not process.returncode\n    assert out\n\n\n@pytest.fixture()\ndef raise_on_session_done(mocker):\n    def _func(exception):\n        from virtualenv.run import session_via_cli  # noqa: PLC0415\n\n        prev_session = session_via_cli\n\n        def _session_via_cli(args, options=None, setup_logging=True, env=None):\n            prev_session(args, options, setup_logging, env)\n            raise exception\n\n        mocker.patch(\"virtualenv.run.session_via_cli\", side_effect=_session_via_cli)\n\n    return _func\n\n\ndef test_fail_no_traceback(raise_on_session_done, tmp_path, capsys):\n    raise_on_session_done(ProcessCallFailedError(code=2, out=\"out\\n\", err=\"err\\n\", cmd=[\"something\"]))\n    with pytest.raises(SystemExit) as context:\n        run_with_catch([str(tmp_path)])\n    assert context.value.code == 2\n    out, err = capsys.readouterr()\n    assert out == f\"subprocess call failed for [{'something'!r}] with code 2\\nout\\nSystemExit: 2\\n\"\n    assert err == \"err\\n\"\n\n\ndef test_fail_with_traceback(raise_on_session_done, tmp_path, capsys):\n    raise_on_session_done(TypeError(\"something bad\"))\n\n    with pytest.raises(TypeError, match=\"something bad\"):\n        run_with_catch([str(tmp_path), \"--with-traceback\"])\n    out, err = capsys.readouterr()\n    assert not out\n    assert not err\n\n\n@pytest.mark.usefixtures(\"session_app_data\")\ndef test_session_report_full(tmp_path: Path, capsys: pytest.CaptureFixture[str]) -> None:\n    run_with_catch([str(tmp_path), \"--setuptools\", \"bundle\", \"--wheel\", \"bundle\"])\n    out, err = capsys.readouterr()\n    assert not err\n    lines = out.splitlines()\n    regexes = [\n        r\"created virtual environment .* in \\d+ms\",\n        r\"  creator .*\",\n        r\"  seeder .*\",\n        r\"    added seed packages: .*pip==.*, setuptools==.*, wheel==.*\",\n        r\"  activators .*\",\n    ]\n    _match_regexes(lines, regexes)\n\n\ndef _match_regexes(lines, regexes):\n    for line, regex in zip(lines, regexes):\n        comp_regex = re.compile(rf\"^{regex}$\")\n        assert comp_regex.match(line), line\n\n\n@pytest.mark.usefixtures(\"session_app_data\")\ndef test_session_report_minimal(tmp_path, capsys):\n    run_with_catch([str(tmp_path), \"--activators\", \"\", \"--without-pip\"])\n    out, err = capsys.readouterr()\n    assert not err\n    lines = out.splitlines()\n    regexes = [\n        r\"created virtual environment .* in \\d+ms\",\n        r\"  creator .*\",\n    ]\n    _match_regexes(lines, regexes)\n\n\n@pytest.mark.usefixtures(\"session_app_data\")\ndef test_session_report_subprocess(tmp_path):\n    # when called via a subprocess the logging framework should flush and POSIX line normalization happen\n    out = check_output(\n        [sys.executable, \"-m\", \"virtualenv\", str(tmp_path), \"--activators\", \"powershell\", \"--without-pip\"],\n        text=True,\n        encoding=\"utf-8\",\n    )\n    lines = out.split(\"\\n\")\n    regexes = [\n        r\"created virtual environment .* in \\d+ms\",\n        r\"  creator .*\",\n        r\"  activators .*\",\n    ]\n    _match_regexes(lines, regexes)\n", "tests/unit/config/cli/test_parser.py": "from __future__ import annotations\n\nimport os\nfrom contextlib import contextmanager\n\nimport pytest\n\nfrom virtualenv.config.cli.parser import VirtualEnvConfigParser, VirtualEnvOptions\nfrom virtualenv.config.ini import IniConfig\nfrom virtualenv.run import session_via_cli\n\n\n@pytest.fixture()\ndef gen_parser_no_conf_env(monkeypatch, tmp_path):\n    keys_to_delete = {key for key in os.environ if key.startswith(\"VIRTUALENV_\")}\n    for key in keys_to_delete:\n        monkeypatch.delenv(key)\n    monkeypatch.setenv(IniConfig.VIRTUALENV_CONFIG_FILE_ENV_VAR, str(tmp_path / \"missing\"))\n\n    @contextmanager\n    def _build():\n        parser = VirtualEnvConfigParser()\n\n        def _run(*args):\n            return parser.parse_args(args=args)\n\n        yield parser, _run\n        parser.enable_help()\n\n    return _build\n\n\ndef test_flag(gen_parser_no_conf_env):\n    with gen_parser_no_conf_env() as (parser, run):\n        parser.add_argument(\"--clear\", dest=\"clear\", action=\"store_true\", help=\"it\", default=False)\n    result = run()\n    assert result.clear is False\n    result = run(\"--clear\")\n    assert result.clear is True\n\n\ndef test_reset_app_data_does_not_conflict_clear():\n    options = VirtualEnvOptions()\n    session_via_cli([\"--clear\", \"venv\"], options=options)\n    assert options.clear is True\n    assert options.reset_app_data is False\n\n\ndef test_builtin_discovery_class_preferred(mocker):\n    mocker.patch(\n        \"virtualenv.run.plugin.discovery._get_default_discovery\",\n        return_value=[\"pluginA\", \"pluginX\", \"builtin\", \"Aplugin\", \"Xplugin\"],\n    )\n\n    options = VirtualEnvOptions()\n    session_via_cli([\"venv\"], options=options)\n    assert options.discovery == \"builtin\"\n", "src/virtualenv/report.py": "from __future__ import annotations\n\nimport logging\nimport sys\n\nLEVELS = {\n    0: logging.CRITICAL,\n    1: logging.ERROR,\n    2: logging.WARNING,\n    3: logging.INFO,\n    4: logging.DEBUG,\n    5: logging.NOTSET,\n}\n\nMAX_LEVEL = max(LEVELS.keys())\nLOGGER = logging.getLogger()\n\n\ndef setup_report(verbosity, show_pid=False):  # noqa: FBT002\n    _clean_handlers(LOGGER)\n    verbosity = min(verbosity, MAX_LEVEL)  # pragma: no cover\n    level = LEVELS[verbosity]\n    msg_format = \"%(message)s\"\n    if level <= logging.DEBUG:\n        locate = \"module\"\n        msg_format = f\"%(relativeCreated)d {msg_format} [%(levelname)s %({locate})s:%(lineno)d]\"\n    if show_pid:\n        msg_format = f\"[%(process)d] {msg_format}\"\n    formatter = logging.Formatter(msg_format)\n    stream_handler = logging.StreamHandler(stream=sys.stdout)\n    stream_handler.setLevel(level)\n    LOGGER.setLevel(logging.NOTSET)\n    stream_handler.setFormatter(formatter)\n    LOGGER.addHandler(stream_handler)\n    level_name = logging.getLevelName(level)\n    logging.debug(\"setup logging to %s\", level_name)\n    logging.getLogger(\"distlib\").setLevel(logging.ERROR)\n    return verbosity\n\n\ndef _clean_handlers(log):\n    for log_handler in list(log.handlers):  # remove handlers of libraries\n        log.removeHandler(log_handler)\n\n\n__all__ = [\n    \"LEVELS\",\n    \"MAX_LEVEL\",\n    \"setup_report\",\n]\n", "src/virtualenv/info.py": "from __future__ import annotations\n\nimport logging\nimport os\nimport platform\nimport sys\nimport tempfile\n\nIMPLEMENTATION = platform.python_implementation()\nIS_PYPY = IMPLEMENTATION == \"PyPy\"\nIS_CPYTHON = IMPLEMENTATION == \"CPython\"\nIS_WIN = sys.platform == \"win32\"\nIS_MAC_ARM64 = sys.platform == \"darwin\" and platform.machine() == \"arm64\"\nROOT = os.path.realpath(os.path.join(os.path.abspath(__file__), os.path.pardir, os.path.pardir))\nIS_ZIPAPP = os.path.isfile(ROOT)\n_CAN_SYMLINK = _FS_CASE_SENSITIVE = _CFG_DIR = _DATA_DIR = None\n\n\ndef fs_is_case_sensitive():\n    global _FS_CASE_SENSITIVE  # noqa: PLW0603\n\n    if _FS_CASE_SENSITIVE is None:\n        with tempfile.NamedTemporaryFile(prefix=\"TmP\") as tmp_file:\n            _FS_CASE_SENSITIVE = not os.path.exists(tmp_file.name.lower())\n            logging.debug(\"filesystem is %scase-sensitive\", \"\" if _FS_CASE_SENSITIVE else \"not \")\n    return _FS_CASE_SENSITIVE\n\n\ndef fs_supports_symlink():\n    global _CAN_SYMLINK  # noqa: PLW0603\n\n    if _CAN_SYMLINK is None:\n        can = False\n        if hasattr(os, \"symlink\"):\n            if IS_WIN:\n                with tempfile.NamedTemporaryFile(prefix=\"TmP\") as tmp_file:\n                    temp_dir = os.path.dirname(tmp_file.name)\n                    dest = os.path.join(temp_dir, f\"{tmp_file.name}-{'b'}\")\n                    try:\n                        os.symlink(tmp_file.name, dest)\n                        can = True\n                    except (OSError, NotImplementedError):\n                        pass\n                logging.debug(\"symlink on filesystem does%s work\", \"\" if can else \" not\")\n            else:\n                can = True\n        _CAN_SYMLINK = can\n    return _CAN_SYMLINK\n\n\ndef fs_path_id(path: str) -> str:\n    return path.casefold() if fs_is_case_sensitive() else path\n\n\n__all__ = (\n    \"IS_CPYTHON\",\n    \"IS_MAC_ARM64\",\n    \"IS_PYPY\",\n    \"IS_WIN\",\n    \"IS_ZIPAPP\",\n    \"ROOT\",\n    \"fs_is_case_sensitive\",\n    \"fs_path_id\",\n    \"fs_supports_symlink\",\n)\n", "src/virtualenv/__main__.py": "from __future__ import annotations\n\nimport logging\nimport os\nimport sys\nfrom timeit import default_timer\n\n\ndef run(args=None, options=None, env=None):\n    env = os.environ if env is None else env\n    start = default_timer()\n    from virtualenv.run import cli_run  # noqa: PLC0415\n    from virtualenv.util.error import ProcessCallFailedError  # noqa: PLC0415\n\n    if args is None:\n        args = sys.argv[1:]\n    try:\n        session = cli_run(args, options, env)\n        logging.warning(LogSession(session, start))\n    except ProcessCallFailedError as exception:\n        print(f\"subprocess call failed for {exception.cmd} with code {exception.code}\")  # noqa: T201\n        print(exception.out, file=sys.stdout, end=\"\")  # noqa: T201\n        print(exception.err, file=sys.stderr, end=\"\")  # noqa: T201\n        raise SystemExit(exception.code)  # noqa: B904\n\n\nclass LogSession:\n    def __init__(self, session, start) -> None:\n        self.session = session\n        self.start = start\n\n    def __str__(self) -> str:\n        spec = self.session.creator.interpreter.spec\n        elapsed = (default_timer() - self.start) * 1000\n        lines = [\n            f\"created virtual environment {spec} in {elapsed:.0f}ms\",\n            f\"  creator {self.session.creator!s}\",\n        ]\n        if self.session.seeder.enabled:\n            lines.append(f\"  seeder {self.session.seeder!s}\")\n            path = self.session.creator.purelib.iterdir()\n            packages = sorted(\"==\".join(i.stem.split(\"-\")) for i in path if i.suffix == \".dist-info\")\n            lines.append(f\"    added seed packages: {', '.join(packages)}\")\n\n        if self.session.activators:\n            lines.append(f\"  activators {','.join(i.__class__.__name__ for i in self.session.activators)}\")\n        return \"\\n\".join(lines)\n\n\ndef run_with_catch(args=None, env=None):\n    from virtualenv.config.cli.parser import VirtualEnvOptions  # noqa: PLC0415\n\n    env = os.environ if env is None else env\n    options = VirtualEnvOptions()\n    try:\n        run(args, options, env)\n    except (KeyboardInterrupt, SystemExit, Exception) as exception:\n        try:\n            if getattr(options, \"with_traceback\", False):\n                raise\n            if not (isinstance(exception, SystemExit) and exception.code == 0):\n                logging.error(\"%s: %s\", type(exception).__name__, exception)  # noqa: TRY400\n            code = exception.code if isinstance(exception, SystemExit) else 1\n            sys.exit(code)\n        finally:\n            logging.shutdown()  # force flush of log messages before the trace is printed\n\n\nif __name__ == \"__main__\":  # pragma: no cov\n    run_with_catch()  # pragma: no cov\n", "src/virtualenv/__init__.py": "from __future__ import annotations\n\nfrom .run import cli_run, session_via_cli\nfrom .version import __version__\n\n__all__ = [\n    \"__version__\",\n    \"cli_run\",\n    \"session_via_cli\",\n]\n", "src/virtualenv/discovery/py_spec.py": "\"\"\"A Python specification is an abstract requirement definition of an interpreter.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport re\n\nPATTERN = re.compile(r\"^(?P<impl>[a-zA-Z]+)?(?P<version>[0-9.]+)?(?:-(?P<arch>32|64))?$\")\n\n\nclass PythonSpec:\n    \"\"\"Contains specification about a Python Interpreter.\"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self,\n        str_spec: str,\n        implementation: str | None,\n        major: int | None,\n        minor: int | None,\n        micro: int | None,\n        architecture: int | None,\n        path: str | None,\n    ) -> None:\n        self.str_spec = str_spec\n        self.implementation = implementation\n        self.major = major\n        self.minor = minor\n        self.micro = micro\n        self.architecture = architecture\n        self.path = path\n\n    @classmethod\n    def from_string_spec(cls, string_spec: str):  # noqa: C901, PLR0912\n        impl, major, minor, micro, arch, path = None, None, None, None, None, None\n        if os.path.isabs(string_spec):  # noqa: PLR1702\n            path = string_spec\n        else:\n            ok = False\n            match = re.match(PATTERN, string_spec)\n            if match:\n\n                def _int_or_none(val):\n                    return None if val is None else int(val)\n\n                try:\n                    groups = match.groupdict()\n                    version = groups[\"version\"]\n                    if version is not None:\n                        versions = tuple(int(i) for i in version.split(\".\") if i)\n                        if len(versions) > 3:  # noqa: PLR2004\n                            raise ValueError  # noqa: TRY301\n                        if len(versions) == 3:  # noqa: PLR2004\n                            major, minor, micro = versions\n                        elif len(versions) == 2:  # noqa: PLR2004\n                            major, minor = versions\n                        elif len(versions) == 1:\n                            version_data = versions[0]\n                            major = int(str(version_data)[0])  # first digit major\n                            if version_data > 9:  # noqa: PLR2004\n                                minor = int(str(version_data)[1:])\n                    ok = True\n                except ValueError:\n                    pass\n                else:\n                    impl = groups[\"impl\"]\n                    if impl in {\"py\", \"python\"}:\n                        impl = None\n                    arch = _int_or_none(groups[\"arch\"])\n\n            if not ok:\n                path = string_spec\n\n        return cls(string_spec, impl, major, minor, micro, arch, path)\n\n    def generate_re(self, *, windows: bool) -> re.Pattern:\n        \"\"\"Generate a regular expression for matching against a filename.\"\"\"\n        version = r\"{}(\\.{}(\\.{})?)?\".format(\n            *(r\"\\d+\" if v is None else v for v in (self.major, self.minor, self.micro))\n        )\n        impl = \"python\" if self.implementation is None else f\"python|{re.escape(self.implementation)}\"\n        suffix = r\"\\.exe\" if windows else \"\"\n        version_conditional = (\n            \"?\"\n            # Windows Python executables are almost always unversioned\n            if windows\n            # Spec is an empty string\n            or self.major is None\n            else \"\"\n        )\n        # Try matching `direct` first, so the `direct` group is filled when possible.\n        return re.compile(\n            rf\"(?P<impl>{impl})(?P<v>{version}){version_conditional}{suffix}$\",\n            flags=re.IGNORECASE,\n        )\n\n    @property\n    def is_abs(self):\n        return self.path is not None and os.path.isabs(self.path)\n\n    def satisfies(self, spec):\n        \"\"\"Called when there's a candidate metadata spec to see if compatible - e.g. PEP-514 on Windows.\"\"\"\n        if spec.is_abs and self.is_abs and self.path != spec.path:\n            return False\n        if spec.implementation is not None and spec.implementation.lower() != self.implementation.lower():\n            return False\n        if spec.architecture is not None and spec.architecture != self.architecture:\n            return False\n\n        for our, req in zip((self.major, self.minor, self.micro), (spec.major, spec.minor, spec.micro)):\n            if req is not None and our is not None and our != req:\n                return False\n        return True\n\n    def __repr__(self) -> str:\n        name = type(self).__name__\n        params = \"implementation\", \"major\", \"minor\", \"micro\", \"architecture\", \"path\"\n        return f\"{name}({', '.join(f'{k}={getattr(self, k)}' for k in params if getattr(self, k) is not None)})\"\n\n\n__all__ = [\n    \"PythonSpec\",\n]\n", "src/virtualenv/discovery/builtin.py": "from __future__ import annotations\n\nimport logging\nimport os\nimport sys\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Callable\n\nfrom virtualenv.info import IS_WIN, fs_path_id\n\nfrom .discover import Discover\nfrom .py_info import PythonInfo\nfrom .py_spec import PythonSpec\n\nif TYPE_CHECKING:\n    from argparse import ArgumentParser\n    from collections.abc import Generator, Iterable, Mapping, Sequence\n\n    from virtualenv.app_data.base import AppData\n\n\nclass Builtin(Discover):\n    python_spec: Sequence[str]\n    app_data: AppData\n    try_first_with: Sequence[str]\n\n    def __init__(self, options) -> None:\n        super().__init__(options)\n        self.python_spec = options.python or [sys.executable]\n        self.app_data = options.app_data\n        self.try_first_with = options.try_first_with\n\n    @classmethod\n    def add_parser_arguments(cls, parser: ArgumentParser) -> None:\n        parser.add_argument(\n            \"-p\",\n            \"--python\",\n            dest=\"python\",\n            metavar=\"py\",\n            type=str,\n            action=\"append\",\n            default=[],\n            help=\"interpreter based on what to create environment (path/identifier) \"\n            \"- by default use the interpreter where the tool is installed - first found wins\",\n        )\n        parser.add_argument(\n            \"--try-first-with\",\n            dest=\"try_first_with\",\n            metavar=\"py_exe\",\n            type=str,\n            action=\"append\",\n            default=[],\n            help=\"try first these interpreters before starting the discovery\",\n        )\n\n    def run(self) -> PythonInfo | None:\n        for python_spec in self.python_spec:\n            result = get_interpreter(python_spec, self.try_first_with, self.app_data, self._env)\n            if result is not None:\n                return result\n        return None\n\n    def __repr__(self) -> str:\n        spec = self.python_spec[0] if len(self.python_spec) == 1 else self.python_spec\n        return f\"{self.__class__.__name__} discover of python_spec={spec!r}\"\n\n\ndef get_interpreter(\n    key, try_first_with: Iterable[str], app_data: AppData | None = None, env: Mapping[str, str] | None = None\n) -> PythonInfo | None:\n    spec = PythonSpec.from_string_spec(key)\n    logging.info(\"find interpreter for spec %r\", spec)\n    proposed_paths = set()\n    env = os.environ if env is None else env\n    for interpreter, impl_must_match in propose_interpreters(spec, try_first_with, app_data, env):\n        key = interpreter.system_executable, impl_must_match\n        if key in proposed_paths:\n            continue\n        logging.info(\"proposed %s\", interpreter)\n        if interpreter.satisfies(spec, impl_must_match):\n            logging.debug(\"accepted %s\", interpreter)\n            return interpreter\n        proposed_paths.add(key)\n    return None\n\n\ndef propose_interpreters(  # noqa: C901, PLR0912, PLR0915\n    spec: PythonSpec,\n    try_first_with: Iterable[str],\n    app_data: AppData | None = None,\n    env: Mapping[str, str] | None = None,\n) -> Generator[tuple[PythonInfo, bool], None, None]:\n    # 0. try with first\n    env = os.environ if env is None else env\n    tested_exes: set[str] = set()\n    for py_exe in try_first_with:\n        path = os.path.abspath(py_exe)\n        try:\n            os.lstat(path)  # Windows Store Python does not work with os.path.exists, but does for os.lstat\n        except OSError:\n            pass\n        else:\n            exe_raw = os.path.abspath(path)\n            exe_id = fs_path_id(exe_raw)\n            if exe_id in tested_exes:\n                continue\n            tested_exes.add(exe_id)\n            yield PythonInfo.from_exe(exe_raw, app_data, env=env), True\n\n    # 1. if it's a path and exists\n    if spec.path is not None:\n        try:\n            os.lstat(spec.path)  # Windows Store Python does not work with os.path.exists, but does for os.lstat\n        except OSError:\n            if spec.is_abs:\n                raise\n        else:\n            exe_raw = os.path.abspath(spec.path)\n            exe_id = fs_path_id(exe_raw)\n            if exe_id not in tested_exes:\n                tested_exes.add(exe_id)\n                yield PythonInfo.from_exe(exe_raw, app_data, env=env), True\n        if spec.is_abs:\n            return\n    else:\n        # 2. otherwise try with the current\n        current_python = PythonInfo.current_system(app_data)\n        exe_raw = str(current_python.executable)\n        exe_id = fs_path_id(exe_raw)\n        if exe_id not in tested_exes:\n            tested_exes.add(exe_id)\n            yield current_python, True\n\n        # 3. otherwise fallback to platform default logic\n        if IS_WIN:\n            from .windows import propose_interpreters  # noqa: PLC0415\n\n            for interpreter in propose_interpreters(spec, app_data, env):\n                exe_raw = str(interpreter.executable)\n                exe_id = fs_path_id(exe_raw)\n                if exe_id in tested_exes:\n                    continue\n                tested_exes.add(exe_id)\n                yield interpreter, True\n    # finally just find on path, the path order matters (as the candidates are less easy to control by end user)\n    find_candidates = path_exe_finder(spec)\n    for pos, path in enumerate(get_paths(env)):\n        logging.debug(LazyPathDump(pos, path, env))\n        for exe, impl_must_match in find_candidates(path):\n            exe_raw = str(exe)\n            exe_id = fs_path_id(exe_raw)\n            if exe_id in tested_exes:\n                continue\n            tested_exes.add(exe_id)\n            interpreter = PathPythonInfo.from_exe(exe_raw, app_data, raise_on_error=False, env=env)\n            if interpreter is not None:\n                yield interpreter, impl_must_match\n\n\ndef get_paths(env: Mapping[str, str]) -> Generator[Path, None, None]:\n    path = env.get(\"PATH\", None)\n    if path is None:\n        try:\n            path = os.confstr(\"CS_PATH\")\n        except (AttributeError, ValueError):\n            path = os.defpath\n    if path:\n        for p in map(Path, path.split(os.pathsep)):\n            if p.exists():\n                yield p\n\n\nclass LazyPathDump:\n    def __init__(self, pos: int, path: Path, env: Mapping[str, str]) -> None:\n        self.pos = pos\n        self.path = path\n        self.env = env\n\n    def __repr__(self) -> str:\n        content = f\"discover PATH[{self.pos}]={self.path}\"\n        if self.env.get(\"_VIRTUALENV_DEBUG\"):  # this is the over the board debug\n            content += \" with =>\"\n            for file_path in self.path.iterdir():\n                try:\n                    if file_path.is_dir() or not (file_path.stat().st_mode & os.X_OK):\n                        continue\n                except OSError:\n                    pass\n                content += \" \"\n                content += file_path.name\n        return content\n\n\ndef path_exe_finder(spec: PythonSpec) -> Callable[[Path], Generator[tuple[Path, bool], None, None]]:\n    \"\"\"Given a spec, return a function that can be called on a path to find all matching files in it.\"\"\"\n    pat = spec.generate_re(windows=sys.platform == \"win32\")\n    direct = spec.str_spec\n    if sys.platform == \"win32\":\n        direct = f\"{direct}.exe\"\n\n    def path_exes(path: Path) -> Generator[tuple[Path, bool], None, None]:\n        # 4. then maybe it's something exact on PATH - if it was direct lookup implementation no longer counts\n        direct_path = path / direct\n        if direct_path.exists():\n            yield direct_path, False\n\n        # 5. or from the spec we can deduce if a name on path matches\n        for exe in path.iterdir():\n            match = pat.fullmatch(exe.name)\n            if match:\n                # the implementation must match when we find \u201cpython[ver]\u201d\n                yield exe.absolute(), match[\"impl\"] == \"python\"\n\n    return path_exes\n\n\nclass PathPythonInfo(PythonInfo):\n    \"\"\"python info from path.\"\"\"\n\n\n__all__ = [\n    \"Builtin\",\n    \"PathPythonInfo\",\n    \"get_interpreter\",\n]\n", "src/virtualenv/discovery/py_info.py": "\"\"\"\nThe PythonInfo contains information about a concrete instance of a Python interpreter.\n\nNote: this file is also used to query target interpreters, so can only use standard library methods\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport logging\nimport os\nimport platform\nimport re\nimport sys\nimport sysconfig\nimport warnings\nfrom collections import OrderedDict, namedtuple\nfrom string import digits\n\nVersionInfo = namedtuple(\"VersionInfo\", [\"major\", \"minor\", \"micro\", \"releaselevel\", \"serial\"])  # noqa: PYI024\n\n\ndef _get_path_extensions():\n    return list(OrderedDict.fromkeys([\"\", *os.environ.get(\"PATHEXT\", \"\").lower().split(os.pathsep)]))\n\n\nEXTENSIONS = _get_path_extensions()\n_CONF_VAR_RE = re.compile(r\"\\{\\w+\\}\")\n\n\nclass PythonInfo:  # noqa: PLR0904\n    \"\"\"Contains information for a Python interpreter.\"\"\"\n\n    def __init__(self) -> None:  # noqa: PLR0915\n        def abs_path(v):\n            return None if v is None else os.path.abspath(v)  # unroll relative elements from path (e.g. ..)\n\n        # qualifies the python\n        self.platform = sys.platform\n        self.implementation = platform.python_implementation()\n        if self.implementation == \"PyPy\":\n            self.pypy_version_info = tuple(sys.pypy_version_info)\n\n        # this is a tuple in earlier, struct later, unify to our own named tuple\n        self.version_info = VersionInfo(*sys.version_info)\n        self.architecture = 64 if sys.maxsize > 2**32 else 32\n\n        # Used to determine some file names.\n        # See `CPython3Windows.python_zip()`.\n        self.version_nodot = sysconfig.get_config_var(\"py_version_nodot\")\n\n        self.version = sys.version\n        self.os = os.name\n\n        # information about the prefix - determines python home\n        self.prefix = abs_path(getattr(sys, \"prefix\", None))  # prefix we think\n        self.base_prefix = abs_path(getattr(sys, \"base_prefix\", None))  # venv\n        self.real_prefix = abs_path(getattr(sys, \"real_prefix\", None))  # old virtualenv\n\n        # information about the exec prefix - dynamic stdlib modules\n        self.base_exec_prefix = abs_path(getattr(sys, \"base_exec_prefix\", None))\n        self.exec_prefix = abs_path(getattr(sys, \"exec_prefix\", None))\n\n        self.executable = abs_path(sys.executable)  # the executable we were invoked via\n        self.original_executable = abs_path(self.executable)  # the executable as known by the interpreter\n        self.system_executable = self._fast_get_system_executable()  # the executable we are based of (if available)\n\n        try:\n            __import__(\"venv\")\n            has = True\n        except ImportError:\n            has = False\n        self.has_venv = has\n        self.path = sys.path\n        self.file_system_encoding = sys.getfilesystemencoding()\n        self.stdout_encoding = getattr(sys.stdout, \"encoding\", None)\n\n        scheme_names = sysconfig.get_scheme_names()\n\n        if \"venv\" in scheme_names:\n            self.sysconfig_scheme = \"venv\"\n            self.sysconfig_paths = {\n                i: sysconfig.get_path(i, expand=False, scheme=self.sysconfig_scheme) for i in sysconfig.get_path_names()\n            }\n            # we cannot use distutils at all if \"venv\" exists, distutils don't know it\n            self.distutils_install = {}\n        # debian / ubuntu python 3.10 without `python3-distutils` will report\n        # mangled `local/bin` / etc. names for the default prefix\n        # intentionally select `posix_prefix` which is the unaltered posix-like paths\n        elif sys.version_info[:2] == (3, 10) and \"deb_system\" in scheme_names:\n            self.sysconfig_scheme = \"posix_prefix\"\n            self.sysconfig_paths = {\n                i: sysconfig.get_path(i, expand=False, scheme=self.sysconfig_scheme) for i in sysconfig.get_path_names()\n            }\n            # we cannot use distutils at all if \"venv\" exists, distutils don't know it\n            self.distutils_install = {}\n        else:\n            self.sysconfig_scheme = None\n            self.sysconfig_paths = {i: sysconfig.get_path(i, expand=False) for i in sysconfig.get_path_names()}\n            self.distutils_install = self._distutils_install().copy()\n\n        # https://bugs.python.org/issue22199\n        makefile = getattr(sysconfig, \"get_makefile_filename\", getattr(sysconfig, \"_get_makefile_filename\", None))\n        self.sysconfig = {\n            k: v\n            for k, v in [\n                # a list of content to store from sysconfig\n                (\"makefile_filename\", makefile()),\n            ]\n            if k is not None\n        }\n\n        config_var_keys = set()\n        for element in self.sysconfig_paths.values():\n            config_var_keys.update(k[1:-1] for k in _CONF_VAR_RE.findall(element))\n        config_var_keys.add(\"PYTHONFRAMEWORK\")\n\n        self.sysconfig_vars = {i: sysconfig.get_config_var(i or \"\") for i in config_var_keys}\n\n        confs = {\n            k: (self.system_prefix if v is not None and v.startswith(self.prefix) else v)\n            for k, v in self.sysconfig_vars.items()\n        }\n        self.system_stdlib = self.sysconfig_path(\"stdlib\", confs)\n        self.system_stdlib_platform = self.sysconfig_path(\"platstdlib\", confs)\n        self.max_size = getattr(sys, \"maxsize\", getattr(sys, \"maxint\", None))\n        self._creators = None\n\n    def _fast_get_system_executable(self):\n        \"\"\"Try to get the system executable by just looking at properties.\"\"\"\n        if self.real_prefix or (  # noqa: PLR1702\n            self.base_prefix is not None and self.base_prefix != self.prefix\n        ):  # if this is a virtual environment\n            if self.real_prefix is None:\n                base_executable = getattr(sys, \"_base_executable\", None)  # some platforms may set this to help us\n                if base_executable is not None:  # noqa: SIM102 # use the saved system executable if present\n                    if sys.executable != base_executable:  # we know we're in a virtual environment, cannot be us\n                        if os.path.exists(base_executable):\n                            return base_executable\n                        # Python may return \"python\" because it was invoked from the POSIX virtual environment\n                        # however some installs/distributions do not provide a version-less \"python\" binary in\n                        # the system install location (see PEP 394) so try to fallback to a versioned binary.\n                        #\n                        # Gate this to Python 3.11 as `sys._base_executable` path resolution is now relative to\n                        # the 'home' key from pyvenv.cfg which often points to the system install location.\n                        major, minor = self.version_info.major, self.version_info.minor\n                        if self.os == \"posix\" and (major, minor) >= (3, 11):\n                            # search relative to the directory of sys._base_executable\n                            base_dir = os.path.dirname(base_executable)\n                            for base_executable in [\n                                os.path.join(base_dir, exe) for exe in (f\"python{major}\", f\"python{major}.{minor}\")\n                            ]:\n                                if os.path.exists(base_executable):\n                                    return base_executable\n            return None  # in this case we just can't tell easily without poking around FS and calling them, bail\n        # if we're not in a virtual environment, this is already a system python, so return the original executable\n        # note we must choose the original and not the pure executable as shim scripts might throw us off\n        return self.original_executable\n\n    def install_path(self, key):\n        result = self.distutils_install.get(key)\n        if result is None:  # use sysconfig if sysconfig_scheme is set or distutils is unavailable\n            # set prefixes to empty => result is relative from cwd\n            prefixes = self.prefix, self.exec_prefix, self.base_prefix, self.base_exec_prefix\n            config_var = {k: \"\" if v in prefixes else v for k, v in self.sysconfig_vars.items()}\n            result = self.sysconfig_path(key, config_var=config_var).lstrip(os.sep)\n        return result\n\n    @staticmethod\n    def _distutils_install():\n        # use distutils primarily because that's what pip does\n        # https://github.com/pypa/pip/blob/main/src/pip/_internal/locations.py#L95\n        # note here we don't import Distribution directly to allow setuptools to patch it\n        with warnings.catch_warnings():  # disable warning for PEP-632\n            warnings.simplefilter(\"ignore\")\n            try:\n                from distutils import dist  # noqa: PLC0415\n                from distutils.command.install import SCHEME_KEYS  # noqa: PLC0415\n            except ImportError:  # if removed or not installed ignore\n                return {}\n\n        d = dist.Distribution({\"script_args\": \"--no-user-cfg\"})  # conf files not parsed so they do not hijack paths\n        if hasattr(sys, \"_framework\"):\n            sys._framework = None  # disable macOS static paths for framework  # noqa: SLF001\n\n        with warnings.catch_warnings():  # disable warning for PEP-632\n            warnings.simplefilter(\"ignore\")\n            i = d.get_command_obj(\"install\", create=True)\n\n        i.prefix = os.sep  # paths generated are relative to prefix that contains the path sep, this makes it relative\n        i.finalize_options()\n        return {key: (getattr(i, f\"install_{key}\")[1:]).lstrip(os.sep) for key in SCHEME_KEYS}\n\n    @property\n    def version_str(self):\n        return \".\".join(str(i) for i in self.version_info[0:3])\n\n    @property\n    def version_release_str(self):\n        return \".\".join(str(i) for i in self.version_info[0:2])\n\n    @property\n    def python_name(self):\n        version_info = self.version_info\n        return f\"python{version_info.major}.{version_info.minor}\"\n\n    @property\n    def is_old_virtualenv(self):\n        return self.real_prefix is not None\n\n    @property\n    def is_venv(self):\n        return self.base_prefix is not None\n\n    def sysconfig_path(self, key, config_var=None, sep=os.sep):\n        pattern = self.sysconfig_paths[key]\n        if config_var is None:\n            config_var = self.sysconfig_vars\n        else:\n            base = self.sysconfig_vars.copy()\n            base.update(config_var)\n            config_var = base\n        return pattern.format(**config_var).replace(\"/\", sep)\n\n    def creators(self, refresh=False):  # noqa: FBT002\n        if self._creators is None or refresh is True:\n            from virtualenv.run.plugin.creators import CreatorSelector  # noqa: PLC0415\n\n            self._creators = CreatorSelector.for_interpreter(self)\n        return self._creators\n\n    @property\n    def system_include(self):\n        path = self.sysconfig_path(\n            \"include\",\n            {\n                k: (self.system_prefix if v is not None and v.startswith(self.prefix) else v)\n                for k, v in self.sysconfig_vars.items()\n            },\n        )\n        if not os.path.exists(path):  # some broken packaging don't respect the sysconfig, fallback to distutils path\n            # the pattern include the distribution name too at the end, remove that via the parent call\n            fallback = os.path.join(self.prefix, os.path.dirname(self.install_path(\"headers\")))\n            if os.path.exists(fallback):\n                path = fallback\n        return path\n\n    @property\n    def system_prefix(self):\n        return self.real_prefix or self.base_prefix or self.prefix\n\n    @property\n    def system_exec_prefix(self):\n        return self.real_prefix or self.base_exec_prefix or self.exec_prefix\n\n    def __repr__(self) -> str:\n        return \"{}({!r})\".format(\n            self.__class__.__name__,\n            {k: v for k, v in self.__dict__.items() if not k.startswith(\"_\")},\n        )\n\n    def __str__(self) -> str:\n        return \"{}({})\".format(\n            self.__class__.__name__,\n            \", \".join(\n                f\"{k}={v}\"\n                for k, v in (\n                    (\"spec\", self.spec),\n                    (\n                        \"system\"\n                        if self.system_executable is not None and self.system_executable != self.executable\n                        else None,\n                        self.system_executable,\n                    ),\n                    (\n                        \"original\"\n                        if self.original_executable not in {self.system_executable, self.executable}\n                        else None,\n                        self.original_executable,\n                    ),\n                    (\"exe\", self.executable),\n                    (\"platform\", self.platform),\n                    (\"version\", repr(self.version)),\n                    (\"encoding_fs_io\", f\"{self.file_system_encoding}-{self.stdout_encoding}\"),\n                )\n                if k is not None\n            ),\n        )\n\n    @property\n    def spec(self):\n        return \"{}{}-{}\".format(self.implementation, \".\".join(str(i) for i in self.version_info), self.architecture)\n\n    @classmethod\n    def clear_cache(cls, app_data):\n        # this method is not used by itself, so here and called functions can import stuff locally\n        from virtualenv.discovery.cached_py_info import clear  # noqa: PLC0415\n\n        clear(app_data)\n        cls._cache_exe_discovery.clear()\n\n    def satisfies(self, spec, impl_must_match):  # noqa: C901\n        \"\"\"Check if a given specification can be satisfied by the this python interpreter instance.\"\"\"\n        if spec.path:\n            if self.executable == os.path.abspath(spec.path):\n                return True  # if the path is a our own executable path we're done\n            if not spec.is_abs:\n                # if path set, and is not our original executable name, this does not match\n                basename = os.path.basename(self.original_executable)\n                spec_path = spec.path\n                if sys.platform == \"win32\":\n                    basename, suffix = os.path.splitext(basename)\n                    if spec_path.endswith(suffix):\n                        spec_path = spec_path[: -len(suffix)]\n                if basename != spec_path:\n                    return False\n\n        if (\n            impl_must_match\n            and spec.implementation is not None\n            and spec.implementation.lower() != self.implementation.lower()\n        ):\n            return False\n\n        if spec.architecture is not None and spec.architecture != self.architecture:\n            return False\n\n        for our, req in zip(self.version_info[0:3], (spec.major, spec.minor, spec.micro)):\n            if req is not None and our is not None and our != req:\n                return False\n        return True\n\n    _current_system = None\n    _current = None\n\n    @classmethod\n    def current(cls, app_data=None):\n        \"\"\"\n        This locates the current host interpreter information. This might be different than what we run into in case\n        the host python has been upgraded from underneath us.\n        \"\"\"  # noqa: D205\n        if cls._current is None:\n            cls._current = cls.from_exe(sys.executable, app_data, raise_on_error=True, resolve_to_host=False)\n        return cls._current\n\n    @classmethod\n    def current_system(cls, app_data=None) -> PythonInfo:\n        \"\"\"\n        This locates the current host interpreter information. This might be different than what we run into in case\n        the host python has been upgraded from underneath us.\n        \"\"\"  # noqa: D205\n        if cls._current_system is None:\n            cls._current_system = cls.from_exe(sys.executable, app_data, raise_on_error=True, resolve_to_host=True)\n        return cls._current_system\n\n    def _to_json(self):\n        # don't save calculated paths, as these are non primitive types\n        return json.dumps(self._to_dict(), indent=2)\n\n    def _to_dict(self):\n        data = {var: (getattr(self, var) if var != \"_creators\" else None) for var in vars(self)}\n\n        data[\"version_info\"] = data[\"version_info\"]._asdict()  # namedtuple to dictionary\n        return data\n\n    @classmethod\n    def from_exe(  # noqa: PLR0913\n        cls,\n        exe,\n        app_data=None,\n        raise_on_error=True,  # noqa: FBT002\n        ignore_cache=False,  # noqa: FBT002\n        resolve_to_host=True,  # noqa: FBT002\n        env=None,\n    ):\n        \"\"\"Given a path to an executable get the python information.\"\"\"\n        # this method is not used by itself, so here and called functions can import stuff locally\n        from virtualenv.discovery.cached_py_info import from_exe  # noqa: PLC0415\n\n        env = os.environ if env is None else env\n        proposed = from_exe(cls, app_data, exe, env=env, raise_on_error=raise_on_error, ignore_cache=ignore_cache)\n\n        if isinstance(proposed, PythonInfo) and resolve_to_host:\n            try:\n                proposed = proposed._resolve_to_system(app_data, proposed)  # noqa: SLF001\n            except Exception as exception:\n                if raise_on_error:\n                    raise\n                logging.info(\"ignore %s due cannot resolve system due to %r\", proposed.original_executable, exception)\n                proposed = None\n        return proposed\n\n    @classmethod\n    def _from_json(cls, payload):\n        # the dictionary unroll here is to protect against pypy bug of interpreter crashing\n        raw = json.loads(payload)\n        return cls._from_dict(raw.copy())\n\n    @classmethod\n    def _from_dict(cls, data):\n        data[\"version_info\"] = VersionInfo(**data[\"version_info\"])  # restore this to a named tuple structure\n        result = cls()\n        result.__dict__ = data.copy()\n        return result\n\n    @classmethod\n    def _resolve_to_system(cls, app_data, target):\n        start_executable = target.executable\n        prefixes = OrderedDict()\n        while target.system_executable is None:\n            prefix = target.real_prefix or target.base_prefix or target.prefix\n            if prefix in prefixes:\n                if len(prefixes) == 1:\n                    # if we're linking back to ourselves accept ourselves with a WARNING\n                    logging.info(\"%r links back to itself via prefixes\", target)\n                    target.system_executable = target.executable\n                    break\n                for at, (p, t) in enumerate(prefixes.items(), start=1):\n                    logging.error(\"%d: prefix=%s, info=%r\", at, p, t)\n                logging.error(\"%d: prefix=%s, info=%r\", len(prefixes) + 1, prefix, target)\n                msg = \"prefixes are causing a circle {}\".format(\"|\".join(prefixes.keys()))\n                raise RuntimeError(msg)\n            prefixes[prefix] = target\n            target = target.discover_exe(app_data, prefix=prefix, exact=False)\n        if target.executable != target.system_executable:\n            target = cls.from_exe(target.system_executable, app_data)\n        target.executable = start_executable\n        return target\n\n    _cache_exe_discovery = {}  # noqa: RUF012\n\n    def discover_exe(self, app_data, prefix, exact=True, env=None):  # noqa: FBT002\n        key = prefix, exact\n        if key in self._cache_exe_discovery and prefix:\n            logging.debug(\"discover exe from cache %s - exact %s: %r\", prefix, exact, self._cache_exe_discovery[key])\n            return self._cache_exe_discovery[key]\n        logging.debug(\"discover exe for %s in %s\", self, prefix)\n        # we don't know explicitly here, do some guess work - our executable name should tell\n        possible_names = self._find_possible_exe_names()\n        possible_folders = self._find_possible_folders(prefix)\n        discovered = []\n        env = os.environ if env is None else env\n        for folder in possible_folders:\n            for name in possible_names:\n                info = self._check_exe(app_data, folder, name, exact, discovered, env)\n                if info is not None:\n                    self._cache_exe_discovery[key] = info\n                    return info\n        if exact is False and discovered:\n            info = self._select_most_likely(discovered, self)\n            folders = os.pathsep.join(possible_folders)\n            self._cache_exe_discovery[key] = info\n            logging.debug(\"no exact match found, chosen most similar of %s within base folders %s\", info, folders)\n            return info\n        msg = \"failed to detect {} in {}\".format(\"|\".join(possible_names), os.pathsep.join(possible_folders))\n        raise RuntimeError(msg)\n\n    def _check_exe(self, app_data, folder, name, exact, discovered, env):  # noqa: PLR0913\n        exe_path = os.path.join(folder, name)\n        if not os.path.exists(exe_path):\n            return None\n        info = self.from_exe(exe_path, app_data, resolve_to_host=False, raise_on_error=False, env=env)\n        if info is None:  # ignore if for some reason we can't query\n            return None\n        for item in [\"implementation\", \"architecture\", \"version_info\"]:\n            found = getattr(info, item)\n            searched = getattr(self, item)\n            if found != searched:\n                if item == \"version_info\":\n                    found, searched = \".\".join(str(i) for i in found), \".\".join(str(i) for i in searched)\n                executable = info.executable\n                logging.debug(\"refused interpreter %s because %s differs %s != %s\", executable, item, found, searched)\n                if exact is False:\n                    discovered.append(info)\n                break\n        else:\n            return info\n        return None\n\n    @staticmethod\n    def _select_most_likely(discovered, target):\n        # no exact match found, start relaxing our requirements then to facilitate system package upgrades that\n        # could cause this (when using copy strategy of the host python)\n        def sort_by(info):\n            # we need to setup some priority of traits, this is as follows:\n            # implementation, major, minor, micro, architecture, tag, serial\n            matches = [\n                info.implementation == target.implementation,\n                info.version_info.major == target.version_info.major,\n                info.version_info.minor == target.version_info.minor,\n                info.architecture == target.architecture,\n                info.version_info.micro == target.version_info.micro,\n                info.version_info.releaselevel == target.version_info.releaselevel,\n                info.version_info.serial == target.version_info.serial,\n            ]\n            return sum((1 << pos if match else 0) for pos, match in enumerate(reversed(matches)))\n\n        sorted_discovered = sorted(discovered, key=sort_by, reverse=True)  # sort by priority in decreasing order\n        return sorted_discovered[0]\n\n    def _find_possible_folders(self, inside_folder):\n        candidate_folder = OrderedDict()\n        executables = OrderedDict()\n        executables[os.path.realpath(self.executable)] = None\n        executables[self.executable] = None\n        executables[os.path.realpath(self.original_executable)] = None\n        executables[self.original_executable] = None\n        for exe in executables:\n            base = os.path.dirname(exe)\n            # following path pattern of the current\n            if base.startswith(self.prefix):\n                relative = base[len(self.prefix) :]\n                candidate_folder[f\"{inside_folder}{relative}\"] = None\n\n        # or at root level\n        candidate_folder[inside_folder] = None\n        return [i for i in candidate_folder if os.path.exists(i)]\n\n    def _find_possible_exe_names(self):\n        name_candidate = OrderedDict()\n        for name in self._possible_base():\n            for at in (3, 2, 1, 0):\n                version = \".\".join(str(i) for i in self.version_info[:at])\n                for arch in [f\"-{self.architecture}\", \"\"]:\n                    for ext in EXTENSIONS:\n                        candidate = f\"{name}{version}{arch}{ext}\"\n                        name_candidate[candidate] = None\n        return list(name_candidate.keys())\n\n    def _possible_base(self):\n        possible_base = OrderedDict()\n        basename = os.path.splitext(os.path.basename(self.executable))[0].rstrip(digits)\n        possible_base[basename] = None\n        possible_base[self.implementation] = None\n        # python is always the final option as in practice is used by multiple implementation as exe name\n        if \"python\" in possible_base:\n            del possible_base[\"python\"]\n        possible_base[\"python\"] = None\n        for base in possible_base:\n            lower = base.lower()\n            yield lower\n            from virtualenv.info import fs_is_case_sensitive  # noqa: PLC0415\n\n            if fs_is_case_sensitive():\n                if base != lower:\n                    yield base\n                upper = base.upper()\n                if upper != base:\n                    yield upper\n\n\nif __name__ == \"__main__\":\n    # dump a JSON representation of the current python\n\n    argv = sys.argv[1:]\n\n    if len(argv) >= 1:\n        start_cookie = argv[0]\n        argv = argv[1:]\n    else:\n        start_cookie = \"\"\n\n    if len(argv) >= 1:\n        end_cookie = argv[0]\n        argv = argv[1:]\n    else:\n        end_cookie = \"\"\n\n    sys.argv = sys.argv[:1] + argv\n\n    info = PythonInfo()._to_json()  # noqa: SLF001\n    sys.stdout.write(\"\".join((start_cookie[::-1], info, end_cookie[::-1])))\n", "src/virtualenv/discovery/discover.py": "from __future__ import annotations\n\nfrom abc import ABC, abstractmethod\n\n\nclass Discover(ABC):\n    \"\"\"Discover and provide the requested Python interpreter.\"\"\"\n\n    @classmethod\n    def add_parser_arguments(cls, parser):\n        \"\"\"\n        Add CLI arguments for this discovery mechanisms.\n\n        :param parser: the CLI parser\n        \"\"\"\n        raise NotImplementedError\n\n    def __init__(self, options) -> None:\n        \"\"\"\n        Create a new discovery mechanism.\n\n        :param options: the parsed options as defined within :meth:`add_parser_arguments`\n        \"\"\"\n        self._has_run = False\n        self._interpreter = None\n        self._env = options.env\n\n    @abstractmethod\n    def run(self):\n        \"\"\"\n        Discovers an interpreter.\n\n        :return: the interpreter ready to use for virtual environment creation\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def interpreter(self):\n        \"\"\":return: the interpreter as returned by :meth:`run`, cached\"\"\"\n        if self._has_run is False:\n            self._interpreter = self.run()\n            self._has_run = True\n        return self._interpreter\n\n\n__all__ = [\n    \"Discover\",\n]\n", "src/virtualenv/discovery/cached_py_info.py": "\"\"\"\n\nWe acquire the python information by running an interrogation script via subprocess trigger. This operation is not\ncheap, especially not on Windows. To not have to pay this hefty cost every time we apply multiple levels of\ncaching.\n\"\"\"  # noqa: D205\n\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport random\nimport sys\nfrom collections import OrderedDict\nfrom pathlib import Path\nfrom shlex import quote\nfrom string import ascii_lowercase, ascii_uppercase, digits\nfrom subprocess import Popen\n\nfrom virtualenv.app_data import AppDataDisabled\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.util.subprocess import subprocess\n\n_CACHE = OrderedDict()\n_CACHE[Path(sys.executable)] = PythonInfo()\n\n\ndef from_exe(cls, app_data, exe, env=None, raise_on_error=True, ignore_cache=False):  # noqa: FBT002, PLR0913\n    env = os.environ if env is None else env\n    result = _get_from_cache(cls, app_data, exe, env, ignore_cache=ignore_cache)\n    if isinstance(result, Exception):\n        if raise_on_error:\n            raise result\n        logging.info(\"%s\", result)\n        result = None\n    return result\n\n\ndef _get_from_cache(cls, app_data, exe, env, ignore_cache=True):  # noqa: FBT002\n    # note here we cannot resolve symlinks, as the symlink may trigger different prefix information if there's a\n    # pyenv.cfg somewhere alongside on python3.5+\n    exe_path = Path(exe)\n    if not ignore_cache and exe_path in _CACHE:  # check in the in-memory cache\n        result = _CACHE[exe_path]\n    else:  # otherwise go through the app data cache\n        py_info = _get_via_file_cache(cls, app_data, exe_path, exe, env)\n        result = _CACHE[exe_path] = py_info\n    # independent if it was from the file or in-memory cache fix the original executable location\n    if isinstance(result, PythonInfo):\n        result.executable = exe\n    return result\n\n\ndef _get_via_file_cache(cls, app_data, path, exe, env):\n    path_text = str(path)\n    try:\n        path_modified = path.stat().st_mtime\n    except OSError:\n        path_modified = -1\n    if app_data is None:\n        app_data = AppDataDisabled()\n    py_info, py_info_store = None, app_data.py_info(path)\n    with py_info_store.locked():\n        if py_info_store.exists():  # if exists and matches load\n            data = py_info_store.read()\n            of_path, of_st_mtime, of_content = data[\"path\"], data[\"st_mtime\"], data[\"content\"]\n            if of_path == path_text and of_st_mtime == path_modified:\n                py_info = cls._from_dict(of_content.copy())\n                sys_exe = py_info.system_executable\n                if sys_exe is not None and not os.path.exists(sys_exe):\n                    py_info_store.remove()\n                    py_info = None\n            else:\n                py_info_store.remove()\n        if py_info is None:  # if not loaded run and save\n            failure, py_info = _run_subprocess(cls, exe, app_data, env)\n            if failure is None:\n                data = {\"st_mtime\": path_modified, \"path\": path_text, \"content\": py_info._to_dict()}  # noqa: SLF001\n                py_info_store.write(data)\n            else:\n                py_info = failure\n    return py_info\n\n\nCOOKIE_LENGTH: int = 32\n\n\ndef gen_cookie():\n    return \"\".join(\n        random.choice(f\"{ascii_lowercase}{ascii_uppercase}{digits}\")  # noqa: S311\n        for _ in range(COOKIE_LENGTH)\n    )\n\n\ndef _run_subprocess(cls, exe, app_data, env):\n    py_info_script = Path(os.path.abspath(__file__)).parent / \"py_info.py\"\n    # Cookies allow to split the serialized stdout output generated by the script collecting the info from the output\n    # generated by something else. The right way to deal with it is to create an anonymous pipe and pass its descriptor\n    # to the child and output to it. But AFAIK all of them are either not cross-platform or too big to implement and are\n    # not in the stdlib. So the easiest and the shortest way I could mind is just using the cookies.\n    # We generate pseudorandom cookies because it easy to implement and avoids breakage from outputting modules source\n    # code, i.e. by debug output libraries. We reverse the cookies to avoid breakages resulting from variable values\n    # appearing in debug output.\n\n    start_cookie = gen_cookie()\n    end_cookie = gen_cookie()\n    with app_data.ensure_extracted(py_info_script) as py_info_script:\n        cmd = [exe, str(py_info_script), start_cookie, end_cookie]\n        # prevent sys.prefix from leaking into the child process - see https://bugs.python.org/issue22490\n        env = env.copy()\n        env.pop(\"__PYVENV_LAUNCHER__\", None)\n        logging.debug(\"get interpreter info via cmd: %s\", LogCmd(cmd))\n        try:\n            process = Popen(\n                cmd,  # noqa: S603\n                universal_newlines=True,\n                stdin=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                stdout=subprocess.PIPE,\n                env=env,\n                encoding=\"utf-8\",\n            )\n            out, err = process.communicate()\n            code = process.returncode\n        except OSError as os_error:\n            out, err, code = \"\", os_error.strerror, os_error.errno\n    result, failure = None, None\n    if code == 0:\n        out_starts = out.find(start_cookie[::-1])\n\n        if out_starts > -1:\n            pre_cookie = out[:out_starts]\n\n            if pre_cookie:\n                sys.stdout.write(pre_cookie)\n\n            out = out[out_starts + COOKIE_LENGTH :]\n\n        out_ends = out.find(end_cookie[::-1])\n\n        if out_ends > -1:\n            post_cookie = out[out_ends + COOKIE_LENGTH :]\n\n            if post_cookie:\n                sys.stdout.write(post_cookie)\n\n            out = out[:out_ends]\n\n        result = cls._from_json(out)\n        result.executable = exe  # keep original executable as this may contain initialization code\n    else:\n        msg = f\"{exe} with code {code}{f' out: {out!r}' if out else ''}{f' err: {err!r}' if err else ''}\"\n        failure = RuntimeError(f\"failed to query {msg}\")\n    return failure, result\n\n\nclass LogCmd:\n    def __init__(self, cmd, env=None) -> None:\n        self.cmd = cmd\n        self.env = env\n\n    def __repr__(self) -> str:\n        cmd_repr = \" \".join(quote(str(c)) for c in self.cmd)\n        if self.env is not None:\n            cmd_repr = f\"{cmd_repr} env of {self.env!r}\"\n        return cmd_repr\n\n\ndef clear(app_data):\n    app_data.py_info_clear()\n    _CACHE.clear()\n\n\n___all___ = [\n    \"from_exe\",\n    \"clear\",\n    \"LogCmd\",\n]\n", "src/virtualenv/discovery/__init__.py": "", "src/virtualenv/discovery/windows/pep514.py": "\"\"\"Implement https://www.python.org/dev/peps/pep-0514/ to discover interpreters - Windows only.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport re\nimport winreg\nfrom logging import basicConfig, getLogger\n\nLOGGER = getLogger(__name__)\n\n\ndef enum_keys(key):\n    at = 0\n    while True:\n        try:\n            yield winreg.EnumKey(key, at)\n        except OSError:\n            break\n        at += 1\n\n\ndef get_value(key, value_name):\n    try:\n        return winreg.QueryValueEx(key, value_name)[0]\n    except OSError:\n        return None\n\n\ndef discover_pythons():\n    for hive, hive_name, key, flags, default_arch in [\n        (winreg.HKEY_CURRENT_USER, \"HKEY_CURRENT_USER\", r\"Software\\Python\", 0, 64),\n        (winreg.HKEY_LOCAL_MACHINE, \"HKEY_LOCAL_MACHINE\", r\"Software\\Python\", winreg.KEY_WOW64_64KEY, 64),\n        (winreg.HKEY_LOCAL_MACHINE, \"HKEY_LOCAL_MACHINE\", r\"Software\\Python\", winreg.KEY_WOW64_32KEY, 32),\n    ]:\n        yield from process_set(hive, hive_name, key, flags, default_arch)\n\n\ndef process_set(hive, hive_name, key, flags, default_arch):\n    try:\n        with winreg.OpenKeyEx(hive, key, 0, winreg.KEY_READ | flags) as root_key:\n            for company in enum_keys(root_key):\n                if company == \"PyLauncher\":  # reserved\n                    continue\n                yield from process_company(hive_name, company, root_key, default_arch)\n    except OSError:\n        pass\n\n\ndef process_company(hive_name, company, root_key, default_arch):\n    with winreg.OpenKeyEx(root_key, company) as company_key:\n        for tag in enum_keys(company_key):\n            spec = process_tag(hive_name, company, company_key, tag, default_arch)\n            if spec is not None:\n                yield spec\n\n\ndef process_tag(hive_name, company, company_key, tag, default_arch):\n    with winreg.OpenKeyEx(company_key, tag) as tag_key:\n        version = load_version_data(hive_name, company, tag, tag_key)\n        if version is not None:  # if failed to get version bail\n            major, minor, _ = version\n            arch = load_arch_data(hive_name, company, tag, tag_key, default_arch)\n            if arch is not None:\n                exe_data = load_exe(hive_name, company, company_key, tag)\n                if exe_data is not None:\n                    exe, args = exe_data\n                    return company, major, minor, arch, exe, args\n                return None\n            return None\n        return None\n\n\ndef load_exe(hive_name, company, company_key, tag):\n    key_path = f\"{hive_name}/{company}/{tag}\"\n    try:\n        with winreg.OpenKeyEx(company_key, rf\"{tag}\\InstallPath\") as ip_key, ip_key:\n            exe = get_value(ip_key, \"ExecutablePath\")\n            if exe is None:\n                ip = get_value(ip_key, None)\n                if ip is None:\n                    msg(key_path, \"no ExecutablePath or default for it\")\n\n                else:\n                    exe = os.path.join(ip, \"python.exe\")\n            if exe is not None and os.path.exists(exe):\n                args = get_value(ip_key, \"ExecutableArguments\")\n                return exe, args\n            msg(key_path, f\"could not load exe with value {exe}\")\n    except OSError:\n        msg(f\"{key_path}/InstallPath\", \"missing\")\n    return None\n\n\ndef load_arch_data(hive_name, company, tag, tag_key, default_arch):\n    arch_str = get_value(tag_key, \"SysArchitecture\")\n    if arch_str is not None:\n        key_path = f\"{hive_name}/{company}/{tag}/SysArchitecture\"\n        try:\n            return parse_arch(arch_str)\n        except ValueError as sys_arch:\n            msg(key_path, sys_arch)\n    return default_arch\n\n\ndef parse_arch(arch_str):\n    if isinstance(arch_str, str):\n        match = re.match(r\"^(\\d+)bit$\", arch_str)\n        if match:\n            return int(next(iter(match.groups())))\n        error = f\"invalid format {arch_str}\"\n    else:\n        error = f\"arch is not string: {arch_str!r}\"\n    raise ValueError(error)\n\n\ndef load_version_data(hive_name, company, tag, tag_key):\n    for candidate, key_path in [\n        (get_value(tag_key, \"SysVersion\"), f\"{hive_name}/{company}/{tag}/SysVersion\"),\n        (tag, f\"{hive_name}/{company}/{tag}\"),\n    ]:\n        if candidate is not None:\n            try:\n                return parse_version(candidate)\n            except ValueError as sys_version:\n                msg(key_path, sys_version)\n    return None\n\n\ndef parse_version(version_str):\n    if isinstance(version_str, str):\n        match = re.match(r\"^(\\d+)(?:\\.(\\d+))?(?:\\.(\\d+))?$\", version_str)\n        if match:\n            return tuple(int(i) if i is not None else None for i in match.groups())\n        error = f\"invalid format {version_str}\"\n    else:\n        error = f\"version is not string: {version_str!r}\"\n    raise ValueError(error)\n\n\ndef msg(path, what):\n    LOGGER.warning(\"PEP-514 violation in Windows Registry at %s error: %s\", path, what)\n\n\ndef _run():\n    basicConfig()\n    interpreters = [repr(spec) for spec in discover_pythons()]\n    print(\"\\n\".join(sorted(interpreters)))  # noqa: T201\n\n\nif __name__ == \"__main__\":\n    _run()\n", "src/virtualenv/discovery/windows/__init__.py": "from __future__ import annotations\n\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.discovery.py_spec import PythonSpec\n\nfrom .pep514 import discover_pythons\n\n# Map of well-known organizations (as per PEP 514 Company Windows Registry key part) versus Python implementation\n_IMPLEMENTATION_BY_ORG = {\n    \"ContinuumAnalytics\": \"CPython\",\n    \"PythonCore\": \"CPython\",\n}\n\n\nclass Pep514PythonInfo(PythonInfo):\n    \"\"\"A Python information acquired from PEP-514.\"\"\"\n\n\ndef propose_interpreters(spec, cache_dir, env):\n    # see if PEP-514 entries are good\n\n    # start with higher python versions in an effort to use the latest version available\n    # and prefer PythonCore over conda pythons (as virtualenv is mostly used by non conda tools)\n    existing = list(discover_pythons())\n    existing.sort(\n        key=lambda i: (*tuple(-1 if j is None else j for j in i[1:4]), 1 if i[0] == \"PythonCore\" else 0),\n        reverse=True,\n    )\n\n    for name, major, minor, arch, exe, _ in existing:\n        # Map well-known/most common organizations to a Python implementation, use the org name as a fallback for\n        # backwards compatibility.\n        implementation = _IMPLEMENTATION_BY_ORG.get(name, name)\n\n        # Pre-filtering based on Windows Registry metadata, for CPython only\n        skip_pre_filter = implementation.lower() != \"cpython\"\n        registry_spec = PythonSpec(None, implementation, major, minor, None, arch, exe)\n        if skip_pre_filter or registry_spec.satisfies(spec):\n            interpreter = Pep514PythonInfo.from_exe(exe, cache_dir, env=env, raise_on_error=False)\n            if interpreter is not None and interpreter.satisfies(spec, impl_must_match=True):\n                yield interpreter  # Final filtering/matching using interpreter metadata\n\n\n__all__ = [\n    \"Pep514PythonInfo\",\n    \"propose_interpreters\",\n]\n", "src/virtualenv/app_data/via_tempdir.py": "from __future__ import annotations\n\nimport logging\nfrom tempfile import mkdtemp\n\nfrom virtualenv.util.path import safe_delete\n\nfrom .via_disk_folder import AppDataDiskFolder\n\n\nclass TempAppData(AppDataDiskFolder):\n    transient = True\n    can_update = False\n\n    def __init__(self) -> None:\n        super().__init__(folder=mkdtemp())\n        logging.debug(\"created temporary app data folder %s\", self.lock.path)\n\n    def reset(self):\n        \"\"\"This is a temporary folder, is already empty to start with.\"\"\"\n\n    def close(self):\n        logging.debug(\"remove temporary app data folder %s\", self.lock.path)\n        safe_delete(self.lock.path)\n\n    def embed_update_log(self, distribution, for_py_version):\n        raise NotImplementedError\n\n\n__all__ = [\n    \"TempAppData\",\n]\n", "src/virtualenv/app_data/read_only.py": "from __future__ import annotations\n\nimport os.path\n\nfrom virtualenv.util.lock import NoOpFileLock\n\nfrom .via_disk_folder import AppDataDiskFolder, PyInfoStoreDisk\n\n\nclass ReadOnlyAppData(AppDataDiskFolder):\n    can_update = False\n\n    def __init__(self, folder: str) -> None:\n        if not os.path.isdir(folder):\n            msg = f\"read-only app data directory {folder} does not exist\"\n            raise RuntimeError(msg)\n        super().__init__(folder)\n        self.lock = NoOpFileLock(folder)\n\n    def reset(self) -> None:\n        msg = \"read-only app data does not support reset\"\n        raise RuntimeError(msg)\n\n    def py_info_clear(self) -> None:\n        raise NotImplementedError\n\n    def py_info(self, path):\n        return _PyInfoStoreDiskReadOnly(self.py_info_at, path)\n\n    def embed_update_log(self, distribution, for_py_version):\n        raise NotImplementedError\n\n\nclass _PyInfoStoreDiskReadOnly(PyInfoStoreDisk):\n    def write(self, content):  # noqa: ARG002\n        msg = \"read-only app data python info cannot be updated\"\n        raise RuntimeError(msg)\n\n\n__all__ = [\n    \"ReadOnlyAppData\",\n]\n", "src/virtualenv/app_data/base.py": "\"\"\"Application data stored by virtualenv.\"\"\"\n\nfrom __future__ import annotations\n\nfrom abc import ABC, abstractmethod\nfrom contextlib import contextmanager\n\nfrom virtualenv.info import IS_ZIPAPP\n\n\nclass AppData(ABC):\n    \"\"\"Abstract storage interface for the virtualenv application.\"\"\"\n\n    @abstractmethod\n    def close(self):\n        \"\"\"Called before virtualenv exits.\"\"\"\n\n    @abstractmethod\n    def reset(self):\n        \"\"\"Called when the user passes in the reset app data.\"\"\"\n\n    @abstractmethod\n    def py_info(self, path):\n        raise NotImplementedError\n\n    @abstractmethod\n    def py_info_clear(self):\n        raise NotImplementedError\n\n    @property\n    def can_update(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    def embed_update_log(self, distribution, for_py_version):\n        raise NotImplementedError\n\n    @property\n    def house(self):\n        raise NotImplementedError\n\n    @property\n    def transient(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    def wheel_image(self, for_py_version, name):\n        raise NotImplementedError\n\n    @contextmanager\n    def ensure_extracted(self, path, to_folder=None):\n        \"\"\"Some paths might be within the zipapp, unzip these to a path on the disk.\"\"\"\n        if IS_ZIPAPP:\n            with self.extract(path, to_folder) as result:\n                yield result\n        else:\n            yield path\n\n    @abstractmethod\n    @contextmanager\n    def extract(self, path, to_folder):\n        raise NotImplementedError\n\n    @abstractmethod\n    @contextmanager\n    def locked(self, path):\n        raise NotImplementedError\n\n\nclass ContentStore(ABC):\n    @abstractmethod\n    def exists(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    def read(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    def write(self, content):\n        raise NotImplementedError\n\n    @abstractmethod\n    def remove(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    @contextmanager\n    def locked(self):\n        pass\n\n\n__all__ = [\n    \"AppData\",\n    \"ContentStore\",\n]\n", "src/virtualenv/app_data/na.py": "from __future__ import annotations\n\nfrom contextlib import contextmanager\n\nfrom .base import AppData, ContentStore\n\n\nclass AppDataDisabled(AppData):\n    \"\"\"No application cache available (most likely as we don't have write permissions).\"\"\"\n\n    transient = True\n    can_update = False\n\n    def __init__(self) -> None:\n        pass\n\n    error = RuntimeError(\"no app data folder available, probably no write access to the folder\")\n\n    def close(self):\n        \"\"\"Do nothing.\"\"\"\n\n    def reset(self):\n        \"\"\"Do nothing.\"\"\"\n\n    def py_info(self, path):  # noqa: ARG002\n        return ContentStoreNA()\n\n    def embed_update_log(self, distribution, for_py_version):  # noqa: ARG002\n        return ContentStoreNA()\n\n    def extract(self, path, to_folder):  # noqa: ARG002\n        raise self.error\n\n    @contextmanager\n    def locked(self, path):  # noqa: ARG002\n        \"\"\"Do nothing.\"\"\"\n        yield\n\n    @property\n    def house(self):\n        raise self.error\n\n    def wheel_image(self, for_py_version, name):  # noqa: ARG002\n        raise self.error\n\n    def py_info_clear(self):\n        \"\"\"Nothing to clear.\"\"\"\n\n\nclass ContentStoreNA(ContentStore):\n    def exists(self):\n        return False\n\n    def read(self):\n        \"\"\"Nothing to read.\"\"\"\n        return\n\n    def write(self, content):\n        \"\"\"Nothing to write.\"\"\"\n\n    def remove(self):\n        \"\"\"Nothing to remove.\"\"\"\n\n    @contextmanager\n    def locked(self):\n        yield\n\n\n__all__ = [\n    \"AppDataDisabled\",\n    \"ContentStoreNA\",\n]\n", "src/virtualenv/app_data/__init__.py": "\"\"\"Application data stored by virtualenv.\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport os\n\nfrom platformdirs import user_data_dir\n\nfrom .na import AppDataDisabled\nfrom .read_only import ReadOnlyAppData\nfrom .via_disk_folder import AppDataDiskFolder\nfrom .via_tempdir import TempAppData\n\n\ndef _default_app_data_dir(env):\n    key = \"VIRTUALENV_OVERRIDE_APP_DATA\"\n    if key in env:\n        return env[key]\n    return user_data_dir(appname=\"virtualenv\", appauthor=\"pypa\")\n\n\ndef make_app_data(folder, **kwargs):\n    is_read_only = kwargs.pop(\"read_only\")\n    env = kwargs.pop(\"env\")\n    if kwargs:  # py3+ kwonly\n        msg = \"unexpected keywords: {}\"\n        raise TypeError(msg)\n\n    if folder is None:\n        folder = _default_app_data_dir(env)\n    folder = os.path.abspath(folder)\n\n    if is_read_only:\n        return ReadOnlyAppData(folder)\n\n    if not os.path.isdir(folder):\n        try:\n            os.makedirs(folder)\n            logging.debug(\"created app data folder %s\", folder)\n        except OSError as exception:\n            logging.info(\"could not create app data folder %s due to %r\", folder, exception)\n\n    if os.access(folder, os.W_OK):\n        return AppDataDiskFolder(folder)\n    logging.debug(\"app data folder %s has no write access\", folder)\n    return TempAppData()\n\n\n__all__ = (\n    \"AppDataDisabled\",\n    \"AppDataDiskFolder\",\n    \"ReadOnlyAppData\",\n    \"TempAppData\",\n    \"make_app_data\",\n)\n", "src/virtualenv/app_data/via_disk_folder.py": "\"\"\"\nA rough layout of the current storage goes as:\n\nvirtualenv-app-data\n\u251c\u2500\u2500 py - <version> <cache information about python interpreters>\n\u2502  \u2514\u2500\u2500 *.json/lock\n\u251c\u2500\u2500 wheel <cache wheels used for seeding>\n\u2502   \u251c\u2500\u2500 house\n\u2502   \u2502   \u2514\u2500\u2500 *.whl <wheels downloaded go here>\n\u2502   \u2514\u2500\u2500 <python major.minor> -> 3.9\n\u2502       \u251c\u2500\u2500 img-<version>\n\u2502       \u2502   \u2514\u2500\u2500 image\n\u2502       \u2502           \u2514\u2500\u2500 <install class> -> CopyPipInstall / SymlinkPipInstall\n\u2502       \u2502               \u2514\u2500\u2500 <wheel name> -> pip-20.1.1-py2.py3-none-any\n\u2502       \u2514\u2500\u2500 embed\n\u2502           \u2514\u2500\u2500 3 -> json format versioning\n\u2502               \u2514\u2500\u2500 *.json -> for every distribution contains data about newer embed versions and releases\n\u2514\u2500\u2500\u2500 unzip <in zip app we cannot refer to some internal files, so first extract them>\n     \u2514\u2500\u2500 <virtualenv version>\n         \u251c\u2500\u2500 py_info.py\n         \u251c\u2500\u2500 debug.py\n         \u2514\u2500\u2500 _virtualenv.py\n\"\"\"  # noqa: D415\n\nfrom __future__ import annotations\n\nimport json\nimport logging\nfrom abc import ABC\nfrom contextlib import contextmanager, suppress\nfrom hashlib import sha256\n\nfrom virtualenv.util.lock import ReentrantFileLock\nfrom virtualenv.util.path import safe_delete\nfrom virtualenv.util.zipapp import extract\nfrom virtualenv.version import __version__\n\nfrom .base import AppData, ContentStore\n\n\nclass AppDataDiskFolder(AppData):\n    \"\"\"Store the application data on the disk within a folder layout.\"\"\"\n\n    transient = False\n    can_update = True\n\n    def __init__(self, folder) -> None:\n        self.lock = ReentrantFileLock(folder)\n\n    def __repr__(self) -> str:\n        return f\"{type(self).__name__}({self.lock.path})\"\n\n    def __str__(self) -> str:\n        return str(self.lock.path)\n\n    def reset(self):\n        logging.debug(\"reset app data folder %s\", self.lock.path)\n        safe_delete(self.lock.path)\n\n    def close(self):\n        \"\"\"Do nothing.\"\"\"\n\n    @contextmanager\n    def locked(self, path):\n        path_lock = self.lock / path\n        with path_lock:\n            yield path_lock.path\n\n    @contextmanager\n    def extract(self, path, to_folder):\n        root = ReentrantFileLock(to_folder()) if to_folder is not None else self.lock / \"unzip\" / __version__\n        with root.lock_for_key(path.name):\n            dest = root.path / path.name\n            if not dest.exists():\n                extract(path, dest)\n            yield dest\n\n    @property\n    def py_info_at(self):\n        return self.lock / \"py_info\" / \"1\"\n\n    def py_info(self, path):\n        return PyInfoStoreDisk(self.py_info_at, path)\n\n    def py_info_clear(self):\n        \"\"\"clear py info.\"\"\"\n        py_info_folder = self.py_info_at\n        with py_info_folder:\n            for filename in py_info_folder.path.iterdir():\n                if filename.suffix == \".json\":\n                    with py_info_folder.lock_for_key(filename.stem):\n                        if filename.exists():\n                            filename.unlink()\n\n    def embed_update_log(self, distribution, for_py_version):\n        return EmbedDistributionUpdateStoreDisk(self.lock / \"wheel\" / for_py_version / \"embed\" / \"3\", distribution)\n\n    @property\n    def house(self):\n        path = self.lock.path / \"wheel\" / \"house\"\n        path.mkdir(parents=True, exist_ok=True)\n        return path\n\n    def wheel_image(self, for_py_version, name):\n        return self.lock.path / \"wheel\" / for_py_version / \"image\" / \"1\" / name\n\n\nclass JSONStoreDisk(ContentStore, ABC):\n    def __init__(self, in_folder, key, msg, msg_args) -> None:\n        self.in_folder = in_folder\n        self.key = key\n        self.msg = msg\n        self.msg_args = (*msg_args, self.file)\n\n    @property\n    def file(self):\n        return self.in_folder.path / f\"{self.key}.json\"\n\n    def exists(self):\n        return self.file.exists()\n\n    def read(self):\n        data, bad_format = None, False\n        try:\n            data = json.loads(self.file.read_text(encoding=\"utf-8\"))\n        except ValueError:\n            bad_format = True\n        except Exception:  # noqa: BLE001, S110\n            pass\n        else:\n            logging.debug(\"got %s from %s\", self.msg, self.msg_args)\n            return data\n        if bad_format:\n            with suppress(OSError):  # reading and writing on the same file may cause race on multiple processes\n                self.remove()\n        return None\n\n    def remove(self):\n        self.file.unlink()\n        logging.debug(\"removed %s at %s\", self.msg, self.msg_args)\n\n    @contextmanager\n    def locked(self):\n        with self.in_folder.lock_for_key(self.key):\n            yield\n\n    def write(self, content):\n        folder = self.file.parent\n        folder.mkdir(parents=True, exist_ok=True)\n        self.file.write_text(json.dumps(content, sort_keys=True, indent=2), encoding=\"utf-8\")\n        logging.debug(\"wrote %s at %s\", self.msg, self.msg_args)\n\n\nclass PyInfoStoreDisk(JSONStoreDisk):\n    def __init__(self, in_folder, path) -> None:\n        key = sha256(str(path).encode(\"utf-8\")).hexdigest()\n        super().__init__(in_folder, key, \"python info of %s\", (path,))\n\n\nclass EmbedDistributionUpdateStoreDisk(JSONStoreDisk):\n    def __init__(self, in_folder, distribution) -> None:\n        super().__init__(\n            in_folder,\n            distribution,\n            \"embed update of distribution %s\",\n            (distribution,),\n        )\n\n\n__all__ = [\n    \"AppDataDiskFolder\",\n    \"JSONStoreDisk\",\n    \"PyInfoStoreDisk\",\n]\n", "src/virtualenv/run/__init__.py": "from __future__ import annotations\n\nimport logging\nimport os\nfrom functools import partial\n\nfrom virtualenv.app_data import make_app_data\nfrom virtualenv.config.cli.parser import VirtualEnvConfigParser\nfrom virtualenv.report import LEVELS, setup_report\nfrom virtualenv.run.session import Session\nfrom virtualenv.seed.wheels.periodic_update import manual_upgrade\nfrom virtualenv.version import __version__\n\nfrom .plugin.activators import ActivationSelector\nfrom .plugin.creators import CreatorSelector\nfrom .plugin.discovery import get_discover\nfrom .plugin.seeders import SeederSelector\n\n\ndef cli_run(args, options=None, setup_logging=True, env=None):  # noqa: FBT002\n    \"\"\"\n    Create a virtual environment given some command line interface arguments.\n\n    :param args: the command line arguments\n    :param options: passing in a ``VirtualEnvOptions`` object allows return of the parsed options\n    :param setup_logging: ``True`` if setup logging handlers, ``False`` to use handlers already registered\n    :param env: environment variables to use\n    :return: the session object of the creation (its structure for now is experimental and might change on short notice)\n    \"\"\"\n    env = os.environ if env is None else env\n    of_session = session_via_cli(args, options, setup_logging, env)\n    with of_session:\n        of_session.run()\n    return of_session\n\n\ndef session_via_cli(args, options=None, setup_logging=True, env=None):  # noqa: FBT002\n    \"\"\"\n    Create a virtualenv session (same as cli_run, but this does not perform the creation). Use this if you just want to\n    query what the virtual environment would look like, but not actually create it.\n\n    :param args: the command line arguments\n    :param options: passing in a ``VirtualEnvOptions`` object allows return of the parsed options\n    :param setup_logging: ``True`` if setup logging handlers, ``False`` to use handlers already registered\n    :param env: environment variables to use\n    :return: the session object of the creation (its structure for now is experimental and might change on short notice)\n    \"\"\"  # noqa: D205\n    env = os.environ if env is None else env\n    parser, elements = build_parser(args, options, setup_logging, env)\n    options = parser.parse_args(args)\n    creator, seeder, activators = tuple(e.create(options) for e in elements)  # create types\n    return Session(\n        options.verbosity,\n        options.app_data,\n        parser._interpreter,  # noqa: SLF001\n        creator,\n        seeder,\n        activators,\n    )\n\n\ndef build_parser(args=None, options=None, setup_logging=True, env=None):  # noqa: FBT002\n    parser = VirtualEnvConfigParser(options, os.environ if env is None else env)\n    add_version_flag(parser)\n    parser.add_argument(\n        \"--with-traceback\",\n        dest=\"with_traceback\",\n        action=\"store_true\",\n        default=False,\n        help=\"on failure also display the stacktrace internals of virtualenv\",\n    )\n    _do_report_setup(parser, args, setup_logging)\n    options = load_app_data(args, parser, options)\n    handle_extra_commands(options)\n\n    discover = get_discover(parser, args)\n    parser._interpreter = interpreter = discover.interpreter  # noqa: SLF001\n    if interpreter is None:\n        msg = f\"failed to find interpreter for {discover}\"\n        raise RuntimeError(msg)\n    elements = [\n        CreatorSelector(interpreter, parser),\n        SeederSelector(interpreter, parser),\n        ActivationSelector(interpreter, parser),\n    ]\n    options, _ = parser.parse_known_args(args)\n    for element in elements:\n        element.handle_selected_arg_parse(options)\n    parser.enable_help()\n    return parser, elements\n\n\ndef build_parser_only(args=None):\n    \"\"\"Used to provide a parser for the doc generation.\"\"\"\n    return build_parser(args)[0]\n\n\ndef handle_extra_commands(options):\n    if options.upgrade_embed_wheels:\n        result = manual_upgrade(options.app_data, options.env)\n        raise SystemExit(result)\n\n\ndef load_app_data(args, parser, options):\n    parser.add_argument(\n        \"--read-only-app-data\",\n        action=\"store_true\",\n        help=\"use app data folder in read-only mode (write operations will fail with error)\",\n    )\n    options, _ = parser.parse_known_args(args, namespace=options)\n\n    # here we need a write-able application data (e.g. the zipapp might need this for discovery cache)\n    parser.add_argument(\n        \"--app-data\",\n        help=\"a data folder used as cache by the virtualenv\",\n        type=partial(make_app_data, read_only=options.read_only_app_data, env=options.env),\n        default=make_app_data(None, read_only=options.read_only_app_data, env=options.env),\n    )\n    parser.add_argument(\n        \"--reset-app-data\",\n        action=\"store_true\",\n        help=\"start with empty app data folder\",\n    )\n    parser.add_argument(\n        \"--upgrade-embed-wheels\",\n        action=\"store_true\",\n        help=\"trigger a manual update of the embedded wheels\",\n    )\n    options, _ = parser.parse_known_args(args, namespace=options)\n    if options.reset_app_data:\n        options.app_data.reset()\n    return options\n\n\ndef add_version_flag(parser):\n    import virtualenv  # noqa: PLC0415\n\n    parser.add_argument(\n        \"--version\",\n        action=\"version\",\n        version=f\"%(prog)s {__version__} from {virtualenv.__file__}\",\n        help=\"display the version of the virtualenv package and its location, then exit\",\n    )\n\n\ndef _do_report_setup(parser, args, setup_logging):\n    level_map = \", \".join(f\"{logging.getLevelName(line)}={c}\" for c, line in sorted(LEVELS.items()))\n    msg = \"verbosity = verbose - quiet, default {}, mapping => {}\"\n    verbosity_group = parser.add_argument_group(\n        title=\"verbosity\",\n        description=msg.format(logging.getLevelName(LEVELS[3]), level_map),\n    )\n    verbosity = verbosity_group.add_mutually_exclusive_group()\n    verbosity.add_argument(\"-v\", \"--verbose\", action=\"count\", dest=\"verbose\", help=\"increase verbosity\", default=2)\n    verbosity.add_argument(\"-q\", \"--quiet\", action=\"count\", dest=\"quiet\", help=\"decrease verbosity\", default=0)\n    option, _ = parser.parse_known_args(args)\n    if setup_logging:\n        setup_report(option.verbosity)\n\n\n__all__ = [\n    \"cli_run\",\n    \"session_via_cli\",\n]\n", "src/virtualenv/run/session.py": "from __future__ import annotations\n\nimport json\nimport logging\n\n\nclass Session:\n    \"\"\"Represents a virtual environment creation session.\"\"\"\n\n    def __init__(self, verbosity, app_data, interpreter, creator, seeder, activators) -> None:  # noqa: PLR0913\n        self._verbosity = verbosity\n        self._app_data = app_data\n        self._interpreter = interpreter\n        self._creator = creator\n        self._seeder = seeder\n        self._activators = activators\n\n    @property\n    def verbosity(self):\n        \"\"\"The verbosity of the run.\"\"\"\n        return self._verbosity\n\n    @property\n    def interpreter(self):\n        \"\"\"Create a virtual environment based on this reference interpreter.\"\"\"\n        return self._interpreter\n\n    @property\n    def creator(self):\n        \"\"\"The creator used to build the virtual environment (must be compatible with the interpreter).\"\"\"\n        return self._creator\n\n    @property\n    def seeder(self):\n        \"\"\"The mechanism used to provide the seed packages (pip, setuptools, wheel).\"\"\"\n        return self._seeder\n\n    @property\n    def activators(self):\n        \"\"\"Activators used to generate activations scripts.\"\"\"\n        return self._activators\n\n    def run(self):\n        self._create()\n        self._seed()\n        self._activate()\n        self.creator.pyenv_cfg.write()\n\n    def _create(self):\n        logging.info(\"create virtual environment via %s\", self.creator)\n        self.creator.run()\n        logging.debug(_DEBUG_MARKER)\n        logging.debug(\"%s\", _Debug(self.creator))\n\n    def _seed(self):\n        if self.seeder is not None and self.seeder.enabled:\n            logging.info(\"add seed packages via %s\", self.seeder)\n            self.seeder.run(self.creator)\n\n    def _activate(self):\n        if self.activators:\n            active = \", \".join(type(i).__name__.replace(\"Activator\", \"\") for i in self.activators)\n            logging.info(\"add activators for %s\", active)\n            for activator in self.activators:\n                activator.generate(self.creator)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self._app_data.close()\n\n\n_DEBUG_MARKER = \"=\" * 30 + \" target debug \" + \"=\" * 30\n\n\nclass _Debug:\n    \"\"\"lazily populate debug.\"\"\"\n\n    def __init__(self, creator) -> None:\n        self.creator = creator\n\n    def __repr__(self) -> str:\n        return json.dumps(self.creator.debug, indent=2)\n\n\n__all__ = [\n    \"Session\",\n]\n", "src/virtualenv/run/plugin/seeders.py": "from __future__ import annotations\n\nfrom .base import ComponentBuilder\n\n\nclass SeederSelector(ComponentBuilder):\n    def __init__(self, interpreter, parser) -> None:\n        possible = self.options(\"virtualenv.seed\")\n        super().__init__(interpreter, parser, \"seeder\", possible)\n\n    def add_selector_arg_parse(self, name, choices):\n        self.parser.add_argument(\n            f\"--{name}\",\n            choices=choices,\n            default=self._get_default(),\n            required=False,\n            help=\"seed packages install method\",\n        )\n        self.parser.add_argument(\n            \"--no-seed\",\n            \"--without-pip\",\n            help=\"do not install seed packages\",\n            action=\"store_true\",\n            dest=\"no_seed\",\n        )\n\n    @staticmethod\n    def _get_default():\n        return \"app-data\"\n\n    def handle_selected_arg_parse(self, options):\n        return super().handle_selected_arg_parse(options)\n\n    def create(self, options):\n        return self._impl_class(options)\n\n\n__all__ = [\n    \"SeederSelector\",\n]\n", "src/virtualenv/run/plugin/discovery.py": "from __future__ import annotations\n\nfrom .base import PluginLoader\n\n\nclass Discovery(PluginLoader):\n    \"\"\"Discovery plugins.\"\"\"\n\n\ndef get_discover(parser, args):\n    discover_types = Discovery.entry_points_for(\"virtualenv.discovery\")\n    discovery_parser = parser.add_argument_group(\n        title=\"discovery\",\n        description=\"discover and provide a target interpreter\",\n    )\n    choices = _get_default_discovery(discover_types)\n    # prefer the builtin if present, otherwise fallback to first defined type\n    choices = sorted(choices, key=lambda a: 0 if a == \"builtin\" else 1)\n    discovery_parser.add_argument(\n        \"--discovery\",\n        choices=choices,\n        default=next(iter(choices)),\n        required=False,\n        help=\"interpreter discovery method\",\n    )\n    options, _ = parser.parse_known_args(args)\n    discover_class = discover_types[options.discovery]\n    discover_class.add_parser_arguments(discovery_parser)\n    options, _ = parser.parse_known_args(args, namespace=options)\n    return discover_class(options)\n\n\ndef _get_default_discovery(discover_types):\n    return list(discover_types.keys())\n\n\n__all__ = [\n    \"Discovery\",\n    \"get_discover\",\n]\n", "src/virtualenv/run/plugin/activators.py": "from __future__ import annotations\n\nfrom argparse import ArgumentTypeError\nfrom collections import OrderedDict\n\nfrom .base import ComponentBuilder\n\n\nclass ActivationSelector(ComponentBuilder):\n    def __init__(self, interpreter, parser) -> None:\n        self.default = None\n        possible = OrderedDict(\n            (k, v) for k, v in self.options(\"virtualenv.activate\").items() if v.supports(interpreter)\n        )\n        super().__init__(interpreter, parser, \"activators\", possible)\n        self.parser.description = \"options for activation scripts\"\n        self.active = None\n\n    def add_selector_arg_parse(self, name, choices):\n        self.default = \",\".join(choices)\n        self.parser.add_argument(\n            f\"--{name}\",\n            default=self.default,\n            metavar=\"comma_sep_list\",\n            required=False,\n            help=\"activators to generate - default is all supported\",\n            type=self._extract_activators,\n        )\n\n    def _extract_activators(self, entered_str):\n        elements = [e.strip() for e in entered_str.split(\",\") if e.strip()]\n        missing = [e for e in elements if e not in self.possible]\n        if missing:\n            msg = f\"the following activators are not available {','.join(missing)}\"\n            raise ArgumentTypeError(msg)\n        return elements\n\n    def handle_selected_arg_parse(self, options):\n        selected_activators = (\n            self._extract_activators(self.default) if options.activators is self.default else options.activators\n        )\n        self.active = {k: v for k, v in self.possible.items() if k in selected_activators}\n        self.parser.add_argument(\n            \"--prompt\",\n            dest=\"prompt\",\n            metavar=\"prompt\",\n            help=(\n                \"provides an alternative prompt prefix for this environment \"\n                \"(value of . means name of the current working directory)\"\n            ),\n            default=None,\n        )\n        for activator in self.active.values():\n            activator.add_parser_arguments(self.parser, self.interpreter)\n\n    def create(self, options):\n        return [activator_class(options) for activator_class in self.active.values()]\n\n\n__all__ = [\n    \"ActivationSelector\",\n]\n", "src/virtualenv/run/plugin/base.py": "from __future__ import annotations\n\nimport sys\nfrom collections import OrderedDict\n\nif sys.version_info >= (3, 8):\n    from importlib.metadata import entry_points\n\n    importlib_metadata_version = ()\nelse:\n    from importlib_metadata import entry_points, version\n\n    importlib_metadata_version = tuple(int(i) for i in version(\"importlib_metadata\").split(\".\")[:2])\n\n\nclass PluginLoader:\n    _OPTIONS = None\n    _ENTRY_POINTS = None\n\n    @classmethod\n    def entry_points_for(cls, key):\n        if sys.version_info >= (3, 10) or importlib_metadata_version >= (3, 6):\n            return OrderedDict((e.name, e.load()) for e in cls.entry_points().select(group=key))\n        return OrderedDict((e.name, e.load()) for e in cls.entry_points().get(key, {}))\n\n    @staticmethod\n    def entry_points():\n        if PluginLoader._ENTRY_POINTS is None:\n            PluginLoader._ENTRY_POINTS = entry_points()\n        return PluginLoader._ENTRY_POINTS\n\n\nclass ComponentBuilder(PluginLoader):\n    def __init__(self, interpreter, parser, name, possible) -> None:\n        self.interpreter = interpreter\n        self.name = name\n        self._impl_class = None\n        self.possible = possible\n        self.parser = parser.add_argument_group(title=name)\n        self.add_selector_arg_parse(name, list(self.possible))\n\n    @classmethod\n    def options(cls, key):\n        if cls._OPTIONS is None:\n            cls._OPTIONS = cls.entry_points_for(key)\n        return cls._OPTIONS\n\n    def add_selector_arg_parse(self, name, choices):\n        raise NotImplementedError\n\n    def handle_selected_arg_parse(self, options):\n        selected = getattr(options, self.name)\n        if selected not in self.possible:\n            msg = f\"No implementation for {self.interpreter}\"\n            raise RuntimeError(msg)\n        self._impl_class = self.possible[selected]\n        self.populate_selected_argparse(selected, options.app_data)\n        return selected\n\n    def populate_selected_argparse(self, selected, app_data):\n        self.parser.description = f\"options for {self.name} {selected}\"\n        self._impl_class.add_parser_arguments(self.parser, self.interpreter, app_data)\n\n    def create(self, options):\n        return self._impl_class(options, self.interpreter)\n\n\n__all__ = [\n    \"ComponentBuilder\",\n    \"PluginLoader\",\n]\n", "src/virtualenv/run/plugin/__init__.py": "", "src/virtualenv/run/plugin/creators.py": "from __future__ import annotations\n\nfrom collections import OrderedDict, defaultdict\nfrom typing import TYPE_CHECKING, NamedTuple\n\nfrom virtualenv.create.describe import Describe\nfrom virtualenv.create.via_global_ref.builtin.builtin_way import VirtualenvBuiltin\n\nfrom .base import ComponentBuilder\n\nif TYPE_CHECKING:\n    from virtualenv.create.creator import Creator, CreatorMeta\n\n\nclass CreatorInfo(NamedTuple):\n    key_to_class: dict[str, type[Creator]]\n    key_to_meta: dict[str, CreatorMeta]\n    describe: type[Describe] | None\n    builtin_key: str\n\n\nclass CreatorSelector(ComponentBuilder):\n    def __init__(self, interpreter, parser) -> None:\n        creators, self.key_to_meta, self.describe, self.builtin_key = self.for_interpreter(interpreter)\n        super().__init__(interpreter, parser, \"creator\", creators)\n\n    @classmethod\n    def for_interpreter(cls, interpreter):\n        key_to_class, key_to_meta, builtin_key, describe = OrderedDict(), {}, None, None\n        errors = defaultdict(list)\n        for key, creator_class in cls.options(\"virtualenv.create\").items():\n            if key == \"builtin\":\n                msg = \"builtin creator is a reserved name\"\n                raise RuntimeError(msg)\n            meta = creator_class.can_create(interpreter)\n            if meta:\n                if meta.error:\n                    errors[meta.error].append(creator_class)\n                else:\n                    if \"builtin\" not in key_to_class and issubclass(creator_class, VirtualenvBuiltin):\n                        builtin_key = key\n                        key_to_class[\"builtin\"] = creator_class\n                        key_to_meta[\"builtin\"] = meta\n                    key_to_class[key] = creator_class\n                    key_to_meta[key] = meta\n            if describe is None and issubclass(creator_class, Describe) and creator_class.can_describe(interpreter):\n                describe = creator_class\n        if not key_to_meta:\n            if errors:\n                rows = [f\"{k} for creators {', '.join(i.__name__ for i in v)}\" for k, v in errors.items()]\n                raise RuntimeError(\"\\n\".join(rows))\n            msg = f\"No virtualenv implementation for {interpreter}\"\n            raise RuntimeError(msg)\n        return CreatorInfo(\n            key_to_class=key_to_class,\n            key_to_meta=key_to_meta,\n            describe=describe,\n            builtin_key=builtin_key,\n        )\n\n    def add_selector_arg_parse(self, name, choices):\n        # prefer the built-in venv if present, otherwise fallback to first defined type\n        choices = sorted(choices, key=lambda a: 0 if a == \"builtin\" else 1)\n        default_value = self._get_default(choices)\n        self.parser.add_argument(\n            f\"--{name}\",\n            choices=choices,\n            default=default_value,\n            required=False,\n            help=f\"create environment via{'' if self.builtin_key is None else f' (builtin = {self.builtin_key})'}\",\n        )\n\n    @staticmethod\n    def _get_default(choices):\n        return next(iter(choices))\n\n    def populate_selected_argparse(self, selected, app_data):\n        self.parser.description = f\"options for {self.name} {selected}\"\n        self._impl_class.add_parser_arguments(self.parser, self.interpreter, self.key_to_meta[selected], app_data)\n\n    def create(self, options):\n        options.meta = self.key_to_meta[getattr(options, self.name)]\n        if not issubclass(self._impl_class, Describe):\n            options.describe = self.describe(options, self.interpreter)\n        return super().create(options)\n\n\n__all__ = [\n    \"CreatorInfo\",\n    \"CreatorSelector\",\n]\n", "src/virtualenv/activation/activator.py": "from __future__ import annotations\n\nimport os\nfrom abc import ABC, abstractmethod\n\n\nclass Activator(ABC):\n    \"\"\"Generates activate script for the virtual environment.\"\"\"\n\n    def __init__(self, options) -> None:\n        \"\"\"\n        Create a new activator generator.\n\n        :param options: the parsed options as defined within :meth:`add_parser_arguments`\n        \"\"\"\n        self.flag_prompt = os.path.basename(os.getcwd()) if options.prompt == \".\" else options.prompt\n\n    @classmethod\n    def supports(cls, interpreter):  # noqa: ARG003\n        \"\"\"\n        Check if the activation script is supported in the given interpreter.\n\n        :param interpreter: the interpreter we need to support\n        :return: ``True`` if supported, ``False`` otherwise\n        \"\"\"\n        return True\n\n    @classmethod  # noqa: B027\n    def add_parser_arguments(cls, parser, interpreter):\n        \"\"\"\n        Add CLI arguments for this activation script.\n\n        :param parser: the CLI parser\n        :param interpreter: the interpreter this virtual environment is based of\n        \"\"\"\n\n    @abstractmethod\n    def generate(self, creator):\n        \"\"\"\n        Generate activate script for the given creator.\n\n        :param creator: the creator (based of :class:`virtualenv.create.creator.Creator`) we used to create this \\\n        virtual environment\n        \"\"\"\n        raise NotImplementedError\n\n\n__all__ = [\n    \"Activator\",\n]\n", "src/virtualenv/activation/via_template.py": "from __future__ import annotations\n\nimport os\nimport sys\nfrom abc import ABC, abstractmethod\n\nfrom .activator import Activator\n\nif sys.version_info >= (3, 10):\n    from importlib.resources import files\n\n    def read_binary(module_name: str, filename: str) -> bytes:\n        return (files(module_name) / filename).read_bytes()\n\nelse:\n    from importlib.resources import read_binary\n\n\nclass ViaTemplateActivator(Activator, ABC):\n    @abstractmethod\n    def templates(self):\n        raise NotImplementedError\n\n    def generate(self, creator):\n        dest_folder = creator.bin_dir\n        replacements = self.replacements(creator, dest_folder)\n        generated = self._generate(replacements, self.templates(), dest_folder, creator)\n        if self.flag_prompt is not None:\n            creator.pyenv_cfg[\"prompt\"] = self.flag_prompt\n        return generated\n\n    def replacements(self, creator, dest_folder):  # noqa: ARG002\n        return {\n            \"__VIRTUAL_PROMPT__\": \"\" if self.flag_prompt is None else self.flag_prompt,\n            \"__VIRTUAL_ENV__\": str(creator.dest),\n            \"__VIRTUAL_NAME__\": creator.env_name,\n            \"__BIN_NAME__\": str(creator.bin_dir.relative_to(creator.dest)),\n            \"__PATH_SEP__\": os.pathsep,\n        }\n\n    def _generate(self, replacements, templates, to_folder, creator):\n        generated = []\n        for template in templates:\n            text = self.instantiate_template(replacements, template, creator)\n            dest = to_folder / self.as_name(template)\n            # remove the file if it already exists - this prevents permission\n            # errors when the dest is not writable\n            if dest.exists():\n                dest.unlink()\n            # Powershell assumes Windows 1252 encoding when reading files without BOM\n            encoding = \"utf-8-sig\" if str(template).endswith(\".ps1\") else \"utf-8\"\n            # use write_bytes to avoid platform specific line normalization (\\n -> \\r\\n)\n            dest.write_bytes(text.encode(encoding))\n            generated.append(dest)\n        return generated\n\n    def as_name(self, template):\n        return template\n\n    def instantiate_template(self, replacements, template, creator):\n        # read content as binary to avoid platform specific line normalization (\\n -> \\r\\n)\n        binary = read_binary(self.__module__, template)\n        text = binary.decode(\"utf-8\", errors=\"strict\")\n        for key, value in replacements.items():\n            value_uni = self._repr_unicode(creator, value)\n            text = text.replace(key, value_uni)\n        return text\n\n    @staticmethod\n    def _repr_unicode(creator, value):  # noqa: ARG004\n        return value  # by default, we just let it be unicode\n\n\n__all__ = [\n    \"ViaTemplateActivator\",\n]\n", "src/virtualenv/activation/__init__.py": "from __future__ import annotations\n\nfrom .bash import BashActivator\nfrom .batch import BatchActivator\nfrom .cshell import CShellActivator\nfrom .fish import FishActivator\nfrom .nushell import NushellActivator\nfrom .powershell import PowerShellActivator\nfrom .python import PythonActivator\n\n__all__ = [\n    \"BashActivator\",\n    \"BatchActivator\",\n    \"CShellActivator\",\n    \"FishActivator\",\n    \"NushellActivator\",\n    \"PowerShellActivator\",\n    \"PythonActivator\",\n]\n", "src/virtualenv/activation/powershell/__init__.py": "from __future__ import annotations\n\nfrom virtualenv.activation.via_template import ViaTemplateActivator\n\n\nclass PowerShellActivator(ViaTemplateActivator):\n    def templates(self):\n        yield \"activate.ps1\"\n\n\n__all__ = [\n    \"PowerShellActivator\",\n]\n", "src/virtualenv/activation/python/activate_this.py": "\"\"\"\nActivate virtualenv for current interpreter:\n\nimport runpy\nrunpy.run_path(this_file)\n\nThis can be used when you must use an existing Python interpreter, not the virtualenv bin/python.\n\"\"\"  # noqa: D415\n\nfrom __future__ import annotations\n\nimport os\nimport site\nimport sys\n\ntry:\n    abs_file = os.path.abspath(__file__)\nexcept NameError as exc:\n    msg = \"You must use import runpy; runpy.run_path(this_file)\"\n    raise AssertionError(msg) from exc\n\nbin_dir = os.path.dirname(abs_file)\nbase = bin_dir[: -len(\"__BIN_NAME__\") - 1]  # strip away the bin part from the __file__, plus the path separator\n\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"__VIRTUAL_PROMPT__\" or os.path.basename(base)  # noqa: SIM222\n\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"__LIB_FOLDERS__\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"__DECODE_PATH__\" else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\n\nsys.real_prefix = sys.prefix\nsys.prefix = base\n", "src/virtualenv/activation/python/__init__.py": "from __future__ import annotations\n\nimport os\nfrom collections import OrderedDict\n\nfrom virtualenv.activation.via_template import ViaTemplateActivator\n\n\nclass PythonActivator(ViaTemplateActivator):\n    def templates(self):\n        yield \"activate_this.py\"\n\n    def replacements(self, creator, dest_folder):\n        replacements = super().replacements(creator, dest_folder)\n        lib_folders = OrderedDict((os.path.relpath(str(i), str(dest_folder)), None) for i in creator.libs)\n        lib_folders = os.pathsep.join(lib_folders.keys()).replace(\"\\\\\", \"\\\\\\\\\")  # escape Windows path characters\n        replacements.update(\n            {\n                \"__LIB_FOLDERS__\": lib_folders,\n                \"__DECODE_PATH__\": \"\",\n            },\n        )\n        return replacements\n\n\n__all__ = [\n    \"PythonActivator\",\n]\n", "src/virtualenv/activation/fish/__init__.py": "from __future__ import annotations\n\nfrom virtualenv.activation.via_template import ViaTemplateActivator\n\n\nclass FishActivator(ViaTemplateActivator):\n    def templates(self):\n        yield \"activate.fish\"\n\n\n__all__ = [\n    \"FishActivator\",\n]\n", "src/virtualenv/activation/batch/__init__.py": "from __future__ import annotations\n\nimport os\n\nfrom virtualenv.activation.via_template import ViaTemplateActivator\n\n\nclass BatchActivator(ViaTemplateActivator):\n    @classmethod\n    def supports(cls, interpreter):\n        return interpreter.os == \"nt\"\n\n    def templates(self):\n        yield \"activate.bat\"\n        yield \"deactivate.bat\"\n        yield \"pydoc.bat\"\n\n    def instantiate_template(self, replacements, template, creator):\n        # ensure the text has all newlines as \\r\\n - required by batch\n        base = super().instantiate_template(replacements, template, creator)\n        return base.replace(os.linesep, \"\\n\").replace(\"\\n\", os.linesep)\n\n\n__all__ = [\n    \"BatchActivator\",\n]\n", "src/virtualenv/activation/nushell/__init__.py": "from __future__ import annotations\n\nfrom virtualenv.activation.via_template import ViaTemplateActivator\n\n\nclass NushellActivator(ViaTemplateActivator):\n    def templates(self):\n        yield \"activate.nu\"\n\n    def replacements(self, creator, dest_folder):  # noqa: ARG002\n        return {\n            \"__VIRTUAL_PROMPT__\": \"\" if self.flag_prompt is None else self.flag_prompt,\n            \"__VIRTUAL_ENV__\": str(creator.dest),\n            \"__VIRTUAL_NAME__\": creator.env_name,\n            \"__BIN_NAME__\": str(creator.bin_dir.relative_to(creator.dest)),\n        }\n\n\n__all__ = [\n    \"NushellActivator\",\n]\n", "src/virtualenv/activation/bash/__init__.py": "from __future__ import annotations\n\nfrom pathlib import Path\n\nfrom virtualenv.activation.via_template import ViaTemplateActivator\n\n\nclass BashActivator(ViaTemplateActivator):\n    def templates(self):\n        yield \"activate.sh\"\n\n    def as_name(self, template):\n        return Path(template).stem\n\n\n__all__ = [\n    \"BashActivator\",\n]\n", "src/virtualenv/activation/cshell/__init__.py": "from __future__ import annotations\n\nfrom virtualenv.activation.via_template import ViaTemplateActivator\n\n\nclass CShellActivator(ViaTemplateActivator):\n    @classmethod\n    def supports(cls, interpreter):\n        return interpreter.os != \"nt\"\n\n    def templates(self):\n        yield \"activate.csh\"\n\n\n__all__ = [\n    \"CShellActivator\",\n]\n", "src/virtualenv/create/debug.py": "\"\"\"Inspect a target Python interpreter virtual environment wise.\"\"\"\n\nfrom __future__ import annotations\n\nimport sys  # built-in\n\n\ndef encode_path(value):\n    if value is None:\n        return None\n    if not isinstance(value, (str, bytes)):\n        value = repr(value) if isinstance(value, type) else repr(type(value))\n    if isinstance(value, bytes):\n        value = value.decode(sys.getfilesystemencoding())\n    return value\n\n\ndef encode_list_path(value):\n    return [encode_path(i) for i in value]\n\n\ndef run():\n    \"\"\"Print debug data about the virtual environment.\"\"\"\n    try:\n        from collections import OrderedDict  # noqa: PLC0415\n    except ImportError:  # pragma: no cover\n        # this is possible if the standard library cannot be accessed\n\n        OrderedDict = dict  # pragma: no cover  # noqa: N806\n    result = OrderedDict([(\"sys\", OrderedDict())])\n    path_keys = (\n        \"executable\",\n        \"_base_executable\",\n        \"prefix\",\n        \"base_prefix\",\n        \"real_prefix\",\n        \"exec_prefix\",\n        \"base_exec_prefix\",\n        \"path\",\n        \"meta_path\",\n    )\n    for key in path_keys:\n        value = getattr(sys, key, None)\n        value = encode_list_path(value) if isinstance(value, list) else encode_path(value)\n        result[\"sys\"][key] = value\n    result[\"sys\"][\"fs_encoding\"] = sys.getfilesystemencoding()\n    result[\"sys\"][\"io_encoding\"] = getattr(sys.stdout, \"encoding\", None)\n    result[\"version\"] = sys.version\n\n    try:\n        import sysconfig  # noqa: PLC0415\n\n        # https://bugs.python.org/issue22199\n        makefile = getattr(sysconfig, \"get_makefile_filename\", getattr(sysconfig, \"_get_makefile_filename\", None))\n        result[\"makefile_filename\"] = encode_path(makefile())\n    except ImportError:\n        pass\n\n    import os  # landmark  # noqa: PLC0415\n\n    result[\"os\"] = repr(os)\n\n    try:\n        import site  # site  # noqa: PLC0415\n\n        result[\"site\"] = repr(site)\n    except ImportError as exception:  # pragma: no cover\n        result[\"site\"] = repr(exception)  # pragma: no cover\n\n    try:\n        import datetime  # site  # noqa: PLC0415\n\n        result[\"datetime\"] = repr(datetime)\n    except ImportError as exception:  # pragma: no cover\n        result[\"datetime\"] = repr(exception)  # pragma: no cover\n\n    try:\n        import math  # site  # noqa: PLC0415\n\n        result[\"math\"] = repr(math)\n    except ImportError as exception:  # pragma: no cover\n        result[\"math\"] = repr(exception)  # pragma: no cover\n\n    # try to print out, this will validate if other core modules are available (json in this case)\n    try:\n        import json  # noqa: PLC0415\n\n        result[\"json\"] = repr(json)\n    except ImportError as exception:\n        result[\"json\"] = repr(exception)\n    else:\n        try:\n            content = json.dumps(result, indent=2)\n            sys.stdout.write(content)\n        except (ValueError, TypeError) as exception:  # pragma: no cover\n            sys.stderr.write(repr(exception))\n            sys.stdout.write(repr(result))  # pragma: no cover\n            raise SystemExit(1)  # noqa: B904  # pragma: no cover\n\n\nif __name__ == \"__main__\":\n    run()\n", "src/virtualenv/create/creator.py": "from __future__ import annotations\n\nimport json\nimport logging\nimport os\nimport sys\nfrom abc import ABC, abstractmethod\nfrom argparse import ArgumentTypeError\nfrom ast import literal_eval\nfrom collections import OrderedDict\nfrom pathlib import Path\n\nfrom virtualenv.discovery.cached_py_info import LogCmd\nfrom virtualenv.util.path import safe_delete\nfrom virtualenv.util.subprocess import run_cmd\nfrom virtualenv.version import __version__\n\nfrom .pyenv_cfg import PyEnvCfg\n\nHERE = Path(os.path.abspath(__file__)).parent\nDEBUG_SCRIPT = HERE / \"debug.py\"\n\n\nclass CreatorMeta:\n    def __init__(self) -> None:\n        self.error = None\n\n\nclass Creator(ABC):\n    \"\"\"A class that given a python Interpreter creates a virtual environment.\"\"\"\n\n    def __init__(self, options, interpreter) -> None:\n        \"\"\"\n        Construct a new virtual environment creator.\n\n        :param options: the CLI option as parsed from :meth:`add_parser_arguments`\n        :param interpreter: the interpreter to create virtual environment from\n        \"\"\"\n        self.interpreter = interpreter\n        self._debug = None\n        self.dest = Path(options.dest)\n        self.clear = options.clear\n        self.no_vcs_ignore = options.no_vcs_ignore\n        self.pyenv_cfg = PyEnvCfg.from_folder(self.dest)\n        self.app_data = options.app_data\n        self.env = options.env\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}({', '.join(f'{k}={v}' for k, v in self._args())})\"\n\n    def _args(self):\n        return [\n            (\"dest\", str(self.dest)),\n            (\"clear\", self.clear),\n            (\"no_vcs_ignore\", self.no_vcs_ignore),\n        ]\n\n    @classmethod\n    def can_create(cls, interpreter):  # noqa: ARG003\n        \"\"\"\n        Determine if we can create a virtual environment.\n\n        :param interpreter: the interpreter in question\n        :return: ``None`` if we can't create, any other object otherwise that will be forwarded to \\\n                  :meth:`add_parser_arguments`\n        \"\"\"\n        return True\n\n    @classmethod\n    def add_parser_arguments(cls, parser, interpreter, meta, app_data):  # noqa: ARG003\n        \"\"\"\n        Add CLI arguments for the creator.\n\n        :param parser: the CLI parser\n        :param app_data: the application data folder\n        :param interpreter: the interpreter we're asked to create virtual environment for\n        :param meta: value as returned by :meth:`can_create`\n        \"\"\"\n        parser.add_argument(\n            \"dest\",\n            help=\"directory to create virtualenv at\",\n            type=cls.validate_dest,\n        )\n        parser.add_argument(\n            \"--clear\",\n            dest=\"clear\",\n            action=\"store_true\",\n            help=\"remove the destination directory if exist before starting (will overwrite files otherwise)\",\n            default=False,\n        )\n        parser.add_argument(\n            \"--no-vcs-ignore\",\n            dest=\"no_vcs_ignore\",\n            action=\"store_true\",\n            help=\"don't create VCS ignore directive in the destination directory\",\n            default=False,\n        )\n\n    @abstractmethod\n    def create(self):\n        \"\"\"Perform the virtual environment creation.\"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    def validate_dest(cls, raw_value):  # noqa: C901\n        \"\"\"No path separator in the path, valid chars and must be write-able.\"\"\"\n\n        def non_write_able(dest, value):\n            common = Path(*os.path.commonprefix([value.parts, dest.parts]))\n            msg = f\"the destination {dest.relative_to(common)} is not write-able at {common}\"\n            raise ArgumentTypeError(msg)\n\n        # the file system must be able to encode\n        # note in newer CPython this is always utf-8 https://www.python.org/dev/peps/pep-0529/\n        encoding = sys.getfilesystemencoding()\n        refused = OrderedDict()\n        kwargs = {\"errors\": \"ignore\"} if encoding != \"mbcs\" else {}\n        for char in str(raw_value):\n            try:\n                trip = char.encode(encoding, **kwargs).decode(encoding)\n                if trip == char:\n                    continue\n                raise ValueError(trip)  # noqa: TRY301\n            except ValueError:\n                refused[char] = None\n        if refused:\n            bad = \"\".join(refused.keys())\n            msg = f\"the file system codec ({encoding}) cannot handle characters {bad!r} within {raw_value!r}\"\n            raise ArgumentTypeError(msg)\n        if os.pathsep in raw_value:\n            msg = (\n                f\"destination {raw_value!r} must not contain the path separator ({os.pathsep})\"\n                f\" as this would break the activation scripts\"\n            )\n            raise ArgumentTypeError(msg)\n\n        value = Path(raw_value)\n        if value.exists() and value.is_file():\n            msg = f\"the destination {value} already exists and is a file\"\n            raise ArgumentTypeError(msg)\n        dest = Path(os.path.abspath(str(value))).resolve()  # on Windows absolute does not imply resolve so use both\n        value = dest\n        while dest:\n            if dest.exists():\n                if os.access(str(dest), os.W_OK):\n                    break\n                non_write_able(dest, value)\n            base, _ = dest.parent, dest.name\n            if base == dest:\n                non_write_able(dest, value)  # pragma: no cover\n            dest = base\n        return str(value)\n\n    def run(self):\n        if self.dest.exists() and self.clear:\n            logging.debug(\"delete %s\", self.dest)\n            safe_delete(self.dest)\n        self.create()\n        self.set_pyenv_cfg()\n        if not self.no_vcs_ignore:\n            self.setup_ignore_vcs()\n\n    def set_pyenv_cfg(self):\n        self.pyenv_cfg.content = OrderedDict()\n        self.pyenv_cfg[\"home\"] = os.path.dirname(os.path.abspath(self.interpreter.system_executable))\n        self.pyenv_cfg[\"implementation\"] = self.interpreter.implementation\n        self.pyenv_cfg[\"version_info\"] = \".\".join(str(i) for i in self.interpreter.version_info)\n        self.pyenv_cfg[\"virtualenv\"] = __version__\n\n    def setup_ignore_vcs(self):\n        \"\"\"Generate ignore instructions for version control systems.\"\"\"\n        # mark this folder to be ignored by VCS, handle https://www.python.org/dev/peps/pep-0610/#registered-vcs\n        git_ignore = self.dest / \".gitignore\"\n        if not git_ignore.exists():\n            git_ignore.write_text(\"# created by virtualenv automatically\\n*\\n\", encoding=\"utf-8\")\n        # Mercurial - does not support the .hgignore file inside a subdirectory directly, but only if included via the\n        # subinclude directive from root, at which point on might as well ignore the directory itself, see\n        # https://www.selenic.com/mercurial/hgignore.5.html for more details\n        # Bazaar - does not support ignore files in sub-directories, only at root level via .bzrignore\n        # Subversion - does not support ignore files, requires direct manipulation with the svn tool\n\n    @property\n    def debug(self):\n        \"\"\":return: debug information about the virtual environment (only valid after :meth:`create` has run)\"\"\"\n        if self._debug is None and self.exe is not None:\n            self._debug = get_env_debug_info(self.exe, self.debug_script(), self.app_data, self.env)\n        return self._debug\n\n    @staticmethod\n    def debug_script():\n        return DEBUG_SCRIPT\n\n\ndef get_env_debug_info(env_exe, debug_script, app_data, env):\n    env = env.copy()\n    env.pop(\"PYTHONPATH\", None)\n\n    with app_data.ensure_extracted(debug_script) as debug_script_extracted:\n        cmd = [str(env_exe), str(debug_script_extracted)]\n        logging.debug(\"debug via %r\", LogCmd(cmd))\n        code, out, err = run_cmd(cmd)\n\n    try:\n        if code != 0:\n            if out:\n                result = literal_eval(out)\n            else:\n                if code == 2 and \"file\" in err:  # noqa: PLR2004\n                    # Re-raise FileNotFoundError from `run_cmd()`\n                    raise OSError(err)  # noqa: TRY301\n                raise Exception(err)  # noqa: TRY002, TRY301\n        else:\n            result = json.loads(out)\n        if err:\n            result[\"err\"] = err\n    except Exception as exception:  # noqa: BLE001\n        return {\"out\": out, \"err\": err, \"returncode\": code, \"exception\": repr(exception)}\n    if \"sys\" in result and \"path\" in result[\"sys\"]:\n        del result[\"sys\"][\"path\"][0]\n    return result\n\n\n__all__ = [\n    \"Creator\",\n    \"CreatorMeta\",\n]\n", "src/virtualenv/create/__init__.py": "", "src/virtualenv/create/pyenv_cfg.py": "from __future__ import annotations\n\nimport logging\nimport os\nfrom collections import OrderedDict\n\n\nclass PyEnvCfg:\n    def __init__(self, content, path) -> None:\n        self.content = content\n        self.path = path\n\n    @classmethod\n    def from_folder(cls, folder):\n        return cls.from_file(folder / \"pyvenv.cfg\")\n\n    @classmethod\n    def from_file(cls, path):\n        content = cls._read_values(path) if path.exists() else OrderedDict()\n        return PyEnvCfg(content, path)\n\n    @staticmethod\n    def _read_values(path):\n        content = OrderedDict()\n        for line in path.read_text(encoding=\"utf-8\").splitlines():\n            equals_at = line.index(\"=\")\n            key = line[:equals_at].strip()\n            value = line[equals_at + 1 :].strip()\n            content[key] = value\n        return content\n\n    def write(self):\n        logging.debug(\"write %s\", self.path)\n        text = \"\"\n        for key, value in self.content.items():\n            normalized_value = os.path.realpath(value) if value and os.path.exists(value) else value\n            line = f\"{key} = {normalized_value}\"\n            logging.debug(\"\\t%s\", line)\n            text += line\n            text += \"\\n\"\n        self.path.write_text(text, encoding=\"utf-8\")\n\n    def refresh(self):\n        self.content = self._read_values(self.path)\n        return self.content\n\n    def __setitem__(self, key, value) -> None:\n        self.content[key] = value\n\n    def __getitem__(self, key):\n        return self.content[key]\n\n    def __contains__(self, item) -> bool:\n        return item in self.content\n\n    def update(self, other):\n        self.content.update(other)\n        return self\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}(path={self.path})\"\n\n\n__all__ = [\n    \"PyEnvCfg\",\n]\n", "src/virtualenv/create/describe.py": "from __future__ import annotations\n\nfrom abc import ABC\nfrom collections import OrderedDict\nfrom pathlib import Path\n\nfrom virtualenv.info import IS_WIN\n\n\nclass Describe:\n    \"\"\"Given a host interpreter tell us information about what the created interpreter might look like.\"\"\"\n\n    suffix = \".exe\" if IS_WIN else \"\"\n\n    def __init__(self, dest, interpreter) -> None:\n        self.interpreter = interpreter\n        self.dest = dest\n        self._stdlib = None\n        self._stdlib_platform = None\n        self._system_stdlib = None\n        self._conf_vars = None\n\n    @property\n    def bin_dir(self):\n        return self.script_dir\n\n    @property\n    def script_dir(self):\n        return self.dest / self.interpreter.install_path(\"scripts\")\n\n    @property\n    def purelib(self):\n        return self.dest / self.interpreter.install_path(\"purelib\")\n\n    @property\n    def platlib(self):\n        return self.dest / self.interpreter.install_path(\"platlib\")\n\n    @property\n    def libs(self):\n        return list(OrderedDict(((self.platlib, None), (self.purelib, None))).keys())\n\n    @property\n    def stdlib(self):\n        if self._stdlib is None:\n            self._stdlib = Path(self.interpreter.sysconfig_path(\"stdlib\", config_var=self._config_vars))\n        return self._stdlib\n\n    @property\n    def stdlib_platform(self):\n        if self._stdlib_platform is None:\n            self._stdlib_platform = Path(self.interpreter.sysconfig_path(\"platstdlib\", config_var=self._config_vars))\n        return self._stdlib_platform\n\n    @property\n    def _config_vars(self):\n        if self._conf_vars is None:\n            self._conf_vars = self._calc_config_vars(self.dest)\n        return self._conf_vars\n\n    def _calc_config_vars(self, to):\n        sys_vars = self.interpreter.sysconfig_vars\n        return {k: (to if v is not None and v.startswith(self.interpreter.prefix) else v) for k, v in sys_vars.items()}\n\n    @classmethod\n    def can_describe(cls, interpreter):  # noqa: ARG003\n        \"\"\"Knows means it knows how the output will look.\"\"\"\n        return True\n\n    @property\n    def env_name(self):\n        return self.dest.parts[-1]\n\n    @property\n    def exe(self):\n        return self.bin_dir / f\"{self.exe_stem()}{self.suffix}\"\n\n    @classmethod\n    def exe_stem(cls):\n        \"\"\"Executable name without suffix - there seems to be no standard way to get this without creating it.\"\"\"\n        raise NotImplementedError\n\n    def script(self, name):\n        return self.script_dir / f\"{name}{self.suffix}\"\n\n\nclass Python3Supports(Describe, ABC):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return interpreter.version_info.major == 3 and super().can_describe(interpreter)  # noqa: PLR2004\n\n\nclass PosixSupports(Describe, ABC):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return interpreter.os == \"posix\" and super().can_describe(interpreter)\n\n\nclass WindowsSupports(Describe, ABC):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return interpreter.os == \"nt\" and super().can_describe(interpreter)\n\n\n__all__ = [\n    \"Describe\",\n    \"PosixSupports\",\n    \"Python3Supports\",\n    \"WindowsSupports\",\n]\n", "src/virtualenv/create/via_global_ref/store.py": "from __future__ import annotations\n\nfrom pathlib import Path\n\n\ndef handle_store_python(meta, interpreter):\n    if is_store_python(interpreter):\n        meta.symlink_error = \"Windows Store Python does not support virtual environments via symlink\"\n    return meta\n\n\ndef is_store_python(interpreter):\n    parts = Path(interpreter.system_executable).parts\n    return (\n        len(parts) > 4  # noqa: PLR2004\n        and parts[-4] == \"Microsoft\"\n        and parts[-3] == \"WindowsApps\"\n        and parts[-2].startswith(\"PythonSoftwareFoundation.Python.3.\")\n        and parts[-1].startswith(\"python\")\n    )\n\n\n__all__ = [\n    \"handle_store_python\",\n    \"is_store_python\",\n]\n", "src/virtualenv/create/via_global_ref/api.py": "from __future__ import annotations\n\nimport logging\nimport os\nfrom abc import ABC\nfrom pathlib import Path\n\nfrom virtualenv.create.creator import Creator, CreatorMeta\nfrom virtualenv.info import fs_supports_symlink\n\n\nclass ViaGlobalRefMeta(CreatorMeta):\n    def __init__(self) -> None:\n        super().__init__()\n        self.copy_error = None\n        self.symlink_error = None\n        if not fs_supports_symlink():\n            self.symlink_error = \"the filesystem does not supports symlink\"\n\n    @property\n    def can_copy(self):\n        return not self.copy_error\n\n    @property\n    def can_symlink(self):\n        return not self.symlink_error\n\n\nclass ViaGlobalRefApi(Creator, ABC):\n    def __init__(self, options, interpreter) -> None:\n        super().__init__(options, interpreter)\n        self.symlinks = self._should_symlink(options)\n        self.enable_system_site_package = options.system_site\n\n    @staticmethod\n    def _should_symlink(options):\n        # Priority of where the option is set to follow the order: CLI, env var, file, hardcoded.\n        # If both set at same level prefers copy over symlink.\n        copies, symlinks = getattr(options, \"copies\", False), getattr(options, \"symlinks\", False)\n        copy_src, sym_src = options.get_source(\"copies\"), options.get_source(\"symlinks\")\n        for level in [\"cli\", \"env var\", \"file\", \"default\"]:\n            s_opt = symlinks if sym_src == level else None\n            c_opt = copies if copy_src == level else None\n            if s_opt is True and c_opt is True:\n                return False\n            if s_opt is True:\n                return True\n            if c_opt is True:\n                return False\n        return False  # fallback to copy\n\n    @classmethod\n    def add_parser_arguments(cls, parser, interpreter, meta, app_data):\n        super().add_parser_arguments(parser, interpreter, meta, app_data)\n        parser.add_argument(\n            \"--system-site-packages\",\n            default=False,\n            action=\"store_true\",\n            dest=\"system_site\",\n            help=\"give the virtual environment access to the system site-packages dir\",\n        )\n        if not meta.can_symlink and not meta.can_copy:\n            msg = \"neither symlink or copy method supported\"\n            raise RuntimeError(msg)\n        group = parser.add_mutually_exclusive_group()\n        if meta.can_symlink:\n            group.add_argument(\n                \"--symlinks\",\n                default=True,\n                action=\"store_true\",\n                dest=\"symlinks\",\n                help=\"try to use symlinks rather than copies, when symlinks are not the default for the platform\",\n            )\n        if meta.can_copy:\n            group.add_argument(\n                \"--copies\",\n                \"--always-copy\",\n                default=not meta.can_symlink,\n                action=\"store_true\",\n                dest=\"copies\",\n                help=\"try to use copies rather than symlinks, even when symlinks are the default for the platform\",\n            )\n\n    def create(self):\n        self.install_patch()\n\n    def install_patch(self):\n        text = self.env_patch_text()\n        if text:\n            pth = self.purelib / \"_virtualenv.pth\"\n            logging.debug(\"create virtualenv import hook file %s\", pth)\n            pth.write_text(\"import _virtualenv\", encoding=\"utf-8\")\n            dest_path = self.purelib / \"_virtualenv.py\"\n            logging.debug(\"create %s\", dest_path)\n            dest_path.write_text(text, encoding=\"utf-8\")\n\n    def env_patch_text(self):\n        \"\"\"Patch the distutils package to not be derailed by its configuration files.\"\"\"\n        with self.app_data.ensure_extracted(Path(__file__).parent / \"_virtualenv.py\") as resolved_path:\n            text = resolved_path.read_text(encoding=\"utf-8\")\n            return text.replace('\"__SCRIPT_DIR__\"', repr(os.path.relpath(str(self.script_dir), str(self.purelib))))\n\n    def _args(self):\n        return [*super()._args(), (\"global\", self.enable_system_site_package)]\n\n    def set_pyenv_cfg(self):\n        super().set_pyenv_cfg()\n        self.pyenv_cfg[\"include-system-site-packages\"] = \"true\" if self.enable_system_site_package else \"false\"\n\n\n__all__ = [\n    \"ViaGlobalRefApi\",\n    \"ViaGlobalRefMeta\",\n]\n", "src/virtualenv/create/via_global_ref/_virtualenv.py": "\"\"\"Patches that are applied at runtime to the virtual environment.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport sys\n\nVIRTUALENV_PATCH_FILE = os.path.join(__file__)\n\n\ndef patch_dist(dist):\n    \"\"\"\n    Distutils allows user to configure some arguments via a configuration file:\n    https://docs.python.org/3/install/index.html#distutils-configuration-files.\n\n    Some of this arguments though don't make sense in context of the virtual environment files, let's fix them up.\n    \"\"\"  # noqa: D205\n    # we cannot allow some install config as that would get packages installed outside of the virtual environment\n    old_parse_config_files = dist.Distribution.parse_config_files\n\n    def parse_config_files(self, *args, **kwargs):\n        result = old_parse_config_files(self, *args, **kwargs)\n        install = self.get_option_dict(\"install\")\n\n        if \"prefix\" in install:  # the prefix governs where to install the libraries\n            install[\"prefix\"] = VIRTUALENV_PATCH_FILE, os.path.abspath(sys.prefix)\n        for base in (\"purelib\", \"platlib\", \"headers\", \"scripts\", \"data\"):\n            key = f\"install_{base}\"\n            if key in install:  # do not allow global configs to hijack venv paths\n                install.pop(key, None)\n        return result\n\n    dist.Distribution.parse_config_files = parse_config_files\n\n\n# Import hook that patches some modules to ignore configuration values that break package installation in case\n# of virtual environments.\n_DISTUTILS_PATCH = \"distutils.dist\", \"setuptools.dist\"\n# https://docs.python.org/3/library/importlib.html#setting-up-an-importer\n\n\nclass _Finder:\n    \"\"\"A meta path finder that allows patching the imported distutils modules.\"\"\"\n\n    fullname = None\n\n    # lock[0] is threading.Lock(), but initialized lazily to avoid importing threading very early at startup,\n    # because there are gevent-based applications that need to be first to import threading by themselves.\n    # See https://github.com/pypa/virtualenv/issues/1895 for details.\n    lock = []  # noqa: RUF012\n\n    def find_spec(self, fullname, path, target=None):  # noqa: ARG002\n        if fullname in _DISTUTILS_PATCH and self.fullname is None:  # noqa: PLR1702\n            # initialize lock[0] lazily\n            if len(self.lock) == 0:\n                import threading  # noqa: PLC0415\n\n                lock = threading.Lock()\n                # there is possibility that two threads T1 and T2 are simultaneously running into find_spec,\n                # observing .lock as empty, and further going into hereby initialization. However due to the GIL,\n                # list.append() operation is atomic and this way only one of the threads will \"win\" to put the lock\n                # - that every thread will use - into .lock[0].\n                # https://docs.python.org/3/faq/library.html#what-kinds-of-global-value-mutation-are-thread-safe\n                self.lock.append(lock)\n\n            from functools import partial  # noqa: PLC0415\n            from importlib.util import find_spec  # noqa: PLC0415\n\n            with self.lock[0]:\n                self.fullname = fullname\n                try:\n                    spec = find_spec(fullname, path)\n                    if spec is not None:\n                        # https://www.python.org/dev/peps/pep-0451/#how-loading-will-work\n                        is_new_api = hasattr(spec.loader, \"exec_module\")\n                        func_name = \"exec_module\" if is_new_api else \"load_module\"\n                        old = getattr(spec.loader, func_name)\n                        func = self.exec_module if is_new_api else self.load_module\n                        if old is not func:\n                            try:  # noqa: SIM105\n                                setattr(spec.loader, func_name, partial(func, old))\n                            except AttributeError:\n                                pass  # C-Extension loaders are r/o such as zipimporter with <3.7\n                        return spec\n                finally:\n                    self.fullname = None\n        return None\n\n    @staticmethod\n    def exec_module(old, module):\n        old(module)\n        if module.__name__ in _DISTUTILS_PATCH:\n            patch_dist(module)\n\n    @staticmethod\n    def load_module(old, name):\n        module = old(name)\n        if module.__name__ in _DISTUTILS_PATCH:\n            patch_dist(module)\n        return module\n\n\nsys.meta_path.insert(0, _Finder())\n", "src/virtualenv/create/via_global_ref/venv.py": "from __future__ import annotations\n\nimport logging\nfrom copy import copy\n\nfrom virtualenv.create.via_global_ref.store import handle_store_python\nfrom virtualenv.discovery.py_info import PythonInfo\nfrom virtualenv.util.error import ProcessCallFailedError\nfrom virtualenv.util.path import ensure_dir\nfrom virtualenv.util.subprocess import run_cmd\n\nfrom .api import ViaGlobalRefApi, ViaGlobalRefMeta\nfrom .builtin.cpython.mac_os import CPython3macOsBrew\nfrom .builtin.pypy.pypy3 import Pypy3Windows\n\n\nclass Venv(ViaGlobalRefApi):\n    def __init__(self, options, interpreter) -> None:\n        self.describe = options.describe\n        super().__init__(options, interpreter)\n        current = PythonInfo.current()\n        self.can_be_inline = interpreter is current and interpreter.executable == interpreter.system_executable\n        self._context = None\n\n    def _args(self):\n        return super()._args() + ([(\"describe\", self.describe.__class__.__name__)] if self.describe else [])\n\n    @classmethod\n    def can_create(cls, interpreter):\n        if interpreter.has_venv:\n            if CPython3macOsBrew.can_describe(interpreter):\n                return CPython3macOsBrew.setup_meta(interpreter)\n            meta = ViaGlobalRefMeta()\n            if interpreter.platform == \"win32\":\n                meta = handle_store_python(meta, interpreter)\n            return meta\n        return None\n\n    def create(self):\n        if self.can_be_inline:\n            self.create_inline()\n        else:\n            self.create_via_sub_process()\n        for lib in self.libs:\n            ensure_dir(lib)\n        super().create()\n        self.executables_for_win_pypy_less_v37()\n\n    def executables_for_win_pypy_less_v37(self):\n        \"\"\"\n        PyPy <= 3.6 (v7.3.3) for Windows contains only pypy3.exe and pypy3w.exe\n        Venv does not handle non-existing exe sources, e.g. python.exe, so this\n        patch does it.\n        \"\"\"  # noqa: D205\n        creator = self.describe\n        if isinstance(creator, Pypy3Windows) and creator.less_v37:\n            for exe in creator.executables(self.interpreter):\n                exe.run(creator, self.symlinks)\n\n    def create_inline(self):\n        from venv import EnvBuilder  # noqa: PLC0415\n\n        builder = EnvBuilder(\n            system_site_packages=self.enable_system_site_package,\n            clear=False,\n            symlinks=self.symlinks,\n            with_pip=False,\n        )\n        builder.create(str(self.dest))\n\n    def create_via_sub_process(self):\n        cmd = self.get_host_create_cmd()\n        logging.info(\"using host built-in venv to create via %s\", \" \".join(cmd))\n        code, out, err = run_cmd(cmd)\n        if code != 0:\n            raise ProcessCallFailedError(code, out, err, cmd)\n\n    def get_host_create_cmd(self):\n        cmd = [self.interpreter.system_executable, \"-m\", \"venv\", \"--without-pip\"]\n        if self.enable_system_site_package:\n            cmd.append(\"--system-site-packages\")\n        cmd.extend((\"--symlinks\" if self.symlinks else \"--copies\", str(self.dest)))\n        return cmd\n\n    def set_pyenv_cfg(self):\n        # prefer venv options over ours, but keep our extra\n        venv_content = copy(self.pyenv_cfg.refresh())\n        super().set_pyenv_cfg()\n        self.pyenv_cfg.update(venv_content)\n\n    def __getattribute__(self, item):\n        describe = object.__getattribute__(self, \"describe\")\n        if describe is not None and hasattr(describe, item):\n            element = getattr(describe, item)\n            if not callable(element) or item == \"script\":\n                return element\n        return object.__getattribute__(self, item)\n\n\n__all__ = [\n    \"Venv\",\n]\n", "src/virtualenv/create/via_global_ref/__init__.py": "", "src/virtualenv/create/via_global_ref/builtin/via_global_self_do.py": "from __future__ import annotations\n\nfrom abc import ABC\n\nfrom virtualenv.create.via_global_ref.api import ViaGlobalRefApi, ViaGlobalRefMeta\nfrom virtualenv.create.via_global_ref.builtin.ref import (\n    ExePathRefToDest,\n    RefMust,\n    RefWhen,\n)\nfrom virtualenv.util.path import ensure_dir\n\nfrom .builtin_way import VirtualenvBuiltin\n\n\nclass BuiltinViaGlobalRefMeta(ViaGlobalRefMeta):\n    def __init__(self) -> None:\n        super().__init__()\n        self.sources = []\n\n\nclass ViaGlobalRefVirtualenvBuiltin(ViaGlobalRefApi, VirtualenvBuiltin, ABC):\n    def __init__(self, options, interpreter) -> None:\n        super().__init__(options, interpreter)\n        self._sources = getattr(options.meta, \"sources\", None)  # if we're created as a describer this might be missing\n\n    @classmethod\n    def can_create(cls, interpreter):\n        \"\"\"By default, all built-in methods assume that if we can describe it we can create it.\"\"\"\n        # first we must be able to describe it\n        if not cls.can_describe(interpreter):\n            return None\n        meta = cls.setup_meta(interpreter)\n        if meta is not None and meta:\n            cls._sources_can_be_applied(interpreter, meta)\n        return meta\n\n    @classmethod\n    def _sources_can_be_applied(cls, interpreter, meta):\n        for src in cls.sources(interpreter):\n            if src.exists:\n                if meta.can_copy and not src.can_copy:\n                    meta.copy_error = f\"cannot copy {src}\"\n                if meta.can_symlink and not src.can_symlink:\n                    meta.symlink_error = f\"cannot symlink {src}\"\n            else:\n                msg = f\"missing required file {src}\"\n                if src.when == RefMust.NA:\n                    meta.error = msg\n                elif src.when == RefMust.COPY:\n                    meta.copy_error = msg\n                elif src.when == RefMust.SYMLINK:\n                    meta.symlink_error = msg\n            if not meta.can_copy and not meta.can_symlink:\n                meta.error = f\"neither copy or symlink supported, copy: {meta.copy_error} symlink: {meta.symlink_error}\"\n            if meta.error:\n                break\n            meta.sources.append(src)\n\n    @classmethod\n    def setup_meta(cls, interpreter):  # noqa: ARG003\n        return BuiltinViaGlobalRefMeta()\n\n    @classmethod\n    def sources(cls, interpreter):\n        for host_exe, targets, must, when in cls._executables(interpreter):\n            yield ExePathRefToDest(host_exe, dest=cls.to_bin, targets=targets, must=must, when=when)\n\n    def to_bin(self, src):\n        return self.bin_dir / src.name\n\n    @classmethod\n    def _executables(cls, interpreter):\n        raise NotImplementedError\n\n    def create(self):\n        dirs = self.ensure_directories()\n        for directory in list(dirs):\n            if any(i for i in dirs if i is not directory and directory.parts == i.parts[: len(directory.parts)]):\n                dirs.remove(directory)\n        for directory in sorted(dirs):\n            ensure_dir(directory)\n\n        self.set_pyenv_cfg()\n        self.pyenv_cfg.write()\n        true_system_site = self.enable_system_site_package\n        try:\n            self.enable_system_site_package = False\n            for src in self._sources:\n                if (\n                    src.when == RefWhen.ANY\n                    or (src.when == RefWhen.SYMLINK and self.symlinks is True)\n                    or (src.when == RefWhen.COPY and self.symlinks is False)\n                ):\n                    src.run(self, self.symlinks)\n        finally:\n            if true_system_site != self.enable_system_site_package:\n                self.enable_system_site_package = true_system_site\n        super().create()\n\n    def ensure_directories(self):\n        return {self.dest, self.bin_dir, self.script_dir, self.stdlib} | set(self.libs)\n\n    def set_pyenv_cfg(self):\n        \"\"\"\n        We directly inject the base prefix and base exec prefix to avoid site.py needing to discover these\n        from home (which usually is done within the interpreter itself).\n        \"\"\"  # noqa: D205\n        super().set_pyenv_cfg()\n        self.pyenv_cfg[\"base-prefix\"] = self.interpreter.system_prefix\n        self.pyenv_cfg[\"base-exec-prefix\"] = self.interpreter.system_exec_prefix\n        self.pyenv_cfg[\"base-executable\"] = self.interpreter.system_executable\n\n\n__all__ = [\n    \"BuiltinViaGlobalRefMeta\",\n    \"ViaGlobalRefVirtualenvBuiltin\",\n]\n", "src/virtualenv/create/via_global_ref/builtin/ref.py": "\"\"\"\nVirtual environments in the traditional sense are built as reference to the host python. This file allows declarative\nreferences to elements on the file system, allowing our system to automatically detect what modes it can support given\nthe constraints: e.g. can the file system symlink, can the files be read, executed, etc.\n\"\"\"  # noqa: D205\n\nfrom __future__ import annotations\n\nimport os\nfrom abc import ABC, abstractmethod\nfrom collections import OrderedDict\nfrom stat import S_IXGRP, S_IXOTH, S_IXUSR\n\nfrom virtualenv.info import fs_is_case_sensitive, fs_supports_symlink\nfrom virtualenv.util.path import copy, make_exe, symlink\n\n\nclass RefMust:\n    NA = \"NA\"\n    COPY = \"copy\"\n    SYMLINK = \"symlink\"\n\n\nclass RefWhen:\n    ANY = \"ANY\"\n    COPY = \"copy\"\n    SYMLINK = \"symlink\"\n\n\nclass PathRef(ABC):\n    \"\"\"Base class that checks if a file reference can be symlink/copied.\"\"\"\n\n    FS_SUPPORTS_SYMLINK = fs_supports_symlink()\n    FS_CASE_SENSITIVE = fs_is_case_sensitive()\n\n    def __init__(self, src, must=RefMust.NA, when=RefWhen.ANY) -> None:\n        self.must = must\n        self.when = when\n        self.src = src\n        try:\n            self.exists = src.exists()\n        except OSError:\n            self.exists = False\n        self._can_read = None if self.exists else False\n        self._can_copy = None if self.exists else False\n        self._can_symlink = None if self.exists else False\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}(src={self.src})\"\n\n    @property\n    def can_read(self):\n        if self._can_read is None:\n            if self.src.is_file():\n                try:\n                    with self.src.open(\"rb\"):\n                        self._can_read = True\n                except OSError:\n                    self._can_read = False\n            else:\n                self._can_read = os.access(str(self.src), os.R_OK)\n        return self._can_read\n\n    @property\n    def can_copy(self):\n        if self._can_copy is None:\n            if self.must == RefMust.SYMLINK:\n                self._can_copy = self.can_symlink\n            else:\n                self._can_copy = self.can_read\n        return self._can_copy\n\n    @property\n    def can_symlink(self):\n        if self._can_symlink is None:\n            if self.must == RefMust.COPY:\n                self._can_symlink = self.can_copy\n            else:\n                self._can_symlink = self.FS_SUPPORTS_SYMLINK and self.can_read\n        return self._can_symlink\n\n    @abstractmethod\n    def run(self, creator, symlinks):\n        raise NotImplementedError\n\n    def method(self, symlinks):\n        if self.must == RefMust.SYMLINK:\n            return symlink\n        if self.must == RefMust.COPY:\n            return copy\n        return symlink if symlinks else copy\n\n\nclass ExePathRef(PathRef, ABC):\n    \"\"\"Base class that checks if a executable can be references via symlink/copy.\"\"\"\n\n    def __init__(self, src, must=RefMust.NA, when=RefWhen.ANY) -> None:\n        super().__init__(src, must, when)\n        self._can_run = None\n\n    @property\n    def can_symlink(self):\n        if self.FS_SUPPORTS_SYMLINK:\n            return self.can_run\n        return False\n\n    @property\n    def can_run(self):\n        if self._can_run is None:\n            mode = self.src.stat().st_mode\n            for key in [S_IXUSR, S_IXGRP, S_IXOTH]:\n                if mode & key:\n                    self._can_run = True\n                break\n            else:\n                self._can_run = False\n        return self._can_run\n\n\nclass PathRefToDest(PathRef):\n    \"\"\"Link a path on the file system.\"\"\"\n\n    def __init__(self, src, dest, must=RefMust.NA, when=RefWhen.ANY) -> None:\n        super().__init__(src, must, when)\n        self.dest = dest\n\n    def run(self, creator, symlinks):\n        dest = self.dest(creator, self.src)\n        method = self.method(symlinks)\n        dest_iterable = dest if isinstance(dest, list) else (dest,)\n        if not dest.parent.exists():\n            dest.parent.mkdir(parents=True, exist_ok=True)\n        for dst in dest_iterable:\n            method(self.src, dst)\n\n\nclass ExePathRefToDest(PathRefToDest, ExePathRef):\n    \"\"\"Link a exe path on the file system.\"\"\"\n\n    def __init__(self, src, targets, dest, must=RefMust.NA, when=RefWhen.ANY) -> None:  # noqa: PLR0913\n        ExePathRef.__init__(self, src, must, when)\n        PathRefToDest.__init__(self, src, dest, must, when)\n        if not self.FS_CASE_SENSITIVE:\n            targets = list(OrderedDict((i.lower(), None) for i in targets).keys())\n        self.base = targets[0]\n        self.aliases = targets[1:]\n        self.dest = dest\n\n    def run(self, creator, symlinks):\n        bin_dir = self.dest(creator, self.src).parent\n        dest = bin_dir / self.base\n        method = self.method(symlinks)\n        method(self.src, dest)\n        if not symlinks:\n            make_exe(dest)\n        for extra in self.aliases:\n            link_file = bin_dir / extra\n            if link_file.exists():\n                link_file.unlink()\n            if symlinks:\n                link_file.symlink_to(self.base)\n            else:\n                copy(self.src, link_file)\n            if not symlinks:\n                make_exe(link_file)\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}(src={self.src}, alias={self.aliases})\"\n\n\n__all__ = [\n    \"ExePathRef\",\n    \"ExePathRefToDest\",\n    \"PathRef\",\n    \"PathRefToDest\",\n    \"RefMust\",\n    \"RefWhen\",\n]\n", "src/virtualenv/create/via_global_ref/builtin/builtin_way.py": "from __future__ import annotations\n\nfrom abc import ABC\n\nfrom virtualenv.create.creator import Creator\nfrom virtualenv.create.describe import Describe\n\n\nclass VirtualenvBuiltin(Creator, Describe, ABC):\n    \"\"\"A creator that does operations itself without delegation, if we can create it we can also describe it.\"\"\"\n\n    def __init__(self, options, interpreter) -> None:\n        Creator.__init__(self, options, interpreter)\n        Describe.__init__(self, self.dest, interpreter)\n\n\n__all__ = [\n    \"VirtualenvBuiltin\",\n]\n", "src/virtualenv/create/via_global_ref/builtin/__init__.py": "", "src/virtualenv/create/via_global_ref/builtin/cpython/common.py": "from __future__ import annotations\n\nimport re\nfrom abc import ABC\nfrom collections import OrderedDict\nfrom pathlib import Path\n\nfrom virtualenv.create.describe import PosixSupports, WindowsSupports\nfrom virtualenv.create.via_global_ref.builtin.ref import RefMust, RefWhen\nfrom virtualenv.create.via_global_ref.builtin.via_global_self_do import ViaGlobalRefVirtualenvBuiltin\n\n\nclass CPython(ViaGlobalRefVirtualenvBuiltin, ABC):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return interpreter.implementation == \"CPython\" and super().can_describe(interpreter)\n\n    @classmethod\n    def exe_stem(cls):\n        return \"python\"\n\n\nclass CPythonPosix(CPython, PosixSupports, ABC):\n    \"\"\"Create a CPython virtual environment on POSIX platforms.\"\"\"\n\n    @classmethod\n    def _executables(cls, interpreter):\n        host_exe = Path(interpreter.system_executable)\n        major, minor = interpreter.version_info.major, interpreter.version_info.minor\n        targets = OrderedDict((i, None) for i in [\"python\", f\"python{major}\", f\"python{major}.{minor}\", host_exe.name])\n        yield host_exe, list(targets.keys()), RefMust.NA, RefWhen.ANY\n\n\nclass CPythonWindows(CPython, WindowsSupports, ABC):\n    @classmethod\n    def _executables(cls, interpreter):\n        # symlink of the python executables does not work reliably, copy always instead\n        # - https://bugs.python.org/issue42013\n        # - venv\n        host = cls.host_python(interpreter)\n        for path in (host.parent / n for n in {\"python.exe\", host.name}):  # noqa: PLC0208\n            yield host, [path.name], RefMust.COPY, RefWhen.ANY\n        # for more info on pythonw.exe see https://stackoverflow.com/a/30313091\n        python_w = host.parent / \"pythonw.exe\"\n        yield python_w, [python_w.name], RefMust.COPY, RefWhen.ANY\n\n    @classmethod\n    def host_python(cls, interpreter):\n        return Path(interpreter.system_executable)\n\n\ndef is_mac_os_framework(interpreter):\n    if interpreter.platform == \"darwin\":\n        return interpreter.sysconfig_vars.get(\"PYTHONFRAMEWORK\") == \"Python3\"\n    return False\n\n\ndef is_macos_brew(interpreter):\n    return interpreter.platform == \"darwin\" and _BREW.fullmatch(interpreter.system_prefix) is not None\n\n\n_BREW = re.compile(\n    r\"/(usr/local|opt/homebrew)/(opt/python@3\\.\\d{1,2}|Cellar/python@3\\.\\d{1,2}/3\\.\\d{1,2}\\.\\d{1,2})/Frameworks/\"\n    r\"Python\\.framework/Versions/3\\.\\d{1,2}\",\n)\n\n__all__ = [\n    \"CPython\",\n    \"CPythonPosix\",\n    \"CPythonWindows\",\n    \"is_mac_os_framework\",\n    \"is_macos_brew\",\n]\n", "src/virtualenv/create/via_global_ref/builtin/cpython/cpython3.py": "from __future__ import annotations\n\nimport abc\nimport fnmatch\nfrom itertools import chain\nfrom operator import methodcaller as method\nfrom pathlib import Path\nfrom textwrap import dedent\n\nfrom virtualenv.create.describe import Python3Supports\nfrom virtualenv.create.via_global_ref.builtin.ref import PathRefToDest\nfrom virtualenv.create.via_global_ref.store import is_store_python\n\nfrom .common import CPython, CPythonPosix, CPythonWindows, is_mac_os_framework, is_macos_brew\n\n\nclass CPython3(CPython, Python3Supports, abc.ABC):\n    \"\"\"CPython 3 or later.\"\"\"\n\n\nclass CPython3Posix(CPythonPosix, CPython3):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return (\n            is_mac_os_framework(interpreter) is False\n            and is_macos_brew(interpreter) is False\n            and super().can_describe(interpreter)\n        )\n\n    def env_patch_text(self):\n        text = super().env_patch_text()\n        if self.pyvenv_launch_patch_active(self.interpreter):\n            text += dedent(\n                \"\"\"\n                # for https://github.com/python/cpython/pull/9516, see https://github.com/pypa/virtualenv/issues/1704\n                import os\n                if \"__PYVENV_LAUNCHER__\" in os.environ:\n                    del os.environ[\"__PYVENV_LAUNCHER__\"]\n                \"\"\",\n            )\n        return text\n\n    @classmethod\n    def pyvenv_launch_patch_active(cls, interpreter):\n        ver = interpreter.version_info\n        return interpreter.platform == \"darwin\" and ((3, 7, 8) > ver >= (3, 7) or (3, 8, 3) > ver >= (3, 8))\n\n\nclass CPython3Windows(CPythonWindows, CPython3):\n    \"\"\"CPython 3 on Windows.\"\"\"\n\n    @classmethod\n    def setup_meta(cls, interpreter):\n        if is_store_python(interpreter):  # store python is not supported here\n            return None\n        return super().setup_meta(interpreter)\n\n    @classmethod\n    def sources(cls, interpreter):\n        if cls.has_shim(interpreter):\n            refs = cls.executables(interpreter)\n        else:\n            refs = chain(\n                cls.executables(interpreter),\n                cls.dll_and_pyd(interpreter),\n                cls.python_zip(interpreter),\n            )\n        yield from refs\n\n    @classmethod\n    def executables(cls, interpreter):\n        return super().sources(interpreter)\n\n    @classmethod\n    def has_shim(cls, interpreter):\n        return interpreter.version_info.minor >= 7 and cls.shim(interpreter) is not None  # noqa: PLR2004\n\n    @classmethod\n    def shim(cls, interpreter):\n        shim = Path(interpreter.system_stdlib) / \"venv\" / \"scripts\" / \"nt\" / \"python.exe\"\n        if shim.exists():\n            return shim\n        return None\n\n    @classmethod\n    def host_python(cls, interpreter):\n        if cls.has_shim(interpreter):\n            # starting with CPython 3.7 Windows ships with a venvlauncher.exe that avoids the need for dll/pyd copies\n            # it also means the wrapper must be copied to avoid bugs such as https://bugs.python.org/issue42013\n            return cls.shim(interpreter)\n        return super().host_python(interpreter)\n\n    @classmethod\n    def dll_and_pyd(cls, interpreter):\n        folders = [Path(interpreter.system_executable).parent]\n\n        # May be missing on some Python hosts.\n        # See https://github.com/pypa/virtualenv/issues/2368\n        dll_folder = Path(interpreter.system_prefix) / \"DLLs\"\n        if dll_folder.is_dir():\n            folders.append(dll_folder)\n\n        for folder in folders:\n            for file in folder.iterdir():\n                if file.suffix in {\".pyd\", \".dll\"}:\n                    yield PathRefToDest(file, cls.to_bin)\n\n    @classmethod\n    def python_zip(cls, interpreter):\n        \"\"\"\n        \"python{VERSION}.zip\" contains compiled *.pyc std lib packages, where\n        \"VERSION\" is `py_version_nodot` var from the `sysconfig` module.\n        :see: https://docs.python.org/3/using/windows.html#the-embeddable-package\n        :see: `discovery.py_info.PythonInfo` class (interpreter).\n        :see: `python -m sysconfig` output.\n\n        :note: The embeddable Python distribution for Windows includes\n        \"python{VERSION}.zip\" and \"python{VERSION}._pth\" files. User can\n        move/rename *zip* file and edit `sys.path` by editing *_pth* file.\n        Here the `pattern` is used only for the default *zip* file name!\n        \"\"\"  # noqa: D205\n        pattern = f\"*python{interpreter.version_nodot}.zip\"\n        matches = fnmatch.filter(interpreter.path, pattern)\n        matched_paths = map(Path, matches)\n        existing_paths = filter(method(\"exists\"), matched_paths)\n        path = next(existing_paths, None)\n        if path is not None:\n            yield PathRefToDest(path, cls.to_bin)\n\n\n__all__ = [\n    \"CPython3\",\n    \"CPython3Posix\",\n    \"CPython3Windows\",\n]\n", "src/virtualenv/create/via_global_ref/builtin/cpython/mac_os.py": "\"\"\"The Apple Framework builds require their own customization.\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport struct\nimport subprocess\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\nfrom textwrap import dedent\n\nfrom virtualenv.create.via_global_ref.builtin.ref import (\n    ExePathRefToDest,\n    PathRefToDest,\n    RefMust,\n)\nfrom virtualenv.create.via_global_ref.builtin.via_global_self_do import BuiltinViaGlobalRefMeta\n\nfrom .common import CPython, CPythonPosix, is_mac_os_framework, is_macos_brew\nfrom .cpython3 import CPython3\n\n\nclass CPythonmacOsFramework(CPython, ABC):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return is_mac_os_framework(interpreter) and super().can_describe(interpreter)\n\n    def create(self):\n        super().create()\n\n        # change the install_name of the copied python executables\n        target = self.desired_mach_o_image_path()\n        current = self.current_mach_o_image_path()\n        for src in self._sources:\n            if isinstance(src, ExePathRefToDest) and (src.must == RefMust.COPY or not self.symlinks):\n                exes = [self.bin_dir / src.base]\n                if not self.symlinks:\n                    exes.extend(self.bin_dir / a for a in src.aliases)\n                for exe in exes:\n                    fix_mach_o(str(exe), current, target, self.interpreter.max_size)\n\n    @classmethod\n    def _executables(cls, interpreter):\n        for _, targets, must, when in super()._executables(interpreter):\n            # Make sure we use the embedded interpreter inside the framework, even if sys.executable points to the\n            # stub executable in ${sys.prefix}/bin.\n            # See http://groups.google.com/group/python-virtualenv/browse_thread/thread/17cab2f85da75951\n            fixed_host_exe = Path(interpreter.prefix) / \"Resources\" / \"Python.app\" / \"Contents\" / \"MacOS\" / \"Python\"\n            yield fixed_host_exe, targets, must, when\n\n    @abstractmethod\n    def current_mach_o_image_path(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    def desired_mach_o_image_path(self):\n        raise NotImplementedError\n\n\nclass CPython3macOsFramework(CPythonmacOsFramework, CPython3, CPythonPosix):\n    def current_mach_o_image_path(self):\n        return \"@executable_path/../../../../Python3\"\n\n    def desired_mach_o_image_path(self):\n        return \"@executable_path/../.Python\"\n\n    @classmethod\n    def sources(cls, interpreter):\n        yield from super().sources(interpreter)\n\n        # add a symlink to the host python image\n        exe = Path(interpreter.prefix) / \"Python3\"\n        yield PathRefToDest(exe, dest=lambda self, _: self.dest / \".Python\", must=RefMust.SYMLINK)\n\n    @property\n    def reload_code(self):\n        result = super().reload_code\n        return dedent(\n            f\"\"\"\n        # the bundled site.py always adds the global site package if we're on python framework build, escape this\n        import sys\n        before = sys._framework\n        try:\n            sys._framework = None\n            {result}\n        finally:\n            sys._framework = before\n        \"\"\",\n        )\n\n\ndef fix_mach_o(exe, current, new, max_size):\n    \"\"\"\n    https://en.wikipedia.org/wiki/Mach-O.\n\n    Mach-O, short for Mach object file format, is a file format for executables, object code, shared libraries,\n    dynamically-loaded code, and core dumps. A replacement for the a.out format, Mach-O offers more extensibility and\n    faster access to information in the symbol table.\n\n    Each Mach-O file is made up of one Mach-O header, followed by a series of load commands, followed by one or more\n    segments, each of which contains between 0 and 255 sections. Mach-O uses the REL relocation format to handle\n    references to symbols. When looking up symbols Mach-O uses a two-level namespace that encodes each symbol into an\n    'object/symbol name' pair that is then linearly searched for by first the object and then the symbol name.\n\n    The basic structure\u2014a list of variable-length \"load commands\" that reference pages of data elsewhere in the file\u2014was\n    also used in the executable file format for Accent. The Accent file format was in turn, based on an idea from Spice\n    Lisp.\n\n    With the introduction of Mac OS X 10.6 platform the Mach-O file underwent a significant modification that causes\n    binaries compiled on a computer running 10.6 or later to be (by default) executable only on computers running Mac\n    OS X 10.6 or later. The difference stems from load commands that the dynamic linker, in previous Mac OS X versions,\n    does not understand. Another significant change to the Mach-O format is the change in how the Link Edit tables\n    (found in the __LINKEDIT section) function. In 10.6 these new Link Edit tables are compressed by removing unused and\n    unneeded bits of information, however Mac OS X 10.5 and earlier cannot read this new Link Edit table format.\n    \"\"\"\n    try:\n        logging.debug(\"change Mach-O for %s from %s to %s\", exe, current, new)\n        _builtin_change_mach_o(max_size)(exe, current, new)\n    except Exception as e:  # noqa: BLE001\n        logging.warning(\"Could not call _builtin_change_mac_o: %s. Trying to call install_name_tool instead.\", e)\n        try:\n            cmd = [\"install_name_tool\", \"-change\", current, new, exe]\n            subprocess.check_call(cmd)  # noqa: S603\n        except Exception:\n            logging.fatal(\"Could not call install_name_tool -- you must have Apple's development tools installed\")\n            raise\n\n\ndef _builtin_change_mach_o(maxint):  # noqa: C901\n    MH_MAGIC = 0xFEEDFACE  # noqa: N806\n    MH_CIGAM = 0xCEFAEDFE  # noqa: N806\n    MH_MAGIC_64 = 0xFEEDFACF  # noqa: N806\n    MH_CIGAM_64 = 0xCFFAEDFE  # noqa: N806\n    FAT_MAGIC = 0xCAFEBABE  # noqa: N806\n    BIG_ENDIAN = \">\"  # noqa: N806\n    LITTLE_ENDIAN = \"<\"  # noqa: N806\n    LC_LOAD_DYLIB = 0xC  # noqa: N806\n\n    class FileView:\n        \"\"\"A proxy for file-like objects that exposes a given view of a file. Modified from macholib.\"\"\"\n\n        def __init__(self, file_obj, start=0, size=maxint) -> None:\n            if isinstance(file_obj, FileView):\n                self._file_obj = file_obj._file_obj  # noqa: SLF001\n            else:\n                self._file_obj = file_obj\n            self._start = start\n            self._end = start + size\n            self._pos = 0\n\n        def __repr__(self) -> str:\n            return f\"<fileview [{self._start:d}, {self._end:d}] {self._file_obj!r}>\"\n\n        def tell(self):\n            return self._pos\n\n        def _checkwindow(self, seek_to, op):\n            if not (self._start <= seek_to <= self._end):\n                msg = f\"{op} to offset {seek_to:d} is outside window [{self._start:d}, {self._end:d}]\"\n                raise OSError(msg)\n\n        def seek(self, offset, whence=0):\n            seek_to = offset\n            if whence == os.SEEK_SET:\n                seek_to += self._start\n            elif whence == os.SEEK_CUR:\n                seek_to += self._start + self._pos\n            elif whence == os.SEEK_END:\n                seek_to += self._end\n            else:\n                msg = f\"Invalid whence argument to seek: {whence!r}\"\n                raise OSError(msg)\n            self._checkwindow(seek_to, \"seek\")\n            self._file_obj.seek(seek_to)\n            self._pos = seek_to - self._start\n\n        def write(self, content):\n            here = self._start + self._pos\n            self._checkwindow(here, \"write\")\n            self._checkwindow(here + len(content), \"write\")\n            self._file_obj.seek(here, os.SEEK_SET)\n            self._file_obj.write(content)\n            self._pos += len(content)\n\n        def read(self, size=maxint):\n            assert size >= 0  # noqa: S101\n            here = self._start + self._pos\n            self._checkwindow(here, \"read\")\n            size = min(size, self._end - here)\n            self._file_obj.seek(here, os.SEEK_SET)\n            read_bytes = self._file_obj.read(size)\n            self._pos += len(read_bytes)\n            return read_bytes\n\n    def read_data(file, endian, num=1):\n        \"\"\"Read a given number of 32-bits unsigned integers from the given file with the given endianness.\"\"\"\n        res = struct.unpack(endian + \"L\" * num, file.read(num * 4))\n        if len(res) == 1:\n            return res[0]\n        return res\n\n    def mach_o_change(at_path, what, value):  # noqa: C901\n        \"\"\"\n        Replace a given name (what) in any LC_LOAD_DYLIB command found in the given binary with a new name (value),\n        provided it's shorter.\n        \"\"\"  # noqa: D205\n\n        def do_macho(file, bits, endian):\n            # Read Mach-O header (the magic number is assumed read by the caller)\n            _cpu_type, _cpu_sub_type, _file_type, n_commands, _size_of_commands, _flags = read_data(file, endian, 6)\n            # 64-bits header has one more field.\n            if bits == 64:  # noqa: PLR2004\n                read_data(file, endian)\n            # The header is followed by n commands\n            for _ in range(n_commands):\n                where = file.tell()\n                # Read command header\n                cmd, cmd_size = read_data(file, endian, 2)\n                if cmd == LC_LOAD_DYLIB:\n                    # The first data field in LC_LOAD_DYLIB commands is the offset of the name, starting from the\n                    # beginning of the  command.\n                    name_offset = read_data(file, endian)\n                    file.seek(where + name_offset, os.SEEK_SET)\n                    # Read the NUL terminated string\n                    load = file.read(cmd_size - name_offset).decode()\n                    load = load[: load.index(\"\\0\")]\n                    # If the string is what is being replaced, overwrite it.\n                    if load == what:\n                        file.seek(where + name_offset, os.SEEK_SET)\n                        file.write(value.encode() + b\"\\0\")\n                # Seek to the next command\n                file.seek(where + cmd_size, os.SEEK_SET)\n\n        def do_file(file, offset=0, size=maxint):\n            file = FileView(file, offset, size)\n            # Read magic number\n            magic = read_data(file, BIG_ENDIAN)\n            if magic == FAT_MAGIC:\n                # Fat binaries contain nfat_arch Mach-O binaries\n                n_fat_arch = read_data(file, BIG_ENDIAN)\n                for _ in range(n_fat_arch):\n                    # Read arch header\n                    _cpu_type, _cpu_sub_type, offset, size, _align = read_data(file, BIG_ENDIAN, 5)\n                    do_file(file, offset, size)\n            elif magic == MH_MAGIC:\n                do_macho(file, 32, BIG_ENDIAN)\n            elif magic == MH_CIGAM:\n                do_macho(file, 32, LITTLE_ENDIAN)\n            elif magic == MH_MAGIC_64:\n                do_macho(file, 64, BIG_ENDIAN)\n            elif magic == MH_CIGAM_64:\n                do_macho(file, 64, LITTLE_ENDIAN)\n\n        assert len(what) >= len(value)  # noqa: S101\n\n        with open(at_path, \"r+b\") as f:\n            do_file(f)\n\n    return mach_o_change\n\n\nclass CPython3macOsBrew(CPython3, CPythonPosix):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return is_macos_brew(interpreter) and super().can_describe(interpreter)\n\n    @classmethod\n    def setup_meta(cls, interpreter):  # noqa: ARG003\n        meta = BuiltinViaGlobalRefMeta()\n        meta.copy_error = \"Brew disables copy creation: https://github.com/Homebrew/homebrew-core/issues/138159\"\n        return meta\n\n\n__all__ = [\n    \"CPython3macOsBrew\",\n    \"CPython3macOsFramework\",\n    \"CPythonmacOsFramework\",\n]\n", "src/virtualenv/create/via_global_ref/builtin/cpython/__init__.py": "", "src/virtualenv/create/via_global_ref/builtin/pypy/common.py": "from __future__ import annotations\n\nimport abc\nfrom pathlib import Path\n\nfrom virtualenv.create.via_global_ref.builtin.ref import PathRefToDest, RefMust, RefWhen\nfrom virtualenv.create.via_global_ref.builtin.via_global_self_do import ViaGlobalRefVirtualenvBuiltin\n\n\nclass PyPy(ViaGlobalRefVirtualenvBuiltin, abc.ABC):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return interpreter.implementation == \"PyPy\" and super().can_describe(interpreter)\n\n    @classmethod\n    def _executables(cls, interpreter):\n        host = Path(interpreter.system_executable)\n        targets = sorted(f\"{name}{PyPy.suffix}\" for name in cls.exe_names(interpreter))\n        yield host, targets, RefMust.NA, RefWhen.ANY\n\n    @classmethod\n    def executables(cls, interpreter):\n        yield from super().sources(interpreter)\n\n    @classmethod\n    def exe_names(cls, interpreter):\n        return {\n            cls.exe_stem(),\n            \"python\",\n            f\"python{interpreter.version_info.major}\",\n            f\"python{interpreter.version_info.major}.{interpreter.version_info.minor}\",\n        }\n\n    @classmethod\n    def sources(cls, interpreter):\n        yield from cls.executables(interpreter)\n        for host in cls._add_shared_libs(interpreter):\n            yield PathRefToDest(host, dest=lambda self, s: self.bin_dir / s.name)\n\n    @classmethod\n    def _add_shared_libs(cls, interpreter):\n        # https://bitbucket.org/pypy/pypy/issue/1922/future-proofing-virtualenv\n        python_dir = Path(interpreter.system_executable).resolve().parent\n        yield from cls._shared_libs(python_dir)\n\n    @classmethod\n    def _shared_libs(cls, python_dir):\n        raise NotImplementedError\n\n\n__all__ = [\n    \"PyPy\",\n]\n", "src/virtualenv/create/via_global_ref/builtin/pypy/pypy3.py": "from __future__ import annotations\n\nimport abc\nfrom pathlib import Path\n\nfrom virtualenv.create.describe import PosixSupports, Python3Supports, WindowsSupports\nfrom virtualenv.create.via_global_ref.builtin.ref import PathRefToDest\n\nfrom .common import PyPy\n\n\nclass PyPy3(PyPy, Python3Supports, abc.ABC):\n    @classmethod\n    def exe_stem(cls):\n        return \"pypy3\"\n\n    @classmethod\n    def exe_names(cls, interpreter):\n        return super().exe_names(interpreter) | {\"pypy\"}\n\n\nclass PyPy3Posix(PyPy3, PosixSupports):\n    \"\"\"PyPy 3 on POSIX.\"\"\"\n\n    @classmethod\n    def _shared_libs(cls, python_dir):\n        # glob for libpypy3-c.so, libpypy3-c.dylib, libpypy3.9-c.so ...\n        return python_dir.glob(\"libpypy3*.*\")\n\n    def to_lib(self, src):\n        return self.dest / \"lib\" / src.name\n\n    @classmethod\n    def sources(cls, interpreter):\n        yield from super().sources(interpreter)\n        # PyPy >= 3.8 supports a standard prefix installation, where older\n        # versions always used a portable/development style installation.\n        # If this is a standard prefix installation, skip the below:\n        if interpreter.system_prefix == \"/usr\":\n            return\n        # Also copy/symlink anything under prefix/lib, which, for \"portable\"\n        # PyPy builds, includes the tk,tcl runtime and a number of shared\n        # objects. In distro-specific builds or on conda this should be empty\n        # (on PyPy3.8+ it will, like on CPython, hold the stdlib).\n        host_lib = Path(interpreter.system_prefix) / \"lib\"\n        stdlib = Path(interpreter.system_stdlib)\n        if host_lib.exists() and host_lib.is_dir():\n            for path in host_lib.iterdir():\n                if stdlib == path:\n                    # For PyPy3.8+ the stdlib lives in lib/pypy3.8\n                    # We need to avoid creating a symlink to it since that\n                    # will defeat the purpose of a virtualenv\n                    continue\n                yield PathRefToDest(path, dest=cls.to_lib)\n\n\nclass Pypy3Windows(PyPy3, WindowsSupports):\n    \"\"\"PyPy 3 on Windows.\"\"\"\n\n    @property\n    def less_v37(self):\n        return self.interpreter.version_info.minor < 7  # noqa: PLR2004\n\n    @classmethod\n    def _shared_libs(cls, python_dir):\n        # glob for libpypy*.dll and libffi*.dll\n        for pattern in [\"libpypy*.dll\", \"libffi*.dll\"]:\n            srcs = python_dir.glob(pattern)\n            yield from srcs\n\n\n__all__ = [\n    \"PyPy3\",\n    \"PyPy3Posix\",\n    \"Pypy3Windows\",\n]\n", "src/virtualenv/create/via_global_ref/builtin/pypy/__init__.py": "", "src/virtualenv/seed/seeder.py": "from __future__ import annotations\n\nfrom abc import ABC, abstractmethod\n\n\nclass Seeder(ABC):\n    \"\"\"A seeder will install some seed packages into a virtual environment.\"\"\"\n\n    def __init__(self, options, enabled) -> None:\n        \"\"\"\n        Create.\n\n        :param options: the parsed options as defined within :meth:`add_parser_arguments`\n        :param enabled: a flag weather the seeder is enabled or not\n        \"\"\"\n        self.enabled = enabled\n        self.env = options.env\n\n    @classmethod\n    def add_parser_arguments(cls, parser, interpreter, app_data):\n        \"\"\"\n        Add CLI arguments for this seed mechanisms.\n\n        :param parser: the CLI parser\n        :param app_data: the CLI parser\n        :param interpreter: the interpreter this virtual environment is based of\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def run(self, creator):\n        \"\"\"\n        Perform the seed operation.\n\n        :param creator: the creator (based of :class:`virtualenv.create.creator.Creator`) we used to create this \\\n        virtual environment\n        \"\"\"\n        raise NotImplementedError\n\n\n__all__ = [\n    \"Seeder\",\n]\n", "src/virtualenv/seed/__init__.py": "", "src/virtualenv/seed/embed/pip_invoke.py": "from __future__ import annotations\n\nimport logging\nfrom contextlib import contextmanager\nfrom subprocess import Popen\n\nfrom virtualenv.discovery.cached_py_info import LogCmd\nfrom virtualenv.seed.embed.base_embed import BaseEmbed\nfrom virtualenv.seed.wheels import Version, get_wheel, pip_wheel_env_run\n\n\nclass PipInvoke(BaseEmbed):\n    def __init__(self, options) -> None:\n        super().__init__(options)\n\n    def run(self, creator):\n        if not self.enabled:\n            return\n        for_py_version = creator.interpreter.version_release_str\n        with self.get_pip_install_cmd(creator.exe, for_py_version) as cmd:\n            env = pip_wheel_env_run(self.extra_search_dir, self.app_data, self.env)\n            self._execute(cmd, env)\n\n    @staticmethod\n    def _execute(cmd, env):\n        logging.debug(\"pip seed by running: %s\", LogCmd(cmd, env))\n        process = Popen(cmd, env=env)  # noqa: S603\n        process.communicate()\n        if process.returncode != 0:\n            msg = f\"failed seed with code {process.returncode}\"\n            raise RuntimeError(msg)\n        return process\n\n    @contextmanager\n    def get_pip_install_cmd(self, exe, for_py_version):\n        cmd = [str(exe), \"-m\", \"pip\", \"-q\", \"install\", \"--only-binary\", \":all:\", \"--disable-pip-version-check\"]\n        if not self.download:\n            cmd.append(\"--no-index\")\n        folders = set()\n        for dist, version in self.distribution_to_versions().items():\n            wheel = get_wheel(\n                distribution=dist,\n                version=version,\n                for_py_version=for_py_version,\n                search_dirs=self.extra_search_dir,\n                download=False,\n                app_data=self.app_data,\n                do_periodic_update=self.periodic_update,\n                env=self.env,\n            )\n            if wheel is None:\n                msg = f\"could not get wheel for distribution {dist}\"\n                raise RuntimeError(msg)\n            folders.add(str(wheel.path.parent))\n            cmd.append(Version.as_pip_req(dist, wheel.version))\n        for folder in sorted(folders):\n            cmd.extend([\"--find-links\", str(folder)])\n        yield cmd\n\n\n__all__ = [\n    \"PipInvoke\",\n]\n", "src/virtualenv/seed/embed/base_embed.py": "from __future__ import annotations\n\nfrom abc import ABC\nfrom pathlib import Path\n\nfrom virtualenv.seed.seeder import Seeder\nfrom virtualenv.seed.wheels import Version\n\nPERIODIC_UPDATE_ON_BY_DEFAULT = True\n\n\nclass BaseEmbed(Seeder, ABC):\n    def __init__(self, options) -> None:\n        super().__init__(options, enabled=options.no_seed is False)\n\n        self.download = options.download\n        self.extra_search_dir = [i.resolve() for i in options.extra_search_dir if i.exists()]\n\n        self.pip_version = options.pip\n        self.setuptools_version = options.setuptools\n        self.wheel_version = options.wheel\n\n        self.no_pip = options.no_pip\n        self.no_setuptools = options.no_setuptools\n        self.no_wheel = options.no_wheel\n        self.app_data = options.app_data\n        self.periodic_update = not options.no_periodic_update\n\n        if not self.distribution_to_versions():\n            self.enabled = False\n\n    @classmethod\n    def distributions(cls) -> dict[str, Version]:\n        return {\n            \"pip\": Version.bundle,\n            \"setuptools\": Version.bundle,\n            \"wheel\": Version.bundle,\n        }\n\n    def distribution_to_versions(self) -> dict[str, str]:\n        return {\n            distribution: getattr(self, f\"{distribution}_version\")\n            for distribution in self.distributions()\n            if getattr(self, f\"no_{distribution}\") is False and getattr(self, f\"{distribution}_version\") != \"none\"\n        }\n\n    @classmethod\n    def add_parser_arguments(cls, parser, interpreter, app_data):  # noqa: ARG003\n        group = parser.add_mutually_exclusive_group()\n        group.add_argument(\n            \"--no-download\",\n            \"--never-download\",\n            dest=\"download\",\n            action=\"store_false\",\n            help=f\"pass to disable download of the latest {'/'.join(cls.distributions())} from PyPI\",\n            default=True,\n        )\n        group.add_argument(\n            \"--download\",\n            dest=\"download\",\n            action=\"store_true\",\n            help=f\"pass to enable download of the latest {'/'.join(cls.distributions())} from PyPI\",\n            default=False,\n        )\n        parser.add_argument(\n            \"--extra-search-dir\",\n            metavar=\"d\",\n            type=Path,\n            nargs=\"+\",\n            help=\"a path containing wheels to extend the internal wheel list (can be set 1+ times)\",\n            default=[],\n        )\n        for distribution, default in cls.distributions().items():\n            if interpreter.version_info[:2] >= (3, 12) and distribution in {\"wheel\", \"setuptools\"}:\n                default = \"none\"  # noqa: PLW2901\n            parser.add_argument(\n                f\"--{distribution}\",\n                dest=distribution,\n                metavar=\"version\",\n                help=f\"version of {distribution} to install as seed: embed, bundle, none or exact version\",\n                default=default,\n            )\n        for distribution in cls.distributions():\n            parser.add_argument(\n                f\"--no-{distribution}\",\n                dest=f\"no_{distribution}\",\n                action=\"store_true\",\n                help=f\"do not install {distribution}\",\n                default=False,\n            )\n        parser.add_argument(\n            \"--no-periodic-update\",\n            dest=\"no_periodic_update\",\n            action=\"store_true\",\n            help=\"disable the periodic (once every 14 days) update of the embedded wheels\",\n            default=not PERIODIC_UPDATE_ON_BY_DEFAULT,\n        )\n\n    def __repr__(self) -> str:\n        result = self.__class__.__name__\n        result += \"(\"\n        if self.extra_search_dir:\n            result += f\"extra_search_dir={', '.join(str(i) for i in self.extra_search_dir)},\"\n        result += f\"download={self.download},\"\n        for distribution in self.distributions():\n            if getattr(self, f\"no_{distribution}\"):\n                continue\n            version = getattr(self, f\"{distribution}_version\", None)\n            if version == \"none\":\n                continue\n            ver = f\"={version or 'latest'}\"\n            result += f\" {distribution}{ver},\"\n        return result[:-1] + \")\"\n\n\n__all__ = [\n    \"BaseEmbed\",\n]\n", "src/virtualenv/seed/embed/__init__.py": "", "src/virtualenv/seed/embed/via_app_data/via_app_data.py": "\"\"\"Bootstrap.\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport sys\nimport traceback\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom subprocess import CalledProcessError\nfrom threading import Lock, Thread\n\nfrom virtualenv.info import fs_supports_symlink\nfrom virtualenv.seed.embed.base_embed import BaseEmbed\nfrom virtualenv.seed.wheels import get_wheel\n\nfrom .pip_install.copy import CopyPipInstall\nfrom .pip_install.symlink import SymlinkPipInstall\n\n\nclass FromAppData(BaseEmbed):\n    def __init__(self, options) -> None:\n        super().__init__(options)\n        self.symlinks = options.symlink_app_data\n\n    @classmethod\n    def add_parser_arguments(cls, parser, interpreter, app_data):\n        super().add_parser_arguments(parser, interpreter, app_data)\n        can_symlink = app_data.transient is False and fs_supports_symlink()\n        sym = \"\" if can_symlink else \"not supported - \"\n        parser.add_argument(\n            \"--symlink-app-data\",\n            dest=\"symlink_app_data\",\n            action=\"store_true\" if can_symlink else \"store_false\",\n            help=f\"{sym} symlink the python packages from the app-data folder (requires seed pip>=19.3)\",\n            default=False,\n        )\n\n    def run(self, creator):\n        if not self.enabled:\n            return\n        with self._get_seed_wheels(creator) as name_to_whl:\n            pip_version = name_to_whl[\"pip\"].version_tuple if \"pip\" in name_to_whl else None\n            installer_class = self.installer_class(pip_version)\n            exceptions = {}\n\n            def _install(name, wheel):\n                try:\n                    logging.debug(\"install %s from wheel %s via %s\", name, wheel, installer_class.__name__)\n                    key = Path(installer_class.__name__) / wheel.path.stem\n                    wheel_img = self.app_data.wheel_image(creator.interpreter.version_release_str, key)\n                    installer = installer_class(wheel.path, creator, wheel_img)\n                    parent = self.app_data.lock / wheel_img.parent\n                    with parent.non_reentrant_lock_for_key(wheel_img.name):\n                        if not installer.has_image():\n                            installer.build_image()\n                    installer.install(creator.interpreter.version_info)\n                except Exception:  # noqa: BLE001\n                    exceptions[name] = sys.exc_info()\n\n            threads = [Thread(target=_install, args=(n, w)) for n, w in name_to_whl.items()]\n            for thread in threads:\n                thread.start()\n            for thread in threads:\n                thread.join()\n            if exceptions:\n                messages = [f\"failed to build image {', '.join(exceptions.keys())} because:\"]\n                for value in exceptions.values():\n                    exc_type, exc_value, exc_traceback = value\n                    messages.append(\"\".join(traceback.format_exception(exc_type, exc_value, exc_traceback)))\n                raise RuntimeError(\"\\n\".join(messages))\n\n    @contextmanager\n    def _get_seed_wheels(self, creator):  # noqa: C901\n        name_to_whl, lock, fail = {}, Lock(), {}\n\n        def _get(distribution, version):\n            for_py_version = creator.interpreter.version_release_str\n            failure, result = None, None\n            # fallback to download in case the exact version is not available\n            for download in [True] if self.download else [False, True]:\n                failure = None\n                try:\n                    result = get_wheel(\n                        distribution=distribution,\n                        version=version,\n                        for_py_version=for_py_version,\n                        search_dirs=self.extra_search_dir,\n                        download=download,\n                        app_data=self.app_data,\n                        do_periodic_update=self.periodic_update,\n                        env=self.env,\n                    )\n                    if result is not None:\n                        break\n                except Exception as exception:\n                    logging.exception(\"fail\")\n                    failure = exception\n            if failure:\n                if isinstance(failure, CalledProcessError):\n                    msg = f\"failed to download {distribution}\"\n                    if version is not None:\n                        msg += f\" version {version}\"\n                    msg += f\", pip download exit code {failure.returncode}\"\n                    output = failure.output + failure.stderr\n                    if output:\n                        msg += \"\\n\"\n                        msg += output\n                else:\n                    msg = repr(failure)\n                logging.error(msg)\n                with lock:\n                    fail[distribution] = version\n            else:\n                with lock:\n                    name_to_whl[distribution] = result\n\n        threads = [\n            Thread(target=_get, args=(distribution, version))\n            for distribution, version in self.distribution_to_versions().items()\n        ]\n        for thread in threads:\n            thread.start()\n        for thread in threads:\n            thread.join()\n        if fail:\n            msg = f\"seed failed due to failing to download wheels {', '.join(fail.keys())}\"\n            raise RuntimeError(msg)\n        yield name_to_whl\n\n    def installer_class(self, pip_version_tuple):\n        if self.symlinks and pip_version_tuple and pip_version_tuple >= (19, 3):  # symlink support requires pip 19.3+\n            return SymlinkPipInstall\n        return CopyPipInstall\n\n    def __repr__(self) -> str:\n        msg = f\", via={'symlink' if self.symlinks else 'copy'}, app_data_dir={self.app_data}\"\n        base = super().__repr__()\n        return f\"{base[:-1]}{msg}{base[-1]}\"\n\n\n__all__ = [\n    \"FromAppData\",\n]\n", "src/virtualenv/seed/embed/via_app_data/__init__.py": "", "src/virtualenv/seed/embed/via_app_data/pip_install/base.py": "from __future__ import annotations\n\nimport logging\nimport os\nimport re\nimport zipfile\nfrom abc import ABC, abstractmethod\nfrom configparser import ConfigParser\nfrom itertools import chain\nfrom pathlib import Path\nfrom tempfile import mkdtemp\n\nfrom distlib.scripts import ScriptMaker, enquote_executable\n\nfrom virtualenv.util.path import safe_delete\n\n\nclass PipInstall(ABC):\n    def __init__(self, wheel, creator, image_folder) -> None:\n        self._wheel = wheel\n        self._creator = creator\n        self._image_dir = image_folder\n        self._extracted = False\n        self.__dist_info = None\n        self._console_entry_points = None\n\n    @abstractmethod\n    def _sync(self, src, dst):\n        raise NotImplementedError\n\n    def install(self, version_info):\n        self._extracted = True\n        self._uninstall_previous_version()\n        # sync image\n        for filename in self._image_dir.iterdir():\n            into = self._creator.purelib / filename.name\n            self._sync(filename, into)\n        # generate console executables\n        consoles = set()\n        script_dir = self._creator.script_dir\n        for name, module in self._console_scripts.items():\n            consoles.update(self._create_console_entry_point(name, module, script_dir, version_info))\n        logging.debug(\"generated console scripts %s\", \" \".join(i.name for i in consoles))\n\n    def build_image(self):\n        # 1. first extract the wheel\n        logging.debug(\"build install image for %s to %s\", self._wheel.name, self._image_dir)\n        with zipfile.ZipFile(str(self._wheel)) as zip_ref:\n            self._shorten_path_if_needed(zip_ref)\n            zip_ref.extractall(str(self._image_dir))\n            self._extracted = True\n        # 2. now add additional files not present in the distribution\n        new_files = self._generate_new_files()\n        # 3. finally fix the records file\n        self._fix_records(new_files)\n\n    def _shorten_path_if_needed(self, zip_ref):\n        if os.name == \"nt\":\n            to_folder = str(self._image_dir)\n            # https://docs.microsoft.com/en-us/windows/win32/fileio/maximum-file-path-limitation\n            zip_max_len = max(len(i) for i in zip_ref.namelist())\n            path_len = zip_max_len + len(to_folder)\n            if path_len > 260:  # noqa: PLR2004\n                self._image_dir.mkdir(exist_ok=True)  # to get a short path must exist\n\n                from virtualenv.util.path import get_short_path_name  # noqa: PLC0415\n\n                to_folder = get_short_path_name(to_folder)\n                self._image_dir = Path(to_folder)\n\n    def _records_text(self, files):\n        return \"\\n\".join(f\"{os.path.relpath(str(rec), str(self._image_dir))},,\" for rec in files)\n\n    def _generate_new_files(self):\n        new_files = set()\n        installer = self._dist_info / \"INSTALLER\"\n        installer.write_text(\"pip\\n\", encoding=\"utf-8\")\n        new_files.add(installer)\n        # inject a no-op root element, as workaround for bug in https://github.com/pypa/pip/issues/7226\n        marker = self._image_dir / f\"{self._dist_info.stem}.virtualenv\"\n        marker.write_text(\"\", encoding=\"utf-8\")\n        new_files.add(marker)\n        folder = mkdtemp()\n        try:\n            to_folder = Path(folder)\n            rel = os.path.relpath(str(self._creator.script_dir), str(self._creator.purelib))\n            version_info = self._creator.interpreter.version_info\n            for name, module in self._console_scripts.items():\n                new_files.update(\n                    Path(os.path.normpath(str(self._image_dir / rel / i.name)))\n                    for i in self._create_console_entry_point(name, module, to_folder, version_info)\n                )\n        finally:\n            safe_delete(folder)\n        return new_files\n\n    @property\n    def _dist_info(self):\n        if self._extracted is False:\n            return None  # pragma: no cover\n        if self.__dist_info is None:\n            files = []\n            for filename in self._image_dir.iterdir():\n                files.append(filename.name)\n                if filename.suffix == \".dist-info\":\n                    self.__dist_info = filename\n                    break\n            else:\n                msg = f\"no .dist-info at {self._image_dir}, has {', '.join(files)}\"\n                raise RuntimeError(msg)  # pragma: no cover\n        return self.__dist_info\n\n    @abstractmethod\n    def _fix_records(self, extra_record_data):\n        raise NotImplementedError\n\n    @property\n    def _console_scripts(self):\n        if self._extracted is False:\n            return None  # pragma: no cover\n        if self._console_entry_points is None:\n            self._console_entry_points = {}\n            entry_points = self._dist_info / \"entry_points.txt\"\n            if entry_points.exists():\n                parser = ConfigParser()\n                with entry_points.open(encoding=\"utf-8\") as file_handler:\n                    parser.read_file(file_handler)\n                if \"console_scripts\" in parser.sections():\n                    for name, value in parser.items(\"console_scripts\"):\n                        match = re.match(r\"(.*?)-?\\d\\.?\\d*\", name)\n                        our_name = match.groups(1)[0] if match else name\n                        self._console_entry_points[our_name] = value\n        return self._console_entry_points\n\n    def _create_console_entry_point(self, name, value, to_folder, version_info):\n        result = []\n        maker = ScriptMakerCustom(to_folder, version_info, self._creator.exe, name)\n        specification = f\"{name} = {value}\"\n        new_files = maker.make(specification)\n        result.extend(Path(i) for i in new_files)\n        return result\n\n    def _uninstall_previous_version(self):\n        dist_name = self._dist_info.stem.split(\"-\")[0]\n        in_folders = chain.from_iterable([i.iterdir() for i in (self._creator.purelib, self._creator.platlib)])\n        paths = (p for p in in_folders if p.stem.split(\"-\")[0] == dist_name and p.suffix == \".dist-info\" and p.is_dir())\n        existing_dist = next(paths, None)\n        if existing_dist is not None:\n            self._uninstall_dist(existing_dist)\n\n    @staticmethod\n    def _uninstall_dist(dist):\n        dist_base = dist.parent\n        logging.debug(\"uninstall existing distribution %s from %s\", dist.stem, dist_base)\n\n        top_txt = dist / \"top_level.txt\"  # add top level packages at folder level\n        paths = (\n            {dist.parent / i.strip() for i in top_txt.read_text(encoding=\"utf-8\").splitlines()}\n            if top_txt.exists()\n            else set()\n        )\n        paths.add(dist)  # add the dist-info folder itself\n\n        base_dirs, record = paths.copy(), dist / \"RECORD\"  # collect entries in record that we did not register yet\n        for name in (\n            (i.split(\",\")[0] for i in record.read_text(encoding=\"utf-8\").splitlines()) if record.exists() else ()\n        ):\n            path = dist_base / name\n            if not any(p in base_dirs for p in path.parents):  # only add if not already added as a base dir\n                paths.add(path)\n\n        for path in sorted(paths):  # actually remove stuff in a stable order\n            if path.exists():\n                if path.is_dir() and not path.is_symlink():\n                    safe_delete(path)\n                else:\n                    path.unlink()\n\n    def clear(self):\n        if self._image_dir.exists():\n            safe_delete(self._image_dir)\n\n    def has_image(self):\n        return self._image_dir.exists() and next(self._image_dir.iterdir()) is not None\n\n\nclass ScriptMakerCustom(ScriptMaker):\n    def __init__(self, target_dir, version_info, executable, name) -> None:\n        super().__init__(None, str(target_dir))\n        self.clobber = True  # overwrite\n        self.set_mode = True  # ensure they are executable\n        self.executable = enquote_executable(str(executable))\n        self.version_info = version_info.major, version_info.minor\n        self.variants = {\"\", \"X\", \"X.Y\"}\n        self._name = name\n\n    def _write_script(self, names, shebang, script_bytes, filenames, ext):  # noqa: PLR0913\n        names.add(f\"{self._name}{self.version_info[0]}.{self.version_info[1]}\")\n        super()._write_script(names, shebang, script_bytes, filenames, ext)\n\n\n__all__ = [\n    \"PipInstall\",\n]\n", "src/virtualenv/seed/embed/via_app_data/pip_install/copy.py": "from __future__ import annotations\n\nimport os\nfrom pathlib import Path\n\nfrom virtualenv.util.path import copy\n\nfrom .base import PipInstall\n\n\nclass CopyPipInstall(PipInstall):\n    def _sync(self, src, dst):\n        copy(src, dst)\n\n    def _generate_new_files(self):\n        # create the pyc files\n        new_files = super()._generate_new_files()\n        new_files.update(self._cache_files())\n        return new_files\n\n    def _cache_files(self):\n        version = self._creator.interpreter.version_info\n        py_c_ext = f\".{self._creator.interpreter.implementation.lower()}-{version.major}{version.minor}.pyc\"\n        for root, dirs, files in os.walk(str(self._image_dir), topdown=True):\n            root_path = Path(root)\n            for name in files:\n                if name.endswith(\".py\"):\n                    yield root_path / f\"{name[:-3]}{py_c_ext}\"\n            for name in dirs:\n                yield root_path / name / \"__pycache__\"\n\n    def _fix_records(self, new_files):\n        extra_record_data_str = self._records_text(new_files)\n        with (self._dist_info / \"RECORD\").open(\"ab\") as file_handler:\n            file_handler.write(extra_record_data_str.encode(\"utf-8\"))\n\n\n__all__ = [\n    \"CopyPipInstall\",\n]\n", "src/virtualenv/seed/embed/via_app_data/pip_install/symlink.py": "from __future__ import annotations\n\nimport os\nfrom stat import S_IREAD, S_IRGRP, S_IROTH\nfrom subprocess import PIPE, Popen\n\nfrom virtualenv.util.path import safe_delete, set_tree\n\nfrom .base import PipInstall\n\n\nclass SymlinkPipInstall(PipInstall):\n    def _sync(self, src, dst):\n        os.symlink(str(src), str(dst))\n\n    def _generate_new_files(self):\n        # create the pyc files, as the build image will be R/O\n        cmd = [str(self._creator.exe), \"-m\", \"compileall\", str(self._image_dir)]\n        process = Popen(cmd, stdout=PIPE, stderr=PIPE)  # noqa: S603\n        process.communicate()\n        # the root pyc is shared, so we'll not symlink that - but still add the pyc files to the RECORD for close\n        root_py_cache = self._image_dir / \"__pycache__\"\n        new_files = set()\n        if root_py_cache.exists():\n            new_files.update(root_py_cache.iterdir())\n            new_files.add(root_py_cache)\n            safe_delete(root_py_cache)\n        core_new_files = super()._generate_new_files()\n        # remove files that are within the image folder deeper than one level (as these will be not linked directly)\n        for file in core_new_files:\n            try:\n                rel = file.relative_to(self._image_dir)\n                if len(rel.parts) > 1:\n                    continue\n            except ValueError:\n                pass\n            new_files.add(file)\n        return new_files\n\n    def _fix_records(self, new_files):\n        new_files.update(i for i in self._image_dir.iterdir())\n        extra_record_data_str = self._records_text(sorted(new_files, key=str))\n        (self._dist_info / \"RECORD\").write_text(extra_record_data_str, encoding=\"utf-8\")\n\n    def build_image(self):\n        super().build_image()\n        # protect the image by making it read only\n        set_tree(self._image_dir, S_IREAD | S_IRGRP | S_IROTH)\n\n    def clear(self):\n        if self._image_dir.exists():\n            safe_delete(self._image_dir)\n        super().clear()\n\n\n__all__ = [\n    \"SymlinkPipInstall\",\n]\n", "src/virtualenv/seed/embed/via_app_data/pip_install/__init__.py": "", "src/virtualenv/seed/wheels/util.py": "from __future__ import annotations\n\nfrom operator import attrgetter\nfrom zipfile import ZipFile\n\n\nclass Wheel:\n    def __init__(self, path) -> None:\n        # https://www.python.org/dev/peps/pep-0427/#file-name-convention\n        # The wheel filename is {distribution}-{version}(-{build tag})?-{python tag}-{abi tag}-{platform tag}.whl\n        self.path = path\n        self._parts = path.stem.split(\"-\")\n\n    @classmethod\n    def from_path(cls, path):\n        if path is not None and path.suffix == \".whl\" and len(path.stem.split(\"-\")) >= 5:  # noqa: PLR2004\n            return cls(path)\n        return None\n\n    @property\n    def distribution(self):\n        return self._parts[0]\n\n    @property\n    def version(self):\n        return self._parts[1]\n\n    @property\n    def version_tuple(self):\n        return self.as_version_tuple(self.version)\n\n    @staticmethod\n    def as_version_tuple(version):\n        result = []\n        for part in version.split(\".\")[0:3]:\n            try:\n                result.append(int(part))\n            except ValueError:  # noqa: PERF203\n                break\n        if not result:\n            raise ValueError(version)\n        return tuple(result)\n\n    @property\n    def name(self):\n        return self.path.name\n\n    def support_py(self, py_version):\n        name = f\"{'-'.join(self.path.stem.split('-')[0:2])}.dist-info/METADATA\"\n        with ZipFile(str(self.path), \"r\") as zip_file:\n            metadata = zip_file.read(name).decode(\"utf-8\")\n        marker = \"Requires-Python:\"\n        requires = next((i[len(marker) :] for i in metadata.splitlines() if i.startswith(marker)), None)\n        if requires is None:  # if it does not specify a python requires the assumption is compatible\n            return True\n        py_version_int = tuple(int(i) for i in py_version.split(\".\"))\n        for require in (i.strip() for i in requires.split(\",\")):\n            # https://www.python.org/dev/peps/pep-0345/#version-specifiers\n            for operator, check in [\n                (\"!=\", lambda v: py_version_int != v),\n                (\"==\", lambda v: py_version_int == v),\n                (\"<=\", lambda v: py_version_int <= v),\n                (\">=\", lambda v: py_version_int >= v),\n                (\"<\", lambda v: py_version_int < v),\n                (\">\", lambda v: py_version_int > v),\n            ]:\n                if require.startswith(operator):\n                    ver_str = require[len(operator) :].strip()\n                    version = tuple((int(i) if i != \"*\" else None) for i in ver_str.split(\".\"))[0:2]\n                    if not check(version):\n                        return False\n                    break\n        return True\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}({self.path})\"\n\n    def __str__(self) -> str:\n        return str(self.path)\n\n\ndef discover_wheels(from_folder, distribution, version, for_py_version):\n    wheels = []\n    for filename in from_folder.iterdir():\n        wheel = Wheel.from_path(filename)\n        if (\n            wheel\n            and wheel.distribution == distribution\n            and (version is None or wheel.version == version)\n            and wheel.support_py(for_py_version)\n        ):\n            wheels.append(wheel)\n    return sorted(wheels, key=attrgetter(\"version_tuple\", \"distribution\"), reverse=True)\n\n\nclass Version:\n    #: the version bundled with virtualenv\n    bundle = \"bundle\"\n    embed = \"embed\"\n    #: custom version handlers\n    non_version = (bundle, embed)\n\n    @staticmethod\n    def of_version(value):\n        return None if value in Version.non_version else value\n\n    @staticmethod\n    def as_pip_req(distribution, version):\n        return f\"{distribution}{Version.as_version_spec(version)}\"\n\n    @staticmethod\n    def as_version_spec(version):\n        of_version = Version.of_version(version)\n        return \"\" if of_version is None else f\"=={of_version}\"\n\n\n__all__ = [\n    \"Version\",\n    \"Wheel\",\n    \"discover_wheels\",\n]\n", "src/virtualenv/seed/wheels/__init__.py": "from __future__ import annotations\n\nfrom .acquire import get_wheel, pip_wheel_env_run\nfrom .util import Version, Wheel\n\n__all__ = [\n    \"Version\",\n    \"Wheel\",\n    \"get_wheel\",\n    \"pip_wheel_env_run\",\n]\n", "src/virtualenv/seed/wheels/bundle.py": "from __future__ import annotations\n\nfrom virtualenv.seed.wheels.embed import get_embed_wheel\n\nfrom .periodic_update import periodic_update\nfrom .util import Version, Wheel, discover_wheels\n\n\ndef from_bundle(distribution, version, for_py_version, search_dirs, app_data, do_periodic_update, env):  # noqa: PLR0913\n    \"\"\"Load the bundled wheel to a cache directory.\"\"\"\n    of_version = Version.of_version(version)\n    wheel = load_embed_wheel(app_data, distribution, for_py_version, of_version)\n\n    if version != Version.embed:\n        # 2. check if we have upgraded embed\n        if app_data.can_update:\n            per = do_periodic_update\n            wheel = periodic_update(distribution, of_version, for_py_version, wheel, search_dirs, app_data, per, env)\n\n        # 3. acquire from extra search dir\n        found_wheel = from_dir(distribution, of_version, for_py_version, search_dirs)\n        if found_wheel is not None and (wheel is None or found_wheel.version_tuple > wheel.version_tuple):\n            wheel = found_wheel\n    return wheel\n\n\ndef load_embed_wheel(app_data, distribution, for_py_version, version):\n    wheel = get_embed_wheel(distribution, for_py_version)\n    if wheel is not None:\n        version_match = version == wheel.version\n        if version is None or version_match:\n            with app_data.ensure_extracted(wheel.path, lambda: app_data.house) as wheel_path:\n                wheel = Wheel(wheel_path)\n        else:  # if version does not match ignore\n            wheel = None\n    return wheel\n\n\ndef from_dir(distribution, version, for_py_version, directories):\n    \"\"\"Load a compatible wheel from a given folder.\"\"\"\n    for folder in directories:\n        for wheel in discover_wheels(folder, distribution, version, for_py_version):\n            return wheel\n    return None\n\n\n__all__ = [\n    \"from_bundle\",\n    \"load_embed_wheel\",\n]\n", "src/virtualenv/seed/wheels/acquire.py": "\"\"\"Bootstrap.\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport sys\nfrom operator import eq, lt\nfrom pathlib import Path\nfrom subprocess import PIPE, CalledProcessError, Popen\n\nfrom .bundle import from_bundle\nfrom .periodic_update import add_wheel_to_update_log\nfrom .util import Version, Wheel, discover_wheels\n\n\ndef get_wheel(  # noqa: PLR0913\n    distribution,\n    version,\n    for_py_version,\n    search_dirs,\n    download,\n    app_data,\n    do_periodic_update,\n    env,\n):\n    \"\"\"Get a wheel with the given distribution-version-for_py_version trio, by using the extra search dir + download.\"\"\"\n    # not all wheels are compatible with all python versions, so we need to py version qualify it\n    wheel = None\n\n    if not download or version != Version.bundle:\n        # 1. acquire from bundle\n        wheel = from_bundle(distribution, version, for_py_version, search_dirs, app_data, do_periodic_update, env)\n\n    if download and wheel is None and version != Version.embed:\n        # 2. download from the internet\n        wheel = download_wheel(\n            distribution=distribution,\n            version_spec=Version.as_version_spec(version),\n            for_py_version=for_py_version,\n            search_dirs=search_dirs,\n            app_data=app_data,\n            to_folder=app_data.house,\n            env=env,\n        )\n        if wheel is not None and app_data.can_update:\n            add_wheel_to_update_log(wheel, for_py_version, app_data)\n\n    return wheel\n\n\ndef download_wheel(distribution, version_spec, for_py_version, search_dirs, app_data, to_folder, env):  # noqa: PLR0913\n    to_download = f\"{distribution}{version_spec or ''}\"\n    logging.debug(\"download wheel %s %s to %s\", to_download, for_py_version, to_folder)\n    cmd = [\n        sys.executable,\n        \"-m\",\n        \"pip\",\n        \"download\",\n        \"--progress-bar\",\n        \"off\",\n        \"--disable-pip-version-check\",\n        \"--only-binary=:all:\",\n        \"--no-deps\",\n        \"--python-version\",\n        for_py_version,\n        \"-d\",\n        str(to_folder),\n        to_download,\n    ]\n    # pip has no interface in python - must be a new sub-process\n    env = pip_wheel_env_run(search_dirs, app_data, env)\n    process = Popen(cmd, env=env, stdout=PIPE, stderr=PIPE, universal_newlines=True, encoding=\"utf-8\")  # noqa: S603\n    out, err = process.communicate()\n    if process.returncode != 0:\n        kwargs = {\"output\": out, \"stderr\": err}\n        raise CalledProcessError(process.returncode, cmd, **kwargs)\n    result = _find_downloaded_wheel(distribution, version_spec, for_py_version, to_folder, out)\n    logging.debug(\"downloaded wheel %s\", result.name)\n    return result\n\n\ndef _find_downloaded_wheel(distribution, version_spec, for_py_version, to_folder, out):\n    for line in out.splitlines():\n        stripped_line = line.lstrip()\n        for marker in (\"Saved \", \"File was already downloaded \"):\n            if stripped_line.startswith(marker):\n                return Wheel(Path(stripped_line[len(marker) :]).absolute())\n    # if for some reason the output does not match fallback to the latest version with that spec\n    return find_compatible_in_house(distribution, version_spec, for_py_version, to_folder)\n\n\ndef find_compatible_in_house(distribution, version_spec, for_py_version, in_folder):\n    wheels = discover_wheels(in_folder, distribution, None, for_py_version)\n    start, end = 0, len(wheels)\n    if version_spec is not None and version_spec:\n        if version_spec.startswith(\"<\"):\n            from_pos, op = 1, lt\n        elif version_spec.startswith(\"==\"):\n            from_pos, op = 2, eq\n        else:\n            raise ValueError(version_spec)\n        version = Wheel.as_version_tuple(version_spec[from_pos:])\n        start = next((at for at, w in enumerate(wheels) if op(w.version_tuple, version)), len(wheels))\n\n    return None if start == end else wheels[start]\n\n\ndef pip_wheel_env_run(search_dirs, app_data, env):\n    env = env.copy()\n    env.update({\"PIP_USE_WHEEL\": \"1\", \"PIP_USER\": \"0\", \"PIP_NO_INPUT\": \"1\"})\n    wheel = get_wheel(\n        distribution=\"pip\",\n        version=None,\n        for_py_version=f\"{sys.version_info.major}.{sys.version_info.minor}\",\n        search_dirs=search_dirs,\n        download=False,\n        app_data=app_data,\n        do_periodic_update=False,\n        env=env,\n    )\n    if wheel is None:\n        msg = \"could not find the embedded pip\"\n        raise RuntimeError(msg)\n    env[\"PYTHONPATH\"] = str(wheel.path)\n    return env\n\n\n__all__ = [\n    \"download_wheel\",\n    \"get_wheel\",\n    \"pip_wheel_env_run\",\n]\n", "src/virtualenv/seed/wheels/periodic_update.py": "\"\"\"Periodically update bundled versions.\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport logging\nimport os\nimport ssl\nimport sys\nfrom datetime import datetime, timedelta, timezone\nfrom itertools import groupby\nfrom pathlib import Path\nfrom shutil import copy2\nfrom subprocess import DEVNULL, Popen\nfrom textwrap import dedent\nfrom threading import Thread\nfrom urllib.error import URLError\nfrom urllib.request import urlopen\n\nfrom virtualenv.app_data import AppDataDiskFolder\nfrom virtualenv.seed.wheels.embed import BUNDLE_SUPPORT\nfrom virtualenv.seed.wheels.util import Wheel\nfrom virtualenv.util.subprocess import CREATE_NO_WINDOW\n\nGRACE_PERIOD_CI = timedelta(hours=1)  # prevent version switch in the middle of a CI run\nGRACE_PERIOD_MINOR = timedelta(days=28)\nUPDATE_PERIOD = timedelta(days=14)\nUPDATE_ABORTED_DELAY = timedelta(hours=1)\n\n\ndef periodic_update(  # noqa: PLR0913\n    distribution,\n    of_version,\n    for_py_version,\n    wheel,\n    search_dirs,\n    app_data,\n    do_periodic_update,\n    env,\n):\n    if do_periodic_update:\n        handle_auto_update(distribution, for_py_version, wheel, search_dirs, app_data, env)\n\n    now = datetime.now(tz=timezone.utc)\n\n    def _update_wheel(ver):\n        updated_wheel = Wheel(app_data.house / ver.filename)\n        logging.debug(\"using %supdated wheel %s\", \"periodically \" if updated_wheel else \"\", updated_wheel)\n        return updated_wheel\n\n    u_log = UpdateLog.from_app_data(app_data, distribution, for_py_version)\n    if of_version is None:\n        for _, group in groupby(u_log.versions, key=lambda v: v.wheel.version_tuple[0:2]):\n            # use only latest patch version per minor, earlier assumed to be buggy\n            all_patches = list(group)\n            ignore_grace_period_minor = any(version for version in all_patches if version.use(now))\n            for version in all_patches:\n                if wheel is not None and Path(version.filename).name == wheel.name:\n                    return wheel\n                if version.use(now, ignore_grace_period_minor):\n                    return _update_wheel(version)\n    else:\n        for version in u_log.versions:\n            if version.wheel.version == of_version:\n                return _update_wheel(version)\n\n    return wheel\n\n\ndef handle_auto_update(distribution, for_py_version, wheel, search_dirs, app_data, env):  # noqa: PLR0913\n    embed_update_log = app_data.embed_update_log(distribution, for_py_version)\n    u_log = UpdateLog.from_dict(embed_update_log.read())\n    if u_log.needs_update:\n        u_log.periodic = True\n        u_log.started = datetime.now(tz=timezone.utc)\n        embed_update_log.write(u_log.to_dict())\n        trigger_update(distribution, for_py_version, wheel, search_dirs, app_data, periodic=True, env=env)\n\n\ndef add_wheel_to_update_log(wheel, for_py_version, app_data):\n    embed_update_log = app_data.embed_update_log(wheel.distribution, for_py_version)\n    logging.debug(\"adding %s information to %s\", wheel.name, embed_update_log.file)\n    u_log = UpdateLog.from_dict(embed_update_log.read())\n    if any(version.filename == wheel.name for version in u_log.versions):\n        logging.warning(\"%s already present in %s\", wheel.name, embed_update_log.file)\n        return\n    # we don't need a release date for sources other than \"periodic\"\n    version = NewVersion(wheel.name, datetime.now(tz=timezone.utc), None, \"download\")\n    u_log.versions.append(version)  # always write at the end for proper updates\n    embed_update_log.write(u_log.to_dict())\n\n\nDATETIME_FMT = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n\n\ndef dump_datetime(value):\n    return None if value is None else value.strftime(DATETIME_FMT)\n\n\ndef load_datetime(value):\n    return None if value is None else datetime.strptime(value, DATETIME_FMT).replace(tzinfo=timezone.utc)\n\n\nclass NewVersion:  # noqa: PLW1641\n    def __init__(self, filename, found_date, release_date, source) -> None:\n        self.filename = filename\n        self.found_date = found_date\n        self.release_date = release_date\n        self.source = source\n\n    @classmethod\n    def from_dict(cls, dictionary):\n        return cls(\n            filename=dictionary[\"filename\"],\n            found_date=load_datetime(dictionary[\"found_date\"]),\n            release_date=load_datetime(dictionary[\"release_date\"]),\n            source=dictionary[\"source\"],\n        )\n\n    def to_dict(self):\n        return {\n            \"filename\": self.filename,\n            \"release_date\": dump_datetime(self.release_date),\n            \"found_date\": dump_datetime(self.found_date),\n            \"source\": self.source,\n        }\n\n    def use(self, now, ignore_grace_period_minor=False, ignore_grace_period_ci=False):  # noqa: FBT002\n        if self.source == \"manual\":\n            return True\n        if self.source == \"periodic\" and (self.found_date < now - GRACE_PERIOD_CI or ignore_grace_period_ci):\n            if not ignore_grace_period_minor:\n                compare_from = self.release_date or self.found_date\n                return now - compare_from >= GRACE_PERIOD_MINOR\n            return True\n        return False\n\n    def __repr__(self) -> str:\n        return (\n            f\"{self.__class__.__name__}(filename={self.filename}), found_date={self.found_date}, \"\n            f\"release_date={self.release_date}, source={self.source})\"\n        )\n\n    def __eq__(self, other):\n        return type(self) == type(other) and all(\n            getattr(self, k) == getattr(other, k) for k in [\"filename\", \"release_date\", \"found_date\", \"source\"]\n        )\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    @property\n    def wheel(self):\n        return Wheel(Path(self.filename))\n\n\nclass UpdateLog:\n    def __init__(self, started, completed, versions, periodic) -> None:\n        self.started = started\n        self.completed = completed\n        self.versions = versions\n        self.periodic = periodic\n\n    @classmethod\n    def from_dict(cls, dictionary):\n        if dictionary is None:\n            dictionary = {}\n        return cls(\n            load_datetime(dictionary.get(\"started\")),\n            load_datetime(dictionary.get(\"completed\")),\n            [NewVersion.from_dict(v) for v in dictionary.get(\"versions\", [])],\n            dictionary.get(\"periodic\"),\n        )\n\n    @classmethod\n    def from_app_data(cls, app_data, distribution, for_py_version):\n        raw_json = app_data.embed_update_log(distribution, for_py_version).read()\n        return cls.from_dict(raw_json)\n\n    def to_dict(self):\n        return {\n            \"started\": dump_datetime(self.started),\n            \"completed\": dump_datetime(self.completed),\n            \"periodic\": self.periodic,\n            \"versions\": [r.to_dict() for r in self.versions],\n        }\n\n    @property\n    def needs_update(self):\n        now = datetime.now(tz=timezone.utc)\n        if self.completed is None:  # never completed\n            return self._check_start(now)\n        if now - self.completed <= UPDATE_PERIOD:\n            return False\n        return self._check_start(now)\n\n    def _check_start(self, now):\n        return self.started is None or now - self.started > UPDATE_ABORTED_DELAY\n\n\ndef trigger_update(distribution, for_py_version, wheel, search_dirs, app_data, env, periodic):  # noqa: PLR0913\n    wheel_path = None if wheel is None else str(wheel.path)\n    cmd = [\n        sys.executable,\n        \"-c\",\n        dedent(\n            \"\"\"\n        from virtualenv.report import setup_report, MAX_LEVEL\n        from virtualenv.seed.wheels.periodic_update import do_update\n        setup_report(MAX_LEVEL, show_pid=True)\n        do_update({!r}, {!r}, {!r}, {!r}, {!r}, {!r})\n        \"\"\",\n        )\n        .strip()\n        .format(distribution, for_py_version, wheel_path, str(app_data), [str(p) for p in search_dirs], periodic),\n    ]\n    debug = env.get(\"_VIRTUALENV_PERIODIC_UPDATE_INLINE\") == \"1\"\n    pipe = None if debug else DEVNULL\n    kwargs = {\"stdout\": pipe, \"stderr\": pipe}\n    if not debug and sys.platform == \"win32\":\n        kwargs[\"creationflags\"] = CREATE_NO_WINDOW\n    process = Popen(cmd, **kwargs)  # noqa: S603\n    logging.info(\n        \"triggered periodic upgrade of %s%s (for python %s) via background process having PID %d\",\n        distribution,\n        \"\" if wheel is None else f\"=={wheel.version}\",\n        for_py_version,\n        process.pid,\n    )\n    if debug:\n        process.communicate()  # on purpose not called to make it a background process\n    else:\n        # set the returncode here -> no ResourceWarning on main process exit if the subprocess still runs\n        process.returncode = 0\n\n\ndef do_update(distribution, for_py_version, embed_filename, app_data, search_dirs, periodic):  # noqa: PLR0913\n    versions = None\n    try:\n        versions = _run_do_update(app_data, distribution, embed_filename, for_py_version, periodic, search_dirs)\n    finally:\n        logging.debug(\"done %s %s with %s\", distribution, for_py_version, versions)\n    return versions\n\n\ndef _run_do_update(  # noqa: C901, PLR0913\n    app_data,\n    distribution,\n    embed_filename,\n    for_py_version,\n    periodic,\n    search_dirs,\n):\n    from virtualenv.seed.wheels import acquire  # noqa: PLC0415\n\n    wheel_filename = None if embed_filename is None else Path(embed_filename)\n    embed_version = None if wheel_filename is None else Wheel(wheel_filename).version_tuple\n    app_data = AppDataDiskFolder(app_data) if isinstance(app_data, str) else app_data\n    search_dirs = [Path(p) if isinstance(p, str) else p for p in search_dirs]\n    wheelhouse = app_data.house\n    embed_update_log = app_data.embed_update_log(distribution, for_py_version)\n    u_log = UpdateLog.from_dict(embed_update_log.read())\n    now = datetime.now(tz=timezone.utc)\n\n    update_versions, other_versions = [], []\n    for version in u_log.versions:\n        if version.source in {\"periodic\", \"manual\"}:\n            update_versions.append(version)\n        else:\n            other_versions.append(version)\n\n    if periodic:\n        source = \"periodic\"\n    else:\n        source = \"manual\"\n        # mark the most recent one as source \"manual\"\n        if update_versions:\n            update_versions[0].source = source\n\n    if wheel_filename is not None:\n        dest = wheelhouse / wheel_filename.name\n        if not dest.exists():\n            copy2(str(wheel_filename), str(wheelhouse))\n    last, last_version, versions, filenames = None, None, [], set()\n    while last is None or not last.use(now, ignore_grace_period_ci=True):\n        download_time = datetime.now(tz=timezone.utc)\n        dest = acquire.download_wheel(\n            distribution=distribution,\n            version_spec=None if last_version is None else f\"<{last_version}\",\n            for_py_version=for_py_version,\n            search_dirs=search_dirs,\n            app_data=app_data,\n            to_folder=wheelhouse,\n            env=os.environ,\n        )\n        if dest is None or (update_versions and update_versions[0].filename == dest.name):\n            break\n        release_date = release_date_for_wheel_path(dest.path)\n        last = NewVersion(filename=dest.path.name, release_date=release_date, found_date=download_time, source=source)\n        logging.info(\"detected %s in %s\", last, datetime.now(tz=timezone.utc) - download_time)\n        versions.append(last)\n        filenames.add(last.filename)\n        last_wheel = last.wheel\n        last_version = last_wheel.version\n        if embed_version is not None and embed_version >= last_wheel.version_tuple:\n            break  # stop download if we reach the embed version\n    u_log.periodic = periodic\n    if not u_log.periodic:\n        u_log.started = now\n    # update other_versions by removing version we just found\n    other_versions = [version for version in other_versions if version.filename not in filenames]\n    u_log.versions = versions + update_versions + other_versions\n    u_log.completed = datetime.now(tz=timezone.utc)\n    embed_update_log.write(u_log.to_dict())\n    return versions\n\n\ndef release_date_for_wheel_path(dest):\n    wheel = Wheel(dest)\n    # the most accurate is to ask PyPi - e.g. https://pypi.org/pypi/pip/json,\n    # see https://warehouse.pypa.io/api-reference/json/ for more details\n    content = _pypi_get_distribution_info_cached(wheel.distribution)\n    if content is not None:\n        try:\n            upload_time = content[\"releases\"][wheel.version][0][\"upload_time\"]\n            return datetime.strptime(upload_time, \"%Y-%m-%dT%H:%M:%S\").replace(tzinfo=timezone.utc)\n        except Exception as exception:  # noqa: BLE001\n            logging.error(\"could not load release date %s because %r\", content, exception)  # noqa: TRY400\n    return None\n\n\ndef _request_context():\n    yield None\n    # fallback to non verified HTTPS (the information we request is not sensitive, so fallback)\n    yield ssl._create_unverified_context()  # noqa: S323, SLF001\n\n\n_PYPI_CACHE = {}\n\n\ndef _pypi_get_distribution_info_cached(distribution):\n    if distribution not in _PYPI_CACHE:\n        _PYPI_CACHE[distribution] = _pypi_get_distribution_info(distribution)\n    return _PYPI_CACHE[distribution]\n\n\ndef _pypi_get_distribution_info(distribution):\n    content, url = None, f\"https://pypi.org/pypi/{distribution}/json\"\n    try:\n        for context in _request_context():\n            try:\n                with urlopen(url, context=context) as file_handler:  # noqa: S310\n                    content = json.load(file_handler)\n                break\n            except URLError as exception:\n                logging.error(\"failed to access %s because %r\", url, exception)  # noqa: TRY400\n    except Exception as exception:  # noqa: BLE001\n        logging.error(\"failed to access %s because %r\", url, exception)  # noqa: TRY400\n    return content\n\n\ndef manual_upgrade(app_data, env):\n    threads = []\n\n    for for_py_version, distribution_to_package in BUNDLE_SUPPORT.items():\n        # load extra search dir for the given for_py\n        for distribution in distribution_to_package:\n            thread = Thread(target=_run_manual_upgrade, args=(app_data, distribution, for_py_version, env))\n            thread.start()\n            threads.append(thread)\n\n    for thread in threads:\n        thread.join()\n\n\ndef _run_manual_upgrade(app_data, distribution, for_py_version, env):\n    start = datetime.now(tz=timezone.utc)\n    from .bundle import from_bundle  # noqa: PLC0415\n\n    current = from_bundle(\n        distribution=distribution,\n        version=None,\n        for_py_version=for_py_version,\n        search_dirs=[],\n        app_data=app_data,\n        do_periodic_update=False,\n        env=env,\n    )\n    logging.warning(\n        \"upgrade %s for python %s with current %s\",\n        distribution,\n        for_py_version,\n        \"\" if current is None else current.name,\n    )\n    versions = do_update(\n        distribution=distribution,\n        for_py_version=for_py_version,\n        embed_filename=current.path,\n        app_data=app_data,\n        search_dirs=[],\n        periodic=False,\n    )\n\n    args = [\n        distribution,\n        for_py_version,\n        datetime.now(tz=timezone.utc) - start,\n    ]\n    if versions:\n        args.append(\"\\n\".join(f\"\\t{v}\" for v in versions))\n    ver_update = \"new entries found:\\n%s\" if versions else \"no new versions found\"\n    msg = f\"upgraded %s for python %s in %s {ver_update}\"\n    logging.warning(msg, *args)\n\n\n__all__ = [\n    \"NewVersion\",\n    \"UpdateLog\",\n    \"add_wheel_to_update_log\",\n    \"do_update\",\n    \"dump_datetime\",\n    \"load_datetime\",\n    \"manual_upgrade\",\n    \"periodic_update\",\n    \"release_date_for_wheel_path\",\n    \"trigger_update\",\n]\n", "src/virtualenv/seed/wheels/embed/__init__.py": "from __future__ import annotations\n\nfrom pathlib import Path\n\nfrom virtualenv.seed.wheels.util import Wheel\n\nBUNDLE_FOLDER = Path(__file__).absolute().parent\nBUNDLE_SUPPORT = {\n    \"3.7\": {\n        \"pip\": \"pip-24.0-py3-none-any.whl\",\n        \"setuptools\": \"setuptools-68.0.0-py3-none-any.whl\",\n        \"wheel\": \"wheel-0.42.0-py3-none-any.whl\",\n    },\n    \"3.8\": {\n        \"pip\": \"pip-24.1-py3-none-any.whl\",\n        \"setuptools\": \"setuptools-70.1.0-py3-none-any.whl\",\n        \"wheel\": \"wheel-0.43.0-py3-none-any.whl\",\n    },\n    \"3.9\": {\n        \"pip\": \"pip-24.1-py3-none-any.whl\",\n        \"setuptools\": \"setuptools-70.1.0-py3-none-any.whl\",\n        \"wheel\": \"wheel-0.43.0-py3-none-any.whl\",\n    },\n    \"3.10\": {\n        \"pip\": \"pip-24.1-py3-none-any.whl\",\n        \"setuptools\": \"setuptools-70.1.0-py3-none-any.whl\",\n        \"wheel\": \"wheel-0.43.0-py3-none-any.whl\",\n    },\n    \"3.11\": {\n        \"pip\": \"pip-24.1-py3-none-any.whl\",\n        \"setuptools\": \"setuptools-70.1.0-py3-none-any.whl\",\n        \"wheel\": \"wheel-0.43.0-py3-none-any.whl\",\n    },\n    \"3.12\": {\n        \"pip\": \"pip-24.1-py3-none-any.whl\",\n        \"setuptools\": \"setuptools-70.1.0-py3-none-any.whl\",\n        \"wheel\": \"wheel-0.43.0-py3-none-any.whl\",\n    },\n    \"3.13\": {\n        \"pip\": \"pip-24.1-py3-none-any.whl\",\n        \"setuptools\": \"setuptools-70.1.0-py3-none-any.whl\",\n        \"wheel\": \"wheel-0.43.0-py3-none-any.whl\",\n    },\n    \"3.14\": {\n        \"pip\": \"pip-24.1-py3-none-any.whl\",\n        \"setuptools\": \"setuptools-70.1.0-py3-none-any.whl\",\n        \"wheel\": \"wheel-0.43.0-py3-none-any.whl\",\n    },\n}\nMAX = \"3.7\"\n\n\ndef get_embed_wheel(distribution, for_py_version):\n    path = BUNDLE_FOLDER / (BUNDLE_SUPPORT.get(for_py_version, {}) or BUNDLE_SUPPORT[MAX]).get(distribution)\n    return Wheel.from_path(path)\n\n\n__all__ = [\n    \"BUNDLE_FOLDER\",\n    \"BUNDLE_SUPPORT\",\n    \"MAX\",\n    \"get_embed_wheel\",\n]\n", "src/virtualenv/util/lock.py": "\"\"\"holds locking functionality that works across processes.\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport os\nfrom abc import ABC, abstractmethod\nfrom contextlib import contextmanager, suppress\nfrom pathlib import Path\nfrom threading import Lock, RLock\n\nfrom filelock import FileLock, Timeout\n\n\nclass _CountedFileLock(FileLock):\n    def __init__(self, lock_file) -> None:\n        parent = os.path.dirname(lock_file)\n        if not os.path.isdir(parent):\n            with suppress(OSError):\n                os.makedirs(parent)\n\n        super().__init__(lock_file)\n        self.count = 0\n        self.thread_safe = RLock()\n\n    def acquire(self, timeout=None, poll_interval=0.05):\n        if not self.thread_safe.acquire(timeout=-1 if timeout is None else timeout):\n            raise Timeout(self.lock_file)\n        if self.count == 0:\n            super().acquire(timeout, poll_interval)\n        self.count += 1\n\n    def release(self, force=False):  # noqa: FBT002\n        with self.thread_safe:\n            if self.count > 0:\n                self.thread_safe.release()\n            if self.count == 1:\n                super().release(force=force)\n            self.count = max(self.count - 1, 0)\n\n\n_lock_store = {}\n_store_lock = Lock()\n\n\nclass PathLockBase(ABC):\n    def __init__(self, folder) -> None:\n        path = Path(folder)\n        self.path = path.resolve() if path.exists() else path\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}({self.path})\"\n\n    def __truediv__(self, other):\n        return type(self)(self.path / other)\n\n    @abstractmethod\n    def __enter__(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        raise NotImplementedError\n\n    @abstractmethod\n    @contextmanager\n    def lock_for_key(self, name, no_block=False):  # noqa: FBT002\n        raise NotImplementedError\n\n    @abstractmethod\n    @contextmanager\n    def non_reentrant_lock_for_key(self, name):\n        raise NotImplementedError\n\n\nclass ReentrantFileLock(PathLockBase):\n    def __init__(self, folder) -> None:\n        super().__init__(folder)\n        self._lock = None\n\n    def _create_lock(self, name=\"\"):\n        lock_file = str(self.path / f\"{name}.lock\")\n        with _store_lock:\n            if lock_file not in _lock_store:\n                _lock_store[lock_file] = _CountedFileLock(lock_file)\n            return _lock_store[lock_file]\n\n    @staticmethod\n    def _del_lock(lock):\n        if lock is not None:\n            with _store_lock, lock.thread_safe:\n                if lock.count == 0:\n                    _lock_store.pop(lock.lock_file, None)\n\n    def __del__(self) -> None:\n        self._del_lock(self._lock)\n\n    def __enter__(self):\n        self._lock = self._create_lock()\n        self._lock_file(self._lock)\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self._release(self._lock)\n        self._del_lock(self._lock)\n        self._lock = None\n\n    def _lock_file(self, lock, no_block=False):  # noqa: FBT002\n        # multiple processes might be trying to get a first lock... so we cannot check if this directory exist without\n        # a lock, but that lock might then become expensive, and it's not clear where that lock should live.\n        # Instead here we just ignore if we fail to create the directory.\n        with suppress(OSError):\n            os.makedirs(str(self.path))\n\n        try:\n            lock.acquire(0.0001)\n        except Timeout:\n            if no_block:\n                raise\n            logging.debug(\"lock file %s present, will block until released\", lock.lock_file)\n            lock.release()  # release the acquire try from above\n            lock.acquire()\n\n    @staticmethod\n    def _release(lock):\n        lock.release()\n\n    @contextmanager\n    def lock_for_key(self, name, no_block=False):  # noqa: FBT002\n        lock = self._create_lock(name)\n        try:\n            try:\n                self._lock_file(lock, no_block)\n                yield\n            finally:\n                self._release(lock)\n        finally:\n            self._del_lock(lock)\n            lock = None\n\n    @contextmanager\n    def non_reentrant_lock_for_key(self, name):\n        with _CountedFileLock(str(self.path / f\"{name}.lock\")):\n            yield\n\n\nclass NoOpFileLock(PathLockBase):\n    def __enter__(self):\n        raise NotImplementedError\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        raise NotImplementedError\n\n    @contextmanager\n    def lock_for_key(self, name, no_block=False):  # noqa: ARG002, FBT002\n        yield\n\n    @contextmanager\n    def non_reentrant_lock_for_key(self, name):  # noqa: ARG002\n        yield\n\n\n__all__ = [\n    \"NoOpFileLock\",\n    \"ReentrantFileLock\",\n    \"Timeout\",\n]\n", "src/virtualenv/util/error.py": "\"\"\"Errors.\"\"\"\n\nfrom __future__ import annotations\n\n\nclass ProcessCallFailedError(RuntimeError):\n    \"\"\"Failed a process call.\"\"\"\n\n    def __init__(self, code, out, err, cmd) -> None:\n        super().__init__(code, out, err, cmd)\n        self.code = code\n        self.out = out\n        self.err = err\n        self.cmd = cmd\n", "src/virtualenv/util/__init__.py": "", "src/virtualenv/util/zipapp.py": "from __future__ import annotations\n\nimport logging\nimport os\nimport zipfile\n\nfrom virtualenv.info import IS_WIN, ROOT\n\n\ndef read(full_path):\n    sub_file = _get_path_within_zip(full_path)\n    with zipfile.ZipFile(ROOT, \"r\") as zip_file, zip_file.open(sub_file) as file_handler:\n        return file_handler.read().decode(\"utf-8\")\n\n\ndef extract(full_path, dest):\n    logging.debug(\"extract %s to %s\", full_path, dest)\n    sub_file = _get_path_within_zip(full_path)\n    with zipfile.ZipFile(ROOT, \"r\") as zip_file:\n        info = zip_file.getinfo(sub_file)\n        info.filename = dest.name\n        zip_file.extract(info, str(dest.parent))\n\n\ndef _get_path_within_zip(full_path):\n    full_path = os.path.realpath(os.path.abspath(str(full_path)))\n    prefix = f\"{ROOT}{os.sep}\"\n    if not full_path.startswith(prefix):\n        msg = f\"full_path={full_path} should start with prefix={prefix}.\"\n        raise RuntimeError(msg)\n    sub_file = full_path[len(prefix) :]\n    if IS_WIN:\n        # paths are always UNIX separators, even on Windows, though __file__ still follows platform default\n        sub_file = sub_file.replace(os.sep, \"/\")\n    return sub_file\n\n\n__all__ = [\n    \"extract\",\n    \"read\",\n]\n", "src/virtualenv/util/path/_permission.py": "from __future__ import annotations\n\nimport os\nfrom stat import S_IXGRP, S_IXOTH, S_IXUSR\n\n\ndef make_exe(filename):\n    original_mode = filename.stat().st_mode\n    levels = [S_IXUSR, S_IXGRP, S_IXOTH]\n    for at in range(len(levels), 0, -1):\n        try:\n            mode = original_mode\n            for level in levels[:at]:\n                mode |= level\n            filename.chmod(mode)\n            break\n        except OSError:\n            continue\n\n\ndef set_tree(folder, stat):\n    for root, _, files in os.walk(str(folder)):\n        for filename in files:\n            os.chmod(os.path.join(root, filename), stat)\n\n\n__all__ = (\n    \"make_exe\",\n    \"set_tree\",\n)\n", "src/virtualenv/util/path/_win.py": "from __future__ import annotations\n\n\ndef get_short_path_name(long_name):\n    \"\"\"Gets the short path name of a given long path - http://stackoverflow.com/a/23598461/200291.\"\"\"\n    import ctypes  # noqa: PLC0415\n    from ctypes import wintypes  # noqa: PLC0415\n\n    _GetShortPathNameW = ctypes.windll.kernel32.GetShortPathNameW  # noqa: N806\n    _GetShortPathNameW.argtypes = [wintypes.LPCWSTR, wintypes.LPWSTR, wintypes.DWORD]\n    _GetShortPathNameW.restype = wintypes.DWORD\n    output_buf_size = 0\n    while True:\n        output_buf = ctypes.create_unicode_buffer(output_buf_size)\n        needed = _GetShortPathNameW(long_name, output_buf, output_buf_size)\n        if output_buf_size >= needed:\n            return output_buf.value\n        output_buf_size = needed\n\n\n__all__ = [\n    \"get_short_path_name\",\n]\n", "src/virtualenv/util/path/_sync.py": "from __future__ import annotations\n\nimport logging\nimport os\nimport shutil\nimport sys\nfrom stat import S_IWUSR\n\n\ndef ensure_dir(path):\n    if not path.exists():\n        logging.debug(\"create folder %s\", str(path))\n        os.makedirs(str(path))\n\n\ndef ensure_safe_to_do(src, dest):\n    if src == dest:\n        msg = f\"source and destination is the same {src}\"\n        raise ValueError(msg)\n    if not dest.exists():\n        return\n    if dest.is_dir() and not dest.is_symlink():\n        logging.debug(\"remove directory %s\", dest)\n        safe_delete(dest)\n    else:\n        logging.debug(\"remove file %s\", dest)\n        dest.unlink()\n\n\ndef symlink(src, dest):\n    ensure_safe_to_do(src, dest)\n    logging.debug(\"symlink %s\", _Debug(src, dest))\n    dest.symlink_to(src, target_is_directory=src.is_dir())\n\n\ndef copy(src, dest):\n    ensure_safe_to_do(src, dest)\n    is_dir = src.is_dir()\n    method = copytree if is_dir else shutil.copy\n    logging.debug(\"copy %s\", _Debug(src, dest))\n    method(str(src), str(dest))\n\n\ndef copytree(src, dest):\n    for root, _, files in os.walk(src):\n        dest_dir = os.path.join(dest, os.path.relpath(root, src))\n        if not os.path.isdir(dest_dir):\n            os.makedirs(dest_dir)\n        for name in files:\n            src_f = os.path.join(root, name)\n            dest_f = os.path.join(dest_dir, name)\n            shutil.copy(src_f, dest_f)\n\n\ndef safe_delete(dest):\n    def onerror(func, path, exc_info):  # noqa: ARG001\n        if not os.access(path, os.W_OK):\n            os.chmod(path, S_IWUSR)\n            func(path)\n        else:\n            raise  # noqa: PLE0704\n\n    kwargs = {\"onexc\" if sys.version_info >= (3, 12) else \"onerror\": onerror}\n    shutil.rmtree(str(dest), ignore_errors=True, **kwargs)\n\n\nclass _Debug:\n    def __init__(self, src, dest) -> None:\n        self.src = src\n        self.dest = dest\n\n    def __str__(self) -> str:\n        return f\"{'directory ' if self.src.is_dir() else ''}{self.src!s} to {self.dest!s}\"\n\n\n__all__ = [\n    \"copy\",\n    \"copytree\",\n    \"ensure_dir\",\n    \"safe_delete\",\n    \"symlink\",\n    \"symlink\",\n]\n", "src/virtualenv/util/path/__init__.py": "from __future__ import annotations\n\nfrom ._permission import make_exe, set_tree\nfrom ._sync import copy, copytree, ensure_dir, safe_delete, symlink\nfrom ._win import get_short_path_name\n\n__all__ = [\n    \"copy\",\n    \"copytree\",\n    \"ensure_dir\",\n    \"get_short_path_name\",\n    \"make_exe\",\n    \"safe_delete\",\n    \"set_tree\",\n    \"symlink\",\n]\n", "src/virtualenv/util/subprocess/__init__.py": "from __future__ import annotations\n\nimport subprocess\n\nCREATE_NO_WINDOW = 0x80000000\n\n\ndef run_cmd(cmd):\n    try:\n        process = subprocess.Popen(\n            cmd,  # noqa: S603\n            universal_newlines=True,\n            stdin=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            encoding=\"utf-8\",\n        )\n        out, err = process.communicate()  # input disabled\n        code = process.returncode\n    except OSError as error:\n        code, out, err = error.errno, \"\", error.strerror\n        if code == 2 and \"file\" in err:  # noqa: PLR2004\n            err = str(error)  # FileNotFoundError in Python >= 3.3\n    return code, out, err\n\n\n__all__ = (\n    \"CREATE_NO_WINDOW\",\n    \"run_cmd\",\n)\n", "src/virtualenv/config/env_var.py": "from __future__ import annotations\n\nfrom contextlib import suppress\n\nfrom .convert import convert\n\n\ndef get_env_var(key, as_type, env):\n    \"\"\"\n    Get the environment variable option.\n\n    :param key: the config key requested\n    :param as_type: the type we would like to convert it to\n    :param env: environment variables to use\n    :return:\n    \"\"\"\n    environ_key = f\"VIRTUALENV_{key.upper()}\"\n    if env.get(environ_key):\n        value = env[environ_key]\n\n        with suppress(Exception):  # note the converter already logs a warning when failures happen\n            source = f\"env var {environ_key}\"\n            as_type = convert(value, as_type, source)\n            return as_type, source\n    return None\n\n\n__all__ = [\n    \"get_env_var\",\n]\n", "src/virtualenv/config/convert.py": "from __future__ import annotations\n\nimport logging\nimport os\nfrom typing import ClassVar\n\n\nclass TypeData:\n    def __init__(self, default_type, as_type) -> None:\n        self.default_type = default_type\n        self.as_type = as_type\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}(base={self.default_type}, as={self.as_type})\"\n\n    def convert(self, value):\n        return self.default_type(value)\n\n\nclass BoolType(TypeData):\n    BOOLEAN_STATES: ClassVar[dict[str, bool]] = {\n        \"1\": True,\n        \"yes\": True,\n        \"true\": True,\n        \"on\": True,\n        \"0\": False,\n        \"no\": False,\n        \"false\": False,\n        \"off\": False,\n    }\n\n    def convert(self, value):\n        if value.lower() not in self.BOOLEAN_STATES:\n            msg = f\"Not a boolean: {value}\"\n            raise ValueError(msg)\n        return self.BOOLEAN_STATES[value.lower()]\n\n\nclass NoneType(TypeData):\n    def convert(self, value):\n        if not value:\n            return None\n        return str(value)\n\n\nclass ListType(TypeData):\n    def _validate(self):\n        \"\"\"no op.\"\"\"\n\n    def convert(self, value, flatten=True):  # noqa: ARG002, FBT002\n        values = self.split_values(value)\n        result = []\n        for a_value in values:\n            sub_values = a_value.split(os.pathsep)\n            result.extend(sub_values)\n        return [self.as_type(i) for i in result]\n\n    def split_values(self, value):\n        \"\"\"\n        Split the provided value into a list.\n\n        First this is done by newlines. If there were no newlines in the text,\n        then we next try to split by comma.\n        \"\"\"\n        if isinstance(value, (str, bytes)):\n            # Use `splitlines` rather than a custom check for whether there is\n            # more than one line. This ensures that the full `splitlines()`\n            # logic is supported here.\n            values = value.splitlines()\n            if len(values) <= 1:\n                values = value.split(\",\")\n            values = filter(None, [x.strip() for x in values])\n        else:\n            values = list(value)\n\n        return values\n\n\ndef convert(value, as_type, source):\n    \"\"\"Convert the value as a given type where the value comes from the given source.\"\"\"\n    try:\n        return as_type.convert(value)\n    except Exception as exception:\n        logging.warning(\"%s failed to convert %r as %r because %r\", source, value, as_type, exception)\n        raise\n\n\n_CONVERT = {bool: BoolType, type(None): NoneType, list: ListType}\n\n\ndef get_type(action):\n    default_type = type(action.default)\n    as_type = default_type if action.type is None else action.type\n    return _CONVERT.get(default_type, TypeData)(default_type, as_type)\n\n\n__all__ = [\n    \"convert\",\n    \"get_type\",\n]\n", "src/virtualenv/config/__init__.py": "", "src/virtualenv/config/ini.py": "from __future__ import annotations\n\nimport logging\nimport os\nfrom configparser import ConfigParser\nfrom pathlib import Path\nfrom typing import ClassVar\n\nfrom platformdirs import user_config_dir\n\nfrom .convert import convert\n\n\nclass IniConfig:\n    VIRTUALENV_CONFIG_FILE_ENV_VAR: ClassVar[str] = \"VIRTUALENV_CONFIG_FILE\"\n    STATE: ClassVar[dict[bool | None, str]] = {None: \"failed to parse\", True: \"active\", False: \"missing\"}\n\n    section = \"virtualenv\"\n\n    def __init__(self, env=None) -> None:\n        env = os.environ if env is None else env\n        config_file = env.get(self.VIRTUALENV_CONFIG_FILE_ENV_VAR, None)\n        self.is_env_var = config_file is not None\n        if config_file is None:\n            config_file = Path(user_config_dir(appname=\"virtualenv\", appauthor=\"pypa\")) / \"virtualenv.ini\"\n        else:\n            config_file = Path(config_file)\n        self.config_file = config_file\n        self._cache = {}\n\n        exception = None\n        self.has_config_file = None\n        try:\n            self.has_config_file = self.config_file.exists()\n        except OSError as exc:\n            exception = exc\n        else:\n            if self.has_config_file:\n                self.config_file = self.config_file.resolve()\n                self.config_parser = ConfigParser()\n                try:\n                    self._load()\n                    self.has_virtualenv_section = self.config_parser.has_section(self.section)\n                except Exception as exc:  # noqa: BLE001\n                    exception = exc\n        if exception is not None:\n            logging.error(\"failed to read config file %s because %r\", config_file, exception)\n\n    def _load(self):\n        with self.config_file.open(\"rt\", encoding=\"utf-8\") as file_handler:\n            return self.config_parser.read_file(file_handler)\n\n    def get(self, key, as_type):\n        cache_key = key, as_type\n        if cache_key in self._cache:\n            return self._cache[cache_key]\n        try:\n            source = \"file\"\n            raw_value = self.config_parser.get(self.section, key.lower())\n            value = convert(raw_value, as_type, source)\n            result = value, source\n        except Exception:  # noqa: BLE001\n            result = None\n        self._cache[cache_key] = result\n        return result\n\n    def __bool__(self) -> bool:\n        return bool(self.has_config_file) and bool(self.has_virtualenv_section)\n\n    @property\n    def epilog(self):\n        return (\n            f\"\\nconfig file {self.config_file} {self.STATE[self.has_config_file]} \"\n            f\"(change{'d' if self.is_env_var else ''} via env var {self.VIRTUALENV_CONFIG_FILE_ENV_VAR})\"\n        )\n", "src/virtualenv/config/cli/__init__.py": "", "src/virtualenv/config/cli/parser.py": "from __future__ import annotations\n\nimport os\nfrom argparse import SUPPRESS, ArgumentDefaultsHelpFormatter, ArgumentParser, Namespace\nfrom collections import OrderedDict\n\nfrom virtualenv.config.convert import get_type\nfrom virtualenv.config.env_var import get_env_var\nfrom virtualenv.config.ini import IniConfig\n\n\nclass VirtualEnvOptions(Namespace):\n    def __init__(self, **kwargs) -> None:\n        super().__init__(**kwargs)\n        self._src = None\n        self._sources = {}\n\n    def set_src(self, key, value, src):\n        setattr(self, key, value)\n        if src.startswith(\"env var\"):\n            src = \"env var\"\n        self._sources[key] = src\n\n    def __setattr__(self, key, value) -> None:\n        if getattr(self, \"_src\", None) is not None:\n            self._sources[key] = self._src\n        super().__setattr__(key, value)\n\n    def get_source(self, key):\n        return self._sources.get(key)\n\n    @property\n    def verbosity(self):\n        if not hasattr(self, \"verbose\") and not hasattr(self, \"quiet\"):\n            return None\n        return max(self.verbose - self.quiet, 0)\n\n    def __repr__(self) -> str:\n        return f\"{type(self).__name__}({', '.join(f'{k}={v}' for k, v in vars(self).items() if not k.startswith('_'))})\"\n\n\nclass VirtualEnvConfigParser(ArgumentParser):\n    \"\"\"Custom option parser which updates its defaults by checking the configuration files and environmental vars.\"\"\"\n\n    def __init__(self, options=None, env=None, *args, **kwargs) -> None:\n        env = os.environ if env is None else env\n        self.file_config = IniConfig(env)\n        self.epilog_list = []\n        self.env = env\n        kwargs[\"epilog\"] = self.file_config.epilog\n        kwargs[\"add_help\"] = False\n        kwargs[\"formatter_class\"] = HelpFormatter\n        kwargs[\"prog\"] = \"virtualenv\"\n        super().__init__(*args, **kwargs)\n        self._fixed = set()\n        if options is not None and not isinstance(options, VirtualEnvOptions):\n            msg = \"options must be of type VirtualEnvOptions\"\n            raise TypeError(msg)\n        self.options = VirtualEnvOptions() if options is None else options\n        self._interpreter = None\n        self._app_data = None\n\n    def _fix_defaults(self):\n        for action in self._actions:\n            action_id = id(action)\n            if action_id not in self._fixed:\n                self._fix_default(action)\n                self._fixed.add(action_id)\n\n    def _fix_default(self, action):\n        if hasattr(action, \"default\") and hasattr(action, \"dest\") and action.default != SUPPRESS:\n            as_type = get_type(action)\n            names = OrderedDict((i.lstrip(\"-\").replace(\"-\", \"_\"), None) for i in action.option_strings)\n            outcome = None\n            for name in names:\n                outcome = get_env_var(name, as_type, self.env)\n                if outcome is not None:\n                    break\n            if outcome is None and self.file_config:\n                for name in names:\n                    outcome = self.file_config.get(name, as_type)\n                    if outcome is not None:\n                        break\n            if outcome is not None:\n                action.default, action.default_source = outcome\n            else:\n                outcome = action.default, \"default\"\n            self.options.set_src(action.dest, *outcome)\n\n    def enable_help(self):\n        self._fix_defaults()\n        self.add_argument(\"-h\", \"--help\", action=\"help\", default=SUPPRESS, help=\"show this help message and exit\")\n\n    def parse_known_args(self, args=None, namespace=None):\n        if namespace is None:\n            namespace = self.options\n        elif namespace is not self.options:\n            msg = \"can only pass in parser.options\"\n            raise ValueError(msg)\n        self._fix_defaults()\n        self.options._src = \"cli\"  # noqa: SLF001\n        try:\n            namespace.env = self.env\n            return super().parse_known_args(args, namespace=namespace)\n        finally:\n            self.options._src = None  # noqa: SLF001\n\n\nclass HelpFormatter(ArgumentDefaultsHelpFormatter):\n    def __init__(self, prog) -> None:\n        super().__init__(prog, max_help_position=32, width=240)\n\n    def _get_help_string(self, action):\n        text = super()._get_help_string(action)\n        if hasattr(action, \"default_source\"):\n            default = \" (default: %(default)s)\"\n            if text.endswith(default):\n                text = f\"{text[: -len(default)]} (default: %(default)s -> from %(default_source)s)\"\n        return text\n\n\n__all__ = [\n    \"HelpFormatter\",\n    \"VirtualEnvConfigParser\",\n    \"VirtualEnvOptions\",\n]\n"}