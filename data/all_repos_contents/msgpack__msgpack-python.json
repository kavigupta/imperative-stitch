{"setup.py": "#!/usr/bin/env python\nimport os\nimport sys\n\nfrom setuptools import Extension, setup\n\nPYPY = hasattr(sys, \"pypy_version_info\")\n\nlibraries = []\nmacros = []\next_modules = []\n\nif sys.platform == \"win32\":\n    libraries.append(\"ws2_32\")\n    macros = [(\"__LITTLE_ENDIAN__\", \"1\")]\n\nif not PYPY and not os.environ.get(\"MSGPACK_PUREPYTHON\"):\n    ext_modules.append(\n        Extension(\n            \"msgpack._cmsgpack\",\n            sources=[\"msgpack/_cmsgpack.c\"],\n            libraries=libraries,\n            include_dirs=[\".\"],\n            define_macros=macros,\n        )\n    )\ndel libraries, macros\n\nsetup(\n    ext_modules=ext_modules,\n    packages=[\"msgpack\"],\n)\n", "test/test_limits.py": "#!/usr/bin/env python\nimport pytest\n\nfrom msgpack import (\n    ExtType,\n    Packer,\n    PackOverflowError,\n    PackValueError,\n    Unpacker,\n    UnpackValueError,\n    packb,\n    unpackb,\n)\n\n\ndef test_integer():\n    x = -(2**63)\n    assert unpackb(packb(x)) == x\n    with pytest.raises(PackOverflowError):\n        packb(x - 1)\n\n    x = 2**64 - 1\n    assert unpackb(packb(x)) == x\n    with pytest.raises(PackOverflowError):\n        packb(x + 1)\n\n\ndef test_array_header():\n    packer = Packer()\n    packer.pack_array_header(2**32 - 1)\n    with pytest.raises(PackValueError):\n        packer.pack_array_header(2**32)\n\n\ndef test_map_header():\n    packer = Packer()\n    packer.pack_map_header(2**32 - 1)\n    with pytest.raises(PackValueError):\n        packer.pack_array_header(2**32)\n\n\ndef test_max_str_len():\n    d = \"x\" * 3\n    packed = packb(d)\n\n    unpacker = Unpacker(max_str_len=3, raw=False)\n    unpacker.feed(packed)\n    assert unpacker.unpack() == d\n\n    unpacker = Unpacker(max_str_len=2, raw=False)\n    with pytest.raises(UnpackValueError):\n        unpacker.feed(packed)\n        unpacker.unpack()\n\n\ndef test_max_bin_len():\n    d = b\"x\" * 3\n    packed = packb(d, use_bin_type=True)\n\n    unpacker = Unpacker(max_bin_len=3)\n    unpacker.feed(packed)\n    assert unpacker.unpack() == d\n\n    unpacker = Unpacker(max_bin_len=2)\n    with pytest.raises(UnpackValueError):\n        unpacker.feed(packed)\n        unpacker.unpack()\n\n\ndef test_max_array_len():\n    d = [1, 2, 3]\n    packed = packb(d)\n\n    unpacker = Unpacker(max_array_len=3)\n    unpacker.feed(packed)\n    assert unpacker.unpack() == d\n\n    unpacker = Unpacker(max_array_len=2)\n    with pytest.raises(UnpackValueError):\n        unpacker.feed(packed)\n        unpacker.unpack()\n\n\ndef test_max_map_len():\n    d = {1: 2, 3: 4, 5: 6}\n    packed = packb(d)\n\n    unpacker = Unpacker(max_map_len=3, strict_map_key=False)\n    unpacker.feed(packed)\n    assert unpacker.unpack() == d\n\n    unpacker = Unpacker(max_map_len=2, strict_map_key=False)\n    with pytest.raises(UnpackValueError):\n        unpacker.feed(packed)\n        unpacker.unpack()\n\n\ndef test_max_ext_len():\n    d = ExtType(42, b\"abc\")\n    packed = packb(d)\n\n    unpacker = Unpacker(max_ext_len=3)\n    unpacker.feed(packed)\n    assert unpacker.unpack() == d\n\n    unpacker = Unpacker(max_ext_len=2)\n    with pytest.raises(UnpackValueError):\n        unpacker.feed(packed)\n        unpacker.unpack()\n\n\n# PyPy fails following tests because of constant folding?\n# https://bugs.pypy.org/issue1721\n# @pytest.mark.skipif(True, reason=\"Requires very large memory.\")\n# def test_binary():\n#    x = b'x' * (2**32 - 1)\n#    assert unpackb(packb(x)) == x\n#    del x\n#    x = b'x' * (2**32)\n#    with pytest.raises(ValueError):\n#        packb(x)\n#\n#\n# @pytest.mark.skipif(True, reason=\"Requires very large memory.\")\n# def test_string():\n#    x = 'x' * (2**32 - 1)\n#    assert unpackb(packb(x)) == x\n#    x += 'y'\n#    with pytest.raises(ValueError):\n#        packb(x)\n#\n#\n# @pytest.mark.skipif(True, reason=\"Requires very large memory.\")\n# def test_array():\n#    x = [0] * (2**32 - 1)\n#    assert unpackb(packb(x)) == x\n#    x.append(0)\n#    with pytest.raises(ValueError):\n#        packb(x)\n\n\n# auto max len\n\n\ndef test_auto_max_array_len():\n    packed = b\"\\xde\\x00\\x06zz\"\n    with pytest.raises(UnpackValueError):\n        unpackb(packed, raw=False)\n\n    unpacker = Unpacker(max_buffer_size=5, raw=False)\n    unpacker.feed(packed)\n    with pytest.raises(UnpackValueError):\n        unpacker.unpack()\n\n\ndef test_auto_max_map_len():\n    # len(packed) == 6 -> max_map_len == 3\n    packed = b\"\\xde\\x00\\x04zzz\"\n    with pytest.raises(UnpackValueError):\n        unpackb(packed, raw=False)\n\n    unpacker = Unpacker(max_buffer_size=6, raw=False)\n    unpacker.feed(packed)\n    with pytest.raises(UnpackValueError):\n        unpacker.unpack()\n", "test/test_sequnpack.py": "#!/usr/bin/env python\nimport io\n\nfrom pytest import raises\n\nfrom msgpack import BufferFull, Unpacker, pack, packb\nfrom msgpack.exceptions import OutOfData\n\n\ndef test_partialdata():\n    unpacker = Unpacker()\n    unpacker.feed(b\"\\xa5\")\n    with raises(StopIteration):\n        next(iter(unpacker))\n    unpacker.feed(b\"h\")\n    with raises(StopIteration):\n        next(iter(unpacker))\n    unpacker.feed(b\"a\")\n    with raises(StopIteration):\n        next(iter(unpacker))\n    unpacker.feed(b\"l\")\n    with raises(StopIteration):\n        next(iter(unpacker))\n    unpacker.feed(b\"l\")\n    with raises(StopIteration):\n        next(iter(unpacker))\n    unpacker.feed(b\"o\")\n    assert next(iter(unpacker)) == \"hallo\"\n\n\ndef test_foobar():\n    unpacker = Unpacker(read_size=3, use_list=1)\n    unpacker.feed(b\"foobar\")\n    assert unpacker.unpack() == ord(b\"f\")\n    assert unpacker.unpack() == ord(b\"o\")\n    assert unpacker.unpack() == ord(b\"o\")\n    assert unpacker.unpack() == ord(b\"b\")\n    assert unpacker.unpack() == ord(b\"a\")\n    assert unpacker.unpack() == ord(b\"r\")\n    with raises(OutOfData):\n        unpacker.unpack()\n\n    unpacker.feed(b\"foo\")\n    unpacker.feed(b\"bar\")\n\n    k = 0\n    for o, e in zip(unpacker, \"foobarbaz\"):\n        assert o == ord(e)\n        k += 1\n    assert k == len(b\"foobar\")\n\n\ndef test_foobar_skip():\n    unpacker = Unpacker(read_size=3, use_list=1)\n    unpacker.feed(b\"foobar\")\n    assert unpacker.unpack() == ord(b\"f\")\n    unpacker.skip()\n    assert unpacker.unpack() == ord(b\"o\")\n    unpacker.skip()\n    assert unpacker.unpack() == ord(b\"a\")\n    unpacker.skip()\n    with raises(OutOfData):\n        unpacker.unpack()\n\n\ndef test_maxbuffersize():\n    with raises(ValueError):\n        Unpacker(read_size=5, max_buffer_size=3)\n    unpacker = Unpacker(read_size=3, max_buffer_size=3, use_list=1)\n    unpacker.feed(b\"fo\")\n    with raises(BufferFull):\n        unpacker.feed(b\"ob\")\n    unpacker.feed(b\"o\")\n    assert ord(\"f\") == next(unpacker)\n    unpacker.feed(b\"b\")\n    assert ord(\"o\") == next(unpacker)\n    assert ord(\"o\") == next(unpacker)\n    assert ord(\"b\") == next(unpacker)\n\n\ndef test_maxbuffersize_file():\n    buff = io.BytesIO(packb(b\"a\" * 10) + packb([b\"a\" * 20] * 2))\n    unpacker = Unpacker(buff, read_size=1, max_buffer_size=19, max_bin_len=20)\n    assert unpacker.unpack() == b\"a\" * 10\n    # assert unpacker.unpack() == [b\"a\" * 20]*2\n    with raises(BufferFull):\n        print(unpacker.unpack())\n\n\ndef test_readbytes():\n    unpacker = Unpacker(read_size=3)\n    unpacker.feed(b\"foobar\")\n    assert unpacker.unpack() == ord(b\"f\")\n    assert unpacker.read_bytes(3) == b\"oob\"\n    assert unpacker.unpack() == ord(b\"a\")\n    assert unpacker.unpack() == ord(b\"r\")\n\n    # Test buffer refill\n    unpacker = Unpacker(io.BytesIO(b\"foobar\"), read_size=3)\n    assert unpacker.unpack() == ord(b\"f\")\n    assert unpacker.read_bytes(3) == b\"oob\"\n    assert unpacker.unpack() == ord(b\"a\")\n    assert unpacker.unpack() == ord(b\"r\")\n\n    # Issue 352\n    u = Unpacker()\n    u.feed(b\"x\")\n    assert bytes(u.read_bytes(1)) == b\"x\"\n    with raises(StopIteration):\n        next(u)\n    u.feed(b\"\\1\")\n    assert next(u) == 1\n\n\ndef test_issue124():\n    unpacker = Unpacker()\n    unpacker.feed(b\"\\xa1?\\xa1!\")\n    assert tuple(unpacker) == (\"?\", \"!\")\n    assert tuple(unpacker) == ()\n    unpacker.feed(b\"\\xa1?\\xa1\")\n    assert tuple(unpacker) == (\"?\",)\n    assert tuple(unpacker) == ()\n    unpacker.feed(b\"!\")\n    assert tuple(unpacker) == (\"!\",)\n    assert tuple(unpacker) == ()\n\n\ndef test_unpack_tell():\n    stream = io.BytesIO()\n    messages = [2**i - 1 for i in range(65)]\n    messages += [-(2**i) for i in range(1, 64)]\n    messages += [\n        b\"hello\",\n        b\"hello\" * 1000,\n        list(range(20)),\n        {i: bytes(i) * i for i in range(10)},\n        {i: bytes(i) * i for i in range(32)},\n    ]\n    offsets = []\n    for m in messages:\n        pack(m, stream)\n        offsets.append(stream.tell())\n    stream.seek(0)\n    unpacker = Unpacker(stream, strict_map_key=False)\n    for m, o in zip(messages, offsets):\n        m2 = next(unpacker)\n        assert m == m2\n        assert o == unpacker.tell()\n", "test/test_format.py": "#!/usr/bin/env python\n\nfrom msgpack import unpackb\n\n\ndef check(src, should, use_list=0, raw=True):\n    assert unpackb(src, use_list=use_list, raw=raw, strict_map_key=False) == should\n\n\ndef testSimpleValue():\n    check(b\"\\x93\\xc0\\xc2\\xc3\", (None, False, True))\n\n\ndef testFixnum():\n    check(b\"\\x92\\x93\\x00\\x40\\x7f\\x93\\xe0\\xf0\\xff\", ((0, 64, 127), (-32, -16, -1)))\n\n\ndef testFixArray():\n    check(b\"\\x92\\x90\\x91\\x91\\xc0\", ((), ((None,),)))\n\n\ndef testFixRaw():\n    check(b\"\\x94\\xa0\\xa1a\\xa2bc\\xa3def\", (b\"\", b\"a\", b\"bc\", b\"def\"))\n\n\ndef testFixMap():\n    check(b\"\\x82\\xc2\\x81\\xc0\\xc0\\xc3\\x81\\xc0\\x80\", {False: {None: None}, True: {None: {}}})\n\n\ndef testUnsignedInt():\n    check(\n        b\"\\x99\\xcc\\x00\\xcc\\x80\\xcc\\xff\\xcd\\x00\\x00\\xcd\\x80\\x00\"\n        b\"\\xcd\\xff\\xff\\xce\\x00\\x00\\x00\\x00\\xce\\x80\\x00\\x00\\x00\"\n        b\"\\xce\\xff\\xff\\xff\\xff\",\n        (0, 128, 255, 0, 32768, 65535, 0, 2147483648, 4294967295),\n    )\n\n\ndef testSignedInt():\n    check(\n        b\"\\x99\\xd0\\x00\\xd0\\x80\\xd0\\xff\\xd1\\x00\\x00\\xd1\\x80\\x00\"\n        b\"\\xd1\\xff\\xff\\xd2\\x00\\x00\\x00\\x00\\xd2\\x80\\x00\\x00\\x00\"\n        b\"\\xd2\\xff\\xff\\xff\\xff\",\n        (0, -128, -1, 0, -32768, -1, 0, -2147483648, -1),\n    )\n\n\ndef testRaw():\n    check(\n        b\"\\x96\\xda\\x00\\x00\\xda\\x00\\x01a\\xda\\x00\\x02ab\\xdb\\x00\\x00\"\n        b\"\\x00\\x00\\xdb\\x00\\x00\\x00\\x01a\\xdb\\x00\\x00\\x00\\x02ab\",\n        (b\"\", b\"a\", b\"ab\", b\"\", b\"a\", b\"ab\"),\n    )\n    check(\n        b\"\\x96\\xda\\x00\\x00\\xda\\x00\\x01a\\xda\\x00\\x02ab\\xdb\\x00\\x00\"\n        b\"\\x00\\x00\\xdb\\x00\\x00\\x00\\x01a\\xdb\\x00\\x00\\x00\\x02ab\",\n        (\"\", \"a\", \"ab\", \"\", \"a\", \"ab\"),\n        raw=False,\n    )\n\n\ndef testArray():\n    check(\n        b\"\\x96\\xdc\\x00\\x00\\xdc\\x00\\x01\\xc0\\xdc\\x00\\x02\\xc2\\xc3\\xdd\\x00\"\n        b\"\\x00\\x00\\x00\\xdd\\x00\\x00\\x00\\x01\\xc0\\xdd\\x00\\x00\\x00\\x02\"\n        b\"\\xc2\\xc3\",\n        ((), (None,), (False, True), (), (None,), (False, True)),\n    )\n\n\ndef testMap():\n    check(\n        b\"\\x96\"\n        b\"\\xde\\x00\\x00\"\n        b\"\\xde\\x00\\x01\\xc0\\xc2\"\n        b\"\\xde\\x00\\x02\\xc0\\xc2\\xc3\\xc2\"\n        b\"\\xdf\\x00\\x00\\x00\\x00\"\n        b\"\\xdf\\x00\\x00\\x00\\x01\\xc0\\xc2\"\n        b\"\\xdf\\x00\\x00\\x00\\x02\\xc0\\xc2\\xc3\\xc2\",\n        (\n            {},\n            {None: False},\n            {True: False, None: False},\n            {},\n            {None: False},\n            {True: False, None: False},\n        ),\n    )\n", "test/test_extension.py": "import array\n\nimport msgpack\nfrom msgpack import ExtType\n\n\ndef test_pack_ext_type():\n    def p(s):\n        packer = msgpack.Packer()\n        packer.pack_ext_type(0x42, s)\n        return packer.bytes()\n\n    assert p(b\"A\") == b\"\\xd4\\x42A\"  # fixext 1\n    assert p(b\"AB\") == b\"\\xd5\\x42AB\"  # fixext 2\n    assert p(b\"ABCD\") == b\"\\xd6\\x42ABCD\"  # fixext 4\n    assert p(b\"ABCDEFGH\") == b\"\\xd7\\x42ABCDEFGH\"  # fixext 8\n    assert p(b\"A\" * 16) == b\"\\xd8\\x42\" + b\"A\" * 16  # fixext 16\n    assert p(b\"ABC\") == b\"\\xc7\\x03\\x42ABC\"  # ext 8\n    assert p(b\"A\" * 0x0123) == b\"\\xc8\\x01\\x23\\x42\" + b\"A\" * 0x0123  # ext 16\n    assert p(b\"A\" * 0x00012345) == b\"\\xc9\\x00\\x01\\x23\\x45\\x42\" + b\"A\" * 0x00012345  # ext 32\n\n\ndef test_unpack_ext_type():\n    def check(b, expected):\n        assert msgpack.unpackb(b) == expected\n\n    check(b\"\\xd4\\x42A\", ExtType(0x42, b\"A\"))  # fixext 1\n    check(b\"\\xd5\\x42AB\", ExtType(0x42, b\"AB\"))  # fixext 2\n    check(b\"\\xd6\\x42ABCD\", ExtType(0x42, b\"ABCD\"))  # fixext 4\n    check(b\"\\xd7\\x42ABCDEFGH\", ExtType(0x42, b\"ABCDEFGH\"))  # fixext 8\n    check(b\"\\xd8\\x42\" + b\"A\" * 16, ExtType(0x42, b\"A\" * 16))  # fixext 16\n    check(b\"\\xc7\\x03\\x42ABC\", ExtType(0x42, b\"ABC\"))  # ext 8\n    check(b\"\\xc8\\x01\\x23\\x42\" + b\"A\" * 0x0123, ExtType(0x42, b\"A\" * 0x0123))  # ext 16\n    check(\n        b\"\\xc9\\x00\\x01\\x23\\x45\\x42\" + b\"A\" * 0x00012345,\n        ExtType(0x42, b\"A\" * 0x00012345),\n    )  # ext 32\n\n\ndef test_extension_type():\n    def default(obj):\n        print(\"default called\", obj)\n        if isinstance(obj, array.array):\n            typecode = 123  # application specific typecode\n            try:\n                data = obj.tobytes()\n            except AttributeError:\n                data = obj.tostring()\n            return ExtType(typecode, data)\n        raise TypeError(f\"Unknown type object {obj!r}\")\n\n    def ext_hook(code, data):\n        print(\"ext_hook called\", code, data)\n        assert code == 123\n        obj = array.array(\"d\")\n        obj.frombytes(data)\n        return obj\n\n    obj = [42, b\"hello\", array.array(\"d\", [1.1, 2.2, 3.3])]\n    s = msgpack.packb(obj, default=default)\n    obj2 = msgpack.unpackb(s, ext_hook=ext_hook)\n    assert obj == obj2\n\n\ndef test_overriding_hooks():\n    def default(obj):\n        if isinstance(obj, int):\n            return {\"__type__\": \"long\", \"__data__\": str(obj)}\n        else:\n            return obj\n\n    obj = {\"testval\": 1823746192837461928374619}\n    refobj = {\"testval\": default(obj[\"testval\"])}\n    refout = msgpack.packb(refobj)\n    assert isinstance(refout, (str, bytes))\n    testout = msgpack.packb(obj, default=default)\n\n    assert refout == testout\n", "test/test_pack.py": "#!/usr/bin/env python\n\nimport struct\nfrom collections import OrderedDict\nfrom io import BytesIO\n\nimport pytest\n\nfrom msgpack import Packer, Unpacker, packb, unpackb\n\n\ndef check(data, use_list=False):\n    re = unpackb(packb(data), use_list=use_list, strict_map_key=False)\n    assert re == data\n\n\ndef testPack():\n    test_data = [\n        0,\n        1,\n        127,\n        128,\n        255,\n        256,\n        65535,\n        65536,\n        4294967295,\n        4294967296,\n        -1,\n        -32,\n        -33,\n        -128,\n        -129,\n        -32768,\n        -32769,\n        -4294967296,\n        -4294967297,\n        1.0,\n        b\"\",\n        b\"a\",\n        b\"a\" * 31,\n        b\"a\" * 32,\n        None,\n        True,\n        False,\n        (),\n        ((),),\n        ((), None),\n        {None: 0},\n        (1 << 23),\n    ]\n    for td in test_data:\n        check(td)\n\n\ndef testPackUnicode():\n    test_data = [\"\", \"abcd\", [\"defgh\"], \"\u0420\u0443\u0441\u0441\u043a\u0438\u0439 \u0442\u0435\u043a\u0441\u0442\"]\n    for td in test_data:\n        re = unpackb(packb(td), use_list=1, raw=False)\n        assert re == td\n        packer = Packer()\n        data = packer.pack(td)\n        re = Unpacker(BytesIO(data), raw=False, use_list=1).unpack()\n        assert re == td\n\n\ndef testPackBytes():\n    test_data = [b\"\", b\"abcd\", (b\"defgh\",)]\n    for td in test_data:\n        check(td)\n\n\ndef testPackByteArrays():\n    test_data = [bytearray(b\"\"), bytearray(b\"abcd\"), (bytearray(b\"defgh\"),)]\n    for td in test_data:\n        check(td)\n\n\ndef testIgnoreUnicodeErrors():\n    re = unpackb(packb(b\"abc\\xeddef\", use_bin_type=False), raw=False, unicode_errors=\"ignore\")\n    assert re == \"abcdef\"\n\n\ndef testStrictUnicodeUnpack():\n    packed = packb(b\"abc\\xeddef\", use_bin_type=False)\n    with pytest.raises(UnicodeDecodeError):\n        unpackb(packed, raw=False, use_list=1)\n\n\ndef testIgnoreErrorsPack():\n    re = unpackb(\n        packb(\"abc\\udc80\\udcffdef\", use_bin_type=True, unicode_errors=\"ignore\"),\n        raw=False,\n        use_list=1,\n    )\n    assert re == \"abcdef\"\n\n\ndef testDecodeBinary():\n    re = unpackb(packb(b\"abc\"), use_list=1)\n    assert re == b\"abc\"\n\n\ndef testPackFloat():\n    assert packb(1.0, use_single_float=True) == b\"\\xca\" + struct.pack(\">f\", 1.0)\n    assert packb(1.0, use_single_float=False) == b\"\\xcb\" + struct.pack(\">d\", 1.0)\n\n\ndef testArraySize(sizes=[0, 5, 50, 1000]):\n    bio = BytesIO()\n    packer = Packer()\n    for size in sizes:\n        bio.write(packer.pack_array_header(size))\n        for i in range(size):\n            bio.write(packer.pack(i))\n\n    bio.seek(0)\n    unpacker = Unpacker(bio, use_list=1)\n    for size in sizes:\n        assert unpacker.unpack() == list(range(size))\n\n\ndef test_manualreset(sizes=[0, 5, 50, 1000]):\n    packer = Packer(autoreset=False)\n    for size in sizes:\n        packer.pack_array_header(size)\n        for i in range(size):\n            packer.pack(i)\n\n    bio = BytesIO(packer.bytes())\n    unpacker = Unpacker(bio, use_list=1)\n    for size in sizes:\n        assert unpacker.unpack() == list(range(size))\n\n    packer.reset()\n    assert packer.bytes() == b\"\"\n\n\ndef testMapSize(sizes=[0, 5, 50, 1000]):\n    bio = BytesIO()\n    packer = Packer()\n    for size in sizes:\n        bio.write(packer.pack_map_header(size))\n        for i in range(size):\n            bio.write(packer.pack(i))  # key\n            bio.write(packer.pack(i * 2))  # value\n\n    bio.seek(0)\n    unpacker = Unpacker(bio, strict_map_key=False)\n    for size in sizes:\n        assert unpacker.unpack() == {i: i * 2 for i in range(size)}\n\n\ndef test_odict():\n    seq = [(b\"one\", 1), (b\"two\", 2), (b\"three\", 3), (b\"four\", 4)]\n    od = OrderedDict(seq)\n    assert unpackb(packb(od), use_list=1) == dict(seq)\n\n    def pair_hook(seq):\n        return list(seq)\n\n    assert unpackb(packb(od), object_pairs_hook=pair_hook, use_list=1) == seq\n\n\ndef test_pairlist():\n    pairlist = [(b\"a\", 1), (2, b\"b\"), (b\"foo\", b\"bar\")]\n    packer = Packer()\n    packed = packer.pack_map_pairs(pairlist)\n    unpacked = unpackb(packed, object_pairs_hook=list, strict_map_key=False)\n    assert pairlist == unpacked\n\n\ndef test_get_buffer():\n    packer = Packer(autoreset=0, use_bin_type=True)\n    packer.pack([1, 2])\n    strm = BytesIO()\n    strm.write(packer.getbuffer())\n    written = strm.getvalue()\n\n    expected = packb([1, 2], use_bin_type=True)\n    assert written == expected\n", "test/test_buffer.py": "from pytest import raises\n\nfrom msgpack import Packer, packb, unpackb\n\n\ndef test_unpack_buffer():\n    from array import array\n\n    buf = array(\"b\")\n    buf.frombytes(packb((b\"foo\", b\"bar\")))\n    obj = unpackb(buf, use_list=1)\n    assert [b\"foo\", b\"bar\"] == obj\n\n\ndef test_unpack_bytearray():\n    buf = bytearray(packb((b\"foo\", b\"bar\")))\n    obj = unpackb(buf, use_list=1)\n    assert [b\"foo\", b\"bar\"] == obj\n    expected_type = bytes\n    assert all(type(s) == expected_type for s in obj)\n\n\ndef test_unpack_memoryview():\n    buf = bytearray(packb((b\"foo\", b\"bar\")))\n    view = memoryview(buf)\n    obj = unpackb(view, use_list=1)\n    assert [b\"foo\", b\"bar\"] == obj\n    expected_type = bytes\n    assert all(type(s) == expected_type for s in obj)\n\n\ndef test_packer_getbuffer():\n    packer = Packer(autoreset=False)\n    packer.pack_array_header(2)\n    packer.pack(42)\n    packer.pack(\"hello\")\n    buffer = packer.getbuffer()\n    assert isinstance(buffer, memoryview)\n    assert bytes(buffer) == b\"\\x92*\\xa5hello\"\n\n    if Packer.__module__ == \"msgpack._cmsgpack\":  # only for Cython\n        # cython Packer supports buffer protocol directly\n        assert bytes(packer) == b\"\\x92*\\xa5hello\"\n\n        with raises(BufferError):\n            packer.pack(42)\n        buffer.release()\n        packer.pack(42)\n        assert bytes(packer) == b\"\\x92*\\xa5hello*\"\n", "test/test_memoryview.py": "#!/usr/bin/env python\n\nfrom array import array\n\nfrom msgpack import packb, unpackb\n\n\ndef make_array(f, data):\n    a = array(f)\n    a.frombytes(data)\n    return a\n\n\ndef _runtest(format, nbytes, expected_header, expected_prefix, use_bin_type):\n    # create a new array\n    original_array = array(format)\n    original_array.fromlist([255] * (nbytes // original_array.itemsize))\n    original_data = original_array.tobytes()\n    view = memoryview(original_array)\n\n    # pack, unpack, and reconstruct array\n    packed = packb(view, use_bin_type=use_bin_type)\n    unpacked = unpackb(packed, raw=(not use_bin_type))\n    reconstructed_array = make_array(format, unpacked)\n\n    # check that we got the right amount of data\n    assert len(original_data) == nbytes\n    # check packed header\n    assert packed[:1] == expected_header\n    # check packed length prefix, if any\n    assert packed[1 : 1 + len(expected_prefix)] == expected_prefix\n    # check packed data\n    assert packed[1 + len(expected_prefix) :] == original_data\n    # check array unpacked correctly\n    assert original_array == reconstructed_array\n\n\ndef test_fixstr_from_byte():\n    _runtest(\"B\", 1, b\"\\xa1\", b\"\", False)\n    _runtest(\"B\", 31, b\"\\xbf\", b\"\", False)\n\n\ndef test_fixstr_from_float():\n    _runtest(\"f\", 4, b\"\\xa4\", b\"\", False)\n    _runtest(\"f\", 28, b\"\\xbc\", b\"\", False)\n\n\ndef test_str16_from_byte():\n    _runtest(\"B\", 2**8, b\"\\xda\", b\"\\x01\\x00\", False)\n    _runtest(\"B\", 2**16 - 1, b\"\\xda\", b\"\\xff\\xff\", False)\n\n\ndef test_str16_from_float():\n    _runtest(\"f\", 2**8, b\"\\xda\", b\"\\x01\\x00\", False)\n    _runtest(\"f\", 2**16 - 4, b\"\\xda\", b\"\\xff\\xfc\", False)\n\n\ndef test_str32_from_byte():\n    _runtest(\"B\", 2**16, b\"\\xdb\", b\"\\x00\\x01\\x00\\x00\", False)\n\n\ndef test_str32_from_float():\n    _runtest(\"f\", 2**16, b\"\\xdb\", b\"\\x00\\x01\\x00\\x00\", False)\n\n\ndef test_bin8_from_byte():\n    _runtest(\"B\", 1, b\"\\xc4\", b\"\\x01\", True)\n    _runtest(\"B\", 2**8 - 1, b\"\\xc4\", b\"\\xff\", True)\n\n\ndef test_bin8_from_float():\n    _runtest(\"f\", 4, b\"\\xc4\", b\"\\x04\", True)\n    _runtest(\"f\", 2**8 - 4, b\"\\xc4\", b\"\\xfc\", True)\n\n\ndef test_bin16_from_byte():\n    _runtest(\"B\", 2**8, b\"\\xc5\", b\"\\x01\\x00\", True)\n    _runtest(\"B\", 2**16 - 1, b\"\\xc5\", b\"\\xff\\xff\", True)\n\n\ndef test_bin16_from_float():\n    _runtest(\"f\", 2**8, b\"\\xc5\", b\"\\x01\\x00\", True)\n    _runtest(\"f\", 2**16 - 4, b\"\\xc5\", b\"\\xff\\xfc\", True)\n\n\ndef test_bin32_from_byte():\n    _runtest(\"B\", 2**16, b\"\\xc6\", b\"\\x00\\x01\\x00\\x00\", True)\n\n\ndef test_bin32_from_float():\n    _runtest(\"f\", 2**16, b\"\\xc6\", b\"\\x00\\x01\\x00\\x00\", True)\n\n\ndef test_multidim_memoryview():\n    # See https://github.com/msgpack/msgpack-python/issues/526\n    view = memoryview(b\"\\00\" * 6)\n    data = view.cast(view.format, (3, 2))\n    packed = packb(data)\n    assert packed == b\"\\xc4\\x06\\x00\\x00\\x00\\x00\\x00\\x00\"\n", "test/test_except.py": "#!/usr/bin/env python\n\nimport datetime\n\nfrom pytest import raises\n\nfrom msgpack import FormatError, OutOfData, StackError, Unpacker, packb, unpackb\n\n\nclass DummyException(Exception):\n    pass\n\n\ndef test_raise_on_find_unsupported_value():\n    with raises(TypeError):\n        packb(datetime.datetime.now())\n\n\ndef test_raise_from_object_hook():\n    def hook(obj):\n        raise DummyException\n\n    raises(DummyException, unpackb, packb({}), object_hook=hook)\n    raises(DummyException, unpackb, packb({\"fizz\": \"buzz\"}), object_hook=hook)\n    raises(DummyException, unpackb, packb({\"fizz\": \"buzz\"}), object_pairs_hook=hook)\n    raises(DummyException, unpackb, packb({\"fizz\": {\"buzz\": \"spam\"}}), object_hook=hook)\n    raises(\n        DummyException,\n        unpackb,\n        packb({\"fizz\": {\"buzz\": \"spam\"}}),\n        object_pairs_hook=hook,\n    )\n\n\ndef test_invalidvalue():\n    incomplete = b\"\\xd9\\x97#DL_\"  # raw8 - length=0x97\n    with raises(ValueError):\n        unpackb(incomplete)\n\n    with raises(OutOfData):\n        unpacker = Unpacker()\n        unpacker.feed(incomplete)\n        unpacker.unpack()\n\n    with raises(FormatError):\n        unpackb(b\"\\xc1\")  # (undefined tag)\n\n    with raises(FormatError):\n        unpackb(b\"\\x91\\xc1\")  # fixarray(len=1) [ (undefined tag) ]\n\n    with raises(StackError):\n        unpackb(b\"\\x91\" * 3000)  # nested fixarray(len=1)\n\n\ndef test_strict_map_key():\n    valid = {\"unicode\": 1, b\"bytes\": 2}\n    packed = packb(valid, use_bin_type=True)\n    assert valid == unpackb(packed, raw=False, strict_map_key=True)\n\n    invalid = {42: 1}\n    packed = packb(invalid, use_bin_type=True)\n    with raises(ValueError):\n        unpackb(packed, raw=False, strict_map_key=True)\n", "test/test_newspec.py": "from msgpack import ExtType, packb, unpackb\n\n\ndef test_str8():\n    header = b\"\\xd9\"\n    data = b\"x\" * 32\n    b = packb(data.decode(), use_bin_type=True)\n    assert len(b) == len(data) + 2\n    assert b[0:2] == header + b\"\\x20\"\n    assert b[2:] == data\n    assert unpackb(b, raw=True) == data\n    assert unpackb(b, raw=False) == data.decode()\n\n    data = b\"x\" * 255\n    b = packb(data.decode(), use_bin_type=True)\n    assert len(b) == len(data) + 2\n    assert b[0:2] == header + b\"\\xff\"\n    assert b[2:] == data\n    assert unpackb(b, raw=True) == data\n    assert unpackb(b, raw=False) == data.decode()\n\n\ndef test_bin8():\n    header = b\"\\xc4\"\n    data = b\"\"\n    b = packb(data, use_bin_type=True)\n    assert len(b) == len(data) + 2\n    assert b[0:2] == header + b\"\\x00\"\n    assert b[2:] == data\n    assert unpackb(b) == data\n\n    data = b\"x\" * 255\n    b = packb(data, use_bin_type=True)\n    assert len(b) == len(data) + 2\n    assert b[0:2] == header + b\"\\xff\"\n    assert b[2:] == data\n    assert unpackb(b) == data\n\n\ndef test_bin16():\n    header = b\"\\xc5\"\n    data = b\"x\" * 256\n    b = packb(data, use_bin_type=True)\n    assert len(b) == len(data) + 3\n    assert b[0:1] == header\n    assert b[1:3] == b\"\\x01\\x00\"\n    assert b[3:] == data\n    assert unpackb(b) == data\n\n    data = b\"x\" * 65535\n    b = packb(data, use_bin_type=True)\n    assert len(b) == len(data) + 3\n    assert b[0:1] == header\n    assert b[1:3] == b\"\\xff\\xff\"\n    assert b[3:] == data\n    assert unpackb(b) == data\n\n\ndef test_bin32():\n    header = b\"\\xc6\"\n    data = b\"x\" * 65536\n    b = packb(data, use_bin_type=True)\n    assert len(b) == len(data) + 5\n    assert b[0:1] == header\n    assert b[1:5] == b\"\\x00\\x01\\x00\\x00\"\n    assert b[5:] == data\n    assert unpackb(b) == data\n\n\ndef test_ext():\n    def check(ext, packed):\n        assert packb(ext) == packed\n        assert unpackb(packed) == ext\n\n    check(ExtType(0x42, b\"Z\"), b\"\\xd4\\x42Z\")  # fixext 1\n    check(ExtType(0x42, b\"ZZ\"), b\"\\xd5\\x42ZZ\")  # fixext 2\n    check(ExtType(0x42, b\"Z\" * 4), b\"\\xd6\\x42\" + b\"Z\" * 4)  # fixext 4\n    check(ExtType(0x42, b\"Z\" * 8), b\"\\xd7\\x42\" + b\"Z\" * 8)  # fixext 8\n    check(ExtType(0x42, b\"Z\" * 16), b\"\\xd8\\x42\" + b\"Z\" * 16)  # fixext 16\n    # ext 8\n    check(ExtType(0x42, b\"\"), b\"\\xc7\\x00\\x42\")\n    check(ExtType(0x42, b\"Z\" * 255), b\"\\xc7\\xff\\x42\" + b\"Z\" * 255)\n    # ext 16\n    check(ExtType(0x42, b\"Z\" * 256), b\"\\xc8\\x01\\x00\\x42\" + b\"Z\" * 256)\n    check(ExtType(0x42, b\"Z\" * 0xFFFF), b\"\\xc8\\xff\\xff\\x42\" + b\"Z\" * 0xFFFF)\n    # ext 32\n    check(ExtType(0x42, b\"Z\" * 0x10000), b\"\\xc9\\x00\\x01\\x00\\x00\\x42\" + b\"Z\" * 0x10000)\n    # needs large memory\n    # check(ExtType(0x42, b'Z'*0xffffffff),\n    #              b'\\xc9\\xff\\xff\\xff\\xff\\x42' + b'Z'*0xffffffff)\n", "test/test_seq.py": "# ruff: noqa: E501\n# ignore line length limit for long comments\nimport io\n\nimport msgpack\n\nbinarydata = bytes(bytearray(range(256)))\n\n\ndef gen_binary_data(idx):\n    return binarydata[: idx % 300]\n\n\ndef test_exceeding_unpacker_read_size():\n    dumpf = io.BytesIO()\n\n    packer = msgpack.Packer()\n\n    NUMBER_OF_STRINGS = 6\n    read_size = 16\n    # 5 ok for read_size=16, while 6 glibc detected *** python: double free or corruption (fasttop):\n    # 20 ok for read_size=256, while 25 segfaults / glibc detected *** python: double free or corruption (!prev)\n    # 40 ok for read_size=1024, while 50 introduces errors\n    # 7000 ok for read_size=1024*1024, while 8000 leads to  glibc detected *** python: double free or corruption (!prev):\n\n    for idx in range(NUMBER_OF_STRINGS):\n        data = gen_binary_data(idx)\n        dumpf.write(packer.pack(data))\n\n    f = io.BytesIO(dumpf.getvalue())\n    dumpf.close()\n\n    unpacker = msgpack.Unpacker(f, read_size=read_size, use_list=1)\n\n    read_count = 0\n    for idx, o in enumerate(unpacker):\n        assert isinstance(o, bytes)\n        assert o == gen_binary_data(idx)\n        read_count += 1\n\n    assert read_count == NUMBER_OF_STRINGS\n", "test/test_read_size.py": "\"\"\"Test Unpacker's read_array_header and read_map_header methods\"\"\"\n\nfrom msgpack import OutOfData, Unpacker, packb\n\nUnexpectedTypeException = ValueError\n\n\ndef test_read_array_header():\n    unpacker = Unpacker()\n    unpacker.feed(packb([\"a\", \"b\", \"c\"]))\n    assert unpacker.read_array_header() == 3\n    assert unpacker.unpack() == \"a\"\n    assert unpacker.unpack() == \"b\"\n    assert unpacker.unpack() == \"c\"\n    try:\n        unpacker.unpack()\n        assert 0, \"should raise exception\"\n    except OutOfData:\n        assert 1, \"okay\"\n\n\ndef test_read_map_header():\n    unpacker = Unpacker()\n    unpacker.feed(packb({\"a\": \"A\"}))\n    assert unpacker.read_map_header() == 1\n    assert unpacker.unpack() == \"a\"\n    assert unpacker.unpack() == \"A\"\n    try:\n        unpacker.unpack()\n        assert 0, \"should raise exception\"\n    except OutOfData:\n        assert 1, \"okay\"\n\n\ndef test_incorrect_type_array():\n    unpacker = Unpacker()\n    unpacker.feed(packb(1))\n    try:\n        unpacker.read_array_header()\n        assert 0, \"should raise exception\"\n    except UnexpectedTypeException:\n        assert 1, \"okay\"\n\n\ndef test_incorrect_type_map():\n    unpacker = Unpacker()\n    unpacker.feed(packb(1))\n    try:\n        unpacker.read_map_header()\n        assert 0, \"should raise exception\"\n    except UnexpectedTypeException:\n        assert 1, \"okay\"\n\n\ndef test_correct_type_nested_array():\n    unpacker = Unpacker()\n    unpacker.feed(packb({\"a\": [\"b\", \"c\", \"d\"]}))\n    try:\n        unpacker.read_array_header()\n        assert 0, \"should raise exception\"\n    except UnexpectedTypeException:\n        assert 1, \"okay\"\n\n\ndef test_incorrect_type_nested_map():\n    unpacker = Unpacker()\n    unpacker.feed(packb([{\"a\": \"b\"}]))\n    try:\n        unpacker.read_map_header()\n        assert 0, \"should raise exception\"\n    except UnexpectedTypeException:\n        assert 1, \"okay\"\n", "test/test_stricttype.py": "from collections import namedtuple\n\nfrom msgpack import ExtType, packb, unpackb\n\n\ndef test_namedtuple():\n    T = namedtuple(\"T\", \"foo bar\")\n\n    def default(o):\n        if isinstance(o, T):\n            return dict(o._asdict())\n        raise TypeError(f\"Unsupported type {type(o)}\")\n\n    packed = packb(T(1, 42), strict_types=True, use_bin_type=True, default=default)\n    unpacked = unpackb(packed, raw=False)\n    assert unpacked == {\"foo\": 1, \"bar\": 42}\n\n\ndef test_tuple():\n    t = (\"one\", 2, b\"three\", (4,))\n\n    def default(o):\n        if isinstance(o, tuple):\n            return {\"__type__\": \"tuple\", \"value\": list(o)}\n        raise TypeError(f\"Unsupported type {type(o)}\")\n\n    def convert(o):\n        if o.get(\"__type__\") == \"tuple\":\n            return tuple(o[\"value\"])\n        return o\n\n    data = packb(t, strict_types=True, use_bin_type=True, default=default)\n    expected = unpackb(data, raw=False, object_hook=convert)\n\n    assert expected == t\n\n\ndef test_tuple_ext():\n    t = (\"one\", 2, b\"three\", (4,))\n\n    MSGPACK_EXT_TYPE_TUPLE = 0\n\n    def default(o):\n        if isinstance(o, tuple):\n            # Convert to list and pack\n            payload = packb(list(o), strict_types=True, use_bin_type=True, default=default)\n            return ExtType(MSGPACK_EXT_TYPE_TUPLE, payload)\n        raise TypeError(repr(o))\n\n    def convert(code, payload):\n        if code == MSGPACK_EXT_TYPE_TUPLE:\n            # Unpack and convert to tuple\n            return tuple(unpackb(payload, raw=False, ext_hook=convert))\n        raise ValueError(f\"Unknown Ext code {code}\")\n\n    data = packb(t, strict_types=True, use_bin_type=True, default=default)\n    expected = unpackb(data, raw=False, ext_hook=convert)\n\n    assert expected == t\n", "test/test_timestamp.py": "import datetime\n\nimport pytest\n\nimport msgpack\nfrom msgpack.ext import Timestamp\n\n\ndef test_timestamp():\n    # timestamp32\n    ts = Timestamp(2**32 - 1)\n    assert ts.to_bytes() == b\"\\xff\\xff\\xff\\xff\"\n    packed = msgpack.packb(ts)\n    assert packed == b\"\\xd6\\xff\" + ts.to_bytes()\n    unpacked = msgpack.unpackb(packed)\n    assert ts == unpacked\n    assert ts.seconds == 2**32 - 1 and ts.nanoseconds == 0\n\n    # timestamp64\n    ts = Timestamp(2**34 - 1, 999999999)\n    assert ts.to_bytes() == b\"\\xee\\x6b\\x27\\xff\\xff\\xff\\xff\\xff\"\n    packed = msgpack.packb(ts)\n    assert packed == b\"\\xd7\\xff\" + ts.to_bytes()\n    unpacked = msgpack.unpackb(packed)\n    assert ts == unpacked\n    assert ts.seconds == 2**34 - 1 and ts.nanoseconds == 999999999\n\n    # timestamp96\n    ts = Timestamp(2**63 - 1, 999999999)\n    assert ts.to_bytes() == b\"\\x3b\\x9a\\xc9\\xff\\x7f\\xff\\xff\\xff\\xff\\xff\\xff\\xff\"\n    packed = msgpack.packb(ts)\n    assert packed == b\"\\xc7\\x0c\\xff\" + ts.to_bytes()\n    unpacked = msgpack.unpackb(packed)\n    assert ts == unpacked\n    assert ts.seconds == 2**63 - 1 and ts.nanoseconds == 999999999\n\n    # negative fractional\n    ts = Timestamp.from_unix(-2.3)  # s: -3, ns: 700000000\n    assert ts.seconds == -3 and ts.nanoseconds == 700000000\n    assert ts.to_bytes() == b\"\\x29\\xb9\\x27\\x00\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\"\n    packed = msgpack.packb(ts)\n    assert packed == b\"\\xc7\\x0c\\xff\" + ts.to_bytes()\n    unpacked = msgpack.unpackb(packed)\n    assert ts == unpacked\n\n\ndef test_unpack_timestamp():\n    # timestamp 32\n    assert msgpack.unpackb(b\"\\xd6\\xff\\x00\\x00\\x00\\x00\") == Timestamp(0)\n\n    # timestamp 64\n    assert msgpack.unpackb(b\"\\xd7\\xff\" + b\"\\x00\" * 8) == Timestamp(0)\n    with pytest.raises(ValueError):\n        msgpack.unpackb(b\"\\xd7\\xff\" + b\"\\xff\" * 8)\n\n    # timestamp 96\n    assert msgpack.unpackb(b\"\\xc7\\x0c\\xff\" + b\"\\x00\" * 12) == Timestamp(0)\n    with pytest.raises(ValueError):\n        msgpack.unpackb(b\"\\xc7\\x0c\\xff\" + b\"\\xff\" * 12) == Timestamp(0)\n\n    # Undefined\n    with pytest.raises(ValueError):\n        msgpack.unpackb(b\"\\xd4\\xff\\x00\")  # fixext 1\n    with pytest.raises(ValueError):\n        msgpack.unpackb(b\"\\xd5\\xff\\x00\\x00\")  # fixext 2\n    with pytest.raises(ValueError):\n        msgpack.unpackb(b\"\\xc7\\x00\\xff\")  # ext8 (len=0)\n    with pytest.raises(ValueError):\n        msgpack.unpackb(b\"\\xc7\\x03\\xff\\0\\0\\0\")  # ext8 (len=3)\n    with pytest.raises(ValueError):\n        msgpack.unpackb(b\"\\xc7\\x05\\xff\\0\\0\\0\\0\\0\")  # ext8 (len=5)\n\n\ndef test_timestamp_from():\n    t = Timestamp(42, 14000)\n    assert Timestamp.from_unix(42.000014) == t\n    assert Timestamp.from_unix_nano(42000014000) == t\n\n\ndef test_timestamp_to():\n    t = Timestamp(42, 14000)\n    assert t.to_unix() == 42.000014\n    assert t.to_unix_nano() == 42000014000\n\n\ndef test_timestamp_datetime():\n    t = Timestamp(42, 14)\n    utc = datetime.timezone.utc\n    assert t.to_datetime() == datetime.datetime(1970, 1, 1, 0, 0, 42, 0, tzinfo=utc)\n\n    ts = datetime.datetime(2024, 4, 16, 8, 43, 9, 420317, tzinfo=utc)\n    ts2 = datetime.datetime(2024, 4, 16, 8, 43, 9, 420318, tzinfo=utc)\n\n    assert (\n        Timestamp.from_datetime(ts2).nanoseconds - Timestamp.from_datetime(ts).nanoseconds == 1000\n    )\n\n    ts3 = datetime.datetime(2024, 4, 16, 8, 43, 9, 4256)\n    ts4 = datetime.datetime(2024, 4, 16, 8, 43, 9, 4257)\n    assert (\n        Timestamp.from_datetime(ts4).nanoseconds - Timestamp.from_datetime(ts3).nanoseconds == 1000\n    )\n\n    assert Timestamp.from_datetime(ts).to_datetime() == ts\n\n\ndef test_unpack_datetime():\n    t = Timestamp(42, 14)\n    utc = datetime.timezone.utc\n    packed = msgpack.packb(t)\n    unpacked = msgpack.unpackb(packed, timestamp=3)\n    assert unpacked == datetime.datetime(1970, 1, 1, 0, 0, 42, 0, tzinfo=utc)\n\n\ndef test_pack_unpack_before_epoch():\n    utc = datetime.timezone.utc\n    t_in = datetime.datetime(1960, 1, 1, tzinfo=utc)\n    packed = msgpack.packb(t_in, datetime=True)\n    unpacked = msgpack.unpackb(packed, timestamp=3)\n    assert unpacked == t_in\n\n\ndef test_pack_datetime():\n    t = Timestamp(42, 14000)\n    dt = t.to_datetime()\n    utc = datetime.timezone.utc\n    assert dt == datetime.datetime(1970, 1, 1, 0, 0, 42, 14, tzinfo=utc)\n\n    packed = msgpack.packb(dt, datetime=True)\n    packed2 = msgpack.packb(t)\n    assert packed == packed2\n\n    unpacked = msgpack.unpackb(packed)\n    print(packed, unpacked)\n    assert unpacked == t\n\n    unpacked = msgpack.unpackb(packed, timestamp=3)\n    assert unpacked == dt\n\n    x = []\n    packed = msgpack.packb(dt, datetime=False, default=x.append)\n    assert x\n    assert x[0] == dt\n    assert msgpack.unpackb(packed) is None\n\n\ndef test_issue451():\n    # https://github.com/msgpack/msgpack-python/issues/451\n    utc = datetime.timezone.utc\n    dt = datetime.datetime(2100, 1, 1, 1, 1, tzinfo=utc)\n    packed = msgpack.packb(dt, datetime=True)\n    assert packed == b\"\\xd6\\xff\\xf4\\x86eL\"\n\n    unpacked = msgpack.unpackb(packed, timestamp=3)\n    assert dt == unpacked\n\n\ndef test_pack_datetime_without_tzinfo():\n    dt = datetime.datetime(1970, 1, 1, 0, 0, 42, 14)\n    with pytest.raises(ValueError, match=\"where tzinfo=None\"):\n        packed = msgpack.packb(dt, datetime=True)\n\n    dt = datetime.datetime(1970, 1, 1, 0, 0, 42, 14)\n    packed = msgpack.packb(dt, datetime=True, default=lambda x: None)\n    assert packed == msgpack.packb(None)\n\n    utc = datetime.timezone.utc\n    dt = datetime.datetime(1970, 1, 1, 0, 0, 42, 14, tzinfo=utc)\n    packed = msgpack.packb(dt, datetime=True)\n    unpacked = msgpack.unpackb(packed, timestamp=3)\n    assert unpacked == dt\n", "test/test_subtype.py": "#!/usr/bin/env python\n\nfrom collections import namedtuple\n\nfrom msgpack import packb\n\n\nclass MyList(list):\n    pass\n\n\nclass MyDict(dict):\n    pass\n\n\nclass MyTuple(tuple):\n    pass\n\n\nMyNamedTuple = namedtuple(\"MyNamedTuple\", \"x y\")\n\n\ndef test_types():\n    assert packb(MyDict()) == packb(dict())\n    assert packb(MyList()) == packb(list())\n    assert packb(MyNamedTuple(1, 2)) == packb((1, 2))\n", "test/test_case.py": "#!/usr/bin/env python\nfrom msgpack import packb, unpackb\n\n\ndef check(length, obj, use_bin_type=True):\n    v = packb(obj, use_bin_type=use_bin_type)\n    assert len(v) == length, f\"{obj!r} length should be {length!r} but get {len(v)!r}\"\n    assert unpackb(v, use_list=0, raw=not use_bin_type) == obj\n\n\ndef test_1():\n    for o in [\n        None,\n        True,\n        False,\n        0,\n        1,\n        (1 << 6),\n        (1 << 7) - 1,\n        -1,\n        -((1 << 5) - 1),\n        -(1 << 5),\n    ]:\n        check(1, o)\n\n\ndef test_2():\n    for o in [1 << 7, (1 << 8) - 1, -((1 << 5) + 1), -(1 << 7)]:\n        check(2, o)\n\n\ndef test_3():\n    for o in [1 << 8, (1 << 16) - 1, -((1 << 7) + 1), -(1 << 15)]:\n        check(3, o)\n\n\ndef test_5():\n    for o in [1 << 16, (1 << 32) - 1, -((1 << 15) + 1), -(1 << 31)]:\n        check(5, o)\n\n\ndef test_9():\n    for o in [\n        1 << 32,\n        (1 << 64) - 1,\n        -((1 << 31) + 1),\n        -(1 << 63),\n        1.0,\n        0.1,\n        -0.1,\n        -1.0,\n    ]:\n        check(9, o)\n\n\ndef check_raw(overhead, num):\n    check(num + overhead, b\" \" * num, use_bin_type=False)\n\n\ndef test_fixraw():\n    check_raw(1, 0)\n    check_raw(1, (1 << 5) - 1)\n\n\ndef test_raw16():\n    check_raw(3, 1 << 5)\n    check_raw(3, (1 << 16) - 1)\n\n\ndef test_raw32():\n    check_raw(5, 1 << 16)\n\n\ndef check_array(overhead, num):\n    check(num + overhead, (None,) * num)\n\n\ndef test_fixarray():\n    check_array(1, 0)\n    check_array(1, (1 << 4) - 1)\n\n\ndef test_array16():\n    check_array(3, 1 << 4)\n    check_array(3, (1 << 16) - 1)\n\n\ndef test_array32():\n    check_array(5, (1 << 16))\n\n\ndef match(obj, buf):\n    assert packb(obj) == buf\n    assert unpackb(buf, use_list=0, strict_map_key=False) == obj\n\n\ndef test_match():\n    cases = [\n        (None, b\"\\xc0\"),\n        (False, b\"\\xc2\"),\n        (True, b\"\\xc3\"),\n        (0, b\"\\x00\"),\n        (127, b\"\\x7f\"),\n        (128, b\"\\xcc\\x80\"),\n        (256, b\"\\xcd\\x01\\x00\"),\n        (-1, b\"\\xff\"),\n        (-33, b\"\\xd0\\xdf\"),\n        (-129, b\"\\xd1\\xff\\x7f\"),\n        ({1: 1}, b\"\\x81\\x01\\x01\"),\n        (1.0, b\"\\xcb\\x3f\\xf0\\x00\\x00\\x00\\x00\\x00\\x00\"),\n        ((), b\"\\x90\"),\n        (\n            tuple(range(15)),\n            b\"\\x9f\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x09\\x0a\\x0b\\x0c\\x0d\\x0e\",\n        ),\n        (\n            tuple(range(16)),\n            b\"\\xdc\\x00\\x10\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x09\\x0a\\x0b\\x0c\\x0d\\x0e\\x0f\",\n        ),\n        ({}, b\"\\x80\"),\n        (\n            {x: x for x in range(15)},\n            b\"\\x8f\\x00\\x00\\x01\\x01\\x02\\x02\\x03\\x03\\x04\\x04\\x05\\x05\\x06\\x06\\x07\\x07\\x08\\x08\\t\\t\\n\\n\\x0b\\x0b\\x0c\\x0c\\r\\r\\x0e\\x0e\",\n        ),\n        (\n            {x: x for x in range(16)},\n            b\"\\xde\\x00\\x10\\x00\\x00\\x01\\x01\\x02\\x02\\x03\\x03\\x04\\x04\\x05\\x05\\x06\\x06\\x07\\x07\\x08\\x08\\t\\t\\n\\n\\x0b\\x0b\\x0c\\x0c\\r\\r\\x0e\\x0e\\x0f\\x0f\",\n        ),\n    ]\n\n    for v, p in cases:\n        match(v, p)\n\n\ndef test_unicode():\n    assert unpackb(packb(\"foobar\"), use_list=1) == \"foobar\"\n", "test/test_obj.py": "#!/usr/bin/env python\n\nfrom pytest import raises\n\nfrom msgpack import packb, unpackb\n\n\ndef _decode_complex(obj):\n    if b\"__complex__\" in obj:\n        return complex(obj[b\"real\"], obj[b\"imag\"])\n    return obj\n\n\ndef _encode_complex(obj):\n    if isinstance(obj, complex):\n        return {b\"__complex__\": True, b\"real\": 1, b\"imag\": 2}\n    return obj\n\n\ndef test_encode_hook():\n    packed = packb([3, 1 + 2j], default=_encode_complex)\n    unpacked = unpackb(packed, use_list=1)\n    assert unpacked[1] == {b\"__complex__\": True, b\"real\": 1, b\"imag\": 2}\n\n\ndef test_decode_hook():\n    packed = packb([3, {b\"__complex__\": True, b\"real\": 1, b\"imag\": 2}])\n    unpacked = unpackb(packed, object_hook=_decode_complex, use_list=1)\n    assert unpacked[1] == 1 + 2j\n\n\ndef test_decode_pairs_hook():\n    packed = packb([3, {1: 2, 3: 4}])\n    prod_sum = 1 * 2 + 3 * 4\n    unpacked = unpackb(\n        packed,\n        object_pairs_hook=lambda lst: sum(k * v for k, v in lst),\n        use_list=1,\n        strict_map_key=False,\n    )\n    assert unpacked[1] == prod_sum\n\n\ndef test_only_one_obj_hook():\n    with raises(TypeError):\n        unpackb(b\"\", object_hook=lambda x: x, object_pairs_hook=lambda x: x)\n\n\ndef test_bad_hook():\n    with raises(TypeError):\n        packed = packb([3, 1 + 2j], default=lambda o: o)\n        unpackb(packed, use_list=1)\n\n\ndef _arr_to_str(arr):\n    return \"\".join(str(c) for c in arr)\n\n\ndef test_array_hook():\n    packed = packb([1, 2, 3])\n    unpacked = unpackb(packed, list_hook=_arr_to_str, use_list=1)\n    assert unpacked == \"123\"\n\n\nclass DecodeError(Exception):\n    pass\n\n\ndef bad_complex_decoder(o):\n    raise DecodeError(\"Ooops!\")\n\n\ndef test_an_exception_in_objecthook1():\n    with raises(DecodeError):\n        packed = packb({1: {\"__complex__\": True, \"real\": 1, \"imag\": 2}})\n        unpackb(packed, object_hook=bad_complex_decoder, strict_map_key=False)\n\n\ndef test_an_exception_in_objecthook2():\n    with raises(DecodeError):\n        packed = packb({1: [{\"__complex__\": True, \"real\": 1, \"imag\": 2}]})\n        unpackb(packed, list_hook=bad_complex_decoder, use_list=1, strict_map_key=False)\n", "test/test_unpack.py": "import sys\nfrom io import BytesIO\n\nfrom pytest import mark, raises\n\nfrom msgpack import ExtType, OutOfData, Unpacker, packb\n\n\ndef test_unpack_array_header_from_file():\n    f = BytesIO(packb([1, 2, 3, 4]))\n    unpacker = Unpacker(f)\n    assert unpacker.read_array_header() == 4\n    assert unpacker.unpack() == 1\n    assert unpacker.unpack() == 2\n    assert unpacker.unpack() == 3\n    assert unpacker.unpack() == 4\n    with raises(OutOfData):\n        unpacker.unpack()\n\n\n@mark.skipif(\n    \"not hasattr(sys, 'getrefcount') == True\",\n    reason=\"sys.getrefcount() is needed to pass this test\",\n)\ndef test_unpacker_hook_refcnt():\n    result = []\n\n    def hook(x):\n        result.append(x)\n        return x\n\n    basecnt = sys.getrefcount(hook)\n\n    up = Unpacker(object_hook=hook, list_hook=hook)\n\n    assert sys.getrefcount(hook) >= basecnt + 2\n\n    up.feed(packb([{}]))\n    up.feed(packb([{}]))\n    assert up.unpack() == [{}]\n    assert up.unpack() == [{}]\n    assert result == [{}, [{}], {}, [{}]]\n\n    del up\n\n    assert sys.getrefcount(hook) == basecnt\n\n\ndef test_unpacker_ext_hook():\n    class MyUnpacker(Unpacker):\n        def __init__(self):\n            super().__init__(ext_hook=self._hook, raw=False)\n\n        def _hook(self, code, data):\n            if code == 1:\n                return int(data)\n            else:\n                return ExtType(code, data)\n\n    unpacker = MyUnpacker()\n    unpacker.feed(packb({\"a\": 1}))\n    assert unpacker.unpack() == {\"a\": 1}\n    unpacker.feed(packb({\"a\": ExtType(1, b\"123\")}))\n    assert unpacker.unpack() == {\"a\": 123}\n    unpacker.feed(packb({\"a\": ExtType(2, b\"321\")}))\n    assert unpacker.unpack() == {\"a\": ExtType(2, b\"321\")}\n\n\ndef test_unpacker_tell():\n    objects = 1, 2, \"abc\", \"def\", \"ghi\"\n    packed = b\"\\x01\\x02\\xa3abc\\xa3def\\xa3ghi\"\n    positions = 1, 2, 6, 10, 14\n    unpacker = Unpacker(BytesIO(packed))\n    for obj, unp, pos in zip(objects, unpacker, positions):\n        assert obj == unp\n        assert pos == unpacker.tell()\n\n\ndef test_unpacker_tell_read_bytes():\n    objects = 1, \"abc\", \"ghi\"\n    packed = b\"\\x01\\x02\\xa3abc\\xa3def\\xa3ghi\"\n    raw_data = b\"\\x02\", b\"\\xa3def\", b\"\"\n    lenghts = 1, 4, 999\n    positions = 1, 6, 14\n    unpacker = Unpacker(BytesIO(packed))\n    for obj, unp, pos, n, raw in zip(objects, unpacker, positions, lenghts, raw_data):\n        assert obj == unp\n        assert pos == unpacker.tell()\n        assert unpacker.read_bytes(n) == raw\n", "docs/conf.py": "# msgpack documentation build configuration file, created by\n# sphinx-quickstart on Sun Feb 24 14:20:50 2013.\n#\n# This file is execfile()d with the current directory set to its containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#import os\n#import sys\n#sys.path.insert(0, os.path.abspath('..'))\n\n# -- General configuration -----------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.\nextensions = [\"sphinx.ext.autodoc\", \"sphinx.ext.viewcode\"]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# The suffix of source filenames.\nsource_suffix = \".rst\"\n\n# The encoding of source files.\n# source_encoding = 'utf-8-sig'\n\n# The master toctree document.\nmaster_doc = \"index\"\n\n# General information about the project.\nproject = \"msgpack\"\ncopyright = \"Inada Naoki\"\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\n# The full version, including alpha/beta/rc tags.\nversion = release = \"1.0\"\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n# language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n# today = ''\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = '%B %d, %Y'\ntoday_fmt = \"%Y-%m-%d\"\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\"_build\"]\n\n# The reST default role (used for this markup: `text`) to use for all documents.\n# default_role = None\n\n# If true, '()' will be appended to :func: etc. cross-reference text.\n# add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \"sphinx\"\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n\n# -- Options for HTML output ---------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \"sphinx_rtd_theme\"\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n# html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n# html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n# html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n# html_last_updated_fmt = '%b %d, %Y'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n# html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n# html_show_sourcelink = True\n\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n# html_show_sphinx = True\n\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n# html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = ''\n\n# This is the file name suffix for HTML files (e.g. \".xhtml\").\n# html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \"msgpackdoc\"\n\n\n# -- Options for LaTeX output --------------------------------------------------\n\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #'preamble': '',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [\n    (\"index\", \"msgpack.tex\", \"msgpack Documentation\", \"Author\", \"manual\"),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# If false, no module index is generated.\n# latex_domain_indices = True\n\n\n# -- Options for manual page output --------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(\"index\", \"msgpack\", \"msgpack Documentation\", [\"Author\"], 1)]\n\n# If true, show URL addresses after external links.\n# man_show_urls = False\n\n\n# -- Options for Texinfo output ------------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        \"index\",\n        \"msgpack\",\n        \"msgpack Documentation\",\n        \"Author\",\n        \"msgpack\",\n        \"One line description of project.\",\n        \"Miscellaneous\",\n    ),\n]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n# texinfo_show_urls = 'footnote'\n\n\n# -- Options for Epub output ---------------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = \"msgpack\"\nepub_author = \"Author\"\nepub_publisher = \"Author\"\nepub_copyright = \"2013, Author\"\n\n# The language of the text. It defaults to the language option\n# or en if the language is not set.\n# epub_language = ''\n\n# The scheme of the identifier. Typical schemes are ISBN or URL.\n# epub_scheme = ''\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n# epub_identifier = ''\n\n# A unique identification for the text.\n# epub_uid = ''\n\n# A tuple containing the cover image and cover page html template filenames.\n# epub_cover = ()\n\n# HTML files that should be inserted before the pages created by sphinx.\n# The format is a list of tuples containing the path and title.\n# epub_pre_files = []\n\n# HTML files shat should be inserted after the pages created by sphinx.\n# The format is a list of tuples containing the path and title.\n# epub_post_files = []\n\n# A list of files that should not be packed into the epub file.\n# epub_exclude_files = []\n\n# The depth of the table of contents in toc.ncx.\n# epub_tocdepth = 3\n\n# Allow duplicate toc entries.\n# epub_tocdup = True\n", "benchmark/benchmark.py": "from msgpack import fallback\n\ntry:\n    from msgpack import _cmsgpack\n\n    has_ext = True\nexcept ImportError:\n    has_ext = False\nimport timeit\n\n\ndef profile(name, func):\n    times = timeit.repeat(func, number=1000, repeat=4)\n    times = \", \".join([\"%8f\" % t for t in times])\n    print(\"%-30s %40s\" % (name, times))\n\n\ndef simple(name, data):\n    if has_ext:\n        packer = _cmsgpack.Packer()\n        profile(\"packing %s (ext)\" % name, lambda: packer.pack(data))\n    packer = fallback.Packer()\n    profile(\"packing %s (fallback)\" % name, lambda: packer.pack(data))\n\n    data = packer.pack(data)\n    if has_ext:\n        profile(\"unpacking %s (ext)\" % name, lambda: _cmsgpack.unpackb(data))\n    profile(\"unpacking %s (fallback)\" % name, lambda: fallback.unpackb(data))\n\n\ndef main():\n    simple(\"integers\", [7] * 10000)\n    simple(\"bytes\", [b\"x\" * n for n in range(100)] * 10)\n    simple(\"lists\", [[]] * 10000)\n    simple(\"dicts\", [{}] * 10000)\n\n\nmain()\n", "msgpack/exceptions.py": "class UnpackException(Exception):\n    \"\"\"Base class for some exceptions raised while unpacking.\n\n    NOTE: unpack may raise exception other than subclass of\n    UnpackException.  If you want to catch all error, catch\n    Exception instead.\n    \"\"\"\n\n\nclass BufferFull(UnpackException):\n    pass\n\n\nclass OutOfData(UnpackException):\n    pass\n\n\nclass FormatError(ValueError, UnpackException):\n    \"\"\"Invalid msgpack format\"\"\"\n\n\nclass StackError(ValueError, UnpackException):\n    \"\"\"Too nested\"\"\"\n\n\n# Deprecated.  Use ValueError instead\nUnpackValueError = ValueError\n\n\nclass ExtraData(UnpackValueError):\n    \"\"\"ExtraData is raised when there is trailing data.\n\n    This exception is raised while only one-shot (not streaming)\n    unpack.\n    \"\"\"\n\n    def __init__(self, unpacked, extra):\n        self.unpacked = unpacked\n        self.extra = extra\n\n    def __str__(self):\n        return \"unpack(b) received extra data.\"\n\n\n# Deprecated.  Use Exception instead to catch all exception during packing.\nPackException = Exception\nPackValueError = ValueError\nPackOverflowError = OverflowError\n", "msgpack/ext.py": "import datetime\nimport struct\nfrom collections import namedtuple\n\n\nclass ExtType(namedtuple(\"ExtType\", \"code data\")):\n    \"\"\"ExtType represents ext type in msgpack.\"\"\"\n\n    def __new__(cls, code, data):\n        if not isinstance(code, int):\n            raise TypeError(\"code must be int\")\n        if not isinstance(data, bytes):\n            raise TypeError(\"data must be bytes\")\n        if not 0 <= code <= 127:\n            raise ValueError(\"code must be 0~127\")\n        return super().__new__(cls, code, data)\n\n\nclass Timestamp:\n    \"\"\"Timestamp represents the Timestamp extension type in msgpack.\n\n    When built with Cython, msgpack uses C methods to pack and unpack `Timestamp`.\n    When using pure-Python msgpack, :func:`to_bytes` and :func:`from_bytes` are used to pack and\n    unpack `Timestamp`.\n\n    This class is immutable: Do not override seconds and nanoseconds.\n    \"\"\"\n\n    __slots__ = [\"seconds\", \"nanoseconds\"]\n\n    def __init__(self, seconds, nanoseconds=0):\n        \"\"\"Initialize a Timestamp object.\n\n        :param int seconds:\n            Number of seconds since the UNIX epoch (00:00:00 UTC Jan 1 1970, minus leap seconds).\n            May be negative.\n\n        :param int nanoseconds:\n            Number of nanoseconds to add to `seconds` to get fractional time.\n            Maximum is 999_999_999.  Default is 0.\n\n        Note: Negative times (before the UNIX epoch) are represented as neg. seconds + pos. ns.\n        \"\"\"\n        if not isinstance(seconds, int):\n            raise TypeError(\"seconds must be an integer\")\n        if not isinstance(nanoseconds, int):\n            raise TypeError(\"nanoseconds must be an integer\")\n        if not (0 <= nanoseconds < 10**9):\n            raise ValueError(\"nanoseconds must be a non-negative integer less than 999999999.\")\n        self.seconds = seconds\n        self.nanoseconds = nanoseconds\n\n    def __repr__(self):\n        \"\"\"String representation of Timestamp.\"\"\"\n        return f\"Timestamp(seconds={self.seconds}, nanoseconds={self.nanoseconds})\"\n\n    def __eq__(self, other):\n        \"\"\"Check for equality with another Timestamp object\"\"\"\n        if type(other) is self.__class__:\n            return self.seconds == other.seconds and self.nanoseconds == other.nanoseconds\n        return False\n\n    def __ne__(self, other):\n        \"\"\"not-equals method (see :func:`__eq__()`)\"\"\"\n        return not self.__eq__(other)\n\n    def __hash__(self):\n        return hash((self.seconds, self.nanoseconds))\n\n    @staticmethod\n    def from_bytes(b):\n        \"\"\"Unpack bytes into a `Timestamp` object.\n\n        Used for pure-Python msgpack unpacking.\n\n        :param b: Payload from msgpack ext message with code -1\n        :type b: bytes\n\n        :returns: Timestamp object unpacked from msgpack ext payload\n        :rtype: Timestamp\n        \"\"\"\n        if len(b) == 4:\n            seconds = struct.unpack(\"!L\", b)[0]\n            nanoseconds = 0\n        elif len(b) == 8:\n            data64 = struct.unpack(\"!Q\", b)[0]\n            seconds = data64 & 0x00000003FFFFFFFF\n            nanoseconds = data64 >> 34\n        elif len(b) == 12:\n            nanoseconds, seconds = struct.unpack(\"!Iq\", b)\n        else:\n            raise ValueError(\n                \"Timestamp type can only be created from 32, 64, or 96-bit byte objects\"\n            )\n        return Timestamp(seconds, nanoseconds)\n\n    def to_bytes(self):\n        \"\"\"Pack this Timestamp object into bytes.\n\n        Used for pure-Python msgpack packing.\n\n        :returns data: Payload for EXT message with code -1 (timestamp type)\n        :rtype: bytes\n        \"\"\"\n        if (self.seconds >> 34) == 0:  # seconds is non-negative and fits in 34 bits\n            data64 = self.nanoseconds << 34 | self.seconds\n            if data64 & 0xFFFFFFFF00000000 == 0:\n                # nanoseconds is zero and seconds < 2**32, so timestamp 32\n                data = struct.pack(\"!L\", data64)\n            else:\n                # timestamp 64\n                data = struct.pack(\"!Q\", data64)\n        else:\n            # timestamp 96\n            data = struct.pack(\"!Iq\", self.nanoseconds, self.seconds)\n        return data\n\n    @staticmethod\n    def from_unix(unix_sec):\n        \"\"\"Create a Timestamp from posix timestamp in seconds.\n\n        :param unix_float: Posix timestamp in seconds.\n        :type unix_float: int or float\n        \"\"\"\n        seconds = int(unix_sec // 1)\n        nanoseconds = int((unix_sec % 1) * 10**9)\n        return Timestamp(seconds, nanoseconds)\n\n    def to_unix(self):\n        \"\"\"Get the timestamp as a floating-point value.\n\n        :returns: posix timestamp\n        :rtype: float\n        \"\"\"\n        return self.seconds + self.nanoseconds / 1e9\n\n    @staticmethod\n    def from_unix_nano(unix_ns):\n        \"\"\"Create a Timestamp from posix timestamp in nanoseconds.\n\n        :param int unix_ns: Posix timestamp in nanoseconds.\n        :rtype: Timestamp\n        \"\"\"\n        return Timestamp(*divmod(unix_ns, 10**9))\n\n    def to_unix_nano(self):\n        \"\"\"Get the timestamp as a unixtime in nanoseconds.\n\n        :returns: posix timestamp in nanoseconds\n        :rtype: int\n        \"\"\"\n        return self.seconds * 10**9 + self.nanoseconds\n\n    def to_datetime(self):\n        \"\"\"Get the timestamp as a UTC datetime.\n\n        :rtype: `datetime.datetime`\n        \"\"\"\n        utc = datetime.timezone.utc\n        return datetime.datetime.fromtimestamp(0, utc) + datetime.timedelta(\n            seconds=self.seconds, microseconds=self.nanoseconds // 1000\n        )\n\n    @staticmethod\n    def from_datetime(dt):\n        \"\"\"Create a Timestamp from datetime with tzinfo.\n\n        :rtype: Timestamp\n        \"\"\"\n        return Timestamp(seconds=int(dt.timestamp()), nanoseconds=dt.microsecond * 1000)\n", "msgpack/fallback.py": "\"\"\"Fallback pure Python implementation of msgpack\"\"\"\n\nimport struct\nimport sys\nfrom datetime import datetime as _DateTime\n\nif hasattr(sys, \"pypy_version_info\"):\n    from __pypy__ import newlist_hint\n    from __pypy__.builders import BytesBuilder\n\n    _USING_STRINGBUILDER = True\n\n    class BytesIO:\n        def __init__(self, s=b\"\"):\n            if s:\n                self.builder = BytesBuilder(len(s))\n                self.builder.append(s)\n            else:\n                self.builder = BytesBuilder()\n\n        def write(self, s):\n            if isinstance(s, memoryview):\n                s = s.tobytes()\n            elif isinstance(s, bytearray):\n                s = bytes(s)\n            self.builder.append(s)\n\n        def getvalue(self):\n            return self.builder.build()\n\nelse:\n    from io import BytesIO\n\n    _USING_STRINGBUILDER = False\n\n    def newlist_hint(size):\n        return []\n\n\nfrom .exceptions import BufferFull, ExtraData, FormatError, OutOfData, StackError\nfrom .ext import ExtType, Timestamp\n\nEX_SKIP = 0\nEX_CONSTRUCT = 1\nEX_READ_ARRAY_HEADER = 2\nEX_READ_MAP_HEADER = 3\n\nTYPE_IMMEDIATE = 0\nTYPE_ARRAY = 1\nTYPE_MAP = 2\nTYPE_RAW = 3\nTYPE_BIN = 4\nTYPE_EXT = 5\n\nDEFAULT_RECURSE_LIMIT = 511\n\n\ndef _check_type_strict(obj, t, type=type, tuple=tuple):\n    if type(t) is tuple:\n        return type(obj) in t\n    else:\n        return type(obj) is t\n\n\ndef _get_data_from_buffer(obj):\n    view = memoryview(obj)\n    if view.itemsize != 1:\n        raise ValueError(\"cannot unpack from multi-byte object\")\n    return view\n\n\ndef unpackb(packed, **kwargs):\n    \"\"\"\n    Unpack an object from `packed`.\n\n    Raises ``ExtraData`` when *packed* contains extra bytes.\n    Raises ``ValueError`` when *packed* is incomplete.\n    Raises ``FormatError`` when *packed* is not valid msgpack.\n    Raises ``StackError`` when *packed* contains too nested.\n    Other exceptions can be raised during unpacking.\n\n    See :class:`Unpacker` for options.\n    \"\"\"\n    unpacker = Unpacker(None, max_buffer_size=len(packed), **kwargs)\n    unpacker.feed(packed)\n    try:\n        ret = unpacker._unpack()\n    except OutOfData:\n        raise ValueError(\"Unpack failed: incomplete input\")\n    except RecursionError:\n        raise StackError\n    if unpacker._got_extradata():\n        raise ExtraData(ret, unpacker._get_extradata())\n    return ret\n\n\n_NO_FORMAT_USED = \"\"\n_MSGPACK_HEADERS = {\n    0xC4: (1, _NO_FORMAT_USED, TYPE_BIN),\n    0xC5: (2, \">H\", TYPE_BIN),\n    0xC6: (4, \">I\", TYPE_BIN),\n    0xC7: (2, \"Bb\", TYPE_EXT),\n    0xC8: (3, \">Hb\", TYPE_EXT),\n    0xC9: (5, \">Ib\", TYPE_EXT),\n    0xCA: (4, \">f\"),\n    0xCB: (8, \">d\"),\n    0xCC: (1, _NO_FORMAT_USED),\n    0xCD: (2, \">H\"),\n    0xCE: (4, \">I\"),\n    0xCF: (8, \">Q\"),\n    0xD0: (1, \"b\"),\n    0xD1: (2, \">h\"),\n    0xD2: (4, \">i\"),\n    0xD3: (8, \">q\"),\n    0xD4: (1, \"b1s\", TYPE_EXT),\n    0xD5: (2, \"b2s\", TYPE_EXT),\n    0xD6: (4, \"b4s\", TYPE_EXT),\n    0xD7: (8, \"b8s\", TYPE_EXT),\n    0xD8: (16, \"b16s\", TYPE_EXT),\n    0xD9: (1, _NO_FORMAT_USED, TYPE_RAW),\n    0xDA: (2, \">H\", TYPE_RAW),\n    0xDB: (4, \">I\", TYPE_RAW),\n    0xDC: (2, \">H\", TYPE_ARRAY),\n    0xDD: (4, \">I\", TYPE_ARRAY),\n    0xDE: (2, \">H\", TYPE_MAP),\n    0xDF: (4, \">I\", TYPE_MAP),\n}\n\n\nclass Unpacker:\n    \"\"\"Streaming unpacker.\n\n    Arguments:\n\n    :param file_like:\n        File-like object having `.read(n)` method.\n        If specified, unpacker reads serialized data from it and `.feed()` is not usable.\n\n    :param int read_size:\n        Used as `file_like.read(read_size)`. (default: `min(16*1024, max_buffer_size)`)\n\n    :param bool use_list:\n        If true, unpack msgpack array to Python list.\n        Otherwise, unpack to Python tuple. (default: True)\n\n    :param bool raw:\n        If true, unpack msgpack raw to Python bytes.\n        Otherwise, unpack to Python str by decoding with UTF-8 encoding (default).\n\n    :param int timestamp:\n        Control how timestamp type is unpacked:\n\n            0 - Timestamp\n            1 - float  (Seconds from the EPOCH)\n            2 - int  (Nanoseconds from the EPOCH)\n            3 - datetime.datetime  (UTC).\n\n    :param bool strict_map_key:\n        If true (default), only str or bytes are accepted for map (dict) keys.\n\n    :param object_hook:\n        When specified, it should be callable.\n        Unpacker calls it with a dict argument after unpacking msgpack map.\n        (See also simplejson)\n\n    :param object_pairs_hook:\n        When specified, it should be callable.\n        Unpacker calls it with a list of key-value pairs after unpacking msgpack map.\n        (See also simplejson)\n\n    :param str unicode_errors:\n        The error handler for decoding unicode. (default: 'strict')\n        This option should be used only when you have msgpack data which\n        contains invalid UTF-8 string.\n\n    :param int max_buffer_size:\n        Limits size of data waiting unpacked.  0 means 2**32-1.\n        The default value is 100*1024*1024 (100MiB).\n        Raises `BufferFull` exception when it is insufficient.\n        You should set this parameter when unpacking data from untrusted source.\n\n    :param int max_str_len:\n        Deprecated, use *max_buffer_size* instead.\n        Limits max length of str. (default: max_buffer_size)\n\n    :param int max_bin_len:\n        Deprecated, use *max_buffer_size* instead.\n        Limits max length of bin. (default: max_buffer_size)\n\n    :param int max_array_len:\n        Limits max length of array.\n        (default: max_buffer_size)\n\n    :param int max_map_len:\n        Limits max length of map.\n        (default: max_buffer_size//2)\n\n    :param int max_ext_len:\n        Deprecated, use *max_buffer_size* instead.\n        Limits max size of ext type.  (default: max_buffer_size)\n\n    Example of streaming deserialize from file-like object::\n\n        unpacker = Unpacker(file_like)\n        for o in unpacker:\n            process(o)\n\n    Example of streaming deserialize from socket::\n\n        unpacker = Unpacker()\n        while True:\n            buf = sock.recv(1024**2)\n            if not buf:\n                break\n            unpacker.feed(buf)\n            for o in unpacker:\n                process(o)\n\n    Raises ``ExtraData`` when *packed* contains extra bytes.\n    Raises ``OutOfData`` when *packed* is incomplete.\n    Raises ``FormatError`` when *packed* is not valid msgpack.\n    Raises ``StackError`` when *packed* contains too nested.\n    Other exceptions can be raised during unpacking.\n    \"\"\"\n\n    def __init__(\n        self,\n        file_like=None,\n        *,\n        read_size=0,\n        use_list=True,\n        raw=False,\n        timestamp=0,\n        strict_map_key=True,\n        object_hook=None,\n        object_pairs_hook=None,\n        list_hook=None,\n        unicode_errors=None,\n        max_buffer_size=100 * 1024 * 1024,\n        ext_hook=ExtType,\n        max_str_len=-1,\n        max_bin_len=-1,\n        max_array_len=-1,\n        max_map_len=-1,\n        max_ext_len=-1,\n    ):\n        if unicode_errors is None:\n            unicode_errors = \"strict\"\n\n        if file_like is None:\n            self._feeding = True\n        else:\n            if not callable(file_like.read):\n                raise TypeError(\"`file_like.read` must be callable\")\n            self.file_like = file_like\n            self._feeding = False\n\n        #: array of bytes fed.\n        self._buffer = bytearray()\n        #: Which position we currently reads\n        self._buff_i = 0\n\n        # When Unpacker is used as an iterable, between the calls to next(),\n        # the buffer is not \"consumed\" completely, for efficiency sake.\n        # Instead, it is done sloppily.  To make sure we raise BufferFull at\n        # the correct moments, we have to keep track of how sloppy we were.\n        # Furthermore, when the buffer is incomplete (that is: in the case\n        # we raise an OutOfData) we need to rollback the buffer to the correct\n        # state, which _buf_checkpoint records.\n        self._buf_checkpoint = 0\n\n        if not max_buffer_size:\n            max_buffer_size = 2**31 - 1\n        if max_str_len == -1:\n            max_str_len = max_buffer_size\n        if max_bin_len == -1:\n            max_bin_len = max_buffer_size\n        if max_array_len == -1:\n            max_array_len = max_buffer_size\n        if max_map_len == -1:\n            max_map_len = max_buffer_size // 2\n        if max_ext_len == -1:\n            max_ext_len = max_buffer_size\n\n        self._max_buffer_size = max_buffer_size\n        if read_size > self._max_buffer_size:\n            raise ValueError(\"read_size must be smaller than max_buffer_size\")\n        self._read_size = read_size or min(self._max_buffer_size, 16 * 1024)\n        self._raw = bool(raw)\n        self._strict_map_key = bool(strict_map_key)\n        self._unicode_errors = unicode_errors\n        self._use_list = use_list\n        if not (0 <= timestamp <= 3):\n            raise ValueError(\"timestamp must be 0..3\")\n        self._timestamp = timestamp\n        self._list_hook = list_hook\n        self._object_hook = object_hook\n        self._object_pairs_hook = object_pairs_hook\n        self._ext_hook = ext_hook\n        self._max_str_len = max_str_len\n        self._max_bin_len = max_bin_len\n        self._max_array_len = max_array_len\n        self._max_map_len = max_map_len\n        self._max_ext_len = max_ext_len\n        self._stream_offset = 0\n\n        if list_hook is not None and not callable(list_hook):\n            raise TypeError(\"`list_hook` is not callable\")\n        if object_hook is not None and not callable(object_hook):\n            raise TypeError(\"`object_hook` is not callable\")\n        if object_pairs_hook is not None and not callable(object_pairs_hook):\n            raise TypeError(\"`object_pairs_hook` is not callable\")\n        if object_hook is not None and object_pairs_hook is not None:\n            raise TypeError(\"object_pairs_hook and object_hook are mutually exclusive\")\n        if not callable(ext_hook):\n            raise TypeError(\"`ext_hook` is not callable\")\n\n    def feed(self, next_bytes):\n        assert self._feeding\n        view = _get_data_from_buffer(next_bytes)\n        if len(self._buffer) - self._buff_i + len(view) > self._max_buffer_size:\n            raise BufferFull\n\n        # Strip buffer before checkpoint before reading file.\n        if self._buf_checkpoint > 0:\n            del self._buffer[: self._buf_checkpoint]\n            self._buff_i -= self._buf_checkpoint\n            self._buf_checkpoint = 0\n\n        # Use extend here: INPLACE_ADD += doesn't reliably typecast memoryview in jython\n        self._buffer.extend(view)\n        view.release()\n\n    def _consume(self):\n        \"\"\"Gets rid of the used parts of the buffer.\"\"\"\n        self._stream_offset += self._buff_i - self._buf_checkpoint\n        self._buf_checkpoint = self._buff_i\n\n    def _got_extradata(self):\n        return self._buff_i < len(self._buffer)\n\n    def _get_extradata(self):\n        return self._buffer[self._buff_i :]\n\n    def read_bytes(self, n):\n        ret = self._read(n, raise_outofdata=False)\n        self._consume()\n        return ret\n\n    def _read(self, n, raise_outofdata=True):\n        # (int) -> bytearray\n        self._reserve(n, raise_outofdata=raise_outofdata)\n        i = self._buff_i\n        ret = self._buffer[i : i + n]\n        self._buff_i = i + len(ret)\n        return ret\n\n    def _reserve(self, n, raise_outofdata=True):\n        remain_bytes = len(self._buffer) - self._buff_i - n\n\n        # Fast path: buffer has n bytes already\n        if remain_bytes >= 0:\n            return\n\n        if self._feeding:\n            self._buff_i = self._buf_checkpoint\n            raise OutOfData\n\n        # Strip buffer before checkpoint before reading file.\n        if self._buf_checkpoint > 0:\n            del self._buffer[: self._buf_checkpoint]\n            self._buff_i -= self._buf_checkpoint\n            self._buf_checkpoint = 0\n\n        # Read from file\n        remain_bytes = -remain_bytes\n        if remain_bytes + len(self._buffer) > self._max_buffer_size:\n            raise BufferFull\n        while remain_bytes > 0:\n            to_read_bytes = max(self._read_size, remain_bytes)\n            read_data = self.file_like.read(to_read_bytes)\n            if not read_data:\n                break\n            assert isinstance(read_data, bytes)\n            self._buffer += read_data\n            remain_bytes -= len(read_data)\n\n        if len(self._buffer) < n + self._buff_i and raise_outofdata:\n            self._buff_i = 0  # rollback\n            raise OutOfData\n\n    def _read_header(self):\n        typ = TYPE_IMMEDIATE\n        n = 0\n        obj = None\n        self._reserve(1)\n        b = self._buffer[self._buff_i]\n        self._buff_i += 1\n        if b & 0b10000000 == 0:\n            obj = b\n        elif b & 0b11100000 == 0b11100000:\n            obj = -1 - (b ^ 0xFF)\n        elif b & 0b11100000 == 0b10100000:\n            n = b & 0b00011111\n            typ = TYPE_RAW\n            if n > self._max_str_len:\n                raise ValueError(f\"{n} exceeds max_str_len({self._max_str_len})\")\n            obj = self._read(n)\n        elif b & 0b11110000 == 0b10010000:\n            n = b & 0b00001111\n            typ = TYPE_ARRAY\n            if n > self._max_array_len:\n                raise ValueError(f\"{n} exceeds max_array_len({self._max_array_len})\")\n        elif b & 0b11110000 == 0b10000000:\n            n = b & 0b00001111\n            typ = TYPE_MAP\n            if n > self._max_map_len:\n                raise ValueError(f\"{n} exceeds max_map_len({self._max_map_len})\")\n        elif b == 0xC0:\n            obj = None\n        elif b == 0xC2:\n            obj = False\n        elif b == 0xC3:\n            obj = True\n        elif 0xC4 <= b <= 0xC6:\n            size, fmt, typ = _MSGPACK_HEADERS[b]\n            self._reserve(size)\n            if len(fmt) > 0:\n                n = struct.unpack_from(fmt, self._buffer, self._buff_i)[0]\n            else:\n                n = self._buffer[self._buff_i]\n            self._buff_i += size\n            if n > self._max_bin_len:\n                raise ValueError(f\"{n} exceeds max_bin_len({self._max_bin_len})\")\n            obj = self._read(n)\n        elif 0xC7 <= b <= 0xC9:\n            size, fmt, typ = _MSGPACK_HEADERS[b]\n            self._reserve(size)\n            L, n = struct.unpack_from(fmt, self._buffer, self._buff_i)\n            self._buff_i += size\n            if L > self._max_ext_len:\n                raise ValueError(f\"{L} exceeds max_ext_len({self._max_ext_len})\")\n            obj = self._read(L)\n        elif 0xCA <= b <= 0xD3:\n            size, fmt = _MSGPACK_HEADERS[b]\n            self._reserve(size)\n            if len(fmt) > 0:\n                obj = struct.unpack_from(fmt, self._buffer, self._buff_i)[0]\n            else:\n                obj = self._buffer[self._buff_i]\n            self._buff_i += size\n        elif 0xD4 <= b <= 0xD8:\n            size, fmt, typ = _MSGPACK_HEADERS[b]\n            if self._max_ext_len < size:\n                raise ValueError(f\"{size} exceeds max_ext_len({self._max_ext_len})\")\n            self._reserve(size + 1)\n            n, obj = struct.unpack_from(fmt, self._buffer, self._buff_i)\n            self._buff_i += size + 1\n        elif 0xD9 <= b <= 0xDB:\n            size, fmt, typ = _MSGPACK_HEADERS[b]\n            self._reserve(size)\n            if len(fmt) > 0:\n                (n,) = struct.unpack_from(fmt, self._buffer, self._buff_i)\n            else:\n                n = self._buffer[self._buff_i]\n            self._buff_i += size\n            if n > self._max_str_len:\n                raise ValueError(f\"{n} exceeds max_str_len({self._max_str_len})\")\n            obj = self._read(n)\n        elif 0xDC <= b <= 0xDD:\n            size, fmt, typ = _MSGPACK_HEADERS[b]\n            self._reserve(size)\n            (n,) = struct.unpack_from(fmt, self._buffer, self._buff_i)\n            self._buff_i += size\n            if n > self._max_array_len:\n                raise ValueError(f\"{n} exceeds max_array_len({self._max_array_len})\")\n        elif 0xDE <= b <= 0xDF:\n            size, fmt, typ = _MSGPACK_HEADERS[b]\n            self._reserve(size)\n            (n,) = struct.unpack_from(fmt, self._buffer, self._buff_i)\n            self._buff_i += size\n            if n > self._max_map_len:\n                raise ValueError(f\"{n} exceeds max_map_len({self._max_map_len})\")\n        else:\n            raise FormatError(\"Unknown header: 0x%x\" % b)\n        return typ, n, obj\n\n    def _unpack(self, execute=EX_CONSTRUCT):\n        typ, n, obj = self._read_header()\n\n        if execute == EX_READ_ARRAY_HEADER:\n            if typ != TYPE_ARRAY:\n                raise ValueError(\"Expected array\")\n            return n\n        if execute == EX_READ_MAP_HEADER:\n            if typ != TYPE_MAP:\n                raise ValueError(\"Expected map\")\n            return n\n        # TODO should we eliminate the recursion?\n        if typ == TYPE_ARRAY:\n            if execute == EX_SKIP:\n                for i in range(n):\n                    # TODO check whether we need to call `list_hook`\n                    self._unpack(EX_SKIP)\n                return\n            ret = newlist_hint(n)\n            for i in range(n):\n                ret.append(self._unpack(EX_CONSTRUCT))\n            if self._list_hook is not None:\n                ret = self._list_hook(ret)\n            # TODO is the interaction between `list_hook` and `use_list` ok?\n            return ret if self._use_list else tuple(ret)\n        if typ == TYPE_MAP:\n            if execute == EX_SKIP:\n                for i in range(n):\n                    # TODO check whether we need to call hooks\n                    self._unpack(EX_SKIP)\n                    self._unpack(EX_SKIP)\n                return\n            if self._object_pairs_hook is not None:\n                ret = self._object_pairs_hook(\n                    (self._unpack(EX_CONSTRUCT), self._unpack(EX_CONSTRUCT)) for _ in range(n)\n                )\n            else:\n                ret = {}\n                for _ in range(n):\n                    key = self._unpack(EX_CONSTRUCT)\n                    if self._strict_map_key and type(key) not in (str, bytes):\n                        raise ValueError(\"%s is not allowed for map key\" % str(type(key)))\n                    if isinstance(key, str):\n                        key = sys.intern(key)\n                    ret[key] = self._unpack(EX_CONSTRUCT)\n                if self._object_hook is not None:\n                    ret = self._object_hook(ret)\n            return ret\n        if execute == EX_SKIP:\n            return\n        if typ == TYPE_RAW:\n            if self._raw:\n                obj = bytes(obj)\n            else:\n                obj = obj.decode(\"utf_8\", self._unicode_errors)\n            return obj\n        if typ == TYPE_BIN:\n            return bytes(obj)\n        if typ == TYPE_EXT:\n            if n == -1:  # timestamp\n                ts = Timestamp.from_bytes(bytes(obj))\n                if self._timestamp == 1:\n                    return ts.to_unix()\n                elif self._timestamp == 2:\n                    return ts.to_unix_nano()\n                elif self._timestamp == 3:\n                    return ts.to_datetime()\n                else:\n                    return ts\n            else:\n                return self._ext_hook(n, bytes(obj))\n        assert typ == TYPE_IMMEDIATE\n        return obj\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        try:\n            ret = self._unpack(EX_CONSTRUCT)\n            self._consume()\n            return ret\n        except OutOfData:\n            self._consume()\n            raise StopIteration\n        except RecursionError:\n            raise StackError\n\n    next = __next__\n\n    def skip(self):\n        self._unpack(EX_SKIP)\n        self._consume()\n\n    def unpack(self):\n        try:\n            ret = self._unpack(EX_CONSTRUCT)\n        except RecursionError:\n            raise StackError\n        self._consume()\n        return ret\n\n    def read_array_header(self):\n        ret = self._unpack(EX_READ_ARRAY_HEADER)\n        self._consume()\n        return ret\n\n    def read_map_header(self):\n        ret = self._unpack(EX_READ_MAP_HEADER)\n        self._consume()\n        return ret\n\n    def tell(self):\n        return self._stream_offset\n\n\nclass Packer:\n    \"\"\"\n    MessagePack Packer\n\n    Usage::\n\n        packer = Packer()\n        astream.write(packer.pack(a))\n        astream.write(packer.pack(b))\n\n    Packer's constructor has some keyword arguments:\n\n    :param default:\n        When specified, it should be callable.\n        Convert user type to builtin type that Packer supports.\n        See also simplejson's document.\n\n    :param bool use_single_float:\n        Use single precision float type for float. (default: False)\n\n    :param bool autoreset:\n        Reset buffer after each pack and return its content as `bytes`. (default: True).\n        If set this to false, use `bytes()` to get content and `.reset()` to clear buffer.\n\n    :param bool use_bin_type:\n        Use bin type introduced in msgpack spec 2.0 for bytes.\n        It also enables str8 type for unicode. (default: True)\n\n    :param bool strict_types:\n        If set to true, types will be checked to be exact. Derived classes\n        from serializable types will not be serialized and will be\n        treated as unsupported type and forwarded to default.\n        Additionally tuples will not be serialized as lists.\n        This is useful when trying to implement accurate serialization\n        for python types.\n\n    :param bool datetime:\n        If set to true, datetime with tzinfo is packed into Timestamp type.\n        Note that the tzinfo is stripped in the timestamp.\n        You can get UTC datetime with `timestamp=3` option of the Unpacker.\n\n    :param str unicode_errors:\n        The error handler for encoding unicode. (default: 'strict')\n        DO NOT USE THIS!!  This option is kept for very specific usage.\n\n    :param int buf_size:\n        Internal buffer size. This option is used only for C implementation.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        default=None,\n        use_single_float=False,\n        autoreset=True,\n        use_bin_type=True,\n        strict_types=False,\n        datetime=False,\n        unicode_errors=None,\n        buf_size=None,\n    ):\n        self._strict_types = strict_types\n        self._use_float = use_single_float\n        self._autoreset = autoreset\n        self._use_bin_type = use_bin_type\n        self._buffer = BytesIO()\n        self._datetime = bool(datetime)\n        self._unicode_errors = unicode_errors or \"strict\"\n        if default is not None and not callable(default):\n            raise TypeError(\"default must be callable\")\n        self._default = default\n\n    def _pack(\n        self,\n        obj,\n        nest_limit=DEFAULT_RECURSE_LIMIT,\n        check=isinstance,\n        check_type_strict=_check_type_strict,\n    ):\n        default_used = False\n        if self._strict_types:\n            check = check_type_strict\n            list_types = list\n        else:\n            list_types = (list, tuple)\n        while True:\n            if nest_limit < 0:\n                raise ValueError(\"recursion limit exceeded\")\n            if obj is None:\n                return self._buffer.write(b\"\\xc0\")\n            if check(obj, bool):\n                if obj:\n                    return self._buffer.write(b\"\\xc3\")\n                return self._buffer.write(b\"\\xc2\")\n            if check(obj, int):\n                if 0 <= obj < 0x80:\n                    return self._buffer.write(struct.pack(\"B\", obj))\n                if -0x20 <= obj < 0:\n                    return self._buffer.write(struct.pack(\"b\", obj))\n                if 0x80 <= obj <= 0xFF:\n                    return self._buffer.write(struct.pack(\"BB\", 0xCC, obj))\n                if -0x80 <= obj < 0:\n                    return self._buffer.write(struct.pack(\">Bb\", 0xD0, obj))\n                if 0xFF < obj <= 0xFFFF:\n                    return self._buffer.write(struct.pack(\">BH\", 0xCD, obj))\n                if -0x8000 <= obj < -0x80:\n                    return self._buffer.write(struct.pack(\">Bh\", 0xD1, obj))\n                if 0xFFFF < obj <= 0xFFFFFFFF:\n                    return self._buffer.write(struct.pack(\">BI\", 0xCE, obj))\n                if -0x80000000 <= obj < -0x8000:\n                    return self._buffer.write(struct.pack(\">Bi\", 0xD2, obj))\n                if 0xFFFFFFFF < obj <= 0xFFFFFFFFFFFFFFFF:\n                    return self._buffer.write(struct.pack(\">BQ\", 0xCF, obj))\n                if -0x8000000000000000 <= obj < -0x80000000:\n                    return self._buffer.write(struct.pack(\">Bq\", 0xD3, obj))\n                if not default_used and self._default is not None:\n                    obj = self._default(obj)\n                    default_used = True\n                    continue\n                raise OverflowError(\"Integer value out of range\")\n            if check(obj, (bytes, bytearray)):\n                n = len(obj)\n                if n >= 2**32:\n                    raise ValueError(\"%s is too large\" % type(obj).__name__)\n                self._pack_bin_header(n)\n                return self._buffer.write(obj)\n            if check(obj, str):\n                obj = obj.encode(\"utf-8\", self._unicode_errors)\n                n = len(obj)\n                if n >= 2**32:\n                    raise ValueError(\"String is too large\")\n                self._pack_raw_header(n)\n                return self._buffer.write(obj)\n            if check(obj, memoryview):\n                n = obj.nbytes\n                if n >= 2**32:\n                    raise ValueError(\"Memoryview is too large\")\n                self._pack_bin_header(n)\n                return self._buffer.write(obj)\n            if check(obj, float):\n                if self._use_float:\n                    return self._buffer.write(struct.pack(\">Bf\", 0xCA, obj))\n                return self._buffer.write(struct.pack(\">Bd\", 0xCB, obj))\n            if check(obj, (ExtType, Timestamp)):\n                if check(obj, Timestamp):\n                    code = -1\n                    data = obj.to_bytes()\n                else:\n                    code = obj.code\n                    data = obj.data\n                assert isinstance(code, int)\n                assert isinstance(data, bytes)\n                L = len(data)\n                if L == 1:\n                    self._buffer.write(b\"\\xd4\")\n                elif L == 2:\n                    self._buffer.write(b\"\\xd5\")\n                elif L == 4:\n                    self._buffer.write(b\"\\xd6\")\n                elif L == 8:\n                    self._buffer.write(b\"\\xd7\")\n                elif L == 16:\n                    self._buffer.write(b\"\\xd8\")\n                elif L <= 0xFF:\n                    self._buffer.write(struct.pack(\">BB\", 0xC7, L))\n                elif L <= 0xFFFF:\n                    self._buffer.write(struct.pack(\">BH\", 0xC8, L))\n                else:\n                    self._buffer.write(struct.pack(\">BI\", 0xC9, L))\n                self._buffer.write(struct.pack(\"b\", code))\n                self._buffer.write(data)\n                return\n            if check(obj, list_types):\n                n = len(obj)\n                self._pack_array_header(n)\n                for i in range(n):\n                    self._pack(obj[i], nest_limit - 1)\n                return\n            if check(obj, dict):\n                return self._pack_map_pairs(len(obj), obj.items(), nest_limit - 1)\n\n            if self._datetime and check(obj, _DateTime) and obj.tzinfo is not None:\n                obj = Timestamp.from_datetime(obj)\n                default_used = 1\n                continue\n\n            if not default_used and self._default is not None:\n                obj = self._default(obj)\n                default_used = 1\n                continue\n\n            if self._datetime and check(obj, _DateTime):\n                raise ValueError(f\"Cannot serialize {obj!r} where tzinfo=None\")\n\n            raise TypeError(f\"Cannot serialize {obj!r}\")\n\n    def pack(self, obj):\n        try:\n            self._pack(obj)\n        except:\n            self._buffer = BytesIO()  # force reset\n            raise\n        if self._autoreset:\n            ret = self._buffer.getvalue()\n            self._buffer = BytesIO()\n            return ret\n\n    def pack_map_pairs(self, pairs):\n        self._pack_map_pairs(len(pairs), pairs)\n        if self._autoreset:\n            ret = self._buffer.getvalue()\n            self._buffer = BytesIO()\n            return ret\n\n    def pack_array_header(self, n):\n        if n >= 2**32:\n            raise ValueError\n        self._pack_array_header(n)\n        if self._autoreset:\n            ret = self._buffer.getvalue()\n            self._buffer = BytesIO()\n            return ret\n\n    def pack_map_header(self, n):\n        if n >= 2**32:\n            raise ValueError\n        self._pack_map_header(n)\n        if self._autoreset:\n            ret = self._buffer.getvalue()\n            self._buffer = BytesIO()\n            return ret\n\n    def pack_ext_type(self, typecode, data):\n        if not isinstance(typecode, int):\n            raise TypeError(\"typecode must have int type.\")\n        if not 0 <= typecode <= 127:\n            raise ValueError(\"typecode should be 0-127\")\n        if not isinstance(data, bytes):\n            raise TypeError(\"data must have bytes type\")\n        L = len(data)\n        if L > 0xFFFFFFFF:\n            raise ValueError(\"Too large data\")\n        if L == 1:\n            self._buffer.write(b\"\\xd4\")\n        elif L == 2:\n            self._buffer.write(b\"\\xd5\")\n        elif L == 4:\n            self._buffer.write(b\"\\xd6\")\n        elif L == 8:\n            self._buffer.write(b\"\\xd7\")\n        elif L == 16:\n            self._buffer.write(b\"\\xd8\")\n        elif L <= 0xFF:\n            self._buffer.write(b\"\\xc7\" + struct.pack(\"B\", L))\n        elif L <= 0xFFFF:\n            self._buffer.write(b\"\\xc8\" + struct.pack(\">H\", L))\n        else:\n            self._buffer.write(b\"\\xc9\" + struct.pack(\">I\", L))\n        self._buffer.write(struct.pack(\"B\", typecode))\n        self._buffer.write(data)\n\n    def _pack_array_header(self, n):\n        if n <= 0x0F:\n            return self._buffer.write(struct.pack(\"B\", 0x90 + n))\n        if n <= 0xFFFF:\n            return self._buffer.write(struct.pack(\">BH\", 0xDC, n))\n        if n <= 0xFFFFFFFF:\n            return self._buffer.write(struct.pack(\">BI\", 0xDD, n))\n        raise ValueError(\"Array is too large\")\n\n    def _pack_map_header(self, n):\n        if n <= 0x0F:\n            return self._buffer.write(struct.pack(\"B\", 0x80 + n))\n        if n <= 0xFFFF:\n            return self._buffer.write(struct.pack(\">BH\", 0xDE, n))\n        if n <= 0xFFFFFFFF:\n            return self._buffer.write(struct.pack(\">BI\", 0xDF, n))\n        raise ValueError(\"Dict is too large\")\n\n    def _pack_map_pairs(self, n, pairs, nest_limit=DEFAULT_RECURSE_LIMIT):\n        self._pack_map_header(n)\n        for k, v in pairs:\n            self._pack(k, nest_limit - 1)\n            self._pack(v, nest_limit - 1)\n\n    def _pack_raw_header(self, n):\n        if n <= 0x1F:\n            self._buffer.write(struct.pack(\"B\", 0xA0 + n))\n        elif self._use_bin_type and n <= 0xFF:\n            self._buffer.write(struct.pack(\">BB\", 0xD9, n))\n        elif n <= 0xFFFF:\n            self._buffer.write(struct.pack(\">BH\", 0xDA, n))\n        elif n <= 0xFFFFFFFF:\n            self._buffer.write(struct.pack(\">BI\", 0xDB, n))\n        else:\n            raise ValueError(\"Raw is too large\")\n\n    def _pack_bin_header(self, n):\n        if not self._use_bin_type:\n            return self._pack_raw_header(n)\n        elif n <= 0xFF:\n            return self._buffer.write(struct.pack(\">BB\", 0xC4, n))\n        elif n <= 0xFFFF:\n            return self._buffer.write(struct.pack(\">BH\", 0xC5, n))\n        elif n <= 0xFFFFFFFF:\n            return self._buffer.write(struct.pack(\">BI\", 0xC6, n))\n        else:\n            raise ValueError(\"Bin is too large\")\n\n    def bytes(self):\n        \"\"\"Return internal buffer contents as bytes object\"\"\"\n        return self._buffer.getvalue()\n\n    def reset(self):\n        \"\"\"Reset internal buffer.\n\n        This method is useful only when autoreset=False.\n        \"\"\"\n        self._buffer = BytesIO()\n\n    def getbuffer(self):\n        \"\"\"Return view of internal buffer.\"\"\"\n        if _USING_STRINGBUILDER:\n            return memoryview(self.bytes())\n        else:\n            return self._buffer.getbuffer()\n", "msgpack/__init__.py": "# ruff: noqa: F401\nimport os\n\nfrom .exceptions import *  # noqa: F403\nfrom .ext import ExtType, Timestamp\n\nversion = (1, 1, 0, \"rc1\")\n__version__ = \"1.1.0rc1\"\n\n\nif os.environ.get(\"MSGPACK_PUREPYTHON\"):\n    from .fallback import Packer, Unpacker, unpackb\nelse:\n    try:\n        from ._cmsgpack import Packer, Unpacker, unpackb\n    except ImportError:\n        from .fallback import Packer, Unpacker, unpackb\n\n\ndef pack(o, stream, **kwargs):\n    \"\"\"\n    Pack object `o` and write it to `stream`\n\n    See :class:`Packer` for options.\n    \"\"\"\n    packer = Packer(**kwargs)\n    stream.write(packer.pack(o))\n\n\ndef packb(o, **kwargs):\n    \"\"\"\n    Pack object `o` and return packed bytes\n\n    See :class:`Packer` for options.\n    \"\"\"\n    return Packer(**kwargs).pack(o)\n\n\ndef unpack(stream, **kwargs):\n    \"\"\"\n    Unpack an object from `stream`.\n\n    Raises `ExtraData` when `stream` contains extra bytes.\n    See :class:`Unpacker` for options.\n    \"\"\"\n    data = stream.read()\n    return unpackb(data, **kwargs)\n\n\n# alias for compatibility to simplejson/marshal/pickle.\nload = unpack\nloads = unpackb\n\ndump = pack\ndumps = packb\n"}