{"test/individual_coverage.py": "#!/usr/bin/env python3\nimport asyncio\nimport fnmatch\nimport os\nimport re\nimport subprocess\nimport sys\nfrom pathlib import Path\n\nimport tomllib\n\nroot = Path(__file__).parent.parent.absolute()\n\n\nasync def main():\n    with open(\"pyproject.toml\", \"rb\") as f:\n        data = tomllib.load(f)\n\n    exclude = re.compile(\n        \"|\".join(\n            f\"({fnmatch.translate(x)})\"\n            for x in data[\"tool\"][\"pytest\"][\"individual_coverage\"][\"exclude\"]\n        )\n    )\n\n    sem = asyncio.Semaphore(os.cpu_count() or 1)\n\n    async def run_tests(f: Path, should_fail: bool) -> None:\n        if f.name == \"__init__.py\":\n            test_file = Path(\"test\") / f.parent.with_name(f\"test_{f.parent.name}.py\")\n        else:\n            test_file = Path(\"test\") / f.with_name(f\"test_{f.name}\")\n\n        coverage_file = f\".coverage-{str(f).replace('/','-')}\"\n\n        async with sem:\n            try:\n                proc = await asyncio.create_subprocess_exec(\n                    \"pytest\",\n                    \"-qq\",\n                    \"--disable-pytest-warnings\",\n                    \"--cov\",\n                    str(f.with_suffix(\"\")).replace(\"/\", \".\"),\n                    \"--cov-fail-under\",\n                    \"100\",\n                    \"--cov-report\",\n                    \"term-missing:skip-covered\",\n                    test_file,\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                    env={\n                        \"COVERAGE_FILE\": coverage_file,\n                        **os.environ,\n                    },\n                )\n                stdout, stderr = await asyncio.wait_for(proc.communicate(), 60)\n            except TimeoutError:\n                raise RuntimeError(f\"{f}: timeout\")\n            finally:\n                Path(coverage_file).unlink(missing_ok=True)\n\n            if should_fail:\n                if proc.returncode != 0:\n                    print(f\"{f}: excluded\")\n                else:\n                    raise RuntimeError(\n                        f\"{f} is now fully covered by {test_file}. Remove it from tool.pytest.individual_coverage in pyproject.toml.\"\n                    )\n            else:\n                if proc.returncode == 0:\n                    print(f\"{f}: ok\")\n                else:\n                    raise RuntimeError(\n                        f\"{f} is not fully covered by {test_file}:\\n{stdout.decode(errors='ignore')}\\n{stderr.decode(errors='ignore')}\"\n                    )\n\n    tasks = []\n    for f in (root / \"mitmproxy\").glob(\"**/*.py\"):\n        f = f.relative_to(root)\n\n        if len(sys.argv) > 1 and sys.argv[1] not in str(f):\n            continue\n\n        if f.name == \"__init__.py\" and f.stat().st_size == 0:\n            print(f\"{f}: empty\")\n            continue\n\n        tasks.append(\n            asyncio.create_task(run_tests(f, should_fail=exclude.match(str(f))))\n        )\n\n    exit_code = 0\n    for task in asyncio.as_completed(tasks):\n        try:\n            await task\n        except RuntimeError as e:\n            print(e)\n            exit_code = 1\n\n    sys.exit(exit_code)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n", "test/conftest.py": "from __future__ import annotations\n\nimport asyncio\nimport os\nimport socket\nimport sys\n\nimport pytest\n\nfrom mitmproxy.utils import data\n\nskip_windows = pytest.mark.skipif(os.name == \"nt\", reason=\"Skipping due to Windows\")\n\nskip_not_windows = pytest.mark.skipif(\n    os.name != \"nt\", reason=\"Skipping due to not Windows\"\n)\n\ntry:\n    s = socket.socket(socket.AF_INET6, socket.SOCK_STREAM)\n    s.bind((\"::1\", 0))\n    s.close()\nexcept OSError:\n    no_ipv6 = True\nelse:\n    no_ipv6 = False\n\nskip_no_ipv6 = pytest.mark.skipif(no_ipv6, reason=\"Host has no IPv6 support\")\n\n\nclass EagerTaskCreationEventLoopPolicy(asyncio.DefaultEventLoopPolicy):\n    def new_event_loop(self):\n        loop = super().new_event_loop()\n        if sys.version_info >= (3, 12):\n            loop.set_task_factory(asyncio.eager_task_factory)\n        return loop\n\n\n@pytest.fixture()\ndef event_loop_policy(request):\n    return EagerTaskCreationEventLoopPolicy()\n\n\n@pytest.fixture()\ndef tdata():\n    return data.Data(__name__)\n\n\nclass AsyncLogCaptureFixture:\n    def __init__(self, caplog: pytest.LogCaptureFixture):\n        self.caplog = caplog\n\n    def set_level(self, level: int | str, logger: str | None = None) -> None:\n        self.caplog.set_level(level, logger)\n\n    async def await_log(self, text, timeout=2):\n        await asyncio.sleep(0)\n        for i in range(int(timeout / 0.01)):\n            if text in self.caplog.text:\n                return True\n            else:\n                await asyncio.sleep(0.01)\n        raise AssertionError(f\"Did not find {text!r} in log:\\n{self.caplog.text}\")\n\n    def clear(self) -> None:\n        self.caplog.clear()\n\n\n@pytest.fixture\ndef caplog_async(caplog):\n    return AsyncLogCaptureFixture(caplog)\n", "test/filename_matching.py": "#!/usr/bin/env python3\nimport glob\nimport os\nimport re\nimport sys\n\n\ndef check_src_files_have_test():\n    missing_test_files = []\n\n    excluded = [\n        \"mitmproxy/contrib/\",\n        \"mitmproxy/io/proto/\",\n        \"mitmproxy/proxy/layers/http\",\n        \"mitmproxy/test/\",\n        \"mitmproxy/tools/\",\n        \"mitmproxy/platform/\",\n        \"mitmproxy/utils/pyinstaller/\",\n    ]\n    src_files = glob.glob(\"mitmproxy/**/*.py\", recursive=True)\n    src_files = [f for f in src_files if os.path.basename(f) != \"__init__.py\"]\n    src_files = [\n        f for f in src_files if not any(os.path.normpath(p) in f for p in excluded)\n    ]\n    for f in src_files:\n        p = os.path.join(\"test\", os.path.dirname(f), \"test_\" + os.path.basename(f))\n        if not os.path.isfile(p):\n            missing_test_files.append((f, p))\n\n    return missing_test_files\n\n\ndef check_test_files_have_src():\n    unknown_test_files = []\n\n    excluded = [\n        \"test/mitmproxy/data/\",\n        \"test/mitmproxy/net/data/\",\n        \"/tservers.py\",\n        \"/conftest.py\",\n    ]\n    test_files = glob.glob(\"test/mitmproxy/**/*.py\", recursive=True)\n    test_files = [f for f in test_files if os.path.basename(f) != \"__init__.py\"]\n    test_files = [\n        f for f in test_files if not any(os.path.normpath(p) in f for p in excluded)\n    ]\n    for f in test_files:\n        p = os.path.join(\n            re.sub(\"^test/\", \"\", os.path.dirname(f)),\n            re.sub(\"^test_\", \"\", os.path.basename(f)),\n        )\n        if not os.path.isfile(p):\n            unknown_test_files.append((f, p))\n\n    return unknown_test_files\n\n\ndef main():\n    exitcode = 0\n\n    missing_test_files = check_src_files_have_test()\n    if missing_test_files:\n        exitcode += 1\n        for f, p in sorted(missing_test_files):\n            print(f\"{f} MUST have a matching test file: {p}\")\n\n    unknown_test_files = check_test_files_have_src()\n    if unknown_test_files:\n        # TODO: enable this in the future\n        # exitcode += 1\n        for f, p in sorted(unknown_test_files):\n            print(f\"{f} DOES NOT MATCH a source file! Expected to find: {p}\")\n\n    sys.exit(exitcode)\n\n\nif __name__ == \"__main__\":\n    main()\n", "test/__init__.py": "", "test/bench/benchmark.py": "import asyncio\nimport cProfile\nimport logging\n\nfrom mitmproxy import ctx\n\n\nclass Benchmark:\n    \"\"\"\n    A simple profiler addon.\n    \"\"\"\n\n    def __init__(self):\n        self.pr = cProfile.Profile()\n        self.started = False\n\n        self.resps = 0\n        self.reqs = 0\n\n    def request(self, f):\n        self.reqs += 1\n\n    def response(self, f):\n        self.resps += 1\n\n    async def procs(self):\n        logging.error(\"starting benchmark\")\n        backend = await asyncio.create_subprocess_exec(\"devd\", \"-q\", \"-p\", \"10001\", \".\")\n        traf = await asyncio.create_subprocess_exec(\n            \"wrk\",\n            \"-c50\",\n            \"-d5s\",\n            \"http://localhost:%s/benchmark.py\" % ctx.master.server.address[1],\n            stdout=asyncio.subprocess.PIPE,\n        )\n        stdout, _ = await traf.communicate()\n        with open(ctx.options.benchmark_save_path + \".bench\", mode=\"wb\") as f:\n            f.write(stdout)\n        logging.error(f\"Proxy saw {self.reqs} requests, {self.resps} responses\")\n        logging.error(stdout.decode(\"ascii\"))\n        backend.kill()\n        ctx.master.shutdown()\n\n    def load(self, loader):\n        loader.add_option(\n            \"benchmark_save_path\",\n            str,\n            \"/tmp/profile\",\n            \"Destination for the .prof and .bench result files\",\n        )\n        ctx.options.update(\n            mode=\"reverse:http://devd.io:10001\",\n        )\n        self.pr.enable()\n\n    def running(self):\n        if not self.started:\n            self.started = True\n            self._task = asyncio.create_task(self.procs())\n\n    def done(self):\n        self.pr.dump_stats(ctx.options.benchmark_save_path + \".prof\")\n\n\naddons = [Benchmark()]\n", "test/helper_tools/inspect_dumpfile.py": "#!/usr/bin/env python3\nfrom pprint import pprint\n\nimport click\n\nfrom mitmproxy.io import tnetstring\n\n\ndef read_tnetstring(input):\n    # tnetstring throw a ValueError on EOF, which is hard to catch\n    # because they raise ValueErrors for a couple of other reasons.\n    # Check for EOF to avoid this.\n    if not input.read(1):\n        return None\n    else:\n        input.seek(-1, 1)\n    return tnetstring.load(input)\n\n\n@click.command()\n@click.argument(\"input\", type=click.File(\"rb\"))\ndef inspect(input):\n    \"\"\"\n    pretty-print a dumpfile\n    \"\"\"\n    while True:\n        data = read_tnetstring(input)\n        if not data:\n            break\n        pprint(data)\n\n\nif __name__ == \"__main__\":\n    inspect()\n", "test/helper_tools/linkify-changelog.py": "#!/usr/bin/env python3\nimport re\nfrom pathlib import Path\n\nchangelog = Path(__file__).parent / \"../../CHANGELOG.md\"\n\ntext = changelog.read_text(encoding=\"utf8\")\ntext, n = re.subn(\n    r\"\\s*\\(([^)]+)#(\\d+)\\)\",\n    \"\\n  (\\\\1[#\\\\2](https://github.com/mitmproxy/mitmproxy/issues/\\\\2))\",\n    text,\n)\nchangelog.write_text(text, encoding=\"utf8\")\nprint(f\"Linkified {n} issues and users.\")\n", "test/helper_tools/passive_close.py": "import socketserver\nfrom time import sleep\n\n\nclass service(socketserver.BaseRequestHandler):\n    def handle(self):\n        data = \"dummy\"\n        print(\"Client connected with \", self.client_address)\n        while True:\n            self.request.send(\n                \"HTTP/1.1 200 OK\\r\\nConnection: close\\r\\nContent-Length: 7\\r\\n\\r\\ncontent\"\n            )\n            data = self.request.recv(1024)\n            if not len(data):\n                print(\"Connection closed by remote: \", self.client_address)\n                sleep(3600)\n\n\nclass ThreadedTCPServer(socketserver.ThreadingMixIn, socketserver.TCPServer):\n    pass\n\n\nserver = ThreadedTCPServer((\"\", 1520), service)\nserver.serve_forever()\n", "test/helper_tools/hunt_memory_leaks.py": "import collections\nimport gc\nimport os\nimport signal\n\nfrom mitmproxy import flow\n\n\ndef load(loader):\n    signal.signal(signal.SIGUSR1, debug1)\n    signal.signal(signal.SIGUSR2, debug2)\n    print(f\"Debug signal registered. Run the following commands for diagnostics:\")\n    print()\n    print(f\"  kill -s USR1 {os.getpid()}\")\n    print(f\"  kill -s USR2 {os.getpid()}\")\n    print()\n\n\ndef debug1(*_):\n    print()\n    print(\"Before GC\")\n    print(\"=======\")\n    print(\"gc.get_stats\", gc.get_stats())\n    print(\"gc.get_count\", gc.get_count())\n    print(\"gc.get_threshold\", gc.get_threshold())\n\n    gc.collect()\n\n    print()\n    print(\"After GC\")\n    print(\"=======\")\n    print(\"gc.get_stats\", gc.get_stats())\n    print(\"gc.get_count\", gc.get_count())\n    print(\"gc.get_threshold\", gc.get_threshold())\n\n    print()\n    print(\"Memory\")\n    print(\"=======\")\n    for t, count in collections.Counter(\n        [str(type(o)) for o in gc.get_objects()]\n    ).most_common(50):\n        print(count, t)\n\n\ndef debug2(*_):\n    print()\n    print(\"Flow References\")\n    print(\"=======\")\n\n    # gc.collect()\n\n    objs = tuple(gc.get_objects())\n    ignore = {id(objs)}  # noqa\n    flows = 0\n    for i in range(len(objs)):\n        try:\n            is_flow = isinstance(objs[i], flow.Flow)\n        except Exception:\n            continue\n        if is_flow:\n            flows += 1\n            # print_refs(objs[i], ignore, set())\n            # break\n    del objs\n\n    print(f\"{flows} flows found.\")\n\n\ndef print_refs(x, ignore: set, seen: set, depth: int = 0, max_depth: int = 10):\n    if id(x) in ignore:\n        return\n\n    if id(x) in seen:\n        print(\n            \"  \" * depth\n            + \"\u2196 \"\n            + repr(str(x))[1:60]\n            + f\" (\\x1b[31mseen\\x1b[0m: {id(x):x})\"\n        )\n        return\n    else:\n        if depth == 0:\n            print(\"- \" + repr(str(x))[1:60] + f\" ({id(x):x})\")\n        else:\n            print(\"  \" * depth + \"\u2196 \" + repr(str(x))[1:60] + f\" ({id(x):x})\")\n        seen.add(id(x))\n\n    if depth == max_depth:\n        return\n\n    referrers = tuple(gc.get_referrers(x))\n    ignore.add(id(referrers))\n    for ref in referrers:\n        print_refs(ref, ignore, seen, depth + 1, max_depth)\n", "test/helper_tools/memoryleak2.py": "import secrets\nfrom pathlib import Path\n\nimport objgraph\n\nfrom mitmproxy import certs\n\nif __name__ == \"__main__\":\n    store = certs.CertStore.from_store(\n        path=Path(\"~/.mitmproxy/\").expanduser(), basename=\"mitmproxy\", key_size=2048\n    )\n    store.STORE_CAP = 5\n\n    for _ in range(5):\n        store.get_cert(\n            commonname=secrets.token_hex(16).encode(), sans=[], organization=None\n        )\n\n    objgraph.show_growth()\n\n    for _ in range(20):\n        store.get_cert(\n            commonname=secrets.token_hex(16).encode(), sans=[], organization=None\n        )\n\n    print(\"====\")\n    objgraph.show_growth()\n", "test/helper_tools/memoryleak.py": "import gc\nimport threading\n\nfrom OpenSSL import SSL\nfrom pympler import muppy\nfrom pympler import refbrowser\n\n# import os\n# os.environ[\"TK_LIBRARY\"] = r\"C:\\Python27\\tcl\\tcl8.5\"\n# os.environ[\"TCL_LIBRARY\"] = r\"C:\\Python27\\tcl\\tcl8.5\"\n\n# Also noteworthy: guppy, objgraph\n\nstep = 0\n__memory_locals__ = True\n\n\ndef str_fun(obj):\n    if isinstance(obj, dict):\n        if \"__memory_locals__\" in obj:\n            return \"(-locals-)\"\n        if \"self\" in obj and isinstance(obj[\"self\"], refbrowser.InteractiveBrowser):\n            return \"(-browser-)\"\n    return (\n        str(id(obj))\n        + \": \"\n        + str(obj)[:100].replace(\"\\r\\n\", \"\\\\r\\\\n\").replace(\"\\n\", \"\\\\n\")\n    )\n\n\ndef request(ctx, flow):\n    global step, ssl\n    print(\"==========\")\n    print(f\"GC: {gc.collect()}\")\n    print(f\"Threads: {threading.active_count()}\")\n\n    step += 1\n    if step == 1:\n        all_objects = muppy.get_objects()\n        ssl = muppy.filter(all_objects, SSL.Connection)[0]\n    if step == 2:\n        ib = refbrowser.InteractiveBrowser(ssl, 2, str_fun, repeat=False)\n        del ssl  # do this to unpollute view\n        ib.main(True)\n        # print(\"\\r\\n\".join(str(x)[:100] for x in gc.get_referrers(ssl)))\n", "test/helper_tools/dumperview.py": "#!/usr/bin/env python3\nimport asyncio\n\nimport click\n\nfrom mitmproxy.addons import dumper\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\ndef run_async(coro):\n    \"\"\"\n    Run the given async function in a new event loop.\n    This allows async functions to be called synchronously.\n    \"\"\"\n    loop = asyncio.new_event_loop()\n    try:\n        return loop.run_until_complete(coro)\n    finally:\n        loop.close()\n\n\ndef show(flow_detail, flows):\n    d = dumper.Dumper()\n    with taddons.context() as ctx:\n        ctx.configure(d, flow_detail=flow_detail)\n        for f in flows:\n            run_async(ctx.cycle(d, f))\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\n@click.option(\"--level\", default=1, help=\"Detail level\")\ndef tcp(level):\n    f1 = tflow.ttcpflow()\n    show(level, [f1])\n\n\n@cli.command()\n@click.option(\"--level\", default=1, help=\"Detail level\")\ndef udp(level):\n    f1 = tflow.tudpflow()\n    show(level, [f1])\n\n\n@cli.command()\n@click.option(\"--level\", default=1, help=\"Detail level\")\ndef large(level):\n    f1 = tflow.tflow(resp=True)\n    f1.response.headers[\"content-type\"] = \"text/html\"\n    f1.response.content = b\"foo bar voing\\n\" * 100\n    show(level, [f1])\n\n\n@cli.command()\n@click.option(\"--level\", default=1, help=\"Detail level\")\ndef small(level):\n    f1 = tflow.tflow(resp=True)\n    f1.response.headers[\"content-type\"] = \"text/html\"\n    f1.response.content = b\"<html><body>Hello!</body></html>\"\n\n    f2 = tflow.tflow(err=True)\n\n    show(\n        level,\n        [\n            f1,\n            f2,\n        ],\n    )\n\n\nif __name__ == \"__main__\":\n    cli()\n", "test/helper_tools/loggrep.py": "#!/usr/bin/env python3\nimport fileinput\nimport re\nimport sys\n\nif __name__ == \"__main__\":\n    if len(sys.argv) < 3:\n        print(f\"Usage: {sys.argv[0]} port filenames\")\n        sys.exit()\n\n    port = sys.argv[1]\n    matches = False\n    for line in fileinput.input(sys.argv[2:]):\n        if re.match(r\"^\\[|(\\d+\\.){3}\", line):\n            matches = port in line\n        if matches:\n            print(line, end=\"\")\n", "test/examples/test_examples.py": "from mitmproxy import contentviews\nfrom mitmproxy.http import Headers\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nclass TestScripts:\n    def test_add_header(self, tdata):\n        with taddons.context() as tctx:\n            a = tctx.script(tdata.path(\"../examples/addons/anatomy2.py\"))\n            f = tflow.tflow()\n            a.request(f)\n            assert f.request.headers[\"myheader\"] == \"value\"\n\n    def test_custom_contentviews(self, tdata):\n        with taddons.context() as tctx:\n            tctx.script(tdata.path(\"../examples/addons/contentview.py\"))\n            swapcase = contentviews.get(\"swapcase\")\n            _, fmt = swapcase(b\"<html>Test!</html>\")\n            assert any(b\"tEST!\" in val[0][1] for val in fmt)\n\n    def test_custom_grpc_contentview(self, tdata):\n        with taddons.context() as tctx:\n            tctx.script(tdata.path(\"../examples/addons/contentview-custom-grpc.py\"))\n            v = contentviews.get(\"customized gRPC/protobuf\")\n\n            p = tdata.path(\"mitmproxy/contentviews/test_grpc_data/msg1.bin\")\n            with open(p, \"rb\") as f:\n                raw = f.read()\n\n            sim_msg_req = tutils.treq(\n                port=443, host=\"example.com\", path=\"/ReverseGeocode\"\n            )\n\n            sim_msg_resp = tutils.tresp()\n\n            sim_flow = tflow.tflow(req=sim_msg_req, resp=sim_msg_resp)\n\n            view_text, output = v(\n                raw, flow=sim_flow, http_message=sim_flow.request\n            )  # simulate request message\n            assert view_text == \"Protobuf (flattened) (addon with custom rules)\"\n            output = list(output)  # assure list conversion if generator\n            assert output == [\n                [\n                    (\"text\", \"[message]  \"),\n                    (\"text\", \"position   \"),\n                    (\"text\", \"1    \"),\n                    (\"text\", \"                               \"),\n                ],\n                [\n                    (\"text\", \"[double]   \"),\n                    (\"text\", \"latitude   \"),\n                    (\"text\", \"1.1  \"),\n                    (\"text\", \"38.89816675798073              \"),\n                ],\n                [\n                    (\"text\", \"[double]   \"),\n                    (\"text\", \"longitude  \"),\n                    (\"text\", \"1.2  \"),\n                    (\"text\", \"-77.03829828366696             \"),\n                ],\n                [\n                    (\"text\", \"[string]   \"),\n                    (\"text\", \"country    \"),\n                    (\"text\", \"3    \"),\n                    (\"text\", \"de_DE                          \"),\n                ],\n                [\n                    (\"text\", \"[uint32]   \"),\n                    (\"text\", \"           \"),\n                    (\"text\", \"6    \"),\n                    (\"text\", \"1                              \"),\n                ],\n                [\n                    (\"text\", \"[string]   \"),\n                    (\"text\", \"app        \"),\n                    (\"text\", \"7    \"),\n                    (\"text\", \"de.mcdonalds.mcdonaldsinfoapp  \"),\n                ],\n            ]\n\n    def test_modify_form(self, tdata):\n        with taddons.context() as tctx:\n            sc = tctx.script(tdata.path(\"../examples/addons/http-modify-form.py\"))\n\n            form_header = Headers(content_type=\"application/x-www-form-urlencoded\")\n            f = tflow.tflow(req=tutils.treq(headers=form_header))\n            sc.request(f)\n\n            assert f.request.urlencoded_form[\"mitmproxy\"] == \"rocks\"\n\n            f.request.headers[\"content-type\"] = \"\"\n            sc.request(f)\n            assert list(f.request.urlencoded_form.items()) == [(\"foo\", \"bar\")]\n\n    def test_modify_querystring(self, tdata):\n        with taddons.context() as tctx:\n            sc = tctx.script(\n                tdata.path(\"../examples/addons/http-modify-query-string.py\")\n            )\n            f = tflow.tflow(req=tutils.treq(path=\"/search?q=term\"))\n\n            sc.request(f)\n            assert f.request.query[\"mitmproxy\"] == \"rocks\"\n\n            f.request.path = \"/\"\n            sc.request(f)\n            assert f.request.query[\"mitmproxy\"] == \"rocks\"\n\n    def test_redirect_requests(self, tdata):\n        with taddons.context() as tctx:\n            sc = tctx.script(tdata.path(\"../examples/addons/http-redirect-requests.py\"))\n            f = tflow.tflow(req=tutils.treq(host=\"example.org\"))\n            sc.request(f)\n            assert f.request.host == \"mitmproxy.org\"\n\n    def test_send_reply_from_proxy(self, tdata):\n        with taddons.context() as tctx:\n            sc = tctx.script(tdata.path(\"../examples/addons/http-reply-from-proxy.py\"))\n            f = tflow.tflow(req=tutils.treq(host=\"example.com\", port=80))\n            sc.request(f)\n            assert f.response.content == b\"Hello World\"\n", "test/examples/__init__.py": "", "test/mitmproxy/test_tls.py": "from mitmproxy import tls\n\nCLIENT_HELLO_NO_EXTENSIONS = bytes.fromhex(\n    \"03015658a756ab2c2bff55f636814deac086b7ca56b65058c7893ffc6074f5245f70205658a75475103a152637\"\n    \"78e1bb6d22e8bbd5b6b0a3a59760ad354e91ba20d353001a0035002f000a000500040009000300060008006000\"\n    \"61006200640100\"\n)\nFULL_CLIENT_HELLO_NO_EXTENSIONS = (\n    b\"\\x16\\x03\\x03\\x00\\x65\"  # record layer\n    b\"\\x01\\x00\\x00\\x61\" + CLIENT_HELLO_NO_EXTENSIONS  # handshake header\n)\n\n\nclass TestClientHello:\n    def test_no_extensions(self):\n        c = tls.ClientHello(CLIENT_HELLO_NO_EXTENSIONS)\n        assert repr(c)\n        assert c.sni is None\n        assert c.cipher_suites == [53, 47, 10, 5, 4, 9, 3, 6, 8, 96, 97, 98, 100]\n        assert c.alpn_protocols == []\n        assert c.extensions == []\n        assert c.raw_bytes(False) == CLIENT_HELLO_NO_EXTENSIONS\n        assert c.raw_bytes(True) == FULL_CLIENT_HELLO_NO_EXTENSIONS\n\n    def test_extensions(self):\n        data = bytes.fromhex(\n            \"03033b70638d2523e1cba15f8364868295305e9c52aceabda4b5147210abc783e6e1000022c02bc02fc02cc030\"\n            \"cca9cca8cc14cc13c009c013c00ac014009c009d002f0035000a0100006cff0100010000000010000e00000b65\"\n            \"78616d706c652e636f6d0017000000230000000d00120010060106030501050304010403020102030005000501\"\n            \"00000000001200000010000e000c02683208687474702f312e3175500000000b00020100000a00080006001d00\"\n            \"170018\"\n        )\n        c = tls.ClientHello(data)\n        assert repr(c)\n        assert c.sni == \"example.com\"\n        assert c.cipher_suites == [\n            49195,\n            49199,\n            49196,\n            49200,\n            52393,\n            52392,\n            52244,\n            52243,\n            49161,\n            49171,\n            49162,\n            49172,\n            156,\n            157,\n            47,\n            53,\n            10,\n        ]\n        assert c.alpn_protocols == [b\"h2\", b\"http/1.1\"]\n        assert c.extensions == [\n            (65281, b\"\\x00\"),\n            (0, b\"\\x00\\x0e\\x00\\x00\\x0bexample.com\"),\n            (23, b\"\"),\n            (35, b\"\"),\n            (\n                13,\n                b\"\\x00\\x10\\x06\\x01\\x06\\x03\\x05\\x01\\x05\\x03\\x04\\x01\\x04\\x03\\x02\\x01\\x02\\x03\",\n            ),\n            (5, b\"\\x01\\x00\\x00\\x00\\x00\"),\n            (18, b\"\"),\n            (16, b\"\\x00\\x0c\\x02h2\\x08http/1.1\"),\n            (30032, b\"\"),\n            (11, b\"\\x01\\x00\"),\n            (10, b\"\\x00\\x06\\x00\\x1d\\x00\\x17\\x00\\x18\"),\n        ]\n\n\nDTLS_CLIENT_HELLO_NO_EXTENSIONS = bytes.fromhex(\n    # No Record or Handshake layer header\n    \"fefd62bf5560a83b2525186d38fb6459837656d7f11\"\n    \"fb630cd44683bb9d9681204c50000000c00020003000a00050004000901000000\"\n)\n\n\nclass TestDTLSClientHello:\n    def test_no_extensions(self):\n        c = tls.ClientHello(DTLS_CLIENT_HELLO_NO_EXTENSIONS, dtls=True)\n        assert repr(c)\n        assert c.sni is None\n        assert c.cipher_suites == [2, 3, 10, 5, 4, 9]\n        assert c.alpn_protocols == []\n        assert c.extensions == []\n\n    def test_extensions(self):\n        # No Record or Handshake layer header\n        data = bytes.fromhex(\n            \"fefd62bf60ba96532f63c4e53196174ff5016d949420d7f970a6b08a9e2a5a8209af0000\"\n            \"000c00020003000a000500040009\"\n            \"01000055000d0010000e0403050306030401050106010807ff01000100000a00080006001d\"\n            \"00170018000b000201000017000000000010000e00000b6578616d706c652e636f6d0010000e\"\n            \"000c02683208687474702f312e31\"\n        )\n        c = tls.ClientHello(data, dtls=True)\n        assert repr(c)\n        assert c.sni == \"example.com\"\n        assert c.cipher_suites == [2, 3, 10, 5, 4, 9]\n        assert c.alpn_protocols == [b\"h2\", b\"http/1.1\"]\n        assert c.extensions == [\n            (13, b\"\\x00\\x0e\\x04\\x03\\x05\\x03\\x06\\x03\\x04\\x01\\x05\\x01\\x06\\x01\\x08\\x07\"),\n            (65281, b\"\\x00\"),\n            (10, b\"\\x00\\x06\\x00\\x1d\\x00\\x17\\x00\\x18\"),\n            (11, b\"\\x01\\x00\"),\n            (23, b\"\"),\n            (0, b\"\\x00\\x0e\\x00\\x00\\x0bexample.com\"),\n            (16, b\"\\x00\\x0c\\x02h2\\x08http/1.1\"),\n        ]\n", "test/mitmproxy/test_command_lexer.py": "import pyparsing\nimport pytest\nfrom hypothesis import example\nfrom hypothesis import given\nfrom hypothesis.strategies import text\n\nfrom mitmproxy import command_lexer\n\n\n@pytest.mark.parametrize(\n    \"test_input,valid\",\n    [\n        (\"'foo'\", True),\n        ('\"foo\"', True),\n        (\"'foo' bar'\", False),\n        (\"'foo' 'bar'\", False),\n        (\"'foo'x\", False),\n        (\"\"\"\"foo    \"\"\", True),\n        (\"\"\"\"foo 'bar'   \"\"\", True),\n        ('\"foo\\\\', True),\n    ],\n)\ndef test_partial_quoted_string(test_input, valid):\n    if valid:\n        assert (\n            command_lexer.PartialQuotedString.parseString(test_input, parseAll=True)[0]\n            == test_input\n        )\n    else:\n        with pytest.raises(pyparsing.ParseException):\n            command_lexer.PartialQuotedString.parseString(test_input, parseAll=True)\n\n\n@pytest.mark.parametrize(\n    \"test_input,expected\",\n    [\n        (\"'foo'\", [\"'foo'\"]),\n        ('\"foo\"', ['\"foo\"']),\n        (\"'foo' 'bar'\", [\"'foo'\", \" \", \"'bar'\"]),\n        (\"'foo'x\", [\"'foo'\", \"x\"]),\n        (\"\"\"\"foo\"\"\", ['\"foo']),\n        (\"\"\"\"foo 'bar' \"\"\", [\"\"\"\"foo 'bar' \"\"\"]),\n        ('\"foo\\\\', ['\"foo\\\\']),\n    ],\n)\ndef test_expr(test_input, expected):\n    assert list(command_lexer.expr.parseString(test_input, parseAll=True)) == expected\n\n\n@given(text())\n@example(r\"foo\")\n@example(r\"'foo\\''\")\n@example(r\"'foo\\\"'\")\n@example(r'\"foo\\\"\"')\n@example(r'\"foo\\'\"')\n@example(\"'foo\\\\'\")\n@example(\"'foo\\\\\\\\'\")\n@example('\"foo\\\\\\'\"')\n@example('\"foo\\\\\\\\\\'\"')\n@example(\"'foo\\\\\\\"'\")\n@example(r\"\\\\\\foo\")\ndef test_quote_unquote_cycle(s):\n    assert command_lexer.unquote(command_lexer.quote(s)).replace(r\"\\x22\", '\"') == s\n\n\n@given(text())\n@example(\"'foo\\\\'\")\ndef test_unquote_never_fails(s):\n    command_lexer.unquote(s)\n", "test/mitmproxy/test_dns.py": "import ipaddress\nimport struct\n\nimport pytest\n\nfrom mitmproxy import dns\nfrom mitmproxy import flowfilter\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nclass TestResourceRecord:\n    def test_str(self):\n        assert (\n            str(dns.ResourceRecord.A(\"test\", ipaddress.IPv4Address(\"1.2.3.4\")))\n            == \"1.2.3.4\"\n        )\n        assert (\n            str(dns.ResourceRecord.AAAA(\"test\", ipaddress.IPv6Address(\"::1\"))) == \"::1\"\n        )\n        assert (\n            str(dns.ResourceRecord.CNAME(\"test\", \"some.other.host\"))\n            == \"some.other.host\"\n        )\n        assert (\n            str(dns.ResourceRecord.PTR(\"test\", \"some.other.host\")) == \"some.other.host\"\n        )\n        assert (\n            str(dns.ResourceRecord.TXT(\"test\", \"unicode text \ud83d\ude00\")) == \"unicode text \ud83d\ude00\"\n        )\n        params = {\n            0: b\"\\x00\",\n            1: b\"\\x01\",\n            2: b\"\",\n            3: b\"\\x02\",\n            4: b\"\\x03\",\n            5: b\"\\x04\",\n            6: b\"\\x05\",\n        }\n        record = dns.https_records.HTTPSRecord(1, \"example.com\", params)\n        assert (\n            str(dns.ResourceRecord.HTTPS(\"example.com\", record))\n            == \"priority: 1 target_name: 'example.com' {'mandatory': b'\\\\x00', 'alpn': b'\\\\x01', 'no_default_alpn': b'', 'port': b'\\\\x02', 'ipv4hint': b'\\\\x03', 'ech': b'\\\\x04', 'ipv6hint': b'\\\\x05'}\"\n        )\n        assert (\n            str(\n                dns.ResourceRecord(\n                    \"test\",\n                    dns.types.A,\n                    dns.classes.IN,\n                    dns.ResourceRecord.DEFAULT_TTL,\n                    b\"\",\n                )\n            )\n            == \"0x (invalid A data)\"\n        )\n        assert (\n            str(\n                dns.ResourceRecord(\n                    \"test\",\n                    dns.types.SOA,\n                    dns.classes.IN,\n                    dns.ResourceRecord.DEFAULT_TTL,\n                    b\"\\x00\\x01\\x02\\x03\",\n                )\n            )\n            == \"0x00010203\"\n        )\n\n    def test_setter(self):\n        rr = dns.ResourceRecord(\n            \"test\", dns.types.ANY, dns.classes.IN, dns.ResourceRecord.DEFAULT_TTL, b\"\"\n        )\n        rr.ipv4_address = ipaddress.IPv4Address(\"8.8.4.4\")\n        assert rr.ipv4_address == ipaddress.IPv4Address(\"8.8.4.4\")\n        rr.ipv6_address = ipaddress.IPv6Address(\"2001:4860:4860::8844\")\n        assert rr.ipv6_address == ipaddress.IPv6Address(\"2001:4860:4860::8844\")\n        rr.domain_name = \"www.example.org\"\n        assert rr.domain_name == \"www.example.org\"\n        rr.text = \"sample text\"\n        assert rr.text == \"sample text\"\n        params = {3: b\"\\x01\\xbb\"}\n        record = dns.https_records.HTTPSRecord(1, \"example.org\", params)\n        rr.data = dns.https_records.pack(record)\n        assert rr.https_ech is None\n        rr.https_ech = \"dGVzdHN0cmluZwo=\"\n        assert rr.https_ech == \"dGVzdHN0cmluZwo=\"\n        rr.https_ech = None\n        assert rr.https_ech is None\n\n\nclass TestMessage:\n    def test_json(self):\n        resp = tutils.tdnsresp()\n        json = resp.to_json()\n        assert json[\"id\"] == resp.id\n        assert len(json[\"questions\"]) == len(resp.questions)\n        assert json[\"questions\"][0][\"name\"] == resp.questions[0].name\n        assert len(json[\"answers\"]) == len(resp.answers)\n        assert json[\"answers\"][0][\"data\"] == str(resp.answers[0])\n\n    def test_responses(self):\n        req = tutils.tdnsreq()\n        resp = tutils.tdnsresp()\n        resp2 = req.succeed(\n            [\n                dns.ResourceRecord.A(\n                    \"dns.google\", ipaddress.IPv4Address(\"8.8.8.8\"), ttl=32\n                ),\n                dns.ResourceRecord.A(\n                    \"dns.google\", ipaddress.IPv4Address(\"8.8.4.4\"), ttl=32\n                ),\n            ]\n        )\n        resp2.timestamp = resp.timestamp\n        assert resp == resp2\n        assert resp2.size == 8\n        with pytest.raises(ValueError):\n            req.fail(dns.response_codes.NOERROR)\n        assert (\n            req.fail(dns.response_codes.FORMERR).response_code\n            == dns.response_codes.FORMERR\n        )\n\n    def test_range(self):\n        def test(what: str, min: int, max: int):\n            req = tutils.tdnsreq()\n            setattr(req, what, min)\n            assert getattr(dns.Message.unpack(req.packed), what) == min\n            setattr(req, what, min - 1)\n            with pytest.raises(ValueError):\n                req.packed\n            setattr(req, what, max)\n            assert getattr(dns.Message.unpack(req.packed), what) == max\n            setattr(req, what, max + 1)\n            with pytest.raises(ValueError):\n                req.packed\n\n        test(\"id\", 0, 2**16 - 1)\n        test(\"reserved\", 0, 7)\n        test(\"op_code\", 0, 0b1111)\n        test(\"response_code\", 0, 0b1111)\n\n    def test_packing(self):\n        def assert_eq(m: dns.Message, b: bytes) -> None:\n            m_b = dns.Message.unpack(b)\n            m_b.timestamp = m.timestamp\n            assert m_b == m\n            assert m_b.packed == m.packed\n\n        assert_eq(\n            tutils.tdnsreq(),\n            b\"\\x00\\x2a\\x01\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x03dns\\x06google\\x00\\x00\\x01\\x00\\x01\",\n        )\n        with pytest.raises(struct.error):\n            dns.Message.unpack(\n                b\"\\x00\\x2a\\x01\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x03dns\\x06google\\x00\\x00\\x01\\x00\\x01\\x00\"\n            )\n        assert_eq(\n            tutils.tdnsresp(),\n            (\n                b\"\\x00\\x2a\\x81\\x80\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x00\\x03dns\\x06google\\x00\\x00\\x01\\x00\\x01\"\n                b\"\\xc0\\x0c\\x00\\x01\\x00\\x01\\x00\\x00\\x00 \\x00\\x04\\x08\\x08\\x08\\x08\\xc0\\x0c\\x00\\x01\\x00\\x01\"\n                b\"\\x00\\x00\\x00 \\x00\\x04\\x08\\x08\\x04\\x04\"\n            ),\n        )\n        with pytest.raises(struct.error):  # question error\n            dns.Message.unpack(\n                b\"\\x00\\x2a\\x01\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x03dns\\x06goo\"\n            )\n        with pytest.raises(struct.error):  # rr length error\n            dns.Message.unpack(\n                b\"\\x00\\x2a\\x81\\x80\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x00\\x03dns\\x06google\\x00\\x00\\x01\\x00\\x01\"\n                + b\"\\xc0\\x0c\\x00\\x01\\x00\\x01\\x00\\x00\\x00 \\x00\\x04\\x08\\x08\\x08\\x08\\xc0\\x0c\\x00\\x01\\x00\\x01\\x00\\x00\\x00 \\x00\\x04\\x08\\x08\\x04\"\n            )\n        txt = dns.Message.unpack(\n            b\"V\\x1a\\x81\\x80\\x00\\x01\\x00\\x01\\x00\\x01\\x00\\x01\\x05alive\\x06github\\x03com\\x00\\x00\"\n            + b\"\\x10\\x00\\x01\\xc0\\x0c\\x00\\x05\\x00\\x01\\x00\\x00\\x0b\\xc6\\x00\\x07\\x04live\\xc0\\x12\\xc0\\x12\\x00\\x06\\x00\\x01\"\n            + b\"\\x00\\x00\\x03\\x84\\x00H\\x07ns-1707\\tawsdns-21\\x02co\\x02uk\\x00\\x11awsdns-hostmaster\\x06amazon\\xc0\\x19\\x00\"\n            + b\"\\x00\\x00\\x01\\x00\\x00\\x1c \\x00\\x00\\x03\\x84\\x00\\x12u\\x00\\x00\\x01Q\\x80\\x00\\x00)\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n        )\n        assert txt.answers[0].domain_name == \"live.github.com\"\n        invalid_rr_domain_name = dns.Message.unpack(\n            b\"V\\x1a\\x81\\x80\\x00\\x01\\x00\\x01\\x00\\x01\\x00\\x01\\x05alive\\x06github\\x03com\\x00\\x00\"\n            + b\"\\x10\\x00\\x01\\xc0\\x0c\\x00\\x05\\x00\\x01\\x00\\x00\\x0b\\xc6\\x00\\x07\\x99live\\xc0\\x12\\xc0\\x12\\x00\\x06\\x00\\x01\"\n            + b\"\\x00\\x00\\x03\\x84\\x00H\\x07ns-1707\\tawsdns-21\\x02co\\x02uk\\x00\\x11awsdns-hostmaster\\x06amazon\\xc0\\x19\\x00\"\n            + b\"\\x00\\x00\\x01\\x00\\x00\\x1c \\x00\\x00\\x03\\x84\\x00\\x12u\\x00\\x00\\x01Q\\x80\\x00\\x00)\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n        )\n        assert invalid_rr_domain_name.answers[0].data == b\"\\x99live\\xc0\\x12\"\n\n        req = tutils.tdnsreq()\n        for flag in (\n            \"authoritative_answer\",\n            \"truncation\",\n            \"recursion_desired\",\n            \"recursion_available\",\n        ):\n            setattr(req, flag, True)\n            assert getattr(dns.Message.unpack(req.packed), flag) is True\n            setattr(req, flag, False)\n            assert getattr(dns.Message.unpack(req.packed), flag) is False\n\n    def test_copy(self):\n        msg = tutils.tdnsresp()\n        assert dns.Message.from_state(msg.get_state()) == msg\n        copy = msg.copy()\n        assert copy is not msg\n        assert copy != msg\n        copy.id = msg.id\n        assert copy == msg\n        assert copy.questions is not msg.questions\n        assert copy.questions == msg.questions\n        assert copy.answers is not msg.answers\n        assert copy.answers == msg.answers\n        assert copy.authorities is not msg.authorities\n        assert copy.authorities == msg.authorities\n        assert copy.additionals is not msg.additionals\n        assert copy.additionals == msg.additionals\n\n\nclass TestDNSFlow:\n    def test_copy(self):\n        f = tflow.tdnsflow(resp=True)\n        assert repr(f)\n        f.get_state()\n        f2 = f.copy()\n        a = f.get_state()\n        b = f2.get_state()\n        del a[\"id\"]\n        del b[\"id\"]\n        assert a == b\n        assert not f == f2\n        assert f is not f2\n\n        assert f.request.get_state() == f2.request.get_state()\n        assert f.request is not f2.request\n        assert f.request == f2.request\n        assert f.response is not f2.response\n        assert f.response.get_state() == f2.response.get_state()\n        assert f.response == f2.response\n\n        f = tflow.tdnsflow(err=True)\n        f2 = f.copy()\n        assert f is not f2\n        assert f.request is not f2.request\n        assert f.request == f2.request\n        assert f.error.get_state() == f2.error.get_state()\n        assert f.error is not f2.error\n\n    def test_match(self):\n        f = tflow.tdnsflow(resp=True)\n        assert not flowfilter.match(\"~b nonexistent\", f)\n        assert flowfilter.match(None, f)\n        assert flowfilter.match(\"~b dns.google\", f)\n        assert flowfilter.match(\"~b 8.8.8.8\", f)\n\n        assert flowfilter.match(\"~bq dns.google\", f)\n        assert not flowfilter.match(\"~bq 8.8.8.8\", f)\n\n        assert flowfilter.match(\"~bs dns.google\", f)\n        assert flowfilter.match(\"~bs 8.8.4.4\", f)\n\n        assert flowfilter.match(\"~dns\", f)\n        assert not flowfilter.match(\"~dns\", tflow.ttcpflow())\n        assert not flowfilter.match(\"~dns\", tflow.tflow())\n\n        f = tflow.tdnsflow(err=True)\n        assert flowfilter.match(\"~e\", f)\n\n        with pytest.raises(ValueError):\n            flowfilter.match(\"~\", f)\n\n    def test_repr(self):\n        f = tflow.tdnsflow()\n        assert \"DNSFlow\" in repr(f)\n", "test/mitmproxy/test_log.py": "from mitmproxy import log\n\n\ndef test_logentry():\n    e = log.LogEntry(\"foo\", \"info\")\n    assert repr(e) == \"LogEntry(foo, info)\"\n\n    f = log.LogEntry(\"foo\", \"warning\")\n    assert e == e\n    assert e != f\n    assert e != 42\n\n\ndef test_dont_pick_up_mutations():\n    x = {\"foo\": \"bar\"}\n    e = log.LogEntry(x, \"info\")\n    x[\"foo\"] = \"baz\"  # this should not affect the log entry anymore.\n    assert repr(e) == \"LogEntry({'foo': 'bar'}, info)\"\n", "test/mitmproxy/test_options.py": "from mitmproxy import options\n\n\ndef test_simple():\n    assert options.Options()\n", "test/mitmproxy/test_websocket.py": "import pytest\nfrom wsproto.frame_protocol import Opcode\n\nfrom mitmproxy import http\nfrom mitmproxy import websocket\nfrom mitmproxy.test import tflow\n\n\nclass TestWebSocketData:\n    def test_repr(self):\n        assert repr(tflow.twebsocketflow().websocket) == \"<WebSocketData (3 messages)>\"\n\n    def test_state(self):\n        f = tflow.twebsocketflow()\n        f2 = http.HTTPFlow.from_state(f.get_state())\n        f2.set_state(f.get_state())\n\n    def test_formatting(self):\n        tf = tflow.twebsocketflow().websocket\n        formatted_messages = tf._get_formatted_messages()\n        assert b\"[OUTGOING] hello binary\" in formatted_messages\n        assert b\"[OUTGOING] hello text\" in formatted_messages\n        assert b\"[INCOMING] it's me\" in formatted_messages\n\n\nclass TestWebSocketMessage:\n    def test_basic(self):\n        m = websocket.WebSocketMessage(Opcode.TEXT, True, b\"foo\")\n        m.set_state(m.get_state())\n        assert m.content == b\"foo\"\n        assert repr(m) == \"'foo'\"\n        m.type = Opcode.BINARY\n        assert repr(m) == \"b'foo'\"\n\n        assert not m.dropped\n        m.drop()\n        assert m.dropped\n\n    def test_text(self):\n        txt = websocket.WebSocketMessage(Opcode.TEXT, True, b\"foo\")\n        bin = websocket.WebSocketMessage(Opcode.BINARY, True, b\"foo\")\n\n        assert txt.is_text\n        assert txt.text == \"foo\"\n        txt.text = \"bar\"\n        assert txt.content == b\"bar\"\n\n        assert not bin.is_text\n        with pytest.raises(AttributeError, match=\"do not have a 'text' attribute.\"):\n            _ = bin.text\n        with pytest.raises(AttributeError, match=\"do not have a 'text' attribute.\"):\n            bin.text = \"bar\"\n\n    def test_message_formatting(self):\n        incoming_message = websocket.WebSocketMessage(\n            Opcode.BINARY, False, b\"Test Incoming\"\n        )\n        outgoing_message = websocket.WebSocketMessage(\n            Opcode.BINARY, True, b\"Test OutGoing\"\n        )\n\n        assert incoming_message._format_ws_message() == b\"[INCOMING] Test Incoming\"\n        assert outgoing_message._format_ws_message() == b\"[OUTGOING] Test OutGoing\"\n", "test/mitmproxy/test_eventsequence.py": "import pytest\n\nfrom mitmproxy import eventsequence\nfrom mitmproxy.proxy import layers\nfrom mitmproxy.test import tflow\n\n\n@pytest.mark.parametrize(\n    \"resp, err\",\n    [\n        (False, False),\n        (True, False),\n        (False, True),\n        (True, True),\n    ],\n)\ndef test_http_flow(resp, err):\n    f = tflow.tflow(resp=resp, err=err)\n    i = eventsequence.iterate(f)\n    assert isinstance(next(i), layers.http.HttpRequestHeadersHook)\n    assert isinstance(next(i), layers.http.HttpRequestHook)\n    if resp:\n        assert isinstance(next(i), layers.http.HttpResponseHeadersHook)\n        assert isinstance(next(i), layers.http.HttpResponseHook)\n    if err:\n        assert isinstance(next(i), layers.http.HttpErrorHook)\n\n\ndef test_websocket_flow():\n    f = tflow.twebsocketflow()\n    i = eventsequence.iterate(f)\n\n    assert isinstance(next(i), layers.http.HttpRequestHeadersHook)\n    assert isinstance(next(i), layers.http.HttpRequestHook)\n    assert isinstance(next(i), layers.http.HttpResponseHeadersHook)\n    assert isinstance(next(i), layers.http.HttpResponseHook)\n\n    assert isinstance(next(i), layers.websocket.WebsocketStartHook)\n    assert len(f.websocket.messages) == 0\n    assert isinstance(next(i), layers.websocket.WebsocketMessageHook)\n    assert len(f.websocket.messages) == 1\n    assert isinstance(next(i), layers.websocket.WebsocketMessageHook)\n    assert len(f.websocket.messages) == 2\n    assert isinstance(next(i), layers.websocket.WebsocketMessageHook)\n    assert len(f.websocket.messages) == 3\n    assert isinstance(next(i), layers.websocket.WebsocketEndHook)\n\n\n@pytest.mark.parametrize(\"err\", [False, True])\ndef test_tcp_flow(err):\n    f = tflow.ttcpflow(err=err)\n    i = eventsequence.iterate(f)\n    assert isinstance(next(i), layers.tcp.TcpStartHook)\n    assert len(f.messages) == 0\n    assert isinstance(next(i), layers.tcp.TcpMessageHook)\n    assert len(f.messages) == 1\n    assert isinstance(next(i), layers.tcp.TcpMessageHook)\n    assert len(f.messages) == 2\n    if err:\n        assert isinstance(next(i), layers.tcp.TcpErrorHook)\n    else:\n        assert isinstance(next(i), layers.tcp.TcpEndHook)\n\n\n@pytest.mark.parametrize(\"err\", [False, True])\ndef test_udp_flow(err):\n    f = tflow.tudpflow(err=err)\n    i = eventsequence.iterate(f)\n    assert isinstance(next(i), layers.udp.UdpStartHook)\n    assert len(f.messages) == 0\n    assert isinstance(next(i), layers.udp.UdpMessageHook)\n    assert len(f.messages) == 1\n    assert isinstance(next(i), layers.udp.UdpMessageHook)\n    assert len(f.messages) == 2\n    if err:\n        assert isinstance(next(i), layers.udp.UdpErrorHook)\n    else:\n        assert isinstance(next(i), layers.udp.UdpEndHook)\n\n\n@pytest.mark.parametrize(\n    \"resp, err\",\n    [\n        (False, False),\n        (True, False),\n        (False, True),\n        (True, True),\n    ],\n)\ndef test_dns(resp, err):\n    f = tflow.tdnsflow(resp=resp, err=err)\n    i = eventsequence.iterate(f)\n    assert isinstance(next(i), layers.dns.DnsRequestHook)\n    if resp:\n        assert isinstance(next(i), layers.dns.DnsResponseHook)\n    if err:\n        assert isinstance(next(i), layers.dns.DnsErrorHook)\n\n\ndef test_invalid():\n    with pytest.raises(TypeError):\n        next(eventsequence.iterate(42))\n", "test/mitmproxy/test_taddons.py": "from mitmproxy.test import taddons\n\n\ndef test_load_script(tdata):\n    with taddons.context() as tctx:\n        s = tctx.script(tdata.path(\"mitmproxy/data/addonscripts/recorder/recorder.py\"))\n        assert s\n", "test/mitmproxy/test_version.py": "import pathlib\nimport runpy\nimport subprocess\nimport sys\nfrom unittest import mock\n\nfrom mitmproxy import version\n\n\ndef test_version(capsys):\n    here = pathlib.Path(__file__).absolute().parent\n    version_file = here / \"..\" / \"..\" / \"mitmproxy\" / \"version.py\"\n    runpy.run_path(str(version_file), run_name=\"__main__\")\n    stdout, stderr = capsys.readouterr()\n    assert len(stdout) > 0\n    assert stdout.strip() == version.VERSION\n\n\ndef test_get_version():\n    version.VERSION = \"3.0.0rc2\"\n\n    with mock.patch(\"subprocess.check_output\") as m, mock.patch(\"subprocess.run\") as m2:\n        m2.return_value = True\n\n        m.return_value = b\"tag-0-cafecafe\"\n        assert version.get_dev_version() == \"3.0.0rc2\"\n\n        sys.frozen = True\n        assert version.get_dev_version() == \"3.0.0rc2 binary\"\n        sys.frozen = False\n\n        m.return_value = b\"tag-2-cafecafe\"\n        assert version.get_dev_version() == \"3.0.0rc2 (+2, commit cafecaf)\"\n\n        m.side_effect = subprocess.CalledProcessError(-1, \"git describe --tags --long\")\n        assert version.get_dev_version() == \"3.0.0rc2\"\n", "test/mitmproxy/test_certs.py": "import ipaddress\nimport os\nfrom datetime import datetime\nfrom datetime import timezone\nfrom pathlib import Path\n\nimport pytest\nfrom cryptography import x509\nfrom cryptography.x509 import NameOID\n\nfrom ..conftest import skip_windows\nfrom mitmproxy import certs\n\n# class TestDNTree:\n#     def test_simple(self):\n#         d = certs.DNTree()\n#         d.add(\"foo.com\", \"foo\")\n#         d.add(\"bar.com\", \"bar\")\n#         assert d.get(\"foo.com\") == \"foo\"\n#         assert d.get(\"bar.com\") == \"bar\"\n#         assert not d.get(\"oink.com\")\n#         assert not d.get(\"oink\")\n#         assert not d.get(\"\")\n#         assert not d.get(\"oink.oink\")\n#\n#         d.add(\"*.match.org\", \"match\")\n#         assert not d.get(\"match.org\")\n#         assert d.get(\"foo.match.org\") == \"match\"\n#         assert d.get(\"foo.foo.match.org\") == \"match\"\n#\n#     def test_wildcard(self):\n#         d = certs.DNTree()\n#         d.add(\"foo.com\", \"foo\")\n#         assert not d.get(\"*.foo.com\")\n#         d.add(\"*.foo.com\", \"wild\")\n#\n#         d = certs.DNTree()\n#         d.add(\"*\", \"foo\")\n#         assert d.get(\"foo.com\") == \"foo\"\n#         assert d.get(\"*.foo.com\") == \"foo\"\n#         assert d.get(\"com\") == \"foo\"\n\n\n@pytest.fixture()\ndef tstore(tdata):\n    return certs.CertStore.from_store(\n        tdata.path(\"mitmproxy/data/confdir\"), \"mitmproxy\", 2048\n    )\n\n\nclass TestCertStore:\n    def test_create_explicit(self, tmpdir):\n        ca = certs.CertStore.from_store(str(tmpdir), \"test\", 2048)\n        assert ca.get_cert(\"foo\", [])\n\n        ca2 = certs.CertStore.from_store(str(tmpdir), \"test\", 2048)\n        assert ca2.get_cert(\"foo\", [])\n\n        assert ca.default_ca.serial == ca2.default_ca.serial\n\n    def test_create_no_common_name(self, tstore):\n        assert tstore.get_cert(None, []).cert.cn is None\n\n    def test_chain_file(self, tdata, tmp_path):\n        cert = Path(tdata.path(\"mitmproxy/data/confdir/mitmproxy-ca.pem\")).read_bytes()\n        (tmp_path / \"mitmproxy-ca.pem\").write_bytes(cert)\n        ca = certs.CertStore.from_store(tmp_path, \"mitmproxy\", 2048)\n        assert ca.default_chain_file is None\n        assert len(ca.default_chain_certs) == 1\n\n        (tmp_path / \"mitmproxy-ca.pem\").write_bytes(2 * cert)\n        ca = certs.CertStore.from_store(tmp_path, \"mitmproxy\", 2048)\n        assert ca.default_chain_file == (tmp_path / \"mitmproxy-ca.pem\")\n        assert len(ca.default_chain_certs) == 2\n\n    def test_sans(self, tstore):\n        c1 = tstore.get_cert(\"foo.com\", [x509.DNSName(\"*.bar.com\")])\n        tstore.get_cert(\"foo.bar.com\", [])\n        # assert c1 == c2\n        c3 = tstore.get_cert(\"bar.com\", [])\n        assert not c1 == c3\n\n    def test_sans_change(self, tstore):\n        tstore.get_cert(\"foo.com\", [x509.DNSName(\"*.bar.com\")])\n        entry = tstore.get_cert(\"foo.bar.com\", [x509.DNSName(\"*.baz.com\")])\n        assert x509.DNSName(\"*.baz.com\") in entry.cert.altnames\n\n    def test_expire(self, tstore):\n        tstore.STORE_CAP = 3\n        tstore.get_cert(\"one.com\", [])\n        tstore.get_cert(\"two.com\", [])\n        tstore.get_cert(\"three.com\", [])\n\n        assert (\"one.com\", x509.GeneralNames([])) in tstore.certs\n        assert (\"two.com\", x509.GeneralNames([])) in tstore.certs\n        assert (\"three.com\", x509.GeneralNames([])) in tstore.certs\n\n        tstore.get_cert(\"one.com\", [])\n\n        assert (\"one.com\", x509.GeneralNames([])) in tstore.certs\n        assert (\"two.com\", x509.GeneralNames([])) in tstore.certs\n        assert (\"three.com\", x509.GeneralNames([])) in tstore.certs\n\n        tstore.get_cert(\"four.com\", [])\n\n        assert (\"one.com\", x509.GeneralNames([])) not in tstore.certs\n        assert (\"two.com\", x509.GeneralNames([])) in tstore.certs\n        assert (\"three.com\", x509.GeneralNames([])) in tstore.certs\n        assert (\"four.com\", x509.GeneralNames([])) in tstore.certs\n\n    def test_overrides(self, tmp_path):\n        ca1 = certs.CertStore.from_store(tmp_path / \"ca1\", \"test\", 2048)\n        ca2 = certs.CertStore.from_store(tmp_path / \"ca2\", \"test\", 2048)\n        assert not ca1.default_ca.serial == ca2.default_ca.serial\n\n        dc = ca2.get_cert(\"foo.com\", [x509.DNSName(\"sans.example.com\")])\n        dcp = tmp_path / \"dc\"\n        dcp.write_bytes(dc.cert.to_pem())\n        ca1.add_cert_file(\"foo.com\", dcp)\n\n        ret = ca1.get_cert(\"foo.com\", [])\n        assert ret.cert.serial == dc.cert.serial\n\n    def test_create_dhparams(self, tmp_path):\n        filename = tmp_path / \"dhparam.pem\"\n        certs.CertStore.load_dhparam(filename)\n        assert filename.exists()\n\n    @skip_windows\n    def test_umask_secret(self, tmpdir):\n        filename = str(tmpdir.join(\"secret\"))\n        with certs.CertStore.umask_secret(), open(filename, \"wb\"):\n            pass\n        # TODO: How do we actually attempt to read that file as another user?\n        assert os.stat(filename).st_mode & 0o77 == 0\n\n    @pytest.mark.parametrize(\n        \"input,output\",\n        [\n            (\n                \"subdomain.example.com\",\n                [\"subdomain.example.com\", \"*.example.com\", \"*.com\"],\n            ),\n            (\n                x509.DNSName(\"subdomain.example.com\"),\n                [\"subdomain.example.com\", \"*.example.com\", \"*.com\"],\n            ),\n            (x509.IPAddress(ipaddress.ip_address(\"127.0.0.1\")), [\"127.0.0.1\"]),\n        ],\n    )\n    def test_asterisk_forms(self, input, output):\n        assert certs.CertStore.asterisk_forms(input) == output\n\n\nclass TestDummyCert:\n    def test_with_ca(self, tstore):\n        r = certs.dummy_cert(\n            tstore.default_privatekey,\n            tstore.default_ca._cert,\n            \"foo.com\",\n            [\n                x509.DNSName(\"one.com\"),\n                x509.DNSName(\"two.com\"),\n                x509.DNSName(\"*.three.com\"),\n                x509.IPAddress(ipaddress.ip_address(\"127.0.0.1\")),\n                x509.DNSName(\"b\u00fccher.example\".encode(\"idna\").decode(\"ascii\")),\n            ],\n            \"Foo Ltd.\",\n        )\n        assert r.cn == \"foo.com\"\n        assert r.altnames == x509.GeneralNames(\n            [\n                x509.DNSName(\"one.com\"),\n                x509.DNSName(\"two.com\"),\n                x509.DNSName(\"*.three.com\"),\n                x509.IPAddress(ipaddress.ip_address(\"127.0.0.1\")),\n                x509.DNSName(\"xn--bcher-kva.example\"),\n            ]\n        )\n        assert r.organization == \"Foo Ltd.\"\n\n        r = certs.dummy_cert(\n            tstore.default_privatekey, tstore.default_ca._cert, None, [], None\n        )\n        assert r.cn is None\n        assert r.organization is None\n        assert r.altnames == x509.GeneralNames([])\n\n\nclass TestCert:\n    def test_simple(self, tdata):\n        with open(tdata.path(\"mitmproxy/net/data/text_cert\"), \"rb\") as f:\n            d = f.read()\n        c1 = certs.Cert.from_pem(d)\n        assert c1.cn == \"google.com\"\n        assert len(c1.altnames) == 436\n        assert c1.organization == \"Google Inc\"\n        assert hash(c1)\n\n        with open(tdata.path(\"mitmproxy/net/data/text_cert_2\"), \"rb\") as f:\n            d = f.read()\n        c2 = certs.Cert.from_pem(d)\n        assert c2.cn == \"www.inode.co.nz\"\n        assert len(c2.altnames) == 2\n        assert c2.fingerprint()\n        assert c2.notbefore == datetime(\n            year=2010,\n            month=1,\n            day=11,\n            hour=19,\n            minute=27,\n            second=36,\n            tzinfo=timezone.utc,\n        )\n        assert c2.notafter == datetime(\n            year=2011,\n            month=1,\n            day=12,\n            hour=9,\n            minute=14,\n            second=55,\n            tzinfo=timezone.utc,\n        )\n        assert c2.subject\n        assert c2.keyinfo == (\"RSA\", 2048)\n        assert c2.serial\n        assert c2.issuer\n        assert c2.to_pem()\n        assert c2.has_expired() is not None\n        assert (\n            repr(c2)\n            == \"<Cert(cn='www.inode.co.nz', altnames=['www.inode.co.nz', 'inode.co.nz'])>\"\n        )\n\n        assert c1 != c2\n\n    def test_convert(self, tdata):\n        with open(tdata.path(\"mitmproxy/net/data/text_cert\"), \"rb\") as f:\n            d = f.read()\n        c = certs.Cert.from_pem(d)\n\n        assert c == certs.Cert.from_pem(c.to_pem())\n        assert c == certs.Cert.from_state(c.get_state())\n        assert c == certs.Cert.from_pyopenssl(c.to_pyopenssl())\n\n    @pytest.mark.parametrize(\n        \"filename,name,bits\",\n        [\n            (\"text_cert\", \"RSA\", 1024),\n            (\"dsa_cert.pem\", \"DSA\", 1024),\n            (\"ec_cert.pem\", \"EC (secp256r1)\", 256),\n        ],\n    )\n    def test_keyinfo(self, tdata, filename, name, bits):\n        with open(tdata.path(f\"mitmproxy/net/data/{filename}\"), \"rb\") as f:\n            d = f.read()\n        c = certs.Cert.from_pem(d)\n        assert c.keyinfo == (name, bits)\n\n    def test_err_broken_sans(self, tdata):\n        with open(tdata.path(\"mitmproxy/net/data/text_cert_weird1\"), \"rb\") as f:\n            d = f.read()\n        c = certs.Cert.from_pem(d)\n        # This breaks unless we ignore a decoding error.\n        assert c.altnames is not None\n\n    def test_state(self, tdata):\n        with open(tdata.path(\"mitmproxy/net/data/text_cert\"), \"rb\") as f:\n            d = f.read()\n        c = certs.Cert.from_pem(d)\n\n        c.get_state()\n        c2 = c.copy()\n        a = c.get_state()\n        b = c2.get_state()\n        assert a == b\n        assert c == c2\n        assert c is not c2\n\n        c2.set_state(a)\n        assert c == c2\n\n    def test_from_store_with_passphrase(self, tdata, tstore):\n        tstore.add_cert_file(\n            \"unencrypted-no-pass\", Path(tdata.path(\"mitmproxy/data/testkey.pem\")), None\n        )\n        tstore.add_cert_file(\n            \"unencrypted-pass\",\n            Path(tdata.path(\"mitmproxy/data/testkey.pem\")),\n            b\"password\",\n        )\n        tstore.add_cert_file(\n            \"encrypted-pass\",\n            Path(tdata.path(\"mitmproxy/data/mitmproxy.pem\")),\n            b\"password\",\n        )\n\n        with pytest.raises(TypeError):\n            tstore.add_cert_file(\n                \"encrypted-no-pass\",\n                Path(tdata.path(\"mitmproxy/data/mitmproxy.pem\")),\n                None,\n            )\n\n    def test_special_character(self, tdata):\n        with open(tdata.path(\"mitmproxy/net/data/text_cert_with_comma\"), \"rb\") as f:\n            d = f.read()\n        c = certs.Cert.from_pem(d)\n\n        assert dict(c.issuer).get(\"O\") == \"DigiCert, Inc.\"\n        assert dict(c.subject).get(\"O\") == \"GitHub, Inc.\"\n\n    def test_multi_valued_rdns(self, tdata):\n        subject = x509.Name(\n            [\n                x509.RelativeDistinguishedName(\n                    [\n                        x509.NameAttribute(NameOID.TITLE, \"Test\"),\n                        x509.NameAttribute(NameOID.COMMON_NAME, \"Multivalue\"),\n                        x509.NameAttribute(NameOID.SURNAME, \"RDNs\"),\n                        x509.NameAttribute(NameOID.ORGANIZATION_NAME, \"TSLA\"),\n                    ]\n                ),\n                x509.RelativeDistinguishedName(\n                    [x509.NameAttribute(NameOID.ORGANIZATION_NAME, \"PyCA\")]\n                ),\n            ]\n        )\n        expected = [\n            (\"2.5.4.12\", \"Test\"),\n            (\"CN\", \"Multivalue\"),\n            (\"2.5.4.4\", \"RDNs\"),\n            (\"O\", \"TSLA\"),\n            (\"O\", \"PyCA\"),\n        ]\n        assert (certs._name_to_keyval(subject)) == expected\n", "test/mitmproxy/test_flowfilter.py": "import io\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy.test import tflow\n\n\nclass TestParsing:\n    def _dump(self, x):\n        c = io.StringIO()\n        x.dump(fp=c)\n        assert c.getvalue()\n\n    def test_parse_err(self):\n        with pytest.raises(ValueError, match=\"Empty filter\"):\n            flowfilter.parse(\"\")\n        with pytest.raises(ValueError, match=\"Invalid filter\"):\n            flowfilter.parse(\"~b\")\n        with pytest.raises(ValueError, match=\"Invalid filter\"):\n            flowfilter.parse(\"~h [\")\n\n    def test_simple(self):\n        assert flowfilter.parse(\"~q\")\n        assert flowfilter.parse(\"~c 10\")\n        assert flowfilter.parse(\"~m foobar\")\n        assert flowfilter.parse(\"~u foobar\")\n        assert flowfilter.parse(\"~q ~c 10\")\n        assert flowfilter.parse(\"~replay\")\n        assert flowfilter.parse(\"~replayq\")\n        assert flowfilter.parse(\"~replays\")\n        assert flowfilter.parse(\"~comment .\")\n        p = flowfilter.parse(\"~q ~c 10\")\n        self._dump(p)\n        assert len(p.lst) == 2\n\n    def test_non_ascii(self):\n        assert flowfilter.parse(\"~s \u0448\u0433\u043d\")\n\n    def test_naked_url(self):\n        a = flowfilter.parse(\"foobar ~h rex\")\n        assert a.lst[0].expr == \"foobar\"\n        assert a.lst[1].expr == \"rex\"\n        self._dump(a)\n\n    def test_quoting(self):\n        a = flowfilter.parse(\"~u 'foo ~u bar' ~u voing\")\n        assert a.lst[0].expr == \"foo ~u bar\"\n        assert a.lst[1].expr == \"voing\"\n        self._dump(a)\n\n        a = flowfilter.parse(\"~u foobar\")\n        assert a.expr == \"foobar\"\n\n        a = flowfilter.parse(r\"~u 'foobar\\\"\\''\")\n        assert a.expr == \"foobar\\\"'\"\n\n        a = flowfilter.parse(r'~u \"foo \\'bar\"')\n        assert a.expr == \"foo 'bar\"\n\n    def test_nesting(self):\n        a = flowfilter.parse(\"(~u foobar & ~h voing)\")\n        assert a.lst[0].expr == \"foobar\"\n        self._dump(a)\n\n    def test_not(self):\n        a = flowfilter.parse(\"!~h test\")\n        assert a.itm.expr == \"test\"\n        a = flowfilter.parse(\"!(~u test & ~h bar)\")\n        assert a.itm.lst[0].expr == \"test\"\n        self._dump(a)\n\n    def test_binaryops(self):\n        a = flowfilter.parse(\"~u foobar | ~h voing\")\n        isinstance(a, flowfilter.FOr)\n        self._dump(a)\n\n        a = flowfilter.parse(\"~u foobar & ~h voing\")\n        isinstance(a, flowfilter.FAnd)\n        self._dump(a)\n\n    def test_wideops(self):\n        a = flowfilter.parse(\"~hq 'header: qvalue'\")\n        assert isinstance(a, flowfilter.FHeadRequest)\n        self._dump(a)\n\n\nclass TestMatchingHTTPFlow:\n    def req(self):\n        return tflow.tflow()\n\n    def resp(self):\n        return tflow.tflow(resp=True)\n\n    def err(self):\n        return tflow.tflow(err=True)\n\n    def q(self, q, o):\n        return flowfilter.parse(q)(o)\n\n    def test_http(self):\n        s = self.req()\n        assert self.q(\"~http\", s)\n        assert not self.q(\"~tcp\", s)\n\n    def test_asset(self):\n        s = self.resp()\n        assert not self.q(\"~a\", s)\n        s.response.headers[\"content-type\"] = \"text/javascript\"\n        assert self.q(\"~a\", s)\n\n    def test_fcontenttype(self):\n        q = self.req()\n        s = self.resp()\n        assert not self.q(\"~t content\", q)\n        assert not self.q(\"~t content\", s)\n\n        q.request.headers[\"content-type\"] = \"text/json\"\n        assert self.q(\"~t json\", q)\n        assert self.q(\"~tq json\", q)\n        assert not self.q(\"~ts json\", q)\n\n        s.response.headers[\"content-type\"] = \"text/json\"\n        assert self.q(\"~t json\", s)\n\n        del s.response.headers[\"content-type\"]\n        s.request.headers[\"content-type\"] = \"text/json\"\n        assert self.q(\"~t json\", s)\n        assert self.q(\"~tq json\", s)\n        assert not self.q(\"~ts json\", s)\n\n    def test_freq_fresp(self):\n        q = self.req()\n        s = self.resp()\n\n        assert self.q(\"~q\", q)\n        assert not self.q(\"~q\", s)\n\n        assert not self.q(\"~s\", q)\n        assert self.q(\"~s\", s)\n\n    def test_ferr(self):\n        e = self.err()\n        assert self.q(\"~e\", e)\n\n    def test_fmarked(self):\n        q = self.req()\n        assert not self.q(\"~marked\", q)\n        q.marked = \":default:\"\n        assert self.q(\"~marked\", q)\n\n    def test_fmarker_char(self):\n        t = tflow.tflow()\n        t.marked = \":default:\"\n        assert not self.q(\"~marker X\", t)\n        t.marked = \"X\"\n        assert self.q(\"~marker X\", t)\n\n    def test_head(self):\n        q = self.req()\n        s = self.resp()\n        assert not self.q(\"~h nonexistent\", q)\n        assert self.q(\"~h qvalue\", q)\n        assert self.q(\"~h header\", q)\n        assert self.q(\"~h 'header: qvalue'\", q)\n\n        assert self.q(\"~h 'header: qvalue'\", s)\n        assert self.q(\"~h 'header-response: svalue'\", s)\n\n        assert self.q(\"~hq 'header: qvalue'\", s)\n        assert not self.q(\"~hq 'header-response: svalue'\", s)\n\n        assert self.q(\"~hq 'header: qvalue'\", q)\n        assert not self.q(\"~hq 'header-request: svalue'\", q)\n\n        assert not self.q(\"~hs 'header: qvalue'\", s)\n        assert self.q(\"~hs 'header-response: svalue'\", s)\n        assert not self.q(\"~hs 'header: qvalue'\", q)\n\n    def match_body(self, q, s):\n        assert not self.q(\"~b nonexistent\", q)\n        assert self.q(\"~b content\", q)\n        assert self.q(\"~b message\", s)\n\n        assert not self.q(\"~bq nomatch\", s)\n        assert self.q(\"~bq content\", q)\n        assert self.q(\"~bq content\", s)\n        assert not self.q(\"~bq message\", q)\n        assert not self.q(\"~bq message\", s)\n\n        s.response.text = \"\u044f\u0447\"  # Cyrillic\n        assert self.q(\"~bs \u044f\u0447\", s)\n        s.response.text = \"\u6d4b\u8bd5\"  # Chinese\n        assert self.q(\"~bs \u6d4b\u8bd5\", s)\n        s.response.text = \"\u0950\"  # Hindi\n        assert self.q(\"~bs \u0950\", s)\n        s.response.text = \"\u0644\u0644\u0647\"  # Arabic\n        assert self.q(\"~bs \u0644\u0644\u0647\", s)\n        s.response.text = \"\u03b8\u03b5\u03cc\u03c2\"  # Greek\n        assert self.q(\"~bs \u03b8\u03b5\u03cc\u03c2\", s)\n        s.response.text = \"\u05dc\u05d5\u05d4\u05d9\u05dd\"  # Hebrew\n        assert self.q(\"~bs \u05dc\u05d5\u05d4\u05d9\u05dd\", s)\n        s.response.text = \"\u795e\"  # Japanese\n        assert self.q(\"~bs \u795e\", s)\n        s.response.text = \"\ud558\ub098\ub2d8\"  # Korean\n        assert self.q(\"~bs \ud558\ub098\ub2d8\", s)\n        s.response.text = \"\u00c4\u00ff\"  # Latin\n        assert self.q(\"~bs \u00c4\u00ff\", s)\n\n        assert not self.q(\"~bs nomatch\", s)\n        assert not self.q(\"~bs content\", q)\n        assert not self.q(\"~bs content\", s)\n        assert not self.q(\"~bs message\", q)\n        s.response.text = \"message\"\n        assert self.q(\"~bs message\", s)\n\n    def test_body(self):\n        q = self.req()\n        s = self.resp()\n        self.match_body(q, s)\n\n        q.request.encode(\"gzip\")\n        s.request.encode(\"gzip\")\n        s.response.encode(\"gzip\")\n        self.match_body(q, s)\n\n    def test_method(self):\n        q = self.req()\n        assert self.q(\"~m get\", q)\n        assert not self.q(\"~m post\", q)\n\n        q.request.method = \"oink\"\n        assert not self.q(\"~m get\", q)\n\n    def test_domain(self):\n        q = self.req()\n        assert self.q(\"~d address\", q)\n        assert not self.q(\"~d none\", q)\n\n    def test_url(self):\n        q = self.req()\n        s = self.resp()\n        assert self.q(\"~u address\", q)\n        assert self.q(\"~u address:22/path\", q)\n        assert not self.q(\"~u moo/path\", q)\n\n        q.request = None\n        assert not self.q(\"~u address\", q)\n\n        assert self.q(\"~u address\", s)\n        assert self.q(\"~u address:22/path\", s)\n        assert not self.q(\"~u moo/path\", s)\n\n    def test_code(self):\n        q = self.req()\n        s = self.resp()\n        assert not self.q(\"~c 200\", q)\n        assert self.q(\"~c 200\", s)\n        assert not self.q(\"~c 201\", s)\n\n    def test_src(self):\n        q = self.req()\n        assert self.q(\"~src 127.0.0.1\", q)\n        assert not self.q(\"~src foobar\", q)\n        assert self.q(\"~src :22\", q)\n        assert not self.q(\"~src :99\", q)\n        assert self.q(\"~src 127.0.0.1:22\", q)\n\n        q.client_conn.peername = None\n        assert not self.q(\"~src address:22\", q)\n        q.client_conn = None\n        assert not self.q(\"~src address:22\", q)\n\n    def test_dst(self):\n        q = self.req()\n        q.server_conn = tflow.tserver_conn()\n        assert self.q(\"~dst address\", q)\n        assert not self.q(\"~dst foobar\", q)\n        assert self.q(\"~dst :22\", q)\n        assert not self.q(\"~dst :99\", q)\n        assert self.q(\"~dst address:22\", q)\n\n        q.server_conn.address = None\n        assert not self.q(\"~dst address:22\", q)\n        q.server_conn = None\n        assert not self.q(\"~dst address:22\", q)\n\n    def test_and(self):\n        s = self.resp()\n        assert self.q(\"~c 200 & ~h head\", s)\n        assert self.q(\"~c 200 & ~h head\", s)\n        assert not self.q(\"~c 200 & ~h nohead\", s)\n        assert self.q(\"(~c 200 & ~h head) & ~b content\", s)\n        assert not self.q(\"(~c 200 & ~h head) & ~b nonexistent\", s)\n        assert not self.q(\"(~c 200 & ~h nohead) & ~b content\", s)\n\n    def test_or(self):\n        s = self.resp()\n        assert self.q(\"~c 200 | ~h nohead\", s)\n        assert self.q(\"~c 201 | ~h head\", s)\n        assert not self.q(\"~c 201 | ~h nohead\", s)\n        assert self.q(\"(~c 201 | ~h nohead) | ~s\", s)\n\n    def test_not(self):\n        s = self.resp()\n        assert not self.q(\"! ~c 200\", s)\n        assert self.q(\"! ~c 201\", s)\n        assert self.q(\"!~c 201 !~c 202\", s)\n        assert not self.q(\"!~c 201 !~c 200\", s)\n\n    def test_replay(self):\n        f = tflow.tflow()\n        assert not self.q(\"~replay\", f)\n        f.is_replay = \"request\"\n        assert self.q(\"~replay\", f)\n        assert self.q(\"~replayq\", f)\n        assert not self.q(\"~replays\", f)\n        f.is_replay = \"response\"\n        assert self.q(\"~replay\", f)\n        assert not self.q(\"~replayq\", f)\n        assert self.q(\"~replays\", f)\n\n    def test_metadata(self):\n        f = tflow.tflow()\n        f.metadata[\"a\"] = 1\n        f.metadata[\"b\"] = \"string\"\n        f.metadata[\"c\"] = {\"key\": \"value\"}\n        assert self.q(\"~meta a\", f)\n        assert not self.q(\"~meta no\", f)\n        assert self.q(\"~meta string\", f)\n        assert self.q(\"~meta key\", f)\n        assert self.q(\"~meta value\", f)\n        assert self.q('~meta \"b: string\"', f)\n        assert self.q(\"~meta \\\"'key': 'value'\\\"\", f)\n\n\nclass TestMatchingDNSFlow:\n    def req(self):\n        return tflow.tdnsflow()\n\n    def resp(self):\n        return tflow.tdnsflow(resp=True)\n\n    def err(self):\n        return tflow.tdnsflow(err=True)\n\n    def q(self, q, o):\n        return flowfilter.parse(q)(o)\n\n    def test_dns(self):\n        s = self.req()\n        assert self.q(\"~dns\", s)\n        assert not self.q(\"~http\", s)\n        assert not self.q(\"~tcp\", s)\n\n    def test_freq_fresp(self):\n        q = self.req()\n        s = self.resp()\n\n        assert self.q(\"~q\", q)\n        assert not self.q(\"~q\", s)\n\n        assert not self.q(\"~s\", q)\n        assert self.q(\"~s\", s)\n\n    def test_ferr(self):\n        e = self.err()\n        assert self.q(\"~e\", e)\n\n    def test_body(self):\n        q = self.req()\n        s = self.resp()\n        assert not self.q(\"~b nonexistent\", q)\n        assert self.q(\"~b dns.google\", q)\n        assert self.q(\"~b 8.8.8.8\", s)\n\n        assert not self.q(\"~bq 8.8.8.8\", s)\n        assert self.q(\"~bq dns.google\", q)\n        assert self.q(\"~bq dns.google\", s)\n\n        assert not self.q(\"~bs dns.google\", q)\n        assert self.q(\"~bs dns.google\", s)\n        assert self.q(\"~bs 8.8.8.8\", s)\n\n    def test_url(self):\n        f = self.req()\n        assert not self.q(\"~u whatever\", f)\n        assert self.q(\"~u dns.google\", f)\n\n\nclass TestMatchingTCPFlow:\n    def flow(self):\n        return tflow.ttcpflow()\n\n    def err(self):\n        return tflow.ttcpflow(err=True)\n\n    def q(self, q, o):\n        return flowfilter.parse(q)(o)\n\n    def test_tcp(self):\n        f = self.flow()\n        assert self.q(\"~tcp\", f)\n        assert not self.q(\"~udp\", f)\n        assert not self.q(\"~http\", f)\n        assert not self.q(\"~websocket\", f)\n\n    def test_ferr(self):\n        e = self.err()\n        assert self.q(\"~e\", e)\n\n    def test_body(self):\n        f = self.flow()\n\n        # Messages sent by client or server\n        assert self.q(\"~b hello\", f)\n        assert self.q(\"~b me\", f)\n        assert not self.q(\"~b nonexistent\", f)\n\n        # Messages sent by client\n        assert self.q(\"~bq hello\", f)\n        assert not self.q(\"~bq me\", f)\n        assert not self.q(\"~bq nonexistent\", f)\n\n        # Messages sent by server\n        assert self.q(\"~bs me\", f)\n        assert not self.q(\"~bs hello\", f)\n        assert not self.q(\"~bs nonexistent\", f)\n\n    def test_src(self):\n        f = self.flow()\n        assert self.q(\"~src 127.0.0.1\", f)\n        assert not self.q(\"~src foobar\", f)\n        assert self.q(\"~src :22\", f)\n        assert not self.q(\"~src :99\", f)\n        assert self.q(\"~src 127.0.0.1:22\", f)\n\n    def test_dst(self):\n        f = self.flow()\n        f.server_conn = tflow.tserver_conn()\n        assert self.q(\"~dst address\", f)\n        assert not self.q(\"~dst foobar\", f)\n        assert self.q(\"~dst :22\", f)\n        assert not self.q(\"~dst :99\", f)\n        assert self.q(\"~dst address:22\", f)\n\n    def test_and(self):\n        f = self.flow()\n        f.server_conn = tflow.tserver_conn()\n        assert self.q(\"~b hello & ~b me\", f)\n        assert not self.q(\"~src wrongaddress & ~b hello\", f)\n        assert self.q(\"(~src :22 & ~dst :22) & ~b hello\", f)\n        assert not self.q(\"(~src address:22 & ~dst :22) & ~b nonexistent\", f)\n        assert not self.q(\"(~src address:22 & ~dst :99) & ~b hello\", f)\n\n    def test_or(self):\n        f = self.flow()\n        f.server_conn = tflow.tserver_conn()\n        assert self.q(\"~b hello | ~b me\", f)\n        assert self.q(\"~src :22 | ~b me\", f)\n        assert not self.q(\"~src :99 | ~dst :99\", f)\n        assert self.q(\"(~src :22 | ~dst :22) | ~b me\", f)\n\n    def test_not(self):\n        f = self.flow()\n        assert not self.q(\"! ~src :22\", f)\n        assert self.q(\"! ~src :99\", f)\n        assert self.q(\"!~src :99 !~src :99\", f)\n        assert not self.q(\"!~src :99 !~src :22\", f)\n\n    def test_request(self):\n        f = self.flow()\n        assert not self.q(\"~q\", f)\n\n    def test_response(self):\n        f = self.flow()\n        assert not self.q(\"~s\", f)\n\n    def test_headers(self):\n        f = self.flow()\n        assert not self.q(\"~h whatever\", f)\n\n        # Request headers\n        assert not self.q(\"~hq whatever\", f)\n\n        # Response headers\n        assert not self.q(\"~hs whatever\", f)\n\n    def test_content_type(self):\n        f = self.flow()\n        assert not self.q(\"~t whatever\", f)\n\n        # Request content-type\n        assert not self.q(\"~tq whatever\", f)\n\n        # Response content-type\n        assert not self.q(\"~ts whatever\", f)\n\n    def test_code(self):\n        f = self.flow()\n        assert not self.q(\"~c 200\", f)\n\n    def test_domain(self):\n        f = self.flow()\n        assert not self.q(\"~d whatever\", f)\n\n    def test_method(self):\n        f = self.flow()\n        assert not self.q(\"~m whatever\", f)\n\n    def test_url(self):\n        f = self.flow()\n        assert not self.q(\"~u whatever\", f)\n\n\nclass TestMatchingUDPFlow:\n    def flow(self):\n        return tflow.tudpflow()\n\n    def err(self):\n        return tflow.tudpflow(err=True)\n\n    def q(self, q, o):\n        return flowfilter.parse(q)(o)\n\n    def test_udp(self):\n        f = self.flow()\n        assert self.q(\"~udp\", f)\n        assert not self.q(\"~tcp\", f)\n        assert not self.q(\"~http\", f)\n        assert not self.q(\"~websocket\", f)\n\n    def test_ferr(self):\n        e = self.err()\n        assert self.q(\"~e\", e)\n\n    def test_body(self):\n        f = self.flow()\n\n        # Messages sent by client or server\n        assert self.q(\"~b hello\", f)\n        assert self.q(\"~b me\", f)\n        assert not self.q(\"~b nonexistent\", f)\n\n        # Messages sent by client\n        assert self.q(\"~bq hello\", f)\n        assert not self.q(\"~bq me\", f)\n        assert not self.q(\"~bq nonexistent\", f)\n\n        # Messages sent by server\n        assert self.q(\"~bs me\", f)\n        assert not self.q(\"~bs hello\", f)\n        assert not self.q(\"~bs nonexistent\", f)\n\n    def test_src(self):\n        f = self.flow()\n        assert self.q(\"~src 127.0.0.1\", f)\n        assert not self.q(\"~src foobar\", f)\n        assert self.q(\"~src :22\", f)\n        assert not self.q(\"~src :99\", f)\n        assert self.q(\"~src 127.0.0.1:22\", f)\n\n    def test_dst(self):\n        f = self.flow()\n        f.server_conn = tflow.tserver_conn()\n        assert self.q(\"~dst address\", f)\n        assert not self.q(\"~dst foobar\", f)\n        assert self.q(\"~dst :22\", f)\n        assert not self.q(\"~dst :99\", f)\n        assert self.q(\"~dst address:22\", f)\n\n    def test_and(self):\n        f = self.flow()\n        f.server_conn = tflow.tserver_conn()\n        assert self.q(\"~b hello & ~b me\", f)\n        assert not self.q(\"~src wrongaddress & ~b hello\", f)\n        assert self.q(\"(~src :22 & ~dst :22) & ~b hello\", f)\n        assert not self.q(\"(~src address:22 & ~dst :22) & ~b nonexistent\", f)\n        assert not self.q(\"(~src address:22 & ~dst :99) & ~b hello\", f)\n\n    def test_or(self):\n        f = self.flow()\n        f.server_conn = tflow.tserver_conn()\n        assert self.q(\"~b hello | ~b me\", f)\n        assert self.q(\"~src :22 | ~b me\", f)\n        assert not self.q(\"~src :99 | ~dst :99\", f)\n        assert self.q(\"(~src :22 | ~dst :22) | ~b me\", f)\n\n    def test_not(self):\n        f = self.flow()\n        assert not self.q(\"! ~src :22\", f)\n        assert self.q(\"! ~src :99\", f)\n        assert self.q(\"!~src :99 !~src :99\", f)\n        assert not self.q(\"!~src :99 !~src :22\", f)\n\n    def test_request(self):\n        f = self.flow()\n        assert not self.q(\"~q\", f)\n\n    def test_response(self):\n        f = self.flow()\n        assert not self.q(\"~s\", f)\n\n    def test_headers(self):\n        f = self.flow()\n        assert not self.q(\"~h whatever\", f)\n\n        # Request headers\n        assert not self.q(\"~hq whatever\", f)\n\n        # Response headers\n        assert not self.q(\"~hs whatever\", f)\n\n    def test_content_type(self):\n        f = self.flow()\n        assert not self.q(\"~t whatever\", f)\n\n        # Request content-type\n        assert not self.q(\"~tq whatever\", f)\n\n        # Response content-type\n        assert not self.q(\"~ts whatever\", f)\n\n    def test_code(self):\n        f = self.flow()\n        assert not self.q(\"~c 200\", f)\n\n    def test_domain(self):\n        f = self.flow()\n        assert not self.q(\"~d whatever\", f)\n\n    def test_method(self):\n        f = self.flow()\n        assert not self.q(\"~m whatever\", f)\n\n    def test_url(self):\n        f = self.flow()\n        assert not self.q(\"~u whatever\", f)\n\n\nclass TestMatchingWebSocketFlow:\n    def flow(self) -> http.HTTPFlow:\n        return tflow.twebsocketflow()\n\n    def q(self, q, o):\n        return flowfilter.parse(q)(o)\n\n    def test_websocket(self):\n        f = self.flow()\n        assert self.q(\"~websocket\", f)\n        assert not self.q(\"~tcp\", f)\n        assert self.q(\"~http\", f)\n\n    def test_handshake(self):\n        f = self.flow()\n        assert self.q(\"~websocket\", f)\n        assert not self.q(\"~tcp\", f)\n        assert self.q(\"~http\", f)\n\n        f = tflow.tflow()\n        assert not self.q(\"~websocket\", f)\n        f = tflow.tflow(resp=True)\n        assert not self.q(\"~websocket\", f)\n\n    def test_domain(self):\n        q = self.flow()\n        assert self.q(\"~d example.com\", q)\n        assert not self.q(\"~d none\", q)\n\n    def test_url(self):\n        q = self.flow()\n        assert self.q(\"~u example.com\", q)\n        assert self.q(\"~u example.com/ws\", q)\n        assert not self.q(\"~u moo/path\", q)\n\n    def test_body(self):\n        f = self.flow()\n\n        # Messages sent by client or server\n        assert self.q(\"~b hello\", f)\n        assert self.q(\"~b me\", f)\n        assert not self.q(\"~b nonexistent\", f)\n\n        # Messages sent by client\n        assert self.q(\"~bq hello\", f)\n        assert not self.q(\"~bq me\", f)\n        assert not self.q(\"~bq nonexistent\", f)\n\n        # Messages sent by server\n        assert self.q(\"~bs me\", f)\n        assert not self.q(\"~bs hello\", f)\n        assert not self.q(\"~bs nonexistent\", f)\n\n    def test_src(self):\n        f = self.flow()\n        assert self.q(\"~src 127.0.0.1\", f)\n        assert not self.q(\"~src foobar\", f)\n        assert self.q(\"~src :22\", f)\n        assert not self.q(\"~src :99\", f)\n        assert self.q(\"~src 127.0.0.1:22\", f)\n\n    def test_dst(self):\n        f = self.flow()\n        f.server_conn = tflow.tserver_conn()\n        assert self.q(\"~dst address\", f)\n        assert not self.q(\"~dst foobar\", f)\n        assert self.q(\"~dst :22\", f)\n        assert not self.q(\"~dst :99\", f)\n        assert self.q(\"~dst address:22\", f)\n\n    def test_and(self):\n        f = self.flow()\n        f.server_conn = tflow.tserver_conn()\n        assert self.q(\"~b hello & ~b me\", f)\n        assert not self.q(\"~src wrongaddress & ~b hello\", f)\n        assert self.q(\"(~src :22 & ~dst :22) & ~b hello\", f)\n        assert not self.q(\"(~src address:22 & ~dst :22) & ~b nonexistent\", f)\n        assert not self.q(\"(~src address:22 & ~dst :99) & ~b hello\", f)\n\n    def test_or(self):\n        f = self.flow()\n        f.server_conn = tflow.tserver_conn()\n        assert self.q(\"~b hello | ~b me\", f)\n        assert self.q(\"~src :22 | ~b me\", f)\n        assert not self.q(\"~src :99 | ~dst :99\", f)\n        assert self.q(\"(~src :22 | ~dst :22) | ~b me\", f)\n\n    def test_not(self):\n        f = self.flow()\n        assert not self.q(\"! ~src :22\", f)\n        assert self.q(\"! ~src :99\", f)\n        assert self.q(\"!~src :99 !~src :99\", f)\n        assert not self.q(\"!~src :99 !~src :22\", f)\n\n\nclass TestMatchingDummyFlow:\n    def flow(self):\n        return tflow.tdummyflow()\n\n    def err(self):\n        return tflow.tdummyflow(err=True)\n\n    def q(self, q, o):\n        return flowfilter.parse(q)(o)\n\n    def test_filters(self):\n        e = self.err()\n        f = self.flow()\n        f.server_conn = tflow.tserver_conn()\n\n        assert self.q(\"~all\", f)\n\n        assert not self.q(\"~a\", f)\n\n        assert not self.q(\"~b whatever\", f)\n        assert not self.q(\"~bq whatever\", f)\n        assert not self.q(\"~bs whatever\", f)\n\n        assert not self.q(\"~c 0\", f)\n\n        assert not self.q(\"~d whatever\", f)\n\n        assert self.q(\"~dst address\", f)\n        assert not self.q(\"~dst nonexistent\", f)\n\n        assert self.q(\"~e\", e)\n        assert not self.q(\"~e\", f)\n\n        assert not self.q(\"~http\", f)\n        assert not self.q(\"~tcp\", f)\n        assert not self.q(\"~websocket\", f)\n\n        assert not self.q(\"~h whatever\", f)\n        assert not self.q(\"~hq whatever\", f)\n        assert not self.q(\"~hs whatever\", f)\n\n        assert not self.q(\"~m whatever\", f)\n\n        assert not self.q(\"~s\", f)\n\n        assert self.q(\"~src 127.0.0.1\", f)\n        assert not self.q(\"~src nonexistent\", f)\n\n        assert not self.q(\"~tcp\", f)\n\n        assert not self.q(\"~t whatever\", f)\n        assert not self.q(\"~tq whatever\", f)\n        assert not self.q(\"~ts whatever\", f)\n\n        assert not self.q(\"~u whatever\", f)\n\n        assert not self.q(\"~q\", f)\n\n        assert not self.q(\"~comment .\", f)\n        f.comment = \"comment\"\n        assert self.q(\"~comment .\", f)\n\n\n@patch(\"traceback.extract_tb\")\ndef test_pyparsing_bug(extract_tb):\n    \"\"\"https://github.com/mitmproxy/mitmproxy/issues/1087\"\"\"\n    # The text is a string with leading and trailing whitespace stripped; if the source is not available it is None.\n    extract_tb.return_value = [(\"\", 1, \"test\", None)]\n    assert flowfilter.parse(\"test\")\n\n\ndef test_match():\n    with pytest.raises(ValueError):\n        flowfilter.match(\"[foobar\", None)\n\n    assert flowfilter.match(None, None)\n    assert not flowfilter.match(\"foobar\", None)\n", "test/mitmproxy/test_hooks.py": "from dataclasses import dataclass\n\nimport pytest\n\nfrom mitmproxy import hooks\n\n\ndef test_hook():\n    with pytest.raises(TypeError, match=\"may not be instantiated directly\"):\n        hooks.Hook()\n\n    class NoDataClass(hooks.Hook):\n        pass\n\n    with pytest.raises(TypeError, match=\"not a dataclass\"):\n        NoDataClass()\n\n    @dataclass\n    class FooHook(hooks.Hook):\n        data: bytes\n\n    e = FooHook(b\"foo\")\n    assert repr(e)\n    assert e.args() == [b\"foo\"]\n    assert FooHook in hooks.all_hooks.values()\n\n    with pytest.warns(RuntimeWarning, match=\"Two conflicting event classes\"):\n\n        @dataclass\n        class FooHook2(hooks.Hook):\n            name = \"foo\"\n\n    @dataclass\n    class AnotherABC(hooks.Hook):\n        name = \"\"\n\n    assert AnotherABC not in hooks.all_hooks.values()\n", "test/mitmproxy/test_exceptions.py": "# TODO: write tests\n", "test/mitmproxy/test_command.py": "import inspect\nimport io\nfrom collections.abc import Sequence\n\nimport pytest\n\nimport mitmproxy.types\nfrom mitmproxy import command\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\nclass TAddon:\n    @command.command(\"cmd1\")\n    def cmd1(self, foo: str) -> str:\n        \"\"\"cmd1 help\"\"\"\n        return \"ret \" + foo\n\n    @command.command(\"cmd2\")\n    def cmd2(self, foo: str) -> str:\n        return 99\n\n    @command.command(\"cmd3\")\n    def cmd3(self, foo: int) -> int:\n        return foo\n\n    @command.command(\"cmd4\")\n    def cmd4(self, a: int, b: str, c: mitmproxy.types.Path) -> str:\n        return \"ok\"\n\n    @command.command(\"subcommand\")\n    def subcommand(\n        self, cmd: mitmproxy.types.Cmd, *args: mitmproxy.types.CmdArgs\n    ) -> str:\n        return \"ok\"\n\n    @command.command(\"empty\")\n    def empty(self) -> None:\n        pass\n\n    @command.command(\"varargs\")\n    def varargs(self, one: str, *var: str) -> Sequence[str]:\n        return list(var)\n\n    def choices(self) -> Sequence[str]:\n        return [\"one\", \"two\", \"three\"]\n\n    @command.argument(\"arg\", type=mitmproxy.types.Choice(\"choices\"))\n    def choose(self, arg: str) -> Sequence[str]:\n        return [\"one\", \"two\", \"three\"]\n\n    @command.command(\"path\")\n    def path(self, arg: mitmproxy.types.Path) -> None:\n        pass\n\n    @command.command(\"flow\")\n    def flow(self, f: flow.Flow, s: str) -> None:\n        pass\n\n\nclass Unsupported:\n    pass\n\n\nclass TypeErrAddon:\n    @command.command(\"noret\")\n    def noret(self):\n        pass\n\n    @command.command(\"invalidret\")\n    def invalidret(self) -> Unsupported:\n        pass\n\n    @command.command(\"invalidarg\")\n    def invalidarg(self, u: Unsupported):\n        pass\n\n\nclass TestCommand:\n    def test_typecheck(self):\n        with taddons.context(loadcore=False) as tctx:\n            cm = command.CommandManager(tctx.master)\n            a = TypeErrAddon()\n            command.Command(cm, \"noret\", a.noret)\n            with pytest.raises(exceptions.CommandError):\n                command.Command(cm, \"invalidret\", a.invalidret)\n            with pytest.raises(exceptions.CommandError):\n                assert command.Command(cm, \"invalidarg\", a.invalidarg)\n\n    def test_varargs(self):\n        with taddons.context() as tctx:\n            cm = command.CommandManager(tctx.master)\n            a = TAddon()\n            c = command.Command(cm, \"varargs\", a.varargs)\n            assert c.signature_help() == \"varargs one *var -> str[]\"\n            assert c.call([\"one\", \"two\", \"three\"]) == [\"two\", \"three\"]\n\n    def test_call(self):\n        with taddons.context() as tctx:\n            cm = command.CommandManager(tctx.master)\n            a = TAddon()\n            c = command.Command(cm, \"cmd.path\", a.cmd1)\n            assert c.call([\"foo\"]) == \"ret foo\"\n            assert c.signature_help() == \"cmd.path foo -> str\"\n\n            c = command.Command(cm, \"cmd.two\", a.cmd2)\n            with pytest.raises(exceptions.CommandError):\n                c.call([\"foo\"])\n\n            c = command.Command(cm, \"cmd.three\", a.cmd3)\n            assert c.call([\"1\"]) == 1\n\n    def test_parse_partial(self):\n        tests = [\n            [\n                \"foo bar\",\n                [\n                    command.ParseResult(\n                        value=\"foo\", type=mitmproxy.types.Cmd, valid=False\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\"bar\", type=mitmproxy.types.Unknown, valid=False\n                    ),\n                ],\n                [],\n            ],\n            [\n                \"cmd1 'bar\",\n                [\n                    command.ParseResult(\n                        value=\"cmd1\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(value=\"'bar\", type=str, valid=True),\n                ],\n                [],\n            ],\n            [\n                \"a\",\n                [command.ParseResult(value=\"a\", type=mitmproxy.types.Cmd, valid=False)],\n                [],\n            ],\n            [\n                \"\",\n                [],\n                [\n                    command.CommandParameter(\"\", mitmproxy.types.Cmd),\n                    command.CommandParameter(\"\", mitmproxy.types.CmdArgs),\n                ],\n            ],\n            [\n                \"cmd3 1\",\n                [\n                    command.ParseResult(\n                        value=\"cmd3\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(value=\"1\", type=int, valid=True),\n                ],\n                [],\n            ],\n            [\n                \"cmd3 \",\n                [\n                    command.ParseResult(\n                        value=\"cmd3\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                ],\n                [command.CommandParameter(\"foo\", int)],\n            ],\n            [\n                \"subcommand \",\n                [\n                    command.ParseResult(\n                        value=\"subcommand\",\n                        type=mitmproxy.types.Cmd,\n                        valid=True,\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                ],\n                [\n                    command.CommandParameter(\"cmd\", mitmproxy.types.Cmd),\n                    command.CommandParameter(\n                        \"args\",\n                        mitmproxy.types.CmdArgs,\n                        kind=inspect.Parameter.VAR_POSITIONAL,\n                    ),\n                ],\n            ],\n            [\n                \"varargs one\",\n                [\n                    command.ParseResult(\n                        value=\"varargs\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(value=\"one\", type=str, valid=True),\n                ],\n                [\n                    command.CommandParameter(\n                        \"var\", str, kind=inspect.Parameter.VAR_POSITIONAL\n                    )\n                ],\n            ],\n            [\n                \"varargs one two three\",\n                [\n                    command.ParseResult(\n                        value=\"varargs\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(value=\"one\", type=str, valid=True),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(value=\"two\", type=str, valid=True),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(value=\"three\", type=str, valid=True),\n                ],\n                [],\n            ],\n            [\n                \"subcommand cmd3 \",\n                [\n                    command.ParseResult(\n                        value=\"subcommand\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\"cmd3\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                ],\n                [command.CommandParameter(\"foo\", int)],\n            ],\n            [\n                \"cmd4\",\n                [\n                    command.ParseResult(\n                        value=\"cmd4\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                ],\n                [\n                    command.CommandParameter(\"a\", int),\n                    command.CommandParameter(\"b\", str),\n                    command.CommandParameter(\"c\", mitmproxy.types.Path),\n                ],\n            ],\n            [\n                \"cmd4 \",\n                [\n                    command.ParseResult(\n                        value=\"cmd4\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                ],\n                [\n                    command.CommandParameter(\"a\", int),\n                    command.CommandParameter(\"b\", str),\n                    command.CommandParameter(\"c\", mitmproxy.types.Path),\n                ],\n            ],\n            [\n                \"cmd4 1\",\n                [\n                    command.ParseResult(\n                        value=\"cmd4\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(value=\"1\", type=int, valid=True),\n                ],\n                [\n                    command.CommandParameter(\"b\", str),\n                    command.CommandParameter(\"c\", mitmproxy.types.Path),\n                ],\n            ],\n            [\n                \"flow\",\n                [\n                    command.ParseResult(\n                        value=\"flow\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                ],\n                [\n                    command.CommandParameter(\"f\", flow.Flow),\n                    command.CommandParameter(\"s\", str),\n                ],\n            ],\n            [\n                \"flow \",\n                [\n                    command.ParseResult(\n                        value=\"flow\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                ],\n                [\n                    command.CommandParameter(\"f\", flow.Flow),\n                    command.CommandParameter(\"s\", str),\n                ],\n            ],\n            [\n                \"flow x\",\n                [\n                    command.ParseResult(\n                        value=\"flow\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(value=\"x\", type=flow.Flow, valid=False),\n                ],\n                [\n                    command.CommandParameter(\"s\", str),\n                ],\n            ],\n            [\n                \"flow x \",\n                [\n                    command.ParseResult(\n                        value=\"flow\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(value=\"x\", type=flow.Flow, valid=False),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                ],\n                [\n                    command.CommandParameter(\"s\", str),\n                ],\n            ],\n            [\n                'flow \"one two',\n                [\n                    command.ParseResult(\n                        value=\"flow\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(value='\"one two', type=flow.Flow, valid=False),\n                ],\n                [\n                    command.CommandParameter(\"s\", str),\n                ],\n            ],\n            [\n                'flow \"three four\"',\n                [\n                    command.ParseResult(\n                        value=\"flow\", type=mitmproxy.types.Cmd, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value='\"three four\"', type=flow.Flow, valid=False\n                    ),\n                ],\n                [\n                    command.CommandParameter(\"s\", str),\n                ],\n            ],\n            [\n                \"spaces '    '\",\n                [\n                    command.ParseResult(\n                        value=\"spaces\", type=mitmproxy.types.Cmd, valid=False\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\"'    '\", type=mitmproxy.types.Unknown, valid=False\n                    ),\n                ],\n                [],\n            ],\n            [\n                'spaces2 \"    \"',\n                [\n                    command.ParseResult(\n                        value=\"spaces2\", type=mitmproxy.types.Cmd, valid=False\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value='\"    \"', type=mitmproxy.types.Unknown, valid=False\n                    ),\n                ],\n                [],\n            ],\n            [\n                '\"abc\"',\n                [\n                    command.ParseResult(\n                        value='\"abc\"', type=mitmproxy.types.Cmd, valid=False\n                    ),\n                ],\n                [],\n            ],\n            [\n                \"'def'\",\n                [\n                    command.ParseResult(\n                        value=\"'def'\", type=mitmproxy.types.Cmd, valid=False\n                    ),\n                ],\n                [],\n            ],\n            [\n                \"cmd10 'a' \\\"b\\\" c\",\n                [\n                    command.ParseResult(\n                        value=\"cmd10\", type=mitmproxy.types.Cmd, valid=False\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\"'a'\", type=mitmproxy.types.Unknown, valid=False\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value='\"b\"', type=mitmproxy.types.Unknown, valid=False\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\"c\", type=mitmproxy.types.Unknown, valid=False\n                    ),\n                ],\n                [],\n            ],\n            [\n                \"cmd11 'a \\\"b\\\" c'\",\n                [\n                    command.ParseResult(\n                        value=\"cmd11\", type=mitmproxy.types.Cmd, valid=False\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\"'a \\\"b\\\" c'\", type=mitmproxy.types.Unknown, valid=False\n                    ),\n                ],\n                [],\n            ],\n            [\n                \"cmd12 \\\"a 'b' c\\\"\",\n                [\n                    command.ParseResult(\n                        value=\"cmd12\", type=mitmproxy.types.Cmd, valid=False\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\"\\\"a 'b' c\\\"\", type=mitmproxy.types.Unknown, valid=False\n                    ),\n                ],\n                [],\n            ],\n            [\n                \"    spaces_at_the_begining_are_not_stripped\",\n                [\n                    command.ParseResult(\n                        value=\"    \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\"spaces_at_the_begining_are_not_stripped\",\n                        type=mitmproxy.types.Cmd,\n                        valid=False,\n                    ),\n                ],\n                [],\n            ],\n            [\n                \"    spaces_at_the_begining_are_not_stripped neither_at_the_end      \",\n                [\n                    command.ParseResult(\n                        value=\"    \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\"spaces_at_the_begining_are_not_stripped\",\n                        type=mitmproxy.types.Cmd,\n                        valid=False,\n                    ),\n                    command.ParseResult(\n                        value=\" \", type=mitmproxy.types.Space, valid=True\n                    ),\n                    command.ParseResult(\n                        value=\"neither_at_the_end\",\n                        type=mitmproxy.types.Unknown,\n                        valid=False,\n                    ),\n                    command.ParseResult(\n                        value=\"      \", type=mitmproxy.types.Space, valid=True\n                    ),\n                ],\n                [],\n            ],\n        ]\n\n        with taddons.context() as tctx:\n            tctx.master.addons.add(TAddon())\n            for s, expected, expectedremain in tests:\n                current, remain = tctx.master.commands.parse_partial(s)\n                assert (s, current, expectedremain) == (s, expected, remain)\n\n\ndef test_simple():\n    with taddons.context() as tctx:\n        c = command.CommandManager(tctx.master)\n        a = TAddon()\n        c.add(\"one.two\", a.cmd1)\n        assert c.commands[\"one.two\"].help == \"cmd1 help\"\n        assert c.execute(\"one.two foo\") == \"ret foo\"\n        assert c.execute('one.two \"foo\"') == \"ret foo\"\n        assert c.execute(\"one.two 'foo bar'\") == \"ret foo bar\"\n        assert c.call(\"one.two\", \"foo\") == \"ret foo\"\n        with pytest.raises(exceptions.CommandError, match=\"Unknown\"):\n            c.execute(\"nonexistent\")\n        with pytest.raises(exceptions.CommandError, match=\"Invalid\"):\n            c.execute(\"\")\n        with pytest.raises(exceptions.CommandError, match=\"argument mismatch\"):\n            c.execute(\"one.two too many args\")\n        with pytest.raises(exceptions.CommandError, match=\"Unknown\"):\n            c.call(\"nonexistent\")\n        with pytest.raises(exceptions.CommandError, match=\"Unknown\"):\n            c.execute(\"\\\\\")\n\n        c.add(\"empty\", a.empty)\n        c.execute(\"empty\")\n\n        fp = io.StringIO()\n        c.dump(fp)\n        assert fp.getvalue()\n\n\ndef test_typename():\n    assert command.typename(str) == \"str\"\n    assert command.typename(Sequence[flow.Flow]) == \"flow[]\"\n\n    assert command.typename(mitmproxy.types.Data) == \"data[][]\"\n    assert command.typename(mitmproxy.types.CutSpec) == \"cut[]\"\n\n    assert command.typename(flow.Flow) == \"flow\"\n    assert command.typename(Sequence[str]) == \"str[]\"\n\n    assert command.typename(mitmproxy.types.Choice(\"foo\")) == \"choice\"\n    assert command.typename(mitmproxy.types.Path) == \"path\"\n    assert command.typename(mitmproxy.types.Cmd) == \"cmd\"\n\n    with pytest.raises(exceptions.CommandError, match=\"missing type annotation\"):\n        command.typename(inspect._empty)\n    with pytest.raises(exceptions.CommandError, match=\"unsupported type\"):\n        command.typename(None)\n\n\nclass DummyConsole:\n    @command.command(\"view.flows.resolve\")\n    def resolve(self, spec: str) -> Sequence[flow.Flow]:\n        n = int(spec)\n        return [tflow.tflow(resp=True)] * n\n\n    @command.command(\"cut\")\n    def cut(self, spec: str) -> mitmproxy.types.Data:\n        return [[\"test\"]]\n\n\ndef test_parsearg():\n    with taddons.context() as tctx:\n        tctx.master.addons.add(DummyConsole())\n        assert command.parsearg(tctx.master.commands, \"foo\", str) == \"foo\"\n        with pytest.raises(exceptions.CommandError, match=\"Unsupported\"):\n            command.parsearg(tctx.master.commands, \"foo\", type)\n        with pytest.raises(exceptions.CommandError):\n            command.parsearg(tctx.master.commands, \"foo\", int)\n\n\nclass TDec:\n    @command.command(\"cmd1\")\n    def cmd1(self, foo: str) -> str:\n        \"\"\"cmd1 help\"\"\"\n        return \"ret \" + foo\n\n    @command.command(\"cmd2\")\n    def cmd2(self, foo: str) -> str:\n        return 99\n\n    @command.command(\"empty\")\n    def empty(self) -> None:\n        pass\n\n\nclass TAttr:\n    def __getattr__(self, item):\n        raise OSError\n\n\nclass TAttr2:\n    def __getattr__(self, item):\n        return TAttr2()\n\n\nclass TCmds(TAttr):\n    def __init__(self):\n        self.TAttr = TAttr()\n        self.TAttr2 = TAttr2()\n\n    @command.command(\"empty\")\n    def empty(self) -> None:\n        pass\n\n\nasync def test_collect_commands(caplog):\n    \"\"\"\n    This tests for errors thrown by getattr() or __getattr__ implementations\n    that return an object for .command_name.\n    \"\"\"\n    with taddons.context() as tctx:\n        c = command.CommandManager(tctx.master)\n        a = TCmds()\n        c.collect_commands(a)\n        assert \"empty\" in c.commands\n\n        a = TypeErrAddon()\n        c.collect_commands(a)\n        assert \"Could not load\" in caplog.text\n\n\ndef test_decorator():\n    with taddons.context() as tctx:\n        c = command.CommandManager(tctx.master)\n        a = TDec()\n        c.collect_commands(a)\n        assert \"cmd1\" in c.commands\n        assert c.execute(\"cmd1 bar\") == \"ret bar\"\n        assert \"empty\" in c.commands\n        assert c.execute(\"empty\") is None\n\n    with taddons.context() as tctx:\n        tctx.master.addons.add(a)\n        assert tctx.master.commands.execute(\"cmd1 bar\") == \"ret bar\"\n\n\ndef test_verify_arg_signature():\n    with pytest.raises(exceptions.CommandError):\n        command.verify_arg_signature(lambda: None, [1, 2], {})\n        print(\"hello there\")\n    command.verify_arg_signature(lambda a, b: None, [1, 2], {})\n", "test/mitmproxy/test_ctx.py": "# TODO: write tests\n", "test/mitmproxy/test_master.py": "import asyncio\nimport gc\n\nfrom mitmproxy.master import Master\n\n\nasync def err():\n    raise RuntimeError\n\n\nasync def test_exception_handler(caplog_async):\n    caplog_async.set_level(\"ERROR\")\n\n    # start proxy master and let it initialize its exception handler\n    master = Master(None)\n    running = asyncio.create_task(master.run())\n    await asyncio.sleep(0)\n\n    # create a task with an unhandled exception...\n    task = asyncio.create_task(err())\n    # make sure said task is run...\n    await asyncio.sleep(0)\n\n    # and garbage-collected...\n    assert task\n    del task\n    gc.collect()\n\n    # and ensure that this triggered a log entry.\n    await caplog_async.await_log(\"Traceback\")\n\n    master.shutdown()\n    await running\n", "test/mitmproxy/test_flow.py": "import io\n\nimport pytest\n\nimport mitmproxy.io\nfrom mitmproxy import flow\nfrom mitmproxy import flowfilter\nfrom mitmproxy import options\nfrom mitmproxy.exceptions import FlowReadException\nfrom mitmproxy.io import tnetstring\nfrom mitmproxy.proxy import layers\nfrom mitmproxy.proxy import server_hooks\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\nclass State:\n    def __init__(self):\n        self.flows = []\n\n    def request(self, f):\n        if f not in self.flows:\n            self.flows.append(f)\n\n    def response(self, f):\n        if f not in self.flows:\n            self.flows.append(f)\n\n    def websocket_start(self, f):\n        if f not in self.flows:\n            self.flows.append(f)\n\n\nclass TestSerialize:\n    def test_roundtrip(self):\n        sio = io.BytesIO()\n        f = tflow.tflow()\n        f.marked = \":default:\"\n        f.marked = True\n        f.comment = \"test comment\"\n        f.request.content = bytes(range(256))\n        w = mitmproxy.io.FlowWriter(sio)\n        w.add(f)\n\n        sio.seek(0)\n        r = mitmproxy.io.FlowReader(sio)\n        lst = list(r.stream())\n        assert len(lst) == 1\n\n        f2 = lst[0]\n        assert f2.get_state() == f.get_state()\n        assert f2.request.data == f.request.data\n        assert f2.marked\n        assert f2.comment == \"test comment\"\n\n    def test_filter(self):\n        sio = io.BytesIO()\n        flt = flowfilter.parse(\"~c 200\")\n        w = mitmproxy.io.FilteredFlowWriter(sio, flt)\n\n        f = tflow.tflow(resp=True)\n        f.response.status_code = 200\n        w.add(f)\n\n        f = tflow.tflow(resp=True)\n        f.response.status_code = 201\n        w.add(f)\n\n        sio.seek(0)\n        r = mitmproxy.io.FlowReader(sio)\n        assert len(list(r.stream()))\n\n    def test_error(self):\n        buf = io.BytesIO()\n        buf.write(b\"bogus\")\n        buf.seek(0)\n        r = mitmproxy.io.FlowReader(buf)\n        with pytest.raises(FlowReadException, match=\"Invalid data format\"):\n            list(r.stream())\n\n        buf = io.BytesIO()\n        f = tflow.tdummyflow()\n        w = mitmproxy.io.FlowWriter(buf)\n        w.add(f)\n\n        buf = io.BytesIO(buf.getvalue().replace(b\"dummy\", b\"nknwn\"))\n        r = mitmproxy.io.FlowReader(buf)\n        with pytest.raises(FlowReadException, match=\"Unknown flow type\"):\n            list(r.stream())\n\n        f = FlowReadException(\"foo\")\n        assert str(f) == \"foo\"\n\n    def test_versioncheck(self):\n        f = tflow.tflow()\n        d = f.get_state()\n        d[\"version\"] = (0, 0)\n        sio = io.BytesIO()\n        tnetstring.dump(d, sio)\n        sio.seek(0)\n\n        r = mitmproxy.io.FlowReader(sio)\n        with pytest.raises(Exception, match=\"version\"):\n            list(r.stream())\n\n    def test_copy(self):\n        \"\"\"\n        _backup may be shared across instances. That should not raise errors.\n        \"\"\"\n        f = tflow.tflow()\n        f.backup()\n        f.request.path = \"/foo\"\n        f2 = f.copy()\n        f2.revert()\n        f.revert()\n\n\nclass TestFlowMaster:\n    async def test_load_http_flow_reverse(self):\n        opts = options.Options(mode=[\"reverse:https://use-this-domain\"])\n        s = State()\n        with taddons.context(s, options=opts) as ctx:\n            f = tflow.tflow(resp=True)\n            await ctx.master.load_flow(f)\n            assert s.flows[0].request.host == \"use-this-domain\"\n\n    async def test_all(self):\n        opts = options.Options(mode=[\"reverse:https://use-this-domain\"])\n        s = State()\n        with taddons.context(s, options=opts) as ctx:\n            f = tflow.tflow(req=None)\n            await ctx.master.addons.handle_lifecycle(\n                server_hooks.ClientConnectedHook(f.client_conn)\n            )\n            f.request = mitmproxy.test.tutils.treq()\n            await ctx.master.addons.handle_lifecycle(layers.http.HttpRequestHook(f))\n            assert len(s.flows) == 1\n\n            f.response = mitmproxy.test.tutils.tresp()\n            await ctx.master.addons.handle_lifecycle(layers.http.HttpResponseHook(f))\n            assert len(s.flows) == 1\n\n            await ctx.master.addons.handle_lifecycle(\n                server_hooks.ClientDisconnectedHook(f.client_conn)\n            )\n\n            f.error = flow.Error(\"msg\")\n            await ctx.master.addons.handle_lifecycle(layers.http.HttpErrorHook(f))\n\n\nclass TestError:\n    def test_getset_state(self):\n        e = flow.Error(\"Error\")\n        state = e.get_state()\n        assert flow.Error.from_state(state).get_state() == e.get_state()\n\n        assert e.copy()\n\n        e2 = flow.Error(\"bar\")\n        assert not e == e2\n        e.set_state(e2.get_state())\n        assert e.get_state() == e2.get_state()\n\n        e3 = e.copy()\n        assert e3.get_state() == e.get_state()\n\n    def test_repr(self):\n        e = flow.Error(\"yay\")\n        assert repr(e)\n        assert str(e)\n", "test/mitmproxy/test_tcp.py": "import pytest\n\nfrom mitmproxy import flowfilter\nfrom mitmproxy import tcp\nfrom mitmproxy.test import tflow\n\n\nclass TestTCPFlow:\n    def test_copy(self):\n        f = tflow.ttcpflow()\n        f.get_state()\n        f2 = f.copy()\n        a = f.get_state()\n        b = f2.get_state()\n        del a[\"id\"]\n        del b[\"id\"]\n        assert a == b\n        assert not f == f2\n        assert f is not f2\n\n        assert f.messages is not f2.messages\n\n        for m in f.messages:\n            assert m.get_state()\n            m2 = m.copy()\n            assert not m == m2\n            assert m is not m2\n\n            a = m.get_state()\n            b = m2.get_state()\n            assert a == b\n\n        m = tcp.TCPMessage(False, \"foo\")\n        m.set_state(f.messages[0].get_state())\n        assert m.timestamp == f.messages[0].timestamp\n\n        f = tflow.ttcpflow(err=True)\n        f2 = f.copy()\n        assert f is not f2\n        assert f.error.get_state() == f2.error.get_state()\n        assert f.error is not f2.error\n\n    def test_match(self):\n        f = tflow.ttcpflow()\n        assert not flowfilter.match(\"~b nonexistent\", f)\n        assert flowfilter.match(None, f)\n        assert not flowfilter.match(\"~b nonexistent\", f)\n\n        f = tflow.ttcpflow(err=True)\n        assert flowfilter.match(\"~e\", f)\n\n        with pytest.raises(ValueError):\n            flowfilter.match(\"~\", f)\n\n    def test_repr(self):\n        f = tflow.ttcpflow()\n        assert \"TCPFlow\" in repr(f)\n        assert \"-> \" in repr(f.messages[0])\n", "test/mitmproxy/test_proxy.py": "import argparse\n\nimport pytest\n\nfrom mitmproxy import options\nfrom mitmproxy.tools import cmdline\nfrom mitmproxy.tools import main\n\n\nclass MockParser(argparse.ArgumentParser):\n    \"\"\"\n    argparse.ArgumentParser sys.exits() by default.\n    Make it more testable by throwing an exception instead.\n    \"\"\"\n\n    def error(self, message):\n        raise Exception(message)\n\n\nclass TestProcessProxyOptions:\n    def p(self, *args):\n        parser = MockParser()\n        opts = options.Options()\n        cmdline.common_options(parser, opts)\n        args = parser.parse_args(args=args)\n        pconf = main.process_options(parser, opts, args)\n        return parser, pconf\n\n    def assert_noerr(self, *args):\n        m, p = self.p(*args)\n        assert p\n        return p\n\n    def test_simple(self):\n        assert self.p()\n\n    def test_certs(self, tdata):\n        with pytest.raises(Exception, match=\"ambiguous option\"):\n            self.assert_noerr(\"--cert\", tdata.path(\"mitmproxy/data/testkey.pem\"))\n", "test/mitmproxy/test_addonmanager.py": "import pytest\n\nfrom mitmproxy import addonmanager\nfrom mitmproxy import addons\nfrom mitmproxy import command\nfrom mitmproxy import exceptions\nfrom mitmproxy import hooks\nfrom mitmproxy import master\nfrom mitmproxy import options\nfrom mitmproxy.addonmanager import Loader\nfrom mitmproxy.proxy.layers.http import HttpRequestHook\nfrom mitmproxy.proxy.layers.http import HttpResponseHook\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\nclass TAddon:\n    def __init__(self, name, addons=None):\n        self.name = name\n        self.response = True\n        self.running_called = False\n        if addons:\n            self.addons = addons\n\n    @command.command(\"test.command\")\n    def testcommand(self) -> str:\n        return \"here\"\n\n    def __repr__(self):\n        return \"Addon(%s)\" % self.name\n\n    def done(self):\n        pass\n\n    def running(self):\n        self.running_called = True\n\n\nclass AsyncTAddon(TAddon):\n    async def done(self):\n        pass\n\n    async def running(self):\n        self.running_called = True\n\n\nclass THalt:\n    def running(self):\n        raise exceptions.AddonHalt\n\n\nclass AsyncTHalt:\n    async def running(self):\n        raise exceptions.AddonHalt\n\n\nclass AOption:\n    def load(self, loader: Loader):\n        loader.add_option(\"custom_option\", bool, False, \"help\")\n\n\nclass AOldAPI:\n    def clientconnect(self):\n        pass\n\n\ndef test_command():\n    with taddons.context() as tctx:\n        tctx.master.addons.add(TAddon(\"test\"))\n        assert tctx.master.commands.execute(\"test.command\") == \"here\"\n\n\nasync def test_halt():\n    o = options.Options()\n    m = master.Master(o)\n    a = addonmanager.AddonManager(m)\n    halt = THalt()\n    end = TAddon(\"end\")\n    a.add(halt)\n    a.add(end)\n\n    assert not end.running_called\n    a.trigger(hooks.RunningHook())\n    assert not end.running_called\n\n    a.remove(halt)\n    a.trigger(hooks.RunningHook())\n    assert end.running_called\n\n\nasync def test_async_halt():\n    o = options.Options()\n    m = master.Master(o)\n    a = addonmanager.AddonManager(m)\n    halt = AsyncTHalt()\n    end = AsyncTAddon(\"end\")\n    a.add(halt)\n    a.add(end)\n\n    assert not end.running_called\n    await a.trigger_event(hooks.RunningHook())\n    assert not end.running_called\n\n    a.remove(halt)\n    await a.trigger_event(hooks.RunningHook())\n    assert end.running_called\n\n\nasync def test_lifecycle():\n    o = options.Options()\n    m = master.Master(o)\n    a = addonmanager.AddonManager(m)\n    a.add(TAddon(\"one\"))\n\n    assert str(a)\n\n    with pytest.raises(exceptions.AddonManagerError):\n        a.add(TAddon(\"one\"))\n    with pytest.raises(exceptions.AddonManagerError):\n        a.remove(TAddon(\"nonexistent\"))\n\n    f = tflow.tflow()\n    await a.handle_lifecycle(HttpRequestHook(f))\n\n    a._configure_all(o.keys())\n\n\ndef test_defaults():\n    assert addons.default_addons()\n\n\nasync def test_mixed_async_sync(caplog):\n    with taddons.context(loadcore=False) as tctx:\n        a = tctx.master.addons\n\n        assert len(a) == 0\n        a1 = TAddon(\"sync\")\n        a2 = AsyncTAddon(\"async\")\n        a.add(a1)\n        a.add(a2)\n\n        # test that we can call both sync and async hooks asynchronously\n        assert not a1.running_called\n        assert not a2.running_called\n        await a.trigger_event(hooks.RunningHook())\n        assert a1.running_called\n        assert a2.running_called\n\n        # test that calling an async hook synchronously fails\n        a1.running_called = False\n        a2.running_called = False\n        a.trigger(hooks.RunningHook())\n        assert a1.running_called\n        assert \"called from sync context\" in caplog.text\n\n\nasync def test_loader(caplog):\n    with taddons.context() as tctx:\n        loader = addonmanager.Loader(tctx.master)\n        loader.add_option(\"custom_option\", bool, False, \"help\")\n        assert \"custom_option\" in loader.master.options\n\n        # calling this again with the same signature is a no-op.\n        loader.add_option(\"custom_option\", bool, False, \"help\")\n        assert not caplog.text\n\n        # a different signature should emit a warning though.\n        loader.add_option(\"custom_option\", bool, True, \"help\")\n        assert \"Over-riding existing option\" in caplog.text\n\n        def cmd(a: str) -> str:\n            return \"foo\"\n\n        loader.add_command(\"test.command\", cmd)\n\n\nasync def test_simple(caplog):\n    with taddons.context(loadcore=False) as tctx:\n        a = tctx.master.addons\n\n        assert len(a) == 0\n        a.add(TAddon(\"one\"))\n        assert a.get(\"one\")\n        assert not a.get(\"two\")\n        assert len(a) == 1\n        a.clear()\n        assert len(a) == 0\n        assert not a.chain\n\n    with taddons.context(loadcore=False) as tctx:\n        a.add(TAddon(\"one\"))\n\n        a.trigger(\"nonexistent\")\n        assert \"AssertionError\" in caplog.text\n\n        f = tflow.tflow()\n        a.trigger(hooks.RunningHook())\n        a.trigger(HttpResponseHook(f))\n        assert \"not callable\" in caplog.text\n        caplog.clear()\n\n        caplog.clear()\n        a.get(\"one\").response = addons\n        a.trigger(HttpResponseHook(f))\n        assert \"not callable\" not in caplog.text\n\n        a.remove(a.get(\"one\"))\n        assert not a.get(\"one\")\n\n        ta = TAddon(\"one\")\n        a.add(ta)\n        a.trigger(hooks.RunningHook())\n        assert ta.running_called\n\n        assert ta in a\n\n\nasync def test_load_option():\n    o = options.Options()\n    m = master.Master(o)\n    a = addonmanager.AddonManager(m)\n    a.add(AOption())\n    assert \"custom_option\" in m.options._options\n\n\nasync def test_nesting():\n    o = options.Options()\n    m = master.Master(o)\n    a = addonmanager.AddonManager(m)\n\n    a.add(\n        TAddon(\"one\", addons=[TAddon(\"two\"), TAddon(\"three\", addons=[TAddon(\"four\")])])\n    )\n    assert len(a.chain) == 1\n    assert a.get(\"one\")\n    assert a.get(\"two\")\n    assert a.get(\"three\")\n    assert a.get(\"four\")\n\n    a.trigger(hooks.RunningHook())\n    assert a.get(\"one\").running_called\n    assert a.get(\"two\").running_called\n    assert a.get(\"three\").running_called\n    assert a.get(\"four\").running_called\n\n    a.remove(a.get(\"three\"))\n    assert not a.get(\"three\")\n    assert not a.get(\"four\")\n\n\nasync def test_old_api(caplog):\n    with taddons.context(loadcore=False) as tctx:\n        tctx.master.addons.add(AOldAPI())\n        assert \"clientconnect event has been removed\" in caplog.text\n", "test/mitmproxy/__init__.py": "# Silence third-party modules\nimport logging\n\nlogging.getLogger(\"hyper\").setLevel(logging.WARNING)\nlogging.getLogger(\"requests\").setLevel(logging.WARNING)\nlogging.getLogger(\"passlib\").setLevel(logging.WARNING)\nlogging.getLogger(\"tornado\").setLevel(logging.WARNING)\n", "test/mitmproxy/test_http.py": "import asyncio\nimport email\nimport json\nimport time\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\n\nfrom mitmproxy import flow\nfrom mitmproxy import flowfilter\nfrom mitmproxy.http import Headers\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.http import Message\nfrom mitmproxy.http import Request\nfrom mitmproxy.http import Response\nfrom mitmproxy.net.http.cookies import CookieAttrs\nfrom mitmproxy.test.tflow import tflow\nfrom mitmproxy.test.tutils import treq\nfrom mitmproxy.test.tutils import tresp\n\n\nclass TestRequest:\n    def test_simple(self):\n        f = tflow()\n        r = f.request\n        u = r.url\n        r.url = u\n        with pytest.raises(ValueError):\n            setattr(r, \"url\", \"\")\n        assert r.url == u\n        r2 = r.copy()\n        assert r.get_state() == r2.get_state()\n        assert hash(r)\n\n    def test_get_url(self):\n        r = treq()\n\n        assert r.url == \"http://address:22/path\"\n\n        r.scheme = \"https\"\n        assert r.url == \"https://address:22/path\"\n\n        r.host = \"host\"\n        r.port = 42\n        assert r.url == \"https://host:42/path\"\n\n        r.host = \"address\"\n        r.port = 22\n        assert r.url == \"https://address:22/path\"\n\n        assert r.pretty_url == \"https://address:22/path\"\n        r.headers[\"Host\"] = \"foo.com:22\"\n        assert r.url == \"https://address:22/path\"\n        assert r.pretty_url == \"https://foo.com:22/path\"\n\n    def test_constrain_encoding(self):\n        r = treq()\n        r.headers[\"accept-encoding\"] = \"gzip, oink\"\n        r.constrain_encoding()\n        assert \"oink\" not in r.headers[\"accept-encoding\"]\n\n        r.headers.set_all(\"accept-encoding\", [\"gzip\", \"oink\"])\n        r.constrain_encoding()\n        assert \"oink\" not in r.headers[\"accept-encoding\"]\n\n    def test_get_content_type(self):\n        resp = tresp()\n        resp.headers = Headers(content_type=\"text/plain\")\n        assert resp.headers[\"content-type\"] == \"text/plain\"\n\n\nclass TestRequestData:\n    def test_init(self):\n        with pytest.raises(UnicodeEncodeError):\n            treq(method=\"f\u00f6\u00f6b\u00e4r\")\n        with pytest.raises(UnicodeEncodeError):\n            treq(scheme=\"f\u00f6\u00f6b\u00e4r\")\n        assert treq(host=\"f\u00f6\u00f6b\u00e4r\").host == \"f\u00f6\u00f6b\u00e4r\"\n        with pytest.raises(UnicodeEncodeError):\n            treq(path=\"/f\u00f6\u00f6b\u00e4r\")\n        with pytest.raises(UnicodeEncodeError):\n            treq(http_version=\"f\u00f6\u00f6/b\u00e4.r\")\n        with pytest.raises(ValueError):\n            treq(headers=\"foobar\")\n        with pytest.raises(ValueError):\n            treq(content=\"foobar\")\n        with pytest.raises(ValueError):\n            treq(trailers=\"foobar\")\n\n        assert isinstance(treq(headers=()).headers, Headers)\n        assert isinstance(treq(trailers=()).trailers, Headers)\n\n\nclass TestRequestCore:\n    \"\"\"\n    Tests for addons and the attributes that are directly proxied from the data structure\n    \"\"\"\n\n    def test_repr(self):\n        request = treq()\n        assert repr(request) == \"Request(GET address:22/path)\"\n        request.host = None\n        assert repr(request) == \"Request(GET /path)\"\n\n    def test_init_conv(self):\n        assert Request(\n            b\"example.com\",\n            80,\n            \"GET\",\n            \"http\",\n            \"example.com\",\n            \"/\",\n            \"HTTP/1.1\",\n            (),\n            None,\n            (),\n            0,\n            0,\n        )  # type: ignore\n\n    def test_make(self):\n        r = Request.make(\"GET\", \"https://example.com/\")\n        assert r.method == \"GET\"\n        assert r.scheme == \"https\"\n        assert r.host == \"example.com\"\n        assert r.port == 443\n        assert r.path == \"/\"\n\n        r = Request.make(\"GET\", \"https://example.com/\", \"content\", {\"Foo\": \"bar\"})\n        assert r.content == b\"content\"\n        assert r.headers[\"content-length\"] == \"7\"\n        assert r.headers[\"Foo\"] == \"bar\"\n\n        Request.make(\"GET\", \"https://example.com/\", content=b\"content\")\n        with pytest.raises(TypeError):\n            Request.make(\"GET\", \"https://example.com/\", content=42)\n\n        r = Request.make(\"GET\", \"https://example.com/\", headers=[(b\"foo\", b\"bar\")])\n        assert r.headers[\"foo\"] == \"bar\"\n\n        r = Request.make(\"GET\", \"https://example.com/\", headers=({\"foo\": \"baz\"}))\n        assert r.headers[\"foo\"] == \"baz\"\n\n        r = Request.make(\"GET\", \"https://example.com/\", headers=Headers(foo=\"qux\"))\n        assert r.headers[\"foo\"] == \"qux\"\n\n        with pytest.raises(TypeError):\n            Request.make(\"GET\", \"https://example.com/\", headers=42)\n\n    def test_first_line_format(self):\n        assert treq(method=b\"CONNECT\").first_line_format == \"authority\"\n        assert treq(authority=b\"example.com\").first_line_format == \"absolute\"\n        assert treq(authority=b\"\").first_line_format == \"relative\"\n\n    def test_method(self):\n        _test_decoded_attr(treq(), \"method\")\n\n    def test_scheme(self):\n        _test_decoded_attr(treq(), \"scheme\")\n\n    def test_port(self):\n        _test_passthrough_attr(treq(), \"port\", 1234)\n        with pytest.raises(ValueError):\n            treq().port = \"foo\"\n\n    def test_path(self):\n        _test_decoded_attr(treq(), \"path\")\n\n    def test_authority(self):\n        request = treq()\n        assert request.authority == request.data.authority.decode(\"idna\")\n\n        # Test IDNA encoding\n        # Set str, get raw bytes\n        request.authority = \"\u00eddna.example\"\n        assert request.data.authority == b\"xn--dna-qma.example\"\n        # Set raw bytes, get decoded\n        request.data.authority = b\"xn--idn-gla.example\"\n        assert request.authority == \"idn\u00e1.example\"\n        # Set bytes, get raw bytes\n        request.authority = b\"xn--dn-qia9b.example\"\n        assert request.data.authority == b\"xn--dn-qia9b.example\"\n        # IDNA encoding is not bijective\n        request.authority = \"fu\u00dfball\"\n        assert request.authority == \"fussball\"\n\n        # Don't fail on garbage\n        request.data.authority = b\"foo\\xff\\x00bar\"\n        assert request.authority.startswith(\"foo\")\n        assert request.authority.endswith(\"bar\")\n        # foo.bar = foo.bar should not cause any side effects.\n        d = request.authority\n        request.authority = d\n        assert request.data.authority == b\"foo\\xff\\x00bar\"\n\n    def test_host_update_also_updates_header(self):\n        request = treq()\n        assert \"host\" not in request.headers\n        request.host = \"example.com\"\n        assert \"host\" not in request.headers\n\n        request.headers[\"Host\"] = \"foo\"\n        request.authority = \"foo\"\n        request.host = \"example.org\"\n        assert request.headers[\"Host\"] == request.authority == \"example.org:22\"\n\n    def test_get_host_header(self):\n        no_hdr = treq()\n        assert no_hdr.host_header is None\n\n        h1 = treq(\n            headers=((b\"host\", b\"header.example.com\"),),\n            authority=b\"authority.example.com\",\n        )\n        assert h1.host_header == \"header.example.com\"\n\n        h2 = h1.copy()\n        h2.http_version = \"HTTP/2.0\"\n        assert h2.host_header == \"authority.example.com\"\n\n        h2_host_only = h2.copy()\n        h2_host_only.authority = \"\"\n        assert h2_host_only.host_header == \"header.example.com\"\n\n    def test_modify_host_header(self):\n        h1 = treq()\n        assert \"host\" not in h1.headers\n\n        h1.host_header = \"example.com\"\n        assert h1.headers[\"Host\"] == \"example.com\"\n        assert not h1.authority\n\n        h1.host_header = None\n        assert \"host\" not in h1.headers\n        assert not h1.authority\n\n        h2 = treq(http_version=b\"HTTP/2.0\")\n        h2.host_header = \"example.org\"\n        assert \"host\" not in h2.headers\n        assert h2.authority == \"example.org\"\n\n        h2.headers[\"Host\"] = \"example.org\"\n        h2.host_header = \"foo.example.com\"\n        assert h2.headers[\"Host\"] == \"foo.example.com\"\n        assert h2.authority == \"foo.example.com\"\n\n        h2.host_header = None\n        assert \"host\" not in h2.headers\n        assert not h2.authority\n\n\nclass TestRequestUtils:\n    \"\"\"\n    Tests for additional convenience methods.\n    \"\"\"\n\n    def test_url(self):\n        request = treq()\n        assert request.url == \"http://address:22/path\"\n\n        request.url = \"https://otheraddress:42/foo\"\n        assert request.scheme == \"https\"\n        assert request.host == \"otheraddress\"\n        assert request.port == 42\n        assert request.path == \"/foo\"\n\n        with pytest.raises(ValueError):\n            request.url = \"not-a-url\"\n\n    def test_url_options(self):\n        request = treq(method=b\"OPTIONS\", path=b\"*\")\n        assert request.url == \"http://address:22\"\n\n    def test_url_authority(self):\n        request = treq(method=b\"CONNECT\")\n        assert request.url == \"address:22\"\n\n    def test_pretty_host(self):\n        request = treq()\n        # Without host header\n        assert request.pretty_host == \"address\"\n        assert request.host == \"address\"\n        # Same port as self.port (22)\n        request.headers[\"host\"] = \"other:22\"\n        assert request.pretty_host == \"other\"\n\n        # Invalid IDNA\n        request.headers[\"host\"] = \".disqus.com\"\n        assert request.pretty_host == \".disqus.com\"\n\n    def test_pretty_url(self):\n        request = treq()\n        # Without host header\n        assert request.url == \"http://address:22/path\"\n        assert request.pretty_url == \"http://address:22/path\"\n\n        request.headers[\"host\"] = \"other:22\"\n        assert request.pretty_url == \"http://other:22/path\"\n\n        request = treq(method=b\"CONNECT\", authority=b\"example:44\")\n        assert request.pretty_url == \"example:44\"\n\n    def test_pretty_url_options(self):\n        request = treq(method=b\"OPTIONS\", path=b\"*\")\n        assert request.pretty_url == \"http://address:22\"\n\n    def test_pretty_url_authority(self):\n        request = treq(method=b\"CONNECT\", authority=\"address:22\")\n        assert request.pretty_url == \"address:22\"\n\n    def test_get_query(self):\n        request = treq()\n        assert not request.query\n\n        request.url = \"http://localhost:80/foo?bar=42\"\n        assert dict(request.query) == {\"bar\": \"42\"}\n\n    def test_set_query(self):\n        request = treq()\n        assert not request.query\n        request.query[\"foo\"] = \"bar\"\n        assert request.query[\"foo\"] == \"bar\"\n        assert request.path == \"/path?foo=bar\"\n        request.query = [(\"foo\", \"bar\")]\n        assert request.query[\"foo\"] == \"bar\"\n        assert request.path == \"/path?foo=bar\"\n\n    def test_get_cookies_none(self):\n        request = treq()\n        request.headers = Headers()\n        assert not request.cookies\n\n    def test_get_cookies_single(self):\n        request = treq()\n        request.headers = Headers(cookie=\"cookiename=cookievalue\")\n        assert len(request.cookies) == 1\n        assert request.cookies[\"cookiename\"] == \"cookievalue\"\n\n    def test_get_cookies_double(self):\n        request = treq()\n        request.headers = Headers(\n            cookie=\"cookiename=cookievalue;othercookiename=othercookievalue\"\n        )\n        result = request.cookies\n        assert len(result) == 2\n        assert result[\"cookiename\"] == \"cookievalue\"\n        assert result[\"othercookiename\"] == \"othercookievalue\"\n\n    def test_get_cookies_withequalsign(self):\n        request = treq()\n        request.headers = Headers(\n            cookie=\"cookiename=coo=kievalue;othercookiename=othercookievalue\"\n        )\n        result = request.cookies\n        assert len(result) == 2\n        assert result[\"cookiename\"] == \"coo=kievalue\"\n        assert result[\"othercookiename\"] == \"othercookievalue\"\n\n    def test_set_cookies(self):\n        request = treq()\n        request.headers = Headers(cookie=\"cookiename=cookievalue\")\n        result = request.cookies\n        result[\"cookiename\"] = \"foo\"\n        assert request.cookies[\"cookiename\"] == \"foo\"\n        request.cookies = [[\"one\", \"uno\"], [\"two\", \"due\"]]\n        assert request.cookies[\"one\"] == \"uno\"\n        assert request.cookies[\"two\"] == \"due\"\n\n    def test_get_path_components(self):\n        request = treq(path=b\"/foo/bar\")\n        assert request.path_components == (\"foo\", \"bar\")\n\n    def test_set_path_components(self):\n        request = treq()\n        request.path_components = [\"foo\", \"baz\"]\n        assert request.path == \"/foo/baz\"\n\n        request.path_components = []\n        assert request.path == \"/\"\n\n        request.path_components = [\"foo\", \"baz\"]\n        request.query[\"hello\"] = \"hello\"\n        assert request.path_components == (\"foo\", \"baz\")\n\n        request.path_components = [\"abc\"]\n        assert request.path == \"/abc?hello=hello\"\n\n    def test_anticache(self):\n        request = treq()\n        request.headers[\"If-Modified-Since\"] = \"foo\"\n        request.headers[\"If-None-Match\"] = \"bar\"\n        request.anticache()\n        assert \"If-Modified-Since\" not in request.headers\n        assert \"If-None-Match\" not in request.headers\n\n    def test_anticomp(self):\n        request = treq()\n        request.headers[\"Accept-Encoding\"] = \"foobar\"\n        request.anticomp()\n        assert request.headers[\"Accept-Encoding\"] == \"identity\"\n\n    def test_constrain_encoding(self):\n        request = treq()\n\n        h = request.headers.copy()\n        request.constrain_encoding()  # no-op if there is no accept_encoding header.\n        assert request.headers == h\n\n        request.headers[\"Accept-Encoding\"] = \"identity, gzip, foo\"\n        request.constrain_encoding()\n        assert \"foo\" not in request.headers[\"Accept-Encoding\"]\n        assert \"gzip\" in request.headers[\"Accept-Encoding\"]\n\n    def test_get_urlencoded_form(self):\n        request = treq(content=b\"foobar=baz\")\n        assert not request.urlencoded_form\n\n        request.headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n        assert list(request.urlencoded_form.items()) == [(\"foobar\", \"baz\")]\n        request.raw_content = b\"\\xff\"\n        assert len(request.urlencoded_form) == 1\n\n    def test_set_urlencoded_form(self):\n        request = treq(content=b\"\\xec\\xed\")\n        request.urlencoded_form = [(\"foo\", \"bar\"), (\"rab\", \"oof\")]\n        assert request.headers[\"Content-Type\"] == \"application/x-www-form-urlencoded\"\n        assert request.content\n\n    def test_get_multipart_form(self):\n        request = treq(content=b\"foobar\")\n        assert not request.multipart_form\n\n        request.headers[\"Content-Type\"] = \"multipart/form-data\"\n        assert list(request.multipart_form.items()) == []\n\n        with mock.patch(\"mitmproxy.net.http.multipart.decode_multipart\") as m:\n            m.side_effect = ValueError\n            assert list(request.multipart_form.items()) == []\n\n    def test_set_multipart_form(self):\n        request = treq()\n        request.multipart_form = [(b\"file\", b\"shell.jpg\"), (b\"file_size\", b\"1000\")]\n        assert request.headers[\"Content-Type\"].startswith(\"multipart/form-data\")\n        assert list(request.multipart_form.items()) == [\n            (b\"file\", b\"shell.jpg\"),\n            (b\"file_size\", b\"1000\"),\n        ]\n\n\nclass TestResponse:\n    def test_simple(self):\n        f = tflow(resp=True)\n        resp = f.response\n        resp2 = resp.copy()\n        assert resp2.get_state() == resp.get_state()\n\n    def test_get_content_type(self):\n        resp = tresp()\n        resp.headers = Headers(content_type=\"text/plain\")\n        assert resp.headers[\"content-type\"] == \"text/plain\"\n\n\nclass TestResponseData:\n    def test_init(self):\n        with pytest.raises(ValueError):\n            tresp(headers=\"foobar\")\n        with pytest.raises(UnicodeEncodeError):\n            tresp(http_version=\"f\u00f6\u00f6/b\u00e4.r\")\n        with pytest.raises(UnicodeEncodeError):\n            tresp(reason=\"f\u00f6\u00f6b\u00e4r\")\n        with pytest.raises(ValueError):\n            tresp(content=\"foobar\")\n        with pytest.raises(ValueError):\n            tresp(trailers=\"foobar\")\n\n        assert isinstance(tresp(headers=()).headers, Headers)\n        assert isinstance(tresp(trailers=()).trailers, Headers)\n\n\nclass TestResponseCore:\n    \"\"\"\n    Tests for addons and the attributes that are directly proxied from the data structure\n    \"\"\"\n\n    def test_repr(self):\n        response = tresp()\n        assert repr(response) == \"Response(200, unknown content type, 7b)\"\n        response.content = None\n        assert repr(response) == \"Response(200, no content)\"\n\n    def test_make(self):\n        r = Response.make()\n        assert r.status_code == 200\n        assert r.content == b\"\"\n\n        r = Response.make(418, \"teatime\")\n        assert r.status_code == 418\n        assert r.content == b\"teatime\"\n        assert r.headers[\"content-length\"] == \"7\"\n\n        Response.make(content=b\"foo\")\n        Response.make(content=\"foo\")\n        with pytest.raises(TypeError):\n            Response.make(content=42)\n\n        r = Response.make(headers=[(b\"foo\", b\"bar\")])\n        assert r.headers[\"foo\"] == \"bar\"\n\n        r = Response.make(headers=({\"foo\": \"baz\"}))\n        assert r.headers[\"foo\"] == \"baz\"\n\n        r = Response.make(headers=Headers(foo=\"qux\"))\n        assert r.headers[\"foo\"] == \"qux\"\n\n        with pytest.raises(TypeError):\n            Response.make(headers=42)\n\n    def test_status_code(self):\n        _test_passthrough_attr(tresp(), \"status_code\")\n\n    def test_reason(self):\n        resp = tresp()\n        assert resp.reason == \"OK\"\n\n        resp.reason = \"ABC\"\n        assert resp.data.reason == b\"ABC\"\n\n        resp.reason = b\"DEF\"\n        assert resp.data.reason == b\"DEF\"\n\n        resp.data.reason = b\"cr\\xe9e\"\n        assert resp.reason == \"cr\u00e9e\"\n\n\nclass TestResponseUtils:\n    \"\"\"\n    Tests for additional convenience methods.\n    \"\"\"\n\n    def test_get_cookies_none(self):\n        resp = tresp()\n        resp.headers = Headers()\n        assert not resp.cookies\n\n    def test_get_cookies_empty(self):\n        resp = tresp()\n        resp.headers = Headers(set_cookie=\"\")\n        assert not resp.cookies\n\n    def test_get_cookies_simple(self):\n        resp = tresp()\n        resp.headers = Headers(set_cookie=\"cookiename=cookievalue\")\n        result = resp.cookies\n        assert len(result) == 1\n        assert \"cookiename\" in result\n        assert result[\"cookiename\"] == (\"cookievalue\", CookieAttrs())\n\n    def test_get_cookies_with_parameters(self):\n        resp = tresp()\n        cookie = \"cookiename=cookievalue;domain=example.com;expires=Wed Oct  21 16:29:41 2015;path=/; HttpOnly\"\n        resp.headers = Headers(set_cookie=cookie)\n        result = resp.cookies\n        assert len(result) == 1\n        assert \"cookiename\" in result\n        assert result[\"cookiename\"][0] == \"cookievalue\"\n        attrs = result[\"cookiename\"][1]\n        assert len(attrs) == 4\n        assert attrs[\"domain\"] == \"example.com\"\n        assert attrs[\"expires\"] == \"Wed Oct  21 16:29:41 2015\"\n        assert attrs[\"path\"] == \"/\"\n        assert attrs[\"httponly\"] is None\n\n    def test_get_cookies_no_value(self):\n        resp = tresp()\n        resp.headers = Headers(\n            set_cookie=\"cookiename=; Expires=Thu, 01-Jan-1970 00:00:01 GMT; path=/\"\n        )\n        result = resp.cookies\n        assert len(result) == 1\n        assert \"cookiename\" in result\n        assert result[\"cookiename\"][0] == \"\"\n        assert len(result[\"cookiename\"][1]) == 2\n\n    def test_get_cookies_twocookies(self):\n        resp = tresp()\n        resp.headers = Headers(\n            [\n                [b\"Set-Cookie\", b\"cookiename=cookievalue\"],\n                [b\"Set-Cookie\", b\"othercookie=othervalue\"],\n            ]\n        )\n        result = resp.cookies\n        assert len(result) == 2\n        assert \"cookiename\" in result\n        assert result[\"cookiename\"] == (\"cookievalue\", CookieAttrs())\n        assert \"othercookie\" in result\n        assert result[\"othercookie\"] == (\"othervalue\", CookieAttrs())\n\n    def test_set_cookies(self):\n        resp = tresp()\n        resp.cookies[\"foo\"] = (\"bar\", {})\n        assert len(resp.cookies) == 1\n        assert resp.cookies[\"foo\"] == (\"bar\", CookieAttrs())\n        resp.cookies = [\n            [\"one\", (\"uno\", CookieAttrs())],\n            [\"two\", (\"due\", CookieAttrs())],\n        ]\n        assert list(resp.cookies.keys()) == [\"one\", \"two\"]\n\n    def test_refresh(self):\n        r = tresp()\n        n = time.time()\n        r.headers[\"date\"] = email.utils.formatdate(n, usegmt=True)\n        pre = r.headers[\"date\"]\n        r.refresh(946681202)\n        assert pre == r.headers[\"date\"]\n\n        r.refresh(946681262)\n        d = email.utils.parsedate_tz(r.headers[\"date\"])\n        d = email.utils.mktime_tz(d)\n        # Weird that this is not exact...\n        assert abs(60 - (d - n)) <= 1\n\n        cookie = \"MOO=BAR; Expires=Tue, 08-Mar-2011 00:20:38 GMT; Path=foo.com; Secure\"\n        r.headers[\"set-cookie\"] = cookie\n        r.refresh()\n        # Cookie refreshing is tested in test_cookies, we just make sure that it's triggered here.\n        assert cookie != r.headers[\"set-cookie\"]\n\n        with mock.patch(\"mitmproxy.net.http.cookies.refresh_set_cookie_header\") as m:\n            m.side_effect = ValueError\n            r.refresh(n)\n\n        # Test negative unixtime, which raises on at least Windows.\n        r.headers[\"date\"] = pre = \"Mon, 01 Jan 1601 00:00:00 GMT\"\n        r.refresh(946681202)\n        assert r.headers[\"date\"] == pre\n\n\nclass TestHTTPFlow:\n    def test_copy(self):\n        f = tflow(resp=True)\n        assert repr(f)\n        f.get_state()\n        f2 = f.copy()\n        a = f.get_state()\n        b = f2.get_state()\n        del a[\"id\"]\n        del b[\"id\"]\n        assert a == b\n        assert not f == f2\n        assert f is not f2\n        assert f.request.get_state() == f2.request.get_state()\n        assert f.request is not f2.request\n        assert f.request.headers == f2.request.headers\n        assert f.request.headers is not f2.request.headers\n        assert f.response.get_state() == f2.response.get_state()\n        assert f.response is not f2.response\n\n        f = tflow(err=True)\n        f2 = f.copy()\n        assert f is not f2\n        assert f.request is not f2.request\n        assert f.request.headers == f2.request.headers\n        assert f.request.headers is not f2.request.headers\n        assert f.error.get_state() == f2.error.get_state()\n        assert f.error is not f2.error\n\n    def test_match(self):\n        f = tflow(resp=True)\n        assert not flowfilter.match(\"~b test\", f)\n        assert flowfilter.match(None, f)\n        assert not flowfilter.match(\"~b test\", f)\n\n        f = tflow(err=True)\n        assert flowfilter.match(\"~e\", f)\n\n        with pytest.raises(ValueError):\n            flowfilter.match(\"~\", f)\n\n    def test_backup(self):\n        f = tflow()\n        f.response = tresp()\n        f.request.content = b\"foo\"\n        assert not f.modified()\n        f.backup()\n        f.request.content = b\"bar\"\n        assert f.modified()\n        f.revert()\n        assert f.request.content == b\"foo\"\n\n    def test_backup_idempotence(self):\n        f = tflow(resp=True)\n        f.backup()\n        f.revert()\n        f.backup()\n        f.revert()\n\n    def test_getset_state(self):\n        f = tflow(resp=True)\n        state = f.get_state()\n        assert f.get_state() == HTTPFlow.from_state(state).get_state()\n\n        f.response = None\n        f.error = flow.Error(\"error\")\n        state = f.get_state()\n        assert f.get_state() == HTTPFlow.from_state(state).get_state()\n\n        f2 = f.copy()\n        f2.id = f.id  # copy creates a different uuid\n        assert f.get_state() == f2.get_state()\n        assert not f == f2\n        f2.error = flow.Error(\"e2\")\n        assert not f == f2\n        f2.backup()\n        f2.intercept()  # to change the state\n        f.set_state(f2.get_state())\n        assert f.get_state() == f2.get_state()\n\n    def test_kill(self):\n        f = tflow()\n        f.intercept()\n        f.resume()\n        assert f.killable\n        f.kill()\n        assert not f.killable\n\n        f = tflow()\n        f.intercept()\n        assert f.killable\n        f.kill()\n        assert not f.killable\n        assert f.error.msg == flow.Error.KILLED_MESSAGE\n\n    def test_intercept(self):\n        f = tflow()\n        f.intercept()\n        assert f.intercepted\n        f.intercept()\n        assert f.intercepted\n\n    def test_resume(self):\n        f = tflow()\n        f.resume()\n        assert not f.intercepted\n        f.intercept()\n        assert f.intercepted\n        f.resume()\n        assert not f.intercepted\n\n    async def test_wait_for_resume(self):\n        f = tflow()\n        await f.wait_for_resume()\n\n        f = tflow()\n        f.intercept()\n        f.resume()\n        await f.wait_for_resume()\n\n        f = tflow()\n        f.intercept()\n        with pytest.raises(asyncio.TimeoutError):\n            await asyncio.wait_for(f.wait_for_resume(), 0.2)\n        f.resume()\n        await f.wait_for_resume()\n\n        f = tflow()\n        f.intercept()\n        with pytest.raises(asyncio.TimeoutError):\n            await asyncio.wait_for(f.wait_for_resume(), 0.2)\n        f.resume()\n        f.intercept()\n        with pytest.raises(asyncio.TimeoutError):\n            await asyncio.wait_for(f.wait_for_resume(), 0.2)\n        f.resume()\n        await f.wait_for_resume()\n\n    def test_resume_duplicated(self):\n        f = tflow()\n        f.intercept()\n        f2 = f.copy()\n        assert f.intercepted is f2.intercepted is True\n        f.resume()\n        f2.resume()\n        assert f.intercepted is f2.intercepted is False\n\n    def test_timestamp_start(self):\n        f = tflow()\n        assert f.timestamp_start == f.request.timestamp_start\n\n\nclass TestHeaders:\n    def _2host(self):\n        return Headers(((b\"Host\", b\"example.com\"), (b\"host\", b\"example.org\")))\n\n    def test_init(self):\n        headers = Headers()\n        assert len(headers) == 0\n\n        headers = Headers([(b\"Host\", b\"example.com\")])\n        assert len(headers) == 1\n        assert headers[\"Host\"] == \"example.com\"\n\n        headers = Headers(Host=\"example.com\")\n        assert len(headers) == 1\n        assert headers[\"Host\"] == \"example.com\"\n\n        headers = Headers([(b\"Host\", b\"invalid\")], Host=\"example.com\")\n        assert len(headers) == 1\n        assert headers[\"Host\"] == \"example.com\"\n\n        headers = Headers(\n            [(b\"Host\", b\"invalid\"), (b\"Accept\", b\"text/plain\")], Host=\"example.com\"\n        )\n        assert len(headers) == 2\n        assert headers[\"Host\"] == \"example.com\"\n        assert headers[\"Accept\"] == \"text/plain\"\n\n        with pytest.raises(TypeError):\n            Headers([(b\"Host\", \"not-bytes\")])\n\n    def test_set(self):\n        headers = Headers()\n        headers[\"foo\"] = \"1\"\n        headers[b\"bar\"] = b\"2\"\n        headers[\"baz\"] = b\"3\"\n        with pytest.raises(TypeError):\n            headers[\"foobar\"] = 42\n        assert len(headers) == 3\n\n    def test_bytes(self):\n        headers = Headers(Host=\"example.com\")\n        assert bytes(headers) == b\"Host: example.com\\r\\n\"\n\n        headers = Headers([(b\"Host\", b\"example.com\"), (b\"Accept\", b\"text/plain\")])\n        assert bytes(headers) == b\"Host: example.com\\r\\nAccept: text/plain\\r\\n\"\n\n        headers = Headers()\n        assert bytes(headers) == b\"\"\n\n    def test_iter(self):\n        headers = Headers([(b\"Set-Cookie\", b\"foo\"), (b\"Set-Cookie\", b\"bar\")])\n        assert list(headers) == [\"Set-Cookie\"]\n\n    def test_insert(self):\n        headers = Headers(Accept=\"text/plain\")\n        headers.insert(0, b\"Host\", \"example.com\")\n        assert headers.fields == ((b\"Host\", b\"example.com\"), (b\"Accept\", b\"text/plain\"))\n\n    def test_items(self):\n        headers = Headers(\n            [\n                (b\"Set-Cookie\", b\"foo\"),\n                (b\"Set-Cookie\", b\"bar\"),\n                (b\"Accept\", b\"text/plain\"),\n            ]\n        )\n        assert list(headers.items()) == [\n            (\"Set-Cookie\", \"foo, bar\"),\n            (\"Accept\", \"text/plain\"),\n        ]\n        assert list(headers.items(multi=True)) == [\n            (\"Set-Cookie\", \"foo\"),\n            (\"Set-Cookie\", \"bar\"),\n            (\"Accept\", \"text/plain\"),\n        ]\n\n\ndef _test_passthrough_attr(message: Message, attr: str, value: Any = b\"foo\") -> None:\n    assert getattr(message, attr) == getattr(message.data, attr)\n    setattr(message, attr, value)\n    assert getattr(message.data, attr) == value\n\n\ndef _test_decoded_attr(message, attr):\n    assert getattr(message, attr) == getattr(message.data, attr).decode(\"utf8\")\n    # Set str, get raw bytes\n    setattr(message, attr, \"foo\")\n    assert getattr(message.data, attr) == b\"foo\"\n    # Set raw bytes, get decoded\n    setattr(\n        message.data, attr, b\"BAR\"\n    )  # use uppercase so that we can also cover request.method\n    assert getattr(message, attr) == \"BAR\"\n    # Set bytes, get raw bytes\n    setattr(message, attr, b\"baz\")\n    assert getattr(message.data, attr) == b\"baz\"\n\n    # Set UTF8\n    setattr(message, attr, \"Non-Autoris\u00e9\")\n    assert getattr(message.data, attr) == b\"Non-Autoris\\xc3\\xa9\"\n    # Don't fail on garbage\n    setattr(message.data, attr, b\"FOO\\xbf\\x00BAR\")\n    assert getattr(message, attr).startswith(\"FOO\")\n    assert getattr(message, attr).endswith(\"BAR\")\n    # foo.bar = foo.bar should not cause any side effects.\n    d = getattr(message, attr)\n    setattr(message, attr, d)\n    assert getattr(message.data, attr) == b\"FOO\\xbf\\x00BAR\"\n\n\nclass TestMessageData:\n    def test_eq(self):\n        data = tresp(timestamp_start=42, timestamp_end=42).data\n        same = tresp(timestamp_start=42, timestamp_end=42).data\n        assert data == same\n\n        other = tresp(content=b\"foo\").data\n        assert data != other\n\n        assert data != 0\n\n    def test_serializable(self):\n        data1 = tresp(timestamp_start=42, timestamp_end=42).data\n        data1.trailers = Headers()\n        data2 = tresp().data.from_state(data1.get_state())  # ResponseData.from_state()\n\n        assert data1 == data2\n\n\nclass TestMessage:\n    def test_init(self):\n        resp = tresp()\n        assert resp.data\n\n    def test_eq_ne(self):\n        resp = tresp(timestamp_start=42, timestamp_end=42)\n        same = tresp(timestamp_start=42, timestamp_end=42)\n        assert resp.data == same.data\n\n        other = tresp(timestamp_start=0, timestamp_end=0)\n        assert resp.data != other.data\n\n        assert resp != 0\n\n    def test_serializable(self):\n        resp = tresp()\n        resp.trailers = Headers()\n        resp2 = Response.from_state(resp.get_state())\n        resp3 = tresp()\n        resp3.set_state(resp.get_state())\n        assert resp.data == resp2.data == resp3.data\n\n    def test_content_length_update(self):\n        resp = tresp()\n        resp.content = b\"foo\"\n        assert resp.data.content == b\"foo\"\n        assert resp.headers[\"content-length\"] == \"3\"\n        resp.content = b\"\"\n        assert resp.data.content == b\"\"\n        assert resp.headers[\"content-length\"] == \"0\"\n        resp.raw_content = b\"bar\"\n        assert resp.data.content == b\"bar\"\n        assert resp.headers[\"content-length\"] == \"0\"\n\n    def test_content_length_not_added_for_response_with_transfer_encoding(self):\n        headers = Headers(((b\"transfer-encoding\", b\"chunked\"),))\n        resp = tresp(headers=headers)\n        resp.content = b\"bar\"\n\n        assert \"content-length\" not in resp.headers\n\n    def test_headers(self):\n        _test_passthrough_attr(tresp(), \"headers\")\n\n    def test_trailers(self):\n        _test_passthrough_attr(tresp(), \"trailers\")\n\n    def test_timestamp_start(self):\n        _test_passthrough_attr(tresp(), \"timestamp_start\")\n\n    def test_timestamp_end(self):\n        _test_passthrough_attr(tresp(), \"timestamp_end\")\n\n    def test_http_version(self):\n        _test_decoded_attr(tresp(), \"http_version\")\n        assert tresp(http_version=b\"HTTP/1.0\").is_http10\n        assert tresp(http_version=b\"HTTP/1.1\").is_http11\n        assert tresp(http_version=b\"HTTP/2.0\").is_http2\n\n\nclass TestMessageContentEncoding:\n    def test_simple(self):\n        r = tresp()\n        assert r.raw_content == b\"message\"\n        assert \"content-encoding\" not in r.headers\n        r.encode(\"gzip\")\n\n        assert r.headers[\"content-encoding\"]\n        assert r.raw_content != b\"message\"\n        assert r.content == b\"message\"\n        assert r.raw_content != b\"message\"\n\n    def test_update_content_length_header(self):\n        r = tresp()\n        assert int(r.headers[\"content-length\"]) == 7\n        r.encode(\"gzip\")\n        assert int(r.headers[\"content-length\"]) == 27\n        r.decode()\n        assert int(r.headers[\"content-length\"]) == 7\n\n    def test_modify(self):\n        r = tresp()\n        assert \"content-encoding\" not in r.headers\n        r.encode(\"gzip\")\n\n        r.content = b\"foo\"\n        assert r.raw_content != b\"foo\"\n        r.decode()\n        assert r.raw_content == b\"foo\"\n\n        with pytest.raises(TypeError):\n            r.content = \"foo\"\n\n    def test_unknown_ce(self):\n        r = tresp()\n        r.headers[\"content-encoding\"] = \"zopfli\"\n        r.raw_content = b\"foo\"\n        with pytest.raises(ValueError):\n            assert r.content\n        assert r.headers[\"content-encoding\"]\n        assert r.get_content(strict=False) == b\"foo\"\n\n    def test_utf8_as_ce(self):\n        r = tresp()\n        r.headers[\"content-encoding\"] = \"utf8\"\n        r.raw_content = b\"foo\"\n        with pytest.raises(ValueError):\n            assert r.content\n        assert r.headers[\"content-encoding\"]\n        assert r.get_content(strict=False) == b\"foo\"\n\n    def test_cannot_decode(self):\n        r = tresp()\n        r.encode(\"gzip\")\n        r.raw_content = b\"foo\"\n        with pytest.raises(ValueError):\n            assert r.content\n        assert r.headers[\"content-encoding\"]\n        assert r.get_content(strict=False) == b\"foo\"\n\n        with pytest.raises(ValueError):\n            r.decode()\n        assert r.raw_content == b\"foo\"\n        assert \"content-encoding\" in r.headers\n\n        r.decode(strict=False)\n        assert r.content == b\"foo\"\n        assert \"content-encoding\" not in r.headers\n\n    def test_none(self):\n        r = tresp(content=None)\n        assert r.content is None\n        r.content = b\"foo\"\n        assert r.content is not None\n        r.content = None\n        assert r.content is None\n\n    def test_cannot_encode(self):\n        r = tresp()\n        r.encode(\"gzip\")\n        r.content = None\n        assert r.headers[\"content-encoding\"]\n        assert r.raw_content is None\n\n        r.headers[\"content-encoding\"] = \"zopfli\"\n        r.content = b\"foo\"\n        assert \"content-encoding\" not in r.headers\n        assert r.raw_content == b\"foo\"\n\n        with pytest.raises(ValueError):\n            r.encode(\"zopfli\")\n        assert r.raw_content == b\"foo\"\n        assert \"content-encoding\" not in r.headers\n\n\nclass TestMessageText:\n    def test_simple(self):\n        r = tresp(content=b\"\\xfc\")\n        assert r.raw_content == b\"\\xfc\"\n        assert r.content == b\"\\xfc\"\n        assert r.text == \"\u00fc\"\n\n        r.encode(\"gzip\")\n        assert r.text == \"\u00fc\"\n        r.decode()\n        assert r.text == \"\u00fc\"\n\n        r.headers[\"content-type\"] = \"text/html; charset=latin1\"\n        r.content = b\"\\xc3\\xbc\"\n        assert r.text == \"\u00c3\u00bc\"\n        r.headers[\"content-type\"] = \"text/html; charset=utf8\"\n        assert r.text == \"\u00fc\"\n\n    def test_guess_json(self):\n        r = tresp(content=b'\"\\xc3\\xbc\"')\n        r.headers[\"content-type\"] = \"application/json\"\n        assert r.text == '\"\u00fc\"'\n\n    def test_guess_meta_charset(self):\n        r = tresp(\n            content=b'<meta http-equiv=\"content-type\" '\n            b'content=\"text/html;charset=gb2312\">\\xe6\\x98\\x8e\\xe4\\xbc\\xaf'\n        )\n        r.headers[\"content-type\"] = \"text/html\"\n        # \"\u93c4\u5e9d\u96c6\" is decoded form of \\xe6\\x98\\x8e\\xe4\\xbc\\xaf in gb18030\n        assert \"\u93c4\u5e9d\u96c6\" in r.text\n\n    def test_guess_css_charset(self):\n        # @charset but not text/css\n        r = tresp(\n            content=b'@charset \"gb2312\";'\n            b'#foo::before {content: \"\\xe6\\x98\\x8e\\xe4\\xbc\\xaf\"}'\n        )\n        # \"\u93c4\u5e9d\u96c6\" is decoded form of \\xe6\\x98\\x8e\\xe4\\xbc\\xaf in gb18030\n        assert \"\u93c4\u5e9d\u96c6\" not in r.text\n\n        # @charset not at the beginning\n        r = tresp(\n            content=b'foo@charset \"gb2312\";'\n            b'#foo::before {content: \"\\xe6\\x98\\x8e\\xe4\\xbc\\xaf\"}'\n        )\n        r.headers[\"content-type\"] = \"text/css\"\n        # \"\u93c4\u5e9d\u96c6\" is decoded form of \\xe6\\x98\\x8e\\xe4\\xbc\\xaf in gb18030\n        assert \"\u93c4\u5e9d\u96c6\" not in r.text\n\n        # @charset and text/css\n        r = tresp(\n            content=b'@charset \"gb2312\";'\n            b'#foo::before {content: \"\\xe6\\x98\\x8e\\xe4\\xbc\\xaf\"}'\n        )\n        r.headers[\"content-type\"] = \"text/css\"\n        # \"\u93c4\u5e9d\u96c6\" is decoded form of \\xe6\\x98\\x8e\\xe4\\xbc\\xaf in gb18030\n        assert \"\u93c4\u5e9d\u96c6\" in r.text\n\n    def test_guess_latin_1(self):\n        r = tresp(content=b\"\\xf0\\xe2\")\n        assert r.text == \"\u00f0\u00e2\"\n\n    def test_none(self):\n        r = tresp(content=None)\n        assert r.text is None\n        r.text = \"foo\"\n        assert r.text is not None\n        r.text = None\n        assert r.text is None\n\n    def test_modify(self):\n        r = tresp()\n\n        r.text = \"\u00fc\"\n        assert r.raw_content == b\"\\xfc\"\n\n        r.headers[\"content-type\"] = \"text/html; charset=utf8\"\n        r.text = \"\u00fc\"\n        assert r.raw_content == b\"\\xc3\\xbc\"\n        assert r.headers[\"content-length\"] == \"2\"\n\n    def test_unknown_ce(self):\n        r = tresp()\n        r.headers[\"content-type\"] = \"text/html; charset=wtf\"\n        r.raw_content = b\"foo\"\n        with pytest.raises(ValueError):\n            assert r.text == \"foo\"\n        assert r.get_text(strict=False) == \"foo\"\n\n    def test_cannot_decode(self):\n        r = tresp()\n        r.headers[\"content-type\"] = \"text/html; charset=utf8\"\n        r.raw_content = b\"\\xff\"\n        with pytest.raises(ValueError):\n            assert r.text\n\n        assert r.get_text(strict=False) == \"\\udcff\"\n\n    def test_cannot_encode(self):\n        r = tresp()\n        r.content = None\n        assert \"content-type\" not in r.headers\n        assert r.raw_content is None\n\n        r.headers[\"content-type\"] = \"text/html; charset=latin1; foo=bar\"\n        r.text = \"\u2603\"\n        assert r.headers[\"content-type\"] == \"text/html; charset=utf-8; foo=bar\"\n        assert r.raw_content == b\"\\xe2\\x98\\x83\"\n\n        r.headers[\"content-type\"] = \"gibberish\"\n        r.text = \"\u2603\"\n        assert r.headers[\"content-type\"] == \"text/plain; charset=utf-8\"\n        assert r.raw_content == b\"\\xe2\\x98\\x83\"\n\n        del r.headers[\"content-type\"]\n        r.text = \"\u2603\"\n        assert r.headers[\"content-type\"] == \"text/plain; charset=utf-8\"\n        assert r.raw_content == b\"\\xe2\\x98\\x83\"\n\n        r.headers[\"content-type\"] = \"text/html; charset=latin1\"\n        r.text = \"\\udcff\"\n        assert r.headers[\"content-type\"] == \"text/html; charset=utf-8\"\n        assert r.raw_content == b\"\\xff\"\n\n    def test_get_json(self):\n        req = treq(content=None)\n        with pytest.raises(TypeError):\n            req.json()\n\n        req = treq(content=b\"\")\n        with pytest.raises(json.decoder.JSONDecodeError):\n            req.json()\n\n        req = treq(content=b\"{}\")\n        assert req.json() == {}\n\n        req = treq(content=b'{\"a\": 1}')\n        assert req.json() == {\"a\": 1}\n\n        req = treq(content=b\"{\")\n\n        with pytest.raises(json.decoder.JSONDecodeError):\n            req.json()\n", "test/mitmproxy/test_connection.py": "import pytest\n\nfrom mitmproxy.connection import Client\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.connection import Server\nfrom mitmproxy.test.tflow import tclient_conn\nfrom mitmproxy.test.tflow import tserver_conn\n\n\nclass TestConnection:\n    def test_basic(self):\n        c = Client(\n            peername=(\"127.0.0.1\", 52314),\n            sockname=(\"127.0.0.1\", 8080),\n            timestamp_start=1607780791,\n            state=ConnectionState.OPEN,\n        )\n        assert not c.tls_established\n        c.timestamp_tls_setup = 1607780792\n        assert c.tls_established\n        assert c.connected\n        c.state = ConnectionState.CAN_WRITE\n        assert not c.connected\n\n    def test_eq(self):\n        c = tclient_conn()\n        c2 = c.copy()\n        assert c == c\n        assert c != c2\n        assert c != 42\n        assert hash(c) != hash(c2)\n\n        c2.id = c.id\n        assert c == c2\n\n\nclass TestClient:\n    def test_basic(self):\n        c = Client(\n            peername=(\"127.0.0.1\", 52314),\n            sockname=(\"127.0.0.1\", 8080),\n            timestamp_start=1607780791,\n            cipher_list=[\"foo\", \"bar\"],\n        )\n        assert repr(c)\n        assert str(c)\n        c.timestamp_tls_setup = 1607780791\n        assert str(c)\n        c.alpn = b\"foo\"\n        assert str(c) == \"Client(127.0.0.1:52314, state=closed, alpn=foo)\"\n\n    def test_state(self):\n        c = tclient_conn()\n        assert Client.from_state(c.get_state()).get_state() == c.get_state()\n\n        c2 = tclient_conn()\n        assert c != c2\n\n        c2.timestamp_start = 42\n        c.set_state(c2.get_state())\n        assert c.timestamp_start == 42\n\n        c3 = c.copy()\n        assert c3.get_state() != c.get_state()\n        c.id = c3.id = \"foo\"\n        assert c3.get_state() == c.get_state()\n\n\nclass TestServer:\n    def test_basic(self):\n        s = Server(address=(\"address\", 22))\n        assert repr(s)\n        assert str(s)\n        s.timestamp_tls_setup = 1607780791\n        assert str(s)\n        s.alpn = b\"foo\"\n        s.sockname = (\"127.0.0.1\", 54321)\n        assert str(s) == \"Server(address:22, state=closed, alpn=foo, src_port=54321)\"\n\n    def test_state(self):\n        c = tserver_conn()\n        c2 = c.copy()\n        assert c2.get_state() != c.get_state()\n        c.id = c2.id = \"foo\"\n        assert c2.get_state() == c.get_state()\n\n    def test_address(self):\n        s = Server(address=(\"address\", 22))\n        s.address = (\"example.com\", 443)\n        s.state = ConnectionState.OPEN\n        with pytest.raises(RuntimeError):\n            s.address = (\"example.com\", 80)\n        # No-op assignment, allowed because it might be triggered by a Server.set_state() call.\n        s.address = (\"example.com\", 443)\n", "test/mitmproxy/test_udp.py": "import pytest\n\nfrom mitmproxy import flowfilter\nfrom mitmproxy import udp\nfrom mitmproxy.test import tflow\n\n\nclass TestUDPFlow:\n    def test_copy(self):\n        f = tflow.tudpflow()\n        f.get_state()\n        f2 = f.copy()\n        a = f.get_state()\n        b = f2.get_state()\n        del a[\"id\"]\n        del b[\"id\"]\n        assert a == b\n        assert not f == f2\n        assert f is not f2\n\n        assert f.messages is not f2.messages\n\n        for m in f.messages:\n            assert m.get_state()\n            m2 = m.copy()\n            assert not m == m2\n            assert m is not m2\n\n            a = m.get_state()\n            b = m2.get_state()\n            assert a == b\n\n        m = udp.UDPMessage(False, \"foo\")\n        m.set_state(f.messages[0].get_state())\n        assert m.timestamp == f.messages[0].timestamp\n\n        f = tflow.tudpflow(err=True)\n        f2 = f.copy()\n        assert f is not f2\n        assert f.error.get_state() == f2.error.get_state()\n        assert f.error is not f2.error\n\n    def test_match(self):\n        f = tflow.tudpflow()\n        assert not flowfilter.match(\"~b nonexistent\", f)\n        assert flowfilter.match(None, f)\n        assert not flowfilter.match(\"~b nonexistent\", f)\n\n        f = tflow.tudpflow(err=True)\n        assert flowfilter.match(\"~e\", f)\n\n        with pytest.raises(ValueError):\n            flowfilter.match(\"~\", f)\n\n    def test_repr(self):\n        f = tflow.tudpflow()\n        assert \"UDPFlow\" in repr(f)\n        assert \"-> \" in repr(f.messages[0])\n", "test/mitmproxy/test_types.py": "import contextlib\nimport os\nfrom collections.abc import Sequence\n\nimport pytest\n\nfrom . import test_command\nimport mitmproxy.exceptions\nimport mitmproxy.types\nfrom mitmproxy import command\nfrom mitmproxy import flow\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\n@contextlib.contextmanager\ndef chdir(path: str):\n    old_dir = os.getcwd()\n    os.chdir(path)\n    yield\n    os.chdir(old_dir)\n\n\ndef test_bool():\n    with taddons.context() as tctx:\n        b = mitmproxy.types._BoolType()\n        assert b.completion(tctx.master.commands, bool, \"b\") == [\"false\", \"true\"]\n        assert b.parse(tctx.master.commands, bool, \"true\") is True\n        assert b.parse(tctx.master.commands, bool, \"false\") is False\n        assert b.is_valid(tctx.master.commands, bool, True) is True\n        assert b.is_valid(tctx.master.commands, bool, \"foo\") is False\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, bool, \"foo\")\n\n\ndef test_str():\n    with taddons.context() as tctx:\n        b = mitmproxy.types._StrType()\n        assert b.is_valid(tctx.master.commands, str, \"foo\") is True\n        assert b.is_valid(tctx.master.commands, str, 1) is False\n        assert b.completion(tctx.master.commands, str, \"\") == []\n        assert b.parse(tctx.master.commands, str, \"foo\") == \"foo\"\n        assert b.parse(tctx.master.commands, str, r\"foo\\nbar\") == \"foo\\nbar\"\n        assert b.parse(tctx.master.commands, str, r\"\\N{BELL}\") == \"\ud83d\udd14\"\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, bool, r\"\\N{UNKNOWN UNICODE SYMBOL!}\")\n\n\ndef test_bytes():\n    with taddons.context() as tctx:\n        b = mitmproxy.types._BytesType()\n        assert b.is_valid(tctx.master.commands, bytes, b\"foo\") is True\n        assert b.is_valid(tctx.master.commands, bytes, 1) is False\n        assert b.completion(tctx.master.commands, bytes, \"\") == []\n        assert b.parse(tctx.master.commands, bytes, \"foo\") == b\"foo\"\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, bytes, \"incomplete escape sequence\\\\\")\n\n\ndef test_unknown():\n    with taddons.context() as tctx:\n        b = mitmproxy.types._UnknownType()\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Unknown, \"foo\") is False\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Unknown, 1) is False\n        assert b.completion(tctx.master.commands, mitmproxy.types.Unknown, \"\") == []\n        assert b.parse(tctx.master.commands, mitmproxy.types.Unknown, \"foo\") == \"foo\"\n\n\ndef test_int():\n    with taddons.context() as tctx:\n        b = mitmproxy.types._IntType()\n        assert b.is_valid(tctx.master.commands, int, \"foo\") is False\n        assert b.is_valid(tctx.master.commands, int, 1) is True\n        assert b.completion(tctx.master.commands, int, \"b\") == []\n        assert b.parse(tctx.master.commands, int, \"1\") == 1\n        assert b.parse(tctx.master.commands, int, \"999\") == 999\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, int, \"foo\")\n\n\ndef test_path(tdata, monkeypatch):\n    with taddons.context() as tctx:\n        b = mitmproxy.types._PathType()\n        assert b.parse(tctx.master.commands, mitmproxy.types.Path, \"/foo\") == \"/foo\"\n        assert b.parse(tctx.master.commands, mitmproxy.types.Path, \"/bar\") == \"/bar\"\n        monkeypatch.setenv(\"HOME\", \"/home/test\")\n        monkeypatch.setenv(\"USERPROFILE\", \"/home/test\")\n        assert (\n            b.parse(tctx.master.commands, mitmproxy.types.Path, \"~/mitm\")\n            == \"/home/test/mitm\"\n        )\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Path, \"foo\") is True\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Path, \"~/mitm\") is True\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Path, 3) is False\n\n        def normPathOpts(prefix, match):\n            ret = []\n            for s in b.completion(tctx.master.commands, mitmproxy.types.Path, match):\n                s = s[len(prefix) :]\n                s = s.replace(os.sep, \"/\")\n                ret.append(s)\n            return ret\n\n        cd = os.path.normpath(tdata.path(\"mitmproxy/completion\"))\n        assert normPathOpts(cd, cd) == [\"/aaa\", \"/aab\", \"/aac\", \"/bbb/\"]\n        assert normPathOpts(cd, os.path.join(cd, \"a\")) == [\"/aaa\", \"/aab\", \"/aac\"]\n        with chdir(cd):\n            assert normPathOpts(\"\", \"./\") == [\"./aaa\", \"./aab\", \"./aac\", \"./bbb/\"]\n            assert normPathOpts(\"\", \"\") == [\"./aaa\", \"./aab\", \"./aac\", \"./bbb/\"]\n        assert b.completion(\n            tctx.master.commands, mitmproxy.types.Path, \"nonexistent\"\n        ) == [\"nonexistent\"]\n\n\ndef test_cmd():\n    with taddons.context() as tctx:\n        tctx.master.addons.add(test_command.TAddon())\n        b = mitmproxy.types._CmdType()\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Cmd, \"foo\") is False\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Cmd, \"cmd1\") is True\n        assert b.parse(tctx.master.commands, mitmproxy.types.Cmd, \"cmd1\") == \"cmd1\"\n        with pytest.raises(ValueError):\n            assert b.parse(tctx.master.commands, mitmproxy.types.Cmd, \"foo\")\n        assert len(b.completion(tctx.master.commands, mitmproxy.types.Cmd, \"\")) == len(\n            tctx.master.commands.commands.keys()\n        )\n\n\ndef test_cutspec():\n    with taddons.context() as tctx:\n        b = mitmproxy.types._CutSpecType()\n        b.parse(tctx.master.commands, mitmproxy.types.CutSpec, \"foo,bar\") == [\n            \"foo\",\n            \"bar\",\n        ]\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.CutSpec, 1) is False\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.CutSpec, \"foo\") is False\n        assert (\n            b.is_valid(tctx.master.commands, mitmproxy.types.CutSpec, \"request.path\")\n            is True\n        )\n\n        assert (\n            b.completion(tctx.master.commands, mitmproxy.types.CutSpec, \"request.p\")\n            == b.valid_prefixes\n        )\n        ret = b.completion(\n            tctx.master.commands, mitmproxy.types.CutSpec, \"request.port,f\"\n        )\n        assert ret[0].startswith(\"request.port,\")\n        assert len(ret) == len(b.valid_prefixes)\n\n\ndef test_marker():\n    with taddons.context() as tctx:\n        b = mitmproxy.types._MarkerType()\n        assert (\n            b.parse(tctx.master.commands, mitmproxy.types.Marker, \":red_circle:\")\n            == \":red_circle:\"\n        )\n        assert (\n            b.parse(tctx.master.commands, mitmproxy.types.Marker, \"true\") == \":default:\"\n        )\n        assert b.parse(tctx.master.commands, mitmproxy.types.Marker, \"false\") == \"\"\n\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, mitmproxy.types.Marker, \":bogus:\")\n\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Marker, \"true\") is True\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Marker, \"false\") is True\n        assert (\n            b.is_valid(tctx.master.commands, mitmproxy.types.Marker, \"bogus\") is False\n        )\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Marker, \"X\") is True\n        assert (\n            b.is_valid(tctx.master.commands, mitmproxy.types.Marker, \":red_circle:\")\n            is True\n        )\n        ret = b.completion(tctx.master.commands, mitmproxy.types.Marker, \":smil\")\n        assert len(ret) > 10\n\n\ndef test_arg():\n    with taddons.context() as tctx:\n        b = mitmproxy.types._ArgType()\n        assert b.completion(tctx.master.commands, mitmproxy.types.CmdArgs, \"\") == []\n        assert b.parse(tctx.master.commands, mitmproxy.types.CmdArgs, \"foo\") == \"foo\"\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.CmdArgs, 1) is False\n\n\ndef test_strseq():\n    with taddons.context() as tctx:\n        b = mitmproxy.types._StrSeqType()\n        assert b.completion(tctx.master.commands, Sequence[str], \"\") == []\n        assert b.parse(tctx.master.commands, Sequence[str], \"foo\") == [\"foo\"]\n        assert b.parse(tctx.master.commands, Sequence[str], \"foo,bar\") == [\"foo\", \"bar\"]\n        assert b.is_valid(tctx.master.commands, Sequence[str], [\"foo\"]) is True\n        assert b.is_valid(tctx.master.commands, Sequence[str], [\"a\", \"b\", 3]) is False\n        assert b.is_valid(tctx.master.commands, Sequence[str], 1) is False\n        assert b.is_valid(tctx.master.commands, Sequence[str], \"foo\") is False\n\n\nclass DummyConsole:\n    @command.command(\"view.flows.resolve\")\n    def resolve(self, spec: str) -> Sequence[flow.Flow]:\n        if spec == \"err\":\n            raise mitmproxy.exceptions.CommandError()\n        try:\n            n = int(spec)\n        except ValueError:\n            n = 1\n        return [tflow.tflow(resp=True)] * n\n\n    @command.command(\"cut\")\n    def cut(self, spec: str) -> mitmproxy.types.Data:\n        return [[\"test\"]]\n\n    @command.command(\"options\")\n    def options(self) -> Sequence[str]:\n        return [\"one\", \"two\", \"three\"]\n\n\ndef test_flow():\n    with taddons.context() as tctx:\n        tctx.master.addons.add(DummyConsole())\n        b = mitmproxy.types._FlowType()\n        assert len(b.completion(tctx.master.commands, flow.Flow, \"\")) == len(\n            b.valid_prefixes\n        )\n        assert b.parse(tctx.master.commands, flow.Flow, \"1\")\n        assert b.parse(tctx.master.commands, flow.Flow, \"has space\")\n        assert b.is_valid(tctx.master.commands, flow.Flow, tflow.tflow()) is True\n        assert b.is_valid(tctx.master.commands, flow.Flow, \"xx\") is False\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, flow.Flow, \"0\")\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, flow.Flow, \"2\")\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, flow.Flow, \"err\")\n\n\ndef test_flows():\n    with taddons.context() as tctx:\n        tctx.master.addons.add(DummyConsole())\n        b = mitmproxy.types._FlowsType()\n        assert len(b.completion(tctx.master.commands, Sequence[flow.Flow], \"\")) == len(\n            b.valid_prefixes\n        )\n        assert (\n            b.is_valid(tctx.master.commands, Sequence[flow.Flow], [tflow.tflow()])\n            is True\n        )\n        assert b.is_valid(tctx.master.commands, Sequence[flow.Flow], \"xx\") is False\n        assert b.is_valid(tctx.master.commands, Sequence[flow.Flow], 0) is False\n        assert len(b.parse(tctx.master.commands, Sequence[flow.Flow], \"0\")) == 0\n        assert len(b.parse(tctx.master.commands, Sequence[flow.Flow], \"1\")) == 1\n        assert len(b.parse(tctx.master.commands, Sequence[flow.Flow], \"2\")) == 2\n        assert len(b.parse(tctx.master.commands, Sequence[flow.Flow], \"has space\")) == 1\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, Sequence[flow.Flow], \"err\")\n\n\ndef test_data():\n    with taddons.context() as tctx:\n        b = mitmproxy.types._DataType()\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Data, 0) is False\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Data, []) is True\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Data, [[\"x\"]]) is True\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Data, [[b\"x\"]]) is True\n        assert b.is_valid(tctx.master.commands, mitmproxy.types.Data, [[1]]) is False\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, mitmproxy.types.Data, \"foo\")\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, mitmproxy.types.Data, \"foo\")\n\n\ndef test_choice():\n    with taddons.context() as tctx:\n        tctx.master.addons.add(DummyConsole())\n        b = mitmproxy.types._ChoiceType()\n        assert (\n            b.is_valid(\n                tctx.master.commands,\n                mitmproxy.types.Choice(\"options\"),\n                \"one\",\n            )\n            is True\n        )\n        assert (\n            b.is_valid(\n                tctx.master.commands,\n                mitmproxy.types.Choice(\"options\"),\n                \"invalid\",\n            )\n            is False\n        )\n        assert (\n            b.is_valid(\n                tctx.master.commands,\n                mitmproxy.types.Choice(\"nonexistent\"),\n                \"invalid\",\n            )\n            is False\n        )\n        comp = b.completion(tctx.master.commands, mitmproxy.types.Choice(\"options\"), \"\")\n        assert comp == [\"one\", \"two\", \"three\"]\n        assert (\n            b.parse(tctx.master.commands, mitmproxy.types.Choice(\"options\"), \"one\")\n            == \"one\"\n        )\n        with pytest.raises(ValueError):\n            b.parse(tctx.master.commands, mitmproxy.types.Choice(\"options\"), \"invalid\")\n\n\ndef test_typemanager():\n    assert mitmproxy.types.CommandTypes.get(bool, None)\n    assert mitmproxy.types.CommandTypes.get(mitmproxy.types.Choice(\"choide\"), None)\n", "test/mitmproxy/test_typemanager.py": "", "test/mitmproxy/test_optmanager.py": "import argparse\nimport copy\nimport io\nfrom collections.abc import Sequence\nfrom pathlib import Path\nfrom typing import Optional\n\nimport pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import options\nfrom mitmproxy import optmanager\n\n\nclass TO(optmanager.OptManager):\n    def __init__(self):\n        super().__init__()\n        self.add_option(\"one\", Optional[int], None, \"help\")\n        self.add_option(\"two\", Optional[int], 2, \"help\")\n        self.add_option(\"bool\", bool, False, \"help\")\n        self.add_option(\"required_int\", int, 2, \"help\")\n\n\nclass TD(optmanager.OptManager):\n    def __init__(self):\n        super().__init__()\n        self.add_option(\"one\", str, \"done\", \"help\")\n        self.add_option(\"two\", str, \"dtwo\", \"help\")\n\n\nclass TD2(TD):\n    def __init__(self):\n        super().__init__()\n        self.add_option(\"three\", str, \"dthree\", \"help\")\n        self.add_option(\"four\", str, \"dfour\", \"help\")\n\n\nclass TM(optmanager.OptManager):\n    def __init__(self):\n        super().__init__()\n        self.add_option(\"two\", Sequence[str], [\"foo\"], \"help\")\n        self.add_option(\"one\", Optional[str], None, \"help\")\n\n\nclass TS(optmanager.OptManager):\n    def __init__(self):\n        super().__init__()\n        self.add_option(\"scripts\", Sequence[str], [], \"help\")\n        self.add_option(\"not_scripts\", Sequence[str], [], \"help\")\n\n\ndef test_defaults():\n    o = TD2()\n    defaults = {\n        \"one\": \"done\",\n        \"two\": \"dtwo\",\n        \"three\": \"dthree\",\n        \"four\": \"dfour\",\n    }\n    for k, v in defaults.items():\n        assert o.default(k) == v\n\n    assert not o.has_changed(\"one\")\n    newvals = dict(\n        one=\"xone\",\n        two=\"xtwo\",\n        three=\"xthree\",\n        four=\"xfour\",\n    )\n    o.update(**newvals)\n    assert o.has_changed(\"one\")\n    for k, v in newvals.items():\n        assert v == getattr(o, k)\n    o.reset()\n    assert not o.has_changed(\"one\")\n\n    for k in o.keys():\n        assert not o.has_changed(k)\n\n\ndef test_required_int():\n    o = TO()\n    with pytest.raises(exceptions.OptionsError):\n        o._parse_setval(o._options[\"required_int\"], [])\n\n\ndef test_deepcopy():\n    o = TD()\n    copy.deepcopy(o)\n\n\ndef test_options():\n    o = TO()\n    assert o.keys() == {\"bool\", \"one\", \"two\", \"required_int\"}\n\n    assert o.one is None\n    assert o.two == 2\n    o.one = 1\n    assert o.one == 1\n\n    with pytest.raises(TypeError):\n        TO(nonexistent=\"value\")\n    with pytest.raises(Exception, match=\"Unknown options\"):\n        o.nonexistent = \"value\"\n    with pytest.raises(Exception, match=\"Unknown options\"):\n        o.update(nonexistent=\"value\")\n    assert o.update_known(nonexistent=\"value\") == {\"nonexistent\": \"value\"}\n\n    rec = []\n\n    def sub(updated):\n        rec.append(copy.copy(o))\n\n    o.changed.connect(sub)\n\n    o.one = 90\n    assert len(rec) == 1\n    assert rec[-1].one == 90\n\n    o.update(one=3)\n    assert len(rec) == 2\n    assert rec[-1].one == 3\n\n\ndef test_setter():\n    o = TO()\n    f = o.setter(\"two\")\n    f(99)\n    assert o.two == 99\n    with pytest.raises(Exception, match=\"No such option\"):\n        o.setter(\"nonexistent\")\n\n\ndef test_toggler():\n    o = TO()\n    f = o.toggler(\"bool\")\n    assert o.bool is False\n    f()\n    assert o.bool is True\n    f()\n    assert o.bool is False\n    with pytest.raises(Exception, match=\"No such option\"):\n        o.toggler(\"nonexistent\")\n\n    with pytest.raises(Exception, match=\"boolean options\"):\n        o.toggler(\"one\")\n\n\nclass Rec:\n    def __init__(self):\n        self.called = None\n\n    def __call__(self, *args, **kwargs):\n        self.called = (args, kwargs)\n\n\ndef test_subscribe():\n    o = TO()\n    r = Rec()\n\n    # pytest.raises keeps a reference here that interferes with the cleanup test\n    # further down.\n    try:\n        o.subscribe(r, [\"unknown\"])\n    except exceptions.OptionsError:\n        pass\n    else:\n        raise AssertionError\n\n    assert len(o._subscriptions) == 0\n\n    o.subscribe(r, [\"two\"])\n    o.one = 2\n    assert not r.called\n    o.two = 3\n    assert r.called\n\n    assert len(o.changed.receivers) == 1\n    del r\n    o.two = 4\n    assert len(o._subscriptions) == 0\n\n    class binder:\n        def __init__(self):\n            self.o = TO()\n            self.called = False\n            self.o.subscribe(self.bound, [\"two\"])\n\n        def bound(self, *args, **kwargs):\n            self.called = True\n\n    t = binder()\n    t.o.one = 3\n    assert not t.called\n    t.o.two = 3\n    assert t.called\n\n\ndef test_rollback():\n    o = TO()\n\n    rec = []\n\n    def sub(updated):\n        rec.append(copy.copy(o))\n\n    recerr = []\n\n    def errsub(**kwargs):\n        recerr.append(kwargs)\n\n    def err(updated):\n        if o.one == 10:\n            raise exceptions.OptionsError()\n        if o.bool is True:\n            raise exceptions.OptionsError()\n\n    o.changed.connect(sub)\n    o.changed.connect(err)\n    o.errored.connect(errsub)\n\n    assert o.one is None\n    with pytest.raises(exceptions.OptionsError):\n        o.one = 10\n    assert o.one is None\n    with pytest.raises(exceptions.OptionsError):\n        o.bool = True\n    assert o.bool is False\n    assert isinstance(recerr[0][\"exc\"], exceptions.OptionsError)\n    assert o.one is None\n    assert o.bool is False\n    assert len(rec) == 4\n    assert rec[0].one == 10\n    assert rec[1].one is None\n    assert rec[2].bool is True\n    assert rec[3].bool is False\n\n    with pytest.raises(exceptions.OptionsError):\n        with o.rollback({\"one\"}, reraise=True):\n            raise exceptions.OptionsError()\n\n\ndef test_simple():\n    o = TO()\n    assert repr(o)\n    assert \"one\" in o\n\n    with pytest.raises(Exception, match=\"No such option\"):\n        assert o.unknown\n\n\ndef test_items():\n    assert TO().items()\n\n\ndef test_serialize():\n    def serialize(\n        opts: optmanager.OptManager, text: str, defaults: bool = False\n    ) -> str:\n        buf = io.StringIO()\n        optmanager.serialize(opts, buf, text, defaults)\n        return buf.getvalue()\n\n    o = TD2()\n    o.three = \"set\"\n    assert \"dfour\" in serialize(o, \"\", defaults=True)\n\n    data = serialize(o, \"\")\n    assert \"dfour\" not in data\n\n    o2 = TD2()\n    optmanager.load(o2, data)\n    assert o2 == o\n    assert not o == 42\n\n    t = \"\"\"\n        unknown: foo\n    \"\"\"\n    data = serialize(o, t)\n    o2 = TD2()\n    optmanager.load(o2, data)\n    assert o2 == o\n\n    t = \"invalid: foo\\ninvalid\"\n    with pytest.raises(Exception, match=\"Config error\"):\n        optmanager.load(o2, t)\n\n    t = \"invalid\"\n    with pytest.raises(Exception, match=\"Config error\"):\n        optmanager.load(o2, t)\n\n    t = \"# a comment\"\n    optmanager.load(o2, t)\n    optmanager.load(o2, \"foobar: '123'\")\n    assert o2.deferred == {\"foobar\": \"123\"}\n\n    t = \"\"\n    optmanager.load(o2, t)\n    optmanager.load(o2, \"foobar: '123'\")\n    assert o2.deferred == {\"foobar\": \"123\"}\n\n\ndef test_serialize_defaults():\n    o = options.Options()\n    buf = io.StringIO()\n    optmanager.serialize(o, buf, \"\", defaults=True)\n    assert buf.getvalue()\n\n\ndef test_saving(tmpdir):\n    o = TD2()\n    o.three = \"set\"\n    dst = Path(tmpdir.join(\"conf\"))\n    optmanager.save(o, dst, defaults=True)\n\n    o2 = TD2()\n    optmanager.load_paths(o2, dst)\n    o2.three = \"foo\"\n    optmanager.save(o2, dst, defaults=True)\n\n    optmanager.load_paths(o, dst)\n    assert o.three == \"foo\"\n\n    with open(dst, \"a\") as f:\n        f.write(\"foobar: '123'\")\n    optmanager.load_paths(o, dst)\n    assert o.deferred == {\"foobar\": \"123\"}\n\n    with open(dst, \"a\") as f:\n        f.write(\"'''\")\n    with pytest.raises(exceptions.OptionsError):\n        optmanager.load_paths(o, dst)\n\n    with open(dst, \"wb\") as f:\n        f.write(b\"\\x01\\x02\\x03\")\n    with pytest.raises(exceptions.OptionsError):\n        optmanager.load_paths(o, dst)\n    with pytest.raises(exceptions.OptionsError):\n        optmanager.save(o, dst)\n\n    with open(dst, \"wb\") as f:\n        f.write(b\"\\xff\\xff\\xff\")\n    with pytest.raises(exceptions.OptionsError):\n        optmanager.load_paths(o, dst)\n    with pytest.raises(exceptions.OptionsError):\n        optmanager.save(o, dst)\n\n\ndef test_merge():\n    m = TM()\n    m.merge(dict(one=\"two\"))\n    assert m.one == \"two\"\n    m.merge(dict(one=None))\n    assert m.one == \"two\"\n    m.merge(dict(two=[\"bar\"]))\n    assert m.two == [\"foo\", \"bar\"]\n\n\ndef test_option():\n    o = optmanager._Option(\"test\", int, 1, \"help\", None)\n    assert o.current() == 1\n    with pytest.raises(TypeError):\n        o.set(\"foo\")\n    with pytest.raises(TypeError):\n        optmanager._Option(\"test\", str, 1, \"help\", None)\n\n    o2 = optmanager._Option(\"test\", int, 1, \"help\", None)\n    assert o2 == o\n    o2.set(5)\n    assert o2 != o\n\n\ndef test_dump_defaults():\n    o = TTypes()\n    buf = io.StringIO()\n    optmanager.dump_defaults(o, buf)\n    assert buf.getvalue()\n\n\ndef test_dump_dicts():\n    o = options.Options()\n    assert optmanager.dump_dicts(o)\n    assert optmanager.dump_dicts(o, [\"http2\", \"listen_port\"])\n\n\nclass TTypes(optmanager.OptManager):\n    def __init__(self):\n        super().__init__()\n        self.add_option(\"str\", str, \"str\", \"help\")\n        self.add_option(\"choices\", str, \"foo\", \"help\", [\"foo\", \"bar\", \"baz\"])\n        self.add_option(\"optstr\", Optional[str], \"optstr\", \"help\")\n        self.add_option(\"bool\", bool, False, \"help\")\n        self.add_option(\"bool_on\", bool, True, \"help\")\n        self.add_option(\"int\", int, 0, \"help\")\n        self.add_option(\"optint\", Optional[int], 0, \"help\")\n        self.add_option(\"seqstr\", Sequence[str], [], \"help\")\n        self.add_option(\"unknown\", float, 0.0, \"help\")\n\n\ndef test_make_parser():\n    parser = argparse.ArgumentParser()\n    opts = TTypes()\n    opts.make_parser(parser, \"str\", short=\"a\")\n    opts.make_parser(parser, \"bool\", short=\"b\")\n    opts.make_parser(parser, \"int\", short=\"c\")\n    opts.make_parser(parser, \"seqstr\", short=\"d\")\n    opts.make_parser(parser, \"bool_on\", short=\"e\")\n\n    with pytest.raises(ValueError):\n        opts.make_parser(parser, \"unknown\")\n\n    # Nonexistent options ignore\n    opts.make_parser(parser, \"nonexistentxxx\")\n\n\ndef test_set():\n    opts = TTypes()\n\n    opts.set(\"str=foo\")\n    assert opts.str == \"foo\"\n    with pytest.raises(exceptions.OptionsError):\n        opts.set(\"str\")\n\n    opts.set(\"optstr=foo\")\n    assert opts.optstr == \"foo\"\n    opts.set(\"optstr\")\n    assert opts.optstr is None\n    with pytest.raises(exceptions.OptionsError, match=\"Received multiple values\"):\n        opts.set(\"optstr=foo\", \"optstr=bar\")\n\n    opts.set(\"bool=false\")\n    assert opts.bool is False\n    opts.set(\"bool\")\n    assert opts.bool is True\n    opts.set(\"bool=true\")\n    assert opts.bool is True\n    with pytest.raises(exceptions.OptionsError):\n        opts.set(\"bool=wobble\")\n\n    opts.set(\"bool=toggle\")\n    assert opts.bool is False\n    opts.set(\"bool=toggle\")\n    assert opts.bool is True\n\n    opts.set(\"int=1\")\n    assert opts.int == 1\n    with pytest.raises(exceptions.OptionsError):\n        opts.set(\"int=wobble\")\n    opts.set(\"optint\")\n    assert opts.optint is None\n\n    assert opts.seqstr == []\n    opts.set(\"seqstr=foo\")\n    assert opts.seqstr == [\"foo\"]\n    opts.set(\"seqstr=foo\", \"seqstr=bar\")\n    assert opts.seqstr == [\"foo\", \"bar\"]\n    opts.set(\"seqstr\")\n    assert opts.seqstr == []\n\n    with pytest.raises(exceptions.OptionsError):\n        opts.set(\"deferredoption=wobble\")\n\n    opts.set(\"deferredoption=wobble\", defer=True)\n    assert \"deferredoption\" in opts.deferred\n    opts.process_deferred()\n    assert \"deferredoption\" in opts.deferred\n    opts.add_option(\"deferredoption\", str, \"default\", \"help\")\n    opts.process_deferred()\n    assert \"deferredoption\" not in opts.deferred\n    assert opts.deferredoption == \"wobble\"\n\n    opts.set(*(\"deferredsequenceoption=a\", \"deferredsequenceoption=b\"), defer=True)\n    assert \"deferredsequenceoption\" in opts.deferred\n    opts.process_deferred()\n    assert \"deferredsequenceoption\" in opts.deferred\n    opts.add_option(\"deferredsequenceoption\", Sequence[str], [], \"help\")\n    opts.process_deferred()\n    assert \"deferredsequenceoption\" not in opts.deferred\n    assert opts.deferredsequenceoption == [\"a\", \"b\"]\n\n\ndef test_load_paths(tdata):\n    opts = TS()\n    conf_path = tdata.path(\"mitmproxy/data/test_config.yml\")\n    optmanager.load_paths(opts, conf_path)\n    assert opts.scripts == [\n        str(Path.home().absolute().joinpath(\"abc\")),\n        str(Path(conf_path).parent.joinpath(\"abc\")),\n        str(Path(conf_path).parent.joinpath(\"../abc\")),\n        str(Path(\"/abc\").absolute()),\n    ]\n    assert opts.not_scripts == [\"~/abc\", \"abc\", \"../abc\", \"/abc\"]\n\n\n@pytest.mark.parametrize(\n    \"script_path, relative_to, expected\",\n    (\n        (\"~/abc\", \".\", Path.home().joinpath(\"abc\")),\n        (\"/abc\", \".\", Path(\"/abc\")),\n        (\"abc\", \".\", Path(\".\").joinpath(\"abc\")),\n        (\"../abc\", \".\", Path(\".\").joinpath(\"../abc\")),\n        (\"~/abc\", \"/tmp\", Path.home().joinpath(\"abc\")),\n        (\"/abc\", \"/tmp\", Path(\"/abc\")),\n        (\"abc\", \"/tmp\", Path(\"/tmp\").joinpath(\"abc\")),\n        (\"../abc\", \"/tmp\", Path(\"/tmp\").joinpath(\"../abc\")),\n        (\"~/abc\", \"foo\", Path.home().joinpath(\"abc\")),\n        (\"/abc\", \"foo\", Path(\"/abc\")),\n        (\"abc\", \"foo\", Path(\"foo\").joinpath(\"abc\")),\n        (\"../abc\", \"foo\", Path(\"foo\").joinpath(\"../abc\")),\n    ),\n)\ndef test_relative_path(script_path, relative_to, expected):\n    assert (\n        optmanager.relative_path(\n            script_path,\n            relative_to=relative_to,\n        )\n        == expected.absolute()\n    )\n", "test/mitmproxy/addons/test_eventstore.py": "import asyncio\nimport logging\n\nfrom mitmproxy.addons import eventstore\n\n\nasync def test_simple():\n    store = eventstore.EventStore()\n    assert not store.data\n\n    sig_add_called = False\n    sig_refresh_called = False\n\n    def sig_add(entry):\n        nonlocal sig_add_called\n        sig_add_called = True\n\n    def sig_refresh():\n        nonlocal sig_refresh_called\n        sig_refresh_called = True\n\n    store.sig_add.connect(sig_add)\n    store.sig_refresh.connect(sig_refresh)\n\n    assert not sig_add_called\n    assert not sig_refresh_called\n\n    # test .log()\n    logging.error(\"test\")\n    await asyncio.sleep(0)\n    assert store.data\n\n    assert sig_add_called\n    assert not sig_refresh_called\n\n    # test .clear()\n    sig_add_called = False\n\n    store.clear()\n    assert not store.data\n\n    assert not sig_add_called\n    assert sig_refresh_called\n    store.done()\n\n\nasync def test_max_size():\n    store = eventstore.EventStore(3)\n    assert store.size == 3\n    logging.warning(\"foo\")\n    logging.warning(\"bar\")\n    logging.warning(\"baz\")\n    await asyncio.sleep(0)\n    assert len(store.data) == 3\n    assert \"baz\" in store.data[-1].msg\n\n    # overflow\n    logging.warning(\"boo\")\n    await asyncio.sleep(0)\n    assert len(store.data) == 3\n    assert \"boo\" in store.data[-1].msg\n    store.done()\n", "test/mitmproxy/addons/test_stickycookie.py": "import pytest\n\nfrom mitmproxy.addons import stickycookie\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils as ntutils\n\n\ndef test_domain_match():\n    assert stickycookie.domain_match(\"www.google.com\", \".google.com\")\n    assert stickycookie.domain_match(\"google.com\", \".google.com\")\n\n\nclass TestStickyCookie:\n    def test_config(self):\n        sc = stickycookie.StickyCookie()\n        with taddons.context(sc) as tctx:\n            with pytest.raises(Exception, match=\"Invalid filter expression\"):\n                tctx.configure(sc, stickycookie=\"~b\")\n\n            tctx.configure(sc, stickycookie=\"foo\")\n            assert sc.flt\n            tctx.configure(sc, stickycookie=None)\n            assert not sc.flt\n\n    def test_simple(self):\n        sc = stickycookie.StickyCookie()\n        with taddons.context(sc) as tctx:\n            tctx.configure(sc, stickycookie=\".*\")\n            f = tflow.tflow(resp=True)\n            f.response.headers[\"set-cookie\"] = \"foo=bar\"\n            sc.request(f)\n\n            sc.response(f)\n\n            assert sc.jar\n            assert \"cookie\" not in f.request.headers\n\n            f = f.copy()\n            sc.request(f)\n            assert f.request.headers[\"cookie\"] == \"foo=bar\"\n\n    def _response(self, sc, cookie, host):\n        f = tflow.tflow(req=ntutils.treq(host=host, port=80), resp=True)\n        f.response.headers[\"Set-Cookie\"] = cookie\n        sc.response(f)\n        return f\n\n    def test_response(self):\n        sc = stickycookie.StickyCookie()\n        with taddons.context(sc) as tctx:\n            tctx.configure(sc, stickycookie=\".*\")\n\n            c = (\n                \"SSID=mooo; domain=.google.com, FOO=bar; Domain=.google.com; Path=/; \"\n                \"Expires=Wed, 13-Jan-2021 22:23:01 GMT; Secure; \"\n            )\n\n            self._response(sc, c, \"host\")\n            assert not sc.jar.keys()\n\n            self._response(sc, c, \"www.google.com\")\n            assert sc.jar.keys()\n\n            sc.jar.clear()\n            self._response(sc, \"SSID=mooo\", \"www.google.com\")\n            assert list(sc.jar.keys())[0] == (\"www.google.com\", 80, \"/\")\n\n    def test_response_multiple(self):\n        sc = stickycookie.StickyCookie()\n        with taddons.context(sc) as tctx:\n            tctx.configure(sc, stickycookie=\".*\")\n\n            # Test setting of multiple cookies\n            c1 = \"somecookie=test; Path=/\"\n            c2 = \"othercookie=helloworld; Path=/\"\n            f = self._response(sc, c1, \"www.google.com\")\n            f.response.headers[\"Set-Cookie\"] = c2\n            sc.response(f)\n            googlekey = list(sc.jar.keys())[0]\n            assert len(sc.jar[googlekey].keys()) == 2\n\n    def test_response_weird(self):\n        sc = stickycookie.StickyCookie()\n        with taddons.context(sc) as tctx:\n            tctx.configure(sc, stickycookie=\".*\")\n\n            # Test setting of weird cookie keys\n            f = tflow.tflow(req=ntutils.treq(host=\"www.google.com\", port=80), resp=True)\n            cs = [\n                \"foo/bar=hello\",\n                \"foo:bar=world\",\n                \"foo@bar=fizz\",\n            ]\n            for c in cs:\n                f.response.headers[\"Set-Cookie\"] = c\n                sc.response(f)\n            googlekey = list(sc.jar.keys())[0]\n            assert len(sc.jar[googlekey].keys()) == len(cs)\n\n    def test_response_overwrite(self):\n        sc = stickycookie.StickyCookie()\n        with taddons.context(sc) as tctx:\n            tctx.configure(sc, stickycookie=\".*\")\n\n            # Test overwriting of a cookie value\n            c1 = \"somecookie=helloworld; Path=/\"\n            c2 = \"somecookie=newvalue; Path=/\"\n            f = self._response(sc, c1, \"www.google.com\")\n            f.response.headers[\"Set-Cookie\"] = c2\n            sc.response(f)\n            googlekey = list(sc.jar.keys())[0]\n            assert len(sc.jar[googlekey]) == 1\n            assert sc.jar[googlekey][\"somecookie\"] == \"newvalue\"\n\n    def test_response_delete(self):\n        sc = stickycookie.StickyCookie()\n        with taddons.context(sc) as tctx:\n            tctx.configure(sc, stickycookie=\".*\")\n\n            # Test that a cookie is be deleted\n            # by setting the expire time in the past\n            f = self._response(sc, \"duffer=zafar; Path=/\", \"www.google.com\")\n            f.response.headers[\"Set-Cookie\"] = (\n                \"duffer=; Expires=Thu, 01-Jan-1970 00:00:00 GMT\"\n            )\n            sc.response(f)\n            assert not sc.jar.keys()\n\n    def test_request(self):\n        sc = stickycookie.StickyCookie()\n        with taddons.context(sc) as tctx:\n            tctx.configure(sc, stickycookie=\".*\")\n\n            f = self._response(sc, \"SSID=mooo\", \"www.google.com\")\n            assert \"cookie\" not in f.request.headers\n            sc.request(f)\n            assert \"cookie\" in f.request.headers\n", "test/mitmproxy/addons/test_proxyauth.py": "import binascii\nfrom unittest import mock\n\nimport ldap3\nimport pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import proxyauth\nfrom mitmproxy.proxy.layers import modes\nfrom mitmproxy.proxy.mode_specs import ProxyMode\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\n@pytest.mark.parametrize(\n    \"scheme, expected\",\n    [\n        (\"\", \" dXNlcm5hbWU6cGFzc3dvcmQ=\\n\"),\n        (\"basic\", \"basic dXNlcm5hbWU6cGFzc3dvcmQ=\\n\"),\n        (\"foobar\", \"foobar dXNlcm5hbWU6cGFzc3dvcmQ=\\n\"),\n    ],\n)\ndef test_mkauth(scheme, expected):\n    assert proxyauth.mkauth(\"username\", \"password\", scheme) == expected\n\n\ndef test_parse_http_basic_auth():\n    input = proxyauth.mkauth(\"test\", \"test\")\n    assert proxyauth.parse_http_basic_auth(input) == (\"basic\", \"test\", \"test\")\n\n\n@pytest.mark.parametrize(\n    \"input\",\n    [\n        \"\",\n        \"foo bar\",\n        \"basic abc\",\n        \"basic \" + binascii.b2a_base64(b\"foo\").decode(\"ascii\"),\n    ],\n)\ndef test_parse_http_basic_auth_error(input):\n    with pytest.raises(ValueError):\n        proxyauth.parse_http_basic_auth(input)\n\n\n@pytest.mark.parametrize(\n    \"mode, expected\",\n    [\n        (\"regular\", True),\n        (\"upstream:proxy\", True),\n        (\"reverse:example.com\", False),\n    ],\n)\ndef test_is_http_proxy(mode, expected):\n    f = tflow.tflow()\n    f.client_conn.proxy_mode = ProxyMode.parse(mode)\n    assert proxyauth.is_http_proxy(f) == expected\n\n\n@pytest.mark.parametrize(\n    \"is_http_proxy, expected\",\n    [\n        (True, \"Proxy-Authorization\"),\n        (False, \"Authorization\"),\n    ],\n)\ndef test_http_auth_header(is_http_proxy, expected):\n    assert proxyauth.http_auth_header(is_http_proxy) == expected\n\n\n@pytest.mark.parametrize(\n    \"is_http_proxy, expected_status_code, expected_header\",\n    [\n        (True, 407, \"Proxy-Authenticate\"),\n        (False, 401, \"WWW-Authenticate\"),\n    ],\n)\ndef test_make_auth_required_response(\n    is_http_proxy, expected_status_code, expected_header\n):\n    resp = proxyauth.make_auth_required_response(is_http_proxy)\n    assert resp.status_code == expected_status_code\n    assert expected_header in resp.headers.keys()\n\n\nclass TestProxyAuth:\n    def test_socks5(self):\n        pa = proxyauth.ProxyAuth()\n        with taddons.context(pa, loadcore=False) as ctx:\n            ctx.configure(pa, proxyauth=\"foo:bar\")\n            data = modes.Socks5AuthData(tflow.tclient_conn(), \"foo\", \"baz\")\n            pa.socks5_auth(data)\n            assert not data.valid\n            data.password = \"bar\"\n            pa.socks5_auth(data)\n            assert data.valid\n\n    def test_authenticate(self):\n        up = proxyauth.ProxyAuth()\n        with taddons.context(up, loadcore=False) as ctx:\n            ctx.configure(up, proxyauth=\"any\")\n\n            f = tflow.tflow()\n            f.client_conn.proxy_mode = ProxyMode.parse(\"regular\")\n            assert not f.response\n            up.authenticate_http(f)\n            assert f.response.status_code == 407\n\n            f = tflow.tflow()\n            f.request.headers[\"Proxy-Authorization\"] = proxyauth.mkauth(\"test\", \"test\")\n            up.authenticate_http(f)\n            assert not f.response\n            assert not f.request.headers.get(\"Proxy-Authorization\")\n\n            f = tflow.tflow()\n            f.client_conn.proxy_mode = ProxyMode.parse(\"reverse:https://example.com\")\n            assert not f.response\n            up.authenticate_http(f)\n            assert f.response.status_code == 401\n\n            f = tflow.tflow()\n            f.client_conn.proxy_mode = ProxyMode.parse(\"reverse:https://example.com\")\n            f.request.headers[\"Authorization\"] = proxyauth.mkauth(\"test\", \"test\")\n            up.authenticate_http(f)\n            assert not f.response\n            assert not f.request.headers.get(\"Authorization\")\n\n    def test_configure(self, monkeypatch, tdata):\n        monkeypatch.setattr(ldap3, \"Server\", mock.MagicMock())\n        monkeypatch.setattr(ldap3, \"Connection\", mock.MagicMock())\n\n        pa = proxyauth.ProxyAuth()\n        with taddons.context(pa) as ctx:\n            with pytest.raises(\n                exceptions.OptionsError, match=\"Invalid proxyauth specification\"\n            ):\n                ctx.configure(pa, proxyauth=\"foo\")\n\n            ctx.configure(pa, proxyauth=\"foo:bar\")\n            assert isinstance(pa.validator, proxyauth.SingleUser)\n            assert pa.validator(\"foo\", \"bar\")\n            assert not pa.validator(\"foo\", \"baz\")\n\n            with pytest.raises(\n                exceptions.OptionsError, match=\"Invalid single-user auth specification.\"\n            ):\n                ctx.configure(pa, proxyauth=\"foo:bar:baz\")\n\n            ctx.configure(pa, proxyauth=\"any\")\n            assert isinstance(pa.validator, proxyauth.AcceptAll)\n            assert pa.validator(\"foo\", \"bar\")\n\n            ctx.configure(pa, proxyauth=None)\n            assert pa.validator is None\n\n            ctx.configure(\n                pa,\n                proxyauth=\"ldap:localhost:cn=default,dc=cdhdt,dc=com:password:ou=application,dc=cdhdt,dc=com\",\n            )\n            assert isinstance(pa.validator, proxyauth.Ldap)\n\n            ctx.configure(\n                pa,\n                proxyauth=\"ldap:localhost:1234:cn=default,dc=cdhdt,dc=com:password:ou=application,dc=cdhdt,dc=com\",\n            )\n            assert isinstance(pa.validator, proxyauth.Ldap)\n\n            ctx.configure(\n                pa,\n                proxyauth=\"ldap:localhost:1234:cn=default,dc=cdhdt,dc=com:password:dc=cdhdt,dc=com?search_filter_key=SamAccountName\",\n            )\n            assert isinstance(pa.validator, proxyauth.Ldap)\n\n            with pytest.raises(\n                exceptions.OptionsError, match=\"Invalid LDAP specification\"\n            ):\n                ctx.configure(pa, proxyauth=\"ldap:test:test:test\")\n\n            with pytest.raises(\n                exceptions.OptionsError, match=\"Invalid LDAP specification\"\n            ):\n                ctx.configure(\n                    pa,\n                    proxyauth=\"ldap:localhost:1234:cn=default,dc=cdhdt,dc=com:password:ou=application,dc=cdhdt,dc=com?key=1\",\n                )\n\n            with pytest.raises(\n                exceptions.OptionsError, match=\"Invalid LDAP specification\"\n            ):\n                ctx.configure(\n                    pa, proxyauth=\"ldap:fake_serveruid=?dc=example,dc=com:person\"\n                )\n\n            with pytest.raises(\n                exceptions.OptionsError, match=\"Invalid LDAP specification\"\n            ):\n                ctx.configure(pa, proxyauth=\"ldapssssssss:fake_server:dn:password:tree\")\n\n            with pytest.raises(\n                exceptions.OptionsError, match=\"Could not open htpasswd file\"\n            ):\n                ctx.configure(\n                    pa, proxyauth=\"@\" + tdata.path(\"mitmproxy/net/data/server.crt\")\n                )\n            with pytest.raises(\n                exceptions.OptionsError, match=\"Could not open htpasswd file\"\n            ):\n                ctx.configure(pa, proxyauth=\"@nonexistent\")\n\n            ctx.configure(pa, proxyauth=\"@\" + tdata.path(\"mitmproxy/net/data/htpasswd\"))\n            assert isinstance(pa.validator, proxyauth.Htpasswd)\n            assert pa.validator(\"test\", \"test\")\n            assert not pa.validator(\"test\", \"foo\")\n\n    def test_handlers(self):\n        up = proxyauth.ProxyAuth()\n        with taddons.context(up) as ctx:\n            ctx.configure(up, proxyauth=\"any\")\n\n            f = tflow.tflow()\n            assert not f.response\n            up.requestheaders(f)\n            assert f.response.status_code == 407\n\n            f = tflow.tflow()\n            f.request.method = \"CONNECT\"\n            assert not f.response\n            up.http_connect(f)\n            assert f.response.status_code == 407\n\n            f = tflow.tflow()\n            f.request.method = \"CONNECT\"\n            f.request.headers[\"Proxy-Authorization\"] = proxyauth.mkauth(\"test\", \"test\")\n            up.http_connect(f)\n            assert not f.response\n\n            f2 = tflow.tflow(client_conn=f.client_conn)\n            up.requestheaders(f2)\n            assert not f2.response\n            assert f2.metadata[\"proxyauth\"] == (\"test\", \"test\")\n\n            f3 = tflow.tflow()\n            f3.is_replay = True\n            up.requestheaders(f3)\n            assert not f2.response\n\n\n@pytest.mark.parametrize(\n    \"spec\",\n    [\n        \"ldaps:localhost:cn=default,dc=cdhdt,dc=com:password:ou=application,dc=cdhdt,dc=com\",\n        \"ldap:localhost:1234:cn=default,dc=cdhdt,dc=com:password:ou=application,dc=cdhdt,dc=com\",\n        \"ldap:localhost:1234:cn=default,dc=cdhdt,dc=com:password:ou=application,dc=cdhdt,dc=com?search_filter_key=cn\",\n    ],\n)\ndef test_ldap(monkeypatch, spec):\n    monkeypatch.setattr(ldap3, \"Server\", mock.MagicMock())\n    monkeypatch.setattr(ldap3, \"Connection\", mock.MagicMock())\n\n    validator = proxyauth.Ldap(spec)\n    assert not validator(\"\", \"\")\n    assert validator(\"foo\", \"bar\")\n    validator.conn.response = False\n    assert not validator(\"foo\", \"bar\")\n", "test/mitmproxy/addons/test_server_side_events.py": "from mitmproxy.addons.server_side_events import ServerSideEvents\nfrom mitmproxy.test.tflow import tflow\n\n\nasync def test_simple(caplog):\n    s = ServerSideEvents()\n    f = tflow(resp=True)\n    f.response.headers[\"content-type\"] = \"text/event-stream\"\n    s.response(f)\n    assert \"mitmproxy currently does not support server side events\" in caplog.text\n", "test/mitmproxy/addons/test_anticomp.py": "from mitmproxy.addons import anticomp\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\nclass TestAntiComp:\n    def test_simple(self):\n        sa = anticomp.AntiComp()\n        with taddons.context(sa) as tctx:\n            f = tflow.tflow(resp=True)\n            sa.request(f)\n\n            tctx.configure(sa, anticomp=True)\n            f = tflow.tflow(resp=True)\n\n            f.request.headers[\"Accept-Encoding\"] = \"foobar\"\n            sa.request(f)\n            assert f.request.headers[\"Accept-Encoding\"] == \"identity\"\n", "test/mitmproxy/addons/test_dns_resolver.py": "import asyncio\nimport ipaddress\nimport socket\nfrom collections.abc import Callable\n\nimport pytest\n\nfrom mitmproxy import dns\nfrom mitmproxy.addons import dns_resolver\nfrom mitmproxy.addons import proxyserver\nfrom mitmproxy.connection import Address\nfrom mitmproxy.proxy.mode_specs import ProxyMode\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nasync def test_simple(monkeypatch):\n    monkeypatch.setattr(\n        dns_resolver, \"resolve_message\", lambda _, __: asyncio.sleep(0, \"resp\")\n    )\n\n    dr = dns_resolver.DnsResolver()\n    with taddons.context(dr, proxyserver.Proxyserver()):\n        f = tflow.tdnsflow()\n        await dr.dns_request(f)\n        assert f.response\n\n        f = tflow.tdnsflow()\n        f.client_conn.proxy_mode = ProxyMode.parse(\"reverse:dns://8.8.8.8\")\n        await dr.dns_request(f)\n        assert not f.response\n\n\nclass DummyLoop:\n    async def getnameinfo(self, socketaddr: Address, flags: int = 0):\n        assert flags == socket.NI_NAMEREQD\n        if socketaddr[0] in (\"8.8.8.8\", \"2001:4860:4860::8888\"):\n            return (\"dns.google\", \"\")\n        e = socket.gaierror()\n        e.errno = socket.EAI_NONAME\n        raise e\n\n    async def getaddrinfo(self, host: str, port: int, *, family: int, type: int):\n        e = socket.gaierror()\n        e.errno = socket.EAI_NONAME\n        if family == socket.AF_INET:\n            if host == \"dns.google\":\n                return [(socket.AF_INET, type, None, None, (\"8.8.8.8\", port))]\n        elif family == socket.AF_INET6:\n            if host == \"dns.google\":\n                return [\n                    (\n                        socket.AF_INET6,\n                        type,\n                        None,\n                        None,\n                        (\"2001:4860:4860::8888\", port, None, None),\n                    )\n                ]\n        else:\n            e.errno = socket.EAI_FAMILY\n        raise e\n\n\nasync def test_resolve():\n    async def fail_with(question: dns.Question, code: int):\n        with pytest.raises(dns_resolver.ResolveError) as ex:\n            await dns_resolver.resolve_question(question, DummyLoop())\n        assert ex.value.response_code == code\n\n    async def succeed_with(\n        question: dns.Question, check: Callable[[dns.ResourceRecord], bool]\n    ):\n        assert any(\n            map(check, await dns_resolver.resolve_question(question, DummyLoop()))\n        )\n\n    await fail_with(\n        dns.Question(\"dns.google\", dns.types.A, dns.classes.CH),\n        dns.response_codes.NOTIMP,\n    )\n    await fail_with(\n        dns.Question(\"not.exists\", dns.types.A, dns.classes.IN),\n        dns.response_codes.NXDOMAIN,\n    )\n    await fail_with(\n        dns.Question(\"dns.google\", dns.types.SOA, dns.classes.IN),\n        dns.response_codes.NOTIMP,\n    )\n    await fail_with(\n        dns.Question(\"totally.invalid\", dns.types.PTR, dns.classes.IN),\n        dns.response_codes.FORMERR,\n    )\n    await fail_with(\n        dns.Question(\"invalid.in-addr.arpa\", dns.types.PTR, dns.classes.IN),\n        dns.response_codes.FORMERR,\n    )\n    await fail_with(\n        dns.Question(\"0.0.0.1.in-addr.arpa\", dns.types.PTR, dns.classes.IN),\n        dns.response_codes.NXDOMAIN,\n    )\n\n    await succeed_with(\n        dns.Question(\"dns.google\", dns.types.A, dns.classes.IN),\n        lambda rr: rr.ipv4_address == ipaddress.IPv4Address(\"8.8.8.8\"),\n    )\n    await succeed_with(\n        dns.Question(\"dns.google\", dns.types.AAAA, dns.classes.IN),\n        lambda rr: rr.ipv6_address == ipaddress.IPv6Address(\"2001:4860:4860::8888\"),\n    )\n    await succeed_with(\n        dns.Question(\"8.8.8.8.in-addr.arpa\", dns.types.PTR, dns.classes.IN),\n        lambda rr: rr.domain_name == \"dns.google\",\n    )\n    await succeed_with(\n        dns.Question(\n            \"8.8.8.8.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.6.8.4.0.6.8.4.1.0.0.2.ip6.arpa\",\n            dns.types.PTR,\n            dns.classes.IN,\n        ),\n        lambda rr: rr.domain_name == \"dns.google\",\n    )\n\n    req = tutils.tdnsreq()\n    req.query = False\n    assert (\n        await dns_resolver.resolve_message(req, DummyLoop())\n    ).response_code == dns.response_codes.REFUSED\n    req.query = True\n    req.op_code = dns.op_codes.IQUERY\n    assert (\n        await dns_resolver.resolve_message(req, DummyLoop())\n    ).response_code == dns.response_codes.NOTIMP\n    req.op_code = dns.op_codes.QUERY\n    resp = await dns_resolver.resolve_message(req, DummyLoop())\n    assert resp.response_code == dns.response_codes.NOERROR\n    assert filter(lambda rr: str(rr.ipv4_address) == \"8.8.8.8\", resp.answers)\n", "test/mitmproxy/addons/test_errorcheck.py": "import logging\n\nimport pytest\n\nfrom mitmproxy.addons.errorcheck import ErrorCheck\nfrom mitmproxy.tools import main\n\n\n@pytest.mark.parametrize(\"run_main\", [main.mitmdump, main.mitmproxy])\ndef test_errorcheck(tdata, capsys, run_main):\n    \"\"\"Integration test: Make sure that we catch errors on startup an exit.\"\"\"\n    with pytest.raises(SystemExit):\n        run_main(\n            [\n                \"-n\",\n                \"-s\",\n                tdata.path(\"mitmproxy/data/addonscripts/load_error.py\"),\n            ]\n        )\n    assert \"Error logged during startup\" in capsys.readouterr().err\n\n\nasync def test_no_error():\n    e = ErrorCheck()\n    await e.shutdown_if_errored()\n    e.finish()\n\n\nasync def test_error_message(capsys):\n    e = ErrorCheck()\n    logging.error(\"wat\")\n    logging.error(\"wat\")\n    with pytest.raises(SystemExit):\n        await e.shutdown_if_errored()\n    assert \"Errors logged during startup, exiting...\" in capsys.readouterr().err\n\n\nasync def test_repeat_error_on_stderr(capsys):\n    e = ErrorCheck(repeat_errors_on_stderr=True)\n    logging.error(\"wat\")\n    with pytest.raises(SystemExit):\n        await e.shutdown_if_errored()\n    assert \"Error logged during startup:\\nwat\" in capsys.readouterr().err\n", "test/mitmproxy/addons/test_asgiapp.py": "import asyncio\nimport json\n\nimport flask\nfrom flask import request\n\nfrom mitmproxy.addons import asgiapp\nfrom mitmproxy.addons import next_layer\nfrom mitmproxy.addons.proxyserver import Proxyserver\nfrom mitmproxy.test import taddons\n\ntapp = flask.Flask(__name__)\n\n\n@tapp.route(\"/\")\ndef hello():\n    return \"testapp\"\n\n\n@tapp.route(\"/parameters\")\ndef request_check():\n    args = {}\n    for k in request.args.keys():\n        args[k] = request.args[k]\n    return json.dumps(args)\n\n\n@tapp.route(\"/requestbody\", methods=[\"POST\"])\ndef request_body():\n    return json.dumps({\"body\": request.data.decode()})\n\n\n@tapp.route(\"/error\")\ndef error():\n    raise ValueError(\"An exception...\")\n\n\nasync def errapp(scope, receive, send):\n    raise ValueError(\"errapp\")\n\n\nasync def noresponseapp(scope, receive, send):\n    return\n\n\nasync def test_asgi_full(caplog):\n    ps = Proxyserver()\n    addons = [\n        asgiapp.WSGIApp(tapp, \"testapp\", 80),\n        asgiapp.ASGIApp(errapp, \"errapp\", 80),\n        asgiapp.ASGIApp(noresponseapp, \"noresponseapp\", 80),\n    ]\n    with taddons.context(ps, *addons) as tctx:\n        tctx.master.addons.add(next_layer.NextLayer())\n        tctx.configure(ps, listen_host=\"127.0.0.1\", listen_port=0)\n        assert await ps.setup_servers()\n        proxy_addr = (\"127.0.0.1\", ps.listen_addrs()[0][1])\n\n        # We parallelize connection establishment/closure because those operations tend to be slow.\n        [\n            (r1, w1),\n            (r2, w2),\n            (r3, w3),\n            (r4, w4),\n            (r5, w5),\n        ] = await asyncio.gather(\n            asyncio.open_connection(*proxy_addr),\n            asyncio.open_connection(*proxy_addr),\n            asyncio.open_connection(*proxy_addr),\n            asyncio.open_connection(*proxy_addr),\n            asyncio.open_connection(*proxy_addr),\n        )\n\n        req = f\"GET http://testapp:80/ HTTP/1.1\\r\\n\\r\\n\"\n        w1.write(req.encode())\n        header = await r1.readuntil(b\"\\r\\n\\r\\n\")\n        assert header.startswith(b\"HTTP/1.1 200 OK\")\n        body = await r1.readuntil(b\"testapp\")\n        assert body == b\"testapp\"\n\n        req = f\"GET http://testapp:80/parameters?param1=1&param2=2 HTTP/1.1\\r\\n\\r\\n\"\n        w2.write(req.encode())\n        header = await r2.readuntil(b\"\\r\\n\\r\\n\")\n        assert header.startswith(b\"HTTP/1.1 200 OK\")\n        body = await r2.readuntil(b\"}\")\n        assert body == b'{\"param1\": \"1\", \"param2\": \"2\"}'\n\n        req = f\"POST http://testapp:80/requestbody HTTP/1.1\\r\\nContent-Length: 6\\r\\n\\r\\nHello!\"\n        w3.write(req.encode())\n        header = await r3.readuntil(b\"\\r\\n\\r\\n\")\n        assert header.startswith(b\"HTTP/1.1 200 OK\")\n        body = await r3.readuntil(b\"}\")\n        assert body == b'{\"body\": \"Hello!\"}'\n\n        req = f\"GET http://errapp:80/?foo=bar HTTP/1.1\\r\\n\\r\\n\"\n        w4.write(req.encode())\n        header = await r4.readuntil(b\"\\r\\n\\r\\n\")\n        assert header.startswith(b\"HTTP/1.1 500\")\n        body = await r4.readuntil(b\"ASGI Error\")\n        assert body == b\"ASGI Error\"\n        assert \"ValueError\" in caplog.text\n\n        req = f\"GET http://noresponseapp:80/ HTTP/1.1\\r\\n\\r\\n\"\n        w5.write(req.encode())\n        header = await r5.readuntil(b\"\\r\\n\\r\\n\")\n        assert header.startswith(b\"HTTP/1.1 500\")\n        body = await r5.readuntil(b\"ASGI Error\")\n        assert body == b\"ASGI Error\"\n        assert \"no response sent\" in caplog.text\n\n        w1.close()\n        w2.close()\n        w3.close()\n        w4.close()\n        w5.close()\n        await asyncio.gather(\n            w1.wait_closed(),\n            w2.wait_closed(),\n            w3.wait_closed(),\n            w4.wait_closed(),\n            w5.wait_closed(),\n        )\n\n        tctx.configure(ps, server=False)\n        assert await ps.setup_servers()\n", "test/mitmproxy/addons/test_modifyheaders.py": "import pytest\n\nfrom mitmproxy.addons.modifyheaders import ModifyHeaders\nfrom mitmproxy.addons.modifyheaders import parse_modify_spec\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test.tutils import tresp\n\n\ndef test_parse_modify_spec():\n    spec = parse_modify_spec(\"/foo/bar/voing\", True)\n    assert spec.matches.pattern == \"foo\"\n    assert spec.subject == b\"bar\"\n    assert spec.read_replacement() == b\"voing\"\n\n    spec = parse_modify_spec(\"/foo/bar/vo/ing/\", False)\n    assert spec.matches.pattern == \"foo\"\n    assert spec.subject == b\"bar\"\n    assert spec.read_replacement() == b\"vo/ing/\"\n\n    spec = parse_modify_spec(\"/bar/voing\", False)\n    assert spec.matches(tflow.tflow())\n    assert spec.subject == b\"bar\"\n    assert spec.read_replacement() == b\"voing\"\n\n    with pytest.raises(ValueError, match=\"Invalid regular expression\"):\n        parse_modify_spec(\"/[/two\", True)\n\n\nclass TestModifyHeaders:\n    def test_configure(self):\n        mh = ModifyHeaders()\n        with taddons.context(mh) as tctx:\n            with pytest.raises(Exception, match=\"Cannot parse modify_headers\"):\n                tctx.configure(mh, modify_headers=[\"/\"])\n            tctx.configure(mh, modify_headers=[\"/foo/bar/voing\"])\n\n    def test_modify_headers(self):\n        mh = ModifyHeaders()\n        with taddons.context(mh) as tctx:\n            tctx.configure(mh, modify_headers=[\"/~q/one/two\", \"/~s/one/three\"])\n            f = tflow.tflow()\n            f.request.headers[\"one\"] = \"xxx\"\n            mh.request(f)\n            assert f.request.headers[\"one\"] == \"two\"\n\n            f = tflow.tflow(resp=True)\n            f.response.headers[\"one\"] = \"xxx\"\n            mh.response(f)\n            assert f.response.headers[\"one\"] == \"three\"\n\n            tctx.configure(mh, modify_headers=[\"/~s/one/two\", \"/~s/one/three\"])\n            f = tflow.tflow(resp=True)\n            f.request.headers[\"one\"] = \"xxx\"\n            f.response.headers[\"one\"] = \"xxx\"\n            mh.response(f)\n            assert f.response.headers.get_all(\"one\") == [\"two\", \"three\"]\n\n            tctx.configure(mh, modify_headers=[\"/~q/one/two\", \"/~q/one/three\"])\n            f = tflow.tflow()\n            f.request.headers[\"one\"] = \"xxx\"\n            mh.request(f)\n            assert f.request.headers.get_all(\"one\") == [\"two\", \"three\"]\n\n            # test removal of existing headers\n            tctx.configure(mh, modify_headers=[\"/~q/one/\", \"/~s/one/\"])\n            f = tflow.tflow()\n            f.request.headers[\"one\"] = \"xxx\"\n            mh.request(f)\n            assert \"one\" not in f.request.headers\n\n            f = tflow.tflow(resp=True)\n            f.response.headers[\"one\"] = \"xxx\"\n            mh.response(f)\n            assert \"one\" not in f.response.headers\n\n            tctx.configure(mh, modify_headers=[\"/one/\"])\n            f = tflow.tflow()\n            f.request.headers[\"one\"] = \"xxx\"\n            mh.request(f)\n            assert \"one\" not in f.request.headers\n\n            f = tflow.tflow(resp=True)\n            f.response.headers[\"one\"] = \"xxx\"\n            mh.response(f)\n            assert \"one\" not in f.response.headers\n\n            # test modifying a header that is also part of the filter expression\n            # https://github.com/mitmproxy/mitmproxy/issues/4245\n            tctx.configure(\n                mh,\n                modify_headers=[\n                    \"/~hq ^user-agent:.+Mozilla.+$/user-agent/Definitely not Mozilla ;)\"\n                ],\n            )\n            f = tflow.tflow()\n            f.request.headers[\"user-agent\"] = \"Hello, it's me, Mozilla\"\n            mh.request(f)\n            assert \"Definitely not Mozilla ;)\" == f.request.headers[\"user-agent\"]\n\n    @pytest.mark.parametrize(\"take\", [True, False])\n    def test_taken(self, take):\n        mh = ModifyHeaders()\n        with taddons.context(mh) as tctx:\n            tctx.configure(mh, modify_headers=[\"/content-length/42\"])\n            f = tflow.tflow()\n            if take:\n                f.response = tresp()\n            mh.request(f)\n            assert (f.request.headers[\"content-length\"] == \"42\") ^ take\n\n            f = tflow.tflow(resp=True)\n            if take:\n                f.kill()\n            mh.response(f)\n            assert (f.response.headers[\"content-length\"] == \"42\") ^ take\n\n\nclass TestModifyHeadersFile:\n    def test_simple(self, tmpdir):\n        mh = ModifyHeaders()\n        with taddons.context(mh) as tctx:\n            tmpfile = tmpdir.join(\"replacement\")\n            tmpfile.write(\"two\")\n            tctx.configure(mh, modify_headers=[\"/~q/one/@\" + str(tmpfile)])\n            f = tflow.tflow()\n            f.request.headers[\"one\"] = \"xxx\"\n            mh.request(f)\n            assert f.request.headers[\"one\"] == \"two\"\n\n    async def test_nonexistent(self, tmpdir, caplog):\n        mh = ModifyHeaders()\n        with taddons.context(mh) as tctx:\n            with pytest.raises(\n                Exception, match=\"Cannot parse modify_headers .* Invalid file path\"\n            ):\n                tctx.configure(mh, modify_headers=[\"/~q/foo/@nonexistent\"])\n\n            tmpfile = tmpdir.join(\"replacement\")\n            tmpfile.write(\"bar\")\n            tctx.configure(mh, modify_headers=[\"/~q/foo/@\" + str(tmpfile)])\n            tmpfile.remove()\n            f = tflow.tflow()\n            f.request.content = b\"foo\"\n            mh.request(f)\n            assert \"Could not read\" in caplog.text\n", "test/mitmproxy/addons/test_comment.py": "from mitmproxy.addons.comment import Comment\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\ndef test_comment():\n    c = Comment()\n    f = tflow.tflow()\n\n    with taddons.context():\n        c.comment([f], \"foo\")\n\n    assert f.comment == \"foo\"\n", "test/mitmproxy/addons/test_readfile.py": "import asyncio\nimport io\nfrom unittest import mock\n\nimport pytest\n\nimport mitmproxy.io\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import readfile\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\n@pytest.fixture\ndef data():\n    f = io.BytesIO()\n\n    w = mitmproxy.io.FlowWriter(f)\n    flows = [\n        tflow.tflow(resp=True),\n        tflow.tflow(err=True),\n        tflow.ttcpflow(),\n        tflow.ttcpflow(err=True),\n    ]\n    for flow in flows:\n        w.add(flow)\n\n    f.seek(0)\n    return f\n\n\n@pytest.fixture\ndef corrupt_data(data):\n    f = io.BytesIO(data.getvalue())\n    f.seek(0, io.SEEK_END)\n    f.write(b\"qibble\")\n    f.seek(0)\n    return f\n\n\nclass TestReadFile:\n    def test_configure(self):\n        rf = readfile.ReadFile()\n        with taddons.context(rf) as tctx:\n            tctx.configure(rf, readfile_filter=\"~q\")\n            with pytest.raises(Exception, match=\"Invalid filter expression\"):\n                tctx.configure(rf, readfile_filter=\"~~\")\n            tctx.configure(rf, readfile_filter=\"\")\n\n    async def test_read(self, tmpdir, data, corrupt_data, caplog_async):\n        rf = readfile.ReadFile()\n        with taddons.context(rf) as tctx:\n            assert not rf.reading()\n\n            tf = tmpdir.join(\"tfile\")\n\n            load_called = asyncio.Event()\n\n            async def load_flow(*_, **__):\n                load_called.set()\n\n            tctx.master.load_flow = load_flow\n\n            tf.write(data.getvalue())\n            tctx.configure(rf, rfile=str(tf), readfile_filter=\".*\")\n            assert not load_called.is_set()\n            rf.running()\n            await load_called.wait()\n\n            while rf.reading():\n                await asyncio.sleep(0)\n\n            tf.write(corrupt_data.getvalue())\n            tctx.configure(rf, rfile=str(tf))\n            rf.running()\n            await caplog_async.await_log(\"corrupted\")\n\n    async def test_corrupt(self, corrupt_data, caplog_async):\n        rf = readfile.ReadFile()\n        with taddons.context(rf):\n            with pytest.raises(exceptions.FlowReadException):\n                await rf.load_flows(io.BytesIO(b\"qibble\"))\n\n            caplog_async.clear()\n            with pytest.raises(exceptions.FlowReadException):\n                await rf.load_flows(corrupt_data)\n            await caplog_async.await_log(\"file corrupted\")\n\n    async def test_nonexistent_file(self, caplog):\n        rf = readfile.ReadFile()\n        with pytest.raises(exceptions.FlowReadException):\n            await rf.load_flows_from_path(\"nonexistent\")\n        assert \"nonexistent\" in caplog.text\n\n\nclass TestReadFileStdin:\n    @mock.patch(\"sys.stdin\")\n    async def test_stdin(self, stdin, data, corrupt_data):\n        rf = readfile.ReadFileStdin()\n        with taddons.context(rf):\n            with mock.patch(\"mitmproxy.master.Master.load_flow\") as mck:\n                stdin.buffer = data\n                mck.assert_not_awaited()\n                await rf.load_flows(stdin.buffer)\n                mck.assert_awaited()\n\n                stdin.buffer = corrupt_data\n                with pytest.raises(exceptions.FlowReadException):\n                    await rf.load_flows(stdin.buffer)\n\n    async def test_normal(self, tmpdir, data):\n        rf = readfile.ReadFileStdin()\n        with taddons.context(rf) as tctx:\n            tf = tmpdir.join(\"tfile\")\n            with mock.patch(\"mitmproxy.master.Master.load_flow\") as mck:\n                tf.write(data.getvalue())\n                tctx.configure(rf, rfile=str(tf))\n                mck.assert_not_awaited()\n                rf.running()\n                await asyncio.sleep(0)\n                mck.assert_awaited()\n", "test/mitmproxy/addons/test_serverplayback.py": "import urllib\n\nimport pytest\n\nimport mitmproxy.test.tutils\nfrom mitmproxy import exceptions\nfrom mitmproxy import io\nfrom mitmproxy.addons import serverplayback\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\ndef tdump(path, flows):\n    with open(path, \"wb\") as f:\n        w = io.FlowWriter(f)\n        for i in flows:\n            w.add(i)\n\n\ndef test_load_file(tmpdir):\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s):\n        fpath = str(tmpdir.join(\"flows\"))\n        tdump(fpath, [tflow.tflow(resp=True)])\n        s.load_file(fpath)\n        assert s.flowmap\n        with pytest.raises(exceptions.CommandError):\n            s.load_file(\"/nonexistent\")\n\n\ndef test_config(tmpdir):\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        fpath = str(tmpdir.join(\"flows\"))\n        tdump(fpath, [tflow.tflow(resp=True)])\n        tctx.configure(s, server_replay=[fpath])\n        s.configured = False\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(s, server_replay=[str(tmpdir)])\n\n\ndef test_server_playback():\n    sp = serverplayback.ServerPlayback()\n    with taddons.context(sp) as tctx:\n        tctx.configure(sp)\n        f = tflow.tflow(resp=True)\n\n        assert not sp.flowmap\n\n        sp.load_flows([f])\n        assert sp.flowmap\n        assert sp.next_flow(f)\n        assert not sp.flowmap\n\n        sp.load_flows([f])\n        assert sp.flowmap\n        sp.clear()\n        assert not sp.flowmap\n\n\ndef test_add_flows():\n    sp = serverplayback.ServerPlayback()\n    with taddons.context(sp) as tctx:\n        tctx.configure(sp)\n        f1 = tflow.tflow(resp=True)\n        f2 = tflow.tflow(resp=True)\n\n        sp.load_flows([f1])\n        sp.add_flows([f2])\n\n        assert sp.next_flow(f1)\n        assert sp.flowmap\n        assert sp.next_flow(f2)\n        assert not sp.flowmap\n\n        sp.add_flows([f1])\n        assert sp.flowmap\n        assert sp.next_flow(f1)\n        assert not sp.flowmap\n\n\ndef test_ignore_host():\n    sp = serverplayback.ServerPlayback()\n    with taddons.context(sp) as tctx:\n        tctx.configure(sp, server_replay_ignore_host=True)\n\n        r = tflow.tflow(resp=True)\n        r2 = tflow.tflow(resp=True)\n\n        r.request.host = \"address\"\n        r2.request.host = \"address\"\n        assert sp._hash(r) == sp._hash(r2)\n        r2.request.host = \"wrong_address\"\n        assert sp._hash(r) == sp._hash(r2)\n\n\ndef test_ignore_content():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(s, server_replay_ignore_content=False)\n\n        r = tflow.tflow(resp=True)\n        r2 = tflow.tflow(resp=True)\n\n        r.request.content = b\"foo\"\n        r2.request.content = b\"foo\"\n        assert s._hash(r) == s._hash(r2)\n        r2.request.content = b\"bar\"\n        assert not s._hash(r) == s._hash(r2)\n\n        tctx.configure(s, server_replay_ignore_content=True)\n        r = tflow.tflow(resp=True)\n        r2 = tflow.tflow(resp=True)\n        r.request.content = b\"foo\"\n        r2.request.content = b\"foo\"\n        assert s._hash(r) == s._hash(r2)\n        r2.request.content = b\"bar\"\n        assert s._hash(r) == s._hash(r2)\n        r2.request.content = b\"\"\n        assert s._hash(r) == s._hash(r2)\n        r2.request.content = None\n        assert s._hash(r) == s._hash(r2)\n\n\ndef test_ignore_content_wins_over_params():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(\n            s,\n            server_replay_ignore_content=True,\n            server_replay_ignore_payload_params=[\"param1\", \"param2\"],\n        )\n\n        # NOTE: parameters are mutually exclusive in options\n        r = tflow.tflow(resp=True)\n        r.request.headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n        r.request.content = b\"paramx=y\"\n\n        r2 = tflow.tflow(resp=True)\n        r2.request.headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n        r2.request.content = b\"paramx=x\"\n\n        # same parameters\n        assert s._hash(r) == s._hash(r2)\n\n\ndef test_ignore_payload_params_other_content_type():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(\n            s,\n            server_replay_ignore_content=False,\n            server_replay_ignore_payload_params=[\"param1\", \"param2\"],\n        )\n\n        r = tflow.tflow(resp=True)\n        r.request.headers[\"Content-Type\"] = \"application/json\"\n        r.request.content = b'{\"param1\":\"1\"}'\n        r2 = tflow.tflow(resp=True)\n        r2.request.headers[\"Content-Type\"] = \"application/json\"\n        r2.request.content = b'{\"param1\":\"1\"}'\n        # same content\n        assert s._hash(r) == s._hash(r2)\n        # distint content (note only x-www-form-urlencoded payload is analysed)\n        r2.request.content = b'{\"param1\":\"2\"}'\n        assert not s._hash(r) == s._hash(r2)\n\n\ndef test_hash():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(s)\n\n        r = tflow.tflow()\n        r2 = tflow.tflow()\n\n        assert s._hash(r)\n        assert s._hash(r) == s._hash(r2)\n        r.request.headers[\"foo\"] = \"bar\"\n        assert s._hash(r) == s._hash(r2)\n        r.request.path = \"voing\"\n        assert s._hash(r) != s._hash(r2)\n\n        r.request.path = \"path?blank_value\"\n        r2.request.path = \"path?\"\n        assert s._hash(r) != s._hash(r2)\n\n\ndef test_headers():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(s, server_replay_use_headers=[\"foo\"])\n\n        r = tflow.tflow(resp=True)\n        r.request.headers[\"foo\"] = \"bar\"\n        r2 = tflow.tflow(resp=True)\n        assert not s._hash(r) == s._hash(r2)\n        r2.request.headers[\"foo\"] = \"bar\"\n        assert s._hash(r) == s._hash(r2)\n        r2.request.headers[\"oink\"] = \"bar\"\n        assert s._hash(r) == s._hash(r2)\n\n        r = tflow.tflow(resp=True)\n        r2 = tflow.tflow(resp=True)\n        assert s._hash(r) == s._hash(r2)\n\n\ndef test_load():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(s)\n\n        r = tflow.tflow(resp=True)\n        r.request.headers[\"key\"] = \"one\"\n\n        r2 = tflow.tflow(resp=True)\n        r2.request.headers[\"key\"] = \"two\"\n\n        s.load_flows([r, r2])\n\n        assert s.count() == 2\n\n        n = s.next_flow(r)\n        assert n.request.headers[\"key\"] == \"one\"\n        assert s.count() == 1\n\n        n = s.next_flow(r)\n        assert n.request.headers[\"key\"] == \"two\"\n        assert not s.flowmap\n        assert s.count() == 0\n\n        assert not s.next_flow(r)\n\n\ndef test_load_with_server_replay_reuse():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(s, server_replay_reuse=True)\n\n        r = tflow.tflow(resp=True)\n        r.request.headers[\"key\"] = \"one\"\n\n        r2 = tflow.tflow(resp=True)\n        r2.request.headers[\"key\"] = \"two\"\n\n        s.load_flows([r, r2])\n\n        assert s.count() == 2\n        s.next_flow(r)\n        assert s.count() == 2\n\n\ndef test_ignore_params():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(s, server_replay_ignore_params=[\"param1\", \"param2\"])\n\n        r = tflow.tflow(resp=True)\n        r.request.path = \"/test?param1=1\"\n        r2 = tflow.tflow(resp=True)\n        r2.request.path = \"/test\"\n        assert s._hash(r) == s._hash(r2)\n        r2.request.path = \"/test?param1=2\"\n        assert s._hash(r) == s._hash(r2)\n        r2.request.path = \"/test?param2=1\"\n        assert s._hash(r) == s._hash(r2)\n        r2.request.path = \"/test?param3=2\"\n        assert not s._hash(r) == s._hash(r2)\n\n\ndef thash(r, r2, setter):\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        s = serverplayback.ServerPlayback()\n        tctx.configure(s, server_replay_ignore_payload_params=[\"param1\", \"param2\"])\n\n        setter(r, paramx=\"x\", param1=\"1\")\n\n        setter(r2, paramx=\"x\", param1=\"1\")\n        # same parameters\n        assert s._hash(r) == s._hash(r2)\n        # ignored parameters !=\n        setter(r2, paramx=\"x\", param1=\"2\")\n        assert s._hash(r) == s._hash(r2)\n        # missing parameter\n        setter(r2, paramx=\"x\")\n        assert s._hash(r) == s._hash(r2)\n        # ignorable parameter added\n        setter(r2, paramx=\"x\", param1=\"2\")\n        assert s._hash(r) == s._hash(r2)\n        # not ignorable parameter changed\n        setter(r2, paramx=\"y\", param1=\"1\")\n        assert not s._hash(r) == s._hash(r2)\n        # not ignorable parameter missing\n        setter(r2, param1=\"1\")\n        r2.request.content = b\"param1=1\"\n        assert not s._hash(r) == s._hash(r2)\n\n\ndef test_ignore_payload_params():\n    def urlencode_setter(r, **kwargs):\n        r.request.content = urllib.parse.urlencode(kwargs).encode()\n\n    r = tflow.tflow(resp=True)\n    r.request.headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n    r2 = tflow.tflow(resp=True)\n    r2.request.headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n    thash(r, r2, urlencode_setter)\n\n    boundary = \"somefancyboundary\"\n\n    def multipart_setter(r, **kwargs):\n        b = f\"--{boundary}\\n\"\n        parts = []\n        for k, v in kwargs.items():\n            parts.append(\n                'Content-Disposition: form-data; name=\"%s\"\\n\\n' \"%s\\n\" % (k, v)\n            )\n        c = b + b.join(parts) + b\n        r.request.content = c.encode()\n        r.request.headers[\"content-type\"] = \"multipart/form-data; boundary=\" + boundary\n\n    r = tflow.tflow(resp=True)\n    r2 = tflow.tflow(resp=True)\n    thash(r, r2, multipart_setter)\n\n\ndef test_runtime_modify_params():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        r = tflow.tflow(resp=True)\n        r.request.path = \"/test?param1=1\"\n        r2 = tflow.tflow(resp=True)\n        r2.request.path = \"/test\"\n\n        s.load_flows([r])\n        hash = next(iter(s.flowmap.keys()))\n\n        tctx.configure(s, server_replay_ignore_params=[\"param1\"])\n        hash_mod = next(iter(s.flowmap.keys()))\n\n        assert hash != hash_mod\n        assert hash_mod == s._hash(r2)\n\n\ndef test_server_playback_full():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(\n            s,\n            server_replay_refresh=True,\n        )\n\n        f = tflow.tflow()\n        f.response = mitmproxy.test.tutils.tresp(content=f.request.content)\n        s.load_flows([f, f])\n\n        tf = tflow.tflow()\n        assert not tf.response\n        s.request(tf)\n        assert tf.response.data == f.response.data\n\n        tf = tflow.tflow()\n        tf.request.content = b\"gibble\"\n        assert not tf.response\n        s.request(tf)\n        assert not tf.response\n\n\nasync def test_server_playback_kill():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(s, server_replay_refresh=True, server_replay_kill_extra=True)\n\n        f = tflow.tflow()\n        f.response = mitmproxy.test.tutils.tresp(content=f.request.content)\n        s.load_flows([f])\n\n        f = tflow.tflow()\n        f.request.host = \"nonexistent\"\n        await tctx.cycle(s, f)\n        assert f.error\n\n\nasync def test_server_playback_kill_new_option():\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(s, server_replay_refresh=True, server_replay_extra=\"kill\")\n\n        f = tflow.tflow()\n        f.response = mitmproxy.test.tutils.tresp(content=f.request.content)\n        s.load_flows([f])\n\n        f = tflow.tflow()\n        f.request.host = \"nonexistent\"\n        await tctx.cycle(s, f)\n        assert f.error\n\n\n@pytest.mark.parametrize(\n    \"option,status\",\n    [\n        (\"204\", 204),\n        (\"400\", 400),\n        (\"404\", 404),\n        (\"500\", 500),\n    ],\n)\nasync def test_server_playback_404(option, status):\n    s = serverplayback.ServerPlayback()\n    with taddons.context(s) as tctx:\n        tctx.configure(s, server_replay_refresh=True, server_replay_extra=option)\n\n        f = tflow.tflow()\n        f.response = mitmproxy.test.tutils.tresp(content=f.request.content)\n        s.load_flows([f])\n\n        f = tflow.tflow()\n        f.request.host = \"nonexistent\"\n        s.request(f)\n        assert f.response.status_code == status\n\n\ndef test_server_playback_response_deleted():\n    \"\"\"\n    The server playback addon holds references to flows that can be modified by the user in the meantime.\n    One thing that can happen is that users remove the response object. This happens for example when doing a client\n    replay at the same time.\n    \"\"\"\n    sp = serverplayback.ServerPlayback()\n    with taddons.context(sp) as tctx:\n        tctx.configure(sp)\n        f1 = tflow.tflow(resp=True)\n        f2 = tflow.tflow(resp=True)\n\n        assert not sp.flowmap\n\n        sp.load_flows([f1, f2])\n        assert sp.flowmap\n\n        f1.response = f2.response = None\n        assert not sp.next_flow(f1)\n        assert not sp.flowmap\n", "test/mitmproxy/addons/test_modifybody.py": "import pytest\n\nfrom mitmproxy.addons import modifybody\nfrom mitmproxy.addons import proxyserver\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test.tutils import tresp\n\n\nclass TestModifyBody:\n    def test_configure(self):\n        mb = modifybody.ModifyBody()\n        with taddons.context(mb) as tctx:\n            tctx.configure(mb, modify_body=[\"one/two/three\"])\n            with pytest.raises(Exception, match=\"Cannot parse modify_body\"):\n                tctx.configure(mb, modify_body=[\"/\"])\n\n    def test_warn_conflict(self, caplog):\n        caplog.set_level(\"DEBUG\")\n        mb = modifybody.ModifyBody()\n        with taddons.context(mb, proxyserver.Proxyserver()) as tctx:\n            tctx.configure(mb, stream_large_bodies=\"3m\", modify_body=[\"one/two/three\"])\n            assert \"Streamed bodies will not be modified\" in caplog.text\n\n    def test_simple(self):\n        mb = modifybody.ModifyBody()\n        with taddons.context(mb) as tctx:\n            tctx.configure(\n                mb,\n                modify_body=[\n                    \"/~q/foo/bar\",\n                    \"/~s/foo/bar\",\n                ],\n            )\n            f = tflow.tflow()\n            f.request.content = b\"foo\"\n            mb.request(f)\n            assert f.request.content == b\"bar\"\n\n            f = tflow.tflow(resp=True)\n            f.response.content = b\"foo\"\n            mb.response(f)\n            assert f.response.content == b\"bar\"\n\n    @pytest.mark.parametrize(\"take\", [True, False])\n    def test_taken(self, take):\n        mb = modifybody.ModifyBody()\n        with taddons.context(mb) as tctx:\n            tctx.configure(mb, modify_body=[\"/foo/bar\"])\n            f = tflow.tflow()\n            f.request.content = b\"foo\"\n            if take:\n                f.response = tresp()\n            mb.request(f)\n            assert (f.request.content == b\"bar\") ^ take\n\n            f = tflow.tflow(resp=True)\n            f.response.content = b\"foo\"\n            if take:\n                f.kill()\n            mb.response(f)\n            assert (f.response.content == b\"bar\") ^ take\n\n    def test_order(self):\n        mb = modifybody.ModifyBody()\n        with taddons.context(mb) as tctx:\n            tctx.configure(\n                mb,\n                modify_body=[\n                    \"/foo/bar\",\n                    \"/bar/baz\",\n                    \"/foo/oh noes!\",\n                    \"/bar/oh noes!\",\n                ],\n            )\n            f = tflow.tflow()\n            f.request.content = b\"foo\"\n            mb.request(f)\n            assert f.request.content == b\"baz\"\n\n\nclass TestModifyBodyFile:\n    def test_simple(self, tmpdir):\n        mb = modifybody.ModifyBody()\n        with taddons.context(mb) as tctx:\n            tmpfile = tmpdir.join(\"replacement\")\n            tmpfile.write(\"bar\")\n            tctx.configure(mb, modify_body=[\"/~q/foo/@\" + str(tmpfile)])\n            f = tflow.tflow()\n            f.request.content = b\"foo\"\n            mb.request(f)\n            assert f.request.content == b\"bar\"\n\n    async def test_nonexistent(self, tmpdir, caplog):\n        mb = modifybody.ModifyBody()\n        with taddons.context(mb) as tctx:\n            with pytest.raises(Exception, match=\"Invalid file path\"):\n                tctx.configure(mb, modify_body=[\"/~q/foo/@nonexistent\"])\n\n            tmpfile = tmpdir.join(\"replacement\")\n            tmpfile.write(\"bar\")\n            tctx.configure(mb, modify_body=[\"/~q/foo/@\" + str(tmpfile)])\n            tmpfile.remove()\n            f = tflow.tflow()\n            f.request.content = b\"foo\"\n            mb.request(f)\n            assert \"Could not read\" in caplog.text\n", "test/mitmproxy/addons/test_keepserving.py": "import asyncio\n\nfrom mitmproxy import command\nfrom mitmproxy.addons import keepserving\nfrom mitmproxy.test import taddons\n\n\nclass Dummy:\n    def __init__(self, val: bool):\n        self.val = val\n\n    def load(self, loader):\n        loader.add_option(\"client_replay\", bool, self.val, \"test\")\n        loader.add_option(\"server_replay\", bool, self.val, \"test\")\n        loader.add_option(\"rfile\", bool, self.val, \"test\")\n\n    @command.command(\"readfile.reading\")\n    def readfile(self) -> bool:\n        return self.val\n\n    @command.command(\"replay.client.count\")\n    def creplay(self) -> int:\n        return 1 if self.val else 0\n\n    @command.command(\"replay.server.count\")\n    def sreplay(self) -> int:\n        return 1 if self.val else 0\n\n\nclass TKS(keepserving.KeepServing):\n    _is_shutdown = False\n\n    def shutdown(self):\n        self.is_shutdown = True\n\n\nasync def test_keepserving():\n    ks = TKS()\n    d = Dummy(True)\n    with taddons.context(ks) as tctx:\n        tctx.master.addons.add(d)\n        ks.running()\n        assert ks.keepgoing()\n\n        d.val = False\n        assert not ks.keepgoing()\n        await asyncio.sleep(0.3)\n        assert ks.is_shutdown\n", "test/mitmproxy/addons/test_browser.py": "from unittest import mock\n\nfrom mitmproxy.addons import browser\nfrom mitmproxy.test import taddons\n\n\ndef test_browser(caplog):\n    caplog.set_level(\"INFO\")\n    with (\n        mock.patch(\"subprocess.Popen\") as po,\n        mock.patch(\"shutil.which\") as which,\n        taddons.context(),\n    ):\n        which.return_value = \"chrome\"\n        b = browser.Browser()\n        b.start()\n        assert po.called\n\n        b.start()\n        assert \"Starting additional browser\" in caplog.text\n        assert len(b.browser) == 2\n        b.done()\n        assert not b.browser\n\n\nasync def test_no_browser(caplog):\n    caplog.set_level(\"INFO\")\n    with mock.patch(\"shutil.which\") as which:\n        which.return_value = False\n\n        b = browser.Browser()\n        b.start()\n        assert \"platform is not supported\" in caplog.text\n\n\nasync def test_get_browser_cmd_executable():\n    with mock.patch(\"shutil.which\") as which:\n        which.side_effect = lambda cmd: cmd == \"chrome\"\n        assert browser.get_browser_cmd() == [\"chrome\"]\n\n\nasync def test_get_browser_cmd_no_executable():\n    with mock.patch(\"shutil.which\") as which:\n        which.return_value = False\n        assert browser.get_browser_cmd() is None\n\n\nasync def test_get_browser_cmd_flatpak():\n    def subprocess_run_mock(cmd, **kwargs):\n        returncode = 0 if cmd == [\"flatpak\", \"info\", \"com.google.Chrome\"] else 1\n        return mock.Mock(returncode=returncode)\n\n    with (\n        mock.patch(\"shutil.which\") as which,\n        mock.patch(\"subprocess.run\") as subprocess_run,\n    ):\n        which.side_effect = lambda cmd: cmd == \"flatpak\"\n        subprocess_run.side_effect = subprocess_run_mock\n        assert browser.get_browser_cmd() == [\n            \"flatpak\",\n            \"run\",\n            \"-p\",\n            \"com.google.Chrome\",\n        ]\n\n\nasync def test_get_browser_cmd_no_flatpak():\n    with (\n        mock.patch(\"shutil.which\") as which,\n        mock.patch(\"subprocess.run\") as subprocess_run,\n    ):\n        which.side_effect = lambda cmd: cmd == \"flatpak\"\n        subprocess_run.return_value = mock.Mock(returncode=1)\n        assert browser.get_browser_cmd() is None\n", "test/mitmproxy/addons/test_strip_ech.py": "from mitmproxy import dns\nfrom mitmproxy.addons import strip_ech\nfrom mitmproxy.net.dns import https_records\nfrom mitmproxy.net.dns import types\nfrom mitmproxy.net.dns.https_records import SVCParamKeys\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nclass TestStripECH:\n    def test_simple(self):\n        se = strip_ech.StripECH()\n        with taddons.context(se) as tctx:\n            params1 = {\n                SVCParamKeys.PORT.value: b\"\\x01\\xbb\",\n                SVCParamKeys.ECH.value: b\"testbytes\",\n            }\n            params2 = {SVCParamKeys.PORT.value: b\"\\x01\\xbb\"}\n            record1 = https_records.HTTPSRecord(1, \"example.com\", params1)\n            record2 = https_records.HTTPSRecord(1, \"example.com\", params2)\n            answers = [\n                dns.ResourceRecord(\n                    \"dns.google\",\n                    dns.types.A,\n                    dns.classes.IN,\n                    32,\n                    b\"\\x08\\x08\\x08\\x08\",\n                ),\n                dns.ResourceRecord(\n                    \"dns.google\",\n                    dns.types.HTTPS,\n                    dns.classes.IN,\n                    32,\n                    https_records.pack(record1),\n                ),\n                dns.ResourceRecord(\n                    \"dns.google\",\n                    dns.types.HTTPS,\n                    dns.classes.IN,\n                    32,\n                    https_records.pack(record2),\n                ),\n            ]\n            resp = tutils.tdnsresp(answers=answers)\n            f = tflow.tdnsflow(resp=resp)\n            tctx.configure(se, strip_ech=True)\n            se.dns_response(f)\n            assert all(\n                answer.https_ech is None\n                for answer in f.response.answers\n                if answer.type == types.HTTPS\n            )\n", "test/mitmproxy/addons/test_blocklist.py": "import pytest\n\nfrom mitmproxy.addons import blocklist\nfrom mitmproxy.exceptions import OptionsError\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\n@pytest.mark.parametrize(\n    \"filter,err\",\n    [\n        (\"/~u index.html/TOOMANY/300\", \"Invalid number of parameters\"),\n        (\":~d ~d ~d:200\", \"Invalid filter\"),\n        (\"/~u index.html/999\", \"Invalid HTTP status code\"),\n        (\"/~u index.html/abc\", \"Invalid HTTP status code\"),\n    ],\n)\ndef test_parse_spec_err(filter, err):\n    with pytest.raises(ValueError, match=err):\n        blocklist.parse_spec(filter)\n\n\nclass TestBlockList:\n    @pytest.mark.parametrize(\n        \"filter,request_url,status_code\",\n        [\n            (\":~u example.org:404\", b\"https://example.org/images/test.jpg\", 404),\n            (\":~u example.com:404\", b\"https://example.org/images/test.jpg\", None),\n            (\":~u test:404\", b\"https://example.org/images/TEST.jpg\", 404),\n            (\"/!jpg/418\", b\"https://example.org/images/test.jpg\", None),\n            (\"/!png/418\", b\"https://example.org/images/test.jpg\", 418),\n        ],\n    )\n    def test_block(self, filter, request_url, status_code):\n        bl = blocklist.BlockList()\n        with taddons.context(bl) as tctx:\n            tctx.configure(bl, block_list=[filter])\n            f = tflow.tflow()\n            f.request.url = request_url\n            bl.request(f)\n            if status_code is not None:\n                assert f.response.status_code == status_code\n                assert f.metadata[\"blocklisted\"]\n            else:\n                assert not f.response\n\n    def test_special_kill_status_closes_connection(self):\n        bl = blocklist.BlockList()\n        with taddons.context(bl) as tctx:\n            tctx.configure(bl, block_list=[\":.*:444\"])\n            f = tflow.tflow()\n            bl.request(f)\n            assert f.error.msg == f.error.KILLED_MESSAGE\n            assert f.response is None\n            assert f.metadata[\"blocklisted\"] is True\n\n    def test_already_handled(self):\n        \"\"\"Test that we don't interfere if another addon already killed this request.\"\"\"\n        bl = blocklist.BlockList()\n        with taddons.context(bl) as tctx:\n            tctx.configure(bl, block_list=[\"/.*/404\"])\n            f = tflow.tflow()\n            f.kill()  # done by another addon.\n            bl.request(f)\n            assert not f.response\n\n    def test_configure_err(self):\n        bl = blocklist.BlockList()\n        with taddons.context(bl) as tctx:\n            with pytest.raises(OptionsError):\n                tctx.configure(bl, block_list=[\"lalelu\"])\n", "test/mitmproxy/addons/test_cut.py": "from unittest import mock\n\nimport pyperclip\nimport pytest\n\nfrom mitmproxy import certs\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import cut\nfrom mitmproxy.addons import view\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\ndef test_extract(tdata):\n    tf = tflow.tflow(resp=True)\n    tests = [\n        [\"request.method\", \"GET\"],\n        [\"request.scheme\", \"http\"],\n        [\"request.host\", \"address\"],\n        [\"request.http_version\", \"HTTP/1.1\"],\n        [\"request.port\", \"22\"],\n        [\"request.path\", \"/path\"],\n        [\"request.url\", \"http://address:22/path\"],\n        [\"request.text\", \"content\"],\n        [\"request.content\", b\"content\"],\n        [\"request.raw_content\", b\"content\"],\n        [\"request.timestamp_start\", \"946681200\"],\n        [\"request.timestamp_end\", \"946681201\"],\n        [\"request.header[header]\", \"qvalue\"],\n        [\"response.status_code\", \"200\"],\n        [\"response.reason\", \"OK\"],\n        [\"response.text\", \"message\"],\n        [\"response.content\", b\"message\"],\n        [\"response.raw_content\", b\"message\"],\n        [\"response.header[header-response]\", \"svalue\"],\n        [\"response.timestamp_start\", \"946681202\"],\n        [\"response.timestamp_end\", \"946681203\"],\n        [\"client_conn.peername.port\", \"22\"],\n        [\"client_conn.peername.host\", \"127.0.0.1\"],\n        [\"client_conn.tls_version\", \"TLSv1.2\"],\n        [\"client_conn.sni\", \"address\"],\n        [\"client_conn.tls_established\", \"true\"],\n        [\"server_conn.address.port\", \"22\"],\n        [\"server_conn.address.host\", \"address\"],\n        [\"server_conn.peername.host\", \"192.168.0.1\"],\n        [\"server_conn.tls_version\", \"TLSv1.2\"],\n        [\"server_conn.sni\", \"address\"],\n        [\"server_conn.tls_established\", \"true\"],\n    ]\n    for spec, expected in tests:\n        ret = cut.extract(spec, tf)\n        assert spec and ret == expected\n\n    with open(tdata.path(\"mitmproxy/net/data/text_cert\"), \"rb\") as f:\n        d = f.read()\n    c1 = certs.Cert.from_pem(d)\n    tf.server_conn.certificate_list = [c1]\n    assert \"CERTIFICATE\" in cut.extract(\"server_conn.certificate_list\", tf)\n\n\ndef test_extract_websocket():\n    tf = tflow.twebsocketflow(messages=True)\n    extracted_request_content = cut.extract(\"request.content\", tf)\n    extracted_response_content = cut.extract(\"response.content\", tf)\n    assert b\"hello binary\" in extracted_request_content\n    assert b\"hello text\" in extracted_request_content\n    assert b\"it's me\" in extracted_request_content\n    assert b\"hello binary\" in extracted_response_content\n    assert b\"hello text\" in extracted_response_content\n    assert b\"it's me\" in extracted_response_content\n\n\ndef test_extract_str():\n    tf = tflow.tflow()\n    tf.request.raw_content = b\"\\xff\"\n    assert cut.extract_str(\"request.raw_content\", tf) == r\"b'\\xff'\"\n\n\ndef test_headername():\n    with pytest.raises(exceptions.CommandError):\n        cut.headername(\"header[foo.\")\n\n\ndef qr(f):\n    with open(f, \"rb\") as fp:\n        return fp.read()\n\n\nasync def test_cut_clip(caplog):\n    v = view.View()\n    c = cut.Cut()\n    with taddons.context() as tctx:\n        tctx.master.addons.add(v, c)\n        v.add([tflow.tflow(resp=True)])\n\n        with mock.patch(\"pyperclip.copy\") as pc:\n            tctx.command(c.clip, \"@all\", \"request.method\")\n            assert pc.called\n\n        with mock.patch(\"pyperclip.copy\") as pc:\n            tctx.command(c.clip, \"@all\", \"request.content\")\n            assert pc.called\n\n        with mock.patch(\"pyperclip.copy\") as pc:\n            tctx.command(c.clip, \"@all\", \"request.method,request.content\")\n            assert pc.called\n\n        with mock.patch(\"pyperclip.copy\") as pc:\n            log_message = (\n                \"Pyperclip could not find a \" \"copy/paste mechanism for your system.\"\n            )\n            pc.side_effect = pyperclip.PyperclipException(log_message)\n            tctx.command(c.clip, \"@all\", \"request.method\")\n            assert log_message in caplog.text\n\n\ndef test_cut_save(tmpdir):\n    f = str(tmpdir.join(\"path\"))\n    v = view.View()\n    c = cut.Cut()\n    with taddons.context() as tctx:\n        tctx.master.addons.add(v, c)\n        v.add([tflow.tflow(resp=True)])\n\n        tctx.command(c.save, \"@all\", \"request.method\", f)\n        assert qr(f) == b\"GET\"\n        tctx.command(c.save, \"@all\", \"request.content\", f)\n        assert qr(f) == b\"content\"\n        tctx.command(c.save, \"@all\", \"request.content\", \"+\" + f)\n        assert qr(f) == b\"content\\ncontent\"\n\n        v.add([tflow.tflow(resp=True)])\n        tctx.command(c.save, \"@all\", \"request.method\", f)\n        assert qr(f).splitlines() == [b\"GET\", b\"GET\"]\n        tctx.command(c.save, \"@all\", \"request.method,request.content\", f)\n        assert qr(f).splitlines() == [b\"GET,b'content'\", b\"GET,b'content'\"]\n\n\n@pytest.mark.parametrize(\n    \"exception, log_message\",\n    [\n        (PermissionError, \"Permission denied\"),\n        (IsADirectoryError, \"Is a directory\"),\n        (FileNotFoundError, \"No such file or directory\"),\n    ],\n)\nasync def test_cut_save_open(exception, log_message, tmpdir, caplog):\n    f = str(tmpdir.join(\"path\"))\n    v = view.View()\n    c = cut.Cut()\n    with taddons.context() as tctx:\n        tctx.master.addons.add(v, c)\n        v.add([tflow.tflow(resp=True)])\n\n        with mock.patch(\"mitmproxy.addons.cut.open\") as m:\n            m.side_effect = exception(log_message)\n            tctx.command(c.save, \"@all\", \"request.method\", f)\n            assert log_message in caplog.text\n\n\ndef test_cut():\n    c = cut.Cut()\n    with taddons.context():\n        tflows = [tflow.tflow(resp=True)]\n        assert c.cut(tflows, [\"request.method\"]) == [[\"GET\"]]\n        assert c.cut(tflows, [\"request.scheme\"]) == [[\"http\"]]\n        assert c.cut(tflows, [\"request.host\"]) == [[\"address\"]]\n        assert c.cut(tflows, [\"request.port\"]) == [[\"22\"]]\n        assert c.cut(tflows, [\"request.path\"]) == [[\"/path\"]]\n        assert c.cut(tflows, [\"request.url\"]) == [[\"http://address:22/path\"]]\n        assert c.cut(tflows, [\"request.content\"]) == [[b\"content\"]]\n        assert c.cut(tflows, [\"request.header[header]\"]) == [[\"qvalue\"]]\n        assert c.cut(tflows, [\"request.header[unknown]\"]) == [[\"\"]]\n\n        assert c.cut(tflows, [\"response.status_code\"]) == [[\"200\"]]\n        assert c.cut(tflows, [\"response.reason\"]) == [[\"OK\"]]\n        assert c.cut(tflows, [\"response.content\"]) == [[b\"message\"]]\n        assert c.cut(tflows, [\"response.header[header-response]\"]) == [[\"svalue\"]]\n        assert c.cut(tflows, [\"moo\"]) == [[\"\"]]\n        with pytest.raises(exceptions.CommandError):\n            assert c.cut(tflows, [\"__dict__\"]) == [[\"\"]]\n\n    with taddons.context():\n        tflows = [tflow.tflow(resp=False)]\n        assert c.cut(tflows, [\"response.reason\"]) == [[\"\"]]\n        assert c.cut(tflows, [\"response.header[key]\"]) == [[\"\"]]\n\n    for f in (tflow.ttcpflow(), tflow.tudpflow()):\n        c = cut.Cut()\n        with taddons.context():\n            tflows = [f]\n            assert c.cut(tflows, [\"request.method\"]) == [[\"\"]]\n            assert c.cut(tflows, [\"response.status\"]) == [[\"\"]]\n", "test/mitmproxy/addons/test_maplocal.py": "import sys\nfrom pathlib import Path\n\nimport pytest\n\nfrom mitmproxy.addons.maplocal import file_candidates\nfrom mitmproxy.addons.maplocal import MapLocal\nfrom mitmproxy.addons.maplocal import MapLocalSpec\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.utils.spec import parse_spec\n\n\n@pytest.mark.parametrize(\n    \"url,spec,expected_candidates\",\n    [\n        # trailing slashes\n        (\"https://example.com/foo\", \":example.com/foo:/tmp\", [\"/tmp/index.html\"]),\n        (\"https://example.com/foo/\", \":example.com/foo:/tmp\", [\"/tmp/index.html\"]),\n        (\"https://example.com/foo\", \":example.com/foo:/tmp/\", [\"/tmp/index.html\"]),\n    ]\n    + [\n        # simple prefixes\n        (\n            \"http://example.com/foo/bar.jpg\",\n            \":example.com/foo:/tmp\",\n            [\"/tmp/bar.jpg\", \"/tmp/bar.jpg/index.html\"],\n        ),\n        (\n            \"https://example.com/foo/bar.jpg\",\n            \":example.com/foo:/tmp\",\n            [\"/tmp/bar.jpg\", \"/tmp/bar.jpg/index.html\"],\n        ),\n        (\n            \"https://example.com/foo/bar.jpg?query\",\n            \":example.com/foo:/tmp\",\n            [\"/tmp/bar.jpg\", \"/tmp/bar.jpg/index.html\"],\n        ),\n        (\n            \"https://example.com/foo/bar/baz.jpg\",\n            \":example.com/foo:/tmp\",\n            [\"/tmp/bar/baz.jpg\", \"/tmp/bar/baz.jpg/index.html\"],\n        ),\n        (\"https://example.com/foo/bar.jpg\", \":/foo/bar.jpg:/tmp\", [\"/tmp/index.html\"]),\n    ]\n    + [\n        # URL decode and special characters\n        (\n            \"http://example.com/foo%20bar.jpg\",\n            \":example.com:/tmp\",\n            [\n                \"/tmp/foo bar.jpg\",\n                \"/tmp/foo bar.jpg/index.html\",\n                \"/tmp/foo_bar.jpg\",\n                \"/tmp/foo_bar.jpg/index.html\",\n            ],\n        ),\n        (\n            \"http://example.com/f\u00f3ob\u00e5r.jpg\",\n            \":example.com:/tmp\",\n            [\n                \"/tmp/f\u00f3ob\u00e5r.jpg\",\n                \"/tmp/f\u00f3ob\u00e5r.jpg/index.html\",\n                \"/tmp/f_ob_r.jpg\",\n                \"/tmp/f_ob_r.jpg/index.html\",\n            ],\n        ),\n    ]\n    + [\n        # index.html\n        (\"https://example.com/foo\", \":example.com/foo:/tmp\", [\"/tmp/index.html\"]),\n        (\"https://example.com/foo/\", \":example.com/foo:/tmp\", [\"/tmp/index.html\"]),\n        (\n            \"https://example.com/foo/bar\",\n            \":example.com/foo:/tmp\",\n            [\"/tmp/bar\", \"/tmp/bar/index.html\"],\n        ),\n        (\n            \"https://example.com/foo/bar/\",\n            \":example.com/foo:/tmp\",\n            [\"/tmp/bar\", \"/tmp/bar/index.html\"],\n        ),\n    ]\n    + [\n        # regex\n        (\n            \"https://example/view.php?f=foo.jpg\",\n            \":example/view.php\\\\?f=(.+):/tmp\",\n            [\"/tmp/foo.jpg\", \"/tmp/foo.jpg/index.html\"],\n        ),\n        (\n            \"https://example/results?id=1&foo=2\",\n            \":example/(results\\\\?id=.+):/tmp\",\n            [\n                \"/tmp/results?id=1&foo=2\",\n                \"/tmp/results?id=1&foo=2/index.html\",\n                \"/tmp/results_id=1_foo=2\",\n                \"/tmp/results_id=1_foo=2/index.html\",\n            ],\n        ),\n    ]\n    + [\n        # test directory traversal detection\n        (\"https://example.com/../../../../../../etc/passwd\", \":example.com:/tmp\", []),\n        # this is slightly hacky, but werkzeug's behavior differs per system.\n        (\n            \"https://example.com/C:\\\\foo.txt\",\n            \":example.com:/tmp\",\n            []\n            if sys.platform == \"win32\"\n            else [\n                \"/tmp/C:\\\\foo.txt\",\n                \"/tmp/C:\\\\foo.txt/index.html\",\n                \"/tmp/C__foo.txt\",\n                \"/tmp/C__foo.txt/index.html\",\n            ],\n        ),\n        (\n            \"https://example.com//etc/passwd\",\n            \":example.com:/tmp\",\n            [\"/tmp/etc/passwd\", \"/tmp/etc/passwd/index.html\"],\n        ),\n    ],\n)\ndef test_file_candidates(url, spec, expected_candidates):\n    # we circumvent the path existence checks here to simplify testing\n    filt, subj, repl = parse_spec(spec)\n    spec = MapLocalSpec(filt, subj, Path(repl))\n\n    candidates = file_candidates(url, spec)\n    assert [x.as_posix() for x in candidates] == expected_candidates\n\n\nclass TestMapLocal:\n    def test_configure(self, tmpdir):\n        ml = MapLocal()\n        with taddons.context(ml) as tctx:\n            tctx.configure(ml, map_local=[\"/foo/bar/\" + str(tmpdir)])\n            with pytest.raises(Exception, match=\"Invalid regular expression\"):\n                tctx.configure(ml, map_local=[\"/foo/+/\" + str(tmpdir)])\n            with pytest.raises(Exception, match=\"Invalid file path\"):\n                tctx.configure(ml, map_local=[\"/foo/.+/three\"])\n\n    def test_simple(self, tmpdir):\n        ml = MapLocal()\n\n        with taddons.context(ml) as tctx:\n            tmpfile = tmpdir.join(\"foo.jpg\")\n            tmpfile.write(\"foo\")\n            tctx.configure(ml, map_local=[\"|//example.org/images|\" + str(tmpdir)])\n            f = tflow.tflow()\n            f.request.url = b\"https://example.org/images/foo.jpg\"\n            ml.request(f)\n            assert f.response.content == b\"foo\"\n\n            tmpfile = tmpdir.join(\"images\", \"bar.jpg\")\n            tmpfile.write(\"bar\", ensure=True)\n            tctx.configure(ml, map_local=[\"|//example.org|\" + str(tmpdir)])\n            f = tflow.tflow()\n            f.request.url = b\"https://example.org/images/bar.jpg\"\n            ml.request(f)\n            assert f.response.content == b\"bar\"\n\n            tmpfile = tmpdir.join(\"foofoobar.jpg\")\n            tmpfile.write(\"foofoobar\", ensure=True)\n            tctx.configure(\n                ml, map_local=[\"|example.org/foo/foo/bar.jpg|\" + str(tmpfile)]\n            )\n            f = tflow.tflow()\n            f.request.url = b\"https://example.org/foo/foo/bar.jpg\"\n            ml.request(f)\n            assert f.response.content == b\"foofoobar\"\n\n    async def test_nonexistent_files(self, tmpdir, monkeypatch, caplog):\n        caplog.set_level(\"INFO\")\n        ml = MapLocal()\n\n        with taddons.context(ml) as tctx:\n            tctx.configure(ml, map_local=[\"|example.org/css|\" + str(tmpdir)])\n            f = tflow.tflow()\n            f.request.url = b\"https://example.org/css/nonexistent\"\n            ml.request(f)\n            assert f.response.status_code == 404\n            assert \"None of the local file candidates exist\" in caplog.text\n\n            tmpfile = tmpdir.join(\"foo.jpg\")\n            tmpfile.write(\"foo\")\n            tctx.configure(ml, map_local=[\"|//example.org/images|\" + str(tmpfile)])\n            tmpfile.remove()\n            monkeypatch.setattr(Path, \"is_file\", lambda x: True)\n            f = tflow.tflow()\n            f.request.url = b\"https://example.org/images/foo.jpg\"\n            ml.request(f)\n            assert \"Could not read\" in caplog.text\n\n    def test_is_killed(self, tmpdir):\n        ml = MapLocal()\n        with taddons.context(ml) as tctx:\n            tmpfile = tmpdir.join(\"foo.jpg\")\n            tmpfile.write(\"foo\")\n            tctx.configure(ml, map_local=[\"|//example.org/images|\" + str(tmpfile)])\n            f = tflow.tflow()\n            f.request.url = b\"https://example.org/images/foo.jpg\"\n            f.kill()\n            ml.request(f)\n            assert not f.response\n", "test/mitmproxy/addons/test_next_layer.py": "from __future__ import annotations\n\nimport dataclasses\nimport logging\nfrom collections.abc import Sequence\nfrom dataclasses import dataclass\nfrom functools import partial\nfrom unittest.mock import MagicMock\n\nimport pytest\n\nfrom mitmproxy.addons.next_layer import NeedsMoreData\nfrom mitmproxy.addons.next_layer import NextLayer\nfrom mitmproxy.addons.next_layer import stack_match\nfrom mitmproxy.connection import Address\nfrom mitmproxy.connection import Client\nfrom mitmproxy.connection import TransportProtocol\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.layer import Layer\nfrom mitmproxy.proxy.layers import ClientQuicLayer\nfrom mitmproxy.proxy.layers import ClientTLSLayer\nfrom mitmproxy.proxy.layers import DNSLayer\nfrom mitmproxy.proxy.layers import HttpLayer\nfrom mitmproxy.proxy.layers import modes\nfrom mitmproxy.proxy.layers import RawQuicLayer\nfrom mitmproxy.proxy.layers import ServerQuicLayer\nfrom mitmproxy.proxy.layers import ServerTLSLayer\nfrom mitmproxy.proxy.layers import TCPLayer\nfrom mitmproxy.proxy.layers import UDPLayer\nfrom mitmproxy.proxy.layers.http import HTTPMode\nfrom mitmproxy.proxy.layers.http import HttpStream\nfrom mitmproxy.proxy.mode_specs import ProxyMode\nfrom mitmproxy.test import taddons\n\nclient_hello_no_extensions = bytes.fromhex(\n    \"1603030065\"  # record header\n    \"01000061\"  # handshake header\n    \"03015658a756ab2c2bff55f636814deac086b7ca56b65058c7893ffc6074f5245f70205658a75475103a152637\"\n    \"78e1bb6d22e8bbd5b6b0a3a59760ad354e91ba20d353001a0035002f000a000500040009000300060008006000\"\n    \"61006200640100\"\n)\nclient_hello_with_extensions = bytes.fromhex(\n    \"16030300bb\"  # record layer\n    \"010000b7\"  # handshake layer\n    \"03033b70638d2523e1cba15f8364868295305e9c52aceabda4b5147210abc783e6e1000022c02bc02fc02cc030\"\n    \"cca9cca8cc14cc13c009c013c00ac014009c009d002f0035000a0100006cff0100010000000010000e00000b65\"\n    \"78616d706c652e636f6d0017000000230000000d00120010060106030501050304010403020102030005000501\"\n    \"00000000001200000010000e000c02683208687474702f312e3175500000000b00020100000a00080006001d00\"\n    \"170018\"\n)\n\ndtls_client_hello_with_extensions = bytes.fromhex(\n    \"16fefd00000000000000000085\"  # record layer\n    \"010000790000000000000079\"  # handshake layer\n    \"fefd62bf0e0bf809df43e7669197be831919878b1a72c07a584d3c0a8ca6665878010000000cc02bc02fc00ac014c02cc0\"\n    \"3001000043000d0010000e0403050306030401050106010807ff01000100000a00080006001d00170018000b00020100001\"\n    \"7000000000010000e00000b6578616d706c652e636f6d\"\n)\n\nquic_client_hello = bytes.fromhex(\n    \"ca0000000108c0618c84b54541320823fcce946c38d8210044e6a93bbb283593f75ffb6f2696b16cfdcb5b1255\"\n    \"577b2af5fc5894188c9568bc65eef253faf7f0520e41341cfa81d6aae573586665ce4e1e41676364820402feec\"\n    \"a81f3d22dbb476893422069066104a43e121c951a08c53b83f960becf99cf5304d5bc5346f52f472bd1a04d192\"\n    \"0bae025064990d27e5e4c325ac46121d3acadebe7babdb96192fb699693d65e2b2e21c53beeb4f40b50673a2f6\"\n    \"c22091cb7c76a845384fedee58df862464d1da505a280bfef91ca83a10bebbcb07855219dbc14aecf8a48da049\"\n    \"d03c77459b39d5355c95306cd03d6bdb471694fa998ca3b1f875ce87915b88ead15c5d6313a443f39aad808922\"\n    \"57ddfa6b4a898d773bb6fb520ede47ebd59d022431b1054a69e0bbbdf9f0fb32fc8bcc4b6879dd8cd5389474b1\"\n    \"99e18333e14d0347740a11916429a818bb8d93295d36e99840a373bb0e14c8b3adcf5e2165e70803f15316fd5e\"\n    \"5eeec04ae68d98f1adb22c54611c80fcd8ece619dbdf97b1510032ec374b7a71f94d9492b8b8cb56f56556dd97\"\n    \"edf1e50fa90e868ff93636a365678bdf3ee3f8e632588cd506b6f44fbfd4d99988238fbd5884c98f6a124108c1\"\n    \"878970780e42b111e3be6215776ef5be5a0205915e6d720d22c6a81a475c9e41ba94e4983b964cb5c8e1f40607\"\n    \"76d1d8d1adcef7587ea084231016bd6ee2643d11a3a35eb7fe4cca2b3f1a4b21e040b0d426412cca6c4271ea63\"\n    \"fb54ed7f57b41cd1af1be5507f87ea4f4a0c997367e883291de2f1b8a49bdaa52bae30064351b1139703400730\"\n    \"18a4104344ec6b4454b50a42e804bc70e78b9b3c82497273859c82ed241b643642d76df6ceab8f916392113a62\"\n    \"b231f228c7300624d74a846bec2f479ab8a8c3461f91c7bf806236e3bd2f54ba1ef8e2a1e0bfdde0c5ad227f7d\"\n    \"364c52510b1ade862ce0c8d7bd24b6d7d21c99b34de6d177eb3d575787b2af55060d76d6c2060befbb7953a816\"\n    \"6f66ad88ecf929dbb0ad3a16cf7dfd39d925e0b4b649c6d0c07ad46ed0229c17fb6a1395f16e1b138aab3af760\"\n    \"2b0ac762c4f611f7f3468997224ffbe500a7c53f92f65e41a3765a9f1d7e3f78208f5b4e147962d8c97d6c1a80\"\n    \"91ffc36090b2043d71853616f34c2185dc883c54ab6d66e10a6c18e0b9a4742597361f8554a42da3373241d0c8\"\n    \"54119bfadccffaf2335b2d97ffee627cb891bda8140a39399f853da4859f7e19682e152243efbaffb662edd19b\"\n    \"3819a74107c7dbe05ecb32e79dcdb1260f153b1ef133e978ccca3d9e400a7ed6c458d77e2956d2cb897b7a298b\"\n    \"fe144b5defdc23dfd2adf69f1fb0917840703402d524987ae3b1dcb85229843c9a419ef46e1ba0ba7783f2a2ec\"\n    \"d057a57518836aef2a7839ebd3688da98b54c942941f642e434727108d59ea25875b3050ca53d4637c76cbcbb9\"\n    \"e972c2b0b781131ee0a1403138b55486fe86bbd644920ee6aa578e3bab32d7d784b5c140295286d90c99b14823\"\n    \"1487f7ea64157001b745aa358c9ea6bec5a8d8b67a7534ec1f7648ff3b435911dfc3dff798d32fbf2efe2c1fcc\"\n    \"278865157590572387b76b78e727d3e7682cb501cdcdf9a0f17676f99d9aa67f10edccc9a92080294e88bf28c2\"\n    \"a9f32ae535fdb27fff7706540472abb9eab90af12b2bea005da189874b0ca69e6ae1690a6f2adf75be3853c94e\"\n    \"fd8098ed579c20cb37be6885d8d713af4ba52958cee383089b98ed9cb26e11127cf88d1b7d254f15f7903dd7ed\"\n    \"297c0013924e88248684fe8f2098326ce51aa6e5\"\n)\n\ndns_query = bytes.fromhex(\"002a01000001000000000000076578616d706c6503636f6d0000010001\")\n\nhttp_get = b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\"\nhttp_get_absolute = b\"GET http://example.com/ HTTP/1.1\\r\\n\\r\\n\"\n\nhttp_connect = b\"CONNECT example.com:443 HTTP/1.1\\r\\nHost: example.com:443\\r\\n\\r\\n\"\n\n\nclass TestNextLayer:\n    @pytest.mark.parametrize(\n        \"ignore, allow, transport_protocol, server_address, data_client, result\",\n        [\n            # ignore\n            pytest.param(\n                [], [], \"tcp\", \"example.com\", b\"\", False, id=\"nothing ignored\"\n            ),\n            pytest.param(\n                [\"example.com\"], [], \"tcp\", \"example.com\", b\"\", True, id=\"address\"\n            ),\n            pytest.param(\n                [\"192.0.2.1\"], [], \"tcp\", \"example.com\", b\"\", True, id=\"ip address\"\n            ),\n            pytest.param(\n                [\"2001:db8::1\"],\n                [],\n                \"tcp\",\n                \"ipv6.example.com\",\n                b\"\",\n                True,\n                id=\"ipv6 address\",\n            ),\n            pytest.param(\n                [\"example.com:443\"],\n                [],\n                \"tcp\",\n                \"example.com\",\n                b\"\",\n                True,\n                id=\"port matches\",\n            ),\n            pytest.param(\n                [\"example.com:123\"],\n                [],\n                \"tcp\",\n                \"example.com\",\n                b\"\",\n                False,\n                id=\"port does not match\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"tcp\",\n                \"192.0.2.1\",\n                http_get,\n                True,\n                id=\"http host header\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"tcp\",\n                \"192.0.2.1\",\n                http_get.replace(b\"Host\", b\"X-Host\"),\n                False,\n                id=\"http host header missing\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"tcp\",\n                \"192.0.2.1\",\n                http_get.split(b\"\\r\\n\", 1)[0],\n                NeedsMoreData,\n                id=\"incomplete http host header\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"tcp\",\n                \"com\",\n                b\"\",\n                False,\n                id=\"partial address match\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"tcp\",\n                None,\n                b\"\",\n                False,\n                id=\"no destination info\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"tcp\",\n                None,\n                client_hello_no_extensions,\n                False,\n                id=\"no sni\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"tcp\",\n                \"192.0.2.1\",\n                client_hello_with_extensions,\n                True,\n                id=\"sni\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"tcp\",\n                \"192.0.2.1\",\n                client_hello_with_extensions[:-5],\n                NeedsMoreData,\n                id=\"incomplete client hello\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"tcp\",\n                \"192.0.2.1\",\n                client_hello_no_extensions[:9] + b\"\\x00\" * 200,\n                False,\n                id=\"invalid client hello\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"tcp\",\n                \"decoy\",\n                client_hello_with_extensions,\n                True,\n                id=\"sni mismatch\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"udp\",\n                \"192.0.2.1\",\n                dtls_client_hello_with_extensions,\n                True,\n                id=\"dtls sni\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"udp\",\n                \"192.0.2.1\",\n                dtls_client_hello_with_extensions[:-5],\n                NeedsMoreData,\n                id=\"incomplete dtls client hello\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"udp\",\n                \"192.0.2.1\",\n                dtls_client_hello_with_extensions[:9] + b\"\\x00\" * 200,\n                False,\n                id=\"invalid dtls client hello\",\n            ),\n            pytest.param(\n                [\"example.com\"],\n                [],\n                \"udp\",\n                \"192.0.2.1\",\n                quic_client_hello,\n                True,\n                id=\"quic sni\",\n            ),\n            # allow\n            pytest.param(\n                [],\n                [\"example.com\"],\n                \"tcp\",\n                \"example.com\",\n                b\"\",\n                False,\n                id=\"allow: allow\",\n            ),\n            pytest.param(\n                [],\n                [\"example.com\"],\n                \"tcp\",\n                \"example.org\",\n                b\"\",\n                True,\n                id=\"allow: ignore\",\n            ),\n            pytest.param(\n                [],\n                [\"example.com\"],\n                \"tcp\",\n                \"decoy\",\n                client_hello_with_extensions,\n                False,\n                id=\"allow: sni mismatch\",\n            ),\n            # allow with ignore\n            pytest.param(\n                [\"binary.example.com\"],\n                [\"example.com\"],\n                \"tcp\",\n                \"example.com\",\n                b\"\",\n                False,\n                id=\"allow+ignore: allowed and not ignored\",\n            ),\n            pytest.param(\n                [\"binary.example.com\"],\n                [\"example.com\"],\n                \"tcp\",\n                \"binary.example.org\",\n                b\"\",\n                True,\n                id=\"allow+ignore: allowed but ignored\",\n            ),\n        ],\n    )\n    def test_ignore_connection(\n        self,\n        ignore: list[str],\n        allow: list[str],\n        transport_protocol: TransportProtocol,\n        server_address: str,\n        data_client: bytes,\n        result: bool | type[NeedsMoreData],\n    ):\n        nl = NextLayer()\n        with taddons.context(nl) as tctx:\n            if ignore:\n                tctx.configure(nl, ignore_hosts=ignore)\n            if allow:\n                tctx.configure(nl, allow_hosts=allow)\n            ctx = Context(\n                Client(peername=(\"192.168.0.42\", 51234), sockname=(\"0.0.0.0\", 8080)),\n                tctx.options,\n            )\n            ctx.client.transport_protocol = transport_protocol\n            if server_address:\n                ctx.server.address = (server_address, 443)\n                ctx.server.peername = (\n                    (\"2001:db8::1\", 443, 0, 0)\n                    if server_address.startswith(\"ipv6\")\n                    else (\"192.0.2.1\", 443)\n                )\n            if result is NeedsMoreData:\n                with pytest.raises(NeedsMoreData):\n                    nl._ignore_connection(ctx, data_client, b\"\")\n            else:\n                assert nl._ignore_connection(ctx, data_client, b\"\") is result\n\n    def test_next_layer(self, monkeypatch, caplog):\n        caplog.set_level(logging.INFO)\n        nl = NextLayer()\n\n        with taddons.context(nl) as tctx:\n            m = MagicMock()\n            m.context = Context(\n                Client(peername=(\"192.168.0.42\", 51234), sockname=(\"0.0.0.0\", 8080)),\n                tctx.options,\n            )\n            m.context.layers = [modes.TransparentProxy(m.context)]\n            m.context.server.address = (\"example.com\", 42)\n            tctx.configure(nl, ignore_hosts=[\"example.com\"])\n\n            m.layer = preexisting = object()\n            nl.next_layer(m)\n            assert m.layer is preexisting\n\n            m.layer = None\n            monkeypatch.setattr(m, \"data_client\", lambda: http_get)\n            nl.next_layer(m)\n            assert m.layer\n\n            m.layer = None\n            monkeypatch.setattr(\n                m, \"data_client\", lambda: client_hello_with_extensions[:-5]\n            )\n            nl.next_layer(m)\n            assert not m.layer\n            assert \"Deferring layer decision\" in caplog.text\n\n\n@dataclass\nclass TConf:\n    before: list[type[Layer]]\n    after: list[type[Layer]]\n    proxy_mode: str = \"regular\"\n    transport_protocol: TransportProtocol = \"tcp\"\n    data_client: bytes = b\"\"\n    data_server: bytes = b\"\"\n    ignore_hosts: Sequence[str] = ()\n    tcp_hosts: Sequence[str] = ()\n    udp_hosts: Sequence[str] = ()\n    ignore_conn: bool = False\n    server_address: Address | None = None\n\n\nexplicit_proxy_configs = [\n    pytest.param(\n        TConf(\n            before=[modes.HttpProxy],\n            after=[modes.HttpProxy, HttpLayer],\n            data_client=http_connect,\n        ),\n        id=f\"explicit proxy: regular http connect\",\n    ),\n    pytest.param(\n        TConf(\n            before=[modes.HttpProxy],\n            after=[modes.HttpProxy, HttpLayer],\n            ignore_hosts=[\".+\"],\n            data_client=http_connect,\n        ),\n        id=f\"explicit proxy: regular http connect disregards ignore_hosts\",\n    ),\n    pytest.param(\n        TConf(\n            before=[modes.HttpProxy],\n            after=[modes.HttpProxy, HttpLayer],\n            ignore_hosts=[\".+\"],\n            data_client=http_get_absolute,\n        ),\n        id=f\"explicit proxy: HTTP over regular proxy disregards ignore_hosts\",\n    ),\n    pytest.param(\n        TConf(\n            before=[modes.HttpProxy],\n            after=[modes.HttpProxy, ClientTLSLayer, HttpLayer],\n            data_client=client_hello_no_extensions,\n        ),\n        id=f\"explicit proxy: secure web proxy\",\n    ),\n    pytest.param(\n        TConf(\n            before=[modes.HttpUpstreamProxy],\n            after=[modes.HttpUpstreamProxy, HttpLayer],\n        ),\n        id=f\"explicit proxy: upstream proxy\",\n    ),\n    pytest.param(\n        TConf(\n            before=[modes.HttpUpstreamProxy],\n            after=[modes.HttpUpstreamProxy, ClientQuicLayer, HttpLayer],\n            transport_protocol=\"udp\",\n        ),\n        id=f\"explicit proxy: experimental http3\",\n    ),\n    pytest.param(\n        TConf(\n            before=[\n                modes.HttpProxy,\n                partial(HttpLayer, mode=HTTPMode.regular),\n                partial(HttpStream, stream_id=1),\n            ],\n            after=[modes.HttpProxy, HttpLayer, HttpStream, HttpLayer],\n            data_client=b\"GET / HTTP/1.1\\r\\n\",\n        ),\n        id=f\"explicit proxy: HTTP over regular proxy\",\n    ),\n    pytest.param(\n        TConf(\n            before=[\n                modes.HttpProxy,\n                partial(HttpLayer, mode=HTTPMode.regular),\n                partial(HttpStream, stream_id=1),\n            ],\n            after=[\n                modes.HttpProxy,\n                HttpLayer,\n                HttpStream,\n                ServerTLSLayer,\n                ClientTLSLayer,\n            ],\n            data_client=client_hello_with_extensions,\n        ),\n        id=f\"explicit proxy: TLS over regular proxy\",\n    ),\n    pytest.param(\n        TConf(\n            before=[\n                modes.HttpProxy,\n                partial(HttpLayer, mode=HTTPMode.regular),\n                partial(HttpStream, stream_id=1),\n                ServerTLSLayer,\n                ClientTLSLayer,\n            ],\n            after=[\n                modes.HttpProxy,\n                HttpLayer,\n                HttpStream,\n                ServerTLSLayer,\n                ClientTLSLayer,\n                HttpLayer,\n            ],\n            data_client=b\"GET / HTTP/1.1\\r\\n\",\n        ),\n        id=f\"explicit proxy: HTTPS over regular proxy\",\n    ),\n    pytest.param(\n        TConf(\n            before=[\n                modes.HttpProxy,\n                partial(HttpLayer, mode=HTTPMode.regular),\n                partial(HttpStream, stream_id=1),\n            ],\n            after=[modes.HttpProxy, HttpLayer, HttpStream, TCPLayer],\n            data_client=b\"\\xff\",\n        ),\n        id=f\"explicit proxy: TCP over regular proxy\",\n    ),\n]\n\nreverse_proxy_configs = []\nfor proto_plain, proto_enc, app_layer in [\n    (\"udp\", \"dtls\", UDPLayer),\n    (\"tcp\", \"tls\", TCPLayer),\n    (\"http\", \"https\", HttpLayer),\n]:\n    if proto_plain == \"udp\":\n        data_client = dtls_client_hello_with_extensions\n    else:\n        data_client = client_hello_with_extensions\n\n    reverse_proxy_configs.extend(\n        [\n            pytest.param(\n                TConf(\n                    before=[modes.ReverseProxy],\n                    after=[modes.ReverseProxy, app_layer],\n                    proxy_mode=f\"reverse:{proto_plain}://example.com:42\",\n                ),\n                id=f\"reverse proxy: {proto_plain} -> {proto_plain}\",\n            ),\n            pytest.param(\n                TConf(\n                    before=[modes.ReverseProxy],\n                    after=[\n                        modes.ReverseProxy,\n                        ServerTLSLayer,\n                        ClientTLSLayer,\n                        app_layer,\n                    ],\n                    proxy_mode=f\"reverse:{proto_enc}://example.com:42\",\n                    data_client=data_client,\n                ),\n                id=f\"reverse proxy: {proto_enc} -> {proto_enc}\",\n            ),\n            pytest.param(\n                TConf(\n                    before=[modes.ReverseProxy],\n                    after=[modes.ReverseProxy, ClientTLSLayer, app_layer],\n                    proxy_mode=f\"reverse:{proto_plain}://example.com:42\",\n                    data_client=data_client,\n                ),\n                id=f\"reverse proxy: {proto_enc} -> {proto_plain}\",\n            ),\n            pytest.param(\n                TConf(\n                    before=[modes.ReverseProxy],\n                    after=[modes.ReverseProxy, ServerTLSLayer, app_layer],\n                    proxy_mode=f\"reverse:{proto_enc}://example.com:42\",\n                ),\n                id=f\"reverse proxy: {proto_plain} -> {proto_enc}\",\n            ),\n        ]\n    )\n\nreverse_proxy_configs.extend(\n    [\n        pytest.param(\n            TConf(\n                before=[modes.ReverseProxy],\n                after=[modes.ReverseProxy, DNSLayer],\n                proxy_mode=\"reverse:dns://example.com:53\",\n            ),\n            id=\"reverse proxy: dns\",\n        ),\n        pytest.param(\n            TConf(\n                before=[modes.ReverseProxy],\n                after=[modes.ReverseProxy, ServerQuicLayer, ClientQuicLayer, HttpLayer],\n                proxy_mode=\"reverse:http3://example.com\",\n            ),\n            id=\"reverse proxy: http3\",\n        ),\n        pytest.param(\n            TConf(\n                before=[modes.ReverseProxy],\n                after=[\n                    modes.ReverseProxy,\n                    ServerQuicLayer,\n                    ClientQuicLayer,\n                    RawQuicLayer,\n                ],\n                proxy_mode=\"reverse:quic://example.com\",\n            ),\n            id=\"reverse proxy: quic\",\n        ),\n        pytest.param(\n            TConf(\n                before=[modes.ReverseProxy],\n                after=[modes.ReverseProxy, TCPLayer],\n                proxy_mode=f\"reverse:http://example.com\",\n                ignore_hosts=[\"example.com\"],\n                server_address=(\"example.com\", 80),\n                data_client=http_get,\n                ignore_conn=True,\n            ),\n            id=\"reverse proxy: ignore_hosts\",\n        ),\n    ]\n)\n\ntransparent_proxy_configs = [\n    pytest.param(\n        TConf(\n            before=[modes.TransparentProxy],\n            after=[modes.TransparentProxy, ServerTLSLayer, ClientTLSLayer],\n            data_client=client_hello_no_extensions,\n        ),\n        id=f\"transparent proxy: tls\",\n    ),\n    pytest.param(\n        TConf(\n            before=[modes.TransparentProxy],\n            after=[modes.TransparentProxy, ServerTLSLayer, ClientTLSLayer],\n            data_client=dtls_client_hello_with_extensions,\n            transport_protocol=\"udp\",\n        ),\n        id=f\"transparent proxy: dtls\",\n    ),\n    pytest.param(\n        TConf(\n            before=[modes.TransparentProxy],\n            after=[modes.TransparentProxy, ServerQuicLayer, ClientQuicLayer],\n            data_client=quic_client_hello,\n            transport_protocol=\"udp\",\n        ),\n        id=\"transparent proxy: quic\",\n    ),\n    pytest.param(\n        TConf(\n            before=[modes.TransparentProxy],\n            after=[modes.TransparentProxy, TCPLayer],\n            data_server=b\"220 service ready\",\n        ),\n        id=\"transparent proxy: raw tcp\",\n    ),\n    pytest.param(\n        http := TConf(\n            before=[modes.TransparentProxy],\n            after=[modes.TransparentProxy, HttpLayer],\n            server_address=(\"192.0.2.1\", 80),\n            data_client=http_get,\n        ),\n        id=\"transparent proxy: http\",\n    ),\n    pytest.param(\n        dataclasses.replace(\n            http,\n            tcp_hosts=[\"192.0.2.1\"],\n            after=[modes.TransparentProxy, TCPLayer],\n        ),\n        id=\"transparent proxy: tcp_hosts\",\n    ),\n    pytest.param(\n        dataclasses.replace(\n            http,\n            ignore_hosts=[\"192.0.2.1\"],\n            after=[modes.TransparentProxy, TCPLayer],\n            ignore_conn=True,\n        ),\n        id=\"transparent proxy: ignore_hosts\",\n    ),\n    pytest.param(\n        udp := TConf(\n            before=[modes.TransparentProxy],\n            after=[modes.TransparentProxy, UDPLayer],\n            server_address=(\"192.0.2.1\", 553),\n            transport_protocol=\"udp\",\n            data_client=b\"\\xff\",\n        ),\n        id=\"transparent proxy: raw udp\",\n    ),\n    pytest.param(\n        dns := dataclasses.replace(\n            udp,\n            after=[modes.TransparentProxy, DNSLayer],\n            data_client=dns_query,\n            server_address=(\"192.0.2.1\", 53),\n        ),\n        id=\"transparent proxy: dns over udp\",\n    ),\n    pytest.param(\n        dataclasses.replace(\n            dns,\n            transport_protocol=\"tcp\",\n        ),\n        id=\"transparent proxy: dns over tcp\",\n    ),\n    pytest.param(\n        dataclasses.replace(\n            udp,\n            udp_hosts=[\"192.0.2.1\"],\n            after=[modes.TransparentProxy, UDPLayer],\n        ),\n        id=\"transparent proxy: udp_hosts\",\n    ),\n    pytest.param(\n        TConf(\n            before=[modes.TransparentProxy],\n            after=[modes.TransparentProxy, DNSLayer],\n            proxy_mode=\"wireguard\",\n            server_address=(\"10.0.0.53\", 53),\n            ignore_hosts=[\".+\"],\n            transport_protocol=\"udp\",\n            data_client=dns_query,\n        ),\n        id=\"wireguard proxy: dns should not be ignored\",\n    ),\n]\n\n\n@pytest.mark.parametrize(\n    \"test_conf\",\n    [\n        *explicit_proxy_configs,\n        *reverse_proxy_configs,\n        *transparent_proxy_configs,\n    ],\n)\ndef test_next_layer(\n    test_conf: TConf,\n):\n    nl = NextLayer()\n    with taddons.context(nl) as tctx:\n        tctx.configure(\n            nl,\n            ignore_hosts=test_conf.ignore_hosts,\n            tcp_hosts=test_conf.tcp_hosts,\n            udp_hosts=test_conf.udp_hosts,\n        )\n\n        ctx = Context(\n            Client(peername=(\"192.168.0.42\", 51234), sockname=(\"0.0.0.0\", 8080)),\n            tctx.options,\n        )\n        ctx.server.address = test_conf.server_address\n        ctx.client.transport_protocol = test_conf.transport_protocol\n        ctx.client.proxy_mode = ProxyMode.parse(test_conf.proxy_mode)\n        ctx.layers = [x(ctx) for x in test_conf.before]\n        nl._next_layer(\n            ctx,\n            data_client=test_conf.data_client,\n            data_server=test_conf.data_server,\n        )\n        assert stack_match(ctx, test_conf.after), f\"Unexpected stack: {ctx.layers}\"\n\n        last_layer = ctx.layers[-1]\n        if isinstance(last_layer, (UDPLayer, TCPLayer)):\n            assert bool(last_layer.flow) ^ test_conf.ignore_conn\n", "test/mitmproxy/addons/test_save.py": "import pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import io\nfrom mitmproxy.addons import save\nfrom mitmproxy.addons import view\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\ndef test_configure(tmp_path):\n    sa = save.Save()\n    with taddons.context(sa) as tctx:\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(sa, save_stream_file=str(tmp_path))\n        with pytest.raises(Exception, match=\"Invalid filter\"):\n            tctx.configure(\n                sa, save_stream_file=str(tmp_path / \"foo\"), save_stream_filter=\"~~\"\n            )\n        tctx.configure(sa, save_stream_filter=\"foo\")\n        assert sa.filt\n        tctx.configure(sa, save_stream_filter=None)\n        assert not sa.filt\n\n\ndef rd(p):\n    with open(p, \"rb\") as f:\n        x = io.FlowReader(f)\n        return list(x.stream())\n\n\ndef test_tcp(tmp_path):\n    sa = save.Save()\n    with taddons.context(sa) as tctx:\n        p = str(tmp_path / \"foo\")\n        tctx.configure(sa, save_stream_file=p)\n\n        tt = tflow.ttcpflow()\n        sa.tcp_start(tt)\n        sa.tcp_end(tt)\n\n        tt = tflow.ttcpflow()\n        sa.tcp_start(tt)\n        sa.tcp_error(tt)\n\n        tctx.configure(sa, save_stream_file=None)\n        assert len(rd(p)) == 2\n\n\ndef test_udp(tmp_path):\n    sa = save.Save()\n    with taddons.context(sa) as tctx:\n        p = str(tmp_path / \"foo\")\n        tctx.configure(sa, save_stream_file=p)\n\n        tt = tflow.tudpflow()\n        sa.udp_start(tt)\n        sa.udp_end(tt)\n\n        tt = tflow.tudpflow()\n        sa.udp_start(tt)\n        sa.udp_error(tt)\n\n        tctx.configure(sa, save_stream_file=None)\n        assert len(rd(p)) == 2\n\n\ndef test_dns(tmp_path):\n    sa = save.Save()\n    with taddons.context(sa) as tctx:\n        p = str(tmp_path / \"foo\")\n        tctx.configure(sa, save_stream_file=p)\n\n        f = tflow.tdnsflow(resp=True)\n        sa.dns_request(f)\n        sa.dns_response(f)\n        tctx.configure(sa, save_stream_file=None)\n        assert rd(p)[0].response\n\n        tctx.configure(sa, save_stream_file=\"+\" + p)\n        f = tflow.tdnsflow(err=True)\n        sa.dns_request(f)\n        sa.dns_error(f)\n        tctx.configure(sa, save_stream_file=None)\n        assert rd(p)[1].error\n\n        tctx.configure(sa, save_stream_file=\"+\" + p)\n        f = tflow.tdnsflow()\n        sa.dns_request(f)\n        tctx.configure(sa, save_stream_file=None)\n        assert not rd(p)[2].response\n\n        f = tflow.tdnsflow()\n        sa.dns_response(f)\n        assert len(rd(p)) == 3\n\n\ndef test_websocket(tmp_path):\n    sa = save.Save()\n    with taddons.context(sa) as tctx:\n        p = str(tmp_path / \"foo\")\n        tctx.configure(sa, save_stream_file=p)\n\n        f = tflow.twebsocketflow()\n        sa.request(f)\n        sa.websocket_end(f)\n\n        f = tflow.twebsocketflow()\n        sa.request(f)\n        sa.websocket_end(f)\n\n        tctx.configure(sa, save_stream_file=None)\n        assert len(rd(p)) == 2\n\n\ndef test_save_command(tmp_path):\n    sa = save.Save()\n    with taddons.context() as tctx:\n        p = str(tmp_path / \"foo\")\n        sa.save([tflow.tflow(resp=True)], p)\n        assert len(rd(p)) == 1\n        sa.save([tflow.tflow(resp=True)], p)\n        assert len(rd(p)) == 1\n        sa.save([tflow.tflow(resp=True)], \"+\" + p)\n        assert len(rd(p)) == 2\n\n        with pytest.raises(exceptions.CommandError):\n            sa.save([tflow.tflow(resp=True)], str(tmp_path))\n\n        v = view.View()\n        tctx.master.addons.add(v)\n        tctx.master.addons.add(sa)\n        tctx.master.commands.execute(\"save.file @shown %s\" % p)\n\n\ndef test_simple(tmp_path):\n    sa = save.Save()\n    with taddons.context(sa) as tctx:\n        p = str(tmp_path / \"foo\")\n\n        tctx.configure(sa, save_stream_file=p)\n\n        f = tflow.tflow(resp=True)\n        sa.request(f)\n        sa.response(f)\n        tctx.configure(sa, save_stream_file=None)\n        assert rd(p)[0].response\n\n        tctx.configure(sa, save_stream_file=\"+\" + p)\n        f = tflow.tflow(err=True)\n        sa.request(f)\n        sa.error(f)\n        tctx.configure(sa, save_stream_file=None)\n        assert rd(p)[1].error\n\n        tctx.configure(sa, save_stream_file=\"+\" + p)\n        f = tflow.tflow()\n        sa.request(f)\n        tctx.configure(sa, save_stream_file=None)\n        assert not rd(p)[2].response\n\n        f = tflow.tflow()\n        sa.response(f)\n        assert len(rd(p)) == 3\n\n\ndef test_rotate_stream(tmp_path):\n    sa = save.Save()\n    with taddons.context(sa) as tctx:\n        tctx.configure(sa, save_stream_file=str(tmp_path / \"a.txt\"))\n        f1 = tflow.tflow(resp=True)\n        f2 = tflow.tflow(resp=True)\n        sa.request(f1)\n        sa.response(f1)\n        sa.request(f2)  # second request already started.\n        tctx.configure(sa, save_stream_file=str(tmp_path / \"b.txt\"))\n        sa.response(f2)\n        sa.done()\n\n        assert len(rd(tmp_path / \"a.txt\")) == 1\n        assert len(rd(tmp_path / \"b.txt\")) == 1\n\n\ndef test_disk_full(tmp_path, monkeypatch, capsys):\n    sa = save.Save()\n    with taddons.context(sa) as tctx:\n        tctx.configure(sa, save_stream_file=str(tmp_path / \"foo.txt\"))\n\n        def _raise(*_):\n            raise OSError(\"wat\")\n\n        monkeypatch.setattr(sa, \"maybe_rotate_to_new_file\", _raise)\n\n        f = tflow.tflow(resp=True)\n        sa.request(f)\n        with pytest.raises(SystemExit):\n            sa.response(f)\n\n        assert \"Error while writing\" in capsys.readouterr().err\n", "test/mitmproxy/addons/test_block.py": "import pytest\n\nfrom mitmproxy import connection\nfrom mitmproxy.addons import block\nfrom mitmproxy.test import taddons\n\n\n@pytest.mark.parametrize(\n    \"block_global, block_private, should_be_killed, address\",\n    [\n        # block_global: loopback\n        (True, False, False, (\"127.0.0.1\",)),\n        (True, False, False, (\"::1\",)),\n        # block_global: private\n        (True, False, False, (\"10.0.0.1\",)),\n        (True, False, False, (\"172.20.0.1\",)),\n        (True, False, False, (\"192.168.1.1\",)),\n        (True, False, False, (\"::ffff:10.0.0.1\",)),\n        (True, False, False, (\"::ffff:172.20.0.1\",)),\n        (True, False, False, (\"::ffff:192.168.1.1\",)),\n        (True, False, False, (\"fe80::\",)),\n        (True, False, False, (r\"::ffff:192.168.1.1%scope\",)),\n        # block_global: global\n        (True, False, True, (\"1.1.1.1\",)),\n        (True, False, True, (\"8.8.8.8\",)),\n        (True, False, True, (\"216.58.207.174\",)),\n        (True, False, True, (\"::ffff:1.1.1.1\",)),\n        (True, False, True, (\"::ffff:8.8.8.8\",)),\n        (True, False, True, (\"::ffff:216.58.207.174\",)),\n        (True, False, True, (\"2001:4860:4860::8888\",)),\n        (True, False, True, (r\"2001:4860:4860::8888%scope\",)),\n        # block_private: loopback\n        (False, True, False, (\"127.0.0.1\",)),\n        (False, True, False, (\"::1\",)),\n        # block_private: private\n        (False, True, True, (\"10.0.0.1\",)),\n        (False, True, True, (\"172.20.0.1\",)),\n        (False, True, True, (\"192.168.1.1\",)),\n        (False, True, True, (\"::ffff:10.0.0.1\",)),\n        (False, True, True, (\"::ffff:172.20.0.1\",)),\n        (False, True, True, (\"::ffff:192.168.1.1\",)),\n        (False, True, True, (r\"::ffff:192.168.1.1%scope\",)),\n        (False, True, True, (\"fe80::\",)),\n        # block_private: global\n        (False, True, False, (\"1.1.1.1\",)),\n        (False, True, False, (\"8.8.8.8\",)),\n        (False, True, False, (\"216.58.207.174\",)),\n        (False, True, False, (\"::ffff:1.1.1.1\",)),\n        (False, True, False, (\"::ffff:8.8.8.8\",)),\n        (False, True, False, (\"::ffff:216.58.207.174\",)),\n        (False, True, False, (r\"::ffff:216.58.207.174%scope\",)),\n        (False, True, False, (\"2001:4860:4860::8888\",)),\n    ],\n)\nasync def test_block_global(block_global, block_private, should_be_killed, address):\n    ar = block.Block()\n    with taddons.context(ar) as tctx:\n        tctx.configure(ar, block_global=block_global, block_private=block_private)\n        client = connection.Client(peername=address, sockname=(\"127.0.0.1\", 8080))\n        ar.client_connected(client)\n        assert bool(client.error) == should_be_killed\n", "test/mitmproxy/addons/test_dumper.py": "import io\nimport shutil\nfrom unittest import mock\n\nimport pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import dumper\nfrom mitmproxy.http import Headers\nfrom mitmproxy.net.dns import response_codes\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\ndef test_configure():\n    d = dumper.Dumper()\n    with taddons.context(d) as ctx:\n        ctx.configure(d, dumper_filter=\"~b foo\")\n        assert d.filter\n\n        f = tflow.tflow(resp=True)\n        assert not d.match(f)\n        f.response.content = b\"foo\"\n        assert d.match(f)\n\n        ctx.configure(d, dumper_filter=None)\n        assert not d.filter\n        with pytest.raises(exceptions.OptionsError):\n            ctx.configure(d, dumper_filter=\"~~\")\n        assert not d.filter\n\n\ndef test_simple():\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d) as ctx:\n        ctx.configure(d, flow_detail=0)\n        d.response(tflow.tflow(resp=True))\n        assert not sio.getvalue()\n        sio.truncate(0)\n\n        ctx.configure(d, flow_detail=1)\n        d.response(tflow.tflow(resp=True))\n        assert sio.getvalue()\n        sio.truncate(0)\n\n        ctx.configure(d, flow_detail=1)\n        d.error(tflow.tflow(err=True))\n        assert sio.getvalue()\n        sio.truncate(0)\n\n        ctx.configure(d, flow_detail=4)\n        d.response(tflow.tflow(resp=True))\n        assert sio.getvalue()\n        sio.truncate(0)\n\n        ctx.configure(d, flow_detail=4)\n        d.response(tflow.tflow(resp=True))\n        assert \"<<\" in sio.getvalue()\n        sio.truncate(0)\n\n        ctx.configure(d, flow_detail=4)\n        d.response(tflow.tflow(err=True))\n        assert \"<<\" in sio.getvalue()\n        sio.truncate(0)\n\n        ctx.configure(d, flow_detail=4)\n        flow = tflow.tflow()\n        flow.request = tutils.treq()\n        flow.client_conn = mock.MagicMock()\n        flow.client_conn.peername[0] = \"foo\"\n        flow.response = tutils.tresp(content=None)\n        flow.is_replay = \"response\"\n        flow.response.status_code = 300\n        d.response(flow)\n        assert sio.getvalue()\n        sio.truncate(0)\n\n        ctx.configure(d, flow_detail=4)\n        flow = tflow.tflow(resp=tutils.tresp(content=b\"{\"))\n        flow.response.headers[\"content-type\"] = \"application/json\"\n        flow.response.status_code = 400\n        d.response(flow)\n        assert sio.getvalue()\n        sio.truncate(0)\n\n        ctx.configure(d, flow_detail=4)\n        flow = tflow.tflow()\n        flow.request.content = None\n        flow.response = tutils.tresp(content=None)\n        d.response(flow)\n        assert \"content missing\" in sio.getvalue()\n        sio.truncate(0)\n\n\ndef test_echo_body():\n    f = tflow.tflow(resp=True)\n    f.response.headers[\"content-type\"] = \"text/html\"\n    f.response.content = b\"foo bar voing\\n\" * 600\n\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d) as ctx:\n        ctx.configure(d, flow_detail=3)\n        d._echo_message(f.response, f)\n        t = sio.getvalue()\n        assert \"cut off\" in t\n\n\ndef test_echo_body_custom_cutoff():\n    f = tflow.tflow(resp=True)\n    f.response.headers[\"content-type\"] = \"text/html\"\n    f.response.content = b\"foo bar voing\\n\" * 4\n\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d) as ctx:\n        ctx.configure(d, flow_detail=3)\n        ctx.configure(d, content_view_lines_cutoff=3)\n        d._echo_message(f.response, f)\n        t = sio.getvalue()\n        assert \"cut off\" in t\n\n\ndef test_echo_trailer():\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d) as ctx:\n        ctx.configure(d, flow_detail=3)\n        f = tflow.tflow(resp=True)\n\n        f.request.headers[\"content-type\"] = \"text/html\"\n        f.request.headers[\"transfer-encoding\"] = \"chunked\"\n        f.request.headers[\"trailer\"] = \"my-little-request-trailer\"\n        f.request.content = b\"some request content\\n\" * 600\n        f.request.trailers = Headers(\n            [(b\"my-little-request-trailer\", b\"foobar-request-trailer\")]\n        )\n\n        f.response.headers[\"transfer-encoding\"] = \"chunked\"\n        f.response.headers[\"trailer\"] = \"my-little-response-trailer\"\n        f.response.content = b\"some response content\\n\" * 100\n        f.response.trailers = Headers(\n            [(b\"my-little-response-trailer\", b\"foobar-response-trailer\")]\n        )\n\n        d.echo_flow(f)\n        t = sio.getvalue()\n        assert \"content-type\" in t\n        assert \"cut off\" in t\n        assert \"some request content\" in t\n        assert \"foobar-request-trailer\" in t\n        assert \"some response content\" in t\n        assert \"foobar-response-trailer\" in t\n\n\ndef test_echo_request_line():\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d) as ctx:\n        ctx.configure(d, flow_detail=3, showhost=True)\n        f = tflow.tflow(resp=True)\n        f.is_replay = \"request\"\n        d._echo_request_line(f)\n        assert \"[replay]\" in sio.getvalue()\n        sio.truncate(0)\n\n        f = tflow.tflow(resp=True)\n        f.is_replay = None\n        d._echo_request_line(f)\n        assert \"[replay]\" not in sio.getvalue()\n        sio.truncate(0)\n\n        f = tflow.tflow(resp=True)\n        f.request.http_version = \"nonstandard\"\n        d._echo_request_line(f)\n        assert \"nonstandard\" in sio.getvalue()\n        sio.truncate(0)\n\n        ctx.configure(d, flow_detail=1, showhost=True)\n        f = tflow.tflow(resp=True)\n        terminalWidth = max(shutil.get_terminal_size()[0] - 25, 50)\n        f.request.url = (\n            \"http://address:22/\" + (\"x\" * terminalWidth) + \"textToBeTruncated\"\n        )\n        d._echo_request_line(f)\n        assert \"textToBeTruncated\" not in sio.getvalue()\n        sio.truncate(0)\n\n\nasync def test_contentview(caplog):\n    caplog.set_level(\"DEBUG\")\n    with mock.patch(\"mitmproxy.contentviews.auto.ViewAuto.__call__\") as va:\n        va.side_effect = ValueError(\"\")\n        sio = io.StringIO()\n        d = dumper.Dumper(sio)\n        with taddons.context(d) as tctx:\n            tctx.configure(d, flow_detail=4)\n            d.response(tflow.tflow())\n            assert \"content viewer failed\" in caplog.text\n\n\ndef test_tcp():\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d) as ctx:\n        ctx.configure(d, flow_detail=3, showhost=True)\n        f = tflow.ttcpflow()\n        d.tcp_message(f)\n        assert \"it's me\" in sio.getvalue()\n        sio.truncate(0)\n\n        f = tflow.ttcpflow(client_conn=True, err=True)\n        d.tcp_error(f)\n        assert \"Error in TCP\" in sio.getvalue()\n\n\ndef test_udp():\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d) as ctx:\n        ctx.configure(d, flow_detail=3, showhost=True)\n        f = tflow.tudpflow()\n        d.udp_message(f)\n        assert \"it's me\" in sio.getvalue()\n        sio.truncate(0)\n\n        f = tflow.tudpflow(client_conn=True, err=True)\n        d.udp_error(f)\n        assert \"Error in UDP\" in sio.getvalue()\n\n\ndef test_dns():\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d) as ctx:\n        ctx.configure(d, flow_detail=3, showhost=True)\n\n        f = tflow.tdnsflow(resp=True)\n        d.dns_response(f)\n        assert \"8.8.8.8\" in sio.getvalue()\n        sio.truncate(0)\n\n        f = tflow.tdnsflow()\n        f.response = f.request.fail(response_codes.NOTIMP)\n        d.dns_response(f)\n        assert \"NOTIMP\" in sio.getvalue()\n        sio.truncate(0)\n\n        f = tflow.tdnsflow(err=True)\n        d.dns_error(f)\n        assert \"error\" in sio.getvalue()\n\n\ndef test_websocket():\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d) as ctx:\n        ctx.configure(d, flow_detail=3, showhost=True)\n        f = tflow.twebsocketflow()\n        d.websocket_message(f)\n        assert \"it's me\" in sio.getvalue()\n        sio.truncate(0)\n\n        d.websocket_end(f)\n        assert \"WebSocket connection closed by\" in sio.getvalue()\n        sio.truncate(0)\n\n        f = tflow.twebsocketflow(err=True)\n        d.websocket_end(f)\n        assert \"Error in WebSocket\" in sio.getvalue()\n        assert \"(reason:\" not in sio.getvalue()\n        sio.truncate(0)\n\n        f = tflow.twebsocketflow(err=True, close_reason=\"Some lame excuse\")\n        d.websocket_end(f)\n        assert \"Error in WebSocket\" in sio.getvalue()\n        assert \"(reason: Some lame excuse)\" in sio.getvalue()\n        sio.truncate(0)\n\n        f = tflow.twebsocketflow(close_code=4000)\n        d.websocket_end(f)\n        assert \"UNKNOWN_ERROR=4000\" in sio.getvalue()\n        assert \"(reason:\" not in sio.getvalue()\n        sio.truncate(0)\n\n        f = tflow.twebsocketflow(close_code=4000, close_reason=\"I swear I had a reason\")\n        d.websocket_end(f)\n        assert \"UNKNOWN_ERROR=4000\" in sio.getvalue()\n        assert \"(reason: I swear I had a reason)\" in sio.getvalue()\n\n\ndef test_http2():\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d):\n        f = tflow.tflow(resp=True)\n        f.response.http_version = b\"HTTP/2.0\"\n        d.response(f)\n        assert \"HTTP/2.0 200 OK\" in sio.getvalue()\n\n\ndef test_quic():\n    sio = io.StringIO()\n    d = dumper.Dumper(sio)\n    with taddons.context(d):\n        f = tflow.ttcpflow()\n        f.client_conn.tls_version = \"QUIC\"\n        # TODO: This should not be metadata, this should be typed attributes.\n        f.metadata[\"quic_stream_id_client\"] = 1\n        f.metadata[\"quic_stream_id_server\"] = 1\n        d.tcp_message(f)\n        assert \"quic stream 1\" in sio.getvalue()\n\n        f2 = tflow.tudpflow()\n        f2.client_conn.tls_version = \"QUIC\"\n        # TODO: This should not be metadata, this should be typed attributes.\n        f2.metadata[\"quic_stream_id_client\"] = 1\n        f2.metadata[\"quic_stream_id_server\"] = 1\n        d.udp_message(f2)\n        assert \"quic stream 1\" in sio.getvalue()\n\n\ndef test_styling():\n    sio = io.StringIO()\n\n    d = dumper.Dumper(sio)\n    d.out_has_vt_codes = True\n    with taddons.context(d):\n        d.response(tflow.tflow(resp=True))\n        assert \"\\x1b[\" in sio.getvalue()\n", "test/mitmproxy/addons/test_upstream_auth.py": "import base64\n\nimport pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import upstream_auth\nfrom mitmproxy.proxy.mode_specs import ProxyMode\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\ndef test_configure():\n    up = upstream_auth.UpstreamAuth()\n    with taddons.context(up) as tctx:\n        tctx.configure(up, upstream_auth=\"test:test\")\n        assert up.auth == b\"Basic\" + b\" \" + base64.b64encode(b\"test:test\")\n\n        tctx.configure(up, upstream_auth=\"test:\")\n        assert up.auth == b\"Basic\" + b\" \" + base64.b64encode(b\"test:\")\n\n        tctx.configure(up, upstream_auth=None)\n        assert not up.auth\n\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(up, upstream_auth=\"\")\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(up, upstream_auth=\":\")\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(up, upstream_auth=\":test\")\n\n\ndef test_simple():\n    up = upstream_auth.UpstreamAuth()\n    with taddons.context(up) as tctx:\n        tctx.configure(up, upstream_auth=\"foo:bar\")\n\n        f = tflow.tflow()\n        up.http_connect_upstream(f)\n        assert \"proxy-authorization\" in f.request.headers\n\n        f = tflow.tflow()\n        up.requestheaders(f)\n        assert \"proxy-authorization\" not in f.request.headers\n        assert \"authorization\" not in f.request.headers\n\n        f.client_conn.proxy_mode = ProxyMode.parse(\"upstream:127.0.0.1\")\n        up.requestheaders(f)\n        assert \"proxy-authorization\" in f.request.headers\n\n        f.client_conn.proxy_mode = ProxyMode.parse(\"reverse:127.0.0.1\")\n        up.requestheaders(f)\n        assert \"authorization\" in f.request.headers\n", "test/mitmproxy/addons/test_mapremote.py": "import pytest\n\nfrom mitmproxy.addons import mapremote\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\nclass TestMapRemote:\n    def test_configure(self):\n        mr = mapremote.MapRemote()\n        with taddons.context(mr) as tctx:\n            tctx.configure(mr, map_remote=[\"one/two/three\"])\n            with pytest.raises(Exception, match=\"Invalid regular expression\"):\n                tctx.configure(mr, map_remote=[\"/foo/+/three\"])\n\n    def test_simple(self):\n        mr = mapremote.MapRemote()\n        with taddons.context(mr) as tctx:\n            tctx.configure(\n                mr,\n                map_remote=[\n                    \":example.org/images/:mitmproxy.org/img/\",\n                ],\n            )\n            f = tflow.tflow()\n            f.request.url = b\"https://example.org/images/test.jpg\"\n            mr.request(f)\n            assert f.request.url == \"https://mitmproxy.org/img/test.jpg\"\n\n    def test_host_header(self):\n        mr = mapremote.MapRemote()\n        with taddons.context(mr) as tctx:\n            tctx.configure(mr, map_remote=[\"|http://[^/]+|http://example.com:4444\"])\n            f = tflow.tflow()\n            f.request.url = b\"http://example.org/example\"\n            f.request.headers[\"Host\"] = \"example.org\"\n            mr.request(f)\n            assert f.request.headers.get(\"Host\", \"\") == \"example.com:4444\"\n\n    def test_is_killed(self):\n        mr = mapremote.MapRemote()\n        with taddons.context(mr) as tctx:\n            tctx.configure(mr, map_remote=[\":example.org:mitmproxy.org\"])\n            f = tflow.tflow()\n            f.request.url = b\"https://example.org/images/test.jpg\"\n            f.kill()\n            mr.request(f)\n            assert f.request.url == \"https://example.org/images/test.jpg\"\n", "test/mitmproxy/addons/test_export.py": "import os\nimport shlex\nfrom unittest import mock\n\nimport pyperclip\nimport pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import export  # heh\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\n@pytest.fixture\ndef get_request():\n    return tflow.tflow(\n        req=tutils.treq(method=b\"GET\", content=b\"\", path=b\"/path?a=foo&a=bar&b=baz\")\n    )\n\n\n@pytest.fixture\ndef get_response():\n    return tflow.tflow(\n        resp=tutils.tresp(status_code=404, content=b\"Test Response Body\")\n    )\n\n\n@pytest.fixture\ndef get_flow():\n    return tflow.tflow(\n        req=tutils.treq(method=b\"GET\", content=b\"\", path=b\"/path?a=foo&a=bar&b=baz\"),\n        resp=tutils.tresp(status_code=404, content=b\"Test Response Body\"),\n    )\n\n\n@pytest.fixture\ndef post_request():\n    return tflow.tflow(\n        req=tutils.treq(method=b\"POST\", headers=(), content=bytes(range(256)))\n    )\n\n\n@pytest.fixture\ndef patch_request():\n    return tflow.tflow(\n        req=tutils.treq(method=b\"PATCH\", content=b\"content\", path=b\"/path?query=param\")\n    )\n\n\n@pytest.fixture\ndef tcp_flow():\n    return tflow.ttcpflow()\n\n\n@pytest.fixture\ndef udp_flow():\n    return tflow.tudpflow()\n\n\n@pytest.fixture\ndef websocket_flow():\n    return tflow.twebsocketflow()\n\n\n@pytest.fixture(scope=\"module\")\ndef export_curl():\n    e = export.Export()\n    with taddons.context() as tctx:\n        tctx.configure(e)\n        yield export.curl_command\n\n\nclass TestExportCurlCommand:\n    def test_get(self, export_curl, get_request):\n        result = (\n            \"\"\"curl -H 'header: qvalue' 'http://address:22/path?a=foo&a=bar&b=baz'\"\"\"\n        )\n        assert export_curl(get_request) == result\n\n    def test_post(self, export_curl, post_request):\n        post_request.request.content = b\"nobinarysupport\"\n        result = \"curl -X POST http://address:22/path -d nobinarysupport\"\n        assert export_curl(post_request) == result\n\n    def test_fails_with_binary_data(self, export_curl, post_request):\n        # shlex.quote doesn't support a bytes object\n        # see https://github.com/python/cpython/pull/10871\n        post_request.request.headers[\"Content-Type\"] = \"application/json; charset=utf-8\"\n        with pytest.raises(exceptions.CommandError):\n            export_curl(post_request)\n\n    def test_patch(self, export_curl, patch_request):\n        result = \"\"\"curl -H 'header: qvalue' -X PATCH 'http://address:22/path?query=param' -d content\"\"\"\n        assert export_curl(patch_request) == result\n\n    def test_tcp(self, export_curl, tcp_flow):\n        with pytest.raises(exceptions.CommandError):\n            export_curl(tcp_flow)\n\n    def test_udp(self, export_curl, udp_flow):\n        with pytest.raises(exceptions.CommandError):\n            export_curl(udp_flow)\n\n    def test_escape_single_quotes_in_body(self, export_curl):\n        request = tflow.tflow(\n            req=tutils.treq(method=b\"POST\", headers=(), content=b\"'&#\")\n        )\n        command = export_curl(request)\n        assert shlex.split(command)[-2] == \"-d\"\n        assert shlex.split(command)[-1] == \"'&#\"\n\n    def test_strip_unnecessary(self, export_curl, get_request):\n        get_request.request.headers.clear()\n        get_request.request.headers[\"host\"] = \"address\"\n        get_request.request.headers[\":authority\"] = \"address\"\n        get_request.request.headers[\"accept-encoding\"] = \"br\"\n        result = \"\"\"curl --compressed 'http://address:22/path?a=foo&a=bar&b=baz'\"\"\"\n        assert export_curl(get_request) == result\n\n    # This tests that we always specify the original host in the URL, which is\n    # important for SNI. If option `export_preserve_original_ip` is true, we\n    # ensure that we still connect to the same IP by using curl's `--resolve`\n    # option.\n    def test_correct_host_used(self, get_request):\n        e = export.Export()\n        with taddons.context() as tctx:\n            tctx.configure(e)\n\n            get_request.request.headers[\"host\"] = \"domain:22\"\n\n            result = \"\"\"curl -H 'header: qvalue' -H 'host: domain:22' 'http://domain:22/path?a=foo&a=bar&b=baz'\"\"\"\n            assert export.curl_command(get_request) == result\n\n            tctx.options.export_preserve_original_ip = True\n            result = (\n                \"\"\"curl --resolve 'domain:22:[192.168.0.1]' -H 'header: qvalue' -H 'host: domain:22' \"\"\"\n                \"\"\"'http://domain:22/path?a=foo&a=bar&b=baz'\"\"\"\n            )\n            assert export.curl_command(get_request) == result\n\n\nclass TestExportHttpieCommand:\n    def test_get(self, get_request):\n        result = (\n            \"\"\"http GET 'http://address:22/path?a=foo&a=bar&b=baz' 'header: qvalue'\"\"\"\n        )\n        assert export.httpie_command(get_request) == result\n\n    def test_post(self, post_request):\n        post_request.request.content = b\"nobinarysupport\"\n        result = \"http POST http://address:22/path <<< nobinarysupport\"\n        assert export.httpie_command(post_request) == result\n\n    def test_fails_with_binary_data(self, post_request):\n        # shlex.quote doesn't support a bytes object\n        # see https://github.com/python/cpython/pull/10871\n        post_request.request.headers[\"Content-Type\"] = \"application/json; charset=utf-8\"\n        with pytest.raises(exceptions.CommandError):\n            export.httpie_command(post_request)\n\n    def test_patch(self, patch_request):\n        result = \"\"\"http PATCH 'http://address:22/path?query=param' 'header: qvalue' <<< content\"\"\"\n        assert export.httpie_command(patch_request) == result\n\n    def test_tcp(self, tcp_flow):\n        with pytest.raises(exceptions.CommandError):\n            export.httpie_command(tcp_flow)\n\n    def test_udp(self, udp_flow):\n        with pytest.raises(exceptions.CommandError):\n            export.httpie_command(udp_flow)\n\n    def test_escape_single_quotes_in_body(self):\n        request = tflow.tflow(\n            req=tutils.treq(method=b\"POST\", headers=(), content=b\"'&#\")\n        )\n        command = export.httpie_command(request)\n        assert shlex.split(command)[-2] == \"<<<\"\n        assert shlex.split(command)[-1] == \"'&#\"\n\n    # See comment in `TestExportCurlCommand.test_correct_host_used`. httpie\n    # currently doesn't have a way of forcing connection to a particular IP, so\n    # the command-line may not always reproduce the original request, in case\n    # the host is resolved to a different IP address.\n    #\n    # httpie tracking issue: https://github.com/httpie/httpie/issues/414\n    def test_correct_host_used(self, get_request):\n        get_request.request.headers[\"host\"] = \"domain:22\"\n\n        result = (\n            \"\"\"http GET 'http://domain:22/path?a=foo&a=bar&b=baz' \"\"\"\n            \"\"\"'header: qvalue' 'host: domain:22'\"\"\"\n        )\n        assert export.httpie_command(get_request) == result\n\n\nclass TestRaw:\n    def test_req_and_resp_present(self, get_flow):\n        assert b\"header: qvalue\" in export.raw(get_flow)\n        assert b\"header-response: svalue\" in export.raw(get_flow)\n\n    def test_get_request_present(self, get_request):\n        assert b\"header: qvalue\" in export.raw(get_request)\n        assert b\"content-length: 0\" in export.raw_request(get_request)\n\n    def test_get_response_present(self, get_response):\n        get_response.request.content = None\n        assert b\"header-response: svalue\" in export.raw(get_response)\n\n    def test_tcp(self, tcp_flow):\n        with pytest.raises(\n            exceptions.CommandError,\n            match=\"Can't export flow with no request or response\",\n        ):\n            export.raw(tcp_flow)\n\n    def test_udp(self, udp_flow):\n        with pytest.raises(\n            exceptions.CommandError,\n            match=\"Can't export flow with no request or response\",\n        ):\n            export.raw(udp_flow)\n\n    def test_websocket(self, websocket_flow):\n        assert b\"hello binary\" in export.raw(websocket_flow)\n        assert b\"hello text\" in export.raw(websocket_flow)\n        assert b\"it's me\" in export.raw(websocket_flow)\n\n\nclass TestRawRequest:\n    def test_get(self, get_request):\n        assert b\"header: qvalue\" in export.raw_request(get_request)\n        assert b\"content-length: 0\" in export.raw_request(get_request)\n\n    def test_no_content(self, get_request):\n        get_request.request.content = None\n        with pytest.raises(exceptions.CommandError):\n            export.raw_request(get_request)\n\n    def test_tcp(self, tcp_flow):\n        with pytest.raises(exceptions.CommandError):\n            export.raw_request(tcp_flow)\n\n    def test_udp(self, udp_flow):\n        with pytest.raises(exceptions.CommandError):\n            export.raw_request(udp_flow)\n\n\nclass TestRawResponse:\n    def test_get(self, get_response):\n        assert b\"header-response: svalue\" in export.raw_response(get_response)\n\n    def test_no_content(self, get_response):\n        get_response.response.content = None\n        with pytest.raises(exceptions.CommandError):\n            export.raw_response(get_response)\n\n    def test_tcp(self, tcp_flow):\n        with pytest.raises(exceptions.CommandError):\n            export.raw_response(tcp_flow)\n\n    def test_udp(self, udp_flow):\n        with pytest.raises(exceptions.CommandError):\n            export.raw_response(udp_flow)\n\n\ndef qr(f):\n    with open(f, \"rb\") as fp:\n        return fp.read()\n\n\ndef test_export(tmp_path) -> None:\n    f = tmp_path / \"outfile\"\n    e = export.Export()\n    with taddons.context() as tctx:\n        tctx.configure(e)\n\n        assert e.formats() == [\"curl\", \"httpie\", \"raw\", \"raw_request\", \"raw_response\"]\n        with pytest.raises(exceptions.CommandError):\n            e.file(\"nonexistent\", tflow.tflow(resp=True), f)\n\n        e.file(\"raw_request\", tflow.tflow(resp=True), f)\n        assert qr(f)\n        os.unlink(f)\n\n        e.file(\"raw_response\", tflow.tflow(resp=True), f)\n        assert qr(f)\n        os.unlink(f)\n\n        e.file(\"curl\", tflow.tflow(resp=True), f)\n        assert qr(f)\n        os.unlink(f)\n\n        e.file(\"httpie\", tflow.tflow(resp=True), f)\n        assert qr(f)\n        os.unlink(f)\n\n        e.file(\"raw\", tflow.twebsocketflow(), f)\n        assert qr(f)\n        os.unlink(f)\n\n\n@pytest.mark.parametrize(\n    \"exception, log_message\",\n    [\n        (PermissionError, \"Permission denied\"),\n        (IsADirectoryError, \"Is a directory\"),\n        (FileNotFoundError, \"No such file or directory\"),\n    ],\n)\nasync def test_export_open(exception, log_message, tmpdir, caplog):\n    f = str(tmpdir.join(\"path\"))\n    e = export.Export()\n    with mock.patch(\"mitmproxy.addons.export.open\") as m:\n        m.side_effect = exception(log_message)\n        e.file(\"raw_request\", tflow.tflow(resp=True), f)\n        assert log_message in caplog.text\n\n\nasync def test_clip(tmpdir, caplog):\n    e = export.Export()\n    with taddons.context() as tctx:\n        tctx.configure(e)\n\n        with pytest.raises(exceptions.CommandError):\n            e.clip(\"nonexistent\", tflow.tflow(resp=True))\n\n        with mock.patch(\"pyperclip.copy\") as pc:\n            e.clip(\"raw_request\", tflow.tflow(resp=True))\n            assert pc.called\n\n        with mock.patch(\"pyperclip.copy\") as pc:\n            e.clip(\"raw_response\", tflow.tflow(resp=True))\n            assert pc.called\n\n        with mock.patch(\"pyperclip.copy\") as pc:\n            e.clip(\"curl\", tflow.tflow(resp=True))\n            assert pc.called\n\n        with mock.patch(\"pyperclip.copy\") as pc:\n            e.clip(\"httpie\", tflow.tflow(resp=True))\n            assert pc.called\n\n        with mock.patch(\"pyperclip.copy\") as pc:\n            log_message = (\n                \"Pyperclip could not find a \" \"copy/paste mechanism for your system.\"\n            )\n            pc.side_effect = pyperclip.PyperclipException(log_message)\n            e.clip(\"raw_request\", tflow.tflow(resp=True))\n            assert log_message in caplog.text\n", "test/mitmproxy/addons/test_savehar.py": "import json\nimport zlib\nfrom pathlib import Path\n\nimport pytest\n\nfrom mitmproxy import io\nfrom mitmproxy import types\nfrom mitmproxy import version\nfrom mitmproxy.addons.save import Save\nfrom mitmproxy.addons.savehar import SaveHar\nfrom mitmproxy.connection import Server\nfrom mitmproxy.exceptions import OptionsError\nfrom mitmproxy.http import Headers\nfrom mitmproxy.http import Request\nfrom mitmproxy.http import Response\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\ntest_dir = Path(__file__).parent.parent\n\n\ndef test_write_error():\n    s = SaveHar()\n\n    with pytest.raises(FileNotFoundError):\n        s.export_har([], types.Path(\"unknown_dir/testing_flow.har\"))\n\n\n@pytest.mark.parametrize(\n    \"header, expected\",\n    [\n        (Headers([(b\"cookie\", b\"foo=bar\")]), [{\"name\": \"foo\", \"value\": \"bar\"}]),\n        (\n            Headers([(b\"cookie\", b\"foo=bar\"), (b\"cookie\", b\"foo=baz\")]),\n            [{\"name\": \"foo\", \"value\": \"bar\"}, {\"name\": \"foo\", \"value\": \"baz\"}],\n        ),\n    ],\n)\ndef test_request_cookies(header: Headers, expected: list[dict]):\n    s = SaveHar()\n    req = Request.make(\"GET\", \"https://exampls.com\", \"\", header)\n    assert s.format_multidict(req.cookies) == expected\n\n\n@pytest.mark.parametrize(\n    \"header, expected\",\n    [\n        (\n            Headers(\n                [\n                    (\n                        b\"set-cookie\",\n                        b\"foo=bar; path=/; domain=.googls.com; priority=high\",\n                    )\n                ]\n            ),\n            [\n                {\n                    \"name\": \"foo\",\n                    \"value\": \"bar\",\n                    \"path\": \"/\",\n                    \"domain\": \".googls.com\",\n                    \"httpOnly\": False,\n                    \"secure\": False,\n                }\n            ],\n        ),\n        (\n            Headers(\n                [\n                    (\n                        b\"set-cookie\",\n                        b\"foo=bar; path=/; domain=.googls.com; Secure; HttpOnly; priority=high\",\n                    ),\n                    (\n                        b\"set-cookie\",\n                        b\"fooz=baz; path=/; domain=.googls.com; priority=high; SameSite=none\",\n                    ),\n                ]\n            ),\n            [\n                {\n                    \"name\": \"foo\",\n                    \"value\": \"bar\",\n                    \"path\": \"/\",\n                    \"domain\": \".googls.com\",\n                    \"httpOnly\": True,\n                    \"secure\": True,\n                },\n                {\n                    \"name\": \"fooz\",\n                    \"value\": \"baz\",\n                    \"path\": \"/\",\n                    \"domain\": \".googls.com\",\n                    \"httpOnly\": False,\n                    \"secure\": False,\n                    \"sameSite\": \"none\",\n                },\n            ],\n        ),\n    ],\n)\ndef test_response_cookies(header: Headers, expected: list[dict]):\n    s = SaveHar()\n    resp = Response.make(200, \"\", header)\n    assert s.format_response_cookies(resp) == expected\n\n\ndef test_seen_server_conn():\n    s = SaveHar()\n\n    flow = tflow.twebsocketflow()\n\n    servers_seen: set[Server] = set()\n    servers_seen.add(flow.server_conn)\n\n    calculated_timings = s.flow_entry(flow, servers_seen)[\"timings\"]\n\n    assert calculated_timings[\"connect\"] == -1.0\n    assert calculated_timings[\"ssl\"] == -1.0\n\n\ndef test_timestamp_end():\n    s = SaveHar()\n    servers_seen: set[Server] = set()\n    flow = tflow.twebsocketflow()\n\n    assert s.flow_entry(flow, set())[\"timings\"][\"send\"] == 1000\n\n    flow.request.timestamp_end = None\n    calculated_timings = s.flow_entry(flow, servers_seen)[\"timings\"]\n\n    assert calculated_timings[\"send\"] == 0\n\n\ndef test_tls_setup():\n    s = SaveHar()\n    servers_seen: set[Server] = set()\n    flow = tflow.twebsocketflow()\n    flow.server_conn.timestamp_tls_setup = None\n\n    assert s.flow_entry(flow, servers_seen)[\"timings\"][\"ssl\"] == -1.0\n\n\ndef test_binary_content():\n    resp_content = SaveHar().make_har(\n        [tflow.tflow(resp=tutils.tresp(content=b\"foo\" + b\"\\xff\" * 10))]\n    )[\"log\"][\"entries\"][0][\"response\"][\"content\"]\n    assert resp_content == {\n        \"compression\": 0,\n        \"encoding\": \"base64\",\n        \"mimeType\": \"\",\n        \"size\": 13,\n        \"text\": \"Zm9v/////////////w==\",\n    }\n\n\n@pytest.mark.parametrize(\n    \"log_file\", [pytest.param(x, id=x.stem) for x in test_dir.glob(\"data/flows/*.mitm\")]\n)\ndef test_savehar(log_file: Path, tmp_path: Path, monkeypatch):\n    monkeypatch.setattr(version, \"VERSION\", \"1.2.3\")\n    s = SaveHar()\n\n    flows = io.read_flows_from_paths([log_file])\n\n    s.export_har(flows, types.Path(tmp_path / \"testing_flow.har\"))\n    expected_har = json.loads(log_file.with_suffix(\".har\").read_bytes())\n    actual_har = json.loads(Path(tmp_path / \"testing_flow.har\").read_bytes())\n\n    assert actual_har == expected_har\n\n\ndef test_flow_entry():\n    \"\"\"https://github.com/mitmproxy/mitmproxy/issues/6579\"\"\"\n    s = SaveHar()\n    req = Request.make(\"CONNECT\", \"https://test.test/\")\n    flow = tflow.tflow(req=req)\n    servers_seen: set[Server] = set()\n\n    flow_entry = s.flow_entry(flow, servers_seen)\n\n    assert flow_entry[\"request\"][\"url\"].startswith(\"https\")\n\n\nclass TestHardumpOption:\n    def test_simple(self, capsys):\n        s = SaveHar()\n        with taddons.context(s) as tctx:\n            tctx.configure(s, hardump=\"-\")\n\n            s.response(tflow.tflow())\n\n            s.error(tflow.tflow())\n\n            ws = tflow.twebsocketflow()\n            s.response(ws)\n            s.websocket_end(ws)\n\n            s.done()\n\n            out = json.loads(capsys.readouterr().out)\n            assert len(out[\"log\"][\"entries\"]) == 3\n\n    def test_filter(self, capsys):\n        s = SaveHar()\n        with taddons.context(s, Save()) as tctx:\n            tctx.configure(s, hardump=\"-\", save_stream_filter=\"~b foo\")\n            with pytest.raises(OptionsError):\n                tctx.configure(s, save_stream_filter=\"~~\")\n\n            s.response(tflow.tflow(req=tflow.treq(content=b\"foo\")))\n            s.response(tflow.tflow())\n\n            s.done()\n\n            out = json.loads(capsys.readouterr().out)\n            assert len(out[\"log\"][\"entries\"]) == 1\n\n    def test_free(self):\n        s = SaveHar()\n        with taddons.context(s, Save()) as tctx:\n            tctx.configure(s, hardump=\"-\")\n            s.response(tflow.tflow())\n            assert s.flows\n            tctx.configure(s, hardump=\"\")\n            assert not s.flows\n\n    def test_compressed(self, tmp_path):\n        s = SaveHar()\n        with taddons.context(s, Save()) as tctx:\n            tctx.configure(s, hardump=str(tmp_path / \"out.zhar\"))\n\n            s.response(tflow.tflow())\n            s.done()\n\n            out = json.loads(zlib.decompress((tmp_path / \"out.zhar\").read_bytes()))\n            assert len(out[\"log\"][\"entries\"]) == 1\n\n\nif __name__ == \"__main__\":\n    version.VERSION = \"1.2.3\"\n    s = SaveHar()\n    for file in test_dir.glob(\"data/flows/*.mitm\"):\n        path = open(file, \"rb\")\n        flows = list(io.FlowReader(path).stream())\n        s.export_har(flows, types.Path(test_dir / f\"data/flows/{file.stem}.har\"))\n", "test/mitmproxy/addons/test_onboarding.py": "import pytest\n\nfrom mitmproxy.addons import onboarding\nfrom mitmproxy.test import taddons\n\n\n@pytest.fixture\ndef client():\n    with onboarding.app.test_client() as client:\n        yield client\n\n\nclass TestApp:\n    def addons(self):\n        return [onboarding.Onboarding()]\n\n    def test_basic(self, client):\n        ob = onboarding.Onboarding()\n        with taddons.context(ob) as tctx:\n            tctx.configure(ob)\n            assert client.get(\"/\").status_code == 200\n\n    @pytest.mark.parametrize(\"ext\", [\"pem\", \"p12\", \"cer\", \"magisk\"])\n    def test_cert(self, client, ext, tdata):\n        ob = onboarding.Onboarding()\n        with taddons.context(ob) as tctx:\n            tctx.configure(ob, confdir=tdata.path(\"mitmproxy/data/confdir\"))\n            resp = client.get(f\"/cert/{ext}\")\n            assert resp.status_code == 200\n            assert resp.data\n\n    @pytest.mark.parametrize(\"ext\", [\"pem\", \"p12\", \"cer\", \"magisk\"])\n    def test_head(self, client, ext, tdata):\n        ob = onboarding.Onboarding()\n        with taddons.context(ob) as tctx:\n            tctx.configure(ob, confdir=tdata.path(\"mitmproxy/data/confdir\"))\n            resp = client.head(f\"http://{tctx.options.onboarding_host}/cert/{ext}\")\n            assert resp.status_code == 200\n            assert \"Content-Length\" in resp.headers\n            assert \"Content-Type\" in resp.headers\n            assert \"Content-Disposition\" in resp.headers\n            assert \"attachment\" in resp.headers[\"Content-Disposition\"]\n            assert not resp.data\n", "test/mitmproxy/addons/test_core.py": "import pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import core\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\ndef test_set():\n    sa = core.Core()\n    with taddons.context(loadcore=False) as tctx:\n        assert tctx.master.options.upstream_cert\n        tctx.command(sa.set, \"upstream_cert\", \"false\")\n        assert not tctx.master.options.upstream_cert\n\n        with pytest.raises(exceptions.CommandError):\n            tctx.command(sa.set, \"nonexistent\")\n\n\ndef test_resume():\n    sa = core.Core()\n    with taddons.context(loadcore=False):\n        f = tflow.tflow()\n        assert not sa.resume([f])\n        f.intercept()\n        sa.resume([f])\n        assert not f.intercepted\n\n\ndef test_mark():\n    sa = core.Core()\n    with taddons.context(loadcore=False):\n        f = tflow.tflow()\n        assert not f.marked\n        sa.mark([f], \":default:\")\n        assert f.marked\n\n        with pytest.raises(exceptions.CommandError):\n            sa.mark([f], \"invalid\")\n\n        sa.mark_toggle([f])\n        assert not f.marked\n        sa.mark_toggle([f])\n        assert f.marked\n\n\ndef test_kill():\n    sa = core.Core()\n    with taddons.context(loadcore=False):\n        f = tflow.tflow()\n        f.intercept()\n        assert f.killable\n        sa.kill([f])\n        assert not f.killable\n\n\ndef test_revert():\n    sa = core.Core()\n    with taddons.context(loadcore=False):\n        f = tflow.tflow()\n        f.backup()\n        f.request.content = b\"bar\"\n        assert f.modified()\n        sa.revert([f])\n        assert not f.modified()\n\n\ndef test_flow_set():\n    sa = core.Core()\n    with taddons.context(loadcore=False):\n        f = tflow.tflow(resp=True)\n        assert sa.flow_set_options()\n\n        assert f.request.method != \"post\"\n        sa.flow_set([f], \"method\", \"post\")\n        assert f.request.method == \"POST\"\n\n        assert f.request.host != \"testhost\"\n        sa.flow_set([f], \"host\", \"testhost\")\n        assert f.request.host == \"testhost\"\n\n        assert f.request.path != \"/test/path\"\n        sa.flow_set([f], \"path\", \"/test/path\")\n        assert f.request.path == \"/test/path\"\n\n        assert f.request.url != \"http://foo.com/bar\"\n        sa.flow_set([f], \"url\", \"http://foo.com/bar\")\n        assert f.request.url == \"http://foo.com/bar\"\n        with pytest.raises(exceptions.CommandError):\n            sa.flow_set([f], \"url\", \"oink\")\n\n        assert f.response.status_code != 404\n        sa.flow_set([f], \"status_code\", \"404\")\n        assert f.response.status_code == 404\n        assert f.response.reason == \"Not Found\"\n        with pytest.raises(exceptions.CommandError):\n            sa.flow_set([f], \"status_code\", \"oink\")\n\n        assert f.response.reason != \"foo\"\n        sa.flow_set([f], \"reason\", \"foo\")\n        assert f.response.reason == \"foo\"\n\n\ndef test_encoding():\n    sa = core.Core()\n    with taddons.context(loadcore=False):\n        f = tflow.tflow()\n        assert sa.encode_options()\n        sa.encode([f], \"request\", \"deflate\")\n        assert f.request.headers[\"content-encoding\"] == \"deflate\"\n\n        sa.encode([f], \"request\", \"br\")\n        assert f.request.headers[\"content-encoding\"] == \"deflate\"\n\n        sa.decode([f], \"request\")\n        assert \"content-encoding\" not in f.request.headers\n\n        sa.encode([f], \"request\", \"br\")\n        assert f.request.headers[\"content-encoding\"] == \"br\"\n\n        sa.encode_toggle([f], \"request\")\n        assert \"content-encoding\" not in f.request.headers\n        sa.encode_toggle([f], \"request\")\n        assert f.request.headers[\"content-encoding\"] == \"deflate\"\n        sa.encode_toggle([f], \"request\")\n        assert \"content-encoding\" not in f.request.headers\n\n\ndef test_options(tmpdir):\n    p = str(tmpdir.join(\"path\"))\n    sa = core.Core()\n    with taddons.context() as tctx:\n        tctx.options.listen_host = \"foo\"\n        assert tctx.options.listen_host == \"foo\"\n        sa.options_reset_one(\"listen_host\")\n        assert tctx.options.listen_host != \"foo\"\n\n        with pytest.raises(exceptions.CommandError):\n            sa.options_reset_one(\"unknown\")\n\n        tctx.options.listen_host = \"foo\"\n        sa.options_save(p)\n        with pytest.raises(exceptions.CommandError):\n            sa.options_save(\"/\")\n\n        sa.options_reset()\n        assert tctx.options.listen_host == \"\"\n        sa.options_load(p)\n        assert tctx.options.listen_host == \"foo\"\n\n        sa.options_load(\"/nonexistent\")\n\n        with open(p, \"a\") as f:\n            f.write(\"'''\")\n        with pytest.raises(exceptions.CommandError):\n            sa.options_load(p)\n\n\ndef test_validation_simple():\n    sa = core.Core()\n    with taddons.context() as tctx:\n        with pytest.raises(\n            exceptions.OptionsError,\n            match=\"requires the upstream_cert option to be enabled\",\n        ):\n            tctx.configure(\n                sa, add_upstream_certs_to_client_chain=True, upstream_cert=False\n            )\n\n\ndef test_client_certs(tdata):\n    sa = core.Core()\n    with taddons.context() as tctx:\n        # Folders should work.\n        tctx.configure(sa, client_certs=tdata.path(\"mitmproxy/data/clientcert\"))\n        # Files, too.\n        tctx.configure(\n            sa, client_certs=tdata.path(\"mitmproxy/data/clientcert/client.pem\")\n        )\n\n        with pytest.raises(\n            exceptions.OptionsError, match=\"certificate path does not exist\"\n        ):\n            tctx.configure(sa, client_certs=\"invalid\")\n", "test/mitmproxy/addons/test_tlsconfig.py": "import ipaddress\nimport ssl\nimport time\nfrom pathlib import Path\n\nimport pytest\nfrom cryptography import x509\nfrom OpenSSL import SSL\n\nfrom mitmproxy import certs\nfrom mitmproxy import connection\nfrom mitmproxy import options\nfrom mitmproxy import tls\nfrom mitmproxy.addons import tlsconfig\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy.layers import modes\nfrom mitmproxy.proxy.layers import quic\nfrom mitmproxy.proxy.layers import tls as proxy_tls\nfrom mitmproxy.test import taddons\nfrom test.mitmproxy.proxy.layers import test_quic\nfrom test.mitmproxy.proxy.layers import test_tls\n\n\ndef test_alpn_select_callback():\n    ctx = SSL.Context(SSL.SSLv23_METHOD)\n    conn = SSL.Connection(ctx)\n\n    # Test that we respect addons setting `client.alpn`.\n    conn.set_app_data(\n        tlsconfig.AppData(server_alpn=b\"h2\", http2=True, client_alpn=b\"qux\")\n    )\n    assert tlsconfig.alpn_select_callback(conn, [b\"http/1.1\", b\"qux\", b\"h2\"]) == b\"qux\"\n    conn.set_app_data(tlsconfig.AppData(server_alpn=b\"h2\", http2=True, client_alpn=b\"\"))\n    assert (\n        tlsconfig.alpn_select_callback(conn, [b\"http/1.1\", b\"qux\", b\"h2\"])\n        == SSL.NO_OVERLAPPING_PROTOCOLS\n    )\n\n    # Test that we try to mirror the server connection's ALPN\n    conn.set_app_data(\n        tlsconfig.AppData(server_alpn=b\"h2\", http2=True, client_alpn=None)\n    )\n    assert tlsconfig.alpn_select_callback(conn, [b\"http/1.1\", b\"qux\", b\"h2\"]) == b\"h2\"\n\n    # Test that we respect the client's preferred HTTP ALPN.\n    conn.set_app_data(tlsconfig.AppData(server_alpn=None, http2=True, client_alpn=None))\n    assert (\n        tlsconfig.alpn_select_callback(conn, [b\"qux\", b\"http/1.1\", b\"h2\"])\n        == b\"http/1.1\"\n    )\n    assert tlsconfig.alpn_select_callback(conn, [b\"qux\", b\"h2\", b\"http/1.1\"]) == b\"h2\"\n\n    # Test no overlap\n    assert (\n        tlsconfig.alpn_select_callback(conn, [b\"qux\", b\"quux\"])\n        == SSL.NO_OVERLAPPING_PROTOCOLS\n    )\n\n    # Test that we don't select an ALPN if the server refused to select one.\n    conn.set_app_data(tlsconfig.AppData(server_alpn=b\"\", http2=True, client_alpn=None))\n    assert (\n        tlsconfig.alpn_select_callback(conn, [b\"http/1.1\"])\n        == SSL.NO_OVERLAPPING_PROTOCOLS\n    )\n\n\nhere = Path(__file__).parent\n\n\ndef _ctx(opts: options.Options) -> context.Context:\n    return context.Context(\n        connection.Client(\n            peername=(\"client\", 1234),\n            sockname=(\"127.0.0.1\", 8080),\n            timestamp_start=1605699329,\n        ),\n        opts,\n    )\n\n\nclass TestTlsConfig:\n    def test_configure(self, tdata):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            with pytest.raises(Exception, match=\"file does not exist\"):\n                tctx.configure(ta, certs=[\"*=nonexistent\"])\n\n            with pytest.raises(Exception, match=\"Invalid ECDH curve\"):\n                tctx.configure(ta, tls_ecdh_curve_client=\"invalid\")\n\n            with pytest.raises(Exception, match=\"Invalid certificate format\"):\n                tctx.configure(\n                    ta,\n                    certs=[\n                        tdata.path(\n                            \"mitmproxy/net/data/verificationcerts/trusted-leaf.key\"\n                        )\n                    ],\n                )\n\n            assert not ta.certstore.certs\n            tctx.configure(\n                ta,\n                certs=[\n                    tdata.path(\"mitmproxy/net/data/verificationcerts/trusted-leaf.pem\")\n                ],\n            )\n            assert ta.certstore.certs\n\n    def test_get_cert(self, tdata):\n        \"\"\"Test that we generate a certificate matching the connection's context.\"\"\"\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ta.configure([\"confdir\"])\n\n            ctx = _ctx(tctx.options)\n\n            # Edge case first: We don't have _any_ idea about the server nor is there a SNI,\n            # so we just return our local IP as subject.\n            entry = ta.get_cert(ctx)\n            assert entry.cert.cn == \"127.0.0.1\"\n\n            # Here we have an existing server connection...\n            ctx.server.address = (\"server-address.example\", 443)\n            with open(\n                tdata.path(\"mitmproxy/net/data/verificationcerts/trusted-leaf.crt\"),\n                \"rb\",\n            ) as f:\n                ctx.server.certificate_list = [certs.Cert.from_pem(f.read())]\n            entry = ta.get_cert(ctx)\n            assert entry.cert.cn == \"example.mitmproxy.org\"\n            assert entry.cert.altnames == x509.GeneralNames(\n                [\n                    x509.DNSName(\"example.mitmproxy.org\"),\n                    x509.IPAddress(ipaddress.ip_address(\"127.0.0.1\")),\n                    x509.DNSName(\"server-address.example\"),\n                ]\n            )\n\n            # And now we also incorporate SNI.\n            ctx.client.sni = \"\ud83c\udf08.sni.example\"\n            entry = ta.get_cert(ctx)\n            assert entry.cert.altnames == x509.GeneralNames(\n                [\n                    x509.DNSName(\"example.mitmproxy.org\"),\n                    x509.DNSName(\"xn--og8h.sni.example\"),\n                    x509.DNSName(\"server-address.example\"),\n                ]\n            )\n\n            with open(tdata.path(\"mitmproxy/data/invalid-subject.pem\"), \"rb\") as f:\n                ctx.server.certificate_list = [certs.Cert.from_pem(f.read())]\n            with pytest.warns(\n                UserWarning, match=\"Country names should be two characters\"\n            ):\n                assert ta.get_cert(ctx)  # does not raise\n\n    def test_tls_clienthello(self):\n        # only really testing for coverage here, there's no point in mirroring the individual conditions\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ctx = _ctx(tctx.options)\n            ch = tls.ClientHelloData(ctx, None)  # type: ignore\n            ta.tls_clienthello(ch)\n            assert not ch.establish_server_tls_first\n\n    def do_handshake(\n        self,\n        tssl_client: test_tls.SSLTest | SSL.Connection,\n        tssl_server: test_tls.SSLTest | SSL.Connection,\n    ) -> bool:\n        # ClientHello\n        with pytest.raises((ssl.SSLWantReadError, SSL.WantReadError)):\n            tssl_client.do_handshake()\n        tssl_server.bio_write(tssl_client.bio_read(65536))\n\n        # ServerHello\n        with pytest.raises((ssl.SSLWantReadError, SSL.WantReadError)):\n            tssl_server.do_handshake()\n        tssl_client.bio_write(tssl_server.bio_read(65536))\n\n        # done\n        tssl_client.do_handshake()\n        tssl_server.bio_write(tssl_client.bio_read(65536))\n        tssl_server.do_handshake()\n\n        return True\n\n    def quic_do_handshake(\n        self,\n        tssl_client: test_quic.SSLTest,\n        tssl_server: test_quic.SSLTest,\n    ) -> bool:\n        tssl_server.write(tssl_client.read())\n        tssl_client.write(tssl_server.read())\n        tssl_server.write(tssl_client.read())\n        return tssl_client.handshake_completed() and tssl_server.handshake_completed()\n\n    def test_tls_start_client(self, tdata):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ta.configure([\"confdir\"])\n            tctx.configure(\n                ta,\n                certs=[\n                    tdata.path(\"mitmproxy/net/data/verificationcerts/trusted-leaf.pem\")\n                ],\n                ciphers_client=\"ECDHE-ECDSA-AES128-GCM-SHA256\",\n            )\n            ctx = _ctx(tctx.options)\n\n            tls_start = tls.TlsData(ctx.client, context=ctx)\n            ta.tls_start_client(tls_start)\n            tssl_server = tls_start.ssl_conn\n\n            # assert that a preexisting ssl_conn is not overwritten\n            ta.tls_start_client(tls_start)\n            assert tssl_server is tls_start.ssl_conn\n\n            tssl_client = test_tls.SSLTest()\n            assert self.do_handshake(tssl_client, tssl_server)\n            assert tssl_client.obj.getpeercert()[\"subjectAltName\"] == (\n                (\"DNS\", \"example.mitmproxy.org\"),\n            )\n\n    def test_quic_start_client(self, tdata):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ta.configure([\"confdir\"])\n            tctx.configure(\n                ta,\n                certs=[\n                    tdata.path(\"mitmproxy/net/data/verificationcerts/trusted-leaf.pem\")\n                ],\n                ciphers_client=\"CHACHA20_POLY1305_SHA256\",\n            )\n            ctx = _ctx(tctx.options)\n\n            tls_start = quic.QuicTlsData(ctx.client, context=ctx)\n            ta.quic_start_client(tls_start)\n            settings_server = tls_start.settings\n            settings_server.alpn_protocols = [\"h3\"]\n            tssl_server = test_quic.SSLTest(server_side=True, settings=settings_server)\n\n            # assert that a preexisting settings is not overwritten\n            ta.quic_start_client(tls_start)\n            assert settings_server is tls_start.settings\n\n            tssl_client = test_quic.SSLTest(alpn=[\"h3\"])\n            assert self.quic_do_handshake(tssl_client, tssl_server)\n            san = tssl_client.quic.tls._peer_certificate.extensions.get_extension_for_class(\n                x509.SubjectAlternativeName\n            )\n            assert san.value.get_values_for_type(x509.DNSName) == [\n                \"example.mitmproxy.org\"\n            ]\n\n    def test_tls_start_server_cannot_verify(self):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ctx = _ctx(tctx.options)\n            ctx.server.address = (\"example.mitmproxy.org\", 443)\n            ctx.server.sni = \"\"  # explicitly opt out of using the address.\n\n            tls_start = tls.TlsData(ctx.server, context=ctx)\n            with pytest.raises(\n                ValueError, match=\"Cannot validate certificate hostname without SNI\"\n            ):\n                ta.tls_start_server(tls_start)\n\n    def test_tls_start_server_verify_failed(self):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ctx = _ctx(tctx.options)\n            ctx.client.alpn_offers = [b\"h2\"]\n            ctx.client.cipher_list = [\"TLS_AES_256_GCM_SHA384\", \"ECDHE-RSA-AES128-SHA\"]\n            ctx.server.address = (\"example.mitmproxy.org\", 443)\n\n            tls_start = tls.TlsData(ctx.server, context=ctx)\n            ta.tls_start_server(tls_start)\n            tssl_client = tls_start.ssl_conn\n            tssl_server = test_tls.SSLTest(server_side=True)\n            with pytest.raises(SSL.Error, match=\"certificate verify failed\"):\n                assert self.do_handshake(tssl_client, tssl_server)\n\n    @pytest.mark.parametrize(\"hostname\", [\"example.mitmproxy.org\", \"192.0.2.42\"])\n    def test_tls_start_server_verify_ok(self, hostname, tdata):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ctx = _ctx(tctx.options)\n            ctx.server.address = (hostname, 443)\n            tctx.configure(\n                ta,\n                ssl_verify_upstream_trusted_ca=tdata.path(\n                    \"mitmproxy/net/data/verificationcerts/trusted-root.crt\"\n                ),\n            )\n\n            tls_start = tls.TlsData(ctx.server, context=ctx)\n            ta.tls_start_server(tls_start)\n            tssl_client = tls_start.ssl_conn\n\n            # assert that a preexisting ssl_conn is not overwritten\n            ta.tls_start_server(tls_start)\n            assert tssl_client is tls_start.ssl_conn\n\n            tssl_server = test_tls.SSLTest(server_side=True, sni=hostname.encode())\n            assert self.do_handshake(tssl_client, tssl_server)\n\n    @pytest.mark.parametrize(\"hostname\", [\"example.mitmproxy.org\", \"192.0.2.42\"])\n    def test_quic_start_server_verify_ok(self, hostname, tdata):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ctx = _ctx(tctx.options)\n            ctx.server.address = (hostname, 443)\n            tctx.configure(\n                ta,\n                ssl_verify_upstream_trusted_ca=tdata.path(\n                    \"mitmproxy/net/data/verificationcerts/trusted-root.crt\"\n                ),\n            )\n\n            tls_start = quic.QuicTlsData(ctx.server, context=ctx)\n            ta.quic_start_server(tls_start)\n            settings_client = tls_start.settings\n            settings_client.alpn_protocols = [\"h3\"]\n            tssl_client = test_quic.SSLTest(settings=settings_client)\n\n            # assert that a preexisting ssl_conn is not overwritten\n            ta.quic_start_server(tls_start)\n            assert settings_client is tls_start.settings\n\n            tssl_server = test_quic.SSLTest(\n                server_side=True, sni=hostname.encode(), alpn=[\"h3\"]\n            )\n            assert self.quic_do_handshake(tssl_client, tssl_server)\n\n    def test_tls_start_server_insecure(self):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ctx = _ctx(tctx.options)\n            ctx.server.address = (\"example.mitmproxy.org\", 443)\n\n            tctx.configure(\n                ta,\n                ssl_verify_upstream_trusted_ca=None,\n                ssl_insecure=True,\n                http2=False,\n                ciphers_server=\"ALL\",\n            )\n            tls_start = tls.TlsData(ctx.server, context=ctx)\n            ta.tls_start_server(tls_start)\n            tssl_client = tls_start.ssl_conn\n            tssl_server = test_tls.SSLTest(server_side=True)\n            assert self.do_handshake(tssl_client, tssl_server)\n\n    def test_quic_start_server_insecure(self):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ctx = _ctx(tctx.options)\n            ctx.server.address = (\"example.mitmproxy.org\", 443)\n            ctx.client.alpn_offers = [b\"h3\"]\n\n            tctx.configure(\n                ta,\n                ssl_verify_upstream_trusted_ca=None,\n                ssl_insecure=True,\n                ciphers_server=\"CHACHA20_POLY1305_SHA256\",\n            )\n            tls_start = quic.QuicTlsData(ctx.server, context=ctx)\n            ta.quic_start_server(tls_start)\n            tssl_client = test_quic.SSLTest(settings=tls_start.settings)\n            tssl_server = test_quic.SSLTest(server_side=True, alpn=[\"h3\"])\n            assert self.quic_do_handshake(tssl_client, tssl_server)\n\n    def test_alpn_selection(self):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ctx = _ctx(tctx.options)\n            ctx.server.address = (\"example.mitmproxy.org\", 443)\n            tls_start = tls.TlsData(ctx.server, context=ctx)\n\n            def assert_alpn(http2, client_offers, expected):\n                tctx.configure(ta, http2=http2)\n                ctx.client.alpn_offers = client_offers\n                ctx.server.alpn_offers = None\n                tls_start.ssl_conn = None\n                ta.tls_start_server(tls_start)\n                assert ctx.server.alpn_offers == expected\n\n            assert_alpn(\n                True, proxy_tls.HTTP_ALPNS + (b\"foo\",), proxy_tls.HTTP_ALPNS + (b\"foo\",)\n            )\n            assert_alpn(\n                False,\n                proxy_tls.HTTP_ALPNS + (b\"foo\",),\n                proxy_tls.HTTP1_ALPNS + (b\"foo\",),\n            )\n            assert_alpn(True, [], [])\n            assert_alpn(False, [], [])\n            ctx.client.timestamp_tls_setup = time.time()\n            # make sure that we don't upgrade h1 to h2,\n            # see comment in tlsconfig.py\n            assert_alpn(True, [], [])\n\n    def test_no_h2_proxy(self, tdata):\n        \"\"\"Do not negotiate h2 on the client<->proxy connection in secure web proxy mode,\n        https://github.com/mitmproxy/mitmproxy/issues/4689\"\"\"\n\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            tctx.configure(\n                ta,\n                certs=[\n                    tdata.path(\"mitmproxy/net/data/verificationcerts/trusted-leaf.pem\")\n                ],\n            )\n\n            ctx = _ctx(tctx.options)\n            # mock up something that looks like a secure web proxy.\n            ctx.layers = [modes.HttpProxy(ctx), 123]\n            tls_start = tls.TlsData(ctx.client, context=ctx)\n            ta.tls_start_client(tls_start)\n            assert tls_start.ssl_conn.get_app_data()[\"client_alpn\"] == b\"http/1.1\"\n\n    @pytest.mark.parametrize(\n        \"client_certs\",\n        [\n            \"mitmproxy/net/data/verificationcerts/trusted-leaf.pem\",\n            \"mitmproxy/net/data/verificationcerts/\",\n        ],\n    )\n    def test_client_cert_file(self, tdata, client_certs):\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta) as tctx:\n            ctx = _ctx(tctx.options)\n            ctx.server.address = (\"example.mitmproxy.org\", 443)\n            tctx.configure(\n                ta,\n                client_certs=tdata.path(client_certs),\n                ssl_verify_upstream_trusted_ca=tdata.path(\n                    \"mitmproxy/net/data/verificationcerts/trusted-root.crt\"\n                ),\n            )\n\n            tls_start = tls.TlsData(ctx.server, context=ctx)\n            ta.tls_start_server(tls_start)\n            tssl_client = tls_start.ssl_conn\n            tssl_server = test_tls.SSLTest(server_side=True)\n\n            assert self.do_handshake(tssl_client, tssl_server)\n            assert tssl_server.obj.getpeercert()\n\n    async def test_ca_expired(self, monkeypatch, caplog):\n        monkeypatch.setattr(certs.Cert, \"has_expired\", lambda self: True)\n        ta = tlsconfig.TlsConfig()\n        with taddons.context(ta):\n            ta.configure([\"confdir\"])\n            assert \"The mitmproxy certificate authority has expired\" in caplog.text\n", "test/mitmproxy/addons/test_intercept.py": "import pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import intercept\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\nasync def test_simple():\n    r = intercept.Intercept()\n    with taddons.context(r) as tctx:\n        assert not r.filt\n        tctx.configure(r, intercept=\"~q\")\n        assert r.filt\n        assert tctx.options.intercept_active\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(r, intercept=\"~~\")\n        tctx.configure(r, intercept=None)\n        assert not r.filt\n        assert not tctx.options.intercept_active\n\n        tctx.configure(r, intercept=\"~s\")\n\n        f = tflow.tflow(resp=True)\n        await tctx.cycle(r, f)\n        assert f.intercepted\n\n        f = tflow.tflow(resp=False)\n        await tctx.cycle(r, f)\n        assert not f.intercepted\n\n        f = tflow.tflow(resp=True)\n        r.response(f)\n        assert f.intercepted\n\n        tctx.configure(r, intercept_active=False)\n        f = tflow.tflow(resp=True)\n        await tctx.cycle(r, f)\n        assert not f.intercepted\n\n        tctx.configure(r, intercept_active=True)\n        f = tflow.tflow(resp=True)\n        await tctx.cycle(r, f)\n        assert f.intercepted\n\n\nasync def test_dns():\n    r = intercept.Intercept()\n    with taddons.context(r) as tctx:\n        tctx.configure(r, intercept=\"~s ~dns\")\n\n        f = tflow.tdnsflow(resp=True)\n        await tctx.cycle(r, f)\n        assert f.intercepted\n\n        f = tflow.tdnsflow(resp=False)\n        await tctx.cycle(r, f)\n        assert not f.intercepted\n\n        tctx.configure(r, intercept_active=False)\n        f = tflow.tdnsflow(resp=True)\n        await tctx.cycle(r, f)\n        assert not f.intercepted\n\n\nasync def test_tcp():\n    r = intercept.Intercept()\n    with taddons.context(r) as tctx:\n        tctx.configure(r, intercept=\"~tcp\")\n        f = tflow.ttcpflow()\n        await tctx.cycle(r, f)\n        assert f.intercepted\n\n        tctx.configure(r, intercept_active=False)\n        f = tflow.ttcpflow()\n        await tctx.cycle(r, f)\n        assert not f.intercepted\n\n\nasync def test_udp():\n    r = intercept.Intercept()\n    with taddons.context(r) as tctx:\n        tctx.configure(r, intercept=\"~udp\")\n        f = tflow.tudpflow()\n        await tctx.cycle(r, f)\n        assert f.intercepted\n\n        tctx.configure(r, intercept_active=False)\n        f = tflow.tudpflow()\n        await tctx.cycle(r, f)\n        assert not f.intercepted\n\n\nasync def test_websocket_message():\n    r = intercept.Intercept()\n    with taddons.context(r) as tctx:\n        tctx.configure(r, intercept='~b \"hello binary\"')\n        f = tflow.twebsocketflow()\n        await tctx.cycle(r, f)\n        assert f.intercepted\n\n        tctx.configure(r, intercept_active=False)\n        f = tflow.twebsocketflow()\n        await tctx.cycle(r, f)\n        assert not f.intercepted\n", "test/mitmproxy/addons/test_termlog.py": "import builtins\nimport io\nimport logging\n\nimport pytest\n\nfrom mitmproxy.addons import termlog\nfrom mitmproxy.test import taddons\nfrom mitmproxy.utils import vt_codes\n\n\n@pytest.fixture(autouse=True)\ndef ensure_cleanup():\n    yield\n    assert not any(isinstance(x, termlog.TermLogHandler) for x in logging.root.handlers)\n\n\ndef test_output(capsys):\n    logging.getLogger().setLevel(logging.DEBUG)\n    t = termlog.TermLog()\n    with taddons.context(t) as tctx:\n        tctx.options.termlog_verbosity = \"info\"\n        tctx.configure(t)\n        logging.info(\"one\")\n        logging.debug(\"two\")\n        logging.warning(\"three\")\n        logging.error(\"four\")\n    out, err = capsys.readouterr()\n    assert \"one\" in out\n    assert \"two\" not in out\n    assert \"three\" in out\n    assert \"four\" in out\n    t.uninstall()\n\n\nasync def test_styling(monkeypatch) -> None:\n    monkeypatch.setattr(vt_codes, \"ensure_supported\", lambda _: True)\n\n    f = io.StringIO()\n    t = termlog.TermLog(out=f)\n    with taddons.context(t) as tctx:\n        tctx.configure(t)\n        logging.warning(\"hello\")\n\n    assert \"\\x1b[33mhello\\x1b[0m\" in f.getvalue()\n    t.uninstall()\n\n\nasync def test_cannot_print(monkeypatch) -> None:\n    def _raise(*args, **kwargs):\n        raise OSError\n\n    monkeypatch.setattr(builtins, \"print\", _raise)\n\n    t = termlog.TermLog()\n    with taddons.context(t) as tctx:\n        tctx.configure(t)\n        with pytest.raises(SystemExit) as exc_info:\n            logging.info(\"Should not log this, but raise instead\")\n\n        assert exc_info.value.args[0] == 1\n\n    t.uninstall()\n", "test/mitmproxy/addons/test_proxyserver.py": "from __future__ import annotations\n\nimport asyncio\nimport socket\nimport ssl\nfrom collections.abc import AsyncGenerator\nfrom collections.abc import Callable\nfrom contextlib import asynccontextmanager\nfrom dataclasses import dataclass\nfrom typing import Any\nfrom typing import ClassVar\nfrom typing import TypeVar\nfrom unittest.mock import Mock\n\nimport mitmproxy_rs\nimport pytest\nfrom aioquic.asyncio.protocol import QuicConnectionProtocol\nfrom aioquic.asyncio.server import QuicServer\nfrom aioquic.h3 import events as h3_events\nfrom aioquic.h3.connection import FrameUnexpected\nfrom aioquic.h3.connection import H3Connection\nfrom aioquic.quic import events as quic_events\nfrom aioquic.quic.configuration import QuicConfiguration\nfrom aioquic.quic.connection import QuicConnection\nfrom aioquic.quic.connection import QuicConnectionError\n\nfrom .test_clientplayback import tcp_server\nimport mitmproxy.platform\nfrom mitmproxy import dns\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import dns_resolver\nfrom mitmproxy.addons.next_layer import NextLayer\nfrom mitmproxy.addons.proxyserver import Proxyserver\nfrom mitmproxy.addons.tlsconfig import TlsConfig\nfrom mitmproxy.connection import Address\nfrom mitmproxy.proxy import layers\nfrom mitmproxy.proxy import server_hooks\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test.tflow import tclient_conn\nfrom mitmproxy.test.tflow import tserver_conn\nfrom mitmproxy.test.tutils import tdnsreq\nfrom mitmproxy.utils import data\n\ntlsdata = data.Data(__name__)\n\n\nclass HelperAddon:\n    def __init__(self):\n        self.flows = []\n\n    def request(self, f):\n        self.flows.append(f)\n\n    def tcp_start(self, f):\n        self.flows.append(f)\n\n\nasync def test_start_stop(caplog_async):\n    caplog_async.set_level(\"INFO\")\n\n    async def server_handler(\n        reader: asyncio.StreamReader, writer: asyncio.StreamWriter\n    ):\n        assert await reader.readuntil(b\"\\r\\n\\r\\n\") == b\"GET /hello HTTP/1.1\\r\\n\\r\\n\"\n        writer.write(b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n        await writer.drain()\n\n    ps = Proxyserver()\n    nl = NextLayer()\n    state = HelperAddon()\n\n    with taddons.context(ps, nl, state) as tctx:\n        async with tcp_server(server_handler) as addr:\n            tctx.configure(ps, listen_host=\"127.0.0.1\", listen_port=0)\n            assert not ps.servers\n            assert await ps.setup_servers()\n            ps.running()\n            await caplog_async.await_log(\"HTTP(S) proxy listening at\")\n            assert ps.servers\n\n            proxy_addr = ps.listen_addrs()[0]\n            reader, writer = await asyncio.open_connection(*proxy_addr)\n            req = f\"GET http://{addr[0]}:{addr[1]}/hello HTTP/1.1\\r\\n\\r\\n\"\n            writer.write(req.encode())\n            assert (\n                await reader.readuntil(b\"\\r\\n\\r\\n\")\n                == b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\"\n            )\n            assert repr(ps) == \"Proxyserver(1 active conns)\"\n\n            await (\n                ps.setup_servers()\n            )  # assert this can always be called without side effects\n            tctx.configure(ps, server=False)\n            await caplog_async.await_log(\"stopped\")\n            if ps.servers.is_updating:\n                async with ps.servers._lock:\n                    pass  # wait until start/stop is finished.\n            assert not ps.servers\n            assert state.flows\n            assert state.flows[0].request.path == \"/hello\"\n            assert state.flows[0].response.status_code == 204\n\n            writer.close()\n            await writer.wait_closed()\n            await _wait_for_connection_closes(ps)\n\n\nasync def _wait_for_connection_closes(ps: Proxyserver):\n    # Waiting here until everything is really torn down... takes some effort.\n    client_handlers = [\n        conn_handler.transports[conn_handler.client].handler\n        for conn_handler in ps.connections.values()\n        if conn_handler.client in conn_handler.transports\n    ]\n    for client_handler in client_handlers:\n        try:\n            await asyncio.wait_for(client_handler, 5)\n        except asyncio.CancelledError:\n            pass\n    for _ in range(5):\n        # Get all other scheduled coroutines to run.\n        await asyncio.sleep(0)\n    assert not ps.connections\n\n\nasync def test_inject() -> None:\n    async def server_handler(\n        reader: asyncio.StreamReader, writer: asyncio.StreamWriter\n    ):\n        while s := await reader.read(1):\n            writer.write(s.upper())\n\n    ps = Proxyserver()\n    nl = NextLayer()\n    state = HelperAddon()\n\n    with taddons.context(ps, nl, state) as tctx:\n        async with tcp_server(server_handler) as addr:\n            tctx.configure(ps, listen_host=\"127.0.0.1\", listen_port=0)\n            assert await ps.setup_servers()\n            ps.running()\n            proxy_addr = ps.servers[\"regular\"].listen_addrs[0]\n            reader, writer = await asyncio.open_connection(*proxy_addr)\n\n            req = f\"CONNECT {addr[0]}:{addr[1]} HTTP/1.1\\r\\n\\r\\n\"\n            writer.write(req.encode())\n            assert (\n                await reader.readuntil(b\"\\r\\n\\r\\n\")\n                == b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\"\n            )\n\n            writer.write(b\"a\")\n            assert await reader.read(1) == b\"A\"\n            ps.inject_tcp(state.flows[0], False, b\"b\")\n            assert await reader.read(1) == b\"B\"\n            ps.inject_tcp(state.flows[0], True, b\"c\")\n            assert await reader.read(1) == b\"c\"\n\n            writer.close()\n            await writer.wait_closed()\n            await _wait_for_connection_closes(ps)\n\n\nasync def test_inject_fail(caplog) -> None:\n    ps = Proxyserver()\n    ps.inject_websocket(tflow.tflow(), True, b\"test\")\n    assert \"Cannot inject WebSocket messages into non-WebSocket flows.\" in caplog.text\n    ps.inject_tcp(tflow.tflow(), True, b\"test\")\n    assert \"Cannot inject TCP messages into non-TCP flows.\" in caplog.text\n\n    ps.inject_udp(tflow.tflow(), True, b\"test\")\n    assert \"Cannot inject UDP messages into non-UDP flows.\" in caplog.text\n    ps.inject_udp(tflow.tudpflow(), True, b\"test\")\n    assert \"Flow is not from a live connection.\" in caplog.text\n\n    ps.inject_websocket(tflow.twebsocketflow(), True, b\"test\")\n    assert \"Flow is not from a live connection.\" in caplog.text\n    ps.inject_websocket(tflow.ttcpflow(), True, b\"test\")\n    assert \"Cannot inject WebSocket messages into non-WebSocket flows\" in caplog.text\n\n\nasync def test_warn_no_nextlayer(caplog):\n    \"\"\"\n    Test that we log an error if the proxy server is started without NextLayer addon.\n    That is a mean trap to fall into when writing end-to-end tests.\n    \"\"\"\n    ps = Proxyserver()\n    with taddons.context(ps) as tctx:\n        tctx.configure(ps, listen_host=\"127.0.0.1\", listen_port=0, server=False)\n        assert await ps.setup_servers()\n        ps.running()\n        assert \"Warning: Running proxyserver without nextlayer addon!\" in caplog.text\n\n\nasync def test_self_connect():\n    server = tserver_conn()\n    client = tclient_conn()\n    server.address = (\"localhost\", 8080)\n    ps = Proxyserver()\n    with taddons.context(ps) as tctx:\n        tctx.configure(ps, listen_host=\"127.0.0.1\", listen_port=0)\n        assert await ps.setup_servers()\n        ps.running()\n        assert ps.servers\n        server.address = (\"localhost\", ps.servers[\"regular\"].listen_addrs[0][1])\n        ps.server_connect(server_hooks.ServerConnectionHookData(server, client))\n        assert \"Request destination unknown\" in server.error\n        tctx.configure(ps, server=False)\n        assert await ps.setup_servers()\n        await _wait_for_connection_closes(ps)\n\n\ndef test_options():\n    ps = Proxyserver()\n    with taddons.context(ps) as tctx:\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(ps, stream_large_bodies=\"invalid\")\n        tctx.configure(ps, stream_large_bodies=\"1m\")\n\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(ps, body_size_limit=\"invalid\")\n        tctx.configure(ps, body_size_limit=\"1m\")\n\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(ps, connect_addr=\"invalid\")\n        tctx.configure(ps, connect_addr=\"1.2.3.4\")\n        assert ps._connect_addr == (\"1.2.3.4\", 0)\n\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(ps, mode=[\"invalid!\"])\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(ps, mode=[\"regular\", \"reverse:example.com\"])\n        tctx.configure(ps, mode=[\"regular\"], server=False)\n\n\nasync def test_startup_err(monkeypatch, caplog) -> None:\n    async def _raise(*_):\n        raise OSError(\"cannot bind\")\n\n    monkeypatch.setattr(asyncio, \"start_server\", _raise)\n\n    ps = Proxyserver()\n    with taddons.context(ps):\n        assert not await ps.setup_servers()\n        assert \"cannot bind\" in caplog.text\n\n\nasync def test_shutdown_err(caplog_async) -> None:\n    caplog_async.set_level(\"INFO\")\n\n    async def _raise(*_):\n        raise OSError(\"cannot close\")\n\n    ps = Proxyserver()\n    with taddons.context(ps) as tctx:\n        tctx.configure(ps, listen_host=\"127.0.0.1\", listen_port=0)\n        assert await ps.setup_servers()\n        ps.running()\n        assert ps.servers\n        for server in ps.servers:\n            setattr(server, \"stop\", _raise)\n        tctx.configure(ps, server=False)\n        await caplog_async.await_log(\"cannot close\")\n        await _wait_for_connection_closes(ps)\n\n\nclass DummyResolver:\n    async def dns_request(self, flow: dns.DNSFlow) -> None:\n        flow.response = await dns_resolver.resolve_message(flow.request, self)\n\n    async def getaddrinfo(self, host: str, port: int, *, family: int, type: int):\n        if family == socket.AF_INET and host == \"dns.google\":\n            return [(socket.AF_INET, type, None, None, (\"8.8.8.8\", port))]\n        e = socket.gaierror()\n        e.errno = socket.EAI_NONAME\n        raise e\n\n\nasync def test_dns(caplog_async) -> None:\n    caplog_async.set_level(\"INFO\")\n    ps = Proxyserver()\n    with taddons.context(ps, DummyResolver()) as tctx:\n        tctx.configure(\n            ps,\n            mode=[\"dns@127.0.0.1:0\"],\n        )\n        assert await ps.setup_servers()\n        ps.running()\n        await caplog_async.await_log(\"DNS server listening at\")\n        assert ps.servers\n        dns_addr = ps.servers[\"dns@127.0.0.1:0\"].listen_addrs[0]\n        s = await mitmproxy_rs.open_udp_connection(*dns_addr)\n        req = tdnsreq()\n        s.write(req.packed)\n        resp = dns.Message.unpack(await s.read(65535))\n        assert req.id == resp.id and \"8.8.8.8\" in str(resp)\n        assert len(ps.connections) == 1\n        s.write(req.packed)\n        resp = dns.Message.unpack(await s.read(65535))\n        assert req.id == resp.id and \"8.8.8.8\" in str(resp)\n        assert len(ps.connections) == 1\n        req.id = req.id + 1\n        s.write(req.packed)\n        resp = dns.Message.unpack(await s.read(65535))\n        assert req.id == resp.id and \"8.8.8.8\" in str(resp)\n        assert len(ps.connections) == 1\n        (dns_conn,) = ps.connections.values()\n        assert isinstance(dns_conn.layer, layers.DNSLayer)\n        assert len(dns_conn.layer.flows) == 2\n\n        s.write(b\"\\x00\")\n        await caplog_async.await_log(\"sent an invalid message\")\n        tctx.configure(ps, server=False)\n        await caplog_async.await_log(\"stopped\")\n\n        s.close()\n        await s.wait_closed()\n        await _wait_for_connection_closes(ps)\n\n\ndef test_validation_no_transparent(monkeypatch):\n    monkeypatch.setattr(mitmproxy.platform, \"original_addr\", None)\n    ps = Proxyserver()\n    with taddons.context(ps) as tctx:\n        with pytest.raises(Exception, match=\"Transparent mode not supported\"):\n            tctx.configure(ps, mode=[\"transparent\"])\n\n\ndef test_transparent_init(monkeypatch):\n    init = Mock()\n    monkeypatch.setattr(mitmproxy.platform, \"original_addr\", lambda: 1)\n    monkeypatch.setattr(mitmproxy.platform, \"init_transparent_mode\", init)\n    ps = Proxyserver()\n    with taddons.context(ps) as tctx:\n        tctx.configure(ps, mode=[\"transparent\"], server=False)\n        assert init.called\n\n\n@asynccontextmanager\nasync def udp_server(\n    handle_datagram: Callable[\n        [asyncio.DatagramTransport, bytes, tuple[str, int]], None\n    ],\n) -> Address:\n    class ServerProtocol(asyncio.DatagramProtocol):\n        def connection_made(self, transport):\n            self.transport = transport\n\n        def datagram_received(self, data, addr):\n            handle_datagram(self.transport, data, addr)\n\n    loop = asyncio.get_running_loop()\n    transport, _ = await loop.create_datagram_endpoint(\n        lambda: ServerProtocol(),\n        local_addr=(\"127.0.0.1\", 0),\n    )\n    socket = transport.get_extra_info(\"socket\")\n\n    try:\n        yield socket.getsockname()\n    finally:\n        transport.close()\n\n\nasync def test_udp(caplog_async) -> None:\n    caplog_async.set_level(\"INFO\")\n\n    def handle_datagram(\n        transport: asyncio.DatagramTransport,\n        data: bytes,\n        remote_addr: Address,\n    ):\n        assert data == b\"\\x16\"\n        transport.sendto(b\"\\x01\", remote_addr)\n\n    ps = Proxyserver()\n    nl = NextLayer()\n\n    with taddons.context(ps, nl) as tctx:\n        async with udp_server(handle_datagram) as server_addr:\n            mode = f\"reverse:udp://{server_addr[0]}:{server_addr[1]}@127.0.0.1:0\"\n            tctx.configure(ps, mode=[mode])\n            assert await ps.setup_servers()\n            ps.running()\n            await caplog_async.await_log(\n                f\"reverse proxy to udp://{server_addr[0]}:{server_addr[1]} listening\"\n            )\n            assert ps.servers\n            addr = ps.servers[mode].listen_addrs[0]\n            stream = await mitmproxy_rs.open_udp_connection(*addr)\n            stream.write(b\"\\x16\")\n            assert b\"\\x01\" == await stream.read(65535)\n            assert repr(ps) == \"Proxyserver(1 active conns)\"\n            assert len(ps.connections) == 1\n            tctx.configure(ps, server=False)\n            await caplog_async.await_log(\"stopped\")\n\n        stream.close()\n        await stream.wait_closed()\n        await _wait_for_connection_closes(ps)\n\n\nclass H3EchoServer(QuicConnectionProtocol):\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self._seen_headers: set[int] = set()\n        self.http: H3Connection | None = None\n\n    def http_headers_received(self, event: h3_events.HeadersReceived) -> None:\n        assert event.push_id is None\n        headers: dict[bytes, bytes] = {}\n        for name, value in event.headers:\n            headers[name] = value\n        response = []\n        if event.stream_id not in self._seen_headers:\n            self._seen_headers.add(event.stream_id)\n            assert headers[b\":authority\"] == b\"example.mitmproxy.org\"\n            assert headers[b\":method\"] == b\"GET\"\n            assert headers[b\":path\"] == b\"/test\"\n            response.append((b\":status\", b\"200\"))\n        response.append((b\"x-response\", headers[b\"x-request\"]))\n        self.http.send_headers(\n            stream_id=event.stream_id, headers=response, end_stream=event.stream_ended\n        )\n        self.transmit()\n\n    def http_data_received(self, event: h3_events.DataReceived) -> None:\n        assert event.push_id is None\n        assert event.stream_id in self._seen_headers\n        try:\n            self.http.send_data(\n                stream_id=event.stream_id,\n                data=event.data,\n                end_stream=event.stream_ended,\n            )\n        except FrameUnexpected:\n            if event.data or not event.stream_ended:\n                raise\n            self._quic.send_stream_data(\n                stream_id=event.stream_id,\n                data=b\"\",\n                end_stream=True,\n            )\n        self.transmit()\n\n    def http_event_received(self, event: h3_events.H3Event) -> None:\n        if isinstance(event, h3_events.HeadersReceived):\n            self.http_headers_received(event)\n        elif isinstance(event, h3_events.DataReceived):\n            self.http_data_received(event)\n        else:\n            raise AssertionError(event)\n\n    def quic_event_received(self, event: quic_events.QuicEvent) -> None:\n        if isinstance(event, quic_events.ProtocolNegotiated):\n            self.http = H3Connection(self._quic)\n        if self.http is not None:\n            for http_event in self.http.handle_event(event):\n                self.http_event_received(http_event)\n\n\nclass QuicDatagramEchoServer(QuicConnectionProtocol):\n    def quic_event_received(self, event: quic_events.QuicEvent) -> None:\n        if isinstance(event, quic_events.DatagramFrameReceived):\n            self._quic.send_datagram_frame(event.data)\n            self.transmit()\n\n\n@asynccontextmanager\nasync def quic_server(\n    create_protocol, alpn: list[str]\n) -> AsyncGenerator[Address, None]:\n    configuration = QuicConfiguration(\n        is_client=False,\n        alpn_protocols=alpn,\n        max_datagram_frame_size=65536,\n    )\n    configuration.load_cert_chain(\n        certfile=tlsdata.path(\"../net/data/verificationcerts/trusted-leaf.crt\"),\n        keyfile=tlsdata.path(\"../net/data/verificationcerts/trusted-leaf.key\"),\n    )\n    loop = asyncio.get_running_loop()\n    transport, server = await loop.create_datagram_endpoint(\n        lambda: QuicServer(\n            configuration=configuration,\n            create_protocol=create_protocol,\n        ),\n        local_addr=(\"127.0.0.1\", 0),\n    )\n    try:\n        yield transport.get_extra_info(\"sockname\")\n    finally:\n        server.close()\n\n\nclass QuicClient(QuicConnectionProtocol):\n    TIMEOUT: ClassVar[int] = 10\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self._waiter = self._loop.create_future()\n\n    def quic_event_received(self, event: quic_events.QuicEvent) -> None:\n        if not self._waiter.done():\n            if isinstance(event, quic_events.ConnectionTerminated):\n                self._waiter.set_exception(\n                    QuicConnectionError(\n                        event.error_code, event.frame_type, event.reason_phrase\n                    )\n                )\n            elif isinstance(event, quic_events.HandshakeCompleted):\n                self._waiter.set_result(None)\n\n    def connection_lost(self, exc: Exception | None) -> None:\n        if not self._waiter.done():\n            self._waiter.set_exception(exc)\n        return super().connection_lost(exc)\n\n    async def wait_handshake(self) -> None:\n        return await asyncio.wait_for(self._waiter, timeout=QuicClient.TIMEOUT)\n\n\nclass QuicDatagramClient(QuicClient):\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self._datagram: asyncio.Future[bytes] = self._loop.create_future()\n\n    def quic_event_received(self, event: quic_events.QuicEvent) -> None:\n        super().quic_event_received(event)\n        if not self._datagram.done():\n            if isinstance(event, quic_events.DatagramFrameReceived):\n                self._datagram.set_result(event.data)\n            elif isinstance(event, quic_events.ConnectionTerminated):\n                self._datagram.set_exception(\n                    QuicConnectionError(\n                        event.error_code, event.frame_type, event.reason_phrase\n                    )\n                )\n\n    def send_datagram(self, data: bytes) -> None:\n        self._quic.send_datagram_frame(data)\n        self.transmit()\n\n    async def recv_datagram(self) -> bytes:\n        return await asyncio.wait_for(self._datagram, timeout=QuicClient.TIMEOUT)\n\n\n@dataclass\nclass H3Response:\n    waiter: asyncio.Future[H3Response]\n    stream_id: int\n    headers: h3_events.H3Event | None = None\n    data: bytes | None = None\n    trailers: h3_events.H3Event | None = None\n    callback: Callable[[str], None] | None = None\n\n    async def wait_result(self) -> H3Response:\n        return await asyncio.wait_for(self.waiter, timeout=QuicClient.TIMEOUT)\n\n    def __setattr__(self, name: str, value: Any) -> None:\n        super().__setattr__(name, value)\n        if self.callback:\n            self.callback(name)\n\n\nclass H3Client(QuicClient):\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self._responses: dict[int, H3Response] = dict()\n        self.http = H3Connection(self._quic)\n\n    def http_headers_received(self, event: h3_events.HeadersReceived) -> None:\n        assert event.push_id is None\n        response = self._responses[event.stream_id]\n        if response.waiter.done():\n            return\n        if response.headers is None:\n            response.headers = event.headers\n            if event.stream_ended:\n                response.waiter.set_result(response)\n        elif response.trailers is None:\n            response.trailers = event.headers\n            if event.stream_ended:\n                response.waiter.set_result(response)\n        else:\n            response.waiter.set_exception(Exception(\"Headers after trailers received.\"))\n\n    def http_data_received(self, event: h3_events.DataReceived) -> None:\n        assert event.push_id is None\n        response = self._responses[event.stream_id]\n        if response.waiter.done():\n            return\n        if response.headers is None:\n            response.waiter.set_exception(Exception(\"Data without headers received.\"))\n        elif response.trailers is None:\n            if response.data is None:\n                response.data = event.data\n            else:\n                response.data = response.data + event.data\n            if event.stream_ended:\n                response.waiter.set_result(response)\n        elif event.data or not event.stream_ended:\n            response.waiter.set_exception(Exception(\"Data after trailers received.\"))\n        else:\n            response.waiter.set_result(response)\n\n    def http_event_received(self, event: h3_events.H3Event) -> None:\n        if isinstance(event, h3_events.HeadersReceived):\n            self.http_headers_received(event)\n        elif isinstance(event, h3_events.DataReceived):\n            self.http_data_received(event)\n        else:\n            raise AssertionError(event)\n\n    def quic_event_received(self, event: quic_events.QuicEvent) -> None:\n        super().quic_event_received(event)\n        for http_event in self.http.handle_event(event):\n            self.http_event_received(http_event)\n\n    def request(\n        self,\n        headers: h3_events.Headers,\n        data: bytes | None = None,\n        trailers: h3_events.Headers | None = None,\n        end_stream: bool = True,\n    ) -> H3Response:\n        stream_id = self._quic.get_next_available_stream_id()\n        self.http.send_headers(\n            stream_id=stream_id,\n            headers=headers,\n            end_stream=data is None and trailers is None and end_stream,\n        )\n        if data is not None:\n            self.http.send_data(\n                stream_id=stream_id,\n                data=data,\n                end_stream=trailers is None and end_stream,\n            )\n        if trailers is not None:\n            self.http.send_headers(\n                stream_id=stream_id,\n                headers=trailers,\n                end_stream=end_stream,\n            )\n        waiter = self._loop.create_future()\n        response = H3Response(waiter=waiter, stream_id=stream_id)\n        self._responses[stream_id] = response\n        self.transmit()\n        return response\n\n\nT = TypeVar(\"T\", bound=QuicClient)\n\n\n@asynccontextmanager\nasync def quic_connect(\n    cls: type[T],\n    alpn: list[str],\n    address: Address,\n) -> AsyncGenerator[T, None]:\n    configuration = QuicConfiguration(\n        is_client=True,\n        alpn_protocols=alpn,\n        server_name=\"example.mitmproxy.org\",\n        verify_mode=ssl.CERT_NONE,\n        max_datagram_frame_size=65536,\n    )\n    loop = asyncio.get_running_loop()\n    transport, protocol = await loop.create_datagram_endpoint(\n        lambda: cls(QuicConnection(configuration=configuration)),\n        local_addr=(\"127.0.0.1\", 0),\n    )\n    assert isinstance(protocol, cls)\n    try:\n        protocol.connect(address)\n        await protocol.wait_handshake()\n        yield protocol\n    finally:\n        protocol.close()\n        await protocol.wait_closed()\n        transport.close()\n\n\nasync def _test_echo(client: H3Client, strict: bool) -> None:\n    def assert_no_data(response: H3Response):\n        if strict:\n            assert response.data is None\n        else:\n            assert not response.data\n\n    headers = [\n        (b\":scheme\", b\"https\"),\n        (b\":authority\", b\"example.mitmproxy.org\"),\n        (b\":method\", b\"GET\"),\n        (b\":path\", b\"/test\"),\n    ]\n    r1 = await client.request(\n        headers=headers + [(b\"x-request\", b\"justheaders\")],\n        data=None,\n        trailers=None,\n    ).wait_result()\n    assert r1.headers == [\n        (b\":status\", b\"200\"),\n        (b\"x-response\", b\"justheaders\"),\n    ]\n    assert_no_data(r1)\n    assert r1.trailers is None\n\n    r2 = await client.request(\n        headers=headers + [(b\"x-request\", b\"hasdata\")],\n        data=b\"echo\",\n        trailers=None,\n    ).wait_result()\n    assert r2.headers == [\n        (b\":status\", b\"200\"),\n        (b\"x-response\", b\"hasdata\"),\n    ]\n    assert r2.data == b\"echo\"\n    assert r2.trailers is None\n\n    r3 = await client.request(\n        headers=headers + [(b\"x-request\", b\"nodata\")],\n        data=None,\n        trailers=[(b\"x-request\", b\"buttrailers\")],\n    ).wait_result()\n    assert r3.headers == [\n        (b\":status\", b\"200\"),\n        (b\"x-response\", b\"nodata\"),\n    ]\n    assert_no_data(r3)\n    assert r3.trailers == [(b\"x-response\", b\"buttrailers\")]\n\n    r4 = await client.request(\n        headers=headers + [(b\"x-request\", b\"this\")],\n        data=b\"has\",\n        trailers=[(b\"x-request\", b\"everything\")],\n    ).wait_result()\n    assert r4.headers == [\n        (b\":status\", b\"200\"),\n        (b\"x-response\", b\"this\"),\n    ]\n    assert r4.data == b\"has\"\n    assert r4.trailers == [(b\"x-response\", b\"everything\")]\n\n    # the following test makes sure that we behave properly if end_stream is sent separately\n    r5 = client.request(\n        headers=headers + [(b\"x-request\", b\"this\")],\n        data=b\"has\",\n        trailers=[(b\"x-request\", b\"everything but end_stream\")],\n        end_stream=False,\n    )\n    if not strict:\n        trailer_waiter = asyncio.get_running_loop().create_future()\n        r5.callback = lambda name: name != \"trailers\" or trailer_waiter.set_result(None)\n        await asyncio.wait_for(trailer_waiter, timeout=QuicClient.TIMEOUT)\n        assert r5.trailers is not None\n        assert not r5.waiter.done()\n    else:\n        await asyncio.sleep(0)\n    client._quic.send_stream_data(\n        stream_id=r5.stream_id,\n        data=b\"\",\n        end_stream=True,\n    )\n    client.transmit()\n    await r5.wait_result()\n    assert r5.headers == [\n        (b\":status\", b\"200\"),\n        (b\"x-response\", b\"this\"),\n    ]\n    assert r5.data == b\"has\"\n    assert r5.trailers == [(b\"x-response\", b\"everything but end_stream\")]\n\n\n@pytest.mark.parametrize(\"scheme\", [\"http3\", \"quic\"])\nasync def test_reverse_http3_and_quic_stream(caplog_async, scheme: str) -> None:\n    caplog_async.set_level(\"INFO\")\n    ps = Proxyserver()\n    nl = NextLayer()\n    ta = TlsConfig()\n    with taddons.context(ps, nl, ta) as tctx:\n        tctx.options.keep_host_header = True\n        ta.configure([\"confdir\"])\n        async with quic_server(H3EchoServer, alpn=[\"h3\"]) as server_addr:\n            mode = f\"reverse:{scheme}://{server_addr[0]}:{server_addr[1]}@127.0.0.1:0\"\n            tctx.configure(\n                ta,\n                ssl_verify_upstream_trusted_ca=tlsdata.path(\n                    \"../net/data/verificationcerts/trusted-root.crt\"\n                ),\n            )\n            tctx.configure(ps, mode=[mode])\n            assert await ps.setup_servers()\n            ps.running()\n            await caplog_async.await_log(\n                f\"reverse proxy to {scheme}://{server_addr[0]}:{server_addr[1]} listening\"\n            )\n            assert ps.servers\n            addr = ps.servers[mode].listen_addrs[0]\n            async with quic_connect(H3Client, alpn=[\"h3\"], address=addr) as client:\n                await _test_echo(client, strict=scheme == \"http3\")\n                assert len(ps.connections) == 1\n\n            tctx.configure(ps, server=False)\n            await caplog_async.await_log(f\"stopped\")\n            await _wait_for_connection_closes(ps)\n\n\nasync def test_reverse_quic_datagram(caplog_async) -> None:\n    caplog_async.set_level(\"INFO\")\n    ps = Proxyserver()\n    nl = NextLayer()\n    ta = TlsConfig()\n    with taddons.context(ps, nl, ta) as tctx:\n        tctx.options.keep_host_header = True\n        ta.configure([\"confdir\"])\n        async with quic_server(QuicDatagramEchoServer, alpn=[\"dgram\"]) as server_addr:\n            mode = f\"reverse:quic://{server_addr[0]}:{server_addr[1]}@127.0.0.1:0\"\n            tctx.configure(\n                ta,\n                ssl_verify_upstream_trusted_ca=tlsdata.path(\n                    \"../net/data/verificationcerts/trusted-root.crt\"\n                ),\n            )\n            tctx.configure(ps, mode=[mode])\n            assert await ps.setup_servers()\n            ps.running()\n            await caplog_async.await_log(\n                f\"reverse proxy to quic://{server_addr[0]}:{server_addr[1]} listening\"\n            )\n            assert ps.servers\n            addr = ps.servers[mode].listen_addrs[0]\n            async with quic_connect(\n                QuicDatagramClient, alpn=[\"dgram\"], address=addr\n            ) as client:\n                client.send_datagram(b\"echo\")\n                assert await client.recv_datagram() == b\"echo\"\n\n            tctx.configure(ps, server=False)\n            await caplog_async.await_log(\"stopped\")\n            await _wait_for_connection_closes(ps)\n\n\n@pytest.mark.skip(\"HTTP/3 for regular mode is not fully supported yet\")\nasync def test_regular_http3(caplog_async, monkeypatch) -> None:\n    caplog_async.set_level(\"INFO\")\n    ps = Proxyserver()\n    nl = NextLayer()\n    ta = TlsConfig()\n    with taddons.context(ps, nl, ta) as tctx:\n        ta.configure([\"confdir\"])\n        async with quic_server(H3EchoServer, alpn=[\"h3\"]) as server_addr:\n            orig_open_connection = mitmproxy_rs.open_udp_connection\n\n            async def open_connection_path(\n                host: str, port: int, *args, **kwargs\n            ) -> mitmproxy_rs.Stream:\n                if host == \"example.mitmproxy.org\" and port == 443:\n                    host = server_addr[0]\n                    port = server_addr[1]\n                return orig_open_connection(host, port, *args, **kwargs)\n\n            monkeypatch.setattr(\n                mitmproxy_rs, \"open_udp_connection\", open_connection_path\n            )\n            mode = f\"http3@127.0.0.1:0\"\n            tctx.configure(\n                ta,\n                ssl_verify_upstream_trusted_ca=tlsdata.path(\n                    \"../net/data/verificationcerts/trusted-root.crt\"\n                ),\n            )\n            tctx.configure(ps, mode=[mode])\n            assert await ps.setup_servers()\n            ps.running()\n            await caplog_async.await_log(f\"HTTP3 proxy listening\")\n            assert ps.servers\n            addr = ps.servers[mode].listen_addrs[0]\n            async with quic_connect(H3Client, alpn=[\"h3\"], address=addr) as client:\n                await _test_echo(client=client, strict=True)\n                assert len(ps.connections) == 1\n\n            tctx.configure(ps, server=False)\n            await caplog_async.await_log(\"stopped\")\n            await _wait_for_connection_closes(ps)\n", "test/mitmproxy/addons/__init__.py": "", "test/mitmproxy/addons/test_command_history.py": "import os\nfrom pathlib import Path\nfrom unittest.mock import patch\n\nfrom mitmproxy.addons import command_history\nfrom mitmproxy.test import taddons\n\n\nclass TestCommandHistory:\n    def test_load_and_save(self, tmpdir):\n        history_file = tmpdir.join(\"command_history\")\n        commands = [\"cmd1\", \"cmd2\", \"cmd3\"]\n        with open(history_file, \"w\") as f:\n            f.write(\"\\n\".join(commands))\n\n        ch = command_history.CommandHistory()\n        ch.VACUUM_SIZE = 4\n        with taddons.context(ch) as tctx:\n            tctx.options.confdir = str(tmpdir)\n            assert ch.history == commands\n            ch.add_command(\"cmd4\")\n            ch.done()\n\n        with open(history_file) as f:\n            assert f.read() == \"cmd3\\ncmd4\\n\"\n\n    async def test_done_writing_failed(self, caplog):\n        ch = command_history.CommandHistory()\n        ch.VACUUM_SIZE = 1\n        with taddons.context(ch) as tctx:\n            ch.history.append(\"cmd1\")\n            ch.history.append(\"cmd2\")\n            ch.history.append(\"cmd3\")\n            tctx.options.confdir = \"/non/existent/path/foobar1234/\"\n            ch.done()\n            assert \"Failed writing to\" in caplog.text\n\n    def test_add_command(self):\n        ch = command_history.CommandHistory()\n        with taddons.context(ch):\n            ch.add_command(\"cmd1\")\n            ch.add_command(\"cmd2\")\n            assert ch.history == [\"cmd1\", \"cmd2\"]\n\n            ch.add_command(\"\")\n            assert ch.history == [\"cmd1\", \"cmd2\"]\n\n    async def test_add_command_failed(self, caplog):\n        ch = command_history.CommandHistory()\n        with taddons.context(ch) as tctx:\n            tctx.options.confdir = \"/non/existent/path/foobar1234/\"\n            ch.add_command(\"cmd1\")\n            assert \"Failed writing to\" in caplog.text\n\n    def test_get_next_and_prev(self, tmpdir):\n        ch = command_history.CommandHistory()\n\n        with taddons.context(ch) as tctx:\n            tctx.options.confdir = str(tmpdir)\n\n            ch.add_command(\"cmd1\")\n\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n\n            ch.add_command(\"cmd2\")\n\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n            assert ch.get_prev() == \"cmd2\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_next() == \"cmd2\"\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n\n            ch.add_command(\"cmd3\")\n\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n            assert ch.get_prev() == \"cmd3\"\n            assert ch.get_prev() == \"cmd2\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_next() == \"cmd2\"\n            assert ch.get_next() == \"cmd3\"\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n            assert ch.get_prev() == \"cmd3\"\n            assert ch.get_prev() == \"cmd2\"\n\n            ch.add_command(\"cmd4\")\n\n            assert ch.get_prev() == \"cmd4\"\n            assert ch.get_prev() == \"cmd3\"\n            assert ch.get_prev() == \"cmd2\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_next() == \"cmd2\"\n            assert ch.get_next() == \"cmd3\"\n            assert ch.get_next() == \"cmd4\"\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n\n            ch.add_command(\"cmd5\")\n            ch.add_command(\"cmd6\")\n\n            assert ch.get_next() == \"\"\n            assert ch.get_prev() == \"cmd6\"\n            assert ch.get_prev() == \"cmd5\"\n            assert ch.get_prev() == \"cmd4\"\n            assert ch.get_next() == \"cmd5\"\n            assert ch.get_prev() == \"cmd4\"\n            assert ch.get_prev() == \"cmd3\"\n            assert ch.get_prev() == \"cmd2\"\n            assert ch.get_next() == \"cmd3\"\n            assert ch.get_prev() == \"cmd2\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_next() == \"cmd2\"\n            assert ch.get_next() == \"cmd3\"\n            assert ch.get_next() == \"cmd4\"\n            assert ch.get_next() == \"cmd5\"\n            assert ch.get_next() == \"cmd6\"\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n\n            ch.clear_history()\n\n    def test_clear(self, tmpdir):\n        ch = command_history.CommandHistory()\n\n        with taddons.context(ch) as tctx:\n            tctx.options.confdir = str(tmpdir)\n            ch.add_command(\"cmd1\")\n            ch.add_command(\"cmd2\")\n            ch.clear_history()\n\n            saved_commands = ch.get_history()\n            assert saved_commands == []\n\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n            assert ch.get_prev() == \"\"\n            assert ch.get_prev() == \"\"\n\n            ch.clear_history()\n\n    async def test_clear_failed(self, monkeypatch, caplog):\n        ch = command_history.CommandHistory()\n\n        with taddons.context(ch) as tctx:\n            tctx.options.confdir = \"/non/existent/path/foobar1234/\"\n\n            with patch.object(Path, \"exists\") as mock_exists:\n                mock_exists.return_value = True\n                with patch.object(Path, \"unlink\") as mock_unlink:\n                    mock_unlink.side_effect = IOError()\n                    ch.clear_history()\n            assert \"Failed deleting\" in caplog.text\n\n    def test_filter(self, tmpdir):\n        ch = command_history.CommandHistory()\n\n        with taddons.context(ch) as tctx:\n            tctx.options.confdir = str(tmpdir)\n\n            ch.add_command(\"cmd1\")\n            ch.add_command(\"cmd2\")\n            ch.add_command(\"abc\")\n            ch.set_filter(\"c\")\n\n            assert ch.get_next() == \"c\"\n            assert ch.get_next() == \"c\"\n            assert ch.get_prev() == \"cmd2\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_next() == \"cmd2\"\n            assert ch.get_next() == \"c\"\n            assert ch.get_next() == \"c\"\n\n            ch.set_filter(\"\")\n\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n            assert ch.get_prev() == \"abc\"\n            assert ch.get_prev() == \"cmd2\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_prev() == \"cmd1\"\n            assert ch.get_next() == \"cmd2\"\n            assert ch.get_next() == \"abc\"\n            assert ch.get_next() == \"\"\n            assert ch.get_next() == \"\"\n\n            ch.clear_history()\n\n    def test_multiple_instances(self, tmpdir):\n        ch = command_history.CommandHistory()\n        with taddons.context(ch) as tctx:\n            tctx.options.confdir = str(tmpdir)\n\n        instances = [\n            command_history.CommandHistory(),\n            command_history.CommandHistory(),\n            command_history.CommandHistory(),\n        ]\n\n        for i in instances:\n            i.configure(\"command_history\")\n            saved_commands = i.get_history()\n            assert saved_commands == []\n\n        instances[0].add_command(\"cmd1\")\n        saved_commands = instances[0].get_history()\n        assert saved_commands == [\"cmd1\"]\n\n        # These instances haven't yet added a new command, so they haven't\n        # yet reloaded their commands from the command file.\n        # This is expected, because if the user is filtering a command on\n        # another window, we don't want to interfere with that\n        saved_commands = instances[1].get_history()\n        assert saved_commands == []\n        saved_commands = instances[2].get_history()\n        assert saved_commands == []\n\n        # Since the second instanced added a new command, its list of\n        # saved commands has been updated to have the commands from the\n        # first instance + its own commands\n        instances[1].add_command(\"cmd2\")\n        saved_commands = instances[1].get_history()\n        assert saved_commands == [\"cmd2\"]\n\n        saved_commands = instances[0].get_history()\n        assert saved_commands == [\"cmd1\"]\n\n        # Third instance is still empty as it has not yet ran any command\n        saved_commands = instances[2].get_history()\n        assert saved_commands == []\n\n        instances[2].add_command(\"cmd3\")\n        saved_commands = instances[2].get_history()\n        assert saved_commands == [\"cmd3\"]\n\n        instances[0].add_command(\"cmd4\")\n        saved_commands = instances[0].get_history()\n        assert saved_commands == [\"cmd1\", \"cmd4\"]\n\n        instances.append(command_history.CommandHistory())\n        instances[3].configure(\"command_history\")\n        saved_commands = instances[3].get_history()\n        assert saved_commands == [\"cmd1\", \"cmd2\", \"cmd3\", \"cmd4\"]\n\n        instances[0].add_command(\"cmd_before_close\")\n        instances.pop(0).done()\n\n        saved_commands = instances[0].get_history()\n        assert saved_commands == [\"cmd2\"]\n\n        instances[0].add_command(\"new_cmd\")\n        saved_commands = instances[0].get_history()\n        assert saved_commands == [\"cmd2\", \"new_cmd\"]\n\n        instances.pop(0).done()\n        instances.pop(0).done()\n        instances.pop(0).done()\n\n        _path = os.path.join(tctx.options.confdir, \"command_history\")\n        lines = open(_path).readlines()\n        saved_commands = [cmd.strip() for cmd in lines]\n        assert saved_commands == [\n            \"cmd1\",\n            \"cmd2\",\n            \"cmd3\",\n            \"cmd4\",\n            \"cmd_before_close\",\n            \"new_cmd\",\n        ]\n\n        instances = [command_history.CommandHistory(), command_history.CommandHistory()]\n\n        for i in instances:\n            i.configure(\"command_history\")\n            i.clear_history()\n            saved_commands = i.get_history()\n            assert saved_commands == []\n\n        instances[0].add_command(\"cmd1\")\n        instances[0].add_command(\"cmd2\")\n        instances[1].add_command(\"cmd3\")\n        instances[1].add_command(\"cmd4\")\n        instances[1].add_command(\"cmd5\")\n\n        saved_commands = instances[1].get_history()\n        assert saved_commands == [\"cmd3\", \"cmd4\", \"cmd5\"]\n\n        instances.pop().done()\n        instances.pop().done()\n\n        _path = os.path.join(tctx.options.confdir, \"command_history\")\n        lines = open(_path).readlines()\n        saved_commands = [cmd.strip() for cmd in lines]\n        assert saved_commands == [\"cmd1\", \"cmd2\", \"cmd3\", \"cmd4\", \"cmd5\"]\n", "test/mitmproxy/addons/test_anticache.py": "from mitmproxy.addons import anticache\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\nclass TestAntiCache:\n    def test_simple(self):\n        sa = anticache.AntiCache()\n        with taddons.context(sa) as tctx:\n            f = tflow.tflow(resp=True)\n            f.request.headers[\"if-modified-since\"] = \"test\"\n            f.request.headers[\"if-none-match\"] = \"test\"\n\n            sa.request(f)\n            assert \"if-modified-since\" in f.request.headers\n            assert \"if-none-match\" in f.request.headers\n\n            tctx.configure(sa, anticache=True)\n            sa.request(f)\n            assert \"if-modified-since\" not in f.request.headers\n            assert \"if-none-match\" not in f.request.headers\n", "test/mitmproxy/addons/test_script.py": "import asyncio\nimport os\nimport re\nimport sys\nimport traceback\n\nimport pytest\n\nfrom mitmproxy import addonmanager\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import script\nfrom mitmproxy.proxy.layers.http import HttpRequestHook\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.tools import main\n\n# We want this to be speedy for testing\nscript.ReloadInterval = 0.1\n\n\ndef test_load_script(tmp_path, tdata, caplog):\n    ns = script.load_script(\n        tdata.path(\"mitmproxy/data/addonscripts/recorder/recorder.py\")\n    )\n    assert ns.addons\n\n    script.load_script(\"nonexistent\")\n    assert \"FileNotFoundError\" in caplog.text\n\n    (tmp_path / \"error.py\").write_text(\"this is invalid syntax\")\n    script.load_script(str(tmp_path / \"error.py\"))\n    assert \"invalid syntax\" in caplog.text\n\n\ndef test_load_fullname(tdata):\n    \"\"\"\n    Test that loading two scripts at locations a/foo.py and b/foo.py works.\n    This only succeeds if they get assigned different basenames.\n\n    \"\"\"\n    ns = script.load_script(tdata.path(\"mitmproxy/data/addonscripts/addon.py\"))\n    assert ns.addons\n    ns2 = script.load_script(\n        tdata.path(\"mitmproxy/data/addonscripts/same_filename/addon.py\")\n    )\n    assert ns.name != ns2.name\n    assert not hasattr(ns2, \"addons\")\n\n\nclass TestScript:\n    def test_notfound(self):\n        with taddons.context():\n            with pytest.raises(exceptions.OptionsError):\n                script.Script(\"nonexistent\", False)\n\n    def test_quotes_around_filename(self, tdata):\n        \"\"\"\n        Test that a script specified as '\"foo.py\"' works to support the calling convention of\n        mitmproxy 2.0, as e.g. used by Cuckoo Sandbox.\n        \"\"\"\n        path = tdata.path(\"mitmproxy/data/addonscripts/recorder/recorder.py\")\n\n        s = script.Script(f'\"{path}\"', False)\n        assert '\"' not in s.fullpath\n\n    async def test_simple(self, tdata, caplog_async):\n        caplog_async.set_level(\"DEBUG\")\n        sc = script.Script(\n            tdata.path(\"mitmproxy/data/addonscripts/recorder/recorder.py\"),\n            True,\n        )\n        with taddons.context(sc) as tctx:\n            tctx.configure(sc)\n            await caplog_async.await_log(\"recorder configure\")\n            rec = tctx.master.addons.get(\"recorder\")\n\n            assert rec.call_log[0][0:2] == (\"recorder\", \"load\")\n\n            rec.call_log = []\n            f = tflow.tflow(resp=True)\n            tctx.master.addons.trigger(HttpRequestHook(f))\n\n            assert rec.call_log[0][1] == \"request\"\n        sc.done()\n\n    async def test_reload(self, tmp_path, caplog_async):\n        caplog_async.set_level(\"INFO\")\n        with taddons.context() as tctx:\n            f = tmp_path / \"foo.py\"\n            f.write_text(\"\\n\")\n            sc = script.Script(str(f), True)\n            tctx.configure(sc)\n            await caplog_async.await_log(\"Loading\")\n            caplog_async.clear()\n\n            for i in range(20):\n                # Some filesystems only have second-level granularity,\n                # so just writing once again is not good enough.\n                f.write_text(\"\\n\")\n                if \"Loading\" in caplog_async.caplog.text:\n                    break\n                await asyncio.sleep(0.1)\n            else:\n                raise AssertionError(\"No reload seen\")\n            sc.done()\n\n    async def test_exception(self, tdata, caplog_async):\n        caplog_async.set_level(\"INFO\")\n        with taddons.context() as tctx:\n            sc = script.Script(\n                tdata.path(\"mitmproxy/data/addonscripts/error.py\"),\n                True,\n            )\n            tctx.master.addons.add(sc)\n            await caplog_async.await_log(\"error load\")\n            tctx.configure(sc)\n\n            f = tflow.tflow(resp=True)\n            tctx.master.addons.trigger(HttpRequestHook(f))\n\n            await caplog_async.await_log(\"ValueError: Error!\")\n            await caplog_async.await_log(\"error.py\")\n            sc.done()\n\n    def test_import_error(self, monkeypatch, tdata, caplog):\n        monkeypatch.setattr(sys, \"frozen\", True, raising=False)\n        script.Script(\n            tdata.path(\"mitmproxy/data/addonscripts/import_error.py\"),\n            reload=False,\n        )\n        assert (\n            \"Note that mitmproxy's binaries include their own Python environment\"\n            in caplog.text\n        )\n\n    def test_configure_error(self, tdata, caplog):\n        with taddons.context():\n            script.Script(\n                tdata.path(\"mitmproxy/data/addonscripts/configure.py\"),\n                False,\n            )\n            assert \"Options Error\" in caplog.text\n\n    async def test_addon(self, tdata, caplog_async):\n        caplog_async.set_level(\"INFO\")\n        with taddons.context() as tctx:\n            sc = script.Script(tdata.path(\"mitmproxy/data/addonscripts/addon.py\"), True)\n            tctx.master.addons.add(sc)\n            await caplog_async.await_log(\"addon running\")\n            assert sc.ns.event_log == [\n                \"scriptload\",\n                \"addonload\",\n                \"scriptconfigure\",\n                \"addonconfigure\",\n            ]\n            sc.done()\n\n\nclass TestCutTraceback:\n    def raise_(self, i):\n        if i > 0:\n            self.raise_(i - 1)\n        raise RuntimeError()\n\n    def test_simple(self):\n        try:\n            self.raise_(4)\n        except RuntimeError:\n            tb = sys.exc_info()[2]\n            tb_cut = addonmanager.cut_traceback(tb, \"test_simple\")\n            assert len(traceback.extract_tb(tb_cut)) == 5\n\n            tb_cut2 = addonmanager.cut_traceback(tb, \"nonexistent\")\n            assert len(traceback.extract_tb(tb_cut2)) == len(traceback.extract_tb(tb))\n\n\nclass TestScriptLoader:\n    async def test_script_run(self, tdata, caplog_async):\n        caplog_async.set_level(\"DEBUG\")\n        rp = tdata.path(\"mitmproxy/data/addonscripts/recorder/recorder.py\")\n        sc = script.ScriptLoader()\n        with taddons.context(sc):\n            sc.script_run([tflow.tflow(resp=True)], rp)\n            await caplog_async.await_log(\"recorder response\")\n            debug = [\n                i.msg for i in caplog_async.caplog.records if i.levelname == \"DEBUG\"\n            ]\n            assert debug == [\n                \"recorder configure\",\n                \"recorder running\",\n                \"recorder requestheaders\",\n                \"recorder request\",\n                \"recorder responseheaders\",\n                \"recorder response\",\n            ]\n\n    async def test_script_run_nonexistent(self, caplog):\n        sc = script.ScriptLoader()\n        sc.script_run([tflow.tflow(resp=True)], \"/\")\n        assert \"No such script\" in caplog.text\n\n    async def test_simple(self, tdata):\n        sc = script.ScriptLoader()\n        with taddons.context(loadcore=False) as tctx:\n            tctx.master.addons.add(sc)\n            sc.running()\n            assert len(tctx.master.addons) == 1\n            tctx.master.options.update(\n                scripts=[tdata.path(\"mitmproxy/data/addonscripts/recorder/recorder.py\")]\n            )\n            assert len(tctx.master.addons) == 1\n            assert len(sc.addons) == 1\n            tctx.master.options.update(scripts=[])\n            assert len(tctx.master.addons) == 1\n            assert len(sc.addons) == 0\n\n    def test_dupes(self):\n        sc = script.ScriptLoader()\n        with taddons.context(sc) as tctx:\n            with pytest.raises(exceptions.OptionsError):\n                tctx.configure(sc, scripts=[\"one\", \"one\"])\n\n    async def test_script_deletion(self, tdata, caplog_async):\n        caplog_async.set_level(\"INFO\")\n        tdir = tdata.path(\"mitmproxy/data/addonscripts/\")\n        with open(tdir + \"/dummy.py\", \"w\") as f:\n            f.write(\"\\n\")\n\n        with taddons.context() as tctx:\n            sl = script.ScriptLoader()\n            tctx.master.addons.add(sl)\n            tctx.configure(\n                sl, scripts=[tdata.path(\"mitmproxy/data/addonscripts/dummy.py\")]\n            )\n            await caplog_async.await_log(\"Loading\")\n\n            os.remove(tdata.path(\"mitmproxy/data/addonscripts/dummy.py\"))\n\n            await caplog_async.await_log(\"Removing\")\n            await asyncio.sleep(0.1)\n            assert not tctx.options.scripts\n            assert not sl.addons\n\n    async def test_order(self, tdata, caplog_async):\n        caplog_async.set_level(\"DEBUG\")\n        rec = tdata.path(\"mitmproxy/data/addonscripts/recorder\")\n        sc = script.ScriptLoader()\n        sc.is_running = True\n        with taddons.context(sc) as tctx:\n            tctx.configure(\n                sc,\n                scripts=[\n                    \"%s/a.py\" % rec,\n                    \"%s/b.py\" % rec,\n                    \"%s/c.py\" % rec,\n                ],\n            )\n            await caplog_async.await_log(\"configure\")\n            debug = [\n                i.msg for i in caplog_async.caplog.records if i.levelname == \"DEBUG\"\n            ]\n            assert debug == [\n                \"a load\",\n                \"a configure\",\n                \"a running\",\n                \"b load\",\n                \"b configure\",\n                \"b running\",\n                \"c load\",\n                \"c configure\",\n                \"c running\",\n            ]\n\n            caplog_async.clear()\n            tctx.configure(\n                sc,\n                scripts=[\n                    \"%s/c.py\" % rec,\n                    \"%s/a.py\" % rec,\n                    \"%s/b.py\" % rec,\n                ],\n            )\n\n            await caplog_async.await_log(\"b configure\")\n            debug = [\n                i.msg for i in caplog_async.caplog.records if i.levelname == \"DEBUG\"\n            ]\n            assert debug == [\n                \"c configure\",\n                \"a configure\",\n                \"b configure\",\n            ]\n\n            caplog_async.clear()\n            tctx.configure(\n                sc,\n                scripts=[\n                    \"%s/e.py\" % rec,\n                    \"%s/a.py\" % rec,\n                ],\n            )\n            await caplog_async.await_log(\"e configure\")\n            debug = [\n                i.msg for i in caplog_async.caplog.records if i.levelname == \"DEBUG\"\n            ]\n            assert debug == [\n                \"c done\",\n                \"b done\",\n                \"a configure\",\n                \"e load\",\n                \"e configure\",\n                \"e running\",\n            ]\n\n            # stop reload tasks\n            tctx.configure(sc, scripts=[])\n\n\ndef test_order(tdata, capsys):\n    \"\"\"Integration test: Make sure that the runtime hooks are triggered on startup in the correct order.\"\"\"\n    main.mitmdump(\n        [\n            \"-n\",\n            \"-s\",\n            tdata.path(\"mitmproxy/data/addonscripts/recorder/recorder.py\"),\n            \"-s\",\n            tdata.path(\"mitmproxy/data/addonscripts/shutdown.py\"),\n        ]\n    )\n    time = r\"\\[[\\d:.]+\\] \"\n    out = capsys.readouterr().out\n    assert re.match(\n        rf\"{time}Loading script.+recorder.py\\n\"\n        rf\"{time}\\('recorder', 'load', .+\\n\"\n        rf\"{time}\\('recorder', 'configure', .+\\n\"\n        rf\"{time}Loading script.+shutdown.py\\n\"\n        rf\"{time}\\('recorder', 'running', .+\\n\"\n        rf\"{time}\\('recorder', 'done', .+\\n$\",\n        out,\n    )\n", "test/mitmproxy/addons/test_stickyauth.py": "import pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons import stickyauth\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\ndef test_configure():\n    r = stickyauth.StickyAuth()\n    with taddons.context(r) as tctx:\n        tctx.configure(r, stickyauth=\"~s\")\n        with pytest.raises(exceptions.OptionsError):\n            tctx.configure(r, stickyauth=\"~~\")\n\n        tctx.configure(r, stickyauth=None)\n        assert not r.flt\n\n\ndef test_simple():\n    r = stickyauth.StickyAuth()\n    with taddons.context(r) as tctx:\n        tctx.configure(r, stickyauth=\".*\")\n        f = tflow.tflow(resp=True)\n        f.request.headers[\"authorization\"] = \"foo\"\n        r.request(f)\n\n        assert \"address\" in r.hosts\n\n        f = tflow.tflow(resp=True)\n        r.request(f)\n        assert f.request.headers[\"authorization\"] == \"foo\"\n", "test/mitmproxy/addons/test_disable_h2c.py": "from mitmproxy import flow\nfrom mitmproxy.addons import disable_h2c\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nclass TestDisableH2CleartextUpgrade:\n    def test_upgrade(self):\n        with taddons.context() as tctx:\n            a = disable_h2c.DisableH2C()\n            tctx.configure(a)\n\n            f = tflow.tflow()\n            f.request.headers[\"upgrade\"] = \"h2c\"\n            f.request.headers[\"connection\"] = \"foo\"\n            f.request.headers[\"http2-settings\"] = \"bar\"\n\n            a.request(f)\n            assert \"upgrade\" not in f.request.headers\n            assert \"connection\" not in f.request.headers\n            assert \"http2-settings\" not in f.request.headers\n\n    def test_prior_knowledge(self):\n        with taddons.context() as tctx:\n            a = disable_h2c.DisableH2C()\n            tctx.configure(a)\n\n            f = tflow.tflow()\n            f.request = tutils.treq(\n                method=b\"PRI\",\n                path=b\"*\",\n                http_version=b\"HTTP/2.0\",\n            )\n            f.intercept()\n\n            a.request(f)\n            assert not f.killable\n            assert f.error.msg == flow.Error.KILLED_MESSAGE\n", "test/mitmproxy/addons/test_view.py": "import pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import flowfilter\nfrom mitmproxy import io\nfrom mitmproxy.addons import view\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.tools.console import consoleaddons\nfrom mitmproxy.tools.console.common import render_marker\nfrom mitmproxy.tools.console.common import SYMBOL_MARK\n\n\ndef tft(*, method=\"get\", start=0):\n    f = tflow.tflow()\n    f.request.method = method\n    f.timestamp_created = start\n    return f\n\n\ndef test_order_refresh():\n    v = view.View()\n    sargs = []\n\n    def save(*args, **kwargs):\n        sargs.extend([args, kwargs])\n\n    v.sig_view_refresh.connect(save)\n\n    tf = tflow.tflow(resp=True)\n    with taddons.context() as tctx:\n        tctx.configure(v, view_order=\"time\")\n        v.add([tf])\n        tf.timestamp_created = 10\n        assert not sargs\n        v.update([tf])\n        assert sargs\n\n\ndef test_order_generators_http():\n    v = view.View()\n    tf = tflow.tflow(resp=True)\n\n    rs = view.OrderRequestStart(v)\n    assert rs.generate(tf) == 946681200\n\n    rm = view.OrderRequestMethod(v)\n    assert rm.generate(tf) == tf.request.method\n\n    ru = view.OrderRequestURL(v)\n    assert ru.generate(tf) == tf.request.url\n\n    sz = view.OrderKeySize(v)\n    assert sz.generate(tf) == len(tf.request.raw_content) + len(tf.response.raw_content)\n\n\ndef test_order_generators_dns():\n    v = view.View()\n    tf = tflow.tdnsflow(resp=True)\n\n    rs = view.OrderRequestStart(v)\n    assert rs.generate(tf) == 946681200\n\n    rm = view.OrderRequestMethod(v)\n    assert rm.generate(tf) == \"QUERY\"\n\n    ru = view.OrderRequestURL(v)\n    assert ru.generate(tf) == \"dns.google\"\n\n    sz = view.OrderKeySize(v)\n    assert sz.generate(tf) == tf.response.size\n\n    tf = tflow.tdnsflow(resp=False)\n    assert sz.generate(tf) == 0\n\n\ndef order_generators_proto(tf, name):\n    v = view.View()\n    rs = view.OrderRequestStart(v)\n    assert rs.generate(tf) == 946681200\n\n    rm = view.OrderRequestMethod(v)\n    assert rm.generate(tf) == name\n\n    ru = view.OrderRequestURL(v)\n    assert ru.generate(tf) == \"address:22\"\n\n    sz = view.OrderKeySize(v)\n    assert sz.generate(tf) == sum(len(m.content) for m in tf.messages)\n\n\ndef test_order_generators_tcp():\n    order_generators_proto(tflow.ttcpflow(), \"TCP\")\n\n\ndef test_order_generators_udp():\n    order_generators_proto(tflow.tudpflow(), \"UDP\")\n\n\ndef test_simple():\n    v = view.View()\n    f = tft(start=1)\n    assert v.store_count() == 0\n    v.requestheaders(f)\n    assert list(v) == [f]\n    assert v.get_by_id(f.id)\n    assert not v.get_by_id(\"nonexistent\")\n\n    # These all just call update\n    v.error(f)\n    v.response(f)\n    v.intercept(f)\n    v.resume(f)\n    v.kill(f)\n    assert list(v) == [f]\n\n    v.requestheaders(f)\n    assert list(v) == [f]\n    assert len(v._store) == 1\n    assert v.store_count() == 1\n\n    f2 = tft(start=3)\n    v.requestheaders(f2)\n    assert list(v) == [f, f2]\n    v.requestheaders(f2)\n    assert list(v) == [f, f2]\n    assert len(v._store) == 2\n\n    assert v.inbounds(0)\n    assert not v.inbounds(-1)\n    assert not v.inbounds(100)\n\n    f3 = tft(start=2)\n    v.requestheaders(f3)\n    assert list(v) == [f, f3, f2]\n    v.requestheaders(f3)\n    assert list(v) == [f, f3, f2]\n    assert len(v._store) == 3\n\n    f.marked = not f.marked\n    f2.marked = not f2.marked\n    v.clear_not_marked()\n    assert list(v) == [f, f2]\n    assert len(v) == 2\n    assert len(v._store) == 2\n\n    v.clear()\n    assert len(v) == 0\n    assert len(v._store) == 0\n\n\ndef test_simple_tcp():\n    v = view.View()\n    f = tflow.ttcpflow()\n    assert v.store_count() == 0\n    v.tcp_start(f)\n    assert list(v) == [f]\n\n    # These all just call update\n    v.tcp_start(f)\n    v.tcp_message(f)\n    v.tcp_error(f)\n    v.tcp_end(f)\n    assert list(v) == [f]\n\n\ndef test_simple_udp():\n    v = view.View()\n    f = tflow.tudpflow()\n    assert v.store_count() == 0\n    v.udp_start(f)\n    assert list(v) == [f]\n\n    # These all just call update\n    v.udp_start(f)\n    v.udp_message(f)\n    v.udp_error(f)\n    v.udp_end(f)\n    assert list(v) == [f]\n\n\ndef test_simple_dns():\n    v = view.View()\n    f = tflow.tdnsflow(resp=True, err=True)\n    assert v.store_count() == 0\n    v.dns_request(f)\n    assert list(v) == [f]\n\n    # These all just call update\n    v.dns_request(f)\n    v.dns_response(f)\n    v.dns_error(f)\n    assert list(v) == [f]\n\n\ndef test_filter():\n    v = view.View()\n    v.requestheaders(tft(method=\"get\"))\n    v.requestheaders(tft(method=\"put\"))\n    v.requestheaders(tft(method=\"get\"))\n    v.requestheaders(tft(method=\"put\"))\n    assert (len(v)) == 4\n    v.set_filter_cmd(\"~m get\")\n    assert [i.request.method for i in v] == [\"GET\", \"GET\"]\n    assert len(v._store) == 4\n    v.set_filter(None)\n\n    assert len(v) == 4\n    v.toggle_marked()\n    assert len(v) == 0\n    v.toggle_marked()\n    assert len(v) == 4\n\n    with pytest.raises(exceptions.CommandError):\n        v.set_filter_cmd(\"~notafilter regex\")\n\n    v[1].marked = True\n    v.toggle_marked()\n    assert len(v) == 1\n    assert v[0].marked\n    v.toggle_marked()\n    assert len(v) == 4\n\n\ndef tdump(path, flows):\n    with open(path, \"wb\") as f:\n        w = io.FlowWriter(f)\n        for i in flows:\n            w.add(i)\n\n\ndef test_create():\n    v = view.View()\n    with taddons.context():\n        v.create(\"get\", \"http://foo.com\")\n        assert len(v) == 1\n        assert v[0].request.url == \"http://foo.com/\"\n        v.create(\"get\", \"http://foo.com\")\n        assert len(v) == 2\n        with pytest.raises(exceptions.CommandError, match=\"Invalid URL\"):\n            v.create(\"get\", \"http://foo.com\\\\\")\n        with pytest.raises(exceptions.CommandError, match=\"Invalid URL\"):\n            v.create(\"get\", \"http://\")\n\n\ndef test_orders():\n    v = view.View()\n    with taddons.context(v):\n        assert v.order_options()\n\n\nasync def test_load(tmpdir, caplog):\n    path = str(tmpdir.join(\"path\"))\n    v = view.View()\n    tdump(path, [tflow.tflow(resp=True), tflow.tflow(resp=True)])\n    v.load_file(path)\n    assert len(v) == 2\n    v.load_file(path)\n    assert len(v) == 4\n    try:\n        v.load_file(\"nonexistent_file_path\")\n    except OSError:\n        assert False\n    with open(path, \"wb\") as f:\n        f.write(b\"invalidflows\")\n    v.load_file(path)\n    assert \"Invalid data format.\" in caplog.text\n\n\ndef test_resolve():\n    v = view.View()\n    with taddons.context() as tctx:\n        f = tft(method=\"get\")\n        assert tctx.command(v.resolve, \"@all\") == []\n        assert tctx.command(v.resolve, \"@focus\") == []\n        assert tctx.command(v.resolve, \"@shown\") == []\n        assert tctx.command(v.resolve, \"@hidden\") == []\n        assert tctx.command(v.resolve, \"@marked\") == []\n        assert tctx.command(v.resolve, \"@unmarked\") == []\n        assert tctx.command(v.resolve, f\"@{f.id}\") == []\n        assert tctx.command(v.resolve, \"~m get\") == []\n        v.requestheaders(f)\n        assert len(tctx.command(v.resolve, \"~m get\")) == 1\n        assert len(tctx.command(v.resolve, \"@focus\")) == 1\n        assert len(tctx.command(v.resolve, \"@all\")) == 1\n        assert len(tctx.command(v.resolve, \"@shown\")) == 1\n        assert len(tctx.command(v.resolve, \"@unmarked\")) == 1\n        assert len(tctx.command(v.resolve, f\"@{f.id}\")) == 1\n        assert tctx.command(v.resolve, \"@hidden\") == []\n        assert tctx.command(v.resolve, \"@marked\") == []\n        v.requestheaders(tft(method=\"put\"))\n        assert len(tctx.command(v.resolve, f\"@{f.id}\")) == 1\n        assert len(tctx.command(v.resolve, \"@focus\")) == 1\n        assert len(tctx.command(v.resolve, \"@shown\")) == 2\n        assert len(tctx.command(v.resolve, \"@all\")) == 2\n        assert tctx.command(v.resolve, \"@hidden\") == []\n        assert tctx.command(v.resolve, \"@marked\") == []\n\n        v.requestheaders(tft(method=\"get\"))\n        v.requestheaders(tft(method=\"put\"))\n\n        f = flowfilter.parse(\"~m get\")\n        v.set_filter(f)\n        v[0].marked = True\n\n        def methods(flows):\n            return [i.request.method for i in flows]\n\n        assert methods(tctx.command(v.resolve, \"~m get\")) == [\"GET\", \"GET\"]\n        assert methods(tctx.command(v.resolve, \"~m put\")) == [\"PUT\", \"PUT\"]\n        assert methods(tctx.command(v.resolve, \"@shown\")) == [\"GET\", \"GET\"]\n        assert methods(tctx.command(v.resolve, \"@hidden\")) == [\"PUT\", \"PUT\"]\n        assert methods(tctx.command(v.resolve, \"@marked\")) == [\"GET\"]\n        assert methods(tctx.command(v.resolve, \"@unmarked\")) == [\"PUT\", \"GET\", \"PUT\"]\n        assert methods(tctx.command(v.resolve, \"@all\")) == [\"GET\", \"PUT\", \"GET\", \"PUT\"]\n\n        with pytest.raises(exceptions.CommandError, match=\"Invalid filter expression\"):\n            tctx.command(v.resolve, \"~\")\n\n\ndef test_movement():\n    v = view.View()\n    with taddons.context():\n        v.go(0)\n        v.add(\n            [\n                tflow.tflow(),\n                tflow.tflow(),\n                tflow.tflow(),\n                tflow.tflow(),\n                tflow.tflow(),\n            ]\n        )\n        assert v.focus.index == 0\n        v.go(-1)\n        assert v.focus.index == 4\n        v.go(0)\n        assert v.focus.index == 0\n        v.go(1)\n        assert v.focus.index == 1\n        v.go(999)\n        assert v.focus.index == 4\n        v.go(-999)\n        assert v.focus.index == 0\n\n        v.focus_next()\n        assert v.focus.index == 1\n        v.focus_prev()\n        assert v.focus.index == 0\n\n        v.clear()\n        v.focus_next()\n        assert v.focus.index is None\n        v.focus_prev()\n        assert v.focus.index is None\n\n\ndef test_duplicate():\n    v = view.View()\n    with taddons.context():\n        f = [\n            tflow.tflow(),\n            tflow.tflow(),\n        ]\n        v.add(f)\n        assert len(v) == 2\n        v.duplicate(f)\n        assert len(v) == 4\n        assert v.focus.index == 2\n\n\ndef test_remove():\n    v = view.View()\n    with taddons.context():\n        f = [tflow.tflow(), tflow.tflow()]\n        v.add(f)\n        assert len(v) == 2\n        v.remove(f)\n        assert len(v) == 0\n\n\ndef test_setgetval():\n    v = view.View()\n    with taddons.context():\n        f = tflow.tflow()\n        v.add([f])\n        v.setvalue([f], \"key\", \"value\")\n        assert v.getvalue(f, \"key\", \"default\") == \"value\"\n        assert v.getvalue(f, \"unknow\", \"default\") == \"default\"\n\n        v.setvalue_toggle([f], \"key\")\n        assert v.getvalue(f, \"key\", \"default\") == \"true\"\n        v.setvalue_toggle([f], \"key\")\n        assert v.getvalue(f, \"key\", \"default\") == \"false\"\n\n\ndef test_order():\n    v = view.View()\n    v.requestheaders(tft(method=\"get\", start=1))\n    v.requestheaders(tft(method=\"put\", start=2))\n    v.requestheaders(tft(method=\"get\", start=3))\n    v.requestheaders(tft(method=\"put\", start=4))\n    assert [i.timestamp_created for i in v] == [1, 2, 3, 4]\n\n    v.set_order(\"method\")\n    assert v.get_order() == \"method\"\n    assert [i.request.method for i in v] == [\"GET\", \"GET\", \"PUT\", \"PUT\"]\n    v.set_reversed(True)\n    assert [i.request.method for i in v] == [\"PUT\", \"PUT\", \"GET\", \"GET\"]\n\n    v.set_order(\"time\")\n    assert v.get_order() == \"time\"\n    assert [i.timestamp_created for i in v] == [4, 3, 2, 1]\n\n    v.set_reversed(False)\n    assert [i.timestamp_created for i in v] == [1, 2, 3, 4]\n    with pytest.raises(exceptions.CommandError):\n        v.set_order(\"not_an_order\")\n\n\ndef test_reversed():\n    v = view.View()\n    v.requestheaders(tft(start=1))\n    v.requestheaders(tft(start=2))\n    v.requestheaders(tft(start=3))\n    v.set_reversed(True)\n\n    assert v[0].timestamp_created == 3\n    assert v[-1].timestamp_created == 1\n    assert v[2].timestamp_created == 1\n    with pytest.raises(IndexError):\n        v[5]\n    with pytest.raises(IndexError):\n        v[-5]\n\n    assert v._bisect(v[0]) == 1\n    assert v._bisect(v[2]) == 3\n\n\ndef test_update():\n    v = view.View()\n    flt = flowfilter.parse(\"~m get\")\n    v.set_filter(flt)\n\n    f = tft(method=\"get\")\n    v.requestheaders(f)\n    assert f in v\n\n    f.request.method = \"put\"\n    v.update([f])\n    assert f not in v\n\n    f.request.method = \"get\"\n    v.update([f])\n    assert f in v\n\n    v.update([f])\n    assert f in v\n\n\nclass Record:\n    def __init__(self):\n        self.calls = []\n\n    def __bool__(self):\n        return bool(self.calls)\n\n    def __repr__(self):\n        return repr(self.calls)\n\n    def __call__(self, *args, **kwargs):\n        self.calls.append((args, kwargs))\n\n\ndef test_signals():\n    v = view.View()\n    rec_add = Record()\n    rec_update = Record()\n    rec_remove = Record()\n    rec_refresh = Record()\n\n    def clearrec():\n        rec_add.calls = []\n        rec_update.calls = []\n        rec_remove.calls = []\n        rec_refresh.calls = []\n\n    v.sig_view_add.connect(rec_add)\n    v.sig_view_update.connect(rec_update)\n    v.sig_view_remove.connect(rec_remove)\n    v.sig_view_refresh.connect(rec_refresh)\n\n    assert not any([rec_add, rec_update, rec_remove, rec_refresh])\n\n    # Simple add\n    v.add([tft()])\n    assert rec_add\n    assert not any([rec_update, rec_remove, rec_refresh])\n\n    # Filter change triggers refresh\n    clearrec()\n    v.set_filter(flowfilter.parse(\"~m put\"))\n    assert rec_refresh\n    assert not any([rec_update, rec_add, rec_remove])\n\n    v.set_filter(flowfilter.parse(\"~m get\"))\n\n    # An update that results in a flow being added to the view\n    clearrec()\n    v[0].request.method = \"PUT\"\n    v.update([v[0]])\n    assert rec_remove\n    assert not any([rec_update, rec_refresh, rec_add])\n\n    # An update that does not affect the view just sends update\n    v.set_filter(flowfilter.parse(\"~m put\"))\n    clearrec()\n    v.update([v[0]])\n    assert rec_update\n    assert not any([rec_remove, rec_refresh, rec_add])\n\n    # An update for a flow in state but not view does not do anything\n    f = v[0]\n    v.set_filter(flowfilter.parse(\"~m get\"))\n    assert not len(v)\n    clearrec()\n    v.update([f])\n    assert not any([rec_add, rec_update, rec_remove, rec_refresh])\n\n\ndef test_focus_follow():\n    v = view.View()\n    with taddons.context(v) as tctx:\n        console_addon = consoleaddons.ConsoleAddon(tctx.master)\n        tctx.configure(console_addon)\n        tctx.configure(v, console_focus_follow=True, view_filter=\"~m get\")\n\n        v.add([tft(start=5)])\n        assert v.focus.index == 0\n\n        v.add([tft(start=4)])\n        assert v.focus.index == 0\n        assert v.focus.flow.timestamp_created == 4\n\n        v.add([tft(start=7)])\n        assert v.focus.index == 2\n        assert v.focus.flow.timestamp_created == 7\n\n        mod = tft(method=\"put\", start=6)\n        v.add([mod])\n        assert v.focus.index == 2\n        assert v.focus.flow.timestamp_created == 7\n\n        mod.request.method = \"GET\"\n        v.update([mod])\n        assert v.focus.index == 2\n        assert v.focus.flow.timestamp_created == 6\n\n\ndef test_focus():\n    # Special case - initialising with a view that already contains data\n    v = view.View()\n    v.add([tft()])\n    f = view.Focus(v)\n    assert f.index == 0\n    assert f.flow is v[0]\n\n    # Start empty\n    v = view.View()\n    f = view.Focus(v)\n    assert f.index is None\n    assert f.flow is None\n\n    v.add([tft(start=1)])\n    assert f.index == 0\n    assert f.flow is v[0]\n\n    # Try to set to something not in view\n    with pytest.raises(ValueError):\n        f.__setattr__(\"flow\", tft())\n    with pytest.raises(ValueError):\n        f.__setattr__(\"index\", 99)\n\n    v.add([tft(start=0)])\n    assert f.index == 1\n    assert f.flow is v[1]\n\n    v.add([tft(start=2)])\n    assert f.index == 1\n    assert f.flow is v[1]\n\n    f.index = 0\n    assert f.index == 0\n    f.index = 1\n\n    v.remove([v[1]])\n    v[1].intercept()\n    assert f.index == 1\n    assert f.flow is v[1]\n\n    v.remove([v[1]])\n    assert f.index == 0\n    assert f.flow is v[0]\n\n    v.remove([v[0]])\n    assert f.index is None\n    assert f.flow is None\n\n    v.add(\n        [\n            tft(method=\"get\", start=0),\n            tft(method=\"get\", start=1),\n            tft(method=\"put\", start=2),\n            tft(method=\"get\", start=3),\n        ]\n    )\n\n    f.flow = v[2]\n    assert f.flow.request.method == \"PUT\"\n\n    filt = flowfilter.parse(\"~m get\")\n    v.set_filter(filt)\n    assert f.index == 2\n\n    filt = flowfilter.parse(\"~m oink\")\n    v.set_filter(filt)\n    assert f.index is None\n\n\ndef test_settings():\n    v = view.View()\n    f = tft()\n\n    with pytest.raises(KeyError):\n        v.settings[f]\n    v.add([f])\n    v.settings[f][\"foo\"] = \"bar\"\n    assert v.settings[f][\"foo\"] == \"bar\"\n    assert len(list(v.settings)) == 1\n    v.remove([f])\n    with pytest.raises(KeyError):\n        v.settings[f]\n    assert not v.settings.keys()\n\n    v.add([f])\n    v.settings[f][\"foo\"] = \"bar\"\n    assert v.settings.keys()\n    v.clear()\n    assert not v.settings.keys()\n\n\ndef test_properties():\n    v = view.View()\n    f = tft()\n    v.requestheaders(f)\n    assert v.get_length() == 1\n    assert not v.get_marked()\n    v.toggle_marked()\n    assert v.get_length() == 0\n    assert v.get_marked()\n\n\ndef test_configure():\n    v = view.View()\n    with taddons.context(v) as tctx:\n        tctx.configure(v, view_filter=\"~q\")\n        with pytest.raises(Exception, match=\"Invalid filter expression\"):\n            tctx.configure(v, view_filter=\"~~\")\n\n        tctx.configure(v, view_order=\"method\")\n        with pytest.raises(Exception, match=\"Unknown flow order\"):\n            tctx.configure(v, view_order=\"no\")\n\n        tctx.configure(v, view_order_reversed=True)\n\n        tctx.configure(v, console_focus_follow=True)\n        assert v.focus_follow\n\n\n@pytest.mark.parametrize(\n    \"marker, expected\",\n    [\n        [\":default:\", SYMBOL_MARK],\n        [\"X\", \"X\"],\n        [\":grapes:\", \"\\N{GRAPES}\"],\n        [\":not valid:\", SYMBOL_MARK],\n        [\":weird\", SYMBOL_MARK],\n    ],\n)\ndef test_marker(marker, expected):\n    assert render_marker(marker) == expected\n", "test/mitmproxy/addons/test_clientplayback.py": "import asyncio\nimport ssl\nfrom contextlib import asynccontextmanager\n\nimport pytest\n\nfrom mitmproxy.addons.clientplayback import ClientPlayback\nfrom mitmproxy.addons.clientplayback import ReplayHandler\nfrom mitmproxy.addons.proxyserver import Proxyserver\nfrom mitmproxy.addons.tlsconfig import TlsConfig\nfrom mitmproxy.connection import Address\nfrom mitmproxy.exceptions import CommandError\nfrom mitmproxy.exceptions import OptionsError\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\n@asynccontextmanager\nasync def tcp_server(handle_conn, **server_args) -> Address:\n    \"\"\"TCP server context manager that...\n\n    1. Exits only after all handlers have returned.\n    2. Ensures that all handlers are closed properly. If we don't do that,\n       we get ghost errors in others tests from StreamWriter.__del__.\n\n    Spawning a TCP server is relatively slow. Consider using in-memory networking for faster tests.\n    \"\"\"\n    if not hasattr(asyncio, \"TaskGroup\"):\n        pytest.skip(\"Skipped because asyncio.TaskGroup is unavailable.\")\n\n    tasks = asyncio.TaskGroup()\n\n    async def handle_conn_wrapper(\n        reader: asyncio.StreamReader,\n        writer: asyncio.StreamWriter,\n    ) -> None:\n        try:\n            await handle_conn(reader, writer)\n        except Exception as e:\n            print(f\"!!! TCP handler failed: {e}\")\n            raise\n        finally:\n            if not writer.is_closing():\n                writer.close()\n            await writer.wait_closed()\n\n    async def _handle(r, w):\n        tasks.create_task(handle_conn_wrapper(r, w))\n\n    server = await asyncio.start_server(_handle, \"127.0.0.1\", 0, **server_args)\n    await server.start_serving()\n    async with server:\n        async with tasks:\n            yield server.sockets[0].getsockname()\n\n\n@pytest.mark.parametrize(\"mode\", [\"http\", \"https\", \"upstream\", \"err\"])\n@pytest.mark.parametrize(\"concurrency\", [-1, 1])\nasync def test_playback(tdata, mode, concurrency):\n    async def handler(reader: asyncio.StreamReader, writer: asyncio.StreamWriter):\n        if mode == \"err\":\n            return\n        req = await reader.readline()\n        if mode == \"upstream\":\n            assert req == b\"GET http://address:22/path HTTP/1.1\\r\\n\"\n        else:\n            assert req == b\"GET /path HTTP/1.1\\r\\n\"\n        req = await reader.readuntil(b\"data\")\n        assert req == (\n            b\"header: qvalue\\r\\n\"\n            b\"content-length: 4\\r\\nHost: example.mitmproxy.org\\r\\n\\r\\n\"\n            b\"data\"\n        )\n        writer.write(b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n        await writer.drain()\n        assert not await reader.read()\n\n    cp = ClientPlayback()\n    ps = Proxyserver()\n    tls = TlsConfig()\n    with taddons.context(cp, ps, tls) as tctx:\n        tctx.configure(cp, client_replay_concurrency=concurrency)\n\n        server_args = {}\n        if mode == \"https\":\n            server_args[\"ssl\"] = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n            server_args[\"ssl\"].load_cert_chain(\n                certfile=tdata.path(\n                    \"mitmproxy/net/data/verificationcerts/trusted-leaf.crt\"\n                ),\n                keyfile=tdata.path(\n                    \"mitmproxy/net/data/verificationcerts/trusted-leaf.key\"\n                ),\n            )\n            tctx.configure(\n                tls,\n                ssl_verify_upstream_trusted_ca=tdata.path(\n                    \"mitmproxy/net/data/verificationcerts/trusted-root.crt\"\n                ),\n            )\n\n        async with tcp_server(handler, **server_args) as addr:\n            cp.running()\n            flow = tflow.tflow(live=False)\n            flow.request.content = b\"data\"\n            if mode == \"upstream\":\n                tctx.options.mode = [f\"upstream:http://{addr[0]}:{addr[1]}\"]\n                flow.request.authority = f\"{addr[0]}:{addr[1]}\"\n                flow.request.host, flow.request.port = \"address\", 22\n            else:\n                flow.request.host, flow.request.port = addr\n            if mode == \"https\":\n                flow.request.scheme = \"https\"\n            # Used for SNI\n            flow.request.host_header = \"example.mitmproxy.org\"\n            cp.start_replay([flow])\n            assert cp.count() == 1\n            await asyncio.wait_for(cp.queue.join(), 5)\n            while cp.replay_tasks:\n                await asyncio.sleep(0.001)\n        if mode != \"err\":\n            assert flow.response.status_code == 204\n        await cp.done()\n\n\nasync def test_playback_https_upstream():\n    async def handler(reader: asyncio.StreamReader, writer: asyncio.StreamWriter):\n        conn_req = await reader.readuntil(b\"\\r\\n\\r\\n\")\n        assert conn_req == b\"CONNECT address:22 HTTP/1.1\\r\\n\\r\\n\"\n        writer.write(b\"HTTP/1.1 502 Bad Gateway\\r\\n\\r\\n\")\n        await writer.drain()\n        assert not await reader.read()\n\n    cp = ClientPlayback()\n    ps = Proxyserver()\n    with taddons.context(cp, ps) as tctx:\n        tctx.configure(cp)\n        async with tcp_server(handler) as addr:\n            cp.running()\n            flow = tflow.tflow(live=False)\n            flow.request.scheme = b\"https\"\n            flow.request.content = b\"data\"\n            tctx.options.mode = [f\"upstream:http://{addr[0]}:{addr[1]}\"]\n            cp.start_replay([flow])\n            assert cp.count() == 1\n            await asyncio.wait_for(cp.queue.join(), 5)\n\n        assert flow.response is None\n        assert (\n            str(flow.error)\n            == f\"Upstream proxy {addr[0]}:{addr[1]} refused HTTP CONNECT request: 502 Bad Gateway\"\n        )\n        await cp.done()\n\n\nasync def test_playback_crash(monkeypatch, caplog_async):\n    async def raise_err(*_, **__):\n        raise ValueError(\"oops\")\n\n    monkeypatch.setattr(ReplayHandler, \"replay\", raise_err)\n    cp = ClientPlayback()\n    with taddons.context(cp):\n        cp.running()\n        cp.start_replay([tflow.tflow(live=False)])\n        await caplog_async.await_log(\"Client replay has crashed!\")\n        assert \"oops\" in caplog_async.caplog.text\n        assert cp.count() == 0\n        await cp.done()\n\n\ndef test_check():\n    cp = ClientPlayback()\n    f = tflow.tflow(resp=True)\n    f.live = True\n    assert \"live flow\" in cp.check(f)\n\n    f = tflow.tflow(resp=True, live=False)\n    f.intercepted = True\n    assert \"intercepted flow\" in cp.check(f)\n\n    f = tflow.tflow(resp=True, live=False)\n    f.request = None\n    assert \"missing request\" in cp.check(f)\n\n    f = tflow.tflow(resp=True, live=False)\n    f.request.raw_content = None\n    assert \"missing content\" in cp.check(f)\n\n    for f in (tflow.ttcpflow(), tflow.tudpflow()):\n        f.live = False\n        assert \"Can only replay HTTP\" in cp.check(f)\n\n\nasync def test_start_stop(tdata, caplog_async):\n    cp = ClientPlayback()\n    with taddons.context(cp):\n        cp.start_replay([tflow.tflow(live=False)])\n        assert cp.count() == 1\n\n        ws_flow = tflow.twebsocketflow()\n        ws_flow.live = False\n        cp.start_replay([ws_flow])\n        await caplog_async.await_log(\"Can't replay WebSocket flows.\")\n        assert cp.count() == 1\n\n        cp.stop_replay()\n        assert cp.count() == 0\n\n\ndef test_load(tdata):\n    cp = ClientPlayback()\n    with taddons.context(cp):\n        cp.load_file(tdata.path(\"mitmproxy/data/dumpfile-018.mitm\"))\n        assert cp.count() == 1\n\n        with pytest.raises(CommandError):\n            cp.load_file(\"/nonexistent\")\n        assert cp.count() == 1\n\n\ndef test_configure(tdata):\n    cp = ClientPlayback()\n    with taddons.context(cp) as tctx:\n        assert cp.count() == 0\n        tctx.configure(\n            cp, client_replay=[tdata.path(\"mitmproxy/data/dumpfile-018.mitm\")]\n        )\n        assert cp.count() == 1\n        tctx.configure(cp, client_replay=[])\n        with pytest.raises(OptionsError):\n            tctx.configure(cp, client_replay=[\"nonexistent\"])\n        tctx.configure(cp, client_replay_concurrency=-1)\n        with pytest.raises(OptionsError):\n            tctx.configure(cp, client_replay_concurrency=-2)\n", "test/mitmproxy/io/test_io.py": "import io\nfrom pathlib import Path\n\nimport pytest\nfrom hypothesis import example\nfrom hypothesis import given\nfrom hypothesis.strategies import binary\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import version\nfrom mitmproxy.io import FlowReader\nfrom mitmproxy.io import tnetstring\n\nhere = Path(__file__).parent.parent / \"data\"\n\n\nclass TestFlowReader:\n    @given(binary())\n    @example(b\"51:11:12345678901#4:this,8:true!0:~,4:true!0:]4:\\\\x00,~}\")\n    @example(b\"0:\")\n    def test_fuzz(self, data):\n        f = io.BytesIO(data)\n        reader = FlowReader(f)\n        try:\n            for _ in reader.stream():\n                pass\n        except exceptions.FlowReadException:\n            pass  # should never raise anything else.\n\n    @pytest.mark.parametrize(\n        \"file\", [pytest.param(x, id=x.stem) for x in here.glob(\"har_files/*.har\")]\n    )\n    def test_har(self, file):\n        with open(file, \"rb\") as f:\n            reader = FlowReader(f)\n            try:\n                for _ in reader.stream():\n                    pass\n            except exceptions.FlowReadException:\n                pass  # should never raise anything else.\n\n    def test_empty(self):\n        assert list(FlowReader(io.BytesIO(b\"\")).stream()) == []\n\n    def test_unknown_type(self):\n        with pytest.raises(exceptions.FlowReadException, match=\"Unknown flow type\"):\n            weird_flow = tnetstring.dumps(\n                {\"type\": \"unknown\", \"version\": version.FLOW_FORMAT_VERSION}\n            )\n            for _ in FlowReader(io.BytesIO(weird_flow)).stream():\n                pass\n\n    def test_cannot_migrate(self):\n        with pytest.raises(\n            exceptions.FlowReadException,\n            match=\"cannot read files with flow format version 0\",\n        ):\n            for _ in FlowReader(io.BytesIO(b\"14:7:version;1:0#}\")).stream():\n                pass\n", "test/mitmproxy/io/test_har.py": "import json\nfrom pathlib import Path\n\nimport pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy.io.har import fix_headers\nfrom mitmproxy.io.har import request_to_flow\nfrom mitmproxy.tools.web.app import flow_to_json\n\ndata_dir = Path(__file__).parent.parent / \"data\"\n\n\ndef hardcode_variable_fields_for_tests(flow: dict) -> None:\n    flow[\"id\"] = \"hardcoded_for_test\"\n    flow[\"timestamp_created\"] = 0\n    flow[\"server_conn\"][\"id\"] = \"hardcoded_for_test\"\n    flow[\"client_conn\"][\"id\"] = \"hardcoded_for_test\"\n\n\ndef file_to_flows(path_name: Path) -> list[dict]:\n    file_json = json.loads(path_name.read_bytes())[\"log\"][\"entries\"]\n    flows = []\n\n    for entry in file_json:\n        expected = request_to_flow(entry)\n        flow_json = flow_to_json(expected)\n        hardcode_variable_fields_for_tests(flow_json)\n        flows.append(flow_json)\n\n    return flows\n\n\ndef test_corrupt():\n    file_json = json.loads(\n        Path(data_dir / \"corrupted_har/broken_headers.json\").read_bytes()\n    )\n    with pytest.raises(exceptions.OptionsError):\n        fix_headers(file_json[\"headers\"])\n\n\n@pytest.mark.parametrize(\n    \"har_file\", [pytest.param(x, id=x.stem) for x in data_dir.glob(\"har_files/*.har\")]\n)\ndef test_har_to_flow(har_file: Path):\n    expected_file = har_file.with_suffix(\".json\")\n\n    expected_flows = json.loads(expected_file.read_bytes())\n    actual_flows = file_to_flows(har_file)\n\n    for expected, actual in zip(expected_flows, actual_flows):\n        actual = json.loads(json.dumps(actual))\n\n        assert actual == expected\n\n\nif __name__ == \"__main__\":\n    for path_name in data_dir.glob(\"har_files/*.har\"):\n        print(path_name)\n\n        flows = file_to_flows(path_name)\n\n        with open(data_dir / f\"har_files/{path_name.stem}.json\", \"w\") as f:\n            json.dump(flows, f, indent=4)\n", "test/mitmproxy/io/test_compat.py": "import pytest\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import io\n\n\n@pytest.mark.parametrize(\n    \"dumpfile, url, count\",\n    [\n        [\"dumpfile-011.mitm\", \"https://example.com/\", 1],\n        [\"dumpfile-018.mitm\", \"https://www.example.com/\", 1],\n        [\"dumpfile-019.mitm\", \"https://webrv.rtb-seller.com/\", 1],\n        [\"dumpfile-7-websocket.mitm\", \"https://echo.websocket.org/\", 6],\n        [\"dumpfile-7.mitm\", \"https://example.com/\", 2],\n        [\"dumpfile-10.mitm\", \"https://example.com/\", 1],\n    ],\n)\ndef test_load(tdata, dumpfile, url, count):\n    with open(tdata.path(\"mitmproxy/data/\" + dumpfile), \"rb\") as f:\n        flow_reader = io.FlowReader(f)\n        flows = list(flow_reader.stream())\n        assert len(flows) == count\n        assert flows[-1].request.url.startswith(url)\n\n\ndef test_cannot_convert(tdata):\n    with open(tdata.path(\"mitmproxy/data/dumpfile-010.mitm\"), \"rb\") as f:\n        flow_reader = io.FlowReader(f)\n        with pytest.raises(exceptions.FlowReadException):\n            list(flow_reader.stream())\n", "test/mitmproxy/io/test_tnetstring.py": "import io\nimport math\nimport random\nimport struct\nimport unittest\n\nfrom mitmproxy.io import tnetstring\n\nMAXINT = 2 ** (struct.Struct(\"i\").size * 8 - 1) - 1\n\n# fmt: off\nFORMAT_EXAMPLES = {\n    b'0:}': {},\n    b'0:]': [],\n    b'51:5:hello,39:11:12345678901#4:this,4:true!0:~4:\\x00\\x00\\x00\\x00,]}':\n    {b'hello': [12345678901, b'this', True, None, b'\\x00\\x00\\x00\\x00']},\n    b'5:12345#': 12345,\n    b'12:this is cool,': b'this is cool',\n    b'19:this is unicode \\xe2\\x98\\x85;': 'this is unicode \\u2605',\n    b'0:,': b'',\n    b'0:;': '',\n    b'0:~': None,\n    b'4:true!': True,\n    b'5:false!': False,\n    b'10:\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00,': b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n    b'24:5:12345#5:67890#5:xxxxx,]': [12345, 67890, b'xxxxx'],\n    b'18:3:0.1^3:0.2^3:0.3^]': [0.1, 0.2, 0.3],\n    b'243:238:233:228:223:218:213:208:203:198:193:188:183:178:173:168:163:158:153:148:143:138:133:128:123:118:113:108:103:99:95:91:87:83:79:75:71:67:63:59:55:51:47:43:39:35:31:27:23:19:15:11:hello-there,]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]': [[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[b'hello-there']]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]  # noqa\n}\n# fmt: on\n\n\ndef get_random_object(random=random, depth=0):\n    \"\"\"Generate a random serializable object.\"\"\"\n    #  The probability of generating a scalar value increases as the depth increase.\n    #  This ensures that we bottom out eventually.\n    if random.randint(depth, 10) <= 4:\n        what = random.randint(0, 1)\n        if what == 0:\n            n = random.randint(0, 10)\n            lst = []\n            for _ in range(n):\n                lst.append(get_random_object(random, depth + 1))\n            return lst\n        if what == 1:\n            n = random.randint(0, 10)\n            d = {}\n            for _ in range(n):\n                n = random.randint(0, 100)\n                k = str([random.randint(32, 126) for _ in range(n)])\n                d[k] = get_random_object(random, depth + 1)\n            return d\n    else:\n        what = random.randint(0, 4)\n        if what == 0:\n            return None\n        if what == 1:\n            return True\n        if what == 2:\n            return False\n        if what == 3:\n            if random.randint(0, 1) == 0:\n                return random.randint(0, MAXINT)\n            else:\n                return -1 * random.randint(0, MAXINT)\n        n = random.randint(0, 100)\n        return bytes(random.randint(32, 126) for _ in range(n))\n\n\nclass Test_Format(unittest.TestCase):\n    def test_roundtrip_format_examples(self):\n        for data, expect in FORMAT_EXAMPLES.items():\n            self.assertEqual(expect, tnetstring.loads(data))\n            self.assertEqual(expect, tnetstring.loads(tnetstring.dumps(expect)))\n            self.assertEqual((expect, b\"\"), tnetstring.pop(data))\n\n    def test_roundtrip_format_random(self):\n        for _ in range(10):\n            v = get_random_object()\n            self.assertEqual(v, tnetstring.loads(tnetstring.dumps(v)))\n            self.assertEqual((v, b\"\"), tnetstring.pop(tnetstring.dumps(v)))\n\n    def test_roundtrip_format_unicode(self):\n        for _ in range(10):\n            v = get_random_object()\n            self.assertEqual(v, tnetstring.loads(tnetstring.dumps(v)))\n            self.assertEqual((v, b\"\"), tnetstring.pop(tnetstring.dumps(v)))\n\n    def test_roundtrip_big_integer(self):\n        # Recent Python versions do not like ints above 4300 digits, https://github.com/python/cpython/issues/95778\n        i1 = math.factorial(1557)\n        s = tnetstring.dumps(i1)\n        i2 = tnetstring.loads(s)\n        self.assertEqual(i1, i2)\n\n\nclass Test_FileLoading(unittest.TestCase):\n    def test_roundtrip_file_examples(self):\n        for data, expect in FORMAT_EXAMPLES.items():\n            s = io.BytesIO()\n            s.write(data)\n            s.write(b\"OK\")\n            s.seek(0)\n            self.assertEqual(expect, tnetstring.load(s))\n            self.assertEqual(b\"OK\", s.read())\n            s = io.BytesIO()\n            tnetstring.dump(expect, s)\n            s.write(b\"OK\")\n            s.seek(0)\n            self.assertEqual(expect, tnetstring.load(s))\n            self.assertEqual(b\"OK\", s.read())\n\n    def test_roundtrip_file_random(self):\n        for _ in range(10):\n            v = get_random_object()\n            s = io.BytesIO()\n            tnetstring.dump(v, s)\n            s.write(b\"OK\")\n            s.seek(0)\n            self.assertEqual(v, tnetstring.load(s))\n            self.assertEqual(b\"OK\", s.read())\n\n    def test_error_on_absurd_lengths(self):\n        s = io.BytesIO()\n        s.write(b\"1000000000000:pwned!,\")\n        s.seek(0)\n        with self.assertRaises(ValueError):\n            tnetstring.load(s)\n        self.assertEqual(s.read(1), b\":\")\n\n\ndef suite():\n    loader = unittest.TestLoader()\n    suite = unittest.TestSuite()\n    suite.addTest(loader.loadTestsFromTestCase(Test_Format))\n    suite.addTest(loader.loadTestsFromTestCase(Test_FileLoading))\n    return suite\n", "test/mitmproxy/tools/test_cmdline.py": "import argparse\n\nfrom mitmproxy import options\nfrom mitmproxy.tools import cmdline\nfrom mitmproxy.tools import main\n\n\ndef test_common():\n    parser = argparse.ArgumentParser()\n    opts = options.Options()\n    cmdline.common_options(parser, opts)\n    args = parser.parse_args(args=[])\n    main.process_options(parser, opts, args)\n\n\ndef test_mitmproxy():\n    opts = options.Options()\n    ap = cmdline.mitmproxy(opts)\n    assert ap\n\n\ndef test_mitmdump():\n    opts = options.Options()\n    ap = cmdline.mitmdump(opts)\n    assert ap\n\n\ndef test_mitmweb():\n    opts = options.Options()\n    ap = cmdline.mitmweb(opts)\n    assert ap\n", "test/mitmproxy/tools/test_dump.py": "import pytest\n\nfrom mitmproxy import options\nfrom mitmproxy.tools import dump\n\n\nclass TestDumpMaster:\n    @pytest.mark.parametrize(\"termlog\", [False, True])\n    async def test_addons_termlog(self, capsys, termlog):\n        o = options.Options()\n        m = dump.DumpMaster(o, with_termlog=termlog)\n        assert (m.addons.get(\"termlog\") is not None) == termlog\n        await m.done()\n\n    @pytest.mark.parametrize(\"dumper\", [False, True])\n    async def test_addons_dumper(self, capsys, dumper):\n        o = options.Options()\n        m = dump.DumpMaster(o, with_dumper=dumper, with_termlog=False)\n        assert (m.addons.get(\"dumper\") is not None) == dumper\n        await m.done()\n", "test/mitmproxy/tools/test_main.py": "import asyncio\n\nfrom mitmproxy.tools import main\n\nshutdown_script = \"mitmproxy/data/addonscripts/shutdown.py\"\n\n\ndef test_mitmweb(event_loop, tdata):\n    asyncio.set_event_loop(event_loop)\n    main.mitmweb(\n        [\n            \"--no-web-open-browser\",\n            \"-s\",\n            tdata.path(shutdown_script),\n            \"-q\",\n            \"-p\",\n            \"0\",\n            \"--web-port\",\n            \"0\",\n        ]\n    )\n\n\ndef test_mitmdump(event_loop, tdata):\n    asyncio.set_event_loop(event_loop)\n    main.mitmdump(\n        [\n            \"-s\",\n            tdata.path(shutdown_script),\n            \"-q\",\n            \"-p\",\n            \"0\",\n        ]\n    )\n", "test/mitmproxy/tools/__init__.py": "", "test/mitmproxy/tools/console/test_statusbar.py": "import pytest\n\nfrom mitmproxy.tools.console import statusbar\n\n\nasync def test_statusbar(console, monkeypatch):\n    console.options.update(\n        modify_headers=[\":~q:foo:bar\"],\n        modify_body=[\":~q:foo:bar\"],\n        ignore_hosts=[\"example.com\", \"example.org\"],\n        tcp_hosts=[\"example.tcp\"],\n        intercept=\"~q\",\n        view_filter=\"~dst example.com\",\n        stickycookie=\"~dst example.com\",\n        stickyauth=\"~dst example.com\",\n        console_default_contentview=\"javascript\",\n        anticache=True,\n        anticomp=True,\n        showhost=True,\n        server_replay_refresh=False,\n        server_replay_extra=\"kill\",\n        upstream_cert=False,\n        stream_large_bodies=\"3m\",\n        mode=[\"transparent\"],\n    )\n    console.options.update(view_order=\"url\", console_focus_follow=True)\n    monkeypatch.setattr(console.addons.get(\"clientplayback\"), \"count\", lambda: 42)\n    monkeypatch.setattr(console.addons.get(\"serverplayback\"), \"count\", lambda: 42)\n    monkeypatch.setattr(statusbar.StatusBar, \"refresh\", lambda x: None)\n\n    bar = statusbar.StatusBar(console)  # this already causes a redraw\n    assert bar.ib._w\n\n\n@pytest.mark.parametrize(\n    \"message,ready_message\",\n    [\n        (\"\", [(\"\", \"\"), (\"warn\", \"\")]),\n        (\n            (\"info\", \"Line fits into statusbar\"),\n            [(\"info\", \"Line fits into statusbar\"), (\"warn\", \"\")],\n        ),\n        (\n            \"Line doesn't fit into statusbar\",\n            [(\"\", \"Line doesn'\\u2026\"), (\"warn\", \"(more in eventlog)\")],\n        ),\n        (\n            (\"alert\", \"Two lines.\\nFirst fits\"),\n            [(\"alert\", \"Two lines.\"), (\"warn\", \"(more in eventlog)\")],\n        ),\n        (\n            \"Two long lines\\nFirst doesn't fit\",\n            [(\"\", \"Two long li\\u2026\"), (\"warn\", \"(more in eventlog)\")],\n        ),\n    ],\n)\ndef test_shorten_message(message, ready_message):\n    assert statusbar.shorten_message(message, max_width=30) == ready_message\n\n\ndef test_shorten_message_narrow():\n    shorten_msg = statusbar.shorten_message(\"error\", max_width=4)\n    assert shorten_msg == [(\"\", \"\\u2026\"), (\"warn\", \"(more in eventlog)\")]\n", "test/mitmproxy/tools/console/test_integration.py": "def test_integration(tdata, console):\n    console.type(\n        f\":view.flows.load {tdata.path('mitmproxy/data/dumpfile-7.mitm')}<enter>\"\n    )\n    console.type(\"<enter><tab><tab>\")\n    console.type(\"<space><tab><tab>\")  # view second flow\n    assert \"http://example.com/\" in console.screen_contents()\n\n\ndef test_options_home_end(console):\n    console.type(\"O<home><end>\")\n    assert \"Options\" in console.screen_contents()\n\n\ndef test_keybindings_home_end(console):\n    console.type(\"K<home><end>\")\n    assert \"Key Binding\" in console.screen_contents()\n\n\ndef test_replay_count(console):\n    console.type(\":replay.server.count<enter>\")\n    assert \"Data viewer\" in console.screen_contents()\n", "test/mitmproxy/tools/console/test_commander.py": "import pytest\n\nfrom mitmproxy import options\nfrom mitmproxy.addons import command_history\nfrom mitmproxy.test import taddons\nfrom mitmproxy.tools.console.commander import commander\n\n\n@pytest.fixture(autouse=True)\ndef commander_tctx(tmpdir):\n    # This runs before each test\n    dir_name = tmpdir.mkdir(\"mitmproxy\").dirname\n    confdir = dir_name\n\n    opts = options.Options()\n    opts.set(*[f\"confdir={confdir}\"])\n    commander_tctx = taddons.context(options=opts)\n    ch = command_history.CommandHistory()\n    commander_tctx.master.addons.add(ch)\n    ch.configure(\"command_history\")\n\n    yield commander_tctx\n\n    # This runs after each test\n    ch.clear_history()\n\n\nclass TestListCompleter:\n    def test_cycle(self):\n        tests = [\n            [\n                \"\",\n                [\"a\", \"b\", \"c\"],\n                [\"a\", \"b\", \"c\", \"a\"],\n                [\"c\", \"b\", \"a\", \"c\"],\n                [\"a\", \"c\", \"a\", \"c\"],\n            ],\n            [\n                \"xxx\",\n                [\"a\", \"b\", \"c\"],\n                [\"xxx\", \"xxx\", \"xxx\"],\n                [\"xxx\", \"xxx\", \"xxx\"],\n                [\"xxx\", \"xxx\", \"xxx\"],\n            ],\n            [\n                \"b\",\n                [\"a\", \"b\", \"ba\", \"bb\", \"c\"],\n                [\"b\", \"ba\", \"bb\", \"b\"],\n                [\"bb\", \"ba\", \"b\", \"bb\"],\n                [\"b\", \"bb\", \"b\", \"bb\"],\n            ],\n        ]\n        for start, opts, cycle, cycle_reverse, cycle_mix in tests:\n            c = commander.ListCompleter(start, opts)\n            for expected in cycle:\n                assert c.cycle() == expected\n            for expected in cycle_reverse:\n                assert c.cycle(False) == expected\n            forward = True\n            for expected in cycle_mix:\n                assert c.cycle(forward) == expected\n                forward = not forward\n\n\nclass TestCommandEdit:\n    def test_open_command_bar(self, commander_tctx):\n        edit = commander.CommandEdit(commander_tctx.master, \"\")\n\n        try:\n            edit.update()\n        except IndexError:\n            pytest.faied(\"Unexpected IndexError\")\n\n    def test_insert(self, commander_tctx):\n        edit = commander.CommandEdit(commander_tctx.master, \"\")\n        edit.keypress(1, \"a\")\n        assert edit.get_edit_text() == \"a\"\n\n        # Don't let users type a space before starting a command\n        # as a usability feature\n        edit = commander.CommandEdit(commander_tctx.master, \"\")\n        edit.keypress(1, \" \")\n        assert edit.get_edit_text() == \"\"\n\n    def test_backspace(self, commander_tctx):\n        edit = commander.CommandEdit(commander_tctx.master, \"\")\n\n        edit.keypress(1, \"a\")\n        edit.keypress(1, \"b\")\n        assert edit.get_edit_text() == \"ab\"\n\n        edit.keypress(1, \"backspace\")\n        assert edit.get_edit_text() == \"a\"\n\n    def test_left(self, commander_tctx):\n        edit = commander.CommandEdit(commander_tctx.master, \"\")\n\n        edit.keypress(1, \"a\")\n        assert edit.cbuf.cursor == 1\n\n        edit.keypress(1, \"left\")\n        assert edit.cbuf.cursor == 0\n\n        # Do it again to make sure it won't go negative\n        edit.keypress(1, \"left\")\n        assert edit.cbuf.cursor == 0\n\n    def test_right(self, commander_tctx):\n        edit = commander.CommandEdit(commander_tctx.master, \"\")\n\n        edit.keypress(1, \"a\")\n        assert edit.cbuf.cursor == 1\n\n        # Make sure cursor won't go past the text\n        edit.keypress(1, \"right\")\n        assert edit.cbuf.cursor == 1\n\n        # Make sure cursor goes left and then back right\n        edit.keypress(1, \"left\")\n        assert edit.cbuf.cursor == 0\n\n        edit.keypress(1, \"right\")\n        assert edit.cbuf.cursor == 1\n\n    def test_up_and_down(self, commander_tctx):\n        edit = commander.CommandEdit(commander_tctx.master, \"\")\n\n        commander_tctx.master.commands.execute(\"commands.history.clear\")\n        commander_tctx.master.commands.execute('commands.history.add \"cmd1\"')\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd1\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd1\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n        edit = commander.CommandEdit(commander_tctx.master, \"\")\n\n        commander_tctx.master.commands.execute(\"commands.history.clear\")\n        commander_tctx.master.commands.execute('commands.history.add \"cmd1\"')\n        commander_tctx.master.commands.execute('commands.history.add \"cmd2\"')\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd2\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd1\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd1\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"cmd2\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"a\")\n        edit.keypress(1, \"b\")\n        edit.keypress(1, \"c\")\n        assert edit.get_edit_text() == \"abc\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"abc\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"abc\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"abc\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"abc\"\n\n        edit = commander.CommandEdit(commander_tctx.master, \"\")\n        commander_tctx.master.commands.execute('commands.history.add \"cmd3\"')\n\n        edit.keypress(1, \"z\")\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"z\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"z\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"z\"\n\n        edit.keypress(1, \"backspace\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd3\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd2\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd1\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"cmd2\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"cmd3\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"c\")\n        assert edit.get_edit_text() == \"c\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd3\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd3\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd2\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"cmd3\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd3\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd2\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd1\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd1\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd1\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"cmd2\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"cmd3\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"backspace\")\n        assert edit.get_edit_text() == \"\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd3\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd2\"\n\n        edit.keypress(1, \"up\")\n        assert edit.get_edit_text() == \"cmd1\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"cmd2\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"cmd3\"\n\n        edit.keypress(1, \"down\")\n        assert edit.get_edit_text() == \"\"\n\n\nclass TestCommandBuffer:\n    def test_backspace(self):\n        tests = [\n            [(\"\", 0), (\"\", 0)],\n            [(\"1\", 0), (\"1\", 0)],\n            [(\"1\", 1), (\"\", 0)],\n            [(\"123\", 3), (\"12\", 2)],\n            [(\"123\", 2), (\"13\", 1)],\n            [(\"123\", 0), (\"123\", 0)],\n        ]\n        with taddons.context() as commander_tctx:\n            for start, output in tests:\n                cb = commander.CommandBuffer(commander_tctx.master)\n                cb.text, cb.cursor = start[0], start[1]\n                cb.backspace()\n                assert cb.text == output[0]\n                assert cb.cursor == output[1]\n\n    def test_left(self):\n        cursors = [3, 2, 1, 0, 0]\n        with taddons.context() as commander_tctx:\n            cb = commander.CommandBuffer(commander_tctx.master)\n            cb.text, cb.cursor = \"abcd\", 4\n            for c in cursors:\n                cb.left()\n                assert cb.cursor == c\n\n    def test_right(self):\n        cursors = [1, 2, 3, 4, 4]\n        with taddons.context() as commander_tctx:\n            cb = commander.CommandBuffer(commander_tctx.master)\n            cb.text, cb.cursor = \"abcd\", 0\n            for c in cursors:\n                cb.right()\n                assert cb.cursor == c\n\n    def test_insert(self):\n        tests = [\n            [(\"\", 0), (\"x\", 1)],\n            [(\"a\", 0), (\"xa\", 1)],\n            [(\"xa\", 2), (\"xax\", 3)],\n        ]\n        with taddons.context() as commander_tctx:\n            for start, output in tests:\n                cb = commander.CommandBuffer(commander_tctx.master)\n                cb.text, cb.cursor = start[0], start[1]\n                cb.insert(\"x\")\n                assert cb.text == output[0]\n                assert cb.cursor == output[1]\n\n    def test_cycle_completion(self):\n        with taddons.context() as commander_tctx:\n            cb = commander.CommandBuffer(commander_tctx.master)\n            cb.text = \"foo bar\"\n            cb.cursor = len(cb.text)\n            cb.cycle_completion()\n\n            ce = commander.CommandEdit(commander_tctx.master, \"se\")\n            ce.keypress(1, \"tab\")\n            ce.update()\n            ret = ce.cbuf.render()\n            assert ret == [\n                (\"commander_command\", \"set\"),\n                (\"text\", \" \"),\n                (\"commander_hint\", \"option \"),\n                (\"commander_hint\", \"*value \"),\n            ]\n\n    def test_render(self):\n        with taddons.context() as commander_tctx:\n            cb = commander.CommandBuffer(commander_tctx.master)\n            cb.text = \"foo\"\n            assert cb.render()\n\n            cb.text = \"set view_filter '~bq test'\"\n            ret = cb.render()\n            assert ret == [\n                (\"commander_command\", \"set\"),\n                (\"text\", \" \"),\n                (\"text\", \"view_filter\"),\n                (\"text\", \" \"),\n                (\"text\", \"'~bq test'\"),\n            ]\n\n            cb.text = \"set\"\n            ret = cb.render()\n            assert ret == [\n                (\"commander_command\", \"set\"),\n                (\"text\", \" \"),\n                (\"commander_hint\", \"option \"),\n                (\"commander_hint\", \"*value \"),\n            ]\n", "test/mitmproxy/tools/console/test_palettes.py": "from mitmproxy.tools.console import palettes\n\n\nclass TestPalette:\n    def test_helptext(self):\n        for i in palettes.palettes.values():\n            assert i.palette(False)\n        for i in palettes.palettes.values():\n            assert i.palette(True)\n", "test/mitmproxy/tools/console/test_quickhelp.py": "import pytest\n\nfrom mitmproxy.test.tflow import tflow\nfrom mitmproxy.tools.console import defaultkeys\nfrom mitmproxy.tools.console import quickhelp\nfrom mitmproxy.tools.console.eventlog import EventLog\nfrom mitmproxy.tools.console.flowlist import FlowListBox\nfrom mitmproxy.tools.console.flowview import FlowView\nfrom mitmproxy.tools.console.grideditor import PathEditor\nfrom mitmproxy.tools.console.help import HelpView\nfrom mitmproxy.tools.console.keybindings import KeyBindings\nfrom mitmproxy.tools.console.keymap import Keymap\nfrom mitmproxy.tools.console.options import Options\nfrom mitmproxy.tools.console.overlay import SimpleOverlay\n\n\n@pytest.fixture(scope=\"module\")\ndef keymap() -> Keymap:\n    km = Keymap(None)\n    defaultkeys.map(km)\n    return km\n\n\ntflow2 = tflow()\ntflow2.intercept()\ntflow2.backup()\ntflow2.marked = \"x\"\n\n\n@pytest.mark.parametrize(\n    \"widget, flow, is_root_widget\",\n    [\n        (FlowListBox, None, False),\n        (FlowListBox, tflow(), False),\n        (FlowView, tflow2, True),\n        (KeyBindings, None, True),\n        (Options, None, True),\n        (HelpView, None, False),\n        (EventLog, None, True),\n        (PathEditor, None, False),\n        (SimpleOverlay, None, False),\n    ],\n)\ndef test_quickhelp(widget, flow, keymap, is_root_widget):\n    qh = quickhelp.make(widget, flow, is_root_widget)\n    for row in [qh.top_items, qh.bottom_items]:\n        for title, v in row.items():\n            if isinstance(v, quickhelp.BasicKeyHelp):\n                key_short = v.key\n            else:\n                b = keymap.binding_for_help(v)\n                if b is None:\n                    raise AssertionError(f\"No binding found for help text: {v}\")\n                key_short = b.key_short()\n            assert len(key_short) + len(title) < 14\n\n\ndef test_make_rows():\n    keymap = Keymap(None)\n    defaultkeys.map(keymap)\n\n    # make sure that we don't crash if a default binding is missing.\n    keymap.unbind(keymap.binding_for_help(\"View event log\"))\n\n    qh = quickhelp.make(HelpView, None, True)\n    assert qh.make_rows(keymap)\n", "test/mitmproxy/tools/console/test_defaultkeys.py": "import mitmproxy.types\nfrom mitmproxy.test.tflow import tflow\n\n\nasync def test_commands_exist(console):\n    await console.load_flow(tflow())\n\n    for binding in console.keymap.bindings:\n        try:\n            parsed, _ = console.commands.parse_partial(binding.command.strip())\n\n            cmd = parsed[0].value\n            args = [a.value for a in parsed[1:] if a.type != mitmproxy.types.Space]\n\n            assert cmd in console.commands.commands\n\n            cmd_obj = console.commands.commands[cmd]\n            cmd_obj.prepare_args(args)\n        except Exception as e:\n            raise ValueError(f\"Invalid binding: {binding.command}\") from e\n", "test/mitmproxy/tools/console/test_flowview.py": "from mitmproxy.test import tflow\n\n\nasync def test_flowview(monkeypatch, console):\n    for f in tflow.tflows():\n        console.commands.call(\"view.clear\")\n        await console.load_flow(f)\n        console.type(\"<enter><tab><tab>\")\n", "test/mitmproxy/tools/console/test_contentview.py": "from mitmproxy import contentviews\nfrom mitmproxy.contentviews.base import format_text\nfrom mitmproxy.test import tflow\n\n\nclass TContentView(contentviews.View):\n    name = \"Test View\"\n\n    def __call__(self, data, **metadata):\n        return \"TContentView\", format_text(\"test_content\")\n\n    def render_priority(self, data, *, content_type=None, **metadata) -> float:\n        return 2\n\n\nasync def test_contentview_flowview(console):\n    assert \"Flows\" in console.screen_contents()\n    flow = tflow.tflow()\n    flow.request.headers[\"content-type\"] = \"text/html\"\n    await console.load_flow(flow)\n    assert \">>\" in console.screen_contents()\n    console.type(\"<enter>\")\n    assert \"Flow Details\" in console.screen_contents()\n    assert \"XML\" in console.screen_contents()\n\n    view = TContentView()\n    contentviews.add(view)\n    assert \"XML\" not in console.screen_contents()\n    assert \"TContentView\" in console.screen_contents()\n    contentviews.remove(view)\n    assert \"XML\" in console.screen_contents()\n    assert \"TContentView\" not in console.screen_contents()\n\n    console.type(\"q\")\n    assert \"Flows\" in console.screen_contents()\n    contentviews.add(view)\n    console.type(\"<enter>\")\n    assert \"Flow Details\" in console.screen_contents()\n    assert \"TContentView\" in console.screen_contents()\n", "test/mitmproxy/tools/console/test_common.py": "import urwid\n\nfrom mitmproxy.test import tflow\nfrom mitmproxy.tools.console import common\n\n\ndef test_format_flow():\n    for f in tflow.tflows():\n        for render_mode in common.RenderMode:\n            assert common.format_flow(f, render_mode=render_mode)\n            assert common.format_flow(\n                f, render_mode=render_mode, hostheader=True, focused=False\n            )\n\n\ndef test_format_keyvals():\n    assert common.format_keyvals(\n        [\n            (\"aa\", \"bb\"),\n            (\"cc\", \"dd\"),\n            (\"ee\", None),\n        ]\n    )\n    wrapped = urwid.Pile(\n        urwid.SimpleFocusListWalker(common.format_keyvals([(\"foo\", \"bar\")]))\n    )\n    assert wrapped.render((30,))\n    assert common.format_keyvals([(\"aa\", wrapped)])\n\n\ndef test_truncated_text():\n    urwid.set_encoding(\"utf8\")\n    half_width_text = common.TruncatedText(\"Half-width\", [])\n    full_width_text = common.TruncatedText(\"\uff26\uff35\uff2c\uff2c\uff0d\uff37\uff29\uff24\uff34\uff28\", [])\n    assert half_width_text.render((10,))\n    assert full_width_text.render((10,))\n", "test/mitmproxy/tools/console/conftest.py": "import re\nimport sys\n\nimport pytest\n\nfrom mitmproxy import options\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.tools.console import window\nfrom mitmproxy.tools.console.master import ConsoleMaster\nfrom mitmproxy.utils.signals import _SignalMixin\n\n\ndef tokenize(input: str) -> list[str]:\n    keys = []\n    for i, k in enumerate(re.split(\"[<>]\", input)):\n        if i % 2:\n            keys.append(k)\n        else:\n            keys.extend(k)\n    return keys\n\n\nclass ConsoleTestMaster(ConsoleMaster):\n    def __init__(self, opts: options.Options) -> None:\n        super().__init__(opts)\n        self.addons.remove(self.addons.get(\"tlsconfig\"))\n\n    def type(self, input: str) -> None:\n        for key in tokenize(input):\n            self.window.keypress(self.ui.get_cols_rows(), key)\n\n    def screen_contents(self) -> str:\n        return b\"\\n\".join(self.window.render((80, 24), True)._text_content()).decode()\n\n\n@pytest.fixture\ndef console(monkeypatch) -> ConsoleTestMaster:\n    \"\"\"Stupid workaround for https://youtrack.jetbrains.com/issue/PY-30279/\"\"\"\n\n\n@pytest.fixture\nasync def console(monkeypatch) -> ConsoleTestMaster:  # noqa\n    # monkeypatch.setattr(window.Screen, \"get_cols_rows\", lambda self: (120, 120))\n    monkeypatch.setattr(window.Screen, \"start\", lambda *_: True)\n    monkeypatch.setattr(ConsoleTestMaster, \"sig_call_in\", lambda *_, **__: True)\n    monkeypatch.setattr(sys.stdout, \"isatty\", lambda: True)\n\n    # extremely hacky: the console UI heavily depends on global signals\n    # that are unfortunately shared across tests\n    # Here we clear all existing signals so that we don't interact with previous instantiations.\n    for sig in signals.__dict__.values():\n        if isinstance(sig, _SignalMixin):\n            sig.receivers.clear()\n\n    opts = options.Options()\n    m = ConsoleTestMaster(opts)\n    opts.server = False\n    opts.console_mouse = False\n    await m.running()\n    yield m\n    await m.done()\n", "test/mitmproxy/tools/console/test_master.py": "from unittest.mock import Mock\n\n\ndef test_spawn_editor(monkeypatch, console):\n    text_data = \"text\"\n    binary_data = b\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x09\"\n\n    console.get_editor = Mock()\n    console.get_editor.return_value = \"editor\"\n    console.get_hex_editor = Mock()\n    console.get_hex_editor.return_value = \"editor\"\n    monkeypatch.setattr(\"subprocess.call\", (lambda _: None))\n\n    console.loop = Mock()\n    console.loop.stop = Mock()\n    console.loop.start = Mock()\n    console.loop.draw_screen = Mock()\n\n    console.spawn_editor(text_data)\n    console.get_editor.assert_called_once()\n\n    console.spawn_editor(binary_data)\n    console.get_hex_editor.assert_called_once()\n\n\ndef test_get_hex_editor(monkeypatch, console):\n    test_editor = \"hexedit\"\n    monkeypatch.setattr(\"shutil.which\", lambda x: x == test_editor)\n    editor = console.get_hex_editor()\n    assert editor == test_editor\n", "test/mitmproxy/tools/console/test_keymap.py": "from unittest import mock\n\nimport pytest\n\nfrom mitmproxy.test import taddons\nfrom mitmproxy.tools.console import keymap\n\n\ndef test_binding():\n    b = keymap.Binding(\"space\", \"cmd\", [\"options\"], \"\")\n    assert b.keyspec() == \" \"\n\n\ndef test_bind():\n    with taddons.context() as tctx:\n        km = keymap.Keymap(tctx.master)\n        km.executor = mock.Mock()\n\n        with pytest.raises(ValueError):\n            km.add(\"foo\", \"bar\", [\"unsupported\"])\n\n        km.add(\"key\", \"str\", [\"options\", \"commands\"])\n        assert km.get(\"options\", \"key\")\n        assert km.get(\"commands\", \"key\")\n        assert not km.get(\"flowlist\", \"key\")\n        assert len(km.list(\"commands\")) == 1\n\n        km.handle(\"unknown\", \"unknown\")\n        assert not km.executor.called\n\n        km.handle(\"options\", \"key\")\n        assert km.executor.called\n\n        km.add(\"glob\", \"str\", [\"global\"])\n        km.executor = mock.Mock()\n        km.handle(\"options\", \"glob\")\n        assert km.executor.called\n\n        assert len(km.list(\"global\")) == 1\n\n\ndef test_join():\n    with taddons.context() as tctx:\n        km = keymap.Keymap(tctx.master)\n        km.add(\"key\", \"str\", [\"options\"], \"help1\")\n        km.add(\"key\", \"str\", [\"commands\"])\n\n        assert len(km.bindings) == 1\n        assert len(km.bindings[0].contexts) == 2\n        assert km.bindings[0].help == \"help1\"\n        km.add(\"key\", \"str\", [\"commands\"], \"help2\")\n        assert len(km.bindings) == 1\n        assert len(km.bindings[0].contexts) == 2\n        assert km.bindings[0].help == \"help2\"\n\n        assert km.get(\"commands\", \"key\")\n        km.unbind(km.bindings[0])\n        assert len(km.bindings) == 0\n        assert not km.get(\"commands\", \"key\")\n\n\ndef test_remove():\n    with taddons.context() as tctx:\n        km = keymap.Keymap(tctx.master)\n        km.add(\"key\", \"str\", [\"options\", \"commands\"], \"help1\")\n        assert len(km.bindings) == 1\n        assert \"options\" in km.bindings[0].contexts\n\n        km.remove(\"key\", [\"options\"])\n        assert len(km.bindings) == 1\n        assert \"options\" not in km.bindings[0].contexts\n\n        km.remove(\"key\", [\"commands\"])\n        assert len(km.bindings) == 0\n\n\ndef test_load_path(tmpdir):\n    dst = str(tmpdir.join(\"conf\"))\n\n    with taddons.context() as tctx:\n        kmc = keymap.KeymapConfig(tctx.master)\n        km = keymap.Keymap(tctx.master)\n        tctx.master.keymap = km\n\n        with open(dst, \"wb\") as f:\n            f.write(b\"\\xff\\xff\\xff\")\n        with pytest.raises(keymap.KeyBindingError, match=\"expected UTF8\"):\n            kmc.load_path(km, dst)\n\n        with open(dst, \"w\") as f:\n            f.write(\"'''\")\n        with pytest.raises(keymap.KeyBindingError):\n            kmc.load_path(km, dst)\n\n        with open(dst, \"w\") as f:\n            f.write(\n                \"\"\"\n                    -   key: key1\n                        ctx: [unknown]\n                        cmd: >\n                            foo bar\n                            foo bar\n                \"\"\"\n            )\n        with pytest.raises(keymap.KeyBindingError):\n            kmc.load_path(km, dst)\n\n        with open(dst, \"w\") as f:\n            f.write(\n                \"\"\"\n                    -   key: key1\n                        ctx: [chooser]\n                        help: one\n                        cmd: >\n                            foo bar\n                            foo bar\n                \"\"\"\n            )\n        kmc.load_path(km, dst)\n        assert km.get(\"chooser\", \"key1\")\n\n        with open(dst, \"w\") as f:\n            f.write(\n                \"\"\"\n                    -   key: key2\n                        ctx: [flowlist]\n                        cmd: foo\n                    -   key: key2\n                        ctx: [flowview]\n                        cmd: bar\n                \"\"\"\n            )\n        kmc.load_path(km, dst)\n        assert km.get(\"flowlist\", \"key2\")\n        assert km.get(\"flowview\", \"key2\")\n\n        km.add(\"key123\", \"str\", [\"flowlist\", \"flowview\"])\n        with open(dst, \"w\") as f:\n            f.write(\n                \"\"\"\n                    -   key: key123\n                        ctx: [options]\n                        cmd: foo\n                \"\"\"\n            )\n        kmc.load_path(km, dst)\n        assert km.get(\"flowlist\", \"key123\")\n        assert km.get(\"flowview\", \"key123\")\n        assert km.get(\"options\", \"key123\")\n\n\ndef test_parse():\n    with taddons.context() as tctx:\n        kmc = keymap.KeymapConfig(tctx.master)\n        assert kmc.parse(\"\") == []\n        assert kmc.parse(\"\\n\\n\\n   \\n\") == []\n        with pytest.raises(keymap.KeyBindingError, match=\"expected a list of keys\"):\n            kmc.parse(\"key: val\")\n        with pytest.raises(keymap.KeyBindingError, match=\"expected a list of keys\"):\n            kmc.parse(\"val\")\n        with pytest.raises(keymap.KeyBindingError, match=\"Unknown key attributes\"):\n            kmc.parse(\n                \"\"\"\n                    -   key: key1\n                        nonexistent: bar\n                \"\"\"\n            )\n        with pytest.raises(\n            keymap.KeyBindingError, match=\"Missing required key attributes\"\n        ):\n            kmc.parse(\n                \"\"\"\n                    -   help: key1\n                \"\"\"\n            )\n        with pytest.raises(keymap.KeyBindingError, match=\"Invalid type for cmd\"):\n            kmc.parse(\n                \"\"\"\n                    -   key: key1\n                        cmd: [ cmd ]\n                \"\"\"\n            )\n        with pytest.raises(keymap.KeyBindingError, match=\"Invalid type for ctx\"):\n            kmc.parse(\n                \"\"\"\n                    -   key: key1\n                        ctx: foo\n                        cmd: cmd\n                \"\"\"\n            )\n        assert kmc.parse(\n            \"\"\"\n                -   key: key1\n                    ctx: [one, two]\n                    help: one\n                    cmd: >\n                        foo bar\n                        foo bar\n            \"\"\"\n        ) == [\n            {\n                \"key\": \"key1\",\n                \"ctx\": [\"one\", \"two\"],\n                \"help\": \"one\",\n                \"cmd\": \"foo bar foo bar\\n\",\n            }\n        ]\n", "test/mitmproxy/tools/console/__init__.py": "", "test/mitmproxy/tools/web/test_static_viewer.py": "import json\nfrom unittest import mock\n\nfrom mitmproxy import flowfilter\nfrom mitmproxy.addons import readfile\nfrom mitmproxy.addons import save\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.tools.web import static_viewer\nfrom mitmproxy.tools.web.app import flow_to_json\n\n\ndef test_save_static(tmpdir):\n    tmpdir.mkdir(\"static\")\n    static_viewer.save_static(tmpdir)\n    assert len(tmpdir.listdir()) == 2\n    assert tmpdir.join(\"index.html\").check(file=1)\n    assert tmpdir.join(\"static/static.js\").read() == \"MITMWEB_STATIC = true;\"\n\n\ndef test_save_filter_help(tmpdir):\n    static_viewer.save_filter_help(tmpdir)\n    f = tmpdir.join(\"/filter-help.json\")\n    assert f.check(file=1)\n    assert f.read() == json.dumps(dict(commands=flowfilter.help))\n\n\ndef test_save_settings(tmpdir):\n    static_viewer.save_settings(tmpdir)\n    f = tmpdir.join(\"/settings.json\")\n    assert f.check(file=1)\n\n\ndef test_save_flows(tmpdir):\n    flows = [tflow.tflow(resp=False), tflow.tflow(resp=True)]\n    static_viewer.save_flows(tmpdir, flows)\n    assert tmpdir.join(\"flows.json\").check(file=1)\n    assert tmpdir.join(\"flows.json\").read() == json.dumps(\n        [flow_to_json(f) for f in flows]\n    )\n\n\ndef test_save_flows_content(tmpdir):\n    flows = [tflow.tflow(resp=False), tflow.tflow(resp=True)]\n    with mock.patch(\"time.time\", mock.Mock(side_effect=[1, 2, 2] * 4)):\n        static_viewer.save_flows_content(tmpdir, flows)\n    flows_path = tmpdir.join(\"flows\")\n    assert len(flows_path.listdir()) == len(flows)\n    for p in flows_path.listdir():\n        assert p.join(\"request\").check(dir=1)\n        assert p.join(\"response\").check(dir=1)\n        assert p.join(\"request/content.data\").check(file=1)\n        assert p.join(\"request/content\").check(dir=1)\n        assert p.join(\"response/content.data\").check(file=1)\n        assert p.join(\"response/content\").check(dir=1)\n        assert p.join(\"request/content/Auto.json\").check(file=1)\n        assert p.join(\"response/content/Auto.json\").check(file=1)\n\n\nasync def test_static_viewer(tmpdir):\n    s = static_viewer.StaticViewer()\n    rf = readfile.ReadFile()\n    sa = save.Save()\n    with taddons.context(rf) as tctx:\n        sa.save([tflow.tflow(resp=True)], str(tmpdir.join(\"foo\")))\n        tctx.master.addons.add(s)\n        tctx.configure(s, web_static_viewer=str(tmpdir), rfile=str(tmpdir.join(\"foo\")))\n        assert tmpdir.join(\"index.html\").check(file=1)\n        assert tmpdir.join(\"static\").check(dir=1)\n        assert tmpdir.join(\"flows\").check(dir=1)\n", "test/mitmproxy/tools/web/test_master.py": "import asyncio\n\nimport pytest\n\nfrom mitmproxy.options import Options\nfrom mitmproxy.tools.web.master import WebMaster\n\n\nasync def test_reuse():\n    async def handler(r, w):\n        pass\n\n    server = await asyncio.start_server(\n        handler, host=\"127.0.0.1\", port=0, reuse_address=False\n    )\n    port = server.sockets[0].getsockname()[1]\n    master = WebMaster(Options(), with_termlog=False)\n    master.options.web_host = \"127.0.0.1\"\n    master.options.web_port = port\n    with pytest.raises(OSError, match=f\"--set web_port={port + 2}\"):\n        await master.running()\n    server.close()\n    # tornado registers some callbacks,\n    # we want to run them to avoid fatal warnings.\n    await asyncio.sleep(0)\n", "test/mitmproxy/tools/web/test_app.py": "import gzip\nimport importlib\nimport json\nimport logging\nfrom pathlib import Path\nfrom unittest import mock\n\nimport pytest\nimport tornado.testing\nfrom tornado import httpclient\nfrom tornado import websocket\n\nfrom mitmproxy import log\nfrom mitmproxy import options\nfrom mitmproxy.test import tflow\nfrom mitmproxy.tools.web import app\nfrom mitmproxy.tools.web import master as webmaster\n\nhere = Path(__file__).parent.absolute()\n\n\n@pytest.fixture(scope=\"module\")\ndef no_tornado_logging():\n    logging.getLogger(\"tornado.access\").disabled = True\n    logging.getLogger(\"tornado.application\").disabled = True\n    logging.getLogger(\"tornado.general\").disabled = True\n    yield\n    logging.getLogger(\"tornado.access\").disabled = False\n    logging.getLogger(\"tornado.application\").disabled = False\n    logging.getLogger(\"tornado.general\").disabled = False\n\n\ndef get_json(resp: httpclient.HTTPResponse):\n    return json.loads(resp.body.decode())\n\n\n@pytest.mark.parametrize(\"filename\", list((here / \"../../../../web/gen\").glob(\"*.py\")))\nasync def test_generated_files(filename):\n    mod = importlib.import_module(f\"web.gen.{filename.stem}\")\n    expected = await mod.make()\n    actual = mod.filename.read_text().replace(\"\\r\\n\", \"\\n\")\n    assert (\n        actual == expected\n    ), f\"{mod.filename} must be regenerated by running {filename.resolve()}.\"\n\n\n@pytest.mark.usefixtures(\"no_tornado_logging\", \"tdata\")\nclass TestApp(tornado.testing.AsyncHTTPTestCase):\n    def get_app(self):\n        async def make_master() -> webmaster.WebMaster:\n            o = options.Options(http2=False)\n            return webmaster.WebMaster(o, with_termlog=False)\n\n        m: webmaster.WebMaster = self.io_loop.asyncio_loop.run_until_complete(\n            make_master()\n        )\n        f = tflow.tflow(resp=True)\n        f.id = \"42\"\n        f.request.content = b\"foo\\nbar\"\n        f2 = tflow.tflow(ws=True, resp=True)\n        f2.request.content = None\n        f2.response.content = None\n        f2.id = \"43\"\n        m.view.add([f, f2])\n        m.view.add([tflow.tflow(err=True)])\n        m.events._add_log(log.LogEntry(\"test log\", \"info\"))\n        m.events.done()\n        self.master = m\n        self.view = m.view\n        self.events = m.events\n        webapp = app.Application(m, None)\n        webapp.settings[\"xsrf_cookies\"] = False\n        return webapp\n\n    def fetch(self, *args, **kwargs) -> httpclient.HTTPResponse:\n        # tornado disallows POST without content by default.\n        return super().fetch(*args, **kwargs, allow_nonstandard_methods=True)\n\n    def put_json(self, url, data: dict) -> httpclient.HTTPResponse:\n        return self.fetch(\n            url,\n            method=\"PUT\",\n            body=json.dumps(data),\n            headers={\"Content-Type\": \"application/json\"},\n        )\n\n    def test_index(self):\n        response: httpclient.HTTPResponse = self.fetch(\"/\")\n        assert response.code == 200\n        assert '\"/' not in str(\n            response.body\n        ), \"HTML content should not contain root-relative paths\"\n\n    def test_filter_help(self):\n        assert self.fetch(\"/filter-help\").code == 200\n\n    def test_flows(self):\n        resp = self.fetch(\"/flows\")\n        assert resp.code == 200\n        assert get_json(resp)[0][\"request\"][\"contentHash\"]\n        assert get_json(resp)[2][\"error\"]\n\n    def test_flows_dump(self):\n        resp = self.fetch(\"/flows/dump\")\n        assert b\"address\" in resp.body\n\n    def test_flows_dump_filter(self):\n        resp = self.fetch(\"/flows/dump?filter=foo\")\n        assert b\"\" == resp.body\n\n    def test_flows_dump_filter_error(self):\n        resp = self.fetch(\"/flows/dump?filter=[\")\n        assert resp.code == 400\n\n    def test_clear(self):\n        events = self.events.data.copy()\n        flows = list(self.view)\n\n        assert self.fetch(\"/clear\", method=\"POST\").code == 200\n\n        assert not len(self.view)\n        assert not len(self.events.data)\n\n        # restore\n        for f in flows:\n            self.view.add([f])\n        self.events.data = events\n\n    def test_resume(self):\n        for f in self.view:\n            f.intercept()\n\n        assert self.fetch(\"/flows/42/resume\", method=\"POST\").code == 200\n        assert sum(f.intercepted for f in self.view) >= 1\n        assert self.fetch(\"/flows/resume\", method=\"POST\").code == 200\n        assert all(not f.intercepted for f in self.view)\n\n    def test_kill(self):\n        for f in self.view:\n            f.backup()\n            f.intercept()\n\n        assert self.fetch(\"/flows/42/kill\", method=\"POST\").code == 200\n        assert sum(f.killable for f in self.view) >= 1\n        assert self.fetch(\"/flows/kill\", method=\"POST\").code == 200\n        assert all(not f.killable for f in self.view)\n        for f in self.view:\n            f.revert()\n\n    def test_flow_delete(self):\n        f = self.view.get_by_id(\"42\")\n        assert f\n\n        assert self.fetch(\"/flows/42\", method=\"DELETE\").code == 200\n\n        assert not self.view.get_by_id(\"42\")\n        self.view.add([f])\n\n        assert self.fetch(\"/flows/1234\", method=\"DELETE\").code == 404\n\n    def test_flow_update(self):\n        f = self.view.get_by_id(\"42\")\n        assert f.request.method == \"GET\"\n        f.backup()\n\n        upd = {\n            \"request\": {\n                \"method\": \"PATCH\",\n                \"port\": 123,\n                \"headers\": [(\"foo\", \"bar\")],\n                \"trailers\": [(\"foo\", \"bar\")],\n                \"content\": \"req\",\n            },\n            \"response\": {\n                \"msg\": \"Non-Authoris\u00e9\",\n                \"code\": 404,\n                \"headers\": [(\"bar\", \"baz\")],\n                \"trailers\": [(\"foo\", \"bar\")],\n                \"content\": \"resp\",\n            },\n            \"marked\": \":red_circle:\",\n            \"comment\": \"I'm a modified comment!\",\n        }\n        assert self.put_json(\"/flows/42\", upd).code == 200\n        assert f.request.method == \"PATCH\"\n        assert f.request.port == 123\n        assert f.request.headers[\"foo\"] == \"bar\"\n        assert f.request.text == \"req\"\n        assert f.response.msg == \"Non-Authoris\u00e9\"\n        assert f.response.status_code == 404\n        assert f.response.headers[\"bar\"] == \"baz\"\n        assert f.response.text == \"resp\"\n        assert f.comment == \"I'm a modified comment!\"\n\n        upd = {\n            \"request\": {\n                \"trailers\": [(\"foo\", \"baz\")],\n            },\n            \"response\": {\n                \"trailers\": [(\"foo\", \"baz\")],\n            },\n        }\n        assert self.put_json(\"/flows/42\", upd).code == 200\n        assert f.request.trailers[\"foo\"] == \"baz\"\n\n        f.revert()\n\n        assert self.put_json(\"/flows/42\", {\"foo\": 42}).code == 400\n        assert self.put_json(\"/flows/42\", {\"request\": {\"foo\": 42}}).code == 400\n        assert self.put_json(\"/flows/42\", {\"response\": {\"foo\": 42}}).code == 400\n        assert self.fetch(\"/flows/42\", method=\"PUT\", body=\"{}\").code == 400\n        assert (\n            self.fetch(\n                \"/flows/42\",\n                method=\"PUT\",\n                headers={\"Content-Type\": \"application/json\"},\n                body=\"!!\",\n            ).code\n            == 400\n        )\n\n    def test_flow_duplicate(self):\n        resp = self.fetch(\"/flows/42/duplicate\", method=\"POST\")\n        assert resp.code == 200\n        f = self.view.get_by_id(resp.body.decode())\n        assert f\n        assert f.id != \"42\"\n        self.view.remove([f])\n\n    def test_flow_revert(self):\n        f = self.view.get_by_id(\"42\")\n        f.backup()\n        f.request.method = \"PATCH\"\n        self.fetch(\"/flows/42/revert\", method=\"POST\")\n        assert not f._backup\n\n    def test_flow_replay(self):\n        with mock.patch(\"mitmproxy.command.CommandManager.call\") as replay_call:\n            assert self.fetch(\"/flows/42/replay\", method=\"POST\").code == 200\n            assert replay_call.called\n\n    def test_flow_content(self):\n        f = self.view.get_by_id(\"42\")\n        f.backup()\n        f.response.headers[\"Content-Disposition\"] = 'inline; filename=\"filename.jpg\"'\n\n        r = self.fetch(\"/flows/42/response/content.data\")\n        assert r.body == b\"message\"\n        assert r.headers[\"Content-Disposition\"] == 'attachment; filename=\"filename.jpg\"'\n\n        del f.response.headers[\"Content-Disposition\"]\n        f.request.path = \"/foo/bar.jpg\"\n        assert (\n            self.fetch(\"/flows/42/response/content.data\").headers[\"Content-Disposition\"]\n            == \"attachment; filename=bar.jpg\"\n        )\n\n        f.response.content = b\"\"\n        r = self.fetch(\"/flows/42/response/content.data\")\n        assert r.code == 200\n        assert r.body == b\"\"\n\n        f.revert()\n\n    def test_flow_content_returns_raw_content_when_decoding_fails(self):\n        f = self.view.get_by_id(\"42\")\n        f.backup()\n\n        f.response.headers[\"Content-Encoding\"] = \"gzip\"\n        # replace gzip magic number with garbage\n        invalid_encoded_content = gzip.compress(b\"Hello world!\").replace(\n            b\"\\x1f\\x8b\", b\"\\xff\\xff\"\n        )\n        f.response.raw_content = invalid_encoded_content\n\n        r = self.fetch(\"/flows/42/response/content.data\")\n        assert r.body == invalid_encoded_content\n        assert r.code == 200\n\n        f.revert()\n\n    def test_update_flow_content(self):\n        assert (\n            self.fetch(\"/flows/42/request/content.data\", method=\"POST\", body=\"new\").code\n            == 200\n        )\n        f = self.view.get_by_id(\"42\")\n        assert f.request.content == b\"new\"\n        assert f.modified()\n        f.revert()\n\n    def test_update_flow_content_multipart(self):\n        body = (\n            b\"--somefancyboundary\\r\\n\"\n            b'Content-Disposition: form-data; name=\"a\"; filename=\"a.txt\"\\r\\n'\n            b\"\\r\\n\"\n            b\"such multipart. very wow.\\r\\n\"\n            b\"--somefancyboundary--\\r\\n\"\n        )\n        assert (\n            self.fetch(\n                \"/flows/42/request/content.data\",\n                method=\"POST\",\n                headers={\n                    \"Content-Type\": 'multipart/form-data; boundary=\"somefancyboundary\"'\n                },\n                body=body,\n            ).code\n            == 200\n        )\n        f = self.view.get_by_id(\"42\")\n        assert f.request.content == b\"such multipart. very wow.\"\n        assert f.modified()\n        f.revert()\n\n    def test_flow_contentview(self):\n        assert get_json(self.fetch(\"/flows/42/request/content/raw\")) == {\n            \"lines\": [[[\"text\", \"foo\"]], [[\"text\", \"bar\"]]],\n            \"description\": \"Raw\",\n        }\n        assert get_json(self.fetch(\"/flows/42/request/content/raw?lines=1\")) == {\n            \"lines\": [[[\"text\", \"foo\"]]],\n            \"description\": \"Raw\",\n        }\n        assert self.fetch(\"/flows/42/messages/content/raw\").code == 400\n\n    def test_flow_contentview_websocket(self):\n        assert get_json(self.fetch(\"/flows/43/messages/content/raw?lines=2\")) == [\n            {\n                \"description\": \"Raw\",\n                \"from_client\": True,\n                \"lines\": [[[\"text\", \"hello binary\"]]],\n                \"timestamp\": 946681203,\n            },\n            {\n                \"description\": \"Raw\",\n                \"from_client\": True,\n                \"lines\": [[[\"text\", \"hello text\"]]],\n                \"timestamp\": 946681204,\n            },\n        ]\n\n    def test_commands(self):\n        resp = self.fetch(\"/commands\")\n        assert resp.code == 200\n        assert get_json(resp)[\"set\"][\"help\"]\n\n    def test_command_execute(self):\n        resp = self.fetch(\"/commands/unknown\", method=\"POST\")\n        assert resp.code == 200\n        assert get_json(resp) == {\"error\": \"Unknown command: unknown\"}\n        resp = self.fetch(\"/commands/commands.history.get\", method=\"POST\")\n        assert resp.code == 200\n        assert get_json(resp) == {\"value\": []}\n\n    def test_events(self):\n        resp = self.fetch(\"/events\")\n        assert resp.code == 200\n        assert get_json(resp)[0][\"level\"] == \"info\"\n\n    def test_options(self):\n        j = get_json(self.fetch(\"/options\"))\n        assert isinstance(j, dict)\n        assert isinstance(j[\"anticache\"], dict)\n\n    def test_option_update(self):\n        assert self.put_json(\"/options\", {\"anticache\": True}).code == 200\n        assert self.put_json(\"/options\", {\"wtf\": True}).code == 400\n        assert self.put_json(\"/options\", {\"anticache\": \"foo\"}).code == 400\n\n    def test_option_save(self):\n        assert self.fetch(\"/options/save\", method=\"POST\").code == 200\n\n    def test_err(self):\n        with mock.patch(\"mitmproxy.tools.web.app.IndexHandler.get\") as f:\n            f.side_effect = RuntimeError\n            assert self.fetch(\"/\").code == 500\n\n    @tornado.testing.gen_test\n    def test_websocket(self):\n        ws_url = f\"ws://localhost:{self.get_http_port()}/updates\"\n\n        ws_client = yield websocket.websocket_connect(ws_url)\n        self.master.options.anticomp = True\n\n        r1 = yield ws_client.read_message()\n        response = json.loads(r1)\n        assert response == {\n            \"resource\": \"options\",\n            \"cmd\": \"update\",\n            \"data\": {\n                \"anticomp\": {\n                    \"value\": True,\n                    \"choices\": None,\n                    \"default\": False,\n                    \"help\": \"Try to convince servers to send us un-compressed data.\",\n                    \"type\": \"bool\",\n                }\n            },\n        }\n        ws_client.close()\n\n        # trigger on_close by opening a second connection.\n        ws_client2 = yield websocket.websocket_connect(ws_url)\n        ws_client2.close()\n", "test/mitmproxy/tools/web/__init__.py": "", "test/mitmproxy/utils/test_data.py": "import pytest\n\nfrom mitmproxy.utils import data\n\n\ndef test_pkg_data():\n    assert data.pkg_data.path(\"tools/console\")\n    with pytest.raises(ValueError):\n        data.pkg_data.path(\"nonexistent\")\n", "test/mitmproxy/utils/test_spec.py": "import pytest\n\nfrom mitmproxy.utils.spec import parse_spec\n\n\ndef test_parse_spec():\n    flow_filter, subject, replacement = parse_spec(\"/foo/bar/voing\")\n    assert flow_filter.pattern == \"foo\"\n    assert subject == \"bar\"\n    assert replacement == \"voing\"\n\n    flow_filter, subject, replacement = parse_spec(\"/bar/voing\")\n    assert flow_filter(1) is True\n    assert subject == \"bar\"\n    assert replacement == \"voing\"\n\n    with pytest.raises(ValueError, match=\"Invalid number of parameters\"):\n        parse_spec(\"/\")\n\n    with pytest.raises(ValueError, match=\"Invalid filter expression\"):\n        parse_spec(\"/~b/one/two\")\n", "test/mitmproxy/utils/test_emoji.py": "from mitmproxy.tools.console.common import SYMBOL_MARK\nfrom mitmproxy.utils import emoji\n\n\ndef test_emoji():\n    assert emoji.emoji[\":default:\"] == SYMBOL_MARK\n", "test/mitmproxy/utils/test_typecheck.py": "import io\nimport typing\nfrom collections.abc import Sequence\nfrom typing import Any\nfrom typing import Optional\nfrom typing import TextIO\nfrom typing import Union\n\nimport pytest\n\nfrom mitmproxy.utils import typecheck\n\n\nclass TBase:\n    def __init__(self, bar: int):\n        pass\n\n\nclass T(TBase):\n    def __init__(self, foo: str):\n        super().__init__(42)\n\n\ndef test_check_option_type():\n    typecheck.check_option_type(\"foo\", 42, int)\n    typecheck.check_option_type(\"foo\", 42, float)\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", 42, str)\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", None, str)\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", b\"foo\", str)\n\n\ndef test_check_union():\n    typecheck.check_option_type(\"foo\", 42, Union[int, str])\n    typecheck.check_option_type(\"foo\", \"42\", Union[int, str])\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", [], Union[int, str])\n\n\ndef test_check_tuple():\n    typecheck.check_option_type(\"foo\", (42, \"42\"), tuple[int, str])\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", None, tuple[int, str])\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", (), tuple[int, str])\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", (42, 42), tuple[int, str])\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", (\"42\", 42), tuple[int, str])\n\n\ndef test_check_sequence():\n    typecheck.check_option_type(\"foo\", [10], Sequence[int])\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", [\"foo\"], Sequence[int])\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", [10, \"foo\"], Sequence[int])\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", [b\"foo\"], Sequence[str])\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", \"foo\", Sequence[str])\n\n\ndef test_check_io():\n    typecheck.check_option_type(\"foo\", io.StringIO(), TextIO)\n    with pytest.raises(TypeError):\n        typecheck.check_option_type(\"foo\", \"foo\", TextIO)\n\n\ndef test_check_any():\n    typecheck.check_option_type(\"foo\", 42, Any)\n    typecheck.check_option_type(\"foo\", object(), Any)\n    typecheck.check_option_type(\"foo\", None, Any)\n\n\ndef test_typesec_to_str():\n    assert (typecheck.typespec_to_str(str)) == \"str\"\n    assert (typecheck.typespec_to_str(Sequence[str])) == \"sequence of str\"\n    assert (typecheck.typespec_to_str(Optional[str])) == \"optional str\"\n    assert (typecheck.typespec_to_str(Optional[int])) == \"optional int\"\n    with pytest.raises(NotImplementedError):\n        typecheck.typespec_to_str(dict)\n\n\ndef test_typing_aliases():\n    assert (typecheck.typespec_to_str(typing.Sequence[str])) == \"sequence of str\"\n    typecheck.check_option_type(\"foo\", [10], typing.Sequence[int])\n    typecheck.check_option_type(\"foo\", (42, \"42\"), tuple[int, str])\n", "test/mitmproxy/utils/test_signals.py": "from unittest import mock\n\nimport pytest\n\nfrom mitmproxy.utils.signals import AsyncSignal\nfrom mitmproxy.utils.signals import SyncSignal\n\n\ndef test_sync_signal() -> None:\n    m = mock.Mock()\n\n    s = SyncSignal(lambda event: None)\n    s.connect(m)\n    s.send(\"foo\")\n\n    assert m.call_args_list == [mock.call(\"foo\")]\n\n    class Foo:\n        called = None\n\n        def bound(self, event):\n            self.called = event\n\n    f = Foo()\n    s.connect(f.bound)\n    s.send(event=\"bar\")\n    assert f.called == \"bar\"\n    assert m.call_args_list == [mock.call(\"foo\"), mock.call(event=\"bar\")]\n\n    s.disconnect(m)\n    s.send(\"baz\")\n    assert f.called == \"baz\"\n    assert m.call_count == 2\n\n    def err(event):\n        raise RuntimeError\n\n    s.connect(err)\n    with pytest.raises(RuntimeError):\n        s.send(42)\n\n\ndef test_signal_weakref() -> None:\n    def m1():\n        pass\n\n    def m2():\n        pass\n\n    s = SyncSignal(lambda: None)\n    s.connect(m1)\n    s.connect(m2)\n    del m2\n    s.send()\n    assert len(s.receivers) == 1\n\n\ndef test_sync_signal_async_receiver() -> None:\n    s = SyncSignal(lambda: None)\n\n    with pytest.raises(AssertionError):\n        s.connect(mock.AsyncMock())\n\n\nasync def test_async_signal() -> None:\n    s = AsyncSignal(lambda event: None)\n    m1 = mock.AsyncMock()\n    m2 = mock.Mock()\n\n    s.connect(m1)\n    s.connect(m2)\n    await s.send(\"foo\")\n    assert m1.call_args_list == m2.call_args_list == [mock.call(\"foo\")]\n\n    s.disconnect(m2)\n\n    await s.send(\"bar\")\n    assert m1.call_count == 2\n    assert m2.call_count == 1\n", "test/mitmproxy/utils/test_debug.py": "import io\nimport sys\nfrom unittest import mock\n\nimport pytest\n\nfrom mitmproxy.utils import debug\n\n\n@pytest.mark.parametrize(\"precompiled\", [True, False])\ndef test_dump_system_info_precompiled(precompiled):\n    sys.frozen = None\n    with mock.patch.object(sys, \"frozen\", precompiled):\n        assert (\"binary\" in debug.dump_system_info()) == precompiled\n\n\ndef test_dump_info():\n    cs = io.StringIO()\n    debug.dump_info(None, None, file=cs)\n    assert cs.getvalue()\n    assert \"Tasks\" not in cs.getvalue()\n\n\nasync def test_dump_info_async():\n    cs = io.StringIO()\n    debug.dump_info(None, None, file=cs)\n    assert \"Tasks\" in cs.getvalue()\n\n\ndef test_dump_stacks():\n    cs = io.StringIO()\n    debug.dump_stacks(None, None, file=cs)\n    assert cs.getvalue()\n\n\ndef test_register_info_dumpers():\n    debug.register_info_dumpers()\n", "test/mitmproxy/utils/test_sliding_window.py": "from mitmproxy.utils import sliding_window\n\n\ndef test_simple():\n    y = list(sliding_window.window(range(1000, 1005), 1, 2))\n    assert y == [\n        # prev this  next  next2\n        (None, 1000, 1001, 1002),\n        (1000, 1001, 1002, 1003),\n        (1001, 1002, 1003, 1004),\n        (1002, 1003, 1004, None),\n        (1003, 1004, None, None),\n    ]\n\n\ndef test_is_lazy():\n    done = False\n\n    def gen():\n        nonlocal done\n        done = True\n        yield 42\n\n    x = sliding_window.window(gen(), 1, 1)\n    assert not done\n    assert list(x)\n    assert done\n", "test/mitmproxy/utils/test_arg_check.py": "import contextlib\nimport io\nfrom unittest import mock\n\nimport pytest\n\nfrom mitmproxy.utils import arg_check\n\n\n@pytest.mark.parametrize(\n    \"arg, output\",\n    [\n        ([\"-T\"], \"-T is deprecated, please use --mode transparent instead\"),\n        ([\"-U\"], \"-U is deprecated, please use --mode upstream:SPEC instead\"),\n        (\n            [\"--confdir\"],\n            \"--confdir is deprecated.\\n\"\n            \"Please use `--set confdir=value` instead.\\n\"\n            \"To show all options and their default values use --options\",\n        ),\n        (\n            [\"--palette\"],\n            \"--palette is deprecated.\\n\"\n            \"Please use `--set console_palette=value` instead.\\n\"\n            \"To show all options and their default values use --options\",\n        ),\n        (\n            [\"--wfile\"],\n            \"--wfile is deprecated.\\n\" \"Please use `--save-stream-file` instead.\",\n        ),\n        ([\"--eventlog\"], \"--eventlog has been removed.\"),\n        (\n            [\"--nonanonymous\"],\n            \"--nonanonymous is deprecated.\\n\"\n            \"Please use `--proxyauth SPEC` instead.\\n\"\n            'SPEC Format: \"username:pass\", \"any\" to accept any user/pass combination,\\n'\n            '\"@path\" to use an Apache htpasswd file, or\\n'\n            '\"ldap[s]:url_server_ldap[:port]:dn_auth:password:dn_subtree[?search_filter_key=...]\" '\n            \"for LDAP authentication.\",\n        ),\n        (\n            [\"--replacements\"],\n            \"--replacements is deprecated.\\n\"\n            \"Please use `--modify-body` or `--modify-headers` instead.\",\n        ),\n        (\n            [\"--underscore_option\"],\n            \"--underscore_option uses underscores, please use hyphens --underscore-option\",\n        ),\n    ],\n)\ndef test_check_args(arg, output):\n    f = io.StringIO()\n    with contextlib.redirect_stdout(f):\n        with mock.patch(\"sys.argv\") as m:\n            m.__getitem__.return_value = arg\n            arg_check.check()\n            assert f.getvalue().strip() == output\n", "test/mitmproxy/utils/test_vt_codes.py": "import io\n\nfrom mitmproxy.utils.vt_codes import ensure_supported\n\n\ndef test_simple():\n    assert not ensure_supported(io.StringIO())\n", "test/mitmproxy/utils/test_strutils.py": "import pytest\n\nfrom mitmproxy.utils import strutils\n\n\ndef test_always_bytes():\n    assert strutils.always_bytes(bytes(range(256))) == bytes(range(256))\n    assert strutils.always_bytes(\"foo\") == b\"foo\"\n    with pytest.raises(ValueError):\n        strutils.always_bytes(\"\\u2605\", \"ascii\")\n    with pytest.raises(TypeError):\n        strutils.always_bytes(42, \"ascii\")\n\n\ndef test_always_str():\n    with pytest.raises(TypeError):\n        strutils.always_str(42)\n    assert strutils.always_str(\"foo\") == \"foo\"\n    assert strutils.always_str(b\"foo\") == \"foo\"\n    assert strutils.always_str(None) is None\n\n\ndef test_escape_control_characters():\n    assert strutils.escape_control_characters(\"one\") == \"one\"\n    assert strutils.escape_control_characters(\"\\00ne\") == \".ne\"\n    assert strutils.escape_control_characters(\"\\nne\") == \"\\nne\"\n    assert strutils.escape_control_characters(\"\\nne\", False) == \".ne\"\n    assert strutils.escape_control_characters(\"\\u2605\") == \"\\u2605\"\n    assert (\n        strutils.escape_control_characters(bytes(bytearray(range(128))).decode())\n        == \".........\\t\\n..\\r.................. !\\\"#$%&'()*+,-./0123456789:;<\"\n        \"=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~.\"\n    )\n    assert (\n        strutils.escape_control_characters(bytes(bytearray(range(128))).decode(), False)\n        == \"................................ !\\\"#$%&'()*+,-./0123456789:;<\"\n        \"=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~.\"\n    )\n\n    with pytest.raises(ValueError):\n        strutils.escape_control_characters(b\"foo\")\n\n\ndef test_bytes_to_escaped_str():\n    assert strutils.bytes_to_escaped_str(b\"foo\") == \"foo\"\n    assert strutils.bytes_to_escaped_str(b\"\\b\") == r\"\\x08\"\n    assert strutils.bytes_to_escaped_str(rb\"&!?=\\)\") == r\"&!?=\\\\)\"\n    assert strutils.bytes_to_escaped_str(b\"\\xc3\\xbc\") == r\"\\xc3\\xbc\"\n    assert strutils.bytes_to_escaped_str(b\"'\") == r\"'\"\n    assert strutils.bytes_to_escaped_str(b'\"') == r'\"'\n\n    assert strutils.bytes_to_escaped_str(b\"'\", escape_single_quotes=True) == r\"\\'\"\n    assert strutils.bytes_to_escaped_str(b'\"', escape_single_quotes=True) == r'\"'\n\n    assert strutils.bytes_to_escaped_str(b\"\\r\\n\\t\") == \"\\\\r\\\\n\\\\t\"\n    assert strutils.bytes_to_escaped_str(b\"\\r\\n\\t\", True) == \"\\r\\n\\t\"\n\n    assert strutils.bytes_to_escaped_str(b\"\\n\", True) == \"\\n\"\n    assert strutils.bytes_to_escaped_str(b\"\\\\n\", True) == \"\\\\ \\\\ n\".replace(\" \", \"\")\n    assert strutils.bytes_to_escaped_str(b\"\\\\\\n\", True) == \"\\\\ \\\\ \\n\".replace(\" \", \"\")\n    assert strutils.bytes_to_escaped_str(b\"\\\\\\\\n\", True) == \"\\\\ \\\\ \\\\ \\\\ n\".replace(\n        \" \", \"\"\n    )\n\n    with pytest.raises(ValueError):\n        strutils.bytes_to_escaped_str(\"such unicode\")\n\n\ndef test_escaped_str_to_bytes():\n    assert strutils.escaped_str_to_bytes(\"foo\") == b\"foo\"\n    assert strutils.escaped_str_to_bytes(\"\\x08\") == b\"\\b\"\n    assert strutils.escaped_str_to_bytes(\"&!?=\\\\\\\\)\") == rb\"&!?=\\)\"\n    assert strutils.escaped_str_to_bytes(\"\\\\x08\") == b\"\\b\"\n    assert strutils.escaped_str_to_bytes(\"&!?=\\\\\\\\)\") == rb\"&!?=\\)\"\n    assert strutils.escaped_str_to_bytes(\"\\u00fc\") == b\"\\xc3\\xbc\"\n\n    with pytest.raises(ValueError):\n        strutils.escaped_str_to_bytes(b\"very byte\")\n\n\ndef test_is_mostly_bin():\n    assert not strutils.is_mostly_bin(b\"foo\\xff\")\n    assert strutils.is_mostly_bin(b\"foo\" + b\"\\xff\" * 10)\n    assert not strutils.is_mostly_bin(\"\")\n\n\ndef test_is_xml():\n    assert not strutils.is_xml(b\"\")\n    assert not strutils.is_xml(b\"foo\")\n    assert strutils.is_xml(b\"<foo\")\n    assert strutils.is_xml(b\"  \\n<foo\")\n\n\ndef test_clean_hanging_newline():\n    s = \"foo\\n\"\n    assert strutils.clean_hanging_newline(s) == \"foo\"\n    assert strutils.clean_hanging_newline(\"foo\") == \"foo\"\n\n\ndef test_hexdump():\n    assert list(strutils.hexdump(b\"one\\0\" * 10))\n\n\nESCAPE_QUOTES = [\n    \"'\" + strutils.SINGLELINE_CONTENT + strutils.NO_ESCAPE + \"'\",\n    '\"' + strutils.SINGLELINE_CONTENT + strutils.NO_ESCAPE + '\"',\n]\n\n\ndef test_split_special_areas():\n    assert strutils.split_special_areas(\"foo\", ESCAPE_QUOTES) == [\"foo\"]\n    assert strutils.split_special_areas(\"foo 'bar' baz\", ESCAPE_QUOTES) == [\n        \"foo \",\n        \"'bar'\",\n        \" baz\",\n    ]\n    assert strutils.split_special_areas(\"\"\"foo 'b\\\\'a\"r' baz\"\"\", ESCAPE_QUOTES) == [\n        \"foo \",\n        \"'b\\\\'a\\\"r'\",\n        \" baz\",\n    ]\n    assert strutils.split_special_areas(\n        \"foo\\n/*bar\\nbaz*/\\nqux\", [r\"/\\*[\\s\\S]+?\\*/\"]\n    ) == [\"foo\\n\", \"/*bar\\nbaz*/\", \"\\nqux\"]\n    assert strutils.split_special_areas(\"foo\\n//bar\\nbaz\", [r\"//.+$\"]) == [\n        \"foo\\n\",\n        \"//bar\",\n        \"\\nbaz\",\n    ]\n\n\ndef test_escape_special_areas():\n    assert (\n        strutils.escape_special_areas('foo \"bar\" baz', ESCAPE_QUOTES, \"*\")\n        == 'foo \"bar\" baz'\n    )\n    esc = strutils.escape_special_areas('foo \"b*r\" b*z', ESCAPE_QUOTES, \"*\")\n    assert esc == 'foo \"b\\ue02ar\" b*z'\n    assert strutils.unescape_special_areas(esc) == 'foo \"b*r\" b*z'\n", "test/mitmproxy/utils/test_human.py": "import time\n\nimport pytest\n\nfrom mitmproxy.utils import human\n\n\ndef test_format_timestamp():\n    assert human.format_timestamp(time.time())\n\n\ndef test_format_timestamp_with_milli():\n    assert human.format_timestamp_with_milli(time.time())\n\n\ndef test_parse_size():\n    assert human.parse_size(\"0\") == 0\n    assert human.parse_size(\"0b\") == 0\n    assert human.parse_size(\"1\") == 1\n    assert human.parse_size(\"1k\") == 1024\n    assert human.parse_size(\"1m\") == 1024**2\n    assert human.parse_size(\"1g\") == 1024**3\n    with pytest.raises(ValueError):\n        human.parse_size(\"1f\")\n    with pytest.raises(ValueError):\n        human.parse_size(\"ak\")\n    assert human.parse_size(None) is None\n\n\ndef test_pretty_size():\n    assert human.pretty_size(0) == \"0b\"\n    assert human.pretty_size(100) == \"100b\"\n    assert human.pretty_size(1024) == \"1.0k\"\n    assert human.pretty_size(1024 + 512) == \"1.5k\"\n    assert human.pretty_size(1024 * 1024) == \"1.0m\"\n    assert human.pretty_size(10 * 1024 * 1024) == \"10.0m\"\n    assert human.pretty_size(100 * 1024 * 1024) == \"100m\"\n\n\ndef test_pretty_duration():\n    assert human.pretty_duration(0.00001) == \"0ms\"\n    assert human.pretty_duration(0.0001) == \"0ms\"\n    assert human.pretty_duration(0.001) == \"1ms\"\n    assert human.pretty_duration(0.01) == \"10ms\"\n    assert human.pretty_duration(0.1) == \"100ms\"\n    assert human.pretty_duration(1) == \"1.00s\"\n    assert human.pretty_duration(10) == \"10.0s\"\n    assert human.pretty_duration(100) == \"100s\"\n    assert human.pretty_duration(1000) == \"1000s\"\n    assert human.pretty_duration(10000) == \"10000s\"\n    assert human.pretty_duration(1.123) == \"1.12s\"\n    assert human.pretty_duration(0.123) == \"123ms\"\n    assert human.pretty_duration(None) == \"\"\n\n\ndef test_format_address():\n    assert human.format_address((\"::1\", \"54010\", \"0\", \"0\")) == \"[::1]:54010\"\n    assert (\n        human.format_address((\"::ffff:127.0.0.1\", \"54010\", \"0\", \"0\"))\n        == \"127.0.0.1:54010\"\n    )\n    assert human.format_address((\"127.0.0.1\", \"54010\")) == \"127.0.0.1:54010\"\n    assert human.format_address((\"example.com\", \"54010\")) == \"example.com:54010\"\n    assert human.format_address((\"::\", \"8080\")) == \"*:8080\"\n    assert human.format_address((\"0.0.0.0\", \"8080\")) == \"*:8080\"\n    assert human.format_address(None) == \"<no address>\"\n", "test/mitmproxy/utils/test_bits.py": "# TODO: write tests\n", "test/mitmproxy/utils/__init__.py": "", "test/mitmproxy/utils/test_asyncio_utils.py": "import asyncio\nimport gc\nimport sys\n\nimport pytest\n\nfrom mitmproxy.utils import asyncio_utils\n\n\nasync def ttask():\n    asyncio_utils.set_current_task_debug_info(name=\"newname\")\n    await asyncio.sleep(999)\n\n\nasync def test_simple(monkeypatch):\n    monkeypatch.setenv(\"PYTEST_CURRENT_TEST\", \"test_foo\")\n    task = asyncio_utils.create_task(ttask(), name=\"ttask\", client=(\"127.0.0.1\", 42313))\n    assert (\n        asyncio_utils.task_repr(task)\n        == \"127.0.0.1:42313: ttask [created in test_foo] (age: 0s)\"\n    )\n    await asyncio.sleep(0)\n    assert \"newname\" in asyncio_utils.task_repr(task)\n    delattr(task, \"created\")\n    assert asyncio_utils.task_repr(task)\n\n\nasync def _raise():\n    raise RuntimeError()\n\n\nasync def test_install_exception_handler():\n    e = asyncio.Event()\n    with asyncio_utils.install_exception_handler(lambda *_, **__: e.set()):\n        t = asyncio.create_task(_raise())\n        await asyncio.sleep(0)\n        assert t.done()\n        del t\n        gc.collect()\n        await e.wait()\n\n\nasync def test_eager_task_factory():\n    x = False\n\n    async def task():\n        nonlocal x\n        x = True\n\n    # assert that override works...\n    assert type(asyncio.get_event_loop_policy()) is asyncio.DefaultEventLoopPolicy\n\n    with asyncio_utils.set_eager_task_factory():\n        _ = asyncio.create_task(task())\n        if sys.version_info >= (3, 12):\n            # ...and the context manager is effective\n            assert x\n\n\n@pytest.fixture()\ndef event_loop_policy(request):\n    # override EagerTaskCreationEventLoopPolicy from top-level conftest\n    return asyncio.DefaultEventLoopPolicy()\n", "test/mitmproxy/utils/test_magisk.py": "import os\n\nfrom cryptography import x509\n\nfrom mitmproxy.test import taddons\nfrom mitmproxy.utils import magisk\n\n\ndef test_get_ca(tdata):\n    with taddons.context() as tctx:\n        tctx.options.confdir = tdata.path(\"mitmproxy/data/confdir\")\n        ca = magisk.get_ca_from_files()\n        assert isinstance(ca, x509.Certificate)\n\n\ndef test_subject_hash_old(tdata):\n    # checks if the hash is the same as that comming form openssl\n    with taddons.context() as tctx:\n        tctx.options.confdir = tdata.path(\"mitmproxy/data/confdir\")\n        ca = magisk.get_ca_from_files()\n        our_hash = magisk.subject_hash_old(ca)\n        assert our_hash == \"efb15d7d\"\n\n\ndef test_magisk_write(tdata, tmp_path):\n    # checks if the hash is the same as that comming form openssl\n    with taddons.context() as tctx:\n        tctx.options.confdir = tdata.path(\"mitmproxy/data/confdir\")\n        magisk_path = tmp_path / \"mitmproxy-magisk-module.zip\"\n        magisk.write_magisk_module(magisk_path)\n\n        assert os.path.exists(magisk_path)\n", "test/mitmproxy/script/test_concurrent.py": "import asyncio\nimport os\nimport time\n\nimport pytest\n\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\nclass TestConcurrent:\n    @pytest.mark.parametrize(\n        \"addon\", [\"concurrent_decorator.py\", \"concurrent_decorator_class.py\"]\n    )\n    async def test_concurrent(self, addon, tdata):\n        with taddons.context() as tctx:\n            sc = tctx.script(tdata.path(f\"mitmproxy/data/addonscripts/{addon}\"))\n            f1, f2 = tflow.tflow(), tflow.tflow()\n            start = time.time()\n            await asyncio.gather(\n                tctx.cycle(sc, f1),\n                tctx.cycle(sc, f2),\n            )\n            end = time.time()\n            # This test may fail on overloaded CI systems, increase upper bound if necessary.\n            if os.environ.get(\"CI\"):\n                assert 0.5 <= end - start\n            else:\n                assert 0.5 <= end - start < 1\n\n    def test_concurrent_err(self, tdata, caplog):\n        with taddons.context() as tctx:\n            tctx.script(\n                tdata.path(\"mitmproxy/data/addonscripts/concurrent_decorator_err.py\")\n            )\n            assert \"decorator not supported\" in caplog.text\n", "test/mitmproxy/script/__init__.py": "", "test/mitmproxy/platform/test_pf.py": "import sys\n\nimport pytest\n\nfrom mitmproxy.platform import pf\n\n\nclass TestLookup:\n    def test_simple(self, tdata):\n        if sys.platform == \"freebsd10\":\n            p = tdata.path(\"mitmproxy/data/pf02\")\n        else:\n            p = tdata.path(\"mitmproxy/data/pf01\")\n        with open(p, \"rb\") as f:\n            d = f.read()\n\n        assert pf.lookup(\"192.168.1.111\", 40000, d) == (\"5.5.5.5\", 80)\n        assert pf.lookup(\"::ffff:192.168.1.111\", 40000, d) == (\"5.5.5.5\", 80)\n        with pytest.raises(Exception, match=\"Could not resolve original destination\"):\n            pf.lookup(\"192.168.1.112\", 40000, d)\n        with pytest.raises(Exception, match=\"Could not resolve original destination\"):\n            pf.lookup(\"192.168.1.111\", 40001, d)\n        assert pf.lookup(\"2a01:e35:8bae:50f0:396f:e6c7:f4f1:f3db\", 40002, d) == (\n            \"2a03:2880:f21f:c5:face:b00c::167\",\n            443,\n        )\n        with pytest.raises(Exception, match=\"Could not resolve original destination\"):\n            pf.lookup(\"2a01:e35:8bae:50f0:396f:e6c7:f4f1:f3db\", 40003, d)\n        with pytest.raises(Exception, match=\"Could not resolve original destination\"):\n            pf.lookup(\"2a01:e35:face:face:face:face:face:face\", 40003, d)\n", "test/mitmproxy/coretypes/test_serializable.py": "from __future__ import annotations\n\nimport copy\nimport dataclasses\nimport enum\nfrom collections.abc import Mapping\nfrom dataclasses import dataclass\nfrom typing import Literal\n\nimport pytest\n\nfrom mitmproxy.coretypes import serializable\nfrom mitmproxy.coretypes.serializable import SerializableDataclass\n\n\nclass SerializableDummy(serializable.Serializable):\n    def __init__(self, i):\n        self.i = i\n\n    def get_state(self):\n        return copy.copy(self.i)\n\n    def set_state(self, i):\n        self.i = i\n\n    @classmethod\n    def from_state(cls, state):\n        return cls(state)\n\n\nclass TestSerializable:\n    def test_copy(self):\n        a = SerializableDummy(42)\n        assert a.i == 42\n        b = a.copy()\n        assert b.i == 42\n\n        a.set_state(1)\n        assert a.i == 1\n        assert b.i == 42\n\n    def test_copy_id(self):\n        a = SerializableDummy({\"id\": \"foo\", \"foo\": 42})\n        b = a.copy()\n        assert a.get_state()[\"id\"] != b.get_state()[\"id\"]\n        assert a.get_state()[\"foo\"] == b.get_state()[\"foo\"]\n\n\n@dataclass\nclass Simple(SerializableDataclass):\n    x: int\n    y: str | None\n\n\n@dataclass\nclass SerializableChild(SerializableDataclass):\n    foo: Simple\n    maybe_foo: Simple | None\n\n\n@dataclass\nclass Inheritance(Simple):\n    z: bool\n\n\nclass TEnum(enum.Enum):\n    A = 1\n    B = 2\n\n\n@dataclass\nclass TLiteral(SerializableDataclass):\n    lit: Literal[\"foo\", \"bar\"]\n\n\n@dataclass\nclass BuiltinChildren(SerializableDataclass):\n    a: list[int] | None\n    b: dict[str, int] | None\n    c: tuple[int, int] | None\n    d: list[Simple]\n    e: TEnum | None\n\n\n@dataclass\nclass Defaults(SerializableDataclass):\n    z: int | None = 42\n\n\n@dataclass\nclass Unsupported(SerializableDataclass):\n    a: Mapping[str, int]\n\n\n@dataclass\nclass Addr(SerializableDataclass):\n    peername: tuple[str, int]\n\n\n@dataclass(frozen=True)\nclass Frozen(SerializableDataclass):\n    x: int\n\n\n@dataclass\nclass FrozenWrapper(SerializableDataclass):\n    f: Frozen\n\n\nclass TestSerializableDataclass:\n    @pytest.mark.parametrize(\n        \"cls, state\",\n        [\n            (Simple, {\"x\": 42, \"y\": \"foo\"}),\n            (Simple, {\"x\": 42, \"y\": None}),\n            (SerializableChild, {\"foo\": {\"x\": 42, \"y\": \"foo\"}, \"maybe_foo\": None}),\n            (\n                SerializableChild,\n                {\"foo\": {\"x\": 42, \"y\": \"foo\"}, \"maybe_foo\": {\"x\": 42, \"y\": \"foo\"}},\n            ),\n            (Inheritance, {\"x\": 42, \"y\": \"foo\", \"z\": True}),\n            (\n                BuiltinChildren,\n                {\n                    \"a\": [1, 2, 3],\n                    \"b\": {\"foo\": 42},\n                    \"c\": (1, 2),\n                    \"d\": [{\"x\": 42, \"y\": \"foo\"}],\n                    \"e\": 1,\n                },\n            ),\n            (BuiltinChildren, {\"a\": None, \"b\": None, \"c\": None, \"d\": [], \"e\": None}),\n            (TLiteral, {\"lit\": \"foo\"}),\n        ],\n    )\n    def test_roundtrip(self, cls, state):\n        a = cls.from_state(copy.deepcopy(state))\n        assert a.get_state() == state\n\n    def test_set(self):\n        s = SerializableChild(foo=Simple(x=42, y=None), maybe_foo=Simple(x=43, y=None))\n        s.set_state({\"foo\": {\"x\": 44, \"y\": None}, \"maybe_foo\": None})\n        assert s.foo.x == 44\n        assert s.maybe_foo is None\n        with pytest.raises(ValueError, match=\"Unexpected fields\"):\n            Simple(0, \"\").set_state({\"x\": 42, \"y\": \"foo\", \"z\": True})\n\n    def test_invalid_none(self):\n        with pytest.raises(ValueError):\n            Simple.from_state({\"x\": None, \"y\": \"foo\"})\n\n    def test_defaults(self):\n        a = Defaults()\n        assert a.get_state() == {\"z\": 42}\n\n    def test_invalid_type(self):\n        with pytest.raises(ValueError):\n            Simple.from_state({\"x\": 42, \"y\": 42})\n        with pytest.raises(ValueError):\n            BuiltinChildren.from_state(\n                {\"a\": None, \"b\": None, \"c\": (\"foo\",), \"d\": [], \"e\": None}\n            )\n\n    def test_invalid_key(self):\n        with pytest.raises(ValueError):\n            Simple.from_state({\"x\": 42, \"y\": \"foo\", \"z\": True})\n\n    def test_invalid_type_in_list(self):\n        with pytest.raises(ValueError, match=\"Invalid value for x\"):\n            BuiltinChildren.from_state(\n                {\n                    \"a\": None,\n                    \"b\": None,\n                    \"c\": None,\n                    \"d\": [{\"x\": \"foo\", \"y\": \"foo\"}],\n                    \"e\": None,\n                }\n            )\n\n    def test_unsupported_type(self):\n        with pytest.raises(TypeError):\n            Unsupported.from_state({\"a\": \"foo\"})\n\n    def test_literal(self):\n        assert TLiteral.from_state({\"lit\": \"foo\"}).get_state() == {\"lit\": \"foo\"}\n        with pytest.raises(ValueError):\n            TLiteral.from_state({\"lit\": \"unknown\"})\n\n    def test_peername(self):\n        assert Addr.from_state({\"peername\": (\"addr\", 42)}).get_state() == {\n            \"peername\": (\"addr\", 42)\n        }\n        assert Addr.from_state({\"peername\": (\"addr\", 42, 0, 0)}).get_state() == {\n            \"peername\": (\"addr\", 42, 0, 0)\n        }\n\n    def test_set_immutable(self):\n        w = FrozenWrapper(Frozen(42))\n        with pytest.raises(dataclasses.FrozenInstanceError):\n            w.f.set_state({\"x\": 43})\n        w.set_state({\"f\": {\"x\": 43}})\n        assert w.f.x == 43\n", "test/mitmproxy/coretypes/test_bidi.py": "import pytest\n\nfrom mitmproxy.coretypes import bidi\n\n\ndef test_bidi():\n    b = bidi.BiDi(a=1, b=2)\n    assert b.a == 1\n    assert b.get_name(1) == \"a\"\n    assert b.get_name(5) is None\n    with pytest.raises(AttributeError):\n        getattr(b, \"c\")\n    with pytest.raises(ValueError):\n        bidi.BiDi(one=1, two=1)\n", "test/mitmproxy/coretypes/test_multidict.py": "import pytest\n\nfrom mitmproxy.coretypes import multidict\n\n\nclass _TMulti:\n    @staticmethod\n    def _kconv(key):\n        return key.lower()\n\n\nclass TMultiDict(_TMulti, multidict.MultiDict):\n    pass\n\n\nclass TestMultiDict:\n    @staticmethod\n    def _multi():\n        return TMultiDict(((\"foo\", \"bar\"), (\"bar\", \"baz\"), (\"Bar\", \"bam\")))\n\n    def test_init(self):\n        md = TMultiDict()\n        assert len(md) == 0\n\n        md = TMultiDict([(\"foo\", \"bar\")])\n        assert len(md) == 1\n        assert md.fields == ((\"foo\", \"bar\"),)\n\n    def test_repr(self):\n        assert repr(self._multi()) == (\n            \"TMultiDict[('foo', 'bar'), ('bar', 'baz'), ('Bar', 'bam')]\"\n        )\n\n    def test_getitem(self):\n        md = TMultiDict([(\"foo\", \"bar\")])\n        assert \"foo\" in md\n        assert \"Foo\" in md\n        assert md[\"foo\"] == \"bar\"\n\n        with pytest.raises(KeyError):\n            assert md[\"bar\"]\n\n        md_multi = TMultiDict([(\"foo\", \"a\"), (\"foo\", \"b\")])\n        assert md_multi[\"foo\"] == \"a\"\n\n    def test_setitem(self):\n        md = TMultiDict()\n        md[\"foo\"] = \"bar\"\n        assert md.fields == ((\"foo\", \"bar\"),)\n\n        md[\"foo\"] = \"baz\"\n        assert md.fields == ((\"foo\", \"baz\"),)\n\n        md[\"bar\"] = \"bam\"\n        assert md.fields == ((\"foo\", \"baz\"), (\"bar\", \"bam\"))\n\n    def test_delitem(self):\n        md = self._multi()\n        del md[\"foo\"]\n        assert \"foo\" not in md\n        assert \"bar\" in md\n\n        with pytest.raises(KeyError):\n            del md[\"foo\"]\n\n        del md[\"bar\"]\n        assert md.fields == ()\n\n    def test_iter(self):\n        md = self._multi()\n        assert list(md.__iter__()) == [\"foo\", \"bar\"]\n\n    def test_len(self):\n        md = TMultiDict()\n        assert len(md) == 0\n\n        md = self._multi()\n        assert len(md) == 2\n\n    def test_eq(self):\n        assert TMultiDict() == TMultiDict()\n        assert not (TMultiDict() == 42)\n\n        md1 = self._multi()\n        md2 = self._multi()\n        assert md1 == md2\n        md1.fields = md1.fields[1:] + md1.fields[:1]\n        assert not (md1 == md2)\n\n    def test_hash(self):\n        \"\"\"\n        If a class defines mutable objects and implements an __eq__() method,\n        it should not implement __hash__(), since the implementation of hashable\n        collections requires that a key's hash value is immutable.\n        \"\"\"\n        with pytest.raises(TypeError):\n            assert hash(TMultiDict())\n\n    def test_get_all(self):\n        md = self._multi()\n        assert md.get_all(\"foo\") == [\"bar\"]\n        assert md.get_all(\"bar\") == [\"baz\", \"bam\"]\n        assert md.get_all(\"baz\") == []\n\n    def test_set_all(self):\n        md = TMultiDict()\n        md.set_all(\"foo\", [\"bar\", \"baz\"])\n        assert md.fields == ((\"foo\", \"bar\"), (\"foo\", \"baz\"))\n\n        md = TMultiDict(\n            (\n                (\"a\", \"b\"),\n                (\"x\", \"x\"),\n                (\"c\", \"d\"),\n                (\"X\", \"X\"),\n                (\"e\", \"f\"),\n            )\n        )\n        md.set_all(\"x\", [\"1\", \"2\", \"3\"])\n        assert md.fields == (\n            (\"a\", \"b\"),\n            (\"x\", \"1\"),\n            (\"c\", \"d\"),\n            (\"X\", \"2\"),\n            (\"e\", \"f\"),\n            (\"x\", \"3\"),\n        )\n        md.set_all(\"x\", [\"4\"])\n        assert md.fields == (\n            (\"a\", \"b\"),\n            (\"x\", \"4\"),\n            (\"c\", \"d\"),\n            (\"e\", \"f\"),\n        )\n\n    def test_add(self):\n        md = self._multi()\n        md.add(\"foo\", \"foo\")\n        assert md.fields == (\n            (\"foo\", \"bar\"),\n            (\"bar\", \"baz\"),\n            (\"Bar\", \"bam\"),\n            (\"foo\", \"foo\"),\n        )\n\n    def test_insert(self):\n        md = TMultiDict([(\"b\", \"b\")])\n        md.insert(0, \"a\", \"a\")\n        md.insert(2, \"c\", \"c\")\n        assert md.fields == ((\"a\", \"a\"), (\"b\", \"b\"), (\"c\", \"c\"))\n\n    def test_keys(self):\n        md = self._multi()\n        assert list(md.keys()) == [\"foo\", \"bar\"]\n        assert list(md.keys(multi=True)) == [\"foo\", \"bar\", \"Bar\"]\n\n    def test_values(self):\n        md = self._multi()\n        assert list(md.values()) == [\"bar\", \"baz\"]\n        assert list(md.values(multi=True)) == [\"bar\", \"baz\", \"bam\"]\n\n    def test_items(self):\n        md = self._multi()\n        assert list(md.items()) == [(\"foo\", \"bar\"), (\"bar\", \"baz\")]\n        assert list(md.items(multi=True)) == [\n            (\"foo\", \"bar\"),\n            (\"bar\", \"baz\"),\n            (\"Bar\", \"bam\"),\n        ]\n\n    def test_state(self):\n        md = self._multi()\n        assert len(md.get_state()) == 3\n        assert md == TMultiDict.from_state(md.get_state())\n\n        md2 = TMultiDict()\n        assert md != md2\n        md2.set_state(md.get_state())\n        assert md == md2\n\n\nclass TParent:\n    def __init__(self):\n        self.vals = tuple()\n\n    def setter(self, vals):\n        self.vals = vals\n\n    def getter(self):\n        return self.vals\n\n\nclass TestMultiDictView:\n    def test_modify(self):\n        p = TParent()\n        tv = multidict.MultiDictView(p.getter, p.setter)\n        assert len(tv) == 0\n        tv[\"a\"] = \"b\"\n        assert p.vals == ((\"a\", \"b\"),)\n        tv[\"c\"] = \"b\"\n        assert p.vals == ((\"a\", \"b\"), (\"c\", \"b\"))\n        assert tv[\"a\"] == \"b\"\n\n    def test_copy(self):\n        p = TParent()\n        tv = multidict.MultiDictView(p.getter, p.setter)\n        c = tv.copy()\n        assert isinstance(c, multidict.MultiDict)\n        assert tv.items() == c.items()\n        c[\"foo\"] = \"bar\"\n        assert tv.items() != c.items()\n", "test/mitmproxy/coretypes/__init__.py": "", "test/mitmproxy/contentviews/test_auto.py": "from . import full_eval\nfrom mitmproxy.contentviews import auto\nfrom mitmproxy.test import tflow\n\n\ndef test_view_auto():\n    v = full_eval(auto.ViewAuto())\n    f = v(\n        b\"foo\",\n    )\n    assert f[0] == \"Raw\"\n\n    f = v(\n        b\"<html></html>\",\n        content_type=\"text/html\",\n    )\n    assert f[0] == \"HTML\"\n\n    f = v(\n        b\"foo\",\n        content_type=\"text/flibble\",\n    )\n    assert f[0] == \"Raw\"\n\n    f = v(\n        b\"<xml></xml>\",\n        content_type=\"text/flibble\",\n    )\n    assert f[0].startswith(\"XML\")\n\n    f = v(\n        b\"<svg></svg>\",\n        content_type=\"image/svg+xml\",\n    )\n    assert f[0].startswith(\"XML\")\n\n    f = v(\n        b\"{}\",\n        content_type=\"application/acme+json\",\n    )\n    assert f[0].startswith(\"JSON\")\n\n    f = v(\n        b\"verybinary\",\n        content_type=\"image/new-magic-image-format\",\n    )\n    assert f[0] == \"Unknown Image\"\n\n    f = v(b\"\\xff\" * 30)\n    assert f[0] == \"Hexdump\"\n\n    f = v(\n        b\"\",\n    )\n    assert f[0] == \"No content\"\n\n    flow = tflow.tflow()\n    flow.request.query = [(\"foo\", \"bar\")]\n    f = v(\n        b\"\",\n        flow=flow,\n        http_message=flow.request,\n    )\n    assert f[0] == \"Query\"\n", "test/mitmproxy/contentviews/test_hex.py": "from . import full_eval\nfrom mitmproxy.contentviews import hex\n\n\nclass TestHexDump:\n    def test_view_hex(self):\n        v = full_eval(hex.ViewHexDump())\n        assert v(b\"foo\")\n\n    def test_render_priority(self):\n        v = hex.ViewHexDump()\n        assert not v.render_priority(b\"ascii\")\n        assert v.render_priority(b\"\\xff\")\n        assert not v.render_priority(b\"\")\n\n\nclass TestHexStream:\n    def test_view_hex(self):\n        v = full_eval(hex.ViewHexStream())\n        assert v(b\"foo\")\n\n    def test_render_priority(self):\n        v = hex.ViewHexStream()\n        assert not v.render_priority(b\"ascii\")\n        assert v.render_priority(b\"\\xff\")\n        assert not v.render_priority(b\"\")\n", "test/mitmproxy/contentviews/test_raw.py": "from . import full_eval\nfrom mitmproxy.contentviews import raw\n\n\ndef test_view_raw():\n    v = full_eval(raw.ViewRaw())\n    assert v(b\"foo\")\n    # unicode\n    assert v(\"\ud83e\udee0\".encode()) == (\n        \"Raw\",\n        [[(\"text\", \"\ud83e\udee0\".encode())]],\n    )\n    # invalid utf8\n    assert v(b\"\\xff\") == (\n        \"Raw\",\n        [[(\"text\", b\"\\xff\")]],\n    )\n\n\ndef test_render_priority():\n    v = raw.ViewRaw()\n    assert v.render_priority(b\"anything\")\n    assert not v.render_priority(b\"\")\n", "test/mitmproxy/contentviews/test_dns.py": "from . import full_eval\nfrom mitmproxy.contentviews import dns\n\nDNS_HTTPS_RECORD_RESPONSE = bytes.fromhex(\n    \"00008180000100010000000107746c732d656368036465760000410001c00c004100010000003c00520001000005004b0049fe0d00\"\n    \"452b00200020015881d41a3e2ef8f2208185dc479245d20624ddd0918a8056f2e26af47e2628000800010001000100034012707562\"\n    \"6c69632e746c732d6563682e646576000000002904d0000000000000\"\n)\n\n\ndef test_simple():\n    v = full_eval(dns.ViewDns())\n    assert v(DNS_HTTPS_RECORD_RESPONSE)\n    assert not v(b\"foobar\")\n\n\ndef test_render_priority():\n    v = dns.ViewDns()\n    assert v.render_priority(b\"\", content_type=\"application/dns-message\")\n    assert not v.render_priority(b\"\", content_type=\"text/plain\")\n    assert not v.render_priority(b\"\")\n", "test/mitmproxy/contentviews/test_grpc.py": "import struct\n\nimport pytest\n\nfrom . import full_eval\nfrom mitmproxy.contentviews import grpc\nfrom mitmproxy.contentviews.grpc import parse_grpc_messages\nfrom mitmproxy.contentviews.grpc import ProtoParser\nfrom mitmproxy.contentviews.grpc import ViewConfig\nfrom mitmproxy.contentviews.grpc import ViewGrpcProtobuf\nfrom mitmproxy.net.encoding import encode\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\ndatadir = \"mitmproxy/contentviews/test_grpc_data/\"\n\n\ndef helper_pack_grpc_message(data: bytes, compress=False, encoding=\"gzip\") -> bytes:\n    if compress:\n        data = encode(data, encoding)\n    header = struct.pack(\"!?i\", compress, len(data))\n    return header + data\n\n\n# fmt: off\ncustom_parser_rules = [\n    ProtoParser.ParserRuleRequest(\n        name = \"Geo coordinate lookup request\",\n        # note on flowfilter: for tflow the port gets appended to the URL's host part\n        filter = \"example\\\\.com.*/ReverseGeocode\",\n        field_definitions=[\n            ProtoParser.ParserFieldDefinition(tag=\"1\", name=\"position\"),\n            ProtoParser.ParserFieldDefinition(tag=\"1.1\", name=\"latitude\", intended_decoding=ProtoParser.DecodedTypes.double),\n            ProtoParser.ParserFieldDefinition(tag=\"1.2\", name=\"longitude\", intended_decoding=ProtoParser.DecodedTypes.double),\n            ProtoParser.ParserFieldDefinition(tag=\"3\", name=\"country\"),\n            ProtoParser.ParserFieldDefinition(tag=\"7\", name=\"app\"),\n        ]\n    ),\n    ProtoParser.ParserRuleResponse(\n        name = \"Geo coordinate lookup response\",\n        # note on flowfilter: for tflow the port gets appended to the URL's host part\n        filter = \"example\\\\.com.*/ReverseGeocode\",\n        field_definitions=[\n            ProtoParser.ParserFieldDefinition(tag=\"1.2\", name=\"address\"),\n            ProtoParser.ParserFieldDefinition(tag=\"1.3\", name=\"address array element\"),\n            ProtoParser.ParserFieldDefinition(tag=\"1.3.1\", name=\"unknown bytes\", intended_decoding=ProtoParser.DecodedTypes.bytes),\n            ProtoParser.ParserFieldDefinition(tag=\"1.3.2\", name=\"element value long\"),\n            ProtoParser.ParserFieldDefinition(tag=\"1.3.3\", name=\"element value short\"),\n            ProtoParser.ParserFieldDefinition(tag=\"\", tag_prefixes=[\"1.5.1\", \"1.5.3\", \"1.5.4\", \"1.5.5\", \"1.5.6\"], name=\"position\"),\n            ProtoParser.ParserFieldDefinition(tag=\".1\", tag_prefixes=[\"1.5.1\", \"1.5.3\", \"1.5.4\", \"1.5.5\", \"1.5.6\"], name=\"latitude\", intended_decoding=ProtoParser.DecodedTypes.double),  # noqa: E501\n            ProtoParser.ParserFieldDefinition(tag=\".2\", tag_prefixes=[\"1.5.1\", \"1.5.3\", \"1.5.4\", \"1.5.5\", \"1.5.6\"], name=\"longitude\", intended_decoding=ProtoParser.DecodedTypes.double),  # noqa: E501\n            ProtoParser.ParserFieldDefinition(tag=\"7\", name=\"app\"),\n        ]\n    ),\n]\n\ncustom_view_config = ViewConfig(\n    parser_options=ProtoParser.ParserOptions(exclude_message_headers=True, include_wiretype=True)\n)\n\ncustom_view_config_parser_rules = ViewConfig(\n    parser_rules=custom_parser_rules\n)\n\nsim_msg_req = tutils.treq(\n    port=443,\n    host=\"example.com\",\n    path=\"/ReverseGeocode\"\n)\nsim_msg_req.headers[\"grpc-encoding\"] = \"gzip\"\nsim_msg_resp = tutils.tresp()\n\nsim_flow = tflow.tflow(\n    req=sim_msg_req,\n    resp=sim_msg_resp\n)\n\n\ndef test_view_protobuf(tdata):\n    v = full_eval(ViewGrpcProtobuf())\n    p = tdata.path(datadir + \"msg1.bin\")\n\n    with open(p, \"rb\") as f:\n        raw = f.read()\n    view_text, output = v(raw)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', '  '), ('text', '1    '), ('text', '                               ')],\n        [('text', '[fixed64]  '), ('text', '  '), ('text', '1.1  '), ('text', '4630671247600644312            ')],\n        [('text', '[fixed64]  '), ('text', '  '), ('text', '1.2  '), ('text', '13858493542095451628           ')],\n        [('text', '[string]   '), ('text', '  '), ('text', '3    '), ('text', 'de_DE                          ')],\n        [('text', '[uint32]   '), ('text', '  '), ('text', '6    '), ('text', '1                              ')],\n        [('text', '[string]   '), ('text', '  '), ('text', '7    '), ('text', 'de.mcdonalds.mcdonaldsinfoapp  ')]\n    ]\n    with pytest.raises(ValueError, match='not a valid protobuf message'):\n        v(b'foobar')\n\n\ndef test_view_protobuf_custom_parsing_request(tdata):\n    v = full_eval(ViewGrpcProtobuf(custom_view_config_parser_rules))\n    p = tdata.path(datadir + \"msg1.bin\")\n    with open(p, \"rb\") as f:\n        raw = f.read()\n    view_text, output = v(raw, flow=sim_flow, http_message=sim_flow.request)  # simulate request message\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', 'position   '), ('text', '1    '), ('text', '                               ')],\n        [('text', '[double]   '), ('text', 'latitude   '), ('text', '1.1  '), ('text', '38.89816675798073              ')],\n        [('text', '[double]   '), ('text', 'longitude  '), ('text', '1.2  '), ('text', '-77.03829828366696             ')],\n        [('text', '[string]   '), ('text', 'country    '), ('text', '3    '), ('text', 'de_DE                          ')],\n        [('text', '[uint32]   '), ('text', '           '), ('text', '6    '), ('text', '1                              ')],\n        [('text', '[string]   '), ('text', 'app        '), ('text', '7    '), ('text', 'de.mcdonalds.mcdonaldsinfoapp  ')]\n    ]\n\n\ndef test_view_protobuf_custom_parsing_response(tdata):\n    # expect to parse 1.3.2 and 1.3.3 as string automatically\n    # even if there is a length delimeted field containing `b\"DC\"`, which would translate to\n    # two deprecated fields [8: group_start, 8: group_end] (and thus represent a valid nested message,\n    # but containing deprecated wire types)\n    custom_view_config_parser_rules.parser_rules[1].field_definitions[3].intended_decoding = None\n    custom_view_config_parser_rules.parser_rules[1].field_definitions[4].intended_decoding = None\n\n    v = full_eval(ViewGrpcProtobuf(custom_view_config_parser_rules))\n    p = tdata.path(datadir + \"msg3.bin\")\n\n    with open(p, \"rb\") as f:\n        raw = f.read()\n    view_text, output = v(raw, flow=sim_flow, http_message=sim_flow.response)  # simulate response message\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', '                       '), ('text', '1        '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[string]   '), ('text', '                       '), ('text', '1.1      '), ('text', '\\x15                                                       ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'address                '), ('text', '1.2      '), ('text', '1650 Pennsylvania Avenue NW, Washington, DC 20502, USA  ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', 'b\\'\"\\'                                                    ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', '1650                                                    ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', '1650                                                    ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x02'                                                 \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', 'Pennsylvania Avenue Northwest                           ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', 'Pennsylvania Avenue NW                                  ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x14\\\\x04'                                             \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', 'Northwest Washington                                    ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', 'Northwest Washington                                    ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x0c\\\\x04'                                             \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', 'Washington                                              ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', 'Washington                                              ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x06\\\\x04'                                             \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', 'District of Columbia                                    ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', 'DC                                                      ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x05\\\\x04'                                             \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', 'USA                                                     ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', 'US                                                      ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x17'                                                 \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', '20502                                                   ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', '20502                                                   ')],  # noqa: E501\n        [('text', '[message]  '), ('text', '                       '), ('text', '1.5      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'position               '), ('text', '1.5.1    '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'latitude               '), ('text', '1.5.1.1  '), ('text', '38.8970309                                              ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'longitude              '), ('text', '1.5.1.2  '), ('text', '-77.03872559999999                                      ')],  # noqa: E501\n        [('text', '[uint32]   '), ('text', '                       '), ('text', '1.5.2    '), ('text', '1                                                       ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'position               '), ('text', '1.5.3    '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'latitude               '), ('text', '1.5.3.1  '), ('text', '38.8962271697085                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'longitude              '), ('text', '1.5.3.2  '), ('text', '-77.0400511802915                                       ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'position               '), ('text', '1.5.4    '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'latitude               '), ('text', '1.5.4.1  '), ('text', '38.8989251302915                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'longitude              '), ('text', '1.5.4.2  '), ('text', '-77.03735321970849                                      ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'position               '), ('text', '1.5.5    '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'latitude               '), ('text', '1.5.5.1  '), ('text', '38.896898                                               ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'longitude              '), ('text', '1.5.5.2  '), ('text', '-77.03917229999999                                      ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'position               '), ('text', '1.5.6    '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'latitude               '), ('text', '1.5.6.1  '), ('text', '38.8982543                                              ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'longitude              '), ('text', '1.5.6.2  '), ('text', '-77.0382321                                             ')],  # noqa: E501\n        [('text', '[string]   '), ('text', '                       '), ('text', '1.7      '), ('text', 'ChIJAXiAory3t4kRpkrvas9dYmQ                             ')],  # noqa: E501\n        [('text', '[message]  '), ('text', '                       '), ('text', '2        '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[uint32]   '), ('text', '                       '), ('text', '2.1      '), ('text', '21                                                      ')],  # noqa: E501\n    ]\n\n\ndef test_view_protobuf_custom_parsing_response2(tdata):\n    # try to parse 1.3.2 and 1.3.3 as string\n    custom_view_config_parser_rules.parser_rules[1].field_definitions[3].intended_decoding = ProtoParser.DecodedTypes.string  # 1.3.2\n    custom_view_config_parser_rules.parser_rules[1].field_definitions[4].intended_decoding = ProtoParser.DecodedTypes.string  # 1.3.3\n\n    v = full_eval(ViewGrpcProtobuf(custom_view_config_parser_rules))\n    p = tdata.path(datadir + \"msg3.bin\")\n\n    with open(p, \"rb\") as f:\n        raw = f.read()\n    view_text, output = v(raw, flow=sim_flow, http_message=sim_flow.response)  # simulate response message\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', '                       '), ('text', '1        '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[string]   '), ('text', '                       '), ('text', '1.1      '), ('text', '\\x15                                                       ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'address                '), ('text', '1.2      '), ('text', '1650 Pennsylvania Avenue NW, Washington, DC 20502, USA  ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', 'b\\'\"\\'                                                    ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', '1650                                                    ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', '1650                                                    ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x02'                                                 \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', 'Pennsylvania Avenue Northwest                           ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', 'Pennsylvania Avenue NW                                  ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x14\\\\x04'                                             \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', 'Northwest Washington                                    ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', 'Northwest Washington                                    ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x0c\\\\x04'                                             \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', 'Washington                                              ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', 'Washington                                              ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x06\\\\x04'                                             \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', 'District of Columbia                                    ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', 'DC                                                      ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x05\\\\x04'                                             \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', 'USA                                                     ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', 'US                                                      ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'address array element  '), ('text', '1.3      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', 'unknown bytes          '), ('text', '1.3.1    '), ('text', \"b'\\\\x17'                                                 \")],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value long     '), ('text', '1.3.2    '), ('text', '20502                                                   ')],  # noqa: E501\n        [('text', '[string]   '), ('text', 'element value short    '), ('text', '1.3.3    '), ('text', '20502                                                   ')],  # noqa: E501\n        [('text', '[message]  '), ('text', '                       '), ('text', '1.5      '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'position               '), ('text', '1.5.1    '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'latitude               '), ('text', '1.5.1.1  '), ('text', '38.8970309                                              ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'longitude              '), ('text', '1.5.1.2  '), ('text', '-77.03872559999999                                      ')],  # noqa: E501\n        [('text', '[uint32]   '), ('text', '                       '), ('text', '1.5.2    '), ('text', '1                                                       ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'position               '), ('text', '1.5.3    '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'latitude               '), ('text', '1.5.3.1  '), ('text', '38.8962271697085                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'longitude              '), ('text', '1.5.3.2  '), ('text', '-77.0400511802915                                       ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'position               '), ('text', '1.5.4    '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'latitude               '), ('text', '1.5.4.1  '), ('text', '38.8989251302915                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'longitude              '), ('text', '1.5.4.2  '), ('text', '-77.03735321970849                                      ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'position               '), ('text', '1.5.5    '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'latitude               '), ('text', '1.5.5.1  '), ('text', '38.896898                                               ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'longitude              '), ('text', '1.5.5.2  '), ('text', '-77.03917229999999                                      ')],  # noqa: E501\n        [('text', '[message]  '), ('text', 'position               '), ('text', '1.5.6    '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'latitude               '), ('text', '1.5.6.1  '), ('text', '38.8982543                                              ')],  # noqa: E501\n        [('text', '[double]   '), ('text', 'longitude              '), ('text', '1.5.6.2  '), ('text', '-77.0382321                                             ')],  # noqa: E501\n        [('text', '[string]   '), ('text', '                       '), ('text', '1.7      '), ('text', 'ChIJAXiAory3t4kRpkrvas9dYmQ                             ')],  # noqa: E501\n        [('text', '[message]  '), ('text', '                       '), ('text', '2        '), ('text', '                                                        ')],  # noqa: E501\n        [('text', '[uint32]   '), ('text', '                       '), ('text', '2.1      '), ('text', '21                                                      ')],  # noqa: E501\n    ]\n\n\ndef test_view_protobuf_custom_config(tdata):\n    v = full_eval(ViewGrpcProtobuf(custom_view_config))\n    p = tdata.path(datadir + \"msg1.bin\")\n\n    with open(p, \"rb\") as f:\n        raw = f.read()\n    view_text, output = v(raw)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[bit_64->fixed64]        '), ('text', '  '), ('text', '1.1  '), ('text', '4630671247600644312            ')],\n        [('text', '[bit_64->fixed64]        '), ('text', '  '), ('text', '1.2  '), ('text', '13858493542095451628           ')],\n        [('text', '[len_delimited->string]  '), ('text', '  '), ('text', '3    '), ('text', 'de_DE                          ')],\n        [('text', '[varint->uint32]         '), ('text', '  '), ('text', '6    '), ('text', '1                              ')],\n        [('text', '[len_delimited->string]  '), ('text', '  '), ('text', '7    '), ('text', 'de.mcdonalds.mcdonaldsinfoapp  ')]\n    ]\n\n\ndef test_view_grpc(tdata):\n    v = full_eval(ViewGrpcProtobuf())\n    p = tdata.path(datadir + \"msg1.bin\")\n\n    with open(p, \"rb\") as f:\n        raw = f.read()\n        # pack into protobuf message\n        raw = helper_pack_grpc_message(raw)\n\n    view_text, output = v(raw, content_type=\"application/grpc\", http_message=sim_msg_req)\n    assert view_text == \"gRPC\"\n    output = list(output)  # assure list conversion if generator\n\n    assert output == [\n        [('text', 'gRPC message 0 (compressed False)')],\n        [('text', '[message]  '), ('text', '  '), ('text', '1    '), ('text', '                               ')],\n        [('text', '[fixed64]  '), ('text', '  '), ('text', '1.1  '), ('text', '4630671247600644312            ')],\n        [('text', '[fixed64]  '), ('text', '  '), ('text', '1.2  '), ('text', '13858493542095451628           ')],\n        [('text', '[string]   '), ('text', '  '), ('text', '3    '), ('text', 'de_DE                          ')],\n        [('text', '[uint32]   '), ('text', '  '), ('text', '6    '), ('text', '1                              ')],\n        [('text', '[string]   '), ('text', '  '), ('text', '7    '), ('text', 'de.mcdonalds.mcdonaldsinfoapp  ')]\n    ]\n    with pytest.raises(ValueError, match='invalid gRPC message'):\n        v(b'foobar', content_type=\"application/grpc\")\n    with pytest.raises(ValueError, match='Failed to decompress gRPC message with gzip'):\n        list(parse_grpc_messages(data=b'\\x01\\x00\\x00\\x00\\x01foobar', compression_scheme=\"gzip\"))\n\n\ndef test_view_grpc_compressed(tdata):\n    v = full_eval(grpc.ViewGrpcProtobuf())\n    p = tdata.path(datadir + \"msg1.bin\")\n\n    with open(p, \"rb\") as f:\n        raw = f.read()\n        # pack into protobuf message\n        raw = helper_pack_grpc_message(raw, True, \"gzip\")\n\n    view_text, output = v(raw, content_type=\"application/grpc\")\n    assert view_text == \"gRPC\"\n    output = list(output)  # assure list conversion if generator\n\n    assert output == [\n        [('text', 'gRPC message 0 (compressed gzip)')],\n        [('text', '[message]  '), ('text', '  '), ('text', '1    '), ('text', '                               ')],\n        [('text', '[fixed64]  '), ('text', '  '), ('text', '1.1  '), ('text', '4630671247600644312            ')],\n        [('text', '[fixed64]  '), ('text', '  '), ('text', '1.2  '), ('text', '13858493542095451628           ')],\n        [('text', '[string]   '), ('text', '  '), ('text', '3    '), ('text', 'de_DE                          ')],\n        [('text', '[uint32]   '), ('text', '  '), ('text', '6    '), ('text', '1                              ')],\n        [('text', '[string]   '), ('text', '  '), ('text', '7    '), ('text', 'de.mcdonalds.mcdonaldsinfoapp  ')]\n    ]\n\n\ndef helper_encode_base128le(val: int):\n    # hacky base128le encoding\n    if val <= 0:\n        return b'\\x00'\n    res = []\n    while val > 0:\n        part = val & 0b1111111\n        val = val >> 7\n        if val > 0:\n            res.append(part + 0x80)\n        else:\n            res.append(part)\n    return bytes(res)\n\n\ndef helper_gen_varint_msg_field(f_idx: int, f_val: int):\n    # manual encoding of protobuf data\n    f_wt = 0  # field type 0 (varint)\n    tag = (f_idx << 3) | f_wt  # combined tag\n    msg = helper_encode_base128le(tag)  # add encoded tag to message\n    msg = msg + helper_encode_base128le(f_val)  # add varint encoded field value\n    return msg\n\n\ndef helper_gen_bits32_msg_field(f_idx: int, f_val: int):\n    # manual encoding of protobuf data\n    f_wt = 5  # field type 5 (bits32)\n    tag = (f_idx << 3) | f_wt  # combined tag\n    msg = helper_encode_base128le(tag)  # add encoded tag to message\n    msg = msg + struct.pack(\"<I\", f_val)  # add varint encoded field value\n    return msg\n\n\ndef helper_gen_bits64_msg_field(f_idx: int, f_val: int):\n    # manual encoding of protobuf data\n    f_wt = 1  # field type 1 (bits64)\n    tag = (f_idx << 3) | f_wt  # combined tag\n    msg = helper_encode_base128le(tag)  # add encoded tag to message\n    msg = msg + struct.pack(\"<Q\", f_val)  # add varint encoded field value\n    return msg\n\n\ndef helper_gen_lendel_msg_field(f_idx: int, f_val: bytes):\n    # manual encoding of protobuf data\n    f_wt = 2  # field type 2 (length delimited messag)\n    tag = (f_idx << 3) | f_wt  # combined tag\n    msg = helper_encode_base128le(tag)  # add encoded tag to message\n    msg = msg + helper_encode_base128le(len(f_val))  # add length of message\n    msg = msg + f_val\n    return msg\n\n\ndef helper_gen_bits64_msg_field_packed(f_idx: int, values: list[int]):\n    # manual encoding of protobuf data\n    msg_inner = b\"\"\n    for f_val in values:\n        msg_inner = msg_inner + struct.pack(\"<Q\", f_val)  # add bits64 encoded field value\n    return helper_gen_lendel_msg_field(f_idx, msg_inner)\n\n\ndef helper_gen_bits32_msg_field_packed(f_idx: int, values: list[int]):\n    # manual encoding of protobuf data\n    msg_inner = b\"\"\n    for f_val in values:\n        msg_inner = msg_inner + struct.pack(\"<I\", f_val)  # add bits32 encoded field value\n    return helper_gen_lendel_msg_field(f_idx, msg_inner)\n\n\ndef helper_gen_varint_msg_field_packed(f_idx: int, values: list[int]):\n    # manual encoding of protobuf data\n    msg_inner = b\"\"\n    for f_val in values:\n        msg_inner = msg_inner + helper_encode_base128le(f_val)  # add varint encoded field value\n    return helper_gen_lendel_msg_field(f_idx, msg_inner)\n\n\ndef helper_gen_lendel_msg_field_packed(f_idx: int, values: list[bytes]):\n    # manual encoding of protobuf data\n    msg_inner = b\"\"\n    for f_val in values:\n        msg_inner = msg_inner + helper_encode_base128le(len(f_val))  # add length of message\n        msg_inner = msg_inner + f_val\n    return helper_gen_lendel_msg_field(f_idx, msg_inner)\n\n\ndef test_special_decoding():\n    msg = helper_gen_varint_msg_field(1, 1)  # small varint\n    msg += helper_gen_varint_msg_field(2, 1 << 32)  # varint > 32bit\n    msg += helper_gen_varint_msg_field(3, 1 << 64)  # varint > 64bit (returned as 0x0 by Kaitai protobuf decoder)\n    msg += helper_gen_bits32_msg_field(4, 0xbf8ccccd)  # bits32\n    msg += helper_gen_bits64_msg_field(5, 0xbff199999999999a)  # bits64\n    msg += helper_gen_varint_msg_field(6, 0xffffffff)  # 32 bit varint negative\n    msg += helper_gen_lendel_msg_field(7, b\"hello world\")  # length delimted message, UTF-8 parsable\n    msg += helper_gen_varint_msg_field(8, 1 << 128)  # oversized varint\n\n    parser = ProtoParser(\n        data=msg,\n        parser_options=ProtoParser.ParserOptions(),\n        rules=[]\n    )\n\n    fields = parser.root_fields\n    assert fields[0].wire_value == 1\n    assert fields[1].wire_value == 1 << 32\n    as_bool = fields[1].decode_as(ProtoParser.DecodedTypes.bool)\n    assert isinstance(as_bool, bool)\n    assert as_bool\n    as_bool = fields[2].decode_as(ProtoParser.DecodedTypes.bool)\n    assert isinstance(as_bool, bool)\n    assert not as_bool\n    assert fields[1].decode_as(ProtoParser.DecodedTypes.float) == 2.121995791e-314\n    assert fields[1].safe_decode_as(ProtoParser.DecodedTypes.uint32) == (ProtoParser.DecodedTypes.uint64, 1 << 32)\n    assert fields[0].safe_decode_as(ProtoParser.DecodedTypes.sfixed32) == (ProtoParser.DecodedTypes.uint32, 1)\n    assert fields[3].wire_type == ProtoParser.WireTypes.bit_32\n    assert fields[4].wire_type == ProtoParser.WireTypes.bit_64\n    # signed 32 bit int (standard encoding)\n    assert fields[5].safe_decode_as(ProtoParser.DecodedTypes.int32) == (ProtoParser.DecodedTypes.int32, -1)\n    # fixed (signed) 32bit int (ZigZag encoding)\n    assert fields[5].safe_decode_as(ProtoParser.DecodedTypes.sint32) == (ProtoParser.DecodedTypes.sint32, -2147483648)\n    # sint64\n    assert fields[1].safe_decode_as(ProtoParser.DecodedTypes.sint64) == (ProtoParser.DecodedTypes.sint64, 2147483648)\n    # int64\n    assert fields[1].safe_decode_as(ProtoParser.DecodedTypes.int64) == (ProtoParser.DecodedTypes.int64, 4294967296)\n\n    # varint 64bit to enum\n    assert fields[1].safe_decode_as(ProtoParser.DecodedTypes.enum) == (ProtoParser.DecodedTypes.enum, 4294967296)\n\n    # bits64 to sfixed64\n    assert fields[4].safe_decode_as(ProtoParser.DecodedTypes.sfixed64) == (ProtoParser.DecodedTypes.sfixed64, -4615739258092021350)\n    # bits64 to fixed64\n    assert fields[4].safe_decode_as(ProtoParser.DecodedTypes.fixed64) == (ProtoParser.DecodedTypes.fixed64, 0xbff199999999999a)\n    # bits64 to double\n    assert fields[4].safe_decode_as(ProtoParser.DecodedTypes.double) == (ProtoParser.DecodedTypes.double, -1.1)\n    # bits64 to float --> failover fixed64 (64bit to large for double)\n    assert fields[4].safe_decode_as(ProtoParser.DecodedTypes.float) == (ProtoParser.DecodedTypes.fixed64, 0xbff199999999999a)\n\n    # bits32 to sfixed32\n    assert fields[3].safe_decode_as(ProtoParser.DecodedTypes.sfixed32) == (ProtoParser.DecodedTypes.sfixed32, -1081291571)\n    # bits32 to fixed32\n    assert fields[3].safe_decode_as(ProtoParser.DecodedTypes.fixed32) == (ProtoParser.DecodedTypes.fixed32, 0xbf8ccccd)\n    # bits32 to float\n    assert fields[3].safe_decode_as(ProtoParser.DecodedTypes.float) == (ProtoParser.DecodedTypes.float, -1.100000023841858)\n    # bits32 to string --> failover fixed32\n    assert fields[3].safe_decode_as(ProtoParser.DecodedTypes.string) == (ProtoParser.DecodedTypes.fixed32, 0xbf8ccccd)\n\n    # length delimeted to string\n    assert fields[6].safe_decode_as(ProtoParser.DecodedTypes.string) == (ProtoParser.DecodedTypes.string, \"hello world\")\n    # length delimeted to bytes\n    assert fields[6].safe_decode_as(ProtoParser.DecodedTypes.bytes) == (ProtoParser.DecodedTypes.bytes, b\"hello world\")\n\n    assert fields[0].wire_value_as_utf8() == \"1\"\n\n    with pytest.raises(TypeError, match=\"intended decoding mismatches wire type\"):\n        fields[0].decode_as(ProtoParser.DecodedTypes.sfixed32)\n    with pytest.raises(TypeError, match=\"wire value too large for int32\"):\n        fields[1].decode_as(ProtoParser.DecodedTypes.int32)\n    with pytest.raises(TypeError, match=\"wire value too large for sint32\"):\n        fields[1].decode_as(ProtoParser.DecodedTypes.sint32)\n    with pytest.raises(TypeError, match=\"wire value too large for uint32\"):\n        fields[1].decode_as(ProtoParser.DecodedTypes.uint32)\n    with pytest.raises(TypeError, match=\"can not be converted to floatingpoint representation\"):\n        fields[6]._wire_value_as_float()\n    with pytest.raises(TypeError, match=\"wire value too large for int64\"):\n        fields[7].decode_as(ProtoParser.DecodedTypes.int64)\n    with pytest.raises(TypeError, match=\"wire value too large\"):\n        fields[7].decode_as(ProtoParser.DecodedTypes.uint64)\n    with pytest.raises(TypeError, match=\"wire value too large for sint64\"):\n        fields[7].decode_as(ProtoParser.DecodedTypes.sint64)\n    with pytest.raises(ValueError, match=\"varint exceeds bounds of provided data\"):\n        ProtoParser.read_fields(\n            wire_data=helper_encode_base128le(1 << 128),\n            options=ProtoParser.ParserOptions(),\n            parent_field=None,\n            rules=[]\n        )\n    with pytest.raises(ValueError, match=\"value exceeds 64bit, violating protobuf specs\"):\n        fields = ProtoParser.read_fields(\n            wire_data=helper_gen_varint_msg_field(1, 1 << 128),\n            options=ProtoParser.ParserOptions(),\n            parent_field=None,\n            rules=[]\n        )\n        fields[0]._value_as_bytes()\n    with pytest.raises(ValueError, match=\".* is not a valid .*WireTypes\"):\n        ProtoParser.read_fields(\n            wire_data=helper_encode_base128le(0x7),  # invalid wiretype 0x7\n            options=ProtoParser.ParserOptions(),\n            parent_field=None,\n            rules=[]\n        )\n\n\ndef test_view_protobuf_custom_config_packed(tdata):\n    # message with repeated field fixed64\n    msg_inner1 = helper_gen_bits64_msg_field(2, 12)\n    msg_inner1 += helper_gen_bits64_msg_field(2, 23)\n    msg_inner1 += helper_gen_bits64_msg_field(2, 456789012345678)\n    msg1 = helper_gen_lendel_msg_field(1, msg_inner1)\n\n    v = full_eval(ViewGrpcProtobuf())\n    view_text, output = v(msg1)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', '  '), ('text', '1    '), ('text', '                 ')],\n        [('text', '[fixed64]  '), ('text', '  '), ('text', '1.2  '), ('text', '12               ')],\n        [('text', '[fixed64]  '), ('text', '  '), ('text', '1.2  '), ('text', '23               ')],\n        [('text', '[fixed64]  '), ('text', '  '), ('text', '1.2  '), ('text', '456789012345678  ')]\n    ]\n\n    # same message as above, but fixed64 values are packed\n    # Note: the decoded has no type indication, as packed values are always contained in\n    #       a length delimited field. The packed fields contain no individual type header\n\n    # decoder has no knowledge of packed repeated field\n    msg_inner2 = helper_gen_bits64_msg_field_packed(2, [12, 23, 456789012345678])\n    msg2 = helper_gen_lendel_msg_field(1, msg_inner2)\n    view_text, output = v(msg2)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', '  '), ('text', '1    '), ('text', '                                                                                         ')],  # noqa: E501\n        [('text', '[bytes]    '), ('text', '  '), ('text', '1.2  '), ('text', \"b'\\\\x0c\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x17\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00Ns\\\\xd1zr\\\\x9f\\\\x01\\\\x00'  \")]  # noqa: E501\n    ]\n\n    # decoder uses custom definition to decode as 1.2 as \"packed, repeated fixed64\"\n    view_config = ViewConfig(\n        parser_options=ProtoParser.ParserOptions(),\n        parser_rules=[\n            ProtoParser.ParserRule(\n                filter=\".*\",\n                name=\"parse packed field\",\n                field_definitions=[\n                    ProtoParser.ParserFieldDefinition(\n                        name=\"packed repeated fixed64\",\n                        tag=\"1.2\",\n                        intended_decoding=ProtoParser.DecodedTypes.fixed64,\n                        as_packed=True\n                    )\n                ]\n            )\n        ]\n    )\n    v = full_eval(ViewGrpcProtobuf(view_config))\n    msg_inner2 = helper_gen_bits64_msg_field_packed(2, [12, 23, 456789012345678])\n    msg2 = helper_gen_lendel_msg_field(1, msg_inner2)\n    # provide the view a flow and response message dummies, to allow custom rules to work\n    view_text, output = v(msg2, flow=sim_flow, http_message=sim_flow.response)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', '                         '), ('text', '1    '), ('text', '                 ')],\n        [('text', '[fixed64]  '), ('text', 'packed repeated fixed64  '), ('text', '1.2  '), ('text', '12               ')],\n        [('text', '[fixed64]  '), ('text', 'packed repeated fixed64  '), ('text', '1.2  '), ('text', '23               ')],\n        [('text', '[fixed64]  '), ('text', 'packed repeated fixed64  '), ('text', '1.2  '), ('text', '456789012345678  ')]\n    ]\n\n    # message with packed repeated messages in field 1.5\n    # Note: protobuf v3 only allows packed encoding for scalar field types, but packed messages\n    #       were spotted in traffic to google gRPC endpoints (f.e. https://play.googleapis.com/log/batch)\n    p_msg1 = helper_gen_lendel_msg_field(1, b\"inner message 1\")\n    p_msg1 += helper_gen_varint_msg_field(2, 1)\n    p_msg2 = helper_gen_lendel_msg_field(1, b\"inner message 2\")\n    p_msg2 += helper_gen_varint_msg_field(2, 2)\n    p_msg3 = helper_gen_lendel_msg_field(1, b\"inner message 3\")\n    p_msg3 += helper_gen_varint_msg_field(2, 3)\n    msg_inner3 = helper_gen_lendel_msg_field_packed(5, [p_msg1, p_msg2, p_msg3])\n    msg3 = helper_gen_lendel_msg_field(1, msg_inner3)\n    view_config = ViewConfig(\n        parser_options=ProtoParser.ParserOptions(),\n        parser_rules=[\n            ProtoParser.ParserRule(\n                filter=\".*\",\n                name=\"parse packed field\",\n                field_definitions=[\n                    ProtoParser.ParserFieldDefinition(\n                        name=\"packed repeated message\",\n                        tag=\"1.5\",\n                        intended_decoding=ProtoParser.DecodedTypes.message,\n                        as_packed=True\n                    )\n                ]\n            )\n        ]\n    )\n    v = full_eval(ViewGrpcProtobuf(view_config))\n    # provide the view a flow and response message dummies, to allow custom rules to work\n    view_text, output = v(msg3, flow=sim_flow, http_message=sim_flow.response)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', '                         '), ('text', '1      '), ('text', '                 ')],\n        [('text', '[message]  '), ('text', 'packed repeated message  '), ('text', '1.5    '), ('text', '                 ')],\n        [('text', '[string]   '), ('text', '                         '), ('text', '1.5.1  '), ('text', 'inner message 1  ')],\n        [('text', '[uint32]   '), ('text', '                         '), ('text', '1.5.2  '), ('text', '1                ')],\n        [('text', '[message]  '), ('text', 'packed repeated message  '), ('text', '1.5    '), ('text', '                 ')],\n        [('text', '[string]   '), ('text', '                         '), ('text', '1.5.1  '), ('text', 'inner message 2  ')],\n        [('text', '[uint32]   '), ('text', '                         '), ('text', '1.5.2  '), ('text', '2                ')],\n        [('text', '[message]  '), ('text', 'packed repeated message  '), ('text', '1.5    '), ('text', '                 ')],\n        [('text', '[string]   '), ('text', '                         '), ('text', '1.5.1  '), ('text', 'inner message 3  ')],\n        [('text', '[uint32]   '), ('text', '                         '), ('text', '1.5.2  '), ('text', '3                ')]\n    ]\n\n    # message with repeated messages in field 1.5 (not packed), has to be detected by failover parsing\n    msg_inner4 = helper_gen_lendel_msg_field(5, p_msg1)\n    msg_inner4 += helper_gen_lendel_msg_field(5, p_msg2)\n    msg_inner4 += helper_gen_lendel_msg_field(5, p_msg3)\n    msg4 = helper_gen_lendel_msg_field(1, msg_inner4)\n    view_config = ViewConfig(\n        parser_options=ProtoParser.ParserOptions(),\n        parser_rules=[\n            ProtoParser.ParserRule(\n                filter=\".*\",\n                name=\"parse packed field\",\n                field_definitions=[\n                    ProtoParser.ParserFieldDefinition(\n                        name=\"packed repeated message\",\n                        tag=\"1.5\",\n                        intended_decoding=ProtoParser.DecodedTypes.message,\n                        as_packed=True\n                    )\n                ]\n            )\n        ]\n    )\n    v = full_eval(ViewGrpcProtobuf(view_config))\n    # provide the view a flow and response message dummies, to allow custom rules to work\n    view_text, output = v(msg4, flow=sim_flow, http_message=sim_flow.response)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', '                         '), ('text', '1      '), ('text', '                 ')],\n        [('text', '[message]  '), ('text', 'packed repeated message  '), ('text', '1.5    '), ('text', '                 ')],\n        [('text', '[string]   '), ('text', '                         '), ('text', '1.5.1  '), ('text', 'inner message 1  ')],\n        [('text', '[uint32]   '), ('text', '                         '), ('text', '1.5.2  '), ('text', '1                ')],\n        [('text', '[message]  '), ('text', 'packed repeated message  '), ('text', '1.5    '), ('text', '                 ')],\n        [('text', '[string]   '), ('text', '                         '), ('text', '1.5.1  '), ('text', 'inner message 2  ')],\n        [('text', '[uint32]   '), ('text', '                         '), ('text', '1.5.2  '), ('text', '2                ')],\n        [('text', '[message]  '), ('text', 'packed repeated message  '), ('text', '1.5    '), ('text', '                 ')],\n        [('text', '[string]   '), ('text', '                         '), ('text', '1.5.1  '), ('text', 'inner message 3  ')],\n        [('text', '[uint32]   '), ('text', '                         '), ('text', '1.5.2  '), ('text', '3                ')]\n    ]\n\n    # packed bit32\n    msg_inner = helper_gen_bits32_msg_field_packed(2, [12, 23, 4567890])\n    msg = helper_gen_lendel_msg_field(1, msg_inner)\n    view_config = ViewConfig(\n        parser_options=ProtoParser.ParserOptions(),\n        parser_rules=[\n            ProtoParser.ParserRule(\n                filter=\".*\",\n                name=\"parse packed field\",\n                field_definitions=[\n                    ProtoParser.ParserFieldDefinition(\n                        name=\"packed repeated fixed32\",\n                        tag=\"1.2\",\n                        intended_decoding=ProtoParser.DecodedTypes.fixed32,\n                        as_packed=True\n                    )\n                ]\n            )\n        ]\n    )\n    v = full_eval(ViewGrpcProtobuf(view_config))\n    # provide the view a flow and response message dummies, to allow custom rules to work\n    view_text, output = v(msg, flow=sim_flow, http_message=sim_flow.response)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', '                         '), ('text', '1    '), ('text', '         ')],\n        [('text', '[fixed32]  '), ('text', 'packed repeated fixed32  '), ('text', '1.2  '), ('text', '12       ')],\n        [('text', '[fixed32]  '), ('text', 'packed repeated fixed32  '), ('text', '1.2  '), ('text', '23       ')],\n        [('text', '[fixed32]  '), ('text', 'packed repeated fixed32  '), ('text', '1.2  '), ('text', '4567890  ')]\n    ]\n\n    # packed bit32, invalid\n    msg_inner = helper_gen_bits32_msg_field_packed(2, [12, 23, 4567890]) + b\"\\x01\"  # data not divisible by 4\n    msg = helper_gen_lendel_msg_field(1, msg_inner)\n    view_config = ViewConfig(\n        parser_options=ProtoParser.ParserOptions(),\n        parser_rules=[\n            ProtoParser.ParserRule(\n                filter=\".*\",\n                name=\"parse packed field\",\n                field_definitions=[\n                    ProtoParser.ParserFieldDefinition(\n                        name=\"packed repeated fixed32\",\n                        tag=\"1.2\",\n                        intended_decoding=ProtoParser.DecodedTypes.fixed32,\n                        as_packed=True\n                    )\n                ]\n            )\n        ]\n    )\n    v = full_eval(ViewGrpcProtobuf(view_config))\n    # provide the view a flow and response message dummies, to allow custom rules to work\n    view_text, output = v(msg, flow=sim_flow, http_message=sim_flow.response)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[bytes]  '), ('text', '  '), ('text', '1  '), ('text', \"b'\\\\x12\\\\x0c\\\\x0c\\\\x00\\\\x00\\\\x00\\\\x17\\\\x00\\\\x00\\\\x00R\\\\xb3E\\\\x00\\\\x01'  \")]  # noqa: E501\n    ]\n\n    # packed bit64, invalid\n    msg_inner = helper_gen_bits64_msg_field_packed(2, [12, 23, 4567890]) + b\"\\x01\"  # data not divisible by 8\n    msg = helper_gen_lendel_msg_field(1, msg_inner)\n    view_config = ViewConfig(\n        parser_options=ProtoParser.ParserOptions(),\n        parser_rules=[\n            ProtoParser.ParserRule(\n                filter=\".*\",\n                name=\"parse packed field\",\n                field_definitions=[\n                    ProtoParser.ParserFieldDefinition(\n                        name=\"packed repeated fixed64\",\n                        tag=\"1.2\",\n                        intended_decoding=ProtoParser.DecodedTypes.fixed64,\n                        as_packed=True\n                    )\n                ]\n            )\n        ]\n    )\n    v = full_eval(ViewGrpcProtobuf(view_config))\n    # provide the view a flow and response message dummies, to allow custom rules to work\n    view_text, output = v(msg, flow=sim_flow, http_message=sim_flow.response)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[bytes]  '), ('text', '  '), ('text', '1  '), ('text', \"b'\\\\x12\\\\x18\\\\x0c\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x17\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00R\\\\xb3E\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x01'\")]  # noqa: E501\n    ]\n\n    # packed varint\n    msg_inner = helper_gen_varint_msg_field_packed(2, [12, 23, 4567890])\n    msg = helper_gen_lendel_msg_field(1, msg_inner)\n    view_config = ViewConfig(\n        parser_options=ProtoParser.ParserOptions(),\n        parser_rules=[\n            ProtoParser.ParserRule(\n                filter=\".*\",\n                name=\"parse packed field\",\n                field_definitions=[\n                    ProtoParser.ParserFieldDefinition(\n                        name=\"packed repeated varint\",\n                        tag=\"1.2\",\n                        intended_decoding=ProtoParser.DecodedTypes.uint32,\n                        as_packed=True\n                    )\n                ]\n            )\n        ]\n    )\n    v = full_eval(ViewGrpcProtobuf(view_config))\n    # provide the view a flow and response message dummies, to allow custom rules to work\n    view_text, output = v(msg, flow=sim_flow, http_message=sim_flow.response)\n    assert view_text == \"Protobuf (flattened)\"\n    output = list(output)  # assure list conversion if generator\n    assert output == [\n        [('text', '[message]  '), ('text', '                        '), ('text', '1    '), ('text', '         ')],\n        [('text', '[uint32]   '), ('text', 'packed repeated varint  '), ('text', '1.2  '), ('text', '12       ')],\n        [('text', '[uint32]   '), ('text', 'packed repeated varint  '), ('text', '1.2  '), ('text', '23       ')],\n        [('text', '[uint32]   '), ('text', 'packed repeated varint  '), ('text', '1.2  '), ('text', '4567890  ')]\n    ]\n\n\ndef test_render_priority():\n    v = grpc.ViewGrpcProtobuf()\n    assert v.render_priority(b\"data\", content_type=\"application/x-protobuf\")\n    assert v.render_priority(b\"data\", content_type=\"application/x-protobuffer\")\n    assert v.render_priority(b\"data\", content_type=\"application/grpc-proto\")\n    assert v.render_priority(b\"data\", content_type=\"application/grpc\")\n    assert v.render_priority(b\"data\", content_type=\"application/prpc\")\n    assert not v.render_priority(b\"data\", content_type=\"text/plain\")\n", "test/mitmproxy/contentviews/test_javascript.py": "import pytest\n\nfrom . import full_eval\nfrom mitmproxy.contentviews import javascript\n\n\ndef test_view_javascript():\n    v = full_eval(javascript.ViewJavaScript())\n    assert v(b\"[1, 2, 3]\")\n    assert v(b\"[1, 2, 3\")\n    assert v(b\"function(a){[1, 2, 3]}\") == (\n        \"JavaScript\",\n        [[(\"text\", \"function(a) {\")], [(\"text\", \"  [1, 2, 3]\")], [(\"text\", \"}\")]],\n    )\n    assert v(b\"\\xfe\")  # invalid utf-8\n\n\n@pytest.mark.parametrize(\n    \"filename\",\n    [\n        \"simple.js\",\n    ],\n)\ndef test_format_xml(filename, tdata):\n    path = tdata.path(\"mitmproxy/contentviews/test_js_data/\" + filename)\n    with open(path) as f:\n        input = f.read()\n    with open(\"-formatted.\".join(path.rsplit(\".\", 1))) as f:\n        expected = f.read()\n    js = javascript.beautify(input)\n    assert js == expected\n\n\ndef test_render_priority():\n    v = javascript.ViewJavaScript()\n    assert v.render_priority(b\"data\", content_type=\"application/x-javascript\")\n    assert v.render_priority(b\"data\", content_type=\"application/javascript\")\n    assert v.render_priority(b\"data\", content_type=\"text/javascript\")\n    assert not v.render_priority(b\"data\", content_type=\"text/plain\")\n", "test/mitmproxy/contentviews/test_base.py": "import pytest\n\nfrom mitmproxy.contentviews import base\n\n\ndef test_format_dict():\n    d = {\"one\": \"two\", \"three\": \"four\"}\n    f_d = base.format_dict(d)\n    assert next(f_d)\n\n    d = {\"adsfa\": \"\"}\n    f_d = base.format_dict(d)\n    assert next(f_d)\n\n    d = {}\n    f_d = base.format_dict(d)\n    with pytest.raises(StopIteration):\n        next(f_d)\n\n\ndef test_format_pairs():\n    d = [(\"a\", \"c\"), (\"b\", \"d\")]\n    f_d = base.format_pairs(d)\n    assert next(f_d)\n\n    d = [(\"abc\", \"\")]\n    f_d = base.format_pairs(d)\n    assert next(f_d)\n\n    d = []\n    f_d = base.format_pairs(d)\n    with pytest.raises(StopIteration):\n        next(f_d)\n", "test/mitmproxy/contentviews/test_css.py": "import pytest\n\nfrom . import full_eval\nfrom mitmproxy.contentviews import css\n\n\n@pytest.mark.parametrize(\n    \"filename\",\n    [\n        \"animation-keyframe.css\",\n        \"blank-lines-and-spaces.css\",\n        \"block-comment.css\",\n        \"empty-rule.css\",\n        \"import-directive.css\",\n        \"indentation.css\",\n        \"media-directive.css\",\n        \"quoted-string.css\",\n        \"selectors.css\",\n        \"simple.css\",\n    ],\n)\ndef test_beautify(filename, tdata):\n    path = tdata.path(\"mitmproxy/contentviews/test_css_data/\" + filename)\n    with open(path) as f:\n        input = f.read()\n    with open(\"-formatted.\".join(path.rsplit(\".\", 1))) as f:\n        expected = f.read()\n    formatted = css.beautify(input)\n    assert formatted == expected\n\n\ndef test_simple():\n    v = full_eval(css.ViewCSS())\n    assert v(b\"#foo{color:red}\") == (\n        \"CSS\",\n        [[(\"text\", \"#foo {\")], [(\"text\", \"    color: red\")], [(\"text\", \"}\")]],\n    )\n    assert v(b\"\") == (\"CSS\", [[(\"text\", \"\")]])\n    assert v(b\"console.log('not really css')\") == (\n        \"CSS\",\n        [[(\"text\", \"console.log('not really css')\")]],\n    )\n\n\ndef test_render_priority():\n    v = css.ViewCSS()\n    assert v.render_priority(b\"data\", content_type=\"text/css\")\n    assert not v.render_priority(b\"data\", content_type=\"text/plain\")\n", "test/mitmproxy/contentviews/test_query.py": "from . import full_eval\nfrom mitmproxy.contentviews import query\nfrom mitmproxy.test import tutils\n\n\ndef test_view_query():\n    d = \"\"\n    v = full_eval(query.ViewQuery())\n    req = tutils.treq()\n    req.query = [(\"foo\", \"bar\"), (\"foo\", \"baz\")]\n    f = v(d, http_message=req)\n    assert f[0] == \"Query\"\n    assert f[1] == [\n        [(\"header\", \"foo: \"), (\"text\", \"bar\")],\n        [(\"header\", \"foo: \"), (\"text\", \"baz\")],\n    ]\n\n    assert v(d) == (\"Query\", [])\n\n\ndef test_render_priority():\n    view = query.ViewQuery()\n    req = tutils.treq()\n    req.query = [(\"foo\", \"bar\"), (\"foo\", \"baz\")]\n    assert view.render_priority(b\"\", http_message=req)\n    assert not view.render_priority(b\"\")\n", "test/mitmproxy/contentviews/test_graphql.py": "from hypothesis import given\nfrom hypothesis.strategies import binary\n\nfrom . import full_eval\nfrom mitmproxy.contentviews import graphql\n\n\ndef test_render_priority():\n    v = graphql.ViewGraphQL()\n    assert 2 == v.render_priority(\n        b\"\"\"{\"query\": \"query P { \\\\n }\"}\"\"\", content_type=\"application/json\"\n    )\n    assert 2 == v.render_priority(\n        b\"\"\"[{\"query\": \"query P { \\\\n }\"}]\"\"\", content_type=\"application/json\"\n    )\n    assert 0 == v.render_priority(\n        b\"\"\"[{\"query\": \"query P { \\\\n }\"}]\"\"\", content_type=\"text/html\"\n    )\n    assert 0 == v.render_priority(\n        b\"\"\"[{\"xquery\": \"query P { \\\\n }\"}]\"\"\", content_type=\"application/json\"\n    )\n    assert 0 == v.render_priority(b\"\"\"[]\"\"\", content_type=\"application/json\")\n    assert 0 == v.render_priority(b\"}\", content_type=\"application/json\")\n\n\ndef test_format_graphql():\n    assert graphql.format_graphql({\"query\": \"query P { \\\\n }\"})\n\n\ndef test_format_query_list():\n    assert graphql.format_query_list([{\"query\": \"query P { \\\\n }\"}])\n\n\ndef test_view_graphql():\n    v = graphql.ViewGraphQL()\n    assert v(b\"\"\"{\"query\": \"query P { \\\\n }\"}\"\"\", content_type=\"application/json\")\n    assert v(b\"\"\"[{\"query\": \"query P { \\\\n }\"}]\"\"\", content_type=\"application/json\")\n\n\n@given(binary())\ndef test_view_graphql_doesnt_crash(data):\n    v = full_eval(graphql.ViewGraphQL())\n    v(data)\n", "test/mitmproxy/contentviews/test_msgpack.py": "from hypothesis import given\nfrom hypothesis.strategies import binary\nfrom msgpack import packb\n\nfrom . import full_eval\nfrom mitmproxy.contentviews import msgpack\n\n\ndef msgpack_encode(content):\n    return packb(content, use_bin_type=True)\n\n\ndef test_parse_msgpack():\n    assert msgpack.parse_msgpack(msgpack_encode({\"foo\": 1}))\n    assert msgpack.parse_msgpack(b\"aoesuteoahu\") is msgpack.PARSE_ERROR\n    assert msgpack.parse_msgpack(msgpack_encode({\"foo\": \"\\xe4\\xb8\\x96\\xe7\\x95\\x8c\"}))\n\n\ndef test_format_msgpack():\n    assert list(\n        msgpack.format_msgpack(\n            {\"string\": \"test\", \"int\": 1, \"float\": 1.44, \"bool\": True}\n        )\n    ) == [\n        [(\"text\", \"{\")],\n        [\n            (\"text\", \"\"),\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"string\"'),\n            (\"text\", \": \"),\n            (\"Token_Literal_String\", '\"test\"'),\n            (\"text\", \",\"),\n        ],\n        [\n            (\"text\", \"\"),\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"int\"'),\n            (\"text\", \": \"),\n            (\"Token_Literal_Number\", \"1\"),\n            (\"text\", \",\"),\n        ],\n        [\n            (\"text\", \"\"),\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"float\"'),\n            (\"text\", \": \"),\n            (\"Token_Literal_Number\", \"1.44\"),\n            (\"text\", \",\"),\n        ],\n        [\n            (\"text\", \"\"),\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"bool\"'),\n            (\"text\", \": \"),\n            (\"Token_Keyword_Constant\", \"True\"),\n        ],\n        [(\"text\", \"\"), (\"text\", \"}\")],\n    ]\n\n    assert list(\n        msgpack.format_msgpack({\"object\": {\"key\": \"value\"}, \"list\": [0, 0, 1, 0, 0]})\n    ) == [\n        [(\"text\", \"{\")],\n        [\n            (\"text\", \"\"),\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"object\"'),\n            (\"text\", \": \"),\n            (\"text\", \"{\"),\n        ],\n        [\n            (\"text\", \"    \"),\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"key\"'),\n            (\"text\", \": \"),\n            (\"Token_Literal_String\", '\"value\"'),\n        ],\n        [(\"text\", \"    \"), (\"text\", \"}\"), (\"text\", \",\")],\n        [\n            (\"text\", \"\"),\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"list\"'),\n            (\"text\", \": \"),\n            (\"text\", \"[\"),\n        ],\n        [\n            (\"text\", \"    \"),\n            (\"text\", \"    \"),\n            (\"Token_Literal_Number\", \"0\"),\n            (\"text\", \",\"),\n        ],\n        [\n            (\"text\", \"    \"),\n            (\"text\", \"    \"),\n            (\"Token_Literal_Number\", \"0\"),\n            (\"text\", \",\"),\n        ],\n        [\n            (\"text\", \"    \"),\n            (\"text\", \"    \"),\n            (\"Token_Literal_Number\", \"1\"),\n            (\"text\", \",\"),\n        ],\n        [\n            (\"text\", \"    \"),\n            (\"text\", \"    \"),\n            (\"Token_Literal_Number\", \"0\"),\n            (\"text\", \",\"),\n        ],\n        [(\"text\", \"    \"), (\"text\", \"    \"), (\"Token_Literal_Number\", \"0\")],\n        [(\"text\", \"    \"), (\"text\", \"]\")],\n        [(\"text\", \"\"), (\"text\", \"}\")],\n    ]\n\n    assert list(msgpack.format_msgpack(\"string\")) == [\n        [(\"Token_Literal_String\", '\"string\"')]\n    ]\n\n    assert list(msgpack.format_msgpack(1.2)) == [[(\"Token_Literal_Number\", \"1.2\")]]\n\n    assert list(msgpack.format_msgpack(True)) == [[(\"Token_Keyword_Constant\", \"True\")]]\n\n    assert list(msgpack.format_msgpack(b\"\\x01\\x02\\x03\")) == [\n        [(\"text\", \"b'\\\\x01\\\\x02\\\\x03'\")]\n    ]\n\n\ndef test_view_msgpack():\n    v = full_eval(msgpack.ViewMsgPack())\n    assert v(msgpack_encode({}))\n    assert not v(b\"aoesuteoahu\")\n    assert v(msgpack_encode([1, 2, 3, 4, 5]))\n    assert v(msgpack_encode({\"foo\": 3}))\n    assert v(msgpack_encode({\"foo\": True, \"nullvalue\": None}))\n\n\n@given(binary())\ndef test_view_msgpack_doesnt_crash(data):\n    v = full_eval(msgpack.ViewMsgPack())\n    v(data)\n\n\ndef test_render_priority():\n    v = msgpack.ViewMsgPack()\n    assert v.render_priority(b\"data\", content_type=\"application/msgpack\")\n    assert v.render_priority(b\"data\", content_type=\"application/x-msgpack\")\n    assert not v.render_priority(b\"data\", content_type=\"text/plain\")\n", "test/mitmproxy/contentviews/test_protobuf.py": "import pytest\n\nfrom . import full_eval\nfrom mitmproxy.contentviews import protobuf\n\ndatadir = \"mitmproxy/contentviews/test_protobuf_data/\"\n\n\ndef test_view_protobuf_request(tdata):\n    v = full_eval(protobuf.ViewProtobuf())\n    p = tdata.path(datadir + \"protobuf01.bin\")\n\n    with open(p, \"rb\") as f:\n        raw = f.read()\n    content_type, output = v(raw)\n    assert content_type == \"Protobuf\"\n    assert output == [[(\"text\", \"1: 3bbc333c-e61c-433b-819a-0b9a8cc103b8\")]]\n    with pytest.raises(ValueError, match=\"Failed to parse input.\"):\n        v(b\"foobar\")\n\n\n@pytest.mark.parametrize(\"filename\", [\"protobuf02.bin\", \"protobuf03.bin\"])\ndef test_format_pbuf(filename, tdata):\n    path = tdata.path(datadir + filename)\n    with open(path, \"rb\") as f:\n        input = f.read()\n    with open(path.replace(\".bin\", \"-decoded.bin\")) as f:\n        expected = f.read()\n\n    assert protobuf.format_pbuf(input) == expected\n\n\ndef test_render_priority():\n    v = protobuf.ViewProtobuf()\n    assert v.render_priority(b\"data\", content_type=\"application/x-protobuf\")\n    assert v.render_priority(b\"data\", content_type=\"application/x-protobuffer\")\n    assert not v.render_priority(b\"data\", content_type=\"text/plain\")\n", "test/mitmproxy/contentviews/test_mqtt.py": "import pytest\n\nfrom . import full_eval\nfrom mitmproxy.contentviews import mqtt\n\n\n@pytest.mark.parametrize(\n    \"data,expected_text\",\n    [\n        pytest.param(b\"\\xc0\\x00\", \"[PINGREQ]\", id=\"PINGREQ\"),\n        pytest.param(b\"\\xd0\\x00\", \"[PINGRESP]\", id=\"PINGRESP\"),\n        pytest.param(\n            b\"\\x90\\x00\", \"Packet type SUBACK is not supported yet!\", id=\"SUBACK\"\n        ),\n        pytest.param(\n            b\"\\xa0\\x00\",\n            \"Packet type UNSUBSCRIBE is not supported yet!\",\n            id=\"UNSUBSCRIBE\",\n        ),\n        pytest.param(\n            b\"\\x82\\x31\\x00\\x03\\x00\\x2cxxxx/yy/zzzzzz/56:6F:5E:6A:01:05/messages/in\\x01\",\n            \"[SUBSCRIBE] sent topic filters: 'xxxx/yy/zzzzzz/56:6F:5E:6A:01:05/messages/in'\",\n            id=\"SUBSCRIBE\",\n        ),\n        pytest.param(\n            b\"\"\"\\x32\\x9a\\x01\\x00\\x2dxxxx/yy/zzzzzz/56:6F:5E:6A:01:05/messages/out\\x00\\x04\"\"\"\n            b\"\"\"{\"body\":{\"parameters\":null},\"header\":{\"from\":\"56:6F:5E:6A:01:05\",\"messageId\":\"connected\",\"type\":\"event\"}}\"\"\",\n            \"\"\"[PUBLISH] '{\"body\":{\"parameters\":null},\"header\":{\"from\":\"56:6F:5E:6A:01:05\",\"\"\"\n            \"\"\"\"messageId\":\"connected\",\"type\":\"event\"}}' to topic 'xxxx/yy/zzzzzz/56:6F:5E:6A:01:05/messages/out'\"\"\",\n            id=\"PUBLISH\",\n        ),\n        pytest.param(\n            b\"\"\"\\x10\\xba\\x01\\x00\\x04MQTT\\x04\\x06\\x00\\x1e\\x00\\x1156:6F:5E:6A:01:05\\x00-\"\"\"\n            b\"\"\"xxxx/yy/zzzzzz/56:6F:5E:6A:01:05/messages/out\"\"\"\n            b\"\"\"\\x00l{\"body\":{\"parameters\":null},\"header\":{\"from\":\"56:6F:5E:6A:01:05\",\"messageId\":\"disconnected\",\"type\":\"event\"}}\"\"\",\n            [\n                \"[CONNECT]\",\n                \"\",\n                \"Client Id: 56:6F:5E:6A:01:05\",\n                \"Will Topic: xxxx/yy/zzzzzz/56:6F:5E:6A:01:05/messages/out\",\n                \"\"\"Will Message: {\"body\":{\"parameters\":null},\"header\":{\"from\":\"56:6F:5E:6A:01:05\",\"\"\"\n                \"\"\"\"messageId\":\"disconnected\",\"type\":\"event\"}}\"\"\",\n                \"User Name: None\",\n                \"Password: None\",\n            ],\n            id=\"CONNECT\",\n        ),\n    ],\n)\ndef test_view_mqtt(data, expected_text):\n    \"\"\"testing helper for single line messages\"\"\"\n    v = full_eval(mqtt.ViewMQTT())\n    content_type, output = v(data)\n    assert content_type == \"MQTT\"\n    if isinstance(expected_text, list):\n        assert output == [[(\"text\", text)] for text in expected_text]\n    else:\n        assert output == [[(\"text\", expected_text)]]\n\n\n@pytest.mark.parametrize(\"data\", [b\"\\xc0\\xff\\xff\\xff\\xff\"])\ndef test_mqtt_malformed(data):\n    v = full_eval(mqtt.ViewMQTT())\n    with pytest.raises(Exception):\n        v(data)\n\n\ndef test_render_priority():\n    # missing: good MQTT heuristics.\n    assert mqtt.ViewMQTT().render_priority(b\"\") == 0\n", "test/mitmproxy/contentviews/test_api.py": "from unittest import mock\n\nimport pytest\n\nfrom mitmproxy import contentviews\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nclass TestContentView(contentviews.View):\n    name = \"test\"\n\n    def __call__(self, *args, **kwargs):\n        pass\n\n    def should_render(self, content_type):\n        return content_type == \"test/123\"\n\n\ndef test_add_remove():\n    tcv = TestContentView()\n    contentviews.add(tcv)\n    assert tcv in contentviews.views\n\n    # repeated addition causes exception\n    with pytest.raises(ValueError, match=\"Duplicate view\"):\n        contentviews.add(tcv)\n\n    contentviews.remove(tcv)\n    assert tcv not in contentviews.views\n\n\ndef test_get_content_view():\n    desc, lines, err = contentviews.get_content_view(\n        contentviews.get(\"Raw\"),\n        b\"[1, 2, 3]\",\n    )\n    assert \"Raw\" in desc\n    assert list(lines)\n    assert not err\n\n    desc, lines, err = contentviews.get_content_view(\n        contentviews.get(\"Auto\"),\n        b\"[1, 2, 3]\",\n        content_type=\"application/json\",\n    )\n    assert desc == \"JSON\"\n    assert list(lines)\n\n    desc, lines, err = contentviews.get_content_view(\n        contentviews.get(\"JSON\"),\n        b\"[1, 2\",\n    )\n    assert \"Couldn't parse\" in desc\n\n    with mock.patch(\"mitmproxy.contentviews.auto.ViewAuto.__call__\") as view_auto:\n        view_auto.side_effect = ValueError\n\n        desc, lines, err = contentviews.get_content_view(\n            contentviews.get(\"Auto\"),\n            b\"[1, 2\",\n        )\n        assert err\n        assert \"Couldn't parse\" in desc\n\n\ndef test_get_message_content_view():\n    f = tflow.tflow()\n    r = tutils.treq()\n    desc, lines, err = contentviews.get_message_content_view(\"raw\", r, f)\n    assert desc == \"Raw\"\n\n    desc, lines, err = contentviews.get_message_content_view(\"unknown\", r, f)\n    assert desc == \"Raw\"\n\n    r.encode(\"gzip\")\n    desc, lines, err = contentviews.get_message_content_view(\"raw\", r, f)\n    assert desc == \"[decoded gzip] Raw\"\n\n    r.headers[\"content-encoding\"] = \"deflate\"\n    desc, lines, err = contentviews.get_message_content_view(\"raw\", r, f)\n    assert desc == \"[cannot decode] Raw\"\n\n    del r.headers[\"content-encoding\"]\n    r.headers[\"content-type\"] = \"multipart/form-data; boundary=AaB03x\"\n    r.content = b\"\"\"\n--AaB03x\nContent-Disposition: form-data; name=\"submit-name\"\n\nLarry\n--AaB03x\n        \"\"\".strip()\n    desc, lines, err = contentviews.get_message_content_view(\"multipart form\", r, f)\n    assert desc == \"Multipart form\"\n\n    r.content = None\n    desc, lines, err = contentviews.get_message_content_view(\"raw\", r, f)\n    assert list(lines) == [[(\"error\", \"content missing\")]]\n", "test/mitmproxy/contentviews/__init__.py": "def full_eval(instance):\n    def call(data, **metadata):\n        x = instance(data, **metadata)\n        if x is None:\n            return None\n        name, generator = x\n        return name, list(generator)\n\n    return call\n", "test/mitmproxy/contentviews/test_multipart.py": "from . import full_eval\nfrom mitmproxy.contentviews import multipart\nfrom mitmproxy.test import tutils\n\n\ndef test_view_multipart():\n    view = full_eval(multipart.ViewMultipart())\n    v = b\"\"\"\n--AaB03x\nContent-Disposition: form-data; name=\"submit-name\"\n\nLarry\n--AaB03x\n        \"\"\".strip()\n    assert view(v, content_type=\"multipart/form-data; boundary=AaB03x\")\n\n    req = tutils.treq()\n    req.headers[\"content-type\"] = \"multipart/form-data; boundary=AaB03x\"\n    req.content = v\n\n    assert view(\n        v, content_type=\"multipart/form-data; boundary=AaB03x\", http_message=req\n    )\n\n    assert not view(v)\n\n    assert not view(v, content_type=\"multipart/form-data\")\n\n    assert not view(v, content_type=\"unparseable\")\n\n\ndef test_render_priority():\n    v = multipart.ViewMultipart()\n    assert v.render_priority(b\"data\", content_type=\"multipart/form-data\")\n    assert not v.render_priority(b\"data\", content_type=\"text/plain\")\n", "test/mitmproxy/contentviews/test_wbxml.py": "from . import full_eval\nfrom mitmproxy.contentviews import wbxml\n\ndatadir = \"mitmproxy/contentviews/test_wbxml_data/\"\n\n\ndef test_wbxml(tdata):\n    v = full_eval(wbxml.ViewWBXML())\n\n    assert v(b\"\\x03\\x01\\x6a\\x00\") == (\"WBXML\", [[(\"text\", '<?xml version=\"1.0\" ?>')]])\n    assert v(b\"foo\") is None\n\n    path = tdata.path(\n        datadir + \"data.wbxml\"\n    )  # File taken from https://github.com/davidpshaw/PyWBXMLDecoder/tree/master/wbxml_samples\n    with open(path, \"rb\") as f:\n        input = f.read()\n    with open(\"-formatted.\".join(path.rsplit(\".\", 1))) as f:\n        expected = f.read()\n\n    p = wbxml.ASCommandResponse.ASCommandResponse(input)\n    assert p.xmlString == expected\n\n\ndef test_render_priority():\n    v = wbxml.ViewWBXML()\n    assert v.render_priority(b\"data\", content_type=\"application/vnd.wap.wbxml\")\n    assert v.render_priority(b\"data\", content_type=\"application/vnd.ms-sync.wbxml\")\n    assert not v.render_priority(b\"data\", content_type=\"text/plain\")\n", "test/mitmproxy/contentviews/test_xml_html.py": "import pytest\n\nfrom . import full_eval\nfrom mitmproxy.contentviews import xml_html\n\ndatadir = \"mitmproxy/contentviews/test_xml_html_data/\"\n\n\ndef test_simple(tdata):\n    v = full_eval(xml_html.ViewXmlHtml())\n    assert v(b\"foo\") == (\"XML\", [[(\"text\", \"foo\")]])\n    assert v(b\"<html></html>\") == (\"HTML\", [[(\"text\", \"<html></html>\")]])\n    assert v(b\"<>\") == (\"XML\", [[(\"text\", \"<>\")]])\n    assert v(b\"<p\") == (\"XML\", [[(\"text\", \"<p\")]])\n\n    with open(tdata.path(datadir + \"simple.html\")) as f:\n        input = f.read()\n    tokens = xml_html.tokenize(input)\n    assert str(next(tokens)) == \"Tag(<!DOCTYPE html>)\"\n\n\n@pytest.mark.parametrize(\n    \"filename\", [\"simple.html\", \"cdata.xml\", \"comment.xml\", \"inline.html\", \"test.html\"]\n)\ndef test_format_xml(filename, tdata):\n    path = tdata.path(datadir + filename)\n    with open(path) as f:\n        input = f.read()\n    with open(\"-formatted.\".join(path.rsplit(\".\", 1))) as f:\n        expected = f.read()\n    tokens = xml_html.tokenize(input)\n    assert xml_html.format_xml(tokens) == expected\n\n\ndef test_render_priority():\n    v = xml_html.ViewXmlHtml()\n    assert v.render_priority(b\"data\", content_type=\"text/xml\")\n    assert v.render_priority(b\"data\", content_type=\"text/xml\")\n    assert v.render_priority(b\"data\", content_type=\"text/html\")\n    assert not v.render_priority(b\"data\", content_type=\"text/plain\")\n    assert not v.render_priority(b\"\", content_type=\"text/xml\")\n    assert v.render_priority(b\"<html/>\")\n", "test/mitmproxy/contentviews/test_http3.py": "import pytest\n\nfrom . import full_eval\nfrom mitmproxy.contentviews import http3\nfrom mitmproxy.tcp import TCPMessage\nfrom mitmproxy.test import tflow\n\n\n@pytest.mark.parametrize(\n    \"data\",\n    [\n        # HEADERS\n        b\"\\x01\\x1d\\x00\\x00\\xd1\\xc1\\xd7P\\x8a\\x08\\x9d\\\\\\x0b\\x81p\\xdcx\\x0f\\x03_P\\x88%\\xb6P\\xc3\\xab\\xbc\\xda\\xe0\\xdd\",\n        # broken HEADERS\n        b\"\\x01\\x1d\\x00\\x00\\xd1\\xc1\\xd7P\\x8a\\x08\\x9d\\\\\\x0b\\x81p\\xdcx\\x0f\\x03_P\\x88%\\xb6P\\xc3\\xab\\xff\\xff\\xff\\xff\",\n        # headers + data\n        (\n            b\"\\x01@I\\x00\\x00\\xdb_'\\x93I|\\xa5\\x89\\xd3M\\x1fj\\x12q\\xd8\\x82\\xa6\\x0bP\\xb0\\xd0C\\x1b_M\\x90\\xd0bXt\\x1eT\\xad\\x8f~\\xfdp\"\n            b\"\\xeb\\xc8\\xc0\\x97\\x07V\\x96\\xd0z\\xbe\\x94\\x08\\x94\\xdcZ\\xd4\\x10\\x04%\\x02\\xe5\\xc6\\xde\\xb8\\x17\\x14\\xc5\\xa3\\x7fT\\x03315\"\n            b'\\x00A;<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\"\"http://www.w3.org/TR/html4/strict.dtd\">\\r\\n<HTML><HEAD><'\n            b'TITLE>Not Found</TITLE>\\r\\n<META HTTP-EQUIV=\"Content-Type\" Content=\"text/html; charset=us-ascii\"></HEAD>\\r\\n<BOD'\n            b\"Y><h2>Not Found</h2>\\r\\n<hr><p>HTTP Error 404. The requested resource is not found.</p>\\r\\n</BODY></HTML>\\r\\n\"\n        ),\n        b\"\",\n    ],\n)\ndef test_view_http3(data):\n    v = full_eval(http3.ViewHttp3())\n    t = tflow.ttcpflow(messages=[TCPMessage(from_client=len(data) > 16, content=data)])\n    t.metadata[\"quic_is_unidirectional\"] = False\n    assert v(b\"\", flow=t, tcp_message=t.messages[0])\n\n\n@pytest.mark.parametrize(\n    \"data\",\n    [\n        # SETTINGS\n        b\"\\x00\\x04\\r\\x06\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x00\\x07\\x00\",\n        # unknown setting\n        b\"\\x00\\x04\\r\\x3f\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x00\\x07\\x00\",\n        # out of bounds\n        b\"\\x00\\x04\\r\\x06\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x00\\x42\\x00\",\n        # incomplete\n        b\"\\x00\\x04\\r\\x06\\xff\\xff\\xff\",\n        # QPACK encoder stream\n        b\"\\x02\",\n    ],\n)\ndef test_view_http3_unidirectional(data):\n    v = full_eval(http3.ViewHttp3())\n    t = tflow.ttcpflow(messages=[TCPMessage(from_client=len(data) > 16, content=data)])\n    t.metadata[\"quic_is_unidirectional\"] = True\n    assert v(b\"\", flow=t, tcp_message=t.messages[0])\n\n\ndef test_render_priority():\n    v = http3.ViewHttp3()\n    assert not v.render_priority(b\"random stuff\")\n", "test/mitmproxy/contentviews/test_urlencoded.py": "from . import full_eval\nfrom mitmproxy.contentviews import urlencoded\nfrom mitmproxy.net.http import url\n\n\ndef test_view_urlencoded():\n    v = full_eval(urlencoded.ViewURLEncoded())\n\n    d = url.encode([(\"one\", \"two\"), (\"three\", \"four\")]).encode()\n    assert v(d)\n\n    d = url.encode([(\"adsfa\", \"\")]).encode()\n    assert v(d)\n\n    assert not v(b\"\\xff\\x00\")\n\n\ndef test_render_priority():\n    v = urlencoded.ViewURLEncoded()\n    assert v.render_priority(b\"data\", content_type=\"application/x-www-form-urlencoded\")\n    assert not v.render_priority(b\"data\", content_type=\"text/plain\")\n", "test/mitmproxy/contentviews/test_json.py": "from hypothesis import given\nfrom hypothesis.strategies import binary\n\nfrom . import full_eval\nfrom mitmproxy.contentviews import json\n\n\ndef test_parse_json():\n    assert json.parse_json(b'{\"foo\": 1}')\n    assert json.parse_json(b\"null\") is None\n    assert json.parse_json(b\"moo\") is json.PARSE_ERROR\n    assert json.parse_json(\n        b'{\"foo\" : \"\\xe4\\xb8\\x96\\xe7\\x95\\x8c\"}'\n    )  # utf8 with chinese characters\n    assert json.parse_json(b'{\"foo\" : \"\\xff\"}') is json.PARSE_ERROR\n\n\ndef test_format_json():\n    assert list(json.format_json({\"data\": [\"str\", 42, True, False, None, {}, []]}))\n    assert list(json.format_json({\"string\": \"test\"})) == [\n        [(\"text\", \"{\"), (\"text\", \"\")],\n        [\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"string\"'),\n            (\"text\", \": \"),\n            (\"Token_Literal_String\", '\"test\"'),\n            (\"text\", \"\"),\n        ],\n        [(\"text\", \"\"), (\"text\", \"}\")],\n    ]\n    assert list(json.format_json({\"num\": 4})) == [\n        [(\"text\", \"{\"), (\"text\", \"\")],\n        [\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"num\"'),\n            (\"text\", \": \"),\n            (\"Token_Literal_Number\", \"4\"),\n            (\"text\", \"\"),\n        ],\n        [(\"text\", \"\"), (\"text\", \"}\")],\n    ]\n    assert list(json.format_json({\"bool\": True})) == [\n        [(\"text\", \"{\"), (\"text\", \"\")],\n        [\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"bool\"'),\n            (\"text\", \": \"),\n            (\"Token_Keyword_Constant\", \"true\"),\n            (\"text\", \"\"),\n        ],\n        [(\"text\", \"\"), (\"text\", \"}\")],\n    ]\n    assert list(json.format_json({\"object\": {\"int\": 1}})) == [\n        [(\"text\", \"{\"), (\"text\", \"\")],\n        [\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"object\"'),\n            (\"text\", \": \"),\n            (\"text\", \"{\"),\n            (\"text\", \"\"),\n        ],\n        [\n            (\"text\", \"        \"),\n            (\"Token_Name_Tag\", '\"int\"'),\n            (\"text\", \": \"),\n            (\"Token_Literal_Number\", \"1\"),\n            (\"text\", \"\"),\n        ],\n        [(\"text\", \"    \"), (\"text\", \"}\"), (\"text\", \"\")],\n        [(\"text\", \"\"), (\"text\", \"}\")],\n    ]\n    assert list(json.format_json({\"list\": [\"string\", 1, True]})) == [\n        [(\"text\", \"{\"), (\"text\", \"\")],\n        [(\"text\", \"    \"), (\"Token_Name_Tag\", '\"list\"'), (\"text\", \": \"), (\"text\", \"[\")],\n        [(\"Token_Literal_String\", '        \"string\"'), (\"text\", \",\")],\n        [(\"Token_Literal_Number\", \"        1\"), (\"text\", \",\")],\n        [(\"Token_Keyword_Constant\", \"        true\"), (\"text\", \"\")],\n        [(\"text\", \"    \"), (\"text\", \"]\"), (\"text\", \"\")],\n        [(\"text\", \"\"), (\"text\", \"}\")],\n    ]\n    assert list(json.format_json({\"list\": []})) == [\n        [(\"text\", \"{\"), (\"text\", \"\")],\n        [\n            (\"text\", \"    \"),\n            (\"Token_Name_Tag\", '\"list\"'),\n            (\"text\", \": \"),\n            (\"text\", \"[]\"),\n            (\"text\", \"\"),\n        ],\n        [(\"text\", \"\"), (\"text\", \"}\")],\n    ]\n    assert list(json.format_json(None)) == [[(\"Token_Keyword_Constant\", \"null\")]]\n    assert list(json.format_json(True)) == [[(\"Token_Keyword_Constant\", \"true\")]]\n    assert list(json.format_json(1)) == [[(\"Token_Literal_Number\", \"1\")]]\n    assert list(json.format_json(\"test\")) == [[(\"Token_Literal_String\", '\"test\"')]]\n    assert list(json.format_json([])) == [[(\"text\", \"[]\")]]\n\n\ndef test_view_json():\n    v = full_eval(json.ViewJSON())\n    assert v(b\"null\")\n    assert v(b\"{}\")\n    assert not v(b\"{\")\n    assert v(b\"[1, 2, 3, 4, 5]\")\n    assert v(b'{\"foo\" : 3}')\n    assert v(b'{\"foo\": true, \"nullvalue\": null}')\n    assert v(b\"[]\")\n\n\n@given(binary())\ndef test_view_json_doesnt_crash(data):\n    v = full_eval(json.ViewJSON())\n    v(data)\n\n\ndef test_render_priority():\n    v = json.ViewJSON()\n    assert v.render_priority(b\"data\", content_type=\"application/json\")\n    assert v.render_priority(b\"data\", content_type=\"application/json-rpc\")\n    assert v.render_priority(b\"data\", content_type=\"application/vnd.api+json\")\n    assert v.render_priority(b\"data\", content_type=\"application/acme+json\")\n    assert not v.render_priority(b\"data\", content_type=\"text/plain\")\n    assert not v.render_priority(b\"\", content_type=\"application/json\")\n", "test/mitmproxy/contentviews/image/test_image_parser.py": "import pytest\n\nfrom mitmproxy.contentviews.image import image_parser\n\n\n@pytest.mark.parametrize(\n    \"filename, metadata\",\n    {\n        # no textual data\n        \"mitmproxy/data/image_parser/ct0n0g04.png\": [\n            (\"Format\", \"Portable network graphics\"),\n            (\"Size\", \"32 x 32 px\"),\n            (\"gamma\", \"1.0\"),\n        ],\n        # with textual data\n        \"mitmproxy/data/image_parser/ct1n0g04.png\": [\n            (\"Format\", \"Portable network graphics\"),\n            (\"Size\", \"32 x 32 px\"),\n            (\"gamma\", \"1.0\"),\n            (\"Title\", \"PngSuite\"),\n            (\"Author\", \"Willem A.J. van Schaik\\n(willem@schaik.com)\"),\n            (\"Copyright\", \"Copyright Willem van Schaik, Singapore 1995-96\"),\n            (\n                \"Description\",\n                \"A compilation of a set of images created to test the\\n\"\n                \"various color-types of the PNG format. Included are\\nblack&white, color,\"\n                \" paletted, with alpha channel, with\\ntransparency formats. All bit-depths\"\n                \" allowed according\\nto the spec are present.\",\n            ),\n            (\"Software\", 'Created on a NeXTstation color using \"pnmtopng\".'),\n            (\"Disclaimer\", \"Freeware.\"),\n        ],\n        # with compressed textual data\n        \"mitmproxy/data/image_parser/ctzn0g04.png\": [\n            (\"Format\", \"Portable network graphics\"),\n            (\"Size\", \"32 x 32 px\"),\n            (\"gamma\", \"1.0\"),\n            (\"Title\", \"PngSuite\"),\n            (\"Author\", \"Willem A.J. van Schaik\\n(willem@schaik.com)\"),\n            (\"Copyright\", \"Copyright Willem van Schaik, Singapore 1995-96\"),\n            (\n                \"Description\",\n                \"A compilation of a set of images created to test the\\n\"\n                \"various color-types of the PNG format. Included are\\nblack&white, color,\"\n                \" paletted, with alpha channel, with\\ntransparency formats. All bit-depths\"\n                \" allowed according\\nto the spec are present.\",\n            ),\n            (\"Software\", 'Created on a NeXTstation color using \"pnmtopng\".'),\n            (\"Disclaimer\", \"Freeware.\"),\n        ],\n        # UTF-8 international text - english\n        \"mitmproxy/data/image_parser/cten0g04.png\": [\n            (\"Format\", \"Portable network graphics\"),\n            (\"Size\", \"32 x 32 px\"),\n            (\"gamma\", \"1.0\"),\n            (\"Title\", \"PngSuite\"),\n            (\"Author\", \"Willem van Schaik (willem@schaik.com)\"),\n            (\"Copyright\", \"Copyright Willem van Schaik, Canada 2011\"),\n            (\n                \"Description\",\n                \"A compilation of a set of images created to test the \"\n                \"various color-types of the PNG format. Included are black&white, color,\"\n                \" paletted, with alpha channel, with transparency formats. All bit-depths\"\n                \" allowed according to the spec are present.\",\n            ),\n            (\"Software\", 'Created on a NeXTstation color using \"pnmtopng\".'),\n            (\"Disclaimer\", \"Freeware.\"),\n        ],\n        # check gamma value\n        \"mitmproxy/data/image_parser/g07n0g16.png\": [\n            (\"Format\", \"Portable network graphics\"),\n            (\"Size\", \"32 x 32 px\"),\n            (\"gamma\", \"0.7\"),\n        ],\n        # check aspect value\n        \"mitmproxy/data/image_parser/aspect.png\": [\n            (\"Format\", \"Portable network graphics\"),\n            (\"Size\", \"1280 x 798 px\"),\n            (\"aspect\", \"72 x 72\"),\n            (\"date:create\", \"2012-07-11T14:04:52-07:00\"),\n            (\"date:modify\", \"2012-07-11T14:04:52-07:00\"),\n        ],\n    }.items(),\n)\ndef test_parse_png(filename, metadata, tdata):\n    with open(tdata.path(filename), \"rb\") as f:\n        assert metadata == image_parser.parse_png(f.read())\n\n\n@pytest.mark.parametrize(\n    \"filename, metadata\",\n    {\n        # check comment\n        \"mitmproxy/data/image_parser/hopper.gif\": [\n            (\"Format\", \"Compuserve GIF\"),\n            (\"Version\", \"GIF89a\"),\n            (\"Size\", \"128 x 128 px\"),\n            (\"background\", \"0\"),\n            (\"comment\", \"b'File written by Adobe Photoshop\\\\xa8 4.0'\"),\n        ],\n        # check background\n        \"mitmproxy/data/image_parser/chi.gif\": [\n            (\"Format\", \"Compuserve GIF\"),\n            (\"Version\", \"GIF89a\"),\n            (\"Size\", \"320 x 240 px\"),\n            (\"background\", \"248\"),\n            (\"comment\", \"b'Created with GIMP'\"),\n        ],\n        # check working with color table\n        \"mitmproxy/data/image_parser/iss634.gif\": [\n            (\"Format\", \"Compuserve GIF\"),\n            (\"Version\", \"GIF89a\"),\n            (\"Size\", \"245 x 245 px\"),\n            (\"background\", \"0\"),\n        ],\n    }.items(),\n)\ndef test_parse_gif(filename, metadata, tdata):\n    with open(tdata.path(filename), \"rb\") as f:\n        assert metadata == image_parser.parse_gif(f.read())\n\n\n@pytest.mark.parametrize(\n    \"filename, metadata\",\n    {\n        # check app0\n        \"mitmproxy/data/image_parser/example.jpg\": [\n            (\"Format\", \"JPEG (ISO 10918)\"),\n            (\"jfif_version\", \"(1, 1)\"),\n            (\"jfif_density\", \"(96, 96)\"),\n            (\"jfif_unit\", \"1\"),\n            (\"Size\", \"256 x 256 px\"),\n        ],\n        # check com\n        \"mitmproxy/data/image_parser/comment.jpg\": [\n            (\"Format\", \"JPEG (ISO 10918)\"),\n            (\"jfif_version\", \"(1, 1)\"),\n            (\"jfif_density\", \"(96, 96)\"),\n            (\"jfif_unit\", \"1\"),\n            (\"comment\", \"b'mitmproxy test image'\"),\n            (\"Size\", \"256 x 256 px\"),\n        ],\n        # check app1\n        \"mitmproxy/data/image_parser/app1.jpeg\": [\n            (\"Format\", \"JPEG (ISO 10918)\"),\n            (\"jfif_version\", \"(1, 1)\"),\n            (\"jfif_density\", \"(72, 72)\"),\n            (\"jfif_unit\", \"1\"),\n            (\"make\", \"Canon\"),\n            (\"model\", \"Canon PowerShot A60\"),\n            (\"modify_date\", \"2004:07:16 18:46:04\"),\n            (\"Size\", \"717 x 558 px\"),\n        ],\n        # check multiple segments\n        \"mitmproxy/data/image_parser/all.jpeg\": [\n            (\"Format\", \"JPEG (ISO 10918)\"),\n            (\"jfif_version\", \"(1, 1)\"),\n            (\"jfif_density\", \"(300, 300)\"),\n            (\"jfif_unit\", \"1\"),\n            (\n                \"comment\",\n                \"b'BARTOLOMEO DI FRUOSINO\\\\r\\\\n(b. ca. 1366, Firenze, d. 1441, \"\n                \"Firenze)\\\\r\\\\n\\\\r\\\\nInferno, from the Divine Comedy by Dante (Folio 1v)\"\n                \"\\\\r\\\\n1430-35\\\\r\\\\nTempera, gold, and silver on parchment, 365 x 265 mm\"\n                \"\\\\r\\\\nBiblioth\\\\xe8que Nationale, Paris\\\\r\\\\n\\\\r\\\\nThe codex in Paris \"\n                \"contains the text of the Inferno, the first of three books of the Divine \"\n                \"Comedy, the masterpiece of the Florentine poet Dante Alighieri (1265-1321).\"\n                \" The codex begins with two full-page illuminations. On folio 1v Dante and \"\n                \"Virgil stand within the doorway of Hell at the upper left and observe its \"\n                \"nine different zones. Dante and Virgil are to wade through successive \"\n                \"circles teeming with images of the damned. The gates of Hell appear  in \"\n                \"the middle, a scarlet row of open sarcophagi before them. Devils orchestrate\"\n                \" the movements of the wretched souls.\\\\r\\\\n\\\\r\\\\nThe vision of the fiery \"\n                'inferno follows a convention established by <A onclick=\"return OpenOther'\n                '(\\\\\\'/html/n/nardo/strozzi3.html\\\\\\')\" HREF=\"/html/n/nardo/strozzi3.html\">'\n                \"Nardo di Cione\\\\'s fresco</A> in the church of Santa Maria Novella, Florence.\"\n                \" Of remarkable vivacity and intensity of expression, the illumination is \"\n                \"executed in Bartolomeo\\\\'s late style.\\\\r\\\\n\\\\r\\\\n\\\\r\\\\n\\\\r\\\\n\\\\r\\\\n\\\\r\\\\n\\\\r\\\\n\"\n                \"--- Keywords: --------------\\\\r\\\\n\\\\r\\\\nAuthor: BARTOLOMEO DI FRUOSINO\"\n                \"\\\\r\\\\nTitle: Inferno, from the Divine Comedy by Dante (Folio 1v)\\\\r\\\\nTime-line:\"\n                \" 1401-1450\\\\r\\\\nSchool: Italian\\\\r\\\\nForm: illumination\\\\r\\\\nType: other\\\\r\\\\n'\",\n            ),\n            (\"Size\", \"750 x 1055 px\"),\n        ],\n    }.items(),\n)\ndef test_parse_jpeg(filename, metadata, tdata):\n    with open(tdata.path(filename), \"rb\") as f:\n        assert metadata == image_parser.parse_jpeg(f.read())\n\n\n# fmt: off\n@pytest.mark.parametrize(\n    \"filename, metadata\",\n    {\n        \"mitmproxy/data/image.ico\": [\n            (\"Format\", \"ICO\"),\n            (\"Number of images\", \"3\"),\n            (\n                \"Image 1\",\n                \"Size: {} x {}\\n\"\n                \"{: >18}Bits per pixel: {}\\n\"\n                \"{: >18}PNG: {}\".format(48, 48, \"\", 24, \"\", False),\n            ),\n            (\n                \"Image 2\",\n                \"Size: {} x {}\\n\"\n                \"{: >18}Bits per pixel: {}\\n\"\n                \"{: >18}PNG: {}\".format(32, 32, \"\", 24, \"\", False),\n            ),\n            (\n                \"Image 3\",\n                \"Size: {} x {}\\n\"\n                \"{: >18}Bits per pixel: {}\\n\"\n                \"{: >18}PNG: {}\".format(16, 16, \"\", 24, \"\", False),\n            ),\n        ]\n    }.items(),\n)\ndef test_ico(filename, metadata, tdata):\n    with open(tdata.path(filename), \"rb\") as f:\n        assert metadata == image_parser.parse_ico(f.read())\n# fmt: on\n", "test/mitmproxy/contentviews/image/__init__.py": "", "test/mitmproxy/contentviews/image/test_view.py": "from .. import full_eval\nfrom mitmproxy.contentviews import image\n\n\ndef test_view_image(tdata):\n    v = full_eval(image.ViewImage())\n    for img in [\n        \"mitmproxy/data/image.png\",\n        \"mitmproxy/data/image.gif\",\n        \"mitmproxy/data/all.jpeg\",\n        \"mitmproxy/data/image.ico\",\n    ]:\n        with open(tdata.path(img), \"rb\") as f:\n            viewname, lines = v(f.read())\n            assert img.split(\".\")[-1].upper() in viewname\n\n    assert v(b\"flibble\") == (\n        \"Unknown Image\",\n        [[(\"header\", \"Image Format: \"), (\"text\", \"unknown\")]],\n    )\n\n\ndef test_render_priority():\n    v = image.ViewImage()\n    assert v.render_priority(b\"\", content_type=\"image/png\")\n    assert v.render_priority(b\"\", content_type=\"image/jpeg\")\n    assert v.render_priority(b\"\", content_type=\"image/gif\")\n    assert v.render_priority(b\"\", content_type=\"image/vnd.microsoft.icon\")\n    assert v.render_priority(b\"\", content_type=\"image/x-icon\")\n    assert v.render_priority(b\"\", content_type=\"image/webp\")\n    assert v.render_priority(b\"\", content_type=\"image/future-unknown-format-42\")\n    assert not v.render_priority(b\"\", content_type=\"image/svg+xml\")\n", "test/mitmproxy/data/servercert/generate.py": "import pathlib\nimport shutil\n\nsrc = pathlib.Path(\"../../net/data/verificationcerts\")\nhere = pathlib.Path(\".\")\n\nshutil.copy(src / \"9da13359.0\", \"9da13359.0\")\n\nfor x in [\"self-signed\", \"trusted-leaf\", \"trusted-root\"]:\n    (here / f\"{x}.pem\").write_text(\n        (src / f\"{x}.crt\").read_text() + (src / f\"{x}.key\").read_text()\n    )\n", "test/mitmproxy/data/addonscripts/stream_modify.py": "import logging\n\n\ndef modify(chunks):\n    for chunk in chunks:\n        yield chunk.replace(b\"foo\", b\"bar\")\n\n\ndef running():\n    logging.info(\"stream_modify running\")\n\n\ndef responseheaders(flow):\n    flow.response.stream = modify\n", "test/mitmproxy/data/addonscripts/load_error.py": "def load(_):\n    raise ValueError()\n", "test/mitmproxy/data/addonscripts/concurrent_decorator_class.py": "import time\n\nfrom mitmproxy.script import concurrent\n\n\nclass ConcurrentClass:\n    @concurrent\n    def request(self, flow):\n        time.sleep(0.25)\n\n    @concurrent\n    async def requestheaders(self, flow):\n        time.sleep(0.25)\n\n\naddons = [ConcurrentClass()]\n", "test/mitmproxy/data/addonscripts/import_error.py": "import nonexistent\n\nnonexistent.foo()\n", "test/mitmproxy/data/addonscripts/shutdown.py": "from mitmproxy import ctx\n\n\ndef running():\n    ctx.master.shutdown()\n", "test/mitmproxy/data/addonscripts/concurrent_decorator_err.py": "from mitmproxy.script import concurrent\n\n\n@concurrent\ndef load(v):\n    pass\n", "test/mitmproxy/data/addonscripts/addon.py": "import logging\n\nevent_log = []\n\n\nclass Addon:\n    @property\n    def event_log(self):\n        return event_log\n\n    def load(self, opts):\n        logging.info(\"addon running\")\n        event_log.append(\"addonload\")\n\n    def configure(self, updated):\n        event_log.append(\"addonconfigure\")\n\n\ndef configure(updated):\n    event_log.append(\"scriptconfigure\")\n\n\ndef load(loader):\n    event_log.append(\"scriptload\")\n\n\naddons = [Addon()]\n", "test/mitmproxy/data/addonscripts/concurrent_decorator.py": "import time\n\nfrom mitmproxy.script import concurrent\n\n\n@concurrent\ndef request(flow):\n    time.sleep(0.25)\n\n\n@concurrent\nasync def requestheaders(flow):\n    time.sleep(0.25)\n", "test/mitmproxy/data/addonscripts/tcp_stream_modify.py": "def tcp_message(flow):\n    message = flow.messages[-1]\n    if not message.from_client:\n        message.content = message.content.replace(b\"foo\", b\"bar\")\n", "test/mitmproxy/data/addonscripts/error.py": "import logging\n\n\ndef load(loader):\n    logging.info(\"error load\")\n\n\ndef request(flow):\n    raise ValueError(\"Error!\")\n", "test/mitmproxy/data/addonscripts/configure.py": "from typing import Optional\n\nfrom mitmproxy import exceptions\n\n\nclass OptionAddon:\n    def load(self, loader):\n        loader.add_option(\n            name=\"optionaddon\",\n            typespec=Optional[int],\n            default=None,\n            help=\"Option Addon\",\n        )\n\n    def configure(self, updates):\n        raise exceptions.OptionsError(\"Options Error\")\n\n\naddons = [OptionAddon()]\n", "test/mitmproxy/data/addonscripts/same_filename/addon.py": "foo = 42\n", "test/mitmproxy/data/addonscripts/recorder/a.py": "import recorder\n\naddons = [recorder.Recorder(\"a\")]\n", "test/mitmproxy/data/addonscripts/recorder/b.py": "import recorder\n\naddons = [recorder.Recorder(\"b\")]\n", "test/mitmproxy/data/addonscripts/recorder/c.py": "import recorder\n\naddons = [recorder.Recorder(\"c\")]\n", "test/mitmproxy/data/addonscripts/recorder/recorder.py": "import logging\n\nfrom mitmproxy import hooks\n\n\nclass Recorder:\n    call_log = []\n\n    def __init__(self, name=\"recorder\"):\n        self.name = name\n\n    def __getattr__(self, attr):\n        if attr in hooks.all_hooks and attr != \"add_log\":\n\n            def prox(*args, **kwargs):\n                lg = (self.name, attr, args, kwargs)\n                logging.info(str(lg))\n                self.call_log.append(lg)\n                logging.debug(f\"{self.name} {attr}\")\n\n            return prox\n        raise AttributeError\n\n\naddons = [Recorder()]\n", "test/mitmproxy/data/addonscripts/recorder/e.py": "import recorder\n\naddons = [recorder.Recorder(\"e\")]\n", "test/mitmproxy/net/test_tls.py": "from pathlib import Path\n\nfrom OpenSSL import crypto\nfrom OpenSSL import SSL\n\nfrom mitmproxy import certs\nfrom mitmproxy.net import tls\n\n\ndef test_make_master_secret_logger():\n    assert tls.make_master_secret_logger(None) is None\n    assert isinstance(tls.make_master_secret_logger(\"filepath\"), tls.MasterSecretLogger)\n\n\ndef test_sslkeylogfile(tdata, monkeypatch):\n    keylog = []\n    monkeypatch.setattr(\n        tls, \"log_master_secret\", lambda conn, secrets: keylog.append(secrets)\n    )\n\n    store = certs.CertStore.from_files(\n        Path(tdata.path(\"mitmproxy/net/data/verificationcerts/trusted-root.pem\")),\n        Path(tdata.path(\"mitmproxy/net/data/dhparam.pem\")),\n    )\n    entry = store.get_cert(\"example.com\", [], None)\n\n    cctx = tls.create_proxy_server_context(\n        method=tls.Method.TLS_CLIENT_METHOD,\n        min_version=tls.DEFAULT_MIN_VERSION,\n        max_version=tls.DEFAULT_MAX_VERSION,\n        cipher_list=None,\n        ecdh_curve=None,\n        verify=tls.Verify.VERIFY_NONE,\n        ca_path=None,\n        ca_pemfile=None,\n        client_cert=None,\n        legacy_server_connect=False,\n    )\n    sctx = tls.create_client_proxy_context(\n        method=tls.Method.TLS_SERVER_METHOD,\n        min_version=tls.DEFAULT_MIN_VERSION,\n        max_version=tls.DEFAULT_MAX_VERSION,\n        cipher_list=None,\n        ecdh_curve=None,\n        chain_file=entry.chain_file,\n        alpn_select_callback=None,\n        request_client_cert=False,\n        extra_chain_certs=(),\n        dhparams=store.dhparams,\n    )\n\n    server = SSL.Connection(sctx)\n    server.set_accept_state()\n\n    server.use_certificate(entry.cert.to_pyopenssl())\n    server.use_privatekey(crypto.PKey.from_cryptography_key(entry.privatekey))\n\n    client = SSL.Connection(cctx)\n    client.set_connect_state()\n\n    read, write = client, server\n    while True:\n        try:\n            read.do_handshake()\n        except SSL.WantReadError:\n            write.bio_write(read.bio_read(2**16))\n        else:\n            break\n        read, write = write, read\n\n    assert keylog\n    assert keylog[0].startswith(b\"SERVER_HANDSHAKE_TRAFFIC_SECRET\")\n\n\ndef test_is_record_magic():\n    assert not tls.starts_like_tls_record(b\"POST /\")\n    assert not tls.starts_like_tls_record(b\"\\x16\\x03\\x04\")\n    assert not tls.starts_like_tls_record(b\"\")\n    assert not tls.starts_like_tls_record(b\"\\x16\")\n    assert not tls.starts_like_tls_record(b\"\\x16\\x03\")\n    assert tls.starts_like_tls_record(b\"\\x16\\x03\\x00\")\n    assert tls.starts_like_tls_record(b\"\\x16\\x03\\x01\")\n    assert tls.starts_like_tls_record(b\"\\x16\\x03\\x02\")\n    assert tls.starts_like_tls_record(b\"\\x16\\x03\\x03\")\n    assert not tls.starts_like_tls_record(bytes.fromhex(\"16fefe\"))\n\n\ndef test_is_dtls_record_magic():\n    assert not tls.starts_like_dtls_record(bytes.fromhex(\"\"))\n    assert not tls.starts_like_dtls_record(bytes.fromhex(\"16\"))\n    assert not tls.starts_like_dtls_record(bytes.fromhex(\"16fe\"))\n    assert tls.starts_like_dtls_record(bytes.fromhex(\"16fefd\"))\n    assert tls.starts_like_dtls_record(bytes.fromhex(\"16fefe\"))\n    assert not tls.starts_like_dtls_record(bytes.fromhex(\"160300\"))\n    assert not tls.starts_like_dtls_record(bytes.fromhex(\"160304\"))\n    assert not tls.starts_like_dtls_record(bytes.fromhex(\"150301\"))\n", "test/mitmproxy/net/test_encoding.py": "from unittest import mock\n\nimport pytest\n\nfrom mitmproxy.net import encoding\n\n\n@pytest.mark.parametrize(\n    \"encoder\",\n    [\n        \"identity\",\n        \"none\",\n    ],\n)\ndef test_identity(encoder):\n    assert b\"string\" == encoding.decode(b\"string\", encoder)\n    assert b\"string\" == encoding.encode(b\"string\", encoder)\n    with pytest.raises(ValueError):\n        encoding.encode(b\"string\", \"nonexistent encoding\")\n\n\n@pytest.mark.parametrize(\n    \"encoder\",\n    [\n        \"gzip\",\n        \"GZIP\",\n        \"br\",\n        \"deflate\",\n        \"zstd\",\n    ],\n)\ndef test_encoders(encoder):\n    \"\"\"\n    This test is for testing byte->byte encoding/decoding\n    \"\"\"\n    assert encoding.decode(None, encoder) is None\n    assert encoding.encode(None, encoder) is None\n\n    assert b\"\" == encoding.decode(b\"\", encoder)\n\n    assert b\"string\" == encoding.decode(encoding.encode(b\"string\", encoder), encoder)\n\n    with pytest.raises(TypeError):\n        encoding.encode(\"string\", encoder)\n\n    with pytest.raises(TypeError):\n        encoding.decode(\"string\", encoder)\n    with pytest.raises(ValueError):\n        encoding.decode(b\"foobar\", encoder)\n\n\n@pytest.mark.parametrize(\"encoder\", [\"utf8\", \"latin-1\"])\ndef test_encoders_strings(encoder):\n    \"\"\"\n    This test is for testing byte->str decoding\n    and str->byte encoding\n    \"\"\"\n    assert \"\" == encoding.decode(b\"\", encoder)\n\n    assert \"string\" == encoding.decode(encoding.encode(\"string\", encoder), encoder)\n\n    with pytest.raises(TypeError):\n        encoding.encode(b\"string\", encoder)\n\n    with pytest.raises(TypeError):\n        encoding.decode(\"foobar\", encoder)\n\n\ndef test_cache():\n    decode_gzip = mock.MagicMock()\n    decode_gzip.return_value = b\"decoded\"\n    encode_gzip = mock.MagicMock()\n    encode_gzip.return_value = b\"encoded\"\n\n    with mock.patch.dict(encoding.custom_decode, gzip=decode_gzip):\n        with mock.patch.dict(encoding.custom_encode, gzip=encode_gzip):\n            assert encoding.decode(b\"encoded\", \"gzip\") == b\"decoded\"\n            assert decode_gzip.call_count == 1\n\n            # should be cached\n            assert encoding.decode(b\"encoded\", \"gzip\") == b\"decoded\"\n            assert decode_gzip.call_count == 1\n\n            # the other way around as well\n            assert encoding.encode(b\"decoded\", \"gzip\") == b\"encoded\"\n            assert encode_gzip.call_count == 0\n\n            # different encoding\n            decode_gzip.return_value = b\"bar\"\n            assert encoding.encode(b\"decoded\", \"deflate\") != b\"decoded\"\n            assert encode_gzip.call_count == 0\n\n            # This is not in the cache anymore\n            assert encoding.encode(b\"decoded\", \"gzip\") == b\"encoded\"\n            assert encode_gzip.call_count == 1\n\n\ndef test_zstd():\n    FRAME_SIZE = 1024\n\n    # Create payload of 1024b\n    test_content = \"a\" * FRAME_SIZE\n\n    # Compress it, will result a single frame\n    single_frame = encoding.encode_zstd(test_content.encode())\n\n    # Concat compressed frame, it'll result two frames, total size of 2048b payload\n    two_frames = single_frame + single_frame\n\n    # Uncompressed single frame should have the size of FRAME_SIZE\n    assert len(encoding.decode_zstd(single_frame)) == FRAME_SIZE\n\n    # Uncompressed two frames should have the size of FRAME_SIZE * 2\n    assert len(encoding.decode_zstd(two_frames)) == FRAME_SIZE * 2\n", "test/mitmproxy/net/test_check.py": "from mitmproxy.net import check\n\n\ndef test_is_valid_host():\n    assert not check.is_valid_host(b\"\")\n    assert not check.is_valid_host(b\"xn--ke.ws\")\n    assert check.is_valid_host(b\"one.two\")\n    assert not check.is_valid_host(b\"one\" * 255)\n    assert check.is_valid_host(b\"one.two.\")\n    # Allow underscore\n    assert check.is_valid_host(b\"one_two\")\n    assert check.is_valid_host(b\"::1\")\n\n    # IP Address Validations\n    assert check.is_valid_host(b\"127.0.0.1\")\n    assert check.is_valid_host(b\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    assert check.is_valid_host(b\"2001:db8:85a3:0:0:8a2e:370:7334\")\n    assert check.is_valid_host(b\"2001:db8:85a3::8a2e:370:7334\")\n    assert not check.is_valid_host(b\"2001:db8::85a3::7334\")\n    assert check.is_valid_host(b\"2001-db8-85a3-8d3-1319-8a2e-370-7348.ipv6-literal.net\")\n\n    # TLD must be between 2 and 63 chars\n    assert check.is_valid_host(b\"example.tl\")\n    assert check.is_valid_host(b\"example.tld\")\n    assert check.is_valid_host(b\"example.\" + b\"x\" * 63)\n    assert not check.is_valid_host(b\"example.\" + b\"x\" * 64)\n\n    # misc characters test\n    assert not check.is_valid_host(b\"ex@mple\")\n    assert not check.is_valid_host(b\"ex@mple.com\")\n    assert not check.is_valid_host(b\"example..com\")\n    assert not check.is_valid_host(b\".example.com\")\n    assert not check.is_valid_host(b\"@.example.com\")\n    assert not check.is_valid_host(b\"!.example.com\")\n\n    # Every label must be between 1 and 63 chars\n    assert not check.is_valid_host(b\".tld\")\n    assert check.is_valid_host(b\"x\" * 1 + b\".tld\")\n    assert check.is_valid_host(b\"x\" * 30 + b\".tld\")\n    assert not check.is_valid_host(b\"x\" * 64 + b\".tld\")\n    assert check.is_valid_host(b\"x\" * 1 + b\".example.tld\")\n    assert check.is_valid_host(b\"x\" * 30 + b\".example.tld\")\n    assert not check.is_valid_host(b\"x\" * 64 + b\".example.tld\")\n\n    # Misc Underscore Test Cases\n    assert check.is_valid_host(b\"_example\")\n    assert check.is_valid_host(b\"_example_\")\n    assert check.is_valid_host(b\"example_\")\n    assert check.is_valid_host(b\"_a.example.tld\")\n    assert check.is_valid_host(b\"a_.example.tld\")\n    assert check.is_valid_host(b\"_a_.example.tld\")\n\n    # Misc Dash/Hyphen/Minus Test Cases\n    assert check.is_valid_host(b\"-example\")\n    assert check.is_valid_host(b\"-example_\")\n    assert check.is_valid_host(b\"example-\")\n    assert check.is_valid_host(b\"-a.example.tld\")\n    assert check.is_valid_host(b\"a-.example.tld\")\n    assert check.is_valid_host(b\"-a-.example.tld\")\n\n    # Misc Combo Test Cases\n    assert check.is_valid_host(b\"api-.example.com\")\n    assert check.is_valid_host(b\"__a.example-site.com\")\n    assert check.is_valid_host(b\"_-a.example-site.com\")\n    assert check.is_valid_host(b\"_a_.example-site.com\")\n    assert check.is_valid_host(b\"-a-.example-site.com\")\n    assert check.is_valid_host(b\"api-.a.example.com\")\n    assert check.is_valid_host(b\"api-._a.example.com\")\n    assert check.is_valid_host(b\"api-.a_.example.com\")\n    assert check.is_valid_host(b\"api-.ab.example.com\")\n\n    # Test str\n    assert check.is_valid_host(\"example.tld\")\n    assert not check.is_valid_host(\"foo..bar\")  # cannot be idna-encoded.\n", "test/mitmproxy/net/test_server_spec.py": "import pytest\n\nfrom mitmproxy.net import server_spec\n\n\n@pytest.mark.parametrize(\n    \"spec,default_scheme,out\",\n    [\n        (\"example.com\", \"https\", (\"https\", (\"example.com\", 443))),\n        (\"http://example.com\", \"https\", (\"http\", (\"example.com\", 80))),\n        (\"smtp.example.com:25\", \"tcp\", (\"tcp\", (\"smtp.example.com\", 25))),\n        (\"http://127.0.0.1\", \"https\", (\"http\", (\"127.0.0.1\", 80))),\n        (\"http://[::1]\", \"https\", (\"http\", (\"::1\", 80))),\n        (\"http://[::1]/\", \"https\", (\"http\", (\"::1\", 80))),\n        (\"https://[::1]/\", \"https\", (\"https\", (\"::1\", 443))),\n        (\"http://[::1]:8080\", \"https\", (\"http\", (\"::1\", 8080))),\n    ],\n)\ndef test_parse(spec, default_scheme, out):\n    assert server_spec.parse(spec, default_scheme) == out\n\n\ndef test_parse_err():\n    with pytest.raises(ValueError, match=\"Invalid server specification\"):\n        server_spec.parse(\":\", \"https\")\n\n    with pytest.raises(ValueError, match=\"Invalid server scheme\"):\n        server_spec.parse(\"ftp://example.com\", \"https\")\n\n    with pytest.raises(ValueError, match=\"Invalid hostname\"):\n        server_spec.parse(\"$$$\", \"https\")\n\n    with pytest.raises(ValueError, match=\"Invalid port\"):\n        server_spec.parse(\"example.com:999999\", \"https\")\n\n    with pytest.raises(ValueError, match=\"Port specification missing\"):\n        server_spec.parse(\"example.com\", \"tcp\")\n", "test/mitmproxy/net/test_local_ip.py": "from mitmproxy.net import local_ip\n\n\ndef test_get_local_ip():\n    # should never error, but may return None depending on the host OS configuration.\n    local_ip.get_local_ip()\n    local_ip.get_local_ip(\"0.0.0.0\")\n    local_ip.get_local_ip(\"127.0.0.1\")\n    local_ip.get_local_ip(\"invalid!\")\n\n\ndef test_get_local_ip6():\n    # should never error, but may return None depending on the host OS configuration.\n    local_ip.get_local_ip6()\n    local_ip.get_local_ip6(\"::\")\n    local_ip.get_local_ip6(\"::1\")\n    local_ip.get_local_ip(\"invalid!\")\n", "test/mitmproxy/net/__init__.py": "", "test/mitmproxy/net/dns/test_https_records.py": "import re\nimport struct\n\nimport pytest\nfrom hypothesis import given\nfrom hypothesis import strategies as st\n\nfrom mitmproxy.net.dns import https_records\n\n\nclass TestHTTPSRecords:\n    def test_simple(self):\n        assert https_records.SVCParamKeys.ALPN.value == 1\n        assert https_records.SVCParamKeys(1).name == \"ALPN\"\n\n    def test_httpsrecord(self):\n        with pytest.raises(\n            TypeError,\n            match=re.escape(\n                \"HTTPSRecord.__init__() missing 3 required positional arguments: 'priority', 'target_name', and 'params'\"\n            ),\n        ):\n            https_records.HTTPSRecord()\n\n    def test_unpack(self):\n        params = {\n            0: b\"\\x00\\x04\\x00\\x06\",\n            1: b\"\\x02h2\\x02h3\",\n            2: b\"\",\n            3: b\"\\x01\\xbb\",\n            4: b\"\\xb9\\xc7l\\x99\\xb9\\xc7m\\x99\\xb9\\xc7n\\x99\\xb9\\xc7o\\x99\",\n            5: b\"testbytes\",\n            6: b\"&\\x06P\\xc0\\x80\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S&\\x06P\\xc0\\x80\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S&\\x06P\\xc0\\x80\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S&\\x06P\\xc0\\x80\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S\",\n        }\n        record = https_records.HTTPSRecord(1, \"example.com\", params)\n        assert https_records.unpack(https_records.pack(record)) == record\n\n        with pytest.raises(\n            struct.error, match=re.escape(\"unpack requires a buffer of 2 bytes\")\n        ):\n            https_records.unpack(b\"\")\n\n        with pytest.raises(\n            struct.error,\n            match=re.escape(\"unpack encountered an illegal characters at offset 3\"),\n        ):\n            https_records.unpack(\n                b\"\\x00\\x01\\x07exampl\\x87\\x03com\\x00\\x00\\x01\\x00\\x06\\x02h2\\x02h3\"\n            )\n\n        with pytest.raises(\n            struct.error, match=re.escape(\"unpack requires a buffer of 25 bytes\")\n        ):\n            https_records.unpack(\n                b\"\\x00\\x01\\x07example\\x03com\\x00\\x00\\x01\\x00\\x06\\x02h2\"\n            )\n\n        with pytest.raises(\n            struct.error, match=re.escape(\"unpack requires a label buffer of 7 bytes\")\n        ):\n            https_records.unpack(b\"\\x00\\x01\\x07exa\")\n\n    def test_pack(self):\n        params = {\n            0: b\"\\x00\\x04\\x00\\x06\",\n            1: b\"\\x02h2\\x02h3\",\n            2: b\"\",\n            3: b\"\\x01\\xbb\",\n            4: b\"\\xb9\\xc7l\\x99\\xb9\\xc7m\\x99\\xb9\\xc7n\\x99\\xb9\\xc7o\\x99\",\n            5: b\"testbytes\",\n            6: b\"&\\x06P\\xc0\\x80\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S&\\x06P\\xc0\\x80\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S&\\x06P\\xc0\\x80\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S&\\x06P\\xc0\\x80\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S\",\n        }\n        record = https_records.HTTPSRecord(1, \"example.com\", params)\n        assert (\n            https_records.pack(record)\n            == b\"\\x00\\x01\\x07example\\x03com\\x00\\x00\\x00\\x00\\x04\\x00\\x04\\x00\\x06\\x00\\x01\\x00\\x06\\x02h2\\x02h3\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x02\\x01\\xbb\\x00\\x04\\x00\\x10\\xb9\\xc7l\\x99\\xb9\\xc7m\\x99\\xb9\\xc7n\\x99\\xb9\\xc7o\\x99\\x00\\x05\\x00\\ttestbytes\\x00\\x06\\x00@&\\x06P\\xc0\\x80\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S&\\x06P\\xc0\\x80\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S&\\x06P\\xc0\\x80\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S&\\x06P\\xc0\\x80\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01S\"\n        )\n\n        record = https_records.HTTPSRecord(1, \"\", {})\n        assert https_records.pack(record) == b\"\\x00\\x01\\x00\"\n\n    @given(st.binary())\n    def test_fuzz_unpack(self, data: bytes):\n        try:\n            https_records.unpack(data)\n        except struct.error:\n            pass\n\n    def test_str(self):\n        params = {\n            0: b\"\\x00\",\n            1: b\"\\x01\",\n            2: b\"\",\n            3: b\"\\x02\",\n            4: b\"\\x03\",\n            5: b\"\\x04\",\n            6: b\"\\x05\",\n        }\n        record = https_records.HTTPSRecord(1, \"example.com\", params)\n        assert (\n            str(record)\n            == \"priority: 1 target_name: 'example.com' {'mandatory': b'\\\\x00', 'alpn': b'\\\\x01', 'no_default_alpn': b'', 'port': b'\\\\x02', 'ipv4hint': b'\\\\x03', 'ech': b'\\\\x04', 'ipv6hint': b'\\\\x05'}\"\n        )\n\n        params = {111: b\"\\x00\"}\n        record = https_records.HTTPSRecord(1, \"example.com\", params)\n        assert (\n            str(record) == \"priority: 1 target_name: 'example.com' {'key111': b'\\\\x00'}\"\n        )\n", "test/mitmproxy/net/dns/test_domain_names.py": "import re\nimport struct\n\nimport pytest\n\nfrom mitmproxy.net.dns import domain_names\n\n\ndef test_unpack_from_with_compression():\n    assert domain_names.unpack_from_with_compression(\n        b\"\\xff\\x03www\\x07example\\x03org\\x00\", 1, domain_names.cache()\n    ) == (\n        \"www.example.org\",\n        17,\n    )\n    with pytest.raises(\n        struct.error, match=re.escape(\"unpack encountered domain name loop\")\n    ):\n        domain_names.unpack_from_with_compression(\n            b\"\\x03www\\xc0\\x00\", 0, domain_names.cache()\n        )\n    assert domain_names.unpack_from_with_compression(\n        b\"\\xff\\xff\\xff\\x07example\\x03org\\x00\\xff\\xff\\xff\\x03www\\xc0\\x03\",\n        19,\n        domain_names.cache(),\n    ) == (\"www.example.org\", 6)\n\n\ndef test_unpack():\n    assert domain_names.unpack(b\"\\x03www\\x07example\\x03org\\x00\") == \"www.example.org\"\n    with pytest.raises(\n        struct.error, match=re.escape(\"unpack requires a buffer of 17 bytes\")\n    ):\n        domain_names.unpack(b\"\\x03www\\x07example\\x03org\\x00\\xff\")\n    with pytest.raises(\n        struct.error,\n        match=re.escape(\"unpack encountered a pointer which is not supported in RDATA\"),\n    ):\n        domain_names.unpack(b\"\\x03www\\x07example\\x03org\\xc0\\x00\")\n    with pytest.raises(\n        struct.error, match=re.escape(\"unpack requires a label buffer of 10 bytes\")\n    ):\n        domain_names.unpack(b\"\\x0a\")\n    with pytest.raises(\n        struct.error, match=re.escape(\"unpack encountered a label of length 64\")\n    ):\n        domain_names.unpack(b\"\\x40\" + (b\"a\" * 64) + b\"\\x00\")\n    with pytest.raises(\n        struct.error,\n        match=re.escape(\"unpack encountered an illegal characters at offset 1\"),\n    ):\n        domain_names.unpack(b\"\\x03\\xff\\xff\\xff\\00\")\n\n\ndef test_pack():\n    assert domain_names.pack(\"\") == b\"\\x00\"\n    with pytest.raises(\n        ValueError, match=re.escape(\"domain name 'hello..world' contains empty labels\")\n    ):\n        domain_names.pack(\"hello..world\")\n    label = \"a\" * 64\n    name = f\"www.{label}.com\"\n    with pytest.raises(\n        ValueError,\n        match=\"label too long\",\n    ):\n        domain_names.pack(name)\n    assert domain_names.pack(\"www.example.org\") == b\"\\x03www\\x07example\\x03org\\x00\"\n", "test/mitmproxy/net/dns/test_response_codes.py": "from mitmproxy.net.dns import response_codes\n\n\ndef test_simple():\n    assert response_codes.NOERROR == 0\n    assert response_codes.to_str(response_codes.NOERROR) == \"NOERROR\"\n    assert response_codes.to_str(100) == \"RCODE(100)\"\n    assert response_codes.http_equiv_status_code(response_codes.NOERROR) == 200\n", "test/mitmproxy/net/dns/test_op_codes.py": "from mitmproxy.net.dns import op_codes\n\n\ndef test_simple():\n    assert op_codes.QUERY == 0\n    assert op_codes.to_str(op_codes.QUERY) == \"QUERY\"\n    assert op_codes.to_str(100) == \"OPCODE(100)\"\n", "test/mitmproxy/net/dns/__init__.py": "", "test/mitmproxy/net/dns/test_types.py": "from mitmproxy.net.dns import types\n\n\ndef test_simple():\n    assert types.A == 1\n    assert types.to_str(types.A) == \"A\"\n    assert types.to_str(0) == \"TYPE(0)\"\n", "test/mitmproxy/net/dns/test_classes.py": "from mitmproxy.net.dns import classes\n\n\ndef test_simple():\n    assert classes.IN == 1\n    assert classes.to_str(classes.IN) == \"IN\"\n    assert classes.to_str(0) == \"CLASS(0)\"\n", "test/mitmproxy/net/data/verificationcerts/generate.py": "\"\"\"\nGenerate SSL test certificates.\n\"\"\"\n\nimport os\nimport shlex\nimport shutil\nimport subprocess\nimport textwrap\n\nROOT_CA = \"trusted-root\"\nSUBJECT = \"example.mitmproxy.org\"\n\n\ndef do(args):\n    print(\"> %s\" % args)\n    args = shlex.split(args)\n    output = subprocess.check_output(args)\n    return output\n\n\ndef genrsa(cert: str):\n    do(f\"openssl genrsa -out {cert}.key 2048\")\n\n\ndef sign(cert: str, subject: str, ip: bool):\n    with open(f\"openssl-{cert}.conf\", \"w\") as f:\n        f.write(\n            textwrap.dedent(\n                f\"\"\"\n        authorityKeyIdentifier=keyid,issuer\n        basicConstraints=CA:FALSE\n        keyUsage = digitalSignature, keyEncipherment\n        subjectAltName = {\"IP\" if ip else \"DNS\" }:{subject}\n        \"\"\"\n            )\n        )\n    do(\n        f\"openssl x509 -req -in {cert}.csr \"\n        f\"-CA {ROOT_CA}.crt \"\n        f\"-CAkey {ROOT_CA}.key \"\n        f\"-CAcreateserial \"\n        f\"-days 7300 \"\n        f\"-sha256 \"\n        f'-extfile \"openssl-{cert}.conf\" '\n        f\"-out {cert}.crt\"\n    )\n    os.remove(f\"openssl-{cert}.conf\")\n\n\ndef mkcert(cert, subject, ip: bool):\n    genrsa(cert)\n    do(\n        f\"openssl req -new -nodes -batch \"\n        f\"-key {cert}.key \"\n        f\"-subj /CN={subject}/O=mitmproxy \"\n        f'-addext \"subjectAltName = {\"IP\" if ip else \"DNS\" }:{subject}\" '\n        f\"-out {cert}.csr\"\n    )\n    sign(cert, subject, ip)\n    os.remove(f\"{cert}.csr\")\n\n\n# create trusted root CA\ngenrsa(\"trusted-root\")\ndo(\n    \"openssl req -x509 -new -nodes -batch \"\n    \"-key trusted-root.key \"\n    \"-days 7300 \"\n    \"-out trusted-root.crt\"\n)\nh = do(\"openssl x509 -hash -noout -in trusted-root.crt\").decode(\"ascii\").strip()\nshutil.copyfile(\"trusted-root.crt\", f\"{h}.0\")\n\n# create trusted leaf cert.\nmkcert(\"trusted-leaf\", SUBJECT, False)\nmkcert(\"trusted-leaf-ip\", \"192.0.2.42\", True)\n\n# create self-signed cert\ngenrsa(\"self-signed\")\ndo(\n    \"openssl req -x509 -new -nodes -batch \"\n    \"-key self-signed.key \"\n    f'-addext \"subjectAltName = DNS:{SUBJECT}\" '\n    \"-days 7300 \"\n    \"-out self-signed.crt\"\n)\n\nfor x in [\"self-signed\", \"trusted-leaf\", \"trusted-leaf-ip\", \"trusted-root\"]:\n    with open(f\"{x}.crt\") as crt, open(f\"{x}.key\") as key, open(f\"{x}.pem\", \"w\") as pem:\n        pem.write(crt.read())\n        pem.write(key.read())\n\nshutil.copyfile(\"trusted-leaf.pem\", \"example.mitmproxy.org.pem\")\n", "test/mitmproxy/net/http/test_headers.py": "import collections\n\nimport pytest\n\nfrom mitmproxy.net.http.headers import assemble_content_type\nfrom mitmproxy.net.http.headers import infer_content_encoding\nfrom mitmproxy.net.http.headers import parse_content_type\n\n\ndef test_parse_content_type():\n    p = parse_content_type\n    assert p(\"text/html\") == (\"text\", \"html\", {})\n    assert p(\"text\") is None\n\n    v = p(\"text/html; charset=UTF-8\")\n    assert v == (\"text\", \"html\", {\"charset\": \"UTF-8\"})\n\n\ndef test_assemble_content_type():\n    p = assemble_content_type\n    assert p(\"text\", \"html\", {}) == \"text/html\"\n    assert p(\"text\", \"html\", {\"charset\": \"utf8\"}) == \"text/html; charset=utf8\"\n    assert (\n        p(\n            \"text\",\n            \"html\",\n            collections.OrderedDict([(\"charset\", \"utf8\"), (\"foo\", \"bar\")]),\n        )\n        == \"text/html; charset=utf8; foo=bar\"\n    )\n\n\n@pytest.mark.parametrize(\n    \"content_type,content,expected\",\n    [\n        (\"\", b\"\", \"latin-1\"),\n        (\"\", b\"foo\", \"latin-1\"),\n        (\"\", b\"\\xfc\", \"latin-1\"),\n        (\"\", b\"\\xf0\\xe2\", \"latin-1\"),\n        (\"text/html; charset=latin1\", b\"\\xc3\\xbc\", \"latin1\"),\n        (\"text/html; charset=utf8\", b\"\\xc3\\xbc\", \"utf8\"),\n        # json\n        (\"application/json\", b'\"\\xc3\\xbc\"', \"utf8\"),\n        # meta charset\n        (\n            \"text/html\",\n            b'<meta http-equiv=\"content-type\" '\n            b'content=\"text/html;charset=gb2312\">\\xe6\\x98\\x8e\\xe4\\xbc\\xaf',\n            \"gb18030\",\n        ),\n        # css charset\n        (\n            \"text/css\",\n            b'@charset \"gb2312\";' b'#foo::before {content: \"\\xe6\\x98\\x8e\\xe4\\xbc\\xaf\"}',\n            \"gb18030\",\n        ),\n    ],\n)\ndef test_infer_content_encoding(content_type, content, expected):\n    # Additional test coverage in `test_http::TestMessageText`\n    assert infer_content_encoding(content_type, content) == expected\n", "test/mitmproxy/net/http/test_cookies.py": "import time\nfrom unittest import mock\n\nimport pytest\n\nfrom mitmproxy.net.http import cookies\n\ncookie_pairs = [\n    [\"=uno\", [[\"\", \"uno\"]]],\n    [\"\", []],\n    [\"one=uno\", [[\"one\", \"uno\"]]],\n    [\"one\", [[\"one\", \"\"]]],\n    [\"one=uno; two=due\", [[\"one\", \"uno\"], [\"two\", \"due\"]]],\n    ['one=\"uno\"; two=\"\\\\due\"', [[\"one\", \"uno\"], [\"two\", \"due\"]]],\n    ['one=\"un\\\\\"o\"', [[\"one\", 'un\"o']]],\n    ['one=\"uno,due\"', [[\"one\", \"uno,due\"]]],\n    [\"one=uno; two; three=tre\", [[\"one\", \"uno\"], [\"two\", \"\"], [\"three\", \"tre\"]]],\n    [\n        \"_lvs2=zHai1+Hq+Tc2vmc2r4GAbdOI5Jopg3EwsdUT9g=; \" \"_rcc2=53VdltWl+Ov6ordflA==;\",\n        [\n            [\"_lvs2\", \"zHai1+Hq+Tc2vmc2r4GAbdOI5Jopg3EwsdUT9g=\"],\n            [\"_rcc2\", \"53VdltWl+Ov6ordflA==\"],\n        ],\n    ],\n]\n\n\ndef test_read_key():\n    tokens = [\n        [(\"foo\", 0), (\"foo\", 3)],\n        [(\"foo\", 1), (\"oo\", 3)],\n        [(\" foo\", 0), (\" foo\", 4)],\n        [(\" foo\", 1), (\"foo\", 4)],\n        [(\" foo;\", 1), (\"foo\", 4)],\n        [(\" foo=\", 1), (\"foo\", 4)],\n        [(\" foo=bar\", 1), (\"foo\", 4)],\n    ]\n    for q, a in tokens:\n        assert cookies._read_key(*q) == a\n\n\ndef test_read_quoted_string():\n    tokens = [\n        [('\"foo\" x', 0), (\"foo\", 5)],\n        [('\"f\\\\oo\" x', 0), (\"foo\", 6)],\n        [(r'\"f\\\\o\" x', 0), (r\"f\\o\", 6)],\n        [(r'\"f\\\\\" x', 0), (r\"f\" + \"\\\\\", 5)],\n        [('\"fo\\\\\"\" x', 0), ('fo\"', 6)],\n        [('\"foo\" x', 7), (\"\", 8)],\n    ]\n    for q, a in tokens:\n        assert cookies._read_quoted_string(*q) == a\n\n\ndef test_read_cookie_pairs():\n    vals = [\n        [\"=uno\", [[\"\", \"uno\"]]],\n        [\"one\", [[\"one\", \"\"]]],\n        [\"one=two\", [[\"one\", \"two\"]]],\n        [\"one=\", [[\"one\", \"\"]]],\n        ['one=\"two\"', [[\"one\", \"two\"]]],\n        ['one=\"two\"; three=four', [[\"one\", \"two\"], [\"three\", \"four\"]]],\n        [\n            'one=\"two\"; three=four; five',\n            [[\"one\", \"two\"], [\"three\", \"four\"], [\"five\", \"\"]],\n        ],\n        ['one=\"\\\\\"two\"; three=four', [[\"one\", '\"two'], [\"three\", \"four\"]]],\n    ]\n    for s, lst in vals:\n        ret, off = cookies._read_cookie_pairs(s)\n        assert ret == lst\n\n\ndef test_pairs_roundtrips():\n    for s, expected in cookie_pairs:\n        ret, off = cookies._read_cookie_pairs(s)\n        assert ret == expected\n\n        s2 = cookies._format_pairs(expected)\n        ret, off = cookies._read_cookie_pairs(s2)\n        assert ret == expected\n\n\ndef test_cookie_roundtrips():\n    for s, expected in cookie_pairs:\n        ret = cookies.parse_cookie_header(s)\n        assert ret == expected\n\n        s2 = cookies.format_cookie_header(expected)\n        ret = cookies.parse_cookie_header(s2)\n        assert ret == expected\n\n\ndef test_parse_set_cookie_pairs():\n    pairs = [\n        [\"=\", [[(\"\", \"\")]]],\n        [\"=;foo=bar\", [[(\"\", \"\"), (\"foo\", \"bar\")]]],\n        [\"=;=;foo=bar\", [[(\"\", \"\"), (\"\", \"\"), (\"foo\", \"bar\")]]],\n        [\"=uno\", [[(\"\", \"uno\")]]],\n        [\"one=uno\", [[(\"one\", \"uno\")]]],\n        [\"one=un\\x20\", [[(\"one\", \"un\\x20\")]]],\n        [\"one=uno; foo\", [[(\"one\", \"uno\"), (\"foo\", None)]]],\n        [\n            \"mun=1.390.f60; \"\n            \"expires=sun, 11-oct-2015 12:38:31 gmt; path=/; \"\n            \"domain=b.aol.com\",\n            [\n                [\n                    (\"mun\", \"1.390.f60\"),\n                    (\"expires\", \"sun, 11-oct-2015 12:38:31 gmt\"),\n                    (\"path\", \"/\"),\n                    (\"domain\", \"b.aol.com\"),\n                ]\n            ],\n        ],\n        [\n            r\"rpb=190%3d1%2616726%3d1%2634832%3d1%2634874%3d1; \"\n            \"domain=.rubiconproject.com; \"\n            \"expires=mon, 11-may-2015 21:54:57 gmt; \"\n            \"path=/\",\n            [\n                [\n                    (\"rpb\", r\"190%3d1%2616726%3d1%2634832%3d1%2634874%3d1\"),\n                    (\"domain\", \".rubiconproject.com\"),\n                    (\"expires\", \"mon, 11-may-2015 21:54:57 gmt\"),\n                    (\"path\", \"/\"),\n                ]\n            ],\n        ],\n    ]\n    for s, expected in pairs:\n        ret, off = cookies._read_set_cookie_pairs(s)\n        assert ret == expected\n\n        s2 = cookies._format_set_cookie_pairs(expected[0])\n        ret2, off = cookies._read_set_cookie_pairs(s2)\n        assert ret2 == expected\n\n\ndef test_parse_set_cookie_header():\n    def set_cookie_equal(obs, exp):\n        assert obs[0] == exp[0]\n        assert obs[1] == exp[1]\n        assert obs[2].items(multi=True) == exp[2]\n\n    vals = [\n        [\"\", []],\n        [\";\", []],\n        [\"=uno\", [(\"\", \"uno\", ())]],\n        [\"one=uno\", [(\"one\", \"uno\", ())]],\n        [\"one=uno; foo=bar\", [(\"one\", \"uno\", ((\"foo\", \"bar\"),))]],\n        [\n            \"one=uno; foo=bar; foo=baz\",\n            [(\"one\", \"uno\", ((\"foo\", \"bar\"), (\"foo\", \"baz\")))],\n        ],\n        # Comma Separated Variant of Set-Cookie Headers\n        [\n            \"foo=bar, doo=dar\",\n            [\n                (\"foo\", \"bar\", ()),\n                (\"doo\", \"dar\", ()),\n            ],\n        ],\n        [\n            \"foo=bar; path=/, doo=dar; roo=rar; zoo=zar\",\n            [\n                (\"foo\", \"bar\", ((\"path\", \"/\"),)),\n                (\"doo\", \"dar\", ((\"roo\", \"rar\"), (\"zoo\", \"zar\"))),\n            ],\n        ],\n        [\n            \"foo=bar; expires=Mon, 24 Aug 2133\",\n            [\n                (\"foo\", \"bar\", ((\"expires\", \"Mon, 24 Aug 2133\"),)),\n            ],\n        ],\n        [\n            \"foo=bar; expires=Mon, 24 Aug 2133 00:00:00 GMT, doo=dar\",\n            [\n                (\"foo\", \"bar\", ((\"expires\", \"Mon, 24 Aug 2133 00:00:00 GMT\"),)),\n                (\"doo\", \"dar\", ()),\n            ],\n        ],\n    ]\n    for s, expected in vals:\n        ret = cookies.parse_set_cookie_header(s)\n        if expected:\n            for i in range(len(expected)):\n                set_cookie_equal(ret[i], expected[i])\n\n            s2 = cookies.format_set_cookie_header(ret)\n            ret2 = cookies.parse_set_cookie_header(s2)\n            for i in range(len(expected)):\n                set_cookie_equal(ret2[i], expected[i])\n        else:\n            assert not ret\n\n\ndef test_refresh_cookie():\n    # Invalid expires format, sent to us by Reddit.\n    c = \"rfoo=bar; Domain=reddit.com; expires=Thu, 31 Dec 2133 23:59:59 GMT; Path=/\"\n    assert cookies.refresh_set_cookie_header(c, 60)\n\n    c = \"MOO=BAR; Expires=Tue, 08-Mar-2011 00:20:38 GMT; Path=foo.com; Secure\"\n    assert \"00:21:38\" in cookies.refresh_set_cookie_header(c, 60)\n\n    c = \"rfoo=bar; Domain=reddit.com; expires=Thu, 31 Dec 2133; Path=/\"\n    assert \"expires\" not in cookies.refresh_set_cookie_header(c, 60)\n\n    c = \"foo,bar\"\n    with pytest.raises(ValueError):\n        cookies.refresh_set_cookie_header(c, 60)\n\n    # https://github.com/mitmproxy/mitmproxy/issues/773\n    c = \">=A\"\n    assert cookies.refresh_set_cookie_header(c, 60)\n\n    # https://github.com/mitmproxy/mitmproxy/issues/1118\n    c = \"foo:bar=bla\"\n    assert cookies.refresh_set_cookie_header(c, 0)\n    c = \"foo/bar=bla\"\n    assert cookies.refresh_set_cookie_header(c, 0)\n\n    # https://github.com/mitmproxy/mitmproxy/issues/2250\n    c = \"\"\n    assert cookies.refresh_set_cookie_header(c, 60) == \"\"\n\n\n@mock.patch(\"time.time\")\ndef test_get_expiration_ts(*args):\n    # Freeze time\n    now_ts = 17\n    time.time.return_value = now_ts\n\n    CA = cookies.CookieAttrs\n    F = cookies.get_expiration_ts\n\n    assert F(CA([(\"Expires\", \"Thu, 01-Jan-1970 00:00:00 GMT\")])) == 0\n    assert F(CA([(\"Expires\", \"Mon, 24-Aug-2133 00:00:00 GMT\")])) == 5164128000\n\n    assert F(CA([(\"Max-Age\", \"0\")])) == now_ts\n    assert F(CA([(\"Max-Age\", \"31\")])) == now_ts + 31\n\n\ndef test_is_expired():\n    CA = cookies.CookieAttrs\n\n    # A cookie can be expired\n    # by setting the expire time in the past\n    assert cookies.is_expired(CA([(\"Expires\", \"Thu, 01-Jan-1970 00:00:00 GMT\")]))\n\n    # or by setting Max-Age to 0\n    assert cookies.is_expired(CA([(\"Max-Age\", \"0\")]))\n\n    # or both\n    assert cookies.is_expired(\n        CA([(\"Expires\", \"Thu, 01-Jan-1970 00:00:00 GMT\"), (\"Max-Age\", \"0\")])\n    )\n\n    assert not cookies.is_expired(CA([(\"Expires\", \"Mon, 24-Aug-2133 00:00:00 GMT\")]))\n    assert not cookies.is_expired(CA([(\"Max-Age\", \"1\")]))\n    assert not cookies.is_expired(\n        CA([(\"Expires\", \"Wed, 15-Jul-2133 00:00:00 GMT\"), (\"Max-Age\", \"1\")])\n    )\n\n    assert not cookies.is_expired(CA([(\"Max-Age\", \"nan\")]))\n    assert not cookies.is_expired(CA([(\"Expires\", \"false\")]))\n\n\ndef test_group_cookies():\n    CA = cookies.CookieAttrs\n    groups = [\n        [\n            \"one=uno; foo=bar; foo=baz\",\n            [(\"one\", \"uno\", CA([])), (\"foo\", \"bar\", CA([])), (\"foo\", \"baz\", CA([]))],\n        ],\n        [\n            \"one=uno; Path=/; foo=bar; Max-Age=0; foo=baz; expires=24-08-1993\",\n            [\n                (\"one\", \"uno\", CA([(\"Path\", \"/\")])),\n                (\"foo\", \"bar\", CA([(\"Max-Age\", \"0\")])),\n                (\"foo\", \"baz\", CA([(\"expires\", \"24-08-1993\")])),\n            ],\n        ],\n        [\"one=uno;\", [(\"one\", \"uno\", CA([]))]],\n        [\n            \"one=uno; Path=/; Max-Age=0; Expires=24-08-1993\",\n            [\n                (\n                    \"one\",\n                    \"uno\",\n                    CA([(\"Path\", \"/\"), (\"Max-Age\", \"0\"), (\"Expires\", \"24-08-1993\")]),\n                )\n            ],\n        ],\n        [\"path=val; Path=/\", [(\"path\", \"val\", CA([(\"Path\", \"/\")]))]],\n    ]\n\n    for c, expected in groups:\n        observed = cookies.group_cookies(cookies.parse_cookie_header(c))\n        assert observed == expected\n", "test/mitmproxy/net/http/test_url.py": "from typing import AnyStr\n\nimport pytest\n\nfrom mitmproxy.net.http import url\nfrom mitmproxy.net.http.url import parse_authority\n\n\ndef test_parse():\n    with pytest.raises(ValueError):\n        url.parse(\"\")\n\n    s, h, po, pa = url.parse(b\"http://foo.com:8888/test\")\n    assert s == b\"http\"\n    assert h == b\"foo.com\"\n    assert po == 8888\n    assert pa == b\"/test\"\n\n    s, h, po, pa = url.parse(\"http://foo/bar\")\n    assert s == b\"http\"\n    assert h == b\"foo\"\n    assert po == 80\n    assert pa == b\"/bar\"\n\n    s, h, po, pa = url.parse(b\"http://user:pass@foo/bar\")\n    assert s == b\"http\"\n    assert h == b\"foo\"\n    assert po == 80\n    assert pa == b\"/bar\"\n\n    s, h, po, pa = url.parse(b\"http://foo\")\n    assert pa == b\"/\"\n\n    s, h, po, pa = url.parse(b\"https://foo\")\n    assert po == 443\n\n    with pytest.raises(ValueError):\n        url.parse(b\"https://foo:bar\")\n\n    # Invalid IDNA\n    with pytest.raises(ValueError):\n        url.parse(\"http://\\xfafoo\")\n    # Invalid PATH\n    with pytest.raises(ValueError):\n        url.parse(\"http:/\\xc6/localhost:56121\")\n    # Null byte in host\n    with pytest.raises(ValueError):\n        url.parse(\"http://foo\\0\")\n    # Invalid IPv6 URL - see http://www.ietf.org/rfc/rfc2732.txt\n    with pytest.raises(ValueError):\n        url.parse(\"http://lo[calhost\")\n\n\ndef test_ascii_check():\n    test_url = \"https://xyz.tax-edu.net?flag=selectCourse&lc_id=42825&lc_name=\u8305\u83bd\u83bd\u732b\u6c13\u732b\u6c13\".encode()\n    scheme, host, port, full_path = url.parse(test_url)\n    assert scheme == b\"https\"\n    assert host == b\"xyz.tax-edu.net\"\n    assert port == 443\n    assert (\n        full_path\n        == b\"/?flag%3DselectCourse%26lc_id%3D42825%26lc_name%3D%E8%8C%85%E8%8E%BD%E8%8E\"\n        b\"%BD%E7%8C%AB%E6%B0%93%E7%8C%AB%E6%B0%93\"\n    )\n\n\ndef test_parse_port_range():\n    # Port out of range\n    with pytest.raises(ValueError):\n        url.parse(\"http://foo:999999\")\n\n\ndef test_unparse():\n    assert url.unparse(\"http\", \"foo.com\", 99, \"\") == \"http://foo.com:99\"\n    assert url.unparse(\"http\", \"foo.com\", 80, \"/bar\") == \"http://foo.com/bar\"\n    assert url.unparse(\"https\", \"foo.com\", 80, \"\") == \"https://foo.com:80\"\n    assert url.unparse(\"https\", \"foo.com\", 443, \"\") == \"https://foo.com\"\n    assert url.unparse(\"https\", \"foo.com\", 443, \"*\") == \"https://foo.com\"\n\n\n# We ignore the byte 126: '~' because of an incompatibility in Python 3.6 and 3.7\n# In 3.6 it is escaped as %7E\n# In 3.7 it stays as ASCII character '~'\n# https://bugs.python.org/issue16285\nsurrogates = (bytes(range(0, 126)) + bytes(range(127, 256))).decode(\n    \"utf8\", \"surrogateescape\"\n)\n\nsurrogates_quoted = (\n    \"%00%01%02%03%04%05%06%07%08%09%0A%0B%0C%0D%0E%0F\"\n    \"%10%11%12%13%14%15%16%17%18%19%1A%1B%1C%1D%1E%1F\"\n    \"%20%21%22%23%24%25%26%27%28%29%2A%2B%2C-./\"\n    \"0123456789%3A%3B%3C%3D%3E%3F%40\"\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n    \"%5B%5C%5D%5E_%60\"\n    \"abcdefghijklmnopqrstuvwxyz\"\n    \"%7B%7C%7D%7F\"  # 7E or ~ is excluded!\n    \"%80%81%82%83%84%85%86%87%88%89%8A%8B%8C%8D%8E%8F\"\n    \"%90%91%92%93%94%95%96%97%98%99%9A%9B%9C%9D%9E%9F\"\n    \"%A0%A1%A2%A3%A4%A5%A6%A7%A8%A9%AA%AB%AC%AD%AE%AF\"\n    \"%B0%B1%B2%B3%B4%B5%B6%B7%B8%B9%BA%BB%BC%BD%BE%BF\"\n    \"%C0%C1%C2%C3%C4%C5%C6%C7%C8%C9%CA%CB%CC%CD%CE%CF\"\n    \"%D0%D1%D2%D3%D4%D5%D6%D7%D8%D9%DA%DB%DC%DD%DE%DF\"\n    \"%E0%E1%E2%E3%E4%E5%E6%E7%E8%E9%EA%EB%EC%ED%EE%EF\"\n    \"%F0%F1%F2%F3%F4%F5%F6%F7%F8%F9%FA%FB%FC%FD%FE%FF\"\n)\n\n\ndef test_empty_key_trailing_equal_sign():\n    \"\"\"\n    Some HTTP clients don't send trailing equal signs for parameters without assigned value, e.g. they send\n        foo=bar&baz&qux=quux\n    instead of\n        foo=bar&baz=&qux=quux\n    The respective behavior of encode() should be driven by a reference string given in similar_to parameter\n    \"\"\"\n    reference_without_equal = \"key1=val1&key2&key3=val3\"\n    reference_with_equal = \"key1=val1&key2=&key3=val3\"\n\n    post_data_empty_key_middle = [(\"one\", \"two\"), (\"emptykey\", \"\"), (\"three\", \"four\")]\n    post_data_empty_key_end = [(\"one\", \"two\"), (\"three\", \"four\"), (\"emptykey\", \"\")]\n\n    assert (\n        url.encode(post_data_empty_key_middle, similar_to=reference_with_equal)\n        == \"one=two&emptykey=&three=four\"\n    )\n    assert (\n        url.encode(post_data_empty_key_end, similar_to=reference_with_equal)\n        == \"one=two&three=four&emptykey=\"\n    )\n    assert (\n        url.encode(post_data_empty_key_middle, similar_to=reference_without_equal)\n        == \"one=two&emptykey&three=four\"\n    )\n    assert (\n        url.encode(post_data_empty_key_end, similar_to=reference_without_equal)\n        == \"one=two&three=four&emptykey\"\n    )\n\n\ndef test_encode():\n    assert url.encode([(\"foo\", \"bar\")])\n    assert url.encode([(\"foo\", surrogates)])\n    assert not url.encode([], similar_to=\"justatext\")\n\n\ndef test_decode():\n    s = \"one=two&three=four\"\n    assert len(url.decode(s)) == 2\n    assert url.decode(surrogates)\n\n\ndef test_quote():\n    assert url.quote(\"foo\") == \"foo\"\n    assert url.quote(\"foo bar\") == \"foo%20bar\"\n    assert url.quote(surrogates) == surrogates_quoted\n\n\ndef test_unquote():\n    assert url.unquote(\"foo\") == \"foo\"\n    assert url.unquote(\"foo%20bar\") == \"foo bar\"\n    assert url.unquote(surrogates_quoted) == surrogates\n\n\ndef test_hostport():\n    assert url.hostport(b\"https\", b\"foo.com\", 8080) == b\"foo.com:8080\"\n\n\ndef test_default_port():\n    assert url.default_port(\"http\") == 80\n    assert url.default_port(b\"https\") == 443\n    assert url.default_port(b\"qux\") is None\n\n\n@pytest.mark.parametrize(\n    \"authority,valid,out\",\n    [\n        [\"foo:42\", True, (\"foo\", 42)],\n        [b\"foo:42\", True, (\"foo\", 42)],\n        [\"127.0.0.1:443\", True, (\"127.0.0.1\", 443)],\n        [\"[2001:db8:42::]:443\", True, (\"2001:db8:42::\", 443)],\n        [b\"xn--aaa-pla.example:80\", True, (\"\u00e4aaa.example\", 80)],\n        [b\"xn--r8jz45g.xn--zckzah:80\", True, (\"\u4f8b\u3048.\u30c6\u30b9\u30c8\", 80)],\n        [\"foo\", True, (\"foo\", None)],\n        [\"foo..bar\", False, (\"foo..bar\", None)],\n        [\"foo:bar\", False, (\"foo:bar\", None)],\n        [b\"foo:bar\", False, (\"foo:bar\", None)],\n        [\"foo:999999999\", False, (\"foo:999999999\", None)],\n        [b\"\\xff\", False, (\"\\udcff\", None)],\n    ],\n)\ndef test_parse_authority(authority: AnyStr, valid: bool, out):\n    assert parse_authority(authority, False) == out\n\n    if valid:\n        assert parse_authority(authority, True) == out\n    else:\n        with pytest.raises(ValueError):\n            parse_authority(authority, True)\n", "test/mitmproxy/net/http/__init__.py": "", "test/mitmproxy/net/http/test_multipart.py": "import pytest\n\nfrom mitmproxy.net.http import multipart\n\n\ndef test_decode():\n    boundary = \"somefancyboundary\"\n    content = (\n        \"--{0}\\n\"\n        'Content-Disposition: form-data; name=\"field1\"\\n\\n'\n        \"value1\\n\"\n        \"--{0}\\n\"\n        'Content-Disposition: form-data; name=\"field2\"\\n\\n'\n        \"value2\\n\"\n        \"--{0}--\".format(boundary).encode()\n    )\n    form = multipart.decode_multipart(\n        f\"multipart/form-data; boundary={boundary}\", content\n    )\n\n    assert len(form) == 2\n    assert form[0] == (b\"field1\", b\"value1\")\n    assert form[1] == (b\"field2\", b\"value2\")\n\n    boundary = \"boundary\u8305\u83bd\"\n    result = multipart.decode_multipart(\n        f\"multipart/form-data; boundary={boundary}\", content\n    )\n    assert result == []\n\n    assert multipart.decode_multipart(\"\", content) == []\n\n\ndef test_encode():\n    data = [(b\"file\", b\"shell.jpg\"), (b\"file_size\", b\"1000\")]\n    content = multipart.encode_multipart(\n        \"multipart/form-data; boundary=127824672498\", data\n    )\n\n    assert b'Content-Disposition: form-data; name=\"file\"' in content\n    assert (\n        b\"Content-Type: text/plain; charset=utf-8\\r\\n\\r\\nshell.jpg\\r\\n\\r\\n--127824672498\\r\\n\"\n        in content\n    )\n    assert b\"1000\\r\\n\\r\\n--127824672498--\\r\\n\"\n    assert len(content) == 252\n\n    with pytest.raises(ValueError, match=r\"boundary found in encoded string\"):\n        multipart.encode_multipart(\n            \"multipart/form-data; boundary=127824672498\", [(b\"key\", b\"--127824672498\")]\n        )\n\n    result = multipart.encode_multipart(\n        \"multipart/form-data; boundary=boundary\u8305\u83bd\", data\n    )\n    assert result == b\"\"\n\n    assert multipart.encode_multipart(\"\", data) == b\"\"\n", "test/mitmproxy/net/http/test_status_codes.py": "from mitmproxy.net.http import status_codes\n\n\ndef test_simple():\n    assert status_codes.IM_A_TEAPOT == 418\n    assert status_codes.RESPONSES[418] == \"I'm a teapot\"\n", "test/mitmproxy/net/http/test_user_agents.py": "from mitmproxy.net.http import user_agents\n\n\ndef test_get_shortcut():\n    assert user_agents.get_by_shortcut(\"c\")[0] == \"chrome\"\n    assert not user_agents.get_by_shortcut(\"_\")\n", "test/mitmproxy/net/http/http1/test_read.py": "import pytest\n\nfrom mitmproxy.http import Headers\nfrom mitmproxy.net.http.http1.read import _read_headers\nfrom mitmproxy.net.http.http1.read import _read_request_line\nfrom mitmproxy.net.http.http1.read import _read_response_line\nfrom mitmproxy.net.http.http1.read import connection_close\nfrom mitmproxy.net.http.http1.read import expected_http_body_size\nfrom mitmproxy.net.http.http1.read import get_header_tokens\nfrom mitmproxy.net.http.http1.read import read_request_head\nfrom mitmproxy.net.http.http1.read import read_response_head\nfrom mitmproxy.net.http.http1.read import validate_headers\nfrom mitmproxy.test.tutils import treq\nfrom mitmproxy.test.tutils import tresp\n\n\ndef test_get_header_tokens():\n    headers = Headers()\n    assert get_header_tokens(headers, \"foo\") == []\n    headers[\"foo\"] = \"bar\"\n    assert get_header_tokens(headers, \"foo\") == [\"bar\"]\n    headers[\"foo\"] = \"bar, voing\"\n    assert get_header_tokens(headers, \"foo\") == [\"bar\", \"voing\"]\n    headers.set_all(\"foo\", [\"bar, voing\", \"oink\"])\n    assert get_header_tokens(headers, \"foo\") == [\"bar\", \"voing\", \"oink\"]\n\n\ndef test_connection_close():\n    headers = Headers()\n    assert connection_close(b\"HTTP/1.0\", headers)\n    assert not connection_close(b\"HTTP/1.1\", headers)\n    assert not connection_close(b\"HTTP/2.0\", headers)\n\n    headers[\"connection\"] = \"keep-alive\"\n    assert not connection_close(b\"HTTP/1.1\", headers)\n\n    headers[\"connection\"] = \"close\"\n    assert connection_close(b\"HTTP/1.1\", headers)\n\n    headers[\"connection\"] = \"foobar\"\n    assert connection_close(b\"HTTP/1.0\", headers)\n    assert not connection_close(b\"HTTP/1.1\", headers)\n\n\ndef test_read_request_head():\n    rfile = [\n        b\"GET / HTTP/1.1\\r\\n\",\n        b\"Content-Length: 4\\r\\n\",\n    ]\n    r = read_request_head(rfile)\n    assert r.method == \"GET\"\n    assert r.headers[\"Content-Length\"] == \"4\"\n    assert r.content is None\n\n\ndef test_read_response_head():\n    rfile = [\n        b\"HTTP/1.1 418 I'm a teapot\\r\\n\",\n        b\"Content-Length: 4\\r\\n\",\n    ]\n    r = read_response_head(rfile)\n    assert r.status_code == 418\n    assert r.headers[\"Content-Length\"] == \"4\"\n    assert r.content is None\n\n\ndef test_validate_headers():\n    # both content-length and chunked (possible request smuggling)\n    with pytest.raises(\n        ValueError,\n        match=\"Received both a Transfer-Encoding and a Content-Length header\",\n    ):\n        validate_headers(\n            Headers(transfer_encoding=\"chunked\", content_length=\"42\"),\n        )\n\n    with pytest.raises(ValueError, match=\"Received an invalid header name\"):\n        validate_headers(\n            Headers([(b\"content-length \", b\"42\")]),\n        )\n\n\ndef test_expected_http_body_size():\n    # Expect: 100-continue\n    assert (\n        expected_http_body_size(\n            treq(headers=Headers(expect=\"100-continue\", content_length=\"42\")),\n        )\n        == 42\n    )\n\n    # http://tools.ietf.org/html/rfc7230#section-3.3\n    assert (\n        expected_http_body_size(\n            treq(method=b\"HEAD\"), tresp(headers=Headers(content_length=\"42\"))\n        )\n        == 0\n    )\n    assert (\n        expected_http_body_size(\n            treq(method=b\"CONNECT\", headers=Headers()),\n            None,\n        )\n        == 0\n    )\n    assert expected_http_body_size(treq(method=b\"CONNECT\"), tresp()) == 0\n    for code in (100, 204, 304):\n        assert expected_http_body_size(treq(), tresp(status_code=code)) == 0\n\n    # chunked\n    assert (\n        expected_http_body_size(\n            treq(headers=Headers(transfer_encoding=\"chunked\")),\n        )\n        is None\n    )\n    assert (\n        expected_http_body_size(\n            treq(headers=Headers(transfer_encoding=\"gzip,\\tchunked\")),\n        )\n        is None\n    )\n    with pytest.raises(ValueError, match=\"Invalid transfer encoding\"):\n        expected_http_body_size(\n            treq(\n                headers=Headers(transfer_encoding=\"chun\\u212aed\")\n            ),  # \"chun\u212aed\".lower() == \"chunked\"\n        )\n    with pytest.raises(ValueError, match=\"Unknown transfer encoding\"):\n        expected_http_body_size(\n            treq(\n                headers=Headers(transfer_encoding=\"chun ked\")\n            ),  # \"chun\u212aed\".lower() == \"chunked\"\n        )\n    with pytest.raises(ValueError, match=\"Unknown transfer encoding\"):\n        expected_http_body_size(\n            treq(headers=Headers(transfer_encoding=\"qux\")),\n        )\n    # transfer-encoding: gzip\n    with pytest.raises(ValueError, match=\"Invalid request transfer encoding\"):\n        expected_http_body_size(\n            treq(headers=Headers(transfer_encoding=\"gzip\")),\n        )\n    assert (\n        expected_http_body_size(\n            treq(),\n            tresp(headers=Headers(transfer_encoding=\"gzip\")),\n        )\n        == -1\n    )\n\n    # explicit length\n    for val in (b\"foo\", b\"-7\"):\n        with pytest.raises(ValueError):\n            expected_http_body_size(treq(headers=Headers(content_length=val)))\n    assert expected_http_body_size(treq(headers=Headers(content_length=\"42\"))) == 42\n    # multiple content-length headers with same value\n    assert (\n        expected_http_body_size(\n            treq(\n                headers=Headers(\n                    [(b\"content-length\", b\"42\"), (b\"content-length\", b\"42\")]\n                )\n            )\n        )\n        == 42\n    )\n    # multiple content-length headers with conflicting value\n    with pytest.raises(ValueError, match=\"Conflicting Content-Length headers\"):\n        expected_http_body_size(\n            treq(\n                headers=Headers(\n                    [(b\"content-length\", b\"42\"), (b\"content-length\", b\"45\")]\n                )\n            )\n        )\n\n    # non-int content-length\n    with pytest.raises(ValueError, match=\"Invalid Content-Length header\"):\n        expected_http_body_size(treq(headers=Headers([(b\"content-length\", b\"NaN\")])))\n    # negative content-length\n    with pytest.raises(ValueError, match=\"Negative Content-Length header\"):\n        expected_http_body_size(treq(headers=Headers([(b\"content-length\", b\"-1\")])))\n\n    # no length\n    assert expected_http_body_size(treq(headers=Headers())) == 0\n    assert (\n        expected_http_body_size(treq(headers=Headers()), tresp(headers=Headers())) == -1\n    )\n\n\ndef test_read_request_line():\n    def t(b):\n        return _read_request_line(b)\n\n    assert t(b\"GET / HTTP/1.1\") == (\"\", 0, b\"GET\", b\"\", b\"\", b\"/\", b\"HTTP/1.1\")\n    assert t(b\"OPTIONS * HTTP/1.1\") == (\"\", 0, b\"OPTIONS\", b\"\", b\"\", b\"*\", b\"HTTP/1.1\")\n    assert t(b\"CONNECT foo:42 HTTP/1.1\") == (\n        \"foo\",\n        42,\n        b\"CONNECT\",\n        b\"\",\n        b\"foo:42\",\n        b\"\",\n        b\"HTTP/1.1\",\n    )\n    assert t(b\"GET http://foo:42/bar HTTP/1.1\") == (\n        \"foo\",\n        42,\n        b\"GET\",\n        b\"http\",\n        b\"foo:42\",\n        b\"/bar\",\n        b\"HTTP/1.1\",\n    )\n    assert t(b\"GET http://foo:42 HTTP/1.1\") == (\n        \"foo\",\n        42,\n        b\"GET\",\n        b\"http\",\n        b\"foo:42\",\n        b\"/\",\n        b\"HTTP/1.1\",\n    )\n\n    with pytest.raises(ValueError):\n        t(b\"GET / WTF/1.1\")\n    with pytest.raises(ValueError):\n        t(b\"CONNECT example.com HTTP/1.1\")  # port missing\n    with pytest.raises(ValueError):\n        t(b\"GET ws://example.com/ HTTP/1.1\")  # port missing\n    with pytest.raises(ValueError):\n        t(b\"this is not http\")\n    with pytest.raises(ValueError):\n        t(b\"\")\n\n\ndef test_read_response_line():\n    def t(b):\n        return _read_response_line(b)\n\n    assert t(b\"HTTP/1.1 200 OK\") == (b\"HTTP/1.1\", 200, b\"OK\")\n    assert t(b\"HTTP/1.1 200\") == (b\"HTTP/1.1\", 200, b\"\")\n\n    # https://github.com/mitmproxy/mitmproxy/issues/784\n    assert t(b\"HTTP/1.1 200 Non-Autoris\\xc3\\xa9\") == (\n        b\"HTTP/1.1\",\n        200,\n        b\"Non-Autoris\\xc3\\xa9\",\n    )\n\n    with pytest.raises(ValueError):\n        assert t(b\"HTTP/1.1\")\n\n    with pytest.raises(ValueError):\n        t(b\"HTTP/1.1 OK OK\")\n    with pytest.raises(ValueError):\n        t(b\"WTF/1.1 200 OK\")\n    with pytest.raises(ValueError):\n        t(b\"\")\n\n\nclass TestReadHeaders:\n    @staticmethod\n    def _read(data):\n        return _read_headers(data.splitlines(keepends=True))\n\n    def test_read_simple(self):\n        data = b\"Header: one\\r\\n\" b\"Header2: two\\r\\n\"\n        headers = self._read(data)\n        assert headers.fields == ((b\"Header\", b\"one\"), (b\"Header2\", b\"two\"))\n\n    def test_read_multi(self):\n        data = b\"Header: one\\r\\n\" b\"Header: two\\r\\n\"\n        headers = self._read(data)\n        assert headers.fields == ((b\"Header\", b\"one\"), (b\"Header\", b\"two\"))\n\n    def test_read_continued(self):\n        data = b\"Header: one\\r\\n\" b\"\\ttwo\\r\\n\" b\"Header2: three\\r\\n\"\n        headers = self._read(data)\n        assert headers.fields == ((b\"Header\", b\"one\\r\\n two\"), (b\"Header2\", b\"three\"))\n\n    def test_read_continued_err(self):\n        data = b\"\\tfoo: bar\\r\\n\"\n        with pytest.raises(ValueError):\n            self._read(data)\n\n    def test_read_err(self):\n        data = b\"foo\"\n        with pytest.raises(ValueError):\n            self._read(data)\n\n    def test_read_empty_name(self):\n        data = b\":foo\"\n        with pytest.raises(ValueError):\n            self._read(data)\n\n    def test_read_empty_value(self):\n        data = b\"bar:\"\n        headers = self._read(data)\n        assert headers.fields == ((b\"bar\", b\"\"),)\n", "test/mitmproxy/net/http/http1/test_assemble.py": "import pytest\n\nfrom mitmproxy.http import Headers\nfrom mitmproxy.net.http.http1.assemble import _assemble_request_headers\nfrom mitmproxy.net.http.http1.assemble import _assemble_request_line\nfrom mitmproxy.net.http.http1.assemble import _assemble_response_headers\nfrom mitmproxy.net.http.http1.assemble import assemble_body\nfrom mitmproxy.net.http.http1.assemble import assemble_request\nfrom mitmproxy.net.http.http1.assemble import assemble_request_head\nfrom mitmproxy.net.http.http1.assemble import assemble_response\nfrom mitmproxy.net.http.http1.assemble import assemble_response_head\nfrom mitmproxy.test.tutils import treq\nfrom mitmproxy.test.tutils import tresp\n\n\ndef test_assemble_request():\n    assert assemble_request(treq()) == (\n        b\"GET /path HTTP/1.1\\r\\n\"\n        b\"header: qvalue\\r\\n\"\n        b\"content-length: 7\\r\\n\"\n        b\"\\r\\n\"\n        b\"content\"\n    )\n\n    with pytest.raises(ValueError):\n        assemble_request(treq(content=None))\n\n\ndef test_assemble_request_head():\n    c = assemble_request_head(treq(content=b\"foo\"))\n    assert b\"GET\" in c\n    assert b\"qvalue\" in c\n    assert b\"content-length\" in c\n    assert b\"foo\" not in c\n\n\ndef test_assemble_response():\n    assert assemble_response(tresp()) == (\n        b\"HTTP/1.1 200 OK\\r\\n\"\n        b\"header-response: svalue\\r\\n\"\n        b\"content-length: 7\\r\\n\"\n        b\"\\r\\n\"\n        b\"message\"\n    )\n\n    resp = tresp()\n    resp.headers[\"transfer-encoding\"] = \"chunked\"\n    resp.headers[\"trailer\"] = \"my-little-trailer\"\n    resp.trailers = Headers([(b\"my-little-trailer\", b\"foobar\")])\n    assert assemble_response(resp) == (\n        b\"HTTP/1.1 200 OK\\r\\n\"\n        b\"header-response: svalue\\r\\n\"\n        b\"content-length: 7\\r\\n\"\n        b\"transfer-encoding: chunked\\r\\n\"\n        b\"trailer: my-little-trailer\\r\\n\"\n        b\"\\r\\n7\\r\\n\"\n        b\"message\"\n        b\"\\r\\n0\\r\\n\"\n        b\"my-little-trailer: foobar\\r\\n\\r\\n\"\n    )\n\n    with pytest.raises(ValueError):\n        assemble_response(tresp(content=None))\n\n\ndef test_assemble_response_head():\n    c = assemble_response_head(tresp())\n    assert b\"200\" in c\n    assert b\"svalue\" in c\n    assert b\"message\" not in c\n\n\ndef test_assemble_body():\n    c = list(assemble_body(Headers(), [b\"body\"], Headers()))\n    assert c == [b\"body\"]\n\n    c = list(\n        assemble_body(\n            Headers(transfer_encoding=\"chunked\"), [b\"123456789a\", b\"\"], Headers()\n        )\n    )\n    assert c == [b\"a\\r\\n123456789a\\r\\n\", b\"0\\r\\n\\r\\n\"]\n\n    c = list(\n        assemble_body(Headers(transfer_encoding=\"chunked\"), [b\"123456789a\"], Headers())\n    )\n    assert c == [b\"a\\r\\n123456789a\\r\\n\", b\"0\\r\\n\\r\\n\"]\n\n    c = list(\n        assemble_body(\n            Headers(transfer_encoding=\"chunked\"),\n            [b\"123456789a\"],\n            Headers(trailer=\"trailer\"),\n        )\n    )\n    assert c == [b\"a\\r\\n123456789a\\r\\n\", b\"0\\r\\ntrailer: trailer\\r\\n\\r\\n\"]\n\n    with pytest.raises(ValueError):\n        list(assemble_body(Headers(), [b\"body\"], Headers(trailer=\"trailer\")))\n\n\ndef test_assemble_request_line():\n    assert _assemble_request_line(treq().data) == b\"GET /path HTTP/1.1\"\n\n    authority_request = treq(method=b\"CONNECT\", authority=b\"address:22\").data\n    assert _assemble_request_line(authority_request) == b\"CONNECT address:22 HTTP/1.1\"\n\n    absolute_request = treq(scheme=b\"http\", authority=b\"address:22\").data\n    assert (\n        _assemble_request_line(absolute_request)\n        == b\"GET http://address:22/path HTTP/1.1\"\n    )\n\n\ndef test_assemble_request_headers():\n    # https://github.com/mitmproxy/mitmproxy/issues/186\n    r = treq(content=b\"\")\n    r.headers[\"Transfer-Encoding\"] = \"chunked\"\n    c = _assemble_request_headers(r.data)\n    assert b\"Transfer-Encoding\" in c\n\n\ndef test_assemble_response_headers():\n    # https://github.com/mitmproxy/mitmproxy/issues/186\n    r = tresp(content=b\"\")\n    r.headers[\"Transfer-Encoding\"] = \"chunked\"\n    c = _assemble_response_headers(r)\n    assert b\"Transfer-Encoding\" in c\n", "test/mitmproxy/net/http/http1/__init__.py": "", "test/mitmproxy/proxy/test_tunnel.py": "import pytest\n\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.connection import Server\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy import tunnel\nfrom mitmproxy.proxy.commands import CloseConnection\nfrom mitmproxy.proxy.commands import CloseTcpConnection\nfrom mitmproxy.proxy.commands import Log\nfrom mitmproxy.proxy.commands import OpenConnection\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.events import ConnectionClosed\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.events import Event\nfrom mitmproxy.proxy.events import Start\nfrom test.mitmproxy.proxy.tutils import Playbook\nfrom test.mitmproxy.proxy.tutils import reply\n\n\nclass TChildLayer(layer.Layer):\n    child_layer: layer.Layer | None = None\n\n    def _handle_event(self, event: Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, Start):\n            yield Log(f\"Got start. Server state: {self.context.server.state.name}\")\n        elif isinstance(event, DataReceived) and event.data == b\"client-hello\":\n            yield SendData(self.context.client, b\"client-hello-reply\")\n        elif isinstance(event, DataReceived) and event.data == b\"server-hello\":\n            yield SendData(self.context.server, b\"server-hello-reply\")\n        elif isinstance(event, DataReceived) and event.data == b\"open\":\n            err = yield OpenConnection(self.context.server)\n            yield Log(f\"Opened: {err=}. Server state: {self.context.server.state.name}\")\n        elif isinstance(event, DataReceived) and event.data == b\"half-close\":\n            err = yield CloseTcpConnection(event.connection, half_close=True)\n        elif isinstance(event, ConnectionClosed):\n            yield Log(f\"Got {event.connection.__class__.__name__.lower()} close.\")\n            yield CloseConnection(event.connection)\n        else:\n            raise AssertionError\n\n\nclass TTunnelLayer(tunnel.TunnelLayer):\n    def start_handshake(self) -> layer.CommandGenerator[None]:\n        yield SendData(self.tunnel_connection, b\"handshake-hello\")\n\n    def receive_handshake_data(\n        self, data: bytes\n    ) -> layer.CommandGenerator[tuple[bool, str | None]]:\n        yield SendData(self.tunnel_connection, data)\n        if data == b\"handshake-success\":\n            return True, None\n        else:\n            return False, \"handshake error\"\n\n    def send_data(self, data: bytes) -> layer.CommandGenerator[None]:\n        yield SendData(self.tunnel_connection, b\"tunneled-\" + data)\n\n    def receive_data(self, data: bytes) -> layer.CommandGenerator[None]:\n        yield from self.event_to_child(\n            DataReceived(self.conn, data.replace(b\"tunneled-\", b\"\"))\n        )\n\n\n@pytest.mark.parametrize(\"success\", [\"success\", \"fail\"])\ndef test_tunnel_handshake_start(tctx: Context, success):\n    server = Server(address=(\"proxy\", 1234))\n    server.state = ConnectionState.OPEN\n\n    tl = TTunnelLayer(tctx, server, tctx.server)\n    tl.child_layer = TChildLayer(tctx)\n    assert repr(tl)\n\n    playbook = Playbook(tl, logs=True)\n    (\n        playbook\n        << SendData(server, b\"handshake-hello\")\n        >> DataReceived(tctx.client, b\"client-hello\")\n        >> DataReceived(server, b\"handshake-\" + success.encode())\n        << SendData(server, b\"handshake-\" + success.encode())\n    )\n    if success == \"success\":\n        playbook << Log(\"Got start. Server state: OPEN\")\n    else:\n        playbook << CloseConnection(server)\n        playbook << Log(\"Got start. Server state: CLOSED\")\n\n    playbook << SendData(tctx.client, b\"client-hello-reply\")\n    if success == \"success\":\n        playbook >> DataReceived(server, b\"tunneled-server-hello\")\n        playbook << SendData(server, b\"tunneled-server-hello-reply\")\n\n    assert playbook\n\n\n@pytest.mark.parametrize(\"success\", [\"success\", \"fail\"])\ndef test_tunnel_handshake_command(tctx: Context, success):\n    server = Server(address=(\"proxy\", 1234))\n\n    tl = TTunnelLayer(tctx, server, tctx.server)\n    tl.child_layer = TChildLayer(tctx)\n\n    playbook = Playbook(tl, logs=True)\n    (\n        playbook\n        << Log(\"Got start. Server state: CLOSED\")\n        >> DataReceived(tctx.client, b\"client-hello\")\n        << SendData(tctx.client, b\"client-hello-reply\")\n        >> DataReceived(tctx.client, b\"open\")\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"handshake-hello\")\n        >> DataReceived(server, b\"handshake-\" + success.encode())\n        << SendData(server, b\"handshake-\" + success.encode())\n    )\n    if success == \"success\":\n        assert (\n            playbook\n            << Log(f\"Opened: err=None. Server state: OPEN\")\n            >> DataReceived(server, b\"tunneled-server-hello\")\n            << SendData(server, b\"tunneled-server-hello-reply\")\n            >> ConnectionClosed(tctx.client)\n            << Log(\"Got client close.\")\n            << CloseConnection(tctx.client)\n        )\n        assert tl.tunnel_state is tunnel.TunnelState.OPEN\n        assert (\n            playbook\n            >> ConnectionClosed(server)\n            << Log(\"Got server close.\")\n            << CloseConnection(server)\n        )\n        assert tl.tunnel_state is tunnel.TunnelState.CLOSED\n    else:\n        assert (\n            playbook\n            << CloseConnection(server)\n            << Log(\"Opened: err='handshake error'. Server state: CLOSED\")\n        )\n        assert tl.tunnel_state is tunnel.TunnelState.CLOSED\n\n\ndef test_tunnel_default_impls(tctx: Context):\n    \"\"\"\n    Some tunnels don't need certain features, so the default behaviour\n    should be to be transparent.\n    \"\"\"\n    server = Server(address=None)\n    server.state = ConnectionState.OPEN\n    tl = tunnel.TunnelLayer(tctx, server, tctx.server)\n    tl.child_layer = TChildLayer(tctx)\n    playbook = Playbook(tl, logs=True)\n    assert (\n        playbook\n        << Log(\"Got start. Server state: OPEN\")\n        >> DataReceived(server, b\"server-hello\")\n        << SendData(server, b\"server-hello-reply\")\n    )\n    assert tl.tunnel_state is tunnel.TunnelState.OPEN\n    assert (\n        playbook\n        >> ConnectionClosed(server)\n        << Log(\"Got server close.\")\n        << CloseConnection(server)\n    )\n    assert tl.tunnel_state is tunnel.TunnelState.CLOSED\n\n    assert (\n        playbook\n        >> DataReceived(tctx.client, b\"open\")\n        << OpenConnection(server)\n        >> reply(None)\n        << Log(\"Opened: err=None. Server state: OPEN\")\n        >> DataReceived(server, b\"half-close\")\n        << CloseTcpConnection(server, half_close=True)\n    )\n\n\ndef test_tunnel_openconnection_error(tctx: Context):\n    server = Server(address=(\"proxy\", 1234))\n\n    tl = TTunnelLayer(tctx, server, tctx.server)\n    tl.child_layer = TChildLayer(tctx)\n\n    playbook = Playbook(tl, logs=True)\n    assert (\n        playbook\n        << Log(\"Got start. Server state: CLOSED\")\n        >> DataReceived(tctx.client, b\"open\")\n        << OpenConnection(server)\n    )\n    assert tl.tunnel_state is tunnel.TunnelState.ESTABLISHING\n    assert (\n        playbook\n        >> reply(\"IPoAC packet dropped.\")\n        << Log(\"Opened: err='IPoAC packet dropped.'. Server state: CLOSED\")\n    )\n    assert tl.tunnel_state is tunnel.TunnelState.CLOSED\n\n\n@pytest.mark.parametrize(\"disconnect\", [\"client\", \"server\"])\ndef test_disconnect_during_handshake_start(tctx: Context, disconnect):\n    server = Server(address=(\"proxy\", 1234))\n    server.state = ConnectionState.OPEN\n\n    tl = TTunnelLayer(tctx, server, tctx.server)\n    tl.child_layer = TChildLayer(tctx)\n\n    playbook = Playbook(tl, logs=True)\n\n    assert playbook << SendData(server, b\"handshake-hello\")\n    if disconnect == \"client\":\n        assert (\n            playbook\n            >> ConnectionClosed(tctx.client)\n            >> ConnectionClosed(\n                server\n            )  # proxyserver will cancel all other connections as well.\n            << CloseConnection(server)\n            << Log(\"Got start. Server state: CLOSED\")\n            << Log(\"Got client close.\")\n            << CloseConnection(tctx.client)\n        )\n    else:\n        assert (\n            playbook\n            >> ConnectionClosed(server)\n            << CloseConnection(server)\n            << Log(\"Got start. Server state: CLOSED\")\n        )\n\n\n@pytest.mark.parametrize(\"disconnect\", [\"client\", \"server\"])\ndef test_disconnect_during_handshake_command(tctx: Context, disconnect):\n    server = Server(address=(\"proxy\", 1234))\n\n    tl = TTunnelLayer(tctx, server, tctx.server)\n    tl.child_layer = TChildLayer(tctx)\n\n    playbook = Playbook(tl, logs=True)\n    assert (\n        playbook\n        << Log(\"Got start. Server state: CLOSED\")\n        >> DataReceived(tctx.client, b\"client-hello\")\n        << SendData(tctx.client, b\"client-hello-reply\")\n        >> DataReceived(tctx.client, b\"open\")\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"handshake-hello\")\n    )\n    if disconnect == \"client\":\n        assert (\n            playbook\n            >> ConnectionClosed(tctx.client)\n            >> ConnectionClosed(\n                server\n            )  # proxyserver will cancel all other connections as well.\n            << CloseConnection(server)\n            << Log(\"Opened: err='connection closed'. Server state: CLOSED\")\n            << Log(\"Got client close.\")\n            << CloseConnection(tctx.client)\n        )\n    else:\n        assert (\n            playbook\n            >> ConnectionClosed(server)\n            << CloseConnection(server)\n            << Log(\"Opened: err='connection closed'. Server state: CLOSED\")\n        )\n\n\ndef test_layer_stack(tctx):\n    stack = tunnel.LayerStack()\n    a = TChildLayer(tctx)\n    b = TChildLayer(tctx)\n    stack /= a\n    stack /= b\n    assert stack[0] == a\n    assert a.child_layer is b\n\n    stack2 = tunnel.LayerStack()\n    stack2 /= TChildLayer(tctx)\n    stack2 /= stack\n    assert stack2[0].child_layer is a  # type: ignore\n", "test/mitmproxy/proxy/test_mode_specs.py": "import dataclasses\n\nimport pytest\n\nfrom mitmproxy.proxy.mode_specs import ProxyMode\nfrom mitmproxy.proxy.mode_specs import Socks5Mode\n\n\ndef test_parse():\n    m = ProxyMode.parse(\"reverse:https://example.com/@127.0.0.1:443\")\n    m = ProxyMode.from_state(m.get_state())\n\n    assert m.type_name == \"reverse\"\n    assert m.full_spec == \"reverse:https://example.com/@127.0.0.1:443\"\n    assert m.data == \"https://example.com/\"\n    assert m.custom_listen_host == \"127.0.0.1\"\n    assert m.custom_listen_port == 443\n    assert repr(m) == \"ProxyMode.parse('reverse:https://example.com/@127.0.0.1:443')\"\n\n    with pytest.raises(ValueError, match=\"unknown mode\"):\n        ProxyMode.parse(\"flibbel\")\n\n    with pytest.raises(ValueError, match=\"invalid port\"):\n        ProxyMode.parse(\"regular@invalid-port\")\n\n    with pytest.raises(ValueError, match=\"invalid port\"):\n        ProxyMode.parse(\"regular@99999\")\n\n    m.set_state(m.get_state())\n    with pytest.raises(dataclasses.FrozenInstanceError):\n        m.set_state(\"regular\")\n\n\ndef test_parse_subclass():\n    assert Socks5Mode.parse(\"socks5\")\n    with pytest.raises(ValueError, match=\"'regular' is not a spec for a socks5 mode\"):\n        Socks5Mode.parse(\"regular\")\n\n\ndef test_listen_addr():\n    assert ProxyMode.parse(\"regular\").listen_port() == 8080\n    assert ProxyMode.parse(\"regular@1234\").listen_port() == 1234\n    assert ProxyMode.parse(\"regular\").listen_port(default=4424) == 4424\n    assert ProxyMode.parse(\"regular@1234\").listen_port(default=4424) == 1234\n\n    assert ProxyMode.parse(\"regular\").listen_host() == \"\"\n    assert ProxyMode.parse(\"regular@127.0.0.2:8080\").listen_host() == \"127.0.0.2\"\n    assert ProxyMode.parse(\"regular\").listen_host(default=\"127.0.0.3\") == \"127.0.0.3\"\n    assert (\n        ProxyMode.parse(\"regular@127.0.0.2:8080\").listen_host(default=\"127.0.0.3\")\n        == \"127.0.0.2\"\n    )\n\n    assert ProxyMode.parse(\"reverse:https://1.2.3.4\").listen_port() == 8080\n    assert ProxyMode.parse(\"reverse:dns://8.8.8.8\").listen_port() == 53\n\n\ndef test_parse_specific_modes():\n    assert ProxyMode.parse(\"regular\")\n    # assert ProxyMode.parse(\"http3\")\n    assert ProxyMode.parse(\"transparent\")\n    assert ProxyMode.parse(\"upstream:https://proxy\")\n    assert ProxyMode.parse(\"reverse:https://host@443\")\n    assert ProxyMode.parse(\"reverse:http3://host@443\")\n    assert ProxyMode.parse(\"socks5\")\n    assert ProxyMode.parse(\"dns\")\n    assert ProxyMode.parse(\"reverse:dns://8.8.8.8\")\n    assert ProxyMode.parse(\"reverse:dtls://127.0.0.1:8004\")\n    assert ProxyMode.parse(\"wireguard\")\n    assert ProxyMode.parse(\"wireguard:foo.conf\").data == \"foo.conf\"\n    assert ProxyMode.parse(\"wireguard@51821\").listen_port() == 51821\n\n    assert ProxyMode.parse(\"local\")\n\n    with pytest.raises(ValueError, match=\"invalid port\"):\n        ProxyMode.parse(\"regular@invalid-port\")\n\n    with pytest.raises(ValueError, match=\"takes no arguments\"):\n        ProxyMode.parse(\"regular:configuration\")\n\n    # with pytest.raises(ValueError, match=\"takes no arguments\"):\n    #     ProxyMode.parse(\"http3:configuration\")\n\n    with pytest.raises(ValueError, match=\"invalid upstream proxy scheme\"):\n        ProxyMode.parse(\"upstream:dns://example.com\")\n\n    with pytest.raises(ValueError, match=\"takes no arguments\"):\n        ProxyMode.parse(\"dns:invalid\")\n\n    with pytest.raises(ValueError, match=\"Port specification missing.\"):\n        ProxyMode.parse(\"reverse:dtls://127.0.0.1\")\n\n    with pytest.raises(ValueError, match=\"invalid intercept spec\"):\n        ProxyMode.parse(\"local:,,,\")\n", "test/mitmproxy/proxy/test_mode_servers.py": "import asyncio\nimport platform\nfrom unittest.mock import AsyncMock\nfrom unittest.mock import MagicMock\nfrom unittest.mock import Mock\n\nimport mitmproxy_rs\nimport pytest\n\nimport mitmproxy.platform\nfrom mitmproxy.addons.proxyserver import Proxyserver\nfrom mitmproxy.proxy.mode_servers import LocalRedirectorInstance\nfrom mitmproxy.proxy.mode_servers import ServerInstance\nfrom mitmproxy.proxy.mode_servers import WireGuardServerInstance\nfrom mitmproxy.proxy.server import ConnectionHandler\nfrom mitmproxy.test import taddons\n\n\ndef test_make():\n    manager = Mock()\n    context = MagicMock()\n    assert ServerInstance.make(\"regular\", manager)\n\n    for mode in [\n        \"regular\",\n        # \"http3\",\n        \"upstream:example.com\",\n        \"transparent\",\n        \"reverse:example.com\",\n        \"socks5\",\n    ]:\n        inst = ServerInstance.make(mode, manager)\n        assert inst\n        assert inst.make_top_layer(context)\n        assert inst.mode.description\n        assert inst.to_json()\n\n    with pytest.raises(\n        ValueError, match=\"is not a spec for a WireGuardServerInstance server.\"\n    ):\n        WireGuardServerInstance.make(\"regular\", manager)\n\n\nasync def test_last_exception_and_running(monkeypatch):\n    manager = MagicMock()\n    err = ValueError(\"something else\")\n\n    def _raise(*_):\n        nonlocal err\n        raise err\n\n    async def _raise_async(*_):\n        nonlocal err\n        raise err\n\n    with taddons.context():\n        inst1 = ServerInstance.make(\"regular@127.0.0.1:0\", manager)\n        await inst1.start()\n        assert inst1.last_exception is None\n        assert inst1.is_running\n        monkeypatch.setattr(inst1._servers[0], \"close\", _raise)\n        with pytest.raises(type(err), match=str(err)):\n            await inst1.stop()\n        assert inst1.last_exception is err\n\n        monkeypatch.setattr(asyncio, \"start_server\", _raise_async)\n        inst2 = ServerInstance.make(\"regular@127.0.0.1:0\", manager)\n        assert inst2.last_exception is None\n        with pytest.raises(type(err), match=str(err)):\n            await inst2.start()\n        assert inst2.last_exception is err\n        assert not inst1.is_running\n\n\nasync def test_tcp_start_stop(caplog_async):\n    caplog_async.set_level(\"INFO\")\n    manager = MagicMock()\n\n    with taddons.context():\n        inst = ServerInstance.make(\"regular@127.0.0.1:0\", manager)\n        await inst.start()\n        assert inst.last_exception is None\n        assert await caplog_async.await_log(\"proxy listening\")\n\n        host, port, *_ = inst.listen_addrs[0]\n        reader, writer = await asyncio.open_connection(host, port)\n        assert await caplog_async.await_log(\"client connect\")\n\n        writer.close()\n        await writer.wait_closed()\n        assert await caplog_async.await_log(\"client disconnect\")\n\n        await inst.stop()\n        assert await caplog_async.await_log(\"stopped\")\n\n\n@pytest.mark.parametrize(\"failure\", [True, False])\nasync def test_transparent(failure, monkeypatch, caplog_async):\n    caplog_async.set_level(\"INFO\")\n    manager = MagicMock()\n\n    if failure:\n        monkeypatch.setattr(mitmproxy.platform, \"original_addr\", None)\n    else:\n        monkeypatch.setattr(\n            mitmproxy.platform, \"original_addr\", lambda s: (\"address\", 42)\n        )\n\n    with taddons.context(Proxyserver()) as tctx:\n        tctx.options.connection_strategy = \"lazy\"\n        inst = ServerInstance.make(\"transparent@127.0.0.1:0\", manager)\n        await inst.start()\n        await caplog_async.await_log(\"listening\")\n\n        host, port, *_ = inst.listen_addrs[0]\n        reader, writer = await asyncio.open_connection(host, port)\n\n        if failure:\n            assert await caplog_async.await_log(\"Transparent mode failure\")\n            writer.close()\n            await writer.wait_closed()\n        else:\n            assert await caplog_async.await_log(\"client connect\")\n            writer.close()\n            await writer.wait_closed()\n            assert await caplog_async.await_log(\"client disconnect\")\n\n        await inst.stop()\n        assert await caplog_async.await_log(\"stopped\")\n\n\nasync def test_wireguard(tdata, monkeypatch, caplog):\n    caplog.set_level(\"DEBUG\")\n\n    async def handle_client(self: ConnectionHandler):\n        t = self.transports[self.client]\n        data = await t.reader.read(65535)\n        t.writer.write(data.upper())\n        await t.writer.drain()\n        t.writer.close()\n\n    monkeypatch.setattr(ConnectionHandler, \"handle_client\", handle_client)\n\n    system = platform.system()\n    if system == \"Linux\":\n        test_client_name = \"linux-x86_64\"\n    elif system == \"Darwin\":\n        test_client_name = \"macos-x86_64\"\n    elif system == \"Windows\":\n        test_client_name = \"windows-x86_64.exe\"\n    else:\n        return pytest.skip(\"Unsupported platform for wg-test-client.\")\n\n    arch = platform.machine()\n    if arch != \"AMD64\" and arch != \"x86_64\":\n        return pytest.skip(\"Unsupported architecture for wg-test-client.\")\n\n    test_client_path = tdata.path(f\"wg-test-client/{test_client_name}\")\n    test_conf = tdata.path(f\"wg-test-client/test.conf\")\n\n    with taddons.context(Proxyserver()):\n        inst = WireGuardServerInstance.make(f\"wireguard:{test_conf}@0\", MagicMock())\n\n        await inst.start()\n        assert \"WireGuard server listening\" in caplog.text\n\n        _, port = inst.listen_addrs[0]\n\n        assert inst.is_running\n        proc = await asyncio.create_subprocess_exec(\n            test_client_path,\n            str(port),\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE,\n        )\n        stdout, stderr = await proc.communicate()\n\n        try:\n            assert proc.returncode == 0\n        except AssertionError:\n            print(stdout)\n            print(stderr)\n            raise\n\n        await inst.stop()\n        assert \"stopped\" in caplog.text\n\n\nasync def test_wireguard_generate_conf(tmp_path):\n    with taddons.context(Proxyserver()) as tctx:\n        tctx.options.confdir = str(tmp_path)\n        inst = WireGuardServerInstance.make(f\"wireguard@0\", MagicMock())\n        assert not inst.client_conf()  # should not error.\n\n        await inst.start()\n\n        assert (tmp_path / \"wireguard.conf\").exists()\n        assert inst.client_conf()\n        assert inst.to_json()[\"wireguard_conf\"]\n        k = inst.server_key\n\n        inst2 = WireGuardServerInstance.make(f\"wireguard@0\", MagicMock())\n        await inst2.start()\n        assert k == inst2.server_key\n\n        await inst.stop()\n        await inst2.stop()\n\n\nasync def test_wireguard_invalid_conf(tmp_path):\n    with taddons.context(Proxyserver()):\n        # directory instead of filename\n        inst = WireGuardServerInstance.make(f\"wireguard:{tmp_path}\", MagicMock())\n\n        with pytest.raises(ValueError, match=\"Invalid configuration file\"):\n            await inst.start()\n\n        assert \"Invalid configuration file\" in repr(inst.last_exception)\n\n\nasync def test_tcp_start_error():\n    manager = MagicMock()\n\n    server = await asyncio.start_server(\n        MagicMock(), host=\"127.0.0.1\", port=0, reuse_address=False\n    )\n    port = server.sockets[0].getsockname()[1]\n\n    with taddons.context() as tctx:\n        inst = ServerInstance.make(f\"regular@127.0.0.1:{port}\", manager)\n        with pytest.raises(\n            OSError, match=f\"proxy failed to listen on 127\\\\.0\\\\.0\\\\.1:{port}\"\n        ):\n            await inst.start()\n        tctx.options.listen_host = \"127.0.0.1\"\n        tctx.options.listen_port = port\n        inst3 = ServerInstance.make(f\"regular\", manager)\n        with pytest.raises(OSError):\n            await inst3.start()\n\n\nasync def test_invalid_protocol(monkeypatch):\n    manager = MagicMock()\n\n    with taddons.context():\n        inst = ServerInstance.make(f\"regular@127.0.0.1:0\", manager)\n        monkeypatch.setattr(inst.mode, \"transport_protocol\", \"invalid_proto\")\n        with pytest.raises(AssertionError, match=f\"invalid_proto\"):\n            await inst.start()\n\n\nasync def test_udp_start_stop(caplog_async):\n    caplog_async.set_level(\"INFO\")\n    manager = MagicMock()\n    manager.connections = {}\n\n    with taddons.context():\n        inst = ServerInstance.make(\"dns@127.0.0.1:0\", manager)\n        await inst.start()\n        assert await caplog_async.await_log(\"server listening\")\n\n        host, port, *_ = inst.listen_addrs[0]\n        stream = await mitmproxy_rs.open_udp_connection(host, port)\n\n        stream.write(b\"\\x00\\x00\\x01\")\n        assert await caplog_async.await_log(\"sent an invalid message\")\n\n        stream.close()\n        await stream.wait_closed()\n\n        await inst.stop()\n        assert await caplog_async.await_log(\"stopped\")\n\n\nasync def test_udp_start_error():\n    manager = MagicMock()\n\n    with taddons.context():\n        inst = ServerInstance.make(\"reverse:udp://127.0.0.1:1234@127.0.0.1:0\", manager)\n        await inst.start()\n        port = inst.listen_addrs[0][1]\n        inst2 = ServerInstance.make(\n            f\"reverse:udp://127.0.0.1:1234@127.0.0.1:{port}\", manager\n        )\n        with pytest.raises(\n            Exception, match=f\"Failed to bind UDP socket to 127.0.0.1:{port}\"\n        ):\n            await inst2.start()\n        await inst.stop()\n\n\nasync def test_udp_dual_stack(caplog_async):\n    caplog_async.set_level(\"DEBUG\")\n    manager = MagicMock()\n    manager.connections = {}\n\n    with taddons.context():\n        inst = ServerInstance.make(\"dns@:0\", manager)\n        await inst.start()\n        assert await caplog_async.await_log(\"server listening\")\n\n        _, port, *_ = inst.listen_addrs[0]\n        stream = await mitmproxy_rs.open_udp_connection(\"127.0.0.1\", port)\n        stream.write(b\"\\x00\\x00\\x01\")\n        assert await caplog_async.await_log(\"sent an invalid message\")\n        stream.close()\n        await stream.wait_closed()\n\n        if \"listening on IPv4 only\" not in caplog_async.caplog.text:\n            caplog_async.clear()\n            stream = await mitmproxy_rs.open_udp_connection(\"::1\", port)\n            stream.write(b\"\\x00\\x00\\x01\")\n            assert await caplog_async.await_log(\"sent an invalid message\")\n            stream.close()\n            await stream.wait_closed()\n\n        await inst.stop()\n        assert await caplog_async.await_log(\"stopped\")\n\n\n@pytest.mark.parametrize(\"transport_protocol\", [\"udp\", \"tcp\"])\nasync def test_dns_start_stop(caplog_async, transport_protocol):\n    caplog_async.set_level(\"INFO\")\n    manager = MagicMock()\n    manager.connections = {}\n\n    with taddons.context():\n        inst = ServerInstance.make(\"dns@127.0.0.1:0\", manager)\n        await inst.start()\n        assert await caplog_async.await_log(\"server listening\")\n\n        host, port, *_ = inst.listen_addrs[0]\n        if transport_protocol == \"tcp\":\n            _, stream = await asyncio.open_connection(\"127.0.0.1\", port)\n        elif transport_protocol == \"udp\":\n            stream = await mitmproxy_rs.open_udp_connection(\"127.0.0.1\", port)\n\n        stream.write(b\"\\x00\\x00\\x01\")\n        assert await caplog_async.await_log(\"sent an invalid message\")\n\n        stream.close()\n        await stream.wait_closed()\n\n        await inst.stop()\n        assert await caplog_async.await_log(\"stopped\")\n\n\n@pytest.fixture()\ndef patched_local_redirector(monkeypatch):\n    start_local_redirector = AsyncMock(return_value=Mock())\n    monkeypatch.setattr(mitmproxy_rs, \"start_local_redirector\", start_local_redirector)\n    # make sure _server and _instance are restored after this test\n    monkeypatch.setattr(LocalRedirectorInstance, \"_server\", None)\n    monkeypatch.setattr(LocalRedirectorInstance, \"_instance\", None)\n    return start_local_redirector\n\n\nasync def test_local_redirector(patched_local_redirector, caplog_async):\n    caplog_async.set_level(\"INFO\")\n\n    with taddons.context():\n        inst = ServerInstance.make(f\"local\", MagicMock())\n        assert not inst.is_running\n\n        await inst.start()\n        assert patched_local_redirector.called\n        assert await caplog_async.await_log(\"Local redirector started.\")\n        assert inst.is_running\n\n        await inst.stop()\n        assert await caplog_async.await_log(\"Local redirector stopped\")\n        assert not inst.is_running\n\n        # just called for coverage\n        inst.make_top_layer(MagicMock())\n\n\nasync def test_local_redirector_startup_err(patched_local_redirector):\n    patched_local_redirector.side_effect = RuntimeError(\n        \"Local redirector startup error\"\n    )\n\n    with taddons.context():\n        inst = ServerInstance.make(f\"local:!curl\", MagicMock())\n        with pytest.raises(RuntimeError):\n            await inst.start()\n        assert not inst.is_running\n\n\nasync def test_multiple_local_redirectors(patched_local_redirector):\n    manager = MagicMock()\n\n    with taddons.context():\n        inst1 = ServerInstance.make(f\"local:curl\", manager)\n        await inst1.start()\n\n        inst2 = ServerInstance.make(f\"local:wget\", manager)\n        with pytest.raises(\n            RuntimeError, match=\"Cannot spawn more than one local redirector\"\n        ):\n            await inst2.start()\n\n\nasync def test_always_uses_current_instance(patched_local_redirector, monkeypatch):\n    manager = MagicMock()\n\n    with taddons.context():\n        inst1 = LocalRedirectorInstance.make(f\"local:curl\", manager)\n        await inst1.start()\n        await inst1.stop()\n\n        handle_stream, _ = patched_local_redirector.await_args[0]\n\n        inst2 = LocalRedirectorInstance.make(f\"local:wget\", manager)\n        await inst2.start()\n\n        monkeypatch.setattr(inst2, \"handle_stream\", handler := AsyncMock())\n        await handle_stream(Mock())\n        assert handler.await_count\n", "test/mitmproxy/proxy/tutils.py": "import collections.abc\nimport difflib\nimport itertools\nimport logging\nimport re\nimport textwrap\nimport traceback\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom typing import Any\nfrom typing import AnyStr\nfrom typing import Generic\nfrom typing import TypeVar\nfrom typing import Union\n\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.events import command_reply_subclasses\nfrom mitmproxy.proxy.layer import Layer\n\nPlaybookEntry = Union[commands.Command, events.Event]\nPlaybookEntryList = list[PlaybookEntry]\n\n\ndef _eq(a: PlaybookEntry, b: PlaybookEntry) -> bool:\n    \"\"\"Compare two commands/events, and possibly update placeholders.\"\"\"\n    if type(a) != type(b):\n        return False\n\n    a_dict = a.__dict__\n    b_dict = b.__dict__\n    # we can assume a.keys() == b.keys()\n    for k in a_dict:\n        if k == \"blocking\":\n            continue\n        x = a_dict[k]\n        y = b_dict[k]\n\n        # if there's a placeholder, make it x.\n        if isinstance(y, _Placeholder):\n            x, y = y, x\n        if isinstance(x, _Placeholder):\n            try:\n                x = x.setdefault(y)\n            except TypeError as e:\n                raise TypeError(\n                    f\"Placeholder type error for {type(a).__name__}.{k}: {e}\"\n                )\n        if x != y:\n            return False\n\n    return True\n\n\ndef eq(\n    a: PlaybookEntry | Iterable[PlaybookEntry],\n    b: PlaybookEntry | Iterable[PlaybookEntry],\n):\n    \"\"\"\n    Compare an indiviual event/command or a list of events/commands.\n    \"\"\"\n    if isinstance(a, collections.abc.Iterable) and isinstance(\n        b, collections.abc.Iterable\n    ):\n        return all(_eq(x, y) for x, y in itertools.zip_longest(a, b))\n    return _eq(a, b)\n\n\ndef _fmt_entry(x: PlaybookEntry):\n    arrow = \">>\" if isinstance(x, events.Event) else \"<<\"\n    x = str(x)\n    x = re.sub(\"Placeholder:None\", \"<unset placeholder>\", x, flags=re.IGNORECASE)\n    x = re.sub(\"Placeholder:\", \"\", x, flags=re.IGNORECASE)\n    x = textwrap.indent(x, \"     \")[5:]\n    return f\"{arrow} {x}\"\n\n\ndef _merge_sends(\n    lst: list[commands.Command], ignore_hooks: bool, ignore_logs: bool\n) -> PlaybookEntryList:\n    current_send = None\n    for x in lst:\n        if isinstance(x, commands.SendData):\n            if current_send is None or current_send.connection != x.connection:\n                current_send = x\n                yield x\n            else:\n                current_send.data += x.data\n        else:\n            ignore = (ignore_hooks and isinstance(x, commands.StartHook)) or (\n                ignore_logs and isinstance(x, commands.Log)\n            )\n            if not ignore:\n                current_send = None\n            yield x\n\n\nclass _TracebackInPlaybook(commands.Command):\n    def __init__(self, exc):\n        self.e = exc\n\n    def __repr__(self):\n        return self.e\n\n\nclass Playbook:\n    \"\"\"\n    Assert that a layer emits the expected commands in reaction to a given sequence of events.\n    For example, the following code asserts that the TCP layer emits an OpenConnection command\n    immediately after starting and does not yield any further commands as a reaction to successful\n    connection establishment.\n\n    assert playbook(tcp.TCPLayer(tctx)) \\\n        << commands.OpenConnection(tctx.server)\n        >> reply(None)\n        << None  # this line is optional.\n\n    This is syntactic sugar for the following:\n\n    t = tcp.TCPLayer(tctx)\n    x1 = list(t.handle_event(events.Start()))\n    assert x1 == [commands.OpenConnection(tctx.server)]\n    x2 = list(t.handle_event(events.OpenConnectionReply(x1[-1])))\n    assert x2 == []\n    \"\"\"\n\n    layer: Layer\n    \"\"\"The base layer\"\"\"\n    expected: PlaybookEntryList\n    \"\"\"expected command/event sequence\"\"\"\n    actual: PlaybookEntryList\n    \"\"\"actual command/event sequence\"\"\"\n    _errored: bool\n    \"\"\"used to check if playbook as been fully asserted\"\"\"\n    logs: bool\n    \"\"\"If False, the playbook specification doesn't contain log commands.\"\"\"\n    hooks: bool\n    \"\"\"If False, the playbook specification doesn't include hooks or hook replies. They are automatically replied to.\"\"\"\n\n    def __init__(\n        self,\n        layer: Layer,\n        hooks: bool = True,\n        logs: bool = False,\n        expected: PlaybookEntryList | None = None,\n    ):\n        if expected is None:\n            expected = [events.Start()]\n\n        self.layer = layer\n        self.expected = expected\n        self.actual = []\n        self._errored = False\n        self.logs = logs\n        self.hooks = hooks\n\n    def __rshift__(self, e):\n        \"\"\"Add an event to send\"\"\"\n        assert isinstance(e, events.Event)\n        self.expected.append(e)\n        return self\n\n    def __lshift__(self, c):\n        \"\"\"Add an expected command\"\"\"\n        if c is None:\n            return self\n        assert isinstance(c, commands.Command)\n\n        prev = self.expected[-1]\n        two_subsequent_sends_to_the_same_remote = (\n            isinstance(c, commands.SendData)\n            and isinstance(prev, commands.SendData)\n            and prev.connection is c.connection\n        )\n        if two_subsequent_sends_to_the_same_remote:\n            prev.data += c.data\n        else:\n            self.expected.append(c)\n\n        return self\n\n    def __bool__(self):\n        \"\"\"Determine if playbook is correct.\"\"\"\n        already_asserted = len(self.actual)\n        i = already_asserted\n        while i < len(self.expected):\n            x = self.expected[i]\n            if isinstance(x, commands.Command):\n                pass\n            else:\n                if hasattr(x, \"playbook_eval\"):\n                    try:\n                        x = self.expected[i] = x.playbook_eval(self)\n                    except Exception:\n                        self.actual.append(_TracebackInPlaybook(traceback.format_exc()))\n                        break\n                for name, value in vars(x).items():\n                    if isinstance(value, _Placeholder):\n                        setattr(x, name, value())\n                if isinstance(x, events.OpenConnectionCompleted) and not x.reply:\n                    x.command.connection.state = ConnectionState.OPEN\n                    x.command.connection.timestamp_start = 1624544785\n                elif isinstance(x, events.ConnectionClosed):\n                    x.connection.state &= ~ConnectionState.CAN_READ\n                    x.connection.timestamp_end = 1624544787\n\n                self.actual.append(x)\n                cmds: list[commands.Command] = []\n                try:\n                    # consume them one by one so that we can extend the log with all commands until traceback.\n                    for cmd in self.layer.handle_event(x):\n                        cmds.append(cmd)\n                except Exception:\n                    self.actual.extend(cmds)\n                    self.actual.append(_TracebackInPlaybook(traceback.format_exc()))\n                    break\n\n                cmds = list(\n                    _merge_sends(\n                        cmds, ignore_hooks=not self.hooks, ignore_logs=not self.logs\n                    )\n                )\n\n                self.actual.extend(cmds)\n                pos = len(self.actual) - len(cmds) - 1\n                hook_replies = []\n                for cmd in cmds:\n                    pos += 1\n                    assert self.actual[pos] == cmd\n                    if isinstance(cmd, commands.CloseTcpConnection) and cmd.half_close:\n                        cmd.connection.state &= ~ConnectionState.CAN_WRITE\n                    elif isinstance(cmd, commands.CloseConnection):\n                        cmd.connection.state = ConnectionState.CLOSED\n                    elif isinstance(cmd, commands.Log):\n                        need_to_emulate_log = (\n                            not self.logs\n                            and cmd.level in (logging.DEBUG, logging.INFO)\n                            and (\n                                pos >= len(self.expected)\n                                or not isinstance(self.expected[pos], commands.Log)\n                            )\n                        )\n                        if need_to_emulate_log:\n                            self.expected.insert(pos, cmd)\n                    elif isinstance(cmd, commands.StartHook) and not self.hooks:\n                        need_to_emulate_hook = not self.hooks and (\n                            pos >= len(self.expected)\n                            or (\n                                not (\n                                    isinstance(self.expected[pos], commands.StartHook)\n                                    and self.expected[pos].name == cmd.name\n                                )\n                            )\n                        )\n                        if need_to_emulate_hook:\n                            self.expected.insert(pos, cmd)\n                            if cmd.blocking:\n                                # the current event may still have yielded more events, so we need to insert\n                                # the reply *after* those additional events.\n                                hook_replies.append(events.HookCompleted(cmd))\n                self.expected = (\n                    self.expected[: pos + 1] + hook_replies + self.expected[pos + 1 :]\n                )\n\n                eq(\n                    self.expected[i:], self.actual[i:]\n                )  # compare now already to set placeholders\n            i += 1\n\n        if not eq(self.expected, self.actual):\n            self._errored = True\n            diffs = list(\n                difflib.ndiff(\n                    [_fmt_entry(x) for x in self.expected],\n                    [_fmt_entry(x) for x in self.actual],\n                )\n            )\n            if already_asserted:\n                diffs.insert(already_asserted, \"==== asserted until here ====\")\n            diff = \"\\n\".join(diffs)\n            raise AssertionError(f\"Playbook mismatch!\\n{diff}\")\n        else:\n            return True\n\n    def __del__(self):\n        # Playbooks are only executed on assert (which signals that the playbook is partially\n        # complete), so we need to signal if someone forgets to assert and playbooks aren't\n        # evaluated.\n        is_final_destruct = not hasattr(self, \"_errored\")\n        if is_final_destruct or (\n            not self._errored and len(self.actual) < len(self.expected)\n        ):\n            raise RuntimeError(\"Unfinished playbook!\")\n\n\nclass reply(events.Event):\n    args: tuple[Any, ...]\n    to: commands.Command | type[commands.Command] | int\n    side_effect: Callable[[Any], Any]\n\n    def __init__(\n        self,\n        *args,\n        to: commands.Command | type[commands.Command] | int = -1,\n        side_effect: Callable[[Any], None] = lambda x: None,\n    ):\n        \"\"\"Utility method to reply to the latest hook in playbooks.\"\"\"\n        assert not args or not isinstance(args[0], commands.Command)\n        self.args = args\n        self.to = to\n        self.side_effect = side_effect\n\n    def playbook_eval(self, playbook: Playbook) -> events.CommandCompleted:\n        if isinstance(self.to, int):\n            expected = playbook.expected[: playbook.expected.index(self)]\n            assert abs(self.to) < len(expected)\n            to = expected[self.to]\n            if not isinstance(to, commands.Command):\n                raise AssertionError(f\"There is no command at offset {self.to}: {to}\")\n            else:\n                self.to = to\n        elif isinstance(self.to, type):\n            for cmd in reversed(playbook.actual):\n                if isinstance(cmd, self.to):\n                    assert isinstance(cmd, commands.Command)\n                    self.to = cmd\n                    break\n            else:\n                raise AssertionError(f\"There is no command of type {self.to}.\")\n        for cmd in reversed(playbook.actual):\n            if eq(self.to, cmd):\n                self.to = cmd\n                break\n        else:\n            raise AssertionError(f\"Expected command {self.to} did not occur.\")\n\n        assert isinstance(self.to, commands.Command)\n        if isinstance(self.to, commands.StartHook):\n            self.side_effect(*self.to.args())\n            reply_cls = events.HookCompleted\n        else:\n            self.side_effect(self.to)\n            reply_cls = command_reply_subclasses[type(self.to)]\n        try:\n            inst = reply_cls(self.to, *self.args)\n        except TypeError as e:\n            raise ValueError(f\"Cannot instantiate {reply_cls.__name__}: {e}\")\n        return inst\n\n\nT = TypeVar(\"T\")\n\n\nclass _Placeholder(Generic[T]):\n    \"\"\"\n    Placeholder value in playbooks, so that objects (flows in particular) can be referenced before\n    they are known. Example:\n\n    f = Placeholder(TCPFlow)\n    assert (\n        playbook(tcp.TCPLayer(tctx))\n        << TcpStartHook(f)  # the flow object returned here is generated by the layer.\n    )\n\n    # We can obtain the flow object now using f():\n    assert f().messages == 0\n    \"\"\"\n\n    def __init__(self, cls: type[T]):\n        self._obj = None\n        self._cls = cls\n\n    def __call__(self) -> T:\n        \"\"\"Get the actual object\"\"\"\n        return self._obj\n\n    def setdefault(self, value: T) -> T:\n        if self._obj is None:\n            if self._cls is not Any and not isinstance(value, self._cls):\n                raise TypeError(\n                    f\"expected {self._cls.__name__}, got {type(value).__name__}.\"\n                )\n            self._obj = value\n        return self._obj\n\n    def __repr__(self):\n        return f\"Placeholder:{repr(self._obj)}\"\n\n    def __str__(self):\n        return f\"Placeholder:{str(self._obj)}\"\n\n\n# noinspection PyPep8Naming\ndef Placeholder(cls: type[T] = Any) -> T | _Placeholder[T]:\n    return _Placeholder(cls)\n\n\nclass _AnyStrPlaceholder(_Placeholder[AnyStr]):\n    def __init__(self, match: AnyStr):\n        super().__init__(type(match))\n        self._match = match\n\n    def setdefault(self, value: AnyStr) -> AnyStr:\n        if self._obj is None:\n            super().setdefault(value)\n            if not re.search(self._match, self._obj, re.DOTALL):  # type: ignore\n                raise ValueError(f\"{self._obj!r} does not match {self._match!r}.\")\n        return self._obj\n\n\n# noinspection PyPep8Naming\ndef BytesMatching(match: bytes) -> bytes | _AnyStrPlaceholder[bytes]:\n    return _AnyStrPlaceholder(match)\n\n\n# noinspection PyPep8Naming\ndef StrMatching(match: str) -> str | _AnyStrPlaceholder[str]:\n    return _AnyStrPlaceholder(match)\n\n\nclass EchoLayer(Layer):\n    \"\"\"Echo layer that sends all data back to the client in lowercase.\"\"\"\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, events.DataReceived):\n            yield commands.SendData(event.connection, event.data.lower())\n        if isinstance(event, events.ConnectionClosed):\n            yield commands.CloseConnection(event.connection)\n\n\nclass RecordLayer(Layer):\n    \"\"\"Layer that records all events but does nothing.\"\"\"\n\n    event_log: list[events.Event]\n\n    def __init__(self, context: context.Context) -> None:\n        super().__init__(context)\n        self.event_log = []\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        self.event_log.append(event)\n        yield from ()\n\n\ndef reply_next_layer(\n    child_layer: type[Layer] | Callable[[context.Context], Layer], *args, **kwargs\n) -> reply:\n    \"\"\"Helper function to simplify the syntax for next_layer events to this:\n    << NextLayerHook(nl)\n    >> reply_next_layer(tutils.EchoLayer)\n    \"\"\"\n\n    def set_layer(next_layer: layer.NextLayer) -> None:\n        next_layer.layer = child_layer(next_layer.context)\n\n    return reply(*args, side_effect=set_layer, **kwargs)\n", "test/mitmproxy/proxy/test_server_hooks.py": "from mitmproxy.proxy import server_hooks\n\n\ndef test_noop():\n    assert server_hooks\n", "test/mitmproxy/proxy/test_context.py": "from mitmproxy.proxy import context\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\n\n\ndef test_context():\n    with taddons.context() as tctx:\n        c = context.Context(tflow.tclient_conn(), tctx.options)\n        assert repr(c)\n        c.layers.append(1)\n        assert repr(c)\n        c2 = c.fork()\n        c.layers.append(2)\n        c2.layers.append(3)\n        assert c.layers == [1, 2]\n        assert c2.layers == [1, 3]\n", "test/mitmproxy/proxy/test_commands.py": "from dataclasses import dataclass\n\nimport pytest\n\nfrom mitmproxy import connection\nfrom mitmproxy.hooks import all_hooks\nfrom mitmproxy.proxy import commands\n\n\n@pytest.fixture\ndef tconn() -> connection.Server:\n    return connection.Server(address=None)\n\n\ndef test_dataclasses(tconn):\n    assert repr(commands.RequestWakeup(58))\n    assert repr(commands.SendData(tconn, b\"foo\"))\n    assert repr(commands.OpenConnection(tconn))\n    assert repr(commands.CloseConnection(tconn))\n    assert repr(commands.CloseTcpConnection(tconn, half_close=True))\n    assert repr(commands.Log(\"hello\"))\n\n\ndef test_start_hook():\n    with pytest.raises(TypeError):\n        commands.StartHook()\n\n    @dataclass\n    class TestHook(commands.StartHook):\n        data: bytes\n\n    f = TestHook(b\"foo\")\n    assert f.args() == [b\"foo\"]\n    assert TestHook in all_hooks.values()\n", "test/mitmproxy/proxy/test_layer.py": "from logging import DEBUG\n\nimport pytest\n\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.context import Context\nfrom test.mitmproxy.proxy import tutils\n\n\nclass TestLayer:\n    def test_continue(self, tctx: Context):\n        class TLayer(layer.Layer):\n            def _handle_event(\n                self, event: events.Event\n            ) -> layer.CommandGenerator[None]:\n                yield commands.OpenConnection(self.context.server)\n                yield commands.OpenConnection(self.context.server)\n\n        assert (\n            tutils.Playbook(TLayer(tctx))\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n        )\n\n    def test_debug_messages(self, tctx: Context):\n        tctx.server.id = \"serverid\"\n\n        class TLayer(layer.Layer):\n            debug = \" \"\n\n            def _handle_event(\n                self, event: events.Event\n            ) -> layer.CommandGenerator[None]:\n                yield from self.state(event)\n\n            def state_foo(self, event: events.Event) -> layer.CommandGenerator[None]:\n                assert isinstance(event, events.Start)\n                yield commands.OpenConnection(self.context.server)\n                self.state = self.state_bar\n\n            state = state_foo\n\n            def state_bar(self, event: events.Event) -> layer.CommandGenerator[None]:\n                assert isinstance(event, events.DataReceived)\n                yield commands.Log(\"baz\")\n\n        tlayer = TLayer(tctx)\n        assert (\n            tutils.Playbook(tlayer, hooks=True, logs=True)\n            << commands.Log(\" >> Start({})\", DEBUG)\n            << commands.Log(\n                \" << OpenConnection({'connection': Server({'id': '\u2026rverid', 'address': None})})\",\n                DEBUG,\n            )\n            << commands.OpenConnection(tctx.server)\n            >> events.DataReceived(tctx.client, b\"foo\")\n            << commands.Log(\" >! DataReceived(client, b'foo')\", DEBUG)\n            >> tutils.reply(None, to=-3)\n            << commands.Log(\n                \" >> Reply(OpenConnection({'connection': Server({'id': '\u2026rverid', 'address': None, \"\n                \"'state': <ConnectionState.OPEN: 3>, 'timestamp_start': 1624544785})}), None)\",\n                DEBUG,\n            )\n            << commands.Log(\" !> DataReceived(client, b'foo')\", DEBUG)\n            << commands.Log(\"baz\")\n        )\n        assert repr(tlayer) == \"TLayer(state: bar)\"\n\n    def test_debug_shorten(self, tctx):\n        t = layer.Layer(tctx)\n        t.debug = \"  \"\n        assert t._Layer__debug(\"x\" * 600).message == \"  \" + \"x\" * 512 + \"\u2026\"\n        assert t._Layer__debug(\"x\" * 600).message == \"  \" + \"x\" * 256 + \"\u2026\"\n        assert t._Layer__debug(\"foo\").message == \"  foo\"\n\n\nclass TestNextLayer:\n    def test_simple(self, tctx: Context):\n        nl = layer.NextLayer(tctx, ask_on_start=True)\n        nl.debug = \"  \"\n        playbook = tutils.Playbook(nl, hooks=True)\n\n        assert (\n            playbook\n            << layer.NextLayerHook(nl)\n            >> tutils.reply()\n            >> events.DataReceived(tctx.client, b\"foo\")\n            << layer.NextLayerHook(nl)\n            >> tutils.reply()\n            >> events.DataReceived(tctx.client, b\"bar\")\n            << layer.NextLayerHook(nl)\n        )\n        assert nl.data_client() == b\"foobar\"\n        assert nl.data_server() == b\"\"\n\n        nl.layer = tutils.EchoLayer(tctx)\n        assert (\n            playbook\n            >> tutils.reply()\n            << commands.SendData(tctx.client, b\"foo\")\n            << commands.SendData(tctx.client, b\"bar\")\n        )\n\n    def test_late_hook_reply(self, tctx: Context):\n        \"\"\"\n        Properly handle case where we receive an additional event while we are waiting for\n        a reply from the proxy core.\n        \"\"\"\n        nl = layer.NextLayer(tctx)\n        playbook = tutils.Playbook(nl)\n\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, b\"foo\")\n            << layer.NextLayerHook(nl)\n            >> events.DataReceived(tctx.client, b\"bar\")\n        )\n        assert nl.data_client() == b\"foo\"  # \"bar\" is paused.\n        nl.layer = tutils.EchoLayer(tctx)\n\n        assert (\n            playbook\n            >> tutils.reply(to=-2)\n            << commands.SendData(tctx.client, b\"foo\")\n            << commands.SendData(tctx.client, b\"bar\")\n        )\n\n    @pytest.mark.parametrize(\"layer_found\", [True, False])\n    def test_receive_close(self, tctx: Context, layer_found: bool):\n        \"\"\"Test that we abort a client connection which has disconnected without any layer being found.\"\"\"\n        nl = layer.NextLayer(tctx)\n        playbook = tutils.Playbook(nl)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, b\"foo\")\n            << layer.NextLayerHook(nl)\n            >> events.ConnectionClosed(tctx.client)\n        )\n        if layer_found:\n            nl.layer = tutils.RecordLayer(tctx)\n            assert playbook >> tutils.reply(to=-2)\n            assert isinstance(nl.layer.event_log[-1], events.ConnectionClosed)\n        else:\n            assert (\n                playbook\n                >> tutils.reply(to=-2)\n                << commands.CloseConnection(tctx.client)\n                << None\n            )\n\n    def test_func_references(self, tctx: Context):\n        nl = layer.NextLayer(tctx)\n        playbook = tutils.Playbook(nl)\n\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, b\"foo\")\n            << layer.NextLayerHook(nl)\n        )\n        nl.layer = tutils.EchoLayer(tctx)\n        handle = nl.handle_event\n\n        playbook >> tutils.reply()\n        playbook << commands.SendData(tctx.client, b\"foo\")\n        assert playbook\n        (sd,) = handle(events.DataReceived(tctx.client, b\"bar\"))\n        assert isinstance(sd, commands.SendData)\n\n    def test_repr(self, tctx: Context):\n        nl = layer.NextLayer(tctx)\n        nl.layer = tutils.EchoLayer(tctx)\n        assert repr(nl)\n        assert nl.stack_pos\n        assert nl.layer.stack_pos\n", "test/mitmproxy/proxy/conftest.py": "import os\n\nimport pytest\nfrom hypothesis import settings\n\nfrom mitmproxy import connection\nfrom mitmproxy import options\nfrom mitmproxy.addons.proxyserver import Proxyserver\nfrom mitmproxy.proxy import context\n\n\n@pytest.fixture\ndef tctx() -> context.Context:\n    opts = options.Options()\n    Proxyserver().load(opts)\n    return context.Context(\n        connection.Client(\n            peername=(\"client\", 1234),\n            sockname=(\"127.0.0.1\", 8080),\n            timestamp_start=1605699329,\n            state=connection.ConnectionState.OPEN,\n        ),\n        opts,\n    )\n\n\nsettings.register_profile(\"fast\", max_examples=10, deadline=None)\nsettings.register_profile(\"deep\", max_examples=100_000, deadline=None)\nsettings.load_profile(os.getenv(\"HYPOTHESIS_PROFILE\", \"fast\"))\n", "test/mitmproxy/proxy/test_events.py": "from unittest.mock import Mock\n\nimport pytest\n\nfrom mitmproxy import connection\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\n\n\n@pytest.fixture\ndef tconn() -> connection.Server:\n    return connection.Server(address=None)\n\n\ndef test_dataclasses(tconn):\n    assert repr(events.Start())\n    assert repr(events.DataReceived(tconn, b\"foo\"))\n    assert repr(events.ConnectionClosed(tconn))\n\n\ndef test_command_completed():\n    with pytest.raises(TypeError):\n        events.CommandCompleted()\n    assert repr(events.HookCompleted(Mock(), None))\n\n    class FooCommand(commands.Command):\n        pass\n\n    with pytest.warns(RuntimeWarning, match=\"properly annotated\"):\n\n        class FooCompleted(events.CommandCompleted):\n            pass\n\n    class FooCompleted1(events.CommandCompleted):\n        command: FooCommand\n\n    with pytest.warns(RuntimeWarning, match=\"conflicting subclasses\"):\n\n        class FooCompleted2(events.CommandCompleted):\n            command: FooCommand\n", "test/mitmproxy/proxy/bench.py": "\"\"\"\nUsage:\n  - pip install pytest-benchmark\n  - pytest bench.py\n\nSee also:\n  - https://github.com/mitmproxy/proxybench\n\"\"\"\n\nimport copy\n\nfrom .layers import test_tcp\nfrom .layers import test_tls\nfrom .layers.http import test_http\nfrom .layers.http import test_http2\n\n\ndef test_bench_http_roundtrip(tctx, benchmark):\n    # benchmark something\n    benchmark(test_http.test_http_proxy, tctx)\n\n\ndef test_bench_http2_roundtrip(tctx, benchmark):\n    # benchmark something\n    benchmark(test_http2.test_simple, tctx)\n\n\ndef test_bench_tcp_roundtrip(tctx, benchmark):\n    # benchmark something\n    benchmark(lambda: test_tcp.test_simple(copy.deepcopy(tctx)))\n\n\ndef test_bench_server_tls(tctx, benchmark):\n    t = test_tls.TestServerTLS().test_simple\n    benchmark(lambda: t(copy.deepcopy(tctx)))\n\n\ndef test_bench_client_tls(tctx, benchmark):\n    t = test_tls.TestClientTLS().test_client_only\n    benchmark(lambda: t(copy.deepcopy(tctx)))\n\n\ndef test_bench_tls_both(tctx, benchmark):\n    t = test_tls.TestClientTLS().test_server_required\n    benchmark(lambda: t(copy.deepcopy(tctx)))\n", "test/mitmproxy/proxy/test_tutils.py": "from collections.abc import Iterable\nfrom dataclasses import dataclass\nfrom typing import Any\n\nimport pytest\n\nfrom . import tutils\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\n\n\nclass TEvent(events.Event):\n    commands: Iterable[Any]\n\n    def __init__(self, cmds=(None,)):\n        self.commands = cmds\n\n\nclass TCommand(commands.Command):\n    x: Any\n\n    def __init__(self, x=None):\n        self.x = x\n\n\n@dataclass\nclass TCommandCompleted(events.CommandCompleted):\n    command: TCommand\n\n\nclass TLayer(layer.Layer):\n    \"\"\"\n    Simple echo layer\n    \"\"\"\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, TEvent):\n            for x in event.commands:\n                yield TCommand(x)\n\n\n@pytest.fixture\ndef tplaybook(tctx):\n    return tutils.Playbook(TLayer(tctx), expected=[])\n\n\ndef test_simple(tplaybook):\n    tplaybook >> TEvent()\n    tplaybook << TCommand()\n    tplaybook >> TEvent([])\n    tplaybook << None\n    assert tplaybook\n\n\ndef test_mismatch(tplaybook):\n    with pytest.raises(AssertionError, match=\"Playbook mismatch\"):\n        tplaybook >> TEvent([])\n        tplaybook << TCommand()\n        assert tplaybook\n\n\ndef test_partial_assert(tplaybook):\n    \"\"\"Developers can assert parts of a playbook and the continue later on.\"\"\"\n    tplaybook >> TEvent()\n    tplaybook << TCommand()\n    assert tplaybook\n\n    tplaybook >> TEvent()\n    tplaybook << TCommand()\n    assert tplaybook\n\n    assert len(tplaybook.actual) == len(tplaybook.expected) == 4\n\n\n@pytest.mark.parametrize(\"typed\", [True, False])\ndef test_placeholder(tplaybook, typed):\n    \"\"\"Developers can specify placeholders for yet unknown attributes.\"\"\"\n    if typed:\n        f = tutils.Placeholder(int)\n    else:\n        f = tutils.Placeholder()\n    tplaybook >> TEvent([42])\n    tplaybook << TCommand(f)\n    assert tplaybook\n    assert f() == 42\n\n\ndef test_placeholder_type_mismatch(tplaybook):\n    \"\"\"Developers can specify placeholders for yet unknown attributes.\"\"\"\n    f = tutils.Placeholder(str)\n    with pytest.raises(\n        TypeError, match=\"Placeholder type error for TCommand.x: expected str, got int.\"\n    ):\n        tplaybook >> TEvent([42])\n        tplaybook << TCommand(f)\n        assert tplaybook\n\n\ndef test_unfinished(tplaybook):\n    \"\"\"We show a warning when playbooks aren't asserted.\"\"\"\n    tplaybook >> TEvent()\n    with pytest.raises(RuntimeError, match=\"Unfinished playbook\"):\n        tplaybook.__del__()\n    tplaybook._errored = True\n    tplaybook.__del__()\n\n\ndef test_command_reply(tplaybook):\n    \"\"\"CommandReplies can use relative offsets to point to the matching command.\"\"\"\n    tplaybook >> TEvent()\n    tplaybook << TCommand()\n    tplaybook >> tutils.reply()\n    assert tplaybook\n    assert tplaybook.actual[1] == tplaybook.actual[2].command\n\n    tplaybook >> TEvent((42,))\n    tplaybook << TCommand(42)\n    tplaybook >> tutils.reply(to=TCommand)\n    assert tplaybook\n    assert tplaybook.actual[4] == tplaybook.actual[5].command\n\n\ndef test_default_playbook(tctx):\n    p = tutils.Playbook(TLayer(tctx))\n    assert p\n    assert len(p.actual) == 1\n    assert isinstance(p.actual[0], events.Start)\n\n\ndef test_eq_blocking():\n    \"\"\"_eq should not consider differences in .blocking\"\"\"\n    a = TCommand()\n    a.blocking = True\n    b = TCommand()\n    b.blocking = False\n    assert tutils._eq(a, b)\n\n\ndef test_eq_placeholder():\n    \"\"\"_eq should assign placeholders.\"\"\"\n    a = TCommand()\n    a.foo = 42\n    a.bar = tutils.Placeholder()\n    b = TCommand()\n    b.foo = tutils.Placeholder()\n    b.bar = 43\n    assert tutils._eq(a, b)\n    assert a.foo == b.foo() == 42\n    assert a.bar() == b.bar == 43\n\n    b.foo._obj = 44\n    assert not tutils._eq(a, b)\n\n\n@pytest.mark.parametrize(\"swap\", [False, True])\ndef test_command_multiple_replies(tplaybook, swap):\n    a = tutils.Placeholder(int)\n    b = tutils.Placeholder(int)\n\n    command1 = TCommand(a)\n    command2 = TCommand(b)\n\n    tplaybook >> TEvent([1])\n    tplaybook << command1\n    tplaybook >> TEvent([2])\n    tplaybook << command2\n\n    if swap:\n        tplaybook >> tutils.reply(to=command1)\n        tplaybook >> tutils.reply(to=command2)\n    else:\n        tplaybook >> tutils.reply(to=command2)\n        tplaybook >> tutils.reply(to=command1)\n    assert tplaybook\n    assert a() == 1\n    assert b() == 2\n", "test/mitmproxy/proxy/__init__.py": "", "test/mitmproxy/proxy/test_server.py": "import asyncio\nimport collections\nfrom unittest import mock\n\nimport pytest\n\nfrom mitmproxy import options\nfrom mitmproxy.connection import Server\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import server\nfrom mitmproxy.proxy import server_hooks\nfrom mitmproxy.proxy.mode_specs import ProxyMode\n\n\nclass MockConnectionHandler(server.SimpleConnectionHandler):\n    hook_handlers: dict[str, mock.Mock]\n\n    def __init__(self):\n        super().__init__(\n            reader=mock.Mock(),\n            writer=mock.Mock(),\n            options=options.Options(),\n            mode=ProxyMode.parse(\"regular\"),\n            hooks=collections.defaultdict(lambda: mock.Mock()),\n        )\n\n\n@pytest.mark.parametrize(\"result\", (\"success\", \"killed\", \"failed\"))\nasync def test_open_connection(result, monkeypatch):\n    handler = MockConnectionHandler()\n    server_connect = handler.hook_handlers[\"server_connect\"]\n    server_connected = handler.hook_handlers[\"server_connected\"]\n    server_connect_error = handler.hook_handlers[\"server_connect_error\"]\n    server_disconnected = handler.hook_handlers[\"server_disconnected\"]\n\n    match result:\n        case \"success\":\n            monkeypatch.setattr(\n                asyncio,\n                \"open_connection\",\n                mock.AsyncMock(return_value=(mock.MagicMock(), mock.MagicMock())),\n            )\n            monkeypatch.setattr(\n                MockConnectionHandler, \"handle_connection\", mock.AsyncMock()\n            )\n        case \"failed\":\n            monkeypatch.setattr(\n                asyncio, \"open_connection\", mock.AsyncMock(side_effect=OSError)\n            )\n        case \"killed\":\n\n            def _kill(d: server_hooks.ServerConnectionHookData) -> None:\n                d.server.error = \"do not connect\"\n\n            server_connect.side_effect = _kill\n\n    await handler.open_connection(\n        commands.OpenConnection(connection=Server(address=(\"server\", 1234)))\n    )\n\n    assert server_connect.call_args[0][0].server.address == (\"server\", 1234)\n\n    assert server_connected.called == (result == \"success\")\n    assert server_connect_error.called == (result != \"success\")\n\n    assert server_disconnected.called == (result == \"success\")\n", "test/mitmproxy/proxy/test_utils.py": "import pytest\n\nfrom mitmproxy.proxy.utils import expect\nfrom mitmproxy.proxy.utils import ReceiveBuffer\n\n\ndef test_expect():\n    class Foo:\n        @expect(str, int)\n        def foo(self, x):\n            return \"\".join(reversed(x))\n\n        @expect(str)\n        def bar(self, x):\n            yield \"\".join(reversed(x))\n\n    f = Foo()\n\n    assert f.foo(\"foo\") == \"oof\"\n    assert list(f.bar(\"bar\")) == [\"rab\"]\n    with pytest.raises(AssertionError, match=r\"Expected str\\|int, got None.\"):\n        f.foo(None)\n\n\ndef test_receive_buffer():\n    buf = ReceiveBuffer()\n    assert len(buf) == 0\n    assert bytes(buf) == b\"\"\n    assert not buf\n\n    buf += b\"foo\"\n    assert len(buf) == 3\n    assert bytes(buf) == b\"foo\"\n    assert buf\n\n    buf += b\"bar\"\n    assert len(buf) == 6\n    assert bytes(buf) == b\"foobar\"\n    assert buf\n\n    buf.clear()\n    assert len(buf) == 0\n    assert bytes(buf) == b\"\"\n    assert not buf\n", "test/mitmproxy/proxy/layers/test_tls.py": "import ssl\nimport time\nfrom logging import DEBUG\nfrom logging import WARNING\n\nimport pytest\nfrom OpenSSL import SSL\n\nfrom mitmproxy import connection\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.connection import Server\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.layers import tls\nfrom mitmproxy.tls import ClientHelloData\nfrom mitmproxy.tls import TlsData\nfrom mitmproxy.utils import data\nfrom test.mitmproxy.proxy import tutils\nfrom test.mitmproxy.proxy.tutils import BytesMatching\nfrom test.mitmproxy.proxy.tutils import StrMatching\n\ntlsdata = data.Data(__name__)\n\n\ndef test_record_contents():\n    data = bytes.fromhex(\"1603010002beef\" \"1603010001ff\")\n    assert list(tls.handshake_record_contents(data)) == [b\"\\xbe\\xef\", b\"\\xff\"]\n    for i in range(6):\n        assert list(tls.handshake_record_contents(data[:i])) == []\n\n\ndef test_record_contents_err():\n    with pytest.raises(ValueError, match=\"Expected TLS record\"):\n        next(tls.handshake_record_contents(b\"GET /error\"))\n\n    empty_record = bytes.fromhex(\"1603010000\")\n    with pytest.raises(ValueError, match=\"Record must not be empty\"):\n        next(tls.handshake_record_contents(empty_record))\n\n\nclient_hello_no_extensions = bytes.fromhex(\n    \"0100006103015658a756ab2c2bff55f636814deac086b7ca56b65058c7893ffc6074f5245f70205658a75475103a152637\"\n    \"78e1bb6d22e8bbd5b6b0a3a59760ad354e91ba20d353001a0035002f000a000500040009000300060008006000\"\n    \"61006200640100\"\n)\nclient_hello_with_extensions = bytes.fromhex(\n    \"16030300bb\"  # record layer\n    \"010000b7\"  # handshake layer\n    \"03033b70638d2523e1cba15f8364868295305e9c52aceabda4b5147210abc783e6e1000022c02bc02fc02cc030\"\n    \"cca9cca8cc14cc13c009c013c00ac014009c009d002f0035000a0100006cff0100010000000010000e00000b65\"\n    \"78616d706c652e636f6d0017000000230000000d00120010060106030501050304010403020102030005000501\"\n    \"00000000001200000010000e000c02683208687474702f312e3175500000000b00020100000a00080006001d00\"\n    \"170018\"\n)\n\n\ndef test_get_client_hello():\n    single_record = bytes.fromhex(\"1603010065\") + client_hello_no_extensions\n    assert tls.get_client_hello(single_record) == client_hello_no_extensions\n\n    split_over_two_records = (\n        bytes.fromhex(\"1603010020\")\n        + client_hello_no_extensions[:32]\n        + bytes.fromhex(\"1603010045\")\n        + client_hello_no_extensions[32:]\n    )\n    assert tls.get_client_hello(split_over_two_records) == client_hello_no_extensions\n\n    incomplete = split_over_two_records[:42]\n    assert tls.get_client_hello(incomplete) is None\n\n\ndef test_parse_client_hello():\n    assert tls.parse_client_hello(client_hello_with_extensions).sni == \"example.com\"\n    assert tls.parse_client_hello(client_hello_with_extensions[:50]) is None\n    with pytest.raises(ValueError):\n        tls.parse_client_hello(\n            client_hello_with_extensions[:183] + b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n        )\n\n\nclass SSLTest:\n    \"\"\"Helper container for Python's builtin SSL object.\"\"\"\n\n    def __init__(\n        self,\n        server_side: bool = False,\n        alpn: list[str] | None = None,\n        sni: bytes | None = b\"example.mitmproxy.org\",\n        max_ver: ssl.TLSVersion | None = None,\n    ):\n        self.inc = ssl.MemoryBIO()\n        self.out = ssl.MemoryBIO()\n        self.ctx = ssl.SSLContext(\n            ssl.PROTOCOL_TLS_SERVER if server_side else ssl.PROTOCOL_TLS_CLIENT\n        )\n\n        self.ctx.verify_mode = ssl.CERT_OPTIONAL\n        self.ctx.load_verify_locations(\n            cafile=tlsdata.path(\"../../net/data/verificationcerts/trusted-root.crt\"),\n        )\n\n        if alpn:\n            self.ctx.set_alpn_protocols(alpn)\n        if server_side:\n            if sni == b\"192.0.2.42\":\n                filename = \"trusted-leaf-ip\"\n            else:\n                filename = \"trusted-leaf\"\n            self.ctx.load_cert_chain(\n                certfile=tlsdata.path(\n                    f\"../../net/data/verificationcerts/{filename}.crt\"\n                ),\n                keyfile=tlsdata.path(\n                    f\"../../net/data/verificationcerts/{filename}.key\"\n                ),\n            )\n        if max_ver:\n            self.ctx.maximum_version = max_ver\n\n        self.obj = self.ctx.wrap_bio(\n            self.inc,\n            self.out,\n            server_hostname=None if server_side else sni,\n            server_side=server_side,\n        )\n\n    def bio_write(self, buf: bytes) -> int:\n        return self.inc.write(buf)\n\n    def bio_read(self, bufsize: int = 2**16) -> bytes:\n        return self.out.read(bufsize)\n\n    def do_handshake(self) -> None:\n        return self.obj.do_handshake()\n\n\ndef _test_echo(\n    playbook: tutils.Playbook, tssl: SSLTest, conn: connection.Connection\n) -> None:\n    tssl.obj.write(b\"Hello World\")\n    data = tutils.Placeholder(bytes)\n    assert (\n        playbook\n        >> events.DataReceived(conn, tssl.bio_read())\n        << commands.SendData(conn, data)\n    )\n    tssl.bio_write(data())\n    assert tssl.obj.read() == b\"hello world\"\n\n\nclass TlsEchoLayer(tutils.EchoLayer):\n    err: str | None = None\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, events.DataReceived) and event.data == b\"open-connection\":\n            err = yield commands.OpenConnection(self.context.server)\n            if err:\n                yield commands.SendData(\n                    event.connection, f\"open-connection failed: {err}\".encode()\n                )\n        else:\n            yield from super()._handle_event(event)\n\n\ndef finish_handshake(\n    playbook: tutils.Playbook, conn: connection.Connection, tssl: SSLTest\n):\n    data = tutils.Placeholder(bytes)\n    tls_hook_data = tutils.Placeholder(TlsData)\n    if isinstance(conn, connection.Client):\n        established_hook = tls.TlsEstablishedClientHook(tls_hook_data)\n    else:\n        established_hook = tls.TlsEstablishedServerHook(tls_hook_data)\n    assert (\n        playbook\n        >> events.DataReceived(conn, tssl.bio_read())\n        << established_hook\n        >> tutils.reply()\n        << commands.SendData(conn, data)\n    )\n    assert tls_hook_data().conn.error is None\n    tssl.bio_write(data())\n\n\ndef reply_tls_start_client(alpn: bytes | None = None, *args, **kwargs) -> tutils.reply:\n    \"\"\"\n    Helper function to simplify the syntax for tls_start_client hooks.\n    \"\"\"\n\n    def make_client_conn(tls_start: TlsData) -> None:\n        # ssl_context = SSL.Context(Method.TLS_METHOD)\n        # ssl_context.set_min_proto_version(SSL.TLS1_3_VERSION)\n        ssl_context = SSL.Context(SSL.SSLv23_METHOD)\n        ssl_context.set_options(\n            SSL.OP_NO_SSLv3 | SSL.OP_NO_TLSv1 | SSL.OP_NO_TLSv1_1 | SSL.OP_NO_TLSv1_2\n        )\n        ssl_context.use_privatekey_file(\n            tlsdata.path(\"../../net/data/verificationcerts/trusted-leaf.key\")\n        )\n        ssl_context.use_certificate_chain_file(\n            tlsdata.path(\"../../net/data/verificationcerts/trusted-leaf.crt\")\n        )\n        if alpn is not None:\n            ssl_context.set_alpn_select_callback(lambda conn, protos: alpn)\n\n        tls_start.ssl_conn = SSL.Connection(ssl_context)\n        tls_start.ssl_conn.set_accept_state()\n\n    return tutils.reply(*args, side_effect=make_client_conn, **kwargs)\n\n\ndef reply_tls_start_server(alpn: bytes | None = None, *args, **kwargs) -> tutils.reply:\n    \"\"\"\n    Helper function to simplify the syntax for tls_start_server hooks.\n    \"\"\"\n\n    def make_server_conn(tls_start: TlsData) -> None:\n        # ssl_context = SSL.Context(Method.TLS_METHOD)\n        # ssl_context.set_min_proto_version(SSL.TLS1_3_VERSION)\n        ssl_context = SSL.Context(SSL.SSLv23_METHOD)\n        ssl_context.set_options(\n            SSL.OP_NO_SSLv3 | SSL.OP_NO_TLSv1 | SSL.OP_NO_TLSv1_1 | SSL.OP_NO_TLSv1_2\n        )\n        ssl_context.load_verify_locations(\n            cafile=tlsdata.path(\"../../net/data/verificationcerts/trusted-root.crt\")\n        )\n        if alpn is not None:\n            ssl_context.set_alpn_protos([alpn])\n        ssl_context.set_verify(SSL.VERIFY_PEER)\n\n        tls_start.ssl_conn = SSL.Connection(ssl_context)\n        tls_start.ssl_conn.set_connect_state()\n        # Set SNI\n        tls_start.ssl_conn.set_tlsext_host_name(tls_start.conn.sni.encode())\n\n        # Manually enable hostname verification.\n        # Recent OpenSSL versions provide slightly nicer ways to do this, but they are not exposed in\n        # cryptography and likely a PITA to add.\n        # https://wiki.openssl.org/index.php/Hostname_validation\n        param = SSL._lib.SSL_get0_param(tls_start.ssl_conn._ssl)\n        # Common Name matching is disabled in both Chrome and Firefox, so we should disable it, too.\n        # https://www.chromestatus.com/feature/4981025180483584\n        SSL._lib.X509_VERIFY_PARAM_set_hostflags(\n            param,\n            SSL._lib.X509_CHECK_FLAG_NO_PARTIAL_WILDCARDS\n            | SSL._lib.X509_CHECK_FLAG_NEVER_CHECK_SUBJECT,\n        )\n        SSL._openssl_assert(\n            SSL._lib.X509_VERIFY_PARAM_set1_host(param, tls_start.conn.sni.encode(), 0)\n            == 1\n        )\n\n    return tutils.reply(*args, side_effect=make_server_conn, **kwargs)\n\n\nclass TestServerTLS:\n    def test_repr(self, tctx):\n        assert repr(tls.ServerTLSLayer(tctx))\n\n    def test_not_connected(self, tctx: context.Context):\n        \"\"\"Test that we don't do anything if no server connection exists.\"\"\"\n        layer = tls.ServerTLSLayer(tctx)\n        layer.child_layer = TlsEchoLayer(tctx)\n\n        assert (\n            tutils.Playbook(layer)\n            >> events.DataReceived(tctx.client, b\"Hello World\")\n            << commands.SendData(tctx.client, b\"hello world\")\n        )\n\n    def test_simple(self, tctx):\n        playbook = tutils.Playbook(tls.ServerTLSLayer(tctx))\n        tctx.server.address = (\"example.mitmproxy.org\", 443)\n        tctx.server.state = ConnectionState.OPEN\n        tctx.server.sni = \"example.mitmproxy.org\"\n\n        tssl = SSLTest(server_side=True)\n\n        # send ClientHello, receive ClientHello\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            << tls.TlsStartServerHook(tutils.Placeholder())\n            >> reply_tls_start_server()\n            << commands.SendData(tctx.server, data)\n        )\n        tssl.bio_write(data())\n        with pytest.raises(ssl.SSLWantReadError):\n            tssl.do_handshake()\n\n        # finish handshake (mitmproxy)\n        finish_handshake(playbook, tctx.server, tssl)\n\n        # finish handshake (locally)\n        tssl.do_handshake()\n        playbook >> events.DataReceived(tctx.server, tssl.bio_read())\n        playbook << None\n        assert playbook\n\n        assert tctx.server.tls_established\n\n        # Echo\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, b\"foo\")\n            << layer.NextLayerHook(tutils.Placeholder())\n            >> tutils.reply_next_layer(TlsEchoLayer)\n            << commands.SendData(tctx.client, b\"foo\")\n        )\n        _test_echo(playbook, tssl, tctx.server)\n\n        with pytest.raises(ssl.SSLWantReadError):\n            tssl.obj.unwrap()\n        assert (\n            playbook\n            >> events.DataReceived(tctx.server, tssl.bio_read())\n            << commands.CloseConnection(tctx.server)\n            >> events.ConnectionClosed(tctx.server)\n            << None\n        )\n\n    def test_untrusted_cert(self, tctx):\n        \"\"\"If the certificate is not trusted, we should fail.\"\"\"\n        playbook = tutils.Playbook(tls.ServerTLSLayer(tctx))\n        tctx.server.address = (\"wrong.host.mitmproxy.org\", 443)\n        tctx.server.sni = \"wrong.host.mitmproxy.org\"\n\n        tssl = SSLTest(server_side=True)\n\n        # send ClientHello\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, b\"open-connection\")\n            << layer.NextLayerHook(tutils.Placeholder())\n            >> tutils.reply_next_layer(TlsEchoLayer)\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n            << tls.TlsStartServerHook(tutils.Placeholder())\n            >> reply_tls_start_server()\n            << commands.SendData(tctx.server, data)\n        )\n\n        # receive ServerHello, finish client handshake\n        tssl.bio_write(data())\n        with pytest.raises(ssl.SSLWantReadError):\n            tssl.do_handshake()\n\n        tls_hook_data = tutils.Placeholder(TlsData)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.server, tssl.bio_read())\n            << commands.Log(\n                # different casing in OpenSSL < 3.0\n                StrMatching(\n                    \"Server TLS handshake failed. Certificate verify failed: [Hh]ostname mismatch\"\n                ),\n                WARNING,\n            )\n            << tls.TlsFailedServerHook(tls_hook_data)\n            >> tutils.reply()\n            << commands.CloseConnection(tctx.server)\n            << commands.SendData(\n                tctx.client,\n                # different casing in OpenSSL < 3.0\n                BytesMatching(\n                    b\"open-connection failed: Certificate verify failed: [Hh]ostname mismatch\"\n                ),\n            )\n        )\n        assert (\n            tls_hook_data().conn.error.lower()\n            == \"Certificate verify failed: Hostname mismatch\".lower()\n        )\n        assert not tctx.server.tls_established\n\n    def test_remote_speaks_no_tls(self, tctx):\n        playbook = tutils.Playbook(tls.ServerTLSLayer(tctx))\n        tctx.server.state = ConnectionState.OPEN\n        tctx.server.sni = \"example.mitmproxy.org\"\n\n        # send ClientHello, receive random garbage back\n        data = tutils.Placeholder(bytes)\n        tls_hook_data = tutils.Placeholder(TlsData)\n        assert (\n            playbook\n            << tls.TlsStartServerHook(tutils.Placeholder())\n            >> reply_tls_start_server()\n            << commands.SendData(tctx.server, data)\n            >> events.DataReceived(tctx.server, b\"HTTP/1.1 404 Not Found\\r\\n\")\n            << commands.Log(\n                \"Server TLS handshake failed. The remote server does not speak TLS.\",\n                WARNING,\n            )\n            << tls.TlsFailedServerHook(tls_hook_data)\n            >> tutils.reply()\n            << commands.CloseConnection(tctx.server)\n        )\n        assert tls_hook_data().conn.error == \"The remote server does not speak TLS.\"\n\n    def test_unsupported_protocol(self, tctx: context.Context):\n        \"\"\"Test the scenario where the server only supports an outdated TLS version by default.\"\"\"\n        playbook = tutils.Playbook(tls.ServerTLSLayer(tctx))\n        tctx.server.address = (\"example.mitmproxy.org\", 443)\n        tctx.server.state = ConnectionState.OPEN\n        tctx.server.sni = \"example.mitmproxy.org\"\n\n        # noinspection PyTypeChecker\n        tssl = SSLTest(server_side=True, max_ver=ssl.TLSVersion.TLSv1_2)\n\n        # send ClientHello\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            << tls.TlsStartServerHook(tutils.Placeholder())\n            >> reply_tls_start_server()\n            << commands.SendData(tctx.server, data)\n        )\n\n        # receive ServerHello\n        tssl.bio_write(data())\n        with pytest.raises(ssl.SSLError):\n            tssl.do_handshake()\n\n        # send back error\n        tls_hook_data = tutils.Placeholder(TlsData)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.server, tssl.bio_read())\n            << commands.Log(\n                \"Server TLS handshake failed. The remote server and mitmproxy cannot agree on a TLS version\"\n                \" to use. You may need to adjust mitmproxy's tls_version_server_min option.\",\n                WARNING,\n            )\n            << tls.TlsFailedServerHook(tls_hook_data)\n            >> tutils.reply()\n            << commands.CloseConnection(tctx.server)\n        )\n        assert tls_hook_data().conn.error\n\n\ndef make_client_tls_layer(\n    tctx: context.Context, **kwargs\n) -> tuple[tutils.Playbook, tls.ClientTLSLayer, SSLTest]:\n    # This is a bit contrived as the client layer expects a server layer as parent.\n    # We also set child layers manually to avoid NextLayer noise.\n    server_layer = tls.ServerTLSLayer(tctx)\n    client_layer = tls.ClientTLSLayer(tctx)\n    server_layer.child_layer = client_layer\n    client_layer.child_layer = TlsEchoLayer(tctx)\n    playbook = tutils.Playbook(server_layer)\n\n    # Add some server config, this is needed anyways.\n    tctx.server.__dict__[\"address\"] = (\n        \"example.mitmproxy.org\",\n        443,\n    )  # .address fails because connection is open\n    tctx.server.sni = \"example.mitmproxy.org\"\n\n    tssl_client = SSLTest(**kwargs)\n    # Start handshake.\n    with pytest.raises(ssl.SSLWantReadError):\n        tssl_client.do_handshake()\n\n    return playbook, client_layer, tssl_client\n\n\nclass TestClientTLS:\n    def test_client_only(self, tctx: context.Context):\n        \"\"\"Test TLS with client only\"\"\"\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx)\n        client_layer.debug = \"  \"\n        assert not tctx.client.tls_established\n\n        # Send ClientHello, receive ServerHello\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.bio_read())\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply()\n            << tls.TlsStartClientHook(tutils.Placeholder())\n            >> reply_tls_start_client()\n            << commands.SendData(tctx.client, data)\n        )\n        tssl_client.bio_write(data())\n        tssl_client.do_handshake()\n        # Finish Handshake\n        finish_handshake(playbook, tctx.client, tssl_client)\n\n        assert tssl_client.obj.getpeercert(True)\n        assert tctx.client.tls_established\n\n        # Echo\n        _test_echo(playbook, tssl_client, tctx.client)\n        other_server = Server(address=None)\n        assert (\n            playbook\n            >> events.DataReceived(other_server, b\"Plaintext\")\n            << commands.SendData(other_server, b\"plaintext\")\n        )\n\n    @pytest.mark.parametrize(\"server_state\", [\"open\", \"closed\"])\n    def test_server_required(self, tctx, server_state):\n        \"\"\"\n        Test the scenario where a server connection is required (for example, because of an unknown ALPN)\n        to establish TLS with the client.\n        \"\"\"\n        if server_state == \"open\":\n            tctx.server.state = ConnectionState.OPEN\n        tssl_server = SSLTest(server_side=True, alpn=[\"quux\"])\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx, alpn=[\"quux\"])\n\n        # We should now get instructed to open a server connection.\n        data = tutils.Placeholder(bytes)\n\n        def require_server_conn(client_hello: ClientHelloData) -> None:\n            client_hello.establish_server_tls_first = True\n\n        (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.bio_read())\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply(side_effect=require_server_conn)\n        )\n        if server_state == \"closed\":\n            playbook << commands.OpenConnection(tctx.server)\n            playbook >> tutils.reply(None)\n        assert (\n            playbook\n            << tls.TlsStartServerHook(tutils.Placeholder())\n            >> reply_tls_start_server(alpn=b\"quux\")\n            << commands.SendData(tctx.server, data)\n        )\n\n        # Establish TLS with the server...\n        tssl_server.bio_write(data())\n        with pytest.raises(ssl.SSLWantReadError):\n            tssl_server.do_handshake()\n\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.server, tssl_server.bio_read())\n            << tls.TlsEstablishedServerHook(tutils.Placeholder())\n            >> tutils.reply()\n            << commands.SendData(tctx.server, data)\n            << tls.TlsStartClientHook(tutils.Placeholder())\n        )\n        tssl_server.bio_write(data())\n        assert tctx.server.tls_established\n        # Server TLS is established, we can now reply to the client handshake...\n\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            >> reply_tls_start_client(alpn=b\"quux\")\n            << commands.SendData(tctx.client, data)\n        )\n        tssl_client.bio_write(data())\n        tssl_client.do_handshake()\n        finish_handshake(playbook, tctx.client, tssl_client)\n\n        # Both handshakes completed!\n        assert tctx.client.tls_established\n        assert tctx.server.tls_established\n        assert tctx.server.sni == tctx.client.sni\n        assert tctx.client.alpn == b\"quux\"\n        assert tctx.server.alpn == b\"quux\"\n        _test_echo(playbook, tssl_server, tctx.server)\n        _test_echo(playbook, tssl_client, tctx.client)\n\n    @pytest.mark.parametrize(\"server_state\", [\"open\", \"closed\"])\n    def test_passthrough_from_clienthello(self, tctx, server_state):\n        \"\"\"\n        Test the scenario where the connection is moved to passthrough mode in the tls_clienthello hook.\n        \"\"\"\n        if server_state == \"open\":\n            tctx.server.timestamp_start = time.time()\n            tctx.server.state = ConnectionState.OPEN\n\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx, alpn=[\"quux\"])\n\n        def make_passthrough(client_hello: ClientHelloData) -> None:\n            client_hello.ignore_connection = True\n\n        client_hello = tssl_client.bio_read()\n        (\n            playbook\n            >> events.DataReceived(tctx.client, client_hello)\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply(side_effect=make_passthrough)\n        )\n        if server_state == \"closed\":\n            playbook << commands.OpenConnection(tctx.server)\n            playbook >> tutils.reply(None)\n        assert (\n            playbook\n            << commands.SendData(tctx.server, client_hello)  # passed through unmodified\n            >> events.DataReceived(\n                tctx.server, b\"ServerHello\"\n            )  # and the same for the serverhello.\n            << commands.SendData(tctx.client, b\"ServerHello\")\n        )\n\n    def test_cannot_parse_clienthello(self, tctx: context.Context):\n        \"\"\"Test the scenario where we cannot parse the ClientHello\"\"\"\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx)\n        tls_hook_data = tutils.Placeholder(TlsData)\n\n        invalid = b\"\\x16\\x03\\x01\\x00\\x00\"\n\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, invalid)\n            << commands.Log(\n                f\"Client TLS handshake failed. Cannot parse ClientHello: {invalid.hex()}\",\n                level=WARNING,\n            )\n            << tls.TlsFailedClientHook(tls_hook_data)\n            >> tutils.reply()\n            << commands.CloseConnection(tctx.client)\n        )\n        assert tls_hook_data().conn.error\n        assert not tctx.client.tls_established\n\n        # Make sure that an active server connection does not cause child layers to spawn.\n        client_layer.debug = \"\"\n        assert (\n            playbook\n            >> events.DataReceived(Server(address=None), b\"data on other stream\")\n            << commands.Log(\">> DataReceived(server, b'data on other stream')\", DEBUG)\n            << commands.Log(\n                \"[tls] Swallowing DataReceived(server, b'data on other stream') as handshake failed.\",\n                DEBUG,\n            )\n        )\n\n    def test_mitmproxy_ca_is_untrusted(self, tctx: context.Context):\n        \"\"\"Test the scenario where the client doesn't trust the mitmproxy CA.\"\"\"\n        playbook, client_layer, tssl_client = make_client_tls_layer(\n            tctx, sni=b\"wrong.host.mitmproxy.org\"\n        )\n        playbook.logs = True\n\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.bio_read())\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply()\n            << tls.TlsStartClientHook(tutils.Placeholder())\n            >> reply_tls_start_client()\n            << commands.SendData(tctx.client, data)\n        )\n        tssl_client.bio_write(data())\n        with pytest.raises(ssl.SSLCertVerificationError):\n            tssl_client.do_handshake()\n        # Finish Handshake\n        tls_hook_data = tutils.Placeholder(TlsData)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.bio_read())\n            << commands.Log(\n                tutils.StrMatching(\n                    \"Client TLS handshake failed. The client does not trust the proxy's certificate \"\n                    \"for wrong.host.mitmproxy.org\"\n                ),\n                WARNING,\n            )\n            << tls.TlsFailedClientHook(tls_hook_data)\n            >> tutils.reply()\n            << commands.CloseConnection(tctx.client)\n            >> events.ConnectionClosed(tctx.client)\n        )\n        assert not tctx.client.tls_established\n        assert tls_hook_data().conn.error\n\n    @pytest.mark.parametrize(\n        \"close_at\", [\"tls_clienthello\", \"tls_start_client\", \"handshake\"]\n    )\n    def test_immediate_disconnect(self, tctx: context.Context, close_at):\n        \"\"\"Test the scenario where the client is disconnecting during the handshake.\n        This may happen because they are not interested in the connection anymore, or because they do not like\n        the proxy certificate.\"\"\"\n        playbook, client_layer, tssl_client = make_client_tls_layer(\n            tctx, sni=b\"wrong.host.mitmproxy.org\"\n        )\n        playbook.logs = True\n        tls_hook_data = tutils.Placeholder(TlsData)\n\n        playbook >> events.DataReceived(tctx.client, tssl_client.bio_read())\n        playbook << tls.TlsClienthelloHook(tutils.Placeholder())\n\n        if close_at == \"tls_clienthello\":\n            assert (\n                playbook\n                >> events.ConnectionClosed(tctx.client)\n                >> tutils.reply(to=-2)\n                << tls.TlsStartClientHook(tutils.Placeholder())\n                >> reply_tls_start_client()\n                << tls.TlsFailedClientHook(tls_hook_data)\n                >> tutils.reply()\n                << commands.CloseConnection(tctx.client)\n            )\n            assert tls_hook_data().conn.error\n            return\n\n        playbook >> tutils.reply()\n        playbook << tls.TlsStartClientHook(tutils.Placeholder())\n\n        if close_at == \"tls_start_client\":\n            assert (\n                playbook\n                >> events.ConnectionClosed(tctx.client)\n                >> reply_tls_start_client(to=-2)\n                << tls.TlsFailedClientHook(tls_hook_data)\n                >> tutils.reply()\n                << commands.CloseConnection(tctx.client)\n            )\n            assert tls_hook_data().conn.error\n            return\n\n        assert (\n            playbook\n            >> reply_tls_start_client()\n            << commands.SendData(tctx.client, tutils.Placeholder())\n            >> events.ConnectionClosed(tctx.client)\n            << commands.Log(\n                \"Client TLS handshake failed. The client disconnected during the handshake. \"\n                \"If this happens consistently for wrong.host.mitmproxy.org, this may indicate that the \"\n                \"client does not trust the proxy's certificate.\"\n            )\n            << tls.TlsFailedClientHook(tls_hook_data)\n            >> tutils.reply()\n            << commands.CloseConnection(tctx.client)\n        )\n        assert tls_hook_data().conn.error\n\n    def test_unsupported_protocol(self, tctx: context.Context):\n        \"\"\"Test the scenario where the client only supports an outdated TLS version by default.\"\"\"\n        playbook, client_layer, tssl_client = make_client_tls_layer(\n            tctx, max_ver=ssl.TLSVersion.TLSv1_2\n        )\n        playbook.logs = True\n\n        tls_hook_data = tutils.Placeholder(TlsData)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.bio_read())\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply()\n            << tls.TlsStartClientHook(tutils.Placeholder())\n            >> reply_tls_start_client()\n            << commands.Log(\n                \"Client TLS handshake failed. Client and mitmproxy cannot agree on a TLS version to \"\n                \"use. You may need to adjust mitmproxy's tls_version_client_min option.\",\n                WARNING,\n            )\n            << tls.TlsFailedClientHook(tls_hook_data)\n            >> tutils.reply()\n            << commands.CloseConnection(tctx.client)\n        )\n        assert tls_hook_data().conn.error\n\n\ndef test_dtls_record_contents():\n    data = bytes.fromhex(\n        \"16fefd00000000000000000002beef\" \"16fefd00000000000000000001ff\"\n    )\n    assert list(tls.dtls_handshake_record_contents(data)) == [b\"\\xbe\\xef\", b\"\\xff\"]\n    for i in range(12):\n        assert list(tls.dtls_handshake_record_contents(data[:i])) == []\n\n\ndef test__dtls_record_contents_err():\n    with pytest.raises(ValueError, match=\"Expected DTLS record\"):\n        next(tls.dtls_handshake_record_contents(b\"GET /this-will-cause-error\"))\n\n    empty_record = bytes.fromhex(\"16fefd00000000000000000000\")\n    with pytest.raises(ValueError, match=\"Record must not be empty\"):\n        next(tls.dtls_handshake_record_contents(empty_record))\n\n\ndtls_client_hello_no_extensions = bytes.fromhex(\n    \"010000360000000000000036fefd62be32f048777da890ddd213b0cb8dc3e2903f88dda1cd5f67808e1169110e840000000\"\n    \"cc02bc02fc00ac014c02cc03001000000\"\n)\ndtls_client_hello_with_extensions = bytes.fromhex(\n    \"16fefd00000000000000000085\"  # record layer\n    \"010000790000000000000079\"  # hanshake layer\n    \"fefd62bf0e0bf809df43e7669197be831919878b1a72c07a584d3c0a8ca6665878010000000cc02bc02fc00ac014c02cc0\"\n    \"3001000043000d0010000e0403050306030401050106010807ff01000100000a00080006001d00170018000b00020100001\"\n    \"7000000000010000e00000b6578616d706c652e636f6d\"\n)\n\n\ndef test_dtls_get_client_hello():\n    single_record = (\n        bytes.fromhex(\"16fefd00000000000000000042\") + dtls_client_hello_no_extensions\n    )\n    assert tls.get_dtls_client_hello(single_record) == dtls_client_hello_no_extensions\n\n    split_over_two_records = (\n        bytes.fromhex(\"16fefd00000000000000000020\")\n        + dtls_client_hello_no_extensions[:32]\n        + bytes.fromhex(\"16fefd00000000000000000022\")\n        + dtls_client_hello_no_extensions[32:]\n    )\n    assert (\n        tls.get_dtls_client_hello(split_over_two_records)\n        == dtls_client_hello_no_extensions\n    )\n\n    incomplete = split_over_two_records[:42]\n    assert tls.get_dtls_client_hello(incomplete) is None\n\n\ndef test_dtls_parse_client_hello():\n    assert (\n        tls.dtls_parse_client_hello(dtls_client_hello_with_extensions).sni\n        == \"example.com\"\n    )\n    assert tls.dtls_parse_client_hello(dtls_client_hello_with_extensions[:50]) is None\n    with pytest.raises(ValueError):\n        tls.dtls_parse_client_hello(\n            # Server Name Length longer than actual Server Name\n            dtls_client_hello_with_extensions[:-16]\n            + b\"\\x00\\x0e\\x00\\x00\\x20\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n        )\n", "test/mitmproxy/proxy/layers/test_dns.py": "import struct\nimport time\n\nimport pytest\nfrom hypothesis import given\nfrom hypothesis import HealthCheck\nfrom hypothesis import settings\nfrom hypothesis import strategies as st\n\nfrom ..tutils import Placeholder\nfrom ..tutils import Playbook\nfrom ..tutils import reply\nfrom mitmproxy.dns import DNSFlow\nfrom mitmproxy.proxy.commands import CloseConnection\nfrom mitmproxy.proxy.commands import Log\nfrom mitmproxy.proxy.commands import OpenConnection\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.events import ConnectionClosed\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.layers import dns\nfrom mitmproxy.test.tutils import tdnsreq\nfrom mitmproxy.test.tutils import tdnsresp\n\n\n@settings(suppress_health_check=[HealthCheck.function_scoped_fixture])\n@given(st.binary())\ndef test_fuzz_unpack_tcp_message(tctx, data):\n    layer = dns.DNSLayer(tctx)\n    try:\n        layer.unpack_message(data, True)\n    except struct.error:\n        pass\n\n\n@settings(suppress_health_check=[HealthCheck.function_scoped_fixture])\n@given(st.binary())\ndef test_fuzz_unpack_udp_message(tctx, data):\n    tctx.client.transport_protocol = \"udp\"\n    tctx.server.transport_protocol = \"udp\"\n\n    layer = dns.DNSLayer(tctx)\n    try:\n        layer.unpack_message(data, True)\n    except struct.error:\n        pass\n\n\n@pytest.mark.parametrize(\"transport_protocol\", [\"tcp\", \"udp\"])\ndef test_invalid_and_dummy_end(tctx, transport_protocol):\n    tctx.client.transport_protocol = transport_protocol\n    tctx.server.transport_protocol = transport_protocol\n\n    data = b\"Not a DNS packet\"\n    if tctx.client.transport_protocol == \"tcp\":\n        data = struct.pack(\"!H\", len(data)) + data\n\n    assert (\n        Playbook(dns.DNSLayer(tctx))\n        >> DataReceived(tctx.client, data)\n        << Log(\n            \"Client(client:1234, state=open) sent an invalid message: question #0: unpack encountered a label of length 99\"\n        )\n        << CloseConnection(tctx.client)\n        >> ConnectionClosed(tctx.client)\n    )\n\n\n@pytest.mark.parametrize(\"transport_protocol\", [\"tcp\", \"udp\"])\ndef test_regular(tctx, transport_protocol):\n    tctx.client.transport_protocol = transport_protocol\n    tctx.server.transport_protocol = transport_protocol\n\n    f = Placeholder(DNSFlow)\n\n    req = tdnsreq()\n    resp = tdnsresp()\n\n    def resolve(flow: DNSFlow):\n        nonlocal req, resp\n        assert flow.request\n        req.timestamp = flow.request.timestamp\n        assert flow.request == req\n        resp.timestamp = time.time()\n        flow.response = resp\n\n    assert (\n        Playbook(dns.DNSLayer(tctx))\n        >> DataReceived(tctx.client, dns.pack_message(req, transport_protocol))\n        << dns.DnsRequestHook(f)\n        >> reply(side_effect=resolve)\n        << dns.DnsResponseHook(f)\n        >> reply()\n        << SendData(tctx.client, dns.pack_message(resp, transport_protocol))\n        >> ConnectionClosed(tctx.client)\n        << None\n    )\n    assert f().request == req\n    assert f().response == resp\n    assert not f().live\n\n\n@pytest.mark.parametrize(\"transport_protocol\", [\"tcp\", \"udp\"])\ndef test_regular_mode_no_hook(tctx, transport_protocol):\n    tctx.client.transport_protocol = transport_protocol\n    tctx.server.transport_protocol = transport_protocol\n\n    f = Placeholder(DNSFlow)\n    layer = dns.DNSLayer(tctx)\n    layer.context.server.address = None\n\n    req = tdnsreq()\n\n    def no_resolve(flow: DNSFlow):\n        nonlocal req\n        assert flow.request\n        req.timestamp = flow.request.timestamp\n        assert flow.request == req\n\n    assert (\n        Playbook(layer)\n        >> DataReceived(\n            tctx.client, dns.pack_message(req, tctx.client.transport_protocol)\n        )\n        << dns.DnsRequestHook(f)\n        >> reply(side_effect=no_resolve)\n        << dns.DnsErrorHook(f)\n        >> reply()\n        >> ConnectionClosed(tctx.client)\n        << None\n    )\n    assert f().request == req\n    assert not f().response\n    assert not f().live\n\n\n@pytest.mark.parametrize(\"transport_protocol\", [\"tcp\", \"udp\"])\ndef test_reverse_premature_close(tctx, transport_protocol):\n    tctx.client.transport_protocol = transport_protocol\n    tctx.server.transport_protocol = transport_protocol\n\n    f = Placeholder(DNSFlow)\n    layer = dns.DNSLayer(tctx)\n    layer.context.server.address = (\"8.8.8.8\", 53)\n\n    req = tdnsreq()\n\n    assert (\n        Playbook(layer)\n        >> DataReceived(\n            tctx.client, dns.pack_message(req, tctx.client.transport_protocol)\n        )\n        << dns.DnsRequestHook(f)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        << SendData(tctx.server, dns.pack_message(req, tctx.server.transport_protocol))\n        >> ConnectionClosed(tctx.client)\n        << CloseConnection(tctx.server)\n        << None\n    )\n    assert f().request\n    assert not f().response\n    assert not f().live\n    req.timestamp = f().request.timestamp\n    assert f().request == req\n\n\n@pytest.mark.parametrize(\"transport_protocol\", [\"tcp\", \"udp\"])\ndef test_reverse(tctx, transport_protocol):\n    tctx.client.transport_protocol = transport_protocol\n    tctx.server.transport_protocol = transport_protocol\n\n    f = Placeholder(DNSFlow)\n    layer = dns.DNSLayer(tctx)\n    layer.context.server.address = (\"8.8.8.8\", 53)\n\n    req = tdnsreq()\n    resp = tdnsresp()\n\n    assert (\n        Playbook(layer)\n        >> DataReceived(\n            tctx.client, dns.pack_message(req, tctx.client.transport_protocol)\n        )\n        << dns.DnsRequestHook(f)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        << SendData(tctx.server, dns.pack_message(req, tctx.server.transport_protocol))\n        >> DataReceived(\n            tctx.server, dns.pack_message(resp, tctx.server.transport_protocol)\n        )\n        << dns.DnsResponseHook(f)\n        >> reply()\n        << SendData(tctx.client, dns.pack_message(resp, tctx.client.transport_protocol))\n        >> ConnectionClosed(tctx.client)\n        << CloseConnection(tctx.server)\n        << None\n    )\n    assert f().request\n    assert f().response\n    assert not f().live\n    req.timestamp = f().request.timestamp\n    resp.timestamp = f().response.timestamp\n    assert f().request == req and f().response == resp\n\n\n@pytest.mark.parametrize(\"transport_protocol\", [\"tcp\", \"udp\"])\ndef test_reverse_fail_connection(tctx, transport_protocol):\n    tctx.client.transport_protocol = transport_protocol\n    tctx.server.transport_protocol = transport_protocol\n\n    f = Placeholder(DNSFlow)\n    layer = dns.DNSLayer(tctx)\n    layer.context.server.address = (\"8.8.8.8\", 53)\n\n    req = tdnsreq()\n\n    assert (\n        Playbook(layer)\n        >> DataReceived(\n            tctx.client, dns.pack_message(req, tctx.client.transport_protocol)\n        )\n        << dns.DnsRequestHook(f)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(\"UDP no likey today.\")\n        << dns.DnsErrorHook(f)\n        >> reply()\n        << None\n    )\n    assert f().request\n    assert not f().response\n    assert f().error.msg == \"UDP no likey today.\"\n    req.timestamp = f().request.timestamp\n    assert f().request == req\n\n\n@pytest.mark.parametrize(\"transport_protocol\", [\"tcp\", \"udp\"])\ndef test_reverse_with_query_resend(tctx, transport_protocol):\n    tctx.client.transport_protocol = transport_protocol\n    tctx.server.transport_protocol = transport_protocol\n\n    f = Placeholder(DNSFlow)\n    layer = dns.DNSLayer(tctx)\n    layer.context.server.address = (\"8.8.8.8\", 53)\n\n    req = tdnsreq()\n    req2 = tdnsreq()\n    req2.reserved = 4\n    resp = tdnsresp()\n\n    assert (\n        Playbook(layer)\n        >> DataReceived(\n            tctx.client, dns.pack_message(req, tctx.client.transport_protocol)\n        )\n        << dns.DnsRequestHook(f)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        << SendData(tctx.server, dns.pack_message(req, tctx.server.transport_protocol))\n        >> DataReceived(\n            tctx.client, dns.pack_message(req2, tctx.client.transport_protocol)\n        )\n        << dns.DnsRequestHook(f)\n        >> reply()\n        << SendData(tctx.server, dns.pack_message(req2, tctx.server.transport_protocol))\n        >> DataReceived(\n            tctx.server, dns.pack_message(resp, tctx.server.transport_protocol)\n        )\n        << dns.DnsResponseHook(f)\n        >> reply()\n        << SendData(tctx.client, dns.pack_message(resp, tctx.client.transport_protocol))\n        >> ConnectionClosed(tctx.client)\n        << CloseConnection(tctx.server)\n        << None\n    )\n    assert f().request\n    assert f().response\n    assert not f().live\n    req2.timestamp = f().request.timestamp\n    resp.timestamp = f().response.timestamp\n    assert f().request == req2\n    assert f().response == resp\n\n\ndef test_tcp_message_over_multiple_events(tctx):\n    tctx.client.transport_protocol = \"tcp\"\n    tctx.server.transport_protocol = \"tcp\"\n\n    layer = dns.DNSLayer(tctx)\n    layer.context.server.address = (\"8.8.8.8\", 53)\n    f = Placeholder(DNSFlow)\n    req = tdnsreq()\n    resp = tdnsresp()\n    resp_bytes = dns.pack_message(resp, tctx.client.transport_protocol)\n    split = len(resp_bytes) // 2\n\n    assert (\n        Playbook(layer)\n        >> DataReceived(\n            tctx.client, dns.pack_message(req, tctx.client.transport_protocol)\n        )\n        << dns.DnsRequestHook(f)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        << SendData(tctx.server, dns.pack_message(req, tctx.server.transport_protocol))\n        >> DataReceived(tctx.server, resp_bytes[:split])\n        >> DataReceived(tctx.server, resp_bytes[split:])\n        << dns.DnsResponseHook(f)\n        >> reply()\n        << SendData(tctx.client, dns.pack_message(resp, tctx.client.transport_protocol))\n        >> ConnectionClosed(tctx.client)\n        << CloseConnection(tctx.server)\n        << None\n    )\n\n\ndef test_query_pipelining_same_event(tctx):\n    tctx.client.transport_protocol = \"tcp\"\n    tctx.server.transport_protocol = \"tcp\"\n\n    layer = dns.DNSLayer(tctx)\n    layer.context.server.address = (\"8.8.8.8\", 53)\n    f1 = Placeholder(DNSFlow)\n    f2 = Placeholder(DNSFlow)\n    req1 = tdnsreq(id=1)\n    req2 = tdnsreq(id=2)\n    resp1 = tdnsresp(id=1)\n    resp2 = tdnsresp(id=2)\n    req_bytes = dns.pack_message(\n        req1, tctx.client.transport_protocol\n    ) + dns.pack_message(req2, tctx.client.transport_protocol)\n\n    assert (\n        Playbook(layer)\n        >> DataReceived(tctx.client, req_bytes)\n        << dns.DnsRequestHook(f1)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        << SendData(tctx.server, dns.pack_message(req1, tctx.server.transport_protocol))\n        << dns.DnsRequestHook(f2)\n        >> reply()\n        << SendData(tctx.server, dns.pack_message(req2, tctx.server.transport_protocol))\n        >> DataReceived(\n            tctx.server, dns.pack_message(resp1, tctx.server.transport_protocol)\n        )\n        << dns.DnsResponseHook(f1)\n        >> reply()\n        << SendData(\n            tctx.client, dns.pack_message(resp1, tctx.server.transport_protocol)\n        )\n        >> DataReceived(\n            tctx.server, dns.pack_message(resp2, tctx.server.transport_protocol)\n        )\n        << dns.DnsResponseHook(f2)\n        >> reply()\n        << SendData(\n            tctx.client, dns.pack_message(resp2, tctx.server.transport_protocol)\n        )\n        >> ConnectionClosed(tctx.client)\n        << CloseConnection(tctx.server)\n        << None\n    )\n\n\ndef test_query_pipelining_multiple_events(tctx):\n    tctx.client.transport_protocol = \"tcp\"\n    tctx.server.transport_protocol = \"tcp\"\n\n    layer = dns.DNSLayer(tctx)\n    layer.context.server.address = (\"8.8.8.8\", 53)\n    f1 = Placeholder(DNSFlow)\n    f2 = Placeholder(DNSFlow)\n    req1 = tdnsreq(id=1)\n    req2 = tdnsreq(id=2)\n    resp1 = tdnsresp(id=1)\n    resp2 = tdnsresp(id=2)\n    req_bytes = dns.pack_message(\n        req1, tctx.client.transport_protocol\n    ) + dns.pack_message(req2, tctx.client.transport_protocol)\n    split = len(req_bytes) * 3 // 4\n\n    assert (\n        Playbook(layer)\n        >> DataReceived(tctx.client, req_bytes[:split])\n        << dns.DnsRequestHook(f1)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        << SendData(tctx.server, dns.pack_message(req1, tctx.server.transport_protocol))\n        >> DataReceived(\n            tctx.server, dns.pack_message(resp1, tctx.server.transport_protocol)\n        )\n        << dns.DnsResponseHook(f1)\n        >> reply()\n        << SendData(\n            tctx.client, dns.pack_message(resp1, tctx.server.transport_protocol)\n        )\n        >> DataReceived(tctx.client, req_bytes[split:])\n        << dns.DnsRequestHook(f2)\n        >> reply()\n        << SendData(tctx.server, dns.pack_message(req2, tctx.server.transport_protocol))\n        >> DataReceived(\n            tctx.server, dns.pack_message(resp2, tctx.server.transport_protocol)\n        )\n        << dns.DnsResponseHook(f2)\n        >> reply()\n        << SendData(\n            tctx.client, dns.pack_message(resp2, tctx.server.transport_protocol)\n        )\n        >> ConnectionClosed(tctx.client)\n        << CloseConnection(tctx.server)\n        << None\n    )\n\n\ndef test_invalid_tcp_message_length(tctx):\n    tctx.client.transport_protocol = \"tcp\"\n    tctx.server.transport_protocol = \"tcp\"\n\n    assert (\n        Playbook(dns.DNSLayer(tctx))\n        >> DataReceived(tctx.client, b\"\\x00\\x00\")\n        << Log(\n            \"Client(client:1234, state=open) sent an invalid message: Message length field cannot be zero\"\n        )\n        << CloseConnection(tctx.client)\n        >> ConnectionClosed(tctx.client)\n    )\n", "test/mitmproxy/proxy/layers/test_tls_fuzz.py": "from hypothesis import example\nfrom hypothesis import given\nfrom hypothesis.strategies import binary\nfrom hypothesis.strategies import integers\n\nfrom mitmproxy.proxy.layers.tls import parse_client_hello\nfrom mitmproxy.tls import ClientHello\n\nclient_hello_with_extensions = bytes.fromhex(\n    \"16030300bb\"  # record layer\n    \"010000b7\"  # handshake layer\n    \"03033b70638d2523e1cba15f8364868295305e9c52aceabda4b5147210abc783e6e1000022c02bc02fc02cc030\"\n    \"cca9cca8cc14cc13c009c013c00ac014009c009d002f0035000a0100006cff0100010000000010000e00000b65\"\n    \"78616d706c652e636f6d0017000000230000000d00120010060106030501050304010403020102030005000501\"\n    \"00000000001200000010000e000c02683208687474702f312e3175500000000b00020100000a00080006001d00\"\n    \"170018\"\n)\n\n\n@given(i=integers(0, len(client_hello_with_extensions)), data=binary())\n@example(i=183, data=b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\")\ndef test_fuzz_parse_client_hello(i, data):\n    try:\n        ch = parse_client_hello(client_hello_with_extensions[:i] + data)\n    except ValueError:\n        pass\n    else:\n        assert ch is None or isinstance(ch, ClientHello)\n", "test/mitmproxy/proxy/layers/test_quic.py": "import ssl\nimport time\nfrom logging import DEBUG\nfrom logging import ERROR\nfrom logging import WARNING\nfrom typing import Literal\nfrom typing import TypeVar\nfrom unittest.mock import MagicMock\n\nimport pytest\nfrom aioquic.buffer import Buffer as QuicBuffer\nfrom aioquic.quic import events as quic_events\nfrom aioquic.quic.configuration import QuicConfiguration\nfrom aioquic.quic.connection import pull_quic_header\nfrom aioquic.quic.connection import QuicConnection\n\nfrom mitmproxy import connection\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy import layers\nfrom mitmproxy.proxy import tunnel\nfrom mitmproxy.proxy.layers import quic\nfrom mitmproxy.proxy.layers import tcp\nfrom mitmproxy.proxy.layers import tls\nfrom mitmproxy.proxy.layers import udp\nfrom mitmproxy.tcp import TCPFlow\nfrom mitmproxy.udp import UDPFlow\nfrom mitmproxy.udp import UDPMessage\nfrom mitmproxy.utils import data\nfrom test.mitmproxy.proxy import tutils\n\ntlsdata = data.Data(__name__)\n\n\nT = TypeVar(\"T\", bound=layer.Layer)\n\n\nclass DummyLayer(layer.Layer):\n    child_layer: layer.Layer | None\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        assert self.child_layer\n        return self.child_layer.handle_event(event)\n\n\nclass TlsEchoLayer(tutils.EchoLayer):\n    err: str | None = None\n    closed: quic.QuicConnectionClosed | None = None\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, events.DataReceived) and event.data == b\"open-connection\":\n            err = yield commands.OpenConnection(self.context.server)\n            if err:\n                yield commands.SendData(\n                    event.connection, f\"open-connection failed: {err}\".encode()\n                )\n        elif (\n            isinstance(event, events.DataReceived) and event.data == b\"close-connection\"\n        ):\n            yield commands.CloseConnection(event.connection)\n        elif (\n            isinstance(event, events.DataReceived)\n            and event.data == b\"close-connection-error\"\n        ):\n            yield quic.CloseQuicConnection(event.connection, 123, None, \"error\")\n        elif isinstance(event, events.DataReceived) and event.data == b\"stop-stream\":\n            yield quic.StopQuicStream(event.connection, 24, 123)\n        elif (\n            isinstance(event, events.DataReceived) and event.data == b\"invalid-command\"\n        ):\n\n            class InvalidConnectionCommand(commands.ConnectionCommand):\n                pass\n\n            yield InvalidConnectionCommand(event.connection)\n        elif (\n            isinstance(event, events.DataReceived)\n            and event.data == b\"invalid-stream-command\"\n        ):\n\n            class InvalidStreamCommand(quic.QuicStreamCommand):\n                pass\n\n            yield InvalidStreamCommand(event.connection, 42)\n        elif isinstance(event, quic.QuicConnectionClosed):\n            self.closed = event\n        elif isinstance(event, quic.QuicStreamDataReceived):\n            yield quic.SendQuicStreamData(\n                event.connection, event.stream_id, event.data, event.end_stream\n            )\n        elif isinstance(event, quic.QuicStreamReset):\n            yield quic.ResetQuicStream(\n                event.connection, event.stream_id, event.error_code\n            )\n        else:\n            yield from super()._handle_event(event)\n\n\nclient_hello = bytes.fromhex(\n    \"ca0000000108c0618c84b54541320823fcce946c38d8210044e6a93bbb283593f75ffb6f2696b16cfdcb5b1255\"\n    \"577b2af5fc5894188c9568bc65eef253faf7f0520e41341cfa81d6aae573586665ce4e1e41676364820402feec\"\n    \"a81f3d22dbb476893422069066104a43e121c951a08c53b83f960becf99cf5304d5bc5346f52f472bd1a04d192\"\n    \"0bae025064990d27e5e4c325ac46121d3acadebe7babdb96192fb699693d65e2b2e21c53beeb4f40b50673a2f6\"\n    \"c22091cb7c76a845384fedee58df862464d1da505a280bfef91ca83a10bebbcb07855219dbc14aecf8a48da049\"\n    \"d03c77459b39d5355c95306cd03d6bdb471694fa998ca3b1f875ce87915b88ead15c5d6313a443f39aad808922\"\n    \"57ddfa6b4a898d773bb6fb520ede47ebd59d022431b1054a69e0bbbdf9f0fb32fc8bcc4b6879dd8cd5389474b1\"\n    \"99e18333e14d0347740a11916429a818bb8d93295d36e99840a373bb0e14c8b3adcf5e2165e70803f15316fd5e\"\n    \"5eeec04ae68d98f1adb22c54611c80fcd8ece619dbdf97b1510032ec374b7a71f94d9492b8b8cb56f56556dd97\"\n    \"edf1e50fa90e868ff93636a365678bdf3ee3f8e632588cd506b6f44fbfd4d99988238fbd5884c98f6a124108c1\"\n    \"878970780e42b111e3be6215776ef5be5a0205915e6d720d22c6a81a475c9e41ba94e4983b964cb5c8e1f40607\"\n    \"76d1d8d1adcef7587ea084231016bd6ee2643d11a3a35eb7fe4cca2b3f1a4b21e040b0d426412cca6c4271ea63\"\n    \"fb54ed7f57b41cd1af1be5507f87ea4f4a0c997367e883291de2f1b8a49bdaa52bae30064351b1139703400730\"\n    \"18a4104344ec6b4454b50a42e804bc70e78b9b3c82497273859c82ed241b643642d76df6ceab8f916392113a62\"\n    \"b231f228c7300624d74a846bec2f479ab8a8c3461f91c7bf806236e3bd2f54ba1ef8e2a1e0bfdde0c5ad227f7d\"\n    \"364c52510b1ade862ce0c8d7bd24b6d7d21c99b34de6d177eb3d575787b2af55060d76d6c2060befbb7953a816\"\n    \"6f66ad88ecf929dbb0ad3a16cf7dfd39d925e0b4b649c6d0c07ad46ed0229c17fb6a1395f16e1b138aab3af760\"\n    \"2b0ac762c4f611f7f3468997224ffbe500a7c53f92f65e41a3765a9f1d7e3f78208f5b4e147962d8c97d6c1a80\"\n    \"91ffc36090b2043d71853616f34c2185dc883c54ab6d66e10a6c18e0b9a4742597361f8554a42da3373241d0c8\"\n    \"54119bfadccffaf2335b2d97ffee627cb891bda8140a39399f853da4859f7e19682e152243efbaffb662edd19b\"\n    \"3819a74107c7dbe05ecb32e79dcdb1260f153b1ef133e978ccca3d9e400a7ed6c458d77e2956d2cb897b7a298b\"\n    \"fe144b5defdc23dfd2adf69f1fb0917840703402d524987ae3b1dcb85229843c9a419ef46e1ba0ba7783f2a2ec\"\n    \"d057a57518836aef2a7839ebd3688da98b54c942941f642e434727108d59ea25875b3050ca53d4637c76cbcbb9\"\n    \"e972c2b0b781131ee0a1403138b55486fe86bbd644920ee6aa578e3bab32d7d784b5c140295286d90c99b14823\"\n    \"1487f7ea64157001b745aa358c9ea6bec5a8d8b67a7534ec1f7648ff3b435911dfc3dff798d32fbf2efe2c1fcc\"\n    \"278865157590572387b76b78e727d3e7682cb501cdcdf9a0f17676f99d9aa67f10edccc9a92080294e88bf28c2\"\n    \"a9f32ae535fdb27fff7706540472abb9eab90af12b2bea005da189874b0ca69e6ae1690a6f2adf75be3853c94e\"\n    \"fd8098ed579c20cb37be6885d8d713af4ba52958cee383089b98ed9cb26e11127cf88d1b7d254f15f7903dd7ed\"\n    \"297c0013924e88248684fe8f2098326ce51aa6e5\"\n)\n\n\ndef test_error_code_to_str():\n    assert quic.error_code_to_str(0x6) == \"FINAL_SIZE_ERROR\"\n    assert quic.error_code_to_str(0x104) == \"H3_CLOSED_CRITICAL_STREAM\"\n    assert quic.error_code_to_str(0xDEAD) == f\"unknown error (0xdead)\"\n\n\ndef test_is_success_error_code():\n    assert quic.is_success_error_code(0x0)\n    assert not quic.is_success_error_code(0x6)\n    assert quic.is_success_error_code(0x100)\n    assert not quic.is_success_error_code(0x104)\n    assert not quic.is_success_error_code(0xDEAD)\n\n\n@pytest.mark.parametrize(\"value\", [\"s1 s2\\n\", \"s1 s2\"])\ndef test_secrets_logger(value: str):\n    logger = MagicMock()\n    quic_logger = quic.QuicSecretsLogger(logger)\n    assert quic_logger.write(value) == 6\n    quic_logger.flush()\n    logger.assert_called_once_with(None, b\"s1 s2\")\n\n\nclass TestParseClientHello:\n    def test_input(self):\n        assert quic.quic_parse_client_hello(client_hello).sni == \"example.com\"\n        with pytest.raises(ValueError):\n            quic.quic_parse_client_hello(\n                client_hello[:183] + b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n            )\n        with pytest.raises(ValueError, match=\"not initial\"):\n            quic.quic_parse_client_hello(\n                b\"\\\\s\\xd8\\xd8\\xa5dT\\x8bc\\xd3\\xae\\x1c\\xb2\\x8a7-\\x1d\\x19j\\x85\\xb0~\\x8c\\x80\\xa5\\x8cY\\xac\\x0ecK\\x7fC2f\\xbcm\\x1b\\xac~\"\n            )\n\n    def test_invalid(self, monkeypatch):\n        class InvalidClientHello(Exception):\n            @property\n            def data(self):\n                raise EOFError()\n\n        monkeypatch.setattr(quic, \"QuicClientHello\", InvalidClientHello)\n        with pytest.raises(ValueError, match=\"Invalid ClientHello\"):\n            quic.quic_parse_client_hello(client_hello)\n\n    def test_connection_error(self, monkeypatch):\n        def raise_conn_err(self, data, addr, now):\n            raise quic.QuicConnectionError(0, 0, \"Conn err\")\n\n        monkeypatch.setattr(QuicConnection, \"receive_datagram\", raise_conn_err)\n        with pytest.raises(ValueError, match=\"Conn err\"):\n            quic.quic_parse_client_hello(client_hello)\n\n    def test_no_return(self):\n        with pytest.raises(ValueError, match=\"No ClientHello\"):\n            quic.quic_parse_client_hello(\n                client_hello[0:1200] + b\"\\x00\" + client_hello[1200:]\n            )\n\n\nclass TestQuicStreamLayer:\n    def test_ignored(self, tctx: context.Context):\n        quic_layer = quic.QuicStreamLayer(tctx, True, 1)\n        assert isinstance(quic_layer.child_layer, layers.TCPLayer)\n        assert not quic_layer.child_layer.flow\n        quic_layer.child_layer.flow = TCPFlow(tctx.client, tctx.server)\n        quic_layer.refresh_metadata()\n        assert quic_layer.child_layer.flow.metadata[\"quic_is_unidirectional\"] is False\n        assert quic_layer.child_layer.flow.metadata[\"quic_initiator\"] == \"server\"\n        assert quic_layer.child_layer.flow.metadata[\"quic_stream_id_client\"] == 1\n        assert quic_layer.child_layer.flow.metadata[\"quic_stream_id_server\"] is None\n        assert quic_layer.stream_id(True) == 1\n        assert quic_layer.stream_id(False) is None\n\n    def test_simple(self, tctx: context.Context):\n        quic_layer = quic.QuicStreamLayer(tctx, False, 2)\n        assert isinstance(quic_layer.child_layer, layer.NextLayer)\n        tunnel_layer = tunnel.TunnelLayer(tctx, tctx.client, tctx.server)\n        quic_layer.child_layer.layer = tunnel_layer\n        tcp_layer = layers.TCPLayer(tctx)\n        tunnel_layer.child_layer = tcp_layer\n        quic_layer.open_server_stream(3)\n        assert tcp_layer.flow.metadata[\"quic_is_unidirectional\"] is True\n        assert tcp_layer.flow.metadata[\"quic_initiator\"] == \"client\"\n        assert tcp_layer.flow.metadata[\"quic_stream_id_client\"] == 2\n        assert tcp_layer.flow.metadata[\"quic_stream_id_server\"] == 3\n        assert quic_layer.stream_id(True) == 2\n        assert quic_layer.stream_id(False) == 3\n\n\nclass TestRawQuicLayer:\n    @pytest.mark.parametrize(\"ignore\", [True, False])\n    def test_error(self, tctx: context.Context, ignore: bool):\n        quic_layer = quic.RawQuicLayer(tctx, ignore=ignore)\n        assert (\n            tutils.Playbook(quic_layer)\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(\"failed to open\")\n            << commands.CloseConnection(tctx.client)\n        )\n        assert quic_layer._handle_event == quic_layer.done\n\n    def test_ignored(self, tctx: context.Context):\n        quic_layer = quic.RawQuicLayer(tctx, ignore=True)\n        assert (\n            tutils.Playbook(quic_layer)\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n            >> events.DataReceived(tctx.client, b\"msg1\")\n            << commands.SendData(tctx.server, b\"msg1\")\n            >> events.DataReceived(tctx.server, b\"msg2\")\n            << commands.SendData(tctx.client, b\"msg2\")\n            >> quic.QuicStreamDataReceived(tctx.client, 0, b\"msg3\", end_stream=False)\n            << quic.SendQuicStreamData(tctx.server, 0, b\"msg3\", end_stream=False)\n            >> quic.QuicStreamDataReceived(tctx.client, 6, b\"msg4\", end_stream=False)\n            << quic.SendQuicStreamData(tctx.server, 2, b\"msg4\", end_stream=False)\n            >> quic.QuicStreamDataReceived(tctx.server, 9, b\"msg5\", end_stream=False)\n            << quic.SendQuicStreamData(tctx.client, 1, b\"msg5\", end_stream=False)\n            >> quic.QuicStreamDataReceived(tctx.client, 0, b\"\", end_stream=True)\n            << quic.SendQuicStreamData(tctx.server, 0, b\"\", end_stream=True)\n            >> quic.QuicStreamReset(tctx.client, 6, 142)\n            << quic.ResetQuicStream(tctx.server, 2, 142)\n            >> quic.QuicConnectionClosed(tctx.client, 42, None, \"closed\")\n            << quic.CloseQuicConnection(tctx.server, 42, None, \"closed\")\n            >> quic.QuicConnectionClosed(tctx.server, 42, None, \"closed\")\n            << None\n        )\n        assert quic_layer._handle_event == quic_layer.done\n\n    def test_msg_inject(self, tctx: context.Context):\n        udpflow = tutils.Placeholder(UDPFlow)\n        playbook = tutils.Playbook(quic.RawQuicLayer(tctx))\n        assert (\n            playbook\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n            >> events.DataReceived(tctx.client, b\"msg1\")\n            << layer.NextLayerHook(tutils.Placeholder())\n            >> tutils.reply_next_layer(udp.UDPLayer)\n            << udp.UdpStartHook(udpflow)\n            >> tutils.reply()\n            << udp.UdpMessageHook(udpflow)\n            >> tutils.reply()\n            << commands.SendData(tctx.server, b\"msg1\")\n            >> udp.UdpMessageInjected(udpflow, UDPMessage(True, b\"msg2\"))\n            << udp.UdpMessageHook(udpflow)\n            >> tutils.reply()\n            << commands.SendData(tctx.server, b\"msg2\")\n            >> udp.UdpMessageInjected(\n                UDPFlow((\"other\", 80), tctx.server), UDPMessage(True, b\"msg3\")\n            )\n            << udp.UdpMessageHook(udpflow)\n            >> tutils.reply()\n            << commands.SendData(tctx.server, b\"msg3\")\n        )\n        with pytest.raises(AssertionError, match=\"not associated\"):\n            playbook >> udp.UdpMessageInjected(\n                UDPFlow((\"notfound\", 0), (\"noexist\", 0)), UDPMessage(True, b\"msg2\")\n            )\n            assert playbook\n\n    def test_reset_with_end_hook(self, tctx: context.Context):\n        tcpflow = tutils.Placeholder(TCPFlow)\n        assert (\n            tutils.Playbook(quic.RawQuicLayer(tctx))\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n            >> quic.QuicStreamDataReceived(tctx.client, 2, b\"msg1\", end_stream=False)\n            << layer.NextLayerHook(tutils.Placeholder())\n            >> tutils.reply_next_layer(tcp.TCPLayer)\n            << tcp.TcpStartHook(tcpflow)\n            >> tutils.reply()\n            << tcp.TcpMessageHook(tcpflow)\n            >> tutils.reply()\n            << quic.SendQuicStreamData(tctx.server, 2, b\"msg1\", end_stream=False)\n            >> quic.QuicStreamReset(tctx.client, 2, 42)\n            << quic.ResetQuicStream(tctx.server, 2, 42)\n            << tcp.TcpEndHook(tcpflow)\n            >> tutils.reply()\n        )\n\n    def test_close_with_end_hooks(self, tctx: context.Context):\n        udpflow = tutils.Placeholder(UDPFlow)\n        tcpflow = tutils.Placeholder(TCPFlow)\n        assert (\n            tutils.Playbook(quic.RawQuicLayer(tctx))\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n            >> events.DataReceived(tctx.client, b\"msg1\")\n            << layer.NextLayerHook(tutils.Placeholder())\n            >> tutils.reply_next_layer(udp.UDPLayer)\n            << udp.UdpStartHook(udpflow)\n            >> tutils.reply()\n            << udp.UdpMessageHook(udpflow)\n            >> tutils.reply()\n            << commands.SendData(tctx.server, b\"msg1\")\n            >> quic.QuicStreamDataReceived(tctx.client, 2, b\"msg2\", end_stream=False)\n            << layer.NextLayerHook(tutils.Placeholder())\n            >> tutils.reply_next_layer(tcp.TCPLayer)\n            << tcp.TcpStartHook(tcpflow)\n            >> tutils.reply()\n            << tcp.TcpMessageHook(tcpflow)\n            >> tutils.reply()\n            << quic.SendQuicStreamData(tctx.server, 2, b\"msg2\", end_stream=False)\n            >> quic.QuicConnectionClosed(tctx.client, 42, None, \"bye\")\n            << quic.CloseQuicConnection(tctx.server, 42, None, \"bye\")\n            << udp.UdpEndHook(udpflow)\n            << tcp.TcpEndHook(tcpflow)\n            >> tutils.reply(to=-2)\n            >> tutils.reply(to=-2)\n            >> quic.QuicConnectionClosed(tctx.server, 42, None, \"bye\")\n        )\n\n    def test_invalid_stream_event(self, tctx: context.Context):\n        playbook = tutils.Playbook(quic.RawQuicLayer(tctx))\n        assert (\n            tutils.Playbook(quic.RawQuicLayer(tctx))\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n        )\n        with pytest.raises(AssertionError, match=\"Unexpected stream event\"):\n\n            class InvalidStreamEvent(quic.QuicStreamEvent):\n                pass\n\n            playbook >> InvalidStreamEvent(tctx.client, 0)\n            assert playbook\n\n    def test_invalid_event(self, tctx: context.Context):\n        playbook = tutils.Playbook(quic.RawQuicLayer(tctx))\n        assert (\n            tutils.Playbook(quic.RawQuicLayer(tctx))\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n        )\n        with pytest.raises(AssertionError, match=\"Unexpected event\"):\n\n            class InvalidEvent(events.Event):\n                pass\n\n            playbook >> InvalidEvent()\n            assert playbook\n\n    def test_full_close(self, tctx: context.Context):\n        assert (\n            tutils.Playbook(quic.RawQuicLayer(tctx))\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n            >> quic.QuicStreamDataReceived(tctx.client, 0, b\"msg1\", end_stream=True)\n            << layer.NextLayerHook(tutils.Placeholder())\n            >> tutils.reply_next_layer(lambda ctx: udp.UDPLayer(ctx, ignore=True))\n            << quic.SendQuicStreamData(tctx.server, 0, b\"msg1\", end_stream=False)\n            << quic.SendQuicStreamData(tctx.server, 0, b\"\", end_stream=True)\n            << quic.StopQuicStream(tctx.server, 0, 0)\n        )\n\n    def test_open_connection(self, tctx: context.Context):\n        server = connection.Server(address=(\"other\", 80))\n\n        def echo_new_server(ctx: context.Context):\n            echo_layer = TlsEchoLayer(ctx)\n            echo_layer.context.server = server\n            return echo_layer\n\n        assert (\n            tutils.Playbook(quic.RawQuicLayer(tctx))\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n            >> quic.QuicStreamDataReceived(\n                tctx.client, 0, b\"open-connection\", end_stream=False\n            )\n            << layer.NextLayerHook(tutils.Placeholder())\n            >> tutils.reply_next_layer(echo_new_server)\n            << commands.OpenConnection(server)\n            >> tutils.reply(\"uhoh\")\n            << quic.SendQuicStreamData(\n                tctx.client, 0, b\"open-connection failed: uhoh\", end_stream=False\n            )\n        )\n\n    def test_invalid_connection_command(self, tctx: context.Context):\n        playbook = tutils.Playbook(quic.RawQuicLayer(tctx))\n        assert (\n            playbook\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n            >> quic.QuicStreamDataReceived(tctx.client, 0, b\"msg1\", end_stream=False)\n            << layer.NextLayerHook(tutils.Placeholder())\n            >> tutils.reply_next_layer(TlsEchoLayer)\n            << quic.SendQuicStreamData(tctx.client, 0, b\"msg1\", end_stream=False)\n        )\n        with pytest.raises(\n            AssertionError, match=\"Unexpected stream connection command\"\n        ):\n            playbook >> quic.QuicStreamDataReceived(\n                tctx.client, 0, b\"invalid-command\", end_stream=False\n            )\n            assert playbook\n\n\nclass MockQuic(QuicConnection):\n    def __init__(self, event) -> None:\n        super().__init__(configuration=QuicConfiguration(is_client=True))\n        self.event = event\n\n    def next_event(self):\n        event = self.event\n        self.event = None\n        return event\n\n    def datagrams_to_send(self, now: float):\n        return []\n\n    def get_timer(self):\n        return None\n\n\ndef make_mock_quic(\n    tctx: context.Context,\n    event: quic_events.QuicEvent | None = None,\n    established: bool = True,\n) -> tuple[tutils.Playbook, MockQuic]:\n    tctx.client.state = connection.ConnectionState.CLOSED\n    quic_layer = quic.QuicLayer(tctx, tctx.client, time=lambda: 0)\n    quic_layer.child_layer = TlsEchoLayer(tctx)\n    mock = MockQuic(event)\n    quic_layer.quic = mock\n    quic_layer.tunnel_state = (\n        tls.tunnel.TunnelState.OPEN\n        if established\n        else tls.tunnel.TunnelState.ESTABLISHING\n    )\n    return tutils.Playbook(quic_layer), mock\n\n\nclass TestQuicLayer:\n    @pytest.mark.parametrize(\"established\", [True, False])\n    def test_invalid_event(self, tctx: context.Context, established: bool):\n        class InvalidEvent(quic_events.QuicEvent):\n            pass\n\n        playbook, conn = make_mock_quic(\n            tctx, event=InvalidEvent(), established=established\n        )\n        with pytest.raises(AssertionError, match=\"Unexpected event\"):\n            assert playbook >> events.DataReceived(tctx.client, b\"\")\n\n    def test_invalid_stream_command(self, tctx: context.Context):\n        playbook, conn = make_mock_quic(\n            tctx, quic_events.DatagramFrameReceived(b\"invalid-stream-command\")\n        )\n        with pytest.raises(AssertionError, match=\"Unexpected stream command\"):\n            assert playbook >> events.DataReceived(tctx.client, b\"\")\n\n    def test_close(self, tctx: context.Context):\n        playbook, conn = make_mock_quic(\n            tctx, quic_events.DatagramFrameReceived(b\"close-connection\")\n        )\n        assert not conn._close_event\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, b\"\")\n            << commands.CloseConnection(tctx.client)\n        )\n        assert conn._close_event\n        assert conn._close_event.error_code == 0\n\n    def test_close_error(self, tctx: context.Context):\n        playbook, conn = make_mock_quic(\n            tctx, quic_events.DatagramFrameReceived(b\"close-connection-error\")\n        )\n        assert not conn._close_event\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, b\"\")\n            << quic.CloseQuicConnection(tctx.client, 123, None, \"error\")\n        )\n        assert conn._close_event\n        assert conn._close_event.error_code == 123\n\n    def test_datagram(self, tctx: context.Context):\n        playbook, conn = make_mock_quic(\n            tctx, quic_events.DatagramFrameReceived(b\"packet\")\n        )\n        assert not conn._datagrams_pending\n        assert playbook >> events.DataReceived(tctx.client, b\"\")\n        assert len(conn._datagrams_pending) == 1\n        assert conn._datagrams_pending[0] == b\"packet\"\n\n    def test_stream_data(self, tctx: context.Context):\n        playbook, conn = make_mock_quic(\n            tctx, quic_events.StreamDataReceived(b\"packet\", False, 42)\n        )\n        assert 42 not in conn._streams\n        assert playbook >> events.DataReceived(tctx.client, b\"\")\n        assert b\"packet\" == conn._streams[42].sender._buffer\n\n    def test_stream_reset(self, tctx: context.Context):\n        playbook, conn = make_mock_quic(tctx, quic_events.StreamReset(123, 42))\n        assert 42 not in conn._streams\n        assert playbook >> events.DataReceived(tctx.client, b\"\")\n        assert conn._streams[42].sender.reset_pending\n        assert conn._streams[42].sender._reset_error_code == 123\n\n    def test_stream_stop(self, tctx: context.Context):\n        playbook, conn = make_mock_quic(\n            tctx, quic_events.DatagramFrameReceived(b\"stop-stream\")\n        )\n        assert 24 not in conn._streams\n        conn._get_or_create_stream_for_send(24)\n        assert playbook >> events.DataReceived(tctx.client, b\"\")\n        assert conn._streams[24].receiver.stop_pending\n        assert conn._streams[24].receiver._stop_error_code == 123\n\n\nclass SSLTest:\n    \"\"\"Helper container for QuicConnection object.\"\"\"\n\n    def __init__(\n        self,\n        server_side: bool = False,\n        alpn: list[str] | None = None,\n        sni: str | None = \"example.mitmproxy.org\",\n        version: int | None = None,\n        settings: quic.QuicTlsSettings | None = None,\n    ):\n        if settings is None:\n            self.ctx = QuicConfiguration(\n                is_client=not server_side,\n                max_datagram_frame_size=65536,\n            )\n\n            self.ctx.verify_mode = ssl.CERT_OPTIONAL\n            self.ctx.load_verify_locations(\n                cafile=tlsdata.path(\n                    \"../../net/data/verificationcerts/trusted-root.crt\"\n                ),\n            )\n\n            if alpn:\n                self.ctx.alpn_protocols = alpn\n            if server_side:\n                if sni == \"192.0.2.42\":\n                    filename = \"trusted-leaf-ip\"\n                else:\n                    filename = \"trusted-leaf\"\n                self.ctx.load_cert_chain(\n                    certfile=tlsdata.path(\n                        f\"../../net/data/verificationcerts/{filename}.crt\"\n                    ),\n                    keyfile=tlsdata.path(\n                        f\"../../net/data/verificationcerts/{filename}.key\"\n                    ),\n                )\n\n            self.ctx.server_name = None if server_side else sni\n\n            if version is not None:\n                self.ctx.supported_versions = [version]\n        else:\n            assert alpn is None\n            assert version is None\n            self.ctx = quic.tls_settings_to_configuration(\n                settings=settings,\n                is_client=not server_side,\n                server_name=sni,\n            )\n\n        self.now = 0.0\n        self.address = (sni, 443)\n        self.quic = None if server_side else QuicConnection(configuration=self.ctx)\n        if not server_side:\n            self.quic.connect(self.address, now=self.now)\n\n    def write(self, buf: bytes) -> int:\n        self.now = self.now + 0.1\n        if self.quic is None:\n            quic_buf = QuicBuffer(data=buf)\n            header = pull_quic_header(quic_buf, host_cid_length=8)\n            self.quic = QuicConnection(\n                configuration=self.ctx,\n                original_destination_connection_id=header.destination_cid,\n            )\n        self.quic.receive_datagram(buf, self.address, self.now)\n\n    def read(self) -> bytes:\n        self.now = self.now + 0.1\n        buf = b\"\"\n        has_data = False\n        for datagram, addr in self.quic.datagrams_to_send(self.now):\n            assert addr == self.address\n            buf += datagram\n            has_data = True\n        if not has_data:\n            raise AssertionError(\"no datagrams to send\")\n        return buf\n\n    def handshake_completed(self) -> bool:\n        while event := self.quic.next_event():\n            if isinstance(event, quic_events.HandshakeCompleted):\n                return True\n        else:\n            return False\n\n\ndef _test_echo(\n    playbook: tutils.Playbook, tssl: SSLTest, conn: connection.Connection\n) -> None:\n    tssl.quic.send_datagram_frame(b\"Hello World\")\n    data = tutils.Placeholder(bytes)\n    assert (\n        playbook\n        >> events.DataReceived(conn, tssl.read())\n        << commands.SendData(conn, data)\n    )\n    tssl.write(data())\n    while event := tssl.quic.next_event():\n        if isinstance(event, quic_events.DatagramFrameReceived):\n            assert event.data == b\"hello world\"\n            break\n    else:\n        raise AssertionError()\n\n\ndef finish_handshake(\n    playbook: tutils.Playbook,\n    conn: connection.Connection,\n    tssl: SSLTest,\n    child_layer: type[T],\n) -> T:\n    result: T | None = None\n\n    def set_layer(next_layer: layer.NextLayer) -> None:\n        nonlocal result\n        result = child_layer(next_layer.context)\n        next_layer.layer = result\n\n    data = tutils.Placeholder(bytes)\n    tls_hook_data = tutils.Placeholder(tls.TlsData)\n    if isinstance(conn, connection.Client):\n        established_hook = tls.TlsEstablishedClientHook(tls_hook_data)\n    else:\n        established_hook = tls.TlsEstablishedServerHook(tls_hook_data)\n    assert (\n        playbook\n        >> events.DataReceived(conn, tssl.read())\n        << established_hook\n        >> tutils.reply()\n        << commands.SendData(conn, data)\n        << layer.NextLayerHook(tutils.Placeholder())\n        >> tutils.reply(side_effect=set_layer)\n    )\n    assert tls_hook_data().conn.error is None\n    tssl.write(data())\n\n    assert result\n    return result\n\n\ndef reply_tls_start_client(alpn: str | None = None, *args, **kwargs) -> tutils.reply:\n    \"\"\"\n    Helper function to simplify the syntax for quic_start_client hooks.\n    \"\"\"\n\n    def make_client_conn(tls_start: quic.QuicTlsData) -> None:\n        config = QuicConfiguration()\n        config.load_cert_chain(\n            tlsdata.path(\"../../net/data/verificationcerts/trusted-leaf.crt\"),\n            tlsdata.path(\"../../net/data/verificationcerts/trusted-leaf.key\"),\n        )\n        tls_start.settings = quic.QuicTlsSettings(\n            certificate=config.certificate,\n            certificate_chain=config.certificate_chain,\n            certificate_private_key=config.private_key,\n        )\n        if alpn is not None:\n            tls_start.settings.alpn_protocols = [alpn]\n\n    return tutils.reply(*args, side_effect=make_client_conn, **kwargs)\n\n\ndef reply_tls_start_server(alpn: str | None = None, *args, **kwargs) -> tutils.reply:\n    \"\"\"\n    Helper function to simplify the syntax for quic_start_server hooks.\n    \"\"\"\n\n    def make_server_conn(tls_start: quic.QuicTlsData) -> None:\n        tls_start.settings = quic.QuicTlsSettings(\n            ca_file=tlsdata.path(\"../../net/data/verificationcerts/trusted-root.crt\"),\n            verify_mode=ssl.CERT_REQUIRED,\n        )\n        if alpn is not None:\n            tls_start.settings.alpn_protocols = [alpn]\n\n    return tutils.reply(*args, side_effect=make_server_conn, **kwargs)\n\n\nclass TestServerQuic:\n    def test_repr(self, tctx: context.Context):\n        assert repr(quic.ServerQuicLayer(tctx, time=lambda: 0))\n\n    def test_not_connected(self, tctx: context.Context):\n        \"\"\"Test that we don't do anything if no server connection exists.\"\"\"\n        layer = quic.ServerQuicLayer(tctx, time=lambda: 0)\n        layer.child_layer = TlsEchoLayer(tctx)\n\n        assert (\n            tutils.Playbook(layer)\n            >> events.DataReceived(tctx.client, b\"Hello World\")\n            << commands.SendData(tctx.client, b\"hello world\")\n        )\n\n    def test_simple(self, tctx: context.Context):\n        tssl = SSLTest(server_side=True)\n\n        playbook = tutils.Playbook(quic.ServerQuicLayer(tctx, time=lambda: tssl.now))\n        tctx.server.address = (\"example.mitmproxy.org\", 443)\n        tctx.server.state = connection.ConnectionState.OPEN\n        tctx.server.sni = \"example.mitmproxy.org\"\n\n        # send ClientHello, receive ClientHello\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            << quic.QuicStartServerHook(tutils.Placeholder())\n            >> reply_tls_start_server()\n            << commands.SendData(tctx.server, data)\n            << commands.RequestWakeup(0.2)\n        )\n        tssl.write(data())\n        assert not tssl.handshake_completed()\n\n        # finish handshake (mitmproxy)\n        echo = finish_handshake(playbook, tctx.server, tssl, TlsEchoLayer)\n\n        # finish handshake (locally)\n        assert tssl.handshake_completed()\n        playbook >> events.DataReceived(tctx.server, tssl.read())\n        playbook << None\n        assert playbook\n\n        assert tctx.server.tls_established\n\n        # Echo\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, b\"foo\")\n            << commands.SendData(tctx.client, b\"foo\")\n        )\n        _test_echo(playbook, tssl, tctx.server)\n\n        tssl.quic.close(42, None, \"goodbye from simple\")\n        playbook >> events.DataReceived(tctx.server, tssl.read())\n        playbook << None\n        assert playbook\n        tssl.now = tssl.now + 60\n        assert (\n            playbook\n            >> tutils.reply(to=commands.RequestWakeup)\n            << commands.CloseConnection(tctx.server)\n            >> events.ConnectionClosed(tctx.server)\n            << None\n        )\n        assert echo.closed\n        assert echo.closed.error_code == 42\n        assert echo.closed.reason_phrase == \"goodbye from simple\"\n\n    def test_untrusted_cert(self, tctx: context.Context):\n        \"\"\"If the certificate is not trusted, we should fail.\"\"\"\n        tssl = SSLTest(server_side=True)\n\n        playbook = tutils.Playbook(quic.ServerQuicLayer(tctx, time=lambda: tssl.now))\n        tctx.server.address = (\"wrong.host.mitmproxy.org\", 443)\n        tctx.server.sni = \"wrong.host.mitmproxy.org\"\n\n        # send ClientHello\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            << layer.NextLayerHook(tutils.Placeholder())\n            >> tutils.reply_next_layer(TlsEchoLayer)\n            >> events.DataReceived(tctx.client, b\"open-connection\")\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(None)\n            << quic.QuicStartServerHook(tutils.Placeholder())\n            >> reply_tls_start_server()\n            << commands.SendData(tctx.server, data)\n            << commands.RequestWakeup(0.2)\n        )\n\n        # receive ServerHello, finish client handshake\n        tssl.write(data())\n        assert not tssl.handshake_completed()\n\n        # exchange termination data\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.server, tssl.read())\n            << commands.SendData(tctx.server, data)\n        )\n        tssl.write(data())\n        tssl.now = tssl.now + 60\n\n        tls_hook_data = tutils.Placeholder(quic.QuicTlsData)\n        assert (\n            playbook\n            >> tutils.reply(to=commands.RequestWakeup)\n            << commands.Log(\n                tutils.StrMatching(\n                    \"Server QUIC handshake failed. hostname 'wrong.host.mitmproxy.org' doesn't match\"\n                ),\n                WARNING,\n            )\n            << tls.TlsFailedServerHook(tls_hook_data)\n            >> tutils.reply()\n            << commands.CloseConnection(tctx.server)\n            << commands.SendData(\n                tctx.client,\n                tutils.BytesMatching(\n                    b\"open-connection failed: hostname 'wrong.host.mitmproxy.org' doesn't match\"\n                ),\n            )\n        )\n        assert tls_hook_data().conn.error.startswith(\n            \"hostname 'wrong.host.mitmproxy.org' doesn't match\"\n        )\n        assert not tctx.server.tls_established\n\n\ndef make_client_tls_layer(\n    tctx: context.Context, no_server: bool = False, **kwargs\n) -> tuple[tutils.Playbook, quic.ClientQuicLayer, SSLTest]:\n    tssl_client = SSLTest(**kwargs)\n\n    # This is a bit contrived as the client layer expects a server layer as parent.\n    # We also set child layers manually to avoid NextLayer noise.\n    server_layer = (\n        DummyLayer(tctx)\n        if no_server\n        else quic.ServerQuicLayer(tctx, time=lambda: tssl_client.now)\n    )\n    client_layer = quic.ClientQuicLayer(tctx, time=lambda: tssl_client.now)\n    server_layer.child_layer = client_layer\n    playbook = tutils.Playbook(server_layer)\n\n    # Add some server config, this is needed anyways.\n    tctx.server.__dict__[\"address\"] = (\n        \"example.mitmproxy.org\",\n        443,\n    )  # .address fails because connection is open\n    tctx.server.sni = \"example.mitmproxy.org\"\n\n    # Start handshake.\n    assert not tssl_client.handshake_completed()\n\n    return playbook, client_layer, tssl_client\n\n\nclass TestClientQuic:\n    def test_http3_disabled(self, tctx: context.Context):\n        \"\"\"Test that we swallow QUIC packets if QUIC and HTTP/3 are disabled.\"\"\"\n        tctx.options.http3 = False\n        assert (\n            tutils.Playbook(quic.ClientQuicLayer(tctx, time=time.time), logs=True)\n            >> events.DataReceived(tctx.client, client_hello)\n            << commands.Log(\n                \"Swallowing QUIC handshake because HTTP/3 is disabled.\", DEBUG\n            )\n            << None\n        )\n\n    def test_client_only(self, tctx: context.Context):\n        \"\"\"Test QUIC with client only\"\"\"\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx)\n        client_layer.debug = \"  \"\n        assert not tctx.client.tls_established\n\n        # Send ClientHello, receive ServerHello\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.read())\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply()\n            << quic.QuicStartClientHook(tutils.Placeholder())\n            >> reply_tls_start_client()\n            << commands.SendData(tctx.client, data)\n            << commands.RequestWakeup(tutils.Placeholder())\n        )\n        tssl_client.write(data())\n        assert tssl_client.handshake_completed()\n        # Finish Handshake\n        finish_handshake(playbook, tctx.client, tssl_client, TlsEchoLayer)\n\n        assert tssl_client.quic.tls._peer_certificate\n        assert tctx.client.tls_established\n\n        # Echo\n        _test_echo(playbook, tssl_client, tctx.client)\n        other_server = connection.Server(address=None)\n        assert (\n            playbook\n            >> events.DataReceived(other_server, b\"Plaintext\")\n            << commands.SendData(other_server, b\"plaintext\")\n        )\n\n        # test the close log\n        tssl_client.now = tssl_client.now + 60\n        assert (\n            playbook\n            >> tutils.reply(to=commands.RequestWakeup)\n            << commands.Log(\n                tutils.StrMatching(\n                    r\"  >> Wakeup\\(command=RequestWakeup\\({'delay': [.\\d]+}\\)\\)\"\n                ),\n                DEBUG,\n            )\n            << commands.Log(\n                \"  [quic] close_notify Client(client:1234, state=open, tls) (reason=Idle timeout)\",\n                DEBUG,\n            )\n            << commands.CloseConnection(tctx.client)\n        )\n\n    @pytest.mark.parametrize(\"server_state\", [\"open\", \"closed\"])\n    def test_server_required(\n        self, tctx: context.Context, server_state: Literal[\"open\", \"closed\"]\n    ):\n        \"\"\"\n        Test the scenario where a server connection is required (for example, because of an unknown ALPN)\n        to establish TLS with the client.\n        \"\"\"\n        if server_state == \"open\":\n            tctx.server.state = connection.ConnectionState.OPEN\n        tssl_server = SSLTest(server_side=True, alpn=[\"quux\"])\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx, alpn=[\"quux\"])\n\n        # We should now get instructed to open a server connection.\n        data = tutils.Placeholder(bytes)\n\n        def require_server_conn(client_hello: tls.ClientHelloData) -> None:\n            client_hello.establish_server_tls_first = True\n\n        (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.read())\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply(side_effect=require_server_conn)\n        )\n        if server_state == \"closed\":\n            playbook << commands.OpenConnection(tctx.server)\n            playbook >> tutils.reply(None)\n        assert (\n            playbook\n            << quic.QuicStartServerHook(tutils.Placeholder())\n            >> reply_tls_start_server(alpn=\"quux\")\n            << commands.SendData(tctx.server, data)\n            << commands.RequestWakeup(tutils.Placeholder())\n        )\n\n        # Establish TLS with the server...\n        tssl_server.write(data())\n        assert not tssl_server.handshake_completed()\n\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.server, tssl_server.read())\n            << tls.TlsEstablishedServerHook(tutils.Placeholder())\n            >> tutils.reply()\n            << commands.SendData(tctx.server, data)\n            << commands.RequestWakeup(tutils.Placeholder())\n            << quic.QuicStartClientHook(tutils.Placeholder())\n        )\n        tssl_server.write(data())\n        assert tctx.server.tls_established\n        # Server TLS is established, we can now reply to the client handshake...\n\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            >> reply_tls_start_client(alpn=\"quux\")\n            << commands.SendData(tctx.client, data)\n            << commands.RequestWakeup(tutils.Placeholder())\n        )\n        tssl_client.write(data())\n        assert tssl_client.handshake_completed()\n        finish_handshake(playbook, tctx.client, tssl_client, TlsEchoLayer)\n\n        # Both handshakes completed!\n        assert tctx.client.tls_established\n        assert tctx.server.tls_established\n        assert tctx.server.sni == tctx.client.sni\n        assert tctx.client.alpn == b\"quux\"\n        assert tctx.server.alpn == b\"quux\"\n        _test_echo(playbook, tssl_client, tctx.client)\n        _test_echo(playbook, tssl_server, tctx.server)\n\n    @pytest.mark.parametrize(\"server_state\", [\"open\", \"closed\"])\n    def test_passthrough_from_clienthello(\n        self, tctx: context.Context, server_state: Literal[\"open\", \"closed\"]\n    ):\n        \"\"\"\n        Test the scenario where the connection is moved to passthrough mode in the tls_clienthello hook.\n        \"\"\"\n        if server_state == \"open\":\n            tctx.server.timestamp_start = time.time()\n            tctx.server.state = connection.ConnectionState.OPEN\n\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx, alpn=[\"quux\"])\n        client_layer.child_layer = TlsEchoLayer(client_layer.context)\n\n        def make_passthrough(client_hello: tls.ClientHelloData) -> None:\n            client_hello.ignore_connection = True\n\n        client_hello = tssl_client.read()\n        (\n            playbook\n            >> events.DataReceived(tctx.client, client_hello)\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply(side_effect=make_passthrough)\n        )\n        if server_state == \"closed\":\n            playbook << commands.OpenConnection(tctx.server)\n            playbook >> tutils.reply(None)\n        assert (\n            playbook\n            << commands.SendData(tctx.server, client_hello)  # passed through unmodified\n            >> events.DataReceived(\n                tctx.server, b\"ServerHello\"\n            )  # and the same for the serverhello.\n            << commands.SendData(tctx.client, b\"ServerHello\")\n        )\n\n    @pytest.mark.parametrize(\n        \"data,err\",\n        [\n            (b\"\\x16\\x03\\x01\\x00\\x00\", \"Packet fixed bit is zero (1603010000)\"),\n            (b\"test\", \"Malformed head (74657374)\"),\n        ],\n    )\n    def test_cannot_parse_clienthello(\n        self, tctx: context.Context, data: bytes, err: str\n    ):\n        \"\"\"Test the scenario where we cannot parse the ClientHello\"\"\"\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx)\n        tls_hook_data = tutils.Placeholder(quic.QuicTlsData)\n\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, data)\n            << commands.Log(\n                f\"Client QUIC handshake failed. Cannot parse QUIC header: {err}\",\n                level=WARNING,\n            )\n            << tls.TlsFailedClientHook(tls_hook_data)\n            >> tutils.reply()\n            << commands.CloseConnection(tctx.client)\n        )\n        assert tls_hook_data().conn.error\n        assert not tctx.client.tls_established\n\n        # Make sure that an active server connection does not cause child layers to spawn.\n        client_layer.debug = \"\"\n        assert (\n            playbook\n            >> events.DataReceived(\n                connection.Server(address=None), b\"data on other stream\"\n            )\n            << commands.Log(\">> DataReceived(server, b'data on other stream')\", DEBUG)\n            << commands.Log(\n                \"[quic] Swallowing DataReceived(server, b'data on other stream') as handshake failed.\",\n                DEBUG,\n            )\n        )\n\n    def test_mitmproxy_ca_is_untrusted(self, tctx: context.Context):\n        \"\"\"Test the scenario where the client doesn't trust the mitmproxy CA.\"\"\"\n        playbook, client_layer, tssl_client = make_client_tls_layer(\n            tctx, sni=\"wrong.host.mitmproxy.org\"\n        )\n        playbook.logs = True\n\n        data = tutils.Placeholder(bytes)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.read())\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply()\n            << quic.QuicStartClientHook(tutils.Placeholder())\n            >> reply_tls_start_client()\n            << commands.SendData(tctx.client, data)\n            << commands.RequestWakeup(tutils.Placeholder())\n        )\n        tssl_client.write(data())\n        assert not tssl_client.handshake_completed()\n\n        # Finish Handshake\n        tls_hook_data = tutils.Placeholder(quic.QuicTlsData)\n        playbook >> events.DataReceived(tctx.client, tssl_client.read())\n        assert playbook\n        tssl_client.now = tssl_client.now + 60\n        assert (\n            playbook\n            >> tutils.reply(to=commands.RequestWakeup)\n            << commands.Log(\n                tutils.StrMatching(\n                    \"Client QUIC handshake failed. hostname 'wrong.host.mitmproxy.org' doesn't match\"\n                ),\n                WARNING,\n            )\n            << tls.TlsFailedClientHook(tls_hook_data)\n            >> tutils.reply()\n            << commands.CloseConnection(tctx.client)\n            >> events.ConnectionClosed(tctx.client)\n        )\n        assert not tctx.client.tls_established\n        assert tls_hook_data().conn.error\n\n    def test_server_unavailable_and_no_settings(self, tctx: context.Context):\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx)\n\n        def require_server_conn(client_hello: tls.ClientHelloData) -> None:\n            client_hello.establish_server_tls_first = True\n\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.read())\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply(side_effect=require_server_conn)\n            << commands.OpenConnection(tctx.server)\n            >> tutils.reply(\"I cannot open the server, Dave\")\n            << commands.Log(\n                f\"Unable to establish QUIC connection with server (I cannot open the server, Dave). \"\n                f\"Trying to establish QUIC with client anyway. \"\n                f\"If you plan to redirect requests away from this server, \"\n                f\"consider setting `connection_strategy` to `lazy` to suppress early connections.\"\n            )\n            << quic.QuicStartClientHook(tutils.Placeholder())\n        )\n        tctx.client.state = connection.ConnectionState.CLOSED\n        assert (\n            playbook\n            >> tutils.reply()\n            << commands.Log(f\"No QUIC context was provided, failing connection.\", ERROR)\n            << commands.CloseConnection(tctx.client)\n            << commands.Log(\n                \"Client QUIC handshake failed. connection closed early\", WARNING\n            )\n            << tls.TlsFailedClientHook(tutils.Placeholder())\n        )\n\n    def test_no_server_tls(self, tctx: context.Context):\n        playbook, client_layer, tssl_client = make_client_tls_layer(\n            tctx, no_server=True\n        )\n\n        def require_server_conn(client_hello: tls.ClientHelloData) -> None:\n            client_hello.establish_server_tls_first = True\n\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.read())\n            << tls.TlsClienthelloHook(tutils.Placeholder())\n            >> tutils.reply(side_effect=require_server_conn)\n            << commands.Log(\n                f\"Unable to establish QUIC connection with server (No server QUIC available.). \"\n                f\"Trying to establish QUIC with client anyway. \"\n                f\"If you plan to redirect requests away from this server, \"\n                f\"consider setting `connection_strategy` to `lazy` to suppress early connections.\"\n            )\n            << quic.QuicStartClientHook(tutils.Placeholder())\n        )\n\n    def test_version_negotiation(self, tctx: context.Context):\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx, version=0)\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, tssl_client.read())\n            << commands.SendData(tctx.client, tutils.Placeholder())\n        )\n        assert client_layer.tunnel_state == tls.tunnel.TunnelState.ESTABLISHING\n\n    def test_non_init_clienthello(self, tctx: context.Context):\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx)\n        data = (\n            b\"\\xc2\\x00\\x00\\x00\\x01\\x08q\\xda\\x98\\x03X-\\x13o\\x08y\\xa5RQv\\xbe\\xe3\\xeb\\x00@a\\x98\\x19\\xf95t\\xad-\\x1c\\\\a\\xdd\\x8c\\xd0\\x15F\"\n            b\"\\xdf\\xdc\\x87cb\\x1eu\\xb0\\x95*\\xac\\xa8\\xf7a \\xb8\\nQ\\xbd=\\xf5x\\xca\\r\\xe6\\x8b\\x05 w\\x9f\\xcd\\x8d\\xcb\\xa0\\x06\\x1e \\x8d.\\x8f\"\n            b\"T\\xda\\x12et\\xe4\\x83\\x93X<o\\xad\\xd5%&\\x8f7\\xa6>\\x8aa\\xd1\\xb2\\x18\\xb6\\xa7\\xf50y\\x9b\\xc5T\\xe1\\x87\\xdd\\x9fqv\\xb0\\x90\\xa7s\"\n            b\"\\xee\\x00\\x00\\x00\\x01\\x08q\\xda\\x98\\x03X-\\x13o\\x08y\\xa5RQv\\xbe\\xe3\\xeb@a*.\\xa8j\\x90\\x1b\\x1a\\x7fZ\\x04\\x0b\\\\\\xc7\\x00\\x03\"\n            b\"\\xd7sC\\xf8G\\x84\\x1e\\xba\\xcf\\x08Z\\xdd\\x98+\\xaa\\x98J\\xca\\xe3\\xb7u1\\x89\\x00\\xdf\\x8e\\x16`\\xd9^\\xc0@i\\x1a\\x10\\x99\\r\\xd8\"\n            b\"\\x1dv3\\xc6\\xb8\\\"\\xb9\\xa8F\\x95K\\x9a/\\xbc'\\xd8\\xd8\\x94\\x8f\\xe7B/\\x05\\x9d\\xfb\\x80\\xa9\\xda@\\xe6\\xb0J\\xfe\\xe0\\x0f\\x02L}\"\n            b\"\\xd9\\xed\\xd2L\\xa7\\xcf\"\n        )\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, data)\n            << commands.Log(\n                f\"Client QUIC handshake failed. Invalid handshake received, roaming not supported. ({data.hex()})\",\n                WARNING,\n            )\n            << tls.TlsFailedClientHook(tutils.Placeholder())\n        )\n        assert client_layer.tunnel_state == tls.tunnel.TunnelState.ESTABLISHING\n\n    def test_invalid_clienthello(self, tctx: context.Context):\n        playbook, client_layer, tssl_client = make_client_tls_layer(tctx)\n        data = client_hello[0:1200] + b\"\\x00\" + client_hello[1200:]\n        assert (\n            playbook\n            >> events.DataReceived(tctx.client, data)\n            << commands.Log(\n                f\"Client QUIC handshake failed. Cannot parse ClientHello: No ClientHello returned. ({data.hex()})\",\n                WARNING,\n            )\n            << tls.TlsFailedClientHook(tutils.Placeholder())\n        )\n        assert client_layer.tunnel_state == tls.tunnel.TunnelState.ESTABLISHING\n\n    def test_tls_reset(self, tctx: context.Context):\n        tctx.client.tls = True\n        tctx.client.sni = \"some\"\n        DummyLayer(tctx)\n        quic.ClientQuicLayer(tctx, time=lambda: 0)\n        assert tctx.client.sni is None\n", "test/mitmproxy/proxy/layers/test_websocket.py": "import secrets\nfrom dataclasses import dataclass\n\nimport pytest\nimport wsproto.events\nfrom wsproto.frame_protocol import Opcode\n\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.http import Request\nfrom mitmproxy.http import Response\nfrom mitmproxy.proxy.commands import CloseConnection\nfrom mitmproxy.proxy.commands import Log\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.events import ConnectionClosed\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.layers import http\nfrom mitmproxy.proxy.layers import websocket\nfrom mitmproxy.proxy.layers.http import HTTPMode\nfrom mitmproxy.proxy.layers.websocket import WebSocketMessageInjected\nfrom mitmproxy.websocket import WebSocketData\nfrom mitmproxy.websocket import WebSocketMessage\nfrom test.mitmproxy.proxy.tutils import Placeholder\nfrom test.mitmproxy.proxy.tutils import Playbook\nfrom test.mitmproxy.proxy.tutils import reply\n\n\n@dataclass\nclass _Masked:\n    unmasked: bytes\n\n    def __eq__(self, other):\n        other = bytearray(other)\n        assert other[1] & 0b1000_0000  # assert this is actually masked\n        other[1] &= 0b0111_1111  # remove mask bit\n        assert other[1] < 126  # (we don't support extended payload length here)\n        mask = other[2:6]\n        payload = bytes(x ^ mask[i % 4] for i, x in enumerate(other[6:]))\n        return self.unmasked == other[:2] + payload\n\n\n# noinspection PyTypeChecker\ndef masked(unmasked: bytes) -> bytes:\n    return _Masked(unmasked)  # type: ignore\n\n\ndef masked_bytes(unmasked: bytes) -> bytes:\n    header = bytearray(unmasked[:2])\n    assert header[1] < 126  # assert that this is neither masked nor extended payload\n    header[1] |= 0b1000_0000\n    mask = secrets.token_bytes(4)\n    masked = bytes(x ^ mask[i % 4] for i, x in enumerate(unmasked[2:]))\n    return bytes(header + mask + masked)\n\n\ndef test_masking():\n    m = masked(b\"\\x02\\x03foo\")\n    assert m == b\"\\x02\\x83\\x1c\\x96\\xd4\\rz\\xf9\\xbb\"\n    assert m == masked_bytes(b\"\\x02\\x03foo\")\n\n\ndef test_upgrade(tctx):\n    \"\"\"Test a HTTP -> WebSocket upgrade\"\"\"\n    tctx.server.address = (\"example.com\", 80)\n    tctx.server.state = ConnectionState.OPEN\n    flow = Placeholder(HTTPFlow)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.transparent))\n        >> DataReceived(\n            tctx.client,\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: upgrade\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Sec-WebSocket-Version: 13\\r\\n\"\n            b\"\\r\\n\",\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << SendData(\n            tctx.server,\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: upgrade\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Sec-WebSocket-Version: 13\\r\\n\"\n            b\"\\r\\n\",\n        )\n        >> DataReceived(\n            tctx.server,\n            b\"HTTP/1.1 101 Switching Protocols\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Connection: Upgrade\\r\\n\"\n            b\"\\r\\n\",\n        )\n        << http.HttpResponseHeadersHook(flow)\n        >> reply()\n        << http.HttpResponseHook(flow)\n        >> reply()\n        << SendData(\n            tctx.client,\n            b\"HTTP/1.1 101 Switching Protocols\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Connection: Upgrade\\r\\n\"\n            b\"\\r\\n\",\n        )\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> DataReceived(tctx.client, masked_bytes(b\"\\x81\\x0bhello world\"))\n        << websocket.WebsocketMessageHook(flow)\n        >> reply()\n        << SendData(tctx.server, masked(b\"\\x81\\x0bhello world\"))\n        >> DataReceived(tctx.server, b\"\\x82\\nhello back\")\n        << websocket.WebsocketMessageHook(flow)\n        >> reply()\n        << SendData(tctx.client, b\"\\x82\\nhello back\")\n        >> DataReceived(tctx.client, masked_bytes(b\"\\x81\\x0bhello again\"))\n        << websocket.WebsocketMessageHook(flow)\n        >> reply()\n        << SendData(tctx.server, masked(b\"\\x81\\x0bhello again\"))\n    )\n    assert len(flow().websocket.messages) == 3\n    assert flow().websocket.messages[0].content == b\"hello world\"\n    assert flow().websocket.messages[0].from_client\n    assert flow().websocket.messages[0].type == Opcode.TEXT\n    assert flow().websocket.messages[1].content == b\"hello back\"\n    assert flow().websocket.messages[1].from_client is False\n    assert flow().websocket.messages[1].type == Opcode.BINARY\n    assert flow().live\n\n\ndef test_upgrade_streamed(tctx):\n    \"\"\"If the HTTP response is streamed, we may get early data from the client.\"\"\"\n    tctx.server.address = (\"example.com\", 80)\n    tctx.server.state = ConnectionState.OPEN\n    flow = Placeholder(HTTPFlow)\n\n    def enable_streaming(flow: HTTPFlow):\n        flow.response.stream = True\n\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.transparent))\n        >> DataReceived(\n            tctx.client,\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: upgrade\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Sec-WebSocket-Version: 13\\r\\n\"\n            b\"\\r\\n\",\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << SendData(\n            tctx.server,\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: upgrade\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Sec-WebSocket-Version: 13\\r\\n\"\n            b\"\\r\\n\",\n        )\n        >> DataReceived(\n            tctx.server,\n            b\"HTTP/1.1 101 Switching Protocols\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Connection: Upgrade\\r\\n\"\n            b\"\\r\\n\",\n        )\n        << http.HttpResponseHeadersHook(flow)\n        >> reply(side_effect=enable_streaming)\n        << SendData(\n            tctx.client,\n            b\"HTTP/1.1 101 Switching Protocols\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Connection: Upgrade\\r\\n\"\n            b\"\\r\\n\",\n        )\n        << http.HttpResponseHook(flow)\n        >> DataReceived(tctx.client, masked_bytes(b\"\\x81\\x0bhello world\"))  # early !!\n        >> reply(to=-2)\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        << websocket.WebsocketMessageHook(flow)\n        >> reply()\n        << SendData(tctx.server, masked(b\"\\x81\\x0bhello world\"))\n        >> DataReceived(tctx.server, b\"\\x82\\nhello back\")\n        << websocket.WebsocketMessageHook(flow)\n        >> reply()\n        << SendData(tctx.client, b\"\\x82\\nhello back\")\n        >> DataReceived(tctx.client, masked_bytes(b\"\\x81\\x0bhello again\"))\n        << websocket.WebsocketMessageHook(flow)\n        >> reply()\n        << SendData(tctx.server, masked(b\"\\x81\\x0bhello again\"))\n    )\n\n\n@pytest.fixture()\ndef ws_testdata(tctx):\n    tctx.server.address = (\"example.com\", 80)\n    tctx.server.state = ConnectionState.OPEN\n    flow = HTTPFlow(tctx.client, tctx.server)\n    flow.request = Request.make(\n        \"GET\",\n        \"http://example.com/\",\n        headers={\n            \"Connection\": \"upgrade\",\n            \"Upgrade\": \"websocket\",\n            \"Sec-WebSocket-Version\": \"13\",\n        },\n    )\n    flow.response = Response.make(\n        101,\n        headers={\n            \"Connection\": \"upgrade\",\n            \"Upgrade\": \"websocket\",\n        },\n    )\n    flow.websocket = WebSocketData()\n    return tctx, Playbook(websocket.WebsocketLayer(tctx, flow)), flow\n\n\ndef test_modify_message(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> DataReceived(tctx.server, b\"\\x81\\x03foo\")\n        << websocket.WebsocketMessageHook(flow)\n    )\n    flow.websocket.messages[-1].content = flow.websocket.messages[-1].content.replace(\n        b\"foo\", b\"foobar\"\n    )\n    playbook >> reply()\n    playbook << SendData(tctx.client, b\"\\x81\\x06foobar\")\n    assert playbook\n\n\ndef test_empty_message(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> DataReceived(tctx.server, b\"\\x81\\x00\")\n        << websocket.WebsocketMessageHook(flow)\n    )\n    assert flow.websocket.messages[-1].content == b\"\"\n    playbook >> reply()\n    playbook << SendData(tctx.client, b\"\\x81\\x00\")\n    assert playbook\n\n\ndef test_drop_message(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> DataReceived(tctx.server, b\"\\x81\\x03foo\")\n        << websocket.WebsocketMessageHook(flow)\n    )\n    flow.websocket.messages[-1].drop()\n    playbook >> reply()\n    playbook << None\n    assert playbook\n\n\ndef test_fragmented(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> DataReceived(tctx.server, b\"\\x01\\x03foo\")\n        >> DataReceived(tctx.server, b\"\\x80\\x03bar\")\n        << websocket.WebsocketMessageHook(flow)\n        >> reply()\n        << SendData(tctx.client, b\"\\x01\\x03foo\")\n        << SendData(tctx.client, b\"\\x80\\x03bar\")\n    )\n    assert flow.websocket.messages[-1].content == b\"foobar\"\n\n\ndef test_unfragmented(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> DataReceived(tctx.server, b\"\\x81\\x06foo\")\n    )\n    # This already triggers wsproto to emit a wsproto.events.Message, see\n    # https://github.com/mitmproxy/mitmproxy/issues/4701\n    assert (\n        playbook\n        >> DataReceived(tctx.server, b\"bar\")\n        << websocket.WebsocketMessageHook(flow)\n        >> reply()\n        << SendData(tctx.client, b\"\\x81\\x06foobar\")\n    )\n    assert flow.websocket.messages[-1].content == b\"foobar\"\n\n\ndef test_protocol_error(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> DataReceived(tctx.server, b\"\\x01\\x03foo\")\n        >> DataReceived(tctx.server, b\"\\x02\\x03bar\")\n        << SendData(\n            tctx.server,\n            masked(b\"\\x88/\\x03\\xeaexpected CONTINUATION, got <Opcode.BINARY: 2>\"),\n        )\n        << CloseConnection(tctx.server)\n        << SendData(\n            tctx.client, b\"\\x88/\\x03\\xeaexpected CONTINUATION, got <Opcode.BINARY: 2>\"\n        )\n        << CloseConnection(tctx.client)\n        << websocket.WebsocketEndHook(flow)\n        >> reply()\n    )\n    assert not flow.websocket.messages\n    assert not flow.live\n\n\ndef test_ping(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> DataReceived(tctx.client, masked_bytes(b\"\\x89\\x11ping-with-payload\"))\n        << Log(\"Received WebSocket ping from client (payload: b'ping-with-payload')\")\n        << SendData(tctx.server, masked(b\"\\x89\\x11ping-with-payload\"))\n        >> DataReceived(tctx.server, b\"\\x8a\\x11pong-with-payload\")\n        << Log(\"Received WebSocket pong from server (payload: b'pong-with-payload')\")\n        << SendData(tctx.client, b\"\\x8a\\x11pong-with-payload\")\n    )\n    assert not flow.websocket.messages\n\n\ndef test_close_normal(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    masked_close = Placeholder(bytes)\n    close = Placeholder(bytes)\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> DataReceived(tctx.client, masked_bytes(b\"\\x88\\x00\"))\n        << SendData(tctx.server, masked_close)\n        << CloseConnection(tctx.server)\n        << SendData(tctx.client, close)\n        << CloseConnection(tctx.client)\n        << websocket.WebsocketEndHook(flow)\n        >> reply()\n    )\n    # wsproto currently handles this inconsistently, see\n    # https://github.com/python-hyper/wsproto/pull/153/files\n    assert masked_close() == masked(b\"\\x88\\x02\\x03\\xe8\") or masked_close() == masked(\n        b\"\\x88\\x00\"\n    )\n    assert close() == b\"\\x88\\x02\\x03\\xe8\" or close() == b\"\\x88\\x00\"\n\n    assert flow.websocket.close_code == 1005\n    assert not flow.live\n\n\ndef test_close_disconnect(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> ConnectionClosed(tctx.server)\n        << CloseConnection(tctx.server)\n        << SendData(tctx.client, b\"\\x88\\x02\\x03\\xe8\")\n        << CloseConnection(tctx.client)\n        << websocket.WebsocketEndHook(flow)\n        >> reply()\n        >> ConnectionClosed(tctx.client)\n    )\n    # The \\x03\\xe8 above is code 1000 (normal closure).\n    # But 1006 (ABNORMAL_CLOSURE) is expected, because the connection was already closed.\n    assert flow.websocket.close_code == 1006\n    assert not flow.live\n\n\ndef test_close_code(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> DataReceived(tctx.server, b\"\\x88\\x02\\x0f\\xa0\")\n        << SendData(tctx.server, masked(b\"\\x88\\x02\\x0f\\xa0\"))\n        << CloseConnection(tctx.server)\n        << SendData(tctx.client, b\"\\x88\\x02\\x0f\\xa0\")\n        << CloseConnection(tctx.client)\n        << websocket.WebsocketEndHook(flow)\n        >> reply()\n    )\n    assert flow.websocket.close_code == 4000\n    assert not flow.live\n\n\ndef test_deflate(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    flow.response.headers[\"Sec-WebSocket-Extensions\"] = (\n        \"permessage-deflate; server_max_window_bits=10\"\n    )\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        # https://tools.ietf.org/html/rfc7692#section-7.2.3.1\n        >> DataReceived(tctx.server, bytes.fromhex(\"c1 07 f2 48 cd c9 c9 07 00\"))\n        << websocket.WebsocketMessageHook(flow)\n        >> reply()\n        << SendData(tctx.client, bytes.fromhex(\"c1 07 f2 48 cd c9 c9 07 00\"))\n    )\n    assert flow.websocket.messages[0].content == b\"Hello\"\n\n\ndef test_unknown_ext(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    flow.response.headers[\"Sec-WebSocket-Extensions\"] = \"funky-bits; param=42\"\n    assert (\n        playbook\n        << Log(\"Ignoring unknown WebSocket extension 'funky-bits'.\")\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n    )\n\n\ndef test_websocket_connection_repr(tctx):\n    ws = websocket.WebsocketConnection(wsproto.ConnectionType.SERVER, conn=tctx.client)\n    assert repr(ws)\n\n\nclass TestFragmentizer:\n    def test_empty(self):\n        f = websocket.Fragmentizer([b\"foo\"], False)\n        assert list(f(b\"\")) == [\n            wsproto.events.BytesMessage(b\"\", message_finished=True),\n        ]\n\n    def test_keep_sizes(self):\n        f = websocket.Fragmentizer([b\"foo\", b\"bar\"], True)\n        assert list(f(b\"foobaz\")) == [\n            wsproto.events.TextMessage(\"foo\", message_finished=False),\n            wsproto.events.TextMessage(\"baz\", message_finished=True),\n        ]\n\n    def test_rechunk(self):\n        f = websocket.Fragmentizer([b\"foo\"], False)\n        f.FRAGMENT_SIZE = 4\n        assert list(f(b\"foobar\")) == [\n            wsproto.events.BytesMessage(b\"foob\", message_finished=False),\n            wsproto.events.BytesMessage(b\"ar\", message_finished=True),\n        ]\n\n\ndef test_inject_message(ws_testdata):\n    tctx, playbook, flow = ws_testdata\n    assert (\n        playbook\n        << websocket.WebsocketStartHook(flow)\n        >> reply()\n        >> WebSocketMessageInjected(\n            flow, WebSocketMessage(Opcode.TEXT, False, b\"hello\")\n        )\n        << websocket.WebsocketMessageHook(flow)\n    )\n    assert flow.websocket.messages[-1].content == b\"hello\"\n    assert flow.websocket.messages[-1].from_client is False\n    assert flow.websocket.messages[-1].injected is True\n    assert playbook >> reply() << SendData(tctx.client, b\"\\x81\\x05hello\")\n", "test/mitmproxy/proxy/layers/test_socks5_fuzz.py": "from hypothesis import given\nfrom hypothesis.strategies import binary\n\nfrom mitmproxy import options\nfrom mitmproxy.connection import Client\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.layers.modes import Socks5Proxy\n\nopts = options.Options()\ntctx = Context(\n    Client(\n        peername=(\"client\", 1234),\n        sockname=(\"127.0.0.1\", 8080),\n        timestamp_start=1605699329,\n    ),\n    opts,\n)\n\n\n@given(binary())\ndef test_socks5_fuzz(data):\n    layer = Socks5Proxy(tctx)\n    list(layer.handle_event(DataReceived(tctx.client, data)))\n", "test/mitmproxy/proxy/layers/test_modes.py": "import copy\n\nimport pytest\n\nfrom mitmproxy import dns\nfrom mitmproxy.addons.proxyauth import ProxyAuth\nfrom mitmproxy.connection import Client\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.connection import Server\nfrom mitmproxy.proxy import layers\nfrom mitmproxy.proxy.commands import CloseConnection\nfrom mitmproxy.proxy.commands import Log\nfrom mitmproxy.proxy.commands import OpenConnection\nfrom mitmproxy.proxy.commands import RequestWakeup\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.events import ConnectionClosed\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.layer import NextLayer\nfrom mitmproxy.proxy.layer import NextLayerHook\nfrom mitmproxy.proxy.layers import http\nfrom mitmproxy.proxy.layers import modes\nfrom mitmproxy.proxy.layers import quic\nfrom mitmproxy.proxy.layers import tcp\nfrom mitmproxy.proxy.layers import tls\nfrom mitmproxy.proxy.layers import udp\nfrom mitmproxy.proxy.layers.http import HTTPMode\nfrom mitmproxy.proxy.layers.tcp import TcpMessageHook\nfrom mitmproxy.proxy.layers.tcp import TcpStartHook\nfrom mitmproxy.proxy.layers.tls import ClientTLSLayer\nfrom mitmproxy.proxy.layers.tls import TlsStartClientHook\nfrom mitmproxy.proxy.layers.tls import TlsStartServerHook\nfrom mitmproxy.proxy.mode_specs import ProxyMode\nfrom mitmproxy.tcp import TCPFlow\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.udp import UDPFlow\nfrom test.mitmproxy.proxy.layers.test_tls import reply_tls_start_client\nfrom test.mitmproxy.proxy.layers.test_tls import reply_tls_start_server\nfrom test.mitmproxy.proxy.tutils import Placeholder\nfrom test.mitmproxy.proxy.tutils import Playbook\nfrom test.mitmproxy.proxy.tutils import reply\nfrom test.mitmproxy.proxy.tutils import reply_next_layer\n\n\ndef test_upstream_https(tctx):\n    \"\"\"\n    Test mitmproxy in HTTPS upstream mode with another mitmproxy instance upstream.\n    In other words:\n\n    mitmdump --mode upstream:https://localhost:8081 --ssl-insecure\n    mitmdump -p 8081\n    curl -x localhost:8080 -k http://example.com\n    \"\"\"\n    tctx1 = Context(\n        Client(\n            peername=(\"client\", 1234),\n            sockname=(\"127.0.0.1\", 8080),\n            timestamp_start=1605699329,\n            state=ConnectionState.OPEN,\n        ),\n        copy.deepcopy(tctx.options),\n    )\n    tctx1.client.proxy_mode = ProxyMode.parse(\n        \"upstream:https://example.mitmproxy.org:8081\"\n    )\n    tctx2 = Context(\n        Client(\n            peername=(\"client\", 4321),\n            sockname=(\"127.0.0.1\", 8080),\n            timestamp_start=1605699329,\n            state=ConnectionState.OPEN,\n        ),\n        copy.deepcopy(tctx.options),\n    )\n    assert tctx2.client.proxy_mode == ProxyMode.parse(\"regular\")\n    del tctx\n\n    proxy1 = Playbook(modes.HttpUpstreamProxy(tctx1), hooks=False)\n    proxy2 = Playbook(modes.HttpProxy(tctx2), hooks=False)\n\n    upstream = Placeholder(Server)\n    server = Placeholder(Server)\n    clienthello = Placeholder(bytes)\n    serverhello = Placeholder(bytes)\n    request = Placeholder(bytes)\n    tls_finished = Placeholder(bytes)\n    response = Placeholder(bytes)\n\n    assert (\n        proxy1\n        >> DataReceived(\n            tctx1.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << NextLayerHook(Placeholder(NextLayer))\n        >> reply_next_layer(lambda ctx: http.HttpLayer(ctx, HTTPMode.upstream))\n        << OpenConnection(upstream)\n        >> reply(None)\n        << TlsStartServerHook(Placeholder())\n        >> reply_tls_start_server(alpn=b\"http/1.1\")\n        << SendData(upstream, clienthello)\n    )\n    assert upstream().address == (\"example.mitmproxy.org\", 8081)\n    assert upstream().sni == \"example.mitmproxy.org\"\n    assert (\n        proxy2\n        >> DataReceived(tctx2.client, clienthello())\n        << NextLayerHook(Placeholder(NextLayer))\n        >> reply_next_layer(ClientTLSLayer)\n        << TlsStartClientHook(Placeholder())\n        >> reply_tls_start_client(alpn=b\"http/1.1\")\n        << SendData(tctx2.client, serverhello)\n    )\n    assert (\n        proxy1\n        # forward serverhello to proxy1\n        >> DataReceived(upstream, serverhello())\n        << SendData(upstream, request)\n    )\n    assert (\n        proxy2\n        >> DataReceived(tctx2.client, request())\n        << SendData(tctx2.client, tls_finished)\n        << NextLayerHook(Placeholder(NextLayer))\n        >> reply_next_layer(lambda ctx: http.HttpLayer(ctx, HTTPMode.regular))\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        << SendData(tctx2.client, response)\n    )\n    assert server().address == (\"example.com\", 80)\n\n    assert (\n        proxy1\n        >> DataReceived(upstream, tls_finished() + response())\n        << SendData(tctx1.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n    )\n\n\n@pytest.mark.parametrize(\"keep_host_header\", [True, False])\ndef test_reverse_proxy(tctx, keep_host_header):\n    \"\"\"Test mitmproxy in reverse proxy mode.\n\n    - make sure that we connect to the right host\n    - make sure that we respect keep_host_header\n    - make sure that we include non-standard ports in the host header (#4280)\n    \"\"\"\n    server = Placeholder(Server)\n    tctx.client.proxy_mode = ProxyMode.parse(\"reverse:http://localhost:8000\")\n    tctx.options.connection_strategy = \"lazy\"\n    tctx.options.keep_host_header = keep_host_header\n    assert (\n        Playbook(modes.ReverseProxy(tctx), hooks=False)\n        >> DataReceived(\n            tctx.client, b\"GET /foo HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\\r\\n\"\n        )\n        << NextLayerHook(Placeholder(NextLayer))\n        >> reply_next_layer(lambda ctx: http.HttpLayer(ctx, HTTPMode.transparent))\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(\n            server,\n            b\"GET /foo HTTP/1.1\\r\\n\"\n            b\"Host: \"\n            + (b\"example.com\" if keep_host_header else b\"localhost:8000\")\n            + b\"\\r\\n\\r\\n\",\n        )\n        >> DataReceived(server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n    )\n    assert server().address == (\"localhost\", 8000)\n\n\ndef test_reverse_dns(tctx):\n    tctx.client.transport_protocol = \"udp\"\n    tctx.server.transport_protocol = \"udp\"\n\n    f = Placeholder(dns.DNSFlow)\n    server = Placeholder(Server)\n    tctx.client.proxy_mode = ProxyMode.parse(\"reverse:dns://8.8.8.8:53\")\n    tctx.options.connection_strategy = \"lazy\"\n    assert (\n        Playbook(modes.ReverseProxy(tctx), hooks=False)\n        >> DataReceived(tctx.client, tflow.tdnsreq().packed)\n        << NextLayerHook(Placeholder(NextLayer))\n        >> reply_next_layer(layers.DNSLayer)\n        << layers.dns.DnsRequestHook(f)\n        >> reply(None)\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(tctx.server, tflow.tdnsreq().packed)\n    )\n    assert server().address == (\"8.8.8.8\", 53)\n\n\n@pytest.mark.parametrize(\"keep_host_header\", [True, False])\ndef test_quic(tctx: Context, keep_host_header: bool):\n    with taddons.context():\n        tctx.options.keep_host_header = keep_host_header\n        tctx.server.sni = \"other.example.com\"\n        tctx.client.proxy_mode = ProxyMode.parse(\"reverse:quic://example.org:443\")\n        client_hello = Placeholder(bytes)\n\n        def set_settings(data: quic.QuicTlsData):\n            data.settings = quic.QuicTlsSettings()\n\n        assert (\n            Playbook(modes.ReverseProxy(tctx))\n            << OpenConnection(tctx.server)\n            >> reply(None)\n            >> DataReceived(tctx.client, b\"\\x00\")\n            << NextLayerHook(Placeholder(NextLayer))\n            >> reply_next_layer(layers.ServerQuicLayer)\n            << quic.QuicStartServerHook(Placeholder(quic.QuicTlsData))\n            >> reply(side_effect=set_settings)\n            << SendData(tctx.server, client_hello)\n            << RequestWakeup(Placeholder(float))\n        )\n        assert tctx.server.address == (\"example.org\", 443)\n        assert quic.quic_parse_client_hello(client_hello()).sni == (\n            \"other.example.com\" if keep_host_header else \"example.org\"\n        )\n\n\ndef test_udp(tctx: Context):\n    tctx.client.proxy_mode = ProxyMode.parse(\"reverse:udp://1.2.3.4:5\")\n    flow = Placeholder(UDPFlow)\n    assert (\n        Playbook(modes.ReverseProxy(tctx))\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        >> DataReceived(tctx.client, b\"test-input\")\n        << NextLayerHook(Placeholder(NextLayer))\n        >> reply_next_layer(layers.UDPLayer)\n        << udp.UdpStartHook(flow)\n        >> reply()\n        << udp.UdpMessageHook(flow)\n        >> reply()\n        << SendData(tctx.server, b\"test-input\")\n    )\n    assert tctx.server.address == (\"1.2.3.4\", 5)\n    assert len(flow().messages) == 1\n    assert flow().messages[0].content == b\"test-input\"\n\n\n@pytest.mark.parametrize(\"patch\", [True, False])\n@pytest.mark.parametrize(\"connection_strategy\", [\"eager\", \"lazy\"])\ndef test_reverse_proxy_tcp_over_tls(\n    tctx: Context, monkeypatch, patch, connection_strategy\n):\n    \"\"\"\n    Test\n        client --TCP-- mitmproxy --TCP over TLS-- server\n    reverse proxying.\n    \"\"\"\n\n    flow = Placeholder(TCPFlow)\n    data = Placeholder(bytes)\n    tctx.client.proxy_mode = ProxyMode.parse(\"reverse:https://localhost:8000\")\n    tctx.options.connection_strategy = connection_strategy\n    playbook = Playbook(modes.ReverseProxy(tctx))\n    if connection_strategy == \"eager\":\n        (\n            playbook\n            << OpenConnection(tctx.server)\n            >> DataReceived(tctx.client, b\"\\x01\\x02\\x03\")\n            >> reply(None, to=OpenConnection(tctx.server))\n        )\n    else:\n        (playbook >> DataReceived(tctx.client, b\"\\x01\\x02\\x03\"))\n    if patch:\n        (\n            playbook\n            << NextLayerHook(Placeholder(NextLayer))\n            >> reply_next_layer(tcp.TCPLayer)\n            << TcpStartHook(flow)\n            >> reply()\n        )\n        if connection_strategy == \"lazy\":\n            (\n                playbook\n                # only now we open a connection\n                << OpenConnection(tctx.server)\n                >> reply(None)\n            )\n        assert (\n            playbook << TcpMessageHook(flow) >> reply() << SendData(tctx.server, data)\n        )\n        assert data() == b\"\\x01\\x02\\x03\"\n    else:\n        (\n            playbook\n            << NextLayerHook(Placeholder(NextLayer))\n            >> reply_next_layer(tls.ServerTLSLayer)\n        )\n        if connection_strategy == \"lazy\":\n            (\n                playbook\n                << NextLayerHook(Placeholder(NextLayer))\n                >> reply_next_layer(tcp.TCPLayer)\n                << TcpStartHook(flow)\n                >> reply()\n                << OpenConnection(tctx.server)\n                >> reply(None)\n            )\n        assert (\n            playbook\n            << TlsStartServerHook(Placeholder())\n            >> reply_tls_start_server()\n            << SendData(tctx.server, data)\n        )\n        assert tls.parse_client_hello(data()).sni == \"localhost\"\n\n\n@pytest.mark.parametrize(\"connection_strategy\", [\"eager\", \"lazy\"])\ndef test_transparent_tcp(tctx: Context, connection_strategy):\n    flow = Placeholder(TCPFlow)\n    tctx.options.connection_strategy = connection_strategy\n    tctx.server.address = (\"address\", 22)\n\n    playbook = Playbook(modes.TransparentProxy(tctx))\n    if connection_strategy == \"lazy\":\n        assert playbook\n    else:\n        assert (\n            playbook\n            << OpenConnection(tctx.server)\n            >> reply(None)\n            >> DataReceived(tctx.server, b\"hello\")\n            << NextLayerHook(Placeholder(NextLayer))\n            >> reply_next_layer(tcp.TCPLayer)\n            << TcpStartHook(flow)\n            >> reply()\n            << TcpMessageHook(flow)\n            >> reply()\n            << SendData(tctx.client, b\"hello\")\n        )\n        assert flow().messages[0].content == b\"hello\"\n        assert not flow().messages[0].from_client\n\n    assert tctx.server.address == (\"address\", 22)\n\n\ndef test_reverse_eager_connect_failure(tctx: Context):\n    \"\"\"\n    Test\n        client --TCP-- mitmproxy --TCP over TLS-- server\n    reverse proxying.\n    \"\"\"\n\n    tctx.client.proxy_mode = ProxyMode.parse(\"reverse:https://localhost:8000\")\n    tctx.options.connection_strategy = \"eager\"\n    playbook = Playbook(modes.ReverseProxy(tctx))\n    assert (\n        playbook\n        << OpenConnection(tctx.server)\n        >> reply(\"IPoAC unstable\")\n        << CloseConnection(tctx.client)\n        >> ConnectionClosed(tctx.client)\n    )\n\n\ndef test_transparent_eager_connect_failure(tctx: Context):\n    \"\"\"Test that we recover from a transparent mode connect error.\"\"\"\n    tctx.options.connection_strategy = \"eager\"\n    tctx.server.address = (\"address\", 22)\n\n    assert (\n        Playbook(modes.TransparentProxy(tctx), logs=True)\n        << OpenConnection(tctx.server)\n        >> reply(\"something something\")\n        << CloseConnection(tctx.client)\n        >> ConnectionClosed(tctx.client)\n    )\n\n\nCLIENT_HELLO = b\"\\x05\\x01\\x00\"\nSERVER_HELLO = b\"\\x05\\x00\"\n\n\n@pytest.mark.parametrize(\n    \"address,packed\",\n    [\n        (\"127.0.0.1\", b\"\\x01\\x7f\\x00\\x00\\x01\"),\n        (\n            \"::1\",\n            b\"\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\",\n        ),\n        (\"example.com\", b\"\\x03\\x0bexample.com\"),\n    ],\n)\ndef test_socks5_success(address: str, packed: bytes, tctx: Context):\n    tctx.options.connection_strategy = \"eager\"\n    playbook = Playbook(modes.Socks5Proxy(tctx))\n    server = Placeholder(Server)\n    nextlayer = Placeholder(NextLayer)\n    assert (\n        playbook\n        >> DataReceived(tctx.client, CLIENT_HELLO)\n        << SendData(tctx.client, SERVER_HELLO)\n        >> DataReceived(\n            tctx.client, b\"\\x05\\x01\\x00\" + packed + b\"\\x12\\x34applicationdata\"\n        )\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(tctx.client, b\"\\x05\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\")\n        << NextLayerHook(nextlayer)\n    )\n    assert server().address == (address, 0x1234)\n    assert nextlayer().data_client() == b\"applicationdata\"\n\n\ndef _valid_socks_auth(data: modes.Socks5AuthData):\n    data.valid = True\n\n\ndef test_socks5_trickle(tctx: Context):\n    ProxyAuth().load(tctx.options)\n    tctx.options.proxyauth = \"user:password\"\n    tctx.options.connection_strategy = \"lazy\"\n    playbook = Playbook(modes.Socks5Proxy(tctx))\n    for x in b\"\\x05\\x01\\x02\":\n        playbook >> DataReceived(tctx.client, bytes([x]))\n    playbook << SendData(tctx.client, b\"\\x05\\x02\")\n    for x in b\"\\x01\\x04user\\x08password\":\n        playbook >> DataReceived(tctx.client, bytes([x]))\n    playbook << modes.Socks5AuthHook(Placeholder())\n    playbook >> reply(side_effect=_valid_socks_auth)\n    playbook << SendData(tctx.client, b\"\\x01\\x00\")\n    for x in b\"\\x05\\x01\\x00\\x01\\x7f\\x00\\x00\\x01\\x12\\x34\":\n        playbook >> DataReceived(tctx.client, bytes([x]))\n    assert playbook << SendData(\n        tctx.client, b\"\\x05\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\"\n    )\n\n\n@pytest.mark.parametrize(\n    \"data,err,msg\",\n    [\n        (\n            b\"GET / HTTP/1.1\",\n            None,\n            \"Probably not a SOCKS request but a regular HTTP request. Invalid SOCKS version. Expected 0x05, got 0x47\",\n        ),\n        (b\"abcd\", None, \"Invalid SOCKS version. Expected 0x05, got 0x61\"),\n        (\n            CLIENT_HELLO + b\"\\x05\\x02\\x00\\x01\\x7f\\x00\\x00\\x01\\x12\\x34\",\n            SERVER_HELLO + b\"\\x05\\x07\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\",\n            r\"Unsupported SOCKS5 request: b'\\x05\\x02\\x00\\x01\\x7f\\x00\\x00\\x01\\x124'\",\n        ),\n        (\n            CLIENT_HELLO + b\"\\x05\\x01\\x00\\xff\\x00\\x00\",\n            SERVER_HELLO + b\"\\x05\\x08\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\",\n            r\"Unknown address type: 255\",\n        ),\n    ],\n)\ndef test_socks5_err(data: bytes, err: bytes, msg: str, tctx: Context):\n    playbook = Playbook(modes.Socks5Proxy(tctx), logs=True) >> DataReceived(\n        tctx.client, data\n    )\n    if err:\n        playbook << SendData(tctx.client, err)\n    playbook << CloseConnection(tctx.client)\n    playbook << Log(msg)\n    assert playbook\n\n\n@pytest.mark.parametrize(\n    \"client_greeting,server_choice,client_auth,server_resp,address,packed\",\n    [\n        (\n            b\"\\x05\\x01\\x02\",\n            b\"\\x05\\x02\",\n            b\"\\x01\\x04user\\x08password\",\n            b\"\\x01\\x00\",\n            \"127.0.0.1\",\n            b\"\\x01\\x7f\\x00\\x00\\x01\",\n        ),\n        (\n            b\"\\x05\\x02\\x01\\x02\",\n            b\"\\x05\\x02\",\n            b\"\\x01\\x04user\\x08password\",\n            b\"\\x01\\x00\",\n            \"127.0.0.1\",\n            b\"\\x01\\x7f\\x00\\x00\\x01\",\n        ),\n    ],\n)\ndef test_socks5_auth_success(\n    client_greeting: bytes,\n    server_choice: bytes,\n    client_auth: bytes,\n    server_resp: bytes,\n    address: bytes,\n    packed: bytes,\n    tctx: Context,\n):\n    ProxyAuth().load(tctx.options)\n    tctx.options.proxyauth = \"user:password\"\n    server = Placeholder(Server)\n    nextlayer = Placeholder(NextLayer)\n    playbook = (\n        Playbook(modes.Socks5Proxy(tctx), logs=True)\n        >> DataReceived(tctx.client, client_greeting)\n        << SendData(tctx.client, server_choice)\n        >> DataReceived(tctx.client, client_auth)\n        << modes.Socks5AuthHook(Placeholder(modes.Socks5AuthData))\n        >> reply(side_effect=_valid_socks_auth)\n        << SendData(tctx.client, server_resp)\n        >> DataReceived(\n            tctx.client, b\"\\x05\\x01\\x00\" + packed + b\"\\x12\\x34applicationdata\"\n        )\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(tctx.client, b\"\\x05\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\")\n        << NextLayerHook(nextlayer)\n    )\n    assert playbook\n    assert server().address == (address, 0x1234)\n    assert nextlayer().data_client() == b\"applicationdata\"\n\n\n@pytest.mark.parametrize(\n    \"client_greeting,server_choice,client_auth,err,msg\",\n    [\n        (\n            b\"\\x05\\x01\\x00\",\n            None,\n            None,\n            b\"\\x05\\xff\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\",\n            \"Client does not support SOCKS5 with user/password authentication.\",\n        ),\n        (\n            b\"\\x05\\x02\\x00\\x02\",\n            b\"\\x05\\x02\",\n            b\"\\x01\\x04\" + b\"user\" + b\"\\x07\" + b\"errcode\",\n            b\"\\x01\\x01\",\n            \"authentication failed\",\n        ),\n    ],\n)\ndef test_socks5_auth_fail(\n    client_greeting: bytes,\n    server_choice: bytes,\n    client_auth: bytes,\n    err: bytes,\n    msg: str,\n    tctx: Context,\n):\n    ProxyAuth().load(tctx.options)\n    tctx.options.proxyauth = \"user:password\"\n    playbook = Playbook(modes.Socks5Proxy(tctx), logs=True) >> DataReceived(\n        tctx.client, client_greeting\n    )\n    if server_choice is None:\n        playbook << SendData(tctx.client, err)\n    else:\n        playbook << SendData(tctx.client, server_choice)\n        playbook >> DataReceived(tctx.client, client_auth)\n        playbook << modes.Socks5AuthHook(Placeholder(modes.Socks5AuthData))\n        playbook >> reply()\n        playbook << SendData(tctx.client, err)\n\n    playbook << CloseConnection(tctx.client)\n    playbook << Log(msg)\n    assert playbook\n\n\ndef test_socks5_eager_err(tctx: Context):\n    tctx.options.connection_strategy = \"eager\"\n    server = Placeholder(Server)\n    assert (\n        Playbook(modes.Socks5Proxy(tctx))\n        >> DataReceived(tctx.client, CLIENT_HELLO)\n        << SendData(tctx.client, SERVER_HELLO)\n        >> DataReceived(tctx.client, b\"\\x05\\x01\\x00\\x01\\x7f\\x00\\x00\\x01\\x12\\x34\")\n        << OpenConnection(server)\n        >> reply(\"out of socks\")\n        << SendData(tctx.client, b\"\\x05\\x04\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\")\n        << CloseConnection(tctx.client)\n    )\n\n\ndef test_socks5_premature_close(tctx: Context):\n    assert (\n        Playbook(modes.Socks5Proxy(tctx), logs=True)\n        >> DataReceived(tctx.client, b\"\\x05\")\n        >> ConnectionClosed(tctx.client)\n        << Log(r\"Client closed connection before completing SOCKS5 handshake: b'\\x05'\")\n        << CloseConnection(tctx.client)\n    )\n", "test/mitmproxy/proxy/layers/test_tcp.py": "import pytest\n\nfrom ..tutils import Placeholder\nfrom ..tutils import Playbook\nfrom ..tutils import reply\nfrom mitmproxy.proxy.commands import CloseConnection\nfrom mitmproxy.proxy.commands import CloseTcpConnection\nfrom mitmproxy.proxy.commands import OpenConnection\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.events import ConnectionClosed\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.layers import tcp\nfrom mitmproxy.proxy.layers.tcp import TcpMessageInjected\nfrom mitmproxy.tcp import TCPFlow\nfrom mitmproxy.tcp import TCPMessage\n\n\ndef test_open_connection(tctx):\n    \"\"\"\n    If there is no server connection yet, establish one,\n    because the server may send data first.\n    \"\"\"\n    assert Playbook(tcp.TCPLayer(tctx, True)) << OpenConnection(tctx.server)\n\n    tctx.server.timestamp_start = 1624544785\n    assert Playbook(tcp.TCPLayer(tctx, True)) << None\n\n\ndef test_open_connection_err(tctx):\n    f = Placeholder(TCPFlow)\n    assert (\n        Playbook(tcp.TCPLayer(tctx))\n        << tcp.TcpStartHook(f)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(\"Connect call failed\")\n        << tcp.TcpErrorHook(f)\n        >> reply()\n        << CloseConnection(tctx.client)\n    )\n\n\ndef test_simple(tctx):\n    \"\"\"open connection, receive data, send it to peer\"\"\"\n    f = Placeholder(TCPFlow)\n\n    assert (\n        Playbook(tcp.TCPLayer(tctx))\n        << tcp.TcpStartHook(f)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        >> DataReceived(tctx.client, b\"hello!\")\n        << tcp.TcpMessageHook(f)\n        >> reply()\n        << SendData(tctx.server, b\"hello!\")\n        >> DataReceived(tctx.server, b\"hi\")\n        << tcp.TcpMessageHook(f)\n        >> reply()\n        << SendData(tctx.client, b\"hi\")\n        >> ConnectionClosed(tctx.server)\n        << CloseTcpConnection(tctx.client, half_close=True)\n        >> ConnectionClosed(tctx.client)\n        << CloseConnection(tctx.server)\n        << tcp.TcpEndHook(f)\n        >> reply()\n        >> ConnectionClosed(tctx.client)\n        << None\n    )\n    assert len(f().messages) == 2\n\n\ndef test_receive_data_before_server_connected(tctx):\n    \"\"\"\n    assert that data received before a server connection is established\n    will still be forwarded.\n    \"\"\"\n    assert (\n        Playbook(tcp.TCPLayer(tctx), hooks=False)\n        << OpenConnection(tctx.server)\n        >> DataReceived(tctx.client, b\"hello!\")\n        >> reply(None, to=-2)\n        << SendData(tctx.server, b\"hello!\")\n    )\n\n\ndef test_receive_data_after_half_close(tctx):\n    \"\"\"\n    data received after the other connection has been half-closed should still be forwarded.\n    \"\"\"\n    assert (\n        Playbook(tcp.TCPLayer(tctx), hooks=False)\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        >> DataReceived(tctx.client, b\"eof-delimited-request\")\n        << SendData(tctx.server, b\"eof-delimited-request\")\n        >> ConnectionClosed(tctx.client)\n        << CloseTcpConnection(tctx.server, half_close=True)\n        >> DataReceived(tctx.server, b\"i'm late\")\n        << SendData(tctx.client, b\"i'm late\")\n        >> ConnectionClosed(tctx.server)\n        << CloseConnection(tctx.client)\n    )\n\n\n@pytest.mark.parametrize(\"ignore\", [True, False])\ndef test_ignore(tctx, ignore):\n    \"\"\"\n    no flow hooks when we set ignore.\n    \"\"\"\n\n    def no_flow_hooks():\n        assert (\n            Playbook(tcp.TCPLayer(tctx, ignore=ignore), hooks=True)\n            << OpenConnection(tctx.server)\n            >> reply(None)\n            >> DataReceived(tctx.client, b\"hello!\")\n            << SendData(tctx.server, b\"hello!\")\n        )\n\n    if ignore:\n        no_flow_hooks()\n    else:\n        with pytest.raises(AssertionError):\n            no_flow_hooks()\n\n\ndef test_inject(tctx):\n    \"\"\"inject data into an open connection.\"\"\"\n    f = Placeholder(TCPFlow)\n\n    assert (\n        Playbook(tcp.TCPLayer(tctx))\n        << tcp.TcpStartHook(f)\n        >> TcpMessageInjected(f, TCPMessage(True, b\"hello!\"))\n        >> reply(to=-2)\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        << tcp.TcpMessageHook(f)\n        >> reply()\n        << SendData(tctx.server, b\"hello!\")\n        # and the other way...\n        >> TcpMessageInjected(\n            f, TCPMessage(False, b\"I have already done the greeting for you.\")\n        )\n        << tcp.TcpMessageHook(f)\n        >> reply()\n        << SendData(tctx.client, b\"I have already done the greeting for you.\")\n        << None\n    )\n    assert len(f().messages) == 2\n", "test/mitmproxy/proxy/layers/__init__.py": "", "test/mitmproxy/proxy/layers/test_udp.py": "import pytest\n\nfrom ..tutils import Placeholder\nfrom ..tutils import Playbook\nfrom ..tutils import reply\nfrom mitmproxy.proxy.commands import CloseConnection\nfrom mitmproxy.proxy.commands import OpenConnection\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.events import ConnectionClosed\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.layers import udp\nfrom mitmproxy.proxy.layers.udp import UdpMessageInjected\nfrom mitmproxy.udp import UDPFlow\nfrom mitmproxy.udp import UDPMessage\n\n\ndef test_open_connection(tctx):\n    \"\"\"\n    If there is no server connection yet, establish one,\n    because the server may send data first.\n    \"\"\"\n    assert Playbook(udp.UDPLayer(tctx, True)) << OpenConnection(tctx.server)\n\n    tctx.server.timestamp_start = 1624544785\n    assert Playbook(udp.UDPLayer(tctx, True)) << None\n\n\ndef test_open_connection_err(tctx):\n    f = Placeholder(UDPFlow)\n    assert (\n        Playbook(udp.UDPLayer(tctx))\n        << udp.UdpStartHook(f)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(\"Connect call failed\")\n        << udp.UdpErrorHook(f)\n        >> reply()\n        << CloseConnection(tctx.client)\n    )\n\n\ndef test_simple(tctx):\n    \"\"\"open connection, receive data, send it to peer\"\"\"\n    f = Placeholder(UDPFlow)\n\n    assert (\n        Playbook(udp.UDPLayer(tctx))\n        << udp.UdpStartHook(f)\n        >> reply()\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        >> DataReceived(tctx.client, b\"hello!\")\n        << udp.UdpMessageHook(f)\n        >> reply()\n        << SendData(tctx.server, b\"hello!\")\n        >> DataReceived(tctx.server, b\"hi\")\n        << udp.UdpMessageHook(f)\n        >> reply()\n        << SendData(tctx.client, b\"hi\")\n        >> ConnectionClosed(tctx.server)\n        << CloseConnection(tctx.client)\n        << udp.UdpEndHook(f)\n        >> reply()\n        >> DataReceived(tctx.server, b\"ignored\")\n        << None\n    )\n    assert len(f().messages) == 2\n\n\ndef test_receive_data_before_server_connected(tctx):\n    \"\"\"\n    assert that data received before a server connection is established\n    will still be forwarded.\n    \"\"\"\n    assert (\n        Playbook(udp.UDPLayer(tctx), hooks=False)\n        << OpenConnection(tctx.server)\n        >> DataReceived(tctx.client, b\"hello!\")\n        >> reply(None, to=-2)\n        << SendData(tctx.server, b\"hello!\")\n    )\n\n\n@pytest.mark.parametrize(\"ignore\", [True, False])\ndef test_ignore(tctx, ignore):\n    \"\"\"\n    no flow hooks when we set ignore.\n    \"\"\"\n\n    def no_flow_hooks():\n        assert (\n            Playbook(udp.UDPLayer(tctx, ignore=ignore), hooks=True)\n            << OpenConnection(tctx.server)\n            >> reply(None)\n            >> DataReceived(tctx.client, b\"hello!\")\n            << SendData(tctx.server, b\"hello!\")\n        )\n\n    if ignore:\n        no_flow_hooks()\n    else:\n        with pytest.raises(AssertionError):\n            no_flow_hooks()\n\n\ndef test_inject(tctx):\n    \"\"\"inject data into an open connection.\"\"\"\n    f = Placeholder(UDPFlow)\n\n    assert (\n        Playbook(udp.UDPLayer(tctx))\n        << udp.UdpStartHook(f)\n        >> UdpMessageInjected(f, UDPMessage(True, b\"hello!\"))\n        >> reply(to=-2)\n        << OpenConnection(tctx.server)\n        >> reply(None)\n        << udp.UdpMessageHook(f)\n        >> reply()\n        << SendData(tctx.server, b\"hello!\")\n        # and the other way...\n        >> UdpMessageInjected(\n            f, UDPMessage(False, b\"I have already done the greeting for you.\")\n        )\n        << udp.UdpMessageHook(f)\n        >> reply()\n        << SendData(tctx.client, b\"I have already done the greeting for you.\")\n        << None\n    )\n    assert len(f().messages) == 2\n", "test/mitmproxy/proxy/layers/http/test_http2.py": "import time\nfrom logging import DEBUG\n\nimport h2.settings\nimport hpack\nimport hyperframe.frame\nimport pytest\nfrom h2.errors import ErrorCodes\n\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.connection import Server\nfrom mitmproxy.flow import Error\nfrom mitmproxy.http import Headers\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.http import Request\nfrom mitmproxy.net.http import status_codes\nfrom mitmproxy.proxy.commands import CloseConnection\nfrom mitmproxy.proxy.commands import Log\nfrom mitmproxy.proxy.commands import OpenConnection\nfrom mitmproxy.proxy.commands import RequestWakeup\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.events import ConnectionClosed\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.layers import http\nfrom mitmproxy.proxy.layers.http import HTTPMode\nfrom mitmproxy.proxy.layers.http._http2 import Http2Client\nfrom mitmproxy.proxy.layers.http._http2 import split_pseudo_headers\nfrom test.mitmproxy.proxy.layers.http.hyper_h2_test_helpers import FrameFactory\nfrom test.mitmproxy.proxy.tutils import Placeholder\nfrom test.mitmproxy.proxy.tutils import Playbook\nfrom test.mitmproxy.proxy.tutils import reply\n\nexample_request_headers = (\n    (b\":method\", b\"GET\"),\n    (b\":scheme\", b\"http\"),\n    (b\":path\", b\"/\"),\n    (b\":authority\", b\"example.com\"),\n)\n\nexample_response_headers = ((b\":status\", b\"200\"),)\n\nexample_request_trailers = ((b\"req-trailer-a\", b\"a\"), (b\"req-trailer-b\", b\"b\"))\n\nexample_response_trailers = ((b\"resp-trailer-a\", b\"a\"), (b\"resp-trailer-b\", b\"b\"))\n\n\n@pytest.fixture\ndef open_h2_server_conn():\n    # this is a bit fake here (port 80, with alpn, but no tls - c'mon),\n    # but we don't want to pollute our tests with TLS handshakes.\n    s = Server(address=(\"example.com\", 80))\n    s.state = ConnectionState.OPEN\n    s.alpn = b\"h2\"\n    return s\n\n\ndef decode_frames(data: bytes) -> list[hyperframe.frame.Frame]:\n    # swallow preamble\n    if data.startswith(b\"PRI * HTTP/2.0\"):\n        data = data[24:]\n    frames = []\n    while data:\n        f, length = hyperframe.frame.Frame.parse_frame_header(data[:9])\n        f.parse_body(memoryview(data[9 : 9 + length]))\n        frames.append(f)\n        data = data[9 + length :]\n    return frames\n\n\ndef start_h2_client(tctx: Context, keepalive: int = 0) -> tuple[Playbook, FrameFactory]:\n    tctx.client.alpn = b\"h2\"\n    tctx.options.http2_ping_keepalive = keepalive\n    frame_factory = FrameFactory()\n\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n    assert (\n        playbook\n        << SendData(tctx.client, Placeholder())  # initial settings frame\n        >> DataReceived(tctx.client, frame_factory.preamble())\n        >> DataReceived(\n            tctx.client, frame_factory.build_settings_frame({}, ack=True).serialize()\n        )\n    )\n    return playbook, frame_factory\n\n\ndef make_h2(open_connection: OpenConnection) -> None:\n    assert isinstance(\n        open_connection, OpenConnection\n    ), f\"Expected OpenConnection event, not {open_connection}\"\n    open_connection.connection.alpn = b\"h2\"\n\n\ndef test_simple(tctx):\n    playbook, cff = start_h2_client(tctx)\n    flow = Placeholder(HTTPFlow)\n    server = Placeholder(Server)\n    initial = Placeholder(bytes)\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << SendData(server, initial)\n    )\n    frames = decode_frames(initial())\n    assert [type(x) for x in frames] == [\n        hyperframe.frame.SettingsFrame,\n        hyperframe.frame.HeadersFrame,\n    ]\n    sff = FrameFactory()\n    assert (\n        playbook\n        # a conforming h2 server would send settings first, we disregard this for now.\n        >> DataReceived(\n            server, sff.build_headers_frame(example_response_headers).serialize()\n        )\n        << http.HttpResponseHeadersHook(flow)\n        >> reply()\n        >> DataReceived(\n            server,\n            sff.build_data_frame(b\"Hello, World!\", flags=[\"END_STREAM\"]).serialize(),\n        )\n        << http.HttpResponseHook(flow)\n        >> reply()\n        << SendData(\n            tctx.client,\n            cff.build_headers_frame(example_response_headers).serialize()\n            + cff.build_data_frame(b\"Hello, World!\").serialize()\n            + cff.build_data_frame(b\"\", flags=[\"END_STREAM\"]).serialize(),\n        )\n    )\n    assert flow().request.url == \"http://example.com/\"\n    assert flow().response.text == \"Hello, World!\"\n\n\n@pytest.mark.parametrize(\"stream\", [\"stream\", \"\"])\ndef test_response_trailers(tctx: Context, open_h2_server_conn: Server, stream):\n    playbook, cff = start_h2_client(tctx)\n    tctx.server = open_h2_server_conn\n    sff = FrameFactory()\n\n    def enable_streaming(flow: HTTPFlow):\n        flow.response.stream = bool(stream)\n\n    flow = Placeholder(HTTPFlow)\n    (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << SendData(tctx.server, Placeholder(bytes))\n        # a conforming h2 server would send settings first, we disregard this for now.\n        >> DataReceived(\n            tctx.server,\n            sff.build_headers_frame(example_response_headers).serialize()\n            + sff.build_data_frame(b\"Hello, World!\").serialize(),\n        )\n        << http.HttpResponseHeadersHook(flow)\n        >> reply(side_effect=enable_streaming)\n    )\n    if stream:\n        playbook << SendData(\n            tctx.client,\n            cff.build_headers_frame(example_response_headers).serialize()\n            + cff.build_data_frame(b\"Hello, World!\").serialize(),\n        )\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.server,\n            sff.build_headers_frame(\n                example_response_trailers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpResponseHook(flow)\n    )\n    assert flow().response.trailers\n    del flow().response.trailers[\"resp-trailer-a\"]\n    if stream:\n        assert (\n            playbook\n            >> reply()\n            << SendData(\n                tctx.client,\n                cff.build_headers_frame(\n                    example_response_trailers[1:], flags=[\"END_STREAM\"]\n                ).serialize(),\n            )\n        )\n    else:\n        assert (\n            playbook\n            >> reply()\n            << SendData(\n                tctx.client,\n                cff.build_headers_frame(example_response_headers).serialize()\n                + cff.build_data_frame(b\"Hello, World!\").serialize()\n                + cff.build_headers_frame(\n                    example_response_trailers[1:], flags=[\"END_STREAM\"]\n                ).serialize(),\n            )\n        )\n\n\n@pytest.mark.parametrize(\"stream\", [\"stream\", \"\"])\ndef test_request_trailers(tctx: Context, open_h2_server_conn: Server, stream):\n    playbook, cff = start_h2_client(tctx)\n    tctx.server = open_h2_server_conn\n\n    def enable_streaming(flow: HTTPFlow):\n        flow.request.stream = bool(stream)\n\n    flow = Placeholder(HTTPFlow)\n    server_data1 = Placeholder(bytes)\n    server_data2 = Placeholder(bytes)\n    (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(example_request_headers).serialize()\n            + cff.build_data_frame(b\"Hello, World!\").serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply(side_effect=enable_streaming)\n    )\n    if stream:\n        playbook << SendData(tctx.server, server_data1)\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_trailers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << SendData(tctx.server, server_data2)\n    )\n    frames = decode_frames(server_data1.setdefault(b\"\") + server_data2())\n    assert [type(x) for x in frames] == [\n        hyperframe.frame.SettingsFrame,\n        hyperframe.frame.HeadersFrame,\n        hyperframe.frame.DataFrame,\n        hyperframe.frame.HeadersFrame,\n    ]\n\n\ndef test_upstream_error(tctx):\n    playbook, cff = start_h2_client(tctx)\n    flow = Placeholder(HTTPFlow)\n    server = Placeholder(Server)\n    err = Placeholder(bytes)\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(\"oops server <> error\")\n        << http.HttpErrorHook(flow)\n        >> reply()\n        << SendData(tctx.client, err)\n    )\n    frames = decode_frames(err())\n    assert [type(x) for x in frames] == [\n        hyperframe.frame.HeadersFrame,\n        hyperframe.frame.DataFrame,\n    ]\n    d = frames[1]\n    assert isinstance(d, hyperframe.frame.DataFrame)\n    assert b\"502 Bad Gateway\" in d.data\n    assert b\"server &lt;&gt; error\" in d.data\n\n\n@pytest.mark.parametrize(\"trailers\", [\"trailers\", \"\"])\ndef test_long_response(tctx: Context, trailers):\n    playbook, cff = start_h2_client(tctx)\n    flow = Placeholder(HTTPFlow)\n    server = Placeholder(Server)\n    initial = Placeholder(bytes)\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << SendData(server, initial)\n    )\n    frames = decode_frames(initial())\n    assert [type(x) for x in frames] == [\n        hyperframe.frame.SettingsFrame,\n        hyperframe.frame.HeadersFrame,\n    ]\n    sff = FrameFactory()\n    assert (\n        playbook\n        # a conforming h2 server would send settings first, we disregard this for now.\n        >> DataReceived(\n            server, sff.build_headers_frame(example_response_headers).serialize()\n        )\n        << http.HttpResponseHeadersHook(flow)\n        >> reply()\n        >> DataReceived(\n            server, sff.build_data_frame(b\"a\" * 10000, flags=[]).serialize()\n        )\n        >> DataReceived(\n            server,\n            sff.build_data_frame(b\"a\" * 10000, flags=[]).serialize(),\n        )\n        >> DataReceived(\n            server,\n            sff.build_data_frame(b\"a\" * 10000, flags=[]).serialize(),\n        )\n        >> DataReceived(\n            server,\n            sff.build_data_frame(b\"a\" * 10000, flags=[]).serialize(),\n        )\n        << SendData(\n            server,\n            sff.build_window_update_frame(0, 40000).serialize()\n            + sff.build_window_update_frame(1, 40000).serialize(),\n        )\n        >> DataReceived(\n            server,\n            sff.build_data_frame(b\"a\" * 10000, flags=[]).serialize(),\n        )\n        >> DataReceived(\n            server,\n            sff.build_data_frame(b\"a\" * 10000, flags=[]).serialize(),\n        )\n        >> DataReceived(\n            server,\n            sff.build_data_frame(b\"a\" * 10000, flags=[]).serialize(),\n        )\n    )\n    if trailers:\n        (\n            playbook\n            >> DataReceived(\n                server,\n                sff.build_headers_frame(\n                    example_response_trailers, flags=[\"END_STREAM\"]\n                ).serialize(),\n            )\n        )\n    else:\n        (\n            playbook\n            >> DataReceived(\n                server,\n                sff.build_data_frame(b\"\", flags=[\"END_STREAM\"]).serialize(),\n            )\n        )\n    (\n        playbook\n        << http.HttpResponseHook(flow)\n        >> reply()\n        << SendData(\n            tctx.client,\n            cff.build_headers_frame(example_response_headers).serialize()\n            + cff.build_data_frame(b\"a\" * 16384).serialize(),\n        )\n        << SendData(\n            tctx.client,\n            cff.build_data_frame(b\"a\" * 16384).serialize(),\n        )\n        << SendData(\n            tctx.client,\n            cff.build_data_frame(b\"a\" * 16384).serialize(),\n        )\n        << SendData(\n            tctx.client,\n            cff.build_data_frame(b\"a\" * 16383).serialize(),\n        )\n        >> DataReceived(\n            tctx.client,\n            cff.build_window_update_frame(0, 65535).serialize()\n            + cff.build_window_update_frame(1, 65535).serialize(),\n        )\n    )\n    if trailers:\n        assert (\n            playbook\n            << SendData(\n                tctx.client,\n                cff.build_data_frame(b\"a\" * 1).serialize(),\n            )\n            << SendData(tctx.client, cff.build_data_frame(b\"a\" * 4464).serialize())\n            << SendData(\n                tctx.client,\n                cff.build_headers_frame(\n                    example_response_trailers, flags=[\"END_STREAM\"]\n                ).serialize(),\n            )\n        )\n    else:\n        assert (\n            playbook\n            << SendData(\n                tctx.client,\n                cff.build_data_frame(b\"a\" * 1).serialize(),\n            )\n            << SendData(tctx.client, cff.build_data_frame(b\"a\" * 4464).serialize())\n            << SendData(\n                tctx.client,\n                cff.build_data_frame(b\"\", flags=[\"END_STREAM\"]).serialize(),\n            )\n        )\n    assert flow().request.url == \"http://example.com/\"\n    assert flow().response.text == \"a\" * 70000\n\n\n@pytest.mark.parametrize(\"stream\", [\"stream\", \"\"])\n@pytest.mark.parametrize(\"when\", [\"request\", \"response\"])\n@pytest.mark.parametrize(\"how\", [\"RST\", \"disconnect\", \"RST+disconnect\"])\ndef test_http2_client_aborts(tctx, stream, when, how):\n    \"\"\"\n    Test handling of the case where a client aborts during request or response transmission.\n\n    If the client aborts the request transmission, we must trigger an error hook,\n    if the client disconnects during response transmission, no error hook is triggered.\n    \"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    playbook, cff = start_h2_client(tctx)\n    resp = Placeholder(bytes)\n\n    def enable_request_streaming(flow: HTTPFlow):\n        flow.request.stream = True\n\n    def enable_response_streaming(flow: HTTPFlow):\n        flow.response.stream = True\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client, cff.build_headers_frame(example_request_headers).serialize()\n        )\n        << http.HttpRequestHeadersHook(flow)\n    )\n    if stream and when == \"request\":\n        assert (\n            playbook\n            >> reply(side_effect=enable_request_streaming)\n            << OpenConnection(server)\n            >> reply(None)\n            << SendData(server, b\"GET / HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\\r\\n\")\n        )\n    else:\n        assert playbook >> reply()\n\n    if when == \"request\":\n        if \"RST\" in how:\n            playbook >> DataReceived(\n                tctx.client,\n                cff.build_rst_stream_frame(1, ErrorCodes.CANCEL).serialize(),\n            )\n        else:\n            playbook >> ConnectionClosed(tctx.client)\n            playbook << CloseConnection(tctx.client)\n\n        if stream:\n            playbook << CloseConnection(server)\n        playbook << http.HttpErrorHook(flow)\n        playbook >> reply()\n\n        if how == \"RST+disconnect\":\n            playbook >> ConnectionClosed(tctx.client)\n            playbook << CloseConnection(tctx.client)\n\n        assert playbook\n        assert (\n            \"stream reset\" in flow().error.msg\n            or \"peer closed connection\" in flow().error.msg\n        )\n        return\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client, cff.build_data_frame(b\"\", flags=[\"END_STREAM\"]).serialize()\n        )\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\\r\\n\")\n        >> DataReceived(server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 6\\r\\n\\r\\n123\")\n        << http.HttpResponseHeadersHook(flow)\n    )\n    if stream:\n        assert (\n            playbook\n            >> reply(side_effect=enable_response_streaming)\n            << SendData(tctx.client, resp)\n        )\n    else:\n        assert playbook >> reply()\n\n    if \"RST\" in how:\n        playbook >> DataReceived(\n            tctx.client, cff.build_rst_stream_frame(1, ErrorCodes.CANCEL).serialize()\n        )\n    else:\n        playbook >> ConnectionClosed(tctx.client)\n        playbook << CloseConnection(tctx.client)\n\n    playbook << CloseConnection(server)\n    playbook << http.HttpErrorHook(flow)\n    playbook >> reply()\n    assert playbook\n\n    if how == \"RST+disconnect\":\n        playbook >> ConnectionClosed(tctx.client)\n        playbook << CloseConnection(tctx.client)\n        assert playbook\n\n    if \"RST\" in how:\n        assert \"stream reset\" in flow().error.msg\n    else:\n        assert \"peer closed connection\" in flow().error.msg\n\n\n@pytest.mark.parametrize(\"normalize\", [True, False])\ndef test_no_normalization(tctx, normalize):\n    \"\"\"Test that we don't normalize headers when we just pass them through.\"\"\"\n    tctx.options.normalize_outbound_headers = normalize\n    tctx.options.validate_inbound_headers = False\n\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    playbook, cff = start_h2_client(tctx)\n\n    request_headers = list(example_request_headers) + [\n        (b\"Should-Not-Be-Capitalized! \", b\" :) \")\n    ]\n    request_headers_lower = [(k.lower(), v) for (k, v) in request_headers]\n    response_headers = list(example_response_headers) + [(b\"Same\", b\"Here\")]\n    response_headers_lower = [(k.lower(), v) for (k, v) in response_headers]\n\n    initial = Placeholder(bytes)\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(request_headers, flags=[\"END_STREAM\"]).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << SendData(server, initial)\n    )\n    frames = decode_frames(initial())\n    assert [type(x) for x in frames] == [\n        hyperframe.frame.SettingsFrame,\n        hyperframe.frame.HeadersFrame,\n    ]\n    assert (\n        hpack.hpack.Decoder().decode(frames[1].data, True) == request_headers_lower\n        if normalize\n        else request_headers\n    )\n\n    sff = FrameFactory()\n    (\n        playbook\n        >> DataReceived(\n            server,\n            sff.build_headers_frame(response_headers, flags=[\"END_STREAM\"]).serialize(),\n        )\n        << http.HttpResponseHeadersHook(flow)\n        >> reply()\n        << http.HttpResponseHook(flow)\n        >> reply()\n    )\n    if normalize:\n        playbook << Log(\n            \"Lowercased 'Same' header as uppercase is not allowed with HTTP/2.\"\n        )\n    hdrs = response_headers_lower if normalize else response_headers\n    assert playbook << SendData(\n        tctx.client, cff.build_headers_frame(hdrs, flags=[\"END_STREAM\"]).serialize()\n    )\n\n    assert flow().request.headers.fields == ((b\"Should-Not-Be-Capitalized! \", b\" :) \"),)\n    assert flow().response.headers.fields == ((b\"Same\", b\"Here\"),)\n\n\n@pytest.mark.parametrize(\n    \"input,pseudo,headers\",\n    [\n        ([(b\"foo\", b\"bar\")], {}, {\"foo\": \"bar\"}),\n        ([(b\":status\", b\"418\")], {b\":status\": b\"418\"}, {}),\n        (\n            [(b\":status\", b\"418\"), (b\"foo\", b\"bar\")],\n            {b\":status\": b\"418\"},\n            {\"foo\": \"bar\"},\n        ),\n    ],\n)\ndef test_split_pseudo_headers(input, pseudo, headers):\n    actual_pseudo, actual_headers = split_pseudo_headers(input)\n    assert pseudo == actual_pseudo\n    assert Headers(**headers) == actual_headers\n\n\ndef test_split_pseudo_headers_err():\n    with pytest.raises(ValueError, match=\"Duplicate HTTP/2 pseudo header\"):\n        split_pseudo_headers([(b\":status\", b\"418\"), (b\":status\", b\"418\")])\n\n\ndef test_rst_then_close(tctx):\n    \"\"\"\n    Test that we properly handle the case of a client that first causes protocol errors and then disconnects.\n\n    Adapted from h2spec http2/5.1/5.\n    \"\"\"\n    playbook, cff = start_h2_client(tctx)\n    flow = Placeholder(HTTPFlow)\n    server = Placeholder(Server)\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> DataReceived(\n            tctx.client, cff.build_data_frame(b\"unexpected data frame\").serialize()\n        )\n        << SendData(\n            tctx.client,\n            cff.build_rst_stream_frame(1, ErrorCodes.STREAM_CLOSED).serialize(),\n        )\n        >> ConnectionClosed(tctx.client)\n        << CloseConnection(tctx.client)\n        >> reply(\"connection cancelled\", to=-5)\n        << http.HttpErrorHook(flow)\n        >> reply()\n    )\n    assert flow().error.msg == \"connection cancelled\"\n\n\ndef test_cancel_then_server_disconnect(tctx):\n    \"\"\"\n    Test that we properly handle the case of the following event sequence:\n        - client cancels a stream\n        - we start an error hook\n        - server disconnects\n        - error hook completes.\n    \"\"\"\n    playbook, cff = start_h2_client(tctx)\n    flow = Placeholder(HTTPFlow)\n    server = Placeholder(Server)\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(\n            tctx.client, cff.build_rst_stream_frame(1, ErrorCodes.CANCEL).serialize()\n        )\n        << CloseConnection(server)\n        << http.HttpErrorHook(flow)\n        >> reply()\n        >> ConnectionClosed(server)\n        << None\n    )\n\n\ndef test_cancel_during_response_hook(tctx):\n    \"\"\"\n    Test that we properly handle the case of the following event sequence:\n        - we receive a server response\n        - we trigger the response hook\n        - the client cancels the stream\n        - the response hook completes\n\n    Given that we have already triggered the response hook, we don't want to trigger the error hook.\n    \"\"\"\n    playbook, cff = start_h2_client(tctx)\n    flow = Placeholder(HTTPFlow)\n    server = Placeholder(Server)\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(server, b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n        << http.HttpResponseHeadersHook(flow)\n        << CloseConnection(server)\n        >> reply(to=-2)\n        << http.HttpResponseHook(flow)\n        >> DataReceived(\n            tctx.client, cff.build_rst_stream_frame(1, ErrorCodes.CANCEL).serialize()\n        )\n        >> reply(to=-2)\n    )\n\n\ndef test_stream_concurrency(tctx):\n    \"\"\"Test that we can send an intercepted request with a lower stream id than one that has already been sent.\"\"\"\n    playbook, cff = start_h2_client(tctx)\n    flow1 = Placeholder(HTTPFlow)\n    flow2 = Placeholder(HTTPFlow)\n\n    reqheadershook1 = http.HttpRequestHeadersHook(flow1)\n    reqheadershook2 = http.HttpRequestHeadersHook(flow2)\n    reqhook1 = http.HttpRequestHook(flow1)\n    reqhook2 = http.HttpRequestHook(flow2)\n\n    server = Placeholder(Server)\n    data_req1 = Placeholder(bytes)\n    data_req2 = Placeholder(bytes)\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"], stream_id=1\n            ).serialize()\n            + cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"], stream_id=3\n            ).serialize(),\n        )\n        << reqheadershook1\n        << reqheadershook2\n        >> reply(to=reqheadershook1)\n        << reqhook1\n        >> reply(to=reqheadershook2)\n        << reqhook2\n        # req 2 overtakes 1 and we already have a reply:\n        >> reply(to=reqhook2)\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << SendData(server, data_req2)\n        >> reply(to=reqhook1)\n        << SendData(server, data_req1)\n    )\n    frames = decode_frames(data_req2())\n    assert [type(x) for x in frames] == [\n        hyperframe.frame.SettingsFrame,\n        hyperframe.frame.HeadersFrame,\n    ]\n    frames = decode_frames(data_req1())\n    assert [type(x) for x in frames] == [\n        hyperframe.frame.HeadersFrame,\n    ]\n\n\ndef test_max_concurrency(tctx):\n    playbook, cff = start_h2_client(tctx)\n    server = Placeholder(Server)\n    req1_bytes = Placeholder(bytes)\n    settings_ack_bytes = Placeholder(bytes)\n    req2_bytes = Placeholder(bytes)\n    playbook.hooks = False\n    sff = FrameFactory()\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"], stream_id=1\n            ).serialize(),\n        )\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << SendData(server, req1_bytes)\n        >> DataReceived(\n            server,\n            sff.build_settings_frame(\n                {h2.settings.SettingCodes.MAX_CONCURRENT_STREAMS: 1}\n            ).serialize(),\n        )\n        << SendData(server, settings_ack_bytes)\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"], stream_id=3\n            ).serialize(),\n        )\n        # Can't send it upstream yet, all streams in use!\n        >> DataReceived(\n            server,\n            sff.build_headers_frame(\n                example_response_headers, flags=[\"END_STREAM\"], stream_id=1\n            ).serialize(),\n        )\n        # But now we can!\n        << SendData(server, req2_bytes)\n        << SendData(tctx.client, Placeholder(bytes))\n        >> DataReceived(\n            server,\n            sff.build_headers_frame(\n                example_response_headers, flags=[\"END_STREAM\"], stream_id=3\n            ).serialize(),\n        )\n        << SendData(tctx.client, Placeholder(bytes))\n    )\n    settings, req1 = decode_frames(req1_bytes())\n    (settings_ack,) = decode_frames(settings_ack_bytes())\n    (req2,) = decode_frames(req2_bytes())\n\n    assert type(settings) == hyperframe.frame.SettingsFrame\n    assert type(req1) == hyperframe.frame.HeadersFrame\n    assert type(settings_ack) == hyperframe.frame.SettingsFrame\n    assert type(req2) == hyperframe.frame.HeadersFrame\n    assert req1.stream_id == 1\n    assert req2.stream_id == 3\n\n\ndef test_stream_concurrent_get_connection(tctx):\n    \"\"\"Test that an immediate second request for the same domain does not trigger a second connection attempt.\"\"\"\n    playbook, cff = start_h2_client(tctx)\n    playbook.hooks = False\n\n    server = Placeholder(Server)\n    data = Placeholder(bytes)\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"], stream_id=1\n            ).serialize(),\n        )\n        << (o := OpenConnection(server))\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"], stream_id=3\n            ).serialize(),\n        )\n        >> reply(None, to=o, side_effect=make_h2)\n        << SendData(server, data)\n    )\n    frames = decode_frames(data())\n    assert [type(x) for x in frames] == [\n        hyperframe.frame.SettingsFrame,\n        hyperframe.frame.HeadersFrame,\n        hyperframe.frame.HeadersFrame,\n    ]\n\n\ndef test_kill_stream(tctx):\n    \"\"\"Test that we can kill individual streams.\"\"\"\n    playbook, cff = start_h2_client(tctx)\n    flow1 = Placeholder(HTTPFlow)\n    flow2 = Placeholder(HTTPFlow)\n\n    req_headers_hook_1 = http.HttpRequestHeadersHook(flow1)\n\n    def kill(flow: HTTPFlow):\n        # Can't use flow.kill() here because that currently still depends on a reply object.\n        flow.error = Error(Error.KILLED_MESSAGE)\n\n    server = Placeholder(Server)\n    data_req1 = Placeholder(bytes)\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"], stream_id=1\n            ).serialize()\n            + cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"], stream_id=3\n            ).serialize(),\n        )\n        << req_headers_hook_1\n        << http.HttpRequestHeadersHook(flow2)\n        >> reply(side_effect=kill)\n        << http.HttpErrorHook(flow2)\n        >> reply()\n        << SendData(\n            tctx.client,\n            cff.build_rst_stream_frame(\n                3, error_code=ErrorCodes.INTERNAL_ERROR\n            ).serialize(),\n        )\n        >> reply(to=req_headers_hook_1)\n        << http.HttpRequestHook(flow1)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << SendData(server, data_req1)\n    )\n    frames = decode_frames(data_req1())\n    assert [type(x) for x in frames] == [\n        hyperframe.frame.SettingsFrame,\n        hyperframe.frame.HeadersFrame,\n    ]\n\n\nclass TestClient:\n    def test_no_data_on_closed_stream(self, tctx):\n        tctx.options.http2_ping_keepalive = 0\n        frame_factory = FrameFactory()\n        req = Request.make(\"GET\", \"http://example.com/\")\n        resp = {\":status\": 200}\n        assert (\n            Playbook(Http2Client(tctx))\n            << SendData(\n                tctx.server, Placeholder(bytes)\n            )  # preamble + initial settings frame\n            >> DataReceived(\n                tctx.server,\n                frame_factory.build_settings_frame({}, ack=True).serialize(),\n            )\n            >> http.RequestHeaders(1, req, end_stream=True)\n            << SendData(\n                tctx.server,\n                b\"\\x00\\x00\\x06\\x01\\x05\\x00\\x00\\x00\\x01\\x82\\x86\\x84\\\\\\x81\\x07\",\n            )\n            >> http.RequestEndOfMessage(1)\n            >> DataReceived(\n                tctx.server, frame_factory.build_headers_frame(resp).serialize()\n            )\n            << http.ReceiveHttp(Placeholder(http.ResponseHeaders))\n            >> http.RequestProtocolError(\n                1, \"cancelled\", code=status_codes.CLIENT_CLOSED_REQUEST\n            )\n            << SendData(\n                tctx.server,\n                frame_factory.build_rst_stream_frame(1, ErrorCodes.CANCEL).serialize(),\n            )\n            >> DataReceived(\n                tctx.server, frame_factory.build_data_frame(b\"foo\").serialize()\n            )\n            << SendData(\n                tctx.server,\n                frame_factory.build_rst_stream_frame(\n                    1, ErrorCodes.STREAM_CLOSED\n                ).serialize(),\n            )\n        )  # important: no ResponseData event here!\n\n    @pytest.mark.parametrize(\n        \"code,log_msg\",\n        [\n            (b\"103\", \"103 Early Hints\"),\n            (b\"1not_a_number\", \"<unknown status> \"),\n        ],\n    )\n    def test_informational_response(self, tctx, code, log_msg):\n        tctx.options.http2_ping_keepalive = 0\n        frame_factory = FrameFactory()\n        req = Request.make(\"GET\", \"http://example.com/\")\n        resp = {\":status\": code}\n        assert (\n            Playbook(Http2Client(tctx), logs=True)\n            << SendData(\n                tctx.server, Placeholder(bytes)\n            )  # preamble + initial settings frame\n            >> http.RequestHeaders(1, req, end_stream=True)\n            << SendData(\n                tctx.server,\n                b\"\\x00\\x00\\x06\\x01\\x05\\x00\\x00\\x00\\x01\\x82\\x86\\x84\\\\\\x81\\x07\",\n            )\n            >> DataReceived(\n                tctx.server, frame_factory.build_headers_frame(resp).serialize()\n            )\n            << Log(f\"Swallowing HTTP/2 informational response: {log_msg}\")\n        )\n\n\ndef test_early_server_data(tctx):\n    playbook, cff = start_h2_client(tctx)\n    sff = FrameFactory()\n\n    tctx.server.address = (\"example.com\", 80)\n    tctx.server.state = ConnectionState.OPEN\n    tctx.server.alpn = b\"h2\"\n\n    flow = Placeholder(HTTPFlow)\n    server1 = Placeholder(bytes)\n    server2 = Placeholder(bytes)\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << (h := http.HttpRequestHook(flow))\n        # Surprise! We get data from the server before the request hook finishes.\n        >> DataReceived(tctx.server, sff.build_settings_frame({}).serialize())\n        << SendData(tctx.server, server1)\n        # Request hook finishes...\n        >> reply(to=h)\n        << SendData(tctx.server, server2)\n    )\n    assert [type(x) for x in decode_frames(server1())] == [\n        hyperframe.frame.SettingsFrame,\n        hyperframe.frame.SettingsFrame,\n    ]\n    assert [type(x) for x in decode_frames(server2())] == [\n        hyperframe.frame.HeadersFrame,\n    ]\n\n\ndef test_request_smuggling_cl(tctx):\n    playbook, cff = start_h2_client(tctx)\n    playbook.hooks = False\n    err = Placeholder(bytes)\n\n    headers = (\n        (b\":method\", b\"POST\"),\n        (b\":scheme\", b\"http\"),\n        (b\":path\", b\"/\"),\n        (b\":authority\", b\"example.com\"),\n        (b\"content-length\", b\"3\"),\n    )\n\n    assert (\n        playbook\n        >> DataReceived(tctx.client, cff.build_headers_frame(headers).serialize())\n        >> DataReceived(\n            tctx.client,\n            cff.build_data_frame(\n                b\"abcPOST / HTTP/1.1 ...\", flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << SendData(tctx.client, err)\n        << CloseConnection(tctx.client)\n    )\n    assert b\"InvalidBodyLengthError\" in err()\n\n\ndef test_request_smuggling_te(tctx):\n    playbook, cff = start_h2_client(tctx)\n    playbook.hooks = False\n    err = Placeholder(bytes)\n\n    headers = (\n        (b\":method\", b\"POST\"),\n        (b\":scheme\", b\"http\"),\n        (b\":path\", b\"/\"),\n        (b\":authority\", b\"example.com\"),\n        (b\"transfer-encoding\", b\"chunked\"),\n    )\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(headers, flags=[\"END_STREAM\"]).serialize(),\n        )\n        << SendData(tctx.client, err)\n        << CloseConnection(tctx.client)\n    )\n    assert b\"Connection-specific header field present\" in err()\n\n\ndef test_request_keepalive(tctx, monkeypatch):\n    playbook, cff = start_h2_client(tctx, 58)\n    flow = Placeholder(HTTPFlow)\n    server = Placeholder(Server)\n    initial = Placeholder(bytes)\n\n    def advance_time(_):\n        t = time.time()\n        monkeypatch.setattr(time, \"time\", lambda: t + 60)\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << RequestWakeup(58)\n        << SendData(server, initial)\n        >> reply(to=-2, side_effect=advance_time)\n        << SendData(\n            server, b\"\\x00\\x00\\x08\\x06\\x00\\x00\\x00\\x00\\x0000000000\"\n        )  # ping frame\n        << RequestWakeup(58)\n    )\n\n\ndef test_keepalive_disconnect(tctx, monkeypatch):\n    playbook, cff = start_h2_client(tctx, 58)\n    playbook.hooks = False\n    sff = FrameFactory()\n    server = Placeholder(Server)\n    wakeup_command = RequestWakeup(58)\n\n    http_response = (\n        sff.build_headers_frame(example_response_headers).serialize()\n        + sff.build_data_frame(b\"\", flags=[\"END_STREAM\"]).serialize()\n    )\n\n    def advance_time(_):\n        t = time.time()\n        monkeypatch.setattr(time, \"time\", lambda: t + 60)\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << wakeup_command\n        << SendData(server, Placeholder(bytes))\n        >> DataReceived(server, http_response)\n        << SendData(tctx.client, Placeholder(bytes))\n        >> ConnectionClosed(server)\n        << CloseConnection(server)\n        >> reply(to=wakeup_command, side_effect=advance_time)\n        << None\n    )\n\n\ndef test_alt_svc(tctx):\n    playbook, cff = start_h2_client(tctx)\n    flow = Placeholder(HTTPFlow)\n    server = Placeholder(Server)\n    initial = Placeholder(bytes)\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            cff.build_headers_frame(\n                example_request_headers, flags=[\"END_STREAM\"]\n            ).serialize(),\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << SendData(server, initial)\n        >> DataReceived(\n            server, cff.build_alt_svc_frame(0, b\"example.com\", b'h3=\":443\"').serialize()\n        )\n        << Log(\"Received HTTP/2 Alt-Svc frame, which will not be forwarded.\", DEBUG)\n    )\n", "test/mitmproxy/proxy/layers/http/test_http_version_interop.py": "import h2.config\nimport h2.connection\nimport h2.events\n\nfrom mitmproxy.connection import Server\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.proxy.commands import CloseConnection\nfrom mitmproxy.proxy.commands import OpenConnection\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.layers import http\nfrom mitmproxy.proxy.layers.http import HTTPMode\nfrom test.mitmproxy.proxy.layers.http.hyper_h2_test_helpers import FrameFactory\nfrom test.mitmproxy.proxy.layers.http.test_http2 import example_response_headers\nfrom test.mitmproxy.proxy.layers.http.test_http2 import make_h2\nfrom test.mitmproxy.proxy.tutils import Placeholder\nfrom test.mitmproxy.proxy.tutils import Playbook\nfrom test.mitmproxy.proxy.tutils import reply\n\nexample_request_headers = (\n    (b\":method\", b\"GET\"),\n    (b\":scheme\", b\"http\"),\n    (b\":path\", b\"/\"),\n    (b\":authority\", b\"example.com\"),\n    (b\"cookie\", \"a=1\"),\n    (b\"cookie\", \"b=2\"),\n)\n\nh2f = FrameFactory()\n\n\ndef event_types(events):\n    return [type(x) for x in events]\n\n\ndef h2_client(tctx: Context) -> tuple[h2.connection.H2Connection, Playbook]:\n    tctx.client.alpn = b\"h2\"\n    tctx.options.http2_ping_keepalive = 0\n\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n    conn = h2.connection.H2Connection()\n    conn.initiate_connection()\n\n    server_preamble = Placeholder(bytes)\n    assert playbook << SendData(tctx.client, server_preamble)\n    assert event_types(conn.receive_data(server_preamble())) == [\n        h2.events.RemoteSettingsChanged\n    ]\n\n    settings_ack = Placeholder(bytes)\n    assert (\n        playbook\n        >> DataReceived(tctx.client, conn.data_to_send())\n        << SendData(tctx.client, settings_ack)\n    )\n    assert event_types(conn.receive_data(settings_ack())) == [\n        h2.events.SettingsAcknowledged\n    ]\n\n    return conn, playbook\n\n\ndef test_h2_to_h1(tctx):\n    \"\"\"Test HTTP/2 -> HTTP/1 request translation\"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n\n    conn, playbook = h2_client(tctx)\n\n    conn.send_headers(1, example_request_headers, end_stream=True)\n    response = Placeholder(bytes)\n    assert (\n        playbook\n        >> DataReceived(tctx.client, conn.data_to_send())\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(\n            server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\ncookie: a=1; b=2\\r\\n\\r\\n\"\n        )\n        >> DataReceived(server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 12\\r\\n\\r\\n\")\n        << http.HttpResponseHeadersHook(flow)\n        >> reply()\n        >> DataReceived(server, b\"Hello World!\")\n        << http.HttpResponseHook(flow)\n        << CloseConnection(server)\n        >> reply(to=-2)\n        << SendData(tctx.client, response)\n    )\n    events = conn.receive_data(response())\n    assert event_types(events) == [\n        h2.events.ResponseReceived,\n        h2.events.DataReceived,\n        h2.events.DataReceived,\n        h2.events.StreamEnded,\n    ]\n    resp: h2.events.ResponseReceived = events[0]\n    body: h2.events.DataReceived = events[1]\n    assert resp.headers == [(b\":status\", b\"200\"), (b\"content-length\", b\"12\")]\n    assert body.data == b\"Hello World!\"\n\n\ndef test_h1_to_h2(tctx):\n    \"\"\"Test HTTP/1 -> HTTP/2 request translation\"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    tctx.options.http2_ping_keepalive = 0\n\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n\n    conf = h2.config.H2Configuration(client_side=False)\n    conn = h2.connection.H2Connection(conf)\n    conn.initiate_connection()\n\n    request = Placeholder(bytes)\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << SendData(server, request)\n    )\n    events = conn.receive_data(request())\n    assert event_types(events) == [\n        h2.events.RemoteSettingsChanged,\n        h2.events.RequestReceived,\n        h2.events.StreamEnded,\n    ]\n\n    conn.send_headers(1, example_response_headers)\n    conn.send_data(1, b\"Hello World!\", end_stream=True)\n    settings_ack = Placeholder(bytes)\n    assert (\n        playbook\n        >> DataReceived(server, conn.data_to_send())\n        << http.HttpResponseHeadersHook(flow)\n        << SendData(server, settings_ack)\n        >> reply(to=-2)\n        << http.HttpResponseHook(flow)\n        >> reply()\n        << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\n\\r\\nHello World!\")\n        << CloseConnection(tctx.client)\n    )\n    assert settings_ack() == b\"\\x00\\x00\\x00\\x04\\x01\\x00\\x00\\x00\\x00\"\n", "test/mitmproxy/proxy/layers/http/hyper_h2_test_helpers.py": "# This file has been copied from https://github.com/python-hyper/hyper-h2/blob/master/test/helpers.py,\n# MIT License\n# -*- coding: utf-8 -*-\n\"\"\"\nhelpers\n~~~~~~~\n\nThis module contains helpers for the h2 tests.\n\"\"\"\n\nfrom hpack.hpack import Encoder\nfrom hyperframe.frame import AltSvcFrame\nfrom hyperframe.frame import ContinuationFrame\nfrom hyperframe.frame import DataFrame\nfrom hyperframe.frame import GoAwayFrame\nfrom hyperframe.frame import HeadersFrame\nfrom hyperframe.frame import PingFrame\nfrom hyperframe.frame import PriorityFrame\nfrom hyperframe.frame import PushPromiseFrame\nfrom hyperframe.frame import RstStreamFrame\nfrom hyperframe.frame import SettingsFrame\nfrom hyperframe.frame import WindowUpdateFrame\n\nSAMPLE_SETTINGS = {\n    SettingsFrame.HEADER_TABLE_SIZE: 4096,\n    SettingsFrame.ENABLE_PUSH: 1,\n    SettingsFrame.MAX_CONCURRENT_STREAMS: 2,\n}\n\n\nclass FrameFactory:\n    \"\"\"\n    A class containing lots of helper methods and state to build frames. This\n    allows test cases to easily build correct HTTP/2 frames to feed to\n    hyper-h2.\n    \"\"\"\n\n    def __init__(self):\n        self.encoder = Encoder()\n\n    def refresh_encoder(self):\n        self.encoder = Encoder()\n\n    def preamble(self):\n        return b\"PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n\"\n\n    def build_headers_frame(self, headers, flags=[], stream_id=1, **priority_kwargs):\n        \"\"\"\n        Builds a single valid headers frame out of the contained headers.\n        \"\"\"\n        f = HeadersFrame(stream_id)\n        f.data = self.encoder.encode(headers)\n        f.flags.add(\"END_HEADERS\")\n        for flag in flags:\n            f.flags.add(flag)\n\n        for k, v in priority_kwargs.items():\n            setattr(f, k, v)\n\n        return f\n\n    def build_continuation_frame(self, header_block, flags=[], stream_id=1):\n        \"\"\"\n        Builds a single continuation frame out of the binary header block.\n        \"\"\"\n        f = ContinuationFrame(stream_id)\n        f.data = header_block\n        f.flags = set(flags)\n\n        return f\n\n    def build_data_frame(self, data, flags=None, stream_id=1, padding_len=0):\n        \"\"\"\n        Builds a single data frame out of a chunk of data.\n        \"\"\"\n        flags = set(flags) if flags is not None else set()\n        f = DataFrame(stream_id)\n        f.data = data\n        f.flags = flags\n\n        if padding_len:\n            flags.add(\"PADDED\")\n            f.pad_length = padding_len\n\n        return f\n\n    def build_settings_frame(self, settings, ack=False):\n        \"\"\"\n        Builds a single settings frame.\n        \"\"\"\n        f = SettingsFrame(0)\n        if ack:\n            f.flags.add(\"ACK\")\n\n        f.settings = settings\n        return f\n\n    def build_window_update_frame(self, stream_id, increment):\n        \"\"\"\n        Builds a single WindowUpdate frame.\n        \"\"\"\n        f = WindowUpdateFrame(stream_id)\n        f.window_increment = increment\n        return f\n\n    def build_ping_frame(self, ping_data, flags=None):\n        \"\"\"\n        Builds a single Ping frame.\n        \"\"\"\n        f = PingFrame(0)\n        f.opaque_data = ping_data\n        if flags:\n            f.flags = set(flags)\n\n        return f\n\n    def build_goaway_frame(self, last_stream_id, error_code=0, additional_data=b\"\"):\n        \"\"\"\n        Builds a single GOAWAY frame.\n        \"\"\"\n        f = GoAwayFrame(0)\n        f.error_code = error_code\n        f.last_stream_id = last_stream_id\n        f.additional_data = additional_data\n        return f\n\n    def build_rst_stream_frame(self, stream_id, error_code=0):\n        \"\"\"\n        Builds a single RST_STREAM frame.\n        \"\"\"\n        f = RstStreamFrame(stream_id)\n        f.error_code = error_code\n        return f\n\n    def build_push_promise_frame(\n        self, stream_id, promised_stream_id, headers, flags=[]\n    ):\n        \"\"\"\n        Builds a single PUSH_PROMISE frame.\n        \"\"\"\n        f = PushPromiseFrame(stream_id)\n        f.promised_stream_id = promised_stream_id\n        f.data = self.encoder.encode(headers)\n        f.flags = set(flags)\n        f.flags.add(\"END_HEADERS\")\n        return f\n\n    def build_priority_frame(self, stream_id, weight, depends_on=0, exclusive=False):\n        \"\"\"\n        Builds a single priority frame.\n        \"\"\"\n        f = PriorityFrame(stream_id)\n        f.depends_on = depends_on\n        f.stream_weight = weight\n        f.exclusive = exclusive\n        return f\n\n    def build_alt_svc_frame(self, stream_id, origin, field):\n        \"\"\"\n        Builds a single ALTSVC frame.\n        \"\"\"\n        f = AltSvcFrame(stream_id)\n        f.origin = origin\n        f.field = field\n        return f\n\n    def change_table_size(self, new_size):\n        \"\"\"\n        Causes the encoder to send a dynamic size update in the next header\n        block it sends.\n        \"\"\"\n        self.encoder.header_table_size = new_size\n", "test/mitmproxy/proxy/layers/http/test_http_fuzz.py": "from typing import Any\n\nimport pytest\nfrom h2.settings import SettingCodes\nfrom hypothesis import example\nfrom hypothesis import given\nfrom hypothesis.strategies import binary\nfrom hypothesis.strategies import booleans\nfrom hypothesis.strategies import composite\nfrom hypothesis.strategies import data\nfrom hypothesis.strategies import dictionaries\nfrom hypothesis.strategies import integers\nfrom hypothesis.strategies import lists\nfrom hypothesis.strategies import sampled_from\nfrom hypothesis.strategies import sets\nfrom hypothesis.strategies import text\n\nfrom mitmproxy import connection\nfrom mitmproxy import options\nfrom mitmproxy.addons.proxyserver import Proxyserver\nfrom mitmproxy.connection import Server\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy.commands import OpenConnection\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.events import ConnectionClosed\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.events import Start\nfrom mitmproxy.proxy.layers import http\nfrom mitmproxy.proxy.layers.http import _http2\nfrom mitmproxy.proxy.layers.http import HTTPMode\nfrom test.mitmproxy.proxy.layers.http.hyper_h2_test_helpers import FrameFactory\nfrom test.mitmproxy.proxy.layers.http.test_http2 import example_request_headers\nfrom test.mitmproxy.proxy.layers.http.test_http2 import example_response_headers\nfrom test.mitmproxy.proxy.layers.http.test_http2 import make_h2\nfrom test.mitmproxy.proxy.layers.http.test_http2 import start_h2_client\nfrom test.mitmproxy.proxy.tutils import _eq\nfrom test.mitmproxy.proxy.tutils import _TracebackInPlaybook\nfrom test.mitmproxy.proxy.tutils import Placeholder\nfrom test.mitmproxy.proxy.tutils import Playbook\nfrom test.mitmproxy.proxy.tutils import reply\n\nopts = options.Options()\nProxyserver().load(opts)\n\n\n@pytest.fixture(scope=\"module\", autouse=True)\ndef disable_h2_error_catching():\n    errs = _http2.CATCH_HYPER_H2_ERRORS\n    _http2.CATCH_HYPER_H2_ERRORS = ()\n    try:\n        yield None\n    finally:\n        _http2.CATCH_HYPER_H2_ERRORS = errs\n\n\nrequest_lines = sampled_from(\n    [\n        b\"GET / HTTP/1.1\",\n        b\"GET http://example.com/ HTTP/1.1\",\n        b\"CONNECT example.com:443 HTTP/1.1\",\n        b\"HEAD /foo HTTP/0.9\",\n    ]\n)\nresponse_lines = sampled_from(\n    [\n        b\"HTTP/1.1 200 OK\",\n        b\"HTTP/1.1 100 Continue\",\n        b\"HTTP/0.9 204 No Content\",\n        b\"HEAD /foo HTTP/0.9\",\n    ]\n)\nheaders = lists(\n    sampled_from(\n        [\n            b\"Host: example.com\",\n            b\"Content-Length: 5\",\n            b\"Expect: 100-continue\",\n            b\"Transfer-Encoding: chunked\",\n            b\"Connection: close\",\n            b\"\",\n        ]\n    )\n)\nbodies = sampled_from([b\"\", b\"12345\", b\"5\\r\\n12345\\r\\n0\\r\\n\\r\\n\"])\n\n\n@composite\ndef mutations(draw, elements):\n    data = draw(elements)\n\n    cut_start = draw(integers(0, len(data)))\n    cut_end = draw(integers(cut_start, len(data)))\n    data = data[:cut_start] + data[cut_end:]\n\n    replace_start = draw(integers(0, len(data)))\n    replace_end = draw(integers(replace_start, len(data)))\n    return data[:replace_start] + draw(binary()) + data[replace_end:]\n\n\n@composite\ndef chunks(draw, elements):\n    data = draw(elements)\n\n    chunks = []\n    a, b = sorted([draw(integers(0, len(data))), draw(integers(0, len(data)))])\n    if a > 0:\n        chunks.append(data[:a])\n    if a != b:\n        chunks.append(data[a:b])\n    if b < len(data):\n        chunks.append(data[b:])\n\n    return chunks\n\n\n@composite\ndef h1_requests(draw):\n    request = draw(request_lines) + b\"\\r\\n\"\n    request += b\"\\r\\n\".join(draw(headers))\n    request += b\"\\r\\n\\r\\n\" + draw(bodies)\n    return request\n\n\n@composite\ndef h2_responses(draw):\n    response = draw(response_lines) + b\"\\r\\n\"\n    response += b\"\\r\\n\".join(draw(headers))\n    response += b\"\\r\\n\\r\\n\" + draw(bodies)\n    return response\n\n\n@given(chunks(mutations(h1_requests())))\ndef test_fuzz_h1_request(data):\n    tctx = _tctx()\n\n    layer = http.HttpLayer(tctx, HTTPMode.regular)\n    for _ in layer.handle_event(Start()):\n        pass\n    for chunk in data:\n        for _ in layer.handle_event(DataReceived(tctx.client, chunk)):\n            pass\n\n\n@given(chunks(mutations(h2_responses())))\n@example([b\"0 OK\\r\\n\\r\\n\", b\"\\r\\n\", b\"5\\r\\n12345\\r\\n0\\r\\n\\r\\n\"])\ndef test_fuzz_h1_response(data):\n    tctx = _tctx()\n    server = Placeholder(connection.Server)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n    )\n    for chunk in data:\n        for _ in playbook.layer.handle_event(events.DataReceived(server(), chunk)):\n            pass\n\n\nh2_flags = sets(\n    sampled_from(\n        [\n            \"END_STREAM\",\n            \"END_HEADERS\",\n        ]\n    )\n)\nh2_stream_ids = integers(0, 3)\nh2_stream_ids_nonzero = integers(1, 3)\n\n\n@composite\ndef h2_headers(draw):\n    required_headers = [\n        [\":path\", \"/\"],\n        [\":scheme\", draw(sampled_from([\"http\", \"https\"]))],\n        [\":method\", draw(sampled_from([\"GET\", \"POST\", \"CONNECT\"]))],\n    ]\n    optional_headers = [\n        [\":authority\", draw(sampled_from([\"example.com:443\", \"example.com\"]))],\n        [\"cookie\", \"foobaz\"],\n        [\"host\", \"example.com\"],\n        [\"content-length\", \"42\"],\n    ]\n    headers = required_headers + draw(lists(sampled_from(optional_headers), max_size=3))\n\n    i = draw(integers(0, len(headers)))\n    p = int(draw(booleans()))\n    r = draw(text())\n    if i > 0:\n        headers[i - 1][p - 1] = r\n    return headers\n\n\n@composite\ndef h2_frames(draw):\n    ff = FrameFactory()\n    headers1 = ff.build_headers_frame(headers=draw(h2_headers()))\n    headers1.flags.clear()\n    headers1.flags |= draw(h2_flags)\n    headers2 = ff.build_headers_frame(\n        headers=draw(h2_headers()),\n        depends_on=draw(h2_stream_ids),\n        stream_weight=draw(integers(0, 255)),\n        exclusive=draw(booleans()),\n    )\n    headers2.flags.clear()\n    headers2.flags |= draw(h2_flags)\n    settings = ff.build_settings_frame(\n        settings=draw(\n            dictionaries(\n                keys=sampled_from(SettingCodes),\n                values=integers(0, 2**32 - 1),\n                max_size=5,\n            )\n        ),\n        ack=draw(booleans()),\n    )\n    continuation = ff.build_continuation_frame(\n        header_block=ff.encoder.encode(draw(h2_headers())), flags=draw(h2_flags)\n    )\n    goaway = ff.build_goaway_frame(draw(h2_stream_ids))\n    push_promise = ff.build_push_promise_frame(\n        stream_id=draw(h2_stream_ids_nonzero),\n        promised_stream_id=draw(h2_stream_ids),\n        headers=draw(h2_headers()),\n    )\n    rst = ff.build_rst_stream_frame(draw(h2_stream_ids_nonzero))\n    prio = ff.build_priority_frame(\n        stream_id=draw(h2_stream_ids_nonzero),\n        weight=draw(integers(0, 255)),\n        depends_on=draw(h2_stream_ids),\n        exclusive=draw(booleans()),\n    )\n    data1 = ff.build_data_frame(draw(binary()), draw(h2_flags))\n    data2 = ff.build_data_frame(\n        draw(binary()), draw(h2_flags), stream_id=draw(h2_stream_ids_nonzero)\n    )\n    window_update = ff.build_window_update_frame(\n        draw(h2_stream_ids), draw(integers(0, 2**32 - 1))\n    )\n\n    frames = draw(\n        lists(\n            sampled_from(\n                [\n                    headers1,\n                    headers2,\n                    settings,\n                    continuation,\n                    goaway,\n                    push_promise,\n                    rst,\n                    prio,\n                    data1,\n                    data2,\n                    window_update,\n                ]\n            ),\n            min_size=1,\n            max_size=11,\n        )\n    )\n    return b\"\".join(x.serialize() for x in frames)\n\n\ndef h2_layer(opts):\n    tctx = _tctx()\n    tctx.client.alpn = b\"h2\"\n\n    layer = http.HttpLayer(tctx, HTTPMode.regular)\n    for _ in layer.handle_event(Start()):\n        pass\n    for _ in layer.handle_event(\n        DataReceived(tctx.client, b\"PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n\")\n    ):\n        pass\n    return tctx, layer\n\n\ndef _h2_request(chunks):\n    tctx, layer = h2_layer(opts)\n    for chunk in chunks:\n        for _ in layer.handle_event(DataReceived(tctx.client, chunk)):\n            pass\n\n\n# fmt: off\n@given(chunks(h2_frames()))\n@example([b'\\x00\\x00\\x00\\x01\\x05\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x05\\x00\\x00\\x00\\x01'])\n@example([b'\\x00\\x00\\x00\\x01\\x07\\x00\\x00\\x00\\x01A\\x88/\\x91\\xd3]\\x05\\\\\\x87\\xa7\\x84\\x86\\x82`\\x80f\\x80\\\\\\x80'])\n@example([b'\\x00\\x00\\x05\\x02\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00'])\n@example([b'\\x00\\x00\\x13\\x01\\x04\\x00\\x00\\x00\\x01A\\x88/\\x91\\xd3]\\x05\\\\\\x87\\xa7\\x84\\x86\\x82`\\x80f\\x80\\\\\\x80'])\n@example([b'\\x00\\x00\\x12\\x01\\x04\\x00\\x00\\x00\\x01\\x84\\x86\\x82`\\x80A\\x88/\\x91\\xd3]\\x05\\\\\\x87\\xa7\\\\\\x81\\x07'])\n@example([b'\\x00\\x00\\x12\\x01\\x04\\x00\\x00\\x00\\x01\\x84\\x86\\x82`\\x80A\\x88/\\x91\\xd3]\\x05\\\\\\x87\\xa7\\\\\\x81\\x07'])\n@example([b'\\x00\\x00\\x14\\x01\\x04\\x00\\x00\\x00\\x01A\\x88/\\x91\\xd3]\\x05\\\\\\x87\\xa7\\x84\\x86`\\x80\\x82f\\x80'])\n@example([\n    b'\\x00\\x00%\\x01\\x04\\x00\\x00\\x00\\x01A\\x8b/\\x91\\xd3]\\x05\\\\\\x87\\xa6\\xe3M3\\x84\\x86\\x82`\\x85\\x94\\xe7\\x8c~\\xfff\\x88/\\x91'\n    b'\\xd3]\\x05\\\\\\x87\\xa7\\\\\\x82h_\\x00\\x00\\x07\\x01\\x05\\x00\\x00\\x00\\x01\\xc1\\x84\\x86\\x82\\xc0\\xbf\\xbe'])\n@example([b'\\x00\\x00\\x03\\x01\\x04\\x00\\x00\\x00\\x01\\x84\\x86\\x82\\x00\\x00\\x08\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'])\ndef test_fuzz_h2_request_chunks(chunks):\n    _h2_request(chunks)\n# fmt: on\n\n\n@given(chunks(mutations(h2_frames())))\ndef test_fuzz_h2_request_mutations(chunks):\n    _h2_request(chunks)\n\n\ndef _tctx() -> context.Context:\n    tctx = context.Context(\n        connection.Client(\n            peername=(\"client\", 1234),\n            sockname=(\"127.0.0.1\", 8080),\n            timestamp_start=1605699329,\n        ),\n        opts,\n    )\n    tctx.options.http2_ping_keepalive = 0\n    return tctx\n\n\ndef _h2_response(chunks):\n    tctx = _tctx()\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n    server = Placeholder(connection.Server)\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << OpenConnection(server)\n        >> reply(None, side_effect=make_h2)\n        << SendData(server, Placeholder())\n    )\n    for chunk in chunks:\n        for _ in playbook.layer.handle_event(events.DataReceived(server(), chunk)):\n            pass\n\n\n# fmt: off\n@given(chunks(h2_frames()))\n@example([b'\\x00\\x00\\x03\\x01\\x04\\x00\\x00\\x00\\x01\\x84\\x86\\x82',\n          b'\\x00\\x00\\x07\\x05\\x04\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x84\\x86\\x82'])\n@example([b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01'])\n@example([b'\\x00\\x00\\x00\\x01\\x04\\x00\\x00\\x00\\x01'])\n@example([b'\\x00\\x00\\x07\\x05\\x04\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x84\\x86\\x82'])\n@example([b'\\x00\\x00\\x06\\x014\\x00\\x01\\x00\\x00\\x00\\x00\\x01@\\x80\\x81c\\x86\\x82'])\n@example([b'\\x00\\x00\\x06\\x01\\x04\\x00\\x00\\x00\\x01@\\x80\\x81c\\x86\\x82'])\ndef test_fuzz_h2_response_chunks(chunks):\n    _h2_response(chunks)\n# fmt: on\n\n\n@given(chunks(mutations(h2_frames())))\ndef test_fuzz_h2_response_mutations(chunks):\n    _h2_response(chunks)\n\n\n@pytest.mark.parametrize(\n    \"example\",\n    [\n        (\n            True,\n            False,\n            [\n                \"data_req\",\n                \"reply_hook_req_headers\",\n                \"reply_openconn\",\n                \"data_resp\",\n                \"data_reqbody\",\n                \"data_respbody\",\n                \"err_server_rst\",\n                \"reply_hook_resp_headers\",\n            ],\n        ),\n        (\n            True,\n            False,\n            [\n                \"data_req\",\n                \"reply_hook_req_headers\",\n                \"reply_openconn\",\n                \"err_server_rst\",\n                \"data_reqbody\",\n                \"reply_hook_error\",\n            ],\n        ),\n    ],\n)\ndef test_cancel_examples(example):\n    \"\"\"\n    We can't specify examples in test_fuzz_cancel (because we use data, see\n    https://hypothesis.readthedocs.io/en/latest/data.html#interactive-draw),\n    so we have this here for explicit examples.\n    \"\"\"\n    stream_req, stream_resp, draws = example\n\n    def draw(lst):\n        if draws:\n            this_draw = draws.pop(0)\n            for name, evt in lst:\n                if name == this_draw:\n                    return name, evt\n            raise AssertionError(\n                f\"{this_draw} not in list: {[name for name, _ in lst]}\"\n            )\n        else:\n            return lst[0]\n\n    _test_cancel(stream_req, stream_resp, draw)\n\n\n@given(stream_request=booleans(), stream_response=booleans(), data=data())\ndef test_fuzz_cancel(stream_request, stream_response, data):\n    _test_cancel(\n        stream_request, stream_response, lambda lst: data.draw(sampled_from(lst))\n    )\n\n\ndef _test_cancel(stream_req, stream_resp, draw):\n    \"\"\"\n    Test that we don't raise an exception if someone disconnects.\n    \"\"\"\n    tctx = _tctx()\n    playbook, cff = start_h2_client(tctx)\n    flow = Placeholder(HTTPFlow)\n    server = Placeholder(Server)\n\n    def maybe_stream(flow: HTTPFlow):\n        if stream_req:\n            flow.request.stream = True\n        if stream_resp and flow.response:\n            flow.response.stream = True\n\n    hook_req_headers = http.HttpRequestHeadersHook(flow)\n    hook_req = http.HttpRequestHook(flow)\n    hook_resp_headers = http.HttpResponseHeadersHook(flow)\n    hook_resp = http.HttpResponseHook(flow)\n    hook_error = http.HttpErrorHook(flow)\n    openconn = OpenConnection(server)\n    send_upstream = SendData(server, Placeholder(bytes))\n\n    data_req = DataReceived(\n        tctx.client, cff.build_headers_frame(example_request_headers).serialize()\n    )\n    data_reqbody = DataReceived(\n        tctx.client, cff.build_data_frame(b\"foo\", flags=[\"END_STREAM\"]).serialize()\n    )\n    data_resp = DataReceived(\n        server, cff.build_headers_frame(example_response_headers).serialize()\n    )\n    data_respbody = DataReceived(\n        server, cff.build_data_frame(b\"bar\", flags=[\"END_STREAM\"]).serialize()\n    )\n\n    client_disc = ConnectionClosed(tctx.client)\n    client_rst = DataReceived(tctx.client, cff.build_rst_stream_frame(1).serialize())\n    server_disc = ConnectionClosed(server)\n    server_rst = DataReceived(server, cff.build_rst_stream_frame(1).serialize())\n\n    evts: dict[str, tuple[Any, Any, Any]] = {}\n    # precondition, but-not-after-this\n    evts[\"data_req\"] = data_req, None, client_disc\n    evts[\"data_reqbody\"] = data_reqbody, data_req, client_disc\n    evts[\"reply_hook_req_headers\"] = (\n        reply(to=hook_req_headers, side_effect=maybe_stream),\n        hook_req_headers,\n        None,\n    )\n    evts[\"reply_hook_req\"] = reply(to=hook_req), hook_req, None\n    evts[\"reply_openconn\"] = (\n        reply(None, to=openconn, side_effect=make_h2),\n        openconn,\n        None,\n    )\n    evts[\"data_resp\"] = data_resp, send_upstream, server_disc\n    evts[\"data_respbody\"] = data_respbody, data_resp, server_disc\n    evts[\"reply_hook_resp_headers\"] = (\n        reply(to=hook_resp_headers, side_effect=maybe_stream),\n        hook_resp_headers,\n        None,\n    )\n    evts[\"reply_hook_resp\"] = reply(to=hook_resp), hook_resp, None\n    evts[\"reply_hook_error\"] = reply(to=hook_error), hook_error, None\n\n    evts[\"err_client_disc\"] = client_disc, None, None\n    evts[\"err_client_rst\"] = client_rst, None, client_disc\n    evts[\"err_server_disc\"] = server_disc, send_upstream, None\n    evts[\"err_server_rst\"] = server_rst, send_upstream, server_disc\n\n    def eq_maybe(a, b):\n        # _eq helpfully raises a TypeError when placeholder types don't match\n        # that is useful in (test) development, but may happen legitimately when fuzzing here.\n        try:\n            return _eq(a, b)\n        except TypeError:\n            return False\n\n    while evts:\n        candidates = []\n        for name, (evt, precon, negprecon) in evts.items():\n            precondition_ok = precon is None or any(\n                eq_maybe(x, precon) for x in playbook.actual\n            )\n            neg_precondition_ok = negprecon is None or not any(\n                eq_maybe(x, negprecon) for x in playbook.actual\n            )\n            if precondition_ok and neg_precondition_ok:\n                # crude hack to increase fuzzing efficiency: make it more likely that we progress.\n                for i in range(1 if name.startswith(\"err_\") else 3):\n                    candidates.append((name, evt))\n        if not candidates:\n            break\n\n        name, evt = draw(candidates)\n        del evts[name]\n        try:\n            assert playbook >> evt\n        except AssertionError:\n            if any(isinstance(x, _TracebackInPlaybook) for x in playbook.actual):\n                raise\n            else:\n                # add commands that the server issued.\n                playbook.expected.extend(playbook.actual[len(playbook.expected) :])\n", "test/mitmproxy/proxy/layers/http/test_http1.py": "import pytest\n\nfrom mitmproxy import http\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.layers.http import Http1Client\nfrom mitmproxy.proxy.layers.http import Http1Server\nfrom mitmproxy.proxy.layers.http import ReceiveHttp\nfrom mitmproxy.proxy.layers.http import RequestData\nfrom mitmproxy.proxy.layers.http import RequestEndOfMessage\nfrom mitmproxy.proxy.layers.http import RequestHeaders\nfrom mitmproxy.proxy.layers.http import ResponseData\nfrom mitmproxy.proxy.layers.http import ResponseEndOfMessage\nfrom mitmproxy.proxy.layers.http import ResponseHeaders\nfrom test.mitmproxy.proxy.tutils import Placeholder\nfrom test.mitmproxy.proxy.tutils import Playbook\n\n\nclass TestServer:\n    @pytest.mark.parametrize(\"pipeline\", [\"pipeline\", None])\n    def test_simple(self, tctx, pipeline):\n        hdrs1 = Placeholder(RequestHeaders)\n        hdrs2 = Placeholder(RequestHeaders)\n        req2 = (\n            b\"GET http://example.com/two HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\" b\"\\r\\n\"\n        )\n        playbook = Playbook(Http1Server(tctx))\n        (\n            playbook\n            >> DataReceived(\n                tctx.client,\n                b\"POST http://example.com/one HTTP/1.1\\r\\n\"\n                b\"Content-Length: 3\\r\\n\"\n                b\"\\r\\n\"\n                b\"abc\" + (req2 if pipeline else b\"\"),\n            )\n            << ReceiveHttp(hdrs1)\n            << ReceiveHttp(RequestData(1, b\"abc\"))\n            << ReceiveHttp(RequestEndOfMessage(1))\n            >> ResponseHeaders(1, http.Response.make(200))\n            << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\ncontent-length: 0\\r\\n\\r\\n\")\n            >> ResponseEndOfMessage(1)\n        )\n        if not pipeline:\n            playbook >> DataReceived(tctx.client, req2)\n        playbook << ReceiveHttp(hdrs2)\n        playbook << ReceiveHttp(RequestEndOfMessage(3))\n        assert playbook\n\n    @pytest.mark.parametrize(\"pipeline\", [\"pipeline\", None])\n    def test_connect(self, tctx, pipeline):\n        playbook = Playbook(Http1Server(tctx))\n        (\n            playbook\n            >> DataReceived(\n                tctx.client,\n                b\"CONNECT example.com:443 HTTP/1.1\\r\\n\"\n                b\"content-length: 0\\r\\n\"\n                b\"\\r\\n\" + (b\"some plain tcp\" if pipeline else b\"\"),\n            )\n            << ReceiveHttp(Placeholder(RequestHeaders))\n            # << ReceiveHttp(RequestEndOfMessage(1))\n            >> ResponseHeaders(1, http.Response.make(200))\n            << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\ncontent-length: 0\\r\\n\\r\\n\")\n            >> ResponseEndOfMessage(1)\n        )\n        if not pipeline:\n            playbook >> DataReceived(tctx.client, b\"some plain tcp\")\n        assert playbook << ReceiveHttp(RequestData(1, b\"some plain tcp\"))\n\n    @pytest.mark.parametrize(\"pipeline\", [\"pipeline\", None])\n    def test_upgrade(self, tctx, pipeline):\n        playbook = Playbook(Http1Server(tctx))\n        (\n            playbook\n            >> DataReceived(\n                tctx.client,\n                b\"POST http://example.com/one HTTP/1.1\\r\\n\"\n                b\"Connection: Upgrade\\r\\n\"\n                b\"Upgrade: websocket\\r\\n\"\n                b\"\\r\\n\" + (b\"some websockets\" if pipeline else b\"\"),\n            )\n            << ReceiveHttp(Placeholder(RequestHeaders))\n            << ReceiveHttp(RequestEndOfMessage(1))\n            >> ResponseHeaders(1, http.Response.make(101))\n            << SendData(\n                tctx.client,\n                b\"HTTP/1.1 101 Switching Protocols\\r\\ncontent-length: 0\\r\\n\\r\\n\",\n            )\n            >> ResponseEndOfMessage(1)\n        )\n        if not pipeline:\n            playbook >> DataReceived(tctx.client, b\"some websockets\")\n        assert playbook << ReceiveHttp(RequestData(1, b\"some websockets\"))\n\n    def test_upgrade_denied(self, tctx):\n        assert (\n            Playbook(Http1Server(tctx))\n            >> DataReceived(\n                tctx.client,\n                b\"GET http://example.com/ HTTP/1.1\\r\\n\"\n                b\"Connection: Upgrade\\r\\n\"\n                b\"Upgrade: websocket\\r\\n\"\n                b\"\\r\\n\",\n            )\n            << ReceiveHttp(Placeholder(RequestHeaders))\n            << ReceiveHttp(RequestEndOfMessage(1))\n            >> ResponseHeaders(1, http.Response.make(200))\n            << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\ncontent-length: 0\\r\\n\\r\\n\")\n            >> ResponseEndOfMessage(1)\n            >> DataReceived(tctx.client, b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n            << ReceiveHttp(Placeholder(RequestHeaders))\n            << ReceiveHttp(RequestEndOfMessage(3))\n        )\n\n\nclass TestClient:\n    @pytest.mark.parametrize(\"pipeline\", [\"pipeline\", None])\n    def test_simple(self, tctx, pipeline):\n        req = http.Request.make(\"GET\", \"http://example.com/\")\n        resp = Placeholder(ResponseHeaders)\n\n        playbook = Playbook(Http1Client(tctx))\n        (\n            playbook\n            >> RequestHeaders(1, req, True)\n            << SendData(tctx.server, b\"GET / HTTP/1.1\\r\\ncontent-length: 0\\r\\n\\r\\n\")\n            >> RequestEndOfMessage(1)\n        )\n        if pipeline:\n            with pytest.raises(\n                AssertionError, match=\"assert self.stream_id == event.stream_id\"\n            ):\n                assert playbook >> RequestHeaders(3, req, True)\n            return\n        assert (\n            playbook\n            >> DataReceived(\n                tctx.server, b\"HTTP/1.1 200 OK\\r\\ncontent-length: 0\\r\\n\\r\\n\"\n            )\n            << ReceiveHttp(resp)\n            << ReceiveHttp(ResponseEndOfMessage(1))\n            # no we can send the next request\n            >> RequestHeaders(3, req, True)\n            << SendData(tctx.server, b\"GET / HTTP/1.1\\r\\ncontent-length: 0\\r\\n\\r\\n\")\n        )\n        assert resp().response.status_code == 200\n\n    def test_connect(self, tctx):\n        req = http.Request.make(\"CONNECT\", \"http://example.com:443\")\n        req.authority = \"example.com:443\"\n        resp = Placeholder(ResponseHeaders)\n\n        playbook = Playbook(Http1Client(tctx))\n        assert (\n            playbook\n            >> RequestHeaders(1, req, True)\n            << SendData(\n                tctx.server,\n                b\"CONNECT example.com:443 HTTP/1.1\\r\\ncontent-length: 0\\r\\n\\r\\n\",\n            )\n            >> RequestEndOfMessage(1)\n            >> DataReceived(\n                tctx.server,\n                b\"HTTP/1.1 200 OK\\r\\ncontent-length: 0\\r\\n\\r\\nsome plain tcp\",\n            )\n            << ReceiveHttp(resp)\n            # << ReceiveHttp(ResponseEndOfMessage(1))\n            << ReceiveHttp(ResponseData(1, b\"some plain tcp\"))\n            # no we can send plain data\n            >> RequestData(1, b\"some more tcp\")\n            << SendData(tctx.server, b\"some more tcp\")\n        )\n\n    def test_upgrade(self, tctx):\n        req = http.Request.make(\n            \"GET\",\n            \"http://example.com/ws\",\n            headers={\n                \"Connection\": \"Upgrade\",\n                \"Upgrade\": \"websocket\",\n            },\n        )\n        resp = Placeholder(ResponseHeaders)\n\n        playbook = Playbook(Http1Client(tctx))\n        assert (\n            playbook\n            >> RequestHeaders(1, req, True)\n            << SendData(\n                tctx.server,\n                b\"GET /ws HTTP/1.1\\r\\nConnection: Upgrade\\r\\nUpgrade: websocket\\r\\ncontent-length: 0\\r\\n\\r\\n\",\n            )\n            >> RequestEndOfMessage(1)\n            >> DataReceived(\n                tctx.server,\n                b\"HTTP/1.1 101 Switching Protocols\\r\\ncontent-length: 0\\r\\n\\r\\nhello\",\n            )\n            << ReceiveHttp(resp)\n            << ReceiveHttp(ResponseEndOfMessage(1))\n            << ReceiveHttp(ResponseData(1, b\"hello\"))\n            # no we can send plain data\n            >> RequestData(1, b\"some more websockets\")\n            << SendData(tctx.server, b\"some more websockets\")\n        )\n\n    def test_upgrade_denied(self, tctx):\n        req = http.Request.make(\n            \"GET\",\n            \"http://example.com/ws\",\n            headers={\n                \"Connection\": \"Upgrade\",\n                \"Upgrade\": \"websocket\",\n            },\n        )\n        resp = Placeholder(ResponseHeaders)\n\n        playbook = Playbook(Http1Client(tctx))\n        assert (\n            playbook\n            >> RequestHeaders(1, req, True)\n            << SendData(\n                tctx.server,\n                b\"GET /ws HTTP/1.1\\r\\nConnection: Upgrade\\r\\nUpgrade: websocket\\r\\ncontent-length: 0\\r\\n\\r\\n\",\n            )\n            >> RequestEndOfMessage(1)\n            >> DataReceived(\n                tctx.server, b\"HTTP/1.1 200 Ok\\r\\ncontent-length: 0\\r\\n\\r\\n\"\n            )\n            << ReceiveHttp(resp)\n            << ReceiveHttp(ResponseEndOfMessage(1))\n            >> RequestHeaders(3, req, True)\n            << SendData(tctx.server, Placeholder(bytes))\n        )\n", "test/mitmproxy/proxy/layers/http/test_http.py": "import gc\nfrom logging import WARNING\n\nimport pytest\n\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.connection import Server\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.http import Response\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.commands import CloseConnection\nfrom mitmproxy.proxy.commands import Log\nfrom mitmproxy.proxy.commands import OpenConnection\nfrom mitmproxy.proxy.commands import SendData\nfrom mitmproxy.proxy.events import ConnectionClosed\nfrom mitmproxy.proxy.events import DataReceived\nfrom mitmproxy.proxy.layers import http\nfrom mitmproxy.proxy.layers import TCPLayer\nfrom mitmproxy.proxy.layers import tls\nfrom mitmproxy.proxy.layers.http import HTTPMode\nfrom mitmproxy.proxy.layers.tcp import TcpMessageInjected\nfrom mitmproxy.proxy.layers.tcp import TcpStartHook\nfrom mitmproxy.proxy.layers.websocket import WebsocketStartHook\nfrom mitmproxy.proxy.mode_specs import ProxyMode\nfrom mitmproxy.tcp import TCPFlow\nfrom mitmproxy.tcp import TCPMessage\nfrom test.mitmproxy.proxy.tutils import BytesMatching\nfrom test.mitmproxy.proxy.tutils import Placeholder\nfrom test.mitmproxy.proxy.tutils import Playbook\nfrom test.mitmproxy.proxy.tutils import reply\nfrom test.mitmproxy.proxy.tutils import reply_next_layer\n\n\ndef test_http_proxy(tctx):\n    \"\"\"Test a simple HTTP GET / request\"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/foo?hello=1 HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET /foo?hello=1 HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(\n            server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 12\\r\\n\\r\\nHello World\"\n        )\n        << http.HttpResponseHeadersHook(flow)\n        >> reply()\n        >> DataReceived(server, b\"!\")\n        << http.HttpResponseHook(flow)\n        >> reply()\n        << SendData(\n            tctx.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 12\\r\\n\\r\\nHello World!\"\n        )\n    )\n    assert server().address == (\"example.com\", 80)\n\n\n@pytest.mark.parametrize(\"strategy\", [\"lazy\", \"eager\"])\ndef test_https_proxy(strategy, tctx):\n    \"\"\"Test a CONNECT request, followed by a HTTP GET /\"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n    tctx.options.connection_strategy = strategy\n\n    (\n        playbook\n        >> DataReceived(tctx.client, b\"CONNECT example.proxy:80 HTTP/1.1\\r\\n\\r\\n\")\n        << http.HttpConnectHook(Placeholder())\n        >> reply()\n    )\n    if strategy == \"eager\":\n        playbook << OpenConnection(server)\n        playbook >> reply(None)\n    (\n        playbook\n        << http.HttpConnectedHook(Placeholder())\n        >> reply(None)\n        << SendData(tctx.client, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n        >> DataReceived(\n            tctx.client, b\"GET /foo?hello=1 HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\"\n        )\n        << layer.NextLayerHook(Placeholder())\n        >> reply_next_layer(lambda ctx: http.HttpLayer(ctx, HTTPMode.transparent))\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n    )\n    if strategy == \"lazy\":\n        playbook << OpenConnection(server)\n        playbook >> reply(None)\n    (\n        playbook\n        << SendData(server, b\"GET /foo?hello=1 HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(\n            server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 12\\r\\n\\r\\nHello World!\"\n        )\n        << http.HttpResponseHeadersHook(flow)\n        >> reply()\n        << http.HttpResponseHook(flow)\n        >> reply()\n        << SendData(\n            tctx.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 12\\r\\n\\r\\nHello World!\"\n        )\n    )\n    assert playbook\n\n\n@pytest.mark.parametrize(\"https_client\", [False, True])\n@pytest.mark.parametrize(\"https_server\", [False, True])\n@pytest.mark.parametrize(\"strategy\", [\"lazy\", \"eager\"])\ndef test_redirect(strategy, https_server, https_client, tctx, monkeypatch):\n    \"\"\"Test redirects between http:// and https:// in regular proxy mode.\"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    tctx.options.connection_strategy = strategy\n    p = Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n\n    if https_server:\n        monkeypatch.setattr(tls, \"ServerTLSLayer\", tls.MockTLSLayer)\n\n    def redirect(flow: HTTPFlow):\n        if https_server:\n            flow.request.url = \"https://redirected.site/\"\n        else:\n            flow.request.url = \"http://redirected.site/\"\n\n    if https_client:\n        p >> DataReceived(tctx.client, b\"CONNECT example.com:80 HTTP/1.1\\r\\n\\r\\n\")\n        if strategy == \"eager\":\n            p << OpenConnection(Placeholder())\n            p >> reply(None)\n        p << SendData(tctx.client, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n        p >> DataReceived(tctx.client, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        p << layer.NextLayerHook(Placeholder())\n        p >> reply_next_layer(lambda ctx: http.HttpLayer(ctx, HTTPMode.transparent))\n    else:\n        p >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n    p << http.HttpRequestHook(flow)\n    p >> reply(side_effect=redirect)\n    p << OpenConnection(server)\n    p >> reply(None)\n    p << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: redirected.site\\r\\n\\r\\n\")\n    p >> DataReceived(\n        server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 12\\r\\n\\r\\nHello World!\"\n    )\n    p << SendData(\n        tctx.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 12\\r\\n\\r\\nHello World!\"\n    )\n\n    assert p\n    if https_server:\n        assert server().address == (\"redirected.site\", 443)\n    else:\n        assert server().address == (\"redirected.site\", 80)\n\n\ndef test_multiple_server_connections(tctx):\n    \"\"\"Test multiple requests being rewritten to different targets.\"\"\"\n    server1 = Placeholder(Server)\n    server2 = Placeholder(Server)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n\n    def redirect(to: str):\n        def side_effect(flow: HTTPFlow):\n            flow.request.url = to\n\n        return side_effect\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << http.HttpRequestHook(Placeholder())\n        >> reply(side_effect=redirect(\"http://one.redirect/\"))\n        << OpenConnection(server1)\n        >> reply(None)\n        << SendData(server1, b\"GET / HTTP/1.1\\r\\nHost: one.redirect\\r\\n\\r\\n\")\n        >> DataReceived(server1, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n    )\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << http.HttpRequestHook(Placeholder())\n        >> reply(side_effect=redirect(\"http://two.redirect/\"))\n        << OpenConnection(server2)\n        >> reply(None)\n        << SendData(server2, b\"GET / HTTP/1.1\\r\\nHost: two.redirect\\r\\n\\r\\n\")\n        >> DataReceived(server2, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n    )\n    assert server1().address == (\"one.redirect\", 80)\n    assert server2().address == (\"two.redirect\", 80)\n\n\n@pytest.mark.parametrize(\"transfer_encoding\", [\"identity\", \"chunked\"])\ndef test_pipelining(tctx, transfer_encoding):\n    \"\"\"Test that multiple requests can be processed over the same connection\"\"\"\n\n    tctx.server.address = (\"example.com\", 80)\n    tctx.server.state = ConnectionState.OPEN\n\n    req = b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\"\n    if transfer_encoding == \"identity\":\n        resp = b\"HTTP/1.1 200 OK\\r\\n\" b\"Content-Length: 12\\r\\n\" b\"\\r\\n\" b\"Hello World!\"\n    else:\n        resp = (\n            b\"HTTP/1.1 200 OK\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"\\r\\n\"\n            b\"c\\r\\n\"\n            b\"Hello World!\\r\\n\"\n            b\"0\\r\\n\"\n            b\"\\r\\n\"\n        )\n\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.transparent), hooks=False)\n        # Roundtrip 1\n        >> DataReceived(tctx.client, req)\n        << SendData(tctx.server, req)\n        >> DataReceived(tctx.server, resp)\n        << SendData(tctx.client, resp)\n        # Roundtrip 2\n        >> DataReceived(tctx.client, req)\n        << SendData(tctx.server, req)\n        >> DataReceived(tctx.server, resp)\n        << SendData(tctx.client, resp)\n    )\n\n\ndef test_http_reply_from_proxy(tctx):\n    \"\"\"Test a response served by mitmproxy itself.\"\"\"\n\n    def reply_from_proxy(flow: HTTPFlow):\n        flow.response = Response.make(418)\n\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << http.HttpRequestHook(Placeholder())\n        >> reply(side_effect=reply_from_proxy)\n        << SendData(\n            tctx.client, b\"HTTP/1.1 418 I'm a teapot\\r\\ncontent-length: 0\\r\\n\\r\\n\"\n        )\n    )\n\n\ndef test_response_until_eof(tctx):\n    \"\"\"Test scenario where the server response body is terminated by EOF.\"\"\"\n    server = Placeholder(Server)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(server, b\"HTTP/1.1 200 OK\\r\\n\\r\\nfoo\")\n        >> ConnectionClosed(server)\n        << CloseConnection(server)\n        << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\n\\r\\nfoo\")\n        << CloseConnection(tctx.client)\n    )\n\n\ndef test_disconnect_while_intercept(tctx):\n    \"\"\"Test a server disconnect while a request is intercepted.\"\"\"\n    tctx.options.connection_strategy = \"eager\"\n\n    server1 = Placeholder(Server)\n    server2 = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(tctx.client, b\"CONNECT example.com:80 HTTP/1.1\\r\\n\\r\\n\")\n        << http.HttpConnectHook(Placeholder(HTTPFlow))\n        >> reply()\n        << OpenConnection(server1)\n        >> reply(None)\n        << http.HttpConnectedHook(Placeholder(HTTPFlow))\n        >> reply(None)\n        << SendData(tctx.client, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n        >> DataReceived(tctx.client, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        << layer.NextLayerHook(Placeholder())\n        >> reply_next_layer(lambda ctx: http.HttpLayer(ctx, HTTPMode.transparent))\n        << http.HttpRequestHook(flow)\n        >> ConnectionClosed(server1)\n        << CloseConnection(server1)\n        >> reply(to=-3)\n        << OpenConnection(server2)\n        >> reply(None)\n        << SendData(server2, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(server2, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n    )\n    assert server1() != server2()\n    assert flow().server_conn == server2()\n    assert not flow().live\n\n\n@pytest.mark.parametrize(\"why\", [\"body_size=0\", \"body_size=3\", \"addon\"])\n@pytest.mark.parametrize(\"transfer_encoding\", [\"identity\", \"chunked\"])\ndef test_response_streaming(tctx, why, transfer_encoding):\n    \"\"\"Test HTTP response streaming\"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n\n    if why.startswith(\"body_size\"):\n        tctx.options.stream_large_bodies = why.replace(\"body_size=\", \"\")\n\n    def enable_streaming(flow: HTTPFlow):\n        if why == \"addon\":\n            flow.response.stream = True\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/largefile HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET /largefile HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(server, b\"HTTP/1.1 200 OK\\r\\n\")\n    )\n    assert flow().live\n    if transfer_encoding == \"identity\":\n        playbook >> DataReceived(server, b\"Content-Length: 6\\r\\n\\r\\n\" b\"abc\")\n    else:\n        playbook >> DataReceived(\n            server, b\"Transfer-Encoding: chunked\\r\\n\\r\\n\" b\"3\\r\\nabc\\r\\n\"\n        )\n\n    playbook << http.HttpResponseHeadersHook(flow)\n    playbook >> reply(side_effect=enable_streaming)\n\n    if transfer_encoding == \"identity\":\n        playbook << SendData(\n            tctx.client, b\"HTTP/1.1 200 OK\\r\\n\" b\"Content-Length: 6\\r\\n\\r\\n\" b\"abc\"\n        )\n        playbook >> DataReceived(server, b\"def\")\n        playbook << SendData(tctx.client, b\"def\")\n    else:\n        if why == \"body_size=3\":\n            playbook >> DataReceived(server, b\"3\\r\\ndef\\r\\n\")\n            playbook << SendData(\n                tctx.client,\n                b\"HTTP/1.1 200 OK\\r\\n\"\n                b\"Transfer-Encoding: chunked\\r\\n\\r\\n\"\n                b\"6\\r\\nabcdef\\r\\n\",\n            )\n        else:\n            playbook << SendData(\n                tctx.client,\n                b\"HTTP/1.1 200 OK\\r\\n\"\n                b\"Transfer-Encoding: chunked\\r\\n\\r\\n\"\n                b\"3\\r\\nabc\\r\\n\",\n            )\n            playbook >> DataReceived(server, b\"3\\r\\ndef\\r\\n\")\n            playbook << SendData(tctx.client, b\"3\\r\\ndef\\r\\n\")\n        playbook >> DataReceived(server, b\"0\\r\\n\\r\\n\")\n\n    playbook << http.HttpResponseHook(flow)\n    playbook >> reply()\n\n    if transfer_encoding == \"chunked\":\n        playbook << SendData(tctx.client, b\"0\\r\\n\\r\\n\")\n\n    assert playbook\n    assert not flow().live\n\n\ndef test_stream_modify(tctx):\n    \"\"\"Test HTTP stream modification\"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n\n    def enable_streaming(flow: HTTPFlow):\n        if flow.response is None:\n            flow.request.stream = lambda x: b\"[\" + x + b\"]\"\n        else:\n            flow.response.stream = lambda x: b\"[\" + x + b\"]\"\n\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n        >> DataReceived(\n            tctx.client,\n            b\"POST http://example.com/ HTTP/1.1\\r\\n\"\n            b\"Host: example.com\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\\r\\n\"\n            b\"3\\r\\nabc\\r\\n\"\n            b\"0\\r\\n\\r\\n\",\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply(side_effect=enable_streaming)\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(\n            server,\n            b\"POST / HTTP/1.1\\r\\n\"\n            b\"Host: example.com\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\\r\\n\"\n            b\"5\\r\\n[abc]\\r\\n\"\n            b\"2\\r\\n[]\\r\\n\",\n        )\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << SendData(server, b\"0\\r\\n\\r\\n\")\n        >> DataReceived(\n            server,\n            b\"HTTP/1.1 200 OK\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\\r\\n\"\n            b\"3\\r\\ndef\\r\\n\"\n            b\"0\\r\\n\\r\\n\",\n        )\n        << http.HttpResponseHeadersHook(flow)\n        >> reply(side_effect=enable_streaming)\n        << SendData(\n            tctx.client,\n            b\"HTTP/1.1 200 OK\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\\r\\n\"\n            b\"5\\r\\n[def]\\r\\n\"\n            b\"2\\r\\n[]\\r\\n\",\n        )\n        << http.HttpResponseHook(flow)\n        >> reply()\n        << SendData(tctx.client, b\"0\\r\\n\\r\\n\")\n    )\n\n\n@pytest.mark.parametrize(\"why\", [\"body_size=0\", \"body_size=3\", \"addon\"])\n@pytest.mark.parametrize(\"transfer_encoding\", [\"identity\", \"chunked\"])\n@pytest.mark.parametrize(\n    \"response\", [\"normal response\", \"early response\", \"early close\", \"early kill\"]\n)\ndef test_request_streaming(tctx, why, transfer_encoding, response):\n    \"\"\"\n    Test HTTP request streaming\n\n    This is a bit more contrived as we may receive server data while we are still sending the request.\n    \"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n\n    if why.startswith(\"body_size\"):\n        tctx.options.stream_large_bodies = why.replace(\"body_size=\", \"\")\n\n    def enable_streaming(flow: HTTPFlow):\n        if why == \"addon\":\n            flow.request.stream = True\n\n    playbook >> DataReceived(\n        tctx.client, b\"POST http://example.com/ HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\"\n    )\n    if transfer_encoding == \"identity\":\n        playbook >> DataReceived(tctx.client, b\"Content-Length: 9\\r\\n\\r\\n\" b\"abc\")\n    else:\n        playbook >> DataReceived(\n            tctx.client, b\"Transfer-Encoding: chunked\\r\\n\\r\\n\" b\"3\\r\\nabc\\r\\n\"\n        )\n\n    playbook << http.HttpRequestHeadersHook(flow)\n    playbook >> reply(side_effect=enable_streaming)\n\n    needs_more_data_before_open = (\n        why == \"body_size=3\" and transfer_encoding == \"chunked\"\n    )\n    if needs_more_data_before_open:\n        playbook >> DataReceived(tctx.client, b\"3\\r\\ndef\\r\\n\")\n\n    playbook << OpenConnection(server)\n    playbook >> reply(None)\n    playbook << SendData(server, b\"POST / HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\")\n\n    if transfer_encoding == \"identity\":\n        playbook << SendData(server, b\"Content-Length: 9\\r\\n\\r\\n\" b\"abc\")\n        playbook >> DataReceived(tctx.client, b\"def\")\n        playbook << SendData(server, b\"def\")\n    else:\n        if needs_more_data_before_open:\n            playbook << SendData(\n                server, b\"Transfer-Encoding: chunked\\r\\n\\r\\n\" b\"6\\r\\nabcdef\\r\\n\"\n            )\n        else:\n            playbook << SendData(\n                server, b\"Transfer-Encoding: chunked\\r\\n\\r\\n\" b\"3\\r\\nabc\\r\\n\"\n            )\n            playbook >> DataReceived(tctx.client, b\"3\\r\\ndef\\r\\n\")\n            playbook << SendData(server, b\"3\\r\\ndef\\r\\n\")\n\n    if response == \"normal response\":\n        if transfer_encoding == \"identity\":\n            playbook >> DataReceived(tctx.client, b\"ghi\")\n            playbook << SendData(server, b\"ghi\")\n        else:\n            playbook >> DataReceived(tctx.client, b\"3\\r\\nghi\\r\\n0\\r\\n\\r\\n\")\n            playbook << SendData(server, b\"3\\r\\nghi\\r\\n\")\n\n        playbook << http.HttpRequestHook(flow)\n        playbook >> reply()\n        if transfer_encoding == \"chunked\":\n            playbook << SendData(server, b\"0\\r\\n\\r\\n\")\n        assert (\n            playbook\n            >> DataReceived(server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n            << http.HttpResponseHeadersHook(flow)\n            >> reply()\n            << http.HttpResponseHook(flow)\n            >> reply()\n            << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        )\n    elif response == \"early response\":\n        # We may receive a response before we have finished sending our request.\n        # We continue sending unless the server closes the connection.\n        # https://tools.ietf.org/html/rfc7231#section-6.5.11\n        assert (\n            playbook\n            >> DataReceived(\n                server,\n                b\"HTTP/1.1 413 Request Entity Too Large\\r\\nContent-Length: 0\\r\\n\\r\\n\",\n            )\n            << http.HttpResponseHeadersHook(flow)\n            >> reply()\n            << http.HttpResponseHook(flow)\n            >> reply()\n            << SendData(\n                tctx.client,\n                b\"HTTP/1.1 413 Request Entity Too Large\\r\\nContent-Length: 0\\r\\n\\r\\n\",\n            )\n        )\n        if transfer_encoding == \"identity\":\n            playbook >> DataReceived(tctx.client, b\"ghi\")\n            playbook << SendData(server, b\"ghi\")\n        else:\n            playbook >> DataReceived(tctx.client, b\"3\\r\\nghi\\r\\n0\\r\\n\\r\\n\")\n            playbook << SendData(server, b\"3\\r\\nghi\\r\\n\")\n        playbook << http.HttpRequestHook(flow)\n        playbook >> reply()\n        if transfer_encoding == \"chunked\":\n            playbook << SendData(server, b\"0\\r\\n\\r\\n\")\n        assert playbook\n    elif response == \"early close\":\n        assert (\n            playbook\n            >> DataReceived(\n                server,\n                b\"HTTP/1.1 413 Request Entity Too Large\\r\\nContent-Length: 0\\r\\n\\r\\n\",\n            )\n            << http.HttpResponseHeadersHook(flow)\n            >> reply()\n            << http.HttpResponseHook(flow)\n            >> reply()\n            << SendData(\n                tctx.client,\n                b\"HTTP/1.1 413 Request Entity Too Large\\r\\nContent-Length: 0\\r\\n\\r\\n\",\n            )\n            >> ConnectionClosed(server)\n            << CloseConnection(server)\n            << CloseConnection(tctx.client)\n        )\n    elif response == \"early kill\":\n        assert (\n            playbook\n            >> ConnectionClosed(server)\n            << CloseConnection(server)\n            << http.HttpErrorHook(flow)\n            >> reply()\n            << SendData(tctx.client, BytesMatching(b\"502 Bad Gateway\"))\n            << CloseConnection(tctx.client)\n        )\n    else:  # pragma: no cover\n        assert False\n\n\n@pytest.mark.parametrize(\"where\", [\"request\", \"response\"])\n@pytest.mark.parametrize(\"transfer_encoding\", [\"identity\", \"chunked\"])\ndef test_body_size_limit(tctx, where, transfer_encoding):\n    \"\"\"Test HTTP request body_size_limit\"\"\"\n    tctx.options.body_size_limit = \"3\"\n    flow = Placeholder(HTTPFlow)\n\n    if transfer_encoding == \"identity\":\n        body = b\"Content-Length: 6\\r\\n\\r\\nabcdef\"\n    else:\n        body = b\"Transfer-Encoding: chunked\\r\\n\\r\\n6\\r\\nabcdef\"\n\n    if where == \"request\":\n        assert (\n            Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n            >> DataReceived(\n                tctx.client,\n                b\"POST http://example.com/ HTTP/1.1\\r\\n\"\n                b\"Host: example.com\\r\\n\" + body,\n            )\n            << http.HttpRequestHeadersHook(flow)\n            >> reply()\n            << http.HttpErrorHook(flow)\n            >> reply()\n            << SendData(\n                tctx.client, BytesMatching(b\"413 Payload Too Large.+body_size_limit\")\n            )\n            << CloseConnection(tctx.client)\n        )\n        assert not flow().live\n    else:\n        server = Placeholder(Server)\n        assert (\n            Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n            >> DataReceived(\n                tctx.client,\n                b\"GET http://example.com/ HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\\r\\n\",\n            )\n            << http.HttpRequestHeadersHook(flow)\n            >> reply()\n            << http.HttpRequestHook(flow)\n            >> reply()\n            << OpenConnection(server)\n            >> reply(None)\n            << SendData(server, b\"GET / HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\\r\\n\")\n            >> DataReceived(server, b\"HTTP/1.1 200 OK\\r\\n\" + body)\n            << http.HttpResponseHeadersHook(flow)\n            >> reply()\n            << http.HttpErrorHook(flow)\n            >> reply()\n            << SendData(tctx.client, BytesMatching(b\"502 Bad Gateway.+body_size_limit\"))\n            << CloseConnection(tctx.client)\n            << CloseConnection(server)\n        )\n        assert not flow().live\n\n\n@pytest.mark.parametrize(\"connect\", [True, False])\ndef test_server_unreachable(tctx, connect):\n    \"\"\"Test the scenario where the target server is unreachable.\"\"\"\n    tctx.options.connection_strategy = \"eager\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n    if connect:\n        playbook >> DataReceived(\n            tctx.client, b\"CONNECT example.com:443 HTTP/1.1\\r\\n\\r\\n\"\n        )\n    else:\n        playbook >> DataReceived(\n            tctx.client, b\"GET http://example.com/ HTTP/1.1\\r\\n\\r\\n\"\n        )\n\n    playbook << OpenConnection(server)\n    playbook >> reply(\"Connection failed\")\n    if not connect:\n        playbook << http.HttpErrorHook(flow)\n    else:\n        playbook << http.HttpConnectErrorHook(flow)\n    playbook >> reply()\n    playbook << SendData(\n        tctx.client, BytesMatching(b\"502 Bad Gateway.+Connection failed\")\n    )\n    if not connect:\n        playbook << CloseConnection(tctx.client)\n\n    assert playbook\n    assert not flow().live\n    if not connect:\n        assert flow().error\n\n\n@pytest.mark.parametrize(\n    \"data\",\n    [\n        None,\n        b\"I don't speak HTTP.\",\n        b\"HTTP/1.1 200 OK\\r\\nContent-Length: 10\\r\\n\\r\\nweee\",\n    ],\n)\ndef test_server_aborts(tctx, data):\n    \"\"\"Test the scenario where the server doesn't serve a response\"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n    )\n    if data:\n        playbook >> DataReceived(server, data)\n    assert (\n        playbook\n        >> ConnectionClosed(server)\n        << CloseConnection(server)\n        << http.HttpErrorHook(flow)\n        >> reply()\n        << SendData(tctx.client, BytesMatching(b\"502 Bad Gateway\"))\n        << CloseConnection(tctx.client)\n    )\n    assert flow().error\n    assert not flow().live\n\n\n@pytest.mark.parametrize(\"redirect\", [\"\", \"change-destination\", \"change-proxy\"])\n@pytest.mark.parametrize(\"domain\", [b\"example.com\", b\"xn--eckwd4c7c.xn--zckzah\"])\n@pytest.mark.parametrize(\"scheme\", [\"http\", \"https\"])\ndef test_upstream_proxy(tctx, redirect, domain, scheme):\n    \"\"\"Test that an upstream HTTP proxy is used.\"\"\"\n    server = Placeholder(Server)\n    server2 = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    tctx.client.proxy_mode = ProxyMode.parse(\"upstream:http://proxy:8080\")\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.upstream), hooks=False)\n\n    if scheme == \"http\":\n        assert (\n            playbook\n            >> DataReceived(\n                tctx.client,\n                b\"GET http://%s/ HTTP/1.1\\r\\nHost: %s\\r\\n\\r\\n\" % (domain, domain),\n            )\n            << OpenConnection(server)\n            >> reply(None)\n            << SendData(\n                server,\n                b\"GET http://%s/ HTTP/1.1\\r\\nHost: %s\\r\\n\\r\\n\" % (domain, domain),\n            )\n        )\n\n    else:\n        assert (\n            playbook\n            >> DataReceived(tctx.client, b\"CONNECT %s:443 HTTP/1.1\\r\\n\\r\\n\" % domain)\n            << SendData(tctx.client, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n            >> DataReceived(tctx.client, b\"GET / HTTP/1.1\\r\\nHost: %s\\r\\n\\r\\n\" % domain)\n            << layer.NextLayerHook(Placeholder())\n            >> reply_next_layer(lambda ctx: http.HttpLayer(ctx, HTTPMode.transparent))\n            << OpenConnection(server)\n            >> reply(None)\n            << SendData(server, b\"CONNECT %s:443 HTTP/1.1\\r\\n\\r\\n\" % domain)\n            >> DataReceived(server, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n            << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: %s\\r\\n\\r\\n\" % domain)\n        )\n\n    playbook >> DataReceived(server, b\"HTTP/1.1 418 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n    playbook << SendData(tctx.client, b\"HTTP/1.1 418 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n\n    assert playbook\n    assert server().address == (\"proxy\", 8080)\n\n    if scheme == \"http\":\n        playbook >> DataReceived(\n            tctx.client,\n            b\"GET http://%s/two HTTP/1.1\\r\\nHost: %s\\r\\n\\r\\n\" % (domain, domain),\n        )\n    else:\n        playbook >> DataReceived(\n            tctx.client, b\"GET /two HTTP/1.1\\r\\nHost: %s\\r\\n\\r\\n\" % domain\n        )\n\n    assert playbook << http.HttpRequestHook(flow)\n    if redirect == \"change-destination\":\n        flow().request.host = domain + b\".test\"\n        flow().request.host_header = domain\n    elif redirect == \"change-proxy\":\n        flow().server_conn.via = (\"http\", (\"other-proxy\", 1234))\n    playbook >> reply()\n\n    if redirect:\n        # Protocol-wise we wouldn't need to open a new connection for plain http host redirects,\n        # but we disregard this edge case to simplify implementation.\n        playbook << OpenConnection(server2)\n        playbook >> reply(None)\n    else:\n        server2 = server\n\n    if scheme == \"http\":\n        if redirect == \"change-destination\":\n            playbook << SendData(\n                server2,\n                b\"GET http://%s.test/two HTTP/1.1\\r\\nHost: %s\\r\\n\\r\\n\"\n                % (domain, domain),\n            )\n        else:\n            playbook << SendData(\n                server2,\n                b\"GET http://%s/two HTTP/1.1\\r\\nHost: %s\\r\\n\\r\\n\" % (domain, domain),\n            )\n    else:\n        if redirect == \"change-destination\":\n            playbook << SendData(\n                server2, b\"CONNECT %s.test:443 HTTP/1.1\\r\\n\\r\\n\" % domain\n            )\n            playbook >> DataReceived(\n                server2, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\"\n            )\n        elif redirect == \"change-proxy\":\n            playbook << SendData(server2, b\"CONNECT %s:443 HTTP/1.1\\r\\n\\r\\n\" % domain)\n            playbook >> DataReceived(\n                server2, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\"\n            )\n        playbook << SendData(server2, b\"GET /two HTTP/1.1\\r\\nHost: %s\\r\\n\\r\\n\" % domain)\n\n    playbook >> DataReceived(server2, b\"HTTP/1.1 418 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n    playbook << SendData(tctx.client, b\"HTTP/1.1 418 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n\n    assert playbook\n\n    if redirect == \"change-destination\":\n        assert flow().server_conn.address[0] == (domain + b\".test\").decode(\"idna\")\n    else:\n        assert flow().server_conn.address[0] == domain.decode(\"idna\")\n\n    if redirect == \"change-proxy\":\n        assert server2().address == flow().server_conn.via[1] == (\"other-proxy\", 1234)\n    else:\n        assert server2().address == flow().server_conn.via[1] == (\"proxy\", 8080)\n\n    playbook >> ConnectionClosed(tctx.client)\n    playbook << CloseConnection(tctx.client)\n    assert playbook\n\n\n@pytest.mark.parametrize(\"mode\", [\"regular\", \"upstream\"])\n@pytest.mark.parametrize(\"close_first\", [\"client\", \"server\"])\ndef test_http_proxy_tcp(tctx, mode, close_first):\n    \"\"\"Test TCP over HTTP CONNECT.\"\"\"\n    server = Placeholder(Server)\n    f = Placeholder(TCPFlow)\n    tctx.options.connection_strategy = \"lazy\"\n\n    if mode == \"upstream\":\n        tctx.client.proxy_mode = ProxyMode.parse(\"upstream:http://proxy:8080\")\n        toplayer = http.HttpLayer(tctx, HTTPMode.upstream)\n    else:\n        tctx.client.proxy_mode = ProxyMode.parse(\"regular\")\n        toplayer = http.HttpLayer(tctx, HTTPMode.regular)\n\n    playbook = Playbook(toplayer, hooks=False)\n    assert (\n        playbook\n        >> DataReceived(tctx.client, b\"CONNECT example:443 HTTP/1.1\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n        >> DataReceived(tctx.client, b\"this is not http\")\n        << layer.NextLayerHook(Placeholder())\n        >> reply_next_layer(lambda ctx: TCPLayer(ctx, ignore=False))\n        << TcpStartHook(f)\n        >> reply()\n        << OpenConnection(server)\n    )\n\n    playbook >> reply(None)\n    if mode == \"upstream\":\n        playbook << SendData(server, b\"CONNECT example:443 HTTP/1.1\\r\\n\\r\\n\")\n        playbook >> DataReceived(server, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n\n    assert (\n        playbook\n        << SendData(server, b\"this is not http\")\n        >> DataReceived(server, b\"true that\")\n        << SendData(tctx.client, b\"true that\")\n    )\n\n    if mode == \"regular\":\n        assert server().address == (\"example\", 443)\n    else:\n        assert server().address == (\"proxy\", 8080)\n\n    assert (\n        playbook\n        >> TcpMessageInjected(\n            f, TCPMessage(False, b\"fake news from your friendly man-in-the-middle\")\n        )\n        << SendData(tctx.client, b\"fake news from your friendly man-in-the-middle\")\n    )\n\n    if close_first == \"client\":\n        a, b = tctx.client, server\n    else:\n        a, b = server, tctx.client\n    assert (\n        playbook\n        >> ConnectionClosed(a)\n        << CloseConnection(b)\n        >> ConnectionClosed(b)\n        << CloseConnection(a)\n    )\n\n\n@pytest.mark.parametrize(\"strategy\", [\"eager\", \"lazy\"])\ndef test_proxy_chain(tctx, strategy):\n    server = Placeholder(Server)\n    tctx.options.connection_strategy = strategy\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n\n    playbook >> DataReceived(tctx.client, b\"CONNECT proxy:8080 HTTP/1.1\\r\\n\\r\\n\")\n    if strategy == \"eager\":\n        playbook << OpenConnection(server)\n        playbook >> reply(None)\n    playbook << SendData(tctx.client, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n\n    playbook >> DataReceived(tctx.client, b\"CONNECT second-proxy:8080 HTTP/1.1\\r\\n\\r\\n\")\n    playbook << layer.NextLayerHook(Placeholder())\n    playbook >> reply_next_layer(lambda ctx: http.HttpLayer(ctx, HTTPMode.transparent))\n    playbook << SendData(\n        tctx.client,\n        b\"HTTP/1.1 502 Bad Gateway\\r\\n\"\n        b\"content-length: 198\\r\\n\"\n        b\"\\r\\n\"\n        b\"mitmproxy received an HTTP CONNECT request even though it is not running in regular/upstream mode. \"\n        b\"This usually indicates a misconfiguration, please see the mitmproxy mode documentation for details.\",\n    )\n\n    assert playbook\n\n\ndef test_no_headers(tctx):\n    \"\"\"Test that we can correctly reassemble requests/responses with no headers.\"\"\"\n    server = Placeholder(Server)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(tctx.client, b\"GET http://example.com/ HTTP/1.1\\r\\n\\r\\n\")\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        >> DataReceived(server, b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n    )\n    assert server().address == (\"example.com\", 80)\n\n\ndef test_http_proxy_without_empty_chunk_in_head_request(tctx):\n    \"\"\"Test handling of an empty, \"chunked\" head response.\"\"\"\n    server = Placeholder(Server)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(tctx.client, b\"HEAD http://example.com/ HTTP/1.1\\r\\n\\r\\n\")\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"HEAD / HTTP/1.1\\r\\n\\r\\n\")\n        >> DataReceived(\n            server, b\"HTTP/1.1 200 OK\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        )\n        << SendData(\n            tctx.client, b\"HTTP/1.1 200 OK\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        )\n    )\n\n\ndef test_http_proxy_relative_request(tctx):\n    \"\"\"Test handling of a relative-form \"GET /\" in regular proxy mode.\"\"\"\n    server = Placeholder(Server)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(tctx.client, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(server, b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n    )\n    assert server().address == (\"example.com\", 80)\n\n\ndef test_http_proxy_relative_request_no_host_header(tctx):\n    \"\"\"Test handling of a relative-form \"GET /\" in regular proxy mode, but without a host header.\"\"\"\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(tctx.client, b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        << SendData(\n            tctx.client,\n            BytesMatching(\n                b\"400 Bad Request.+\"\n                b\"HTTP request has no host header, destination unknown.\"\n            ),\n        )\n        << CloseConnection(tctx.client)\n    )\n\n\ndef test_http_expect(tctx):\n    \"\"\"Test handling of a 'Expect: 100-continue' header.\"\"\"\n    server = Placeholder(Server)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            b\"PUT http://example.com/large-file HTTP/1.1\\r\\n\"\n            b\"Host: example.com\\r\\n\"\n            b\"Content-Length: 15\\r\\n\"\n            b\"Expect: 100-continue\\r\\n\\r\\n\",\n        )\n        << SendData(tctx.client, b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n        >> DataReceived(tctx.client, b\"lots of content\")\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(\n            server,\n            b\"PUT /large-file HTTP/1.1\\r\\n\"\n            b\"Host: example.com\\r\\n\"\n            b\"Content-Length: 15\\r\\n\\r\\n\"\n            b\"lots of content\",\n        )\n        >> DataReceived(server, b\"HTTP/1.1 201 Created\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 201 Created\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n    )\n    assert server().address == (\"example.com\", 80)\n\n\n@pytest.mark.parametrize(\"stream\", [True, False])\ndef test_http_client_aborts(tctx, stream):\n    \"\"\"Test handling of the case where a client aborts during request transmission.\"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=True)\n\n    def enable_streaming(flow: HTTPFlow):\n        flow.request.stream = True\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            b\"POST http://example.com/ HTTP/1.1\\r\\n\"\n            b\"Host: example.com\\r\\n\"\n            b\"Content-Length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"abc\",\n        )\n        << http.HttpRequestHeadersHook(flow)\n    )\n    if stream:\n        assert (\n            playbook\n            >> reply(side_effect=enable_streaming)\n            << OpenConnection(server)\n            >> reply(None)\n            << SendData(\n                server,\n                b\"POST / HTTP/1.1\\r\\n\"\n                b\"Host: example.com\\r\\n\"\n                b\"Content-Length: 6\\r\\n\"\n                b\"\\r\\n\"\n                b\"abc\",\n            )\n        )\n    else:\n        assert playbook >> reply()\n    playbook >> ConnectionClosed(tctx.client)\n    playbook << CloseConnection(tctx.client)\n    if stream:\n        playbook << CloseConnection(server)\n\n    playbook << http.HttpErrorHook(flow)\n    playbook >> reply()\n    playbook << None\n    assert playbook\n\n    assert \"peer closed connection\" in flow().error.msg\n    assert not flow().live\n\n\n@pytest.mark.parametrize(\"stream\", [True, False])\ndef test_http_server_aborts(tctx, stream):\n    \"\"\"Test handling of the case where a server aborts during response transmission.\"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n\n    def enable_streaming(flow: HTTPFlow):\n        flow.response.stream = True\n\n    assert (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\\r\\n\",\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\\r\\n\")\n        >> DataReceived(\n            server, b\"HTTP/1.1 200 OK\\r\\n\" b\"Content-Length: 6\\r\\n\" b\"\\r\\n\" b\"abc\"\n        )\n        << http.HttpResponseHeadersHook(flow)\n    )\n    if stream:\n        assert (\n            playbook\n            >> reply(side_effect=enable_streaming)\n            << SendData(\n                tctx.client,\n                b\"HTTP/1.1 200 OK\\r\\n\" b\"Content-Length: 6\\r\\n\" b\"\\r\\n\" b\"abc\",\n            )\n        )\n    else:\n        assert playbook >> reply()\n    assert (\n        playbook\n        >> ConnectionClosed(server)\n        << CloseConnection(server)\n        << http.HttpErrorHook(flow)\n    )\n    if stream:\n        playbook >> reply()\n        playbook << CloseConnection(tctx.client)\n        assert playbook\n    else:\n        assert (\n            playbook\n            >> reply()\n            << SendData(\n                tctx.client, BytesMatching(b\"502 Bad Gateway.+peer closed connection\")\n            )\n            << CloseConnection(tctx.client)\n        )\n\n    assert \"peer closed connection\" in flow().error.msg\n    assert not flow().live\n\n\n@pytest.mark.parametrize(\n    \"when\",\n    [\n        \"http_connect\",\n        \"requestheaders\",\n        \"request\",\n        \"script-response-responseheaders\",\n        \"responseheaders\",\n        \"response\",\n        \"error\",\n    ],\n)\ndef test_kill_flow(tctx, when):\n    \"\"\"Test that we properly kill flows if instructed to do so\"\"\"\n    tctx.options.connection_strategy = \"lazy\"\n    server = Placeholder(Server)\n    connect_flow = Placeholder(HTTPFlow)\n    flow = Placeholder(HTTPFlow)\n\n    def kill(flow: HTTPFlow):\n        flow.kill()\n\n    def assert_kill(err_hook: bool = True):\n        playbook >> reply(side_effect=kill)\n        if err_hook:\n            playbook << http.HttpErrorHook(flow)\n            playbook >> reply()\n        playbook << CloseConnection(tctx.client)\n        assert playbook\n        if flow():\n            assert not flow().live\n\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n    assert (\n        playbook\n        >> DataReceived(tctx.client, b\"CONNECT example.com:80 HTTP/1.1\\r\\n\\r\\n\")\n        << http.HttpConnectHook(connect_flow)\n    )\n    if when == \"http_connect\":\n        return assert_kill(False)\n    assert (\n        playbook\n        >> reply()\n        << http.HttpConnectedHook(connect_flow)\n        >> reply()\n        << SendData(tctx.client, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n        >> DataReceived(\n            tctx.client, b\"GET /foo?hello=1 HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\"\n        )\n        << layer.NextLayerHook(Placeholder())\n        >> reply_next_layer(lambda ctx: http.HttpLayer(ctx, HTTPMode.transparent))\n        << http.HttpRequestHeadersHook(flow)\n    )\n    if when == \"requestheaders\":\n        return assert_kill()\n    playbook >> reply()\n    playbook << http.HttpRequestHook(flow)\n    if when == \"request\":\n        return assert_kill()\n    if when == \"script-response-responseheaders\":\n        assert (\n            playbook\n            >> reply(side_effect=lambda f: setattr(f, \"response\", Response.make()))\n            << http.HttpResponseHeadersHook(flow)\n        )\n        return assert_kill()\n    assert (\n        playbook\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET /foo?hello=1 HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(\n            server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 12\\r\\n\\r\\nHello World\"\n        )\n        << http.HttpResponseHeadersHook(flow)\n    )\n    if when == \"responseheaders\":\n        return assert_kill()\n\n    if when == \"response\":\n        assert (\n            playbook\n            >> reply()\n            >> DataReceived(server, b\"!\")\n            << http.HttpResponseHook(flow)\n        )\n        return assert_kill(False)\n    elif when == \"error\":\n        assert (\n            playbook\n            >> reply()\n            >> ConnectionClosed(server)\n            << CloseConnection(server)\n            << http.HttpErrorHook(flow)\n        )\n        return assert_kill(False)\n    else:\n        raise AssertionError\n\n\ndef test_close_during_connect_hook(tctx):\n    flow = Placeholder(HTTPFlow)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n        >> DataReceived(\n            tctx.client,\n            b\"CONNECT hi.ls:443 HTTP/1.1\\r\\n\"\n            b\"Proxy-Connection: keep-alive\\r\\n\"\n            b\"Connection: keep-alive\\r\\n\"\n            b\"Host: hi.ls:443\\r\\n\\r\\n\",\n        )\n        << http.HttpConnectHook(flow)\n        >> ConnectionClosed(tctx.client)\n        << CloseConnection(tctx.client)\n        >> reply(to=-3)\n    )\n\n\n@pytest.mark.parametrize(\"client_close\", [b\"\", b\"Connection: close\\r\\n\"])\n@pytest.mark.parametrize(\"server_close\", [b\"\", b\"Connection: close\\r\\n\"])\ndef test_connection_close_header(tctx, client_close, server_close):\n    \"\"\"Test that we correctly close connections if we have a `Connection: close` header.\"\"\"\n    if not client_close and not server_close:\n        return\n    server = Placeholder(Server)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example/ HTTP/1.1\\r\\n\"\n            b\"Host: example\\r\\n\" + client_close + b\"\\r\\n\",\n        )\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(\n            server, b\"GET / HTTP/1.1\\r\\n\" b\"Host: example\\r\\n\" + client_close + b\"\\r\\n\"\n        )\n        >> DataReceived(\n            server,\n            b\"HTTP/1.1 200 OK\\r\\n\" b\"Content-Length: 0\\r\\n\" + server_close + b\"\\r\\n\",\n        )\n        << CloseConnection(server)\n        << SendData(\n            tctx.client,\n            b\"HTTP/1.1 200 OK\\r\\n\" b\"Content-Length: 0\\r\\n\" + server_close + b\"\\r\\n\",\n        )\n        << CloseConnection(tctx.client)\n    )\n\n\n@pytest.mark.parametrize(\"proto\", [\"websocket\", \"tcp\", \"none\"])\ndef test_upgrade(tctx, proto):\n    \"\"\"Test a HTTP -> WebSocket upgrade with different protocols enabled\"\"\"\n    if proto != \"websocket\":\n        tctx.options.websocket = False\n    if proto != \"tcp\":\n        tctx.options.rawtcp = False\n\n    tctx.server.address = (\"example.com\", 80)\n    tctx.server.state = ConnectionState.OPEN\n    http_flow = Placeholder(HTTPFlow)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.transparent))\n    (\n        playbook\n        >> DataReceived(\n            tctx.client,\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: upgrade\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Sec-WebSocket-Version: 13\\r\\n\"\n            b\"\\r\\n\",\n        )\n        << http.HttpRequestHeadersHook(http_flow)\n        >> reply()\n        << http.HttpRequestHook(http_flow)\n        >> reply()\n        << SendData(\n            tctx.server,\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: upgrade\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Sec-WebSocket-Version: 13\\r\\n\"\n            b\"\\r\\n\",\n        )\n        >> DataReceived(\n            tctx.server,\n            b\"HTTP/1.1 101 Switching Protocols\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Connection: Upgrade\\r\\n\"\n            b\"\\r\\n\",\n        )\n        << http.HttpResponseHeadersHook(http_flow)\n        >> reply()\n        << http.HttpResponseHook(http_flow)\n        >> reply()\n        << SendData(\n            tctx.client,\n            b\"HTTP/1.1 101 Switching Protocols\\r\\n\"\n            b\"Upgrade: websocket\\r\\n\"\n            b\"Connection: Upgrade\\r\\n\"\n            b\"\\r\\n\",\n        )\n    )\n    if proto == \"websocket\":\n        assert playbook << WebsocketStartHook(http_flow)\n    elif proto == \"tcp\":\n        assert playbook << TcpStartHook(Placeholder(TCPFlow))\n    else:\n        assert (\n            playbook\n            << Log(\n                \"Sent HTTP 101 response, but no protocol is enabled to upgrade to.\",\n                WARNING,\n            )\n            << CloseConnection(tctx.client)\n        )\n\n\ndef test_dont_reuse_closed(tctx):\n    \"\"\"Test that a closed connection is not reused.\"\"\"\n    server = Placeholder(Server)\n    server2 = Placeholder(Server)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        >> ConnectionClosed(server)\n        << CloseConnection(server)\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/two HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << OpenConnection(server2)\n        >> reply(None)\n        << SendData(server2, b\"GET /two HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(server2, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n    )\n\n\ndef test_reuse_error(tctx):\n    \"\"\"Test that an errored connection is reused.\"\"\"\n    tctx.server.address = (\"example.com\", 443)\n    tctx.server.error = \"tls verify failed\"\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.transparent), hooks=False)\n        >> DataReceived(tctx.client, b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        << SendData(tctx.client, BytesMatching(b\"502 Bad Gateway.+tls verify failed\"))\n        << CloseConnection(tctx.client)\n    )\n\n\ndef test_transparent_sni(tctx):\n    \"\"\"Test that we keep the SNI in lazy transparent mode.\"\"\"\n    tctx.client.sni = \"example.com\"\n    tctx.server.address = (\"192.0.2.42\", 443)\n    tctx.server.tls = True\n\n    flow = Placeholder(HTTPFlow)\n\n    server = Placeholder(Server)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.transparent))\n        >> DataReceived(tctx.client, b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n    )\n    assert server().address == (\"192.0.2.42\", 443)\n    assert server().sni == \"example.com\"\n\n\ndef test_reverse_sni(tctx):\n    \"\"\"Test that we use the destination address as SNI in reverse mode.\"\"\"\n    tctx.client.sni = \"localhost\"\n    tctx.server.address = (\"192.0.2.42\", 443)\n    tctx.server.tls = True\n    tctx.server.sni = \"example.local\"\n\n    flow = Placeholder(HTTPFlow)\n\n    server = Placeholder(Server)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.transparent))\n        >> DataReceived(tctx.client, b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n    )\n    assert server().address == (\"192.0.2.42\", 443)\n    assert server().sni == \"example.local\"\n\n\ndef test_original_server_disconnects(tctx):\n    \"\"\"Test that we correctly handle the case where the initial server conn is just closed.\"\"\"\n    tctx.server.state = ConnectionState.OPEN\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.transparent))\n        >> ConnectionClosed(tctx.server)\n        << CloseConnection(tctx.server)\n    )\n\n\ndef test_request_smuggling(tctx):\n    \"\"\"Test that we reject request smuggling\"\"\"\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\n\"\n            b\"Host: example.com\\r\\n\"\n            b\"Content-Length: 42\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\\r\\n\",\n        )\n        << SendData(\n            tctx.client,\n            BytesMatching(\n                b\"Received both a Transfer-Encoding and a Content-Length header\"\n            ),\n        )\n        << CloseConnection(tctx.client)\n    )\n\n\ndef test_request_smuggling_whitespace(tctx):\n    \"\"\"Test that we reject header names with whitespace\"\"\"\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\n\"\n            b\"Host: example.com\\r\\n\"\n            b\"Content-Length : 42\\r\\n\\r\\n\",\n        )\n        << SendData(tctx.client, BytesMatching(b\"Received an invalid header name\"))\n        << CloseConnection(tctx.client)\n    )\n\n\ndef test_request_smuggling_validation_disabled(tctx):\n    \"\"\"Test that we don't reject request smuggling when validation is disabled.\"\"\"\n    tctx.options.validate_inbound_headers = False\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\n\"\n            b\"Host: example.com\\r\\n\"\n            b\"Content-Length: 4\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\\r\\n\"\n            b\"4\\r\\n\"\n            b\"abcd\\r\\n\"\n            b\"0\\r\\n\"\n            b\"\\r\\n\",\n        )\n        << OpenConnection(Placeholder(Server))\n    )\n\n\ndef test_request_smuggling_te_te(tctx):\n    \"\"\"Test that we reject transfer-encoding headers that are weird in some way\"\"\"\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            (\n                \"GET http://example.com/ HTTP/1.1\\r\\n\"\n                \"Host: example.com\\r\\n\"\n                \"Transfer-Encoding: chun\u212aed\\r\\n\\r\\n\"\n            ).encode(),\n        )  # note the non-standard \"\u212a\"\n        << SendData(tctx.client, BytesMatching(b\"Invalid transfer encoding\"))\n        << CloseConnection(tctx.client)\n    )\n\n\ndef test_invalid_content_length(tctx):\n    \"\"\"Test that we still trigger flow hooks for requests with semantic errors\"\"\"\n    flow = Placeholder(HTTPFlow)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n        >> DataReceived(\n            tctx.client,\n            (\n                b\"GET http://example.com/ HTTP/1.1\\r\\n\"\n                b\"Host: example.com\\r\\n\"\n                b\"Content-Length: NaN\\r\\n\\r\\n\"\n            ),\n        )\n        << SendData(tctx.client, BytesMatching(b\"Invalid Content-Length header\"))\n        << CloseConnection(tctx.client)\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << http.HttpErrorHook(flow)\n        >> reply()\n    )\n\n\ndef test_chunked_and_content_length_set_by_addon(tctx):\n    \"\"\"Test that we don't crash when an addon sets a transfer-encoding header\n\n    We reject a request with both transfer-encoding and content-length header to\n    thwart request smuggling, but if a user explicitly sets it we should not crash.\n    \"\"\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n\n    def make_chunked(flow: HTTPFlow):\n        if flow.response:\n            flow.response.headers[\"Transfer-Encoding\"] = \"chunked\"\n        else:\n            flow.request.headers[\"Transfer-Encoding\"] = \"chunked\"\n\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n        >> DataReceived(\n            tctx.client,\n            b\"POST http://example.com/ HTTP/1.1\\r\\n\"\n            b\"Host: example.com\\r\\n\"\n            b\"Content-Length: 0\\r\\n\\r\\n\",\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply(side_effect=make_chunked)\n        << http.HttpRequestHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(\n            server,\n            b\"POST / HTTP/1.1\\r\\n\"\n            b\"Host: example.com\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\\r\\n\"\n            b\"0\\r\\n\\r\\n\",\n        )\n        >> DataReceived(server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")\n        << http.HttpResponseHeadersHook(flow)\n        >> reply()\n        << http.HttpResponseHook(flow)\n        >> reply(side_effect=make_chunked)\n        << SendData(\n            tctx.client,\n            b\"HTTP/1.1 200 OK\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\\r\\n\"\n            b\"0\\r\\n\\r\\n\",\n        )\n    )\n\n\ndef test_connect_more_newlines(tctx):\n    \"\"\"Ignore superfluous \\r\\n in CONNECT request, https://github.com/mitmproxy/mitmproxy/issues/4870\"\"\"\n    server = Placeholder(Server)\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n    nl = Placeholder(layer.NextLayer)\n\n    assert (\n        playbook\n        >> DataReceived(tctx.client, b\"CONNECT example.com:80 HTTP/1.1\\r\\n\\r\\n\\r\\n\")\n        << http.HttpConnectHook(Placeholder())\n        >> reply()\n        << OpenConnection(server)\n        >> reply(None)\n        << http.HttpConnectedHook(Placeholder())\n        >> reply()\n        << SendData(tctx.client, b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n        >> DataReceived(tctx.client, b\"\\x16\\x03\\x03\\x00\\xb3\\x01\\x00\\x00\\xaf\\x03\\x03\")\n        << layer.NextLayerHook(nl)\n    )\n    assert nl().data_client() == b\"\\x16\\x03\\x03\\x00\\xb3\\x01\\x00\\x00\\xaf\\x03\\x03\"\n\n\ndef test_connect_unauthorized(tctx):\n    \"\"\"Continue a connection after proxyauth returns a 407, https://github.com/mitmproxy/mitmproxy/issues/6420\"\"\"\n    playbook = Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n    flow = Placeholder(HTTPFlow)\n\n    def require_auth(f: HTTPFlow):\n        f.response = Response.make(\n            status_code=407, headers={\"Proxy-Authenticate\": f'Basic realm=\"mitmproxy\"'}\n        )\n\n    assert (\n        playbook\n        >> DataReceived(tctx.client, b\"CONNECT example.com:80 HTTP/1.1\\r\\n\\r\\n\")\n        << http.HttpConnectHook(flow)\n        >> reply(side_effect=require_auth)\n        << http.HttpConnectErrorHook(flow)\n        >> reply()\n        << SendData(\n            tctx.client,\n            b\"HTTP/1.1 407 Proxy Authentication Required\\r\\n\"\n            b'Proxy-Authenticate: Basic realm=\"mitmproxy\"\\r\\n'\n            b\"content-length: 0\\r\\n\\r\\n\",\n        )\n        >> DataReceived(\n            tctx.client,\n            b\"CONNECT example.com:80 HTTP/1.1\\r\\n\"\n            b\"Proxy-Authorization: Basic dGVzdDp0ZXN0\\r\\n\\r\\n\",\n        )\n        << http.HttpConnectHook(Placeholder(HTTPFlow))\n        >> reply()\n        << OpenConnection(Placeholder(Server))\n    )\n\n\ndef flows_tracked() -> int:\n    return sum(isinstance(x, HTTPFlow) for x in gc.get_objects())\n\n\ndef test_memory_usage_completed_flows(tctx):\n    \"\"\"Make sure that flows are not kept in memory after they are completed.\"\"\"\n    gc.collect()\n    flow_count = flows_tracked()\n\n    server = Placeholder(Server)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << OpenConnection(server)\n        >> reply(None)\n        << SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        >> DataReceived(server, b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n        << SendData(tctx.client, b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n    )\n\n    gc.collect()\n    assert flows_tracked() == flow_count\n\n\ndef test_memory_usage_errored_flows(tctx):\n    \"\"\"Make sure that flows are not kept in memory after they errored.\"\"\"\n    gc.collect()\n    flow_count = flows_tracked()\n\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular), hooks=False)\n        >> DataReceived(\n            tctx.client,\n            b\"GET http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\",\n        )\n        << OpenConnection(Placeholder(Server))\n        >> reply(\"connection failed\")\n        << SendData(tctx.client, BytesMatching(b\"502 Bad Gateway.+connection failed\"))\n        << CloseConnection(tctx.client)\n    )\n\n    gc.collect()\n    assert flows_tracked() == flow_count\n\n\ndef test_drop_stream_with_paused_events(tctx):\n    \"\"\"Make sure that we don't crash if we still have paused events for streams that error.\"\"\"\n    tctx.options.stream_large_bodies = \"1\"\n    server = Placeholder(Server)\n    flow = Placeholder(HTTPFlow)\n    assert (\n        Playbook(http.HttpLayer(tctx, HTTPMode.regular))\n        >> DataReceived(\n            tctx.client,\n            b\"POST http://example.com/ HTTP/1.1\\r\\nHost: example.com\\r\\nContent-Length: 4\\r\\n\\r\\ndata\",\n        )\n        << http.HttpRequestHeadersHook(flow)\n        >> reply()\n        << OpenConnection(server)\n        >> reply(\"Connection killed: error\")\n        << http.HttpErrorHook(flow)\n        >> reply()\n        << SendData(tctx.client, BytesMatching(b\"502 Bad Gateway.+Connection killed\"))\n        << CloseConnection(tctx.client)\n    )\n", "test/mitmproxy/proxy/layers/http/test_http3.py": "import collections.abc\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\n\nimport pylsqpack\nimport pytest\nfrom aioquic._buffer import Buffer\nfrom aioquic.h3.connection import encode_frame\nfrom aioquic.h3.connection import encode_settings\nfrom aioquic.h3.connection import encode_uint_var\nfrom aioquic.h3.connection import ErrorCode\nfrom aioquic.h3.connection import FrameType\nfrom aioquic.h3.connection import Headers as H3Headers\nfrom aioquic.h3.connection import parse_settings\nfrom aioquic.h3.connection import Setting\nfrom aioquic.h3.connection import StreamType\n\nfrom mitmproxy import connection\nfrom mitmproxy import version\nfrom mitmproxy.flow import Error\nfrom mitmproxy.http import Headers\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.http import Request\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layers\nfrom mitmproxy.proxy.layers import http\nfrom mitmproxy.proxy.layers import quic\nfrom mitmproxy.proxy.layers.http._http3 import Http3Client\nfrom test.mitmproxy.proxy import tutils\n\nexample_request_headers = [\n    (b\":method\", b\"GET\"),\n    (b\":scheme\", b\"http\"),\n    (b\":path\", b\"/\"),\n    (b\":authority\", b\"example.com\"),\n]\n\nexample_response_headers = [(b\":status\", b\"200\")]\n\nexample_request_trailers = [(b\"req-trailer-a\", b\"a\"), (b\"req-trailer-b\", b\"b\")]\n\nexample_response_trailers = [(b\"resp-trailer-a\", b\"a\"), (b\"resp-trailer-b\", b\"b\")]\n\n\ndef decode_frame(frame_type: int, frame_data: bytes) -> bytes:\n    buf = Buffer(data=frame_data)\n    assert buf.pull_uint_var() == frame_type\n    return buf.pull_bytes(buf.pull_uint_var())\n\n\nclass CallbackPlaceholder(tutils._Placeholder[bytes]):\n    \"\"\"Data placeholder that invokes a callback once its bytes get set.\"\"\"\n\n    def __init__(self, cb: Callable[[bytes], None]):\n        super().__init__(bytes)\n        self._cb = cb\n\n    def setdefault(self, value: bytes) -> bytes:\n        if self._obj is None:\n            self._cb(value)\n        return super().setdefault(value)\n\n\nclass DelayedPlaceholder(tutils._Placeholder[bytes]):\n    \"\"\"Data placeholder that resolves its bytes when needed.\"\"\"\n\n    def __init__(self, resolve: Callable[[], bytes]):\n        super().__init__(bytes)\n        self._resolve = resolve\n\n    def __call__(self) -> bytes:\n        if self._obj is None:\n            self._obj = self._resolve()\n        return super().__call__()\n\n\nclass MultiPlaybook(tutils.Playbook):\n    \"\"\"Playbook that allows multiple events and commands to be registered at once.\"\"\"\n\n    def __lshift__(self, c):\n        if isinstance(c, collections.abc.Iterable):\n            for c_i in c:\n                super().__lshift__(c_i)\n        else:\n            super().__lshift__(c)\n        return self\n\n    def __rshift__(self, e):\n        if isinstance(e, collections.abc.Iterable):\n            for e_i in e:\n                super().__rshift__(e_i)\n        else:\n            super().__rshift__(e)\n        return self\n\n\nclass FrameFactory:\n    \"\"\"Helper class for generating QUIC stream events and commands.\"\"\"\n\n    def __init__(self, conn: connection.Connection, is_client: bool) -> None:\n        self.conn = conn\n        self.is_client = is_client\n        self.decoder = pylsqpack.Decoder(\n            max_table_capacity=4096,\n            blocked_streams=16,\n        )\n        self.decoder_placeholders: list[tutils.Placeholder[bytes]] = []\n        self.encoder = pylsqpack.Encoder()\n        self.encoder_placeholder: tutils.Placeholder[bytes] | None = None\n        self.peer_stream_id: dict[StreamType, int] = {}\n        self.local_stream_id: dict[StreamType, int] = {}\n        self.max_push_id: int | None = None\n\n    def get_default_stream_id(self, stream_type: StreamType, for_local: bool) -> int:\n        if stream_type == StreamType.CONTROL:\n            stream_id = 2\n        elif stream_type == StreamType.QPACK_ENCODER:\n            stream_id = 6\n        elif stream_type == StreamType.QPACK_DECODER:\n            stream_id = 10\n        else:\n            raise AssertionError(stream_type)\n        if self.is_client is not for_local:\n            stream_id = stream_id + 1\n        return stream_id\n\n    def send_stream_type(\n        self,\n        stream_type: StreamType,\n        stream_id: int | None = None,\n    ) -> quic.SendQuicStreamData:\n        assert stream_type not in self.peer_stream_id\n        if stream_id is None:\n            stream_id = self.get_default_stream_id(stream_type, for_local=False)\n        self.peer_stream_id[stream_type] = stream_id\n        return quic.SendQuicStreamData(\n            connection=self.conn,\n            stream_id=stream_id,\n            data=encode_uint_var(stream_type),\n            end_stream=False,\n        )\n\n    def receive_stream_type(\n        self,\n        stream_type: StreamType,\n        stream_id: int | None = None,\n    ) -> quic.QuicStreamDataReceived:\n        assert stream_type not in self.local_stream_id\n        if stream_id is None:\n            stream_id = self.get_default_stream_id(stream_type, for_local=True)\n        self.local_stream_id[stream_type] = stream_id\n        return quic.QuicStreamDataReceived(\n            connection=self.conn,\n            stream_id=stream_id,\n            data=encode_uint_var(stream_type),\n            end_stream=False,\n        )\n\n    def send_max_push_id(self) -> quic.SendQuicStreamData:\n        def cb(data: bytes) -> None:\n            buf = Buffer(data=data)\n            assert buf.pull_uint_var() == FrameType.MAX_PUSH_ID\n            buf = Buffer(data=buf.pull_bytes(buf.pull_uint_var()))\n            self.max_push_id = buf.pull_uint_var()\n            assert buf.eof()\n\n        return quic.SendQuicStreamData(\n            connection=self.conn,\n            stream_id=self.peer_stream_id[StreamType.CONTROL],\n            data=CallbackPlaceholder(cb),\n            end_stream=False,\n        )\n\n    def send_settings(self) -> quic.SendQuicStreamData:\n        assert self.encoder_placeholder is None\n        placeholder = tutils.Placeholder(bytes)\n        self.encoder_placeholder = placeholder\n\n        def cb(data: bytes) -> None:\n            buf = Buffer(data=data)\n            assert buf.pull_uint_var() == FrameType.SETTINGS\n            settings = parse_settings(buf.pull_bytes(buf.pull_uint_var()))\n            placeholder.setdefault(\n                self.encoder.apply_settings(\n                    max_table_capacity=settings[Setting.QPACK_MAX_TABLE_CAPACITY],\n                    blocked_streams=settings[Setting.QPACK_BLOCKED_STREAMS],\n                )\n            )\n\n        return quic.SendQuicStreamData(\n            connection=self.conn,\n            stream_id=self.peer_stream_id[StreamType.CONTROL],\n            data=CallbackPlaceholder(cb),\n            end_stream=False,\n        )\n\n    def receive_settings(\n        self,\n        settings: dict[int, int] = {\n            Setting.QPACK_MAX_TABLE_CAPACITY: 4096,\n            Setting.QPACK_BLOCKED_STREAMS: 16,\n            Setting.ENABLE_CONNECT_PROTOCOL: 1,\n            Setting.DUMMY: 1,\n        },\n    ) -> quic.QuicStreamDataReceived:\n        return quic.QuicStreamDataReceived(\n            connection=self.conn,\n            stream_id=self.local_stream_id[StreamType.CONTROL],\n            data=encode_frame(FrameType.SETTINGS, encode_settings(settings)),\n            end_stream=False,\n        )\n\n    def send_encoder(self) -> quic.SendQuicStreamData:\n        def cb(data: bytes) -> bytes:\n            self.decoder.feed_encoder(data)\n            return data\n\n        return quic.SendQuicStreamData(\n            connection=self.conn,\n            stream_id=self.peer_stream_id[StreamType.QPACK_ENCODER],\n            data=CallbackPlaceholder(cb),\n            end_stream=False,\n        )\n\n    def receive_encoder(self) -> quic.QuicStreamDataReceived:\n        assert self.encoder_placeholder is not None\n        placeholder = self.encoder_placeholder\n        self.encoder_placeholder = None\n\n        return quic.QuicStreamDataReceived(\n            connection=self.conn,\n            stream_id=self.local_stream_id[StreamType.QPACK_ENCODER],\n            data=placeholder,\n            end_stream=False,\n        )\n\n    def send_decoder(self) -> quic.SendQuicStreamData:\n        def cb(data: bytes) -> None:\n            self.encoder.feed_decoder(data)\n\n        return quic.SendQuicStreamData(\n            self.conn,\n            stream_id=self.peer_stream_id[StreamType.QPACK_DECODER],\n            data=CallbackPlaceholder(cb),\n            end_stream=False,\n        )\n\n    def receive_decoder(self) -> quic.QuicStreamDataReceived:\n        assert self.decoder_placeholders\n        placeholder = self.decoder_placeholders.pop(0)\n\n        return quic.QuicStreamDataReceived(\n            self.conn,\n            stream_id=self.local_stream_id[StreamType.QPACK_DECODER],\n            data=placeholder,\n            end_stream=False,\n        )\n\n    def send_headers(\n        self,\n        headers: H3Headers,\n        stream_id: int = 0,\n        end_stream: bool = False,\n    ) -> Iterable[quic.SendQuicStreamData]:\n        placeholder = tutils.Placeholder(bytes)\n        self.decoder_placeholders.append(placeholder)\n\n        def decode(data: bytes) -> None:\n            buf = Buffer(data=data)\n            assert buf.pull_uint_var() == FrameType.HEADERS\n            frame_data = buf.pull_bytes(buf.pull_uint_var())\n            decoder, actual_headers = self.decoder.feed_header(stream_id, frame_data)\n            placeholder.setdefault(decoder)\n            assert headers == actual_headers\n\n        yield self.send_encoder()\n        yield quic.SendQuicStreamData(\n            connection=self.conn,\n            stream_id=stream_id,\n            data=CallbackPlaceholder(decode),\n            end_stream=end_stream,\n        )\n\n    def receive_headers(\n        self,\n        headers: H3Headers,\n        stream_id: int = 0,\n        end_stream: bool = False,\n    ) -> Iterable[quic.QuicStreamDataReceived]:\n        data = tutils.Placeholder(bytes)\n\n        def encode() -> bytes:\n            encoder, frame_data = self.encoder.encode(stream_id, headers)\n            data.setdefault(encode_frame(FrameType.HEADERS, frame_data))\n            return encoder\n\n        yield quic.QuicStreamDataReceived(\n            connection=self.conn,\n            stream_id=self.local_stream_id[StreamType.QPACK_ENCODER],\n            data=DelayedPlaceholder(encode),\n            end_stream=False,\n        )\n        yield quic.QuicStreamDataReceived(\n            connection=self.conn,\n            stream_id=stream_id,\n            data=data,\n            end_stream=end_stream,\n        )\n\n    def send_data(\n        self,\n        data: bytes,\n        stream_id: int = 0,\n        end_stream: bool = False,\n    ) -> quic.SendQuicStreamData:\n        return quic.SendQuicStreamData(\n            self.conn,\n            stream_id=stream_id,\n            data=encode_frame(FrameType.DATA, data),\n            end_stream=end_stream,\n        )\n\n    def receive_data(\n        self,\n        data: bytes,\n        stream_id: int = 0,\n        end_stream: bool = False,\n    ) -> quic.QuicStreamDataReceived:\n        return quic.QuicStreamDataReceived(\n            connection=self.conn,\n            stream_id=stream_id,\n            data=encode_frame(FrameType.DATA, data),\n            end_stream=end_stream,\n        )\n\n    def send_reset(self, error_code: int, stream_id: int = 0) -> quic.ResetQuicStream:\n        return quic.ResetQuicStream(\n            connection=self.conn,\n            stream_id=stream_id,\n            error_code=error_code,\n        )\n\n    def receive_reset(\n        self, error_code: int, stream_id: int = 0\n    ) -> quic.QuicStreamReset:\n        return quic.QuicStreamReset(\n            connection=self.conn,\n            stream_id=stream_id,\n            error_code=error_code,\n        )\n\n    def send_init(self) -> Iterable[quic.SendQuicStreamData]:\n        yield self.send_stream_type(StreamType.CONTROL)\n        yield self.send_settings()\n        if not self.is_client:\n            yield self.send_max_push_id()\n        yield self.send_stream_type(StreamType.QPACK_ENCODER)\n        yield self.send_stream_type(StreamType.QPACK_DECODER)\n\n    def receive_init(self) -> Iterable[quic.QuicStreamDataReceived]:\n        yield self.receive_stream_type(StreamType.CONTROL)\n        yield self.receive_stream_type(StreamType.QPACK_ENCODER)\n        yield self.receive_stream_type(StreamType.QPACK_DECODER)\n        yield self.receive_settings()\n\n    @property\n    def is_done(self) -> bool:\n        return self.encoder_placeholder is None and not self.decoder_placeholders\n\n\n@pytest.fixture\ndef open_h3_server_conn():\n    # this is a bit fake here (port 80, with alpn, but no tls - c'mon),\n    # but we don't want to pollute our tests with TLS handshakes.\n    server = connection.Server(address=(\"example.com\", 80), transport_protocol=\"udp\")\n    server.state = connection.ConnectionState.OPEN\n    server.alpn = b\"h3\"\n    return server\n\n\ndef start_h3_client(tctx: context.Context) -> tuple[tutils.Playbook, FrameFactory]:\n    tctx.client.alpn = b\"h3\"\n    tctx.client.transport_protocol = \"udp\"\n    tctx.server.transport_protocol = \"udp\"\n\n    playbook = MultiPlaybook(layers.HttpLayer(tctx, layers.http.HTTPMode.regular))\n    cff = FrameFactory(conn=tctx.client, is_client=True)\n    assert (\n        playbook\n        << cff.send_init()\n        >> cff.receive_init()\n        << cff.send_encoder()\n        >> cff.receive_encoder()\n    )\n    return playbook, cff\n\n\ndef make_h3(open_connection: commands.OpenConnection) -> None:\n    open_connection.connection.alpn = b\"h3\"\n\n\ndef test_ignore_push(tctx: context.Context):\n    playbook, cff = start_h3_client(tctx)\n\n\ndef test_fail_without_header(tctx: context.Context):\n    playbook = MultiPlaybook(layers.http.Http3Server(tctx))\n    cff = FrameFactory(tctx.client, is_client=True)\n    assert (\n        playbook\n        << cff.send_init()\n        >> cff.receive_init()\n        << cff.send_encoder()\n        >> cff.receive_encoder()\n        >> http.ResponseProtocolError(0, \"first message\", http.status_codes.NO_RESPONSE)\n        << cff.send_reset(ErrorCode.H3_INTERNAL_ERROR)\n    )\n    assert cff.is_done\n\n\ndef test_invalid_header(tctx: context.Context):\n    playbook, cff = start_h3_client(tctx)\n    assert (\n        playbook\n        >> cff.receive_headers(\n            [\n                (b\":method\", b\"CONNECT\"),\n                (b\":path\", b\"/\"),\n                (b\":authority\", b\"example.com\"),\n            ],\n            end_stream=True,\n        )\n        << cff.send_decoder()  # for receive_headers\n        << quic.CloseQuicConnection(\n            tctx.client,\n            error_code=ErrorCode.H3_GENERAL_PROTOCOL_ERROR,\n            frame_type=None,\n            reason_phrase=\"Invalid HTTP/3 request headers: Required pseudo header is missing: b':scheme'\",\n        )\n        # ensure that once we close, we don't process messages anymore\n        >> cff.receive_headers(\n            [\n                (b\":method\", b\"CONNECT\"),\n                (b\":path\", b\"/\"),\n                (b\":authority\", b\"example.com\"),\n            ],\n            end_stream=True,\n        )\n    )\n\n\ndef test_simple(tctx: context.Context):\n    playbook, cff = start_h3_client(tctx)\n    flow = tutils.Placeholder(HTTPFlow)\n    server = tutils.Placeholder(connection.Server)\n    sff = FrameFactory(server, is_client=False)\n    assert (\n        playbook\n        # request client\n        >> cff.receive_headers(example_request_headers, end_stream=True)\n        << (request := http.HttpRequestHeadersHook(flow))\n        << cff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=request)\n        << http.HttpRequestHook(flow)\n        >> tutils.reply()\n        # request server\n        << commands.OpenConnection(server)\n        >> tutils.reply(None, side_effect=make_h3)\n        << sff.send_init()\n        << sff.send_headers(example_request_headers, end_stream=True)\n        >> sff.receive_init()\n        << sff.send_encoder()\n        >> sff.receive_encoder()\n        >> sff.receive_decoder()  # for send_headers\n        # response server\n        >> sff.receive_headers(example_response_headers)\n        << (response := http.HttpResponseHeadersHook(flow))\n        << sff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=response)\n        >> sff.receive_data(b\"Hello, World!\", end_stream=True)\n        << http.HttpResponseHook(flow)\n        >> tutils.reply()\n        # response client\n        << cff.send_headers(example_response_headers)\n        << cff.send_data(b\"Hello, World!\")\n        << cff.send_data(b\"\", end_stream=True)\n        >> cff.receive_decoder()  # for send_headers\n    )\n    assert cff.is_done and sff.is_done\n    assert flow().request.url == \"http://example.com/\"\n    assert flow().response.text == \"Hello, World!\"\n\n\n@pytest.mark.parametrize(\"stream\", [\"stream\", \"\"])\ndef test_response_trailers(\n    tctx: context.Context,\n    open_h3_server_conn: connection.Server,\n    stream: str,\n):\n    playbook, cff = start_h3_client(tctx)\n    tctx.server = open_h3_server_conn\n    sff = FrameFactory(tctx.server, is_client=False)\n\n    def enable_streaming(flow: HTTPFlow):\n        flow.response.stream = stream\n\n    flow = tutils.Placeholder(HTTPFlow)\n    (\n        playbook\n        # request client\n        >> cff.receive_headers(example_request_headers, end_stream=True)\n        << (request := http.HttpRequestHeadersHook(flow))\n        << cff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=request)\n        << http.HttpRequestHook(flow)\n        >> tutils.reply()\n        # request server\n        << sff.send_init()\n        << sff.send_headers(example_request_headers, end_stream=True)\n        >> sff.receive_init()\n        << sff.send_encoder()\n        >> sff.receive_encoder()\n        >> sff.receive_decoder()  # for send_headers\n        # response server\n        >> sff.receive_headers(example_response_headers)\n        << (response_headers := http.HttpResponseHeadersHook(flow))\n        << sff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=response_headers, side_effect=enable_streaming)\n    )\n    if stream:\n        (\n            playbook\n            << cff.send_headers(example_response_headers)\n            >> cff.receive_decoder()  # for send_headers\n            >> sff.receive_data(b\"Hello, World!\")\n            << cff.send_data(b\"Hello, World!\")\n        )\n    else:\n        playbook >> sff.receive_data(b\"Hello, World!\")\n    assert (\n        playbook\n        >> sff.receive_headers(example_response_trailers, end_stream=True)\n        << (response := http.HttpResponseHook(flow))\n        << sff.send_decoder()  # for receive_headers\n    )\n    assert flow().response.trailers\n    del flow().response.trailers[\"resp-trailer-a\"]\n    if stream:\n        assert (\n            playbook\n            >> tutils.reply(to=response)\n            << cff.send_headers(example_response_trailers[1:], end_stream=True)\n            >> cff.receive_decoder()  # for send_headers\n        )\n    else:\n        assert (\n            playbook\n            >> tutils.reply(to=response)\n            << cff.send_headers(example_response_headers)\n            << cff.send_data(b\"Hello, World!\")\n            << cff.send_headers(example_response_trailers[1:], end_stream=True)\n            >> cff.receive_decoder()  # for send_headers\n            >> cff.receive_decoder()  # for send_headers\n        )\n    assert cff.is_done and sff.is_done\n\n\n@pytest.mark.parametrize(\"stream\", [\"stream\", \"\"])\ndef test_request_trailers(\n    tctx: context.Context,\n    open_h3_server_conn: connection.Server,\n    stream: str,\n):\n    playbook, cff = start_h3_client(tctx)\n    tctx.server = open_h3_server_conn\n    sff = FrameFactory(tctx.server, is_client=False)\n\n    def enable_streaming(flow: HTTPFlow):\n        flow.request.stream = stream\n\n    flow = tutils.Placeholder(HTTPFlow)\n    (\n        playbook\n        # request client\n        >> cff.receive_headers(example_request_headers)\n        << (request_headers := http.HttpRequestHeadersHook(flow))\n        << cff.send_decoder()  # for receive_headers\n        >> cff.receive_data(b\"Hello World!\")\n        >> tutils.reply(to=request_headers, side_effect=enable_streaming)\n    )\n    if not stream:\n        (\n            playbook\n            >> cff.receive_headers(example_request_trailers, end_stream=True)\n            << (request := http.HttpRequestHook(flow))\n            << cff.send_decoder()  # for receive_headers\n            >> tutils.reply(to=request)\n        )\n    (\n        playbook\n        # request server\n        << sff.send_init()\n        << sff.send_headers(example_request_headers)\n        << sff.send_data(b\"Hello World!\")\n    )\n    if not stream:\n        playbook << sff.send_headers(example_request_trailers, end_stream=True)\n    (\n        playbook\n        >> sff.receive_init()\n        << sff.send_encoder()\n        >> sff.receive_encoder()\n        >> sff.receive_decoder()  # for send_headers\n    )\n    if stream:\n        (\n            playbook\n            >> cff.receive_headers(example_request_trailers, end_stream=True)\n            << (request := http.HttpRequestHook(flow))\n            << cff.send_decoder()  # for receive_headers\n            >> tutils.reply(to=request)\n            << sff.send_headers(example_request_trailers, end_stream=True)\n        )\n    assert playbook >> sff.receive_decoder()  # for send_headers\n\n    assert cff.is_done and sff.is_done\n\n\ndef test_upstream_error(tctx: context.Context):\n    playbook, cff = start_h3_client(tctx)\n    flow = tutils.Placeholder(HTTPFlow)\n    server = tutils.Placeholder(connection.Server)\n    err = tutils.Placeholder(bytes)\n    assert (\n        playbook\n        # request client\n        >> cff.receive_headers(example_request_headers, end_stream=True)\n        << (request := http.HttpRequestHeadersHook(flow))\n        << cff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=request)\n        << http.HttpRequestHook(flow)\n        >> tutils.reply()\n        # request server\n        << commands.OpenConnection(server)\n        >> tutils.reply(\"oops server <> error\")\n        << http.HttpErrorHook(flow)\n        >> tutils.reply()\n        << cff.send_headers(\n            [\n                (b\":status\", b\"502\"),\n                (b\"server\", version.MITMPROXY.encode()),\n                (b\"content-type\", b\"text/html\"),\n            ]\n        )\n        << quic.SendQuicStreamData(\n            tctx.client,\n            stream_id=0,\n            data=err,\n            end_stream=True,\n        )\n        >> cff.receive_decoder()  # for send_headers\n    )\n    assert cff.is_done\n    data = decode_frame(FrameType.DATA, err())\n    assert b\"502 Bad Gateway\" in data\n    assert b\"server &lt;&gt; error\" in data\n\n\n@pytest.mark.parametrize(\"stream\", [\"stream\", \"\"])\n@pytest.mark.parametrize(\"when\", [\"request\", \"response\"])\n@pytest.mark.parametrize(\"how\", [\"RST\", \"disconnect\", \"RST+disconnect\"])\ndef test_http3_client_aborts(tctx: context.Context, stream: str, when: str, how: str):\n    \"\"\"\n    Test handling of the case where a client aborts during request or response transmission.\n\n    If the client aborts the request transmission, we must trigger an error hook,\n    if the client disconnects during response transmission, no error hook is triggered.\n    \"\"\"\n    server = tutils.Placeholder(connection.Server)\n    flow = tutils.Placeholder(HTTPFlow)\n    playbook, cff = start_h3_client(tctx)\n\n    def enable_request_streaming(flow: HTTPFlow):\n        flow.request.stream = True\n\n    def enable_response_streaming(flow: HTTPFlow):\n        flow.response.stream = True\n\n    assert (\n        playbook\n        >> cff.receive_headers(example_request_headers)\n        << (request_headers := http.HttpRequestHeadersHook(flow))\n        << cff.send_decoder()  # for receive_headers\n    )\n    if stream and when == \"request\":\n        assert (\n            playbook\n            >> tutils.reply(side_effect=enable_request_streaming, to=request_headers)\n            << commands.OpenConnection(server)\n            >> tutils.reply(None)\n            << commands.SendData(\n                server, b\"GET / HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\\r\\n\"\n            )\n        )\n    else:\n        assert playbook >> tutils.reply(to=request_headers)\n\n    if when == \"request\":\n        if \"RST\" in how:\n            playbook >> cff.receive_reset(ErrorCode.H3_REQUEST_CANCELLED)\n        else:\n            playbook >> quic.QuicConnectionClosed(\n                tctx.client,\n                error_code=ErrorCode.H3_REQUEST_CANCELLED,\n                frame_type=None,\n                reason_phrase=\"peer closed connection\",\n            )\n\n        if stream:\n            playbook << commands.CloseConnection(server)\n        playbook << http.HttpErrorHook(flow)\n        playbook >> tutils.reply()\n\n        if how == \"RST+disconnect\":\n            playbook >> quic.QuicConnectionClosed(\n                tctx.client,\n                error_code=ErrorCode.H3_NO_ERROR,\n                frame_type=None,\n                reason_phrase=\"peer closed connection\",\n            )\n        assert playbook\n        assert (\n            \"stream reset\" in flow().error.msg\n            or \"peer closed connection\" in flow().error.msg\n        )\n        return\n\n    assert (\n        playbook\n        >> cff.receive_data(b\"\", end_stream=True)\n        << http.HttpRequestHook(flow)\n        >> tutils.reply()\n        << commands.OpenConnection(server)\n        >> tutils.reply(None)\n        << commands.SendData(server, b\"GET / HTTP/1.1\\r\\n\" b\"Host: example.com\\r\\n\\r\\n\")\n        >> events.DataReceived(\n            server, b\"HTTP/1.1 200 OK\\r\\nContent-Length: 6\\r\\n\\r\\n123\"\n        )\n        << http.HttpResponseHeadersHook(flow)\n    )\n    if stream:\n        assert (\n            playbook\n            >> tutils.reply(side_effect=enable_response_streaming)\n            << cff.send_headers(\n                [\n                    (b\":status\", b\"200\"),\n                    (b\"content-length\", b\"6\"),\n                ]\n            )\n            << cff.send_data(b\"123\")\n        )\n    else:\n        assert playbook >> tutils.reply()\n\n    if \"RST\" in how:\n        playbook >> cff.receive_reset(ErrorCode.H3_REQUEST_CANCELLED)\n    else:\n        playbook >> quic.QuicConnectionClosed(\n            tctx.client,\n            error_code=ErrorCode.H3_REQUEST_CANCELLED,\n            frame_type=None,\n            reason_phrase=\"peer closed connection\",\n        )\n\n    playbook << commands.CloseConnection(server)\n    playbook << http.HttpErrorHook(flow)\n    playbook >> tutils.reply()\n    assert playbook\n\n    if how == \"RST+disconnect\":\n        playbook >> quic.QuicConnectionClosed(\n            tctx.client,\n            error_code=ErrorCode.H3_REQUEST_CANCELLED,\n            frame_type=None,\n            reason_phrase=\"peer closed connection\",\n        )\n        assert playbook\n\n    if \"RST\" in how:\n        assert \"stream reset\" in flow().error.msg\n    else:\n        assert \"peer closed connection\" in flow().error.msg\n\n\ndef test_rst_then_close(tctx):\n    \"\"\"\n    Test that we properly handle the case of a client that first causes protocol errors and then disconnects.\n\n    This is slightly different to H2, as QUIC will close the connection immediately.\n    \"\"\"\n    playbook, cff = start_h3_client(tctx)\n    flow = tutils.Placeholder(HTTPFlow)\n    server = tutils.Placeholder(connection.Server)\n    err = tutils.Placeholder(str)\n\n    assert (\n        playbook\n        # request client\n        >> cff.receive_headers(example_request_headers, end_stream=True)\n        << (request := http.HttpRequestHeadersHook(flow))\n        << cff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=request)\n        << http.HttpRequestHook(flow)\n        >> tutils.reply()\n        # request server\n        << (open := commands.OpenConnection(server))\n        >> cff.receive_data(b\"unexpected data frame\")\n        << quic.CloseQuicConnection(\n            tctx.client,\n            error_code=quic.QuicErrorCode.PROTOCOL_VIOLATION,\n            frame_type=None,\n            reason_phrase=err,\n        )\n        >> quic.QuicConnectionClosed(\n            tctx.client,\n            error_code=quic.QuicErrorCode.PROTOCOL_VIOLATION,\n            frame_type=None,\n            reason_phrase=err,\n        )\n        >> tutils.reply(\"connection cancelled\", to=open)\n        << http.HttpErrorHook(flow)\n        >> tutils.reply()\n    )\n    assert flow().error.msg == \"connection cancelled\"\n\n\ndef test_cancel_then_server_disconnect(tctx: context.Context):\n    \"\"\"\n    Test that we properly handle the case of the following event sequence:\n        - client cancels a stream\n        - we start an error hook\n        - server disconnects\n        - error hook completes.\n    \"\"\"\n    playbook, cff = start_h3_client(tctx)\n    flow = tutils.Placeholder(HTTPFlow)\n    server = tutils.Placeholder(connection.Server)\n    assert (\n        playbook\n        # request client\n        >> cff.receive_headers(example_request_headers, end_stream=True)\n        << (request := http.HttpRequestHeadersHook(flow))\n        << cff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=request)\n        << http.HttpRequestHook(flow)\n        >> tutils.reply()\n        # request server\n        << commands.OpenConnection(server)\n        >> tutils.reply(None)\n        << commands.SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        # cancel\n        >> cff.receive_reset(error_code=ErrorCode.H3_REQUEST_CANCELLED)\n        << commands.CloseConnection(server)\n        << http.HttpErrorHook(flow)\n        >> tutils.reply()\n        >> events.ConnectionClosed(server)\n        << None\n    )\n    assert cff.is_done\n\n\ndef test_cancel_during_response_hook(tctx: context.Context):\n    \"\"\"\n    Test that we properly handle the case of the following event sequence:\n        - we receive a server response\n        - we trigger the response hook\n        - the client cancels the stream\n        - the response hook completes\n\n    Given that we have already triggered the response hook, we don't want to trigger the error hook.\n    \"\"\"\n    playbook, cff = start_h3_client(tctx)\n    flow = tutils.Placeholder(HTTPFlow)\n    server = tutils.Placeholder(connection.Server)\n    assert (\n        playbook\n        # request client\n        >> cff.receive_headers(example_request_headers, end_stream=True)\n        << (request := http.HttpRequestHeadersHook(flow))\n        << cff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=request)\n        << http.HttpRequestHook(flow)\n        >> tutils.reply()\n        # request server\n        << commands.OpenConnection(server)\n        >> tutils.reply(None)\n        << commands.SendData(server, b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\")\n        # response server\n        >> events.DataReceived(server, b\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n        << (reponse_headers := http.HttpResponseHeadersHook(flow))\n        << commands.CloseConnection(server)\n        >> tutils.reply(to=reponse_headers)\n        << (response := http.HttpResponseHook(flow))\n        >> cff.receive_reset(error_code=ErrorCode.H3_REQUEST_CANCELLED)\n        >> tutils.reply(to=response)\n        << cff.send_reset(ErrorCode.H3_INTERNAL_ERROR)\n    )\n    assert cff.is_done\n\n\ndef test_stream_concurrency(tctx: context.Context):\n    \"\"\"Test that we can send an intercepted request with a lower stream id than one that has already been sent.\"\"\"\n    playbook, cff = start_h3_client(tctx)\n    flow1 = tutils.Placeholder(HTTPFlow)\n    flow2 = tutils.Placeholder(HTTPFlow)\n    server = tutils.Placeholder(connection.Server)\n    sff = FrameFactory(server, is_client=False)\n    headers1 = [*example_request_headers, (b\"x-order\", b\"1\")]\n    headers2 = [*example_request_headers, (b\"x-order\", b\"2\")]\n    assert (\n        playbook\n        # request client\n        >> cff.receive_headers(headers1, stream_id=0, end_stream=True)\n        << (request_header1 := http.HttpRequestHeadersHook(flow1))\n        << cff.send_decoder()  # for receive_headers\n        >> cff.receive_headers(headers2, stream_id=4, end_stream=True)\n        << (request_header2 := http.HttpRequestHeadersHook(flow2))\n        << cff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=request_header1)\n        << (request1 := http.HttpRequestHook(flow1))\n        >> tutils.reply(to=request_header2)\n        << (request2 := http.HttpRequestHook(flow2))\n        # req 2 overtakes 1 and we already have a reply:\n        >> tutils.reply(to=request2)\n        # request server\n        << commands.OpenConnection(server)\n        >> tutils.reply(None, side_effect=make_h3)\n        << sff.send_init()\n        << sff.send_headers(headers2, stream_id=0, end_stream=True)\n        >> sff.receive_init()\n        << sff.send_encoder()\n        >> sff.receive_encoder()\n        >> sff.receive_decoder()  # for send_headers\n        >> tutils.reply(to=request1)\n        << sff.send_headers(headers1, stream_id=4, end_stream=True)\n        >> sff.receive_decoder()  # for send_headers\n    )\n    assert cff.is_done and sff.is_done\n\n\ndef test_stream_concurrent_get_connection(tctx: context.Context):\n    \"\"\"Test that an immediate second request for the same domain does not trigger a second connection attempt.\"\"\"\n    playbook, cff = start_h3_client(tctx)\n    playbook.hooks = False\n    server = tutils.Placeholder(connection.Server)\n    sff = FrameFactory(server, is_client=False)\n    assert (\n        playbook\n        >> cff.receive_headers(example_request_headers, stream_id=0, end_stream=True)\n        << cff.send_decoder()  # for receive_headers\n        << (o := commands.OpenConnection(server))\n        >> cff.receive_headers(example_request_headers, stream_id=4, end_stream=True)\n        << cff.send_decoder()  # for receive_headers\n        >> tutils.reply(None, to=o, side_effect=make_h3)\n        << sff.send_init()\n        << sff.send_headers(example_request_headers, stream_id=0, end_stream=True)\n        << sff.send_headers(example_request_headers, stream_id=4, end_stream=True)\n        >> sff.receive_init()\n        << sff.send_encoder()\n        >> sff.receive_encoder()\n        >> sff.receive_decoder()  # for send_headers\n        >> sff.receive_decoder()  # for send_headers\n    )\n    assert cff.is_done and sff.is_done\n\n\ndef test_kill_stream(tctx: context.Context):\n    \"\"\"Test that we can kill individual streams.\"\"\"\n    playbook, cff = start_h3_client(tctx)\n    flow1 = tutils.Placeholder(HTTPFlow)\n    flow2 = tutils.Placeholder(HTTPFlow)\n    server = tutils.Placeholder(connection.Server)\n    sff = FrameFactory(server, is_client=False)\n    headers1 = [*example_request_headers, (b\"x-order\", b\"1\")]\n    headers2 = [*example_request_headers, (b\"x-order\", b\"2\")]\n\n    def kill(flow: HTTPFlow):\n        # Can't use flow.kill() here because that currently still depends on a reply object.\n        flow.error = Error(Error.KILLED_MESSAGE)\n\n    assert (\n        playbook\n        # request client\n        >> cff.receive_headers(headers1, stream_id=0, end_stream=True)\n        << (request_header1 := http.HttpRequestHeadersHook(flow1))\n        << cff.send_decoder()  # for receive_headers\n        >> cff.receive_headers(headers2, stream_id=4, end_stream=True)\n        << (request_header2 := http.HttpRequestHeadersHook(flow2))\n        << cff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=request_header2, side_effect=kill)\n        << http.HttpErrorHook(flow2)\n        >> tutils.reply()\n        << cff.send_reset(ErrorCode.H3_INTERNAL_ERROR, stream_id=4)\n        >> tutils.reply(to=request_header1)\n        << http.HttpRequestHook(flow1)\n        >> tutils.reply()\n        # request server\n        << commands.OpenConnection(server)\n        >> tutils.reply(None, side_effect=make_h3)\n        << sff.send_init()\n        << sff.send_headers(headers1, stream_id=0, end_stream=True)\n        >> sff.receive_init()\n        << sff.send_encoder()\n        >> sff.receive_encoder()\n        >> sff.receive_decoder()  # for send_headers\n    )\n    assert cff.is_done and sff.is_done\n\n\nclass TestClient:\n    def test_no_data_on_closed_stream(self, tctx: context.Context):\n        frame_factory = FrameFactory(tctx.server, is_client=False)\n        playbook = MultiPlaybook(Http3Client(tctx))\n        req = Request.make(\"GET\", \"http://example.com/\")\n        resp = [(b\":status\", b\"200\")]\n        assert (\n            playbook\n            << frame_factory.send_init()\n            >> frame_factory.receive_init()\n            << frame_factory.send_encoder()\n            >> frame_factory.receive_encoder()\n            >> http.RequestHeaders(1, req, end_stream=True)\n            << frame_factory.send_headers(\n                [\n                    (b\":method\", b\"GET\"),\n                    (b\":scheme\", b\"http\"),\n                    (b\":path\", b\"/\"),\n                    (b\"content-length\", b\"0\"),\n                ],\n                end_stream=True,\n            )\n            >> frame_factory.receive_decoder()  # for send_headers\n            >> http.RequestEndOfMessage(1)\n            >> frame_factory.receive_headers(resp)\n            << http.ReceiveHttp(tutils.Placeholder(http.ResponseHeaders))\n            << frame_factory.send_decoder()  # for receive_headers\n            >> http.RequestProtocolError(\n                1, \"cancelled\", code=http.status_codes.CLIENT_CLOSED_REQUEST\n            )\n            << frame_factory.send_reset(ErrorCode.H3_REQUEST_CANCELLED)\n            >> frame_factory.receive_data(b\"foo\")\n            << quic.StopQuicStream(tctx.server, 0, ErrorCode.H3_REQUEST_CANCELLED)\n        )  # important: no ResponseData event here!\n\n        assert frame_factory.is_done\n\n    def test_ignore_wrong_order(self, tctx: context.Context):\n        frame_factory = FrameFactory(tctx.server, is_client=False)\n        playbook = MultiPlaybook(Http3Client(tctx))\n        req = Request.make(\"GET\", \"http://example.com/\")\n        assert (\n            playbook\n            << frame_factory.send_init()\n            >> frame_factory.receive_init()\n            << frame_factory.send_encoder()\n            >> frame_factory.receive_encoder()\n            >> http.RequestTrailers(1, Headers([(b\"x-trailer\", b\"\")]))\n            << commands.Log(\n                \"Received RequestTrailers(stream_id=0, trailers=Headers[(b'x-trailer', b'')]) unexpectedly: \"\n                \"trailing HEADERS frame is not allowed in this state\"\n            )\n            >> http.RequestEndOfMessage(1)\n            << commands.Log(\n                \"Received RequestEndOfMessage(stream_id=0) unexpectedly: \"\n                \"DATA frame is not allowed in this state\"\n            )\n            >> http.RequestData(1, b\"123\")\n            << commands.Log(\n                \"Received RequestData(stream_id=0, data=b'123') unexpectedly: \"\n                \"DATA frame is not allowed in this state\"\n            )\n            >> http.RequestHeaders(1, req, end_stream=False)\n            << frame_factory.send_headers(\n                [\n                    (b\":method\", b\"GET\"),\n                    (b\":scheme\", b\"http\"),\n                    (b\":path\", b\"/\"),\n                    (b\"content-length\", b\"0\"),\n                ],\n                end_stream=False,\n            )\n            >> frame_factory.receive_decoder()  # for send_headers\n            >> http.RequestHeaders(1, req, end_stream=False)\n            << commands.Log(\n                \"Received RequestHeaders(stream_id=0, request=Request(GET example.com:80/),\"\n                \" end_stream=False, replay_flow=None) unexpectedly: \"\n                \"initial HEADERS frame is not allowed in this state\"\n            )\n        )\n\n\ndef test_early_server_data(tctx: context.Context):\n    playbook, cff = start_h3_client(tctx)\n    sff = FrameFactory(tctx.server, is_client=False)\n\n    tctx.server.address = (\"example.com\", 80)\n    tctx.server.state = connection.ConnectionState.OPEN\n    tctx.server.alpn = b\"h3\"\n\n    flow = tutils.Placeholder(HTTPFlow)\n    assert (\n        playbook\n        >> cff.receive_headers(example_request_headers, end_stream=True)\n        << (request_header := http.HttpRequestHeadersHook(flow))\n        << cff.send_decoder()  # for receive_headers\n        >> tutils.reply(to=request_header)\n        << (request := http.HttpRequestHook(flow))\n        # Surprise! We get data from the server before the request hook finishes.\n        >> sff.receive_stream_type(StreamType.CONTROL)\n        << sff.send_init()\n        >> sff.receive_stream_type(StreamType.QPACK_ENCODER)\n        >> sff.receive_stream_type(StreamType.QPACK_DECODER)\n        >> sff.receive_settings()\n        << sff.send_encoder()\n        >> sff.receive_encoder()\n        # Request hook finishes...\n        >> tutils.reply(to=request)\n        << sff.send_headers(example_request_headers, end_stream=True)\n    )\n", "docs/build.py": "#!/usr/bin/env python3\nimport shutil\nimport subprocess\nfrom pathlib import Path\n\nhere = Path(__file__).parent\n\nfor script in sorted((here / \"scripts\").glob(\"*.py\")):\n    print(f\"Generating output for {script.name}...\")\n    out = subprocess.check_output([\"python3\", script.absolute()], cwd=here, text=True)\n    if out:\n        (here / \"src\" / \"generated\" / f\"{script.stem}.html\").write_text(\n            out, encoding=\"utf8\"\n        )\n\nif (here / \"public\").exists():\n    shutil.rmtree(here / \"public\")\nsubprocess.run([\"hugo\"], cwd=here / \"src\", check=True)\n", "docs/scripts/filters.py": "#!/usr/bin/env python3\nfrom mitmproxy import flowfilter\n\nprint('<table class=\"table filtertable\"><tbody>')\nfor i in flowfilter.help:\n    print(\"<tr><th>%s</th><td>%s</td></tr>\" % i)\nprint(\"</tbody></table>\")\n", "docs/scripts/options.py": "#!/usr/bin/env python3\nimport asyncio\n\nfrom mitmproxy import options\nfrom mitmproxy import optmanager\nfrom mitmproxy.tools import console\nfrom mitmproxy.tools import dump\nfrom mitmproxy.tools import web\n\nmasters = {\n    \"mitmproxy\": console.master.ConsoleMaster,\n    \"mitmdump\": dump.DumpMaster,\n    \"mitmweb\": web.master.WebMaster,\n}\n\nunified_options = {}\n\n\nasync def dump():\n    for tool_name, master in masters.items():\n        opts = options.Options()\n        _ = master(opts)\n        for key, option in optmanager.dump_dicts(opts).items():\n            if key in unified_options:\n                unified_options[key][\"tools\"].append(tool_name)\n            else:\n                unified_options[key] = option\n                unified_options[key][\"tools\"] = [tool_name]\n\n\nasyncio.run(dump())\n\nprint(\n    \"\"\"\n      <table class=\\\"table optiontable\\\">\n        <thead>\n          <tr>\n            <th>Name</th>\n            <th>Type</th>\n            <th>Description</th>\n        </tr>\n        </thead>\n        <tbody>\n      \"\"\".strip()\n)\nfor key, option in sorted(unified_options.items(), key=lambda t: t[0]):\n    print(\n        f\"\"\"\n          <tr id=\"{key}\">\n          <th>\n            <a class=\"anchor\" href=\"#{key}\">#&nbsp;&nbsp;</a>\n            {key}<br/>\n            {' '.join([\"<span class='badge'>{}</span>\".format(t) for t in option['tools']])}</th>\n          <td>{option['type']}</td>\n          <td>{option['help']}<br/>\n            Default: {option['default']}\n            {\"<br/>Choices: {}\".format(', '.join(option['choices'])) if option['choices'] else \"\"}\n          </td>\n          </tr>\n          \"\"\".strip()\n    )\nprint(\"</tbody></table>\")\n", "docs/scripts/api-render.py": "#!/usr/bin/env python3\nimport os\nimport shutil\nimport textwrap\nfrom pathlib import Path\n\nimport pdoc.render_helpers\n\nhere = Path(__file__).parent\n\nif os.environ.get(\"DOCS_ARCHIVE\", False):\n    edit_url_map = {}\nelse:\n    edit_url_map = {\n        \"mitmproxy\": \"https://github.com/mitmproxy/mitmproxy/blob/main/mitmproxy/\",\n    }\n\npdoc.render.configure(\n    template_directory=here / \"pdoc-template\",\n    edit_url_map=edit_url_map,\n)\n# We can't configure Hugo, but we can configure pdoc.\npdoc.render_helpers.formatter.cssclass = \"chroma pdoc-code\"\n\nmodules = [\n    \"mitmproxy.addonmanager\",\n    \"mitmproxy.certs\",\n    \"mitmproxy.connection\",\n    \"mitmproxy.coretypes.multidict\",\n    \"mitmproxy.dns\",\n    \"mitmproxy.flow\",\n    \"mitmproxy.http\",\n    \"mitmproxy.net.server_spec\",\n    \"mitmproxy.proxy.context\",\n    \"mitmproxy.proxy.mode_specs\",\n    \"mitmproxy.proxy.server_hooks\",\n    \"mitmproxy.tcp\",\n    \"mitmproxy.tls\",\n    \"mitmproxy.udp\",\n    \"mitmproxy.websocket\",\n    here / \"..\" / \"src\" / \"generated\" / \"events.py\",\n]\n\npdoc.pdoc(*modules, output_directory=here / \"..\" / \"src\" / \"generated\" / \"api\")\n\napi_content = here / \"..\" / \"src\" / \"content\" / \"api\"\nif api_content.exists():\n    shutil.rmtree(api_content)\n\napi_content.mkdir()\n\nfor module in modules:\n    if isinstance(module, Path):\n        continue\n    filename = f\"api/{module.replace('.', '/')}.html\"\n    (api_content / f\"{module}.md\").write_bytes(\n        textwrap.dedent(\n            f\"\"\"\n        ---\n        title: \"{module}\"\n        url: \"{filename}\"\n\n        menu:\n            addons:\n                parent: 'Event Hooks & API'\n        ---\n\n        {{{{< readfile file=\"/generated/{filename}\" >}}}}\n        \"\"\"\n        ).encode()\n    )\n\n(here / \"..\" / \"src\" / \"content\" / \"addons-api.md\").touch()\n", "docs/scripts/api-events.py": "#!/usr/bin/env python3\nimport contextlib\nimport inspect\nimport textwrap\nimport typing\nfrom pathlib import Path\n\nfrom mitmproxy import addonmanager\nfrom mitmproxy import hooks\nfrom mitmproxy import log\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy import server_hooks\nfrom mitmproxy.proxy.layers import dns\nfrom mitmproxy.proxy.layers import modes\nfrom mitmproxy.proxy.layers import quic\nfrom mitmproxy.proxy.layers import tcp\nfrom mitmproxy.proxy.layers import tls\nfrom mitmproxy.proxy.layers import udp\nfrom mitmproxy.proxy.layers import websocket\nfrom mitmproxy.proxy.layers.http import _hooks as http\n\nknown = set()\n\n\ndef category(name: str, desc: str, hooks: list[type[hooks.Hook]]) -> None:\n    all_params = [\n        list(inspect.signature(hook.__init__, eval_str=True).parameters.values())[1:]\n        for hook in hooks\n    ]\n\n    # slightly overengineered, but this was fun to write.  \u00af\\_(\u30c4)_/\u00af\n    imports = set()\n    types = set()\n    for params in all_params:\n        for param in params:\n            try:\n                imports.add(inspect.getmodule(param.annotation).__name__)\n                for t in typing.get_args(param.annotation):\n                    imports.add(inspect.getmodule(t).__name__)\n            except AttributeError:\n                raise ValueError(f\"Missing type annotation: {params}\")\n    imports.discard(\"builtins\")\n    if types:\n        print(f\"from typing import {', '.join(sorted(types))}\")\n    print(\"import logging\")\n    for imp in sorted(imports):\n        print(f\"import {imp}\")\n    print()\n\n    print(f\"class {name}Events:\")\n    print(f'    \"\"\"{desc}\"\"\"')\n\n    first = True\n    for hook, params in zip(hooks, all_params):\n        if first:\n            first = False\n        else:\n            print()\n        if hook.name in known:\n            raise RuntimeError(f\"Already documented: {hook}\")\n        known.add(hook.name)\n        doc = inspect.getdoc(hook)\n        print(f\"    @staticmethod\")\n        print(f\"    def {hook.name}({', '.join(str(p) for p in params)}):\")\n        print(textwrap.indent(f'\"\"\"\\n{doc}\\n\"\"\"', \"        \"))\n        if params:\n            print(\n                f'        logging.info(f\"{hook.name}: {\" \".join(\"{\" + p.name + \"=}\" for p in params)}\")'\n            )\n        else:\n            print(f'        logging.info(\"{hook.name}\")')\n    print(\"\")\n\n\noutfile = Path(__file__).parent.parent / \"src\" / \"generated\" / \"events.py\"\n\nwith outfile.open(\"w\") as f, contextlib.redirect_stdout(f):\n    print(\"# This file is autogenerated, do not edit manually.\")\n\n    category(\n        \"Lifecycle\",\n        \"\",\n        [\n            addonmanager.LoadHook,\n            hooks.RunningHook,\n            hooks.ConfigureHook,\n            hooks.DoneHook,\n        ],\n    )\n\n    category(\n        \"Connection\",\n        \"\",\n        [\n            server_hooks.ClientConnectedHook,\n            server_hooks.ClientDisconnectedHook,\n            server_hooks.ServerConnectHook,\n            server_hooks.ServerConnectedHook,\n            server_hooks.ServerDisconnectedHook,\n            server_hooks.ServerConnectErrorHook,\n        ],\n    )\n\n    category(\n        \"HTTP\",\n        \"\",\n        [\n            http.HttpRequestHeadersHook,\n            http.HttpRequestHook,\n            http.HttpResponseHeadersHook,\n            http.HttpResponseHook,\n            http.HttpErrorHook,\n            http.HttpConnectHook,\n            http.HttpConnectUpstreamHook,\n            http.HttpConnectedHook,\n            http.HttpConnectErrorHook,\n        ],\n    )\n\n    category(\n        \"DNS\",\n        \"\",\n        [\n            dns.DnsRequestHook,\n            dns.DnsResponseHook,\n            dns.DnsErrorHook,\n        ],\n    )\n\n    category(\n        \"TCP\",\n        \"\",\n        [\n            tcp.TcpStartHook,\n            tcp.TcpMessageHook,\n            tcp.TcpEndHook,\n            tcp.TcpErrorHook,\n        ],\n    )\n\n    category(\n        \"UDP\",\n        \"\",\n        [\n            udp.UdpStartHook,\n            udp.UdpMessageHook,\n            udp.UdpEndHook,\n            udp.UdpErrorHook,\n        ],\n    )\n\n    category(\n        \"QUIC\",\n        \"\",\n        [\n            quic.QuicStartClientHook,\n            quic.QuicStartServerHook,\n        ],\n    )\n\n    category(\n        \"TLS\",\n        \"\",\n        [\n            tls.TlsClienthelloHook,\n            tls.TlsStartClientHook,\n            tls.TlsStartServerHook,\n            tls.TlsEstablishedClientHook,\n            tls.TlsEstablishedServerHook,\n            tls.TlsFailedClientHook,\n            tls.TlsFailedServerHook,\n        ],\n    )\n\n    category(\n        \"WebSocket\",\n        \"\",\n        [\n            websocket.WebsocketStartHook,\n            websocket.WebsocketMessageHook,\n            websocket.WebsocketEndHook,\n        ],\n    )\n\n    category(\n        \"SOCKSv5\",\n        \"\",\n        [\n            modes.Socks5AuthHook,\n        ],\n    )\n\n    category(\n        \"AdvancedLifecycle\",\n        \"\",\n        [\n            layer.NextLayerHook,\n            hooks.UpdateHook,\n            log.AddLogHook,\n        ],\n    )\n\nnot_documented = set(hooks.all_hooks.keys()) - known\nif not_documented:\n    raise RuntimeError(f\"Not documented: {not_documented}\")\n", "docs/scripts/examples.py": "#!/usr/bin/env python3\nimport re\nfrom pathlib import Path\n\nhere = Path(__file__).absolute().parent\nexample_dir = here / \"..\" / \"src\" / \"examples\" / \"addons\"\nexamples = example_dir.glob(\"*.py\")\n\noverview = []\nlistings = []\n\nfor example in examples:\n    code = example.read_text()\n    slug = str(example.with_suffix(\"\").relative_to(example_dir))\n    slug = re.sub(r\"[^a-zA-Z]\", \"-\", slug)\n    match = re.search(\n        r'''\n        ^\n        (?:[#][^\\n]*\\n)?  # there might be a shebang\n        \"\"\"\n        \\s*\n        (.+?)\n        \\s*\n        (?:\\n\\n|\"\"\")     # stop on empty line or end of comment\n    ''',\n        code,\n        re.VERBOSE,\n    )\n    if match:\n        comment = \" \u2014 \" + match.group(1)\n    else:\n        comment = \"\"\n    overview.append(f\"  * [{example.name}](#{slug}){comment}\\n\")\n    listings.append(\n        f\"\"\"\n<h3 id=\"{slug}\">Example: {example.name}</h3>\n\n```python\n{code.strip()}\n```\n\"\"\"\n    )\n\nprint(\n    f\"\"\"\n# Addon Examples\n\n### Dedicated Example Addons\n\n{\"\".join(overview)}\n\n### Built-In Addons\n\nMuch of mitmproxy\u2019s own functionality is defined in\n[a suite of built-in addons](https://github.com/mitmproxy/mitmproxy/tree/main/mitmproxy/addons),\nimplementing everything from functionality like anticaching and sticky cookies to our onboarding webapp.\nThe built-in addons make for instructive reading, and you will quickly see that quite complex functionality\ncan often boil down to a very small, completely self-contained modules.\n\n\n### Additional Community Examples\n\nAdditional examples contributed by the mitmproxy community can be found\n[on GitHub](https://github.com/mitmproxy/mitmproxy/tree/main/examples/contrib).\n\n-------------------------\n\n{\"\".join(listings)}\n\"\"\"\n)\n", "docs/scripts/clirecording/screenplays.py": "#!/usr/bin/env python3\nfrom clidirector import CliDirector\n\n\ndef record_user_interface(d: CliDirector):\n    tmux = d.start_session(width=120, height=36)\n    window = tmux.attached_window\n\n    d.start_recording(\"recordings/mitmproxy_user_interface.cast\")\n    d.message(\n        \"Welcome to the mitmproxy tutorial. In this lesson we cover the user interface.\"\n    )\n    d.pause(1)\n    d.exec(\"mitmproxy\")\n    d.pause(3)\n\n    d.message(\"This is the default view of mitmproxy.\")\n    d.message(\"mitmproxy adds rows to the view as new requests come in.\")\n    d.message(\"Let\u2019s generate some requests using `curl` in a separate terminal.\")\n\n    pane_top = d.current_pane\n    pane_bottom = window.split_window(attach=True)\n    pane_bottom.resize_pane(height=12)\n\n    d.focus_pane(pane_bottom)\n    d.pause(2)\n\n    d.type(\"curl\")\n    d.message(\"Use curl\u2019s `--proxy` option to configure mitmproxy as a proxy.\")\n    d.type(\" --proxy http://127.0.0.1:8080\")\n\n    d.message(\"We use the text-based weather service `wttr.in`.\")\n    d.exec(' \"http://wttr.in/Dunedin?0\"')\n\n    d.pause(2)\n    d.press_key(\"Up\")\n    d.press_key(\"Left\", count=3)\n    d.press_key(\"BSpace\", count=7)\n    d.exec(\"Innsbruck\")\n\n    d.pause(2)\n    d.exec(\"exit\", target=pane_bottom)\n\n    d.focus_pane(pane_top)\n\n    d.message(\"You see the requests to `wttr.in` in the list of flows.\")\n\n    d.message(\"mitmproxy is controlled using keyboard shortcuts.\")\n    d.message(\"Use your arrow keys `\u2191` and `\u2193` to change the focused flow (`>>`).\")\n    d.press_key(\"Down\", pause=0.5)\n    d.press_key(\"Up\", pause=0.5)\n    d.press_key(\"Down\", pause=0.5)\n    d.press_key(\"Up\", pause=0.5)\n\n    d.message(\"The focused flow (`>>`) is used as a target for various commands.\")\n\n    d.message(\"One such command shows the flow details, it is bound to `ENTER`.\")\n\n    d.message(\"Press `ENTER` to view the details of the focused flow.\")\n    d.press_key(\"Enter\")\n\n    d.message(\"The flow details view has 3 panes: request, response, and detail.\")\n    d.message(\"Use your arrow keys `\u2190` and `\u2192` to switch between panes.\")\n    d.press_key(\"Right\", count=2, pause=2.5)\n    d.press_key(\"Left\", count=2, pause=1)\n\n    d.message(\n        \"Press `q` to exit the current view.\",\n    )\n    d.type(\"q\")\n\n    d.message(\"Press `?` to get a list of all available keyboard shortcuts.\")\n    d.type(\"?\")\n    d.pause(2)\n    d.press_key(\"Down\", count=20, pause=0.25)\n\n    d.message(\"Tip: Remember the `?` shortcut. It works in every view.\")\n    d.message(\"Press `q` to exit the current view.\")\n    d.type(\"q\")\n\n    d.message(\"Each shortcut is internally bound to a command.\")\n    d.message(\"You can also execute commands directly (without using shortcuts).\")\n    d.message(\"Press `:` to open the command prompt at the bottom.\")\n    d.type(\":\")\n\n    d.message(\"Enter `console.view.flow @focus`.\")\n    d.type(\"console.view.flow @focus\")\n\n    d.message(\"The command `console.view.flow` opens the details view for a flow.\")\n\n    d.message(\"The argument `@focus` defines the target flow.\")\n\n    d.message(\"Press `ENTER` to execute the command.\")\n    d.press_key(\"Enter\")\n\n    d.message(\n        \"Commands unleash the full power of mitmproxy, i.e., to configure interceptions.\"\n    )\n\n    d.message(\"You now know basics of mitmproxy\u2019s UI and how to control it.\")\n    d.pause(1)\n\n    d.message(\"In the next lesson you will learn to intercept flows.\")\n    d.save_instructions(\"recordings/mitmproxy_user_interface_instructions.json\")\n    d.end()\n\n\ndef record_intercept_requests(d: CliDirector):\n    tmux = d.start_session(width=120, height=36)\n    window = tmux.attached_window\n\n    d.start_recording(\"recordings/mitmproxy_intercept_requests.cast\")\n    d.message(\n        \"Welcome to the mitmproxy tutorial. In this lesson we cover the interception of requests.\"\n    )\n    d.pause(1)\n    d.exec(\"mitmproxy\")\n    d.pause(3)\n\n    d.message(\"We first need to configure mitmproxy to intercept requests.\")\n\n    d.message(\n        \"Press `i` to prepopulate mitmproxy\u2019s command prompt with `set intercept ''`.\"\n    )\n    d.type(\"i\")\n    d.pause(2)\n\n    d.message(\n        \"We use the flow filter expression `~u <regex>` to only intercept specific URLs.\"\n    )\n    d.message(\n        \"Additionally, we use the filter `~q` to only intercept requests, but not responses.\"\n    )\n    d.message(\"We combine both flow filters using `&`.\")\n\n    d.message(\n        \"Enter `~u /Dunedin & ~q` between the quotes of the `set intercept` command and press `ENTER`.\"\n    )\n    d.exec(\"~u /Dunedin & ~q\")\n    d.message(\"The bottom bar shows that the interception has been configured.\")\n\n    d.message(\"Let\u2019s generate a request using `curl` in a separate terminal.\")\n\n    pane_top = d.current_pane\n    pane_bottom = window.split_window(attach=True)\n    pane_bottom.resize_pane(height=12)\n\n    d.focus_pane(pane_bottom)\n    d.pause(2)\n\n    d.exec('curl --proxy http://127.0.0.1:8080 \"http://wttr.in/Dunedin?0\"')\n    d.pause(2)\n\n    d.focus_pane(pane_top)\n\n    d.message(\"You see a new line in in the list of flows.\")\n    d.message(\n        \"The new flow is displayed in red to indicate that it has been intercepted.\"\n    )\n    d.message(\n        \"Put the focus (`>>`) on the intercepted flow. This is already the case in our example.\"\n    )\n    d.message(\"Press `a` to resume this flow without making any changes.\")\n    d.type(\"a\")\n    d.pause(2)\n\n    d.focus_pane(pane_bottom)\n\n    d.message(\"Submit another request and focus its flow.\")\n    d.press_key(\"Up\")\n    d.press_key(\"Enter\")\n    d.pause(2)\n\n    d.focus_pane(pane_top)\n    d.press_key(\"Down\")\n    d.pause(1)\n\n    d.message(\n        \"Press `X` to kill this flow, i.e., discard it without forwarding it to its final destination `wttr.in`.\"\n    )\n    d.type(\"X\")\n    d.pause(3)\n\n    d.message(\"In the next lesson you will learn to modify intercepted flows.\")\n    d.save_instructions(\"recordings/mitmproxy_intercept_requests_instructions.json\")\n    d.end()\n\n\ndef record_modify_requests(d: CliDirector):\n    tmux = d.start_session(width=120, height=36)\n    window = tmux.attached_window\n\n    d.start_recording(\"recordings/mitmproxy_modify_requests.cast\")\n    d.message(\n        \"Welcome to the mitmproxy tutorial. In this lesson we cover the modification of intercepted requests.\"\n    )\n    d.pause(1)\n    d.exec(\"mitmproxy\")\n    d.pause(3)\n\n    d.message(\n        \"We configure and use the same interception rule as in the last tutorial.\"\n    )\n    d.message(\n        \"Press `i` to prepopulate mitmproxy\u2019s command prompt, enter the flow filter `~u /Dunedin & ~q`, and press `ENTER`.\"\n    )\n    d.type(\"i\")\n    d.pause(2)\n    d.exec(\"~u /Dunedin & ~q\")\n\n    d.message(\"Let\u2019s generate a request using `curl` in a separate terminal.\")\n\n    pane_top = d.current_pane\n    pane_bottom = window.split_window(attach=True)\n    pane_bottom.resize_pane(height=12)\n\n    d.focus_pane(pane_bottom)\n    d.pause(2)\n\n    d.exec('curl --proxy http://127.0.0.1:8080 \"http://wttr.in/Dunedin?0\"')\n    d.pause(2)\n\n    d.focus_pane(pane_top)\n\n    d.message(\"We now want to modify the intercepted request.\")\n    d.message(\n        \"Put the focus (`>>`) on the intercepted flow. This is already the case in our example.\"\n    )\n\n    d.message(\"Press `ENTER` to open the details view for the intercepted flow.\")\n    d.press_key(\"Enter\")\n\n    d.message(\"Press `e` to edit the intercepted flow.\")\n    d.type(\"e\")\n\n    d.message(\"mitmproxy asks which part to modify.\")\n\n    d.message(\"Select `path` by using your arrow keys and press `ENTER`.\")\n    d.press_key(\"Down\", count=3, pause=0.5)\n    d.pause(1)\n    d.press_key(\"Enter\")\n\n    d.message(\n        \"mitmproxy shows all path components line by line, in our example its just `Dunedin`.\"\n    )\n    d.message(\"Press `ENTER` to modify the selected path component.\")\n    d.press_key(\"Down\", pause=2)\n    d.press_key(\"Enter\")\n\n    d.message(\"Replace `Dunedin` with `Innsbruck`.\")\n    d.press_key(\"BSpace\", count=7, pause=0.5)\n    d.type(\"Innsbruck\", pause=0.5)\n\n    d.message(\"Press `ESC` to confirm your change.\")\n    d.press_key(\"Escape\")\n\n    d.message(\"Press `q` to go back to the flow details view.\")\n    d.type(\"q\")\n\n    d.message(\"Press `a` to resume the intercepted flow.\")\n    d.type(\"a\")\n    d.pause(2)\n\n    d.message(\n        \"You see that the request URL was modified and `wttr.in` replied with the weather report for `Innsbruck`.\"\n    )\n\n    d.message(\"In the next lesson you will learn to replay flows.\")\n    d.save_instructions(\"recordings/mitmproxy_modify_requests_instructions.json\")\n    d.end()\n\n\ndef record_replay_requests(d: CliDirector):\n    tmux = d.start_session(width=120, height=36)\n    window = tmux.attached_window\n\n    d.start_recording(\"recordings/mitmproxy_replay_requests.cast\")\n    d.message(\n        \"Welcome to the mitmproxy tutorial. In this lesson we cover replaying requests.\"\n    )\n    d.pause(1)\n    d.exec(\"mitmproxy\")\n    d.pause(3)\n\n    d.message(\n        \"Let\u2019s generate a request that we can replay. We use `curl` in a separate terminal.\"\n    )\n\n    pane_top = d.current_pane\n    pane_bottom = window.split_window(attach=True)\n    pane_bottom.resize_pane(height=12)\n\n    d.focus_pane(pane_bottom)\n    d.pause(2)\n\n    d.exec('curl --proxy http://127.0.0.1:8080 \"http://wttr.in/Dunedin?0\"')\n    d.pause(2)\n\n    d.focus_pane(pane_top)\n\n    d.message(\"We now want to replay the this request.\")\n    d.message(\n        \"Put the focus (`>>`) on the request that should be replayed. This is already the case in our example.\"\n    )\n    d.message(\"Press `r` to replay the request.\")\n    d.type(\"r\")\n\n    d.message(\n        \"Note that no new rows are added for replayed flows, but the existing row is updated.\"\n    )\n    d.message(\n        \"Every time you press `r`, mitmproxy sends this request to the server again and updates the flow.\"\n    )\n    d.press_key(\"r\", count=4, pause=1)\n\n    d.message(\"You can also modify a flow before replaying it.\")\n    d.message(\"It works as shown in the previous lesson, by pressing `e`.\")\n\n    d.message(\n        \"Congratulations! You have completed all lessons of the mitmproxy tutorial.\"\n    )\n    d.save_instructions(\"recordings/mitmproxy_replay_requests_instructions.json\")\n    d.end()\n", "docs/scripts/clirecording/clidirector.py": "import json\nimport random\nimport subprocess\nimport threading\nimport time\nfrom typing import NamedTuple\n\nimport libtmux\n\n\nclass InstructionSpec(NamedTuple):\n    instruction: str\n    time_from: float\n    time_to: float\n\n\nclass CliDirector:\n    def __init__(self):\n        self.record_start = None\n        self.pause_between_keys = 0.2\n        self.instructions: list[InstructionSpec] = []\n\n    def start(self, filename: str, width: int = 0, height: int = 0) -> libtmux.Session:\n        self.start_session(width, height)\n        self.start_recording(filename)\n        return self.tmux_session\n\n    def start_session(self, width: int = 0, height: int = 0) -> libtmux.Session:\n        self.tmux_server = libtmux.Server()\n        self.tmux_session = self.tmux_server.new_session(\n            session_name=\"asciinema_recorder\", kill_session=True\n        )\n        self.tmux_pane = self.tmux_session.attached_window.attached_pane\n        self.tmux_version = self.tmux_pane.display_message(\"#{version}\", True)\n        if width and height:\n            self.resize_window(width, height)\n        self.pause(3)\n        return self.tmux_session\n\n    def start_recording(self, filename: str) -> None:\n        self.asciinema_proc = subprocess.Popen(\n            [\n                \"asciinema\",\n                \"rec\",\n                \"-y\",\n                \"--overwrite\",\n                \"-c\",\n                \"tmux attach -t asciinema_recorder\",\n                filename,\n            ]\n        )\n        self.pause(1.5)\n        self.record_start = time.time()\n\n    def resize_window(self, width: int, height: int) -> None:\n        subprocess.Popen(\n            [\"resize\", \"-s\", str(height), str(width)],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n        )\n\n    def end(self) -> None:\n        self.end_recording()\n        self.end_session()\n\n    def end_recording(self) -> None:\n        self.asciinema_proc.terminate()\n        self.asciinema_proc.wait(timeout=5)\n        self.record_start = None\n        self.instructions = []\n\n    def end_session(self) -> None:\n        self.tmux_session.kill_session()\n\n    def press_key(\n        self, keys: str, count=1, pause: float | None = None, target=None\n    ) -> None:\n        if pause is None:\n            pause = self.pause_between_keys\n        if target is None:\n            target = self.tmux_pane\n        for i in range(count):\n            if keys == \" \":\n                keys = \"Space\"\n            target.send_keys(cmd=keys, enter=False, suppress_history=False)\n\n            # inspired by https://github.com/dmotz/TuringType\n            real_pause = random.uniform(0, pause) + 0.4 * pause\n            if keys == \"Space\":\n                real_pause += 1.5 * pause\n            elif keys == \".\":\n                real_pause += pause\n            elif random.random() > 0.75:\n                real_pause += pause\n            elif random.random() > 0.95:\n                real_pause += 2 * pause\n            self.pause(real_pause)\n\n    def type(self, keys: str, pause: float | None = None, target=None) -> None:\n        if pause is None:\n            pause = self.pause_between_keys\n        if target is None:\n            target = self.tmux_pane\n        target.select_pane()\n        for key in keys:\n            self.press_key(key, pause=pause, target=target)\n\n    def exec(self, keys: str, target=None) -> None:\n        if target is None:\n            target = self.tmux_pane\n        self.type(keys, target=target)\n        self.pause(1.25)\n        self.press_key(\"Enter\", target=target)\n        self.pause(0.5)\n\n    def focus_pane(self, pane: libtmux.Pane, set_active_pane: bool = True) -> None:\n        pane.select_pane()\n        if set_active_pane:\n            self.tmux_pane = pane\n\n    def pause(self, seconds: float) -> None:\n        time.sleep(seconds)\n\n    def run_external(self, command: str) -> None:\n        subprocess.run(command, shell=True)\n\n    def message(\n        self,\n        msg: str,\n        duration: int | None = None,\n        add_instruction: bool = True,\n        instruction_html: str = \"\",\n    ) -> None:\n        if duration is None:\n            duration = len(msg) * 0.08  # seconds\n        self.tmux_session.set_option(\n            \"display-time\", int(duration * 1000)\n        )  # milliseconds\n        self.tmux_pane.display_message(\" \" + msg)\n\n        if add_instruction or instruction_html:\n            if not instruction_html:\n                instruction_html = msg\n            self.instruction(instruction=instruction_html, duration=duration)\n        self.pause(duration + 0.5)\n\n    def popup(self, content: str, duration: int = 4) -> None:\n        # todo: check if installed tmux version supports display-popup\n\n        # tmux's display-popup is blocking, so we close it in a separate thread\n        t = threading.Thread(target=self.close_popup, args=[duration])\n        t.start()\n\n        lines = content.splitlines()\n        self.tmux_pane.cmd(\"display-popup\", \"\", *lines)\n        t.join()\n\n    def close_popup(self, duration: float = 0) -> None:\n        self.pause(duration)\n        self.tmux_pane.cmd(\"display-popup\", \"-C\")\n\n    def instruction(\n        self, instruction: str, duration: float = 3, time_from: float | None = None\n    ) -> None:\n        if time_from is None:\n            time_from = self.current_time\n\n        self.instructions.append(\n            InstructionSpec(\n                instruction=str(len(self.instructions) + 1) + \". \" + instruction,\n                time_from=round(time_from, 1),\n                time_to=round(time_from + duration, 1),\n            )\n        )\n\n    def save_instructions(self, output_path: str) -> None:\n        instr_as_dicts = []\n        for instr in self.instructions:\n            instr_as_dicts.append(instr._asdict())\n        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(instr_as_dicts, f, ensure_ascii=False, indent=4)\n\n    @property\n    def current_time(self) -> float:\n        now = time.time()\n        return round(now - self.record_start, 1)\n\n    @property\n    def current_pane(self) -> libtmux.Pane:\n        return self.tmux_pane\n", "docs/scripts/clirecording/record.py": "#!/usr/bin/env python3\nimport screenplays\nfrom clidirector import CliDirector\n\nif __name__ == \"__main__\":\n    director = CliDirector()\n    screenplays.record_user_interface(director)\n    screenplays.record_intercept_requests(director)\n    screenplays.record_modify_requests(director)\n    screenplays.record_replay_requests(director)\n", "release/release.py": "#!/usr/bin/env -S python3 -u\nimport datetime\nimport http.client\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\nimport time\nfrom pathlib import Path\n\n# Security: No third-party dependencies here!\n\nroot = Path(__file__).absolute().parent.parent\n\n\ndef get(url: str) -> http.client.HTTPResponse:\n    assert url.startswith(\"https://\")\n    host, path = re.split(r\"(?=/)\", url.removeprefix(\"https://\"), maxsplit=1)\n    conn = http.client.HTTPSConnection(host)\n    conn.request(\"GET\", path, headers={\"User-Agent\": \"mitmproxy/release-bot\"})\n    resp = conn.getresponse()\n    print(f\"HTTP {resp.status} {resp.reason}\")\n    return resp\n\n\ndef get_json(url: str) -> dict:\n    resp = get(url)\n    body = resp.read()\n    try:\n        return json.loads(body)\n    except Exception as e:\n        raise RuntimeError(f\"{resp.status=} {body=}\") from e\n\n\nif __name__ == \"__main__\":\n    version = sys.argv[1]\n    assert re.match(r\"^\\d+\\.\\d+\\.\\d+$\", version)\n    major_version = int(version.split(\".\")[0])\n\n    skip_branch_status_check = sys.argv[2] == \"true\"\n\n    # changing this is useful for testing on a fork.\n    repo = os.environ.get(\"GITHUB_REPOSITORY\", \"mitmproxy/mitmproxy\")\n    print(f\"{version=} {skip_branch_status_check=} {repo=}\")\n\n    branch = subprocess.run(\n        [\"git\", \"branch\", \"--show-current\"],\n        cwd=root,\n        check=True,\n        capture_output=True,\n        text=True,\n    ).stdout.strip()\n\n    print(\"\u27a1\ufe0f Working dir clean?\")\n    assert not subprocess.run([\"git\", \"status\", \"--porcelain\"]).stdout\n\n    if skip_branch_status_check:\n        print(f\"\u26a0\ufe0f Skipping status check for {branch}.\")\n    else:\n        print(f\"\u27a1\ufe0f CI is passing for {branch}?\")\n        assert (\n            get_json(f\"https://api.github.com/repos/{repo}/commits/{branch}/status\")[\n                \"state\"\n            ]\n            == \"success\"\n        )\n\n    print(\"\u27a1\ufe0f Updating CHANGELOG.md...\")\n    changelog = root / \"CHANGELOG.md\"\n    date = datetime.date.today().strftime(\"%d %B %Y\")\n    title = f\"## {date}: mitmproxy {version}\"\n    cl = changelog.read_text(\"utf8\")\n    assert title not in cl\n    cl, ok = re.subn(r\"(?<=## Unreleased: mitmproxy next)\", f\"\\n\\n\\n{title}\", cl)\n    assert ok == 1\n    changelog.write_text(cl, \"utf8\")\n\n    print(\"\u27a1\ufe0f Updating web assets...\")\n    subprocess.run([\"npm\", \"ci\"], cwd=root / \"web\", check=True, capture_output=True)\n    subprocess.run(\n        [\"npm\", \"start\", \"prod\"], cwd=root / \"web\", check=True, capture_output=True\n    )\n\n    print(\"\u27a1\ufe0f Updating version...\")\n    version_py = root / \"mitmproxy\" / \"version.py\"\n    ver = version_py.read_text(\"utf8\")\n    ver, ok = re.subn(r'(?<=VERSION = \")[^\"]+', version, ver)\n    assert ok == 1\n    version_py.write_text(ver, \"utf8\")\n\n    print(\"\u27a1\ufe0f Do release commit...\")\n    subprocess.run(\n        [\"git\", \"config\", \"user.email\", \"noreply@mitmproxy.org\"], cwd=root, check=True\n    )\n    subprocess.run(\n        [\"git\", \"config\", \"user.name\", \"mitmproxy release bot\"], cwd=root, check=True\n    )\n    subprocess.run(\n        [\"git\", \"commit\", \"-a\", \"-m\", f\"mitmproxy {version}\"], cwd=root, check=True\n    )\n    tag_name = f\"v{version}\"\n    subprocess.run([\"git\", \"tag\", tag_name], cwd=root, check=True)\n    release_sha = subprocess.run(\n        [\"git\", \"rev-parse\", \"HEAD\"],\n        cwd=root,\n        check=True,\n        capture_output=True,\n        text=True,\n    ).stdout.strip()\n\n    if branch == \"main\":\n        print(\"\u27a1\ufe0f Bump version...\")\n        next_dev_version = f\"{major_version + 1}.0.0.dev\"\n        ver, ok = re.subn(r'(?<=VERSION = \")[^\"]+', next_dev_version, ver)\n        assert ok == 1\n        version_py.write_text(ver, \"utf8\")\n\n        print(\"\u27a1\ufe0f Reopen main for development...\")\n        subprocess.run(\n            [\"git\", \"commit\", \"-a\", \"-m\", f\"reopen main for development\"],\n            cwd=root,\n            check=True,\n        )\n\n    print(\"\u27a1\ufe0f Pushing...\")\n    subprocess.run(\n        [\"git\", \"push\", \"--atomic\", \"origin\", branch, tag_name], cwd=root, check=True\n    )\n\n    print(\"\u27a1\ufe0f Creating release on GitHub...\")\n    subprocess.run(\n        [\n            \"gh\",\n            \"release\",\n            \"create\",\n            tag_name,\n            \"--title\",\n            f\"mitmproxy {version}\",\n            \"--notes-file\",\n            \"release/github-release-notes.txt\",\n        ],\n        cwd=root,\n        check=True,\n    )\n\n    print(\"\u27a1\ufe0f Dispatching release workflow...\")\n    subprocess.run(\n        [\"gh\", \"workflow\", \"run\", \"main.yml\", \"--ref\", tag_name], cwd=root, check=True\n    )\n\n    print(\"\")\n    print(\"\u2705 CI is running now.\")\n\n    while True:\n        print(\"\u231b Waiting for CI...\")\n        workflows = get_json(\n            f\"https://api.github.com/repos/{repo}/actions/runs?head_sha={release_sha}\"\n        )[\"workflow_runs\"]\n\n        all_done = True\n        if not workflows:\n            all_done = False  # we expect to have at least one workflow.\n        for workflow in workflows:\n            if workflow[\"status\"] != \"completed\":\n                all_done = False\n            if workflow[\"status\"] == \"waiting\":\n                print(f\"\u26a0\ufe0f CI is waiting for approval: {workflow['html_url']}\")\n\n        if all_done:\n            for workflow in workflows:\n                if workflow[\"conclusion\"] != \"success\":\n                    print(f\"\u26a0\ufe0f {workflow['display_title']} workflow run failed.\")\n            break\n        else:\n            time.sleep(30)  # relatively strict rate limits here.\n\n    print(\"\u27a1\ufe0f Checking GitHub Releases...\")\n    resp = get(f\"https://api.github.com/repos/{repo}/releases/tags/{version}\")\n    assert resp.status == 200\n\n    print(\"\u27a1\ufe0f Checking PyPI...\")\n    pypi_data = get_json(\"https://pypi.org/pypi/mitmproxy/json\")\n    assert version in pypi_data[\"releases\"]\n\n    print(\"\u27a1\ufe0f Checking docs archive...\")\n    resp = get(f\"https://docs.mitmproxy.org/archive/v{major_version}/\")\n    assert resp.status == 200\n\n    print(f\"\u27a1\ufe0f Checking Docker ({version} tag)...\")\n    resp = get(\n        f\"https://hub.docker.com/v2/repositories/mitmproxy/mitmproxy/tags/{version}\"\n    )\n    assert resp.status == 200\n\n    if branch == \"main\":\n        print(\"\u27a1\ufe0f Checking Docker (latest tag)...\")\n        docker_latest_data = get_json(\n            \"https://hub.docker.com/v2/repositories/mitmproxy/mitmproxy/tags/latest\"\n        )\n        docker_last_updated = datetime.datetime.fromisoformat(\n            docker_latest_data[\"last_updated\"].replace(\"Z\", \"+00:00\")\n        )\n        print(f\"Last update: {docker_last_updated.isoformat(timespec='minutes')}\")\n        assert docker_last_updated > datetime.datetime.now(\n            datetime.timezone.utc\n        ) - datetime.timedelta(hours=2)\n\n    print(\"\")\n    print(\"\u2705 All done. \ud83e\udd73\")\n    print(\"\")\n", "release/deploy-microsoft-store.py": "#!/usr/bin/env python3\n\"\"\"\nThis script submits a single MSIX installer to the Microsoft Store.\n\nThe client_secret will expire after 24 months and needs to be recreated (see docstring below).\n\nReferences:\n    - https://docs.microsoft.com/en-us/windows/uwp/monetize/manage-app-submissions\n    - https://docs.microsoft.com/en-us/windows/uwp/monetize/python-code-examples-for-the-windows-store-submission-api\n    - https://docs.microsoft.com/en-us/windows/uwp/monetize/python-code-examples-for-submissions-game-options-and-trailers\n\"\"\"\n\nimport http.client\nimport json\nimport os\nimport sys\nimport tempfile\nimport urllib.parse\nfrom zipfile import ZipFile\n\n# Security: No third-party dependencies here!\n\nassert (\n    os.environ[\"GITHUB_REF\"].startswith(\"refs/tags/\")\n    or os.environ[\"GITHUB_REF\"] == \"refs/heads/citest\"\n)\n\napp_id = os.environ[\"MSFT_APP_ID\"]\n\"\"\"\nThe public application ID / product ID of the app.\nFor https://www.microsoft.com/store/productId/9NWNDLQMNZD7, the app id is 9NWNDLQMNZD7.\n\"\"\"\napp_flight = os.environ.get(\"MSFT_APP_FLIGHT\", \"\")\n\"\"\"\nThe application flight we want to target. This is useful to deploy ci test builds to a subset of users.\n\"\"\"\ntenant_id = os.environ[\"MSFT_TENANT_ID\"]\n\"\"\"\nThe tenant ID for the Azure AD application.\nhttps://partner.microsoft.com/en-us/dashboard/account/v3/usermanagement\n\"\"\"\nclient_id = os.environ[\"MSFT_CLIENT_ID\"]\n\"\"\"\nThe client ID for the Azure AD application.\nhttps://partner.microsoft.com/en-us/dashboard/account/v3/usermanagement\n\"\"\"\nclient_secret = os.environ[\"MSFT_CLIENT_SECRET\"]\n\"\"\"\nThe client secret. Expires every 24 months and needs to be recreated at\nhttps://partner.microsoft.com/en-us/dashboard/account/v3/usermanagement\nor at https://portal.azure.com/ -> App registrations -> Certificates & Secrets -> Client secrets.\n\"\"\"\n\n\ntry:\n    _, msi_file = sys.argv\nexcept ValueError:\n    print(f\"Usage: {sys.argv[0]} installer.msix\")\n    sys.exit(1)\n\nif app_flight:\n    app_id = f\"{app_id}/flights/{app_flight}\"\n    pending_submission = \"pendingFlightSubmission\"\n    packages = \"flightPackages\"\nelse:\n    pending_submission = \"pendingApplicationSubmission\"\n    packages = \"applicationPackages\"\n\nprint(\"Obtaining auth token...\")\nauth = http.client.HTTPSConnection(\"login.microsoftonline.com\")\nauth.request(\n    \"POST\",\n    f\"/{tenant_id}/oauth2/token\",\n    body=urllib.parse.urlencode(\n        {\n            \"grant_type\": \"client_credentials\",\n            \"client_id\": client_id,\n            \"client_secret\": client_secret,\n            \"resource\": \"https://manage.devcenter.microsoft.com\",\n        }\n    ),\n    headers={\"Content-Type\": \"application/x-www-form-urlencoded; charset=utf-8\"},\n)\ntoken = json.loads(auth.getresponse().read())[\"access_token\"]\nauth.close()\nheaders = {\n    \"Authorization\": f\"Bearer {token}\",\n    \"Content-type\": \"application/json\",\n    \"User-Agent\": \"Python/mitmproxy\",\n}\n\n\ndef request(method: str, path: str, body: str = \"\") -> bytes:\n    print(f\"{method} {path}\")\n    conn.request(method, path, body, headers=headers)\n    resp = conn.getresponse()\n    data = resp.read()\n    print(f\"{resp.status} {resp.reason}\")\n    # noinspection PyUnreachableCode\n    if False:\n        assert \"CI\" not in os.environ\n        # This contains sensitive data such as the fileUploadUrl, so don't print it in production.\n        print(data.decode(errors=\"ignore\"))\n    assert 200 <= resp.status < 300\n    return data\n\n\nprint(\"Getting app info...\")\nconn = http.client.HTTPSConnection(\"manage.devcenter.microsoft.com\")\n# print(request(\"GET\", f\"/v1.0/my/applications/{app_id}/listflights\"))\napp_info = json.loads(request(\"GET\", f\"/v1.0/my/applications/{app_id}\"))\n\nif pending_submission in app_info:\n    print(\"Deleting pending submission...\")\n    request(\n        \"DELETE\",\n        f\"/v1.0/my/applications/{app_id}/submissions/{app_info[pending_submission]['id']}\",\n    )\n\nprint(\"Creating new submission...\")\nsubmission = json.loads(request(\"POST\", f\"/v1.0/my/applications/{app_id}/submissions\"))\n\nprint(\"Updating submission...\")\n# Mark all existing packages for deletion.\nfor package in submission[packages]:\n    package[\"fileStatus\"] = \"PendingDelete\"\nsubmission[packages].append(\n    {\n        \"fileName\": f\"installer.msix\",\n        \"fileStatus\": \"PendingUpload\",\n        \"minimumDirectXVersion\": \"None\",\n        \"minimumSystemRam\": \"None\",\n    }\n)\nrequest(\n    \"PUT\",\n    f\"/v1.0/my/applications/{app_id}/submissions/{submission['id']}\",\n    json.dumps(submission),\n)\nconn.close()\n\nprint(f\"Zipping {msi_file}...\")\nwith tempfile.TemporaryFile() as zipfile:\n    with ZipFile(zipfile, \"w\") as f:\n        f.write(msi_file, f\"installer.msix\")\n    zip_size = zipfile.tell()\n    zipfile.seek(0)\n\n    print(\"Uploading zip file...\")\n    host, _, path = submission[\"fileUploadUrl\"].removeprefix(\"https://\").partition(\"/\")\n    upload = http.client.HTTPSConnection(host)\n    upload.request(\n        \"PUT\",\n        \"/\" + path,\n        zipfile,\n        {\n            \"x-ms-blob-type\": \"BlockBlob\",\n            \"x-ms-version\": \"2019-12-12\",\n            \"Content-Length\": str(zip_size),\n        },\n    )\nresp = upload.getresponse()\nresp.read()\nprint(resp.status, resp.reason)\nassert 200 <= resp.status < 300\nupload.close()\n\nprint(\"Publishing submission...\")\n# previous connection has timed out during upload.\nconn = http.client.HTTPSConnection(\"manage.devcenter.microsoft.com\")\nrequest(\"POST\", f\"/v1.0/my/applications/{app_id}/submissions/{submission['id']}/commit\")\n# We could wait until it's published here, but CI is billed by the minute.\n# resp = request(\"GET\", f\"/v1.0/my/applications/{app_id}/submissions/{submission['id']}/status\")\nconn.close()\n", "release/deploy.py": "#!/usr/bin/env python3\nimport os\nimport subprocess\nfrom pathlib import Path\n\n# Security: No third-party dependencies here!\n\nroot = Path(__file__).absolute().parent.parent\n\nif __name__ == \"__main__\":\n    ref = os.environ[\"GITHUB_REF\"]\n    branch: str | None = None\n    tag: str | None = None\n    if ref.startswith(\"refs/heads/\"):\n        branch = ref.replace(\"refs/heads/\", \"\")\n    elif ref.startswith(\"refs/tags/\"):\n        if not ref.startswith(\"refs/tags/v\"):\n            raise AssertionError(f\"Unexpected tag: {ref}\")\n        tag = ref.replace(\"refs/tags/v\", \"\")\n    else:\n        raise AssertionError\n\n    # Upload binaries (be it release or snapshot)\n    if tag:\n        upload_dir = tag\n    else:\n        upload_dir = f\"branches/{branch}\"\n    # Ideally we could have R2 pull from S3 automatically, but that's not possible yet. So we upload to both.\n    print(f\"Uploading binaries to snapshots.mitmproxy.org/{upload_dir}...\")\n    subprocess.check_call(\n        [\n            \"aws\",\n            \"s3\",\n            \"sync\",\n            \"--delete\",\n            *(\"--acl\", \"public-read\"),\n            *(\"--exclude\", \"*.msix\"),\n            root / \"release/dist\",\n            f\"s3://snapshots.mitmproxy.org/{upload_dir}\",\n        ]\n    )\n    if tag:\n        # We can't scope R2 tokens, so they are only exposed in the deploy env.\n        print(f\"Uploading binaries to downloads.mitmproxy.org/{upload_dir}...\")\n        subprocess.check_call(\n            [\n                \"aws\",\n                \"s3\",\n                \"sync\",\n                \"--delete\",\n                *(\"--acl\", \"public-read\"),\n                *(\"--exclude\", \"*.msix\"),\n                *(\n                    \"--endpoint-url\",\n                    f\"https://{os.environ['R2_ACCOUNT_ID']}.r2.cloudflarestorage.com\",\n                ),\n                root / \"release/dist\",\n                f\"s3://downloads/{upload_dir}\",\n            ],\n            env={\n                **os.environ,\n                \"AWS_REGION\": \"auto\",\n                \"AWS_ACCESS_KEY_ID\": os.environ[\"R2_ACCESS_KEY_ID\"],\n                \"AWS_SECRET_ACCESS_KEY\": os.environ[\"R2_SECRET_ACCESS_KEY\"],\n            },\n        )\n\n    # Upload releases to PyPI\n    if tag:\n        print(f\"Uploading wheel to PyPI...\")\n        (whl,) = root.glob(\"release/dist/mitmproxy-*-py3-none-any.whl\")\n        subprocess.check_call([\"twine\", \"upload\", whl])\n\n    # Upload docs\n    def upload_docs(path: str, src: Path = root / \"docs/public\"):\n        subprocess.check_call([\"aws\", \"configure\", \"set\", \"preview.cloudfront\", \"true\"])\n        subprocess.check_call(\n            [\n                \"aws\",\n                \"s3\",\n                \"sync\",\n                \"--delete\",\n                \"--acl\",\n                \"public-read\",\n                src,\n                f\"s3://docs.mitmproxy.org{path}\",\n            ]\n        )\n        subprocess.check_call(\n            [\n                \"aws\",\n                \"cloudfront\",\n                \"create-invalidation\",\n                \"--distribution-id\",\n                \"E1TH3USJHFQZ5Q\",\n                \"--paths\",\n                f\"{path}/*\",\n            ]\n        )\n\n    if branch == \"main\":\n        print(f\"Uploading dev docs...\")\n        upload_docs(\"/dev\")\n    if tag:\n        print(f\"Uploading release docs...\")\n        upload_docs(\"/stable\")\n        upload_docs(f\"/archive/v{tag.split('.')[0]}\", src=root / \"docs/archive\")\n", "release/selftest.py": "\"\"\"\nThis addons is used for binaries to perform a minimal selftest. Use like so:\n\n  mitmdump -s selftest.py -p 0\n\"\"\"\n\nimport asyncio\nimport logging\nimport ssl\nimport sys\nfrom pathlib import Path\n\nfrom mitmproxy import ctx\n\n\ndef load(_):\n    # force a random port\n    ctx.options.listen_port = 0\n    try:\n        ctx.options.web_open_browser = False\n    except KeyError:\n        pass\n\n\ndef running():\n    # attach is somewhere so that it's not collected.\n    ctx.task = asyncio.create_task(make_request())  # type: ignore\n\n\nasync def make_request():\n    try:\n        cafile = Path(ctx.options.confdir).expanduser() / \"mitmproxy-ca.pem\"\n        while not cafile.exists():\n            await asyncio.sleep(0.01)\n        ssl_ctx = ssl.create_default_context(cafile=cafile)\n        port = ctx.master.addons.get(\"proxyserver\").listen_addrs()[0][1]\n        reader, writer = await asyncio.open_connection(\"127.0.0.1\", port, ssl=ssl_ctx)\n        writer.write(b\"GET / HTTP/1.1\\r\\nHost: mitm.it\\r\\nConnection: close\\r\\n\\r\\n\")\n        await writer.drain()\n        resp = await reader.read()\n        if b\"This page is served by your local mitmproxy instance\" not in resp:\n            raise RuntimeError(resp)\n        logging.info(\"Self-test successful.\")\n        ctx.master.shutdown()\n    except Exception as e:\n        print(f\"{e!r}\")\n        sys.exit(1)\n", "release/build.py": "#!/usr/bin/env python3\nfrom __future__ import annotations\n\nimport hashlib\nimport os\nimport platform\nimport re\nimport shutil\nimport subprocess\nimport tarfile\nimport urllib.request\nimport warnings\nimport zipfile\nfrom datetime import datetime\nfrom pathlib import Path\n\nimport click\nimport cryptography.fernet\n\nhere = Path(__file__).absolute().parent\n\nTEMP_DIR = here / \"build\"\nDIST_DIR = here / \"dist\"\n\n\n@click.group(chain=True)\n@click.option(\"--dirty\", is_flag=True)\ndef cli(dirty):\n    if dirty:\n        print(\"Keeping temporary files.\")\n    else:\n        print(\"Cleaning up temporary files...\")\n        if TEMP_DIR.exists():\n            shutil.rmtree(TEMP_DIR)\n        if DIST_DIR.exists():\n            shutil.rmtree(DIST_DIR)\n\n        TEMP_DIR.mkdir()\n        DIST_DIR.mkdir()\n\n\n@cli.command()\ndef wheel():\n    \"\"\"Build the wheel for PyPI.\"\"\"\n    print(\"Building wheel...\")\n    subprocess.check_call(\n        [\n            \"python\",\n            \"-m\",\n            \"build\",\n            \"--outdir\",\n            DIST_DIR,\n        ]\n    )\n    if os.environ.get(\"GITHUB_REF\", \"\").startswith(\"refs/tags/\"):\n        ver = version()  # assert for tags that the version matches the tag.\n    else:\n        ver = \"*\"\n    (whl,) = DIST_DIR.glob(f\"mitmproxy-{ver}-py3-none-any.whl\")\n    print(f\"Found wheel package: {whl}\")\n    subprocess.check_call([\"tox\", \"-e\", \"wheeltest\", \"--\", whl])\n\n\nclass ZipFile2(zipfile.ZipFile):\n    # ZipFile and tarfile have slightly different APIs. Let's fix that.\n    def add(self, name: str, arcname: str) -> None:\n        return self.write(name, arcname)\n\n    def __enter__(self) -> ZipFile2:\n        return self\n\n    @property\n    def name(self) -> str:\n        assert self.filename\n        return self.filename\n\n\ndef archive(path: Path) -> tarfile.TarFile | ZipFile2:\n    if platform.system() == \"Windows\":\n        return ZipFile2(path.with_name(f\"{path.name}.zip\"), \"w\")\n    else:\n        return tarfile.open(path.with_name(f\"{path.name}.tar.gz\"), \"w:gz\")\n\n\ndef version() -> str:\n    if ref := os.environ.get(\"GITHUB_REF\", \"\"):\n        if ref.startswith(\"refs/tags/\") and not ref.startswith(\"refs/tags/v\"):\n            raise AssertionError(f\"Unexpected tag: {ref}\")\n        return (\n            ref.removeprefix(\"refs/heads/\")\n            .removeprefix(\"refs/pull/\")\n            .removeprefix(\"refs/tags/v\")\n            .replace(\"/\", \"-\")\n        )\n    else:\n        return os.environ.get(\"BUILD_VERSION\", \"dev\")\n\n\ndef operating_system() -> str:\n    match platform.system():\n        case \"Windows\":\n            system = \"windows\"\n        case \"Linux\":\n            system = \"linux\"\n        case \"Darwin\":\n            system = \"macos\"\n        case other:\n            warnings.warn(\"Unexpected system.\")\n            system = other\n    match platform.machine():\n        case \"AMD64\" | \"x86_64\":\n            machine = \"x86_64\"\n        case \"arm64\":\n            machine = \"arm64\"\n        case other:\n            warnings.warn(\"Unexpected platform.\")\n            machine = other\n    return f\"{system}-{machine}\"\n\n\ndef _pyinstaller(specfile: str) -> None:\n    print(f\"Invoking PyInstaller with {specfile}...\")\n    subprocess.check_call(\n        [\n            \"pyinstaller\",\n            \"--clean\",\n            \"--workpath\",\n            TEMP_DIR / \"pyinstaller/temp\",\n            \"--distpath\",\n            TEMP_DIR / \"pyinstaller/out\",\n            specfile,\n        ],\n        cwd=here / \"specs\",\n    )\n\n\n@cli.command()\ndef standalone_binaries():\n    \"\"\"Windows and Linux: Build the standalone binaries generated with PyInstaller\"\"\"\n    with archive(DIST_DIR / f\"mitmproxy-{version()}-{operating_system()}\") as f:\n        _pyinstaller(\"standalone.spec\")\n\n        _test_binaries(TEMP_DIR / \"pyinstaller/out\")\n\n        for tool in [\"mitmproxy\", \"mitmdump\", \"mitmweb\"]:\n            executable = TEMP_DIR / \"pyinstaller/out\" / tool\n            if platform.system() == \"Windows\":\n                executable = executable.with_suffix(\".exe\")\n\n            f.add(str(executable), str(executable.name))\n    print(f\"Packed {f.name!r}.\")\n\n\n@cli.command()\n@click.option(\"--keychain\")\n@click.option(\"--team-id\")\n@click.option(\"--apple-id\")\n@click.option(\"--password\")\ndef macos_app(\n    keychain: str | None,\n    team_id: str | None,\n    apple_id: str | None,\n    password: str | None,\n) -> None:\n    \"\"\"\n    macOS: Build into mitmproxy.app.\n\n    If you do not specify options, notarization is skipped.\n    \"\"\"\n\n    _pyinstaller(\"onedir.spec\")\n    _test_binaries(TEMP_DIR / \"pyinstaller/out/mitmproxy.app/Contents/MacOS\")\n\n    if keychain:\n        assert isinstance(team_id, str)\n        assert isinstance(apple_id, str)\n        assert isinstance(password, str)\n        # Notarize the app bundle.\n        subprocess.check_call(\n            [\n                \"xcrun\",\n                \"notarytool\",\n                \"store-credentials\",\n                \"AC_PASSWORD\",\n                *([\"--keychain\", keychain]),\n                *([\"--team-id\", team_id]),\n                *([\"--apple-id\", apple_id]),\n                *([\"--password\", password]),\n            ]\n        )\n        subprocess.check_call(\n            [\n                \"ditto\",\n                \"-c\",\n                \"-k\",\n                \"--keepParent\",\n                TEMP_DIR / \"pyinstaller/out/mitmproxy.app\",\n                TEMP_DIR / \"notarize.zip\",\n            ]\n        )\n        subprocess.check_call(\n            [\n                \"xcrun\",\n                \"notarytool\",\n                \"submit\",\n                TEMP_DIR / \"notarize.zip\",\n                *([\"--keychain\", keychain]),\n                *([\"--keychain-profile\", \"AC_PASSWORD\"]),\n                \"--wait\",\n            ]\n        )\n        # 2023: it's not possible to staple to unix executables.\n        # subprocess.check_call([\n        #     \"xcrun\",\n        #     \"stapler\",\n        #     \"staple\",\n        #     TEMP_DIR / \"pyinstaller/out/mitmproxy.app\",\n        # ])\n    else:\n        warnings.warn(\"Notarization skipped.\")\n\n    with archive(DIST_DIR / f\"mitmproxy-{version()}-{operating_system()}\") as f:\n        f.add(str(TEMP_DIR / \"pyinstaller/out/mitmproxy.app\"), \"mitmproxy.app\")\n    print(f\"Packed {f.name!r}.\")\n\n\ndef _ensure_pyinstaller_onedir():\n    if not (TEMP_DIR / \"pyinstaller/out/onedir\").exists():\n        _pyinstaller(\"onedir.spec\")\n        _test_binaries(TEMP_DIR / \"pyinstaller/out/onedir\")\n\n\ndef _test_binaries(binary_directory: Path) -> None:\n    for tool in [\"mitmproxy\", \"mitmdump\", \"mitmweb\"]:\n        executable = binary_directory / tool\n        if platform.system() == \"Windows\":\n            executable = executable.with_suffix(\".exe\")\n\n        print(f\"> {tool} --version\")\n        subprocess.check_call([executable, \"--version\"])\n\n        if tool == \"mitmproxy\":\n            continue  # requires a TTY, which we don't have here.\n\n        print(f\"> {tool} -s selftest.py\")\n        subprocess.check_call([executable, \"-s\", here / \"selftest.py\"])\n\n\n@cli.command()\ndef msix_installer():\n    \"\"\"Windows: Build the MSIX installer for the Windows Store.\"\"\"\n    _ensure_pyinstaller_onedir()\n\n    shutil.copytree(\n        TEMP_DIR / \"pyinstaller/out/onedir\",\n        TEMP_DIR / \"msix\",\n        dirs_exist_ok=True,\n    )\n    shutil.copytree(here / \"windows-installer\", TEMP_DIR / \"msix\", dirs_exist_ok=True)\n\n    manifest = TEMP_DIR / \"msix/AppxManifest.xml\"\n    app_version = version()\n    if not re.match(r\"\\d+\\.\\d+\\.\\d+\", app_version):\n        app_version = (\n            datetime.now()\n            .strftime(\"%y%m.%d.%H%M\")\n            .replace(\".0\", \".\")\n            .replace(\".0\", \".\")\n            .replace(\".0\", \".\")\n        )\n    manifest.write_text(manifest.read_text().replace(\"1.2.3\", app_version))\n\n    makeappx_exe = (\n        Path(os.environ[\"ProgramFiles(x86)\"])\n        / \"Windows Kits/10/App Certification Kit/makeappx.exe\"\n    )\n    subprocess.check_call(\n        [\n            makeappx_exe,\n            \"pack\",\n            \"/d\",\n            TEMP_DIR / \"msix\",\n            \"/p\",\n            DIST_DIR / f\"mitmproxy-{version()}-installer.msix\",\n        ],\n    )\n    assert (DIST_DIR / f\"mitmproxy-{version()}-installer.msix\").exists()\n\n\n@cli.command()\ndef installbuilder_installer():\n    \"\"\"Windows: Build the InstallBuilder installer.\"\"\"\n    _ensure_pyinstaller_onedir()\n\n    IB_VERSION = \"23.4.0\"\n    IB_SETUP_SHA256 = \"e4ff212ed962f9e0030d918b8a6e4d6dd8a9adc8bf8bc1833459351ee649eff3\"\n    IB_DIR = here / \"installbuilder\"\n    IB_SETUP = IB_DIR / \"setup\" / f\"{IB_VERSION}-installer.exe\"\n    IB_CLI = Path(\n        rf\"C:\\Program Files\\InstallBuilder Enterprise {IB_VERSION}\\bin\\builder-cli.exe\"\n    )\n    IB_LICENSE = IB_DIR / \"license.xml\"\n\n    if not IB_LICENSE.exists():\n        print(\"Decrypt InstallBuilder license...\")\n        f = cryptography.fernet.Fernet(os.environ[\"CI_BUILD_KEY\"].encode())\n        with (\n            open(IB_LICENSE.with_suffix(\".xml.enc\"), \"rb\") as infile,\n            open(IB_LICENSE, \"wb\") as outfile,\n        ):\n            outfile.write(f.decrypt(infile.read()))\n\n    if not IB_CLI.exists():\n        if not IB_SETUP.exists():\n            url = (\n                f\"https://github.com/mitmproxy/installbuilder-mirror/releases/download/\"\n                f\"{IB_VERSION}/installbuilder-enterprise-{IB_VERSION}-windows-x64-installer.exe\"\n            )\n            print(f\"Downloading InstallBuilder from {url}...\")\n\n            def report(block, blocksize, total):\n                done = block * blocksize\n                if round(100 * done / total) != round(100 * (done - blocksize) / total):\n                    print(f\"Downloading... {round(100 * done / total)}%\")\n\n            tmp = IB_SETUP.with_suffix(\".tmp\")\n            urllib.request.urlretrieve(\n                url,\n                tmp,\n                reporthook=report,\n            )\n            tmp.rename(IB_SETUP)\n\n        ib_setup_hash = hashlib.sha256()\n        with IB_SETUP.open(\"rb\") as fp:\n            while True:\n                data = fp.read(65_536)\n                if not data:\n                    break\n                ib_setup_hash.update(data)\n        if ib_setup_hash.hexdigest() != IB_SETUP_SHA256:  # pragma: no cover\n            raise RuntimeError(\n                f\"InstallBuilder hashes don't match: {ib_setup_hash.hexdigest()}\"\n            )\n\n        print(\"Install InstallBuilder...\")\n        subprocess.run(\n            [IB_SETUP, \"--mode\", \"unattended\", \"--unattendedmodeui\", \"none\"], check=True\n        )\n        assert IB_CLI.is_file()\n\n    print(\"Run InstallBuilder...\")\n    subprocess.check_call(\n        [\n            IB_CLI,\n            \"build\",\n            str(IB_DIR / \"mitmproxy.xml\"),\n            \"windows-x64\",\n            \"--license\",\n            str(IB_LICENSE),\n            \"--setvars\",\n            f\"project.version={version()}\",\n            \"--verbose\",\n        ],\n        cwd=IB_DIR,\n    )\n    installer = DIST_DIR / f\"mitmproxy-{version()}-windows-x64-installer.exe\"\n    assert installer.exists()\n\n    # unify filenames\n    installer = installer.rename(\n        installer.with_name(installer.name.replace(\"x64\", \"x86_64\"))\n    )\n\n    print(\"Run installer...\")\n    subprocess.run(\n        [installer, \"--mode\", \"unattended\", \"--unattendedmodeui\", \"none\"], check=True\n    )\n    _test_binaries(Path(r\"C:\\Program Files\\mitmproxy\\bin\"))\n\n\nif __name__ == \"__main__\":\n    cli()\n", "release/build-and-deploy-docker.py": "#!/usr/bin/env python3\n\"\"\"\nBuilding and deploying docker images is a bit of a special snowflake as we don't get a file we can upload/download\nas an artifact. So we need to do everything in one job.\n\"\"\"\n\nimport os\nimport shutil\nimport subprocess\nfrom pathlib import Path\n\n# Security: No third-party dependencies here!\n\nroot = Path(__file__).absolute().parent.parent\n\nref = os.environ[\"GITHUB_REF\"]\nbranch: str | None = None\ntag: str | None = None\nif ref.startswith(\"refs/heads/\"):\n    branch = ref.replace(\"refs/heads/\", \"\")\nelif ref.startswith(\"refs/tags/\"):\n    if not ref.startswith(\"refs/tags/v\"):\n        raise AssertionError(f\"Unexpected tag: {ref}\")\n    tag = ref.replace(\"refs/tags/v\", \"\")\nelse:\n    raise AssertionError(\"Failed to parse $GITHUB_REF\")\n\n(whl,) = root.glob(\"release/dist/mitmproxy-*-py3-none-any.whl\")\ndocker_build_dir = root / \"release/docker\"\nshutil.copy(whl, docker_build_dir / whl.name)\n\n# Build for this platform and test if it runs.\nsubprocess.check_call(\n    [\n        \"docker\",\n        \"buildx\",\n        \"build\",\n        \"--tag\",\n        \"localtesting\",\n        \"--load\",\n        \"--build-arg\",\n        f\"MITMPROXY_WHEEL={whl.name}\",\n        \".\",\n    ],\n    cwd=docker_build_dir,\n)\nr = subprocess.run(\n    [\n        \"docker\",\n        \"run\",\n        \"--rm\",\n        \"-v\",\n        f\"{root / 'release'}:/release\",\n        \"localtesting\",\n        \"mitmdump\",\n        \"-s\",\n        \"/release/selftest.py\",\n    ],\n    capture_output=True,\n)\nprint(r.stdout.decode())\nassert \"Self-test successful\" in r.stdout.decode()\nassert r.returncode == 0\n\n# Now we can deploy.\nsubprocess.check_call(\n    [\n        \"docker\",\n        \"login\",\n        \"-u\",\n        os.environ[\"DOCKER_USERNAME\"],\n        \"-p\",\n        os.environ[\"DOCKER_PASSWORD\"],\n    ]\n)\n\n\ndef _buildx(docker_tag):\n    subprocess.check_call(\n        [\n            \"docker\",\n            \"buildx\",\n            \"build\",\n            \"--tag\",\n            docker_tag,\n            \"--push\",\n            \"--platform\",\n            \"linux/amd64,linux/arm64\",\n            \"--build-arg\",\n            f\"MITMPROXY_WHEEL={whl.name}\",\n            \".\",\n        ],\n        cwd=docker_build_dir,\n    )\n\n\nif branch == \"main\":\n    _buildx(\"mitmproxy/mitmproxy:dev\")\nelif branch == \"citest\":\n    _buildx(\"mitmproxy/mitmproxy:citest\")\nelif tag:\n    _buildx(f\"mitmproxy/mitmproxy:{tag}\")\n    _buildx(\"mitmproxy/mitmproxy:latest\")\nelse:\n    raise AssertionError\n", "web/gen/options_js.py": "#!/usr/bin/env python3\n\nimport asyncio\nimport io\nimport json\nfrom collections.abc import Sequence\nfrom contextlib import redirect_stdout\nfrom pathlib import Path\n\nfrom mitmproxy import options\nfrom mitmproxy import optmanager\nfrom mitmproxy.tools.web import master\n\nhere = Path(__file__).parent.absolute()\n\nfilename = here / \"../src/js/ducks/_options_gen.ts\"\n\n\ndef _ts_type(t):\n    if t == bool:\n        return \"boolean\"\n    if t == str:\n        return \"string\"\n    if t == int:\n        return \"number\"\n    if t == Sequence[str]:\n        return \"string[]\"\n    if t == str | None:\n        return \"string | undefined\"\n    if t == int | None:\n        return \"number | undefined\"\n    raise RuntimeError(t)\n\n\nasync def make() -> str:\n    o = options.Options()\n    m = master.WebMaster(o)\n    opt: optmanager._Option\n\n    with redirect_stdout(io.StringIO()) as s:\n        print(\"/** Auto-generated by web/gen/options_js.py */\")\n\n        print(\"export interface OptionsState {\")\n        for _, opt in sorted(m.options.items()):\n            print(f\"    {opt.name}: {_ts_type(opt.typespec)};\")\n        print(\"}\")\n        print(\"\")\n        print(\"export type Option = keyof OptionsState;\")\n        print(\"\")\n        print(\"export const defaultState: OptionsState = {\")\n        for _, opt in sorted(m.options.items()):\n            print(\n                f\"    {opt.name}: {json.dumps(opt.default)},\".replace(\n                    \": null\", \": undefined\"\n                )\n            )\n        print(\"};\")\n\n    await m.done()\n    return s.getvalue()\n\n\nif __name__ == \"__main__\":\n    filename.write_bytes(asyncio.run(make()).encode())\n", "web/gen/tflow_js.py": "#!/usr/bin/env python3\n\nimport asyncio\nimport json\nimport textwrap\nfrom pathlib import Path\n\nfrom mitmproxy import certs\nfrom mitmproxy.http import Headers\nfrom mitmproxy.test import tflow\nfrom mitmproxy.tools.web import app\n\nhere = Path(__file__).parent.absolute()\n\nfilename = here / \"../src/js/__tests__/ducks/_tflow.ts\"\n\n\nasync def make() -> str:\n    tf_http = tflow.tflow(resp=True, err=True, ws=True)\n    tf_http.id = \"d91165be-ca1f-4612-88a9-c0f8696f3e29\"\n    tf_http.client_conn.id = \"4a18d1a0-50a1-48dd-9aa6-d45d74282939\"\n    tf_http.server_conn.id = \"f087e7b2-6d0a-41a8-a8f0-e1a4761395f8\"\n    tf_http.server_conn.certificate_list = [\n        certs.Cert.from_pem(\n            (\n                here / \"../../test/mitmproxy/net/data/verificationcerts/self-signed.pem\"\n            ).read_bytes()\n        )\n    ]\n    tf_http.request.trailers = Headers(trailer=\"qvalue\")\n    tf_http.response.trailers = Headers(trailer=\"qvalue\")\n    tf_http.comment = \"I'm a comment!\"\n\n    tf_tcp = tflow.ttcpflow(err=True)\n    tf_tcp.id = \"2ea7012b-21b5-4f8f-98cd-d49819954001\"\n    tf_tcp.client_conn.id = \"8be32b99-a0b3-446e-93bc-b29982fe1322\"\n    tf_tcp.server_conn.id = \"e33bb2cd-c07e-4214-9a8e-3a8f85f25200\"\n\n    tf_udp = tflow.tudpflow(err=True)\n    tf_udp.id = \"f9f7b2b9-7727-4477-822d-d3526e5b8951\"\n    tf_udp.client_conn.id = \"0a8833da-88e4-429d-ac54-61cda8a7f91c\"\n    tf_udp.server_conn.id = \"c49f9c2b-a729-4b16-9212-d181717e294b\"\n\n    tf_dns = tflow.tdnsflow(resp=True, err=True)\n    tf_dns.id = \"5434da94-1017-42fa-872d-a189508d48e4\"\n    tf_dns.client_conn.id = \"0b4cc0a3-6acb-4880-81c0-1644084126fc\"\n    tf_dns.server_conn.id = \"db5294af-c008-4098-a320-a94f901eaf2f\"\n\n    # language=TypeScript\n    content = (\n        \"/** Auto-generated by web/gen/tflow_js.py */\\n\"\n        \"import {HTTPFlow, TCPFlow, UDPFlow, DNSFlow} from '../../flow';\\n\"\n        \"export function THTTPFlow(): Required<HTTPFlow> {\\n\"\n        \"    return %s\\n\"\n        \"}\\n\"\n        \"export function TTCPFlow(): Required<TCPFlow> {\\n\"\n        \"    return %s\\n\"\n        \"}\\n\"\n        \"export function TUDPFlow(): Required<UDPFlow> {\\n\"\n        \"    return %s\\n\"\n        \"}\\n\"\n        \"export function TDNSFlow(): Required<DNSFlow> {\\n\"\n        \"    return %s\\n\"\n        \"}\\n\"\n        % (\n            textwrap.indent(\n                json.dumps(app.flow_to_json(tf_http), indent=4, sort_keys=True), \"    \"\n            ),\n            textwrap.indent(\n                json.dumps(app.flow_to_json(tf_tcp), indent=4, sort_keys=True), \"    \"\n            ),\n            textwrap.indent(\n                json.dumps(app.flow_to_json(tf_udp), indent=4, sort_keys=True), \"    \"\n            ),\n            textwrap.indent(\n                json.dumps(app.flow_to_json(tf_dns), indent=4, sort_keys=True), \"    \"\n            ),\n        )\n    )\n    content = content.replace(\": null\", \": undefined\")\n    return content\n\n\nif __name__ == \"__main__\":\n    filename.write_bytes(asyncio.run(make()).encode())\n", "web/gen/state_js.py": "#!/usr/bin/env python3\n\nimport asyncio\nimport json\nimport textwrap\nfrom pathlib import Path\nfrom unittest.mock import Mock\n\nfrom mitmproxy import options\nfrom mitmproxy.proxy.mode_servers import ServerInstance\nfrom mitmproxy.tools.web import app\nfrom mitmproxy.tools.web import master\n\nhere = Path(__file__).parent.absolute()\n\nfilename = here / \"../src/js/__tests__/ducks/_tbackendstate.ts\"\n\n\nasync def make() -> str:\n    o = options.Options()\n    m = master.WebMaster(o)\n\n    si1 = ServerInstance.make(\"regular\", m.proxyserver)\n    sock1 = Mock()\n    sock1.getsockname.return_value = (\"127.0.0.1\", 8080)\n    sock2 = Mock()\n    sock2.getsockname.return_value = (\"::1\", 8080)\n    server = Mock()\n    server.sockets = [sock1, sock2]\n    si1._servers = [server]\n    si2 = ServerInstance.make(\"reverse:example.com\", m.proxyserver)\n    si2.last_exception = RuntimeError(\"I failed somehow.\")\n    si3 = ServerInstance.make(\"socks5\", m.proxyserver)\n    m.proxyserver.servers._instances.update(\n        {\n            si1.mode: si1,\n            si2.mode: si2,\n            si3.mode: si3,\n        }\n    )\n\n    data = app.State.get_json(m)\n    await m.done()\n\n    data.update(available=True)\n    data[\"contentViews\"] = [\"Auto\", \"Raw\"]\n    data[\"version\"] = \"1.2.3\"\n\n    # language=TypeScript\n    content = (\n        \"/** Auto-generated by web/gen/state_js.py */\\n\"\n        \"import {BackendState} from '../../ducks/backendState';\\n\"\n        \"export function TBackendState(): Required<BackendState> {\\n\"\n        \"    return %s\\n\"\n        \"}\\n\"\n        % textwrap.indent(json.dumps(data, indent=4, sort_keys=True), \"    \").lstrip()\n    )\n\n    return content\n\n\nif __name__ == \"__main__\":\n    filename.write_bytes(asyncio.run(make()).encode())\n", "examples/addons/anatomy.py": "\"\"\"\nBasic skeleton of a mitmproxy addon.\n\nRun as follows: mitmproxy -s anatomy.py\n\"\"\"\n\nimport logging\n\n\nclass Counter:\n    def __init__(self):\n        self.num = 0\n\n    def request(self, flow):\n        self.num = self.num + 1\n        logging.info(\"We've seen %d flows\" % self.num)\n\n\naddons = [Counter()]\n", "examples/addons/wsgi-flask-app.py": "\"\"\"\nHost a WSGI app in mitmproxy.\n\nThis example shows how to graft a WSGI app onto mitmproxy. In this\ninstance, we're using the Flask framework (http://flask.pocoo.org/) to expose\na single simplest-possible page.\n\"\"\"\n\nfrom flask import Flask\n\nfrom mitmproxy.addons import asgiapp\n\napp = Flask(\"proxapp\")\n\n\n@app.route(\"/\")\ndef hello_world() -> str:\n    return \"Hello World!\"\n\n\naddons = [\n    # Host app at the magic domain \"example.com\" on port 80. Requests to this\n    # domain and port combination will now be routed to the WSGI app instance.\n    asgiapp.WSGIApp(app, \"example.com\", 80),\n    # TLS works too, but the magic domain needs to be resolvable from the mitmproxy machine due to mitmproxy's design.\n    # mitmproxy will connect to said domain and use its certificate but won't send any data.\n    # By using `--set upstream_cert=false` and `--set connection_strategy_lazy` the local certificate is used instead.\n    # asgiapp.WSGIApp(app, \"example.com\", 443),\n]\n", "examples/addons/commands-paths.py": "\"\"\"Handle file paths as command arguments.\"\"\"\n\nimport logging\nfrom collections.abc import Sequence\n\nfrom mitmproxy import command\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy import types\nfrom mitmproxy.log import ALERT\n\n\nclass MyAddon:\n    @command.command(\"myaddon.histogram\")\n    def histogram(\n        self,\n        flows: Sequence[flow.Flow],\n        path: types.Path,\n    ) -> None:\n        totals: dict[str, int] = {}\n        for f in flows:\n            if isinstance(f, http.HTTPFlow):\n                totals[f.request.host] = totals.setdefault(f.request.host, 0) + 1\n\n        with open(path, \"w+\") as fp:\n            for cnt, dom in sorted((v, k) for (k, v) in totals.items()):\n                fp.write(f\"{cnt}: {dom}\\n\")\n\n        logging.log(ALERT, \"done\")\n\n\naddons = [MyAddon()]\n", "examples/addons/shutdown.py": "\"\"\"\nA simple way of shutting down the mitmproxy instance to stop everything.\n\nUsage:\n\n    mitmproxy -s shutdown.py\n\n    and then send a HTTP request to trigger the shutdown:\n    curl --proxy localhost:8080 http://example.com/path\n\"\"\"\n\nimport logging\n\nfrom mitmproxy import ctx\nfrom mitmproxy import http\n\n\ndef request(flow: http.HTTPFlow) -> None:\n    # a random condition to make this example a bit more interactive\n    if flow.request.pretty_url == \"http://example.com/path\":\n        logging.info(\"Shutting down everything...\")\n        ctx.master.shutdown()\n", "examples/addons/duplicate-modify-replay.py": "\"\"\"Take incoming HTTP requests and replay them with modified parameters.\"\"\"\n\nfrom mitmproxy import ctx\n\n\ndef request(flow):\n    # Avoid an infinite loop by not replaying already replayed requests\n    if flow.is_replay == \"request\":\n        return\n    flow = flow.copy()\n    # Only interactive tools have a view. If we have one, add a duplicate entry\n    # for our flow.\n    if \"view\" in ctx.master.addons:\n        ctx.master.commands.call(\"view.flows.duplicate\", [flow])\n    flow.request.path = \"/changed\"\n    ctx.master.commands.call(\"replay.client\", [flow])\n", "examples/addons/log-events.py": "\"\"\"Post messages to mitmproxy's event log.\"\"\"\n\nimport logging\n\nfrom mitmproxy.addonmanager import Loader\nfrom mitmproxy.log import ALERT\n\nlogger = logging.getLogger(__name__)\n\n\ndef load(loader: Loader):\n    logger.info(\"This is some informative text.\")\n    logger.warning(\"This is a warning.\")\n    logger.error(\"This is an error.\")\n    logger.log(\n        ALERT,\n        \"This is an alert. It has the same urgency as info, but will also pop up in the status bar.\",\n    )\n", "examples/addons/options-configure.py": "\"\"\"React to configuration changes.\"\"\"\n\nfrom typing import Optional\n\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\n\n\nclass AddHeader:\n    def load(self, loader):\n        loader.add_option(\n            name=\"addheader\",\n            typespec=Optional[int],\n            default=None,\n            help=\"Add a header to responses\",\n        )\n\n    def configure(self, updates):\n        if \"addheader\" in updates:\n            if ctx.options.addheader is not None and ctx.options.addheader > 100:\n                raise exceptions.OptionsError(\"addheader must be <= 100\")\n\n    def response(self, flow):\n        if ctx.options.addheader is not None:\n            flow.response.headers[\"addheader\"] = str(ctx.options.addheader)\n\n\naddons = [AddHeader()]\n", "examples/addons/http-modify-query-string.py": "\"\"\"Modify HTTP query parameters.\"\"\"\n\nfrom mitmproxy import http\n\n\ndef request(flow: http.HTTPFlow) -> None:\n    flow.request.query[\"mitmproxy\"] = \"rocks\"\n", "examples/addons/commands-simple.py": "\"\"\"Add a custom command to mitmproxy's command prompt.\"\"\"\n\nimport logging\n\nfrom mitmproxy import command\n\n\nclass MyAddon:\n    def __init__(self):\n        self.num = 0\n\n    @command.command(\"myaddon.inc\")\n    def inc(self) -> None:\n        self.num += 1\n        logging.info(f\"num = {self.num}\")\n\n\naddons = [MyAddon()]\n", "examples/addons/http-redirect-requests.py": "\"\"\"Redirect HTTP requests to another server.\"\"\"\n\nfrom mitmproxy import http\n\n\ndef request(flow: http.HTTPFlow) -> None:\n    # pretty_host takes the \"Host\" header of the request into account,\n    # which is useful in transparent mode where we usually only have the IP\n    # otherwise.\n    if flow.request.pretty_host == \"example.org\":\n        flow.request.host = \"mitmproxy.org\"\n", "examples/addons/filter-flows.py": "\"\"\"\nUse mitmproxy's filter pattern in scripts.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\n\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy.addonmanager import Loader\n\n\nclass Filter:\n    filter: flowfilter.TFilter\n\n    def configure(self, updated):\n        if \"flowfilter\" in updated:\n            self.filter = flowfilter.parse(\".\")\n\n    def load(self, loader: Loader):\n        loader.add_option(\"flowfilter\", str, \"\", \"Check that flow matches filter.\")\n\n    def response(self, flow: http.HTTPFlow) -> None:\n        if flowfilter.match(self.filter, flow):\n            logging.info(\"Flow matches filter:\")\n            logging.info(flow)\n\n\naddons = [Filter()]\n", "examples/addons/options-simple.py": "\"\"\"\nAdd a new mitmproxy option.\n\nUsage:\n\n    mitmproxy -s options-simple.py --set addheader=true\n\"\"\"\n\nfrom mitmproxy import ctx\n\n\nclass AddHeader:\n    def __init__(self):\n        self.num = 0\n\n    def load(self, loader):\n        loader.add_option(\n            name=\"addheader\",\n            typespec=bool,\n            default=False,\n            help=\"Add a count header to responses\",\n        )\n\n    def response(self, flow):\n        if ctx.options.addheader:\n            self.num = self.num + 1\n            flow.response.headers[\"count\"] = str(self.num)\n\n\naddons = [AddHeader()]\n", "examples/addons/websocket-simple.py": "\"\"\"Process individual messages from a WebSocket connection.\"\"\"\n\nimport logging\nimport re\n\nfrom mitmproxy import http\n\n\ndef websocket_message(flow: http.HTTPFlow):\n    assert flow.websocket is not None  # make type checker happy\n    # get the latest message\n    message = flow.websocket.messages[-1]\n\n    # was the message sent from the client or server?\n    if message.from_client:\n        logging.info(f\"Client sent a message: {message.content!r}\")\n    else:\n        logging.info(f\"Server sent a message: {message.content!r}\")\n\n    # manipulate the message content\n    message.content = re.sub(rb\"^Hello\", b\"HAPPY\", message.content)\n\n    if b\"FOOBAR\" in message.content:\n        # kill the message and not send it to the other endpoint\n        message.drop()\n", "examples/addons/anatomy2.py": "\"\"\"An addon using the abbreviated scripting syntax.\"\"\"\n\n\ndef request(flow):\n    flow.request.headers[\"myheader\"] = \"value\"\n", "examples/addons/http-modify-form.py": "\"\"\"Modify an HTTP form submission.\"\"\"\n\nfrom mitmproxy import http\n\n\ndef request(flow: http.HTTPFlow) -> None:\n    if flow.request.urlencoded_form:\n        # If there's already a form, one can just add items to the dict:\n        flow.request.urlencoded_form[\"mitmproxy\"] = \"rocks\"\n    else:\n        # One can also just pass new form data.\n        # This sets the proper content type and overrides the body.\n        flow.request.urlencoded_form = [(\"foo\", \"bar\")]  # type: ignore[assignment]\n", "examples/addons/contentview.py": "\"\"\"\nAdd a custom message body pretty-printer for use inside mitmproxy.\n\nThis example shows how one can add a custom contentview to mitmproxy,\nwhich is used to pretty-print HTTP bodies for example.\nThe content view API is explained in the mitmproxy.contentviews module.\n\"\"\"\n\nfrom mitmproxy import contentviews\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy.addonmanager import Loader\n\n\nclass ViewSwapCase(contentviews.View):\n    name = \"swapcase\"\n\n    def __call__(\n        self,\n        data: bytes,\n        *,\n        content_type: str | None = None,\n        flow: flow.Flow | None = None,\n        http_message: http.Message | None = None,\n        **unknown_metadata,\n    ) -> contentviews.TViewResult:\n        return \"case-swapped text\", contentviews.format_text(data.swapcase())\n\n    def render_priority(\n        self,\n        data: bytes,\n        *,\n        content_type: str | None = None,\n        flow: flow.Flow | None = None,\n        http_message: http.Message | None = None,\n        **unknown_metadata,\n    ) -> float:\n        if content_type == \"text/plain\":\n            return 1\n        else:\n            return 0\n\n\nview = ViewSwapCase()\n\n\ndef load(loader: Loader):\n    contentviews.add(view)\n\n\ndef done():\n    contentviews.remove(view)\n", "examples/addons/io-read-saved-flows.py": "#!/usr/bin/env python\n\"\"\"\nRead a mitmproxy dump file.\n\"\"\"\n\nimport pprint\nimport sys\n\nfrom mitmproxy import http\nfrom mitmproxy import io\nfrom mitmproxy.exceptions import FlowReadException\n\nwith open(sys.argv[1], \"rb\") as logfile:\n    freader = io.FlowReader(logfile)\n    pp = pprint.PrettyPrinter(indent=4)\n    try:\n        for f in freader.stream():\n            print(f)\n            if isinstance(f, http.HTTPFlow):\n                print(f.request.host)\n            pp.pprint(f.get_state())\n            print(\"\")\n    except FlowReadException as e:\n        print(f\"Flow file corrupted: {e}\")\n", "examples/addons/contentview-custom-grpc.py": "\"\"\"\nAdd a custom version of the gRPC/protobuf content view, which parses\nprotobuf messages based on a user defined rule set.\n\n\"\"\"\n\nfrom mitmproxy import contentviews\nfrom mitmproxy.addonmanager import Loader\nfrom mitmproxy.contentviews.grpc import ProtoParser\nfrom mitmproxy.contentviews.grpc import ViewConfig\nfrom mitmproxy.contentviews.grpc import ViewGrpcProtobuf\n\nconfig: ViewConfig = ViewConfig()\nconfig.parser_rules = [\n    # Note:\n    #\n    # The first two ParserRules use the same flow filter, although one should reply to request messages and the other to responses.\n    # Even with '~s' and '~q' filter expressions, the whole flow would be matched (for '~s') or not matched at all (for '~q'), if\n    # the contentview displays a http.Message belonging to a flow with existing request and response.\n    # The rules would have to be applied on per-message-basis, instead of per-flow-basis to distinguish request and response (the\n    # contentview deals with a single message, either request or response, the flow filter with a flow contiaing both).\n    #\n    # Thus different ParserRule classes are used to restrict rules to requests or responses were needed:\n    #\n    # - ParserRule: applied to requests and responses\n    # - ParserRuleRequest: applies to requests only\n    # - ParserRuleResponse: applies to responses only\n    #\n    # The actual 'filter' definition in the rule, would still match the whole flow. This means '~u' expressions could\n    # be used, to match the URL from the request of a flow, while the ParserRuleResponse is only applied to the response.\n    ProtoParser.ParserRuleRequest(\n        name=\"Geo coordinate lookup request\",\n        # note on flowfilter: for tflow the port gets appended to the URL's host part\n        filter=\"example\\\\.com.*/ReverseGeocode\",\n        field_definitions=[\n            ProtoParser.ParserFieldDefinition(tag=\"1\", name=\"position\"),\n            ProtoParser.ParserFieldDefinition(\n                tag=\"1.1\",\n                name=\"latitude\",\n                intended_decoding=ProtoParser.DecodedTypes.double,\n            ),\n            ProtoParser.ParserFieldDefinition(\n                tag=\"1.2\",\n                name=\"longitude\",\n                intended_decoding=ProtoParser.DecodedTypes.double,\n            ),\n            ProtoParser.ParserFieldDefinition(tag=\"3\", name=\"country\"),\n            ProtoParser.ParserFieldDefinition(tag=\"7\", name=\"app\"),\n        ],\n    ),\n    ProtoParser.ParserRuleResponse(\n        name=\"Geo coordinate lookup response\",\n        # note on flowfilter: for tflow the port gets appended to the URL's host part\n        filter=\"example\\\\.com.*/ReverseGeocode\",\n        field_definitions=[\n            ProtoParser.ParserFieldDefinition(tag=\"1.2\", name=\"address\"),\n            ProtoParser.ParserFieldDefinition(tag=\"1.3\", name=\"address array element\"),\n            ProtoParser.ParserFieldDefinition(\n                tag=\"1.3.1\",\n                name=\"unknown bytes\",\n                intended_decoding=ProtoParser.DecodedTypes.bytes,\n            ),\n            ProtoParser.ParserFieldDefinition(tag=\"1.3.2\", name=\"element value long\"),\n            ProtoParser.ParserFieldDefinition(tag=\"1.3.3\", name=\"element value short\"),\n            ProtoParser.ParserFieldDefinition(\n                tag=\"\",\n                tag_prefixes=[\"1.5.1\", \"1.5.3\", \"1.5.4\", \"1.5.5\", \"1.5.6\"],\n                name=\"position\",\n            ),\n            ProtoParser.ParserFieldDefinition(\n                tag=\".1\",\n                tag_prefixes=[\"1.5.1\", \"1.5.3\", \"1.5.4\", \"1.5.5\", \"1.5.6\"],\n                name=\"latitude\",\n                intended_decoding=ProtoParser.DecodedTypes.double,\n            ),\n            ProtoParser.ParserFieldDefinition(\n                tag=\".2\",\n                tag_prefixes=[\"1.5.1\", \"1.5.3\", \"1.5.4\", \"1.5.5\", \"1.5.6\"],\n                name=\"longitude\",\n                intended_decoding=ProtoParser.DecodedTypes.double,\n            ),\n            ProtoParser.ParserFieldDefinition(tag=\"7\", name=\"app\"),\n        ],\n    ),\n]\n\n\nclass ViewGrpcWithRules(ViewGrpcProtobuf):\n    name = \"customized gRPC/protobuf\"\n\n    def __init__(self) -> None:\n        super().__init__(config=config)\n\n    def __call__(self, *args, **kwargs) -> contentviews.TViewResult:\n        heading, lines = super().__call__(*args, **kwargs)\n        return heading + \" (addon with custom rules)\", lines\n\n    def render_priority(self, *args, **kwargs) -> float:\n        # increase priority above default gRPC view\n        s_prio = super().render_priority(*args, **kwargs)\n        return s_prio + 1 if s_prio > 0 else s_prio\n\n\nview = ViewGrpcWithRules()\n\n\ndef load(loader: Loader):\n    contentviews.add(view)\n\n\ndef done():\n    contentviews.remove(view)\n", "examples/addons/websocket-inject-message.py": "\"\"\"\nInject a WebSocket message into a running connection.\n\nThis example shows how to inject a WebSocket message into a running connection.\n\"\"\"\n\nimport asyncio\n\nfrom mitmproxy import ctx\nfrom mitmproxy import http\n\n# Simple example: Inject a message as a response to an event\n\n\ndef websocket_message(flow: http.HTTPFlow):\n    assert flow.websocket is not None  # make type checker happy\n    last_message = flow.websocket.messages[-1]\n    if last_message.is_text and \"secret\" in last_message.text:\n        last_message.drop()\n        ctx.master.commands.call(\n            \"inject.websocket\", flow, last_message.from_client, b\"ssssssh\"\n        )\n\n\n# Complex example: Schedule a periodic timer\n\n\nasync def inject_async(flow: http.HTTPFlow):\n    msg = \"hello from mitmproxy! \"\n    assert flow.websocket is not None  # make type checker happy\n    while flow.websocket.timestamp_end is None:\n        ctx.master.commands.call(\"inject.websocket\", flow, True, msg.encode())\n        await asyncio.sleep(1)\n        msg = msg[1:] + msg[:1]\n\n\n# Python 3.11: replace with TaskGroup\ntasks = set()\n\n\ndef websocket_start(flow: http.HTTPFlow):\n    # we need to hold a reference to the task, otherwise it will be garbage collected.\n    t = asyncio.create_task(inject_async(flow))\n    tasks.add(t)\n    t.add_done_callback(tasks.remove)\n", "examples/addons/http-stream-simple.py": "\"\"\"\nSelect which responses should be streamed.\n\nEnable response streaming for all HTTP flows.\nThis is equivalent to passing `--set stream_large_bodies=1` to mitmproxy.\n\"\"\"\n\n\ndef responseheaders(flow):\n    \"\"\"\n    Enables streaming for all responses.\n    This is equivalent to passing `--set stream_large_bodies=1` to mitmproxy.\n    \"\"\"\n    flow.response.stream = True\n", "examples/addons/tcp-simple.py": "\"\"\"\nProcess individual messages from a TCP connection.\n\nThis script replaces full occurrences of \"foo\" with \"bar\" and prints various details for each message.\nPlease note that TCP is stream-based and *not* message-based. mitmproxy splits stream contents into \"messages\"\nas they are received by socket.recv(). This is pretty arbitrary and should not be relied on.\nHowever, it is sometimes good enough as a quick hack.\n\nExample Invocation:\n\n    mitmdump --tcp-hosts \".*\" -s examples/tcp-simple.py\n\"\"\"\n\nimport logging\n\nfrom mitmproxy import tcp\nfrom mitmproxy.utils import strutils\n\n\ndef tcp_message(flow: tcp.TCPFlow):\n    message = flow.messages[-1]\n    message.content = message.content.replace(b\"foo\", b\"bar\")\n\n    logging.info(\n        f\"tcp_message[from_client={message.from_client}), content={strutils.bytes_to_escaped_str(message.content)}]\"\n    )\n", "examples/addons/internet-in-mirror.py": "\"\"\"\nMirror all web pages.\n\nUseful if you are living down under.\n\"\"\"\n\nfrom mitmproxy import http\n\n\ndef response(flow: http.HTTPFlow) -> None:\n    if flow.response and flow.response.content:\n        flow.response.content = flow.response.content.replace(\n            b\"</head>\", b\"<style>body {transform: scaleX(-1);}</style></head>\"\n        )\n", "examples/addons/io-write-flow-file.py": "\"\"\"\nGenerate a mitmproxy dump file.\n\nThis script demonstrates how to generate a mitmproxy dump file,\nas it would also be generated by passing `-w` to mitmproxy.\nIn contrast to `-w`, this gives you full control over which\nflows should be saved and also allows you to rotate files or log\nto multiple files in parallel.\n\"\"\"\n\nimport os\nimport random\nfrom typing import BinaryIO\n\nfrom mitmproxy import http\nfrom mitmproxy import io\n\n\nclass Writer:\n    def __init__(self) -> None:\n        # We are using an environment variable to keep the example as simple as possible,\n        # consider implementing this as a mitmproxy option instead.\n        filename = os.getenv(\"MITMPROXY_OUTFILE\", \"out.mitm\")\n        self.f: BinaryIO = open(filename, \"wb\")\n        self.w = io.FlowWriter(self.f)\n\n    def response(self, flow: http.HTTPFlow) -> None:\n        if random.choice([True, False]):\n            self.w.add(flow)\n\n    def done(self):\n        self.f.close()\n\n\naddons = [Writer()]\n", "examples/addons/http-stream-modify.py": "\"\"\"\nModify a streamed response.\n\nGenerally speaking, we recommend *not* to stream messages you need to modify.\nModifying streamed responses is tricky and brittle:\n    - If the transfer encoding isn't chunked, you cannot simply change the content length.\n    - If you want to replace all occurrences of \"foobar\", make sure to catch the cases\n      where one chunk ends with [...]foo\" and the next starts with \"bar[...].\n\"\"\"\n\nfrom collections.abc import Iterable\n\n\ndef modify(data: bytes) -> bytes | Iterable[bytes]:\n    \"\"\"\n    This function will be called for each chunk of request/response body data that arrives at the proxy,\n    and once at the end of the message with an empty bytes argument (b\"\").\n\n    It may either return bytes or an iterable of bytes (which would result in multiple HTTP/2 data frames).\n    \"\"\"\n    return data.replace(b\"foo\", b\"bar\")\n\n\ndef responseheaders(flow):\n    flow.response.stream = modify\n", "examples/addons/commands-flows.py": "\"\"\"Handle flows as command arguments.\"\"\"\n\nimport logging\nfrom collections.abc import Sequence\n\nfrom mitmproxy import command\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy.log import ALERT\n\n\nclass MyAddon:\n    @command.command(\"myaddon.addheader\")\n    def addheader(self, flows: Sequence[flow.Flow]) -> None:\n        for f in flows:\n            if isinstance(f, http.HTTPFlow):\n                f.request.headers[\"myheader\"] = \"value\"\n        logging.log(ALERT, \"done\")\n\n\naddons = [MyAddon()]\n", "examples/addons/http-trailers.py": "\"\"\"\nThis script simply prints all received HTTP Trailers.\n\nHTTP requests and responses can contain trailing headers which are sent after\nthe body is fully transmitted. Such trailers need to be announced in the initial\nheaders by name, so the receiving endpoint can wait and read them after the\nbody.\n\"\"\"\n\nfrom mitmproxy import http\nfrom mitmproxy.http import Headers\n\n\ndef request(flow: http.HTTPFlow):\n    if flow.request.trailers:\n        print(\"HTTP Trailers detected! Request contains:\", flow.request.trailers)\n\n    if flow.request.path == \"/inject_trailers\":\n        if flow.request.is_http10:\n            # HTTP/1.0 doesn't support trailers\n            return\n        elif flow.request.is_http11:\n            if not flow.request.content:\n                # Avoid sending a body on GET requests or a 0 byte chunked body with trailers.\n                # Otherwise some servers return 400 Bad Request.\n                return\n            # HTTP 1.1 requires transfer-encoding: chunked to send trailers\n            flow.request.headers[\"transfer-encoding\"] = \"chunked\"\n        # HTTP 2+ supports trailers on all requests/responses\n\n        flow.request.headers[\"trailer\"] = \"x-my-injected-trailer-header\"\n        flow.request.trailers = Headers([(b\"x-my-injected-trailer-header\", b\"foobar\")])\n        print(\"Injected a new request trailer...\", flow.request.headers[\"trailer\"])\n\n\ndef response(flow: http.HTTPFlow):\n    assert flow.response\n    if flow.response.trailers:\n        print(\"HTTP Trailers detected! Response contains:\", flow.response.trailers)\n\n    if flow.request.path == \"/inject_trailers\":\n        if flow.request.is_http10:\n            return\n        elif flow.request.is_http11:\n            if not flow.response.content:\n                return\n            flow.response.headers[\"transfer-encoding\"] = \"chunked\"\n\n        flow.response.headers[\"trailer\"] = \"x-my-injected-trailer-header\"\n        flow.response.trailers = Headers([(b\"x-my-injected-trailer-header\", b\"foobar\")])\n        print(\"Injected a new response trailer...\", flow.response.headers[\"trailer\"])\n", "examples/addons/nonblocking.py": "\"\"\"\nMake events hooks non-blocking using async or @concurrent.\n\"\"\"\n\nimport asyncio\nimport logging\nimport time\n\nfrom mitmproxy.script import concurrent\n\n# Toggle between asyncio and thread-based alternatives.\nif True:\n    # Hooks can be async, which allows the hook to call async functions and perform async I/O\n    # without blocking other requests. This is generally preferred for new addons.\n    async def request(flow):\n        logging.info(f\"handle request: {flow.request.host}{flow.request.path}\")\n        await asyncio.sleep(5)\n        logging.info(f\"start  request: {flow.request.host}{flow.request.path}\")\n\nelse:\n    # Another option is to use @concurrent, which launches the hook in its own thread.\n    # Please note that this generally opens the door to race conditions and decreases performance if not required.\n    @concurrent  # Remove this to make it synchronous and see what happens\n    def request(flow):\n        logging.info(f\"handle request: {flow.request.host}{flow.request.path}\")\n        time.sleep(5)\n        logging.info(f\"start  request: {flow.request.host}{flow.request.path}\")\n", "examples/addons/http-add-header.py": "\"\"\"Add an HTTP header to each response.\"\"\"\n\n\nclass AddHeader:\n    def __init__(self):\n        self.num = 0\n\n    def response(self, flow):\n        self.num = self.num + 1\n        flow.response.headers[\"count\"] = str(self.num)\n\n\naddons = [AddHeader()]\n", "examples/addons/http-reply-from-proxy.py": "\"\"\"Send a reply from the proxy without sending the request to the remote server.\"\"\"\n\nfrom mitmproxy import http\n\n\ndef request(flow: http.HTTPFlow) -> None:\n    if flow.request.pretty_url == \"http://example.com/path\":\n        flow.response = http.Response.make(\n            200,  # (optional) status code\n            b\"Hello World\",  # (optional) content\n            {\"Content-Type\": \"text/html\"},  # (optional) headers\n        )\n", "examples/contrib/har_dump.py": "\"\"\"\nThis addon is now part of mitmproxy! See mitmproxy/addons/savehar.py.\n\"\"\"\n", "examples/contrib/mitmproxywrapper.py": "#!/usr/bin/env python\n#\n# Helper tool to enable/disable OS X proxy and wrap mitmproxy\n#\n# Get usage information with:\n#\n# mitmproxywrapper.py -h\n#\nimport argparse\nimport contextlib\nimport os\nimport re\nimport signal\nimport socketserver\nimport subprocess\nimport sys\n\n\nclass Wrapper:\n    def __init__(self, port, use_mitmweb, extra_arguments=None):\n        self.port = port\n        self.use_mitmweb = use_mitmweb\n        self.extra_arguments = extra_arguments\n\n    def run_networksetup_command(self, *arguments):\n        return subprocess.check_output(\n            [\"sudo\", \"networksetup\"] + list(arguments)\n        ).decode()\n\n    def proxy_state_for_service(self, service):\n        state = self.run_networksetup_command(\"-getwebproxy\", service).splitlines()\n        return dict([re.findall(r\"([^:]+): (.*)\", line)[0] for line in state])\n\n    def enable_proxy_for_service(self, service):\n        print(f\"Enabling proxy on {service}...\")\n        for subcommand in [\"-setwebproxy\", \"-setsecurewebproxy\"]:\n            self.run_networksetup_command(\n                subcommand, service, \"127.0.0.1\", str(self.port)\n            )\n\n    def disable_proxy_for_service(self, service):\n        print(f\"Disabling proxy on {service}...\")\n        for subcommand in [\"-setwebproxystate\", \"-setsecurewebproxystate\"]:\n            self.run_networksetup_command(subcommand, service, \"Off\")\n\n    def interface_name_to_service_name_map(self):\n        order = self.run_networksetup_command(\"-listnetworkserviceorder\")\n        mapping = re.findall(\n            r\"\\(\\d+\\)\\s(.*)$\\n\\(.*Device: (.+)\\)$\", order, re.MULTILINE\n        )\n        return {b: a for (a, b) in mapping}\n\n    def run_command_with_input(self, command, input):\n        popen = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n        (stdout, stderr) = popen.communicate(input.encode())\n        return stdout.decode()\n\n    def primary_interace_name(self):\n        scutil_script = \"get State:/Network/Global/IPv4\\nd.show\\n\"\n        stdout = self.run_command_with_input(\"/usr/sbin/scutil\", scutil_script)\n        (interface,) = re.findall(r\"PrimaryInterface\\s*:\\s*(.+)\", stdout)\n        return interface\n\n    def primary_service_name(self):\n        return self.interface_name_to_service_name_map()[self.primary_interace_name()]\n\n    def proxy_enabled_for_service(self, service):\n        return self.proxy_state_for_service(service)[\"Enabled\"] == \"Yes\"\n\n    def toggle_proxy(self):\n        new_state = not self.proxy_enabled_for_service(self.primary_service_name())\n        for service_name in self.connected_service_names():\n            if self.proxy_enabled_for_service(service_name) and not new_state:\n                self.disable_proxy_for_service(service_name)\n            elif not self.proxy_enabled_for_service(service_name) and new_state:\n                self.enable_proxy_for_service(service_name)\n\n    def connected_service_names(self):\n        scutil_script = \"list\\n\"\n        stdout = self.run_command_with_input(\"/usr/sbin/scutil\", scutil_script)\n        service_ids = re.findall(r\"State:/Network/Service/(.+)/IPv4\", stdout)\n\n        service_names = []\n        for service_id in service_ids:\n            scutil_script = f\"show Setup:/Network/Service/{service_id}\\n\"\n            stdout = self.run_command_with_input(\"/usr/sbin/scutil\", scutil_script)\n            (service_name,) = re.findall(r\"UserDefinedName\\s*:\\s*(.+)\", stdout)\n            service_names.append(service_name)\n\n        return service_names\n\n    def wrap_mitmproxy(self):\n        with self.wrap_proxy():\n            cmd = [\"mitmweb\" if self.use_mitmweb else \"mitmproxy\", \"-p\", str(self.port)]\n            if self.extra_arguments:\n                cmd.extend(self.extra_arguments)\n            subprocess.check_call(cmd)\n\n    def wrap_honeyproxy(self):\n        with self.wrap_proxy():\n            popen = subprocess.Popen(\"honeyproxy.sh\")\n            try:\n                popen.wait()\n            except KeyboardInterrupt:\n                popen.terminate()\n\n    @contextlib.contextmanager\n    def wrap_proxy(self):\n        connected_service_names = self.connected_service_names()\n        for service_name in connected_service_names:\n            if not self.proxy_enabled_for_service(service_name):\n                self.enable_proxy_for_service(service_name)\n\n        yield\n\n        for service_name in connected_service_names:\n            if self.proxy_enabled_for_service(service_name):\n                self.disable_proxy_for_service(service_name)\n\n    @classmethod\n    def ensure_superuser(cls):\n        if os.getuid() != 0:\n            print(\"Relaunching with sudo...\")\n            os.execv(\"/usr/bin/sudo\", [\"/usr/bin/sudo\"] + sys.argv)\n\n    @classmethod\n    def main(cls):\n        parser = argparse.ArgumentParser(\n            description=\"Helper tool for OS X proxy configuration and mitmproxy.\",\n            epilog=\"Any additional arguments will be passed on unchanged to mitmproxy/mitmweb.\",\n        )\n        parser.add_argument(\n            \"-t\",\n            \"--toggle\",\n            action=\"store_true\",\n            help=\"just toggle the proxy configuration\",\n        )\n        # parser.add_argument('--honeyproxy', action='store_true', help='run honeyproxy instead of mitmproxy')\n        parser.add_argument(\n            \"-p\",\n            \"--port\",\n            type=int,\n            help=\"override the default port of 8080\",\n            default=8080,\n        )\n        parser.add_argument(\n            \"-P\",\n            \"--port-random\",\n            action=\"store_true\",\n            help=\"choose a random unused port\",\n        )\n        parser.add_argument(\n            \"-w\",\n            \"--web\",\n            action=\"store_true\",\n            help=\"web interface: run mitmweb instead of mitmproxy\",\n        )\n        args, extra_arguments = parser.parse_known_args()\n        port = args.port\n\n        # Allocate a random unused port, and hope no other process steals it before mitmproxy/mitmweb uses it.\n        # Passing the allocated socket to mitmproxy/mitmweb would be nicer of course.\n        if args.port_random:\n            with socketserver.TCPServer((\"localhost\", 0), None) as s:\n                port = s.server_address[1]\n                print(f\"Using random port {port}...\")\n\n        wrapper = cls(port=port, use_mitmweb=args.web, extra_arguments=extra_arguments)\n\n        def handler(signum, frame):\n            print(\"Cleaning up proxy settings...\")\n            wrapper.toggle_proxy()\n\n        signal.signal(signal.SIGINT, handler)\n\n        if args.toggle:\n            wrapper.toggle_proxy()\n        # elif args.honeyproxy:\n        #     wrapper.wrap_honeyproxy()\n        else:\n            wrapper.wrap_mitmproxy()\n\n\nif __name__ == \"__main__\":\n    Wrapper.ensure_superuser()\n    Wrapper.main()\n", "examples/contrib/save_streamed_data.py": "\"\"\"\nSave streamed requests and responses\n\nIf the option 'save_streamed_data' is set to a format string then\nstreamed requests and responses are written to individual files with a name\nderived from the string. Apart from python strftime() formating (using the\nrequest start time) the following codes can also be used:\n    - %+T: The time stamp of the request with microseconds\n    - %+D: 'req' or 'rsp' indicating the direction of the data\n    - %+I: The client connection ID\n    - %+C: The client IP address\nA good starting point for a template could be '~/streamed_files/%+D:%+T:%+I',\na more complex example is '~/streamed_files/%+C/%Y-%m-%d%/%+D:%+T:%+I'.\nThe client connection ID combined with the request time stamp should be unique\nfor associating a file with its corresponding flow in the stream saved with\n'--save-stream-file'.\n\nThis addon is not compatible with addons that use the same mechanism to\ncapture streamed data, http-stream-modify.py for instance.\n\"\"\"\n\nimport logging\nimport os\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom mitmproxy import ctx\n\n\nclass StreamSaver:\n    TAG = \"save_streamed_data: \"\n\n    def __init__(self, flow, direction):\n        self.flow = flow\n        self.direction = direction\n        self.fh = None\n        self.path = None\n\n    def done(self):\n        if self.fh:\n            self.fh.close()\n            self.fh = None\n        # Make sure we have no circular references\n        self.flow = None\n\n    def __call__(self, data):\n        # End of stream?\n        if len(data) == 0:\n            self.done()\n            return data\n\n        # Just in case the option changes while a stream is in flight\n        if not ctx.options.save_streamed_data:\n            return data\n\n        # This is a safeguard but should not be needed\n        if not self.flow or not self.flow.request:\n            return data\n\n        if not self.fh:\n            self.path = datetime.fromtimestamp(\n                self.flow.request.timestamp_start\n            ).strftime(ctx.options.save_streamed_data)\n            self.path = self.path.replace(\"%+T\", str(self.flow.request.timestamp_start))\n            self.path = self.path.replace(\"%+I\", str(self.flow.client_conn.id))\n            self.path = self.path.replace(\"%+D\", self.direction)\n            self.path = self.path.replace(\"%+C\", self.flow.client_conn.address[0])\n            self.path = os.path.expanduser(self.path)\n\n            parent = Path(self.path).parent\n            try:\n                if not parent.exists():\n                    parent.mkdir(parents=True, exist_ok=True)\n            except OSError:\n                logging.error(f\"{self.TAG}Failed to create directory: {parent}\")\n\n            try:\n                self.fh = open(self.path, \"wb\", buffering=0)\n            except OSError:\n                logging.error(f\"{self.TAG}Failed to open for writing: {self.path}\")\n\n        if self.fh:\n            try:\n                self.fh.write(data)\n            except OSError:\n                logging.error(f\"{self.TAG}Failed to write to: {self.path}\")\n\n        return data\n\n\ndef load(loader):\n    loader.add_option(\n        \"save_streamed_data\",\n        Optional[str],\n        None,\n        \"Format string for saving streamed data to files. If set each streamed request or response is written \"\n        \"to a file with a name derived from the string. In addition to formating supported by python \"\n        \"strftime() (using the request start time) the code '%+T' is replaced with the time stamp of the request, \"\n        \"'%+D' by 'req' or 'rsp' depending on the direction of the data, '%+C' by the client IP addresses and \"\n        \"'%+I' by the client connection ID.\",\n    )\n\n\ndef requestheaders(flow):\n    if ctx.options.save_streamed_data and flow.request.stream:\n        flow.request.stream = StreamSaver(flow, \"req\")\n\n\ndef responseheaders(flow):\n    if isinstance(flow.request.stream, StreamSaver):\n        flow.request.stream.done()\n    if ctx.options.save_streamed_data and flow.response.stream:\n        flow.response.stream = StreamSaver(flow, \"rsp\")\n\n\ndef response(flow):\n    if isinstance(flow.response.stream, StreamSaver):\n        flow.response.stream.done()\n\n\ndef error(flow):\n    if flow.request and isinstance(flow.request.stream, StreamSaver):\n        flow.request.stream.done()\n    if flow.response and isinstance(flow.response.stream, StreamSaver):\n        flow.response.stream.done()\n", "examples/contrib/link_expander.py": "# This script determines if request is an HTML webpage and if so seeks out\n# relative links (<a href=\"./about.html\">) and expands them to absolute links\n# In practice this can be used to front an indexing spider that may not have the capability to expand relative page links.\n# Usage: mitmdump -s link_expander.py or mitmproxy -s link_expander.py\nimport re\nfrom urllib.parse import urljoin\n\n\ndef response(flow):\n    if (\n        \"Content-Type\" in flow.response.headers\n        and flow.response.headers[\"Content-Type\"].find(\"text/html\") != -1\n    ):\n        pageUrl = flow.request.url\n        pageText = flow.response.text\n        pattern = (\n            r\"<a\\s+(?:[^>]*?\\s+)?href=(?P<delimiter>[\\\"'])\"\n            r\"(?P<link>(?!https?:\\/\\/|ftps?:\\/\\/|\\/\\/|#|javascript:|mailto:).*?)(?P=delimiter)\"\n        )\n        rel_matcher = re.compile(pattern, flags=re.IGNORECASE)\n        rel_matches = rel_matcher.finditer(pageText)\n        map_dict = {}\n        for match_num, match in enumerate(rel_matches):\n            (delimiter, rel_link) = match.group(\"delimiter\", \"link\")\n            abs_link = urljoin(pageUrl, rel_link)\n            map_dict[\"{0}{1}{0}\".format(delimiter, rel_link)] = \"{0}{1}{0}\".format(\n                delimiter, abs_link\n            )\n        for map in map_dict.items():\n            pageText = pageText.replace(*map)\n            # Uncomment the following to print the expansion mapping\n            # print(\"{0} -> {1}\".format(*map))\n        flow.response.text = pageText\n", "examples/contrib/tls_passthrough.py": "\"\"\"\nThis addon allows conditional TLS Interception based on a user-defined strategy.\n\nExample:\n\n    > mitmdump -s tls_passthrough.py\n\n    1. curl --proxy http://localhost:8080 https://example.com --insecure\n    // works - we'll also see the contents in mitmproxy\n\n    2. curl --proxy http://localhost:8080 https://example.com\n    // fails with a certificate error, which we will also see in mitmproxy\n\n    3. curl --proxy http://localhost:8080 https://example.com\n    // works again, but mitmproxy does not intercept and we do *not* see the contents\n\"\"\"\n\nimport collections\nimport logging\nimport random\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom enum import Enum\n\nfrom mitmproxy import connection\nfrom mitmproxy import ctx\nfrom mitmproxy import tls\nfrom mitmproxy.addonmanager import Loader\nfrom mitmproxy.utils import human\n\n\nclass InterceptionResult(Enum):\n    SUCCESS = 1\n    FAILURE = 2\n    SKIPPED = 3\n\n\nclass TlsStrategy(ABC):\n    def __init__(self):\n        # A server_address -> interception results mapping\n        self.history = collections.defaultdict(lambda: collections.deque(maxlen=200))\n\n    @abstractmethod\n    def should_intercept(self, server_address: connection.Address) -> bool:\n        raise NotImplementedError()\n\n    def record_success(self, server_address):\n        self.history[server_address].append(InterceptionResult.SUCCESS)\n\n    def record_failure(self, server_address):\n        self.history[server_address].append(InterceptionResult.FAILURE)\n\n    def record_skipped(self, server_address):\n        self.history[server_address].append(InterceptionResult.SKIPPED)\n\n\nclass ConservativeStrategy(TlsStrategy):\n    \"\"\"\n    Conservative Interception Strategy - only intercept if there haven't been any failed attempts\n    in the history.\n    \"\"\"\n\n    def should_intercept(self, server_address: connection.Address) -> bool:\n        return InterceptionResult.FAILURE not in self.history[server_address]\n\n\nclass ProbabilisticStrategy(TlsStrategy):\n    \"\"\"\n    Fixed probability that we intercept a given connection.\n    \"\"\"\n\n    def __init__(self, p: float):\n        self.p = p\n        super().__init__()\n\n    def should_intercept(self, server_address: connection.Address) -> bool:\n        return random.uniform(0, 1) < self.p\n\n\nclass MaybeTls:\n    strategy: TlsStrategy\n\n    def load(self, loader: Loader):\n        loader.add_option(\n            \"tls_strategy\",\n            int,\n            0,\n            \"TLS passthrough strategy. If set to 0, connections will be passed through after the first unsuccessful \"\n            \"handshake. If set to 0 < p <= 100, connections with be passed through with probability p.\",\n        )\n\n    def configure(self, updated):\n        if \"tls_strategy\" not in updated:\n            return\n        if ctx.options.tls_strategy > 0:\n            self.strategy = ProbabilisticStrategy(ctx.options.tls_strategy / 100)\n        else:\n            self.strategy = ConservativeStrategy()\n\n    @staticmethod\n    def get_addr(server: connection.Server):\n        # .peername may be unset in upstream proxy mode, so we need a fallback.\n        return server.peername or server.address\n\n    def tls_clienthello(self, data: tls.ClientHelloData):\n        server_address = self.get_addr(data.context.server)\n        if not self.strategy.should_intercept(server_address):\n            logging.info(f\"TLS passthrough: {human.format_address(server_address)}.\")\n            data.ignore_connection = True\n            self.strategy.record_skipped(server_address)\n\n    def tls_established_client(self, data: tls.TlsData):\n        server_address = self.get_addr(data.context.server)\n        logging.info(\n            f\"TLS handshake successful: {human.format_address(server_address)}\"\n        )\n        self.strategy.record_success(server_address)\n\n    def tls_failed_client(self, data: tls.TlsData):\n        server_address = self.get_addr(data.context.server)\n        logging.info(f\"TLS handshake failed: {human.format_address(server_address)}\")\n        self.strategy.record_failure(server_address)\n\n\naddons = [MaybeTls()]\n", "examples/contrib/ntlm_upstream_proxy.py": "import base64\nimport binascii\nimport logging\nimport socket\nfrom typing import Any\nfrom typing import Optional\n\nfrom ntlm_auth import gss_channel_bindings\nfrom ntlm_auth import ntlm\n\nfrom mitmproxy import addonmanager\nfrom mitmproxy import ctx\nfrom mitmproxy import http\nfrom mitmproxy.net.http import http1\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.layers.http import HttpConnectUpstreamHook\nfrom mitmproxy.proxy.layers.http import HttpLayer\nfrom mitmproxy.proxy.layers.http import HttpStream\nfrom mitmproxy.proxy.layers.http._upstream_proxy import HttpUpstreamProxy\n\n\nclass NTLMUpstreamAuth:\n    \"\"\"\n    This addon handles authentication to systems upstream from us for the\n    upstream proxy and reverse proxy mode. There are 3 cases:\n    - Upstream proxy CONNECT requests should have authentication added, and\n      subsequent already connected requests should not.\n    - Upstream proxy regular requests\n    - Reverse proxy regular requests (CONNECT is invalid in this mode)\n    \"\"\"\n\n    def load(self, loader: addonmanager.Loader) -> None:\n        logging.info(\"NTLMUpstreamAuth loader\")\n        loader.add_option(\n            name=\"upstream_ntlm_auth\",\n            typespec=Optional[str],\n            default=None,\n            help=\"\"\"\n            Add HTTP NTLM authentication to upstream proxy requests.\n            Format: username:password.\n            \"\"\",\n        )\n        loader.add_option(\n            name=\"upstream_ntlm_domain\",\n            typespec=Optional[str],\n            default=None,\n            help=\"\"\"\n            Add HTTP NTLM domain for authentication to upstream proxy requests.\n            \"\"\",\n        )\n        loader.add_option(\n            name=\"upstream_proxy_address\",\n            typespec=Optional[str],\n            default=None,\n            help=\"\"\"\n                upstream poxy address.\n                \"\"\",\n        )\n        loader.add_option(\n            name=\"upstream_ntlm_compatibility\",\n            typespec=int,\n            default=3,\n            help=\"\"\"\n            Add HTTP NTLM compatibility for authentication to upstream proxy requests.\n            Valid values are 0-5 (Default: 3)\n            \"\"\",\n        )\n        logging.debug(\"AddOn: NTLM Upstream Authentication - Loaded\")\n\n    def running(self):\n        def extract_flow_from_context(context: Context) -> http.HTTPFlow:\n            if context and context.layers:\n                for x in context.layers:\n                    if isinstance(x, HttpLayer):\n                        for _, stream in x.streams.items():\n                            return (\n                                stream.flow if isinstance(stream, HttpStream) else None\n                            )\n\n        def build_connect_flow(\n            context: Context, connect_header: tuple\n        ) -> http.HTTPFlow:\n            flow = extract_flow_from_context(context)\n            if not flow:\n                logging.error(\"failed to build connect flow\")\n                raise\n            flow.request.content = b\"\"  # we should send empty content for handshake\n            header_name, header_value = connect_header\n            flow.request.headers.add(header_name, header_value)\n            return flow\n\n        def patched_start_handshake(self) -> layer.CommandGenerator[None]:\n            assert self.conn.address\n            self.ntlm_context = CustomNTLMContext(ctx)\n            proxy_authorization = self.ntlm_context.get_ntlm_start_negotiate_message()\n            self.flow = build_connect_flow(\n                self.context, (\"Proxy-Authorization\", proxy_authorization)\n            )\n            yield HttpConnectUpstreamHook(self.flow)\n            raw = http1.assemble_request(self.flow.request)\n            yield commands.SendData(self.tunnel_connection, raw)\n\n        def extract_proxy_authenticate_msg(response_head: list) -> str:\n            for header in response_head:\n                if b\"Proxy-Authenticate\" in header:\n                    challenge_message = str(bytes(header).decode(\"utf-8\"))\n                    try:\n                        token = challenge_message.split(\": \")[1]\n                    except IndexError:\n                        logging.error(\"Failed to extract challenge_message\")\n                        raise\n                    return token\n\n        def patched_receive_handshake_data(\n            self, data\n        ) -> layer.CommandGenerator[tuple[bool, str | None]]:\n            self.buf += data\n            response_head = self.buf.maybe_extract_lines()\n            if response_head:\n                response_head = [bytes(x) for x in response_head]\n                try:\n                    response = http1.read_response_head(response_head)\n                except ValueError:\n                    return True, None\n                challenge_message = extract_proxy_authenticate_msg(response_head)\n                if 200 <= response.status_code < 300:\n                    if self.buf:\n                        yield from self.receive_data(data)\n                        del self.buf\n                    return True, None\n                else:\n                    if not challenge_message:\n                        return True, None\n                    proxy_authorization = (\n                        self.ntlm_context.get_ntlm_challenge_response_message(\n                            challenge_message\n                        )\n                    )\n                    self.flow = build_connect_flow(\n                        self.context, (\"Proxy-Authorization\", proxy_authorization)\n                    )\n                    raw = http1.assemble_request(self.flow.request)\n                    yield commands.SendData(self.tunnel_connection, raw)\n                    return False, None\n            else:\n                return False, None\n\n        HttpUpstreamProxy.start_handshake = patched_start_handshake\n        HttpUpstreamProxy.receive_handshake_data = patched_receive_handshake_data\n\n    def done(self):\n        logging.info(\"close ntlm session\")\n\n\naddons = [NTLMUpstreamAuth()]\n\n\nclass CustomNTLMContext:\n    def __init__(\n        self,\n        ctx,\n        preferred_type: str = \"NTLM\",\n        cbt_data: gss_channel_bindings.GssChannelBindingsStruct = None,\n    ):\n        # TODO:// take care the cbt_data\n        auth: str = ctx.options.upstream_ntlm_auth\n        domain: str = str(ctx.options.upstream_ntlm_domain).upper()\n        ntlm_compatibility: int = ctx.options.upstream_ntlm_compatibility\n        username, password = tuple(auth.split(\":\"))\n        workstation = socket.gethostname().upper()\n        logging.debug(f'\\nntlm context with the details: \"{domain}\\\\{username}\", *****')\n        self.preferred_type = preferred_type\n        self.ntlm_context = ntlm.NtlmContext(\n            username=username,\n            password=password,\n            domain=domain,\n            workstation=workstation,\n            ntlm_compatibility=ntlm_compatibility,\n            cbt_data=cbt_data,\n        )\n\n    def get_ntlm_start_negotiate_message(self) -> str:\n        negotiate_message = self.ntlm_context.step()\n        negotiate_message_base_64_in_bytes = base64.b64encode(negotiate_message)\n        negotiate_message_base_64_ascii = negotiate_message_base_64_in_bytes.decode(\n            \"ascii\"\n        )\n        negotiate_message_base_64_final = (\n            f\"{self.preferred_type} {negotiate_message_base_64_ascii}\"\n        )\n        logging.debug(\n            f\"{self.preferred_type} Authentication, negotiate message: {negotiate_message_base_64_final}\"\n        )\n        return negotiate_message_base_64_final\n\n    def get_ntlm_challenge_response_message(self, challenge_message: str) -> Any:\n        challenge_message = challenge_message.replace(self.preferred_type + \" \", \"\", 1)\n        try:\n            challenge_message_ascii_bytes = base64.b64decode(\n                challenge_message, validate=True\n            )\n        except binascii.Error as err:\n            logging.debug(\n                f\"{self.preferred_type} Authentication fail with error {err.__str__()}\"\n            )\n            return False\n        authenticate_message = self.ntlm_context.step(challenge_message_ascii_bytes)\n        negotiate_message_base_64 = \"{} {}\".format(\n            self.preferred_type, base64.b64encode(authenticate_message).decode(\"ascii\")\n        )\n        logging.debug(\n            f\"{self.preferred_type} Authentication, response to challenge message: {negotiate_message_base_64}\"\n        )\n        return negotiate_message_base_64\n", "examples/contrib/search.py": "import logging\nimport re\nfrom collections.abc import Sequence\nfrom json import dumps\n\nfrom mitmproxy import command\nfrom mitmproxy import flow\n\nMARKER = \":mag:\"\nRESULTS_STR = \"Search Results: \"\n\n\nclass Search:\n    def __init__(self):\n        self.exp = None\n\n    @command.command(\"search\")\n    def _search(self, flows: Sequence[flow.Flow], regex: str) -> None:\n        \"\"\"\n        Defines a command named \"search\" that matches\n        the given regular expression against most parts\n        of each request/response included in the selected flows.\n\n        Usage: from the flow list view, type \":search\" followed by\n        a space, then a flow selection expression; e.g., \"@shown\",\n        then the desired regular expression to perform the search.\n\n        Alternatively, define a custom shortcut in keys.yaml; e.g.:\n        -\n          key: \"/\"\n          ctx: [\"flowlist\"]\n          cmd: \"console.command search @shown \"\n\n        Flows containing matches to the expression will be marked\n        with the magnifying glass emoji, and their comments will\n        contain JSON-formatted search results.\n\n        To view flow comments, enter the flow view\n        and navigate to the detail tab.\n        \"\"\"\n\n        try:\n            self.exp = re.compile(regex)\n        except re.error as e:\n            logging.error(e)\n            return\n\n        for _flow in flows:\n            # Erase previous results while preserving other comments:\n            comments = list()\n            for c in _flow.comment.split(\"\\n\"):\n                if c.startswith(RESULTS_STR):\n                    break\n                comments.append(c)\n            _flow.comment = \"\\n\".join(comments)\n\n            if _flow.marked == MARKER:\n                _flow.marked = False\n\n            results = {k: v for k, v in self.flow_results(_flow).items() if v}\n            if results:\n                comments.append(RESULTS_STR)\n                comments.append(dumps(results, indent=2))\n                _flow.comment = \"\\n\".join(comments)\n                _flow.marked = MARKER\n\n    def header_results(self, message):\n        results = {k: self.exp.findall(v) for k, v in message.headers.items()}\n        return {k: v for k, v in results.items() if v}\n\n    def flow_results(self, _flow):\n        results = dict()\n        results.update({\"flow_comment\": self.exp.findall(_flow.comment)})\n        if _flow.request is not None:\n            results.update({\"request_path\": self.exp.findall(_flow.request.path)})\n            results.update({\"request_headers\": self.header_results(_flow.request)})\n            if _flow.request.text:\n                results.update({\"request_body\": self.exp.findall(_flow.request.text)})\n        if _flow.response is not None:\n            results.update({\"response_headers\": self.header_results(_flow.response)})\n            if _flow.response.text:\n                results.update({\"response_body\": self.exp.findall(_flow.response.text)})\n        return results\n\n\naddons = [Search()]\n", "examples/contrib/remote-debug.py": "\"\"\"\nThis script enables remote debugging of the mitmproxy console *UI* with PyCharm.\nFor general debugging purposes, it is easier to just debug mitmdump within PyCharm.\n\nUsage:\n    - pip install pydevd on the mitmproxy machine\n    - Open the Run/Debug Configuration dialog box in PyCharm, and select the\n      Python Remote Debug configuration type.\n    - Debugging works in the way that mitmproxy connects to the debug server\n      on startup. Specify host and port that mitmproxy can use to reach your\n      PyCharm instance on startup.\n    - Adjust this inline script accordingly.\n    - Start debug server in PyCharm\n    - Set breakpoints\n    - Start mitmproxy -s remote_debug.py\n\"\"\"\n\n\ndef load(_):\n    import pydevd_pycharm\n\n    pydevd_pycharm.settrace(\n        \"localhost\", port=5678, stdoutToServer=True, stderrToServer=True, suspend=False\n    )\n", "examples/contrib/dns_spoofing.py": "\"\"\"\nThis script makes it possible to use mitmproxy in scenarios where IP spoofing\nhas been used to redirect connections to mitmproxy. The way this works is that\nwe rely on either the TLS Server Name Indication (SNI) or the Host header of the\nHTTP request. Of course, this is not foolproof - if an HTTPS connection comes\nwithout SNI, we don't know the actual target and cannot construct a certificate\nthat looks valid. Similarly, if there's no Host header or a spoofed Host header,\nwe're out of luck as well. Using transparent mode is the better option most of\nthe time.\n\nUsage:\n    mitmproxy\n        -p 443\n        -s dns_spoofing.py\n        # Used as the target location if neither SNI nor host header are present.\n        --mode reverse:http://example.com/\n        # To avoid auto rewriting of host header by the reverse proxy target.\n        --set keep_host_header\n    mitmdump\n        -p 80\n        --mode reverse:http://localhost:443/\n\n    (Setting up a single proxy instance and using iptables to redirect to it\n    works as well)\n\"\"\"\n\nimport re\n\n# This regex extracts splits the host header into host and port.\n# Handles the edge case of IPv6 addresses containing colons.\n# https://bugzilla.mozilla.org/show_bug.cgi?id=45891\nparse_host_header = re.compile(r\"^(?P<host>[^:]+|\\[.+\\])(?::(?P<port>\\d+))?$\")\n\n\nclass Rerouter:\n    def request(self, flow):\n        if flow.client_conn.tls_established:\n            flow.request.scheme = \"https\"\n            sni = flow.client_conn.sni\n            port = 443\n        else:\n            flow.request.scheme = \"http\"\n            sni = None\n            port = 80\n\n        host_header = flow.request.host_header\n        m = parse_host_header.match(host_header)\n        if m:\n            host_header = m.group(\"host\").strip(\"[]\")\n            if m.group(\"port\"):\n                port = int(m.group(\"port\"))\n\n        flow.request.host_header = host_header\n        flow.request.host = sni or host_header\n        flow.request.port = port\n\n\naddons = [Rerouter()]\n", "examples/contrib/test_jsondump.py": "import base64\nimport json\n\nimport requests_mock\n\nfrom mitmproxy.test import taddons\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\nexample_dir = tutils.test_data.push(\"../examples\")\n\n\nclass TestJSONDump:\n    def echo_response(self, request, context):\n        self.request = {\"json\": request.json(), \"headers\": request.headers}\n        return \"\"\n\n    def flow(self, resp_content=b\"message\"):\n        times = dict(\n            timestamp_start=746203272,\n            timestamp_end=746203272,\n        )\n\n        # Create a dummy flow for testing\n        return tflow.tflow(\n            req=tutils.treq(method=b\"GET\", **times),\n            resp=tutils.tresp(content=resp_content, **times),\n        )\n\n    def test_simple(self, tmpdir):\n        with taddons.context() as tctx:\n            a = tctx.script(example_dir.path(\"complex/jsondump.py\"))\n            path = str(tmpdir.join(\"jsondump.out\"))\n            tctx.configure(a, dump_destination=path)\n            tctx.invoke(a, \"response\", self.flow())\n            tctx.invoke(a, \"done\")\n            with open(path) as inp:\n                entry = json.loads(inp.readline())\n            assert entry[\"response\"][\"content\"] == \"message\"\n\n    def test_contentencode(self, tmpdir):\n        with taddons.context() as tctx:\n            a = tctx.script(example_dir.path(\"complex/jsondump.py\"))\n            path = str(tmpdir.join(\"jsondump.out\"))\n            content = b\"foo\" + b\"\\xff\" * 10\n            tctx.configure(a, dump_destination=path, dump_encodecontent=True)\n\n            tctx.invoke(a, \"response\", self.flow(resp_content=content))\n            tctx.invoke(a, \"done\")\n            with open(path) as inp:\n                entry = json.loads(inp.readline())\n            assert entry[\"response\"][\"content\"] == base64.b64encode(content).decode(\n                \"utf-8\"\n            )\n\n    def test_http(self, tmpdir):\n        with requests_mock.Mocker() as mock:\n            mock.post(\"http://my-server\", text=self.echo_response)\n            with taddons.context() as tctx:\n                a = tctx.script(example_dir.path(\"complex/jsondump.py\"))\n                tctx.configure(\n                    a,\n                    dump_destination=\"http://my-server\",\n                    dump_username=\"user\",\n                    dump_password=\"pass\",\n                )\n\n                tctx.invoke(a, \"response\", self.flow())\n                tctx.invoke(a, \"done\")\n\n                assert self.request[\"json\"][\"response\"][\"content\"] == \"message\"\n                assert self.request[\"headers\"][\"Authorization\"] == \"Basic dXNlcjpwYXNz\"\n", "examples/contrib/test_xss_scanner.py": "import pytest\nimport requests\n\nfrom examples.complex import xss_scanner as xss\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nclass TestXSSScanner:\n    def test_get_XSS_info(self):\n        # First type of exploit: <script>PAYLOAD</script>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><script>%s</script><html>\" % xss.FULL_PAYLOAD,\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            \"</script><script>alert(0)</script><script>\",\n            xss.FULL_PAYLOAD.decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        xss_info = xss.get_XSS_data(\n            b\"<html><script>%s</script><html>\"\n            % xss.FULL_PAYLOAD.replace(b\"'\", b\"%27\").replace(b'\"', b\"%22\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            \"</script><script>alert(0)</script><script>\",\n            xss.FULL_PAYLOAD.replace(b\"'\", b\"%27\")\n            .replace(b'\"', b\"%22\")\n            .decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><script>%s</script><html>\"\n            % xss.FULL_PAYLOAD.replace(b\"'\", b\"%27\")\n            .replace(b'\"', b\"%22\")\n            .replace(b\"/\", b\"%2F\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n        # Second type of exploit: <script>t='PAYLOAD'</script>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><script>t='%s';</script></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .replace(b'\"', b\"%22\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            \"';alert(0);g='\",\n            xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .replace(b'\"', b\"%22\")\n            .decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><script>t='%s';</script></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b'\"', b\"%22\")\n            .replace(b\"'\", b\"%22\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n        # Third type of exploit: <script>t=\"PAYLOAD\"</script>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b'<html><script>t=\"%s\";</script></html>'\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .replace(b\"'\", b\"%27\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            '\";alert(0);g=\"',\n            xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .replace(b\"'\", b\"%27\")\n            .decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable:\n        xss_info = xss.get_XSS_data(\n            b'<html><script>t=\"%s\";</script></html>'\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\"'\", b\"%27\")\n            .replace(b'\"', b\"%22\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n        # Fourth type of exploit: <a href='PAYLOAD'>Test</a>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><a href='%s'>Test</a></html>\" % xss.FULL_PAYLOAD,\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            \"'><script>alert(0)</script>\",\n            xss.FULL_PAYLOAD.decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><a href='OtherStuff%s'>Test</a></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"'\", b\"%27\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n        # Fifth type of exploit: <a href=\"PAYLOAD\">Test</a>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b'<html><a href=\"%s\">Test</a></html>'\n            % xss.FULL_PAYLOAD.replace(b\"'\", b\"%27\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            '\"><script>alert(0)</script>',\n            xss.FULL_PAYLOAD.replace(b\"'\", b\"%27\").decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable:\n        xss_info = xss.get_XSS_data(\n            b'<html><a href=\"OtherStuff%s\">Test</a></html>'\n            % xss.FULL_PAYLOAD.replace(b\"'\", b\"%27\").replace(b'\"', b\"%22\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n        # Sixth type of exploit: <a href=PAYLOAD>Test</a>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><a href=%s>Test</a></html>\" % xss.FULL_PAYLOAD,\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            \"><script>alert(0)</script>\",\n            xss.FULL_PAYLOAD.decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable\n        xss_info = xss.get_XSS_data(\n            b\"<html><a href=OtherStuff%s>Test</a></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .replace(b\"=\", b\"%3D\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n        # Seventh type of exploit: <html>PAYLOAD</html>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><b>%s</b></html>\" % xss.FULL_PAYLOAD,\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            \"<script>alert(0)</script>\",\n            xss.FULL_PAYLOAD.decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable\n        xss_info = xss.get_XSS_data(\n            b\"<html><b>%s</b></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .replace(b\"/\", b\"%2F\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n        # Eighth type of exploit: <a href=PAYLOAD>Test</a>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><a href=%s>Test</a></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\").replace(b\">\", b\"%3E\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            \"Javascript:alert(0)\",\n            xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><a href=OtherStuff%s>Test</a></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .replace(b\"=\", b\"%3D\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n        # Ninth type of exploit: <a href=\"STUFF PAYLOAD\">Test</a>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b'<html><a href=\"STUFF %s\">Test</a></html>'\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\").replace(b\">\", b\"%3E\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            '\" onmouseover=\"alert(0)\" t=\"',\n            xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable:\n        xss_info = xss.get_XSS_data(\n            b'<html><a href=\"STUFF %s\">Test</a></html>'\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .replace(b'\"', b\"%22\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n        # Tenth type of exploit: <a href='STUFF PAYLOAD'>Test</a>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><a href='STUFF %s'>Test</a></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\").replace(b\">\", b\"%3E\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            \"' onmouseover='alert(0)' t='\",\n            xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><a href='STUFF %s'>Test</a></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .replace(b\"'\", b\"%22\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n        # Eleventh type of exploit: <a href=STUFF_PAYLOAD>Test</a>\n        # Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><a href=STUFF%s>Test</a></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\").replace(b\">\", b\"%3E\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_xss_info = xss.XSSData(\n            \"https://example.com\",\n            \"End of URL\",\n            \" onmouseover=alert(0) t=\",\n            xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .decode(\"utf-8\"),\n        )\n        assert xss_info == expected_xss_info\n        # Non-Exploitable:\n        xss_info = xss.get_XSS_data(\n            b\"<html><a href=STUFF_%s>Test</a></html>\"\n            % xss.FULL_PAYLOAD.replace(b\"<\", b\"%3C\")\n            .replace(b\">\", b\"%3E\")\n            .replace(b\"=\", b\"%3D\"),\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert xss_info is None\n\n    def test_get_SQLi_data(self):\n        sqli_data = xss.get_SQLi_data(\n            \"<html>SQL syntax MySQL</html>\",\n            \"<html></html>\",\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        expected_sqli_data = xss.SQLiData(\n            \"https://example.com\", \"End of URL\", \"SQL syntax.*MySQL\", \"MySQL\"\n        )\n        assert sqli_data == expected_sqli_data\n        sqli_data = xss.get_SQLi_data(\n            \"<html>SQL syntax MySQL</html>\",\n            \"<html>SQL syntax MySQL</html>\",\n            \"https://example.com\",\n            \"End of URL\",\n        )\n        assert sqli_data is None\n\n    def test_inside_quote(self):\n        assert not xss.inside_quote(\"'\", b\"no\", 0, b\"no\")\n        assert xss.inside_quote(\"'\", b\"yes\", 0, b\"'yes'\")\n        assert xss.inside_quote(\"'\", b\"yes\", 1, b\"'yes'otherJunk'yes'more\")\n        assert not xss.inside_quote(\"'\", b\"longStringNotInIt\", 1, b\"short\")\n\n    def test_paths_to_text(self):\n        text = xss.paths_to_text(\n            \"\"\"<html><head><h1>STRING</h1></head>\n                                    <script>STRING</script>\n                                    <a href=STRING></a></html>\"\"\",\n            \"STRING\",\n        )\n        expected_text = [\"/html/head/h1\", \"/html/script\"]\n        assert text == expected_text\n        assert xss.paths_to_text(\"\"\"<html></html>\"\"\", \"STRING\") == []\n\n    def mocked_requests_vuln(*args, headers=None, cookies=None):\n        class MockResponse:\n            def __init__(self, html, headers=None, cookies=None):\n                self.text = html\n\n        return MockResponse(\"<html>%s</html>\" % xss.FULL_PAYLOAD)\n\n    def mocked_requests_invuln(*args, headers=None, cookies=None):\n        class MockResponse:\n            def __init__(self, html, headers=None, cookies=None):\n                self.text = html\n\n        return MockResponse(\"<html></html>\")\n\n    def test_test_end_of_url_injection(self, get_request_vuln):\n        xss_info = xss.test_end_of_URL_injection(\n            \"<html></html>\", \"https://example.com/index.html\", {}\n        )[0]\n        expected_xss_info = xss.XSSData(\n            \"https://example.com/index.html/1029zxcs'd\\\"ao<ac>so[sb]po(pc)se;sl/bsl\\\\eq=3847asd\",\n            \"End of URL\",\n            \"<script>alert(0)</script>\",\n            \"1029zxcs\\\\'d\\\"ao<ac>so[sb]po(pc)se;sl/bsl\\\\\\\\eq=3847asd\",\n        )\n        sqli_info = xss.test_end_of_URL_injection(\n            \"<html></html>\", \"https://example.com/\", {}\n        )[1]\n        assert xss_info == expected_xss_info\n        assert sqli_info is None\n\n    def test_test_referer_injection(self, get_request_vuln):\n        xss_info = xss.test_referer_injection(\n            \"<html></html>\", \"https://example.com/\", {}\n        )[0]\n        expected_xss_info = xss.XSSData(\n            \"https://example.com/\",\n            \"Referer\",\n            \"<script>alert(0)</script>\",\n            \"1029zxcs\\\\'d\\\"ao<ac>so[sb]po(pc)se;sl/bsl\\\\\\\\eq=3847asd\",\n        )\n        sqli_info = xss.test_referer_injection(\n            \"<html></html>\", \"https://example.com/\", {}\n        )[1]\n        assert xss_info == expected_xss_info\n        assert sqli_info is None\n\n    def test_test_user_agent_injection(self, get_request_vuln):\n        xss_info = xss.test_user_agent_injection(\n            \"<html></html>\", \"https://example.com/\", {}\n        )[0]\n        expected_xss_info = xss.XSSData(\n            \"https://example.com/\",\n            \"User Agent\",\n            \"<script>alert(0)</script>\",\n            \"1029zxcs\\\\'d\\\"ao<ac>so[sb]po(pc)se;sl/bsl\\\\\\\\eq=3847asd\",\n        )\n        sqli_info = xss.test_user_agent_injection(\n            \"<html></html>\", \"https://example.com/\", {}\n        )[1]\n        assert xss_info == expected_xss_info\n        assert sqli_info is None\n\n    def test_test_query_injection(self, get_request_vuln):\n        xss_info = xss.test_query_injection(\n            \"<html></html>\", \"https://example.com/vuln.php?cmd=ls\", {}\n        )[0]\n        expected_xss_info = xss.XSSData(\n            \"https://example.com/vuln.php?cmd=1029zxcs'd\\\"ao<ac>so[sb]po(pc)se;sl/bsl\\\\eq=3847asd\",\n            \"Query\",\n            \"<script>alert(0)</script>\",\n            \"1029zxcs\\\\'d\\\"ao<ac>so[sb]po(pc)se;sl/bsl\\\\\\\\eq=3847asd\",\n        )\n        sqli_info = xss.test_query_injection(\n            \"<html></html>\", \"https://example.com/vuln.php?cmd=ls\", {}\n        )[1]\n        assert xss_info == expected_xss_info\n        assert sqli_info is None\n\n    @pytest.fixture(scope=\"function\")\n    def get_request_vuln(self, monkeypatch):\n        monkeypatch.setattr(requests, \"get\", self.mocked_requests_vuln)\n\n    @pytest.fixture(scope=\"function\")\n    def get_request_invuln(self, monkeypatch):\n        monkeypatch.setattr(requests, \"get\", self.mocked_requests_invuln)\n\n    @pytest.fixture(scope=\"function\")\n    def mock_gethostbyname(self, monkeypatch):\n        def gethostbyname(domain):\n            claimed_domains = [\"google.com\"]\n            if domain not in claimed_domains:\n                from socket import gaierror\n\n                raise gaierror(\"[Errno -2] Name or service not known\")\n            else:\n                return \"216.58.221.46\"\n\n        monkeypatch.setattr(\"socket.gethostbyname\", gethostbyname)\n\n    def test_find_unclaimed_URLs(self, logger, mock_gethostbyname):\n        xss.find_unclaimed_URLs(\n            '<html><script src=\"http://google.com\"></script></html>',\n            \"https://example.com\",\n        )\n        assert logger.args == []\n        xss.find_unclaimed_URLs(\n            '<html><script src=\"http://unclaimedDomainName.com\"></script></html>',\n            \"https://example.com\",\n        )\n        assert (\n            logger.args[0]\n            == 'XSS found in https://example.com due to unclaimed URL \"http://unclaimedDomainName.com\".'\n        )\n        xss.find_unclaimed_URLs(\n            '<html><iframe src=\"http://unclaimedDomainName.com\"></iframe></html>',\n            \"https://example.com\",\n        )\n        assert (\n            logger.args[1]\n            == 'XSS found in https://example.com due to unclaimed URL \"http://unclaimedDomainName.com\".'\n        )\n        xss.find_unclaimed_URLs(\n            '<html><link rel=\"stylesheet\" href=\"http://unclaimedDomainName.com\"></html>',\n            \"https://example.com\",\n        )\n        assert (\n            logger.args[2]\n            == 'XSS found in https://example.com due to unclaimed URL \"http://unclaimedDomainName.com\".'\n        )\n\n    def test_log_XSS_data(self, logger):\n        xss.log_XSS_data(None)\n        assert logger.args == []\n        # self, url: str, injection_point: str, exploit: str, line: str\n        xss.log_XSS_data(\n            xss.XSSData(\"https://example.com\", \"Location\", \"String\", \"Line of HTML\")\n        )\n        assert logger.args[0] == \"===== XSS Found ====\"\n        assert logger.args[1] == \"XSS URL: https://example.com\"\n        assert logger.args[2] == \"Injection Point: Location\"\n        assert logger.args[3] == \"Suggested Exploit: String\"\n        assert logger.args[4] == \"Line: Line of HTML\"\n\n    def test_log_SQLi_data(self, logger):\n        xss.log_SQLi_data(None)\n        assert logger.args == []\n        xss.log_SQLi_data(\n            xss.SQLiData(\"https://example.com\", \"Location\", \"Oracle.*Driver\", \"Oracle\")\n        )\n        assert logger.args[0] == \"===== SQLi Found =====\"\n        assert logger.args[1] == \"SQLi URL: https://example.com\"\n        assert logger.args[2] == \"Injection Point: Location\"\n        assert logger.args[3] == \"Regex used: Oracle.*Driver\"\n\n    def test_get_cookies(self):\n        mocked_req = tutils.treq()\n        mocked_req.cookies = [(\"cookieName2\", \"cookieValue2\")]\n        mocked_flow = tflow.tflow(req=mocked_req)\n        # It only uses the request cookies\n        assert xss.get_cookies(mocked_flow) == {\"cookieName2\": \"cookieValue2\"}\n\n    def test_response(self, get_request_invuln, logger):\n        mocked_flow = tflow.tflow(\n            req=tutils.treq(path=b\"index.html?q=1\"),\n            resp=tutils.tresp(content=b\"<html></html>\"),\n        )\n        xss.response(mocked_flow)\n        assert logger.args == []\n\n    def test_data_equals(self):\n        xssData = xss.XSSData(\"a\", \"b\", \"c\", \"d\")\n        sqliData = xss.SQLiData(\"a\", \"b\", \"c\", \"d\")\n        assert xssData == xssData\n        assert sqliData == sqliData\n", "examples/contrib/jsondump.py": "\"\"\"\nThis script serializes the entire traffic dump, including websocket traffic,\nas JSON, and either sends it to a URL or writes to a file. The serialization\nformat is optimized for Elasticsearch; the script can be used to send all\ncaptured traffic to Elasticsearch directly.\n\nUsage:\n\n    mitmproxy\n        --mode reverse:http://example.com/\n        -s examples/complex/jsondump.py\n\nConfiguration:\n\n    Send to a URL:\n\n        cat > ~/.mitmproxy/config.yaml <<EOF\n        dump_destination: \"https://elastic.search.local/my-index/my-type\"\n        # Optional Basic auth:\n        dump_username: \"never-gonna-give-you-up\"\n        dump_password: \"never-gonna-let-you-down\"\n        # Optional base64 encoding of content fields\n        # to store as binary fields in Elasticsearch:\n        dump_encodecontent: true\n        EOF\n\n    Dump to a local file:\n\n        cat > ~/.mitmproxy/config.yaml <<EOF\n        dump_destination: \"/user/rastley/output.log\"\n        EOF\n\"\"\"\n\nimport base64\nimport json\nimport logging\nfrom queue import Queue\nfrom threading import Lock\nfrom threading import Thread\n\nimport requests\n\nfrom mitmproxy import ctx\n\nFILE_WORKERS = 1\nHTTP_WORKERS = 10\n\n\nclass JSONDumper:\n    \"\"\"\n    JSONDumper performs JSON serialization and some extra processing\n    for out-of-the-box Elasticsearch support, and then either writes\n    the result to a file or sends it to a URL.\n    \"\"\"\n\n    def __init__(self):\n        self.outfile = None\n        self.transformations = None\n        self.encode = None\n        self.url = None\n        self.lock = None\n        self.auth = None\n        self.queue = Queue()\n\n    def done(self):\n        self.queue.join()\n        if self.outfile:\n            self.outfile.close()\n\n    fields = {\n        \"timestamp\": (\n            (\"error\", \"timestamp\"),\n            (\"request\", \"timestamp_start\"),\n            (\"request\", \"timestamp_end\"),\n            (\"response\", \"timestamp_start\"),\n            (\"response\", \"timestamp_end\"),\n            (\"client_conn\", \"timestamp_start\"),\n            (\"client_conn\", \"timestamp_end\"),\n            (\"client_conn\", \"timestamp_tls_setup\"),\n            (\"server_conn\", \"timestamp_start\"),\n            (\"server_conn\", \"timestamp_end\"),\n            (\"server_conn\", \"timestamp_tls_setup\"),\n            (\"server_conn\", \"timestamp_tcp_setup\"),\n        ),\n        \"ip\": (\n            (\"server_conn\", \"source_address\"),\n            (\"server_conn\", \"ip_address\"),\n            (\"server_conn\", \"address\"),\n            (\"client_conn\", \"address\"),\n        ),\n        \"ws_messages\": ((\"messages\",),),\n        \"headers\": (\n            (\"request\", \"headers\"),\n            (\"response\", \"headers\"),\n        ),\n        \"content\": (\n            (\"request\", \"content\"),\n            (\"response\", \"content\"),\n        ),\n    }\n\n    def _init_transformations(self):\n        self.transformations = [\n            {\n                \"fields\": self.fields[\"headers\"],\n                \"func\": dict,\n            },\n            {\n                \"fields\": self.fields[\"timestamp\"],\n                \"func\": lambda t: int(t * 1000),\n            },\n            {\n                \"fields\": self.fields[\"ip\"],\n                \"func\": lambda addr: {\n                    \"host\": addr[0].replace(\"::ffff:\", \"\"),\n                    \"port\": addr[1],\n                },\n            },\n            {\n                \"fields\": self.fields[\"ws_messages\"],\n                \"func\": lambda ms: [\n                    {\n                        \"type\": m[0],\n                        \"from_client\": m[1],\n                        \"content\": base64.b64encode(bytes(m[2], \"utf-8\"))\n                        if self.encode\n                        else m[2],\n                        \"timestamp\": int(m[3] * 1000),\n                    }\n                    for m in ms\n                ],\n            },\n        ]\n\n        if self.encode:\n            self.transformations.append(\n                {\n                    \"fields\": self.fields[\"content\"],\n                    \"func\": base64.b64encode,\n                }\n            )\n\n    @staticmethod\n    def transform_field(obj, path, func):\n        \"\"\"\n        Apply a transformation function `func` to a value\n        under the specified `path` in the `obj` dictionary.\n        \"\"\"\n        for key in path[:-1]:\n            if not (key in obj and obj[key]):\n                return\n            obj = obj[key]\n        if path[-1] in obj and obj[path[-1]]:\n            obj[path[-1]] = func(obj[path[-1]])\n\n    @classmethod\n    def convert_to_strings(cls, obj):\n        \"\"\"\n        Recursively convert all list/dict elements of type `bytes` into strings.\n        \"\"\"\n        if isinstance(obj, dict):\n            return {\n                cls.convert_to_strings(key): cls.convert_to_strings(value)\n                for key, value in obj.items()\n            }\n        elif isinstance(obj, list) or isinstance(obj, tuple):\n            return [cls.convert_to_strings(element) for element in obj]\n        elif isinstance(obj, bytes):\n            return str(obj)[2:-1]\n        return obj\n\n    def worker(self):\n        while True:\n            frame = self.queue.get()\n            self.dump(frame)\n            self.queue.task_done()\n\n    def dump(self, frame):\n        \"\"\"\n        Transform and dump (write / send) a data frame.\n        \"\"\"\n        for tfm in self.transformations:\n            for field in tfm[\"fields\"]:\n                self.transform_field(frame, field, tfm[\"func\"])\n        frame = self.convert_to_strings(frame)\n\n        if self.outfile:\n            self.lock.acquire()\n            self.outfile.write(json.dumps(frame) + \"\\n\")\n            self.lock.release()\n        else:\n            requests.post(self.url, json=frame, auth=(self.auth or None))\n\n    @staticmethod\n    def load(loader):\n        \"\"\"\n        Extra options to be specified in `~/.mitmproxy/config.yaml`.\n        \"\"\"\n        loader.add_option(\n            \"dump_encodecontent\", bool, False, \"Encode content as base64.\"\n        )\n        loader.add_option(\n            \"dump_destination\",\n            str,\n            \"jsondump.out\",\n            \"Output destination: path to a file or URL.\",\n        )\n        loader.add_option(\n            \"dump_username\", str, \"\", \"Basic auth username for URL destinations.\"\n        )\n        loader.add_option(\n            \"dump_password\", str, \"\", \"Basic auth password for URL destinations.\"\n        )\n\n    def configure(self, _):\n        \"\"\"\n        Determine the destination type and path, initialize the output\n        transformation rules.\n        \"\"\"\n        self.encode = ctx.options.dump_encodecontent\n\n        if ctx.options.dump_destination.startswith(\"http\"):\n            self.outfile = None\n            self.url = ctx.options.dump_destination\n            logging.info(\"Sending all data frames to %s\" % self.url)\n            if ctx.options.dump_username and ctx.options.dump_password:\n                self.auth = (ctx.options.dump_username, ctx.options.dump_password)\n                logging.info(\"HTTP Basic auth enabled.\")\n        else:\n            self.outfile = open(ctx.options.dump_destination, \"a\")\n            self.url = None\n            self.lock = Lock()\n            logging.info(\"Writing all data frames to %s\" % ctx.options.dump_destination)\n\n        self._init_transformations()\n\n        for i in range(FILE_WORKERS if self.outfile else HTTP_WORKERS):\n            t = Thread(target=self.worker)\n            t.daemon = True\n            t.start()\n\n    def response(self, flow):\n        \"\"\"\n        Dump request/response pairs.\n        \"\"\"\n        self.queue.put(flow.get_state())\n\n    def error(self, flow):\n        \"\"\"\n        Dump errors.\n        \"\"\"\n        self.queue.put(flow.get_state())\n\n    def websocket_end(self, flow):\n        \"\"\"\n        Dump websocket messages once the connection ends.\n\n        Alternatively, you can replace `websocket_end` with\n        `websocket_message` if you want the messages to be\n        dumped one at a time with full metadata. Warning:\n        this takes up _a lot_ of space.\n        \"\"\"\n        self.queue.put(flow.get_state())\n\n\naddons = [JSONDumper()]  # pylint: disable=invalid-name\n", "examples/contrib/check_ssl_pinning.py": "import ipaddress\nimport time\n\nimport OpenSSL\n\nimport mitmproxy\nfrom mitmproxy import ctx\nfrom mitmproxy.certs import Cert\n\n# Certificate for client connection is generated in dummy_cert() in certs.py. Monkeypatching\n# the function to generate test cases for SSL Pinning.\n\n\ndef monkey_dummy_cert(privkey, cacert, commonname, sans):\n    ss = []\n    for i in sans:\n        try:\n            ipaddress.ip_address(i.decode(\"ascii\"))\n        except ValueError:\n            # Change values in Certificate's Alt Name as well.\n            if ctx.options.certwrongCN:\n                ss.append(b\"DNS:%sm\" % i)\n            else:\n                ss.append(b\"DNS:%s\" % i)\n        else:\n            ss.append(b\"IP:%s\" % i)\n    ss = b\", \".join(ss)\n\n    cert = OpenSSL.crypto.X509()\n    if ctx.options.certbeginon:\n        # Set certificate start time somewhere in the future\n        cert.gmtime_adj_notBefore(3600 * 48)\n    else:\n        cert.gmtime_adj_notBefore(-3600 * 48)\n\n    if ctx.options.certexpire:\n        # sets the expire date of the certificate in the past.\n        cert.gmtime_adj_notAfter(-3600 * 24)\n    else:\n        cert.gmtime_adj_notAfter(94608000)  # = 24 * 60 * 60 * 365 * 3\n\n    cert.set_issuer(cacert.get_subject())\n    if commonname is not None and len(commonname) < 64:\n        if ctx.options.certwrongCN:\n            # append an extra char to make certs common name different than original one.\n            # APpending a char in the end of the domain name.\n            new_cn = commonname + b\"m\"\n            cert.get_subject().CN = new_cn\n\n        else:\n            cert.get_subject().CN = commonname\n\n    cert.set_serial_number(int(time.time() * 10000))\n    if ss:\n        cert.set_version(2)\n        cert.add_extensions(\n            [OpenSSL.crypto.X509Extension(b\"subjectAltName\", False, ss)]\n        )\n        cert.set_pubkey(cacert.get_pubkey())\n        cert.sign(privkey, \"sha256\")\n        return Cert(cert)\n\n\nclass CheckSSLPinning:\n    def load(self, loader):\n        loader.add_option(\n            \"certbeginon\",\n            bool,\n            False,\n            \"\"\"\n            Sets SSL Certificate's 'Begins On' time in future.\n            \"\"\",\n        )\n        loader.add_option(\n            \"certexpire\",\n            bool,\n            False,\n            \"\"\"\n            Sets SSL Certificate's 'Expires On' time in the past.\n            \"\"\",\n        )\n\n        loader.add_option(\n            \"certwrongCN\",\n            bool,\n            False,\n            \"\"\"\n            Sets SSL Certificate's CommonName(CN) different from the domain name.\n            \"\"\",\n        )\n\n    def clientconnect(self, layer):\n        mitmproxy.certs.dummy_cert = monkey_dummy_cert\n", "examples/contrib/block_dns_over_https.py": "\"\"\"\nThis module is for blocking DNS over HTTPS requests.\n\nIt loads a blocklist of IPs and hostnames that are known to serve DNS over HTTPS requests.\nIt also uses headers, query params, and paths to detect DoH (and block it)\n\"\"\"\n\nimport logging\n\n# known DoH providers' hostnames and IP addresses to block\ndefault_blocklist: dict = {\n    \"hostnames\": [\n        \"dns.adguard.com\",\n        \"dns-family.adguard.com\",\n        \"dns.google\",\n        \"cloudflare-dns.com\",\n        \"mozilla.cloudflare-dns.com\",\n        \"security.cloudflare-dns.com\",\n        \"family.cloudflare-dns.com\",\n        \"dns.quad9.net\",\n        \"dns9.quad9.net\",\n        \"dns10.quad9.net\",\n        \"dns11.quad9.net\",\n        \"doh.opendns.com\",\n        \"doh.familyshield.opendns.com\",\n        \"doh.cleanbrowsing.org\",\n        \"doh.xfinity.com\",\n        \"dohdot.coxlab.net\",\n        \"odvr.nic.cz\",\n        \"doh.dnslify.com\",\n        \"dns.nextdns.io\",\n        \"dns.dnsoverhttps.net\",\n        \"doh.crypto.sx\",\n        \"doh.powerdns.org\",\n        \"doh-fi.blahdns.com\",\n        \"doh-jp.blahdns.com\",\n        \"doh-de.blahdns.com\",\n        \"doh.ffmuc.net\",\n        \"dns.dns-over-https.com\",\n        \"doh.securedns.eu\",\n        \"dns.rubyfish.cn\",\n        \"dns.containerpi.com\",\n        \"dns.containerpi.com\",\n        \"dns.containerpi.com\",\n        \"doh-2.seby.io\",\n        \"doh.seby.io\",\n        \"commons.host\",\n        \"doh.dnswarden.com\",\n        \"doh.dnswarden.com\",\n        \"doh.dnswarden.com\",\n        \"dns-nyc.aaflalo.me\",\n        \"dns.aaflalo.me\",\n        \"doh.applied-privacy.net\",\n        \"doh.captnemo.in\",\n        \"doh.tiar.app\",\n        \"doh.tiarap.org\",\n        \"doh.dns.sb\",\n        \"rdns.faelix.net\",\n        \"doh.li\",\n        \"doh.armadillodns.net\",\n        \"jp.tiar.app\",\n        \"jp.tiarap.org\",\n        \"doh.42l.fr\",\n        \"dns.hostux.net\",\n        \"dns.hostux.net\",\n        \"dns.aa.net.uk\",\n        \"adblock.mydns.network\",\n        \"ibksturm.synology.me\",\n        \"jcdns.fun\",\n        \"ibuki.cgnat.net\",\n        \"dns.twnic.tw\",\n        \"example.doh.blockerdns.com\",\n        \"dns.digitale-gesellschaft.ch\",\n        \"doh.libredns.gr\",\n        \"doh.centraleu.pi-dns.com\",\n        \"doh.northeu.pi-dns.com\",\n        \"doh.westus.pi-dns.com\",\n        \"doh.eastus.pi-dns.com\",\n        \"dns.flatuslifir.is\",\n        \"private.canadianshield.cira.ca\",\n        \"protected.canadianshield.cira.ca\",\n        \"family.canadianshield.cira.ca\",\n        \"dns.google.com\",\n        \"dns.google.com\",\n    ],\n    \"ips\": [\n        \"104.16.248.249\",\n        \"104.16.248.249\",\n        \"104.16.249.249\",\n        \"104.16.249.249\",\n        \"104.18.2.55\",\n        \"104.18.26.128\",\n        \"104.18.27.128\",\n        \"104.18.3.55\",\n        \"104.18.44.204\",\n        \"104.18.44.204\",\n        \"104.18.45.204\",\n        \"104.18.45.204\",\n        \"104.182.57.196\",\n        \"104.236.178.232\",\n        \"104.24.122.53\",\n        \"104.24.123.53\",\n        \"104.28.0.106\",\n        \"104.28.1.106\",\n        \"104.31.90.138\",\n        \"104.31.91.138\",\n        \"115.159.131.230\",\n        \"116.202.176.26\",\n        \"116.203.115.192\",\n        \"136.144.215.158\",\n        \"139.59.48.222\",\n        \"139.99.222.72\",\n        \"146.112.41.2\",\n        \"146.112.41.3\",\n        \"146.185.167.43\",\n        \"149.112.112.10\",\n        \"149.112.112.11\",\n        \"149.112.112.112\",\n        \"149.112.112.9\",\n        \"149.112.121.10\",\n        \"149.112.121.20\",\n        \"149.112.121.30\",\n        \"149.112.122.10\",\n        \"149.112.122.20\",\n        \"149.112.122.30\",\n        \"159.69.198.101\",\n        \"168.235.81.167\",\n        \"172.104.93.80\",\n        \"172.65.3.223\",\n        \"174.138.29.175\",\n        \"174.68.248.77\",\n        \"176.103.130.130\",\n        \"176.103.130.131\",\n        \"176.103.130.132\",\n        \"176.103.130.134\",\n        \"176.56.236.175\",\n        \"178.62.214.105\",\n        \"185.134.196.54\",\n        \"185.134.197.54\",\n        \"185.213.26.187\",\n        \"185.216.27.142\",\n        \"185.228.168.10\",\n        \"185.228.168.168\",\n        \"185.235.81.1\",\n        \"185.26.126.37\",\n        \"185.26.126.37\",\n        \"185.43.135.1\",\n        \"185.95.218.42\",\n        \"185.95.218.43\",\n        \"195.30.94.28\",\n        \"2001:148f:fffe::1\",\n        \"2001:19f0:7001:3259:5400:2ff:fe71:bc9\",\n        \"2001:19f0:7001:5554:5400:2ff:fe57:3077\",\n        \"2001:19f0:7001:5554:5400:2ff:fe57:3077\",\n        \"2001:19f0:7001:5554:5400:2ff:fe57:3077\",\n        \"2001:4860:4860::8844\",\n        \"2001:4860:4860::8888\",\n        \"2001:4b98:dc2:43:216:3eff:fe86:1d28\",\n        \"2001:558:fe21:6b:96:113:151:149\",\n        \"2001:608:a01::3\",\n        \"2001:678:888:69:c45d:2738:c3f2:1878\",\n        \"2001:8b0::2022\",\n        \"2001:8b0::2023\",\n        \"2001:c50:ffff:1:101:101:101:101\",\n        \"210.17.9.228\",\n        \"217.169.20.22\",\n        \"217.169.20.23\",\n        \"2400:6180:0:d0::5f73:4001\",\n        \"2400:8902::f03c:91ff:feda:c514\",\n        \"2604:180:f3::42\",\n        \"2604:a880:1:20::51:f001\",\n        \"2606:4700::6810:f8f9\",\n        \"2606:4700::6810:f9f9\",\n        \"2606:4700::6812:1a80\",\n        \"2606:4700::6812:1b80\",\n        \"2606:4700::6812:237\",\n        \"2606:4700::6812:337\",\n        \"2606:4700:3033::6812:2ccc\",\n        \"2606:4700:3033::6812:2dcc\",\n        \"2606:4700:3033::6818:7b35\",\n        \"2606:4700:3034::681c:16a\",\n        \"2606:4700:3035::6818:7a35\",\n        \"2606:4700:3035::681f:5a8a\",\n        \"2606:4700:3036::681c:6a\",\n        \"2606:4700:3036::681f:5b8a\",\n        \"2606:4700:60:0:a71e:6467:cef8:2a56\",\n        \"2620:10a:80bb::10\",\n        \"2620:10a:80bb::20\",\n        \"2620:10a:80bb::30\" \"2620:10a:80bc::10\",\n        \"2620:10a:80bc::20\",\n        \"2620:10a:80bc::30\",\n        \"2620:119:fc::2\",\n        \"2620:119:fc::3\",\n        \"2620:fe::10\",\n        \"2620:fe::11\",\n        \"2620:fe::9\",\n        \"2620:fe::fe:10\",\n        \"2620:fe::fe:11\",\n        \"2620:fe::fe:9\",\n        \"2620:fe::fe\",\n        \"2a00:5a60::ad1:ff\",\n        \"2a00:5a60::ad2:ff\",\n        \"2a00:5a60::bad1:ff\",\n        \"2a00:5a60::bad2:ff\",\n        \"2a00:d880:5:bf0::7c93\",\n        \"2a01:4f8:1c0c:8233::1\",\n        \"2a01:4f8:1c1c:6b4b::1\",\n        \"2a01:4f8:c2c:52bf::1\",\n        \"2a01:4f9:c010:43ce::1\",\n        \"2a01:4f9:c01f:4::abcd\",\n        \"2a01:7c8:d002:1ef:5054:ff:fe40:3703\",\n        \"2a01:9e00::54\",\n        \"2a01:9e00::55\",\n        \"2a01:9e01::54\",\n        \"2a01:9e01::55\",\n        \"2a02:1205:34d5:5070:b26e:bfff:fe1d:e19b\",\n        \"2a03:4000:38:53c::2\",\n        \"2a03:b0c0:0:1010::e9a:3001\",\n        \"2a04:bdc7:100:70::abcd\",\n        \"2a05:fc84::42\",\n        \"2a05:fc84::43\",\n        \"2a07:a8c0::\",\n        \"2a0d:4d00:81::1\",\n        \"2a0d:5600:33:3::abcd\",\n        \"35.198.2.76\",\n        \"35.231.247.227\",\n        \"45.32.55.94\",\n        \"45.67.219.208\",\n        \"45.76.113.31\",\n        \"45.77.180.10\",\n        \"45.90.28.0\",\n        \"46.101.66.244\",\n        \"46.227.200.54\",\n        \"46.227.200.55\",\n        \"46.239.223.80\",\n        \"8.8.4.4\",\n        \"8.8.8.8\",\n        \"83.77.85.7\",\n        \"88.198.91.187\",\n        \"9.9.9.10\",\n        \"9.9.9.11\",\n        \"9.9.9.9\",\n        \"94.130.106.88\",\n        \"95.216.181.228\",\n        \"95.216.212.177\",\n        \"96.113.151.148\",\n    ],\n}\n\n# additional hostnames to block\nadditional_doh_names: list[str] = [\"dns.google.com\"]\n\n# additional IPs to block\nadditional_doh_ips: list[str] = []\n\ndoh_hostnames, doh_ips = default_blocklist[\"hostnames\"], default_blocklist[\"ips\"]\n\n# convert to sets for faster lookups\ndoh_hostnames = set(doh_hostnames)\ndoh_ips = set(doh_ips)\n\n\ndef _has_dns_message_content_type(flow):\n    \"\"\"\n    Check if HTTP request has a DNS-looking 'Content-Type' header\n\n    :param flow: mitmproxy flow\n    :return: True if 'Content-Type' header is DNS-looking, False otherwise\n    \"\"\"\n    doh_content_types = [\"application/dns-message\"]\n    if \"Content-Type\" in flow.request.headers:\n        if flow.request.headers[\"Content-Type\"] in doh_content_types:\n            return True\n    return False\n\n\ndef _request_has_dns_query_string(flow):\n    \"\"\"\n    Check if the query string of a request contains the parameter 'dns'\n\n    :param flow: mitmproxy flow\n    :return: True is 'dns' is a parameter in the query string, False otherwise\n    \"\"\"\n    return \"dns\" in flow.request.query\n\n\ndef _request_is_dns_json(flow):\n    \"\"\"\n    Check if the request looks like DoH with JSON.\n\n    The only known implementations of DoH with JSON are Cloudflare and Google.\n\n    For more info, see:\n    - https://developers.cloudflare.com/1.1.1.1/dns-over-https/json-format/\n    - https://developers.google.com/speed/public-dns/docs/doh/json\n\n    :param flow: mitmproxy flow\n    :return: True is request looks like DNS JSON, False otherwise\n    \"\"\"\n    # Header 'Accept: application/dns-json' is required in Cloudflare's DoH JSON API\n    # or they return a 400 HTTP response code\n    if \"Accept\" in flow.request.headers:\n        if flow.request.headers[\"Accept\"] == \"application/dns-json\":\n            return True\n    # Google's DoH JSON API is https://dns.google/resolve\n    path = flow.request.path.split(\"?\")[0]\n    if flow.request.host == \"dns.google\" and path == \"/resolve\":\n        return True\n    return False\n\n\ndef _request_has_doh_looking_path(flow):\n    \"\"\"\n    Check if the path looks like it's DoH.\n    Most common one is '/dns-query', likely because that's what's in the RFC\n\n    :param flow: mitmproxy flow\n    :return: True if path looks like it's DoH, otherwise False\n    \"\"\"\n    doh_paths = [\n        \"/dns-query\",  # used in example in RFC 8484 (see https://tools.ietf.org/html/rfc8484#section-4.1.1)\n    ]\n    path = flow.request.path.split(\"?\")[0]\n    return path in doh_paths\n\n\ndef _requested_hostname_is_in_doh_blocklist(flow):\n    \"\"\"\n    Check if server hostname is in our DoH provider blocklist.\n\n    The current blocklist is taken from https://github.com/curl/curl/wiki/DNS-over-HTTPS.\n\n    :param flow: mitmproxy flow\n    :return: True if server's hostname is in DoH blocklist, otherwise False\n    \"\"\"\n    hostname = flow.request.host\n    ip = flow.server_conn.address\n    return hostname in doh_hostnames or hostname in doh_ips or ip in doh_ips\n\n\ndoh_request_detection_checks = [\n    _has_dns_message_content_type,\n    _request_has_dns_query_string,\n    _request_is_dns_json,\n    _requested_hostname_is_in_doh_blocklist,\n    _request_has_doh_looking_path,\n]\n\n\ndef request(flow):\n    for check in doh_request_detection_checks:\n        is_doh = check(flow)\n        if is_doh:\n            logging.warning(\n                '[DoH Detection] DNS over HTTPS request detected via method \"%s\"'\n                % check.__name__\n            )\n            flow.kill()\n            break\n", "examples/contrib/change_upstream_proxy.py": "from mitmproxy import http\nfrom mitmproxy.connection import Server\nfrom mitmproxy.net.server_spec import ServerSpec\n\n# This scripts demonstrates how mitmproxy can switch to a second/different upstream proxy\n# in upstream proxy mode.\n#\n# Usage: mitmdump\n#   -s change_upstream_proxy.py\n#   --mode upstream:http://default-upstream-proxy:8080/\n#   --set connection_strategy=lazy\n#   --set upstream_cert=false\n#\n# If you want to change the target server, you should modify flow.request.host and flow.request.port\n\n\ndef proxy_address(flow: http.HTTPFlow) -> tuple[str, int]:\n    # Poor man's loadbalancing: route every second domain through the alternative proxy.\n    if hash(flow.request.host) % 2 == 1:\n        return (\"localhost\", 8082)\n    else:\n        return (\"localhost\", 8081)\n\n\ndef request(flow: http.HTTPFlow) -> None:\n    address = proxy_address(flow)\n\n    is_proxy_change = address != flow.server_conn.via.address\n    server_connection_already_open = flow.server_conn.timestamp_start is not None\n    if is_proxy_change and server_connection_already_open:\n        # server_conn already refers to an existing connection (which cannot be modified),\n        # so we need to replace it with a new server connection object.\n        flow.server_conn = Server(address=flow.server_conn.address)\n    flow.server_conn.via = ServerSpec((\"http\", address))\n", "examples/contrib/suppress_error_responses.py": "\"\"\"\nThis script suppresses the 502 Bad Gateway messages, mitmproxy sends if the server is not responsing correctly.\nFor example, this functionality can be helpful if mitmproxy is used in between a web scanner and a web application.\nWithout this script, if the web application under test crashes, mitmproxy will send 502 Bad Gateway responses.\nThese responses are irritating the web application scanner since they obfuscate the actual problem.\n\"\"\"\n\nfrom mitmproxy import http\nfrom mitmproxy.exceptions import HttpSyntaxException\n\n\ndef error(self, flow: http.HTTPFlow):\n    \"\"\"Kills the flow if it has an error different to HTTPSyntaxException.\n    Sometimes, web scanners generate malformed HTTP syntax on purpose and we do not want to kill these requests.\n    \"\"\"\n    if flow.error is not None and not isinstance(flow.error, HttpSyntaxException):\n        flow.kill()\n", "examples/contrib/domain_fronting.py": "import json\nfrom dataclasses import dataclass\n\nfrom mitmproxy import ctx\nfrom mitmproxy.addonmanager import Loader\nfrom mitmproxy.http import HTTPFlow\n\n\"\"\"\nThis extension implements support for domain fronting.\n\nUsage:\n\n   mitmproxy -s examples/contrib/domain_fronting.py --set domainfrontingfile=./domain_fronting.json\n\nIn the following basic example, www.example.com will be used for DNS requests and SNI values\nbut the secret.example.com value will be used for the HTTP host header:\n\n    {\n        \"mappings\": [\n            {\n                \"patterns\": [\"secret.example.com\"],\n                \"server\": \"www.example.com\"\n            }\n        ]\n    }\n\nThe following example demonstrates the usage of a wildcard (at the beginning of the domain name only):\n\n    {\n        \"mappings\": [\n            {\n                \"patterns\": [\"*.foo.example.com\"],\n                \"server\": \"www.example.com\"\n            }\n        ]\n    }\n\nIn the following example, we override the HTTP host header:\n\n    {\n        \"mappings\": [\n            {\n                \"patterns\": [\"foo.example\"],\n                \"server\": \"www.example.com\",\n                \"host\": \"foo.proxy.example.com\"\n            }\n        ]\n    }\n\n\"\"\"\n\n\n@dataclass\nclass Mapping:\n    server: str | None\n    host: str | None\n\n\nclass HttpsDomainFronting:\n    # configurations for regular (\"foo.example.com\") mappings:\n    star_mappings: dict[str, Mapping]\n\n    # Configurations for star (\"*.example.com\") mappings:\n    strict_mappings: dict[str, Mapping]\n\n    def __init__(self) -> None:\n        self.strict_mappings = {}\n        self.star_mappings = {}\n\n    def _resolve_addresses(self, host: str) -> Mapping | None:\n        mapping = self.strict_mappings.get(host)\n        if mapping is not None:\n            return mapping\n\n        index = 0\n        while True:\n            index = host.find(\".\", index)\n            if index == -1:\n                break\n            super_domain = host[(index + 1) :]\n            mapping = self.star_mappings.get(super_domain)\n            if mapping is not None:\n                return mapping\n            index += 1\n\n        return None\n\n    def load(self, loader: Loader) -> None:\n        loader.add_option(\n            name=\"domainfrontingfile\",\n            typespec=str,\n            default=\"./fronting.json\",\n            help=\"Domain fronting configuration file\",\n        )\n\n    def _load_configuration_file(self, filename: str) -> None:\n        config = json.load(open(filename))\n        strict_mappings: dict[str, Mapping] = {}\n        star_mappings: dict[str, Mapping] = {}\n        for mapping in config[\"mappings\"]:\n            item = Mapping(server=mapping.get(\"server\"), host=mapping.get(\"host\"))\n            for pattern in mapping[\"patterns\"]:\n                if pattern.startswith(\"*.\"):\n                    star_mappings[pattern[2:]] = item\n                else:\n                    strict_mappings[pattern] = item\n        self.strict_mappings = strict_mappings\n        self.star_mappings = star_mappings\n\n    def configure(self, updated: set[str]) -> None:\n        if \"domainfrontingfile\" in updated:\n            domain_fronting_file = ctx.options.domainfrontingfile\n            self._load_configuration_file(domain_fronting_file)\n\n    def request(self, flow: HTTPFlow) -> None:\n        if not flow.request.scheme == \"https\":\n            return\n        # We use the host header to dispatch the request:\n        target = flow.request.host_header\n        if target is None:\n            return\n        mapping = self._resolve_addresses(target)\n        if mapping is not None:\n            flow.request.host = mapping.server or target\n            flow.request.headers[\"host\"] = mapping.host or target\n\n\naddons = [HttpsDomainFronting()]\n", "examples/contrib/custom_next_layer.py": "\"\"\"\nThis addon demonstrates how to override next_layer to modify the protocol in use.\nIn this example, we are forcing connections to example.com:443 to instead go as plaintext\nto example.com:80.\n\nExample usage:\n\n    - mitmdump -s custom_next_layer.py\n    - curl -x localhost:8080 -k https://example.com\n\"\"\"\n\nimport logging\n\nfrom mitmproxy import ctx\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy import layers\n\n\ndef running():\n    # We change the connection strategy to lazy so that next_layer happens before we actually connect upstream.\n    # Alternatively we could also change the server address in `server_connect`.\n    ctx.options.connection_strategy = \"lazy\"\n\n\ndef next_layer(nextlayer: layer.NextLayer):\n    logging.info(\n        f\"{nextlayer.context=}\\n\"\n        f\"{nextlayer.data_client()[:70]=}\\n\"\n        f\"{nextlayer.data_server()[:70]=}\\n\"\n    )\n\n    if nextlayer.context.server.address == (\"example.com\", 443):\n        nextlayer.context.server.address = (\"example.com\", 80)\n\n        # We are disabling ALPN negotiation as our curl client would otherwise agree on HTTP/2,\n        # which our example server here does not accept for plaintext connections.\n        nextlayer.context.client.alpn = b\"\"\n\n        # We know all layers that come next: First negotiate TLS with the client, then do simple TCP passthrough.\n        # Setting only one layer here would also work, in that case next_layer would be called again after TLS establishment.\n        nextlayer.layer = layers.ClientTLSLayer(nextlayer.context)\n        nextlayer.layer.child_layer = layers.TCPLayer(nextlayer.context)\n", "examples/contrib/all_markers.py": "from mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy.utils import emoji\n\n\n@command.command(\"all.markers\")\ndef all_markers():\n    \"Create a new flow showing all marker values\"\n    for marker in emoji.emoji:\n        ctx.master.commands.call(\n            \"view.flows.create\", \"get\", f\"https://example.com/{marker}\"\n        )\n        ctx.master.commands.call(\"flow.mark\", [ctx.master.view[-1]], marker)\n", "examples/contrib/xss_scanner.py": "r\"\"\"\n\n __   __ _____ _____     _____\n \\ \\ / // ____/ ____|   / ____|\n  \\ V /| (___| (___    | (___   ___ __ _ _ __  _ __   ___ _ __\n   > <  \\___ \\\\___ \\    \\___ \\ / __/ _` | '_ \\| '_ \\ / _ \\ '__|\n  / . \\ ____) |___) |   ____) | (_| (_| | | | | | | |  __/ |\n /_/ \\_\\_____/_____/   |_____/ \\___\\__,_|_| |_|_| |_|\\___|_|\n\n\nThis script automatically scans all visited webpages for XSS and SQLi vulnerabilities.\n\nUsage: mitmproxy -s xss_scanner.py\n\nThis script scans for vulnerabilities by injecting a fuzzing payload (see PAYLOAD below) into 4 different places\nand examining the HTML to look for XSS and SQLi injection vulnerabilities. The XSS scanning functionality works by\nlooking to see whether it is possible to inject HTML based off of of where the payload appears in the page and what\ncharacters are escaped. In addition, it also looks for any script tags that load javascript from unclaimed domains.\nThe SQLi scanning functionality works by using regular expressions to look for errors from a number of different\ncommon databases. Since it is only looking for errors, it will not find blind SQLi vulnerabilities.\n\nThe 4 places it injects the payload into are:\n1. URLs         (e.g. https://example.com/ -> https://example.com/PAYLOAD/)\n2. Queries      (e.g. https://example.com/index.html?a=b -> https://example.com/index.html?a=PAYLOAD)\n3. Referers     (e.g. The referer changes from https://example.com to PAYLOAD)\n4. User Agents  (e.g. The UA changes from Chrome to PAYLOAD)\n\nReports from this script show up in the event log (viewable by pressing e) and formatted like:\n\n===== XSS Found ====\nXSS URL: http://daviddworken.com/vulnerableUA.php\nInjection Point: User Agent\nSuggested Exploit: <script>alert(0)</script>\nLine: 1029zxcs'd\"ao<ac>so[sb]po(pc)se;sl/bsl\\eq=3847asd\n\n\"\"\"\n\nimport logging\nimport re\nimport socket\nfrom html.parser import HTMLParser\nfrom typing import NamedTuple\nfrom typing import Optional\nfrom urllib.parse import urlparse\n\nimport requests\n\nfrom mitmproxy import http\n\n# The actual payload is put between a frontWall and a backWall to make it easy\n# to locate the payload with regular expressions\nFRONT_WALL = b\"1029zxc\"\nBACK_WALL = b\"3847asd\"\nPAYLOAD = b\"\"\"s'd\"ao<ac>so[sb]po(pc)se;sl/bsl\\\\eq=\"\"\"\nFULL_PAYLOAD = FRONT_WALL + PAYLOAD + BACK_WALL\n\n\n# A XSSData is a named tuple with the following fields:\n#   - url -> str\n#   - injection_point -> str\n#   - exploit -> str\n#   - line -> str\nclass XSSData(NamedTuple):\n    url: str\n    injection_point: str\n    exploit: str\n    line: str\n\n\n# A SQLiData is named tuple with the following fields:\n#   - url -> str\n#   - injection_point -> str\n#   - regex -> str\n#   - dbms -> str\nclass SQLiData(NamedTuple):\n    url: str\n    injection_point: str\n    regex: str\n    dbms: str\n\n\nVulnData = tuple[Optional[XSSData], Optional[SQLiData]]\nCookies = dict[str, str]\n\n\ndef get_cookies(flow: http.HTTPFlow) -> Cookies:\n    \"\"\"Return a dict going from cookie names to cookie values\n    - Note that it includes both the cookies sent in the original request and\n      the cookies sent by the server\"\"\"\n    return {name: value for name, value in flow.request.cookies.fields}\n\n\ndef find_unclaimed_URLs(body, requestUrl):\n    \"\"\"Look for unclaimed URLs in script tags and log them if found\"\"\"\n\n    def getValue(attrs: list[tuple[str, str]], attrName: str) -> str | None:\n        for name, value in attrs:\n            if attrName == name:\n                return value\n        return None\n\n    class ScriptURLExtractor(HTMLParser):\n        script_URLs: list[str] = []\n\n        def handle_starttag(self, tag, attrs):\n            if (tag == \"script\" or tag == \"iframe\") and \"src\" in [\n                name for name, value in attrs\n            ]:\n                self.script_URLs.append(getValue(attrs, \"src\"))\n            if (\n                tag == \"link\"\n                and getValue(attrs, \"rel\") == \"stylesheet\"\n                and \"href\" in [name for name, value in attrs]\n            ):\n                self.script_URLs.append(getValue(attrs, \"href\"))\n\n    parser = ScriptURLExtractor()\n    parser.feed(body)\n    for url in parser.script_URLs:\n        url_parser = urlparse(url)\n        domain = url_parser.netloc\n        try:\n            socket.gethostbyname(domain)\n        except socket.gaierror:\n            logging.error(f'XSS found in {requestUrl} due to unclaimed URL \"{url}\".')\n\n\ndef test_end_of_URL_injection(\n    original_body: str, request_URL: str, cookies: Cookies\n) -> VulnData:\n    \"\"\"Test the given URL for XSS via injection onto the end of the URL and\n    log the XSS if found\"\"\"\n    parsed_URL = urlparse(request_URL)\n    path = parsed_URL.path\n    if path != \"\" and path[-1] != \"/\":  # ensure the path ends in a /\n        path += \"/\"\n    path += FULL_PAYLOAD.decode(\n        \"utf-8\"\n    )  # the path must be a string while the payload is bytes\n    url = parsed_URL._replace(path=path).geturl()\n    body = requests.get(url, cookies=cookies).text.lower()\n    xss_info = get_XSS_data(body, url, \"End of URL\")\n    sqli_info = get_SQLi_data(body, original_body, url, \"End of URL\")\n    return xss_info, sqli_info\n\n\ndef test_referer_injection(\n    original_body: str, request_URL: str, cookies: Cookies\n) -> VulnData:\n    \"\"\"Test the given URL for XSS via injection into the referer and\n    log the XSS if found\"\"\"\n    body = requests.get(\n        request_URL, headers={\"referer\": FULL_PAYLOAD}, cookies=cookies\n    ).text.lower()\n    xss_info = get_XSS_data(body, request_URL, \"Referer\")\n    sqli_info = get_SQLi_data(body, original_body, request_URL, \"Referer\")\n    return xss_info, sqli_info\n\n\ndef test_user_agent_injection(\n    original_body: str, request_URL: str, cookies: Cookies\n) -> VulnData:\n    \"\"\"Test the given URL for XSS via injection into the user agent and\n    log the XSS if found\"\"\"\n    body = requests.get(\n        request_URL, headers={\"User-Agent\": FULL_PAYLOAD}, cookies=cookies\n    ).text.lower()\n    xss_info = get_XSS_data(body, request_URL, \"User Agent\")\n    sqli_info = get_SQLi_data(body, original_body, request_URL, \"User Agent\")\n    return xss_info, sqli_info\n\n\ndef test_query_injection(original_body: str, request_URL: str, cookies: Cookies):\n    \"\"\"Test the given URL for XSS via injection into URL queries and\n    log the XSS if found\"\"\"\n    parsed_URL = urlparse(request_URL)\n    query_string = parsed_URL.query\n    # queries is a list of parameters where each parameter is set to the payload\n    queries = [\n        query.split(\"=\")[0] + \"=\" + FULL_PAYLOAD.decode(\"utf-8\")\n        for query in query_string.split(\"&\")\n    ]\n    new_query_string = \"&\".join(queries)\n    new_URL = parsed_URL._replace(query=new_query_string).geturl()\n    body = requests.get(new_URL, cookies=cookies).text.lower()\n    xss_info = get_XSS_data(body, new_URL, \"Query\")\n    sqli_info = get_SQLi_data(body, original_body, new_URL, \"Query\")\n    return xss_info, sqli_info\n\n\ndef log_XSS_data(xss_info: XSSData | None) -> None:\n    \"\"\"Log information about the given XSS to mitmproxy\"\"\"\n    # If it is None, then there is no info to log\n    if not xss_info:\n        return\n    logging.error(\"===== XSS Found ====\")\n    logging.error(\"XSS URL: %s\" % xss_info.url)\n    logging.error(\"Injection Point: %s\" % xss_info.injection_point)\n    logging.error(\"Suggested Exploit: %s\" % xss_info.exploit)\n    logging.error(\"Line: %s\" % xss_info.line)\n\n\ndef log_SQLi_data(sqli_info: SQLiData | None) -> None:\n    \"\"\"Log information about the given SQLi to mitmproxy\"\"\"\n    if not sqli_info:\n        return\n    logging.error(\"===== SQLi Found =====\")\n    logging.error(\"SQLi URL: %s\" % sqli_info.url)\n    logging.error(\"Injection Point: %s\" % sqli_info.injection_point)\n    logging.error(\"Regex used: %s\" % sqli_info.regex)\n    logging.error(\"Suspected DBMS: %s\" % sqli_info.dbms)\n    return\n\n\ndef get_SQLi_data(\n    new_body: str, original_body: str, request_URL: str, injection_point: str\n) -> SQLiData | None:\n    \"\"\"Return a SQLiDict if there is a SQLi otherwise return None\n    String String URL String -> (SQLiDict or None)\"\"\"\n    # Regexes taken from Damn Small SQLi Scanner: https://github.com/stamparm/DSSS/blob/master/dsss.py#L17\n    DBMS_ERRORS = {\n        \"MySQL\": (\n            r\"SQL syntax.*MySQL\",\n            r\"Warning.*mysql_.*\",\n            r\"valid MySQL result\",\n            r\"MySqlClient\\.\",\n        ),\n        \"PostgreSQL\": (\n            r\"PostgreSQL.*ERROR\",\n            r\"Warning.*\\Wpg_.*\",\n            r\"valid PostgreSQL result\",\n            r\"Npgsql\\.\",\n        ),\n        \"Microsoft SQL Server\": (\n            r\"Driver.* SQL[\\-\\_\\ ]*Server\",\n            r\"OLE DB.* SQL Server\",\n            r\"(\\W|\\A)SQL Server.*Driver\",\n            r\"Warning.*mssql_.*\",\n            r\"(\\W|\\A)SQL Server.*[0-9a-fA-F]{8}\",\n            r\"(?s)Exception.*\\WSystem\\.Data\\.SqlClient\\.\",\n            r\"(?s)Exception.*\\WRoadhouse\\.Cms\\.\",\n        ),\n        \"Microsoft Access\": (\n            r\"Microsoft Access Driver\",\n            r\"JET Database Engine\",\n            r\"Access Database Engine\",\n        ),\n        \"Oracle\": (\n            r\"\\bORA-[0-9][0-9][0-9][0-9]\",\n            r\"Oracle error\",\n            r\"Oracle.*Driver\",\n            r\"Warning.*\\Woci_.*\",\n            r\"Warning.*\\Wora_.*\",\n        ),\n        \"IBM DB2\": (r\"CLI Driver.*DB2\", r\"DB2 SQL error\", r\"\\bdb2_\\w+\\(\"),\n        \"SQLite\": (\n            r\"SQLite/JDBCDriver\",\n            r\"SQLite.Exception\",\n            r\"System.Data.SQLite.SQLiteException\",\n            r\"Warning.*sqlite_.*\",\n            r\"Warning.*SQLite3::\",\n            r\"\\[SQLITE_ERROR\\]\",\n        ),\n        \"Sybase\": (\n            r\"(?i)Warning.*sybase.*\",\n            r\"Sybase message\",\n            r\"Sybase.*Server message.*\",\n        ),\n    }\n    for dbms, regexes in DBMS_ERRORS.items():\n        for regex in regexes:  # type: ignore\n            if re.search(regex, new_body, re.IGNORECASE) and not re.search(\n                regex, original_body, re.IGNORECASE\n            ):\n                return SQLiData(request_URL, injection_point, regex, dbms)\n    return None\n\n\n# A qc is either ' or \"\ndef inside_quote(\n    qc: str, substring_bytes: bytes, text_index: int, body_bytes: bytes\n) -> bool:\n    \"\"\"Whether the Numberth occurrence of the first string in the second\n    string is inside quotes as defined by the supplied QuoteChar\"\"\"\n    substring = substring_bytes.decode(\"utf-8\")\n    body = body_bytes.decode(\"utf-8\")\n    num_substrings_found = 0\n    in_quote = False\n    for index, char in enumerate(body):\n        # Whether the next chunk of len(substring) chars is the substring\n        next_part_is_substring = (not (index + len(substring) > len(body))) and (\n            body[index : index + len(substring)] == substring\n        )\n        # Whether this char is escaped with a \\\n        is_not_escaped = (index - 1 < 0 or index - 1 > len(body)) or (\n            body[index - 1] != \"\\\\\"\n        )\n        if char == qc and is_not_escaped:\n            in_quote = not in_quote\n        if next_part_is_substring:\n            if num_substrings_found == text_index:\n                return in_quote\n            num_substrings_found += 1\n    return False\n\n\ndef paths_to_text(html: str, string: str) -> list[str]:\n    \"\"\"Return list of Paths to a given str in the given HTML tree\n    - Note that it does a BFS\"\"\"\n\n    def remove_last_occurence_of_sub_string(string: str, substr: str) -> str:\n        \"\"\"Delete the last occurrence of substr from str\n        String String -> String\n        \"\"\"\n        index = string.rfind(substr)\n        return string[:index] + string[index + len(substr) :]\n\n    class PathHTMLParser(HTMLParser):\n        currentPath = \"\"\n        paths: list[str] = []\n\n        def handle_starttag(self, tag, attrs):\n            self.currentPath += \"/\" + tag\n\n        def handle_endtag(self, tag):\n            self.currentPath = remove_last_occurence_of_sub_string(\n                self.currentPath, \"/\" + tag\n            )\n\n        def handle_data(self, data):\n            if string in data:\n                self.paths.append(self.currentPath)\n\n    parser = PathHTMLParser()\n    parser.feed(html)\n    return parser.paths\n\n\ndef get_XSS_data(\n    body: str | bytes, request_URL: str, injection_point: str\n) -> XSSData | None:\n    \"\"\"Return a XSSDict if there is a XSS otherwise return None\"\"\"\n\n    def in_script(text, index, body) -> bool:\n        \"\"\"Whether the Numberth occurrence of the first string in the second\n        string is inside a script tag\"\"\"\n        paths = paths_to_text(body.decode(\"utf-8\"), text.decode(\"utf-8\"))\n        try:\n            path = paths[index]\n            return \"script\" in path\n        except IndexError:\n            return False\n\n    def in_HTML(text: bytes, index: int, body: bytes) -> bool:\n        \"\"\"Whether the Numberth occurrence of the first string in the second\n        string is inside the HTML but not inside a script tag or part of\n        a HTML attribute\"\"\"\n        # if there is a < then lxml will interpret that as a tag, so only search for the stuff before it\n        text = text.split(b\"<\")[0]\n        paths = paths_to_text(body.decode(\"utf-8\"), text.decode(\"utf-8\"))\n        try:\n            path = paths[index]\n            return \"script\" not in path\n        except IndexError:\n            return False\n\n    def inject_javascript_handler(html: str) -> bool:\n        \"\"\"Whether you can inject a Javascript:alert(0) as a link\"\"\"\n\n        class injectJSHandlerHTMLParser(HTMLParser):\n            injectJSHandler = False\n\n            def handle_starttag(self, tag, attrs):\n                for name, value in attrs:\n                    if name == \"href\" and value.startswith(FRONT_WALL.decode(\"utf-8\")):\n                        self.injectJSHandler = True\n\n        parser = injectJSHandlerHTMLParser()\n        parser.feed(html)\n        return parser.injectJSHandler\n\n    # Only convert the body to bytes if needed\n    if isinstance(body, str):\n        body = bytes(body, \"utf-8\")\n    # Regex for between 24 and 72 (aka 24*3) characters encapsulated by the walls\n    regex = re.compile(b\"\"\"%s.{24,72}?%s\"\"\" % (FRONT_WALL, BACK_WALL))\n    matches = regex.findall(body)\n    for index, match in enumerate(matches):\n        # Where the string is injected into the HTML\n        in_script_val = in_script(match, index, body)\n        in_HTML_val = in_HTML(match, index, body)\n        in_tag = not in_script_val and not in_HTML_val\n        in_single_quotes = inside_quote(\"'\", match, index, body)\n        in_double_quotes = inside_quote('\"', match, index, body)\n        # Whether you can inject:\n        inject_open_angle = b\"ao<ac\" in match  # open angle brackets\n        inject_close_angle = b\"ac>so\" in match  # close angle brackets\n        inject_single_quotes = b\"s'd\" in match  # single quotes\n        inject_double_quotes = b'd\"ao' in match  # double quotes\n        inject_slash = b\"sl/bsl\" in match  # forward slashes\n        inject_semi = b\"se;sl\" in match  # semicolons\n        inject_equals = b\"eq=\" in match  # equals sign\n        if (\n            in_script_val and inject_slash and inject_open_angle and inject_close_angle\n        ):  # e.g. <script>PAYLOAD</script>\n            return XSSData(\n                request_URL,\n                injection_point,\n                \"</script><script>alert(0)</script><script>\",\n                match.decode(\"utf-8\"),\n            )\n        elif (\n            in_script_val and in_single_quotes and inject_single_quotes and inject_semi\n        ):  # e.g. <script>t='PAYLOAD';</script>\n            return XSSData(\n                request_URL, injection_point, \"';alert(0);g='\", match.decode(\"utf-8\")\n            )\n        elif (\n            in_script_val and in_double_quotes and inject_double_quotes and inject_semi\n        ):  # e.g. <script>t=\"PAYLOAD\";</script>\n            return XSSData(\n                request_URL, injection_point, '\";alert(0);g=\"', match.decode(\"utf-8\")\n            )\n        elif (\n            in_tag\n            and in_single_quotes\n            and inject_single_quotes\n            and inject_open_angle\n            and inject_close_angle\n            and inject_slash\n        ):\n            # e.g. <a href='PAYLOAD'>Test</a>\n            return XSSData(\n                request_URL,\n                injection_point,\n                \"'><script>alert(0)</script>\",\n                match.decode(\"utf-8\"),\n            )\n        elif (\n            in_tag\n            and in_double_quotes\n            and inject_double_quotes\n            and inject_open_angle\n            and inject_close_angle\n            and inject_slash\n        ):\n            # e.g. <a href=\"PAYLOAD\">Test</a>\n            return XSSData(\n                request_URL,\n                injection_point,\n                '\"><script>alert(0)</script>',\n                match.decode(\"utf-8\"),\n            )\n        elif (\n            in_tag\n            and not in_double_quotes\n            and not in_single_quotes\n            and inject_open_angle\n            and inject_close_angle\n            and inject_slash\n        ):\n            # e.g. <a href=PAYLOAD>Test</a>\n            return XSSData(\n                request_URL,\n                injection_point,\n                \"><script>alert(0)</script>\",\n                match.decode(\"utf-8\"),\n            )\n        elif inject_javascript_handler(\n            body.decode(\"utf-8\")\n        ):  # e.g. <html><a href=PAYLOAD>Test</a>\n            return XSSData(\n                request_URL,\n                injection_point,\n                \"Javascript:alert(0)\",\n                match.decode(\"utf-8\"),\n            )\n        elif (\n            in_tag and in_double_quotes and inject_double_quotes and inject_equals\n        ):  # e.g. <a href=\"PAYLOAD\">Test</a>\n            return XSSData(\n                request_URL,\n                injection_point,\n                '\" onmouseover=\"alert(0)\" t=\"',\n                match.decode(\"utf-8\"),\n            )\n        elif (\n            in_tag and in_single_quotes and inject_single_quotes and inject_equals\n        ):  # e.g. <a href='PAYLOAD'>Test</a>\n            return XSSData(\n                request_URL,\n                injection_point,\n                \"' onmouseover='alert(0)' t='\",\n                match.decode(\"utf-8\"),\n            )\n        elif (\n            in_tag and not in_single_quotes and not in_double_quotes and inject_equals\n        ):  # e.g. <a href=PAYLOAD>Test</a>\n            return XSSData(\n                request_URL,\n                injection_point,\n                \" onmouseover=alert(0) t=\",\n                match.decode(\"utf-8\"),\n            )\n        elif (\n            in_HTML_val\n            and not in_script_val\n            and inject_open_angle\n            and inject_close_angle\n            and inject_slash\n        ):  # e.g. <html>PAYLOAD</html>\n            return XSSData(\n                request_URL,\n                injection_point,\n                \"<script>alert(0)</script>\",\n                match.decode(\"utf-8\"),\n            )\n        else:\n            return None\n    return None\n\n\n# response is mitmproxy's entry point\ndef response(flow: http.HTTPFlow) -> None:\n    assert flow.response\n    cookies_dict = get_cookies(flow)\n    resp = flow.response.get_text(strict=False)\n    assert resp\n    # Example: http://xss.guru/unclaimedScriptTag.html\n    find_unclaimed_URLs(resp, flow.request.url)\n    results = test_end_of_URL_injection(resp, flow.request.url, cookies_dict)\n    log_XSS_data(results[0])\n    log_SQLi_data(results[1])\n    # Example: https://daviddworken.com/vulnerableReferer.php\n    results = test_referer_injection(resp, flow.request.url, cookies_dict)\n    log_XSS_data(results[0])\n    log_SQLi_data(results[1])\n    # Example: https://daviddworken.com/vulnerableUA.php\n    results = test_user_agent_injection(resp, flow.request.url, cookies_dict)\n    log_XSS_data(results[0])\n    log_SQLi_data(results[1])\n    if \"?\" in flow.request.url:\n        # Example: https://daviddworken.com/vulnerable.php?name=\n        results = test_query_injection(resp, flow.request.url, cookies_dict)\n        log_XSS_data(results[0])\n        log_SQLi_data(results[1])\n", "examples/contrib/http_manipulate_cookies.py": "\"\"\"\nThis script is an example of how to manipulate cookies both outgoing (requests)\nand ingoing (responses). In particular, this script inserts a cookie (specified\nin a json file) into every request (overwriting any existing cookie of the same\nname), and removes cookies from every response that have a certain set of names\nspecified in the variable (set) FILTER_COOKIES.\n\nUsage:\n\n    mitmproxy -s examples/contrib/http_manipulate_cookies.py\n\nNote:\n    this was created as a response to SO post:\n    https://stackoverflow.com/questions/55358072/cookie-manipulation-in-mitmproxy-requests-and-responses\n\n\"\"\"\n\nimport json\n\nfrom mitmproxy import http\n\nPATH_TO_COOKIES = \"./cookies.json\"  # insert your path to the cookie file here\nFILTER_COOKIES = {\n    \"mycookie\",\n    \"_ga\",\n}  # update this to the specific cookie names you want to remove\n# NOTE: use a set for lookup efficiency\n\n\n# -- Helper functions --\ndef load_json_cookies() -> list[dict[str, str | None]]:\n    \"\"\"\n    Load a particular json file containing a list of cookies.\n    \"\"\"\n    with open(PATH_TO_COOKIES) as f:\n        return json.load(f)\n\n\n# NOTE: or just hardcode the cookies as [{\"name\": \"\", \"value\": \"\"}]\n\n\ndef stringify_cookies(cookies: list[dict[str, str | None]]) -> str:\n    \"\"\"\n    Creates a cookie string from a list of cookie dicts.\n    \"\"\"\n    return \"; \".join(\n        [\n            f\"{c['name']}={c['value']}\"\n            if c.get(\"value\", None) is not None\n            else f\"{c['name']}\"\n            for c in cookies\n        ]\n    )\n\n\ndef parse_cookies(cookie_string: str) -> list[dict[str, str | None]]:\n    \"\"\"\n    Parses a cookie string into a list of cookie dicts.\n    \"\"\"\n    return [\n        {\"name\": g[0], \"value\": g[1]} if len(g) == 2 else {\"name\": g[0], \"value\": None}\n        for g in [\n            k.split(\"=\", 1) for k in [c.strip() for c in cookie_string.split(\";\")] if k\n        ]\n    ]\n\n\n# -- Main interception functionality --\ndef request(flow: http.HTTPFlow) -> None:\n    \"\"\"Add a specific set of cookies to every request.\"\"\"\n    # obtain any cookies from the request\n    _req_cookies_str = flow.request.headers.get(\"cookie\", \"\")\n    req_cookies = parse_cookies(_req_cookies_str)\n\n    # add our cookies to the original cookies from the request\n    all_cookies = req_cookies + load_json_cookies()\n    # NOTE: by adding it to the end we should overwrite any existing cookies\n    # of the same name but if you want to be more careful you can iterate over\n    # the req_cookies and remove the ones you want to overwrite first.\n\n    # modify the request with the combined cookies\n    flow.request.headers[\"cookie\"] = stringify_cookies(all_cookies)\n\n\ndef response(flow: http.HTTPFlow) -> None:\n    \"\"\"Remove a specific cookie from every response.\"\"\"\n    set_cookies_str = flow.response.headers.get_all(\"set-cookie\")\n    # NOTE: According to docs, for use with the \"Set-Cookie\" and \"Cookie\" headers, either use `Response.cookies` or see `Headers.get_all`.\n    set_cookies_str_modified: list[str] = []\n\n    if set_cookies_str:\n        for cookie in set_cookies_str:\n            resp_cookies = parse_cookies(cookie)\n\n            # remove the cookie we want to remove\n            resp_cookies = [c for c in resp_cookies if c[\"name\"] not in FILTER_COOKIES]\n\n            # append the modified cookies to the list that will change the requested cookies\n            set_cookies_str_modified.append(stringify_cookies(resp_cookies))\n\n        # modify the request with the combined cookies\n        flow.response.headers.set_all(\"set-cookie\", set_cookies_str_modified)\n", "examples/contrib/sslstrip.py": "\"\"\"\nThis script implements an sslstrip-like attack based on mitmproxy.\nhttps://moxie.org/software/sslstrip/\n\"\"\"\n\nimport re\nimport urllib.parse\n\nfrom mitmproxy import http\n\n# set of SSL/TLS capable hosts\nsecure_hosts: set[str] = set()\n\n\ndef request(flow: http.HTTPFlow) -> None:\n    flow.request.headers.pop(\"If-Modified-Since\", None)\n    flow.request.headers.pop(\"Cache-Control\", None)\n\n    # do not force https redirection\n    flow.request.headers.pop(\"Upgrade-Insecure-Requests\", None)\n\n    # proxy connections to SSL-enabled hosts\n    if flow.request.pretty_host in secure_hosts:\n        flow.request.scheme = \"https\"\n        flow.request.port = 443\n\n        # We need to update the request destination to whatever is specified in the host header:\n        # Having no TLS Server Name Indication from the client and just an IP address as request.host\n        # in transparent mode, TLS server name certificate validation would fail.\n        flow.request.host = flow.request.pretty_host\n\n\ndef response(flow: http.HTTPFlow) -> None:\n    assert flow.response\n    flow.response.headers.pop(\"Strict-Transport-Security\", None)\n    flow.response.headers.pop(\"Public-Key-Pins\", None)\n\n    # strip links in response body\n    flow.response.content = flow.response.content.replace(b\"https://\", b\"http://\")\n\n    # strip meta tag upgrade-insecure-requests in response body\n    csp_meta_tag_pattern = rb'<meta.*http-equiv=[\"\\']Content-Security-Policy[\\'\"].*upgrade-insecure-requests.*?>'\n    flow.response.content = re.sub(\n        csp_meta_tag_pattern, b\"\", flow.response.content, flags=re.IGNORECASE\n    )\n\n    # strip links in 'Location' header\n    if flow.response.headers.get(\"Location\", \"\").startswith(\"https://\"):\n        location = flow.response.headers[\"Location\"]\n        hostname = urllib.parse.urlparse(location).hostname\n        if hostname:\n            secure_hosts.add(hostname)\n        flow.response.headers[\"Location\"] = location.replace(\"https://\", \"http://\", 1)\n\n    # strip upgrade-insecure-requests in Content-Security-Policy header\n    csp_header = flow.response.headers.get(\"Content-Security-Policy\", \"\")\n    if re.search(\"upgrade-insecure-requests\", csp_header, flags=re.IGNORECASE):\n        csp = flow.response.headers[\"Content-Security-Policy\"]\n        new_header = re.sub(\n            r\"upgrade-insecure-requests[;\\s]*\", \"\", csp, flags=re.IGNORECASE\n        )\n        flow.response.headers[\"Content-Security-Policy\"] = new_header\n\n    # strip secure flag from 'Set-Cookie' headers\n    cookies = flow.response.headers.get_all(\"Set-Cookie\")\n    cookies = [re.sub(r\";\\s*secure\\s*\", \"\", s) for s in cookies]\n    flow.response.headers.set_all(\"Set-Cookie\", cookies)\n", "examples/contrib/modify_body_inject_iframe.py": "# (this script works best with --anticache)\nfrom bs4 import BeautifulSoup\n\nfrom mitmproxy import ctx\nfrom mitmproxy import http\n\n\nclass Injector:\n    def load(self, loader):\n        loader.add_option(\"iframe\", str, \"\", \"IFrame to inject\")\n\n    def response(self, flow: http.HTTPFlow) -> None:\n        if ctx.options.iframe:\n            html = BeautifulSoup(flow.response.content, \"html.parser\")\n            if html.body:\n                iframe = html.new_tag(\n                    \"iframe\", src=ctx.options.iframe, frameborder=0, height=0, width=0\n                )\n                html.body.insert(0, iframe)\n                flow.response.content = str(html).encode(\"utf8\")\n\n\naddons = [Injector()]\n", "examples/contrib/httpdump.py": "#!/usr/bin/env python\n# dump content to files based on a filter\n# usage: mitmdump -s httpdump.py \"~ts application/json\"\n#\n# options:\n#   - dumper_folder: content dump destination folder (default: ./httpdump)\n#   - open_browser: open integrated browser with proxy configured at start (default: true)\n#\n# remember to add your own mitmproxy authoritative certs in your browser/os!\n# certs docs: https://docs.mitmproxy.org/stable/concepts-certificates/\n# filter expressions docs: https://docs.mitmproxy.org/stable/concepts-filters/\nimport logging\nimport mimetypes\nimport os\nfrom pathlib import Path\n\nfrom mitmproxy import ctx\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\n\n\nclass HTTPDump:\n    def load(self, loader):\n        self.filter = ctx.options.dumper_filter\n\n        loader.add_option(\n            name=\"dumper_folder\",\n            typespec=str,\n            default=\"httpdump\",\n            help=\"content dump destination folder\",\n        )\n        loader.add_option(\n            name=\"open_browser\",\n            typespec=bool,\n            default=True,\n            help=\"open integrated browser at start\",\n        )\n\n    def running(self):\n        if ctx.options.open_browser:\n            ctx.master.commands.call(\"browser.start\")\n\n    def configure(self, updated):\n        if \"dumper_filter\" in updated:\n            self.filter = ctx.options.dumper_filter\n\n    def response(self, flow: http.HTTPFlow) -> None:\n        if flowfilter.match(self.filter, flow):\n            self.dump(flow)\n\n    def dump(self, flow: http.HTTPFlow):\n        if not flow.response:\n            return\n\n        # create dir\n        folder = Path(ctx.options.dumper_folder) / flow.request.host\n        if not folder.exists():\n            os.makedirs(folder)\n\n        # calculate path\n        path = \"-\".join(flow.request.path_components)\n        filename = \"-\".join([path, flow.id])\n        content_type = flow.response.headers.get(\"content-type\", \"\").split(\";\")[0]\n        ext = mimetypes.guess_extension(content_type) or \"\"\n        filepath = folder / f\"{filename}{ext}\"\n\n        # dump to file\n        if flow.response.content:\n            with open(filepath, \"wb\") as f:\n                f.write(flow.response.content)\n            logging.info(f\"Saved! {filepath}\")\n\n\naddons = [HTTPDump()]\n", "examples/contrib/webscanner_helper/urlindex.py": "import abc\nimport datetime\nimport json\nimport logging\nfrom pathlib import Path\n\nfrom mitmproxy import flowfilter\nfrom mitmproxy.http import HTTPFlow\n\nlogger = logging.getLogger(__name__)\n\n\nclass UrlIndexWriter(abc.ABC):\n    \"\"\"Abstract Add-on to write seen URLs.\n\n    For example, these URLs can be injected in a web application to improve the crawling of web application scanners.\n    The injection can be done using the URLInjection Add-on.\n    \"\"\"\n\n    def __init__(self, filename: Path):\n        \"\"\"Initializes the UrlIndexWriter.\n\n        Args:\n            filename: Path to file to which the URL index will be written.\n        \"\"\"\n        self.filepath = filename\n\n    @abc.abstractmethod\n    def load(self):\n        \"\"\"Load existing URL index.\"\"\"\n\n    @abc.abstractmethod\n    def add_url(self, flow: HTTPFlow):\n        \"\"\"Add new URL to URL index.\"\"\"\n\n    @abc.abstractmethod\n    def save(self):\n        pass\n\n\nclass SetEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, set):\n            return list(obj)\n        return json.JSONEncoder.default(self, obj)\n\n\nclass JSONUrlIndexWriter(UrlIndexWriter):\n    \"\"\"Writes seen URLs as JSON.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.host_urls = {}\n\n    def load(self):\n        if self.filepath.exists():\n            with self.filepath.open(\"r\") as f:\n                self.host_urls = json.load(f)\n            for host in self.host_urls.keys():\n                for path, methods in self.host_urls[host].items():\n                    for method, codes in methods.items():\n                        self.host_urls[host][path] = {method: set(codes)}\n\n    def add_url(self, flow: HTTPFlow):\n        req = flow.request\n        res = flow.response\n\n        if req is not None and res is not None:\n            urls = self.host_urls.setdefault(\n                f\"{req.scheme}://{req.host}:{req.port}\", dict()\n            )\n            methods = urls.setdefault(req.path, {})\n            codes = methods.setdefault(req.method, set())\n            codes.add(res.status_code)\n\n    def save(self):\n        with self.filepath.open(\"w\") as f:\n            json.dump(self.host_urls, f, cls=SetEncoder)\n\n\nclass TextUrlIndexWriter(UrlIndexWriter):\n    \"\"\"Writes seen URLs as text.\"\"\"\n\n    def load(self):\n        pass\n\n    def add_url(self, flow: HTTPFlow):\n        res = flow.response\n        req = flow.request\n        if res is not None and req is not None:\n            with self.filepath.open(\"a+\") as f:\n                f.write(\n                    f\"{datetime.datetime.utcnow().isoformat()} STATUS: {res.status_code} METHOD: \"\n                    f\"{req.method} URL:{req.url}\\n\"\n                )\n\n    def save(self):\n        pass\n\n\nWRITER: dict[str, type[UrlIndexWriter]] = {\n    \"json\": JSONUrlIndexWriter,\n    \"text\": TextUrlIndexWriter,\n}\n\n\ndef filter_404(flow) -> bool:\n    \"\"\"Filters responses with status code 404.\"\"\"\n    return flow.response.status_code != 404\n\n\nclass UrlIndexAddon:\n    \"\"\"Add-on to write seen URLs, either as JSON or as text.\n\n    For example, these URLs can be injected in a web application to improve the crawling of web application scanners.\n    The injection can be done using the URLInjection Add-on.\n    \"\"\"\n\n    index_filter: str | flowfilter.TFilter | None\n    writer: UrlIndexWriter\n\n    OPT_FILEPATH = \"URLINDEX_FILEPATH\"\n    OPT_APPEND = \"URLINDEX_APPEND\"\n    OPT_INDEX_FILTER = \"URLINDEX_FILTER\"\n\n    def __init__(\n        self,\n        file_path: str | Path,\n        append: bool = True,\n        index_filter: str | flowfilter.TFilter = filter_404,\n        index_format: str = \"json\",\n    ):\n        \"\"\"Initializes the urlindex add-on.\n\n        Args:\n            file_path: Path to file to which the URL index will be written. Can either be given as str or Path.\n            append: Bool to decide whether to append new URLs to the given file (as opposed to overwrite the contents\n                of the file)\n            index_filer: A mitmproxy filter with which the seen URLs will be filtered before being written. Can either\n                be given as str or as flowfilter.TFilter\n            index_format: The format of the URL index, can either be \"json\" or \"text\".\n        \"\"\"\n\n        if isinstance(index_filter, str):\n            self.index_filter = flowfilter.parse(index_filter)\n            if self.index_filter is None:\n                raise ValueError(\"Invalid filter expression.\")\n        else:\n            self.index_filter = index_filter\n\n        file_path = Path(file_path)\n        try:\n            self.writer = WRITER[index_format.lower()](file_path)\n        except KeyError:\n            raise ValueError(f\"Format '{index_format}' is not supported.\")\n\n        if not append and file_path.exists():\n            file_path.unlink()\n\n        self.writer.load()\n\n    def response(self, flow: HTTPFlow):\n        \"\"\"Checks if the response should be included in the URL based on the index_filter and adds it to the URL index\n        if appropriate.\n        \"\"\"\n        if isinstance(self.index_filter, str) or self.index_filter is None:\n            raise ValueError(\"Invalid filter expression.\")\n        else:\n            if self.index_filter(flow):\n                self.writer.add_url(flow)\n\n    def done(self):\n        \"\"\"Writes the URL index.\"\"\"\n        self.writer.save()\n", "examples/contrib/webscanner_helper/test_urlindex.py": "import json\nfrom json import JSONDecodeError\nfrom pathlib import Path\nfrom unittest import mock\nfrom unittest.mock import patch\n\nfrom examples.contrib.webscanner_helper.urlindex import filter_404\nfrom examples.contrib.webscanner_helper.urlindex import JSONUrlIndexWriter\nfrom examples.contrib.webscanner_helper.urlindex import SetEncoder\nfrom examples.contrib.webscanner_helper.urlindex import TextUrlIndexWriter\nfrom examples.contrib.webscanner_helper.urlindex import UrlIndexAddon\nfrom examples.contrib.webscanner_helper.urlindex import UrlIndexWriter\nfrom examples.contrib.webscanner_helper.urlindex import WRITER\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nclass TestBaseClass:\n    @patch.multiple(UrlIndexWriter, __abstractmethods__=set())\n    def test_base_class(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        index_writer = UrlIndexWriter(tmpfile)\n        index_writer.load()\n        index_writer.add_url(tflow.tflow())\n        index_writer.save()\n\n\nclass TestSetEncoder:\n    def test_set_encoder_set(self):\n        test_set = {\"foo\", \"bar\", \"42\"}\n        result = SetEncoder.default(SetEncoder(), test_set)\n        assert isinstance(result, list)\n        assert \"foo\" in result\n        assert \"bar\" in result\n        assert \"42\" in result\n\n    def test_set_encoder_str(self):\n        test_str = \"test\"\n        try:\n            SetEncoder.default(SetEncoder(), test_str)\n        except TypeError:\n            assert True\n        else:\n            assert False\n\n\nclass TestJSONUrlIndexWriter:\n    def test_load(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(\n                '{\"http://example.com:80\": {\"/\": {\"GET\": [301]}}, \"http://www.example.com:80\": {\"/\": {\"GET\": [302]}}}'\n            )\n        writer = JSONUrlIndexWriter(filename=tmpfile)\n        writer.load()\n        assert \"http://example.com:80\" in writer.host_urls\n        assert \"/\" in writer.host_urls[\"http://example.com:80\"]\n        assert \"GET\" in writer.host_urls[\"http://example.com:80\"][\"/\"]\n        assert 301 in writer.host_urls[\"http://example.com:80\"][\"/\"][\"GET\"]\n\n    def test_load_empty(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(\"{}\")\n        writer = JSONUrlIndexWriter(filename=tmpfile)\n        writer.load()\n        assert len(writer.host_urls) == 0\n\n    def test_load_nonexisting(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        writer = JSONUrlIndexWriter(filename=tmpfile)\n        writer.load()\n        assert len(writer.host_urls) == 0\n\n    def test_add(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        writer = JSONUrlIndexWriter(filename=tmpfile)\n        f = tflow.tflow(resp=tutils.tresp())\n        url = f\"{f.request.scheme}://{f.request.host}:{f.request.port}\"\n        writer.add_url(f)\n        assert url in writer.host_urls\n        assert f.request.path in writer.host_urls[url]\n\n    def test_save(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        writer = JSONUrlIndexWriter(filename=tmpfile)\n        f = tflow.tflow(resp=tutils.tresp())\n        url = f\"{f.request.scheme}://{f.request.host}:{f.request.port}\"\n        writer.add_url(f)\n        writer.save()\n\n        with open(tmpfile) as results:\n            try:\n                content = json.load(results)\n            except JSONDecodeError:\n                assert False\n            assert url in content\n\n\nclass TestTestUrlIndexWriter:\n    def test_load(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(\n                \"2020-04-22T05:41:08.679231 STATUS: 200 METHOD: GET URL:http://example.com\"\n            )\n        writer = TextUrlIndexWriter(filename=tmpfile)\n        writer.load()\n        assert True\n\n    def test_load_empty(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(\"{}\")\n        writer = TextUrlIndexWriter(filename=tmpfile)\n        writer.load()\n        assert True\n\n    def test_load_nonexisting(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        writer = TextUrlIndexWriter(filename=tmpfile)\n        writer.load()\n        assert True\n\n    def test_add(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        writer = TextUrlIndexWriter(filename=tmpfile)\n        f = tflow.tflow(resp=tutils.tresp())\n        url = f\"{f.request.scheme}://{f.request.host}:{f.request.port}\"\n        method = f.request.method\n        code = f.response.status_code\n        writer.add_url(f)\n\n        with open(tmpfile) as results:\n            content = results.read()\n        assert url in content\n        assert method in content\n        assert str(code) in content\n\n    def test_save(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        writer = TextUrlIndexWriter(filename=tmpfile)\n        f = tflow.tflow(resp=tutils.tresp())\n        url = f\"{f.request.scheme}://{f.request.host}:{f.request.port}\"\n        method = f.request.method\n        code = f.response.status_code\n        writer.add_url(f)\n        writer.save()\n\n        with open(tmpfile) as results:\n            content = results.read()\n        assert url in content\n        assert method in content\n        assert str(code) in content\n\n\nclass TestWriter:\n    def test_writer_dict(self):\n        assert \"json\" in WRITER\n        assert isinstance(WRITER[\"json\"], JSONUrlIndexWriter.__class__)\n        assert \"text\" in WRITER\n        assert isinstance(WRITER[\"text\"], TextUrlIndexWriter.__class__)\n\n\nclass TestFilter:\n    def test_filer_true(self):\n        f = tflow.tflow(resp=tutils.tresp())\n        assert filter_404(f)\n\n    def test_filter_false(self):\n        f = tflow.tflow(resp=tutils.tresp())\n        f.response.status_code = 404\n        assert not filter_404(f)\n\n\nclass TestUrlIndexAddon:\n    def test_init(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        UrlIndexAddon(tmpfile)\n\n    def test_init_format(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        try:\n            UrlIndexAddon(tmpfile, index_format=\"test\")\n        except ValueError:\n            assert True\n        else:\n            assert False\n\n    def test_init_filter(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        try:\n            UrlIndexAddon(tmpfile, index_filter=\"i~nvalid\")\n        except ValueError:\n            assert True\n        else:\n            assert False\n\n    def test_init_append(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(\"\")\n        url_index = UrlIndexAddon(tmpfile, append=False)\n        f = tflow.tflow(resp=tutils.tresp())\n        with mock.patch(\n            \"examples.complex.webscanner_helper.urlindex.JSONUrlIndexWriter.add_url\"\n        ):\n            url_index.response(f)\n        assert not Path(tmpfile).exists()\n\n    def test_response(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        url_index = UrlIndexAddon(tmpfile)\n        f = tflow.tflow(resp=tutils.tresp())\n        with mock.patch(\n            \"examples.complex.webscanner_helper.urlindex.JSONUrlIndexWriter.add_url\"\n        ) as mock_add_url:\n            url_index.response(f)\n        mock_add_url.assert_called()\n\n    def test_response_None(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        url_index = UrlIndexAddon(tmpfile)\n        url_index.index_filter = None\n        f = tflow.tflow(resp=tutils.tresp())\n        try:\n            url_index.response(f)\n        except ValueError:\n            assert True\n        else:\n            assert False\n\n    def test_done(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        url_index = UrlIndexAddon(tmpfile)\n        with mock.patch(\n            \"examples.complex.webscanner_helper.urlindex.JSONUrlIndexWriter.save\"\n        ) as mock_save:\n            url_index.done()\n        mock_save.assert_called()\n", "examples/contrib/webscanner_helper/watchdog.py": "import logging\nimport pathlib\nimport time\nfrom datetime import datetime\n\nimport mitmproxy.connections\nimport mitmproxy.http\nfrom mitmproxy.addons.export import curl_command\nfrom mitmproxy.addons.export import raw\nfrom mitmproxy.exceptions import HttpSyntaxException\n\nlogger = logging.getLogger(__name__)\n\n\nclass WatchdogAddon:\n    \"\"\"The Watchdog Add-on can be used in combination with web application scanners in oder to check if the device\n        under test responds correctls to the scanner's responses.\n\n    The Watchdog Add-on checks if the device under test responds correctly to the scanner's responses.\n    If the Watchdog sees that the DUT is no longer responding correctly, an multiprocessing event is set.\n    This information can be used to restart the device under test if necessary.\n    \"\"\"\n\n    def __init__(self, event, outdir: pathlib.Path, timeout=None):\n        \"\"\"Initializes the Watchdog.\n\n        Args:\n            event: multiprocessing.Event that will be set if the watchdog is triggered.\n            outdir: path to a directory in which the triggering requests will be saved (curl and raw).\n            timeout_conn: float that specifies the timeout for the server connection\n        \"\"\"\n        self.error_event = event\n        self.flow_dir = outdir\n        if self.flow_dir.exists() and not self.flow_dir.is_dir():\n            raise RuntimeError(\"Watchtdog output path must be a directory.\")\n        elif not self.flow_dir.exists():\n            self.flow_dir.mkdir(parents=True)\n        self.last_trigger: None | float = None\n        self.timeout: None | float = timeout\n\n    def serverconnect(self, conn: mitmproxy.connections.ServerConnection):\n        if self.timeout is not None:\n            conn.settimeout(self.timeout)\n\n    @classmethod\n    def not_in_timeout(cls, last_triggered, timeout):\n        \"\"\"Checks if current error lies not in timeout after last trigger (potential reset of connection).\"\"\"\n        return (\n            last_triggered is None\n            or timeout is None\n            or (time.time() - last_triggered > timeout)\n        )\n\n    def error(self, flow):\n        \"\"\"Checks if the watchdog will be triggered.\n\n        Only triggers watchdog for timeouts after last reset and if flow.error is set (shows that error is a server\n        error). Ignores HttpSyntaxException Errors since this can be triggered on purpose by web application scanner.\n\n        Args:\n            flow: mitmproxy.http.flow\n        \"\"\"\n        if (\n            self.not_in_timeout(self.last_trigger, self.timeout)\n            and flow.error is not None\n            and not isinstance(flow.error, HttpSyntaxException)\n        ):\n            self.last_trigger = time.time()\n            logger.error(f\"Watchdog triggered! Cause: {flow}\")\n            self.error_event.set()\n\n            # save the request which might have caused the problem\n            if flow.request:\n                with (self.flow_dir / f\"{datetime.utcnow().isoformat()}.curl\").open(\n                    \"w\"\n                ) as f:\n                    f.write(curl_command(flow))\n                with (self.flow_dir / f\"{datetime.utcnow().isoformat()}.raw\").open(\n                    \"wb\"\n                ) as f:\n                    f.write(raw(flow))\n", "examples/contrib/webscanner_helper/test_urldict.py": "from examples.contrib.webscanner_helper.urldict import URLDict\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\nurl = \"http://10.10.10.10\"\nnew_content_body = \"New Body\"\nnew_content_title = \"New Title\"\ncontent = f'{{\"body\": \"{new_content_body}\", \"title\": \"{new_content_title}\"}}'\nurl_error = \"i~nvalid\"\ninput_file_content = f'{{\"{url}\": {content}}}'\ninput_file_content_error = f'{{\"{url_error}\": {content}}}'\n\n\nclass TestUrlDict:\n    def test_urldict_empty(self):\n        urldict = URLDict()\n        dump = urldict.dumps()\n        assert dump == \"{}\"\n\n    def test_urldict_loads(self):\n        urldict = URLDict.loads(input_file_content)\n        dump = urldict.dumps()\n        assert dump == input_file_content\n\n    def test_urldict_set_error(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(input_file_content_error)\n        with open(tmpfile) as tfile:\n            try:\n                URLDict.load(tfile)\n            except ValueError:\n                assert True\n            else:\n                assert False\n\n    def test_urldict_get(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(input_file_content)\n        with open(tmpfile) as tfile:\n            urldict = URLDict.load(tfile)\n\n        f = tflow.tflow(resp=tutils.tresp())\n        f.request.url = url\n        selection = urldict[f]\n        assert \"body\" in selection[0]\n        assert new_content_body in selection[0][\"body\"]\n        assert \"title\" in selection[0]\n        assert new_content_title in selection[0][\"title\"]\n\n        selection_get = urldict.get(f)\n        assert \"body\" in selection_get[0]\n        assert new_content_body in selection_get[0][\"body\"]\n        assert \"title\" in selection_get[0]\n        assert new_content_title in selection_get[0][\"title\"]\n\n        try:\n            urldict[\"body\"]\n        except KeyError:\n            assert True\n        else:\n            assert False\n\n        assert urldict.get(\"body\", default=\"default\") == \"default\"\n\n    def test_urldict_dumps(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(input_file_content)\n        with open(tmpfile) as tfile:\n            urldict = URLDict.load(tfile)\n\n        dump = urldict.dumps()\n        assert dump == input_file_content\n\n    def test_urldict_dump(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        outfile = tmpdir.join(\"outfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(input_file_content)\n        with open(tmpfile) as tfile:\n            urldict = URLDict.load(tfile)\n        with open(outfile, \"w\") as ofile:\n            urldict.dump(ofile)\n\n        with open(outfile) as ofile:\n            output = ofile.read()\n        assert output == input_file_content\n", "examples/contrib/webscanner_helper/proxyauth_selenium.py": "import abc\nimport logging\nimport random\nimport string\nimport time\nfrom typing import Any\nfrom typing import cast\n\nfrom selenium import webdriver\n\nimport mitmproxy.http\nfrom mitmproxy import flowfilter\nfrom mitmproxy import master\nfrom mitmproxy.script import concurrent\n\nlogger = logging.getLogger(__name__)\n\ncookie_key_name = {\n    \"path\": \"Path\",\n    \"expires\": \"Expires\",\n    \"domain\": \"Domain\",\n    \"is_http_only\": \"HttpOnly\",\n    \"is_secure\": \"Secure\",\n}\n\n\ndef randomString(string_length=10):\n    \"\"\"Generate a random string of fixed length\"\"\"\n    letters = string.ascii_lowercase\n    return \"\".join(random.choice(letters) for i in range(string_length))\n\n\nclass AuthorizationOracle(abc.ABC):\n    \"\"\"Abstract class for an authorization oracle which decides if a given request or response is authenticated.\"\"\"\n\n    @abc.abstractmethod\n    def is_unauthorized_request(self, flow: mitmproxy.http.HTTPFlow) -> bool:\n        pass\n\n    @abc.abstractmethod\n    def is_unauthorized_response(self, flow: mitmproxy.http.HTTPFlow) -> bool:\n        pass\n\n\nclass SeleniumAddon:\n    \"\"\"This Addon can be used in combination with web application scanners in order to help them to authenticate\n    against a web application.\n\n    Since the authentication is highly dependant on the web application, this add-on includes the abstract method\n    *login*. In order to use the add-on, a class for the web application inheriting from SeleniumAddon needs to be\n    created. This class needs to include the concrete selenium actions necessary to authenticate against the web\n    application. In addition, an authentication oracle which inherits from AuthorizationOracle should be created.\n    \"\"\"\n\n    def __init__(self, fltr: str, domain: str, auth_oracle: AuthorizationOracle):\n        self.filter = flowfilter.parse(fltr)\n        self.auth_oracle = auth_oracle\n        self.domain = domain\n        self.browser = None\n        self.set_cookies = False\n\n        options = webdriver.FirefoxOptions()\n        options.headless = True\n\n        profile = webdriver.FirefoxProfile()\n        profile.set_preference(\"network.proxy.type\", 0)\n        self.browser = webdriver.Firefox(firefox_profile=profile, options=options)\n        self.cookies: list[dict[str, str]] = []\n\n    def _login(self, flow):\n        self.cookies = self.login(flow)\n        self.browser.get(\"about:blank\")\n        self._set_request_cookies(flow)\n        self.set_cookies = True\n\n    def request(self, flow: mitmproxy.http.HTTPFlow):\n        if flow.request.is_replay:\n            logger.warning(\"Caught replayed request: \" + str(flow))\n        if (\n            not self.filter or self.filter(flow)\n        ) and self.auth_oracle.is_unauthorized_request(flow):\n            logger.debug(\"unauthorized request detected, perform login\")\n            self._login(flow)\n\n    # has to be concurrent because replay.client is blocking and replayed flows\n    # will also call response\n    @concurrent\n    def response(self, flow: mitmproxy.http.HTTPFlow):\n        if flow.response and (self.filter is None or self.filter(flow)):\n            if self.auth_oracle.is_unauthorized_response(flow):\n                self._login(flow)\n                new_flow = flow.copy()\n                if master and hasattr(master, \"commands\"):\n                    # cast necessary for mypy\n                    cast(Any, master).commands.call(\"replay.client\", [new_flow])\n                    count = 0\n                    while new_flow.response is None and count < 10:\n                        logger.error(\"waiting since \" + str(count) + \" ...\")\n                        count = count + 1\n                        time.sleep(1)\n                    if new_flow.response:\n                        flow.response = new_flow.response\n                else:\n                    logger.warning(\n                        \"Could not call 'replay.client' command since master was not initialized yet.\"\n                    )\n\n            if self.set_cookies and flow.response:\n                logger.debug(\"set set-cookie header for response\")\n                self._set_set_cookie_headers(flow)\n                self.set_cookies = False\n\n    def done(self):\n        self.browser.close()\n\n    def _set_set_cookie_headers(self, flow: mitmproxy.http.HTTPFlow):\n        if flow.response and self.cookies:\n            for cookie in self.cookies:\n                parts = [f\"{cookie['name']}={cookie['value']}\"]\n                for k, v in cookie_key_name.items():\n                    if k in cookie and isinstance(cookie[k], str):\n                        parts.append(f\"{v}={cookie[k]}\")\n                    elif k in cookie and isinstance(cookie[k], bool) and cookie[k]:\n                        parts.append(cookie[k])\n                encoded_c = \"; \".join(parts)\n                flow.response.headers[\"set-cookie\"] = encoded_c\n\n    def _set_request_cookies(self, flow: mitmproxy.http.HTTPFlow):\n        if self.cookies:\n            cookies = \"; \".join(\n                map(lambda c: f\"{c['name']}={c['value']}\", self.cookies)\n            )\n            flow.request.headers[\"cookie\"] = cookies\n\n    @abc.abstractmethod\n    def login(self, flow: mitmproxy.http.HTTPFlow) -> list[dict[str, str]]:\n        pass\n", "examples/contrib/webscanner_helper/mapping.py": "import copy\nimport logging\n\nfrom bs4 import BeautifulSoup\n\nfrom examples.contrib.webscanner_helper.urldict import URLDict\nfrom mitmproxy.http import HTTPFlow\n\nNO_CONTENT = object()\n\n\nclass MappingAddonConfig:\n    HTML_PARSER = \"html.parser\"\n\n\nclass MappingAddon:\n    \"\"\"The mapping add-on can be used in combination with web application scanners to reduce their false positives.\n\n    Many web application scanners produce false positives caused by dynamically changing content of web applications\n    such as the current time or current measurements. When testing for injection vulnerabilities, web application\n    scanners are tricked into thinking they changed the content with the injected payload. In realty, the content of\n    the web application changed notwithstanding the scanner's input. When the mapping add-on is used to map the content\n    to a fixed value, these false positives can be avoided.\n    \"\"\"\n\n    OPT_MAPPING_FILE = \"mapping_file\"\n    \"\"\"File where urls and css selector to mapped content is stored.\n\n    Elements will be replaced with the content given in this file. If the content is none it will be set to the first\n    seen value.\n\n    Example:\n\n        {\n            \"http://10.10.10.10\": {\n                \"body\": \"My Text\"\n            },\n            \"URL\": {\n                \"css selector\": \"Replace with this\"\n            }\n        }\n    \"\"\"\n\n    OPT_MAP_PERSISTENT = \"map_persistent\"\n    \"\"\"Whether to store all new content in the configuration file.\"\"\"\n\n    def __init__(self, filename: str, persistent: bool = False) -> None:\n        \"\"\"Initializes the mapping add-on\n\n        Args:\n            filename: str that provides the name of the file in which the urls and css selectors to mapped content is\n                stored.\n            persistent: bool that indicates whether to store all new content in the configuration file.\n\n        Example:\n            The file in which the mapping config is given should be in the following format:\n            {\n                \"http://10.10.10.10\": {\n                    \"body\": \"My Text\"\n                },\n                \"<URL>\": {\n                    \"<css selector>\": \"Replace with this\"\n                }\n            }\n        \"\"\"\n        self.filename = filename\n        self.persistent = persistent\n        self.logger = logging.getLogger(self.__class__.__name__)\n        with open(filename) as f:\n            self.mapping_templates = URLDict.load(f)\n\n    def load(self, loader):\n        loader.add_option(\n            self.OPT_MAPPING_FILE,\n            str,\n            \"\",\n            \"File where replacement configuration is stored.\",\n        )\n        loader.add_option(\n            self.OPT_MAP_PERSISTENT,\n            bool,\n            False,\n            \"Whether to store all new content in the configuration file.\",\n        )\n\n    def configure(self, updated):\n        if self.OPT_MAPPING_FILE in updated:\n            self.filename = updated[self.OPT_MAPPING_FILE]\n            with open(self.filename) as f:\n                self.mapping_templates = URLDict.load(f)\n\n        if self.OPT_MAP_PERSISTENT in updated:\n            self.persistent = updated[self.OPT_MAP_PERSISTENT]\n\n    def replace(\n        self, soup: BeautifulSoup, css_sel: str, replace: BeautifulSoup\n    ) -> None:\n        \"\"\"Replaces the content of soup that matches the css selector with the given replace content.\"\"\"\n        for content in soup.select(css_sel):\n            self.logger.debug(f'replace \"{content}\" with \"{replace}\"')\n            content.replace_with(copy.copy(replace))\n\n    def apply_template(\n        self, soup: BeautifulSoup, template: dict[str, BeautifulSoup]\n    ) -> None:\n        \"\"\"Applies the given mapping template to the given soup.\"\"\"\n        for css_sel, replace in template.items():\n            mapped = soup.select(css_sel)\n            if not mapped:\n                self.logger.warning(\n                    f'Could not find \"{css_sel}\", can not freeze anything.'\n                )\n            else:\n                self.replace(\n                    soup,\n                    css_sel,\n                    BeautifulSoup(replace, features=MappingAddonConfig.HTML_PARSER),\n                )\n\n    def response(self, flow: HTTPFlow) -> None:\n        \"\"\"If a response is received, check if we should replace some content.\"\"\"\n        try:\n            templates = self.mapping_templates[flow]\n            res = flow.response\n            if res is not None:\n                encoding = res.headers.get(\"content-encoding\", \"utf-8\")\n                content_type = res.headers.get(\"content-type\", \"text/html\")\n\n                if \"text/html\" in content_type and encoding == \"utf-8\":\n                    content = BeautifulSoup(res.content, MappingAddonConfig.HTML_PARSER)\n                    for template in templates:\n                        self.apply_template(content, template)\n                    res.content = content.encode(encoding)\n                else:\n                    self.logger.warning(\n                        f\"Unsupported content type '{content_type}' or content encoding '{encoding}'\"\n                    )\n        except KeyError:\n            pass\n\n    def done(self) -> None:\n        \"\"\"Dumps all new content into the configuration file if self.persistent is set.\"\"\"\n        if self.persistent:\n            # make sure that all items are strings and not soups.\n            def value_dumper(value):\n                store = {}\n                if value is None:\n                    return \"None\"\n                try:\n                    for css_sel, soup in value.items():\n                        store[css_sel] = str(soup)\n                except Exception:\n                    raise RuntimeError(value)\n                return store\n\n            with open(self.filename, \"w\") as f:\n                self.mapping_templates.dump(f, value_dumper)\n", "examples/contrib/webscanner_helper/urldict.py": "import itertools\nimport json\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import MutableMapping\nfrom typing import Any\nfrom typing import cast\nfrom typing import TextIO\n\nfrom mitmproxy import flowfilter\nfrom mitmproxy.http import HTTPFlow\n\n\ndef f_id(x):\n    return x\n\n\nclass URLDict(MutableMapping):\n    \"\"\"Data structure to store information using filters as keys.\"\"\"\n\n    def __init__(self):\n        self.store: dict[flowfilter.TFilter, Any] = {}\n\n    def __getitem__(self, key, *, count=0):\n        if count:\n            ret = itertools.islice(self.get_generator(key), 0, count)\n        else:\n            ret = list(self.get_generator(key))\n\n        if ret:\n            return ret\n        else:\n            raise KeyError\n\n    def __setitem__(self, key: str, value):\n        fltr = flowfilter.parse(key)\n        if fltr:\n            self.store.__setitem__(fltr, value)\n        else:\n            raise ValueError(\"Not a valid filter\")\n\n    def __delitem__(self, key):\n        self.store.__delitem__(key)\n\n    def __iter__(self):\n        return self.store.__iter__()\n\n    def __len__(self):\n        return self.store.__len__()\n\n    def get_generator(self, flow: HTTPFlow) -> Generator[Any, None, None]:\n        for fltr, value in self.store.items():\n            if flowfilter.match(fltr, flow):\n                yield value\n\n    def get(self, flow: HTTPFlow, default=None, *, count=0) -> list[Any]:\n        try:\n            return self.__getitem__(flow, count=count)\n        except KeyError:\n            return default\n\n    @classmethod\n    def _load(cls, json_obj, value_loader: Callable = f_id):\n        url_dict = cls()\n        for fltr, value in json_obj.items():\n            url_dict[fltr] = value_loader(value)\n        return url_dict\n\n    @classmethod\n    def load(cls, f: TextIO, value_loader: Callable = f_id):\n        json_obj = json.load(f)\n        return cls._load(json_obj, value_loader)\n\n    @classmethod\n    def loads(cls, json_str: str, value_loader: Callable = f_id):\n        json_obj = json.loads(json_str)\n        return cls._load(json_obj, value_loader)\n\n    def _dump(self, value_dumper: Callable = f_id) -> dict:\n        dumped: dict[flowfilter.TFilter | str, Any] = {}\n        for fltr, value in self.store.items():\n            if hasattr(fltr, \"pattern\"):\n                # cast necessary for mypy\n                dumped[cast(Any, fltr).pattern] = value_dumper(value)\n            else:\n                dumped[str(fltr)] = value_dumper(value)\n        return dumped\n\n    def dump(self, f: TextIO, value_dumper: Callable = f_id):\n        json.dump(self._dump(value_dumper), f)\n\n    def dumps(self, value_dumper: Callable = f_id):\n        return json.dumps(self._dump(value_dumper))\n", "examples/contrib/webscanner_helper/urlinjection.py": "import abc\nimport html\nimport json\nimport logging\n\nfrom mitmproxy import flowfilter\nfrom mitmproxy.http import HTTPFlow\n\nlogger = logging.getLogger(__name__)\n\n\nclass InjectionGenerator:\n    \"\"\"Abstract class for an generator of the injection content in order to inject the URL index.\"\"\"\n\n    ENCODING = \"UTF8\"\n\n    @abc.abstractmethod\n    def inject(self, index, flow: HTTPFlow):\n        \"\"\"Injects the given URL index into the given flow.\"\"\"\n\n\nclass HTMLInjection(InjectionGenerator):\n    \"\"\"Injects the URL index either by creating a new HTML page or by appending is to an existing page.\"\"\"\n\n    def __init__(self, insert: bool = False):\n        \"\"\"Initializes the HTMLInjection.\n\n        Args:\n            insert: boolean to decide whether to insert the URL index to an existing page (True) or to create a new\n                page containing the URL index.\n        \"\"\"\n        self.insert = insert\n\n    @classmethod\n    def _form_html(cls, url):\n        return f'<form action=\"{url}\" method=\"POST\"></form>'\n\n    @classmethod\n    def _link_html(cls, url):\n        return f'<a href=\"{url}\">link to {url}</a>'\n\n    @classmethod\n    def index_html(cls, index):\n        link_htmls = []\n        for scheme_netloc, paths in index.items():\n            for path, methods in paths.items():\n                url = scheme_netloc + path\n                if \"POST\" in methods:\n                    link_htmls.append(cls._form_html(url))\n\n                if \"GET\" in methods:\n                    link_htmls.append(cls._link_html(url))\n        return \"</ br>\".join(link_htmls)\n\n    @classmethod\n    def landing_page(cls, index):\n        return (\n            '<head><meta charset=\"UTF-8\"></head><body>'\n            + cls.index_html(index)\n            + \"</body>\"\n        )\n\n    def inject(self, index, flow: HTTPFlow):\n        if flow.response is not None:\n            if flow.response.status_code != 404 and not self.insert:\n                logger.warning(\n                    f\"URL '{flow.request.url}' didn't return 404 status, \"\n                    f\"index page would overwrite valid page.\"\n                )\n            elif self.insert:\n                content = flow.response.content.decode(\n                    self.ENCODING, \"backslashreplace\"\n                )\n                if \"</body>\" in content:\n                    content = content.replace(\n                        \"</body>\", self.index_html(index) + \"</body>\"\n                    )\n                else:\n                    content += self.index_html(index)\n                flow.response.content = content.encode(self.ENCODING)\n            else:\n                flow.response.content = self.landing_page(index).encode(self.ENCODING)\n\n\nclass RobotsInjection(InjectionGenerator):\n    \"\"\"Injects the URL index by creating a new robots.txt including the URLs.\"\"\"\n\n    def __init__(self, directive=\"Allow\"):\n        self.directive = directive\n\n    @classmethod\n    def robots_txt(cls, index, directive=\"Allow\"):\n        lines = [\"User-agent: *\"]\n        for scheme_netloc, paths in index.items():\n            for path, methods in paths.items():\n                lines.append(directive + \": \" + path)\n        return \"\\n\".join(lines)\n\n    def inject(self, index, flow: HTTPFlow):\n        if flow.response is not None:\n            if flow.response.status_code != 404:\n                logger.warning(\n                    f\"URL '{flow.request.url}' didn't return 404 status, \"\n                    f\"index page would overwrite valid page.\"\n                )\n            else:\n                flow.response.content = self.robots_txt(index, self.directive).encode(\n                    self.ENCODING\n                )\n\n\nclass SitemapInjection(InjectionGenerator):\n    \"\"\"Injects the URL index by creating a new sitemap including the URLs.\"\"\"\n\n    @classmethod\n    def sitemap(cls, index):\n        lines = [\n            '<?xml version=\"1.0\" encoding=\"UTF-8\"?><urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">'\n        ]\n        for scheme_netloc, paths in index.items():\n            for path, methods in paths.items():\n                url = scheme_netloc + path\n                lines.append(f\"<url><loc>{html.escape(url)}</loc></url>\")\n        lines.append(\"</urlset>\")\n        return \"\\n\".join(lines)\n\n    def inject(self, index, flow: HTTPFlow):\n        if flow.response is not None:\n            if flow.response.status_code != 404:\n                logger.warning(\n                    f\"URL '{flow.request.url}' didn't return 404 status, \"\n                    f\"index page would overwrite valid page.\"\n                )\n            else:\n                flow.response.content = self.sitemap(index).encode(self.ENCODING)\n\n\nclass UrlInjectionAddon:\n    \"\"\"The UrlInjection add-on can be used in combination with web application scanners to improve their crawling\n    performance.\n\n    The given URls will be injected into the web application. With this, web application scanners can find pages to\n    crawl much easier. Depending on the Injection generator, the URLs will be injected at different places of the\n    web application. It is possible to create a landing page which includes the URL (HTMLInjection()), to inject the\n    URLs to an existing page (HTMLInjection(insert=True)), to create a robots.txt containing the URLs\n    (RobotsInjection()) or to create a sitemap.xml which includes the URLS (SitemapInjection()).\n    It is necessary that the web application scanner can find the newly created page containing the URL index. For\n    example, the newly created page can be set as starting point for the web application scanner.\n    The URL index needed for the injection can be generated by the UrlIndex Add-on.\n    \"\"\"\n\n    def __init__(\n        self, flt: str, url_index_file: str, injection_gen: InjectionGenerator\n    ):\n        \"\"\"Initializes the UrlIndex add-on.\n\n        Args:\n            flt: mitmproxy filter to decide on which pages the URLs will be injected (str).\n            url_index_file: Path to the file which includes the URL index in JSON format (e.g. generated by the UrlIndexAddon), given\n                as str.\n            injection_gen: InjectionGenerator that should be used to inject the URLs into the web application.\n        \"\"\"\n        self.name = f\"{self.__class__.__name__}-{injection_gen.__class__.__name__}-{self.__hash__()}\"\n        self.flt = flowfilter.parse(flt)\n        self.injection_gen = injection_gen\n        with open(url_index_file) as f:\n            self.url_store = json.load(f)\n\n    def response(self, flow: HTTPFlow):\n        \"\"\"Checks if the response matches the filter and such should be injected.\n        Injects the URL index if appropriate.\n        \"\"\"\n        if flow.response is not None:\n            if self.flt is not None and self.flt(flow):\n                self.injection_gen.inject(self.url_store, flow)\n                flow.response.status_code = 200\n                flow.response.headers[\"content-type\"] = \"text/html\"\n                logger.debug(\n                    f\"Set status code to 200 and set content to logged \"\n                    f\"urls. Method: {self.injection_gen}\"\n                )\n", "examples/contrib/webscanner_helper/test_proxyauth_selenium.py": "from unittest import mock\nfrom unittest.mock import MagicMock\n\nimport pytest\n\nfrom examples.contrib.webscanner_helper.proxyauth_selenium import AuthorizationOracle\nfrom examples.contrib.webscanner_helper.proxyauth_selenium import logger\nfrom examples.contrib.webscanner_helper.proxyauth_selenium import randomString\nfrom examples.contrib.webscanner_helper.proxyauth_selenium import SeleniumAddon\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nclass TestRandomString:\n    def test_random_string(self):\n        res = randomString()\n        assert isinstance(res, str)\n        assert len(res) == 10\n\n        res_5 = randomString(5)\n        assert isinstance(res_5, str)\n        assert len(res_5) == 5\n\n\nclass AuthenticationOracleTest(AuthorizationOracle):\n    def is_unauthorized_request(self, flow: HTTPFlow) -> bool:\n        return True\n\n    def is_unauthorized_response(self, flow: HTTPFlow) -> bool:\n        return True\n\n\noracle = AuthenticationOracleTest()\n\n\n@pytest.fixture(scope=\"module\", autouse=True)\ndef selenium_addon(request):\n    addon = SeleniumAddon(\n        fltr=r\"~u http://example\\.com/login\\.php\",\n        domain=r\"~d http://example\\.com\",\n        auth_oracle=oracle,\n    )\n    browser = MagicMock()\n    addon.browser = browser\n    yield addon\n\n    def fin():\n        addon.browser.close()\n\n    request.addfinalizer(fin)\n\n\nclass TestSeleniumAddon:\n    def test_request_replay(self, selenium_addon):\n        f = tflow.tflow(resp=tutils.tresp())\n        f.request.is_replay = True\n        with mock.patch.object(logger, \"warning\") as mock_warning:\n            selenium_addon.request(f)\n        mock_warning.assert_called()\n\n    def test_request(self, selenium_addon):\n        f = tflow.tflow(resp=tutils.tresp())\n        f.request.url = \"http://example.com/login.php\"\n        selenium_addon.set_cookies = False\n        assert not selenium_addon.set_cookies\n        with mock.patch.object(logger, \"debug\") as mock_debug:\n            selenium_addon.request(f)\n        mock_debug.assert_called()\n        assert selenium_addon.set_cookies\n\n    def test_request_filtered(self, selenium_addon):\n        f = tflow.tflow(resp=tutils.tresp())\n        selenium_addon.set_cookies = False\n        assert not selenium_addon.set_cookies\n        selenium_addon.request(f)\n        assert not selenium_addon.set_cookies\n\n    def test_request_cookies(self, selenium_addon):\n        f = tflow.tflow(resp=tutils.tresp())\n        f.request.url = \"http://example.com/login.php\"\n        selenium_addon.set_cookies = False\n        assert not selenium_addon.set_cookies\n        with mock.patch.object(logger, \"debug\") as mock_debug:\n            with mock.patch(\n                \"examples.complex.webscanner_helper.proxyauth_selenium.SeleniumAddon.login\",\n                return_value=[{\"name\": \"cookie\", \"value\": \"test\"}],\n            ) as mock_login:\n                selenium_addon.request(f)\n        mock_debug.assert_called()\n        assert selenium_addon.set_cookies\n        mock_login.assert_called()\n\n    def test_request_filter_None(self, selenium_addon):\n        f = tflow.tflow(resp=tutils.tresp())\n        fltr = selenium_addon.filter\n        selenium_addon.filter = None\n        assert not selenium_addon.filter\n        selenium_addon.set_cookies = False\n        assert not selenium_addon.set_cookies\n\n        with mock.patch.object(logger, \"debug\") as mock_debug:\n            selenium_addon.request(f)\n        mock_debug.assert_called()\n        selenium_addon.filter = fltr\n        assert selenium_addon.set_cookies\n\n    def test_response(self, selenium_addon):\n        f = tflow.tflow(resp=tutils.tresp())\n        f.request.url = \"http://example.com/login.php\"\n        selenium_addon.set_cookies = False\n        with mock.patch(\n            \"examples.complex.webscanner_helper.proxyauth_selenium.SeleniumAddon.login\",\n            return_value=[],\n        ) as mock_login:\n            selenium_addon.response(f)\n        mock_login.assert_called()\n\n    def test_response_cookies(self, selenium_addon):\n        f = tflow.tflow(resp=tutils.tresp())\n        f.request.url = \"http://example.com/login.php\"\n        selenium_addon.set_cookies = False\n        with mock.patch(\n            \"examples.complex.webscanner_helper.proxyauth_selenium.SeleniumAddon.login\",\n            return_value=[{\"name\": \"cookie\", \"value\": \"test\"}],\n        ) as mock_login:\n            selenium_addon.response(f)\n        mock_login.assert_called()\n", "examples/contrib/webscanner_helper/test_urlinjection.py": "import json\nfrom unittest import mock\n\nfrom examples.contrib.webscanner_helper.urlinjection import HTMLInjection\nfrom examples.contrib.webscanner_helper.urlinjection import InjectionGenerator\nfrom examples.contrib.webscanner_helper.urlinjection import logger\nfrom examples.contrib.webscanner_helper.urlinjection import RobotsInjection\nfrom examples.contrib.webscanner_helper.urlinjection import SitemapInjection\nfrom examples.contrib.webscanner_helper.urlinjection import UrlInjectionAddon\nfrom mitmproxy import flowfilter\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\nindex = json.loads(\n    '{\"http://example.com:80\": {\"/\": {\"GET\": [301]}}, \"http://www.example.com:80\": {\"/test\": {\"POST\": [302]}}}'\n)\n\n\nclass TestInjectionGenerator:\n    def test_inject(self):\n        f = tflow.tflow(resp=tutils.tresp())\n        injection_generator = InjectionGenerator()\n        injection_generator.inject(index=index, flow=f)\n        assert True\n\n\nclass TestHTMLInjection:\n    def test_inject_not404(self):\n        html_injection = HTMLInjection()\n        f = tflow.tflow(resp=tutils.tresp())\n\n        with mock.patch.object(logger, \"warning\") as mock_warning:\n            html_injection.inject(index, f)\n        assert mock_warning.called\n\n    def test_inject_insert(self):\n        html_injection = HTMLInjection(insert=True)\n        f = tflow.tflow(resp=tutils.tresp())\n        assert \"example.com\" not in str(f.response.content)\n        html_injection.inject(index, f)\n        assert \"example.com\" in str(f.response.content)\n\n    def test_inject_insert_body(self):\n        html_injection = HTMLInjection(insert=True)\n        f = tflow.tflow(resp=tutils.tresp())\n        f.response.text = \"<body></body>\"\n        assert \"example.com\" not in str(f.response.content)\n        html_injection.inject(index, f)\n        assert \"example.com\" in str(f.response.content)\n\n    def test_inject_404(self):\n        html_injection = HTMLInjection()\n        f = tflow.tflow(resp=tutils.tresp())\n        f.response.status_code = 404\n        assert \"example.com\" not in str(f.response.content)\n        html_injection.inject(index, f)\n        assert \"example.com\" in str(f.response.content)\n\n\nclass TestRobotsInjection:\n    def test_inject_not404(self):\n        robots_injection = RobotsInjection()\n        f = tflow.tflow(resp=tutils.tresp())\n\n        with mock.patch.object(logger, \"warning\") as mock_warning:\n            robots_injection.inject(index, f)\n        assert mock_warning.called\n\n    def test_inject_404(self):\n        robots_injection = RobotsInjection()\n        f = tflow.tflow(resp=tutils.tresp())\n        f.response.status_code = 404\n        assert \"Allow: /test\" not in str(f.response.content)\n        robots_injection.inject(index, f)\n        assert \"Allow: /test\" in str(f.response.content)\n\n\nclass TestSitemapInjection:\n    def test_inject_not404(self):\n        sitemap_injection = SitemapInjection()\n        f = tflow.tflow(resp=tutils.tresp())\n\n        with mock.patch.object(logger, \"warning\") as mock_warning:\n            sitemap_injection.inject(index, f)\n        assert mock_warning.called\n\n    def test_inject_404(self):\n        sitemap_injection = SitemapInjection()\n        f = tflow.tflow(resp=tutils.tresp())\n        f.response.status_code = 404\n        assert \"<url><loc>http://example.com:80/</loc></url>\" not in str(\n            f.response.content\n        )\n        sitemap_injection.inject(index, f)\n        assert \"<url><loc>http://example.com:80/</loc></url>\" in str(f.response.content)\n\n\nclass TestUrlInjectionAddon:\n    def test_init(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            json.dump(index, tfile)\n        flt = f\"~u .*/site.html$\"\n        url_injection = UrlInjectionAddon(\n            f\"~u .*/site.html$\", tmpfile, HTMLInjection(insert=True)\n        )\n        assert \"http://example.com:80\" in url_injection.url_store\n        fltr = flowfilter.parse(flt)\n        f = tflow.tflow(resp=tutils.tresp())\n        f.request.url = \"http://example.com/site.html\"\n        assert fltr(f)\n        assert \"http://example.com:80\" not in str(f.response.content)\n        url_injection.response(f)\n        assert \"http://example.com:80\" in str(f.response.content)\n", "examples/contrib/webscanner_helper/__init__.py": "", "examples/contrib/webscanner_helper/test_watchdog.py": "import multiprocessing\nimport time\nfrom pathlib import Path\nfrom unittest import mock\n\nfrom examples.contrib.webscanner_helper.watchdog import logger\nfrom examples.contrib.webscanner_helper.watchdog import WatchdogAddon\nfrom mitmproxy.connections import ServerConnection\nfrom mitmproxy.exceptions import HttpSyntaxException\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nclass TestWatchdog:\n    def test_init_file(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(\"\")\n        event = multiprocessing.Event()\n        try:\n            WatchdogAddon(event, Path(tmpfile))\n        except RuntimeError:\n            assert True\n        else:\n            assert False\n\n    def test_init_dir(self, tmpdir):\n        event = multiprocessing.Event()\n        mydir = tmpdir.join(\"mydir\")\n        assert not Path(mydir).exists()\n        WatchdogAddon(event, Path(mydir))\n        assert Path(mydir).exists()\n\n    def test_serverconnect(self, tmpdir):\n        event = multiprocessing.Event()\n        w = WatchdogAddon(event, Path(tmpdir), timeout=10)\n        with mock.patch(\n            \"mitmproxy.connections.ServerConnection.settimeout\"\n        ) as mock_set_timeout:\n            w.serverconnect(ServerConnection(\"127.0.0.1\"))\n        mock_set_timeout.assert_called()\n\n    def test_serverconnect_None(self, tmpdir):\n        event = multiprocessing.Event()\n        w = WatchdogAddon(event, Path(tmpdir))\n        with mock.patch(\n            \"mitmproxy.connections.ServerConnection.settimeout\"\n        ) as mock_set_timeout:\n            w.serverconnect(ServerConnection(\"127.0.0.1\"))\n        assert not mock_set_timeout.called\n\n    def test_trigger(self, tmpdir):\n        event = multiprocessing.Event()\n        w = WatchdogAddon(event, Path(tmpdir))\n        f = tflow.tflow(resp=tutils.tresp())\n        f.error = \"Test Error\"\n\n        with mock.patch.object(logger, \"error\") as mock_error:\n            open_mock = mock.mock_open()\n            with mock.patch(\"pathlib.Path.open\", open_mock, create=True):\n                w.error(f)\n            mock_error.assert_called()\n            open_mock.assert_called()\n\n    def test_trigger_http_synatx(self, tmpdir):\n        event = multiprocessing.Event()\n        w = WatchdogAddon(event, Path(tmpdir))\n        f = tflow.tflow(resp=tutils.tresp())\n        f.error = HttpSyntaxException()\n        assert isinstance(f.error, HttpSyntaxException)\n\n        with mock.patch.object(logger, \"error\") as mock_error:\n            open_mock = mock.mock_open()\n            with mock.patch(\"pathlib.Path.open\", open_mock, create=True):\n                w.error(f)\n            assert not mock_error.called\n            assert not open_mock.called\n\n    def test_timeout(self, tmpdir):\n        event = multiprocessing.Event()\n        w = WatchdogAddon(event, Path(tmpdir))\n\n        assert w.not_in_timeout(None, None)\n        assert w.not_in_timeout(time.time, None)\n        with mock.patch(\"time.time\", return_value=5):\n            assert not w.not_in_timeout(3, 20)\n            assert w.not_in_timeout(3, 1)\n", "examples/contrib/webscanner_helper/test_mapping.py": "from collections.abc import Callable\nfrom typing import TextIO\nfrom unittest import mock\nfrom unittest.mock import MagicMock\n\nfrom examples.contrib.webscanner_helper.mapping import MappingAddon\nfrom examples.contrib.webscanner_helper.mapping import MappingAddonConfig\nfrom mitmproxy.test import tflow\nfrom mitmproxy.test import tutils\n\n\nclass TestConfig:\n    def test_config(self):\n        assert MappingAddonConfig.HTML_PARSER == \"html.parser\"\n\n\nurl = \"http://10.10.10.10\"\nnew_content = \"My Text\"\nmapping_content = f'{{\"{url}\": {{\"body\": \"{new_content}\"}}}}'\n\n\nclass TestMappingAddon:\n    def test_init(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(mapping_content)\n        mapping = MappingAddon(tmpfile)\n        assert \"My Text\" in str(mapping.mapping_templates._dump())\n\n    def test_load(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(mapping_content)\n        mapping = MappingAddon(tmpfile)\n        loader = MagicMock()\n\n        mapping.load(loader)\n        assert \"mapping_file\" in str(loader.add_option.call_args_list)\n        assert \"map_persistent\" in str(loader.add_option.call_args_list)\n\n    def test_configure(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(mapping_content)\n        mapping = MappingAddon(tmpfile)\n        new_filename = \"My new filename\"\n        updated = {\n            str(mapping.OPT_MAPPING_FILE): new_filename,\n            str(mapping.OPT_MAP_PERSISTENT): True,\n        }\n\n        open_mock = mock.mock_open(read_data=\"{}\")\n        with mock.patch(\"builtins.open\", open_mock):\n            mapping.configure(updated)\n        assert new_filename in str(open_mock.mock_calls)\n        assert mapping.filename == new_filename\n        assert mapping.persistent\n\n    def test_response_filtered(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(mapping_content)\n        mapping = MappingAddon(tmpfile)\n        f = tflow.tflow(resp=tutils.tresp())\n        test_content = b\"Test\"\n        f.response.content = test_content\n\n        mapping.response(f)\n        assert f.response.content == test_content\n\n    def test_response(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(mapping_content)\n        mapping = MappingAddon(tmpfile)\n        f = tflow.tflow(resp=tutils.tresp())\n        test_content = b\"<body> Test </body>\"\n        f.response.content = test_content\n        f.request.url = url\n\n        mapping.response(f)\n        assert f.response.content.decode(\"utf-8\") == new_content\n\n    def test_response_content_type(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(mapping_content)\n        mapping = MappingAddon(tmpfile)\n        f = tflow.tflow(resp=tutils.tresp())\n        test_content = b\"<body> Test </body>\"\n        f.response.content = test_content\n        f.request.url = url\n        f.response.headers.add(\"content-type\", \"content-type\")\n\n        mapping.response(f)\n        assert f.response.content == test_content\n\n    def test_response_not_existing(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(mapping_content)\n        mapping = MappingAddon(tmpfile)\n        f = tflow.tflow(resp=tutils.tresp())\n        test_content = b\"<title> Test </title>\"\n        f.response.content = test_content\n        f.request.url = url\n        mapping.response(f)\n        assert f.response.content == test_content\n\n    def test_persistance_false(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(mapping_content)\n        mapping = MappingAddon(tmpfile)\n\n        open_mock = mock.mock_open(read_data=\"{}\")\n        with mock.patch(\"builtins.open\", open_mock):\n            mapping.done()\n        assert len(open_mock.mock_calls) == 0\n\n    def test_persistance_true(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(mapping_content)\n        mapping = MappingAddon(tmpfile, persistent=True)\n\n        open_mock = mock.mock_open(read_data=\"{}\")\n        with mock.patch(\"builtins.open\", open_mock):\n            mapping.done()\n        with open(tmpfile) as tfile:\n            results = tfile.read()\n        assert len(open_mock.mock_calls) != 0\n        assert results == mapping_content\n\n    def test_persistance_true_add_content(self, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(mapping_content)\n        mapping = MappingAddon(tmpfile, persistent=True)\n\n        f = tflow.tflow(resp=tutils.tresp())\n        test_content = b\"<title> Test </title>\"\n        f.response.content = test_content\n        f.request.url = url\n\n        mapping.response(f)\n        mapping.done()\n        with open(tmpfile) as tfile:\n            results = tfile.read()\n        assert mapping_content in results\n\n    def mock_dump(self, f: TextIO, value_dumper: Callable):\n        assert value_dumper(None) == \"None\"\n        try:\n            value_dumper(\"Test\")\n        except RuntimeError:\n            assert True\n        else:\n            assert False\n\n    def test_dump(selfself, tmpdir):\n        tmpfile = tmpdir.join(\"tmpfile\")\n        with open(tmpfile, \"w\") as tfile:\n            tfile.write(\"{}\")\n        mapping = MappingAddon(tmpfile, persistent=True)\n        with mock.patch(\n            \"examples.complex.webscanner_helper.urldict.URLDict.dump\",\n            selfself.mock_dump,\n        ):\n            mapping.done()\n", "mitmproxy/log.py": "from __future__ import annotations\n\nimport logging\nimport os\nimport typing\nimport warnings\nfrom dataclasses import dataclass\n\nfrom mitmproxy import hooks\nfrom mitmproxy.contrib import click as miniclick\nfrom mitmproxy.utils import human\n\nif typing.TYPE_CHECKING:\n    from mitmproxy import master\n\nALERT = logging.INFO + 1\n\"\"\"\nThe ALERT logging level has the same urgency as info, but\nsignals to interactive tools that the user's attention should be\ndrawn to the output even if they're not currently looking at the\nevent log.\n\"\"\"\nlogging.addLevelName(ALERT, \"ALERT\")\n\nLogLevels = [\n    \"error\",\n    \"warn\",\n    \"info\",\n    \"alert\",\n    \"debug\",\n]\n\nLOG_COLORS = {logging.ERROR: \"red\", logging.WARNING: \"yellow\", ALERT: \"magenta\"}\n\n\nclass MitmFormatter(logging.Formatter):\n    def __init__(self, colorize: bool):\n        super().__init__()\n        self.colorize = colorize\n        time = \"[%s]\"\n        client = \"[%s]\"\n        if colorize:\n            time = miniclick.style(time, fg=\"cyan\", dim=True)\n            client = miniclick.style(client, fg=\"yellow\", dim=True)\n\n        self.with_client = f\"{time}{client} %s\"\n        self.without_client = f\"{time} %s\"\n\n    default_time_format = \"%H:%M:%S\"\n    default_msec_format = \"%s.%03d\"\n\n    def format(self, record: logging.LogRecord) -> str:\n        time = self.formatTime(record)\n        message = record.getMessage()\n        if record.exc_info:\n            message = f\"{message}\\n{self.formatException(record.exc_info)}\"\n        if self.colorize:\n            message = miniclick.style(\n                message,\n                fg=LOG_COLORS.get(record.levelno),\n                # dim=(record.levelno <= logging.DEBUG)\n            )\n        if client := getattr(record, \"client\", None):\n            client = human.format_address(client)\n            return self.with_client % (time, client, message)\n        else:\n            return self.without_client % (time, message)\n\n\nclass MitmLogHandler(logging.Handler):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._initiated_in_test = os.environ.get(\"PYTEST_CURRENT_TEST\")\n\n    def filter(self, record: logging.LogRecord) -> bool:\n        # We can't remove stale handlers here because that would modify .handlers during iteration!\n        return bool(\n            super().filter(record)\n            and (\n                not self._initiated_in_test\n                or self._initiated_in_test == os.environ.get(\"PYTEST_CURRENT_TEST\")\n            )\n        )\n\n    def install(self) -> None:\n        if self._initiated_in_test:\n            for h in list(logging.getLogger().handlers):\n                if (\n                    isinstance(h, MitmLogHandler)\n                    and h._initiated_in_test != self._initiated_in_test\n                ):\n                    h.uninstall()\n\n        logging.getLogger().addHandler(self)\n\n    def uninstall(self) -> None:\n        logging.getLogger().removeHandler(self)\n\n\n# everything below is deprecated!\n\n\nclass LogEntry:\n    def __init__(self, msg, level):\n        # it's important that we serialize to string here already so that we don't pick up changes\n        # happening after this log statement.\n        self.msg = str(msg)\n        self.level = level\n\n    def __eq__(self, other):\n        if isinstance(other, LogEntry):\n            return self.__dict__ == other.__dict__\n        return False\n\n    def __repr__(self):\n        return f\"LogEntry({self.msg}, {self.level})\"\n\n\nclass Log:\n    \"\"\"\n    The central logger, exposed to scripts as mitmproxy.ctx.log.\n\n    Deprecated: Please use the standard Python logging module instead.\n    \"\"\"\n\n    def __init__(self, master):\n        self.master = master\n\n    def debug(self, txt):\n        \"\"\"\n        Log with level debug.\n        \"\"\"\n        warnings.warn(\n            \"mitmproxy's ctx.log.debug() is deprecated. Please use the standard Python logging module instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        logging.getLogger().debug(txt)\n\n    def info(self, txt):\n        \"\"\"\n        Log with level info.\n        \"\"\"\n        warnings.warn(\n            \"mitmproxy's ctx.log.info() is deprecated. Please use the standard Python logging module instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        logging.getLogger().info(txt)\n\n    def alert(self, txt):\n        \"\"\"\n        Log with level alert. Alerts have the same urgency as info, but\n        signals to interactive tools that the user's attention should be\n        drawn to the output even if they're not currently looking at the\n        event log.\n        \"\"\"\n        warnings.warn(\n            \"mitmproxy's ctx.log.alert() is deprecated. Please use the standard Python logging module instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        logging.getLogger().log(ALERT, txt)\n\n    def warn(self, txt):\n        \"\"\"\n        Log with level warn.\n        \"\"\"\n        warnings.warn(\n            \"mitmproxy's ctx.log.warn() is deprecated. Please use the standard Python logging module instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        logging.getLogger().warning(txt)\n\n    def error(self, txt):\n        \"\"\"\n        Log with level error.\n        \"\"\"\n        warnings.warn(\n            \"mitmproxy's ctx.log.error() is deprecated. Please use the standard Python logging module instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        logging.getLogger().error(txt)\n\n    def __call__(self, text, level=\"info\"):\n        warnings.warn(\n            \"mitmproxy's ctx.log() is deprecated. Please use the standard Python logging module instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        logging.getLogger().log(level=logging.getLevelName(level.upper()), msg=text)\n\n\nLOGGING_LEVELS_TO_LOGENTRY = {\n    logging.ERROR: \"error\",\n    logging.WARNING: \"warn\",\n    logging.INFO: \"info\",\n    ALERT: \"alert\",\n    logging.DEBUG: \"debug\",\n}\n\n\nclass LegacyLogEvents(MitmLogHandler):\n    \"\"\"Emit deprecated `add_log` events from stdlib logging.\"\"\"\n\n    def __init__(\n        self,\n        master: master.Master,\n    ):\n        super().__init__()\n        self.master = master\n        self.formatter = MitmFormatter(colorize=False)\n\n    def emit(self, record: logging.LogRecord) -> None:\n        entry = LogEntry(\n            msg=self.format(record),\n            level=LOGGING_LEVELS_TO_LOGENTRY.get(record.levelno, \"error\"),\n        )\n        self.master.event_loop.call_soon_threadsafe(\n            self.master.addons.trigger,\n            AddLogHook(entry),\n        )\n\n\n@dataclass\nclass AddLogHook(hooks.Hook):\n    \"\"\"\n    **Deprecated:** Starting with mitmproxy 9, users should use the standard Python logging module instead, for example\n    by calling `logging.getLogger().addHandler()`.\n\n    Called whenever a new log entry is created through the mitmproxy\n    context. Be careful not to log from this event, which will cause an\n    infinite loop!\n    \"\"\"\n\n    entry: LogEntry\n\n\ndef log_tier(level):\n    \"\"\"\n    Comparison method for \"old\" LogEntry log tiers.\n    Ideally you should use the standard Python logging module instead.\n    \"\"\"\n    return dict(error=0, warn=1, info=2, alert=2, debug=3).get(level)\n", "mitmproxy/connection.py": "import dataclasses\nimport time\nimport uuid\nimport warnings\nfrom abc import ABCMeta\nfrom collections.abc import Sequence\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom enum import Flag\nfrom typing import Literal\n\nfrom mitmproxy import certs\nfrom mitmproxy.coretypes import serializable\nfrom mitmproxy.net import server_spec\nfrom mitmproxy.proxy import mode_specs\nfrom mitmproxy.utils import human\n\n\nclass ConnectionState(Flag):\n    \"\"\"The current state of the underlying socket.\"\"\"\n\n    CLOSED = 0\n    CAN_READ = 1\n    CAN_WRITE = 2\n    OPEN = CAN_READ | CAN_WRITE\n\n\nTransportProtocol = Literal[\"tcp\", \"udp\"]\n\n\n# practically speaking we may have IPv6 addresses with flowinfo and scope_id,\n# but type checking isn't good enough to properly handle tuple unions.\n# this version at least provides useful type checking messages.\nAddress = tuple[str, int]\n\nkw_only = {\"kw_only\": True}\n\n\n# noinspection PyDataclass\n@dataclass(**kw_only)\nclass Connection(serializable.SerializableDataclass, metaclass=ABCMeta):\n    \"\"\"\n    Base class for client and server connections.\n\n    The connection object only exposes metadata about the connection, but not the underlying socket object.\n    This is intentional, all I/O should be handled by `mitmproxy.proxy.server` exclusively.\n    \"\"\"\n\n    peername: Address | None\n    \"\"\"The remote's `(ip, port)` tuple for this connection.\"\"\"\n    sockname: Address | None\n    \"\"\"Our local `(ip, port)` tuple for this connection.\"\"\"\n\n    state: ConnectionState = field(\n        default=ConnectionState.CLOSED, metadata={\"serialize\": False}\n    )\n    \"\"\"The current connection state.\"\"\"\n\n    # all connections have a unique id. While\n    # f.client_conn == f2.client_conn already holds true for live flows (where we have object identity),\n    # we also want these semantics for recorded flows.\n    id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    \"\"\"A unique UUID to identify the connection.\"\"\"\n    transport_protocol: TransportProtocol = field(default=\"tcp\")\n    \"\"\"The connection protocol in use.\"\"\"\n    error: str | None = None\n    \"\"\"\n    A string describing a general error with connections to this address.\n\n    The purpose of this property is to signal that new connections to the particular endpoint should not be attempted,\n    for example because it uses an untrusted TLS certificate. Regular (unexpected) disconnects do not set the error\n    property. This property is only reused per client connection.\n    \"\"\"\n\n    tls: bool = False\n    \"\"\"\n    `True` if TLS should be established, `False` otherwise.\n    Note that this property only describes if a connection should eventually be protected using TLS.\n    To check if TLS has already been established, use `Connection.tls_established`.\n    \"\"\"\n    certificate_list: Sequence[certs.Cert] = ()\n    \"\"\"\n    The TLS certificate list as sent by the peer.\n    The first certificate is the end-entity certificate.\n\n    > [RFC 8446] Prior to TLS 1.3, \"certificate_list\" ordering required each\n    > certificate to certify the one immediately preceding it; however,\n    > some implementations allowed some flexibility.  Servers sometimes\n    > send both a current and deprecated intermediate for transitional\n    > purposes, and others are simply configured incorrectly, but these\n    > cases can nonetheless be validated properly.  For maximum\n    > compatibility, all implementations SHOULD be prepared to handle\n    > potentially extraneous certificates and arbitrary orderings from any\n    > TLS version, with the exception of the end-entity certificate which\n    > MUST be first.\n    \"\"\"\n    alpn: bytes | None = None\n    \"\"\"The application-layer protocol as negotiated using\n    [ALPN](https://en.wikipedia.org/wiki/Application-Layer_Protocol_Negotiation).\"\"\"\n    alpn_offers: Sequence[bytes] = ()\n    \"\"\"The ALPN offers as sent in the ClientHello.\"\"\"\n    # we may want to add SSL_CIPHER_description here, but that's currently not exposed by cryptography\n    cipher: str | None = None\n    \"\"\"The active cipher name as returned by OpenSSL's `SSL_CIPHER_get_name`.\"\"\"\n    cipher_list: Sequence[str] = ()\n    \"\"\"Ciphers accepted by the proxy server on this connection.\"\"\"\n    tls_version: str | None = None\n    \"\"\"The active TLS version.\"\"\"\n    sni: str | None = None\n    \"\"\"\n    The [Server Name Indication (SNI)](https://en.wikipedia.org/wiki/Server_Name_Indication) sent in the ClientHello.\n    \"\"\"\n\n    timestamp_start: float | None = None\n    timestamp_end: float | None = None\n    \"\"\"*Timestamp:* Connection has been closed.\"\"\"\n    timestamp_tls_setup: float | None = None\n    \"\"\"*Timestamp:* TLS handshake has been completed successfully.\"\"\"\n\n    @property\n    def connected(self) -> bool:\n        \"\"\"*Read-only:* `True` if Connection.state is ConnectionState.OPEN, `False` otherwise.\"\"\"\n        return self.state is ConnectionState.OPEN\n\n    @property\n    def tls_established(self) -> bool:\n        \"\"\"*Read-only:* `True` if TLS has been established, `False` otherwise.\"\"\"\n        return self.timestamp_tls_setup is not None\n\n    def __eq__(self, other):\n        if isinstance(other, Connection):\n            return self.id == other.id\n        return False\n\n    def __hash__(self):\n        return hash(self.id)\n\n    def __repr__(self):\n        attrs = {\n            # ensure these come first.\n            \"id\": None,\n            \"address\": None,\n        }\n        for f in dataclasses.fields(self):\n            val = getattr(self, f.name)\n            if val != f.default:\n                if f.name == \"cipher_list\":\n                    val = f\"<{len(val)} ciphers>\"\n                elif f.name == \"id\":\n                    val = f\"\u2026{val[-6:]}\"\n                attrs[f.name] = val\n        return f\"{type(self).__name__}({attrs!r})\"\n\n    @property\n    def alpn_proto_negotiated(self) -> bytes | None:  # pragma: no cover\n        \"\"\"*Deprecated:* An outdated alias for Connection.alpn.\"\"\"\n        warnings.warn(\n            \"Connection.alpn_proto_negotiated is deprecated, use Connection.alpn instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return self.alpn\n\n\n# noinspection PyDataclass\n@dataclass(eq=False, repr=False, **kw_only)\nclass Client(Connection):\n    \"\"\"A connection between a client and mitmproxy.\"\"\"\n\n    peername: Address\n    \"\"\"The client's address.\"\"\"\n    sockname: Address\n    \"\"\"The local address we received this connection on.\"\"\"\n\n    mitmcert: certs.Cert | None = None\n    \"\"\"\n    The certificate used by mitmproxy to establish TLS with the client.\n    \"\"\"\n\n    proxy_mode: mode_specs.ProxyMode = field(\n        default=mode_specs.ProxyMode.parse(\"regular\")\n    )\n    \"\"\"The proxy server type this client has been connecting to.\"\"\"\n\n    timestamp_start: float = field(default_factory=time.time)\n    \"\"\"*Timestamp:* TCP SYN received\"\"\"\n\n    def __str__(self):\n        if self.alpn:\n            tls_state = f\", alpn={self.alpn.decode(errors='replace')}\"\n        elif self.tls_established:\n            tls_state = \", tls\"\n        else:\n            tls_state = \"\"\n        state = self.state.name\n        assert state\n        return f\"Client({human.format_address(self.peername)}, state={state.lower()}{tls_state})\"\n\n    @property\n    def address(self):  # pragma: no cover\n        \"\"\"*Deprecated:* An outdated alias for Client.peername.\"\"\"\n        warnings.warn(\n            \"Client.address is deprecated, use Client.peername instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return self.peername\n\n    @address.setter\n    def address(self, x):  # pragma: no cover\n        warnings.warn(\n            \"Client.address is deprecated, use Client.peername instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        self.peername = x\n\n    @property\n    def cipher_name(self) -> str | None:  # pragma: no cover\n        \"\"\"*Deprecated:* An outdated alias for Connection.cipher.\"\"\"\n        warnings.warn(\n            \"Client.cipher_name is deprecated, use Client.cipher instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return self.cipher\n\n    @property\n    def clientcert(self) -> certs.Cert | None:  # pragma: no cover\n        \"\"\"*Deprecated:* An outdated alias for Connection.certificate_list[0].\"\"\"\n        warnings.warn(\n            \"Client.clientcert is deprecated, use Client.certificate_list instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        if self.certificate_list:\n            return self.certificate_list[0]\n        else:\n            return None\n\n    @clientcert.setter\n    def clientcert(self, val):  # pragma: no cover\n        warnings.warn(\n            \"Client.clientcert is deprecated, use Client.certificate_list instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        if val:\n            self.certificate_list = [val]\n        else:\n            self.certificate_list = []\n\n\n# noinspection PyDataclass\n@dataclass(eq=False, repr=False, **kw_only)\nclass Server(Connection):\n    \"\"\"A connection between mitmproxy and an upstream server.\"\"\"\n\n    address: Address | None  # type: ignore\n    \"\"\"\n    The server's `(host, port)` address tuple.\n\n    The host can either be a domain or a plain IP address.\n    Which of those two will be present depends on the proxy mode and the client.\n    For explicit proxies, this value will reflect what the client instructs mitmproxy to connect to.\n    For example, if the client starts off a connection with `CONNECT example.com HTTP/1.1`, it will be `example.com`.\n    For transparent proxies such as WireGuard mode, this value will be an IP address.\n    \"\"\"\n\n    peername: Address | None = None\n    \"\"\"\n    The server's resolved `(ip, port)` tuple. Will be set during connection establishment.\n    May be `None` in upstream proxy mode when the address is resolved by the upstream proxy only.\n    \"\"\"\n    sockname: Address | None = None\n\n    timestamp_start: float | None = None\n    \"\"\"\n    *Timestamp:* Connection establishment started.\n\n    For IP addresses, this corresponds to sending a TCP SYN; for domains, this corresponds to starting a DNS lookup.\n    \"\"\"\n    timestamp_tcp_setup: float | None = None\n    \"\"\"*Timestamp:* TCP ACK received.\"\"\"\n\n    via: server_spec.ServerSpec | None = None\n    \"\"\"An optional proxy server specification via which the connection should be established.\"\"\"\n\n    def __str__(self):\n        if self.alpn:\n            tls_state = f\", alpn={self.alpn.decode(errors='replace')}\"\n        elif self.tls_established:\n            tls_state = \", tls\"\n        else:\n            tls_state = \"\"\n        if self.sockname:\n            local_port = f\", src_port={self.sockname[1]}\"\n        else:\n            local_port = \"\"\n        state = self.state.name\n        assert state\n        return f\"Server({human.format_address(self.address)}, state={state.lower()}{tls_state}{local_port})\"\n\n    def __setattr__(self, name, value):\n        if name in (\"address\", \"via\"):\n            connection_open = (\n                self.__dict__.get(\"state\", ConnectionState.CLOSED)\n                is ConnectionState.OPEN\n            )\n            # assigning the current value is okay, that may be an artifact of calling .set_state().\n            attr_changed = self.__dict__.get(name) != value\n            if connection_open and attr_changed:\n                raise RuntimeError(f\"Cannot change server.{name} on open connection.\")\n        return super().__setattr__(name, value)\n\n    @property\n    def ip_address(self) -> Address | None:  # pragma: no cover\n        \"\"\"*Deprecated:* An outdated alias for `Server.peername`.\"\"\"\n        warnings.warn(\n            \"Server.ip_address is deprecated, use Server.peername instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return self.peername\n\n    @property\n    def cert(self) -> certs.Cert | None:  # pragma: no cover\n        \"\"\"*Deprecated:* An outdated alias for `Connection.certificate_list[0]`.\"\"\"\n        warnings.warn(\n            \"Server.cert is deprecated, use Server.certificate_list instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        if self.certificate_list:\n            return self.certificate_list[0]\n        else:\n            return None\n\n    @cert.setter\n    def cert(self, val):  # pragma: no cover\n        warnings.warn(\n            \"Server.cert is deprecated, use Server.certificate_list instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        if val:\n            self.certificate_list = [val]\n        else:\n            self.certificate_list = []\n\n\n__all__ = [\"Connection\", \"Client\", \"Server\", \"ConnectionState\"]\n", "mitmproxy/options.py": "from collections.abc import Sequence\nfrom typing import Optional\n\nfrom mitmproxy import optmanager\n\nCONF_DIR = \"~/.mitmproxy\"\nCONF_BASENAME = \"mitmproxy\"\nCONTENT_VIEW_LINES_CUTOFF = 512\nKEY_SIZE = 2048\n\n\nclass Options(optmanager.OptManager):\n    def __init__(self, **kwargs) -> None:\n        super().__init__()\n        self.add_option(\n            \"server\", bool, True, \"Start a proxy server. Enabled by default.\"\n        )\n        self.add_option(\n            \"showhost\",\n            bool,\n            False,\n            \"Use the Host header to construct URLs for display.\",\n        )\n\n        # Proxy options\n        self.add_option(\n            \"add_upstream_certs_to_client_chain\",\n            bool,\n            False,\n            \"\"\"\n            Add all certificates of the upstream server to the certificate chain\n            that will be served to the proxy client, as extras.\n            \"\"\",\n        )\n        self.add_option(\n            \"confdir\",\n            str,\n            CONF_DIR,\n            \"Location of the default mitmproxy configuration files.\",\n        )\n        self.add_option(\n            \"certs\",\n            Sequence[str],\n            [],\n            \"\"\"\n            SSL certificates of the form \"[domain=]path\". The domain may include\n            a wildcard, and is equal to \"*\" if not specified. The file at path\n            is a certificate in PEM format. If a private key is included in the\n            PEM, it is used, else the default key in the conf dir is used. The\n            PEM file should contain the full certificate chain, with the leaf\n            certificate as the first entry.\n            \"\"\",\n        )\n        self.add_option(\n            \"cert_passphrase\",\n            Optional[str],\n            None,\n            \"\"\"\n            Passphrase for decrypting the private key provided in the --cert option.\n\n            Note that passing cert_passphrase on the command line makes your passphrase visible in your system's\n            process list. Specify it in config.yaml to avoid this.\n            \"\"\",\n        )\n        self.add_option(\n            \"ciphers_client\",\n            Optional[str],\n            None,\n            \"Set supported ciphers for client <-> mitmproxy connections using OpenSSL syntax.\",\n        )\n        self.add_option(\n            \"ciphers_server\",\n            Optional[str],\n            None,\n            \"Set supported ciphers for mitmproxy <-> server connections using OpenSSL syntax.\",\n        )\n        self.add_option(\n            \"client_certs\", Optional[str], None, \"Client certificate file or directory.\"\n        )\n        self.add_option(\n            \"ignore_hosts\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Ignore host and forward all traffic without processing it. In\n            transparent mode, it is recommended to use an IP address (range),\n            not the hostname. In regular mode, only SSL traffic is ignored and\n            the hostname should be used. The supplied value is interpreted as a\n            regular expression and matched on the ip or the hostname.\n            \"\"\",\n        )\n        self.add_option(\"allow_hosts\", Sequence[str], [], \"Opposite of --ignore-hosts.\")\n        self.add_option(\n            \"listen_host\",\n            str,\n            \"\",\n            \"Address to bind proxy server(s) to (may be overridden for individual modes, see `mode`).\",\n        )\n        self.add_option(\n            \"listen_port\",\n            Optional[int],\n            None,\n            \"Port to bind proxy server(s) to (may be overridden for individual modes, see `mode`). \"\n            \"By default, the port is mode-specific. The default regular HTTP proxy spawns on port 8080.\",\n        )\n        self.add_option(\n            \"mode\",\n            Sequence[str],\n            [\"regular\"],\n            \"\"\"\n            The proxy server type(s) to spawn. Can be passed multiple times.\n\n            Mitmproxy supports \"regular\" (HTTP), \"transparent\", \"socks5\", \"reverse:SPEC\",\n            \"upstream:SPEC\", and \"wireguard[:PATH]\" proxy servers. For reverse and upstream proxy modes, SPEC\n            is host specification in the form of \"http[s]://host[:port]\". For WireGuard mode, PATH may point to\n            a file containing key material. If no such file exists, it will be created on startup.\n\n            You may append `@listen_port` or `@listen_host:listen_port` to override `listen_host` or `listen_port` for\n            a specific proxy mode. Features such as client playback will use the first mode to determine\n            which upstream server to use.\n            \"\"\",\n        )\n        self.add_option(\n            \"upstream_cert\",\n            bool,\n            True,\n            \"Connect to upstream server to look up certificate details.\",\n        )\n\n        self.add_option(\n            \"http2\",\n            bool,\n            True,\n            \"Enable/disable HTTP/2 support. HTTP/2 support is enabled by default.\",\n        )\n        self.add_option(\n            \"http2_ping_keepalive\",\n            int,\n            58,\n            \"\"\"\n            Send a PING frame if an HTTP/2 connection is idle for more than\n            the specified number of seconds to prevent the remote site from closing it.\n            Set to 0 to disable this feature.\n            \"\"\",\n        )\n        self.add_option(\n            \"http3\",\n            bool,\n            True,\n            \"Enable/disable support for QUIC and HTTP/3. Enabled by default.\",\n        )\n        self.add_option(\n            \"websocket\",\n            bool,\n            True,\n            \"Enable/disable WebSocket support. \"\n            \"WebSocket support is enabled by default.\",\n        )\n        self.add_option(\n            \"rawtcp\",\n            bool,\n            True,\n            \"Enable/disable raw TCP connections. \"\n            \"TCP connections are enabled by default. \",\n        )\n        self.add_option(\n            \"ssl_insecure\",\n            bool,\n            False,\n            \"Do not verify upstream server SSL/TLS certificates.\",\n        )\n        self.add_option(\n            \"ssl_verify_upstream_trusted_confdir\",\n            Optional[str],\n            None,\n            \"\"\"\n            Path to a directory of trusted CA certificates for upstream server\n            verification prepared using the c_rehash tool.\n            \"\"\",\n        )\n        self.add_option(\n            \"ssl_verify_upstream_trusted_ca\",\n            Optional[str],\n            None,\n            \"Path to a PEM formatted trusted CA certificate.\",\n        )\n        self.add_option(\n            \"tcp_hosts\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Generic TCP SSL proxy mode for all hosts that match the pattern.\n            Similar to --ignore-hosts, but SSL connections are intercepted.\n            The communication contents are printed to the log in verbose mode.\n            \"\"\",\n        )\n        self.add_option(\n            \"udp_hosts\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Generic UDP SSL proxy mode for all hosts that match the pattern.\n            Similar to --ignore-hosts, but SSL connections are intercepted.\n            The communication contents are printed to the log in verbose mode.\n            \"\"\",\n        )\n        self.add_option(\n            \"content_view_lines_cutoff\",\n            int,\n            CONTENT_VIEW_LINES_CUTOFF,\n            \"\"\"\n            Flow content view lines limit. Limit is enabled by default to\n            speedup flows browsing.\n            \"\"\",\n        )\n        self.add_option(\n            \"key_size\",\n            int,\n            KEY_SIZE,\n            \"\"\"\n            TLS key size for certificates and CA.\n            \"\"\",\n        )\n\n        self.update(**kwargs)\n", "mitmproxy/command.py": "\"\"\"\nThis module manages and invokes typed commands.\n\"\"\"\n\nimport functools\nimport inspect\nimport logging\nimport sys\nimport textwrap\nimport types\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nfrom typing import Any\nfrom typing import NamedTuple\n\nimport pyparsing\n\nimport mitmproxy.types\nfrom mitmproxy import command_lexer\nfrom mitmproxy import exceptions\nfrom mitmproxy.command_lexer import unquote\n\n\ndef verify_arg_signature(f: Callable, args: Iterable[Any], kwargs: dict) -> None:\n    sig = inspect.signature(f, eval_str=True)\n    try:\n        sig.bind(*args, **kwargs)\n    except TypeError as v:\n        raise exceptions.CommandError(\"command argument mismatch: %s\" % v.args[0])\n\n\ndef typename(t: type) -> str:\n    \"\"\"\n    Translates a type to an explanatory string.\n    \"\"\"\n    if t == inspect._empty:  # type: ignore\n        raise exceptions.CommandError(\"missing type annotation\")\n    to = mitmproxy.types.CommandTypes.get(t, None)\n    if not to:\n        raise exceptions.CommandError(\n            \"unsupported type: %s\" % getattr(t, \"__name__\", t)\n        )\n    return to.display\n\n\ndef _empty_as_none(x: Any) -> Any:\n    if x == inspect.Signature.empty:\n        return None\n    return x\n\n\nclass CommandParameter(NamedTuple):\n    name: str\n    type: type\n    kind: inspect._ParameterKind = inspect.Parameter.POSITIONAL_OR_KEYWORD\n\n    def __str__(self):\n        if self.kind is inspect.Parameter.VAR_POSITIONAL:\n            return f\"*{self.name}\"\n        else:\n            return self.name\n\n\nclass Command:\n    name: str\n    manager: \"CommandManager\"\n    signature: inspect.Signature\n    help: str | None\n\n    def __init__(self, manager: \"CommandManager\", name: str, func: Callable) -> None:\n        self.name = name\n        self.manager = manager\n        self.func = func\n        self.signature = inspect.signature(self.func, eval_str=True)\n\n        if func.__doc__:\n            txt = func.__doc__.strip()\n            self.help = \"\\n\".join(textwrap.wrap(txt))\n        else:\n            self.help = None\n\n        # This fails with a CommandException if types are invalid\n        for name, parameter in self.signature.parameters.items():\n            t = parameter.annotation\n            if not mitmproxy.types.CommandTypes.get(parameter.annotation, None):\n                raise exceptions.CommandError(\n                    f\"Argument {name} has an unknown type {t} in {func}.\"\n                )\n        if self.return_type and not mitmproxy.types.CommandTypes.get(\n            self.return_type, None\n        ):\n            raise exceptions.CommandError(\n                f\"Return type has an unknown type ({self.return_type}) in {func}.\"\n            )\n\n    @property\n    def return_type(self) -> type | None:\n        return _empty_as_none(self.signature.return_annotation)\n\n    @property\n    def parameters(self) -> list[CommandParameter]:\n        \"\"\"Returns a list of CommandParameters.\"\"\"\n        ret = []\n        for name, param in self.signature.parameters.items():\n            ret.append(CommandParameter(name, param.annotation, param.kind))\n        return ret\n\n    def signature_help(self) -> str:\n        params = \" \".join(str(param) for param in self.parameters)\n        if self.return_type:\n            ret = f\" -> {typename(self.return_type)}\"\n        else:\n            ret = \"\"\n        return f\"{self.name} {params}{ret}\"\n\n    def prepare_args(self, args: Sequence[str]) -> inspect.BoundArguments:\n        try:\n            bound_arguments = self.signature.bind(*args)\n        except TypeError:\n            expected = f\"Expected: {str(self.signature.parameters)}\"\n            received = f\"Received: {str(args)}\"\n            raise exceptions.CommandError(\n                f\"Command argument mismatch: \\n    {expected}\\n    {received}\"\n            )\n\n        for name, value in bound_arguments.arguments.items():\n            param = self.signature.parameters[name]\n            convert_to = param.annotation\n            if param.kind == param.VAR_POSITIONAL:\n                bound_arguments.arguments[name] = tuple(\n                    parsearg(self.manager, x, convert_to) for x in value\n                )\n            else:\n                bound_arguments.arguments[name] = parsearg(\n                    self.manager, value, convert_to\n                )\n\n        bound_arguments.apply_defaults()\n\n        return bound_arguments\n\n    def call(self, args: Sequence[str]) -> Any:\n        \"\"\"\n        Call the command with a list of arguments. At this point, all\n        arguments are strings.\n        \"\"\"\n        bound_args = self.prepare_args(args)\n        ret = self.func(*bound_args.args, **bound_args.kwargs)\n        if ret is None and self.return_type is None:\n            return\n        typ = mitmproxy.types.CommandTypes.get(self.return_type)\n        assert typ\n        if not typ.is_valid(self.manager, typ, ret):\n            raise exceptions.CommandError(\n                f\"{self.name} returned unexpected data - expected {typ.display}\"\n            )\n        return ret\n\n\nclass ParseResult(NamedTuple):\n    value: str\n    type: type\n    valid: bool\n\n\nclass CommandManager:\n    commands: dict[str, Command]\n\n    def __init__(self, master):\n        self.master = master\n        self.commands = {}\n\n    def collect_commands(self, addon):\n        for i in dir(addon):\n            if not i.startswith(\"__\"):\n                o = getattr(addon, i)\n                try:\n                    # hasattr is not enough, see https://github.com/mitmproxy/mitmproxy/issues/3794\n                    is_command = isinstance(getattr(o, \"command_name\", None), str)\n                except Exception:\n                    pass  # getattr may raise if o implements __getattr__.\n                else:\n                    if is_command:\n                        try:\n                            self.add(o.command_name, o)\n                        except exceptions.CommandError as e:\n                            logging.warning(\n                                f\"Could not load command {o.command_name}: {e}\"\n                            )\n\n    def add(self, path: str, func: Callable):\n        self.commands[path] = Command(self, path, func)\n\n    @functools.lru_cache(maxsize=128)\n    def parse_partial(\n        self, cmdstr: str\n    ) -> tuple[Sequence[ParseResult], Sequence[CommandParameter]]:\n        \"\"\"\n        Parse a possibly partial command. Return a sequence of ParseResults and a sequence of remainder type help items.\n        \"\"\"\n\n        parts: pyparsing.ParseResults = command_lexer.expr.parseString(\n            cmdstr, parseAll=True\n        )\n\n        parsed: list[ParseResult] = []\n        next_params: list[CommandParameter] = [\n            CommandParameter(\"\", mitmproxy.types.Cmd),\n            CommandParameter(\"\", mitmproxy.types.CmdArgs),\n        ]\n        expected: CommandParameter | None = None\n        for part in parts:\n            if part.isspace():\n                parsed.append(\n                    ParseResult(\n                        value=part,\n                        type=mitmproxy.types.Space,\n                        valid=True,\n                    )\n                )\n                continue\n\n            if expected and expected.kind is inspect.Parameter.VAR_POSITIONAL:\n                assert not next_params\n            elif next_params:\n                expected = next_params.pop(0)\n            else:\n                expected = CommandParameter(\"\", mitmproxy.types.Unknown)\n\n            arg_is_known_command = (\n                expected.type == mitmproxy.types.Cmd and part in self.commands\n            )\n            arg_is_unknown_command = (\n                expected.type == mitmproxy.types.Cmd and part not in self.commands\n            )\n            command_args_following = (\n                next_params and next_params[0].type == mitmproxy.types.CmdArgs\n            )\n            if arg_is_known_command and command_args_following:\n                next_params = self.commands[part].parameters + next_params[1:]\n            if arg_is_unknown_command and command_args_following:\n                next_params.pop(0)\n\n            to = mitmproxy.types.CommandTypes.get(expected.type, None)\n            valid = False\n            if to:\n                try:\n                    to.parse(self, expected.type, part)\n                except ValueError:\n                    valid = False\n                else:\n                    valid = True\n\n            parsed.append(\n                ParseResult(\n                    value=part,\n                    type=expected.type,\n                    valid=valid,\n                )\n            )\n\n        return parsed, next_params\n\n    def call(self, command_name: str, *args: Any) -> Any:\n        \"\"\"\n        Call a command with native arguments. May raise CommandError.\n        \"\"\"\n        if command_name not in self.commands:\n            raise exceptions.CommandError(\"Unknown command: %s\" % command_name)\n        return self.commands[command_name].func(*args)\n\n    def call_strings(self, command_name: str, args: Sequence[str]) -> Any:\n        \"\"\"\n        Call a command using a list of string arguments. May raise CommandError.\n        \"\"\"\n        if command_name not in self.commands:\n            raise exceptions.CommandError(\"Unknown command: %s\" % command_name)\n\n        return self.commands[command_name].call(args)\n\n    def execute(self, cmdstr: str) -> Any:\n        \"\"\"\n        Execute a command string. May raise CommandError.\n        \"\"\"\n        parts, _ = self.parse_partial(cmdstr)\n        if not parts:\n            raise exceptions.CommandError(f\"Invalid command: {cmdstr!r}\")\n        command_name, *args = (\n            unquote(part.value) for part in parts if part.type != mitmproxy.types.Space\n        )\n        return self.call_strings(command_name, args)\n\n    def dump(self, out=sys.stdout) -> None:\n        cmds = list(self.commands.values())\n        cmds.sort(key=lambda x: x.signature_help())\n        for c in cmds:\n            for hl in (c.help or \"\").splitlines():\n                print(\"# \" + hl, file=out)\n            print(c.signature_help(), file=out)\n            print(file=out)\n\n\ndef parsearg(manager: CommandManager, spec: str, argtype: type) -> Any:\n    \"\"\"\n    Convert a string to a argument to the appropriate type.\n    \"\"\"\n    t = mitmproxy.types.CommandTypes.get(argtype, None)\n    if not t:\n        raise exceptions.CommandError(f\"Unsupported argument type: {argtype}\")\n    try:\n        return t.parse(manager, argtype, spec)\n    except ValueError as e:\n        raise exceptions.CommandError(str(e)) from e\n\n\ndef command(name: str | None = None):\n    def decorator(function):\n        @functools.wraps(function)\n        def wrapper(*args, **kwargs):\n            verify_arg_signature(function, args, kwargs)\n            return function(*args, **kwargs)\n\n        wrapper.__dict__[\"command_name\"] = name or function.__name__.replace(\"_\", \".\")\n        return wrapper\n\n    return decorator\n\n\ndef argument(name, type):\n    \"\"\"\n    Set the type of a command argument at runtime. This is useful for more\n    specific types such as mitmproxy.types.Choice, which we cannot annotate\n    directly as mypy does not like that.\n    \"\"\"\n\n    def decorator(f: types.FunctionType) -> types.FunctionType:\n        assert name in f.__annotations__\n        f.__annotations__[name] = type\n        return f\n\n    return decorator\n", "mitmproxy/command_lexer.py": "import re\n\nimport pyparsing\n\n# TODO: There is a lot of work to be done here.\n# The current implementation is written in a way that _any_ input is valid,\n# which does not make sense once things get more complex.\n\nPartialQuotedString = pyparsing.Regex(\n    re.compile(\n        r\"\"\"\n            \"[^\"]*(?:\"|$)  # double-quoted string that ends with double quote or EOF\n            |\n            '[^']*(?:'|$)  # single-quoted string that ends with double quote or EOF\n        \"\"\",\n        re.VERBOSE,\n    )\n)\n\nexpr = pyparsing.ZeroOrMore(\n    PartialQuotedString\n    | pyparsing.Word(\" \\r\\n\\t\")\n    | pyparsing.CharsNotIn(\"\"\"'\" \\r\\n\\t\"\"\")\n).leaveWhitespace()\n\n\ndef quote(val: str) -> str:\n    if val and all(char not in val for char in \"'\\\" \\r\\n\\t\"):\n        return val\n    if '\"' not in val:\n        return f'\"{val}\"'\n    if \"'\" not in val:\n        return f\"'{val}'\"\n    return '\"' + val.replace('\"', r\"\\x22\") + '\"'\n\n\ndef unquote(x: str) -> str:\n    if len(x) > 1 and x[0] in \"'\\\"\" and x[0] == x[-1]:\n        return x[1:-1]\n    else:\n        return x\n", "mitmproxy/http.py": "import binascii\nimport json\nimport os\nimport time\nimport urllib.parse\nimport warnings\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom dataclasses import dataclass\nfrom dataclasses import fields\nfrom email.utils import formatdate\nfrom email.utils import mktime_tz\nfrom email.utils import parsedate_tz\nfrom typing import Any\nfrom typing import cast\n\nfrom mitmproxy import flow\nfrom mitmproxy.coretypes import multidict\nfrom mitmproxy.coretypes import serializable\nfrom mitmproxy.net import encoding\nfrom mitmproxy.net.http import cookies\nfrom mitmproxy.net.http import multipart\nfrom mitmproxy.net.http import status_codes\nfrom mitmproxy.net.http import url\nfrom mitmproxy.net.http.headers import assemble_content_type\nfrom mitmproxy.net.http.headers import infer_content_encoding\nfrom mitmproxy.net.http.headers import parse_content_type\nfrom mitmproxy.utils import human\nfrom mitmproxy.utils import strutils\nfrom mitmproxy.utils import typecheck\nfrom mitmproxy.utils.strutils import always_bytes\nfrom mitmproxy.utils.strutils import always_str\nfrom mitmproxy.websocket import WebSocketData\n\n\n# While headers _should_ be ASCII, it's not uncommon for certain headers to be utf-8 encoded.\ndef _native(x: bytes) -> str:\n    return x.decode(\"utf-8\", \"surrogateescape\")\n\n\ndef _always_bytes(x: str | bytes) -> bytes:\n    return strutils.always_bytes(x, \"utf-8\", \"surrogateescape\")\n\n\n# This cannot be easily typed with mypy yet, so we just specify MultiDict without concrete types.\nclass Headers(multidict.MultiDict):  # type: ignore\n    \"\"\"\n    Header class which allows both convenient access to individual headers as well as\n    direct access to the underlying raw data. Provides a full dictionary interface.\n\n    Create headers with keyword arguments:\n    >>> h = Headers(host=\"example.com\", content_type=\"application/xml\")\n\n    Headers mostly behave like a normal dict:\n    >>> h[\"Host\"]\n    \"example.com\"\n\n    Headers are case insensitive:\n    >>> h[\"host\"]\n    \"example.com\"\n\n    Headers can also be created from a list of raw (header_name, header_value) byte tuples:\n    >>> h = Headers([\n        (b\"Host\",b\"example.com\"),\n        (b\"Accept\",b\"text/html\"),\n        (b\"accept\",b\"application/xml\")\n    ])\n\n    Multiple headers are folded into a single header as per RFC 7230:\n    >>> h[\"Accept\"]\n    \"text/html, application/xml\"\n\n    Setting a header removes all existing headers with the same name:\n    >>> h[\"Accept\"] = \"application/text\"\n    >>> h[\"Accept\"]\n    \"application/text\"\n\n    `bytes(h)` returns an HTTP/1 header block:\n    >>> print(bytes(h))\n    Host: example.com\n    Accept: application/text\n\n    For full control, the raw header fields can be accessed:\n    >>> h.fields\n\n    Caveats:\n     - For use with the \"Set-Cookie\" and \"Cookie\" headers, either use `Response.cookies` or see `Headers.get_all`.\n    \"\"\"\n\n    def __init__(self, fields: Iterable[tuple[bytes, bytes]] = (), **headers):\n        \"\"\"\n        *Args:*\n         - *fields:* (optional) list of ``(name, value)`` header byte tuples,\n           e.g. ``[(b\"Host\", b\"example.com\")]``. All names and values must be bytes.\n         - *\\\\*\\\\*headers:* Additional headers to set. Will overwrite existing values from `fields`.\n           For convenience, underscores in header names will be transformed to dashes -\n           this behaviour does not extend to other methods.\n\n        If ``**headers`` contains multiple keys that have equal ``.lower()`` representations,\n        the behavior is undefined.\n        \"\"\"\n        super().__init__(fields)\n\n        for key, value in self.fields:\n            if not isinstance(key, bytes) or not isinstance(value, bytes):\n                raise TypeError(\"Header fields must be bytes.\")\n\n        # content_type -> content-type\n        self.update(\n            {\n                _always_bytes(name).replace(b\"_\", b\"-\"): _always_bytes(value)\n                for name, value in headers.items()\n            }\n        )\n\n    fields: tuple[tuple[bytes, bytes], ...]\n\n    @staticmethod\n    def _reduce_values(values) -> str:\n        # Headers can be folded\n        return \", \".join(values)\n\n    @staticmethod\n    def _kconv(key) -> str:\n        # Headers are case-insensitive\n        return key.lower()\n\n    def __bytes__(self) -> bytes:\n        if self.fields:\n            return b\"\\r\\n\".join(b\": \".join(field) for field in self.fields) + b\"\\r\\n\"\n        else:\n            return b\"\"\n\n    def __delitem__(self, key: str | bytes) -> None:\n        key = _always_bytes(key)\n        super().__delitem__(key)\n\n    def __iter__(self) -> Iterator[str]:\n        for x in super().__iter__():\n            yield _native(x)\n\n    def get_all(self, name: str | bytes) -> list[str]:\n        \"\"\"\n        Like `Headers.get`, but does not fold multiple headers into a single one.\n        This is useful for Set-Cookie and Cookie headers, which do not support folding.\n\n        *See also:*\n         - <https://tools.ietf.org/html/rfc7230#section-3.2.2>\n         - <https://datatracker.ietf.org/doc/html/rfc6265#section-5.4>\n         - <https://datatracker.ietf.org/doc/html/rfc7540#section-8.1.2.5>\n        \"\"\"\n        name = _always_bytes(name)\n        return [_native(x) for x in super().get_all(name)]\n\n    def set_all(self, name: str | bytes, values: Iterable[str | bytes]):\n        \"\"\"\n        Explicitly set multiple headers for the given key.\n        See `Headers.get_all`.\n        \"\"\"\n        name = _always_bytes(name)\n        values = [_always_bytes(x) for x in values]\n        return super().set_all(name, values)\n\n    def insert(self, index: int, key: str | bytes, value: str | bytes):\n        key = _always_bytes(key)\n        value = _always_bytes(value)\n        super().insert(index, key, value)\n\n    def items(self, multi=False):\n        if multi:\n            return ((_native(k), _native(v)) for k, v in self.fields)\n        else:\n            return super().items()\n\n\n@dataclass\nclass MessageData(serializable.Serializable):\n    http_version: bytes\n    headers: Headers\n    content: bytes | None\n    trailers: Headers | None\n    timestamp_start: float\n    timestamp_end: float | None\n\n    # noinspection PyUnreachableCode\n    if __debug__:\n\n        def __post_init__(self):\n            for field in fields(self):\n                val = getattr(self, field.name)\n                typecheck.check_option_type(field.name, val, field.type)\n\n    def set_state(self, state):\n        for k, v in state.items():\n            if k in (\"headers\", \"trailers\") and v is not None:\n                v = Headers.from_state(v)\n            setattr(self, k, v)\n\n    def get_state(self):\n        state = vars(self).copy()\n        state[\"headers\"] = state[\"headers\"].get_state()\n        if state[\"trailers\"] is not None:\n            state[\"trailers\"] = state[\"trailers\"].get_state()\n        return state\n\n    @classmethod\n    def from_state(cls, state):\n        state[\"headers\"] = Headers.from_state(state[\"headers\"])\n        if state[\"trailers\"] is not None:\n            state[\"trailers\"] = Headers.from_state(state[\"trailers\"])\n        return cls(**state)\n\n\n@dataclass\nclass RequestData(MessageData):\n    host: str\n    port: int\n    method: bytes\n    scheme: bytes\n    authority: bytes\n    path: bytes\n\n\n@dataclass\nclass ResponseData(MessageData):\n    status_code: int\n    reason: bytes\n\n\nclass Message(serializable.Serializable):\n    \"\"\"Base class for `Request` and `Response`.\"\"\"\n\n    @classmethod\n    def from_state(cls, state):\n        return cls(**state)\n\n    def get_state(self):\n        return self.data.get_state()\n\n    def set_state(self, state):\n        self.data.set_state(state)\n\n    data: MessageData\n    stream: Callable[[bytes], Iterable[bytes] | bytes] | bool = False\n    \"\"\"\n    This attribute controls if the message body should be streamed.\n\n    If `False`, mitmproxy will buffer the entire body before forwarding it to the destination.\n    This makes it possible to perform string replacements on the entire body.\n    If `True`, the message body will not be buffered on the proxy\n    but immediately forwarded instead.\n    Alternatively, a transformation function can be specified, which will be called for each chunk of data.\n    Please note that packet boundaries generally should not be relied upon.\n\n    This attribute must be set in the `requestheaders` or `responseheaders` hook.\n    Setting it in `request` or  `response` is already too late, mitmproxy has buffered the message body already.\n    \"\"\"\n\n    @property\n    def http_version(self) -> str:\n        \"\"\"\n        HTTP version string, for example `HTTP/1.1`.\n        \"\"\"\n        return self.data.http_version.decode(\"utf-8\", \"surrogateescape\")\n\n    @http_version.setter\n    def http_version(self, http_version: str | bytes) -> None:\n        self.data.http_version = strutils.always_bytes(\n            http_version, \"utf-8\", \"surrogateescape\"\n        )\n\n    @property\n    def is_http10(self) -> bool:\n        return self.data.http_version == b\"HTTP/1.0\"\n\n    @property\n    def is_http11(self) -> bool:\n        return self.data.http_version == b\"HTTP/1.1\"\n\n    @property\n    def is_http2(self) -> bool:\n        return self.data.http_version == b\"HTTP/2.0\"\n\n    @property\n    def is_http3(self) -> bool:\n        return self.data.http_version == b\"HTTP/3\"\n\n    @property\n    def headers(self) -> Headers:\n        \"\"\"\n        The HTTP headers.\n        \"\"\"\n        return self.data.headers\n\n    @headers.setter\n    def headers(self, h: Headers) -> None:\n        self.data.headers = h\n\n    @property\n    def trailers(self) -> Headers | None:\n        \"\"\"\n        The [HTTP trailers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Trailer).\n        \"\"\"\n        return self.data.trailers\n\n    @trailers.setter\n    def trailers(self, h: Headers | None) -> None:\n        self.data.trailers = h\n\n    @property\n    def raw_content(self) -> bytes | None:\n        \"\"\"\n        The raw (potentially compressed) HTTP message body.\n\n        In contrast to `Message.content` and `Message.text`, accessing this property never raises.\n\n        *See also:* `Message.content`, `Message.text`\n        \"\"\"\n        return self.data.content\n\n    @raw_content.setter\n    def raw_content(self, content: bytes | None) -> None:\n        self.data.content = content\n\n    @property\n    def content(self) -> bytes | None:\n        \"\"\"\n        The uncompressed HTTP message body as bytes.\n\n        Accessing this attribute may raise a `ValueError` when the HTTP content-encoding is invalid.\n\n        *See also:* `Message.raw_content`, `Message.text`\n        \"\"\"\n        return self.get_content()\n\n    @content.setter\n    def content(self, value: bytes | None) -> None:\n        self.set_content(value)\n\n    @property\n    def text(self) -> str | None:\n        \"\"\"\n        The uncompressed and decoded HTTP message body as text.\n\n        Accessing this attribute may raise a `ValueError` when either content-encoding or charset is invalid.\n\n        *See also:* `Message.raw_content`, `Message.content`\n        \"\"\"\n        return self.get_text()\n\n    @text.setter\n    def text(self, value: str | None) -> None:\n        self.set_text(value)\n\n    def set_content(self, value: bytes | None) -> None:\n        if value is None:\n            self.raw_content = None\n            return\n        if not isinstance(value, bytes):\n            raise TypeError(\n                f\"Message content must be bytes, not {type(value).__name__}. \"\n                \"Please use .text if you want to assign a str.\"\n            )\n        ce = self.headers.get(\"content-encoding\")\n        try:\n            self.raw_content = encoding.encode(value, ce or \"identity\")\n        except ValueError:\n            # So we have an invalid content-encoding?\n            # Let's remove it!\n            del self.headers[\"content-encoding\"]\n            self.raw_content = value\n\n        if \"transfer-encoding\" in self.headers:\n            # https://httpwg.org/specs/rfc7230.html#header.content-length\n            # don't set content-length if a transfer-encoding is provided\n            pass\n        else:\n            self.headers[\"content-length\"] = str(len(self.raw_content))\n\n    def get_content(self, strict: bool = True) -> bytes | None:\n        \"\"\"\n        Similar to `Message.content`, but does not raise if `strict` is `False`.\n        Instead, the compressed message body is returned as-is.\n        \"\"\"\n        if self.raw_content is None:\n            return None\n        ce = self.headers.get(\"content-encoding\")\n        if ce:\n            try:\n                content = encoding.decode(self.raw_content, ce)\n                # A client may illegally specify a byte -> str encoding here (e.g. utf8)\n                if isinstance(content, str):\n                    raise ValueError(f\"Invalid Content-Encoding: {ce}\")\n                return content\n            except ValueError:\n                if strict:\n                    raise\n                return self.raw_content\n        else:\n            return self.raw_content\n\n    def set_text(self, text: str | None) -> None:\n        if text is None:\n            self.content = None\n            return\n        enc = infer_content_encoding(self.headers.get(\"content-type\", \"\"))\n\n        try:\n            self.content = cast(bytes, encoding.encode(text, enc))\n        except ValueError:\n            # Fall back to UTF-8 and update the content-type header.\n            ct = parse_content_type(self.headers.get(\"content-type\", \"\")) or (\n                \"text\",\n                \"plain\",\n                {},\n            )\n            ct[2][\"charset\"] = \"utf-8\"\n            self.headers[\"content-type\"] = assemble_content_type(*ct)\n            enc = \"utf8\"\n            self.content = text.encode(enc, \"surrogateescape\")\n\n    def get_text(self, strict: bool = True) -> str | None:\n        \"\"\"\n        Similar to `Message.text`, but does not raise if `strict` is `False`.\n        Instead, the message body is returned as surrogate-escaped UTF-8.\n        \"\"\"\n        content = self.get_content(strict)\n        if content is None:\n            return None\n        enc = infer_content_encoding(self.headers.get(\"content-type\", \"\"), content)\n        try:\n            return cast(str, encoding.decode(content, enc))\n        except ValueError:\n            if strict:\n                raise\n            return content.decode(\"utf8\", \"surrogateescape\")\n\n    @property\n    def timestamp_start(self) -> float:\n        \"\"\"\n        *Timestamp:* Headers received.\n        \"\"\"\n        return self.data.timestamp_start\n\n    @timestamp_start.setter\n    def timestamp_start(self, timestamp_start: float) -> None:\n        self.data.timestamp_start = timestamp_start\n\n    @property\n    def timestamp_end(self) -> float | None:\n        \"\"\"\n        *Timestamp:* Last byte received.\n        \"\"\"\n        return self.data.timestamp_end\n\n    @timestamp_end.setter\n    def timestamp_end(self, timestamp_end: float | None):\n        self.data.timestamp_end = timestamp_end\n\n    def decode(self, strict: bool = True) -> None:\n        \"\"\"\n        Decodes body based on the current Content-Encoding header, then\n        removes the header. If there is no Content-Encoding header, no\n        action is taken.\n\n        *Raises:*\n         - `ValueError`, when the content-encoding is invalid and strict is True.\n        \"\"\"\n        decoded = self.get_content(strict)\n        self.headers.pop(\"content-encoding\", None)\n        self.content = decoded\n\n    def encode(self, encoding: str) -> None:\n        \"\"\"\n        Encodes body with the given encoding, where e is \"gzip\", \"deflate\", \"identity\", \"br\", or \"zstd\".\n        Any existing content-encodings are overwritten, the content is not decoded beforehand.\n\n        *Raises:*\n         - `ValueError`, when the specified content-encoding is invalid.\n        \"\"\"\n        self.headers[\"content-encoding\"] = encoding\n        self.content = self.raw_content\n        if \"content-encoding\" not in self.headers:\n            raise ValueError(f\"Invalid content encoding {repr(encoding)}\")\n\n    def json(self, **kwargs: Any) -> Any:\n        \"\"\"\n        Returns the JSON encoded content of the response, if any.\n        `**kwargs` are optional arguments that will be\n        passed to `json.loads()`.\n\n        Will raise if the content can not be decoded and then parsed as JSON.\n\n        *Raises:*\n         - `json.decoder.JSONDecodeError` if content is not valid JSON.\n         - `TypeError` if the content is not available, for example because the response\n            has been streamed.\n        \"\"\"\n        content = self.get_content(strict=False)\n        if content is None:\n            raise TypeError(\"Message content is not available.\")\n        else:\n            return json.loads(content, **kwargs)\n\n\nclass Request(Message):\n    \"\"\"\n    An HTTP request.\n    \"\"\"\n\n    data: RequestData\n\n    def __init__(\n        self,\n        host: str,\n        port: int,\n        method: bytes,\n        scheme: bytes,\n        authority: bytes,\n        path: bytes,\n        http_version: bytes,\n        headers: Headers | tuple[tuple[bytes, bytes], ...],\n        content: bytes | None,\n        trailers: Headers | tuple[tuple[bytes, bytes], ...] | None,\n        timestamp_start: float,\n        timestamp_end: float | None,\n    ):\n        # auto-convert invalid types to retain compatibility with older code.\n        if isinstance(host, bytes):\n            host = host.decode(\"idna\", \"strict\")\n        if isinstance(method, str):\n            method = method.encode(\"ascii\", \"strict\")\n        if isinstance(scheme, str):\n            scheme = scheme.encode(\"ascii\", \"strict\")\n        if isinstance(authority, str):\n            authority = authority.encode(\"ascii\", \"strict\")\n        if isinstance(path, str):\n            path = path.encode(\"ascii\", \"strict\")\n        if isinstance(http_version, str):\n            http_version = http_version.encode(\"ascii\", \"strict\")\n\n        if isinstance(content, str):\n            raise ValueError(f\"Content must be bytes, not {type(content).__name__}\")\n        if not isinstance(headers, Headers):\n            headers = Headers(headers)\n        if trailers is not None and not isinstance(trailers, Headers):\n            trailers = Headers(trailers)\n\n        self.data = RequestData(\n            host=host,\n            port=port,\n            method=method,\n            scheme=scheme,\n            authority=authority,\n            path=path,\n            http_version=http_version,\n            headers=headers,\n            content=content,\n            trailers=trailers,\n            timestamp_start=timestamp_start,\n            timestamp_end=timestamp_end,\n        )\n\n    def __repr__(self) -> str:\n        if self.host and self.port:\n            hostport = f\"{self.host}:{self.port}\"\n        else:\n            hostport = \"\"\n        path = self.path or \"\"\n        return f\"Request({self.method} {hostport}{path})\"\n\n    @classmethod\n    def make(\n        cls,\n        method: str,\n        url: str,\n        content: bytes | str = \"\",\n        headers: (\n            Headers | dict[str | bytes, str | bytes] | Iterable[tuple[bytes, bytes]]\n        ) = (),\n    ) -> \"Request\":\n        \"\"\"\n        Simplified API for creating request objects.\n        \"\"\"\n        # Headers can be list or dict, we differentiate here.\n        if isinstance(headers, Headers):\n            pass\n        elif isinstance(headers, dict):\n            headers = Headers(\n                (\n                    always_bytes(k, \"utf-8\", \"surrogateescape\"),\n                    always_bytes(v, \"utf-8\", \"surrogateescape\"),\n                )\n                for k, v in headers.items()\n            )\n        elif isinstance(headers, Iterable):\n            headers = Headers(headers)  # type: ignore\n        else:\n            raise TypeError(\n                \"Expected headers to be an iterable or dict, but is {}.\".format(\n                    type(headers).__name__\n                )\n            )\n\n        req = cls(\n            \"\",\n            0,\n            method.encode(\"utf-8\", \"surrogateescape\"),\n            b\"\",\n            b\"\",\n            b\"\",\n            b\"HTTP/1.1\",\n            headers,\n            b\"\",\n            None,\n            time.time(),\n            time.time(),\n        )\n\n        req.url = url\n        # Assign this manually to update the content-length header.\n        if isinstance(content, bytes):\n            req.content = content\n        elif isinstance(content, str):\n            req.text = content\n        else:\n            raise TypeError(\n                f\"Expected content to be str or bytes, but is {type(content).__name__}.\"\n            )\n\n        return req\n\n    @property\n    def first_line_format(self) -> str:\n        \"\"\"\n        *Read-only:* HTTP request form as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230#section-5.3).\n\n        origin-form and asterisk-form are subsumed as \"relative\".\n        \"\"\"\n        if self.method == \"CONNECT\":\n            return \"authority\"\n        elif self.authority:\n            return \"absolute\"\n        else:\n            return \"relative\"\n\n    @property\n    def method(self) -> str:\n        \"\"\"\n        HTTP request method, e.g. \"GET\".\n        \"\"\"\n        return self.data.method.decode(\"utf-8\", \"surrogateescape\").upper()\n\n    @method.setter\n    def method(self, val: str | bytes) -> None:\n        self.data.method = always_bytes(val, \"utf-8\", \"surrogateescape\")\n\n    @property\n    def scheme(self) -> str:\n        \"\"\"\n        HTTP request scheme, which should be \"http\" or \"https\".\n        \"\"\"\n        return self.data.scheme.decode(\"utf-8\", \"surrogateescape\")\n\n    @scheme.setter\n    def scheme(self, val: str | bytes) -> None:\n        self.data.scheme = always_bytes(val, \"utf-8\", \"surrogateescape\")\n\n    @property\n    def authority(self) -> str:\n        \"\"\"\n        HTTP request authority.\n\n        For HTTP/1, this is the authority portion of the request target\n        (in either absolute-form or authority-form).\n        For origin-form and asterisk-form requests, this property is set to an empty string.\n\n        For HTTP/2, this is the :authority pseudo header.\n\n        *See also:* `Request.host`, `Request.host_header`, `Request.pretty_host`\n        \"\"\"\n        try:\n            return self.data.authority.decode(\"idna\")\n        except UnicodeError:\n            return self.data.authority.decode(\"utf8\", \"surrogateescape\")\n\n    @authority.setter\n    def authority(self, val: str | bytes) -> None:\n        if isinstance(val, str):\n            try:\n                val = val.encode(\"idna\", \"strict\")\n            except UnicodeError:\n                val = val.encode(\"utf8\", \"surrogateescape\")  # type: ignore\n        self.data.authority = val\n\n    @property\n    def host(self) -> str:\n        \"\"\"\n        Target server for this request. This may be parsed from the raw request\n        (e.g. from a ``GET http://example.com/ HTTP/1.1`` request line)\n        or inferred from the proxy mode (e.g. an IP in transparent mode).\n\n        Setting the host attribute also updates the host header and authority information, if present.\n\n        *See also:* `Request.authority`, `Request.host_header`, `Request.pretty_host`\n        \"\"\"\n        return self.data.host\n\n    @host.setter\n    def host(self, val: str | bytes) -> None:\n        self.data.host = always_str(val, \"idna\", \"strict\")\n        self._update_host_and_authority()\n\n    @property\n    def host_header(self) -> str | None:\n        \"\"\"\n        The request's host/authority header.\n\n        This property maps to either ``request.headers[\"Host\"]`` or\n        ``request.authority``, depending on whether it's HTTP/1.x or HTTP/2.0.\n\n        *See also:* `Request.authority`,`Request.host`, `Request.pretty_host`\n        \"\"\"\n        if self.is_http2 or self.is_http3:\n            return self.authority or self.data.headers.get(\"Host\", None)\n        else:\n            return self.data.headers.get(\"Host\", None)\n\n    @host_header.setter\n    def host_header(self, val: None | str | bytes) -> None:\n        if val is None:\n            if self.is_http2 or self.is_http3:\n                self.data.authority = b\"\"\n            self.headers.pop(\"Host\", None)\n        else:\n            if self.is_http2 or self.is_http3:\n                self.authority = val  # type: ignore\n            if not (self.is_http2 or self.is_http3) or \"Host\" in self.headers:\n                # For h2, we only overwrite, but not create, as :authority is the h2 host header.\n                self.headers[\"Host\"] = val\n\n    @property\n    def port(self) -> int:\n        \"\"\"\n        Target port.\n        \"\"\"\n        return self.data.port\n\n    @port.setter\n    def port(self, port: int) -> None:\n        if not isinstance(port, int):\n            raise ValueError(f\"Port must be an integer, not {port!r}.\")\n\n        self.data.port = port\n        self._update_host_and_authority()\n\n    def _update_host_and_authority(self) -> None:\n        val = url.hostport(self.scheme, self.host, self.port)\n\n        # Update host header\n        if \"Host\" in self.data.headers:\n            self.data.headers[\"Host\"] = val\n        # Update authority\n        if self.data.authority:\n            self.authority = val\n\n    @property\n    def path(self) -> str:\n        \"\"\"\n        HTTP request path, e.g. \"/index.html\" or \"/index.html?a=b\".\n        Usually starts with a slash, except for OPTIONS requests, which may just be \"*\".\n\n        This attribute includes both path and query parts of the target URI\n        (see Sections 3.3 and 3.4 of [RFC3986](https://datatracker.ietf.org/doc/html/rfc3986)).\n        \"\"\"\n        return self.data.path.decode(\"utf-8\", \"surrogateescape\")\n\n    @path.setter\n    def path(self, val: str | bytes) -> None:\n        self.data.path = always_bytes(val, \"utf-8\", \"surrogateescape\")\n\n    @property\n    def url(self) -> str:\n        \"\"\"\n        The full URL string, constructed from `Request.scheme`, `Request.host`, `Request.port` and `Request.path`.\n\n        Settings this property updates these attributes as well.\n        \"\"\"\n        if self.first_line_format == \"authority\":\n            return f\"{self.host}:{self.port}\"\n        return url.unparse(self.scheme, self.host, self.port, self.path)\n\n    @url.setter\n    def url(self, val: str | bytes) -> None:\n        val = always_str(val, \"utf-8\", \"surrogateescape\")\n        self.scheme, self.host, self.port, self.path = url.parse(val)\n\n    @property\n    def pretty_host(self) -> str:\n        \"\"\"\n        *Read-only:* Like `Request.host`, but using `Request.host_header` header as an additional (preferred) data source.\n        This is useful in transparent mode where `Request.host` is only an IP address.\n\n        *Warning:* When working in adversarial environments, this may not reflect the actual destination\n        as the Host header could be spoofed.\n        \"\"\"\n        authority = self.host_header\n        if authority:\n            return url.parse_authority(authority, check=False)[0]\n        else:\n            return self.host\n\n    @property\n    def pretty_url(self) -> str:\n        \"\"\"\n        *Read-only:* Like `Request.url`, but using `Request.pretty_host` instead of `Request.host`.\n        \"\"\"\n        if self.first_line_format == \"authority\":\n            return self.authority\n\n        host_header = self.host_header\n        if not host_header:\n            return self.url\n\n        pretty_host, pretty_port = url.parse_authority(host_header, check=False)\n        pretty_port = pretty_port or url.default_port(self.scheme) or 443\n\n        return url.unparse(self.scheme, pretty_host, pretty_port, self.path)\n\n    def _get_query(self):\n        query = urllib.parse.urlparse(self.url).query\n        return tuple(url.decode(query))\n\n    def _set_query(self, query_data):\n        query = url.encode(query_data)\n        _, _, path, params, _, fragment = urllib.parse.urlparse(self.url)\n        self.path = urllib.parse.urlunparse([\"\", \"\", path, params, query, fragment])\n\n    @property\n    def query(self) -> multidict.MultiDictView[str, str]:\n        \"\"\"\n        The request query as a mutable mapping view on the request's path.\n        For the most part, this behaves like a dictionary.\n        Modifications to the MultiDictView update `Request.path`, and vice versa.\n        \"\"\"\n        return multidict.MultiDictView(self._get_query, self._set_query)\n\n    @query.setter\n    def query(self, value):\n        self._set_query(value)\n\n    def _get_cookies(self):\n        h = self.headers.get_all(\"Cookie\")\n        return tuple(cookies.parse_cookie_headers(h))\n\n    def _set_cookies(self, value):\n        self.headers[\"cookie\"] = cookies.format_cookie_header(value)\n\n    @property\n    def cookies(self) -> multidict.MultiDictView[str, str]:\n        \"\"\"\n        The request cookies.\n        For the most part, this behaves like a dictionary.\n        Modifications to the MultiDictView update `Request.headers`, and vice versa.\n        \"\"\"\n        return multidict.MultiDictView(self._get_cookies, self._set_cookies)\n\n    @cookies.setter\n    def cookies(self, value):\n        self._set_cookies(value)\n\n    @property\n    def path_components(self) -> tuple[str, ...]:\n        \"\"\"\n        The URL's path components as a tuple of strings.\n        Components are unquoted.\n        \"\"\"\n        path = urllib.parse.urlparse(self.url).path\n        # This needs to be a tuple so that it's immutable.\n        # Otherwise, this would fail silently:\n        #   request.path_components.append(\"foo\")\n        return tuple(url.unquote(i) for i in path.split(\"/\") if i)\n\n    @path_components.setter\n    def path_components(self, components: Iterable[str]):\n        components = map(lambda x: url.quote(x, safe=\"\"), components)\n        path = \"/\" + \"/\".join(components)\n        _, _, _, params, query, fragment = urllib.parse.urlparse(self.url)\n        self.path = urllib.parse.urlunparse([\"\", \"\", path, params, query, fragment])\n\n    def anticache(self) -> None:\n        \"\"\"\n        Modifies this request to remove headers that might produce a cached response.\n        \"\"\"\n        delheaders = (\n            \"if-modified-since\",\n            \"if-none-match\",\n        )\n        for i in delheaders:\n            self.headers.pop(i, None)\n\n    def anticomp(self) -> None:\n        \"\"\"\n        Modify the Accept-Encoding header to only accept uncompressed responses.\n        \"\"\"\n        self.headers[\"accept-encoding\"] = \"identity\"\n\n    def constrain_encoding(self) -> None:\n        \"\"\"\n        Limits the permissible Accept-Encoding values, based on what we can decode appropriately.\n        \"\"\"\n        accept_encoding = self.headers.get(\"accept-encoding\")\n        if accept_encoding:\n            self.headers[\"accept-encoding\"] = \", \".join(\n                e\n                for e in {\"gzip\", \"identity\", \"deflate\", \"br\", \"zstd\"}\n                if e in accept_encoding\n            )\n\n    def _get_urlencoded_form(self):\n        is_valid_content_type = (\n            \"application/x-www-form-urlencoded\"\n            in self.headers.get(\"content-type\", \"\").lower()\n        )\n        if is_valid_content_type:\n            return tuple(url.decode(self.get_text(strict=False)))\n        return ()\n\n    def _set_urlencoded_form(self, form_data: Sequence[tuple[str, str]]) -> None:\n        \"\"\"\n        Sets the body to the URL-encoded form data, and adds the appropriate content-type header.\n        This will overwrite the existing content if there is one.\n        \"\"\"\n        self.headers[\"content-type\"] = \"application/x-www-form-urlencoded\"\n        self.content = url.encode(form_data, self.get_text(strict=False)).encode()\n\n    @property\n    def urlencoded_form(self) -> multidict.MultiDictView[str, str]:\n        \"\"\"\n        The URL-encoded form data.\n\n        If the content-type indicates non-form data or the form could not be parsed, this is set to\n        an empty `MultiDictView`.\n\n        Modifications to the MultiDictView update `Request.content`, and vice versa.\n        \"\"\"\n        return multidict.MultiDictView(\n            self._get_urlencoded_form, self._set_urlencoded_form\n        )\n\n    @urlencoded_form.setter\n    def urlencoded_form(self, value):\n        self._set_urlencoded_form(value)\n\n    def _get_multipart_form(self) -> list[tuple[bytes, bytes]]:\n        is_valid_content_type = (\n            \"multipart/form-data\" in self.headers.get(\"content-type\", \"\").lower()\n        )\n        if is_valid_content_type and self.content is not None:\n            try:\n                return multipart.decode_multipart(\n                    self.headers.get(\"content-type\"), self.content\n                )\n            except ValueError:\n                pass\n        return []\n\n    def _set_multipart_form(self, value: list[tuple[bytes, bytes]]) -> None:\n        ct = self.headers.get(\"content-type\", \"\")\n        is_valid_content_type = ct.lower().startswith(\"multipart/form-data\")\n        if not is_valid_content_type:\n            \"\"\"\n            Generate a random boundary here.\n\n            See <https://datatracker.ietf.org/doc/html/rfc2046#section-5.1.1> for specifications\n            on generating the boundary.\n            \"\"\"\n            boundary = \"-\" * 20 + binascii.hexlify(os.urandom(16)).decode()\n            self.headers[\"content-type\"] = ct = (\n                f\"multipart/form-data; boundary={boundary}\"\n            )\n        self.content = multipart.encode_multipart(ct, value)\n\n    @property\n    def multipart_form(self) -> multidict.MultiDictView[bytes, bytes]:\n        \"\"\"\n        The multipart form data.\n\n        If the content-type indicates non-form data or the form could not be parsed, this is set to\n        an empty `MultiDictView`.\n\n        Modifications to the MultiDictView update `Request.content`, and vice versa.\n        \"\"\"\n        return multidict.MultiDictView(\n            self._get_multipart_form, self._set_multipart_form\n        )\n\n    @multipart_form.setter\n    def multipart_form(self, value: list[tuple[bytes, bytes]]) -> None:\n        self._set_multipart_form(value)\n\n\nclass Response(Message):\n    \"\"\"\n    An HTTP response.\n    \"\"\"\n\n    data: ResponseData\n\n    def __init__(\n        self,\n        http_version: bytes,\n        status_code: int,\n        reason: bytes,\n        headers: Headers | tuple[tuple[bytes, bytes], ...],\n        content: bytes | None,\n        trailers: None | Headers | tuple[tuple[bytes, bytes], ...],\n        timestamp_start: float,\n        timestamp_end: float | None,\n    ):\n        # auto-convert invalid types to retain compatibility with older code.\n        if isinstance(http_version, str):\n            http_version = http_version.encode(\"ascii\", \"strict\")\n        if isinstance(reason, str):\n            reason = reason.encode(\"ascii\", \"strict\")\n\n        if isinstance(content, str):\n            raise ValueError(f\"Content must be bytes, not {type(content).__name__}\")\n        if not isinstance(headers, Headers):\n            headers = Headers(headers)\n        if trailers is not None and not isinstance(trailers, Headers):\n            trailers = Headers(trailers)\n\n        self.data = ResponseData(\n            http_version=http_version,\n            status_code=status_code,\n            reason=reason,\n            headers=headers,\n            content=content,\n            trailers=trailers,\n            timestamp_start=timestamp_start,\n            timestamp_end=timestamp_end,\n        )\n\n    def __repr__(self) -> str:\n        if self.raw_content:\n            ct = self.headers.get(\"content-type\", \"unknown content type\")\n            size = human.pretty_size(len(self.raw_content))\n            details = f\"{ct}, {size}\"\n        else:\n            details = \"no content\"\n        return f\"Response({self.status_code}, {details})\"\n\n    @classmethod\n    def make(\n        cls,\n        status_code: int = 200,\n        content: bytes | str = b\"\",\n        headers: (\n            Headers | Mapping[str, str | bytes] | Iterable[tuple[bytes, bytes]]\n        ) = (),\n    ) -> \"Response\":\n        \"\"\"\n        Simplified API for creating response objects.\n        \"\"\"\n        if isinstance(headers, Headers):\n            headers = headers\n        elif isinstance(headers, dict):\n            headers = Headers(\n                (\n                    always_bytes(k, \"utf-8\", \"surrogateescape\"),  # type: ignore\n                    always_bytes(v, \"utf-8\", \"surrogateescape\"),\n                )\n                for k, v in headers.items()\n            )\n        elif isinstance(headers, Iterable):\n            headers = Headers(headers)  # type: ignore\n        else:\n            raise TypeError(\n                \"Expected headers to be an iterable or dict, but is {}.\".format(\n                    type(headers).__name__\n                )\n            )\n\n        resp = cls(\n            b\"HTTP/1.1\",\n            status_code,\n            status_codes.RESPONSES.get(status_code, \"\").encode(),\n            headers,\n            None,\n            None,\n            time.time(),\n            time.time(),\n        )\n\n        # Assign this manually to update the content-length header.\n        if isinstance(content, bytes):\n            resp.content = content\n        elif isinstance(content, str):\n            resp.text = content\n        else:\n            raise TypeError(\n                f\"Expected content to be str or bytes, but is {type(content).__name__}.\"\n            )\n\n        return resp\n\n    @property\n    def status_code(self) -> int:\n        \"\"\"\n        HTTP Status Code, e.g. ``200``.\n        \"\"\"\n        return self.data.status_code\n\n    @status_code.setter\n    def status_code(self, status_code: int) -> None:\n        self.data.status_code = status_code\n\n    @property\n    def reason(self) -> str:\n        \"\"\"\n        HTTP reason phrase, for example \"Not Found\".\n\n        HTTP/2 responses do not contain a reason phrase, an empty string will be returned instead.\n        \"\"\"\n        # Encoding: http://stackoverflow.com/a/16674906/934719\n        return self.data.reason.decode(\"ISO-8859-1\")\n\n    @reason.setter\n    def reason(self, reason: str | bytes) -> None:\n        self.data.reason = strutils.always_bytes(reason, \"ISO-8859-1\")\n\n    def _get_cookies(self):\n        h = self.headers.get_all(\"set-cookie\")\n        all_cookies = cookies.parse_set_cookie_headers(h)\n        return tuple((name, (value, attrs)) for name, value, attrs in all_cookies)\n\n    def _set_cookies(self, value):\n        cookie_headers = []\n        for k, v in value:\n            header = cookies.format_set_cookie_header([(k, v[0], v[1])])\n            cookie_headers.append(header)\n        self.headers.set_all(\"set-cookie\", cookie_headers)\n\n    @property\n    def cookies(\n        self,\n    ) -> multidict.MultiDictView[str, tuple[str, multidict.MultiDict[str, str | None]]]:\n        \"\"\"\n        The response cookies. A possibly empty `MultiDictView`, where the keys are cookie\n        name strings, and values are `(cookie value, attributes)` tuples. Within\n        attributes, unary attributes (e.g. `HTTPOnly`) are indicated by a `None` value.\n        Modifications to the MultiDictView update `Response.headers`, and vice versa.\n\n        *Warning:* Changes to `attributes` will not be picked up unless you also reassign\n        the `(cookie value, attributes)` tuple directly in the `MultiDictView`.\n        \"\"\"\n        return multidict.MultiDictView(self._get_cookies, self._set_cookies)\n\n    @cookies.setter\n    def cookies(self, value):\n        self._set_cookies(value)\n\n    def refresh(self, now=None):\n        \"\"\"\n        This fairly complex and heuristic function refreshes a server\n        response for replay.\n\n         - It adjusts date, expires, and last-modified headers.\n         - It adjusts cookie expiration.\n        \"\"\"\n        if not now:\n            now = time.time()\n        delta = now - self.timestamp_start\n        refresh_headers = [\n            \"date\",\n            \"expires\",\n            \"last-modified\",\n        ]\n        for i in refresh_headers:\n            if i in self.headers:\n                d = parsedate_tz(self.headers[i])\n                if d:\n                    new = mktime_tz(d) + delta\n                    try:\n                        self.headers[i] = formatdate(new, usegmt=True)\n                    except OSError:  # pragma: no cover\n                        pass  # value out of bounds on Windows only (which is why we exclude it from coverage).\n        c = []\n        for set_cookie_header in self.headers.get_all(\"set-cookie\"):\n            try:\n                refreshed = cookies.refresh_set_cookie_header(set_cookie_header, delta)\n            except ValueError:\n                refreshed = set_cookie_header\n            c.append(refreshed)\n        if c:\n            self.headers.set_all(\"set-cookie\", c)\n\n\nclass HTTPFlow(flow.Flow):\n    \"\"\"\n    An HTTPFlow is a collection of objects representing a single HTTP\n    transaction.\n    \"\"\"\n\n    request: Request\n    \"\"\"The client's HTTP request.\"\"\"\n    response: Response | None = None\n    \"\"\"The server's HTTP response.\"\"\"\n    error: flow.Error | None = None\n    \"\"\"\n    A connection or protocol error affecting this flow.\n\n    Note that it's possible for a Flow to have both a response and an error\n    object. This might happen, for instance, when a response was received\n    from the server, but there was an error sending it back to the client.\n    \"\"\"\n\n    websocket: WebSocketData | None = None\n    \"\"\"\n    If this HTTP flow initiated a WebSocket connection, this attribute contains all associated WebSocket data.\n    \"\"\"\n\n    def get_state(self) -> serializable.State:\n        return {\n            **super().get_state(),\n            \"request\": self.request.get_state(),\n            \"response\": self.response.get_state() if self.response else None,\n            \"websocket\": self.websocket.get_state() if self.websocket else None,\n        }\n\n    def set_state(self, state: serializable.State) -> None:\n        self.request = Request.from_state(state.pop(\"request\"))\n        self.response = Response.from_state(r) if (r := state.pop(\"response\")) else None\n        self.websocket = (\n            WebSocketData.from_state(w) if (w := state.pop(\"websocket\")) else None\n        )\n        super().set_state(state)\n\n    def __repr__(self):\n        s = \"<HTTPFlow\"\n        for a in (\n            \"request\",\n            \"response\",\n            \"websocket\",\n            \"error\",\n            \"client_conn\",\n            \"server_conn\",\n        ):\n            if getattr(self, a, False):\n                s += f\"\\r\\n  {a} = {{flow.{a}}}\"\n        s += \">\"\n        return s.format(flow=self)\n\n    @property\n    def timestamp_start(self) -> float:\n        \"\"\"*Read-only:* An alias for `Request.timestamp_start`.\"\"\"\n        return self.request.timestamp_start\n\n    @property\n    def mode(self) -> str:  # pragma: no cover\n        warnings.warn(\"HTTPFlow.mode is deprecated.\", DeprecationWarning, stacklevel=2)\n        return getattr(self, \"_mode\", \"regular\")\n\n    @mode.setter\n    def mode(self, val: str) -> None:  # pragma: no cover\n        warnings.warn(\"HTTPFlow.mode is deprecated.\", DeprecationWarning, stacklevel=2)\n        self._mode = val\n\n    def copy(self):\n        f = super().copy()\n        if self.request:\n            f.request = self.request.copy()\n        if self.response:\n            f.response = self.response.copy()\n        return f\n\n\n__all__ = [\n    \"HTTPFlow\",\n    \"Message\",\n    \"Request\",\n    \"Response\",\n    \"Headers\",\n]\n", "mitmproxy/exceptions.py": "\"\"\"\n\nEdit 2020-12 @mhils:\n    The advice below hasn't paid off in any form. We now just use builtin exceptions and specialize where necessary.\n\n---\n\nWe try to be very hygienic regarding the exceptions we throw:\n\n- Every exception that might be externally visible to users shall be a subclass\n  of MitmproxyException.p\n- Every exception in the base net module shall be a subclass\n  of NetlibException, and will not be propagated directly to users.\n\nSee also: http://lucumr.pocoo.org/2014/10/16/on-error-handling/\n\"\"\"\n\n\nclass MitmproxyException(Exception):\n    \"\"\"\n    Base class for all exceptions thrown by mitmproxy.\n    \"\"\"\n\n    def __init__(self, message=None):\n        super().__init__(message)\n\n\nclass FlowReadException(MitmproxyException):\n    pass\n\n\nclass ControlException(MitmproxyException):\n    pass\n\n\nclass CommandError(Exception):\n    pass\n\n\nclass OptionsError(MitmproxyException):\n    pass\n\n\nclass AddonManagerError(MitmproxyException):\n    pass\n\n\nclass AddonHalt(MitmproxyException):\n    \"\"\"\n    Raised by addons to signal that no further handlers should handle this event.\n    \"\"\"\n", "mitmproxy/certs.py": "import contextlib\nimport datetime\nimport ipaddress\nimport os\nimport sys\nimport warnings\nfrom collections.abc import Iterable\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import cast\nfrom typing import NewType\nfrom typing import Optional\nfrom typing import Union\n\nimport OpenSSL\nfrom cryptography import x509\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives.asymmetric import dsa\nfrom cryptography.hazmat.primitives.asymmetric import ec\nfrom cryptography.hazmat.primitives.asymmetric import rsa\nfrom cryptography.hazmat.primitives.serialization import pkcs12\nfrom cryptography.x509 import ExtendedKeyUsageOID\nfrom cryptography.x509 import NameOID\n\nfrom mitmproxy.coretypes import serializable\n\n# Default expiry must not be too long: https://github.com/mitmproxy/mitmproxy/issues/815\nCA_EXPIRY = datetime.timedelta(days=10 * 365)\nCERT_EXPIRY = datetime.timedelta(days=365)\n\n# Generated with \"openssl dhparam\". It's too slow to generate this on startup.\nDEFAULT_DHPARAM = b\"\"\"\n-----BEGIN DH PARAMETERS-----\nMIICCAKCAgEAyT6LzpwVFS3gryIo29J5icvgxCnCebcdSe/NHMkD8dKJf8suFCg3\nO2+dguLakSVif/t6dhImxInJk230HmfC8q93hdcg/j8rLGJYDKu3ik6H//BAHKIv\nj5O9yjU3rXCfmVJQic2Nne39sg3CreAepEts2TvYHhVv3TEAzEqCtOuTjgDv0ntJ\nGwpj+BJBRQGG9NvprX1YGJ7WOFBP/hWU7d6tgvE6Xa7T/u9QIKpYHMIkcN/l3ZFB\nchZEqVlyrcngtSXCROTPcDOQ6Q8QzhaBJS+Z6rcsd7X+haiQqvoFcmaJ08Ks6LQC\nZIL2EtYJw8V8z7C0igVEBIADZBI6OTbuuhDwRw//zU1uq52Oc48CIZlGxTYG/Evq\no9EWAXUYVzWkDSTeBH1r4z/qLPE2cnhtMxbFxuvK53jGB0emy2y1Ei6IhKshJ5qX\nIB/aE7SSHyQ3MDHHkCmQJCsOd4Mo26YX61NZ+n501XjqpCBQ2+DfZCBh8Va2wDyv\nA2Ryg9SUz8j0AXViRNMJgJrr446yro/FuJZwnQcO3WQnXeqSBnURqKjmqkeFP+d8\n6mk2tqJaY507lRNqtGlLnj7f5RNoBFJDCLBNurVgfvq9TCVWKDIFD4vZRjCrnl6I\nrD693XKIHUCWOjMh1if6omGXKHH40QuME2gNa50+YPn1iYDl88uDbbMCAQI=\n-----END DH PARAMETERS-----\n\"\"\"\n\n\nclass Cert(serializable.Serializable):\n    \"\"\"Representation of a (TLS) certificate.\"\"\"\n\n    _cert: x509.Certificate\n\n    def __init__(self, cert: x509.Certificate):\n        assert isinstance(cert, x509.Certificate)\n        self._cert = cert\n\n    def __eq__(self, other):\n        return self.fingerprint() == other.fingerprint()\n\n    def __repr__(self):\n        altnames = [str(x.value) for x in self.altnames]\n        return f\"<Cert(cn={self.cn!r}, altnames={altnames!r})>\"\n\n    def __hash__(self):\n        return self._cert.__hash__()\n\n    @classmethod\n    def from_state(cls, state):\n        return cls.from_pem(state)\n\n    def get_state(self):\n        return self.to_pem()\n\n    def set_state(self, state):\n        self._cert = x509.load_pem_x509_certificate(state)\n\n    @classmethod\n    def from_pem(cls, data: bytes) -> \"Cert\":\n        cert = x509.load_pem_x509_certificate(data)  # type: ignore\n        return cls(cert)\n\n    def to_pem(self) -> bytes:\n        return self._cert.public_bytes(serialization.Encoding.PEM)\n\n    @classmethod\n    def from_pyopenssl(self, x509: OpenSSL.crypto.X509) -> \"Cert\":\n        return Cert(x509.to_cryptography())\n\n    def to_pyopenssl(self) -> OpenSSL.crypto.X509:\n        return OpenSSL.crypto.X509.from_cryptography(self._cert)\n\n    def fingerprint(self) -> bytes:\n        return self._cert.fingerprint(hashes.SHA256())\n\n    @property\n    def issuer(self) -> list[tuple[str, str]]:\n        return _name_to_keyval(self._cert.issuer)\n\n    @property\n    def notbefore(self) -> datetime.datetime:\n        try:\n            # type definitions haven't caught up with new API yet.\n            return self._cert.not_valid_before_utc  # type: ignore\n        except AttributeError:  # pragma: no cover\n            # cryptography < 42.0\n            return self._cert.not_valid_before.replace(tzinfo=datetime.timezone.utc)\n\n    @property\n    def notafter(self) -> datetime.datetime:\n        try:\n            return self._cert.not_valid_after_utc  # type: ignore\n        except AttributeError:  # pragma: no cover\n            return self._cert.not_valid_after.replace(tzinfo=datetime.timezone.utc)\n\n    def has_expired(self) -> bool:\n        if sys.version_info < (3, 11):  # pragma: no cover\n            return datetime.datetime.now(datetime.timezone.utc) > self.notafter\n        return datetime.datetime.now(datetime.UTC) > self.notafter\n\n    @property\n    def subject(self) -> list[tuple[str, str]]:\n        return _name_to_keyval(self._cert.subject)\n\n    @property\n    def serial(self) -> int:\n        return self._cert.serial_number\n\n    @property\n    def keyinfo(self) -> tuple[str, int]:\n        public_key = self._cert.public_key()\n        if isinstance(public_key, rsa.RSAPublicKey):\n            return \"RSA\", public_key.key_size\n        if isinstance(public_key, dsa.DSAPublicKey):\n            return \"DSA\", public_key.key_size\n        if isinstance(public_key, ec.EllipticCurvePublicKey):\n            return f\"EC ({public_key.curve.name})\", public_key.key_size\n        return (\n            public_key.__class__.__name__.replace(\"PublicKey\", \"\").replace(\"_\", \"\"),\n            getattr(public_key, \"key_size\", -1),\n        )  # pragma: no cover\n\n    @property\n    def cn(self) -> str | None:\n        attrs = self._cert.subject.get_attributes_for_oid(x509.NameOID.COMMON_NAME)\n        if attrs:\n            return cast(str, attrs[0].value)\n        return None\n\n    @property\n    def organization(self) -> str | None:\n        attrs = self._cert.subject.get_attributes_for_oid(\n            x509.NameOID.ORGANIZATION_NAME\n        )\n        if attrs:\n            return cast(str, attrs[0].value)\n        return None\n\n    @property\n    def altnames(self) -> x509.GeneralNames:\n        \"\"\"\n        Get all SubjectAlternativeName DNS altnames.\n        \"\"\"\n        try:\n            sans = self._cert.extensions.get_extension_for_class(\n                x509.SubjectAlternativeName\n            ).value\n        except x509.ExtensionNotFound:\n            return x509.GeneralNames([])\n        else:\n            return x509.GeneralNames(sans)\n\n\ndef _name_to_keyval(name: x509.Name) -> list[tuple[str, str]]:\n    parts = []\n    for attr in name:\n        k = attr.rfc4514_string().partition(\"=\")[0]\n        v = cast(str, attr.value)\n        parts.append((k, v))\n    return parts\n\n\ndef create_ca(\n    organization: str,\n    cn: str,\n    key_size: int,\n) -> tuple[rsa.RSAPrivateKeyWithSerialization, x509.Certificate]:\n    now = datetime.datetime.now()\n\n    private_key = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=key_size,\n    )  # type: ignore\n    name = x509.Name(\n        [\n            x509.NameAttribute(NameOID.COMMON_NAME, cn),\n            x509.NameAttribute(NameOID.ORGANIZATION_NAME, organization),\n        ]\n    )\n    builder = x509.CertificateBuilder()\n    builder = builder.serial_number(x509.random_serial_number())\n    builder = builder.subject_name(name)\n    builder = builder.not_valid_before(now - datetime.timedelta(days=2))\n    builder = builder.not_valid_after(now + CA_EXPIRY)\n    builder = builder.issuer_name(name)\n    builder = builder.public_key(private_key.public_key())\n    builder = builder.add_extension(\n        x509.BasicConstraints(ca=True, path_length=None), critical=True\n    )\n    builder = builder.add_extension(\n        x509.ExtendedKeyUsage([ExtendedKeyUsageOID.SERVER_AUTH]), critical=False\n    )\n    builder = builder.add_extension(\n        x509.KeyUsage(\n            digital_signature=False,\n            content_commitment=False,\n            key_encipherment=False,\n            data_encipherment=False,\n            key_agreement=False,\n            key_cert_sign=True,\n            crl_sign=True,\n            encipher_only=False,\n            decipher_only=False,\n        ),\n        critical=True,\n    )\n    builder = builder.add_extension(\n        x509.SubjectKeyIdentifier.from_public_key(private_key.public_key()),\n        critical=False,\n    )\n    cert = builder.sign(private_key=private_key, algorithm=hashes.SHA256())  # type: ignore\n    return private_key, cert\n\n\ndef _fix_legacy_sans(sans: Iterable[x509.GeneralName] | list[str]) -> x509.GeneralNames:\n    \"\"\"\n    SANs used to be a list of strings in mitmproxy 10.1 and below, but now they're a list of GeneralNames.\n    This function converts the old format to the new one.\n    \"\"\"\n    if isinstance(sans, x509.GeneralNames):\n        return sans\n    elif (\n        isinstance(sans, list) and len(sans) > 0 and isinstance(sans[0], str)\n    ):  # pragma: no cover\n        warnings.warn(\n            \"Passing SANs as a list of strings is deprecated.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n\n        ss: list[x509.GeneralName] = []\n        for x in cast(list[str], sans):\n            try:\n                ip = ipaddress.ip_address(x)\n            except ValueError:\n                x = x.encode(\"idna\").decode()\n                ss.append(x509.DNSName(x))\n            else:\n                ss.append(x509.IPAddress(ip))\n        return x509.GeneralNames(ss)\n    else:\n        return x509.GeneralNames(sans)\n\n\ndef dummy_cert(\n    privkey: rsa.RSAPrivateKey,\n    cacert: x509.Certificate,\n    commonname: str | None,\n    sans: Iterable[x509.GeneralName],\n    organization: str | None = None,\n) -> Cert:\n    \"\"\"\n    Generates a dummy certificate.\n\n    privkey: CA private key\n    cacert: CA certificate\n    commonname: Common name for the generated certificate.\n    sans: A list of Subject Alternate Names.\n    organization: Organization name for the generated certificate.\n\n    Returns cert if operation succeeded, None if not.\n    \"\"\"\n    builder = x509.CertificateBuilder()\n    builder = builder.issuer_name(cacert.subject)\n    builder = builder.add_extension(\n        x509.ExtendedKeyUsage([ExtendedKeyUsageOID.SERVER_AUTH]), critical=False\n    )\n    builder = builder.public_key(cacert.public_key())\n\n    now = datetime.datetime.now()\n    builder = builder.not_valid_before(now - datetime.timedelta(days=2))\n    builder = builder.not_valid_after(now + CERT_EXPIRY)\n\n    subject = []\n    is_valid_commonname = commonname is not None and len(commonname) < 64\n    if is_valid_commonname:\n        assert commonname is not None\n        subject.append(x509.NameAttribute(NameOID.COMMON_NAME, commonname))\n    if organization is not None:\n        assert organization is not None\n        subject.append(x509.NameAttribute(NameOID.ORGANIZATION_NAME, organization))\n    builder = builder.subject_name(x509.Name(subject))\n    builder = builder.serial_number(x509.random_serial_number())\n\n    # RFC 5280 \u00a74.2.1.6: subjectAltName is critical if subject is empty.\n    builder = builder.add_extension(\n        x509.SubjectAlternativeName(_fix_legacy_sans(sans)),\n        critical=not is_valid_commonname,\n    )\n\n    # https://datatracker.ietf.org/doc/html/rfc5280#section-4.2.1.1\n    builder = builder.add_extension(\n        x509.AuthorityKeyIdentifier.from_issuer_public_key(cacert.public_key()),\n        critical=False,\n    )\n    # If CA and leaf cert have the same Subject Key Identifier, SChannel breaks in funny ways,\n    # see https://github.com/mitmproxy/mitmproxy/issues/6494.\n    # https://datatracker.ietf.org/doc/html/rfc5280#section-4.2.1.2 states\n    # that SKI is optional for the leaf cert, so we skip that.\n\n    cert = builder.sign(private_key=privkey, algorithm=hashes.SHA256())  # type: ignore\n    return Cert(cert)\n\n\n@dataclass(frozen=True)\nclass CertStoreEntry:\n    cert: Cert\n    privatekey: rsa.RSAPrivateKey\n    chain_file: Path | None\n    chain_certs: list[Cert]\n\n\nTCustomCertId = str  # manually provided certs (e.g. mitmproxy's --certs)\nTGeneratedCertId = tuple[Optional[str], x509.GeneralNames]  # (common_name, sans)\nTCertId = Union[TCustomCertId, TGeneratedCertId]\n\nDHParams = NewType(\"DHParams\", bytes)\n\n\nclass CertStore:\n    \"\"\"\n    Implements an in-memory certificate store.\n    \"\"\"\n\n    STORE_CAP = 100\n    certs: dict[TCertId, CertStoreEntry]\n    expire_queue: list[CertStoreEntry]\n\n    def __init__(\n        self,\n        default_privatekey: rsa.RSAPrivateKey,\n        default_ca: Cert,\n        default_chain_file: Path | None,\n        dhparams: DHParams,\n    ):\n        self.default_privatekey = default_privatekey\n        self.default_ca = default_ca\n        self.default_chain_file = default_chain_file\n        self.default_chain_certs = (\n            x509.load_pem_x509_certificates(self.default_chain_file.read_bytes())\n            if self.default_chain_file\n            else [default_ca]\n        )\n        self.dhparams = dhparams\n        self.certs = {}\n        self.expire_queue = []\n\n    def expire(self, entry: CertStoreEntry) -> None:\n        self.expire_queue.append(entry)\n        if len(self.expire_queue) > self.STORE_CAP:\n            d = self.expire_queue.pop(0)\n            self.certs = {k: v for k, v in self.certs.items() if v != d}\n\n    @staticmethod\n    def load_dhparam(path: Path) -> DHParams:\n        # mitmproxy<=0.10 doesn't generate a dhparam file.\n        # Create it now if necessary.\n        if not path.exists():\n            path.write_bytes(DEFAULT_DHPARAM)\n\n        # we could use cryptography for this, but it's unclear how to convert cryptography's object to pyOpenSSL's\n        # expected format.\n        bio = OpenSSL.SSL._lib.BIO_new_file(  # type: ignore\n            str(path).encode(sys.getfilesystemencoding()), b\"r\"\n        )\n        if bio != OpenSSL.SSL._ffi.NULL:  # type: ignore\n            bio = OpenSSL.SSL._ffi.gc(bio, OpenSSL.SSL._lib.BIO_free)  # type: ignore\n            dh = OpenSSL.SSL._lib.PEM_read_bio_DHparams(  # type: ignore\n                bio,\n                OpenSSL.SSL._ffi.NULL,  # type: ignore\n                OpenSSL.SSL._ffi.NULL,  # type: ignore\n                OpenSSL.SSL._ffi.NULL,  # type: ignore\n            )\n            dh = OpenSSL.SSL._ffi.gc(dh, OpenSSL.SSL._lib.DH_free)  # type: ignore\n            return dh\n        raise RuntimeError(\"Error loading DH Params.\")  # pragma: no cover\n\n    @classmethod\n    def from_store(\n        cls,\n        path: Path | str,\n        basename: str,\n        key_size: int,\n        passphrase: bytes | None = None,\n    ) -> \"CertStore\":\n        path = Path(path)\n        ca_file = path / f\"{basename}-ca.pem\"\n        dhparam_file = path / f\"{basename}-dhparam.pem\"\n        if not ca_file.exists():\n            cls.create_store(path, basename, key_size)\n        return cls.from_files(ca_file, dhparam_file, passphrase)\n\n    @classmethod\n    def from_files(\n        cls, ca_file: Path, dhparam_file: Path, passphrase: bytes | None = None\n    ) -> \"CertStore\":\n        raw = ca_file.read_bytes()\n        key = load_pem_private_key(raw, passphrase)\n        dh = cls.load_dhparam(dhparam_file)\n        certs = x509.load_pem_x509_certificates(raw)\n        ca = Cert(certs[0])\n        if len(certs) > 1:\n            chain_file: Path | None = ca_file\n        else:\n            chain_file = None\n        return cls(key, ca, chain_file, dh)\n\n    @staticmethod\n    @contextlib.contextmanager\n    def umask_secret():\n        \"\"\"\n        Context to temporarily set umask to its original value bitor 0o77.\n        Useful when writing private keys to disk so that only the owner\n        will be able to read them.\n        \"\"\"\n        original_umask = os.umask(0)\n        os.umask(original_umask | 0o77)\n        try:\n            yield\n        finally:\n            os.umask(original_umask)\n\n    @staticmethod\n    def create_store(\n        path: Path, basename: str, key_size: int, organization=None, cn=None\n    ) -> None:\n        path.mkdir(parents=True, exist_ok=True)\n\n        organization = organization or basename\n        cn = cn or basename\n\n        key: rsa.RSAPrivateKeyWithSerialization\n        ca: x509.Certificate\n        key, ca = create_ca(organization=organization, cn=cn, key_size=key_size)\n\n        # Dump the CA plus private key.\n        with CertStore.umask_secret():\n            # PEM format\n            (path / f\"{basename}-ca.pem\").write_bytes(\n                key.private_bytes(\n                    encoding=serialization.Encoding.PEM,\n                    format=serialization.PrivateFormat.TraditionalOpenSSL,\n                    encryption_algorithm=serialization.NoEncryption(),\n                )\n                + ca.public_bytes(serialization.Encoding.PEM)\n            )\n\n            # PKCS12 format for Windows devices\n            (path / f\"{basename}-ca.p12\").write_bytes(\n                pkcs12.serialize_key_and_certificates(  # type: ignore\n                    name=basename.encode(),\n                    key=key,\n                    cert=ca,\n                    cas=None,\n                    encryption_algorithm=serialization.NoEncryption(),\n                )\n            )\n\n        # Dump the certificate in PEM format\n        pem_cert = ca.public_bytes(serialization.Encoding.PEM)\n        (path / f\"{basename}-ca-cert.pem\").write_bytes(pem_cert)\n        # Create a .cer file with the same contents for Android\n        (path / f\"{basename}-ca-cert.cer\").write_bytes(pem_cert)\n\n        # Dump the certificate in PKCS12 format for Windows devices\n        (path / f\"{basename}-ca-cert.p12\").write_bytes(\n            pkcs12.serialize_key_and_certificates(\n                name=basename.encode(),\n                key=None,  # type: ignore\n                cert=ca,\n                cas=None,\n                encryption_algorithm=serialization.NoEncryption(),\n            )\n        )\n\n        (path / f\"{basename}-dhparam.pem\").write_bytes(DEFAULT_DHPARAM)\n\n    def add_cert_file(\n        self, spec: str, path: Path, passphrase: bytes | None = None\n    ) -> None:\n        raw = path.read_bytes()\n        cert = Cert.from_pem(raw)\n        try:\n            key = load_pem_private_key(raw, password=passphrase)\n        except ValueError:\n            key = self.default_privatekey\n\n        self.add_cert(CertStoreEntry(cert, key, path, [cert]), spec)\n\n    def add_cert(self, entry: CertStoreEntry, *names: str) -> None:\n        \"\"\"\n        Adds a cert to the certstore. We register the CN in the cert plus\n        any SANs, and also the list of names provided as an argument.\n        \"\"\"\n        if entry.cert.cn:\n            self.certs[entry.cert.cn] = entry\n        for i in entry.cert.altnames:\n            self.certs[str(i.value)] = entry\n        for i in names:\n            self.certs[i] = entry\n\n    @staticmethod\n    def asterisk_forms(dn: str | x509.GeneralName) -> list[str]:\n        \"\"\"\n        Return all asterisk forms for a domain. For example, for www.example.com this will return\n        [b\"www.example.com\", b\"*.example.com\", b\"*.com\"]. The single wildcard \"*\" is omitted.\n        \"\"\"\n        if isinstance(dn, str):\n            parts = dn.split(\".\")\n            ret = [dn]\n            for i in range(1, len(parts)):\n                ret.append(\"*.\" + \".\".join(parts[i:]))\n            return ret\n        elif isinstance(dn, x509.DNSName):\n            return CertStore.asterisk_forms(dn.value)\n        else:\n            return [str(dn.value)]\n\n    def get_cert(\n        self,\n        commonname: str | None,\n        sans: Iterable[x509.GeneralName],\n        organization: str | None = None,\n    ) -> CertStoreEntry:\n        \"\"\"\n        commonname: Common name for the generated certificate. Must be a\n        valid, plain-ASCII, IDNA-encoded domain name.\n\n        sans: A list of Subject Alternate Names.\n\n        organization: Organization name for the generated certificate.\n        \"\"\"\n        sans = _fix_legacy_sans(sans)\n\n        potential_keys: list[TCertId] = []\n        if commonname:\n            potential_keys.extend(self.asterisk_forms(commonname))\n        for s in sans:\n            potential_keys.extend(self.asterisk_forms(s))\n        potential_keys.append(\"*\")\n        potential_keys.append((commonname, sans))\n\n        name = next(filter(lambda key: key in self.certs, potential_keys), None)\n        if name:\n            entry = self.certs[name]\n        else:\n            entry = CertStoreEntry(\n                cert=dummy_cert(\n                    self.default_privatekey,\n                    self.default_ca._cert,\n                    commonname,\n                    sans,\n                    organization,\n                ),\n                privatekey=self.default_privatekey,\n                chain_file=self.default_chain_file,\n                chain_certs=self.default_chain_certs,\n            )\n            self.certs[(commonname, sans)] = entry\n            self.expire(entry)\n\n        return entry\n\n\ndef load_pem_private_key(data: bytes, password: bytes | None) -> rsa.RSAPrivateKey:\n    \"\"\"\n    like cryptography's load_pem_private_key, but silently falls back to not using a password\n    if the private key is unencrypted.\n    \"\"\"\n    try:\n        return serialization.load_pem_private_key(data, password)  # type: ignore\n    except TypeError:\n        if password is not None:\n            return load_pem_private_key(data, None)\n        raise\n", "mitmproxy/flowfilter.py": "\"\"\"\nThe following operators are understood:\n\n    ~q          Request\n    ~s          Response\n\nHeaders:\n\n    Patterns are matched against \"name: value\" strings. Field names are\n    all-lowercase.\n\n    ~a          Asset content-type in response. Asset content types are:\n                    text/javascript\n                    application/x-javascript\n                    application/javascript\n                    text/css\n                    image/*\n                    font/*\n                    application/font-*\n    ~h rex      Header line in either request or response\n    ~hq rex     Header in request\n    ~hs rex     Header in response\n\n    ~b rex      Expression in the body of either request or response\n    ~bq rex     Expression in the body of request\n    ~bs rex     Expression in the body of response\n    ~t rex      Shortcut for content-type header.\n\n    ~d rex      Request domain\n    ~m rex      Method\n    ~u rex      URL\n    ~c CODE     Response code.\n    rex         Equivalent to ~u rex\n\"\"\"\n\nimport functools\nimport re\nimport sys\nfrom collections.abc import Sequence\nfrom typing import ClassVar\nfrom typing import Protocol\n\nimport pyparsing as pp\n\nfrom mitmproxy import dns\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy import tcp\nfrom mitmproxy import udp\n\n\ndef only(*types):\n    def decorator(fn):\n        @functools.wraps(fn)\n        def filter_types(self, flow):\n            if isinstance(flow, types):\n                return fn(self, flow)\n            return False\n\n        return filter_types\n\n    return decorator\n\n\nclass _Token:\n    def dump(self, indent=0, fp=sys.stdout):\n        print(\n            \"{spacing}{name}{expr}\".format(\n                spacing=\"\\t\" * indent,\n                name=self.__class__.__name__,\n                expr=getattr(self, \"expr\", \"\"),\n            ),\n            file=fp,\n        )\n\n\nclass _Action(_Token):\n    code: ClassVar[str]\n    help: ClassVar[str]\n\n    @classmethod\n    def make(klass, s, loc, toks):\n        return klass(*toks[1:])\n\n\nclass FErr(_Action):\n    code = \"e\"\n    help = \"Match error\"\n\n    def __call__(self, f):\n        return True if f.error else False\n\n\nclass FMarked(_Action):\n    code = \"marked\"\n    help = \"Match marked flows\"\n\n    def __call__(self, f):\n        return bool(f.marked)\n\n\nclass FHTTP(_Action):\n    code = \"http\"\n    help = \"Match HTTP flows\"\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        return True\n\n\nclass FWebSocket(_Action):\n    code = \"websocket\"\n    help = \"Match WebSocket flows\"\n\n    @only(http.HTTPFlow)\n    def __call__(self, f: http.HTTPFlow):\n        return f.websocket is not None\n\n\nclass FTCP(_Action):\n    code = \"tcp\"\n    help = \"Match TCP flows\"\n\n    @only(tcp.TCPFlow)\n    def __call__(self, f):\n        return True\n\n\nclass FUDP(_Action):\n    code = \"udp\"\n    help = \"Match UDP flows\"\n\n    @only(udp.UDPFlow)\n    def __call__(self, f):\n        return True\n\n\nclass FDNS(_Action):\n    code = \"dns\"\n    help = \"Match DNS flows\"\n\n    @only(dns.DNSFlow)\n    def __call__(self, f):\n        return True\n\n\nclass FReq(_Action):\n    code = \"q\"\n    help = \"Match request with no response\"\n\n    @only(http.HTTPFlow, dns.DNSFlow)\n    def __call__(self, f):\n        if not f.response:\n            return True\n\n\nclass FResp(_Action):\n    code = \"s\"\n    help = \"Match response\"\n\n    @only(http.HTTPFlow, dns.DNSFlow)\n    def __call__(self, f):\n        return bool(f.response)\n\n\nclass FAll(_Action):\n    code = \"all\"\n    help = \"Match all flows\"\n\n    def __call__(self, f: flow.Flow):\n        return True\n\n\nclass _Rex(_Action):\n    flags = 0\n    is_binary = True\n\n    def __init__(self, expr):\n        self.expr = expr\n        if self.is_binary:\n            expr = expr.encode()\n        try:\n            self.re = re.compile(expr, self.flags)\n        except Exception:\n            raise ValueError(\"Cannot compile expression.\")\n\n\ndef _check_content_type(rex, message):\n    return any(\n        name.lower() == b\"content-type\" and rex.search(value)\n        for name, value in message.headers.fields\n    )\n\n\nclass FAsset(_Action):\n    code = \"a\"\n    help = \"Match asset in response: CSS, JavaScript, images, fonts.\"\n    ASSET_TYPES = [\n        re.compile(x)\n        for x in [\n            b\"text/javascript\",\n            b\"application/x-javascript\",\n            b\"application/javascript\",\n            b\"text/css\",\n            b\"image/.*\",\n            b\"font/.*\",\n            b\"application/font.*\",\n        ]\n    ]\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        if f.response:\n            for i in self.ASSET_TYPES:\n                if _check_content_type(i, f.response):\n                    return True\n        return False\n\n\nclass FContentType(_Rex):\n    code = \"t\"\n    help = \"Content-type header\"\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        if _check_content_type(self.re, f.request):\n            return True\n        elif f.response and _check_content_type(self.re, f.response):\n            return True\n        return False\n\n\nclass FContentTypeRequest(_Rex):\n    code = \"tq\"\n    help = \"Request Content-Type header\"\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        return _check_content_type(self.re, f.request)\n\n\nclass FContentTypeResponse(_Rex):\n    code = \"ts\"\n    help = \"Response Content-Type header\"\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        if f.response:\n            return _check_content_type(self.re, f.response)\n        return False\n\n\nclass FHead(_Rex):\n    code = \"h\"\n    help = \"Header\"\n    flags = re.MULTILINE\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        if f.request and self.re.search(bytes(f.request.headers)):\n            return True\n        if f.response and self.re.search(bytes(f.response.headers)):\n            return True\n        return False\n\n\nclass FHeadRequest(_Rex):\n    code = \"hq\"\n    help = \"Request header\"\n    flags = re.MULTILINE\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        if f.request and self.re.search(bytes(f.request.headers)):\n            return True\n\n\nclass FHeadResponse(_Rex):\n    code = \"hs\"\n    help = \"Response header\"\n    flags = re.MULTILINE\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        if f.response and self.re.search(bytes(f.response.headers)):\n            return True\n\n\nclass FBod(_Rex):\n    code = \"b\"\n    help = \"Body\"\n    flags = re.DOTALL\n\n    @only(http.HTTPFlow, tcp.TCPFlow, udp.UDPFlow, dns.DNSFlow)\n    def __call__(self, f):\n        if isinstance(f, http.HTTPFlow):\n            if (\n                f.request\n                and (content := f.request.get_content(strict=False)) is not None\n            ):\n                if self.re.search(content):\n                    return True\n            if (\n                f.response\n                and (content := f.response.get_content(strict=False)) is not None\n            ):\n                if self.re.search(content):\n                    return True\n            if f.websocket:\n                for wmsg in f.websocket.messages:\n                    if wmsg.content is not None and self.re.search(wmsg.content):\n                        return True\n        elif isinstance(f, (tcp.TCPFlow, udp.UDPFlow)):\n            for msg in f.messages:\n                if msg.content is not None and self.re.search(msg.content):\n                    return True\n        elif isinstance(f, dns.DNSFlow):\n            if f.request and self.re.search(f.request.content):\n                return True\n            if f.response and self.re.search(f.response.content):\n                return True\n        return False\n\n\nclass FBodRequest(_Rex):\n    code = \"bq\"\n    help = \"Request body\"\n    flags = re.DOTALL\n\n    @only(http.HTTPFlow, tcp.TCPFlow, udp.UDPFlow, dns.DNSFlow)\n    def __call__(self, f):\n        if isinstance(f, http.HTTPFlow):\n            if (\n                f.request\n                and (content := f.request.get_content(strict=False)) is not None\n            ):\n                if self.re.search(content):\n                    return True\n            if f.websocket:\n                for wmsg in f.websocket.messages:\n                    if wmsg.from_client and self.re.search(wmsg.content):\n                        return True\n        elif isinstance(f, (tcp.TCPFlow, udp.UDPFlow)):\n            for msg in f.messages:\n                if msg.from_client and self.re.search(msg.content):\n                    return True\n        elif isinstance(f, dns.DNSFlow):\n            if f.request and self.re.search(f.request.content):\n                return True\n\n\nclass FBodResponse(_Rex):\n    code = \"bs\"\n    help = \"Response body\"\n    flags = re.DOTALL\n\n    @only(http.HTTPFlow, tcp.TCPFlow, udp.UDPFlow, dns.DNSFlow)\n    def __call__(self, f):\n        if isinstance(f, http.HTTPFlow):\n            if (\n                f.response\n                and (content := f.response.get_content(strict=False)) is not None\n            ):\n                if self.re.search(content):\n                    return True\n            if f.websocket:\n                for wmsg in f.websocket.messages:\n                    if not wmsg.from_client and self.re.search(wmsg.content):\n                        return True\n        elif isinstance(f, (tcp.TCPFlow, udp.UDPFlow)):\n            for msg in f.messages:\n                if not msg.from_client and self.re.search(msg.content):\n                    return True\n        elif isinstance(f, dns.DNSFlow):\n            if f.response and self.re.search(f.response.content):\n                return True\n\n\nclass FMethod(_Rex):\n    code = \"m\"\n    help = \"Method\"\n    flags = re.IGNORECASE\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        return bool(self.re.search(f.request.data.method))\n\n\nclass FDomain(_Rex):\n    code = \"d\"\n    help = \"Domain\"\n    flags = re.IGNORECASE\n    is_binary = False\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        return bool(\n            self.re.search(f.request.host) or self.re.search(f.request.pretty_host)\n        )\n\n\nclass FUrl(_Rex):\n    code = \"u\"\n    help = \"URL\"\n    is_binary = False\n    flags = re.IGNORECASE\n\n    # FUrl is special, because it can be \"naked\".\n\n    @classmethod\n    def make(klass, s, loc, toks):\n        if len(toks) > 1:\n            toks = toks[1:]\n        return klass(*toks)\n\n    @only(http.HTTPFlow, dns.DNSFlow)\n    def __call__(self, f):\n        if not f or not f.request:\n            return False\n        if isinstance(f, http.HTTPFlow):\n            return self.re.search(f.request.pretty_url)\n        elif isinstance(f, dns.DNSFlow):\n            return f.request.questions and self.re.search(f.request.questions[0].name)\n\n\nclass FSrc(_Rex):\n    code = \"src\"\n    help = \"Match source address\"\n    is_binary = False\n\n    def __call__(self, f):\n        if not f.client_conn or not f.client_conn.peername:\n            return False\n        r = f\"{f.client_conn.peername[0]}:{f.client_conn.peername[1]}\"\n        return f.client_conn.peername and self.re.search(r)\n\n\nclass FDst(_Rex):\n    code = \"dst\"\n    help = \"Match destination address\"\n    is_binary = False\n\n    def __call__(self, f):\n        if not f.server_conn or not f.server_conn.address:\n            return False\n        r = f\"{f.server_conn.address[0]}:{f.server_conn.address[1]}\"\n        return f.server_conn.address and self.re.search(r)\n\n\nclass FReplay(_Action):\n    code = \"replay\"\n    help = \"Match replayed flows\"\n\n    def __call__(self, f):\n        return f.is_replay is not None\n\n\nclass FReplayClient(_Action):\n    code = \"replayq\"\n    help = \"Match replayed client request\"\n\n    def __call__(self, f):\n        return f.is_replay == \"request\"\n\n\nclass FReplayServer(_Action):\n    code = \"replays\"\n    help = \"Match replayed server response\"\n\n    def __call__(self, f):\n        return f.is_replay == \"response\"\n\n\nclass FMeta(_Rex):\n    code = \"meta\"\n    help = \"Flow metadata\"\n    flags = re.MULTILINE\n    is_binary = False\n\n    def __call__(self, f):\n        m = \"\\n\".join([f\"{key}: {value}\" for key, value in f.metadata.items()])\n        return self.re.search(m)\n\n\nclass FMarker(_Rex):\n    code = \"marker\"\n    help = \"Match marked flows with specified marker\"\n    is_binary = False\n\n    def __call__(self, f):\n        return self.re.search(f.marked)\n\n\nclass FComment(_Rex):\n    code = \"comment\"\n    help = \"Flow comment\"\n    flags = re.MULTILINE\n    is_binary = False\n\n    def __call__(self, f):\n        return self.re.search(f.comment)\n\n\nclass _Int(_Action):\n    def __init__(self, num):\n        self.num = int(num)\n\n\nclass FCode(_Int):\n    code = \"c\"\n    help = \"HTTP response code\"\n\n    @only(http.HTTPFlow)\n    def __call__(self, f):\n        if f.response and f.response.status_code == self.num:\n            return True\n\n\nclass FAnd(_Token):\n    def __init__(self, lst):\n        self.lst = lst\n\n    def dump(self, indent=0, fp=sys.stdout):\n        super().dump(indent, fp)\n        for i in self.lst:\n            i.dump(indent + 1, fp)\n\n    def __call__(self, f):\n        return all(i(f) for i in self.lst)\n\n\nclass FOr(_Token):\n    def __init__(self, lst):\n        self.lst = lst\n\n    def dump(self, indent=0, fp=sys.stdout):\n        super().dump(indent, fp)\n        for i in self.lst:\n            i.dump(indent + 1, fp)\n\n    def __call__(self, f):\n        return any(i(f) for i in self.lst)\n\n\nclass FNot(_Token):\n    def __init__(self, itm):\n        self.itm = itm[0]\n\n    def dump(self, indent=0, fp=sys.stdout):\n        super().dump(indent, fp)\n        self.itm.dump(indent + 1, fp)\n\n    def __call__(self, f):\n        return not self.itm(f)\n\n\nfilter_unary: Sequence[type[_Action]] = [\n    FAsset,\n    FErr,\n    FHTTP,\n    FMarked,\n    FReplay,\n    FReplayClient,\n    FReplayServer,\n    FReq,\n    FResp,\n    FTCP,\n    FUDP,\n    FDNS,\n    FWebSocket,\n    FAll,\n]\nfilter_rex: Sequence[type[_Rex]] = [\n    FBod,\n    FBodRequest,\n    FBodResponse,\n    FContentType,\n    FContentTypeRequest,\n    FContentTypeResponse,\n    FDomain,\n    FDst,\n    FHead,\n    FHeadRequest,\n    FHeadResponse,\n    FMethod,\n    FSrc,\n    FUrl,\n    FMeta,\n    FMarker,\n    FComment,\n]\nfilter_int = [FCode]\n\n\ndef _make():\n    # Order is important - multi-char expressions need to come before narrow\n    # ones.\n    parts = []\n    for cls in filter_unary:\n        f = pp.Literal(f\"~{cls.code}\") + pp.WordEnd()\n        f.setParseAction(cls.make)\n        parts.append(f)\n\n    # This is a bit of a hack to simulate Word(pyparsing_unicode.printables),\n    # which has a horrible performance with len(pyparsing.pyparsing_unicode.printables) == 1114060\n    unicode_words = pp.CharsNotIn(\"()~'\\\"\" + pp.ParserElement.DEFAULT_WHITE_CHARS)\n    unicode_words.skipWhitespace = True\n    regex = (\n        unicode_words\n        | pp.QuotedString('\"', escChar=\"\\\\\")\n        | pp.QuotedString(\"'\", escChar=\"\\\\\")\n    )\n    for cls in filter_rex:\n        f = pp.Literal(f\"~{cls.code}\") + pp.WordEnd() + regex.copy()\n        f.setParseAction(cls.make)\n        parts.append(f)\n\n    for cls in filter_int:\n        f = pp.Literal(f\"~{cls.code}\") + pp.WordEnd() + pp.Word(pp.nums)\n        f.setParseAction(cls.make)\n        parts.append(f)\n\n    # A naked rex is a URL rex:\n    f = regex.copy()\n    f.setParseAction(FUrl.make)\n    parts.append(f)\n\n    atom = pp.MatchFirst(parts)\n    expr = pp.infixNotation(\n        atom,\n        [\n            (pp.Literal(\"!\").suppress(), 1, pp.opAssoc.RIGHT, lambda x: FNot(*x)),\n            (pp.Literal(\"&\").suppress(), 2, pp.opAssoc.LEFT, lambda x: FAnd(*x)),\n            (pp.Literal(\"|\").suppress(), 2, pp.opAssoc.LEFT, lambda x: FOr(*x)),\n        ],\n    )\n    expr = pp.OneOrMore(expr)\n    return expr.setParseAction(lambda x: FAnd(x) if len(x) != 1 else x)\n\n\nbnf = _make()\n\n\nclass TFilter(Protocol):\n    pattern: str\n\n    def __call__(self, f: flow.Flow) -> bool: ...  # pragma: no cover\n\n\ndef parse(s: str) -> TFilter:\n    \"\"\"\n    Parse a filter expression and return the compiled filter function.\n    If the filter syntax is invalid, `ValueError` is raised.\n    \"\"\"\n    if not s:\n        raise ValueError(\"Empty filter expression\")\n    try:\n        flt = bnf.parseString(s, parseAll=True)[0]\n        flt.pattern = s\n        return flt\n    except (pp.ParseException, ValueError) as e:\n        raise ValueError(f\"Invalid filter expression: {s!r}\") from e\n\n\ndef match(flt: str | TFilter, flow: flow.Flow) -> bool:\n    \"\"\"\n    Matches a flow against a compiled filter expression.\n    Returns True if matched, False if not.\n\n    If flt is a string, it will be compiled as a filter expression.\n    If the expression is invalid, ValueError is raised.\n    \"\"\"\n    if isinstance(flt, str):\n        flt = parse(flt)\n    if flt:\n        return flt(flow)\n    return True\n\n\nmatch_all: TFilter = parse(\"~all\")\n\"\"\"A filter function that matches all flows\"\"\"\n\n\nhelp = []\nfor a in filter_unary:\n    help.append((f\"~{a.code}\", a.help))\nfor b in filter_rex:\n    help.append((f\"~{b.code} regex\", b.help))\nfor c in filter_int:\n    help.append((f\"~{c.code} int\", c.help))\nhelp.sort()\nhelp.extend(\n    [\n        (\"!\", \"unary not\"),\n        (\"&\", \"and\"),\n        (\"|\", \"or\"),\n        (\"(...)\", \"grouping\"),\n    ]\n)\n", "mitmproxy/addonmanager.py": "import contextlib\nimport inspect\nimport logging\nimport pprint\nimport sys\nimport traceback\nimport types\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom dataclasses import dataclass\nfrom typing import Any\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import hooks\n\nlogger = logging.getLogger(__name__)\n\n\ndef _get_name(itm):\n    return getattr(itm, \"name\", itm.__class__.__name__.lower())\n\n\ndef cut_traceback(tb, func_name):\n    \"\"\"\n    Cut off a traceback at the function with the given name.\n    The func_name's frame is excluded.\n\n    Args:\n        tb: traceback object, as returned by sys.exc_info()[2]\n        func_name: function name\n\n    Returns:\n        Reduced traceback.\n    \"\"\"\n    tb_orig = tb\n    for _, _, fname, _ in traceback.extract_tb(tb):\n        tb = tb.tb_next\n        if fname == func_name:\n            break\n    return tb or tb_orig\n\n\n@contextlib.contextmanager\ndef safecall():\n    try:\n        yield\n    except (exceptions.AddonHalt, exceptions.OptionsError):\n        raise\n    except Exception:\n        etype, value, tb = sys.exc_info()\n        tb = cut_traceback(tb, \"invoke_addon_sync\")\n        tb = cut_traceback(tb, \"invoke_addon\")\n        assert etype\n        assert value\n        logger.error(\n            f\"Addon error: {value}\",\n            exc_info=(etype, value, tb),\n        )\n\n\nclass Loader:\n    \"\"\"\n    A loader object is passed to the load() event when addons start up.\n    \"\"\"\n\n    def __init__(self, master):\n        self.master = master\n\n    def add_option(\n        self,\n        name: str,\n        typespec: type,\n        default: Any,\n        help: str,\n        choices: Sequence[str] | None = None,\n    ) -> None:\n        \"\"\"\n        Add an option to mitmproxy.\n\n        Help should be a single paragraph with no linebreaks - it will be\n        reflowed by tools. Information on the data type should be omitted -\n        it will be generated and added by tools as needed.\n        \"\"\"\n        assert not isinstance(choices, str)\n        if name in self.master.options:\n            existing = self.master.options._options[name]\n            same_signature = (\n                existing.name == name\n                and existing.typespec == typespec\n                and existing.default == default\n                and existing.help == help\n                and existing.choices == choices\n            )\n            if same_signature:\n                return\n            else:\n                logger.warning(\"Over-riding existing option %s\" % name)\n        self.master.options.add_option(name, typespec, default, help, choices)\n\n    def add_command(self, path: str, func: Callable) -> None:\n        \"\"\"Add a command to mitmproxy.\n\n        Unless you are generating commands programatically,\n        this API should be avoided. Decorate your function with `@mitmproxy.command.command` instead.\n        \"\"\"\n        self.master.commands.add(path, func)\n\n\ndef traverse(chain):\n    \"\"\"\n    Recursively traverse an addon chain.\n    \"\"\"\n    for a in chain:\n        yield a\n        if hasattr(a, \"addons\"):\n            yield from traverse(a.addons)\n\n\n@dataclass\nclass LoadHook(hooks.Hook):\n    \"\"\"\n    Called when an addon is first loaded. This event receives a Loader\n    object, which contains methods for adding options and commands. This\n    method is where the addon configures itself.\n    \"\"\"\n\n    loader: Loader\n\n\nclass AddonManager:\n    def __init__(self, master):\n        self.lookup = {}\n        self.chain = []\n        self.master = master\n        master.options.changed.connect(self._configure_all)\n\n    def _configure_all(self, updated):\n        self.trigger(hooks.ConfigureHook(updated))\n\n    def clear(self):\n        \"\"\"\n        Remove all addons.\n        \"\"\"\n        for a in self.chain:\n            self.invoke_addon_sync(a, hooks.DoneHook())\n        self.lookup = {}\n        self.chain = []\n\n    def get(self, name):\n        \"\"\"\n        Retrieve an addon by name. Addon names are equal to the .name\n        attribute on the instance, or the lower case class name if that\n        does not exist.\n        \"\"\"\n        return self.lookup.get(name, None)\n\n    def register(self, addon):\n        \"\"\"\n        Register an addon, call its load event, and then register all its\n        sub-addons. This should be used by addons that dynamically manage\n        addons.\n\n        If the calling addon is already running, it should follow with\n        running and configure events. Must be called within a current\n        context.\n        \"\"\"\n        api_changes = {\n            # mitmproxy 6 -> mitmproxy 7\n            \"clientconnect\": f\"The clientconnect event has been removed, use client_connected instead\",\n            \"clientdisconnect\": f\"The clientdisconnect event has been removed, use client_disconnected instead\",\n            \"serverconnect\": \"The serverconnect event has been removed, use server_connect and server_connected instead\",\n            \"serverdisconnect\": f\"The serverdisconnect event has been removed, use server_disconnected instead\",\n            # mitmproxy 8 -> mitmproxy 9\n            \"add_log\": \"The add_log event has been deprecated, use Python's builtin logging module instead\",\n        }\n        for a in traverse([addon]):\n            for old, msg in api_changes.items():\n                if hasattr(a, old):\n                    logger.warning(\n                        f\"{msg}. For more details, see https://docs.mitmproxy.org/dev/addons-api-changelog/.\"\n                    )\n            name = _get_name(a)\n            if name in self.lookup:\n                raise exceptions.AddonManagerError(\n                    \"An addon called '%s' already exists.\" % name\n                )\n        loader = Loader(self.master)\n        self.invoke_addon_sync(addon, LoadHook(loader))\n        for a in traverse([addon]):\n            name = _get_name(a)\n            self.lookup[name] = a\n        for a in traverse([addon]):\n            self.master.commands.collect_commands(a)\n        self.master.options.process_deferred()\n        return addon\n\n    def add(self, *addons):\n        \"\"\"\n        Add addons to the end of the chain, and run their load event.\n        If any addon has sub-addons, they are registered.\n        \"\"\"\n        for i in addons:\n            self.chain.append(self.register(i))\n\n    def remove(self, addon):\n        \"\"\"\n        Remove an addon and all its sub-addons.\n\n        If the addon is not in the chain - that is, if it's managed by a\n        parent addon - it's the parent's responsibility to remove it from\n        its own addons attribute.\n        \"\"\"\n        for a in traverse([addon]):\n            n = _get_name(a)\n            if n not in self.lookup:\n                raise exceptions.AddonManagerError(\"No such addon: %s\" % n)\n            self.chain = [i for i in self.chain if i is not a]\n            del self.lookup[_get_name(a)]\n        self.invoke_addon_sync(addon, hooks.DoneHook())\n\n    def __len__(self):\n        return len(self.chain)\n\n    def __str__(self):\n        return pprint.pformat([str(i) for i in self.chain])\n\n    def __contains__(self, item):\n        name = _get_name(item)\n        return name in self.lookup\n\n    async def handle_lifecycle(self, event: hooks.Hook):\n        \"\"\"\n        Handle a lifecycle event.\n        \"\"\"\n        message = event.args()[0]\n\n        await self.trigger_event(event)\n\n        if isinstance(message, flow.Flow):\n            await self.trigger_event(hooks.UpdateHook([message]))\n\n    def _iter_hooks(self, addon, event: hooks.Hook):\n        \"\"\"\n        Enumerate all hook callables belonging to the given addon\n        \"\"\"\n        assert isinstance(event, hooks.Hook)\n        for a in traverse([addon]):\n            func = getattr(a, event.name, None)\n            if func:\n                if callable(func):\n                    yield a, func\n                elif isinstance(func, types.ModuleType):\n                    # we gracefully exclude module imports with the same name as hooks.\n                    # For example, a user may have \"from mitmproxy import log\" in an addon,\n                    # which has the same name as the \"log\" hook. In this particular case,\n                    # we end up in an error loop because we \"log\" this error.\n                    pass\n                else:\n                    raise exceptions.AddonManagerError(\n                        f\"Addon handler {event.name} ({a}) not callable\"\n                    )\n\n    async def invoke_addon(self, addon, event: hooks.Hook):\n        \"\"\"\n        Asynchronously invoke an event on an addon and all its children.\n        \"\"\"\n        for addon, func in self._iter_hooks(addon, event):\n            res = func(*event.args())\n            # Support both async and sync hook functions\n            if res is not None and inspect.isawaitable(res):\n                await res\n\n    def invoke_addon_sync(self, addon, event: hooks.Hook):\n        \"\"\"\n        Invoke an event on an addon and all its children.\n        \"\"\"\n        for addon, func in self._iter_hooks(addon, event):\n            if inspect.iscoroutinefunction(func):\n                raise exceptions.AddonManagerError(\n                    f\"Async handler {event.name} ({addon}) cannot be called from sync context\"\n                )\n            func(*event.args())\n\n    async def trigger_event(self, event: hooks.Hook):\n        \"\"\"\n        Asynchronously trigger an event across all addons.\n        \"\"\"\n        for i in self.chain:\n            try:\n                with safecall():\n                    await self.invoke_addon(i, event)\n            except exceptions.AddonHalt:\n                return\n\n    def trigger(self, event: hooks.Hook):\n        \"\"\"\n        Trigger an event across all addons.\n\n        This API is discouraged and may be deprecated in the future.\n        Use `trigger_event()` instead, which provides the same functionality but supports async hooks.\n        \"\"\"\n        for i in self.chain:\n            try:\n                with safecall():\n                    self.invoke_addon_sync(i, event)\n            except exceptions.AddonHalt:\n                return\n", "mitmproxy/ctx.py": "from __future__ import annotations\n\nimport typing\n\nif typing.TYPE_CHECKING:\n    import mitmproxy.log\n    import mitmproxy.master\n    import mitmproxy.options\n\nmaster: mitmproxy.master.Master\noptions: mitmproxy.options.Options\n\nlog: mitmproxy.log.Log\n\"\"\"Deprecated: Use Python's builtin `logging` module instead.\"\"\"\n", "mitmproxy/version.py": "import os\nimport subprocess\nimport sys\n\nVERSION = \"11.0.0.dev\"\nMITMPROXY = \"mitmproxy \" + VERSION\n\n# Serialization format version. This is displayed nowhere, it just needs to be incremented by one\n# for each change in the file format.\nFLOW_FORMAT_VERSION = 20\n\n\ndef get_dev_version() -> str:\n    \"\"\"\n    Return a detailed version string, sourced either from VERSION or obtained dynamically using git.\n    \"\"\"\n\n    mitmproxy_version = VERSION\n\n    here = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n    try:  # pragma: no cover\n        # Check that we're in the mitmproxy repository: https://github.com/mitmproxy/mitmproxy/issues/3987\n        # cb0e3287090786fad566feb67ac07b8ef361b2c3 is the first mitmproxy commit.\n        subprocess.run(\n            [\"git\", \"cat-file\", \"-e\", \"cb0e3287090786fad566feb67ac07b8ef361b2c3\"],\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            cwd=here,\n            check=True,\n        )\n        git_describe = subprocess.check_output(\n            [\"git\", \"describe\", \"--tags\", \"--long\"],\n            stderr=subprocess.STDOUT,\n            cwd=here,\n        )\n        last_tag, tag_dist_str, commit = git_describe.decode().strip().rsplit(\"-\", 2)\n        commit = commit.lstrip(\"g\")[:7]\n        tag_dist = int(tag_dist_str)\n    except Exception:\n        pass\n    else:\n        # Add commit info for non-tagged releases\n        if tag_dist > 0:\n            mitmproxy_version += f\" (+{tag_dist}, commit {commit})\"\n\n    # PyInstaller build indicator, if using precompiled binary\n    if getattr(sys, \"frozen\", False):\n        mitmproxy_version += \" binary\"\n\n    return mitmproxy_version\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    print(VERSION)\n", "mitmproxy/flow.py": "from __future__ import annotations\n\nimport asyncio\nimport copy\nimport time\nimport uuid\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom typing import Any\nfrom typing import ClassVar\n\nfrom mitmproxy import connection\nfrom mitmproxy import exceptions\nfrom mitmproxy import version\nfrom mitmproxy.coretypes import serializable\n\n\n@dataclass\nclass Error(serializable.SerializableDataclass):\n    \"\"\"\n    An Error.\n\n    This is distinct from an protocol error response (say, a HTTP code 500),\n    which is represented by a normal `mitmproxy.http.Response` object. This class is\n    responsible for indicating errors that fall outside of normal protocol\n    communications, like interrupted connections, timeouts, or protocol errors.\n    \"\"\"\n\n    msg: str\n    \"\"\"Message describing the error.\"\"\"\n\n    timestamp: float = field(default_factory=time.time)\n    \"\"\"Unix timestamp of when this error happened.\"\"\"\n\n    KILLED_MESSAGE: ClassVar[str] = \"Connection killed.\"\n\n    def __str__(self):\n        return self.msg\n\n    def __repr__(self):\n        return self.msg\n\n\nclass Flow(serializable.Serializable):\n    \"\"\"\n    Base class for network flows. A flow is a collection of objects,\n    for example HTTP request/response pairs or a list of TCP messages.\n\n    See also:\n     - mitmproxy.http.HTTPFlow\n     - mitmproxy.tcp.TCPFlow\n     - mitmproxy.udp.UDPFlow\n    \"\"\"\n\n    client_conn: connection.Client\n    \"\"\"The client that connected to mitmproxy.\"\"\"\n\n    server_conn: connection.Server\n    \"\"\"\n    The server mitmproxy connected to.\n\n    Some flows may never cause mitmproxy to initiate a server connection,\n    for example because their response is replayed by mitmproxy itself.\n    To simplify implementation, those flows will still have a `server_conn` attribute\n    with a `timestamp_start` set to `None`.\n    \"\"\"\n\n    error: Error | None = None\n    \"\"\"A connection or protocol error affecting this flow.\"\"\"\n\n    intercepted: bool\n    \"\"\"\n    If `True`, the flow is currently paused by mitmproxy.\n    We're waiting for a user action to forward the flow to its destination.\n    \"\"\"\n\n    marked: str = \"\"\n    \"\"\"\n    If this attribute is a non-empty string the flow has been marked by the user.\n\n    A string value will be used as the marker annotation. May either be a single character or a Unicode emoji name.\n\n    For example `:grapes:` becomes `\ud83c\udf47` in views that support emoji rendering.\n    Consult the [Github API Emoji List](https://api.github.com/emojis) for a list of emoji that may be used.\n    Not all emoji, especially [emoji modifiers](https://en.wikipedia.org/wiki/Miscellaneous_Symbols_and_Pictographs#Emoji_modifiers)\n    will render consistently.\n\n    The default marker for the view will be used if the Unicode emoji name can not be interpreted.\n    \"\"\"\n\n    is_replay: str | None\n    \"\"\"\n    This attribute indicates if this flow has been replayed in either direction.\n\n     - a value of `request` indicates that the request has been artifically replayed by mitmproxy to the server.\n     - a value of `response` indicates that the response to the client's request has been set by server replay.\n    \"\"\"\n\n    live: bool\n    \"\"\"\n    If `True`, the flow belongs to a currently active connection.\n    If `False`, the flow may have been already completed or loaded from disk.\n    \"\"\"\n\n    timestamp_created: float\n    \"\"\"\n    The Unix timestamp of when this flow was created.\n\n    In contrast to `timestamp_start`, this value will not change when a flow is replayed.\n    \"\"\"\n\n    def __init__(\n        self,\n        client_conn: connection.Client,\n        server_conn: connection.Server,\n        live: bool = False,\n    ) -> None:\n        self.id = str(uuid.uuid4())\n        self.client_conn = client_conn\n        self.server_conn = server_conn\n        self.live = live\n        self.timestamp_created = time.time()\n\n        self.intercepted: bool = False\n        self._resume_event: asyncio.Event | None = None\n        self._backup: Flow | None = None\n        self.marked: str = \"\"\n        self.is_replay: str | None = None\n        self.metadata: dict[str, Any] = dict()\n        self.comment: str = \"\"\n\n    __types: dict[str, type[Flow]] = {}\n\n    type: ClassVar[\n        str\n    ]  # automatically derived from the class name in __init_subclass__\n    \"\"\"The flow type, for example `http`, `tcp`, or `dns`.\"\"\"\n\n    def __init_subclass__(cls, **kwargs):\n        cls.type = cls.__name__.removesuffix(\"Flow\").lower()\n        Flow.__types[cls.type] = cls\n\n    def get_state(self) -> serializable.State:\n        state = {\n            \"version\": version.FLOW_FORMAT_VERSION,\n            \"type\": self.type,\n            \"id\": self.id,\n            \"error\": self.error.get_state() if self.error else None,\n            \"client_conn\": self.client_conn.get_state(),\n            \"server_conn\": self.server_conn.get_state(),\n            \"intercepted\": self.intercepted,\n            \"is_replay\": self.is_replay,\n            \"marked\": self.marked,\n            \"metadata\": copy.deepcopy(self.metadata),\n            \"comment\": self.comment,\n            \"timestamp_created\": self.timestamp_created,\n        }\n        state[\"backup\"] = copy.deepcopy(self._backup) if self._backup != state else None\n        return state\n\n    def set_state(self, state: serializable.State) -> None:\n        assert state.pop(\"version\") == version.FLOW_FORMAT_VERSION\n        assert state.pop(\"type\") == self.type\n        self.id = state.pop(\"id\")\n        if state[\"error\"]:\n            if self.error:\n                self.error.set_state(state.pop(\"error\"))\n            else:\n                self.error = Error.from_state(state.pop(\"error\"))\n        else:\n            self.error = state.pop(\"error\")\n        self.client_conn.set_state(state.pop(\"client_conn\"))\n        self.server_conn.set_state(state.pop(\"server_conn\"))\n        self.intercepted = state.pop(\"intercepted\")\n        self.is_replay = state.pop(\"is_replay\")\n        self.marked = state.pop(\"marked\")\n        self.metadata = state.pop(\"metadata\")\n        self.comment = state.pop(\"comment\")\n        self.timestamp_created = state.pop(\"timestamp_created\")\n        self._backup = state.pop(\"backup\", None)\n        assert state == {}\n\n    @classmethod\n    def from_state(cls, state: serializable.State) -> Flow:\n        try:\n            flow_cls = Flow.__types[state[\"type\"]]\n        except KeyError:\n            raise ValueError(f\"Unknown flow type: {state['type']}\")\n        client = connection.Client(peername=(\"\", 0), sockname=(\"\", 0))\n        server = connection.Server(address=None)\n        f = flow_cls(client, server)\n        f.set_state(state)\n        return f\n\n    def copy(self):\n        \"\"\"Make a copy of this flow.\"\"\"\n        f = super().copy()\n        f.live = False\n        return f\n\n    def modified(self):\n        \"\"\"\n        `True` if this file has been modified by a user, `False` otherwise.\n        \"\"\"\n        if self._backup:\n            return self._backup != self.get_state()\n        else:\n            return False\n\n    def backup(self, force=False):\n        \"\"\"\n        Save a backup of this flow, which can be restored by calling `Flow.revert()`.\n        \"\"\"\n        if not self._backup:\n            self._backup = self.get_state()\n\n    def revert(self):\n        \"\"\"\n        Revert to the last backed up state.\n        \"\"\"\n        if self._backup:\n            self.set_state(self._backup)\n            self._backup = None\n\n    @property\n    def killable(self):\n        \"\"\"*Read-only:* `True` if this flow can be killed, `False` otherwise.\"\"\"\n        return self.live and not (self.error and self.error.msg == Error.KILLED_MESSAGE)\n\n    def kill(self):\n        \"\"\"\n        Kill this flow. The current request/response will not be forwarded to its destination.\n        \"\"\"\n        if not self.killable:\n            raise exceptions.ControlException(\"Flow is not killable.\")\n        # TODO: The way we currently signal killing is not ideal. One major problem is that we cannot kill\n        #  flows in transit (https://github.com/mitmproxy/mitmproxy/issues/4711), even though they are advertised\n        #  as killable. An alternative approach would be to introduce a `KillInjected` event similar to\n        #  `MessageInjected`, which should fix this issue.\n        self.error = Error(Error.KILLED_MESSAGE)\n        self.intercepted = False\n        self.live = False\n\n    def intercept(self):\n        \"\"\"\n        Intercept this Flow. Processing will stop until resume is\n        called.\n        \"\"\"\n        if self.intercepted:\n            return\n        self.intercepted = True\n        if self._resume_event is not None:\n            self._resume_event.clear()\n\n    async def wait_for_resume(self):\n        \"\"\"\n        Wait until this Flow is resumed.\n        \"\"\"\n        if not self.intercepted:\n            return\n        if self._resume_event is None:\n            self._resume_event = asyncio.Event()\n        await self._resume_event.wait()\n\n    def resume(self):\n        \"\"\"\n        Continue with the flow \u2013 called after an intercept().\n        \"\"\"\n        if not self.intercepted:\n            return\n        self.intercepted = False\n        if self._resume_event is not None:\n            self._resume_event.set()\n\n    @property\n    def timestamp_start(self) -> float:\n        \"\"\"\n        *Read-only:* Start time of the flow.\n        Depending on the flow type, this property is an alias for\n        `mitmproxy.connection.Client.timestamp_start` or `mitmproxy.http.Request.timestamp_start`.\n        \"\"\"\n        return self.client_conn.timestamp_start\n\n\n__all__ = [\n    \"Flow\",\n    \"Error\",\n]\n", "mitmproxy/tcp.py": "import time\n\nfrom mitmproxy import connection\nfrom mitmproxy import flow\nfrom mitmproxy.coretypes import serializable\n\n\nclass TCPMessage(serializable.Serializable):\n    \"\"\"\n    An individual TCP \"message\".\n    Note that TCP is *stream-based* and not *message-based*.\n    For practical purposes the stream is chunked into messages here,\n    but you should not rely on message boundaries.\n    \"\"\"\n\n    def __init__(self, from_client, content, timestamp=None):\n        self.from_client = from_client\n        self.content = content\n        self.timestamp = timestamp or time.time()\n\n    @classmethod\n    def from_state(cls, state):\n        return cls(*state)\n\n    def get_state(self):\n        return self.from_client, self.content, self.timestamp\n\n    def set_state(self, state):\n        self.from_client, self.content, self.timestamp = state\n\n    def __repr__(self):\n        return \"{direction} {content}\".format(\n            direction=\"->\" if self.from_client else \"<-\", content=repr(self.content)\n        )\n\n\nclass TCPFlow(flow.Flow):\n    \"\"\"\n    A TCPFlow is a simplified representation of a TCP session.\n    \"\"\"\n\n    messages: list[TCPMessage]\n    \"\"\"\n    The messages transmitted over this connection.\n\n    The latest message can be accessed as `flow.messages[-1]` in event hooks.\n    \"\"\"\n\n    def __init__(\n        self,\n        client_conn: connection.Client,\n        server_conn: connection.Server,\n        live: bool = False,\n    ):\n        super().__init__(client_conn, server_conn, live)\n        self.messages = []\n\n    def get_state(self) -> serializable.State:\n        return {\n            **super().get_state(),\n            \"messages\": [m.get_state() for m in self.messages],\n        }\n\n    def set_state(self, state: serializable.State) -> None:\n        self.messages = [TCPMessage.from_state(m) for m in state.pop(\"messages\")]\n        super().set_state(state)\n\n    def __repr__(self):\n        return f\"<TCPFlow ({len(self.messages)} messages)>\"\n\n\n__all__ = [\n    \"TCPFlow\",\n    \"TCPMessage\",\n]\n", "mitmproxy/master.py": "import asyncio\nimport logging\n\nfrom . import ctx as mitmproxy_ctx\nfrom .addons import termlog\nfrom .proxy.mode_specs import ReverseMode\nfrom .utils import asyncio_utils\nfrom mitmproxy import addonmanager\nfrom mitmproxy import command\nfrom mitmproxy import eventsequence\nfrom mitmproxy import hooks\nfrom mitmproxy import http\nfrom mitmproxy import log\nfrom mitmproxy import options\n\nlogger = logging.getLogger(__name__)\n\n\nclass Master:\n    \"\"\"\n    The master handles mitmproxy's main event loop.\n    \"\"\"\n\n    event_loop: asyncio.AbstractEventLoop\n    _termlog_addon: termlog.TermLog | None = None\n\n    def __init__(\n        self,\n        opts: options.Options,\n        event_loop: asyncio.AbstractEventLoop | None = None,\n        with_termlog: bool = False,\n    ):\n        self.options: options.Options = opts or options.Options()\n        self.commands = command.CommandManager(self)\n        self.addons = addonmanager.AddonManager(self)\n\n        if with_termlog:\n            self._termlog_addon = termlog.TermLog()\n            self.addons.add(self._termlog_addon)\n\n        self.log = log.Log(self)  # deprecated, do not use.\n        self._legacy_log_events = log.LegacyLogEvents(self)\n        self._legacy_log_events.install()\n\n        # We expect an active event loop here already because some addons\n        # may want to spawn tasks during the initial configuration phase,\n        # which happens before run().\n        self.event_loop = event_loop or asyncio.get_running_loop()\n        self.should_exit = asyncio.Event()\n        mitmproxy_ctx.master = self\n        mitmproxy_ctx.log = self.log  # deprecated, do not use.\n        mitmproxy_ctx.options = self.options\n\n    async def run(self) -> None:\n        with (\n            asyncio_utils.install_exception_handler(self._asyncio_exception_handler),\n            asyncio_utils.set_eager_task_factory(),\n        ):\n            self.should_exit.clear()\n\n            # Can we exit before even bringing up servers?\n            if ec := self.addons.get(\"errorcheck\"):\n                await ec.shutdown_if_errored()\n            if ps := self.addons.get(\"proxyserver\"):\n                # This may block for some proxy modes, so we also monitor should_exit.\n                await asyncio.wait(\n                    [\n                        asyncio.create_task(ps.setup_servers()),\n                        asyncio.create_task(self.should_exit.wait()),\n                    ],\n                    return_when=asyncio.FIRST_COMPLETED,\n                )\n                if self.should_exit.is_set():\n                    return\n                # Did bringing up servers fail?\n                if ec := self.addons.get(\"errorcheck\"):\n                    await ec.shutdown_if_errored()\n\n            try:\n                await self.running()\n                # Any errors in the final part of startup?\n                if ec := self.addons.get(\"errorcheck\"):\n                    await ec.shutdown_if_errored()\n                    ec.finish()\n\n                await self.should_exit.wait()\n            finally:\n                # if running() was called, we also always want to call done().\n                # .wait might be cancelled (e.g. by sys.exit), so  this needs to be in a finally block.\n                await self.done()\n\n    def shutdown(self):\n        \"\"\"\n        Shut down the proxy. This method is thread-safe.\n        \"\"\"\n        # We may add an exception argument here.\n        self.event_loop.call_soon_threadsafe(self.should_exit.set)\n\n    async def running(self) -> None:\n        await self.addons.trigger_event(hooks.RunningHook())\n\n    async def done(self) -> None:\n        await self.addons.trigger_event(hooks.DoneHook())\n        self._legacy_log_events.uninstall()\n        if self._termlog_addon is not None:\n            self._termlog_addon.uninstall()\n\n    def _asyncio_exception_handler(self, loop, context) -> None:\n        try:\n            exc: Exception = context[\"exception\"]\n        except KeyError:\n            logger.error(f\"Unhandled asyncio error: {context}\")\n        else:\n            if isinstance(exc, OSError) and exc.errno == 10038:\n                return  # suppress https://bugs.python.org/issue43253\n            logger.error(\n                \"Unhandled error in task.\",\n                exc_info=(type(exc), exc, exc.__traceback__),\n            )\n\n    async def load_flow(self, f):\n        \"\"\"\n        Loads a flow\n        \"\"\"\n\n        if (\n            isinstance(f, http.HTTPFlow)\n            and len(self.options.mode) == 1\n            and self.options.mode[0].startswith(\"reverse:\")\n        ):\n            # When we load flows in reverse proxy mode, we adjust the target host to\n            # the reverse proxy destination for all flows we load. This makes it very\n            # easy to replay saved flows against a different host.\n            # We may change this in the future so that clientplayback always replays to the first mode.\n            mode = ReverseMode.parse(self.options.mode[0])\n            assert isinstance(mode, ReverseMode)\n            f.request.host, f.request.port, *_ = mode.address\n            f.request.scheme = mode.scheme\n\n        for e in eventsequence.iterate(f):\n            await self.addons.handle_lifecycle(e)\n", "mitmproxy/types.py": "import codecs\nimport glob\nimport os\nimport re\nfrom collections.abc import Sequence\nfrom typing import Any\nfrom typing import TYPE_CHECKING\nfrom typing import Union\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy.utils import emoji\nfrom mitmproxy.utils import strutils\n\nif TYPE_CHECKING:  # pragma: no cover\n    from mitmproxy.command import CommandManager\n\n\nclass Path(str):\n    pass\n\n\nclass Cmd(str):\n    pass\n\n\nclass CmdArgs(str):\n    pass\n\n\nclass Unknown(str):\n    pass\n\n\nclass Space(str):\n    pass\n\n\nclass CutSpec(Sequence[str]):\n    pass\n\n\nclass Data(Sequence[Sequence[Union[str, bytes]]]):\n    pass\n\n\nclass Marker(str):\n    pass\n\n\nclass Choice:\n    def __init__(self, options_command):\n        self.options_command = options_command\n\n    def __instancecheck__(self, instance):  # pragma: no cover\n        # return false here so that arguments are piped through parsearg,\n        # which does extended validation.\n        return False\n\n\nclass _BaseType:\n    typ: type = object\n    display: str = \"\"\n\n    def completion(self, manager: \"CommandManager\", t: Any, s: str) -> Sequence[str]:\n        \"\"\"\n        Returns a list of completion strings for a given prefix. The strings\n        returned don't necessarily need to be suffixes of the prefix, since\n        completers will do prefix filtering themselves..\n        \"\"\"\n        raise NotImplementedError\n\n    def parse(self, manager: \"CommandManager\", typ: Any, s: str) -> Any:\n        \"\"\"\n        Parse a string, given the specific type instance (to allow rich type annotations like Choice) and a string.\n\n        Raises ValueError if the value is invalid.\n        \"\"\"\n        raise NotImplementedError\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        \"\"\"\n        Check if data is valid for this type.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass _BoolType(_BaseType):\n    typ = bool\n    display = \"bool\"\n\n    def completion(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        return [\"false\", \"true\"]\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> bool:\n        if s == \"true\":\n            return True\n        elif s == \"false\":\n            return False\n        else:\n            raise ValueError(\"Booleans are 'true' or 'false', got %s\" % s)\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        return val in [True, False]\n\n\nclass _StrType(_BaseType):\n    typ = str\n    display = \"str\"\n\n    # https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals\n    escape_sequences = re.compile(\n        r\"\"\"\n        \\\\ (\n        [\\\\'\"abfnrtv]  # Standard C escape sequence\n        | [0-7]{1,3}   # Character with octal value\n        | x..          # Character with hex value\n        | N{[^}]+}     # Character name in the Unicode database\n        | u....        # Character with 16-bit hex value\n        | U........    # Character with 32-bit hex value\n        )\n        \"\"\",\n        re.VERBOSE,\n    )\n\n    @staticmethod\n    def _unescape(match: re.Match) -> str:\n        return codecs.decode(match.group(0), \"unicode-escape\")  # type: ignore\n\n    def completion(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        return []\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> str:\n        return self.escape_sequences.sub(self._unescape, s)\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        return isinstance(val, str)\n\n\nclass _BytesType(_BaseType):\n    typ = bytes\n    display = \"bytes\"\n\n    def completion(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        return []\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> bytes:\n        return strutils.escaped_str_to_bytes(s)\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        return isinstance(val, bytes)\n\n\nclass _UnknownType(_BaseType):\n    typ = Unknown\n    display = \"unknown\"\n\n    def completion(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        return []\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> str:\n        return s\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        return False\n\n\nclass _IntType(_BaseType):\n    typ = int\n    display = \"int\"\n\n    def completion(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        return []\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> int:\n        return int(s)\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        return isinstance(val, int)\n\n\nclass _PathType(_BaseType):\n    typ = Path\n    display = \"path\"\n\n    def completion(\n        self, manager: \"CommandManager\", t: type, start: str\n    ) -> Sequence[str]:\n        if not start:\n            start = \"./\"\n        path = os.path.expanduser(start)\n        ret = []\n        if os.path.isdir(path):\n            files = glob.glob(os.path.join(path, \"*\"))\n            prefix = start\n        else:\n            files = glob.glob(path + \"*\")\n            prefix = os.path.dirname(start)\n        prefix = prefix or \"./\"\n        for f in files:\n            display = os.path.join(prefix, os.path.normpath(os.path.basename(f)))\n            if os.path.isdir(f):\n                display += \"/\"\n            ret.append(display)\n        if not ret:\n            ret = [start]\n        ret.sort()\n        return ret\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> str:\n        return os.path.expanduser(s)\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        return isinstance(val, str)\n\n\nclass _CmdType(_BaseType):\n    typ = Cmd\n    display = \"cmd\"\n\n    def completion(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        return list(manager.commands.keys())\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> str:\n        if s not in manager.commands:\n            raise ValueError(\"Unknown command: %s\" % s)\n        return s\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        return val in manager.commands\n\n\nclass _ArgType(_BaseType):\n    typ = CmdArgs\n    display = \"arg\"\n\n    def completion(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        return []\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> str:\n        return s\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        return isinstance(val, str)\n\n\nclass _StrSeqType(_BaseType):\n    typ = Sequence[str]\n    display = \"str[]\"\n\n    def completion(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        return []\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        return [x.strip() for x in s.split(\",\")]\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        if isinstance(val, str) or isinstance(val, bytes):\n            return False\n        try:\n            for v in val:\n                if not isinstance(v, str):\n                    return False\n        except TypeError:\n            return False\n        return True\n\n\nclass _CutSpecType(_BaseType):\n    typ = CutSpec\n    display = \"cut[]\"\n    valid_prefixes = [\n        \"request.method\",\n        \"request.scheme\",\n        \"request.host\",\n        \"request.http_version\",\n        \"request.port\",\n        \"request.path\",\n        \"request.url\",\n        \"request.text\",\n        \"request.content\",\n        \"request.raw_content\",\n        \"request.timestamp_start\",\n        \"request.timestamp_end\",\n        \"request.header[\",\n        \"response.status_code\",\n        \"response.reason\",\n        \"response.text\",\n        \"response.content\",\n        \"response.timestamp_start\",\n        \"response.timestamp_end\",\n        \"response.raw_content\",\n        \"response.header[\",\n        \"client_conn.peername.port\",\n        \"client_conn.peername.host\",\n        \"client_conn.tls_version\",\n        \"client_conn.sni\",\n        \"client_conn.tls_established\",\n        \"server_conn.address.port\",\n        \"server_conn.address.host\",\n        \"server_conn.ip_address.host\",\n        \"server_conn.tls_version\",\n        \"server_conn.sni\",\n        \"server_conn.tls_established\",\n    ]\n\n    def completion(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        spec = s.split(\",\")\n        opts = []\n        for pref in self.valid_prefixes:\n            spec[-1] = pref\n            opts.append(\",\".join(spec))\n        return opts\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> CutSpec:\n        parts: Any = s.split(\",\")\n        return parts\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        if not isinstance(val, str):\n            return False\n        parts = [x.strip() for x in val.split(\",\")]\n        for p in parts:\n            for pref in self.valid_prefixes:\n                if p.startswith(pref):\n                    break\n            else:\n                return False\n        return True\n\n\nclass _BaseFlowType(_BaseType):\n    viewmarkers = [\n        \"@all\",\n        \"@focus\",\n        \"@shown\",\n        \"@hidden\",\n        \"@marked\",\n        \"@unmarked\",\n    ]\n    valid_prefixes = viewmarkers + [\n        \"~q\",\n        \"~s\",\n        \"~a\",\n        \"~hq\",\n        \"~hs\",\n        \"~b\",\n        \"~bq\",\n        \"~bs\",\n        \"~t\",\n        \"~d\",\n        \"~m\",\n        \"~u\",\n        \"~c\",\n    ]\n\n    def completion(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[str]:\n        return self.valid_prefixes\n\n\nclass _FlowType(_BaseFlowType):\n    typ = flow.Flow\n    display = \"flow\"\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> flow.Flow:\n        try:\n            flows = manager.call_strings(\"view.flows.resolve\", [s])\n        except exceptions.CommandError as e:\n            raise ValueError(str(e)) from e\n        if len(flows) != 1:\n            raise ValueError(\n                \"Command requires one flow, specification matched %s.\" % len(flows)\n            )\n        return flows[0]\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        return isinstance(val, flow.Flow)\n\n\nclass _FlowsType(_BaseFlowType):\n    typ = Sequence[flow.Flow]\n    display = \"flow[]\"\n\n    def parse(self, manager: \"CommandManager\", t: type, s: str) -> Sequence[flow.Flow]:\n        try:\n            return manager.call_strings(\"view.flows.resolve\", [s])\n        except exceptions.CommandError as e:\n            raise ValueError(str(e)) from e\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        try:\n            for v in val:\n                if not isinstance(v, flow.Flow):\n                    return False\n        except TypeError:\n            return False\n        return True\n\n\nclass _DataType(_BaseType):\n    typ = Data\n    display = \"data[][]\"\n\n    def completion(\n        self, manager: \"CommandManager\", t: type, s: str\n    ) -> Sequence[str]:  # pragma: no cover\n        raise ValueError(\"data cannot be passed as argument\")\n\n    def parse(\n        self, manager: \"CommandManager\", t: type, s: str\n    ) -> Any:  # pragma: no cover\n        raise ValueError(\"data cannot be passed as argument\")\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        # FIXME: validate that all rows have equal length, and all columns have equal types\n        try:\n            for row in val:\n                for cell in row:\n                    if not (isinstance(cell, str) or isinstance(cell, bytes)):\n                        return False\n        except TypeError:\n            return False\n        return True\n\n\nclass _ChoiceType(_BaseType):\n    typ = Choice\n    display = \"choice\"\n\n    def completion(self, manager: \"CommandManager\", t: Choice, s: str) -> Sequence[str]:\n        return manager.execute(t.options_command)\n\n    def parse(self, manager: \"CommandManager\", t: Choice, s: str) -> str:\n        opts = manager.execute(t.options_command)\n        if s not in opts:\n            raise ValueError(\"Invalid choice.\")\n        return s\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: Any) -> bool:\n        try:\n            opts = manager.execute(typ.options_command)\n        except exceptions.CommandError:\n            return False\n        return val in opts\n\n\nALL_MARKERS = [\"true\", \"false\"] + list(emoji.emoji)\n\n\nclass _MarkerType(_BaseType):\n    typ = Marker\n    display = \"marker\"\n\n    def completion(self, manager: \"CommandManager\", t: Choice, s: str) -> Sequence[str]:\n        return ALL_MARKERS\n\n    def parse(self, manager: \"CommandManager\", t: Choice, s: str) -> str:\n        if s not in ALL_MARKERS:\n            raise ValueError(\"Invalid choice.\")\n        if s == \"true\":\n            return \":default:\"\n        elif s == \"false\":\n            return \"\"\n        return s\n\n    def is_valid(self, manager: \"CommandManager\", typ: Any, val: str) -> bool:\n        return val in ALL_MARKERS\n\n\nclass TypeManager:\n    def __init__(self, *types):\n        self.typemap = {}\n        for t in types:\n            self.typemap[t.typ] = t()\n\n    def get(self, t: type | None, default=None) -> _BaseType | None:\n        if type(t) in self.typemap:\n            return self.typemap[type(t)]\n        return self.typemap.get(t, default)\n\n\nCommandTypes = TypeManager(\n    _ArgType,\n    _BoolType,\n    _ChoiceType,\n    _CmdType,\n    _CutSpecType,\n    _DataType,\n    _FlowType,\n    _FlowsType,\n    _IntType,\n    _MarkerType,\n    _PathType,\n    _StrType,\n    _StrSeqType,\n    _BytesType,\n)\n", "mitmproxy/dns.py": "from __future__ import annotations\n\nimport base64\nimport itertools\nimport random\nimport struct\nimport time\nfrom dataclasses import dataclass\nfrom ipaddress import IPv4Address\nfrom ipaddress import IPv6Address\nfrom typing import ClassVar\n\nfrom mitmproxy import flow\nfrom mitmproxy.coretypes import serializable\nfrom mitmproxy.net.dns import classes\nfrom mitmproxy.net.dns import domain_names\nfrom mitmproxy.net.dns import https_records\nfrom mitmproxy.net.dns import op_codes\nfrom mitmproxy.net.dns import response_codes\nfrom mitmproxy.net.dns import types\nfrom mitmproxy.net.dns.https_records import HTTPSRecord\nfrom mitmproxy.net.dns.https_records import SVCParamKeys\n\n# DNS parameters taken from https://www.iana.org/assignments/dns-parameters/dns-parameters.xml\n\n\n@dataclass\nclass Question(serializable.SerializableDataclass):\n    HEADER: ClassVar[struct.Struct] = struct.Struct(\"!HH\")\n\n    name: str\n    type: int\n    class_: int\n\n    def __str__(self) -> str:\n        return self.name\n\n    def to_json(self) -> dict:\n        \"\"\"\n        Converts the question into json for mitmweb.\n        Sync with web/src/flow.ts.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"type\": types.to_str(self.type),\n            \"class\": classes.to_str(self.class_),\n        }\n\n\n@dataclass\nclass ResourceRecord(serializable.SerializableDataclass):\n    DEFAULT_TTL: ClassVar[int] = 60\n    HEADER: ClassVar[struct.Struct] = struct.Struct(\"!HHIH\")\n\n    name: str\n    type: int\n    class_: int\n    ttl: int\n    data: bytes\n\n    def __str__(self) -> str:\n        try:\n            if self.type == types.A:\n                return str(self.ipv4_address)\n            if self.type == types.AAAA:\n                return str(self.ipv6_address)\n            if self.type in (types.NS, types.CNAME, types.PTR):\n                return self.domain_name\n            if self.type == types.TXT:\n                return self.text\n            if self.type == types.HTTPS:\n                return str(https_records.unpack(self.data))\n        except Exception:\n            return f\"0x{self.data.hex()} (invalid {types.to_str(self.type)} data)\"\n        return f\"0x{self.data.hex()}\"\n\n    @property\n    def text(self) -> str:\n        return self.data.decode(\"utf-8\")\n\n    @text.setter\n    def text(self, value: str) -> None:\n        self.data = value.encode(\"utf-8\")\n\n    @property\n    def ipv4_address(self) -> IPv4Address:\n        return IPv4Address(self.data)\n\n    @ipv4_address.setter\n    def ipv4_address(self, ip: IPv4Address) -> None:\n        self.data = ip.packed\n\n    @property\n    def ipv6_address(self) -> IPv6Address:\n        return IPv6Address(self.data)\n\n    @ipv6_address.setter\n    def ipv6_address(self, ip: IPv6Address) -> None:\n        self.data = ip.packed\n\n    @property\n    def domain_name(self) -> str:\n        return domain_names.unpack(self.data)\n\n    @domain_name.setter\n    def domain_name(self, name: str) -> None:\n        self.data = domain_names.pack(name)\n\n    @property\n    def https_ech(self) -> str | None:\n        record = https_records.unpack(self.data)\n        ech_bytes = record.params.get(SVCParamKeys.ECH.value, None)\n        if ech_bytes is not None:\n            return base64.b64encode(ech_bytes).decode(\"utf-8\")\n        else:\n            return None\n\n    @https_ech.setter\n    def https_ech(self, ech: str | None) -> None:\n        record = https_records.unpack(self.data)\n        if ech is None:\n            record.params.pop(SVCParamKeys.ECH.value, None)\n        else:\n            ech_bytes = base64.b64decode(ech.encode(\"utf-8\"))\n            record.params[SVCParamKeys.ECH.value] = ech_bytes\n        self.data = https_records.pack(record)\n\n    def to_json(self) -> dict:\n        \"\"\"\n        Converts the resource record into json for mitmweb.\n        Sync with web/src/flow.ts.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"type\": types.to_str(self.type),\n            \"class\": classes.to_str(self.class_),\n            \"ttl\": self.ttl,\n            \"data\": str(self),\n        }\n\n    @classmethod\n    def A(cls, name: str, ip: IPv4Address, *, ttl: int = DEFAULT_TTL) -> ResourceRecord:\n        \"\"\"Create an IPv4 resource record.\"\"\"\n        return cls(name, types.A, classes.IN, ttl, ip.packed)\n\n    @classmethod\n    def AAAA(\n        cls, name: str, ip: IPv6Address, *, ttl: int = DEFAULT_TTL\n    ) -> ResourceRecord:\n        \"\"\"Create an IPv6 resource record.\"\"\"\n        return cls(name, types.AAAA, classes.IN, ttl, ip.packed)\n\n    @classmethod\n    def CNAME(\n        cls, alias: str, canonical: str, *, ttl: int = DEFAULT_TTL\n    ) -> ResourceRecord:\n        \"\"\"Create a canonical internet name resource record.\"\"\"\n        return cls(alias, types.CNAME, classes.IN, ttl, domain_names.pack(canonical))\n\n    @classmethod\n    def PTR(cls, inaddr: str, ptr: str, *, ttl: int = DEFAULT_TTL) -> ResourceRecord:\n        \"\"\"Create a canonical internet name resource record.\"\"\"\n        return cls(inaddr, types.PTR, classes.IN, ttl, domain_names.pack(ptr))\n\n    @classmethod\n    def TXT(cls, name: str, text: str, *, ttl: int = DEFAULT_TTL) -> ResourceRecord:\n        \"\"\"Create a textual resource record.\"\"\"\n        return cls(name, types.TXT, classes.IN, ttl, text.encode(\"utf-8\"))\n\n    @classmethod\n    def HTTPS(\n        cls, name: str, record: HTTPSRecord, ttl: int = DEFAULT_TTL\n    ) -> ResourceRecord:\n        \"\"\"Create a HTTPS resource record\"\"\"\n        return cls(name, types.HTTPS, classes.IN, ttl, https_records.pack(record))\n\n\n# comments are taken from rfc1035\n@dataclass\nclass Message(serializable.SerializableDataclass):\n    HEADER: ClassVar[struct.Struct] = struct.Struct(\"!HHHHHH\")\n\n    timestamp: float\n    \"\"\"The time at which the message was sent or received.\"\"\"\n    id: int\n    \"\"\"An identifier assigned by the program that generates any kind of query.\"\"\"\n    query: bool\n    \"\"\"A field that specifies whether this message is a query.\"\"\"\n    op_code: int\n    \"\"\"\n    A field that specifies kind of query in this message.\n    This value is set by the originator of a request and copied into the response.\n    \"\"\"\n    authoritative_answer: bool\n    \"\"\"\n    This field is valid in responses, and specifies that the responding name server\n    is an authority for the domain name in question section.\n    \"\"\"\n    truncation: bool\n    \"\"\"Specifies that this message was truncated due to length greater than that permitted on the transmission channel.\"\"\"\n    recursion_desired: bool\n    \"\"\"\n    This field may be set in a query and is copied into the response.\n    If set, it directs the name server to pursue the query recursively.\n    \"\"\"\n    recursion_available: bool\n    \"\"\"This field is set or cleared in a response, and denotes whether recursive query support is available in the name server.\"\"\"\n    reserved: int\n    \"\"\"Reserved for future use.  Must be zero in all queries and responses.\"\"\"\n    response_code: int\n    \"\"\"This field is set as part of responses.\"\"\"\n    questions: list[Question]\n    \"\"\"\n    The question section is used to carry the \"question\" in most queries, i.e.\n    the parameters that define what is being asked.\n    \"\"\"\n    answers: list[ResourceRecord]\n    \"\"\"First resource record section.\"\"\"\n    authorities: list[ResourceRecord]\n    \"\"\"Second resource record section.\"\"\"\n    additionals: list[ResourceRecord]\n    \"\"\"Third resource record section.\"\"\"\n\n    def __str__(self) -> str:\n        return \"\\r\\n\".join(\n            map(\n                str,\n                itertools.chain(\n                    self.questions, self.answers, self.authorities, self.additionals\n                ),\n            )\n        )\n\n    @property\n    def content(self) -> bytes:\n        \"\"\"Returns the user-friendly content of all parts as encoded bytes.\"\"\"\n        return str(self).encode()\n\n    @property\n    def size(self) -> int:\n        \"\"\"Returns the cumulative data size of all resource record sections.\"\"\"\n        return sum(\n            len(x.data)\n            for x in itertools.chain.from_iterable(\n                [self.answers, self.authorities, self.additionals]\n            )\n        )\n\n    def fail(self, response_code: int) -> Message:\n        if response_code == response_codes.NOERROR:\n            raise ValueError(\"response_code must be an error code.\")\n        return Message(\n            timestamp=time.time(),\n            id=self.id,\n            query=False,\n            op_code=self.op_code,\n            authoritative_answer=False,\n            truncation=False,\n            recursion_desired=self.recursion_desired,\n            recursion_available=False,\n            reserved=0,\n            response_code=response_code,\n            questions=self.questions,\n            answers=[],\n            authorities=[],\n            additionals=[],\n        )\n\n    def succeed(self, answers: list[ResourceRecord]) -> Message:\n        return Message(\n            timestamp=time.time(),\n            id=self.id,\n            query=False,\n            op_code=self.op_code,\n            authoritative_answer=False,\n            truncation=False,\n            recursion_desired=self.recursion_desired,\n            recursion_available=True,\n            reserved=0,\n            response_code=response_codes.NOERROR,\n            questions=self.questions,\n            answers=answers,\n            authorities=[],\n            additionals=[],\n        )\n\n    @classmethod\n    def unpack(cls, buffer: bytes) -> Message:\n        \"\"\"Converts the entire given buffer into a DNS message.\"\"\"\n        length, msg = cls.unpack_from(buffer, 0)\n        if length != len(buffer):\n            raise struct.error(f\"unpack requires a buffer of {length} bytes\")\n        return msg\n\n    @classmethod\n    def unpack_from(cls, buffer: bytes | bytearray, offset: int) -> tuple[int, Message]:\n        \"\"\"Converts the buffer from a given offset into a DNS message and also returns its length.\"\"\"\n        (\n            id,\n            flags,\n            len_questions,\n            len_answers,\n            len_authorities,\n            len_additionals,\n        ) = Message.HEADER.unpack_from(buffer, offset)\n        msg = Message(\n            timestamp=time.time(),\n            id=id,\n            query=(flags & (1 << 15)) == 0,\n            op_code=(flags >> 11) & 0b1111,\n            authoritative_answer=(flags & (1 << 10)) != 0,\n            truncation=(flags & (1 << 9)) != 0,\n            recursion_desired=(flags & (1 << 8)) != 0,\n            recursion_available=(flags & (1 << 7)) != 0,\n            reserved=(flags >> 4) & 0b111,\n            response_code=flags & 0b1111,\n            questions=[],\n            answers=[],\n            authorities=[],\n            additionals=[],\n        )\n        offset += Message.HEADER.size\n        cached_names = domain_names.cache()\n\n        def unpack_domain_name() -> str:\n            nonlocal buffer, offset, cached_names\n            name, length = domain_names.unpack_from_with_compression(\n                buffer, offset, cached_names\n            )\n            offset += length\n            return name\n\n        for i in range(0, len_questions):\n            try:\n                name = unpack_domain_name()\n                type, class_ = Question.HEADER.unpack_from(buffer, offset)\n                offset += Question.HEADER.size\n                msg.questions.append(Question(name=name, type=type, class_=class_))\n            except struct.error as e:\n                raise struct.error(f\"question #{i}: {str(e)}\")\n\n        def unpack_rrs(\n            section: list[ResourceRecord], section_name: str, count: int\n        ) -> None:\n            nonlocal buffer, offset\n            for i in range(0, count):\n                try:\n                    name = unpack_domain_name()\n                    type, class_, ttl, len_data = ResourceRecord.HEADER.unpack_from(\n                        buffer, offset\n                    )\n                    offset += ResourceRecord.HEADER.size\n                    end_data = offset + len_data\n                    if len(buffer) < end_data:\n                        raise struct.error(\n                            f\"unpack requires a data buffer of {len_data} bytes\"\n                        )\n                    data = buffer[offset:end_data]\n                    if 0b11000000 in data:\n                        # the resource record might contains a compressed domain name, if so, uncompressed in advance\n                        try:\n                            (\n                                rr_name,\n                                rr_name_len,\n                            ) = domain_names.unpack_from_with_compression(\n                                buffer, offset, cached_names\n                            )\n                            if rr_name_len == len_data:\n                                data = domain_names.pack(rr_name)\n                        except struct.error:\n                            pass\n                    section.append(ResourceRecord(name, type, class_, ttl, data))\n                    offset += len_data\n                except struct.error as e:\n                    raise struct.error(f\"{section_name} #{i}: {str(e)}\")\n\n        unpack_rrs(msg.answers, \"answer\", len_answers)\n        unpack_rrs(msg.authorities, \"authority\", len_authorities)\n        unpack_rrs(msg.additionals, \"additional\", len_additionals)\n        return (offset, msg)\n\n    @property\n    def packed(self) -> bytes:\n        \"\"\"Converts the message into network bytes.\"\"\"\n        if self.id < 0 or self.id > 65535:\n            raise ValueError(f\"DNS message's id {self.id} is out of bounds.\")\n        flags = 0\n        if not self.query:\n            flags |= 1 << 15\n        if self.op_code < 0 or self.op_code > 0b1111:\n            raise ValueError(f\"DNS message's op_code {self.op_code} is out of bounds.\")\n        flags |= self.op_code << 11\n        if self.authoritative_answer:\n            flags |= 1 << 10\n        if self.truncation:\n            flags |= 1 << 9\n        if self.recursion_desired:\n            flags |= 1 << 8\n        if self.recursion_available:\n            flags |= 1 << 7\n        if self.reserved < 0 or self.reserved > 0b111:\n            raise ValueError(\n                f\"DNS message's reserved value of {self.reserved} is out of bounds.\"\n            )\n        flags |= self.reserved << 4\n        if self.response_code < 0 or self.response_code > 0b1111:\n            raise ValueError(\n                f\"DNS message's response_code {self.response_code} is out of bounds.\"\n            )\n        flags |= self.response_code\n        data = bytearray()\n        data.extend(\n            Message.HEADER.pack(\n                self.id,\n                flags,\n                len(self.questions),\n                len(self.answers),\n                len(self.authorities),\n                len(self.additionals),\n            )\n        )\n        # TODO implement compression\n        for question in self.questions:\n            data.extend(domain_names.pack(question.name))\n            data.extend(Question.HEADER.pack(question.type, question.class_))\n        for rr in (*self.answers, *self.authorities, *self.additionals):\n            data.extend(domain_names.pack(rr.name))\n            data.extend(\n                ResourceRecord.HEADER.pack(rr.type, rr.class_, rr.ttl, len(rr.data))\n            )\n            data.extend(rr.data)\n        return bytes(data)\n\n    def to_json(self) -> dict:\n        \"\"\"\n        Converts the message into json for mitmweb.\n        Sync with web/src/flow.ts.\n        \"\"\"\n        return {\n            \"id\": self.id,\n            \"query\": self.query,\n            \"op_code\": op_codes.to_str(self.op_code),\n            \"authoritative_answer\": self.authoritative_answer,\n            \"truncation\": self.truncation,\n            \"recursion_desired\": self.recursion_desired,\n            \"recursion_available\": self.recursion_available,\n            \"response_code\": response_codes.to_str(self.response_code),\n            \"status_code\": response_codes.http_equiv_status_code(self.response_code),\n            \"questions\": [question.to_json() for question in self.questions],\n            \"answers\": [rr.to_json() for rr in self.answers],\n            \"authorities\": [rr.to_json() for rr in self.authorities],\n            \"additionals\": [rr.to_json() for rr in self.additionals],\n            \"size\": self.size,\n            \"timestamp\": self.timestamp,\n        }\n\n    def copy(self) -> Message:\n        # we keep the copy semantics but change the ID generation\n        state = self.get_state()\n        state[\"id\"] = random.randint(0, 65535)\n        return Message.from_state(state)\n\n\nclass DNSFlow(flow.Flow):\n    \"\"\"A DNSFlow is a collection of DNS messages representing a single DNS query.\"\"\"\n\n    request: Message\n    \"\"\"The DNS request.\"\"\"\n    response: Message | None = None\n    \"\"\"The DNS response.\"\"\"\n\n    def get_state(self) -> serializable.State:\n        return {\n            **super().get_state(),\n            \"request\": self.request.get_state(),\n            \"response\": self.response.get_state() if self.response else None,\n        }\n\n    def set_state(self, state: serializable.State) -> None:\n        self.request = Message.from_state(state.pop(\"request\"))\n        self.response = Message.from_state(r) if (r := state.pop(\"response\")) else None\n        super().set_state(state)\n\n    def __repr__(self) -> str:\n        return f\"<DNSFlow\\r\\n  request={repr(self.request)}\\r\\n  response={repr(self.response)}\\r\\n>\"\n", "mitmproxy/tls.py": "import io\nfrom dataclasses import dataclass\n\nfrom kaitaistruct import KaitaiStream\nfrom OpenSSL import SSL\n\nfrom mitmproxy import connection\nfrom mitmproxy.contrib.kaitaistruct import dtls_client_hello\nfrom mitmproxy.contrib.kaitaistruct import tls_client_hello\nfrom mitmproxy.net import check\nfrom mitmproxy.proxy import context\n\n\nclass ClientHello:\n    \"\"\"\n    A TLS ClientHello is the first message sent by the client when initiating TLS.\n    \"\"\"\n\n    _raw_bytes: bytes\n\n    def __init__(self, raw_client_hello: bytes, dtls: bool = False):\n        \"\"\"Create a TLS ClientHello object from raw bytes.\"\"\"\n        self._raw_bytes = raw_client_hello\n        if dtls:\n            self._client_hello = dtls_client_hello.DtlsClientHello(\n                KaitaiStream(io.BytesIO(raw_client_hello))\n            )\n        else:\n            self._client_hello = tls_client_hello.TlsClientHello(\n                KaitaiStream(io.BytesIO(raw_client_hello))\n            )\n\n    def raw_bytes(self, wrap_in_record: bool = True) -> bytes:\n        \"\"\"\n        The raw ClientHello bytes as seen on the wire.\n\n        If `wrap_in_record` is True, the ClientHello will be wrapped in a synthetic TLS record\n        (`0x160303 + len(chm) + 0x01 + len(ch)`), which is the format expected by some tools.\n        The synthetic record assumes TLS version (`0x0303`), which may be different from what has been sent over the\n        wire. JA3 hashes are unaffected by this as they only use the TLS version from the ClientHello data structure.\n\n        A future implementation may return not just the exact ClientHello, but also the exact record(s) as seen on the\n        wire.\n        \"\"\"\n        if isinstance(self._client_hello, dtls_client_hello.DtlsClientHello):\n            raise NotImplementedError\n\n        if wrap_in_record:\n            return (\n                # record layer\n                b\"\\x16\\x03\\x03\"\n                + (len(self._raw_bytes) + 4).to_bytes(2, byteorder=\"big\")\n                +\n                # handshake header\n                b\"\\x01\"\n                + len(self._raw_bytes).to_bytes(3, byteorder=\"big\")\n                +\n                # ClientHello as defined in https://datatracker.ietf.org/doc/html/rfc8446#section-4.1.2.\n                self._raw_bytes\n            )\n        else:\n            return self._raw_bytes\n\n    @property\n    def cipher_suites(self) -> list[int]:\n        \"\"\"The cipher suites offered by the client (as raw ints).\"\"\"\n        return self._client_hello.cipher_suites.cipher_suites\n\n    @property\n    def sni(self) -> str | None:\n        \"\"\"\n        The [Server Name Indication](https://en.wikipedia.org/wiki/Server_Name_Indication),\n        which indicates which hostname the client wants to connect to.\n        \"\"\"\n        if ext := getattr(self._client_hello, \"extensions\", None):\n            for extension in ext.extensions:\n                is_valid_sni_extension = (\n                    extension.type == 0x00\n                    and len(extension.body.server_names) == 1\n                    and extension.body.server_names[0].name_type == 0\n                    and check.is_valid_host(extension.body.server_names[0].host_name)\n                )\n                if is_valid_sni_extension:\n                    return extension.body.server_names[0].host_name.decode(\"ascii\")\n        return None\n\n    @property\n    def alpn_protocols(self) -> list[bytes]:\n        \"\"\"\n        The application layer protocols offered by the client as part of the\n        [ALPN](https://en.wikipedia.org/wiki/Application-Layer_Protocol_Negotiation) TLS extension.\n        \"\"\"\n        if ext := getattr(self._client_hello, \"extensions\", None):\n            for extension in ext.extensions:\n                if extension.type == 0x10:\n                    return list(x.name for x in extension.body.alpn_protocols)\n        return []\n\n    @property\n    def extensions(self) -> list[tuple[int, bytes]]:\n        \"\"\"The raw list of extensions in the form of `(extension_type, raw_bytes)` tuples.\"\"\"\n        ret = []\n        if ext := getattr(self._client_hello, \"extensions\", None):\n            for extension in ext.extensions:\n                body = getattr(extension, \"_raw_body\", extension.body)\n                ret.append((extension.type, body))\n        return ret\n\n    def __repr__(self):\n        return f\"ClientHello(sni: {self.sni}, alpn_protocols: {self.alpn_protocols})\"\n\n\n@dataclass\nclass ClientHelloData:\n    \"\"\"\n    Event data for `tls_clienthello` event hooks.\n    \"\"\"\n\n    context: context.Context\n    \"\"\"The context object for this connection.\"\"\"\n    client_hello: ClientHello\n    \"\"\"The entire parsed TLS ClientHello.\"\"\"\n    ignore_connection: bool = False\n    \"\"\"\n    If set to `True`, do not intercept this connection and forward encrypted contents unmodified.\n    \"\"\"\n    establish_server_tls_first: bool = False\n    \"\"\"\n    If set to `True`, pause this handshake and establish TLS with an upstream server first.\n    This makes it possible to process the server certificate when generating an interception certificate.\n    \"\"\"\n\n\n@dataclass\nclass TlsData:\n    \"\"\"\n    Event data for `tls_start_client`, `tls_start_server`, and `tls_handshake` event hooks.\n    \"\"\"\n\n    conn: connection.Connection\n    \"\"\"The affected connection.\"\"\"\n    context: context.Context\n    \"\"\"The context object for this connection.\"\"\"\n    ssl_conn: SSL.Connection | None = None\n    \"\"\"\n    The associated pyOpenSSL `SSL.Connection` object.\n    This will be set by an addon in the `tls_start_*` event hooks.\n    \"\"\"\n    is_dtls: bool = False\n    \"\"\"\n    If set to `True`, indicates that it is a DTLS event.\n    \"\"\"\n", "mitmproxy/eventsequence.py": "from collections.abc import Callable\nfrom collections.abc import Iterator\nfrom typing import Any\n\nfrom mitmproxy import dns\nfrom mitmproxy import flow\nfrom mitmproxy import hooks\nfrom mitmproxy import http\nfrom mitmproxy import tcp\nfrom mitmproxy import udp\nfrom mitmproxy.proxy import layers\n\nTEventGenerator = Iterator[hooks.Hook]\n\n\ndef _iterate_http(f: http.HTTPFlow) -> TEventGenerator:\n    if f.request:\n        yield layers.http.HttpRequestHeadersHook(f)\n        yield layers.http.HttpRequestHook(f)\n    if f.response:\n        yield layers.http.HttpResponseHeadersHook(f)\n        yield layers.http.HttpResponseHook(f)\n    if f.websocket:\n        message_queue = f.websocket.messages\n        f.websocket.messages = []\n        yield layers.websocket.WebsocketStartHook(f)\n        for m in message_queue:\n            f.websocket.messages.append(m)\n            yield layers.websocket.WebsocketMessageHook(f)\n        yield layers.websocket.WebsocketEndHook(f)\n    elif f.error:\n        yield layers.http.HttpErrorHook(f)\n\n\ndef _iterate_tcp(f: tcp.TCPFlow) -> TEventGenerator:\n    messages = f.messages\n    f.messages = []\n    yield layers.tcp.TcpStartHook(f)\n    while messages:\n        f.messages.append(messages.pop(0))\n        yield layers.tcp.TcpMessageHook(f)\n    if f.error:\n        yield layers.tcp.TcpErrorHook(f)\n    else:\n        yield layers.tcp.TcpEndHook(f)\n\n\ndef _iterate_udp(f: udp.UDPFlow) -> TEventGenerator:\n    messages = f.messages\n    f.messages = []\n    yield layers.udp.UdpStartHook(f)\n    while messages:\n        f.messages.append(messages.pop(0))\n        yield layers.udp.UdpMessageHook(f)\n    if f.error:\n        yield layers.udp.UdpErrorHook(f)\n    else:\n        yield layers.udp.UdpEndHook(f)\n\n\ndef _iterate_dns(f: dns.DNSFlow) -> TEventGenerator:\n    if f.request:\n        yield layers.dns.DnsRequestHook(f)\n    if f.response:\n        yield layers.dns.DnsResponseHook(f)\n    if f.error:\n        yield layers.dns.DnsErrorHook(f)\n\n\n_iterate_map: dict[type[flow.Flow], Callable[[Any], TEventGenerator]] = {\n    http.HTTPFlow: _iterate_http,\n    tcp.TCPFlow: _iterate_tcp,\n    udp.UDPFlow: _iterate_udp,\n    dns.DNSFlow: _iterate_dns,\n}\n\n\ndef iterate(f: flow.Flow) -> TEventGenerator:\n    try:\n        e = _iterate_map[type(f)]\n    except KeyError as err:\n        raise TypeError(f\"Unknown flow type: {f.__class__.__name__}\") from err\n    else:\n        yield from e(f)\n", "mitmproxy/udp.py": "import time\n\nfrom mitmproxy import connection\nfrom mitmproxy import flow\nfrom mitmproxy.coretypes import serializable\n\n\nclass UDPMessage(serializable.Serializable):\n    \"\"\"\n    An individual UDP datagram.\n    \"\"\"\n\n    def __init__(self, from_client, content, timestamp=None):\n        self.from_client = from_client\n        self.content = content\n        self.timestamp = timestamp or time.time()\n\n    @classmethod\n    def from_state(cls, state):\n        return cls(*state)\n\n    def get_state(self):\n        return self.from_client, self.content, self.timestamp\n\n    def set_state(self, state):\n        self.from_client, self.content, self.timestamp = state\n\n    def __repr__(self):\n        return \"{direction} {content}\".format(\n            direction=\"->\" if self.from_client else \"<-\", content=repr(self.content)\n        )\n\n\nclass UDPFlow(flow.Flow):\n    \"\"\"\n    A UDPFlow is a representation of a UDP session.\n    \"\"\"\n\n    messages: list[UDPMessage]\n    \"\"\"\n    The messages transmitted over this connection.\n\n    The latest message can be accessed as `flow.messages[-1]` in event hooks.\n    \"\"\"\n\n    def __init__(\n        self,\n        client_conn: connection.Client,\n        server_conn: connection.Server,\n        live: bool = False,\n    ):\n        super().__init__(client_conn, server_conn, live)\n        self.messages = []\n\n    def get_state(self) -> serializable.State:\n        return {\n            **super().get_state(),\n            \"messages\": [m.get_state() for m in self.messages],\n        }\n\n    def set_state(self, state: serializable.State) -> None:\n        self.messages = [UDPMessage.from_state(m) for m in state.pop(\"messages\")]\n        super().set_state(state)\n\n    def __repr__(self):\n        return f\"<UDPFlow ({len(self.messages)} messages)>\"\n\n\n__all__ = [\n    \"UDPFlow\",\n    \"UDPMessage\",\n]\n", "mitmproxy/optmanager.py": "from __future__ import annotations\n\nimport contextlib\nimport copy\nimport pprint\nimport textwrap\nimport weakref\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import Optional\nfrom typing import TextIO\n\nimport ruamel.yaml\n\nfrom mitmproxy import exceptions\nfrom mitmproxy.utils import signals\nfrom mitmproxy.utils import typecheck\n\n\"\"\"\n    The base implementation for Options.\n\"\"\"\n\nunset = object()\n\n\nclass _Option:\n    __slots__ = (\"name\", \"typespec\", \"value\", \"_default\", \"choices\", \"help\")\n\n    def __init__(\n        self,\n        name: str,\n        typespec: type | object,  # object for Optional[x], which is not a type.\n        default: Any,\n        help: str,\n        choices: Sequence[str] | None,\n    ) -> None:\n        typecheck.check_option_type(name, default, typespec)\n        self.name = name\n        self.typespec = typespec\n        self._default = default\n        self.value = unset\n        self.help = textwrap.dedent(help).strip().replace(\"\\n\", \" \")\n        self.choices = choices\n\n    def __repr__(self):\n        return f\"{self.current()} [{self.typespec}]\"\n\n    @property\n    def default(self):\n        return copy.deepcopy(self._default)\n\n    def current(self) -> Any:\n        if self.value is unset:\n            v = self.default\n        else:\n            v = self.value\n        return copy.deepcopy(v)\n\n    def set(self, value: Any) -> None:\n        typecheck.check_option_type(self.name, value, self.typespec)\n        self.value = value\n\n    def reset(self) -> None:\n        self.value = unset\n\n    def has_changed(self) -> bool:\n        return self.current() != self.default\n\n    def __eq__(self, other) -> bool:\n        for i in self.__slots__:\n            if getattr(self, i) != getattr(other, i):\n                return False\n        return True\n\n    def __deepcopy__(self, _):\n        o = _Option(self.name, self.typespec, self.default, self.help, self.choices)\n        if self.has_changed():\n            o.value = self.current()\n        return o\n\n\n@dataclass\nclass _UnconvertedStrings:\n    val: list[str]\n\n\ndef _sig_changed_spec(updated: set[str]) -> None:  # pragma: no cover\n    ...  # expected function signature for OptManager.changed receivers.\n\n\ndef _sig_errored_spec(exc: Exception) -> None:  # pragma: no cover\n    ...  # expected function signature for OptManager.errored receivers.\n\n\nclass OptManager:\n    \"\"\"\n    OptManager is the base class from which Options objects are derived.\n\n    .changed is a Signal that triggers whenever options are\n    updated. If any handler in the chain raises an exceptions.OptionsError\n    exception, all changes are rolled back, the exception is suppressed,\n    and the .errored signal is notified.\n\n    Optmanager always returns a deep copy of options to ensure that\n    mutation doesn't change the option state inadvertently.\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.deferred: dict[str, Any] = {}\n        self.changed = signals.SyncSignal(_sig_changed_spec)\n        self.changed.connect(self._notify_subscribers)\n        self.errored = signals.SyncSignal(_sig_errored_spec)\n        self._subscriptions: list[tuple[weakref.ref[Callable], set[str]]] = []\n        # Options must be the last attribute here - after that, we raise an\n        # error for attribute assignment to unknown options.\n        self._options: dict[str, Any] = {}\n\n    def add_option(\n        self,\n        name: str,\n        typespec: type | object,\n        default: Any,\n        help: str,\n        choices: Sequence[str] | None = None,\n    ) -> None:\n        self._options[name] = _Option(name, typespec, default, help, choices)\n        self.changed.send(updated={name})\n\n    @contextlib.contextmanager\n    def rollback(self, updated, reraise=False):\n        old = copy.deepcopy(self._options)\n        try:\n            yield\n        except exceptions.OptionsError as e:\n            # Notify error handlers\n            self.errored.send(exc=e)\n            # Rollback\n            self.__dict__[\"_options\"] = old\n            self.changed.send(updated=updated)\n            if reraise:\n                raise e\n\n    def subscribe(self, func, opts):\n        \"\"\"\n        Subscribe a callable to the .changed signal, but only for a\n        specified list of options. The callable should accept arguments\n        (options, updated), and may raise an OptionsError.\n\n        The event will automatically be unsubscribed if the callable goes out of scope.\n        \"\"\"\n        for i in opts:\n            if i not in self._options:\n                raise exceptions.OptionsError(\"No such option: %s\" % i)\n\n        self._subscriptions.append((signals.make_weak_ref(func), set(opts)))\n\n    def _notify_subscribers(self, updated) -> None:\n        cleanup = False\n        for ref, opts in self._subscriptions:\n            callback = ref()\n            if callback is not None:\n                if opts & updated:\n                    callback(self, updated)\n            else:\n                cleanup = True\n\n        if cleanup:\n            self.__dict__[\"_subscriptions\"] = [\n                (ref, opts) for (ref, opts) in self._subscriptions if ref() is not None\n            ]\n\n    def __eq__(self, other):\n        if isinstance(other, OptManager):\n            return self._options == other._options\n        return False\n\n    def __deepcopy__(self, memodict=None):\n        o = OptManager()\n        o.__dict__[\"_options\"] = copy.deepcopy(self._options, memodict)\n        return o\n\n    __copy__ = __deepcopy__\n\n    def __getattr__(self, attr):\n        if attr in self._options:\n            return self._options[attr].current()\n        else:\n            raise AttributeError(\"No such option: %s\" % attr)\n\n    def __setattr__(self, attr, value):\n        # This is slightly tricky. We allow attributes to be set on the instance\n        # until we have an _options attribute. After that, assignment is sent to\n        # the update function, and will raise an error for unknown options.\n        opts = self.__dict__.get(\"_options\")\n        if not opts:\n            super().__setattr__(attr, value)\n        else:\n            self.update(**{attr: value})\n\n    def keys(self):\n        return set(self._options.keys())\n\n    def items(self):\n        return self._options.items()\n\n    def __contains__(self, k):\n        return k in self._options\n\n    def reset(self):\n        \"\"\"\n        Restore defaults for all options.\n        \"\"\"\n        for o in self._options.values():\n            o.reset()\n        self.changed.send(updated=set(self._options.keys()))\n\n    def update_known(self, **kwargs):\n        \"\"\"\n        Update and set all known options from kwargs. Returns a dictionary\n        of unknown options.\n        \"\"\"\n        known, unknown = {}, {}\n        for k, v in kwargs.items():\n            if k in self._options:\n                known[k] = v\n            else:\n                unknown[k] = v\n        updated = set(known.keys())\n        if updated:\n            with self.rollback(updated, reraise=True):\n                for k, v in known.items():\n                    self._options[k].set(v)\n                self.changed.send(updated=updated)\n        return unknown\n\n    def update_defer(self, **kwargs):\n        unknown = self.update_known(**kwargs)\n        self.deferred.update(unknown)\n\n    def update(self, **kwargs):\n        u = self.update_known(**kwargs)\n        if u:\n            raise KeyError(\"Unknown options: %s\" % \", \".join(u.keys()))\n\n    def setter(self, attr):\n        \"\"\"\n        Generate a setter for a given attribute. This returns a callable\n        taking a single argument.\n        \"\"\"\n        if attr not in self._options:\n            raise KeyError(\"No such option: %s\" % attr)\n\n        def setter(x):\n            setattr(self, attr, x)\n\n        return setter\n\n    def toggler(self, attr):\n        \"\"\"\n        Generate a toggler for a boolean attribute. This returns a callable\n        that takes no arguments.\n        \"\"\"\n        if attr not in self._options:\n            raise KeyError(\"No such option: %s\" % attr)\n        o = self._options[attr]\n        if o.typespec != bool:\n            raise ValueError(\"Toggler can only be used with boolean options\")\n\n        def toggle():\n            setattr(self, attr, not getattr(self, attr))\n\n        return toggle\n\n    def default(self, option: str) -> Any:\n        return self._options[option].default\n\n    def has_changed(self, option):\n        \"\"\"\n        Has the option changed from the default?\n        \"\"\"\n        return self._options[option].has_changed()\n\n    def merge(self, opts):\n        \"\"\"\n        Merge a dict of options into this object. Options that have None\n        value are ignored. Lists and tuples are appended to the current\n        option value.\n        \"\"\"\n        toset = {}\n        for k, v in opts.items():\n            if v is not None:\n                if isinstance(v, (list, tuple)):\n                    toset[k] = getattr(self, k) + v\n                else:\n                    toset[k] = v\n        self.update(**toset)\n\n    def __repr__(self):\n        options = pprint.pformat(self._options, indent=4).strip(\" {}\")\n        if \"\\n\" in options:\n            options = \"\\n    \" + options + \"\\n\"\n        return \"{mod}.{cls}({{{options}}})\".format(\n            mod=type(self).__module__, cls=type(self).__name__, options=options\n        )\n\n    def set(self, *specs: str, defer: bool = False) -> None:\n        \"\"\"\n        Takes a list of set specification in standard form (option=value).\n        Options that are known are updated immediately. If defer is true,\n        options that are not known are deferred, and will be set once they\n        are added.\n\n        May raise an `OptionsError` if a value is malformed or an option is unknown and defer is False.\n        \"\"\"\n        # First, group specs by option name.\n        unprocessed: dict[str, list[str]] = {}\n        for spec in specs:\n            if \"=\" in spec:\n                name, value = spec.split(\"=\", maxsplit=1)\n                unprocessed.setdefault(name, []).append(value)\n            else:\n                unprocessed.setdefault(spec, [])\n\n        # Second, convert values to the correct type.\n        processed: dict[str, Any] = {}\n        for name in list(unprocessed.keys()):\n            if name in self._options:\n                processed[name] = self._parse_setval(\n                    self._options[name], unprocessed.pop(name)\n                )\n\n        # Third, stash away unrecognized options or complain about them.\n        if defer:\n            self.deferred.update(\n                {k: _UnconvertedStrings(v) for k, v in unprocessed.items()}\n            )\n        elif unprocessed:\n            raise exceptions.OptionsError(\n                f\"Unknown option(s): {', '.join(unprocessed)}\"\n            )\n\n        # Finally, apply updated options.\n        self.update(**processed)\n\n    def process_deferred(self) -> None:\n        \"\"\"\n        Processes options that were deferred in previous calls to set, and\n        have since been added.\n        \"\"\"\n        update: dict[str, Any] = {}\n        for optname, value in self.deferred.items():\n            if optname in self._options:\n                if isinstance(value, _UnconvertedStrings):\n                    value = self._parse_setval(self._options[optname], value.val)\n                update[optname] = value\n        self.update(**update)\n        for k in update.keys():\n            del self.deferred[k]\n\n    def _parse_setval(self, o: _Option, values: list[str]) -> Any:\n        \"\"\"\n        Convert a string to a value appropriate for the option type.\n        \"\"\"\n        if o.typespec == Sequence[str]:\n            return values\n        if len(values) > 1:\n            raise exceptions.OptionsError(\n                f\"Received multiple values for {o.name}: {values}\"\n            )\n\n        optstr: str | None\n        if values:\n            optstr = values[0]\n        else:\n            optstr = None\n\n        if o.typespec in (str, Optional[str]):\n            if o.typespec == str and optstr is None:\n                raise exceptions.OptionsError(f\"Option is required: {o.name}\")\n            return optstr\n        elif o.typespec in (int, Optional[int]):\n            if optstr:\n                try:\n                    return int(optstr)\n                except ValueError:\n                    raise exceptions.OptionsError(f\"Not an integer: {optstr}\")\n            elif o.typespec == int:\n                raise exceptions.OptionsError(f\"Option is required: {o.name}\")\n            else:\n                return None\n        elif o.typespec == bool:\n            if optstr == \"toggle\":\n                return not o.current()\n            if not optstr or optstr == \"true\":\n                return True\n            elif optstr == \"false\":\n                return False\n            else:\n                raise exceptions.OptionsError(\n                    'Boolean must be \"true\", \"false\", or have the value omitted (a synonym for \"true\").'\n                )\n        raise NotImplementedError(f\"Unsupported option type: {o.typespec}\")\n\n    def make_parser(self, parser, optname, metavar=None, short=None):\n        \"\"\"\n        Auto-Create a command-line parser entry for a named option. If the\n        option does not exist, it is ignored.\n        \"\"\"\n        if optname not in self._options:\n            return\n\n        o = self._options[optname]\n\n        def mkf(x, s):\n            x = x.replace(\"_\", \"-\")\n            f = [\"--%s\" % x]\n            if s:\n                f.append(\"-\" + s)\n            return f\n\n        flags = mkf(optname, short)\n\n        if o.typespec == bool:\n            g = parser.add_mutually_exclusive_group(required=False)\n            onf = mkf(optname, None)\n            offf = mkf(\"no-\" + optname, None)\n            # The short option for a bool goes to whatever is NOT the default\n            if short:\n                if o.default:\n                    offf = mkf(\"no-\" + optname, short)\n                else:\n                    onf = mkf(optname, short)\n            g.add_argument(\n                *offf,\n                action=\"store_false\",\n                dest=optname,\n            )\n            g.add_argument(*onf, action=\"store_true\", dest=optname, help=o.help)\n            parser.set_defaults(**{optname: None})\n        elif o.typespec in (int, Optional[int]):\n            parser.add_argument(\n                *flags,\n                action=\"store\",\n                type=int,\n                dest=optname,\n                help=o.help,\n                metavar=metavar,\n            )\n        elif o.typespec in (str, Optional[str]):\n            parser.add_argument(\n                *flags,\n                action=\"store\",\n                type=str,\n                dest=optname,\n                help=o.help,\n                metavar=metavar,\n                choices=o.choices,\n            )\n        elif o.typespec == Sequence[str]:\n            parser.add_argument(\n                *flags,\n                action=\"append\",\n                type=str,\n                dest=optname,\n                help=o.help + \" May be passed multiple times.\",\n                metavar=metavar,\n                choices=o.choices,\n            )\n        else:\n            raise ValueError(\"Unsupported option type: %s\", o.typespec)\n\n\ndef dump_defaults(opts, out: TextIO):\n    \"\"\"\n    Dumps an annotated file with all options.\n    \"\"\"\n    # Sort data\n    s = ruamel.yaml.comments.CommentedMap()\n    for k in sorted(opts.keys()):\n        o = opts._options[k]\n        s[k] = o.default\n        txt = o.help.strip()\n\n        if o.choices:\n            txt += \" Valid values are %s.\" % \", \".join(repr(c) for c in o.choices)\n        else:\n            t = typecheck.typespec_to_str(o.typespec)\n            txt += \" Type %s.\" % t\n\n        txt = \"\\n\".join(textwrap.wrap(txt))\n        s.yaml_set_comment_before_after_key(k, before=\"\\n\" + txt)\n    return ruamel.yaml.YAML().dump(s, out)\n\n\ndef dump_dicts(opts, keys: Iterable[str] | None = None) -> dict:\n    \"\"\"\n    Dumps the options into a list of dict object.\n\n    Return: A list like: { \"anticache\": { type: \"bool\", default: false, value: true, help: \"help text\"} }\n    \"\"\"\n    options_dict = {}\n    if keys is None:\n        keys = opts.keys()\n    for k in sorted(keys):\n        o = opts._options[k]\n        t = typecheck.typespec_to_str(o.typespec)\n        option = {\n            \"type\": t,\n            \"default\": o.default,\n            \"value\": o.current(),\n            \"help\": o.help,\n            \"choices\": o.choices,\n        }\n        options_dict[k] = option\n    return options_dict\n\n\ndef parse(text):\n    if not text:\n        return {}\n    try:\n        yaml = ruamel.yaml.YAML(typ=\"safe\", pure=True)\n        data = yaml.load(text)\n    except ruamel.yaml.error.YAMLError as v:\n        if hasattr(v, \"problem_mark\"):\n            snip = v.problem_mark.get_snippet()\n            raise exceptions.OptionsError(\n                \"Config error at line %s:\\n%s\\n%s\"\n                % (v.problem_mark.line + 1, snip, getattr(v, \"problem\", \"\"))\n            )\n        else:\n            raise exceptions.OptionsError(\"Could not parse options.\")\n    if isinstance(data, str):\n        raise exceptions.OptionsError(\"Config error - no keys found.\")\n    elif data is None:\n        return {}\n    return data\n\n\ndef load(opts: OptManager, text: str, cwd: Path | str | None = None) -> None:\n    \"\"\"\n    Load configuration from text, over-writing options already set in\n    this object. May raise OptionsError if the config file is invalid.\n    \"\"\"\n    data = parse(text)\n\n    scripts = data.get(\"scripts\")\n    if scripts is not None and cwd is not None:\n        data[\"scripts\"] = [\n            str(relative_path(Path(path), relative_to=Path(cwd))) for path in scripts\n        ]\n\n    opts.update_defer(**data)\n\n\ndef load_paths(opts: OptManager, *paths: Path | str) -> None:\n    \"\"\"\n    Load paths in order. Each path takes precedence over the previous\n    path. Paths that don't exist are ignored, errors raise an\n    OptionsError.\n    \"\"\"\n    for p in paths:\n        p = Path(p).expanduser()\n        if p.exists() and p.is_file():\n            with p.open(encoding=\"utf8\") as f:\n                try:\n                    txt = f.read()\n                except UnicodeDecodeError as e:\n                    raise exceptions.OptionsError(f\"Error reading {p}: {e}\")\n            try:\n                load(opts, txt, cwd=p.absolute().parent)\n            except exceptions.OptionsError as e:\n                raise exceptions.OptionsError(f\"Error reading {p}: {e}\")\n\n\ndef serialize(\n    opts: OptManager, file: TextIO, text: str, defaults: bool = False\n) -> None:\n    \"\"\"\n    Performs a round-trip serialization. If text is not None, it is\n    treated as a previous serialization that should be modified\n    in-place.\n\n    - If \"defaults\" is False, only options with non-default values are\n        serialized. Default values in text are preserved.\n    - Unknown options in text are removed.\n    - Raises OptionsError if text is invalid.\n    \"\"\"\n    data = parse(text)\n    for k in opts.keys():\n        if defaults or opts.has_changed(k):\n            data[k] = getattr(opts, k)\n    for k in list(data.keys()):\n        if k not in opts._options:\n            del data[k]\n\n    ruamel.yaml.YAML().dump(data, file)\n\n\ndef save(opts: OptManager, path: Path | str, defaults: bool = False) -> None:\n    \"\"\"\n    Save to path. If the destination file exists, modify it in-place.\n\n    Raises OptionsError if the existing data is corrupt.\n    \"\"\"\n    path = Path(path).expanduser()\n    if path.exists() and path.is_file():\n        with path.open(encoding=\"utf8\") as f:\n            try:\n                data = f.read()\n            except UnicodeDecodeError as e:\n                raise exceptions.OptionsError(f\"Error trying to modify {path}: {e}\")\n    else:\n        data = \"\"\n\n    with path.open(\"w\", encoding=\"utf8\") as f:\n        serialize(opts, f, data, defaults)\n\n\ndef relative_path(script_path: Path | str, *, relative_to: Path | str) -> Path:\n    \"\"\"\n    Make relative paths found in config files relative to said config file,\n    instead of relative to where the command is ran.\n    \"\"\"\n    script_path = Path(script_path)\n    # Edge case when $HOME is not an absolute path\n    if script_path.expanduser() != script_path and not script_path.is_absolute():\n        script_path = script_path.expanduser().absolute()\n    return (relative_to / script_path.expanduser()).absolute()\n", "mitmproxy/__init__.py": "", "mitmproxy/websocket.py": "\"\"\"\nMitmproxy used to have its own WebSocketFlow type until mitmproxy 6, but now WebSocket connections now are represented\nas HTTP flows as well. They can be distinguished from regular HTTP requests by having the\n`mitmproxy.http.HTTPFlow.websocket` attribute set.\n\nThis module only defines the classes for individual `WebSocketMessage`s and the `WebSocketData` container.\n\"\"\"\n\nimport time\nimport warnings\nfrom dataclasses import dataclass\nfrom dataclasses import field\n\nfrom wsproto.frame_protocol import Opcode\n\nfrom mitmproxy.coretypes import serializable\n\nWebSocketMessageState = tuple[int, bool, bytes, float, bool, bool]\n\n\nclass WebSocketMessage(serializable.Serializable):\n    \"\"\"\n    A single WebSocket message sent from one peer to the other.\n\n    Fragmented WebSocket messages are reassembled by mitmproxy and then\n    represented as a single instance of this class.\n\n    The [WebSocket RFC](https://tools.ietf.org/html/rfc6455) specifies both\n    text and binary messages. To avoid a whole class of nasty type confusion bugs,\n    mitmproxy stores all message contents as `bytes`. If you need a `str`, you can access the `text` property\n    on text messages:\n\n    >>> if message.is_text:\n    >>>     text = message.text\n    \"\"\"\n\n    from_client: bool\n    \"\"\"True if this messages was sent by the client.\"\"\"\n    type: Opcode\n    \"\"\"\n    The message type, as per RFC 6455's [opcode](https://tools.ietf.org/html/rfc6455#section-5.2).\n\n    Mitmproxy currently only exposes messages assembled from `TEXT` and `BINARY` frames.\n    \"\"\"\n    content: bytes\n    \"\"\"A byte-string representing the content of this message.\"\"\"\n    timestamp: float\n    \"\"\"Timestamp of when this message was received or created.\"\"\"\n    dropped: bool\n    \"\"\"True if the message has not been forwarded by mitmproxy, False otherwise.\"\"\"\n    injected: bool\n    \"\"\"True if the message was injected and did not originate from a client/server, False otherwise\"\"\"\n\n    def __init__(\n        self,\n        type: int | Opcode,\n        from_client: bool,\n        content: bytes,\n        timestamp: float | None = None,\n        dropped: bool = False,\n        injected: bool = False,\n    ) -> None:\n        self.from_client = from_client\n        self.type = Opcode(type)\n        self.content = content\n        self.timestamp: float = timestamp or time.time()\n        self.dropped = dropped\n        self.injected = injected\n\n    @classmethod\n    def from_state(cls, state: WebSocketMessageState):\n        return cls(*state)\n\n    def get_state(self) -> WebSocketMessageState:\n        return (\n            int(self.type),\n            self.from_client,\n            self.content,\n            self.timestamp,\n            self.dropped,\n            self.injected,\n        )\n\n    def set_state(self, state: WebSocketMessageState) -> None:\n        (\n            typ,\n            self.from_client,\n            self.content,\n            self.timestamp,\n            self.dropped,\n            self.injected,\n        ) = state\n        self.type = Opcode(typ)\n\n    def _format_ws_message(self) -> bytes:\n        if self.from_client:\n            return b\"[OUTGOING] \" + self.content\n        else:\n            return b\"[INCOMING] \" + self.content\n\n    def __repr__(self):\n        if self.type == Opcode.TEXT:\n            return repr(self.content.decode(errors=\"replace\"))\n        else:\n            return repr(self.content)\n\n    @property\n    def is_text(self) -> bool:\n        \"\"\"\n        `True` if this message is assembled from WebSocket `TEXT` frames,\n        `False` if it is assembled from `BINARY` frames.\n        \"\"\"\n        return self.type == Opcode.TEXT\n\n    def drop(self):\n        \"\"\"Drop this message, i.e. don't forward it to the other peer.\"\"\"\n        self.dropped = True\n\n    def kill(self):  # pragma: no cover\n        \"\"\"A deprecated alias for `.drop()`.\"\"\"\n        warnings.warn(\n            \"WebSocketMessage.kill() is deprecated, use .drop() instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        self.drop()\n\n    @property\n    def text(self) -> str:\n        \"\"\"\n        The message content as text.\n\n        This attribute is only available if `WebSocketMessage.is_text` is `True`.\n\n        *See also:* `WebSocketMessage.content`\n        \"\"\"\n        if self.type != Opcode.TEXT:\n            raise AttributeError(\n                f\"{self.type.name.title()} WebSocket frames do not have a 'text' attribute.\"\n            )\n\n        return self.content.decode()\n\n    @text.setter\n    def text(self, value: str) -> None:\n        if self.type != Opcode.TEXT:\n            raise AttributeError(\n                f\"{self.type.name.title()} WebSocket frames do not have a 'text' attribute.\"\n            )\n\n        self.content = value.encode()\n\n\n@dataclass\nclass WebSocketData(serializable.SerializableDataclass):\n    \"\"\"\n    A data container for everything related to a single WebSocket connection.\n    This is typically accessed as `mitmproxy.http.HTTPFlow.websocket`.\n    \"\"\"\n\n    messages: list[WebSocketMessage] = field(default_factory=list)\n    \"\"\"All `WebSocketMessage`s transferred over this connection.\"\"\"\n\n    closed_by_client: bool | None = None\n    \"\"\"\n    `True` if the client closed the connection,\n    `False` if the server closed the connection,\n    `None` if the connection is active.\n    \"\"\"\n    close_code: int | None = None\n    \"\"\"[Close Code](https://tools.ietf.org/html/rfc6455#section-7.1.5)\"\"\"\n    close_reason: str | None = None\n    \"\"\"[Close Reason](https://tools.ietf.org/html/rfc6455#section-7.1.6)\"\"\"\n\n    timestamp_end: float | None = None\n    \"\"\"*Timestamp:* WebSocket connection closed.\"\"\"\n\n    def __repr__(self):\n        return f\"<WebSocketData ({len(self.messages)} messages)>\"\n\n    def _get_formatted_messages(self) -> bytes:\n        return b\"\\n\".join(m._format_ws_message() for m in self.messages)\n", "mitmproxy/hooks.py": "import re\nimport warnings\nfrom collections.abc import Sequence\nfrom dataclasses import dataclass\nfrom dataclasses import fields\nfrom dataclasses import is_dataclass\nfrom typing import Any\nfrom typing import ClassVar\nfrom typing import TYPE_CHECKING\n\nimport mitmproxy.flow\n\nif TYPE_CHECKING:\n    import mitmproxy.addonmanager\n    import mitmproxy.log\n\n\nclass Hook:\n    name: ClassVar[str]\n\n    def args(self) -> list[Any]:\n        args = []\n        for field in fields(self):  # type: ignore[arg-type]\n            args.append(getattr(self, field.name))\n        return args\n\n    def __new__(cls, *args, **kwargs):\n        if cls is Hook:\n            raise TypeError(\"Hook may not be instantiated directly.\")\n        if not is_dataclass(cls):\n            raise TypeError(\"Subclass is not a dataclass.\")\n        return super().__new__(cls)\n\n    def __init_subclass__(cls, **kwargs):\n        # initialize .name attribute. HttpRequestHook -> http_request\n        if cls.__dict__.get(\"name\", None) is None:\n            name = cls.__name__.replace(\"Hook\", \"\")\n            cls.name = re.sub(\"(?!^)([A-Z]+)\", r\"_\\1\", name).lower()\n        if cls.name in all_hooks:\n            other = all_hooks[cls.name]\n            warnings.warn(\n                f\"Two conflicting event classes for {cls.name}: {cls} and {other}\",\n                RuntimeWarning,\n            )\n        if cls.name == \"\":\n            return  # don't register Hook class.\n        all_hooks[cls.name] = cls\n\n        # define a custom hash and __eq__ function so that events are hashable and not comparable.\n        cls.__hash__ = object.__hash__  # type: ignore\n        cls.__eq__ = object.__eq__  # type: ignore\n\n\nall_hooks: dict[str, type[Hook]] = {}\n\n\n@dataclass\nclass ConfigureHook(Hook):\n    \"\"\"\n    Called when configuration changes. The updated argument is a\n    set-like object containing the keys of all changed options. This\n    event is called during startup with all options in the updated set.\n    \"\"\"\n\n    updated: set[str]\n\n\n@dataclass\nclass DoneHook(Hook):\n    \"\"\"\n    Called when the addon shuts down, either by being removed from\n    the mitmproxy instance, or when mitmproxy itself shuts down. On\n    shutdown, this event is called after the event loop is\n    terminated, guaranteeing that it will be the final event an addon\n    sees. Note that log handlers are shut down at this point, so\n    calls to log functions will produce no output.\n    \"\"\"\n\n\n@dataclass\nclass RunningHook(Hook):\n    \"\"\"\n    Called when the proxy is completely up and running. At this point,\n    you can expect all addons to be loaded and all options to be set.\n    \"\"\"\n\n\n@dataclass\nclass UpdateHook(Hook):\n    \"\"\"\n    Update is called when one or more flow objects have been modified,\n    usually from a different addon.\n    \"\"\"\n\n    flows: Sequence[mitmproxy.flow.Flow]\n", "mitmproxy/addons/save.py": "import logging\nimport os.path\nimport sys\nfrom collections.abc import Sequence\nfrom datetime import datetime\nfrom functools import lru_cache\nfrom pathlib import Path\nfrom typing import Literal\nfrom typing import Optional\n\nimport mitmproxy.types\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import dns\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy import io\nfrom mitmproxy import tcp\nfrom mitmproxy import udp\nfrom mitmproxy.log import ALERT\n\n\n@lru_cache\ndef _path(path: str) -> str:\n    \"\"\"Extract the path from a path spec (which may have an extra \"+\" at the front)\"\"\"\n    if path.startswith(\"+\"):\n        path = path[1:]\n    return os.path.expanduser(path)\n\n\n@lru_cache\ndef _mode(path: str) -> Literal[\"ab\", \"wb\"]:\n    \"\"\"Extract the writing mode (overwrite or append) from a path spec\"\"\"\n    if path.startswith(\"+\"):\n        return \"ab\"\n    else:\n        return \"wb\"\n\n\nclass Save:\n    def __init__(self) -> None:\n        self.stream: io.FilteredFlowWriter | None = None\n        self.filt: flowfilter.TFilter | None = None\n        self.active_flows: set[flow.Flow] = set()\n        self.current_path: str | None = None\n\n    def load(self, loader):\n        loader.add_option(\n            \"save_stream_file\",\n            Optional[str],\n            None,\n            \"\"\"\n            Stream flows to file as they arrive. Prefix path with + to append.\n            The full path can use python strftime() formating, missing\n            directories are created as needed. A new file is opened every time\n            the formatted string changes.\n            \"\"\",\n        )\n        loader.add_option(\n            \"save_stream_filter\",\n            Optional[str],\n            None,\n            \"Filter which flows are written to file.\",\n        )\n\n    def configure(self, updated):\n        if \"save_stream_filter\" in updated:\n            if ctx.options.save_stream_filter:\n                try:\n                    self.filt = flowfilter.parse(ctx.options.save_stream_filter)\n                except ValueError as e:\n                    raise exceptions.OptionsError(str(e)) from e\n            else:\n                self.filt = None\n        if \"save_stream_file\" in updated or \"save_stream_filter\" in updated:\n            if ctx.options.save_stream_file:\n                try:\n                    self.maybe_rotate_to_new_file()\n                except OSError as e:\n                    raise exceptions.OptionsError(str(e)) from e\n                assert self.stream\n                self.stream.flt = self.filt\n            else:\n                self.done()\n\n    def maybe_rotate_to_new_file(self) -> None:\n        path = datetime.today().strftime(_path(ctx.options.save_stream_file))\n        if self.current_path == path:\n            return\n\n        if self.stream:\n            self.stream.fo.close()\n            self.stream = None\n\n        new_log_file = Path(path)\n        new_log_file.parent.mkdir(parents=True, exist_ok=True)\n\n        f = new_log_file.open(_mode(ctx.options.save_stream_file))\n        self.stream = io.FilteredFlowWriter(f, self.filt)\n        self.current_path = path\n\n    def save_flow(self, flow: flow.Flow) -> None:\n        \"\"\"\n        Write the flow to the stream, but first check if we need to rotate to a new file.\n        \"\"\"\n        if not self.stream:\n            return\n        try:\n            self.maybe_rotate_to_new_file()\n            self.stream.add(flow)\n        except OSError as e:\n            # If we somehow fail to write flows to a logfile, we really want to crash visibly\n            # instead of letting traffic through unrecorded.\n            # No normal logging here, that would not be triggered anymore.\n            sys.stderr.write(f\"Error while writing to {self.current_path}: {e}\")\n            sys.exit(1)\n        else:\n            self.active_flows.discard(flow)\n\n    def done(self) -> None:\n        if self.stream:\n            for f in self.active_flows:\n                self.stream.add(f)\n            self.active_flows.clear()\n\n            self.current_path = None\n            self.stream.fo.close()\n            self.stream = None\n\n    @command.command(\"save.file\")\n    def save(self, flows: Sequence[flow.Flow], path: mitmproxy.types.Path) -> None:\n        \"\"\"\n        Save flows to a file. If the path starts with a +, flows are\n        appended to the file, otherwise it is over-written.\n        \"\"\"\n        try:\n            with open(_path(path), _mode(path)) as f:\n                stream = io.FlowWriter(f)\n                for i in flows:\n                    stream.add(i)\n        except OSError as e:\n            raise exceptions.CommandError(e) from e\n        if path.endswith(\".har\") or path.endswith(\".zhar\"):  # pragma: no cover\n            logging.log(\n                ALERT,\n                f\"Saved as mitmproxy dump file. To save HAR files, use the `save.har` command.\",\n            )\n        else:\n            logging.log(ALERT, f\"Saved {len(flows)} flows.\")\n\n    def tcp_start(self, flow: tcp.TCPFlow):\n        if self.stream:\n            self.active_flows.add(flow)\n\n    def tcp_end(self, flow: tcp.TCPFlow):\n        self.save_flow(flow)\n\n    def tcp_error(self, flow: tcp.TCPFlow):\n        self.tcp_end(flow)\n\n    def udp_start(self, flow: udp.UDPFlow):\n        if self.stream:\n            self.active_flows.add(flow)\n\n    def udp_end(self, flow: udp.UDPFlow):\n        self.save_flow(flow)\n\n    def udp_error(self, flow: udp.UDPFlow):\n        self.udp_end(flow)\n\n    def websocket_end(self, flow: http.HTTPFlow):\n        self.save_flow(flow)\n\n    def request(self, flow: http.HTTPFlow):\n        if self.stream:\n            self.active_flows.add(flow)\n\n    def response(self, flow: http.HTTPFlow):\n        # websocket flows will receive a websocket_end,\n        # we don't want to persist them here already\n        if flow.websocket is None:\n            self.save_flow(flow)\n\n    def error(self, flow: http.HTTPFlow):\n        self.response(flow)\n\n    def dns_request(self, flow: dns.DNSFlow):\n        if self.stream:\n            self.active_flows.add(flow)\n\n    def dns_response(self, flow: dns.DNSFlow):\n        self.save_flow(flow)\n\n    def dns_error(self, flow: dns.DNSFlow):\n        self.save_flow(flow)\n", "mitmproxy/addons/termlog.py": "from __future__ import annotations\n\nimport asyncio\nimport logging\nimport sys\nfrom typing import IO\n\nfrom mitmproxy import ctx\nfrom mitmproxy import log\nfrom mitmproxy.utils import vt_codes\n\n\nclass TermLog:\n    _teardown_task: asyncio.Task | None = None\n\n    def __init__(self, out: IO[str] | None = None):\n        self.logger = TermLogHandler(out)\n        self.logger.install()\n\n    def load(self, loader):\n        loader.add_option(\n            \"termlog_verbosity\", str, \"info\", \"Log verbosity.\", choices=log.LogLevels\n        )\n        self.logger.setLevel(logging.INFO)\n\n    def configure(self, updated):\n        if \"termlog_verbosity\" in updated:\n            self.logger.setLevel(ctx.options.termlog_verbosity.upper())\n\n    def uninstall(self) -> None:\n        # uninstall the log dumper.\n        # This happens at the very very end after done() is completed,\n        # because we don't want to uninstall while other addons are still logging.\n        self.logger.uninstall()\n\n\nclass TermLogHandler(log.MitmLogHandler):\n    def __init__(self, out: IO[str] | None = None):\n        super().__init__()\n        self.file: IO[str] = out or sys.stdout\n        self.has_vt_codes = vt_codes.ensure_supported(self.file)\n        self.formatter = log.MitmFormatter(self.has_vt_codes)\n\n    def emit(self, record: logging.LogRecord) -> None:\n        try:\n            print(self.format(record), file=self.file)\n        except OSError:\n            # We cannot print, exit immediately.\n            # See https://github.com/mitmproxy/mitmproxy/issues/4669\n            sys.exit(1)\n", "mitmproxy/addons/block.py": "import ipaddress\nimport logging\n\nfrom mitmproxy import ctx\n\n\nclass Block:\n    def load(self, loader):\n        loader.add_option(\n            \"block_global\",\n            bool,\n            True,\n            \"\"\"\n            Block connections from public IP addresses.\n            \"\"\",\n        )\n        loader.add_option(\n            \"block_private\",\n            bool,\n            False,\n            \"\"\"\n            Block connections from local (private) IP addresses.\n            This option does not affect loopback addresses (connections from the local machine),\n            which are always permitted.\n            \"\"\",\n        )\n\n    def client_connected(self, client):\n        parts = client.peername[0].rsplit(\"%\", 1)\n        address = ipaddress.ip_address(parts[0])\n        if isinstance(address, ipaddress.IPv6Address):\n            address = address.ipv4_mapped or address\n\n        if address.is_loopback:\n            return\n\n        if ctx.options.block_private and address.is_private:\n            logging.warning(\n                f\"Client connection from {client.peername[0]} killed by block_private option.\"\n            )\n            client.error = \"Connection killed by block_private.\"\n\n        if ctx.options.block_global and address.is_global:\n            logging.warning(\n                f\"Client connection from {client.peername[0]} killed by block_global option.\"\n            )\n            client.error = \"Connection killed by block_global.\"\n", "mitmproxy/addons/asgiapp.py": "import asyncio\nimport logging\nimport urllib.parse\n\nimport asgiref.compatibility\nimport asgiref.wsgi\n\nfrom mitmproxy import ctx\nfrom mitmproxy import http\n\nlogger = logging.getLogger(__name__)\n\n\nclass ASGIApp:\n    \"\"\"\n    An addon that hosts an ASGI/WSGI HTTP app within mitmproxy, at a specified hostname and port.\n\n    Some important caveats:\n        - This implementation will block and wait until the entire HTTP response is completed before sending out data.\n        - It currently only implements the HTTP protocol (Lifespan and WebSocket are unimplemented).\n    \"\"\"\n\n    def __init__(self, asgi_app, host: str, port: int | None):\n        asgi_app = asgiref.compatibility.guarantee_single_callable(asgi_app)\n        self.asgi_app, self.host, self.port = asgi_app, host, port\n\n    @property\n    def name(self) -> str:\n        return f\"asgiapp:{self.host}:{self.port}\"\n\n    def should_serve(self, flow: http.HTTPFlow) -> bool:\n        return bool(\n            flow.request.pretty_host == self.host\n            and (self.port is None or flow.request.port == self.port)\n            and flow.live\n            and not flow.error\n            and not flow.response\n        )\n\n    async def request(self, flow: http.HTTPFlow) -> None:\n        if self.should_serve(flow):\n            await serve(self.asgi_app, flow)\n\n\nclass WSGIApp(ASGIApp):\n    def __init__(self, wsgi_app, host: str, port: int | None):\n        asgi_app = asgiref.wsgi.WsgiToAsgi(wsgi_app)\n        super().__init__(asgi_app, host, port)\n\n\nHTTP_VERSION_MAP = {\n    \"HTTP/1.0\": \"1.0\",\n    \"HTTP/1.1\": \"1.1\",\n    \"HTTP/2.0\": \"2\",\n}\n\n\ndef make_scope(flow: http.HTTPFlow) -> dict:\n    # %3F is a quoted question mark\n    quoted_path = urllib.parse.quote_from_bytes(flow.request.data.path).split(\n        \"%3F\", maxsplit=1\n    )\n\n    # (Unicode string) \u2013 HTTP request target excluding any query string, with percent-encoded\n    # sequences and UTF-8 byte sequences decoded into characters.\n    path = quoted_path[0]\n\n    # (byte string) \u2013 URL portion after the ?, percent-encoded.\n    query_string: bytes\n    if len(quoted_path) > 1:\n        query_string = urllib.parse.unquote(quoted_path[1]).encode()\n    else:\n        query_string = b\"\"\n\n    return {\n        \"type\": \"http\",\n        \"asgi\": {\n            \"version\": \"3.0\",\n            \"spec_version\": \"2.1\",\n        },\n        \"http_version\": HTTP_VERSION_MAP.get(flow.request.http_version, \"1.1\"),\n        \"method\": flow.request.method,\n        \"scheme\": flow.request.scheme.upper(),\n        \"path\": path,\n        \"raw_path\": flow.request.path,\n        \"query_string\": query_string,\n        \"headers\": [\n            (name.lower(), value) for (name, value) in flow.request.headers.fields\n        ],\n        \"client\": flow.client_conn.peername,\n        \"extensions\": {\n            \"mitmproxy.master\": ctx.master,\n        },\n    }\n\n\nasync def serve(app, flow: http.HTTPFlow):\n    \"\"\"\n    Serves app on flow.\n    \"\"\"\n\n    scope = make_scope(flow)\n    done = asyncio.Event()\n    received_body = False\n    sent_response = False\n\n    async def receive():\n        nonlocal received_body\n        if not received_body:\n            received_body = True\n            return {\n                \"type\": \"http.request\",\n                \"body\": flow.request.raw_content,\n            }\n        else:  # pragma: no cover\n            # We really don't expect this to be called a second time, but what to do?\n            # We just wait until the request is done before we continue here with sending a disconnect.\n            await done.wait()\n            return {\"type\": \"http.disconnect\"}\n\n    async def send(event):\n        if event[\"type\"] == \"http.response.start\":\n            flow.response = http.Response.make(\n                event[\"status\"], b\"\", event.get(\"headers\", [])\n            )\n            flow.response.decode()\n        elif event[\"type\"] == \"http.response.body\":\n            assert flow.response\n            flow.response.content += event.get(\"body\", b\"\")\n            if not event.get(\"more_body\", False):\n                nonlocal sent_response\n                sent_response = True\n        else:\n            raise AssertionError(f\"Unexpected event: {event['type']}\")\n\n    try:\n        await app(scope, receive, send)\n        if not sent_response:\n            raise RuntimeError(f\"no response sent.\")\n    except Exception as e:\n        logger.exception(f\"Error in asgi app: {e}\")\n        flow.response = http.Response.make(500, b\"ASGI Error.\")\n    finally:\n        done.set()\n", "mitmproxy/addons/browser.py": "import logging\nimport shutil\nimport subprocess\nimport tempfile\n\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy.log import ALERT\n\n\ndef get_chrome_executable() -> str | None:\n    for browser in (\n        \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\",\n        # https://stackoverflow.com/questions/40674914/google-chrome-path-in-windows-10\n        r\"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\",\n        r\"C:\\Program Files (x86)\\Google\\Application\\chrome.exe\",\n        # Linux binary names from Python's webbrowser module.\n        \"google-chrome\",\n        \"google-chrome-stable\",\n        \"chrome\",\n        \"chromium\",\n        \"chromium-browser\",\n        \"google-chrome-unstable\",\n    ):\n        if shutil.which(browser):\n            return browser\n\n    return None\n\n\ndef get_chrome_flatpak() -> str | None:\n    if shutil.which(\"flatpak\"):\n        for browser in (\n            \"com.google.Chrome\",\n            \"org.chromium.Chromium\",\n            \"com.github.Eloston.UngoogledChromium\",\n            \"com.google.ChromeDev\",\n        ):\n            if (\n                subprocess.run(\n                    [\"flatpak\", \"info\", browser],\n                    stdout=subprocess.DEVNULL,\n                    stderr=subprocess.DEVNULL,\n                ).returncode\n                == 0\n            ):\n                return browser\n\n    return None\n\n\ndef get_browser_cmd() -> list[str] | None:\n    if browser := get_chrome_executable():\n        return [browser]\n    elif browser := get_chrome_flatpak():\n        return [\"flatpak\", \"run\", \"-p\", browser]\n\n    return None\n\n\nclass Browser:\n    browser: list[subprocess.Popen] = []\n    tdir: list[tempfile.TemporaryDirectory] = []\n\n    @command.command(\"browser.start\")\n    def start(self) -> None:\n        \"\"\"\n        Start an isolated instance of Chrome that points to the currently\n        running proxy.\n        \"\"\"\n        if len(self.browser) > 0:\n            logging.log(ALERT, \"Starting additional browser\")\n\n        cmd = get_browser_cmd()\n        if not cmd:\n            logging.log(\n                ALERT, \"Your platform is not supported yet - please submit a patch.\"\n            )\n            return\n\n        tdir = tempfile.TemporaryDirectory()\n        self.tdir.append(tdir)\n        self.browser.append(\n            subprocess.Popen(\n                [\n                    *cmd,\n                    \"--user-data-dir=%s\" % str(tdir.name),\n                    \"--proxy-server={}:{}\".format(\n                        ctx.options.listen_host or \"127.0.0.1\",\n                        ctx.options.listen_port or \"8080\",\n                    ),\n                    \"--disable-fre\",\n                    \"--no-default-browser-check\",\n                    \"--no-first-run\",\n                    \"--disable-extensions\",\n                    \"about:blank\",\n                ],\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n            )\n        )\n\n    def done(self):\n        for browser in self.browser:\n            browser.kill()\n        for tdir in self.tdir:\n            tdir.cleanup()\n        self.browser = []\n        self.tdir = []\n", "mitmproxy/addons/eventstore.py": "import asyncio\nimport collections\nimport logging\nfrom collections.abc import Callable\n\nfrom mitmproxy import command\nfrom mitmproxy import log\nfrom mitmproxy.log import LogEntry\nfrom mitmproxy.utils import signals\n\n\nclass EventStore:\n    def __init__(self, size: int = 10000) -> None:\n        self.data: collections.deque[LogEntry] = collections.deque(maxlen=size)\n        self.sig_add = signals.SyncSignal(lambda entry: None)\n        self.sig_refresh = signals.SyncSignal(lambda: None)\n\n        self.logger = CallbackLogger(self._add_log)\n        self.logger.install()\n\n    def done(self):\n        self.logger.uninstall()\n\n    def _add_log(self, entry: LogEntry) -> None:\n        self.data.append(entry)\n        self.sig_add.send(entry)\n\n    @property\n    def size(self) -> int | None:\n        return self.data.maxlen\n\n    @command.command(\"eventstore.clear\")\n    def clear(self) -> None:\n        \"\"\"\n        Clear the event log.\n        \"\"\"\n        self.data.clear()\n        self.sig_refresh.send()\n\n\nclass CallbackLogger(log.MitmLogHandler):\n    def __init__(\n        self,\n        callback: Callable[[LogEntry], None],\n    ):\n        super().__init__()\n        self.callback = callback\n        self.event_loop = asyncio.get_running_loop()\n        self.formatter = log.MitmFormatter(colorize=False)\n\n    def emit(self, record: logging.LogRecord) -> None:\n        entry = LogEntry(\n            msg=self.format(record),\n            level=log.LOGGING_LEVELS_TO_LOGENTRY.get(record.levelno, \"error\"),\n        )\n        self.event_loop.call_soon_threadsafe(self.callback, entry)\n", "mitmproxy/addons/blocklist.py": "from collections.abc import Sequence\nfrom typing import NamedTuple\n\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy import version\nfrom mitmproxy.net.http.status_codes import NO_RESPONSE\nfrom mitmproxy.net.http.status_codes import RESPONSES\n\n\nclass BlockSpec(NamedTuple):\n    matches: flowfilter.TFilter\n    status_code: int\n\n\ndef parse_spec(option: str) -> BlockSpec:\n    \"\"\"\n    Parses strings in the following format, enforces number of segments:\n\n        /flow-filter/status\n\n    \"\"\"\n    sep, rem = option[0], option[1:]\n\n    parts = rem.lower().split(sep, 2)\n    if len(parts) != 2:\n        raise ValueError(\"Invalid number of parameters (2 are expected)\")\n    flow_patt, status = parts\n    try:\n        status_code = int(status)\n    except ValueError:\n        raise ValueError(f\"Invalid HTTP status code: {status}\")\n    flow_filter = flowfilter.parse(flow_patt)\n    if not RESPONSES.get(status_code):\n        raise ValueError(f\"Invalid HTTP status code: {status}\")\n\n    return BlockSpec(matches=flow_filter, status_code=status_code)\n\n\nclass BlockList:\n    def __init__(self) -> None:\n        self.items: list[BlockSpec] = []\n\n    def load(self, loader):\n        loader.add_option(\n            \"block_list\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Block matching requests and return an empty response with the specified HTTP status.\n            Option syntax is \"/flow-filter/status-code\", where flow-filter describes\n            which requests this rule should be applied to and status-code is the HTTP status code to return for\n            blocked requests. The separator (\"/\" in the example) can be any character.\n            Setting a non-standard status code of 444 will close the connection without sending a response.\n            \"\"\",\n        )\n\n    def configure(self, updated):\n        if \"block_list\" in updated:\n            self.items = []\n            for option in ctx.options.block_list:\n                try:\n                    spec = parse_spec(option)\n                except ValueError as e:\n                    raise exceptions.OptionsError(\n                        f\"Cannot parse block_list option {option}: {e}\"\n                    ) from e\n                self.items.append(spec)\n\n    def request(self, flow: http.HTTPFlow) -> None:\n        if flow.response or flow.error or not flow.live:\n            return\n\n        for spec in self.items:\n            if spec.matches(flow):\n                flow.metadata[\"blocklisted\"] = True\n                if spec.status_code == NO_RESPONSE:\n                    flow.kill()\n                else:\n                    flow.response = http.Response.make(\n                        spec.status_code, headers={\"Server\": version.MITMPROXY}\n                    )\n", "mitmproxy/addons/view.py": "\"\"\"\nThe View:\n\n- Keeps track of a store of flows\n- Maintains a filtered, ordered view onto that list of flows\n- Exposes a number of signals so the view can be monitored\n- Tracks focus within the view\n- Exposes a settings store for flows that automatically expires if the flow is\n  removed from the store.\n\"\"\"\n\nimport collections\nimport logging\nimport re\nfrom collections.abc import Iterator\nfrom collections.abc import MutableMapping\nfrom collections.abc import Sequence\nfrom typing import Any\nfrom typing import Optional\n\nimport sortedcontainers\n\nimport mitmproxy.flow\nfrom mitmproxy import command\nfrom mitmproxy import connection\nfrom mitmproxy import ctx\nfrom mitmproxy import dns\nfrom mitmproxy import exceptions\nfrom mitmproxy import flowfilter\nfrom mitmproxy import hooks\nfrom mitmproxy import http\nfrom mitmproxy import io\nfrom mitmproxy import tcp\nfrom mitmproxy import udp\nfrom mitmproxy.log import ALERT\nfrom mitmproxy.utils import human\nfrom mitmproxy.utils import signals\n\n# The underlying sorted list implementation expects the sort key to be stable\n# for the lifetime of the object. However, if we sort by size, for instance,\n# the sort order changes as the flow progresses through its lifecycle. We\n# address this through two means:\n#\n# - Let order keys cache the sort value by flow ID.\n#\n# - Add a facility to refresh items in the list by removing and re-adding them\n# when they are updated.\n\n\nclass _OrderKey:\n    def __init__(self, view):\n        self.view = view\n\n    def generate(self, f: mitmproxy.flow.Flow) -> Any:  # pragma: no cover\n        pass\n\n    def refresh(self, f):\n        k = self._key()\n        old = self.view.settings[f][k]\n        new = self.generate(f)\n        if old != new:\n            self.view._view.remove(f)\n            self.view.settings[f][k] = new\n            self.view._view.add(f)\n            self.view.sig_view_refresh.send()\n\n    def _key(self):\n        return \"_order_%s\" % id(self)\n\n    def __call__(self, f):\n        if f.id in self.view._store:\n            k = self._key()\n            s = self.view.settings[f]\n            if k in s:\n                return s[k]\n            val = self.generate(f)\n            s[k] = val\n            return val\n        else:\n            return self.generate(f)\n\n\nclass OrderRequestStart(_OrderKey):\n    def generate(self, f: mitmproxy.flow.Flow) -> float:\n        return f.timestamp_created\n\n\nclass OrderRequestMethod(_OrderKey):\n    def generate(self, f: mitmproxy.flow.Flow) -> str:\n        if isinstance(f, http.HTTPFlow):\n            return f.request.method\n        elif isinstance(f, (tcp.TCPFlow, udp.UDPFlow)):\n            return f.type.upper()\n        elif isinstance(f, dns.DNSFlow):\n            return dns.op_codes.to_str(f.request.op_code)\n        else:\n            raise NotImplementedError()\n\n\nclass OrderRequestURL(_OrderKey):\n    def generate(self, f: mitmproxy.flow.Flow) -> str:\n        if isinstance(f, http.HTTPFlow):\n            return f.request.url\n        elif isinstance(f, (tcp.TCPFlow, udp.UDPFlow)):\n            return human.format_address(f.server_conn.address)\n        elif isinstance(f, dns.DNSFlow):\n            return f.request.questions[0].name if f.request.questions else \"\"\n        else:\n            raise NotImplementedError()\n\n\nclass OrderKeySize(_OrderKey):\n    def generate(self, f: mitmproxy.flow.Flow) -> int:\n        if isinstance(f, http.HTTPFlow):\n            size = 0\n            if f.request.raw_content:\n                size += len(f.request.raw_content)\n            if f.response and f.response.raw_content:\n                size += len(f.response.raw_content)\n            return size\n        elif isinstance(f, (tcp.TCPFlow, udp.UDPFlow)):\n            size = 0\n            for message in f.messages:\n                size += len(message.content)\n            return size\n        elif isinstance(f, dns.DNSFlow):\n            return f.response.size if f.response else 0\n        else:\n            raise NotImplementedError()\n\n\norders = [\n    (\"t\", \"time\"),\n    (\"m\", \"method\"),\n    (\"u\", \"url\"),\n    (\"z\", \"size\"),\n]\n\n\ndef _signal_with_flow(flow: mitmproxy.flow.Flow) -> None: ...\n\n\ndef _sig_view_remove(flow: mitmproxy.flow.Flow, index: int) -> None: ...\n\n\nclass View(collections.abc.Sequence):\n    def __init__(self) -> None:\n        super().__init__()\n        self._store: collections.OrderedDict[str, mitmproxy.flow.Flow] = (\n            collections.OrderedDict()\n        )\n        self.filter = flowfilter.match_all\n        # Should we show only marked flows?\n        self.show_marked = False\n\n        self.default_order = OrderRequestStart(self)\n        self.orders = dict(\n            time=OrderRequestStart(self),\n            method=OrderRequestMethod(self),\n            url=OrderRequestURL(self),\n            size=OrderKeySize(self),\n        )\n        self.order_key: _OrderKey = self.default_order\n        self.order_reversed = False\n        self.focus_follow = False\n\n        self._view = sortedcontainers.SortedListWithKey(key=self.order_key)\n\n        # The sig_view* signals broadcast events that affect the view. That is,\n        # an update to a flow in the store but not in the view does not trigger\n        # a signal. All signals are called after the view has been updated.\n        self.sig_view_update = signals.SyncSignal(_signal_with_flow)\n        self.sig_view_add = signals.SyncSignal(_signal_with_flow)\n        self.sig_view_remove = signals.SyncSignal(_sig_view_remove)\n        # Signals that the view should be refreshed completely\n        self.sig_view_refresh = signals.SyncSignal(lambda: None)\n\n        # The sig_store* signals broadcast events that affect the underlying\n        # store. If a flow is removed from just the view, sig_view_remove is\n        # triggered. If it is removed from the store while it is also in the\n        # view, both sig_store_remove and sig_view_remove are triggered.\n        self.sig_store_remove = signals.SyncSignal(_signal_with_flow)\n        # Signals that the store should be refreshed completely\n        self.sig_store_refresh = signals.SyncSignal(lambda: None)\n\n        self.focus = Focus(self)\n        self.settings = Settings(self)\n\n    def load(self, loader):\n        loader.add_option(\n            \"view_filter\", Optional[str], None, \"Limit the view to matching flows.\"\n        )\n        loader.add_option(\n            \"view_order\",\n            str,\n            \"time\",\n            \"Flow sort order.\",\n            choices=list(map(lambda c: c[1], orders)),\n        )\n        loader.add_option(\n            \"view_order_reversed\", bool, False, \"Reverse the sorting order.\"\n        )\n        loader.add_option(\n            \"console_focus_follow\", bool, False, \"Focus follows new flows.\"\n        )\n\n    def store_count(self):\n        return len(self._store)\n\n    def _rev(self, idx: int) -> int:\n        \"\"\"\n        Reverses an index, if needed\n        \"\"\"\n        if self.order_reversed:\n            if idx < 0:\n                idx = -idx - 1\n            else:\n                idx = len(self._view) - idx - 1\n                if idx < 0:\n                    raise IndexError\n        return idx\n\n    def __len__(self):\n        return len(self._view)\n\n    def __getitem__(self, offset) -> Any:\n        return self._view[self._rev(offset)]\n\n    # Reflect some methods to the efficient underlying implementation\n\n    def _bisect(self, f: mitmproxy.flow.Flow) -> int:\n        v = self._view.bisect_right(f)\n        return self._rev(v - 1) + 1\n\n    def index(\n        self, f: mitmproxy.flow.Flow, start: int = 0, stop: int | None = None\n    ) -> int:\n        return self._rev(self._view.index(f, start, stop))\n\n    def __contains__(self, f: Any) -> bool:\n        return self._view.__contains__(f)\n\n    def _order_key_name(self):\n        return \"_order_%s\" % id(self.order_key)\n\n    def _base_add(self, f):\n        self.settings[f][self._order_key_name()] = self.order_key(f)\n        self._view.add(f)\n\n    def _refilter(self):\n        self._view.clear()\n        for i in self._store.values():\n            if self.show_marked and not i.marked:\n                continue\n            if self.filter(i):\n                self._base_add(i)\n        self.sig_view_refresh.send()\n\n    \"\"\" View API \"\"\"\n\n    # Focus\n    @command.command(\"view.focus.go\")\n    def go(self, offset: int) -> None:\n        \"\"\"\n        Go to a specified offset. Positive offests are from the beginning of\n        the view, negative from the end of the view, so that 0 is the first\n        flow, -1 is the last flow.\n        \"\"\"\n        if len(self) == 0:\n            return\n        if offset < 0:\n            offset = len(self) + offset\n        if offset < 0:\n            offset = 0\n        if offset > len(self) - 1:\n            offset = len(self) - 1\n        self.focus.flow = self[offset]\n\n    @command.command(\"view.focus.next\")\n    def focus_next(self) -> None:\n        \"\"\"\n        Set focus to the next flow.\n        \"\"\"\n        if self.focus.index is not None:\n            idx = self.focus.index + 1\n            if self.inbounds(idx):\n                self.focus.flow = self[idx]\n        else:\n            pass\n\n    @command.command(\"view.focus.prev\")\n    def focus_prev(self) -> None:\n        \"\"\"\n        Set focus to the previous flow.\n        \"\"\"\n        if self.focus.index is not None:\n            idx = self.focus.index - 1\n            if self.inbounds(idx):\n                self.focus.flow = self[idx]\n        else:\n            pass\n\n    # Order\n    @command.command(\"view.order.options\")\n    def order_options(self) -> Sequence[str]:\n        \"\"\"\n        Choices supported by the view_order option.\n        \"\"\"\n        return list(sorted(self.orders.keys()))\n\n    @command.command(\"view.order.reverse\")\n    def set_reversed(self, boolean: bool) -> None:\n        self.order_reversed = boolean\n        self.sig_view_refresh.send()\n\n    @command.command(\"view.order.set\")\n    def set_order(self, order_key: str) -> None:\n        \"\"\"\n        Sets the current view order.\n        \"\"\"\n        if order_key not in self.orders:\n            raise exceptions.CommandError(\"Unknown flow order: %s\" % order_key)\n        key = self.orders[order_key]\n        self.order_key = key\n        newview = sortedcontainers.SortedListWithKey(key=key)\n        newview.update(self._view)\n        self._view = newview\n\n    @command.command(\"view.order\")\n    def get_order(self) -> str:\n        \"\"\"\n        Returns the current view order.\n        \"\"\"\n        order = \"\"\n        for k in self.orders.keys():\n            if self.order_key == self.orders[k]:\n                order = k\n        return order\n\n    # Filter\n    @command.command(\"view.filter.set\")\n    def set_filter_cmd(self, filter_expr: str) -> None:\n        \"\"\"\n        Sets the current view filter.\n        \"\"\"\n        filt = None\n        if filter_expr:\n            try:\n                filt = flowfilter.parse(filter_expr)\n            except ValueError as e:\n                raise exceptions.CommandError(str(e)) from e\n        self.set_filter(filt)\n\n    def set_filter(self, flt: flowfilter.TFilter | None):\n        self.filter = flt or flowfilter.match_all\n        self._refilter()\n\n    # View Updates\n    @command.command(\"view.clear\")\n    def clear(self) -> None:\n        \"\"\"\n        Clears both the store and view.\n        \"\"\"\n        self._store.clear()\n        self._view.clear()\n        self.sig_view_refresh.send()\n        self.sig_store_refresh.send()\n\n    @command.command(\"view.clear_unmarked\")\n    def clear_not_marked(self) -> None:\n        \"\"\"\n        Clears only the unmarked flows.\n        \"\"\"\n        for flow in self._store.copy().values():\n            if not flow.marked:\n                self._store.pop(flow.id)\n\n        self._refilter()\n        self.sig_store_refresh.send()\n\n    # View Settings\n    @command.command(\"view.settings.getval\")\n    def getvalue(self, flow: mitmproxy.flow.Flow, key: str, default: str) -> str:\n        \"\"\"\n        Get a value from the settings store for the specified flow.\n        \"\"\"\n        return self.settings[flow].get(key, default)\n\n    @command.command(\"view.settings.setval.toggle\")\n    def setvalue_toggle(self, flows: Sequence[mitmproxy.flow.Flow], key: str) -> None:\n        \"\"\"\n        Toggle a boolean value in the settings store, setting the value to\n        the string \"true\" or \"false\".\n        \"\"\"\n        updated = []\n        for f in flows:\n            current = self.settings[f].get(\"key\", \"false\")\n            self.settings[f][key] = \"false\" if current == \"true\" else \"true\"\n            updated.append(f)\n        ctx.master.addons.trigger(hooks.UpdateHook(updated))\n\n    @command.command(\"view.settings.setval\")\n    def setvalue(\n        self, flows: Sequence[mitmproxy.flow.Flow], key: str, value: str\n    ) -> None:\n        \"\"\"\n        Set a value in the settings store for the specified flows.\n        \"\"\"\n        updated = []\n        for f in flows:\n            self.settings[f][key] = value\n            updated.append(f)\n        ctx.master.addons.trigger(hooks.UpdateHook(updated))\n\n    # Flows\n    @command.command(\"view.flows.duplicate\")\n    def duplicate(self, flows: Sequence[mitmproxy.flow.Flow]) -> None:\n        \"\"\"\n        Duplicates the specified flows, and sets the focus to the first\n        duplicate.\n        \"\"\"\n        dups = [f.copy() for f in flows]\n        if dups:\n            self.add(dups)\n            self.focus.flow = dups[0]\n            logging.log(ALERT, \"Duplicated %s flows\" % len(dups))\n\n    @command.command(\"view.flows.remove\")\n    def remove(self, flows: Sequence[mitmproxy.flow.Flow]) -> None:\n        \"\"\"\n        Removes the flow from the underlying store and the view.\n        \"\"\"\n        for f in flows:\n            if f.id in self._store:\n                if f.killable:\n                    f.kill()\n                if f in self._view:\n                    # We manually pass the index here because multiple flows may have the same\n                    # sorting key, and we cannot reconstruct the index from that.\n                    idx = self._view.index(f)\n                    self._view.remove(f)\n                    self.sig_view_remove.send(flow=f, index=idx)\n                del self._store[f.id]\n                self.sig_store_remove.send(flow=f)\n        if len(flows) > 1:\n            logging.log(ALERT, \"Removed %s flows\" % len(flows))\n\n    @command.command(\"view.flows.resolve\")\n    def resolve(self, flow_spec: str) -> Sequence[mitmproxy.flow.Flow]:\n        \"\"\"\n        Resolve a flow list specification to an actual list of flows.\n        \"\"\"\n        if flow_spec == \"@all\":\n            return [i for i in self._store.values()]\n        if flow_spec == \"@focus\":\n            return [self.focus.flow] if self.focus.flow else []\n        elif flow_spec == \"@shown\":\n            return [i for i in self]\n        elif flow_spec == \"@hidden\":\n            return [i for i in self._store.values() if i not in self._view]\n        elif flow_spec == \"@marked\":\n            return [i for i in self._store.values() if i.marked]\n        elif flow_spec == \"@unmarked\":\n            return [i for i in self._store.values() if not i.marked]\n        elif re.match(r\"@[0-9a-f\\-,]{36,}\", flow_spec):\n            ids = flow_spec[1:].split(\",\")\n            return [i for i in self._store.values() if i.id in ids]\n        else:\n            try:\n                filt = flowfilter.parse(flow_spec)\n            except ValueError as e:\n                raise exceptions.CommandError(str(e)) from e\n            return [i for i in self._store.values() if filt(i)]\n\n    @command.command(\"view.flows.create\")\n    def create(self, method: str, url: str) -> None:\n        try:\n            req = http.Request.make(method.upper(), url)\n        except ValueError as e:\n            raise exceptions.CommandError(\"Invalid URL: %s\" % e)\n\n        c = connection.Client(\n            peername=(\"\", 0),\n            sockname=(\"\", 0),\n            timestamp_start=req.timestamp_start - 0.0001,\n        )\n        s = connection.Server(address=(req.host, req.port))\n\n        f = http.HTTPFlow(c, s)\n        f.request = req\n        f.request.headers[\"Host\"] = req.host\n        self.add([f])\n\n    @command.command(\"view.flows.load\")\n    def load_file(self, path: mitmproxy.types.Path) -> None:\n        \"\"\"\n        Load flows into the view, without processing them with addons.\n        \"\"\"\n        try:\n            with open(path, \"rb\") as f:\n                for i in io.FlowReader(f).stream():\n                    # Do this to get a new ID, so we can load the same file N times and\n                    # get new flows each time. It would be more efficient to just have a\n                    # .newid() method or something.\n                    self.add([i.copy()])\n        except OSError as e:\n            logging.error(e.strerror)\n        except exceptions.FlowReadException as e:\n            logging.error(str(e))\n\n    def add(self, flows: Sequence[mitmproxy.flow.Flow]) -> None:\n        \"\"\"\n        Adds a flow to the state. If the flow already exists, it is\n        ignored.\n        \"\"\"\n        for f in flows:\n            if f.id not in self._store:\n                self._store[f.id] = f\n                if self.filter(f):\n                    self._base_add(f)\n                    if self.focus_follow:\n                        self.focus.flow = f\n                    self.sig_view_add.send(flow=f)\n\n    def get_by_id(self, flow_id: str) -> mitmproxy.flow.Flow | None:\n        \"\"\"\n        Get flow with the given id from the store.\n        Returns None if the flow is not found.\n        \"\"\"\n        return self._store.get(flow_id)\n\n    # View Properties\n    @command.command(\"view.properties.length\")\n    def get_length(self) -> int:\n        \"\"\"\n        Returns view length.\n        \"\"\"\n        return len(self)\n\n    @command.command(\"view.properties.marked\")\n    def get_marked(self) -> bool:\n        \"\"\"\n        Returns true if view is in marked mode.\n        \"\"\"\n        return self.show_marked\n\n    @command.command(\"view.properties.marked.toggle\")\n    def toggle_marked(self) -> None:\n        \"\"\"\n        Toggle whether to show marked views only.\n        \"\"\"\n        self.show_marked = not self.show_marked\n        self._refilter()\n\n    @command.command(\"view.properties.inbounds\")\n    def inbounds(self, index: int) -> bool:\n        \"\"\"\n        Is this 0 <= index < len(self)?\n        \"\"\"\n        return 0 <= index < len(self)\n\n    # Event handlers\n    def configure(self, updated):\n        if \"view_filter\" in updated:\n            filt = None\n            if ctx.options.view_filter:\n                try:\n                    filt = flowfilter.parse(ctx.options.view_filter)\n                except ValueError as e:\n                    raise exceptions.OptionsError(str(e)) from e\n            self.set_filter(filt)\n        if \"view_order\" in updated:\n            if ctx.options.view_order not in self.orders:\n                raise exceptions.OptionsError(\n                    \"Unknown flow order: %s\" % ctx.options.view_order\n                )\n            self.set_order(ctx.options.view_order)\n        if \"view_order_reversed\" in updated:\n            self.set_reversed(ctx.options.view_order_reversed)\n        if \"console_focus_follow\" in updated:\n            self.focus_follow = ctx.options.console_focus_follow\n\n    def requestheaders(self, f):\n        self.add([f])\n\n    def error(self, f):\n        self.update([f])\n\n    def response(self, f):\n        self.update([f])\n\n    def intercept(self, f):\n        self.update([f])\n\n    def resume(self, f):\n        self.update([f])\n\n    def kill(self, f):\n        self.update([f])\n\n    def tcp_start(self, f):\n        self.add([f])\n\n    def tcp_message(self, f):\n        self.update([f])\n\n    def tcp_error(self, f):\n        self.update([f])\n\n    def tcp_end(self, f):\n        self.update([f])\n\n    def udp_start(self, f):\n        self.add([f])\n\n    def udp_message(self, f):\n        self.update([f])\n\n    def udp_error(self, f):\n        self.update([f])\n\n    def udp_end(self, f):\n        self.update([f])\n\n    def dns_request(self, f):\n        self.add([f])\n\n    def dns_response(self, f):\n        self.update([f])\n\n    def dns_error(self, f):\n        self.update([f])\n\n    def update(self, flows: Sequence[mitmproxy.flow.Flow]) -> None:\n        \"\"\"\n        Updates a list of flows. If flow is not in the state, it's ignored.\n        \"\"\"\n        for f in flows:\n            if f.id in self._store:\n                if self.filter(f):\n                    if f not in self._view:\n                        self._base_add(f)\n                        if self.focus_follow:\n                            self.focus.flow = f\n                        self.sig_view_add.send(flow=f)\n                    else:\n                        # This is a tad complicated. The sortedcontainers\n                        # implementation assumes that the order key is stable. If\n                        # it changes mid-way Very Bad Things happen. We detect when\n                        # this happens, and re-fresh the item.\n                        self.order_key.refresh(f)\n                        self.sig_view_update.send(flow=f)\n                else:\n                    try:\n                        idx = self._view.index(f)\n                    except ValueError:\n                        pass  # The value was not in the view\n                    else:\n                        self._view.remove(f)\n                        self.sig_view_remove.send(flow=f, index=idx)\n\n\nclass Focus:\n    \"\"\"\n    Tracks a focus element within a View.\n    \"\"\"\n\n    def __init__(self, v: View) -> None:\n        self.view = v\n        self._flow: mitmproxy.flow.Flow | None = None\n        self.sig_change = signals.SyncSignal(lambda: None)\n        if len(self.view):\n            self.flow = self.view[0]\n        v.sig_view_add.connect(self._sig_view_add)\n        v.sig_view_remove.connect(self._sig_view_remove)\n        v.sig_view_refresh.connect(self._sig_view_refresh)\n\n    @property\n    def flow(self) -> mitmproxy.flow.Flow | None:\n        return self._flow\n\n    @flow.setter\n    def flow(self, f: mitmproxy.flow.Flow | None):\n        if f is not None and f not in self.view:\n            raise ValueError(\"Attempt to set focus to flow not in view\")\n        self._flow = f\n        self.sig_change.send()\n\n    @property\n    def index(self) -> int | None:\n        if self.flow:\n            return self.view.index(self.flow)\n        return None\n\n    @index.setter\n    def index(self, idx):\n        if idx < 0 or idx > len(self.view) - 1:\n            raise ValueError(\"Index out of view bounds\")\n        self.flow = self.view[idx]\n\n    def _nearest(self, f, v):\n        return min(v._bisect(f), len(v) - 1)\n\n    def _sig_view_remove(self, flow, index):\n        if len(self.view) == 0:\n            self.flow = None\n        elif flow is self.flow:\n            self.index = min(index, len(self.view) - 1)\n\n    def _sig_view_refresh(self):\n        if len(self.view) == 0:\n            self.flow = None\n        elif self.flow is None:\n            self.flow = self.view[0]\n        elif self.flow not in self.view:\n            self.flow = self.view[self._nearest(self.flow, self.view)]\n\n    def _sig_view_add(self, flow):\n        # We only have to act if we don't have a focus element\n        if not self.flow:\n            self.flow = flow\n\n\nclass Settings(collections.abc.Mapping):\n    def __init__(self, view: View) -> None:\n        self.view = view\n        self._values: MutableMapping[str, dict] = {}\n        view.sig_store_remove.connect(self._sig_store_remove)\n        view.sig_store_refresh.connect(self._sig_store_refresh)\n\n    def __iter__(self) -> Iterator:\n        return iter(self._values)\n\n    def __len__(self) -> int:\n        return len(self._values)\n\n    def __getitem__(self, f: mitmproxy.flow.Flow) -> dict:\n        if f.id not in self.view._store:\n            raise KeyError\n        return self._values.setdefault(f.id, {})\n\n    def _sig_store_remove(self, flow):\n        if flow.id in self._values:\n            del self._values[flow.id]\n\n    def _sig_store_refresh(self):\n        for fid in list(self._values.keys()):\n            if fid not in self.view._store:\n                del self._values[fid]\n", "mitmproxy/addons/core.py": "import logging\nimport os\nfrom collections.abc import Sequence\n\nimport mitmproxy.types\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import hooks\nfrom mitmproxy import optmanager\nfrom mitmproxy.log import ALERT\nfrom mitmproxy.net.http import status_codes\nfrom mitmproxy.utils import emoji\n\nlogger = logging.getLogger(__name__)\n\nCONF_DIR = \"~/.mitmproxy\"\nLISTEN_PORT = 8080\n\n\nclass Core:\n    def configure(self, updated):\n        opts = ctx.options\n        if opts.add_upstream_certs_to_client_chain and not opts.upstream_cert:\n            raise exceptions.OptionsError(\n                \"add_upstream_certs_to_client_chain requires the upstream_cert option to be enabled.\"\n            )\n        if \"client_certs\" in updated:\n            if opts.client_certs:\n                client_certs = os.path.expanduser(opts.client_certs)\n                if not os.path.exists(client_certs):\n                    raise exceptions.OptionsError(\n                        f\"Client certificate path does not exist: {opts.client_certs}\"\n                    )\n\n    @command.command(\"set\")\n    def set(self, option: str, *value: str) -> None:\n        \"\"\"\n        Set an option. When the value is omitted, booleans are set to true,\n        strings and integers are set to None (if permitted), and sequences\n        are emptied. Boolean values can be true, false or toggle.\n        Multiple values are concatenated with a single space.\n        \"\"\"\n        if value:\n            specs = [f\"{option}={v}\" for v in value]\n        else:\n            specs = [option]\n        try:\n            ctx.options.set(*specs)\n        except exceptions.OptionsError as e:\n            raise exceptions.CommandError(e) from e\n\n    @command.command(\"flow.resume\")\n    def resume(self, flows: Sequence[flow.Flow]) -> None:\n        \"\"\"\n        Resume flows if they are intercepted.\n        \"\"\"\n        intercepted = [i for i in flows if i.intercepted]\n        for f in intercepted:\n            f.resume()\n        ctx.master.addons.trigger(hooks.UpdateHook(intercepted))\n\n    # FIXME: this will become view.mark later\n    @command.command(\"flow.mark\")\n    def mark(self, flows: Sequence[flow.Flow], marker: mitmproxy.types.Marker) -> None:\n        \"\"\"\n        Mark flows.\n        \"\"\"\n        updated = []\n        if marker not in emoji.emoji:\n            raise exceptions.CommandError(f\"invalid marker value\")\n\n        for i in flows:\n            i.marked = marker\n            updated.append(i)\n        ctx.master.addons.trigger(hooks.UpdateHook(updated))\n\n    # FIXME: this will become view.mark.toggle later\n    @command.command(\"flow.mark.toggle\")\n    def mark_toggle(self, flows: Sequence[flow.Flow]) -> None:\n        \"\"\"\n        Toggle mark for flows.\n        \"\"\"\n        for i in flows:\n            if i.marked:\n                i.marked = \"\"\n            else:\n                i.marked = \":default:\"\n        ctx.master.addons.trigger(hooks.UpdateHook(flows))\n\n    @command.command(\"flow.kill\")\n    def kill(self, flows: Sequence[flow.Flow]) -> None:\n        \"\"\"\n        Kill running flows.\n        \"\"\"\n        updated = []\n        for f in flows:\n            if f.killable:\n                f.kill()\n                updated.append(f)\n        logger.log(ALERT, \"Killed %s flows.\" % len(updated))\n        ctx.master.addons.trigger(hooks.UpdateHook(updated))\n\n    # FIXME: this will become view.revert later\n    @command.command(\"flow.revert\")\n    def revert(self, flows: Sequence[flow.Flow]) -> None:\n        \"\"\"\n        Revert flow changes.\n        \"\"\"\n        updated = []\n        for f in flows:\n            if f.modified():\n                f.revert()\n                updated.append(f)\n        logger.log(ALERT, \"Reverted %s flows.\" % len(updated))\n        ctx.master.addons.trigger(hooks.UpdateHook(updated))\n\n    @command.command(\"flow.set.options\")\n    def flow_set_options(self) -> Sequence[str]:\n        return [\n            \"host\",\n            \"status_code\",\n            \"method\",\n            \"path\",\n            \"url\",\n            \"reason\",\n        ]\n\n    @command.command(\"flow.set\")\n    @command.argument(\"attr\", type=mitmproxy.types.Choice(\"flow.set.options\"))\n    def flow_set(self, flows: Sequence[flow.Flow], attr: str, value: str) -> None:\n        \"\"\"\n        Quickly set a number of common values on flows.\n        \"\"\"\n        val: int | str = value\n        if attr == \"status_code\":\n            try:\n                val = int(val)  # type: ignore\n            except ValueError as v:\n                raise exceptions.CommandError(\n                    \"Status code is not an integer: %s\" % val\n                ) from v\n\n        updated = []\n        for f in flows:\n            req = getattr(f, \"request\", None)\n            rupdate = True\n            if req:\n                if attr == \"method\":\n                    req.method = val\n                elif attr == \"host\":\n                    req.host = val\n                elif attr == \"path\":\n                    req.path = val\n                elif attr == \"url\":\n                    try:\n                        req.url = val\n                    except ValueError as e:\n                        raise exceptions.CommandError(\n                            f\"URL {repr(val)} is invalid: {e}\"\n                        ) from e\n                else:\n                    self.rupdate = False\n\n            resp = getattr(f, \"response\", None)\n            supdate = True\n            if resp:\n                if attr == \"status_code\":\n                    resp.status_code = val\n                    if val in status_codes.RESPONSES:\n                        resp.reason = status_codes.RESPONSES[val]  # type: ignore\n                elif attr == \"reason\":\n                    resp.reason = val\n                else:\n                    supdate = False\n\n            if rupdate or supdate:\n                updated.append(f)\n\n        ctx.master.addons.trigger(hooks.UpdateHook(updated))\n        logger.log(ALERT, f\"Set {attr} on  {len(updated)} flows.\")\n\n    @command.command(\"flow.decode\")\n    def decode(self, flows: Sequence[flow.Flow], part: str) -> None:\n        \"\"\"\n        Decode flows.\n        \"\"\"\n        updated = []\n        for f in flows:\n            p = getattr(f, part, None)\n            if p:\n                f.backup()\n                p.decode()\n                updated.append(f)\n        ctx.master.addons.trigger(hooks.UpdateHook(updated))\n        logger.log(ALERT, \"Decoded %s flows.\" % len(updated))\n\n    @command.command(\"flow.encode.toggle\")\n    def encode_toggle(self, flows: Sequence[flow.Flow], part: str) -> None:\n        \"\"\"\n        Toggle flow encoding on and off, using deflate for encoding.\n        \"\"\"\n        updated = []\n        for f in flows:\n            p = getattr(f, part, None)\n            if p:\n                f.backup()\n                current_enc = p.headers.get(\"content-encoding\", \"identity\")\n                if current_enc == \"identity\":\n                    p.encode(\"deflate\")\n                else:\n                    p.decode()\n                updated.append(f)\n        ctx.master.addons.trigger(hooks.UpdateHook(updated))\n        logger.log(ALERT, \"Toggled encoding on %s flows.\" % len(updated))\n\n    @command.command(\"flow.encode\")\n    @command.argument(\"encoding\", type=mitmproxy.types.Choice(\"flow.encode.options\"))\n    def encode(\n        self,\n        flows: Sequence[flow.Flow],\n        part: str,\n        encoding: str,\n    ) -> None:\n        \"\"\"\n        Encode flows with a specified encoding.\n        \"\"\"\n        updated = []\n        for f in flows:\n            p = getattr(f, part, None)\n            if p:\n                current_enc = p.headers.get(\"content-encoding\", \"identity\")\n                if current_enc == \"identity\":\n                    f.backup()\n                    p.encode(encoding)\n                    updated.append(f)\n        ctx.master.addons.trigger(hooks.UpdateHook(updated))\n        logger.log(ALERT, \"Encoded %s flows.\" % len(updated))\n\n    @command.command(\"flow.encode.options\")\n    def encode_options(self) -> Sequence[str]:\n        \"\"\"\n        The possible values for an encoding specification.\n        \"\"\"\n        return [\"gzip\", \"deflate\", \"br\", \"zstd\"]\n\n    @command.command(\"options.load\")\n    def options_load(self, path: mitmproxy.types.Path) -> None:\n        \"\"\"\n        Load options from a file.\n        \"\"\"\n        try:\n            optmanager.load_paths(ctx.options, path)\n        except (OSError, exceptions.OptionsError) as e:\n            raise exceptions.CommandError(\"Could not load options - %s\" % e) from e\n\n    @command.command(\"options.save\")\n    def options_save(self, path: mitmproxy.types.Path) -> None:\n        \"\"\"\n        Save options to a file.\n        \"\"\"\n        try:\n            optmanager.save(ctx.options, path)\n        except OSError as e:\n            raise exceptions.CommandError(\"Could not save options - %s\" % e) from e\n\n    @command.command(\"options.reset\")\n    def options_reset(self) -> None:\n        \"\"\"\n        Reset all options to defaults.\n        \"\"\"\n        ctx.options.reset()\n\n    @command.command(\"options.reset.one\")\n    def options_reset_one(self, name: str) -> None:\n        \"\"\"\n        Reset one option to its default value.\n        \"\"\"\n        if name not in ctx.options:\n            raise exceptions.CommandError(\"No such option: %s\" % name)\n        setattr(\n            ctx.options,\n            name,\n            ctx.options.default(name),\n        )\n", "mitmproxy/addons/upstream_auth.py": "import base64\nimport re\nfrom typing import Optional\n\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import http\nfrom mitmproxy.proxy import mode_specs\nfrom mitmproxy.utils import strutils\n\n\ndef parse_upstream_auth(auth: str) -> bytes:\n    pattern = re.compile(\".+:\")\n    if pattern.search(auth) is None:\n        raise exceptions.OptionsError(\"Invalid upstream auth specification: %s\" % auth)\n    return b\"Basic\" + b\" \" + base64.b64encode(strutils.always_bytes(auth))\n\n\nclass UpstreamAuth:\n    \"\"\"\n    This addon handles authentication to systems upstream from us for the\n    upstream proxy and reverse proxy mode. There are 3 cases:\n\n    - Upstream proxy CONNECT requests should have authentication added, and\n      subsequent already connected requests should not.\n    - Upstream proxy regular requests\n    - Reverse proxy regular requests (CONNECT is invalid in this mode)\n    \"\"\"\n\n    auth: bytes | None = None\n\n    def load(self, loader):\n        loader.add_option(\n            \"upstream_auth\",\n            Optional[str],\n            None,\n            \"\"\"\n            Add HTTP Basic authentication to upstream proxy and reverse proxy\n            requests. Format: username:password.\n            \"\"\",\n        )\n\n    def configure(self, updated):\n        if \"upstream_auth\" in updated:\n            if ctx.options.upstream_auth is None:\n                self.auth = None\n            else:\n                self.auth = parse_upstream_auth(ctx.options.upstream_auth)\n\n    def http_connect_upstream(self, f: http.HTTPFlow):\n        if self.auth:\n            f.request.headers[\"Proxy-Authorization\"] = self.auth\n\n    def requestheaders(self, f: http.HTTPFlow):\n        if self.auth:\n            if (\n                isinstance(f.client_conn.proxy_mode, mode_specs.UpstreamMode)\n                and f.request.scheme == \"http\"\n            ):\n                f.request.headers[\"Proxy-Authorization\"] = self.auth\n            elif isinstance(f.client_conn.proxy_mode, mode_specs.ReverseMode):\n                f.request.headers[\"Authorization\"] = self.auth\n", "mitmproxy/addons/onboarding.py": "from mitmproxy import ctx\nfrom mitmproxy.addons import asgiapp\nfrom mitmproxy.addons.onboardingapp import app\n\nAPP_HOST = \"mitm.it\"\n\n\nclass Onboarding(asgiapp.WSGIApp):\n    name = \"onboarding\"\n\n    def __init__(self):\n        super().__init__(app, APP_HOST, None)\n\n    def load(self, loader):\n        loader.add_option(\n            \"onboarding\", bool, True, \"Toggle the mitmproxy onboarding app.\"\n        )\n        loader.add_option(\n            \"onboarding_host\",\n            str,\n            APP_HOST,\n            \"\"\"\n            Onboarding app domain. For transparent mode, use an IP when a DNS\n            entry for the app domain is not present.\n            \"\"\",\n        )\n\n    def configure(self, updated):\n        self.host = ctx.options.onboarding_host\n        app.config[\"CONFDIR\"] = ctx.options.confdir\n\n    async def request(self, f):\n        if ctx.options.onboarding:\n            await super().request(f)\n", "mitmproxy/addons/maplocal.py": "import logging\nimport mimetypes\nimport re\nimport urllib.parse\nfrom collections.abc import Sequence\nfrom pathlib import Path\nfrom typing import NamedTuple\n\nfrom werkzeug.security import safe_join\n\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy import version\nfrom mitmproxy.utils.spec import parse_spec\n\n\nclass MapLocalSpec(NamedTuple):\n    matches: flowfilter.TFilter\n    regex: str\n    local_path: Path\n\n\ndef parse_map_local_spec(option: str) -> MapLocalSpec:\n    filter, regex, replacement = parse_spec(option)\n\n    try:\n        re.compile(regex)\n    except re.error as e:\n        raise ValueError(f\"Invalid regular expression {regex!r} ({e})\")\n\n    try:\n        path = Path(replacement).expanduser().resolve(strict=True)\n    except FileNotFoundError as e:\n        raise ValueError(f\"Invalid file path: {replacement} ({e})\")\n\n    return MapLocalSpec(filter, regex, path)\n\n\ndef _safe_path_join(root: Path, untrusted: str) -> Path:\n    \"\"\"Join a Path element with an untrusted str.\n\n    This is a convenience wrapper for werkzeug's safe_join,\n    raising a ValueError if the path is malformed.\"\"\"\n    untrusted_parts = Path(untrusted).parts\n    joined = safe_join(root.as_posix(), *untrusted_parts)\n    if joined is None:\n        raise ValueError(\"Untrusted paths.\")\n    return Path(joined)\n\n\ndef file_candidates(url: str, spec: MapLocalSpec) -> list[Path]:\n    \"\"\"\n    Get all potential file candidates given a URL and a mapping spec ordered by preference.\n    This function already assumes that the spec regex matches the URL.\n    \"\"\"\n    m = re.search(spec.regex, url)\n    assert m\n    if m.groups():\n        suffix = m.group(1)\n    else:\n        suffix = re.split(spec.regex, url, maxsplit=1)[1]\n        suffix = suffix.split(\"?\")[0]  # remove query string\n        suffix = suffix.strip(\"/\")\n\n    if suffix:\n        decoded_suffix = urllib.parse.unquote(suffix)\n        suffix_candidates = [decoded_suffix, f\"{decoded_suffix}/index.html\"]\n\n        escaped_suffix = re.sub(r\"[^0-9a-zA-Z\\-_.=(),/]\", \"_\", decoded_suffix)\n        if decoded_suffix != escaped_suffix:\n            suffix_candidates.extend([escaped_suffix, f\"{escaped_suffix}/index.html\"])\n        try:\n            return [_safe_path_join(spec.local_path, x) for x in suffix_candidates]\n        except ValueError:\n            return []\n    else:\n        return [spec.local_path / \"index.html\"]\n\n\nclass MapLocal:\n    def __init__(self) -> None:\n        self.replacements: list[MapLocalSpec] = []\n\n    def load(self, loader):\n        loader.add_option(\n            \"map_local\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Map remote resources to a local file using a pattern of the form\n            \"[/flow-filter]/url-regex/file-or-directory-path\", where the\n            separator can be any character.\n            \"\"\",\n        )\n\n    def configure(self, updated):\n        if \"map_local\" in updated:\n            self.replacements = []\n            for option in ctx.options.map_local:\n                try:\n                    spec = parse_map_local_spec(option)\n                except ValueError as e:\n                    raise exceptions.OptionsError(\n                        f\"Cannot parse map_local option {option}: {e}\"\n                    ) from e\n\n                self.replacements.append(spec)\n\n    def request(self, flow: http.HTTPFlow) -> None:\n        if flow.response or flow.error or not flow.live:\n            return\n\n        url = flow.request.pretty_url\n\n        all_candidates = []\n        for spec in self.replacements:\n            if spec.matches(flow) and re.search(spec.regex, url):\n                if spec.local_path.is_file():\n                    candidates = [spec.local_path]\n                else:\n                    candidates = file_candidates(url, spec)\n                all_candidates.extend(candidates)\n\n                local_file = None\n                for candidate in candidates:\n                    if candidate.is_file():\n                        local_file = candidate\n                        break\n\n                if local_file:\n                    headers = {\"Server\": version.MITMPROXY}\n                    mimetype = mimetypes.guess_type(str(local_file))[0]\n                    if mimetype:\n                        headers[\"Content-Type\"] = mimetype\n\n                    try:\n                        contents = local_file.read_bytes()\n                    except OSError as e:\n                        logging.warning(f\"Could not read file: {e}\")\n                        continue\n\n                    flow.response = http.Response.make(200, contents, headers)\n                    # only set flow.response once, for the first matching rule\n                    return\n        if all_candidates:\n            flow.response = http.Response.make(404)\n            logging.info(\n                f\"None of the local file candidates exist: {', '.join(str(x) for x in all_candidates)}\"\n            )\n", "mitmproxy/addons/stickyauth.py": "from typing import Optional\n\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flowfilter\n\n\nclass StickyAuth:\n    def __init__(self):\n        self.flt = None\n        self.hosts = {}\n\n    def load(self, loader):\n        loader.add_option(\n            \"stickyauth\",\n            Optional[str],\n            None,\n            \"Set sticky auth filter. Matched against requests.\",\n        )\n\n    def configure(self, updated):\n        if \"stickyauth\" in updated:\n            if ctx.options.stickyauth:\n                try:\n                    self.flt = flowfilter.parse(ctx.options.stickyauth)\n                except ValueError as e:\n                    raise exceptions.OptionsError(str(e)) from e\n            else:\n                self.flt = None\n\n    def request(self, flow):\n        if self.flt:\n            host = flow.request.host\n            if \"authorization\" in flow.request.headers:\n                self.hosts[host] = flow.request.headers[\"authorization\"]\n            elif flowfilter.match(self.flt, flow):\n                if host in self.hosts:\n                    flow.request.headers[\"authorization\"] = self.hosts[host]\n", "mitmproxy/addons/strip_ech.py": "from mitmproxy import ctx\nfrom mitmproxy import dns\nfrom mitmproxy.net.dns import types\n\n\nclass StripECH:\n    def load(self, loader):\n        loader.add_option(\n            \"strip_ech\",\n            bool,\n            True,\n            \"Strip DNS HTTPS records to prevent clients from sending Encrypted ClientHello (ECH) messages\",\n        )\n\n    def dns_response(self, flow: dns.DNSFlow):\n        assert flow.response\n        if ctx.options.strip_ech:\n            for answer in flow.response.answers:\n                if answer.type == types.HTTPS:\n                    answer.https_ech = None\n", "mitmproxy/addons/errorcheck.py": "import asyncio\nimport logging\nimport sys\n\nfrom mitmproxy import log\nfrom mitmproxy.contrib import click as miniclick\nfrom mitmproxy.utils import vt_codes\n\n\nclass ErrorCheck:\n    \"\"\"Monitor startup for error log entries, and terminate immediately if there are some.\"\"\"\n\n    repeat_errors_on_stderr: bool\n    \"\"\"\n    Repeat all errors on stderr before exiting.\n    This is useful for the console UI, which otherwise swallows all output.\n    \"\"\"\n\n    def __init__(self, repeat_errors_on_stderr: bool = False) -> None:\n        self.repeat_errors_on_stderr = repeat_errors_on_stderr\n\n        self.logger = ErrorCheckHandler()\n        self.logger.install()\n\n    def finish(self):\n        self.logger.uninstall()\n\n    async def shutdown_if_errored(self):\n        # don't run immediately, wait for all logging tasks to finish.\n        await asyncio.sleep(0)\n        if self.logger.has_errored:\n            plural = \"s\" if len(self.logger.has_errored) > 1 else \"\"\n            if self.repeat_errors_on_stderr:\n                message = f\"Error{plural} logged during startup:\"\n                if vt_codes.ensure_supported(sys.stderr):  # pragma: no cover\n                    message = miniclick.style(message, fg=\"red\")\n                details = \"\\n\".join(\n                    self.logger.format(r) for r in self.logger.has_errored\n                )\n                print(f\"{message}\\n{details}\", file=sys.stderr)\n            else:\n                print(\n                    f\"Error{plural} logged during startup, exiting...\", file=sys.stderr\n                )\n\n            sys.exit(1)\n\n\nclass ErrorCheckHandler(log.MitmLogHandler):\n    def __init__(self) -> None:\n        super().__init__(logging.ERROR)\n        self.has_errored: list[logging.LogRecord] = []\n\n    def emit(self, record: logging.LogRecord) -> None:\n        self.has_errored.append(record)\n", "mitmproxy/addons/proxyserver.py": "\"\"\"\nThis addon is responsible for starting/stopping the proxy server sockets/instances specified by the mode option.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport collections\nimport ipaddress\nimport logging\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom contextlib import contextmanager\nfrom typing import Optional\n\nfrom wsproto.frame_protocol import Opcode\n\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import http\nfrom mitmproxy import platform\nfrom mitmproxy import tcp\nfrom mitmproxy import udp\nfrom mitmproxy import websocket\nfrom mitmproxy.connection import Address\nfrom mitmproxy.flow import Flow\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import mode_specs\nfrom mitmproxy.proxy import server_hooks\nfrom mitmproxy.proxy.layers.tcp import TcpMessageInjected\nfrom mitmproxy.proxy.layers.udp import UdpMessageInjected\nfrom mitmproxy.proxy.layers.websocket import WebSocketMessageInjected\nfrom mitmproxy.proxy.mode_servers import ProxyConnectionHandler\nfrom mitmproxy.proxy.mode_servers import ServerInstance\nfrom mitmproxy.proxy.mode_servers import ServerManager\nfrom mitmproxy.utils import asyncio_utils\nfrom mitmproxy.utils import human\nfrom mitmproxy.utils import signals\n\nlogger = logging.getLogger(__name__)\n\n\nclass Servers:\n    def __init__(self, manager: ServerManager):\n        self.changed = signals.AsyncSignal(lambda: None)\n        self._instances: dict[mode_specs.ProxyMode, ServerInstance] = dict()\n        self._lock = asyncio.Lock()\n        self._manager = manager\n\n    @property\n    def is_updating(self) -> bool:\n        return self._lock.locked()\n\n    async def update(self, modes: Iterable[mode_specs.ProxyMode]) -> bool:\n        all_ok = True\n\n        async with self._lock:\n            new_instances: dict[mode_specs.ProxyMode, ServerInstance] = {}\n\n            start_tasks = []\n            if ctx.options.server:\n                # Create missing modes and keep existing ones.\n                for spec in modes:\n                    if spec in self._instances:\n                        instance = self._instances[spec]\n                    else:\n                        instance = ServerInstance.make(spec, self._manager)\n                        start_tasks.append(instance.start())\n                    new_instances[spec] = instance\n\n            # Shutdown modes that have been removed from the list.\n            stop_tasks = [\n                s.stop()\n                for spec, s in self._instances.items()\n                if spec not in new_instances\n            ]\n\n            self._instances = new_instances\n            # Notify listeners about the new not-yet-started servers.\n            await self.changed.send()\n\n            # We first need to free ports before starting new servers.\n            for ret in await asyncio.gather(*stop_tasks, return_exceptions=True):\n                if ret:\n                    all_ok = False\n                    logger.error(str(ret))\n            for ret in await asyncio.gather(*start_tasks, return_exceptions=True):\n                if ret:\n                    all_ok = False\n                    logger.error(str(ret))\n\n        await self.changed.send()\n        return all_ok\n\n    def __len__(self) -> int:\n        return len(self._instances)\n\n    def __iter__(self) -> Iterator[ServerInstance]:\n        return iter(self._instances.values())\n\n    def __getitem__(self, mode: str | mode_specs.ProxyMode) -> ServerInstance:\n        if isinstance(mode, str):\n            mode = mode_specs.ProxyMode.parse(mode)\n        return self._instances[mode]\n\n\nclass Proxyserver(ServerManager):\n    \"\"\"\n    This addon runs the actual proxy server.\n    \"\"\"\n\n    connections: dict[tuple | str, ProxyConnectionHandler]\n    servers: Servers\n\n    is_running: bool\n    _connect_addr: Address | None = None\n    _update_task: asyncio.Task | None = None\n\n    def __init__(self):\n        self.connections = {}\n        self.servers = Servers(self)\n        self.is_running = False\n\n    def __repr__(self):\n        return f\"Proxyserver({len(self.connections)} active conns)\"\n\n    @contextmanager\n    def register_connection(\n        self, connection_id: tuple | str, handler: ProxyConnectionHandler\n    ):\n        self.connections[connection_id] = handler\n        try:\n            yield\n        finally:\n            del self.connections[connection_id]\n\n    def load(self, loader):\n        loader.add_option(\n            \"connection_strategy\",\n            str,\n            \"eager\",\n            \"Determine when server connections should be established. When set to lazy, mitmproxy \"\n            \"tries to defer establishing an upstream connection as long as possible. This makes it possible to \"\n            \"use server replay while being offline. When set to eager, mitmproxy can detect protocols with \"\n            \"server-side greetings, as well as accurately mirror TLS ALPN negotiation.\",\n            choices=(\"eager\", \"lazy\"),\n        )\n        loader.add_option(\n            \"stream_large_bodies\",\n            Optional[str],\n            None,\n            \"\"\"\n            Stream data to the client if response body exceeds the given\n            threshold. If streamed, the body will not be stored in any way,\n            and such responses cannot be modified. Understands k/m/g\n            suffixes, i.e. 3m for 3 megabytes.\n            \"\"\",\n        )\n        loader.add_option(\n            \"body_size_limit\",\n            Optional[str],\n            None,\n            \"\"\"\n            Byte size limit of HTTP request and response bodies. Understands\n            k/m/g suffixes, i.e. 3m for 3 megabytes.\n            \"\"\",\n        )\n        loader.add_option(\n            \"keep_host_header\",\n            bool,\n            False,\n            \"\"\"\n            Reverse Proxy: Keep the original host header instead of rewriting it\n            to the reverse proxy target.\n            \"\"\",\n        )\n        loader.add_option(\n            \"proxy_debug\",\n            bool,\n            False,\n            \"Enable debug logs in the proxy core.\",\n        )\n        loader.add_option(\n            \"normalize_outbound_headers\",\n            bool,\n            True,\n            \"\"\"\n            Normalize outgoing HTTP/2 header names, but emit a warning when doing so.\n            HTTP/2 does not allow uppercase header names. This option makes sure that HTTP/2 headers set\n            in custom scripts are lowercased before they are sent.\n            \"\"\",\n        )\n        loader.add_option(\n            \"validate_inbound_headers\",\n            bool,\n            True,\n            \"\"\"\n            Make sure that incoming HTTP requests are not malformed.\n            Disabling this option makes mitmproxy vulnerable to HTTP smuggling attacks.\n            \"\"\",\n        )\n        loader.add_option(\n            \"connect_addr\",\n            Optional[str],\n            None,\n            \"\"\"Set the local IP address that mitmproxy should use when connecting to upstream servers.\"\"\",\n        )\n\n    def running(self):\n        self.is_running = True\n\n    def configure(self, updated) -> None:\n        if \"stream_large_bodies\" in updated:\n            try:\n                human.parse_size(ctx.options.stream_large_bodies)\n            except ValueError:\n                raise exceptions.OptionsError(\n                    f\"Invalid stream_large_bodies specification: \"\n                    f\"{ctx.options.stream_large_bodies}\"\n                )\n        if \"body_size_limit\" in updated:\n            try:\n                human.parse_size(ctx.options.body_size_limit)\n            except ValueError:\n                raise exceptions.OptionsError(\n                    f\"Invalid body_size_limit specification: \"\n                    f\"{ctx.options.body_size_limit}\"\n                )\n        if \"connect_addr\" in updated:\n            try:\n                if ctx.options.connect_addr:\n                    self._connect_addr = (\n                        str(ipaddress.ip_address(ctx.options.connect_addr)),\n                        0,\n                    )\n                else:\n                    self._connect_addr = None\n            except ValueError:\n                raise exceptions.OptionsError(\n                    f\"Invalid value for connect_addr: {ctx.options.connect_addr!r}. Specify a valid IP address.\"\n                )\n        if \"mode\" in updated or \"server\" in updated:\n            # Make sure that all modes are syntactically valid...\n            modes: list[mode_specs.ProxyMode] = []\n            for mode in ctx.options.mode:\n                try:\n                    modes.append(mode_specs.ProxyMode.parse(mode))\n                except ValueError as e:\n                    raise exceptions.OptionsError(\n                        f\"Invalid proxy mode specification: {mode} ({e})\"\n                    )\n\n            # ...and don't listen on the same address.\n            listen_addrs = [\n                (\n                    m.listen_host(ctx.options.listen_host),\n                    m.listen_port(ctx.options.listen_port),\n                    m.transport_protocol,\n                )\n                for m in modes\n            ]\n            if len(set(listen_addrs)) != len(listen_addrs):\n                (host, port, _) = collections.Counter(listen_addrs).most_common(1)[0][0]\n                dup_addr = human.format_address((host or \"0.0.0.0\", port))\n                raise exceptions.OptionsError(\n                    f\"Cannot spawn multiple servers on the same address: {dup_addr}\"\n                )\n\n            if ctx.options.mode and not ctx.master.addons.get(\"nextlayer\"):\n                logger.warning(\"Warning: Running proxyserver without nextlayer addon!\")\n            if any(isinstance(m, mode_specs.TransparentMode) for m in modes):\n                if platform.original_addr:\n                    platform.init_transparent_mode()\n                else:\n                    raise exceptions.OptionsError(\n                        \"Transparent mode not supported on this platform.\"\n                    )\n\n            if self.is_running:\n                self._update_task = asyncio_utils.create_task(\n                    self.servers.update(modes), name=\"update servers\"\n                )\n\n    async def setup_servers(self) -> bool:\n        \"\"\"Setup proxy servers. This may take an indefinite amount of time to complete (e.g. on permission prompts).\"\"\"\n        return await self.servers.update(\n            [mode_specs.ProxyMode.parse(m) for m in ctx.options.mode]\n        )\n\n    def listen_addrs(self) -> list[Address]:\n        return [addr for server in self.servers for addr in server.listen_addrs]\n\n    def inject_event(self, event: events.MessageInjected):\n        connection_id: str | tuple\n        if event.flow.client_conn.transport_protocol != \"udp\":\n            connection_id = event.flow.client_conn.id\n        else:  # pragma: no cover\n            # temporary workaround: for UDP we don't have persistent client IDs yet.\n            connection_id = (\n                event.flow.client_conn.peername,\n                event.flow.client_conn.sockname,\n            )\n        if connection_id not in self.connections:\n            raise ValueError(\"Flow is not from a live connection.\")\n        self.connections[connection_id].server_event(event)\n\n    @command.command(\"inject.websocket\")\n    def inject_websocket(\n        self, flow: Flow, to_client: bool, message: bytes, is_text: bool = True\n    ):\n        if not isinstance(flow, http.HTTPFlow) or not flow.websocket:\n            logger.warning(\"Cannot inject WebSocket messages into non-WebSocket flows.\")\n\n        msg = websocket.WebSocketMessage(\n            Opcode.TEXT if is_text else Opcode.BINARY, not to_client, message\n        )\n        event = WebSocketMessageInjected(flow, msg)\n        try:\n            self.inject_event(event)\n        except ValueError as e:\n            logger.warning(str(e))\n\n    @command.command(\"inject.tcp\")\n    def inject_tcp(self, flow: Flow, to_client: bool, message: bytes):\n        if not isinstance(flow, tcp.TCPFlow):\n            logger.warning(\"Cannot inject TCP messages into non-TCP flows.\")\n\n        event = TcpMessageInjected(flow, tcp.TCPMessage(not to_client, message))\n        try:\n            self.inject_event(event)\n        except ValueError as e:\n            logger.warning(str(e))\n\n    @command.command(\"inject.udp\")\n    def inject_udp(self, flow: Flow, to_client: bool, message: bytes):\n        if not isinstance(flow, udp.UDPFlow):\n            logger.warning(\"Cannot inject UDP messages into non-UDP flows.\")\n\n        event = UdpMessageInjected(flow, udp.UDPMessage(not to_client, message))\n        try:\n            self.inject_event(event)\n        except ValueError as e:\n            logger.warning(str(e))\n\n    def server_connect(self, data: server_hooks.ServerConnectionHookData):\n        if data.server.sockname is None:\n            data.server.sockname = self._connect_addr\n\n        # Prevent mitmproxy from recursively connecting to itself.\n        assert data.server.address\n        connect_host, connect_port, *_ = data.server.address\n\n        for server in self.servers:\n            for listen_host, listen_port, *_ in server.listen_addrs:\n                self_connect = (\n                    connect_port == listen_port\n                    and connect_host in (\"localhost\", \"127.0.0.1\", \"::1\", listen_host)\n                    and server.mode.transport_protocol == data.server.transport_protocol\n                )\n                if self_connect:\n                    data.server.error = (\n                        \"Request destination unknown. \"\n                        \"Unable to figure out where this request should be forwarded to.\"\n                    )\n                    return\n", "mitmproxy/addons/stickycookie.py": "import collections\nfrom http import cookiejar\nfrom typing import Optional\n\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy.net.http import cookies\n\nTOrigin = tuple[str, int, str]\n\n\ndef ckey(attrs: dict[str, str], f: http.HTTPFlow) -> TOrigin:\n    \"\"\"\n    Returns a (domain, port, path) tuple.\n    \"\"\"\n    domain = f.request.host\n    path = \"/\"\n    if \"domain\" in attrs:\n        domain = attrs[\"domain\"]\n    if \"path\" in attrs:\n        path = attrs[\"path\"]\n    return (domain, f.request.port, path)\n\n\ndef domain_match(a: str, b: str) -> bool:\n    if cookiejar.domain_match(a, b):  # type: ignore\n        return True\n    elif cookiejar.domain_match(a, b.strip(\".\")):  # type: ignore\n        return True\n    return False\n\n\nclass StickyCookie:\n    def __init__(self) -> None:\n        self.jar: collections.defaultdict[TOrigin, dict[str, str]] = (\n            collections.defaultdict(dict)\n        )\n        self.flt: flowfilter.TFilter | None = None\n\n    def load(self, loader):\n        loader.add_option(\n            \"stickycookie\",\n            Optional[str],\n            None,\n            \"Set sticky cookie filter. Matched against requests.\",\n        )\n\n    def configure(self, updated):\n        if \"stickycookie\" in updated:\n            if ctx.options.stickycookie:\n                try:\n                    self.flt = flowfilter.parse(ctx.options.stickycookie)\n                except ValueError as e:\n                    raise exceptions.OptionsError(str(e)) from e\n            else:\n                self.flt = None\n\n    def response(self, flow: http.HTTPFlow):\n        assert flow.response\n        if self.flt:\n            for name, (value, attrs) in flow.response.cookies.items(multi=True):\n                # FIXME: We now know that Cookie.py screws up some cookies with\n                # valid RFC 822/1123 datetime specifications for expiry. Sigh.\n                dom_port_path = ckey(attrs, flow)\n\n                if domain_match(flow.request.host, dom_port_path[0]):\n                    if cookies.is_expired(attrs):\n                        # Remove the cookie from jar\n                        self.jar[dom_port_path].pop(name, None)\n\n                        # If all cookies of a dom_port_path have been removed\n                        # then remove it from the jar itself\n                        if not self.jar[dom_port_path]:\n                            self.jar.pop(dom_port_path, None)\n                    else:\n                        self.jar[dom_port_path][name] = value\n\n    def request(self, flow: http.HTTPFlow):\n        if self.flt:\n            cookie_list: list[tuple[str, str]] = []\n            if flowfilter.match(self.flt, flow):\n                for (domain, port, path), c in self.jar.items():\n                    match = [\n                        domain_match(flow.request.host, domain),\n                        flow.request.port == port,\n                        flow.request.path.startswith(path),\n                    ]\n                    if all(match):\n                        cookie_list.extend(c.items())\n            if cookie_list:\n                # FIXME: we need to formalise this...\n                flow.metadata[\"stickycookie\"] = True\n                flow.request.headers[\"cookie\"] = cookies.format_cookie_header(\n                    cookie_list\n                )\n", "mitmproxy/addons/modifybody.py": "import logging\nimport re\nfrom collections.abc import Sequence\n\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy.addons.modifyheaders import ModifySpec\nfrom mitmproxy.addons.modifyheaders import parse_modify_spec\nfrom mitmproxy.log import ALERT\n\nlogger = logging.getLogger(__name__)\n\n\nclass ModifyBody:\n    def __init__(self) -> None:\n        self.replacements: list[ModifySpec] = []\n\n    def load(self, loader):\n        loader.add_option(\n            \"modify_body\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Replacement pattern of the form \"[/flow-filter]/regex/[@]replacement\", where\n            the separator can be any character. The @ allows to provide a file path that\n            is used to read the replacement string.\n            \"\"\",\n        )\n\n    def configure(self, updated):\n        if \"modify_body\" in updated:\n            self.replacements = []\n            for option in ctx.options.modify_body:\n                try:\n                    spec = parse_modify_spec(option, True)\n                except ValueError as e:\n                    raise exceptions.OptionsError(\n                        f\"Cannot parse modify_body option {option}: {e}\"\n                    ) from e\n\n                self.replacements.append(spec)\n\n        stream_and_modify_conflict = (\n            ctx.options.modify_body\n            and ctx.options.stream_large_bodies\n            and (\"modify_body\" in updated or \"stream_large_bodies\" in updated)\n        )\n        if stream_and_modify_conflict:\n            logger.log(\n                ALERT,\n                \"Both modify_body and stream_large_bodies are active. \"\n                \"Streamed bodies will not be modified.\",\n            )\n\n    def request(self, flow):\n        if flow.response or flow.error or not flow.live:\n            return\n        self.run(flow)\n\n    def response(self, flow):\n        if flow.error or not flow.live:\n            return\n        self.run(flow)\n\n    def run(self, flow):\n        for spec in self.replacements:\n            if spec.matches(flow):\n                try:\n                    replacement = spec.read_replacement()\n                except OSError as e:\n                    logging.warning(f\"Could not read replacement file: {e}\")\n                    continue\n                if flow.response:\n                    flow.response.content = re.sub(\n                        spec.subject,\n                        replacement,\n                        flow.response.content,\n                        flags=re.DOTALL,\n                    )\n                else:\n                    flow.request.content = re.sub(\n                        spec.subject, replacement, flow.request.content, flags=re.DOTALL\n                    )\n", "mitmproxy/addons/modifyheaders.py": "import logging\nimport re\nfrom collections.abc import Sequence\nfrom pathlib import Path\nfrom typing import NamedTuple\n\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy.http import Headers\nfrom mitmproxy.utils import strutils\nfrom mitmproxy.utils.spec import parse_spec\n\n\nclass ModifySpec(NamedTuple):\n    matches: flowfilter.TFilter\n    subject: bytes\n    replacement_str: str\n\n    def read_replacement(self) -> bytes:\n        \"\"\"\n        Process the replacement str. This usually just involves converting it to bytes.\n        However, if it starts with `@`, we interpret the rest as a file path to read from.\n\n        Raises:\n            - IOError if the file cannot be read.\n        \"\"\"\n        if self.replacement_str.startswith(\"@\"):\n            return Path(self.replacement_str[1:]).expanduser().read_bytes()\n        else:\n            # We could cache this at some point, but unlikely to be a problem.\n            return strutils.escaped_str_to_bytes(self.replacement_str)\n\n\ndef parse_modify_spec(option: str, subject_is_regex: bool) -> ModifySpec:\n    flow_filter, subject_str, replacement = parse_spec(option)\n\n    subject = strutils.escaped_str_to_bytes(subject_str)\n    if subject_is_regex:\n        try:\n            re.compile(subject)\n        except re.error as e:\n            raise ValueError(f\"Invalid regular expression {subject!r} ({e})\")\n\n    spec = ModifySpec(flow_filter, subject, replacement)\n\n    try:\n        spec.read_replacement()\n    except OSError as e:\n        raise ValueError(f\"Invalid file path: {replacement[1:]} ({e})\")\n\n    return spec\n\n\nclass ModifyHeaders:\n    def __init__(self) -> None:\n        self.replacements: list[ModifySpec] = []\n\n    def load(self, loader):\n        loader.add_option(\n            \"modify_headers\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Header modify pattern of the form \"[/flow-filter]/header-name/[@]header-value\", where the\n            separator can be any character. The @ allows to provide a file path that is used to read\n            the header value string. An empty header-value removes existing header-name headers.\n            \"\"\",\n        )\n\n    def configure(self, updated):\n        if \"modify_headers\" in updated:\n            self.replacements = []\n            for option in ctx.options.modify_headers:\n                try:\n                    spec = parse_modify_spec(option, False)\n                except ValueError as e:\n                    raise exceptions.OptionsError(\n                        f\"Cannot parse modify_headers option {option}: {e}\"\n                    ) from e\n                self.replacements.append(spec)\n\n    def request(self, flow):\n        if flow.response or flow.error or not flow.live:\n            return\n        self.run(flow, flow.request.headers)\n\n    def response(self, flow):\n        if flow.error or not flow.live:\n            return\n        self.run(flow, flow.response.headers)\n\n    def run(self, flow: http.HTTPFlow, hdrs: Headers) -> None:\n        matches = []\n\n        # first check all the filters against the original, unmodified flow\n        for spec in self.replacements:\n            matches.append(spec.matches(flow))\n\n        # unset all specified headers\n        for i, spec in enumerate(self.replacements):\n            if matches[i]:\n                hdrs.pop(spec.subject, None)\n\n        # set all specified headers if the replacement string is not empty\n\n        for i, spec in enumerate(self.replacements):\n            if matches[i]:\n                try:\n                    replacement = spec.read_replacement()\n                except OSError as e:\n                    logging.warning(f\"Could not read replacement file: {e}\")\n                    continue\n                else:\n                    if replacement:\n                        hdrs.add(spec.subject, replacement)\n", "mitmproxy/addons/anticache.py": "from mitmproxy import ctx\n\n\nclass AntiCache:\n    def load(self, loader):\n        loader.add_option(\n            \"anticache\",\n            bool,\n            False,\n            \"\"\"\n            Strip out request headers that might cause the server to return\n            304-not-modified.\n            \"\"\",\n        )\n\n    def request(self, flow):\n        if ctx.options.anticache:\n            flow.request.anticache()\n", "mitmproxy/addons/tlsconfig.py": "import ipaddress\nimport logging\nimport os\nimport ssl\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import TypedDict\n\nfrom aioquic.h3.connection import H3_ALPN\nfrom aioquic.tls import CipherSuite\nfrom cryptography import x509\nfrom OpenSSL import crypto\nfrom OpenSSL import SSL\n\nfrom mitmproxy import certs\nfrom mitmproxy import connection\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import tls\nfrom mitmproxy.net import tls as net_tls\nfrom mitmproxy.options import CONF_BASENAME\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy.layers import modes\nfrom mitmproxy.proxy.layers import quic\nfrom mitmproxy.proxy.layers import tls as proxy_tls\n\n# We manually need to specify this, otherwise OpenSSL may select a non-HTTP2 cipher by default.\n# https://ssl-config.mozilla.org/#config=old\n\nDEFAULT_CIPHERS = (\n    \"ECDHE-ECDSA-AES128-GCM-SHA256\",\n    \"ECDHE-RSA-AES128-GCM-SHA256\",\n    \"ECDHE-ECDSA-AES256-GCM-SHA384\",\n    \"ECDHE-RSA-AES256-GCM-SHA384\",\n    \"ECDHE-ECDSA-CHACHA20-POLY1305\",\n    \"ECDHE-RSA-CHACHA20-POLY1305\",\n    \"DHE-RSA-AES128-GCM-SHA256\",\n    \"DHE-RSA-AES256-GCM-SHA384\",\n    \"DHE-RSA-CHACHA20-POLY1305\",\n    \"ECDHE-ECDSA-AES128-SHA256\",\n    \"ECDHE-RSA-AES128-SHA256\",\n    \"ECDHE-ECDSA-AES128-SHA\",\n    \"ECDHE-RSA-AES128-SHA\",\n    \"ECDHE-ECDSA-AES256-SHA384\",\n    \"ECDHE-RSA-AES256-SHA384\",\n    \"ECDHE-ECDSA-AES256-SHA\",\n    \"ECDHE-RSA-AES256-SHA\",\n    \"DHE-RSA-AES128-SHA256\",\n    \"DHE-RSA-AES256-SHA256\",\n    \"AES128-GCM-SHA256\",\n    \"AES256-GCM-SHA384\",\n    \"AES128-SHA256\",\n    \"AES256-SHA256\",\n    \"AES128-SHA\",\n    \"AES256-SHA\",\n    \"DES-CBC3-SHA\",\n)\n\n# 2022/05: X509_CHECK_FLAG_NEVER_CHECK_SUBJECT is not available in LibreSSL, ignore gracefully as it's not critical.\nDEFAULT_HOSTFLAGS = (\n    SSL._lib.X509_CHECK_FLAG_NO_PARTIAL_WILDCARDS  # type: ignore\n    | getattr(SSL._lib, \"X509_CHECK_FLAG_NEVER_CHECK_SUBJECT\", 0)  # type: ignore\n)\n\n\nclass AppData(TypedDict):\n    client_alpn: bytes | None\n    server_alpn: bytes | None\n    http2: bool\n\n\ndef alpn_select_callback(conn: SSL.Connection, options: list[bytes]) -> Any:\n    app_data: AppData = conn.get_app_data()\n    client_alpn = app_data[\"client_alpn\"]\n    server_alpn = app_data[\"server_alpn\"]\n    http2 = app_data[\"http2\"]\n    if client_alpn is not None:\n        if client_alpn in options:\n            return client_alpn\n        else:\n            return SSL.NO_OVERLAPPING_PROTOCOLS\n    if server_alpn and server_alpn in options:\n        return server_alpn\n    if server_alpn == b\"\":\n        # We do have a server connection, but the remote server refused to negotiate a protocol:\n        # We need to mirror this on the client connection.\n        return SSL.NO_OVERLAPPING_PROTOCOLS\n    http_alpns = proxy_tls.HTTP_ALPNS if http2 else proxy_tls.HTTP1_ALPNS\n    # client sends in order of preference, so we are nice and respect that.\n    for alpn in options:\n        if alpn in http_alpns:\n            return alpn\n    else:\n        return SSL.NO_OVERLAPPING_PROTOCOLS\n\n\nclass TlsConfig:\n    \"\"\"\n    This addon supplies the proxy core with the desired OpenSSL connection objects to negotiate TLS.\n    \"\"\"\n\n    certstore: certs.CertStore = None  # type: ignore\n\n    # TODO: We should support configuring TLS 1.3 cipher suites (https://github.com/mitmproxy/mitmproxy/issues/4260)\n    # TODO: We should re-use SSL.Context options here, if only for TLS session resumption.\n    #       This may require patches to pyOpenSSL, as some functionality is only exposed on contexts.\n    # TODO: This addon should manage the following options itself, which are current defined in mitmproxy/options.py:\n    #  - upstream_cert\n    #  - add_upstream_certs_to_client_chain\n    #  - ciphers_client\n    #  - ciphers_server\n    #  - key_size\n    #  - certs\n    #  - cert_passphrase\n    #  - ssl_verify_upstream_trusted_ca\n    #  - ssl_verify_upstream_trusted_confdir\n\n    def load(self, loader):\n        loader.add_option(\n            name=\"tls_version_client_min\",\n            typespec=str,\n            default=net_tls.DEFAULT_MIN_VERSION.name,\n            choices=[x.name for x in net_tls.Version],\n            help=f\"Set the minimum TLS version for client connections.\",\n        )\n        loader.add_option(\n            name=\"tls_version_client_max\",\n            typespec=str,\n            default=net_tls.DEFAULT_MAX_VERSION.name,\n            choices=[x.name for x in net_tls.Version],\n            help=f\"Set the maximum TLS version for client connections.\",\n        )\n        loader.add_option(\n            name=\"tls_version_server_min\",\n            typespec=str,\n            default=net_tls.DEFAULT_MIN_VERSION.name,\n            choices=[x.name for x in net_tls.Version],\n            help=f\"Set the minimum TLS version for server connections.\",\n        )\n        loader.add_option(\n            name=\"tls_version_server_max\",\n            typespec=str,\n            default=net_tls.DEFAULT_MAX_VERSION.name,\n            choices=[x.name for x in net_tls.Version],\n            help=f\"Set the maximum TLS version for server connections.\",\n        )\n        loader.add_option(\n            name=\"tls_ecdh_curve_client\",\n            typespec=str | None,\n            default=None,\n            help=\"Use a specific elliptic curve for ECDHE key exchange on client connections. \"\n            'OpenSSL syntax, for example \"prime256v1\" (see `openssl ecparam -list_curves`).',\n        )\n        loader.add_option(\n            name=\"tls_ecdh_curve_server\",\n            typespec=str | None,\n            default=None,\n            help=\"Use a specific elliptic curve for ECDHE key exchange on server connections. \"\n            'OpenSSL syntax, for example \"prime256v1\" (see `openssl ecparam -list_curves`).',\n        )\n\n    def tls_clienthello(self, tls_clienthello: tls.ClientHelloData):\n        conn_context = tls_clienthello.context\n        tls_clienthello.establish_server_tls_first = (\n            conn_context.server.tls and ctx.options.connection_strategy == \"eager\"\n        )\n\n    def tls_start_client(self, tls_start: tls.TlsData) -> None:\n        \"\"\"Establish TLS or DTLS between client and proxy.\"\"\"\n        if tls_start.ssl_conn is not None:\n            return  # a user addon has already provided the pyOpenSSL context.\n\n        assert isinstance(tls_start.conn, connection.Client)\n\n        client: connection.Client = tls_start.conn\n        server: connection.Server = tls_start.context.server\n\n        entry = self.get_cert(tls_start.context)\n\n        if not client.cipher_list and ctx.options.ciphers_client:\n            client.cipher_list = ctx.options.ciphers_client.split(\":\")\n        # don't assign to client.cipher_list, doesn't need to be stored.\n        cipher_list = client.cipher_list or DEFAULT_CIPHERS\n\n        if ctx.options.add_upstream_certs_to_client_chain:  # pragma: no cover\n            # exempted from coverage until https://bugs.python.org/issue18233 is fixed.\n            extra_chain_certs = server.certificate_list\n        else:\n            extra_chain_certs = []\n\n        ssl_ctx = net_tls.create_client_proxy_context(\n            method=net_tls.Method.DTLS_SERVER_METHOD\n            if tls_start.is_dtls\n            else net_tls.Method.TLS_SERVER_METHOD,\n            min_version=net_tls.Version[ctx.options.tls_version_client_min],\n            max_version=net_tls.Version[ctx.options.tls_version_client_max],\n            cipher_list=tuple(cipher_list),\n            ecdh_curve=ctx.options.tls_ecdh_curve_client,\n            chain_file=entry.chain_file,\n            request_client_cert=False,\n            alpn_select_callback=alpn_select_callback,\n            extra_chain_certs=tuple(extra_chain_certs),\n            dhparams=self.certstore.dhparams,\n        )\n        tls_start.ssl_conn = SSL.Connection(ssl_ctx)\n\n        tls_start.ssl_conn.use_certificate(entry.cert.to_pyopenssl())\n        tls_start.ssl_conn.use_privatekey(\n            crypto.PKey.from_cryptography_key(entry.privatekey)\n        )\n\n        # Force HTTP/1 for secure web proxies, we currently don't support CONNECT over HTTP/2.\n        # There is a proof-of-concept branch at https://github.com/mhils/mitmproxy/tree/http2-proxy,\n        # but the complexity outweighs the benefits for now.\n        if len(tls_start.context.layers) == 2 and isinstance(\n            tls_start.context.layers[0], modes.HttpProxy\n        ):\n            client_alpn: bytes | None = b\"http/1.1\"\n        else:\n            client_alpn = client.alpn\n\n        tls_start.ssl_conn.set_app_data(\n            AppData(\n                client_alpn=client_alpn,\n                server_alpn=server.alpn,\n                http2=ctx.options.http2,\n            )\n        )\n        tls_start.ssl_conn.set_accept_state()\n\n    def tls_start_server(self, tls_start: tls.TlsData) -> None:\n        \"\"\"Establish TLS or DTLS between proxy and server.\"\"\"\n        if tls_start.ssl_conn is not None:\n            return  # a user addon has already provided the pyOpenSSL context.\n\n        assert isinstance(tls_start.conn, connection.Server)\n\n        client: connection.Client = tls_start.context.client\n        # tls_start.conn may be different from tls_start.context.server, e.g. an upstream HTTPS proxy.\n        server: connection.Server = tls_start.conn\n        assert server.address\n\n        if ctx.options.ssl_insecure:\n            verify = net_tls.Verify.VERIFY_NONE\n        else:\n            verify = net_tls.Verify.VERIFY_PEER\n\n        if server.sni is None:\n            server.sni = client.sni or server.address[0]\n\n        if not server.alpn_offers:\n            if client.alpn_offers:\n                if ctx.options.http2:\n                    # We would perfectly support HTTP/1 -> HTTP/2, but we want to keep things on the same protocol\n                    # version. There are some edge cases where we want to mirror the regular server's behavior\n                    # accurately, for example header capitalization.\n                    server.alpn_offers = tuple(client.alpn_offers)\n                else:\n                    server.alpn_offers = tuple(\n                        x for x in client.alpn_offers if x != b\"h2\"\n                    )\n            else:\n                # We either have no client TLS or a client without ALPN.\n                # - If the client does use TLS but did not send an ALPN extension, we want to mirror that upstream.\n                # - If the client does not use TLS, there's no clear-cut answer. As a pragmatic approach, we also do\n                #   not send any ALPN extension in this case, which defaults to whatever protocol we are speaking\n                #   or falls back to HTTP.\n                server.alpn_offers = []\n\n        if not server.cipher_list and ctx.options.ciphers_server:\n            server.cipher_list = ctx.options.ciphers_server.split(\":\")\n        # don't assign to client.cipher_list, doesn't need to be stored.\n        cipher_list = server.cipher_list or DEFAULT_CIPHERS\n\n        client_cert: str | None = None\n        if ctx.options.client_certs:\n            client_certs = os.path.expanduser(ctx.options.client_certs)\n            if os.path.isfile(client_certs):\n                client_cert = client_certs\n            else:\n                server_name: str = server.sni or server.address[0]\n                p = os.path.join(client_certs, f\"{server_name}.pem\")\n                if os.path.isfile(p):\n                    client_cert = p\n\n        ssl_ctx = net_tls.create_proxy_server_context(\n            method=net_tls.Method.DTLS_CLIENT_METHOD\n            if tls_start.is_dtls\n            else net_tls.Method.TLS_CLIENT_METHOD,\n            min_version=net_tls.Version[ctx.options.tls_version_server_min],\n            max_version=net_tls.Version[ctx.options.tls_version_server_max],\n            cipher_list=tuple(cipher_list),\n            ecdh_curve=ctx.options.tls_ecdh_curve_server,\n            verify=verify,\n            ca_path=ctx.options.ssl_verify_upstream_trusted_confdir,\n            ca_pemfile=ctx.options.ssl_verify_upstream_trusted_ca,\n            client_cert=client_cert,\n            legacy_server_connect=ctx.options.ssl_insecure,\n        )\n\n        tls_start.ssl_conn = SSL.Connection(ssl_ctx)\n        if server.sni:\n            # We need to set SNI + enable hostname verification.\n            assert isinstance(server.sni, str)\n            # Manually enable hostname verification on the context object.\n            # https://wiki.openssl.org/index.php/Hostname_validation\n            param = SSL._lib.SSL_get0_param(tls_start.ssl_conn._ssl)  # type: ignore\n            # Matching on the CN is disabled in both Chrome and Firefox, so we disable it, too.\n            # https://www.chromestatus.com/feature/4981025180483584\n\n            SSL._lib.X509_VERIFY_PARAM_set_hostflags(param, DEFAULT_HOSTFLAGS)  # type: ignore\n\n            try:\n                ip: bytes = ipaddress.ip_address(server.sni).packed\n            except ValueError:\n                host_name = server.sni.encode(\"idna\")\n                tls_start.ssl_conn.set_tlsext_host_name(host_name)\n                ok = SSL._lib.X509_VERIFY_PARAM_set1_host(  # type: ignore\n                    param, host_name, len(host_name)\n                )  # type: ignore\n                SSL._openssl_assert(ok == 1)  # type: ignore\n            else:\n                # RFC 6066: Literal IPv4 and IPv6 addresses are not permitted in \"HostName\",\n                # so we don't call set_tlsext_host_name.\n                ok = SSL._lib.X509_VERIFY_PARAM_set1_ip(param, ip, len(ip))  # type: ignore\n                SSL._openssl_assert(ok == 1)  # type: ignore\n        elif verify is not net_tls.Verify.VERIFY_NONE:\n            raise ValueError(\"Cannot validate certificate hostname without SNI\")\n\n        if server.alpn_offers:\n            tls_start.ssl_conn.set_alpn_protos(server.alpn_offers)\n\n        tls_start.ssl_conn.set_connect_state()\n\n    def quic_start_client(self, tls_start: quic.QuicTlsData) -> None:\n        \"\"\"Establish QUIC between client and proxy.\"\"\"\n        if tls_start.settings is not None:\n            return  # a user addon has already provided the settings.\n        tls_start.settings = quic.QuicTlsSettings()\n\n        # keep the following part in sync with `tls_start_client`\n        assert isinstance(tls_start.conn, connection.Client)\n\n        client: connection.Client = tls_start.conn\n        server: connection.Server = tls_start.context.server\n\n        entry = self.get_cert(tls_start.context)\n\n        if not client.cipher_list and ctx.options.ciphers_client:\n            client.cipher_list = ctx.options.ciphers_client.split(\":\")\n\n        if ctx.options.add_upstream_certs_to_client_chain:  # pragma: no cover\n            extra_chain_certs = server.certificate_list\n        else:\n            extra_chain_certs = []\n\n        # set context parameters\n        if client.cipher_list:\n            tls_start.settings.cipher_suites = [\n                CipherSuite[cipher] for cipher in client.cipher_list\n            ]\n        # if we don't have upstream ALPN, we allow all offered by the client\n        tls_start.settings.alpn_protocols = [\n            alpn.decode(\"ascii\")\n            for alpn in [alpn for alpn in (client.alpn, server.alpn) if alpn]\n            or client.alpn_offers\n        ]\n\n        # set the certificates\n        tls_start.settings.certificate = entry.cert._cert\n        tls_start.settings.certificate_private_key = entry.privatekey\n        tls_start.settings.certificate_chain = [\n            cert._cert for cert in (*entry.chain_certs, *extra_chain_certs)\n        ]\n\n    def quic_start_server(self, tls_start: quic.QuicTlsData) -> None:\n        \"\"\"Establish QUIC between proxy and server.\"\"\"\n        if tls_start.settings is not None:\n            return  # a user addon has already provided the settings.\n        tls_start.settings = quic.QuicTlsSettings()\n\n        # keep the following part in sync with `tls_start_server`\n        assert isinstance(tls_start.conn, connection.Server)\n\n        client: connection.Client = tls_start.context.client\n        server: connection.Server = tls_start.conn\n        assert server.address\n\n        if ctx.options.ssl_insecure:\n            tls_start.settings.verify_mode = ssl.CERT_NONE\n        else:\n            tls_start.settings.verify_mode = ssl.CERT_REQUIRED\n\n        if server.sni is None:\n            server.sni = client.sni or server.address[0]\n\n        if not server.alpn_offers:\n            if client.alpn_offers:\n                server.alpn_offers = tuple(client.alpn_offers)\n            else:\n                # aioquic fails if no ALPN is offered, so use H3\n                server.alpn_offers = tuple(alpn.encode(\"ascii\") for alpn in H3_ALPN)\n\n        if not server.cipher_list and ctx.options.ciphers_server:\n            server.cipher_list = ctx.options.ciphers_server.split(\":\")\n\n        # set context parameters\n        if server.cipher_list:\n            tls_start.settings.cipher_suites = [\n                CipherSuite[cipher] for cipher in server.cipher_list\n            ]\n        if server.alpn_offers:\n            tls_start.settings.alpn_protocols = [\n                alpn.decode(\"ascii\") for alpn in server.alpn_offers\n            ]\n\n        # set the certificates\n        # NOTE client certificates are not supported\n        tls_start.settings.ca_path = ctx.options.ssl_verify_upstream_trusted_confdir\n        tls_start.settings.ca_file = ctx.options.ssl_verify_upstream_trusted_ca\n\n    def running(self):\n        # FIXME: We have a weird bug where the contract for configure is not followed and it is never called with\n        # confdir or command_history as updated.\n        self.configure(\"confdir\")  # pragma: no cover\n\n    def configure(self, updated):\n        if (\n            \"certs\" in updated\n            or \"confdir\" in updated\n            or \"key_size\" in updated\n            or \"cert_passphrase\" in updated\n        ):\n            certstore_path = os.path.expanduser(ctx.options.confdir)\n            self.certstore = certs.CertStore.from_store(\n                path=certstore_path,\n                basename=CONF_BASENAME,\n                key_size=ctx.options.key_size,\n                passphrase=ctx.options.cert_passphrase.encode(\"utf8\")\n                if ctx.options.cert_passphrase\n                else None,\n            )\n            if self.certstore.default_ca.has_expired():\n                logging.warning(\n                    \"The mitmproxy certificate authority has expired!\\n\"\n                    \"Please delete all CA-related files in your ~/.mitmproxy folder.\\n\"\n                    \"The CA will be regenerated automatically after restarting mitmproxy.\\n\"\n                    \"See https://docs.mitmproxy.org/stable/concepts-certificates/ for additional help.\",\n                )\n\n            for certspec in ctx.options.certs:\n                parts = certspec.split(\"=\", 1)\n                if len(parts) == 1:\n                    parts = [\"*\", parts[0]]\n\n                cert = Path(parts[1]).expanduser()\n                if not cert.exists():\n                    raise exceptions.OptionsError(\n                        f\"Certificate file does not exist: {cert}\"\n                    )\n                try:\n                    self.certstore.add_cert_file(\n                        parts[0],\n                        cert,\n                        passphrase=ctx.options.cert_passphrase.encode(\"utf8\")\n                        if ctx.options.cert_passphrase\n                        else None,\n                    )\n                except ValueError as e:\n                    raise exceptions.OptionsError(\n                        f\"Invalid certificate format for {cert}: {e}\"\n                    ) from e\n\n        if \"tls_ecdh_curve_client\" in updated or \"tls_ecdh_curve_server\" in updated:\n            for ecdh_curve in [\n                ctx.options.tls_ecdh_curve_client,\n                ctx.options.tls_ecdh_curve_server,\n            ]:\n                if ecdh_curve is not None:\n                    try:\n                        crypto.get_elliptic_curve(ecdh_curve)\n                    except Exception as e:\n                        raise exceptions.OptionsError(\n                            f\"Invalid ECDH curve: {ecdh_curve!r}\"\n                        ) from e\n\n    def get_cert(self, conn_context: context.Context) -> certs.CertStoreEntry:\n        \"\"\"\n        This function determines the Common Name (CN), Subject Alternative Names (SANs) and Organization Name\n        our certificate should have and then fetches a matching cert from the certstore.\n        \"\"\"\n        altnames: list[x509.GeneralName] = []\n        organization: str | None = None\n\n        # Use upstream certificate if available.\n        if ctx.options.upstream_cert and conn_context.server.certificate_list:\n            upstream_cert = conn_context.server.certificate_list[0]\n            if upstream_cert.cn:\n                altnames.append(_ip_or_dns_name(upstream_cert.cn))\n            altnames.extend(upstream_cert.altnames)\n            if upstream_cert.organization:\n                organization = upstream_cert.organization\n\n        # Add SNI or our local IP address.\n        if conn_context.client.sni:\n            altnames.append(_ip_or_dns_name(conn_context.client.sni))\n        else:\n            altnames.append(_ip_or_dns_name(conn_context.client.sockname[0]))\n\n        # If we already know of a server address, include that in the SANs as well.\n        if conn_context.server.address:\n            altnames.append(_ip_or_dns_name(conn_context.server.address[0]))\n\n        # only keep first occurrence of each hostname\n        altnames = list(dict.fromkeys(altnames))\n\n        # RFC 2818: If a subjectAltName extension of type dNSName is present, that MUST be used as the identity.\n        # In other words, the Common Name is irrelevant then.\n        cn = next((str(x.value) for x in altnames), None)\n        return self.certstore.get_cert(cn, altnames, organization)\n\n\ndef _ip_or_dns_name(val: str) -> x509.GeneralName:\n    \"\"\"Convert a string into either an x509.IPAddress or x509.DNSName object.\"\"\"\n    try:\n        ip = ipaddress.ip_address(val)\n    except ValueError:\n        return x509.DNSName(val.encode(\"idna\").decode())\n    else:\n        return x509.IPAddress(ip)\n", "mitmproxy/addons/proxyauth.py": "from __future__ import annotations\n\nimport binascii\nimport weakref\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom collections.abc import MutableMapping\nfrom typing import Optional\n\nimport ldap3\nimport passlib.apache\n\nfrom mitmproxy import connection\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import http\nfrom mitmproxy.net.http import status_codes\nfrom mitmproxy.proxy import mode_specs\nfrom mitmproxy.proxy.layers import modes\n\nREALM = \"mitmproxy\"\n\n\nclass ProxyAuth:\n    validator: Validator | None = None\n\n    def __init__(self) -> None:\n        self.authenticated: MutableMapping[connection.Client, tuple[str, str]] = (\n            weakref.WeakKeyDictionary()\n        )\n        \"\"\"Contains all connections that are permanently authenticated after an HTTP CONNECT\"\"\"\n\n    def load(self, loader):\n        loader.add_option(\n            \"proxyauth\",\n            Optional[str],\n            None,\n            \"\"\"\n            Require proxy authentication. Format:\n            \"username:pass\",\n            \"any\" to accept any user/pass combination,\n            \"@path\" to use an Apache htpasswd file,\n            or \"ldap[s]:url_server_ldap[:port]:dn_auth:password:dn_subtree[?search_filter_key=...]\" for LDAP authentication.\n            \"\"\",\n        )\n\n    def configure(self, updated):\n        if \"proxyauth\" in updated:\n            auth = ctx.options.proxyauth\n            if auth:\n                if auth == \"any\":\n                    self.validator = AcceptAll()\n                elif auth.startswith(\"@\"):\n                    self.validator = Htpasswd(auth)\n                elif ctx.options.proxyauth.startswith(\"ldap\"):\n                    self.validator = Ldap(auth)\n                elif \":\" in ctx.options.proxyauth:\n                    self.validator = SingleUser(auth)\n                else:\n                    raise exceptions.OptionsError(\"Invalid proxyauth specification.\")\n            else:\n                self.validator = None\n\n    def socks5_auth(self, data: modes.Socks5AuthData) -> None:\n        if self.validator and self.validator(data.username, data.password):\n            data.valid = True\n            self.authenticated[data.client_conn] = data.username, data.password\n\n    def http_connect(self, f: http.HTTPFlow) -> None:\n        if self.validator and self.authenticate_http(f):\n            # Make a note that all further requests over this connection are ok.\n            self.authenticated[f.client_conn] = f.metadata[\"proxyauth\"]\n\n    def requestheaders(self, f: http.HTTPFlow) -> None:\n        if self.validator:\n            # Is this connection authenticated by a previous HTTP CONNECT?\n            if f.client_conn in self.authenticated:\n                f.metadata[\"proxyauth\"] = self.authenticated[f.client_conn]\n            elif f.is_replay:\n                pass\n            else:\n                self.authenticate_http(f)\n\n    def authenticate_http(self, f: http.HTTPFlow) -> bool:\n        \"\"\"\n        Authenticate an HTTP request, returns if authentication was successful.\n\n        If valid credentials are found, the matching authentication header is removed.\n        In no or invalid credentials are found, flow.response is set to an error page.\n        \"\"\"\n        assert self.validator\n        username = None\n        password = None\n        is_valid = False\n\n        is_proxy = is_http_proxy(f)\n        auth_header = http_auth_header(is_proxy)\n        try:\n            auth_value = f.request.headers.get(auth_header, \"\")\n            scheme, username, password = parse_http_basic_auth(auth_value)\n            is_valid = self.validator(username, password)\n        except Exception:\n            pass\n\n        if is_valid:\n            f.metadata[\"proxyauth\"] = (username, password)\n            del f.request.headers[auth_header]\n            return True\n        else:\n            f.response = make_auth_required_response(is_proxy)\n            return False\n\n\ndef make_auth_required_response(is_proxy: bool) -> http.Response:\n    if is_proxy:\n        status_code = status_codes.PROXY_AUTH_REQUIRED\n        headers = {\"Proxy-Authenticate\": f'Basic realm=\"{REALM}\"'}\n    else:\n        status_code = status_codes.UNAUTHORIZED\n        headers = {\"WWW-Authenticate\": f'Basic realm=\"{REALM}\"'}\n\n    reason = http.status_codes.RESPONSES[status_code]\n    return http.Response.make(\n        status_code,\n        (\n            f\"<html>\"\n            f\"<head><title>{status_code} {reason}</title></head>\"\n            f\"<body><h1>{status_code} {reason}</h1></body>\"\n            f\"</html>\"\n        ),\n        headers,\n    )\n\n\ndef http_auth_header(is_proxy: bool) -> str:\n    if is_proxy:\n        return \"Proxy-Authorization\"\n    else:\n        return \"Authorization\"\n\n\ndef is_http_proxy(f: http.HTTPFlow) -> bool:\n    \"\"\"\n    Returns:\n        - True, if authentication is done as if mitmproxy is a proxy\n        - False, if authentication is done as if mitmproxy is an HTTP server\n    \"\"\"\n    return isinstance(\n        f.client_conn.proxy_mode, (mode_specs.RegularMode, mode_specs.UpstreamMode)\n    )\n\n\ndef mkauth(username: str, password: str, scheme: str = \"basic\") -> str:\n    \"\"\"\n    Craft a basic auth string\n    \"\"\"\n    v = binascii.b2a_base64((username + \":\" + password).encode(\"utf8\")).decode(\"ascii\")\n    return scheme + \" \" + v\n\n\ndef parse_http_basic_auth(s: str) -> tuple[str, str, str]:\n    \"\"\"\n    Parse a basic auth header.\n    Raises a ValueError if the input is invalid.\n    \"\"\"\n    scheme, authinfo = s.split()\n    if scheme.lower() != \"basic\":\n        raise ValueError(\"Unknown scheme\")\n    try:\n        user, password = (\n            binascii.a2b_base64(authinfo.encode()).decode(\"utf8\", \"replace\").split(\":\")\n        )\n    except binascii.Error as e:\n        raise ValueError(str(e))\n    return scheme, user, password\n\n\nclass Validator(ABC):\n    \"\"\"Base class for all username/password validators.\"\"\"\n\n    @abstractmethod\n    def __call__(self, username: str, password: str) -> bool:\n        raise NotImplementedError\n\n\nclass AcceptAll(Validator):\n    def __call__(self, username: str, password: str) -> bool:\n        return True\n\n\nclass SingleUser(Validator):\n    def __init__(self, proxyauth: str):\n        try:\n            self.username, self.password = proxyauth.split(\":\")\n        except ValueError:\n            raise exceptions.OptionsError(\"Invalid single-user auth specification.\")\n\n    def __call__(self, username: str, password: str) -> bool:\n        return self.username == username and self.password == password\n\n\nclass Htpasswd(Validator):\n    def __init__(self, proxyauth: str):\n        path = proxyauth[1:]\n        try:\n            self.htpasswd = passlib.apache.HtpasswdFile(path)\n        except (ValueError, OSError):\n            raise exceptions.OptionsError(f\"Could not open htpasswd file: {path}\")\n\n    def __call__(self, username: str, password: str) -> bool:\n        return self.htpasswd.check_password(username, password)\n\n\nclass Ldap(Validator):\n    conn: ldap3.Connection\n    server: ldap3.Server\n    dn_subtree: str\n    filter_key: str\n\n    def __init__(self, proxyauth: str):\n        (\n            use_ssl,\n            url,\n            port,\n            ldap_user,\n            ldap_pass,\n            self.dn_subtree,\n            self.filter_key,\n        ) = self.parse_spec(proxyauth)\n        server = ldap3.Server(url, port=port, use_ssl=use_ssl)\n        conn = ldap3.Connection(server, ldap_user, ldap_pass, auto_bind=True)\n        self.conn = conn\n        self.server = server\n\n    @staticmethod\n    def parse_spec(spec: str) -> tuple[bool, str, int | None, str, str, str, str]:\n        try:\n            if spec.count(\":\") > 4:\n                (\n                    security,\n                    url,\n                    port_str,\n                    ldap_user,\n                    ldap_pass,\n                    dn_subtree,\n                ) = spec.split(\":\")\n                port = int(port_str)\n            else:\n                security, url, ldap_user, ldap_pass, dn_subtree = spec.split(\":\")\n                port = None\n\n            if \"?\" in dn_subtree:\n                dn_subtree, search_str = dn_subtree.split(\"?\")\n                key, value = search_str.split(\"=\")\n                if key == \"search_filter_key\":\n                    search_filter_key = value\n                else:\n                    raise ValueError\n            else:\n                search_filter_key = \"cn\"\n\n            if security == \"ldaps\":\n                use_ssl = True\n            elif security == \"ldap\":\n                use_ssl = False\n            else:\n                raise ValueError\n\n            return (\n                use_ssl,\n                url,\n                port,\n                ldap_user,\n                ldap_pass,\n                dn_subtree,\n                search_filter_key,\n            )\n        except ValueError:\n            raise exceptions.OptionsError(f\"Invalid LDAP specification: {spec}\")\n\n    def __call__(self, username: str, password: str) -> bool:\n        if not username or not password:\n            return False\n        self.conn.search(self.dn_subtree, f\"({self.filter_key}={username})\")\n        if self.conn.response:\n            c = ldap3.Connection(\n                self.server, self.conn.response[0][\"dn\"], password, auto_bind=True\n            )\n            if c:\n                return True\n        return False\n", "mitmproxy/addons/server_side_events.py": "import logging\n\nfrom mitmproxy import http\n\n\nclass ServerSideEvents:\n    \"\"\"\n    Server-Side Events are currently swallowed if there's no streaming,\n    see https://github.com/mitmproxy/mitmproxy/issues/4469.\n\n    Until this bug is fixed, this addon warns the user about this.\n    \"\"\"\n\n    def response(self, flow: http.HTTPFlow):\n        assert flow.response\n        is_sse = flow.response.headers.get(\"content-type\", \"\").startswith(\n            \"text/event-stream\"\n        )\n        if is_sse and not flow.response.stream:\n            logging.warning(\n                \"mitmproxy currently does not support server side events. As a workaround, you can enable response \"\n                \"streaming for such flows: https://github.com/mitmproxy/mitmproxy/issues/4469\"\n            )\n", "mitmproxy/addons/serverplayback.py": "import hashlib\nimport logging\nimport urllib\nfrom collections.abc import Hashable\nfrom collections.abc import Sequence\nfrom typing import Any\n\nimport mitmproxy.types\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import hooks\nfrom mitmproxy import http\nfrom mitmproxy import io\n\nlogger = logging.getLogger(__name__)\n\nHASH_OPTIONS = [\n    \"server_replay_ignore_content\",\n    \"server_replay_ignore_host\",\n    \"server_replay_ignore_params\",\n    \"server_replay_ignore_payload_params\",\n    \"server_replay_ignore_port\",\n    \"server_replay_use_headers\",\n]\n\n\nclass ServerPlayback:\n    flowmap: dict[Hashable, list[http.HTTPFlow]]\n    configured: bool\n\n    def __init__(self):\n        self.flowmap = {}\n        self.configured = False\n\n    def load(self, loader):\n        loader.add_option(\n            \"server_replay_kill_extra\",\n            bool,\n            False,\n            \"Kill extra requests during replay (for which no replayable response was found).\"\n            \"[Deprecated, prefer to use server_replay_extra='kill']\",\n        )\n        loader.add_option(\n            \"server_replay_extra\",\n            str,\n            \"forward\",\n            \"Behaviour for extra requests during replay for which no replayable response was found. \"\n            \"Setting a numeric string value will return an empty HTTP response with the respective status code.\",\n            choices=[\"forward\", \"kill\", \"204\", \"400\", \"404\", \"500\"],\n        )\n        loader.add_option(\n            \"server_replay_reuse\",\n            bool,\n            False,\n            \"\"\"\n            Don't remove flows from server replay state after use. This makes it\n            possible to replay same response multiple times.\n            \"\"\",\n        )\n        loader.add_option(\n            \"server_replay_nopop\",\n            bool,\n            False,\n            \"\"\"\n            Deprecated alias for `server_replay_reuse`.\n            \"\"\",\n        )\n        loader.add_option(\n            \"server_replay_refresh\",\n            bool,\n            True,\n            \"\"\"\n            Refresh server replay responses by adjusting date, expires and\n            last-modified headers, as well as adjusting cookie expiration.\n            \"\"\",\n        )\n        loader.add_option(\n            \"server_replay_use_headers\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Request headers that need to match while searching for a saved flow\n            to replay.\n            \"\"\",\n        )\n        loader.add_option(\n            \"server_replay\",\n            Sequence[str],\n            [],\n            \"Replay server responses from a saved file.\",\n        )\n        loader.add_option(\n            \"server_replay_ignore_content\",\n            bool,\n            False,\n            \"Ignore request content while searching for a saved flow to replay.\",\n        )\n        loader.add_option(\n            \"server_replay_ignore_params\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Request parameters to be ignored while searching for a saved flow\n            to replay.\n            \"\"\",\n        )\n        loader.add_option(\n            \"server_replay_ignore_payload_params\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Request payload parameters (application/x-www-form-urlencoded or\n            multipart/form-data) to be ignored while searching for a saved flow\n            to replay.\n            \"\"\",\n        )\n        loader.add_option(\n            \"server_replay_ignore_host\",\n            bool,\n            False,\n            \"\"\"\n            Ignore request destination host while searching for a saved flow\n            to replay.\n            \"\"\",\n        )\n        loader.add_option(\n            \"server_replay_ignore_port\",\n            bool,\n            False,\n            \"\"\"\n            Ignore request destination port while searching for a saved flow\n            to replay.\n            \"\"\",\n        )\n\n    @command.command(\"replay.server\")\n    def load_flows(self, flows: Sequence[flow.Flow]) -> None:\n        \"\"\"\n        Replay server responses from flows.\n        \"\"\"\n        self.flowmap = {}\n        self.add_flows(flows)\n\n    @command.command(\"replay.server.add\")\n    def add_flows(self, flows: Sequence[flow.Flow]) -> None:\n        \"\"\"\n        Add responses from flows to server replay list.\n        \"\"\"\n        for f in flows:\n            if isinstance(f, http.HTTPFlow):\n                lst = self.flowmap.setdefault(self._hash(f), [])\n                lst.append(f)\n        ctx.master.addons.trigger(hooks.UpdateHook([]))\n\n    @command.command(\"replay.server.file\")\n    def load_file(self, path: mitmproxy.types.Path) -> None:\n        try:\n            flows = io.read_flows_from_paths([path])\n        except exceptions.FlowReadException as e:\n            raise exceptions.CommandError(str(e))\n        self.load_flows(flows)\n\n    @command.command(\"replay.server.stop\")\n    def clear(self) -> None:\n        \"\"\"\n        Stop server replay.\n        \"\"\"\n        self.flowmap = {}\n        ctx.master.addons.trigger(hooks.UpdateHook([]))\n\n    @command.command(\"replay.server.count\")\n    def count(self) -> int:\n        return sum(len(i) for i in self.flowmap.values())\n\n    def _hash(self, flow: http.HTTPFlow) -> Hashable:\n        \"\"\"\n        Calculates a loose hash of the flow request.\n        \"\"\"\n        r = flow.request\n        _, _, path, _, query, _ = urllib.parse.urlparse(r.url)\n        queriesArray = urllib.parse.parse_qsl(query, keep_blank_values=True)\n\n        key: list[Any] = [str(r.scheme), str(r.method), str(path)]\n        if not ctx.options.server_replay_ignore_content:\n            if ctx.options.server_replay_ignore_payload_params and r.multipart_form:\n                key.extend(\n                    (k, v)\n                    for k, v in r.multipart_form.items(multi=True)\n                    if k.decode(errors=\"replace\")\n                    not in ctx.options.server_replay_ignore_payload_params\n                )\n            elif ctx.options.server_replay_ignore_payload_params and r.urlencoded_form:\n                key.extend(\n                    (k, v)\n                    for k, v in r.urlencoded_form.items(multi=True)\n                    if k not in ctx.options.server_replay_ignore_payload_params\n                )\n            else:\n                key.append(str(r.raw_content))\n\n        if not ctx.options.server_replay_ignore_host:\n            key.append(r.pretty_host)\n        if not ctx.options.server_replay_ignore_port:\n            key.append(r.port)\n\n        filtered = []\n        ignore_params = ctx.options.server_replay_ignore_params or []\n        for p in queriesArray:\n            if p[0] not in ignore_params:\n                filtered.append(p)\n        for p in filtered:\n            key.append(p[0])\n            key.append(p[1])\n\n        if ctx.options.server_replay_use_headers:\n            headers = []\n            for i in ctx.options.server_replay_use_headers:\n                v = r.headers.get(i)\n                headers.append((i, v))\n            key.append(headers)\n        return hashlib.sha256(repr(key).encode(\"utf8\", \"surrogateescape\")).digest()\n\n    def next_flow(self, flow: http.HTTPFlow) -> http.HTTPFlow | None:\n        \"\"\"\n        Returns the next flow object, or None if no matching flow was\n        found.\n        \"\"\"\n        hash = self._hash(flow)\n        if hash in self.flowmap:\n            if ctx.options.server_replay_reuse or ctx.options.server_replay_nopop:\n                return next(\n                    (flow for flow in self.flowmap[hash] if flow.response), None\n                )\n            else:\n                ret = self.flowmap[hash].pop(0)\n                while not ret.response:\n                    if self.flowmap[hash]:\n                        ret = self.flowmap[hash].pop(0)\n                    else:\n                        del self.flowmap[hash]\n                        return None\n                if not self.flowmap[hash]:\n                    del self.flowmap[hash]\n                return ret\n        else:\n            return None\n\n    def configure(self, updated):\n        if ctx.options.server_replay_kill_extra:\n            logger.warning(\n                \"server_replay_kill_extra has been deprecated, \"\n                \"please update your config to use server_replay_extra='kill'.\"\n            )\n        if ctx.options.server_replay_nopop:  # pragma: no cover\n            logger.error(\n                \"server_replay_nopop has been renamed to server_replay_reuse, please update your config.\"\n            )\n        if not self.configured and ctx.options.server_replay:\n            self.configured = True\n            try:\n                flows = io.read_flows_from_paths(ctx.options.server_replay)\n            except exceptions.FlowReadException as e:\n                raise exceptions.OptionsError(str(e))\n            self.load_flows(flows)\n        if any(option in updated for option in HASH_OPTIONS):\n            self.recompute_hashes()\n\n    def recompute_hashes(self) -> None:\n        \"\"\"\n        Rebuild flowmap if the hashing method has changed during execution,\n        see https://github.com/mitmproxy/mitmproxy/issues/4506\n        \"\"\"\n        flows = [flow for lst in self.flowmap.values() for flow in lst]\n        self.load_flows(flows)\n\n    def request(self, f: http.HTTPFlow) -> None:\n        if self.flowmap:\n            rflow = self.next_flow(f)\n            if rflow:\n                assert rflow.response\n                response = rflow.response.copy()\n                if ctx.options.server_replay_refresh:\n                    response.refresh()\n                f.response = response\n                f.is_replay = \"response\"\n            elif (\n                ctx.options.server_replay_kill_extra\n                or ctx.options.server_replay_extra == \"kill\"\n            ):\n                logging.warning(\n                    \"server_playback: killed non-replay request {}\".format(\n                        f.request.url\n                    )\n                )\n                f.kill()\n            elif ctx.options.server_replay_extra != \"forward\":\n                logging.warning(\n                    \"server_playback: returned {} non-replay request {}\".format(\n                        ctx.options.server_replay_extra, f.request.url\n                    )\n                )\n                f.response = http.Response.make(int(ctx.options.server_replay_extra))\n                f.is_replay = \"response\"\n", "mitmproxy/addons/mapremote.py": "import re\nfrom collections.abc import Sequence\nfrom typing import NamedTuple\n\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy.utils.spec import parse_spec\n\n\nclass MapRemoteSpec(NamedTuple):\n    matches: flowfilter.TFilter\n    subject: str\n    replacement: str\n\n\ndef parse_map_remote_spec(option: str) -> MapRemoteSpec:\n    spec = MapRemoteSpec(*parse_spec(option))\n\n    try:\n        re.compile(spec.subject)\n    except re.error as e:\n        raise ValueError(f\"Invalid regular expression {spec.subject!r} ({e})\")\n\n    return spec\n\n\nclass MapRemote:\n    def __init__(self) -> None:\n        self.replacements: list[MapRemoteSpec] = []\n\n    def load(self, loader):\n        loader.add_option(\n            \"map_remote\",\n            Sequence[str],\n            [],\n            \"\"\"\n            Map remote resources to another remote URL using a pattern of the form\n            \"[/flow-filter]/url-regex/replacement\", where the separator can\n            be any character.\n            \"\"\",\n        )\n\n    def configure(self, updated):\n        if \"map_remote\" in updated:\n            self.replacements = []\n            for option in ctx.options.map_remote:\n                try:\n                    spec = parse_map_remote_spec(option)\n                except ValueError as e:\n                    raise exceptions.OptionsError(\n                        f\"Cannot parse map_remote option {option}: {e}\"\n                    ) from e\n\n                self.replacements.append(spec)\n\n    def request(self, flow: http.HTTPFlow) -> None:\n        if flow.response or flow.error or not flow.live:\n            return\n        for spec in self.replacements:\n            if spec.matches(flow):\n                url = flow.request.pretty_url\n                new_url = re.sub(spec.subject, spec.replacement, url)\n                # this is a bit messy: setting .url also updates the host header,\n                # so we really only do that if the replacement affected the URL.\n                if url != new_url:\n                    flow.request.url = new_url  # type: ignore\n", "mitmproxy/addons/savehar.py": "\"\"\"Write flow objects to a HAR file\"\"\"\n\nimport base64\nimport json\nimport logging\nimport zlib\nfrom collections.abc import Sequence\nfrom datetime import datetime\nfrom datetime import timezone\nfrom typing import Any\n\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy import types\nfrom mitmproxy import version\nfrom mitmproxy.addonmanager import Loader\nfrom mitmproxy.connection import Server\nfrom mitmproxy.coretypes.multidict import _MultiDict\nfrom mitmproxy.log import ALERT\nfrom mitmproxy.utils import human\nfrom mitmproxy.utils import strutils\n\nlogger = logging.getLogger(__name__)\n\n\nclass SaveHar:\n    def __init__(self) -> None:\n        self.flows: list[flow.Flow] = []\n        self.filt: flowfilter.TFilter | None = None\n\n    @command.command(\"save.har\")\n    def export_har(self, flows: Sequence[flow.Flow], path: types.Path) -> None:\n        \"\"\"Export flows to an HAR (HTTP Archive) file.\"\"\"\n\n        har = json.dumps(self.make_har(flows), indent=4).encode()\n\n        if path.endswith(\".zhar\"):\n            har = zlib.compress(har, 9)\n\n        with open(path, \"wb\") as f:\n            f.write(har)\n\n        logging.log(ALERT, f\"HAR file saved ({human.pretty_size(len(har))} bytes).\")\n\n    def make_har(self, flows: Sequence[flow.Flow]) -> dict:\n        entries = []\n        skipped = 0\n        # A list of server seen till now is maintained so we can avoid\n        # using 'connect' time for entries that use an existing connection.\n        servers_seen: set[Server] = set()\n\n        for f in flows:\n            if isinstance(f, http.HTTPFlow):\n                entries.append(self.flow_entry(f, servers_seen))\n            else:\n                skipped += 1\n\n        if skipped > 0:\n            logger.info(f\"Skipped {skipped} flows that weren't HTTP flows.\")\n\n        return {\n            \"log\": {\n                \"version\": \"1.2\",\n                \"creator\": {\n                    \"name\": \"mitmproxy\",\n                    \"version\": version.VERSION,\n                    \"comment\": \"\",\n                },\n                \"pages\": [],\n                \"entries\": entries,\n            }\n        }\n\n    def load(self, loader: Loader):\n        loader.add_option(\n            \"hardump\",\n            str,\n            \"\",\n            \"\"\"\n            Save a HAR file with all flows on exit.\n            You may select particular flows by setting save_stream_filter.\n            For mitmdump, enabling this option will mean that flows are kept in memory.\n            \"\"\",\n        )\n\n    def configure(self, updated):\n        if \"save_stream_filter\" in updated:\n            if ctx.options.save_stream_filter:\n                try:\n                    self.filt = flowfilter.parse(ctx.options.save_stream_filter)\n                except ValueError as e:\n                    raise exceptions.OptionsError(str(e)) from e\n            else:\n                self.filt = None\n\n        if \"hardump\" in updated:\n            if not ctx.options.hardump:\n                self.flows = []\n\n    def response(self, flow: http.HTTPFlow) -> None:\n        # websocket flows will receive a websocket_end,\n        # we don't want to persist them here already\n        if flow.websocket is None:\n            self._save_flow(flow)\n\n    def error(self, flow: http.HTTPFlow) -> None:\n        self.response(flow)\n\n    def websocket_end(self, flow: http.HTTPFlow) -> None:\n        self._save_flow(flow)\n\n    def _save_flow(self, flow: http.HTTPFlow) -> None:\n        if ctx.options.hardump:\n            flow_matches = self.filt is None or self.filt(flow)\n            if flow_matches:\n                self.flows.append(flow)\n\n    def done(self):\n        if ctx.options.hardump:\n            if ctx.options.hardump == \"-\":\n                har = self.make_har(self.flows)\n                print(json.dumps(har, indent=4))\n            else:\n                self.export_har(self.flows, ctx.options.hardump)\n\n    def flow_entry(self, flow: http.HTTPFlow, servers_seen: set[Server]) -> dict:\n        \"\"\"Creates HAR entry from flow\"\"\"\n\n        if flow.server_conn in servers_seen:\n            connect_time = -1.0\n            ssl_time = -1.0\n        elif flow.server_conn.timestamp_tcp_setup:\n            assert flow.server_conn.timestamp_start\n            connect_time = 1000 * (\n                flow.server_conn.timestamp_tcp_setup - flow.server_conn.timestamp_start\n            )\n\n            if flow.server_conn.timestamp_tls_setup:\n                ssl_time = 1000 * (\n                    flow.server_conn.timestamp_tls_setup\n                    - flow.server_conn.timestamp_tcp_setup\n                )\n            else:\n                ssl_time = -1.0\n            servers_seen.add(flow.server_conn)\n        else:\n            connect_time = -1.0\n            ssl_time = -1.0\n\n        if flow.request.timestamp_end:\n            send = 1000 * (flow.request.timestamp_end - flow.request.timestamp_start)\n        else:\n            send = 0\n\n        if flow.response and flow.request.timestamp_end:\n            wait = 1000 * (flow.response.timestamp_start - flow.request.timestamp_end)\n        else:\n            wait = 0\n\n        if flow.response and flow.response.timestamp_end:\n            receive = 1000 * (\n                flow.response.timestamp_end - flow.response.timestamp_start\n            )\n\n        else:\n            receive = 0\n\n        timings: dict[str, float | None] = {\n            \"connect\": connect_time,\n            \"ssl\": ssl_time,\n            \"send\": send,\n            \"receive\": receive,\n            \"wait\": wait,\n        }\n\n        if flow.response:\n            response_body_size = (\n                len(flow.response.raw_content) if flow.response.raw_content else 0\n            )\n            response_body_decoded_size = (\n                len(flow.response.content) if flow.response.content else 0\n            )\n            response_body_compression = response_body_decoded_size - response_body_size\n            response = {\n                \"status\": flow.response.status_code,\n                \"statusText\": flow.response.reason,\n                \"httpVersion\": flow.response.http_version,\n                \"cookies\": self.format_response_cookies(flow.response),\n                \"headers\": self.format_multidict(flow.response.headers),\n                \"content\": {\n                    \"size\": response_body_size,\n                    \"compression\": response_body_compression,\n                    \"mimeType\": flow.response.headers.get(\"Content-Type\", \"\"),\n                },\n                \"redirectURL\": flow.response.headers.get(\"Location\", \"\"),\n                \"headersSize\": len(str(flow.response.headers)),\n                \"bodySize\": response_body_size,\n            }\n            if flow.response.content and strutils.is_mostly_bin(flow.response.content):\n                response[\"content\"][\"text\"] = base64.b64encode(\n                    flow.response.content\n                ).decode()\n                response[\"content\"][\"encoding\"] = \"base64\"\n            else:\n                text_content = flow.response.get_text(strict=False)\n                if text_content is None:\n                    response[\"content\"][\"text\"] = \"\"\n                else:\n                    response[\"content\"][\"text\"] = text_content\n        else:\n            response = {\n                \"status\": 0,\n                \"statusText\": \"\",\n                \"httpVersion\": \"\",\n                \"headers\": [],\n                \"cookies\": [],\n                \"content\": {},\n                \"redirectURL\": \"\",\n                \"headersSize\": -1,\n                \"bodySize\": -1,\n                \"_transferSize\": 0,\n                \"_error\": None,\n            }\n            if flow.error:\n                response[\"_error\"] = flow.error.msg\n\n        if flow.request.method == \"CONNECT\":\n            url = f\"https://{flow.request.pretty_url}/\"\n        else:\n            url = flow.request.pretty_url\n\n        entry: dict[str, Any] = {\n            \"startedDateTime\": datetime.fromtimestamp(\n                flow.request.timestamp_start, timezone.utc\n            ).isoformat(),\n            \"time\": sum(v for v in timings.values() if v is not None and v >= 0),\n            \"request\": {\n                \"method\": flow.request.method,\n                \"url\": url,\n                \"httpVersion\": flow.request.http_version,\n                \"cookies\": self.format_multidict(flow.request.cookies),\n                \"headers\": self.format_multidict(flow.request.headers),\n                \"queryString\": self.format_multidict(flow.request.query),\n                \"headersSize\": len(str(flow.request.headers)),\n                \"bodySize\": len(flow.request.content) if flow.request.content else 0,\n            },\n            \"response\": response,\n            \"cache\": {},\n            \"timings\": timings,\n        }\n\n        if flow.request.method in [\"POST\", \"PUT\", \"PATCH\"]:\n            params = self.format_multidict(flow.request.urlencoded_form)\n            entry[\"request\"][\"postData\"] = {\n                \"mimeType\": flow.request.headers.get(\"Content-Type\", \"\"),\n                \"text\": flow.request.get_text(strict=False),\n                \"params\": params,\n            }\n\n        if flow.server_conn.peername:\n            entry[\"serverIPAddress\"] = str(flow.server_conn.peername[0])\n\n        websocket_messages = []\n        if flow.websocket:\n            for message in flow.websocket.messages:\n                if message.is_text:\n                    data = message.text\n                else:\n                    data = base64.b64encode(message.content).decode()\n                websocket_message = {\n                    \"type\": \"send\" if message.from_client else \"receive\",\n                    \"time\": message.timestamp,\n                    \"opcode\": message.type.value,\n                    \"data\": data,\n                }\n                websocket_messages.append(websocket_message)\n\n            entry[\"_resourceType\"] = \"websocket\"\n            entry[\"_webSocketMessages\"] = websocket_messages\n        return entry\n\n    def format_response_cookies(self, response: http.Response) -> list[dict]:\n        \"\"\"Formats the response's cookie header to list of cookies\"\"\"\n        cookie_list = response.cookies.items(multi=True)\n        rv = []\n        for name, (value, attrs) in cookie_list:\n            cookie = {\n                \"name\": name,\n                \"value\": value,\n                \"path\": attrs.get(\"path\", \"/\"),\n                \"domain\": attrs.get(\"domain\", \"\"),\n                \"httpOnly\": \"httpOnly\" in attrs,\n                \"secure\": \"secure\" in attrs,\n            }\n            # TODO: handle expires attribute here.\n            # This is not quite trivial because we need to parse random date formats.\n            # For now, we just ignore the attribute.\n\n            if \"sameSite\" in attrs:\n                cookie[\"sameSite\"] = attrs[\"sameSite\"]\n\n            rv.append(cookie)\n        return rv\n\n    def format_multidict(self, obj: _MultiDict[str, str]) -> list[dict]:\n        return [{\"name\": k, \"value\": v} for k, v in obj.items(multi=True)]\n", "mitmproxy/addons/command_history.py": "import logging\nimport os\nimport pathlib\nfrom collections.abc import Sequence\n\nfrom mitmproxy import command\nfrom mitmproxy import ctx\n\n\nclass CommandHistory:\n    VACUUM_SIZE = 1024\n\n    def __init__(self) -> None:\n        self.history: list[str] = []\n        self.filtered_history: list[str] = [\"\"]\n        self.current_index: int = 0\n\n    def load(self, loader):\n        loader.add_option(\n            \"command_history\",\n            bool,\n            True,\n            \"\"\"Persist command history between mitmproxy invocations.\"\"\",\n        )\n\n    @property\n    def history_file(self) -> pathlib.Path:\n        return pathlib.Path(os.path.expanduser(ctx.options.confdir)) / \"command_history\"\n\n    def running(self):\n        # FIXME: We have a weird bug where the contract for configure is not followed and it is never called with\n        # confdir or command_history as updated.\n        self.configure(\"command_history\")  # pragma: no cover\n\n    def configure(self, updated):\n        if \"command_history\" in updated or \"confdir\" in updated:\n            if ctx.options.command_history and self.history_file.is_file():\n                self.history = self.history_file.read_text().splitlines()\n                self.set_filter(\"\")\n\n    def done(self):\n        if ctx.options.command_history and len(self.history) >= self.VACUUM_SIZE:\n            # vacuum history so that it doesn't grow indefinitely.\n            history_str = \"\\n\".join(self.history[-self.VACUUM_SIZE // 2 :]) + \"\\n\"\n            try:\n                self.history_file.write_text(history_str)\n            except Exception as e:\n                logging.warning(f\"Failed writing to {self.history_file}: {e}\")\n\n    @command.command(\"commands.history.add\")\n    def add_command(self, command: str) -> None:\n        if not command.strip():\n            return\n\n        self.history.append(command)\n        if ctx.options.command_history:\n            try:\n                with self.history_file.open(\"a\") as f:\n                    f.write(f\"{command}\\n\")\n            except Exception as e:\n                logging.warning(f\"Failed writing to {self.history_file}: {e}\")\n\n        self.set_filter(\"\")\n\n    @command.command(\"commands.history.get\")\n    def get_history(self) -> Sequence[str]:\n        \"\"\"Get the entire command history.\"\"\"\n        return self.history.copy()\n\n    @command.command(\"commands.history.clear\")\n    def clear_history(self):\n        if self.history_file.exists():\n            try:\n                self.history_file.unlink()\n            except Exception as e:\n                logging.warning(f\"Failed deleting {self.history_file}: {e}\")\n        self.history = []\n        self.set_filter(\"\")\n\n    # Functionality to provide a filtered list that can be iterated through.\n\n    @command.command(\"commands.history.filter\")\n    def set_filter(self, prefix: str) -> None:\n        self.filtered_history = [cmd for cmd in self.history if cmd.startswith(prefix)]\n        self.filtered_history.append(prefix)\n        self.current_index = len(self.filtered_history) - 1\n\n    @command.command(\"commands.history.next\")\n    def get_next(self) -> str:\n        self.current_index = min(self.current_index + 1, len(self.filtered_history) - 1)\n        return self.filtered_history[self.current_index]\n\n    @command.command(\"commands.history.prev\")\n    def get_prev(self) -> str:\n        self.current_index = max(0, self.current_index - 1)\n        return self.filtered_history[self.current_index]\n", "mitmproxy/addons/anticomp.py": "from mitmproxy import ctx\n\n\nclass AntiComp:\n    def load(self, loader):\n        loader.add_option(\n            \"anticomp\",\n            bool,\n            False,\n            \"Try to convince servers to send us un-compressed data.\",\n        )\n\n    def request(self, flow):\n        if ctx.options.anticomp:\n            flow.request.anticomp()\n", "mitmproxy/addons/clientplayback.py": "from __future__ import annotations\n\nimport asyncio\nimport logging\nimport time\nfrom collections.abc import Sequence\nfrom types import TracebackType\nfrom typing import cast\nfrom typing import Literal\n\nimport mitmproxy.types\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy import io\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.connection import Server\nfrom mitmproxy.hooks import UpdateHook\nfrom mitmproxy.log import ALERT\nfrom mitmproxy.options import Options\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layers\nfrom mitmproxy.proxy import server\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.layer import CommandGenerator\nfrom mitmproxy.proxy.layers.http import HTTPMode\nfrom mitmproxy.proxy.mode_specs import UpstreamMode\nfrom mitmproxy.utils import asyncio_utils\n\nlogger = logging.getLogger(__name__)\n\n\nclass MockServer(layers.http.HttpConnection):\n    \"\"\"\n    A mock HTTP \"server\" that just pretends it received a full HTTP request,\n    which is then processed by the proxy core.\n    \"\"\"\n\n    flow: http.HTTPFlow\n\n    def __init__(self, flow: http.HTTPFlow, context: Context):\n        super().__init__(context, context.client)\n        self.flow = flow\n\n    def _handle_event(self, event: events.Event) -> CommandGenerator[None]:\n        if isinstance(event, events.Start):\n            content = self.flow.request.raw_content\n            self.flow.request.timestamp_start = self.flow.request.timestamp_end = (\n                time.time()\n            )\n            yield layers.http.ReceiveHttp(\n                layers.http.RequestHeaders(\n                    1,\n                    self.flow.request,\n                    end_stream=not (content or self.flow.request.trailers),\n                    replay_flow=self.flow,\n                )\n            )\n            if content:\n                yield layers.http.ReceiveHttp(layers.http.RequestData(1, content))\n            if self.flow.request.trailers:  # pragma: no cover\n                # TODO: Cover this once we support HTTP/1 trailers.\n                yield layers.http.ReceiveHttp(\n                    layers.http.RequestTrailers(1, self.flow.request.trailers)\n                )\n            yield layers.http.ReceiveHttp(layers.http.RequestEndOfMessage(1))\n        elif isinstance(\n            event,\n            (\n                layers.http.ResponseHeaders,\n                layers.http.ResponseData,\n                layers.http.ResponseTrailers,\n                layers.http.ResponseEndOfMessage,\n                layers.http.ResponseProtocolError,\n            ),\n        ):\n            pass\n        else:  # pragma: no cover\n            logger.warning(f\"Unexpected event during replay: {event}\")\n\n\nclass ReplayHandler(server.ConnectionHandler):\n    layer: layers.HttpLayer\n\n    def __init__(self, flow: http.HTTPFlow, options: Options) -> None:\n        client = flow.client_conn.copy()\n        client.state = ConnectionState.OPEN\n\n        context = Context(client, options)\n        context.server = Server(address=(flow.request.host, flow.request.port))\n        if flow.request.scheme == \"https\":\n            context.server.tls = True\n            context.server.sni = flow.request.pretty_host\n        if options.mode and options.mode[0].startswith(\"upstream:\"):\n            mode = UpstreamMode.parse(options.mode[0])\n            assert isinstance(mode, UpstreamMode)  # remove once mypy supports Self.\n            context.server.via = flow.server_conn.via = (mode.scheme, mode.address)\n\n        super().__init__(context)\n\n        if options.mode and options.mode[0].startswith(\"upstream:\"):\n            self.layer = layers.HttpLayer(context, HTTPMode.upstream)\n        else:\n            self.layer = layers.HttpLayer(context, HTTPMode.transparent)\n        self.layer.connections[client] = MockServer(flow, context.fork())\n        self.flow = flow\n        self.done = asyncio.Event()\n\n    async def replay(self) -> None:\n        self.server_event(events.Start())\n        await self.done.wait()\n\n    def log(\n        self,\n        message: str,\n        level: int = logging.INFO,\n        exc_info: Literal[True]\n        | tuple[type[BaseException] | None, BaseException | None, TracebackType | None]\n        | None = None,\n    ) -> None:\n        assert isinstance(level, int)\n        logger.log(level=level, msg=f\"[replay] {message}\")\n\n    async def handle_hook(self, hook: commands.StartHook) -> None:\n        (data,) = hook.args()\n        await ctx.master.addons.handle_lifecycle(hook)\n        if isinstance(data, flow.Flow):\n            await data.wait_for_resume()\n        if isinstance(hook, (layers.http.HttpResponseHook, layers.http.HttpErrorHook)):\n            if self.transports:\n                # close server connections\n                for x in self.transports.values():\n                    if x.handler:\n                        x.handler.cancel()\n                await asyncio.wait(\n                    [x.handler for x in self.transports.values() if x.handler]\n                )\n            # signal completion\n            self.done.set()\n\n\nclass ClientPlayback:\n    playback_task: asyncio.Task | None = None\n    inflight: http.HTTPFlow | None\n    queue: asyncio.Queue\n    options: Options\n    replay_tasks: set[asyncio.Task]\n\n    def __init__(self):\n        self.queue = asyncio.Queue()\n        self.inflight = None\n        self.task = None\n        self.replay_tasks = set()\n\n    def running(self):\n        self.options = ctx.options\n        self.playback_task = asyncio_utils.create_task(\n            self.playback(), name=\"client playback\"\n        )\n\n    async def done(self):\n        if self.playback_task:\n            self.playback_task.cancel()\n            try:\n                await self.playback_task\n            except asyncio.CancelledError:\n                pass\n\n    async def playback(self):\n        while True:\n            self.inflight = await self.queue.get()\n            try:\n                assert self.inflight\n                h = ReplayHandler(self.inflight, self.options)\n                if ctx.options.client_replay_concurrency == -1:\n                    t = asyncio_utils.create_task(\n                        h.replay(), name=\"client playback awaiting response\"\n                    )\n                    # keep a reference so this is not garbage collected\n                    self.replay_tasks.add(t)\n                    t.add_done_callback(self.replay_tasks.remove)\n                else:\n                    await h.replay()\n            except Exception:\n                logger.exception(f\"Client replay has crashed!\")\n            self.queue.task_done()\n            self.inflight = None\n\n    def check(self, f: flow.Flow) -> str | None:\n        if f.live or f == self.inflight:\n            return \"Can't replay live flow.\"\n        if f.intercepted:\n            return \"Can't replay intercepted flow.\"\n        if isinstance(f, http.HTTPFlow):\n            if not f.request:\n                return \"Can't replay flow with missing request.\"\n            if f.request.raw_content is None:\n                return \"Can't replay flow with missing content.\"\n            if f.websocket is not None:\n                return \"Can't replay WebSocket flows.\"\n        else:\n            return \"Can only replay HTTP flows.\"\n        return None\n\n    def load(self, loader):\n        loader.add_option(\n            \"client_replay\",\n            Sequence[str],\n            [],\n            \"Replay client requests from a saved file.\",\n        )\n        loader.add_option(\n            \"client_replay_concurrency\",\n            int,\n            1,\n            \"Concurrency limit on in-flight client replay requests. Currently the only valid values are 1 and -1 (no limit).\",\n        )\n\n    def configure(self, updated):\n        if \"client_replay\" in updated and ctx.options.client_replay:\n            try:\n                flows = io.read_flows_from_paths(ctx.options.client_replay)\n            except exceptions.FlowReadException as e:\n                raise exceptions.OptionsError(str(e))\n            self.start_replay(flows)\n\n        if \"client_replay_concurrency\" in updated:\n            if ctx.options.client_replay_concurrency not in [-1, 1]:\n                raise exceptions.OptionsError(\n                    \"Currently the only valid client_replay_concurrency values are -1 and 1.\"\n                )\n\n    @command.command(\"replay.client.count\")\n    def count(self) -> int:\n        \"\"\"\n        Approximate number of flows queued for replay.\n        \"\"\"\n        return self.queue.qsize() + int(bool(self.inflight))\n\n    @command.command(\"replay.client.stop\")\n    def stop_replay(self) -> None:\n        \"\"\"\n        Clear the replay queue.\n        \"\"\"\n        updated = []\n        while True:\n            try:\n                f = self.queue.get_nowait()\n            except asyncio.QueueEmpty:\n                break\n            else:\n                self.queue.task_done()\n                f.revert()\n                updated.append(f)\n\n        ctx.master.addons.trigger(UpdateHook(updated))\n        logger.log(ALERT, \"Client replay queue cleared.\")\n\n    @command.command(\"replay.client\")\n    def start_replay(self, flows: Sequence[flow.Flow]) -> None:\n        \"\"\"\n        Add flows to the replay queue, skipping flows that can't be replayed.\n        \"\"\"\n        updated: list[http.HTTPFlow] = []\n        for f in flows:\n            err = self.check(f)\n            if err:\n                logger.warning(err)\n                continue\n\n            http_flow = cast(http.HTTPFlow, f)\n\n            # Prepare the flow for replay\n            http_flow.backup()\n            http_flow.is_replay = \"request\"\n            http_flow.response = None\n            http_flow.error = None\n            self.queue.put_nowait(http_flow)\n            updated.append(http_flow)\n        ctx.master.addons.trigger(UpdateHook(updated))\n\n    @command.command(\"replay.client.file\")\n    def load_file(self, path: mitmproxy.types.Path) -> None:\n        \"\"\"\n        Load flows from file, and add them to the replay queue.\n        \"\"\"\n        try:\n            flows = io.read_flows_from_paths([path])\n        except exceptions.FlowReadException as e:\n            raise exceptions.CommandError(str(e))\n        self.start_replay(flows)\n", "mitmproxy/addons/__init__.py": "from mitmproxy.addons import anticache\nfrom mitmproxy.addons import anticomp\nfrom mitmproxy.addons import block\nfrom mitmproxy.addons import blocklist\nfrom mitmproxy.addons import browser\nfrom mitmproxy.addons import clientplayback\nfrom mitmproxy.addons import command_history\nfrom mitmproxy.addons import comment\nfrom mitmproxy.addons import core\nfrom mitmproxy.addons import cut\nfrom mitmproxy.addons import disable_h2c\nfrom mitmproxy.addons import dns_resolver\nfrom mitmproxy.addons import export\nfrom mitmproxy.addons import maplocal\nfrom mitmproxy.addons import mapremote\nfrom mitmproxy.addons import modifybody\nfrom mitmproxy.addons import modifyheaders\nfrom mitmproxy.addons import next_layer\nfrom mitmproxy.addons import onboarding\nfrom mitmproxy.addons import proxyauth\nfrom mitmproxy.addons import proxyserver\nfrom mitmproxy.addons import save\nfrom mitmproxy.addons import savehar\nfrom mitmproxy.addons import script\nfrom mitmproxy.addons import serverplayback\nfrom mitmproxy.addons import stickyauth\nfrom mitmproxy.addons import stickycookie\nfrom mitmproxy.addons import strip_ech\nfrom mitmproxy.addons import tlsconfig\nfrom mitmproxy.addons import upstream_auth\n\n\ndef default_addons():\n    return [\n        core.Core(),\n        browser.Browser(),\n        block.Block(),\n        strip_ech.StripECH(),\n        blocklist.BlockList(),\n        anticache.AntiCache(),\n        anticomp.AntiComp(),\n        clientplayback.ClientPlayback(),\n        command_history.CommandHistory(),\n        comment.Comment(),\n        cut.Cut(),\n        disable_h2c.DisableH2C(),\n        export.Export(),\n        onboarding.Onboarding(),\n        proxyauth.ProxyAuth(),\n        proxyserver.Proxyserver(),\n        dns_resolver.DnsResolver(),\n        script.ScriptLoader(),\n        next_layer.NextLayer(),\n        serverplayback.ServerPlayback(),\n        mapremote.MapRemote(),\n        maplocal.MapLocal(),\n        modifybody.ModifyBody(),\n        modifyheaders.ModifyHeaders(),\n        stickyauth.StickyAuth(),\n        stickycookie.StickyCookie(),\n        save.Save(),\n        savehar.SaveHar(),\n        tlsconfig.TlsConfig(),\n        upstream_auth.UpstreamAuth(),\n    ]\n", "mitmproxy/addons/dns_resolver.py": "import asyncio\nimport ipaddress\nimport socket\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\n\nfrom mitmproxy import dns\nfrom mitmproxy.proxy import mode_specs\n\nIP4_PTR_SUFFIX = \".in-addr.arpa\"\nIP6_PTR_SUFFIX = \".ip6.arpa\"\n\n\nclass ResolveError(Exception):\n    \"\"\"Exception thrown by different resolve methods.\"\"\"\n\n    def __init__(self, response_code: int) -> None:\n        assert response_code != dns.response_codes.NOERROR\n        self.response_code = response_code\n\n\nasync def resolve_question_by_name(\n    question: dns.Question,\n    loop: asyncio.AbstractEventLoop,\n    family: socket.AddressFamily,\n    ip: Callable[[str], ipaddress.IPv4Address | ipaddress.IPv6Address],\n) -> Iterable[dns.ResourceRecord]:\n    try:\n        addrinfos = await loop.getaddrinfo(\n            host=question.name, port=0, family=family, type=socket.SOCK_STREAM\n        )\n    except socket.gaierror as e:\n        if e.errno == socket.EAI_NONAME:\n            raise ResolveError(dns.response_codes.NXDOMAIN)\n        else:\n            # NOTE might fail on Windows for IPv6 queries:\n            # https://stackoverflow.com/questions/66755681/getaddrinfo-c-on-windows-not-handling-ipv6-correctly-returning-error-code-1\n            raise ResolveError(dns.response_codes.SERVFAIL)  # pragma: no cover\n    return map(\n        lambda addrinfo: dns.ResourceRecord(\n            name=question.name,\n            type=question.type,\n            class_=question.class_,\n            ttl=dns.ResourceRecord.DEFAULT_TTL,\n            data=ip(addrinfo[4][0]).packed,\n        ),\n        addrinfos,\n    )\n\n\nasync def resolve_question_by_addr(\n    question: dns.Question,\n    loop: asyncio.AbstractEventLoop,\n    suffix: str,\n    sockaddr: Callable[[list[str]], tuple[str, int] | tuple[str, int, int, int]],\n) -> Iterable[dns.ResourceRecord]:\n    try:\n        addr = sockaddr(question.name[: -len(suffix)].split(\".\")[::-1])\n    except ValueError:\n        raise ResolveError(dns.response_codes.FORMERR)\n    try:\n        name, _ = await loop.getnameinfo(addr, flags=socket.NI_NAMEREQD)\n    except socket.gaierror as e:\n        raise ResolveError(\n            dns.response_codes.NXDOMAIN\n            if e.errno == socket.EAI_NONAME\n            else dns.response_codes.SERVFAIL\n        )\n    return [\n        dns.ResourceRecord(\n            name=question.name,\n            type=question.type,\n            class_=question.class_,\n            ttl=dns.ResourceRecord.DEFAULT_TTL,\n            data=dns.domain_names.pack(name),\n        )\n    ]\n\n\nasync def resolve_question(\n    question: dns.Question, loop: asyncio.AbstractEventLoop\n) -> Iterable[dns.ResourceRecord]:\n    \"\"\"Resolve the question into resource record(s), throwing ResolveError if an error condition occurs.\"\"\"\n\n    if question.class_ != dns.classes.IN:\n        raise ResolveError(dns.response_codes.NOTIMP)\n    if question.type == dns.types.A:\n        return await resolve_question_by_name(\n            question, loop, socket.AddressFamily.AF_INET, ipaddress.IPv4Address\n        )\n    elif question.type == dns.types.AAAA:\n        return await resolve_question_by_name(\n            question, loop, socket.AddressFamily.AF_INET6, ipaddress.IPv6Address\n        )\n    elif question.type == dns.types.PTR:\n        name_lower = question.name.lower()\n        if name_lower.endswith(IP4_PTR_SUFFIX):\n            return await resolve_question_by_addr(\n                question=question,\n                loop=loop,\n                suffix=IP4_PTR_SUFFIX,\n                sockaddr=lambda x: (str(ipaddress.IPv4Address(\".\".join(x))), 0),\n            )\n        elif name_lower.endswith(IP6_PTR_SUFFIX):\n            return await resolve_question_by_addr(\n                question=question,\n                loop=loop,\n                suffix=IP6_PTR_SUFFIX,\n                sockaddr=lambda x: (\n                    str(ipaddress.IPv6Address(bytes.fromhex(\"\".join(x)))),\n                    0,\n                    0,\n                    0,\n                ),\n            )\n        else:\n            raise ResolveError(dns.response_codes.FORMERR)\n    else:\n        raise ResolveError(dns.response_codes.NOTIMP)\n\n\nasync def resolve_message(\n    message: dns.Message, loop: asyncio.AbstractEventLoop\n) -> dns.Message:\n    try:\n        if not message.query:\n            raise ResolveError(\n                dns.response_codes.REFUSED\n            )  # we cannot resolve an answer\n        if message.op_code != dns.op_codes.QUERY:\n            raise ResolveError(\n                dns.response_codes.NOTIMP\n            )  # inverse queries and others are not supported\n        rrs: list[dns.ResourceRecord] = []\n        for question in message.questions:\n            rrs.extend(await resolve_question(question, loop))\n    except ResolveError as e:\n        return message.fail(e.response_code)\n    else:\n        return message.succeed(rrs)\n\n\nclass DnsResolver:\n    async def dns_request(self, flow: dns.DNSFlow) -> None:\n        should_resolve = (\n            (\n                isinstance(flow.client_conn.proxy_mode, mode_specs.DnsMode)\n                or (\n                    isinstance(flow.client_conn.proxy_mode, mode_specs.WireGuardMode)\n                    and flow.server_conn.address == (\"10.0.0.53\", 53)\n                )\n            )\n            and flow.live\n            and not flow.response\n            and not flow.error\n        )\n        if should_resolve:\n            # TODO: We need to handle overly long responses here.\n            flow.response = await resolve_message(\n                flow.request, asyncio.get_running_loop()\n            )\n", "mitmproxy/addons/keepserving.py": "from __future__ import annotations\n\nimport asyncio\n\nfrom mitmproxy import ctx\nfrom mitmproxy.utils import asyncio_utils\n\n\nclass KeepServing:\n    _watch_task: asyncio.Task | None = None\n\n    def load(self, loader):\n        loader.add_option(\n            \"keepserving\",\n            bool,\n            False,\n            \"\"\"\n            Continue serving after client playback, server playback or file\n            read. This option is ignored by interactive tools, which always keep\n            serving.\n            \"\"\",\n        )\n\n    def keepgoing(self) -> bool:\n        checks = [\n            \"readfile.reading\",\n            \"replay.client.count\",\n            \"replay.server.count\",\n        ]\n        return any([ctx.master.commands.call(c) for c in checks])\n\n    def shutdown(self):  # pragma: no cover\n        ctx.master.shutdown()\n\n    async def watch(self):\n        while True:\n            await asyncio.sleep(0.1)\n            if not self.keepgoing():\n                self.shutdown()\n\n    def running(self):\n        opts = [\n            ctx.options.client_replay,\n            ctx.options.server_replay,\n            ctx.options.rfile,\n        ]\n        if any(opts) and not ctx.options.keepserving:\n            self._watch_task = asyncio_utils.create_task(\n                self.watch(), name=\"keepserving\"\n            )\n", "mitmproxy/addons/script.py": "import asyncio\nimport importlib.machinery\nimport importlib.util\nimport logging\nimport os\nimport sys\nimport types\nfrom collections.abc import Sequence\n\nimport mitmproxy.types as mtypes\nfrom mitmproxy import addonmanager\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import eventsequence\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import hooks\nfrom mitmproxy.utils import asyncio_utils\n\nlogger = logging.getLogger(__name__)\n\n\ndef load_script(path: str) -> types.ModuleType | None:\n    fullname = \"__mitmproxy_script__.{}\".format(\n        os.path.splitext(os.path.basename(path))[0]\n    )\n    # the fullname is not unique among scripts, so if there already is an existing script with said\n    # fullname, remove it.\n    sys.modules.pop(fullname, None)\n    oldpath = sys.path\n    sys.path.insert(0, os.path.dirname(path))\n    m = None\n    try:\n        loader = importlib.machinery.SourceFileLoader(fullname, path)\n        spec = importlib.util.spec_from_loader(fullname, loader=loader)\n        assert spec\n        m = importlib.util.module_from_spec(spec)\n        loader.exec_module(m)\n        if not getattr(m, \"name\", None):\n            m.name = path  # type: ignore\n    except ImportError as e:\n        if getattr(sys, \"frozen\", False):\n            e.msg += (\n                f\".\\n\"\n                f\"Note that mitmproxy's binaries include their own Python environment. \"\n                f\"If your addon requires the installation of additional dependencies, \"\n                f\"please install mitmproxy from PyPI \"\n                f\"(https://docs.mitmproxy.org/stable/overview-installation/#installation-from-the-python-package-index-pypi).\"\n            )\n        script_error_handler(path, e)\n    except Exception as e:\n        script_error_handler(path, e)\n    finally:\n        sys.path[:] = oldpath\n        return m\n\n\ndef script_error_handler(path: str, exc: Exception) -> None:\n    \"\"\"\n    Log errors during script loading.\n    \"\"\"\n    tback = exc.__traceback__\n    tback = addonmanager.cut_traceback(\n        tback, \"invoke_addon_sync\"\n    )  # we're calling configure() on load\n    tback = addonmanager.cut_traceback(\n        tback, \"_call_with_frames_removed\"\n    )  # module execution from importlib\n    logger.error(f\"error in script {path}\", exc_info=(type(exc), exc, tback))\n\n\nReloadInterval = 1\n\n\nclass Script:\n    \"\"\"\n    An addon that manages a single script.\n    \"\"\"\n\n    def __init__(self, path: str, reload: bool) -> None:\n        self.name = \"scriptmanager:\" + path\n        self.path = path\n        self.fullpath = os.path.expanduser(path.strip(\"'\\\" \"))\n        self.ns: types.ModuleType | None = None\n        self.is_running = False\n\n        if not os.path.isfile(self.fullpath):\n            raise exceptions.OptionsError(f\"No such script: {self.fullpath}\")\n\n        self.reloadtask = None\n        if reload:\n            self.reloadtask = asyncio_utils.create_task(\n                self.watcher(),\n                name=f\"script watcher for {path}\",\n            )\n        else:\n            self.loadscript()\n\n    def running(self):\n        self.is_running = True\n\n    def done(self):\n        if self.reloadtask:\n            self.reloadtask.cancel()\n\n    @property\n    def addons(self):\n        return [self.ns] if self.ns else []\n\n    def loadscript(self):\n        logger.info(\"Loading script %s\" % self.path)\n        if self.ns:\n            ctx.master.addons.remove(self.ns)\n        self.ns = None\n        with addonmanager.safecall():\n            ns = load_script(self.fullpath)\n            ctx.master.addons.register(ns)\n            self.ns = ns\n        if self.ns:\n            try:\n                ctx.master.addons.invoke_addon_sync(\n                    self.ns, hooks.ConfigureHook(ctx.options.keys())\n                )\n            except Exception as e:\n                script_error_handler(self.fullpath, e)\n            if self.is_running:\n                # We're already running, so we call that on the addon now.\n                ctx.master.addons.invoke_addon_sync(self.ns, hooks.RunningHook())\n\n    async def watcher(self):\n        # Script loading is terminally confused at the moment.\n        # This here is a stopgap workaround to defer loading.\n        await asyncio.sleep(0)\n        last_mtime = 0.0\n        while True:\n            try:\n                mtime = os.stat(self.fullpath).st_mtime\n            except FileNotFoundError:\n                logger.info(\"Removing script %s\" % self.path)\n                scripts = list(ctx.options.scripts)\n                scripts.remove(self.path)\n                ctx.options.update(scripts=scripts)\n                return\n            if mtime > last_mtime:\n                self.loadscript()\n                last_mtime = mtime\n            await asyncio.sleep(ReloadInterval)\n\n\nclass ScriptLoader:\n    \"\"\"\n    An addon that manages loading scripts from options.\n    \"\"\"\n\n    def __init__(self):\n        self.is_running = False\n        self.addons = []\n\n    def load(self, loader):\n        loader.add_option(\"scripts\", Sequence[str], [], \"Execute a script.\")\n\n    def running(self):\n        self.is_running = True\n\n    @command.command(\"script.run\")\n    def script_run(self, flows: Sequence[flow.Flow], path: mtypes.Path) -> None:\n        \"\"\"\n        Run a script on the specified flows. The script is configured with\n        the current options and all lifecycle events for each flow are\n        simulated. Note that the load event is not invoked.\n        \"\"\"\n        if not os.path.isfile(path):\n            logger.error(\"No such script: %s\" % path)\n            return\n        mod = load_script(path)\n        if mod:\n            with addonmanager.safecall():\n                ctx.master.addons.invoke_addon_sync(\n                    mod,\n                    hooks.ConfigureHook(ctx.options.keys()),\n                )\n                ctx.master.addons.invoke_addon_sync(mod, hooks.RunningHook())\n                for f in flows:\n                    for evt in eventsequence.iterate(f):\n                        ctx.master.addons.invoke_addon_sync(mod, evt)\n\n    def configure(self, updated):\n        if \"scripts\" in updated:\n            for s in ctx.options.scripts:\n                if ctx.options.scripts.count(s) > 1:\n                    raise exceptions.OptionsError(\"Duplicate script\")\n\n            for a in self.addons[:]:\n                if a.path not in ctx.options.scripts:\n                    logger.info(\"Un-loading script: %s\" % a.path)\n                    ctx.master.addons.remove(a)\n                    self.addons.remove(a)\n\n            # The machinations below are to ensure that:\n            #   - Scripts remain in the same order\n            #   - Scripts are not initialized un-necessarily. If only a\n            #   script's order in the script list has changed, it is just\n            #   moved.\n\n            current = {}\n            for a in self.addons:\n                current[a.path] = a\n\n            ordered = []\n            newscripts = []\n            for s in ctx.options.scripts:\n                if s in current:\n                    ordered.append(current[s])\n                else:\n                    sc = Script(s, True)\n                    ordered.append(sc)\n                    newscripts.append(sc)\n\n            self.addons = ordered\n\n            for s in newscripts:\n                ctx.master.addons.register(s)\n                if self.is_running:\n                    # If we're already running, we configure and tell the addon\n                    # we're up and running.\n                    ctx.master.addons.invoke_addon_sync(s, hooks.RunningHook())\n", "mitmproxy/addons/export.py": "import logging\nimport shlex\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom typing import Any\n\nimport pyperclip\n\nimport mitmproxy.types\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy.net.http.http1 import assemble\nfrom mitmproxy.utils import strutils\n\n\ndef cleanup_request(f: flow.Flow) -> http.Request:\n    if not getattr(f, \"request\", None):\n        raise exceptions.CommandError(\"Can't export flow with no request.\")\n    assert isinstance(f, http.HTTPFlow)\n    request = f.request.copy()\n    request.decode(strict=False)\n    return request\n\n\ndef pop_headers(request: http.Request) -> http.Request:\n    # Remove some headers that are redundant for curl/httpie export\n    request.headers.pop(\"content-length\")\n    if request.headers.get(\"host\", \"\") == request.host:\n        request.headers.pop(\"host\")\n    if request.headers.get(\":authority\", \"\") == request.host:\n        request.headers.pop(\":authority\")\n    return request\n\n\ndef cleanup_response(f: flow.Flow) -> http.Response:\n    if not getattr(f, \"response\", None):\n        raise exceptions.CommandError(\"Can't export flow with no response.\")\n    assert isinstance(f, http.HTTPFlow)\n    response = f.response.copy()  # type: ignore\n    response.decode(strict=False)\n    return response\n\n\ndef request_content_for_console(request: http.Request) -> str:\n    try:\n        text = request.get_text(strict=True)\n        assert text\n    except ValueError:\n        # shlex.quote doesn't support a bytes object\n        # see https://github.com/python/cpython/pull/10871\n        raise exceptions.CommandError(\"Request content must be valid unicode\")\n    escape_control_chars = {chr(i): f\"\\\\x{i:02x}\" for i in range(32)}\n    return \"\".join(escape_control_chars.get(x, x) for x in text)\n\n\ndef curl_command(f: flow.Flow) -> str:\n    request = cleanup_request(f)\n    request = pop_headers(request)\n    args = [\"curl\"]\n\n    server_addr = f.server_conn.peername[0] if f.server_conn.peername else None\n\n    if (\n        ctx.options.export_preserve_original_ip\n        and server_addr\n        and request.pretty_host != server_addr\n    ):\n        resolve = f\"{request.pretty_host}:{request.port}:[{server_addr}]\"\n        args.append(\"--resolve\")\n        args.append(resolve)\n\n    for k, v in request.headers.items(multi=True):\n        if k.lower() == \"accept-encoding\":\n            args.append(\"--compressed\")\n        else:\n            args += [\"-H\", f\"{k}: {v}\"]\n\n    if request.method != \"GET\":\n        args += [\"-X\", request.method]\n\n    args.append(request.pretty_url)\n\n    if request.content:\n        args += [\"-d\", request_content_for_console(request)]\n    return \" \".join(shlex.quote(arg) for arg in args)\n\n\ndef httpie_command(f: flow.Flow) -> str:\n    request = cleanup_request(f)\n    request = pop_headers(request)\n\n    # TODO: Once https://github.com/httpie/httpie/issues/414 is implemented, we\n    # should ensure we always connect to the IP address specified in the flow,\n    # similar to how it's done in curl_command.\n    url = request.pretty_url\n\n    args = [\"http\", request.method, url]\n    for k, v in request.headers.items(multi=True):\n        args.append(f\"{k}: {v}\")\n    cmd = \" \".join(shlex.quote(arg) for arg in args)\n    if request.content:\n        cmd += \" <<< \" + shlex.quote(request_content_for_console(request))\n    return cmd\n\n\ndef raw_request(f: flow.Flow) -> bytes:\n    request = cleanup_request(f)\n    if request.raw_content is None:\n        raise exceptions.CommandError(\"Request content missing.\")\n    return assemble.assemble_request(request)\n\n\ndef raw_response(f: flow.Flow) -> bytes:\n    response = cleanup_response(f)\n    if response.raw_content is None:\n        raise exceptions.CommandError(\"Response content missing.\")\n    return assemble.assemble_response(response)\n\n\ndef raw(f: flow.Flow, separator=b\"\\r\\n\\r\\n\") -> bytes:\n    \"\"\"Return either the request or response if only one exists, otherwise return both\"\"\"\n    request_present = (\n        isinstance(f, http.HTTPFlow) and f.request and f.request.raw_content is not None\n    )\n    response_present = (\n        isinstance(f, http.HTTPFlow)\n        and f.response\n        and f.response.raw_content is not None\n    )\n\n    if request_present and response_present:\n        parts = [raw_request(f), raw_response(f)]\n        if isinstance(f, http.HTTPFlow) and f.websocket:\n            parts.append(f.websocket._get_formatted_messages())\n        return separator.join(parts)\n    elif request_present:\n        return raw_request(f)\n    elif response_present:\n        return raw_response(f)\n    else:\n        raise exceptions.CommandError(\"Can't export flow with no request or response.\")\n\n\nformats: dict[str, Callable[[flow.Flow], str | bytes]] = dict(\n    curl=curl_command,\n    httpie=httpie_command,\n    raw=raw,\n    raw_request=raw_request,\n    raw_response=raw_response,\n)\n\n\nclass Export:\n    def load(self, loader):\n        loader.add_option(\n            \"export_preserve_original_ip\",\n            bool,\n            False,\n            \"\"\"\n            When exporting a request as an external command, make an effort to\n            connect to the same IP as in the original request. This helps with\n            reproducibility in cases where the behaviour depends on the\n            particular host we are connecting to. Currently this only affects\n            curl exports.\n            \"\"\",\n        )\n\n    @command.command(\"export.formats\")\n    def formats(self) -> Sequence[str]:\n        \"\"\"\n        Return a list of the supported export formats.\n        \"\"\"\n        return list(sorted(formats.keys()))\n\n    @command.command(\"export.file\")\n    def file(self, format: str, flow: flow.Flow, path: mitmproxy.types.Path) -> None:\n        \"\"\"\n        Export a flow to path.\n        \"\"\"\n        if format not in formats:\n            raise exceptions.CommandError(\"No such export format: %s\" % format)\n        func: Any = formats[format]\n        v = func(flow)\n        try:\n            with open(path, \"wb\") as fp:\n                if isinstance(v, bytes):\n                    fp.write(v)\n                else:\n                    fp.write(v.encode(\"utf-8\"))\n        except OSError as e:\n            logging.error(str(e))\n\n    @command.command(\"export.clip\")\n    def clip(self, format: str, f: flow.Flow) -> None:\n        \"\"\"\n        Export a flow to the system clipboard.\n        \"\"\"\n        try:\n            pyperclip.copy(self.export_str(format, f))\n        except pyperclip.PyperclipException as e:\n            logging.error(str(e))\n\n    @command.command(\"export\")\n    def export_str(self, format: str, f: flow.Flow) -> str:\n        \"\"\"\n        Export a flow and return the result.\n        \"\"\"\n        if format not in formats:\n            raise exceptions.CommandError(\"No such export format: %s\" % format)\n        func = formats[format]\n\n        return strutils.always_str(func(f), \"utf8\", \"backslashreplace\")\n", "mitmproxy/addons/disable_h2c.py": "import logging\n\n\nclass DisableH2C:\n    \"\"\"\n    We currently only support HTTP/2 over a TLS connection.\n\n    Some clients try to upgrade a connection from HTTP/1.1 to h2c. We need to\n    remove those headers to avoid protocol errors if one endpoints suddenly\n    starts sending HTTP/2 frames.\n\n    Some clients might use HTTP/2 Prior Knowledge to directly initiate a session\n    by sending the connection preface. We just kill those flows.\n    \"\"\"\n\n    def process_flow(self, f):\n        if f.request.headers.get(\"upgrade\", \"\") == \"h2c\":\n            logging.warning(\n                \"HTTP/2 cleartext connections (h2c upgrade requests) are currently not supported.\"\n            )\n            del f.request.headers[\"upgrade\"]\n            if \"connection\" in f.request.headers:\n                del f.request.headers[\"connection\"]\n            if \"http2-settings\" in f.request.headers:\n                del f.request.headers[\"http2-settings\"]\n\n        is_connection_preface = (\n            f.request.method == \"PRI\"\n            and f.request.path == \"*\"\n            and f.request.http_version == \"HTTP/2.0\"\n        )\n        if is_connection_preface:\n            f.kill()\n            logging.warning(\n                \"Initiating HTTP/2 connections with prior knowledge are currently not supported.\"\n            )\n\n    # Handlers\n\n    def request(self, f):\n        self.process_flow(f)\n", "mitmproxy/addons/next_layer.py": "\"\"\"\nThis addon determines the next protocol layer in our proxy stack.\nWhenever a protocol layer in the proxy wants to pass a connection to a child layer and isn't sure which protocol comes\nnext, it calls the `next_layer` hook, which ends up here.\nFor example, if mitmproxy runs as a regular proxy, we first need to determine if\nnew clients start with a TLS handshake right away (Secure Web Proxy) or send a plaintext HTTP CONNECT request.\nThis addon here peeks at the incoming bytes and then makes a decision based on proxy mode, mitmproxy options, etc.\n\nFor a typical HTTPS request, this addon is called a couple of times: First to determine that we start with an HTTP layer\nwhich processes the `CONNECT` request, a second time to determine that the client then starts negotiating TLS, and a\nthird time when we check if the protocol within that TLS stream is actually HTTP or something else.\n\nSometimes it's useful to hardcode specific logic in next_layer when one wants to do fancy things.\nIn that case it's not necessary to modify mitmproxy's source, adding a custom addon with a next_layer event hook\nthat sets nextlayer.layer works just as well.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport re\nimport sys\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nfrom typing import Any\nfrom typing import cast\n\nfrom mitmproxy import ctx\nfrom mitmproxy.net.tls import starts_like_dtls_record\nfrom mitmproxy.net.tls import starts_like_tls_record\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy import layers\nfrom mitmproxy.proxy import mode_specs\nfrom mitmproxy.proxy import tunnel\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.layer import Layer\nfrom mitmproxy.proxy.layers import ClientQuicLayer\nfrom mitmproxy.proxy.layers import ClientTLSLayer\nfrom mitmproxy.proxy.layers import DNSLayer\nfrom mitmproxy.proxy.layers import HttpLayer\nfrom mitmproxy.proxy.layers import modes\nfrom mitmproxy.proxy.layers import RawQuicLayer\nfrom mitmproxy.proxy.layers import ServerQuicLayer\nfrom mitmproxy.proxy.layers import ServerTLSLayer\nfrom mitmproxy.proxy.layers import TCPLayer\nfrom mitmproxy.proxy.layers import UDPLayer\nfrom mitmproxy.proxy.layers.http import HTTPMode\nfrom mitmproxy.proxy.layers.quic import quic_parse_client_hello\nfrom mitmproxy.proxy.layers.tls import dtls_parse_client_hello\nfrom mitmproxy.proxy.layers.tls import HTTP1_ALPNS\nfrom mitmproxy.proxy.layers.tls import HTTP_ALPNS\nfrom mitmproxy.proxy.layers.tls import parse_client_hello\nfrom mitmproxy.tls import ClientHello\n\nif sys.version_info < (3, 11):\n    from typing_extensions import assert_never\nelse:\n    from typing import assert_never\n\nlogger = logging.getLogger(__name__)\n\n\ndef stack_match(\n    context: Context, layers: Sequence[type[Layer] | tuple[type[Layer], ...]]\n) -> bool:\n    if len(context.layers) != len(layers):\n        return False\n    return all(\n        expected is Any or isinstance(actual, expected)\n        for actual, expected in zip(context.layers, layers)\n    )\n\n\nclass NeedsMoreData(Exception):\n    \"\"\"Signal that the decision on which layer to put next needs to be deferred within the NextLayer addon.\"\"\"\n\n\nclass NextLayer:\n    ignore_hosts: Sequence[re.Pattern] = ()\n    allow_hosts: Sequence[re.Pattern] = ()\n    tcp_hosts: Sequence[re.Pattern] = ()\n    udp_hosts: Sequence[re.Pattern] = ()\n\n    def configure(self, updated):\n        if \"tcp_hosts\" in updated:\n            self.tcp_hosts = [\n                re.compile(x, re.IGNORECASE) for x in ctx.options.tcp_hosts\n            ]\n        if \"udp_hosts\" in updated:\n            self.udp_hosts = [\n                re.compile(x, re.IGNORECASE) for x in ctx.options.udp_hosts\n            ]\n        if \"allow_hosts\" in updated or \"ignore_hosts\" in updated:\n            self.ignore_hosts = [\n                re.compile(x, re.IGNORECASE) for x in ctx.options.ignore_hosts\n            ]\n            self.allow_hosts = [\n                re.compile(x, re.IGNORECASE) for x in ctx.options.allow_hosts\n            ]\n\n    def next_layer(self, nextlayer: layer.NextLayer):\n        if nextlayer.layer:\n            return  # do not override something another addon has set.\n        try:\n            nextlayer.layer = self._next_layer(\n                nextlayer.context,\n                nextlayer.data_client(),\n                nextlayer.data_server(),\n            )\n        except NeedsMoreData:\n            logger.info(\n                f\"Deferring layer decision, not enough data: {nextlayer.data_client().hex()}\"\n            )\n\n    def _next_layer(\n        self, context: Context, data_client: bytes, data_server: bytes\n    ) -> Layer | None:\n        assert context.layers\n\n        def s(*layers):\n            return stack_match(context, layers)\n\n        tcp_based = context.client.transport_protocol == \"tcp\"\n        udp_based = context.client.transport_protocol == \"udp\"\n\n        # 1)  check for --ignore/--allow\n        if self._ignore_connection(context, data_client, data_server):\n            return (\n                layers.TCPLayer(context, ignore=True)\n                if tcp_based\n                else layers.UDPLayer(context, ignore=True)\n            )\n\n        # 2)  Handle proxy modes with well-defined next protocol\n        # 2a) Reverse proxy: derive from spec\n        if s(modes.ReverseProxy):\n            return self._setup_reverse_proxy(context, data_client)\n        # 2b) Explicit HTTP proxies\n        if s((modes.HttpProxy, modes.HttpUpstreamProxy)):\n            return self._setup_explicit_http_proxy(context, data_client)\n\n        # 3)  Handle security protocols\n        # 3a) TLS/DTLS\n        is_tls_or_dtls = (\n            tcp_based\n            and starts_like_tls_record(data_client)\n            or udp_based\n            and starts_like_dtls_record(data_client)\n        )\n        if is_tls_or_dtls:\n            server_tls = ServerTLSLayer(context)\n            server_tls.child_layer = ClientTLSLayer(context)\n            return server_tls\n        # 3b) QUIC\n        if udp_based and _starts_like_quic(data_client):\n            server_quic = ServerQuicLayer(context)\n            server_quic.child_layer = ClientQuicLayer(context)\n            return server_quic\n\n        # 4)  Check for --tcp/--udp\n        if tcp_based and self._is_destination_in_hosts(context, self.tcp_hosts):\n            return layers.TCPLayer(context)\n        if udp_based and self._is_destination_in_hosts(context, self.udp_hosts):\n            return layers.UDPLayer(context)\n\n        # 5)  Handle application protocol\n        # 5a) Is it DNS?\n        if context.server.address and context.server.address[1] in (53, 5353):\n            return layers.DNSLayer(context)\n\n        # 5b) We have no other specialized layers for UDP, so we fall back to raw forwarding.\n        if udp_based:\n            return layers.UDPLayer(context)\n        # 5b) Check for raw tcp mode.\n        very_likely_http = context.client.alpn in HTTP_ALPNS\n        probably_no_http = not very_likely_http and (\n            # the first three bytes should be the HTTP verb, so A-Za-z is expected.\n            len(data_client) < 3\n            or not data_client[:3].isalpha()\n            # a server greeting would be uncharacteristic.\n            or data_server\n        )\n        if ctx.options.rawtcp and probably_no_http:\n            return layers.TCPLayer(context)\n        # 5c) Assume HTTP by default.\n        return layers.HttpLayer(context, HTTPMode.transparent)\n\n    def _ignore_connection(\n        self,\n        context: Context,\n        data_client: bytes,\n        data_server: bytes,\n    ) -> bool | None:\n        \"\"\"\n        Returns:\n            True, if the connection should be ignored.\n            False, if it should not be ignored.\n\n        Raises:\n            NeedsMoreData, if we need to wait for more input data.\n        \"\"\"\n        if not ctx.options.ignore_hosts and not ctx.options.allow_hosts:\n            return False\n        # Special handling for wireguard mode: if the hostname is \"10.0.0.53\", do not ignore the connection\n        if isinstance(\n            context.client.proxy_mode, mode_specs.WireGuardMode\n        ) and context.server.address == (\"10.0.0.53\", 53):\n            return False\n        hostnames: list[str] = []\n        if context.server.peername:\n            host, port, *_ = context.server.peername\n            hostnames.append(f\"{host}:{port}\")\n        if context.server.address:\n            host, port, *_ = context.server.address\n            hostnames.append(f\"{host}:{port}\")\n\n            # We also want to check for TLS SNI and HTTP host headers, but in order to ignore connections based on that\n            # they must have a destination address. If they don't, we don't know how to establish an upstream connection\n            # if we ignore.\n            if host_header := self._get_host_header(context, data_client, data_server):\n                if not re.search(r\":\\d+$\", host_header):\n                    host_header = f\"{host_header}:{port}\"\n                hostnames.append(host_header)\n            if (\n                client_hello := self._get_client_hello(context, data_client)\n            ) and client_hello.sni:\n                hostnames.append(f\"{client_hello.sni}:{port}\")\n\n        if not hostnames:\n            return False\n\n        if ctx.options.allow_hosts:\n            not_allowed = not any(\n                re.search(rex, host, re.IGNORECASE)\n                for host in hostnames\n                for rex in ctx.options.allow_hosts\n            )\n            if not_allowed:\n                return True\n\n        if ctx.options.ignore_hosts:\n            ignored = any(\n                re.search(rex, host, re.IGNORECASE)\n                for host in hostnames\n                for rex in ctx.options.ignore_hosts\n            )\n            if ignored:\n                return True\n\n        return False\n\n    @staticmethod\n    def _get_host_header(\n        context: Context,\n        data_client: bytes,\n        data_server: bytes,\n    ) -> str | None:\n        \"\"\"\n        Try to read a host header from data_client.\n\n        Returns:\n            The host header value, or None, if no host header was found.\n\n        Raises:\n            NeedsMoreData, if the HTTP request is incomplete.\n        \"\"\"\n        if context.client.transport_protocol != \"tcp\" or data_server:\n            return None\n\n        host_header_expected = context.client.alpn in HTTP1_ALPNS or re.match(\n            rb\"[A-Z]{3,}.+HTTP/\", data_client, re.IGNORECASE\n        )\n        if host_header_expected:\n            if m := re.search(\n                rb\"\\r\\n(?:Host:\\s+(.+?)\\s*)?\\r\\n\", data_client, re.IGNORECASE\n            ):\n                if host := m.group(1):\n                    return host.decode(\"utf-8\", \"surrogateescape\")\n                else:\n                    return None  # \\r\\n\\r\\n - header end came first.\n            else:\n                raise NeedsMoreData\n        else:\n            return None\n\n    @staticmethod\n    def _get_client_hello(context: Context, data_client: bytes) -> ClientHello | None:\n        \"\"\"\n        Try to read a TLS/DTLS/QUIC ClientHello from data_client.\n\n        Returns:\n            A complete ClientHello, or None, if no ClientHello was found.\n\n        Raises:\n            NeedsMoreData, if the ClientHello is incomplete.\n        \"\"\"\n        match context.client.transport_protocol:\n            case \"tcp\":\n                if starts_like_tls_record(data_client):\n                    try:\n                        ch = parse_client_hello(data_client)\n                    except ValueError:\n                        pass\n                    else:\n                        if ch is None:\n                            raise NeedsMoreData\n                        return ch\n                return None\n            case \"udp\":\n                try:\n                    return quic_parse_client_hello(data_client)\n                except ValueError:\n                    pass\n\n                try:\n                    ch = dtls_parse_client_hello(data_client)\n                except ValueError:\n                    pass\n                else:\n                    if ch is None:\n                        raise NeedsMoreData\n                    return ch\n                return None\n            case _:  # pragma: no cover\n                assert_never(context.client.transport_protocol)\n\n    @staticmethod\n    def _setup_reverse_proxy(context: Context, data_client: bytes) -> Layer:\n        spec = cast(mode_specs.ReverseMode, context.client.proxy_mode)\n        stack = tunnel.LayerStack()\n\n        match spec.scheme:\n            case \"http\":\n                if starts_like_tls_record(data_client):\n                    stack /= ClientTLSLayer(context)\n                stack /= HttpLayer(context, HTTPMode.transparent)\n            case \"https\":\n                stack /= ServerTLSLayer(context)\n                if starts_like_tls_record(data_client):\n                    stack /= ClientTLSLayer(context)\n                stack /= HttpLayer(context, HTTPMode.transparent)\n\n            case \"tcp\":\n                if starts_like_tls_record(data_client):\n                    stack /= ClientTLSLayer(context)\n                stack /= TCPLayer(context)\n            case \"tls\":\n                stack /= ServerTLSLayer(context)\n                if starts_like_tls_record(data_client):\n                    stack /= ClientTLSLayer(context)\n                stack /= TCPLayer(context)\n\n            case \"udp\":\n                if starts_like_dtls_record(data_client):\n                    stack /= ClientTLSLayer(context)\n                stack /= UDPLayer(context)\n            case \"dtls\":\n                stack /= ServerTLSLayer(context)\n                if starts_like_dtls_record(data_client):\n                    stack /= ClientTLSLayer(context)\n                stack /= UDPLayer(context)\n\n            case \"dns\":\n                # TODO: DNS-over-TLS / DNS-over-DTLS\n                # is_tls_or_dtls = (\n                #     context.client.transport_protocol == \"tcp\" and starts_like_tls_record(data_client)\n                #     or\n                #     context.client.transport_protocol == \"udp\" and starts_like_dtls_record(data_client)\n                # )\n                # if is_tls_or_dtls:\n                #     stack /= ClientTLSLayer(context)\n                stack /= DNSLayer(context)\n\n            case \"http3\":\n                stack /= ServerQuicLayer(context)\n                stack /= ClientQuicLayer(context)\n                stack /= HttpLayer(context, HTTPMode.transparent)\n            case \"quic\":\n                stack /= ServerQuicLayer(context)\n                stack /= ClientQuicLayer(context)\n                stack /= RawQuicLayer(context)\n\n            case _:  # pragma: no cover\n                assert_never(spec.scheme)\n\n        return stack[0]\n\n    @staticmethod\n    def _setup_explicit_http_proxy(context: Context, data_client: bytes) -> Layer:\n        stack = tunnel.LayerStack()\n\n        if context.client.transport_protocol == \"udp\":\n            stack /= layers.ClientQuicLayer(context)\n        elif starts_like_tls_record(data_client):\n            stack /= layers.ClientTLSLayer(context)\n\n        if isinstance(context.layers[0], modes.HttpUpstreamProxy):\n            stack /= layers.HttpLayer(context, HTTPMode.upstream)\n        else:\n            stack /= layers.HttpLayer(context, HTTPMode.regular)\n\n        return stack[0]\n\n    @staticmethod\n    def _is_destination_in_hosts(context: Context, hosts: Iterable[re.Pattern]) -> bool:\n        return any(\n            (context.server.address and rex.search(context.server.address[0]))\n            or (context.client.sni and rex.search(context.client.sni))\n            for rex in hosts\n        )\n\n\ndef _starts_like_quic(data_client: bytes) -> bool:\n    # FIXME: handle clienthellos distributed over multiple packets?\n    # FIXME: perf\n    try:\n        quic_parse_client_hello(data_client)\n    except ValueError:\n        return False\n    else:\n        return True\n", "mitmproxy/addons/cut.py": "import csv\nimport io\nimport logging\nimport os.path\nfrom collections.abc import Sequence\nfrom typing import Any\n\nimport pyperclip\n\nimport mitmproxy.types\nfrom mitmproxy import certs\nfrom mitmproxy import command\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy.log import ALERT\n\nlogger = logging.getLogger(__name__)\n\n\ndef headername(spec: str):\n    if not (spec.startswith(\"header[\") and spec.endswith(\"]\")):\n        raise exceptions.CommandError(\"Invalid header spec: %s\" % spec)\n    return spec[len(\"header[\") : -1].strip()\n\n\ndef is_addr(v):\n    return isinstance(v, tuple) and len(v) > 1\n\n\ndef extract(cut: str, f: flow.Flow) -> str | bytes:\n    # Hack for https://github.com/mitmproxy/mitmproxy/issues/6721:\n    # Make \"save body\" keybind work for WebSocket flows.\n    # Ideally the keybind would be smarter and this here can get removed.\n    if (\n        isinstance(f, http.HTTPFlow)\n        and f.websocket\n        and cut in (\"request.content\", \"response.content\")\n    ):\n        return f.websocket._get_formatted_messages()\n\n    path = cut.split(\".\")\n    current: Any = f\n    for i, spec in enumerate(path):\n        if spec.startswith(\"_\"):\n            raise exceptions.CommandError(\"Can't access internal attribute %s\" % spec)\n\n        part = getattr(current, spec, None)\n        if i == len(path) - 1:\n            if spec == \"port\" and is_addr(current):\n                return str(current[1])\n            if spec == \"host\" and is_addr(current):\n                return str(current[0])\n            elif spec.startswith(\"header[\"):\n                if not current:\n                    return \"\"\n                return current.headers.get(headername(spec), \"\")\n            elif isinstance(part, bytes):\n                return part\n            elif isinstance(part, bool):\n                return \"true\" if part else \"false\"\n            elif isinstance(part, certs.Cert):  # pragma: no cover\n                return part.to_pem().decode(\"ascii\")\n            elif (\n                isinstance(part, list)\n                and len(part) > 0\n                and isinstance(part[0], certs.Cert)\n            ):\n                # TODO: currently this extracts only the very first cert as PEM-encoded string.\n                return part[0].to_pem().decode(\"ascii\")\n        current = part\n    return str(current or \"\")\n\n\ndef extract_str(cut: str, f: flow.Flow) -> str:\n    ret = extract(cut, f)\n    if isinstance(ret, bytes):\n        return repr(ret)\n    else:\n        return ret\n\n\nclass Cut:\n    @command.command(\"cut\")\n    def cut(\n        self,\n        flows: Sequence[flow.Flow],\n        cuts: mitmproxy.types.CutSpec,\n    ) -> mitmproxy.types.Data:\n        \"\"\"\n        Cut data from a set of flows. Cut specifications are attribute paths\n        from the base of the flow object, with a few conveniences - \"port\"\n        and \"host\" retrieve parts of an address tuple, \".header[key]\"\n        retrieves a header value. Return values converted to strings or\n        bytes: SSL certificates are converted to PEM format, bools are \"true\"\n        or \"false\", \"bytes\" are preserved, and all other values are\n        converted to strings.\n        \"\"\"\n        ret: list[list[str | bytes]] = []\n        for f in flows:\n            ret.append([extract(c, f) for c in cuts])\n        return ret  # type: ignore\n\n    @command.command(\"cut.save\")\n    def save(\n        self,\n        flows: Sequence[flow.Flow],\n        cuts: mitmproxy.types.CutSpec,\n        path: mitmproxy.types.Path,\n    ) -> None:\n        \"\"\"\n        Save cuts to file. If there are multiple flows or cuts, the format\n        is UTF-8 encoded CSV. If there is exactly one row and one column,\n        the data is written to file as-is, with raw bytes preserved. If the\n        path is prefixed with a \"+\", values are appended if there is an\n        existing file.\n        \"\"\"\n        append = False\n        if path.startswith(\"+\"):\n            append = True\n            epath = os.path.expanduser(path[1:])\n            path = mitmproxy.types.Path(epath)\n        try:\n            if len(cuts) == 1 and len(flows) == 1:\n                with open(path, \"ab\" if append else \"wb\") as fp:\n                    if fp.tell() > 0:\n                        # We're appending to a file that already exists and has content\n                        fp.write(b\"\\n\")\n                    v = extract(cuts[0], flows[0])\n                    if isinstance(v, bytes):\n                        fp.write(v)\n                    else:\n                        fp.write(v.encode(\"utf8\"))\n                logger.log(ALERT, \"Saved single cut.\")\n            else:\n                with open(\n                    path, \"a\" if append else \"w\", newline=\"\", encoding=\"utf8\"\n                ) as tfp:\n                    writer = csv.writer(tfp)\n                    for f in flows:\n                        vals = [extract_str(c, f) for c in cuts]\n                        writer.writerow(vals)\n                logger.log(\n                    ALERT,\n                    \"Saved %s cuts over %d flows as CSV.\" % (len(cuts), len(flows)),\n                )\n        except OSError as e:\n            logger.error(str(e))\n\n    @command.command(\"cut.clip\")\n    def clip(\n        self,\n        flows: Sequence[flow.Flow],\n        cuts: mitmproxy.types.CutSpec,\n    ) -> None:\n        \"\"\"\n        Send cuts to the clipboard. If there are multiple flows or cuts, the\n        format is UTF-8 encoded CSV. If there is exactly one row and one\n        column, the data is written to file as-is, with raw bytes preserved.\n        \"\"\"\n        v: str | bytes\n        fp = io.StringIO(newline=\"\")\n        if len(cuts) == 1 and len(flows) == 1:\n            v = extract_str(cuts[0], flows[0])\n            fp.write(v)\n            logger.log(ALERT, \"Clipped single cut.\")\n        else:\n            writer = csv.writer(fp)\n            for f in flows:\n                vals = [extract_str(c, f) for c in cuts]\n                writer.writerow(vals)\n            logger.log(ALERT, \"Clipped %s cuts as CSV.\" % len(cuts))\n        try:\n            pyperclip.copy(fp.getvalue())\n        except pyperclip.PyperclipException as e:\n            logger.error(str(e))\n", "mitmproxy/addons/comment.py": "from collections.abc import Sequence\n\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import flow\nfrom mitmproxy.hooks import UpdateHook\n\n\nclass Comment:\n    @command.command(\"flow.comment\")\n    def comment(self, flow: Sequence[flow.Flow], comment: str) -> None:\n        \"Add a comment to a flow\"\n\n        updated = []\n        for f in flow:\n            f.comment = comment\n            updated.append(f)\n\n        ctx.master.addons.trigger(UpdateHook(updated))\n", "mitmproxy/addons/dumper.py": "from __future__ import annotations\n\nimport itertools\nimport logging\nimport shutil\nimport sys\nfrom typing import IO\nfrom typing import Optional\n\nfrom wsproto.frame_protocol import CloseReason\n\nfrom mitmproxy import contentviews\nfrom mitmproxy import ctx\nfrom mitmproxy import dns\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy.contrib import click as miniclick\nfrom mitmproxy.net.dns import response_codes\nfrom mitmproxy.options import CONTENT_VIEW_LINES_CUTOFF\nfrom mitmproxy.tcp import TCPFlow\nfrom mitmproxy.tcp import TCPMessage\nfrom mitmproxy.udp import UDPFlow\nfrom mitmproxy.udp import UDPMessage\nfrom mitmproxy.utils import human\nfrom mitmproxy.utils import strutils\nfrom mitmproxy.utils import vt_codes\nfrom mitmproxy.websocket import WebSocketData\nfrom mitmproxy.websocket import WebSocketMessage\n\n\ndef indent(n: int, text: str) -> str:\n    lines = str(text).strip().splitlines()\n    pad = \" \" * n\n    return \"\\n\".join(pad + i for i in lines)\n\n\nCONTENTVIEW_STYLES: dict[str, dict[str, str | bool]] = {\n    \"highlight\": dict(bold=True),\n    \"offset\": dict(fg=\"blue\"),\n    \"header\": dict(fg=\"green\", bold=True),\n    \"text\": dict(fg=\"green\"),\n}\n\n\nclass Dumper:\n    def __init__(self, outfile: IO[str] | None = None):\n        self.filter: flowfilter.TFilter | None = None\n        self.outfp: IO[str] = outfile or sys.stdout\n        self.out_has_vt_codes = vt_codes.ensure_supported(self.outfp)\n\n    def load(self, loader):\n        loader.add_option(\n            \"flow_detail\",\n            int,\n            1,\n            f\"\"\"\n            The display detail level for flows in mitmdump: 0 (quiet) to 4 (very verbose).\n              0: no output\n              1: shortened request URL with response status code\n              2: full request URL with response status code and HTTP headers\n              3: 2 + truncated response content, content of WebSocket and TCP messages (content_view_lines_cutoff: {CONTENT_VIEW_LINES_CUTOFF})\n              4: 3 + nothing is truncated\n            \"\"\",\n        )\n        loader.add_option(\n            \"dumper_default_contentview\",\n            str,\n            \"auto\",\n            \"The default content view mode.\",\n            choices=[i.name.lower() for i in contentviews.views],\n        )\n        loader.add_option(\n            \"dumper_filter\", Optional[str], None, \"Limit which flows are dumped.\"\n        )\n\n    def configure(self, updated):\n        if \"dumper_filter\" in updated:\n            if ctx.options.dumper_filter:\n                try:\n                    self.filter = flowfilter.parse(ctx.options.dumper_filter)\n                except ValueError as e:\n                    raise exceptions.OptionsError(str(e)) from e\n            else:\n                self.filter = None\n\n    def style(self, text: str, **style) -> str:\n        if style and self.out_has_vt_codes:\n            text = miniclick.style(text, **style)\n        return text\n\n    def echo(self, text: str, ident=None, **style):\n        if ident:\n            text = indent(ident, text)\n        text = self.style(text, **style)\n        print(text, file=self.outfp)\n\n    def _echo_headers(self, headers: http.Headers):\n        for k, v in headers.fields:\n            ks = strutils.bytes_to_escaped_str(k)\n            ks = self.style(ks, fg=\"blue\")\n            vs = strutils.bytes_to_escaped_str(v)\n            self.echo(f\"{ks}: {vs}\", ident=4)\n\n    def _echo_trailers(self, trailers: http.Headers | None):\n        if not trailers:\n            return\n        self.echo(\"--- HTTP Trailers\", fg=\"magenta\", ident=4)\n        self._echo_headers(trailers)\n\n    def _colorful(self, line):\n        yield \"    \"  # we can already indent here\n        for style, text in line:\n            yield self.style(text, **CONTENTVIEW_STYLES.get(style, {}))\n\n    def _echo_message(\n        self,\n        message: http.Message | TCPMessage | UDPMessage | WebSocketMessage,\n        flow: http.HTTPFlow | TCPFlow | UDPFlow,\n    ):\n        _, lines, error = contentviews.get_message_content_view(\n            ctx.options.dumper_default_contentview, message, flow\n        )\n        if error:\n            logging.debug(error)\n\n        if ctx.options.flow_detail == 3:\n            lines_to_echo = itertools.islice(\n                lines, ctx.options.content_view_lines_cutoff\n            )\n        else:\n            lines_to_echo = lines\n\n        content = \"\\r\\n\".join(\"\".join(self._colorful(line)) for line in lines_to_echo)\n        if content:\n            self.echo(\"\")\n            self.echo(content)\n\n        if next(lines, None):\n            self.echo(\"(cut off)\", ident=4, dim=True)\n\n        if ctx.options.flow_detail >= 2:\n            self.echo(\"\")\n\n    def _fmt_client(self, flow: flow.Flow) -> str:\n        if flow.is_replay == \"request\":\n            return self.style(\"[replay]\", fg=\"yellow\", bold=True)\n        elif flow.client_conn.peername:\n            return self.style(\n                strutils.escape_control_characters(\n                    human.format_address(flow.client_conn.peername)\n                )\n            )\n        else:  # pragma: no cover\n            # this should not happen, but we're defensive here.\n            return \"\"\n\n    def _echo_request_line(self, flow: http.HTTPFlow) -> None:\n        client = self._fmt_client(flow)\n\n        pushed = \" PUSH_PROMISE\" if \"h2-pushed-stream\" in flow.metadata else \"\"\n        method = flow.request.method + pushed\n        method_color = dict(GET=\"green\", DELETE=\"red\").get(method.upper(), \"magenta\")\n        method = self.style(\n            strutils.escape_control_characters(method), fg=method_color, bold=True\n        )\n        if ctx.options.showhost:\n            url = flow.request.pretty_url\n        else:\n            url = flow.request.url\n\n        if ctx.options.flow_detail == 1:\n            # We need to truncate before applying styles, so we just focus on the URL.\n            terminal_width_limit = max(shutil.get_terminal_size()[0] - 25, 50)\n            if len(url) > terminal_width_limit:\n                url = url[:terminal_width_limit] + \"\u2026\"\n        url = self.style(strutils.escape_control_characters(url), bold=True)\n\n        http_version = \"\"\n        if not (\n            flow.request.is_http10 or flow.request.is_http11\n        ) or flow.request.http_version != getattr(\n            flow.response, \"http_version\", \"HTTP/1.1\"\n        ):\n            # Hide version for h1 <-> h1 connections.\n            http_version = \" \" + flow.request.http_version\n\n        self.echo(f\"{client}: {method} {url}{http_version}\")\n\n    def _echo_response_line(self, flow: http.HTTPFlow) -> None:\n        if flow.is_replay == \"response\":\n            replay_str = \"[replay]\"\n            replay = self.style(replay_str, fg=\"yellow\", bold=True)\n        else:\n            replay_str = \"\"\n            replay = \"\"\n\n        assert flow.response\n        code_int = flow.response.status_code\n        code_color = None\n        if 200 <= code_int < 300:\n            code_color = \"green\"\n        elif 300 <= code_int < 400:\n            code_color = \"magenta\"\n        elif 400 <= code_int < 600:\n            code_color = \"red\"\n        code = self.style(\n            str(code_int),\n            fg=code_color,\n            bold=True,\n            blink=(code_int == 418),\n        )\n\n        if not (flow.response.is_http2 or flow.response.is_http3):\n            reason = flow.response.reason\n        else:\n            reason = http.status_codes.RESPONSES.get(flow.response.status_code, \"\")\n        reason = self.style(\n            strutils.escape_control_characters(reason), fg=code_color, bold=True\n        )\n\n        if flow.response.raw_content is None:\n            size = \"(content missing)\"\n        else:\n            size = human.pretty_size(len(flow.response.raw_content))\n        size = self.style(size, bold=True)\n\n        http_version = \"\"\n        if (\n            not (flow.response.is_http10 or flow.response.is_http11)\n            or flow.request.http_version != flow.response.http_version\n        ):\n            # Hide version for h1 <-> h1 connections.\n            http_version = f\"{flow.response.http_version} \"\n\n        arrows = self.style(\" <<\", bold=True)\n        if ctx.options.flow_detail == 1:\n            # This aligns the HTTP response code with the HTTP request method:\n            # 127.0.0.1:59519: GET http://example.com/\n            #               << 304 Not Modified 0b\n            pad = max(\n                0,\n                len(human.format_address(flow.client_conn.peername))\n                - (2 + len(http_version) + len(replay_str)),\n            )\n            arrows = \" \" * pad + arrows\n\n        self.echo(f\"{replay}{arrows} {http_version}{code} {reason} {size}\")\n\n    def echo_flow(self, f: http.HTTPFlow) -> None:\n        if f.request:\n            self._echo_request_line(f)\n            if ctx.options.flow_detail >= 2:\n                self._echo_headers(f.request.headers)\n            if ctx.options.flow_detail >= 3:\n                self._echo_message(f.request, f)\n            if ctx.options.flow_detail >= 2:\n                self._echo_trailers(f.request.trailers)\n\n        if f.response:\n            self._echo_response_line(f)\n            if ctx.options.flow_detail >= 2:\n                self._echo_headers(f.response.headers)\n            if ctx.options.flow_detail >= 3:\n                self._echo_message(f.response, f)\n            if ctx.options.flow_detail >= 2:\n                self._echo_trailers(f.response.trailers)\n\n        if f.error:\n            msg = strutils.escape_control_characters(f.error.msg)\n            self.echo(f\" << {msg}\", bold=True, fg=\"red\")\n\n        self.outfp.flush()\n\n    def match(self, f):\n        if ctx.options.flow_detail == 0:\n            return False\n        if not self.filter:\n            return True\n        elif flowfilter.match(self.filter, f):\n            return True\n        return False\n\n    def response(self, f):\n        if self.match(f):\n            self.echo_flow(f)\n\n    def error(self, f):\n        if self.match(f):\n            self.echo_flow(f)\n\n    def websocket_message(self, f: http.HTTPFlow):\n        assert f.websocket is not None  # satisfy type checker\n        if self.match(f):\n            message = f.websocket.messages[-1]\n\n            direction = \"->\" if message.from_client else \"<-\"\n            self.echo(\n                f\"{human.format_address(f.client_conn.peername)} \"\n                f\"{direction} WebSocket {message.type.name.lower()} message \"\n                f\"{direction} {human.format_address(f.server_conn.address)}{f.request.path}\"\n            )\n            if ctx.options.flow_detail >= 3:\n                self._echo_message(message, f)\n\n    def websocket_end(self, f: http.HTTPFlow):\n        assert f.websocket is not None  # satisfy type checker\n        if self.match(f):\n            if f.websocket.close_code in {1000, 1001, 1005}:\n                c = \"client\" if f.websocket.closed_by_client else \"server\"\n                self.echo(\n                    f\"WebSocket connection closed by {c}: {f.websocket.close_code} {f.websocket.close_reason}\"\n                )\n            else:\n                error = flow.Error(\n                    f\"WebSocket Error: {self.format_websocket_error(f.websocket)}\"\n                )\n                self.echo(\n                    f\"Error in WebSocket connection to {human.format_address(f.server_conn.address)}: {error}\",\n                    fg=\"red\",\n                )\n\n    def format_websocket_error(self, websocket: WebSocketData) -> str:\n        try:\n            ret = CloseReason(websocket.close_code).name  # type: ignore\n        except ValueError:\n            ret = f\"UNKNOWN_ERROR={websocket.close_code}\"\n        if websocket.close_reason:\n            ret += f\" (reason: {websocket.close_reason})\"\n        return ret\n\n    def _proto_error(self, f):\n        if self.match(f):\n            self.echo(\n                f\"Error in {f.type.upper()} connection to {human.format_address(f.server_conn.address)}: {f.error}\",\n                fg=\"red\",\n            )\n\n    def tcp_error(self, f):\n        self._proto_error(f)\n\n    def udp_error(self, f):\n        self._proto_error(f)\n\n    def _proto_message(self, f: TCPFlow | UDPFlow) -> None:\n        if self.match(f):\n            message = f.messages[-1]\n            direction = \"->\" if message.from_client else \"<-\"\n            if f.client_conn.tls_version == \"QUIC\":\n                if f.type == \"tcp\":\n                    quic_type = \"stream\"\n                else:\n                    quic_type = \"dgrams\"\n                # TODO: This should not be metadata, this should be typed attributes.\n                flow_type = (\n                    f\"quic {quic_type} {f.metadata.get('quic_stream_id_client','')} \"\n                    f\"{direction} mitmproxy {direction} \"\n                    f\"quic {quic_type} {f.metadata.get('quic_stream_id_server','')}\"\n                )\n            else:\n                flow_type = f.type\n            self.echo(\n                \"{client} {direction} {type} {direction} {server}\".format(\n                    client=human.format_address(f.client_conn.peername),\n                    server=human.format_address(f.server_conn.address),\n                    direction=direction,\n                    type=flow_type,\n                )\n            )\n            if ctx.options.flow_detail >= 3:\n                self._echo_message(message, f)\n\n    def tcp_message(self, f):\n        self._proto_message(f)\n\n    def udp_message(self, f):\n        self._proto_message(f)\n\n    def _echo_dns_query(self, f: dns.DNSFlow) -> None:\n        client = self._fmt_client(f)\n        opcode = dns.op_codes.to_str(f.request.op_code)\n        type = dns.types.to_str(f.request.questions[0].type)\n\n        desc = f\"DNS {opcode} ({type})\"\n        desc_color = {\n            \"A\": \"green\",\n            \"AAAA\": \"magenta\",\n        }.get(type, \"red\")\n        desc = self.style(desc, fg=desc_color)\n\n        name = self.style(f.request.questions[0].name, bold=True)\n        self.echo(f\"{client}: {desc} {name}\")\n\n    def dns_response(self, f: dns.DNSFlow):\n        assert f.response\n        if self.match(f):\n            self._echo_dns_query(f)\n\n            arrows = self.style(\" <<\", bold=True)\n            if f.response.answers:\n                answers = \", \".join(\n                    self.style(str(x), fg=\"bright_blue\") for x in f.response.answers\n                )\n            else:\n                answers = self.style(\n                    response_codes.to_str(\n                        f.response.response_code,\n                    ),\n                    fg=\"red\",\n                )\n            self.echo(f\"{arrows} {answers}\")\n\n    def dns_error(self, f: dns.DNSFlow):\n        assert f.error\n        if self.match(f):\n            self._echo_dns_query(f)\n            msg = strutils.escape_control_characters(f.error.msg)\n            self.echo(f\" << {msg}\", bold=True, fg=\"red\")\n", "mitmproxy/addons/readfile.py": "import asyncio\nimport logging\nimport os.path\nimport sys\nfrom typing import BinaryIO\nfrom typing import Optional\n\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flowfilter\nfrom mitmproxy import io\n\nlogger = logging.getLogger(__name__)\n\n\nclass ReadFile:\n    \"\"\"\n    An addon that handles reading from file on startup.\n    \"\"\"\n\n    def __init__(self):\n        self.filter = None\n        self._read_task: asyncio.Task | None = None\n\n    def load(self, loader):\n        loader.add_option(\"rfile\", Optional[str], None, \"Read flows from file.\")\n        loader.add_option(\n            \"readfile_filter\", Optional[str], None, \"Read only matching flows.\"\n        )\n\n    def configure(self, updated):\n        if \"readfile_filter\" in updated:\n            if ctx.options.readfile_filter:\n                try:\n                    self.filter = flowfilter.parse(ctx.options.readfile_filter)\n                except ValueError as e:\n                    raise exceptions.OptionsError(str(e)) from e\n            else:\n                self.filter = None\n\n    async def load_flows(self, fo: BinaryIO) -> int:\n        cnt = 0\n        freader = io.FlowReader(fo)\n        try:\n            for flow in freader.stream():\n                if self.filter and not self.filter(flow):\n                    continue\n                await ctx.master.load_flow(flow)\n                cnt += 1\n        except (OSError, exceptions.FlowReadException) as e:\n            if cnt:\n                logging.warning(\"Flow file corrupted - loaded %i flows.\" % cnt)\n            else:\n                logging.error(\"Flow file corrupted.\")\n            raise exceptions.FlowReadException(str(e)) from e\n        else:\n            return cnt\n\n    async def load_flows_from_path(self, path: str) -> int:\n        path = os.path.expanduser(path)\n        try:\n            with open(path, \"rb\") as f:\n                return await self.load_flows(f)\n        except OSError as e:\n            logging.error(f\"Cannot load flows: {e}\")\n            raise exceptions.FlowReadException(str(e)) from e\n\n    async def doread(self, rfile: str) -> None:\n        try:\n            await self.load_flows_from_path(rfile)\n        except exceptions.FlowReadException as e:\n            logger.exception(f\"Failed to read {ctx.options.rfile}: {e}\")\n\n    def running(self):\n        if ctx.options.rfile:\n            self._read_task = asyncio.create_task(self.doread(ctx.options.rfile))\n\n    @command.command(\"readfile.reading\")\n    def reading(self) -> bool:\n        return bool(self._read_task and not self._read_task.done())\n\n\nclass ReadFileStdin(ReadFile):\n    \"\"\"Support the special case of \"-\" for reading from stdin\"\"\"\n\n    async def load_flows_from_path(self, path: str) -> int:\n        if path == \"-\":  # pragma: no cover\n            # Need to think about how to test this. This function is scheduled\n            # onto the event loop, where a sys.stdin mock has no effect.\n            return await self.load_flows(sys.stdin.buffer)\n        else:\n            return await super().load_flows_from_path(path)\n", "mitmproxy/addons/intercept.py": "from typing import Optional\n\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import flowfilter\n\n\nclass Intercept:\n    filt: flowfilter.TFilter | None = None\n\n    def load(self, loader):\n        loader.add_option(\"intercept_active\", bool, False, \"Intercept toggle\")\n        loader.add_option(\n            \"intercept\", Optional[str], None, \"Intercept filter expression.\"\n        )\n\n    def configure(self, updated):\n        if \"intercept\" in updated:\n            if ctx.options.intercept:\n                try:\n                    self.filt = flowfilter.parse(ctx.options.intercept)\n                except ValueError as e:\n                    raise exceptions.OptionsError(str(e)) from e\n                ctx.options.intercept_active = True\n            else:\n                self.filt = None\n                ctx.options.intercept_active = False\n\n    def should_intercept(self, f: flow.Flow) -> bool:\n        return bool(\n            ctx.options.intercept_active\n            and self.filt\n            and self.filt(f)\n            and not f.is_replay\n        )\n\n    def process_flow(self, f: flow.Flow) -> None:\n        if self.should_intercept(f):\n            f.intercept()\n\n    # Handlers\n\n    def request(self, f):\n        self.process_flow(f)\n\n    def response(self, f):\n        self.process_flow(f)\n\n    def tcp_message(self, f):\n        self.process_flow(f)\n\n    def udp_message(self, f):\n        self.process_flow(f)\n\n    def dns_request(self, f):\n        self.process_flow(f)\n\n    def dns_response(self, f):\n        self.process_flow(f)\n\n    def websocket_message(self, f):\n        self.process_flow(f)\n", "mitmproxy/addons/onboardingapp/__init__.py": "import os\n\nfrom flask import Flask\nfrom flask import render_template\n\nfrom mitmproxy.options import CONF_BASENAME\nfrom mitmproxy.options import CONF_DIR\nfrom mitmproxy.utils.magisk import write_magisk_module\n\napp = Flask(__name__)\n# will be overridden in the addon, setting this here so that the Flask app can be run standalone.\napp.config[\"CONFDIR\"] = CONF_DIR\n\n\n@app.route(\"/\")\ndef index():\n    return render_template(\"index.html\")\n\n\n@app.route(\"/cert/pem\")\ndef pem():\n    return read_cert(\"pem\", \"application/x-x509-ca-cert\")\n\n\n@app.route(\"/cert/p12\")\ndef p12():\n    return read_cert(\"p12\", \"application/x-pkcs12\")\n\n\n@app.route(\"/cert/cer\")\ndef cer():\n    return read_cert(\"cer\", \"application/x-x509-ca-cert\")\n\n\n@app.route(\"/cert/magisk\")\ndef magisk():\n    filename = CONF_BASENAME + f\"-magisk-module.zip\"\n    p = os.path.join(app.config[\"CONFDIR\"], filename)\n    p = os.path.expanduser(p)\n\n    if not os.path.exists(p):\n        write_magisk_module(p)\n\n    with open(p, \"rb\") as f:\n        cert = f.read()\n\n    return cert, {\n        \"Content-Type\": \"application/zip\",\n        \"Content-Disposition\": f\"attachment; filename={filename}\",\n    }\n\n\ndef read_cert(ext, content_type):\n    filename = CONF_BASENAME + f\"-ca-cert.{ext}\"\n    p = os.path.join(app.config[\"CONFDIR\"], filename)\n    p = os.path.expanduser(p)\n    with open(p, \"rb\") as f:\n        cert = f.read()\n\n    return cert, {\n        \"Content-Type\": content_type,\n        \"Content-Disposition\": f\"attachment; filename={filename}\",\n    }\n", "mitmproxy/io/tnetstring.py": "\"\"\"\ntnetstring:  data serialization using typed netstrings\n======================================================\n\nThis is a custom Python 3 implementation of tnetstrings.\nCompared to other implementations, the main difference\nis that this implementation supports a custom unicode datatype.\n\nAn ordinary tnetstring is a blob of data prefixed with its length and postfixed\nwith its type. Here are some examples:\n\n    >>> tnetstring.dumps(\"hello world\")\n    11:hello world,\n    >>> tnetstring.dumps(12345)\n    5:12345#\n    >>> tnetstring.dumps([12345, True, 0])\n    19:5:12345#4:true!1:0#]\n\nThis module gives you the following functions:\n\n    :dump:    dump an object as a tnetstring to a file\n    :dumps:   dump an object as a tnetstring to a string\n    :load:    load a tnetstring-encoded object from a file\n    :loads:   load a tnetstring-encoded object from a string\n\nNote that since parsing a tnetstring requires reading all the data into memory\nat once, there's no efficiency gain from using the file-based versions of these\nfunctions.  They're only here so you can use load() to read precisely one\nitem from a file or socket without consuming any extra data.\n\nThe tnetstrings specification explicitly states that strings are binary blobs\nand forbids the use of unicode at the protocol level.\n**This implementation decodes dictionary keys as surrogate-escaped ASCII**,\nall other strings are returned as plain bytes.\n\n:Copyright: (c) 2012-2013 by Ryan Kelly <ryan@rfk.id.au>.\n:Copyright: (c) 2014 by Carlo Pires <carlopires@gmail.com>.\n:Copyright: (c) 2016 by Maximilian Hils <tnetstring3@maximilianhils.com>.\n\n:License: MIT\n\"\"\"\n\nimport collections\nfrom typing import BinaryIO\nfrom typing import Union\n\nTSerializable = Union[None, str, bool, int, float, bytes, list, tuple, dict]\n\n\ndef dumps(value: TSerializable) -> bytes:\n    \"\"\"\n    This function dumps a python object as a tnetstring.\n    \"\"\"\n    #  This uses a deque to collect output fragments in reverse order,\n    #  then joins them together at the end.  It's measurably faster\n    #  than creating all the intermediate strings.\n    q: collections.deque = collections.deque()\n    _rdumpq(q, 0, value)\n    return b\"\".join(q)\n\n\ndef dump(value: TSerializable, file_handle: BinaryIO) -> None:\n    \"\"\"\n    This function dumps a python object as a tnetstring and\n    writes it to the given file.\n    \"\"\"\n    file_handle.write(dumps(value))\n\n\ndef _rdumpq(q: collections.deque, size: int, value: TSerializable) -> int:\n    \"\"\"\n    Dump value as a tnetstring, to a deque instance, last chunks first.\n\n    This function generates the tnetstring representation of the given value,\n    pushing chunks of the output onto the given deque instance.  It pushes\n    the last chunk first, then recursively generates more chunks.\n\n    When passed in the current size of the string in the queue, it will return\n    the new size of the string in the queue.\n\n    Operating last-chunk-first makes it easy to calculate the size written\n    for recursive structures without having to build their representation as\n    a string.  This is measurably faster than generating the intermediate\n    strings, especially on deeply nested structures.\n    \"\"\"\n    write = q.appendleft\n    if value is None:\n        write(b\"0:~\")\n        return size + 3\n    elif value is True:\n        write(b\"4:true!\")\n        return size + 7\n    elif value is False:\n        write(b\"5:false!\")\n        return size + 8\n    elif isinstance(value, int):\n        data = str(value).encode()\n        ldata = len(data)\n        span = str(ldata).encode()\n        write(b\"%s:%s#\" % (span, data))\n        return size + 2 + len(span) + ldata\n    elif isinstance(value, float):\n        #  Use repr() for float rather than str().\n        #  It round-trips more accurately.\n        #  Probably unnecessary in later python versions that\n        #  use David Gay's ftoa routines.\n        data = repr(value).encode()\n        ldata = len(data)\n        span = str(ldata).encode()\n        write(b\"%s:%s^\" % (span, data))\n        return size + 2 + len(span) + ldata\n    elif isinstance(value, bytes):\n        data = value\n        ldata = len(data)\n        span = str(ldata).encode()\n        write(b\",\")\n        write(data)\n        write(b\":\")\n        write(span)\n        return size + 2 + len(span) + ldata\n    elif isinstance(value, str):\n        data = value.encode(\"utf8\")\n        ldata = len(data)\n        span = str(ldata).encode()\n        write(b\";\")\n        write(data)\n        write(b\":\")\n        write(span)\n        return size + 2 + len(span) + ldata\n    elif isinstance(value, (list, tuple)):\n        write(b\"]\")\n        init_size = size = size + 1\n        for item in reversed(value):\n            size = _rdumpq(q, size, item)\n        span = str(size - init_size).encode()\n        write(b\":\")\n        write(span)\n        return size + 1 + len(span)\n    elif isinstance(value, dict):\n        write(b\"}\")\n        init_size = size = size + 1\n        for k, v in value.items():\n            size = _rdumpq(q, size, v)\n            size = _rdumpq(q, size, k)\n        span = str(size - init_size).encode()\n        write(b\":\")\n        write(span)\n        return size + 1 + len(span)\n    else:\n        raise ValueError(f\"unserializable object: {value} ({type(value)})\")\n\n\ndef loads(string: bytes) -> TSerializable:\n    \"\"\"\n    This function parses a tnetstring into a python object.\n    \"\"\"\n    return pop(string)[0]\n\n\ndef load(file_handle: BinaryIO) -> TSerializable:\n    \"\"\"load(file) -> object\n\n    This function reads a tnetstring from a file and parses it into a\n    python object.  The file must support the read() method, and this\n    function promises not to read more data than necessary.\n    \"\"\"\n    #  Read the length prefix one char at a time.\n    #  Note that the netstring spec explicitly forbids padding zeros.\n    c = file_handle.read(1)\n    if c == b\"\":  # we want to detect this special case.\n        raise ValueError(\"not a tnetstring: empty file\")\n    data_length = b\"\"\n    while c.isdigit():\n        data_length += c\n        if len(data_length) > 12:\n            raise ValueError(\"not a tnetstring: absurdly large length prefix\")\n        c = file_handle.read(1)\n    if c != b\":\":\n        raise ValueError(\"not a tnetstring: missing or invalid length prefix\")\n\n    data = file_handle.read(int(data_length))\n    data_type = file_handle.read(1)[0]\n\n    return parse(data_type, data)\n\n\ndef parse(data_type: int, data: bytes) -> TSerializable:\n    if data_type == ord(b\",\"):\n        return data\n    if data_type == ord(b\";\"):\n        return data.decode(\"utf8\")\n    if data_type == ord(b\"#\"):\n        try:\n            return int(data)\n        except ValueError:\n            raise ValueError(f\"not a tnetstring: invalid integer literal: {data!r}\")\n    if data_type == ord(b\"^\"):\n        try:\n            return float(data)\n        except ValueError:\n            raise ValueError(f\"not a tnetstring: invalid float literal: {data!r}\")\n    if data_type == ord(b\"!\"):\n        if data == b\"true\":\n            return True\n        elif data == b\"false\":\n            return False\n        else:\n            raise ValueError(f\"not a tnetstring: invalid boolean literal: {data!r}\")\n    if data_type == ord(b\"~\"):\n        if data:\n            raise ValueError(f\"not a tnetstring: invalid null literal: {data!r}\")\n        return None\n    if data_type == ord(b\"]\"):\n        lst = []\n        while data:\n            item, data = pop(data)\n            lst.append(item)  # type: ignore\n        return lst\n    if data_type == ord(b\"}\"):\n        d = {}\n        while data:\n            key, data = pop(data)\n            val, data = pop(data)\n            d[key] = val  # type: ignore\n        return d\n    raise ValueError(f\"unknown type tag: {data_type}\")\n\n\ndef pop(data: bytes) -> tuple[TSerializable, bytes]:\n    \"\"\"\n    This function parses a tnetstring into a python object.\n    It returns a tuple giving the parsed object and a string\n    containing any unparsed data from the end of the string.\n    \"\"\"\n    #  Parse out data length, type and remaining string.\n    try:\n        blength, data = data.split(b\":\", 1)\n        length = int(blength)\n    except ValueError:\n        raise ValueError(\n            f\"not a tnetstring: missing or invalid length prefix: {data!r}\"\n        )\n    try:\n        data, data_type, remain = data[:length], data[length], data[length + 1 :]\n    except IndexError:\n        #  This fires if len(data) < dlen, meaning we don't need\n        #  to further validate that data is the right length.\n        raise ValueError(f\"not a tnetstring: invalid length prefix: {length}\")\n    # Parse the data based on the type tag.\n    return parse(data_type, data), remain\n\n\n__all__ = [\"dump\", \"dumps\", \"load\", \"loads\", \"pop\"]\n", "mitmproxy/io/har.py": "\"\"\"Reads HAR files into flow objects\"\"\"\n\nimport base64\nimport logging\nimport time\nfrom datetime import datetime\n\nfrom mitmproxy import connection\nfrom mitmproxy import exceptions\nfrom mitmproxy import http\nfrom mitmproxy.net.http.headers import infer_content_encoding\n\nlogger = logging.getLogger(__name__)\n\n\ndef fix_headers(\n    request_headers: list[dict[str, str]] | list[tuple[str, str]],\n) -> http.Headers:\n    \"\"\"Converts provided headers into (b\"header-name\", b\"header-value\") tuples\"\"\"\n    flow_headers: list[tuple[bytes, bytes]] = []\n    for header in request_headers:\n        # Applications that use the {\"name\":item,\"value\":item} notation are Brave,Chrome,Edge,Firefox,Charles,Fiddler,Insomnia,Safari\n        if isinstance(header, dict):\n            key = header[\"name\"]\n            value = header[\"value\"]\n\n        # Application that uses the [name, value] notation is Slack\n\n        else:\n            try:\n                key = header[0]\n                value = header[1]\n            except IndexError as e:\n                raise exceptions.OptionsError(str(e)) from e\n        flow_headers.append((key.encode(), value.encode()))\n\n    return http.Headers(flow_headers)\n\n\ndef request_to_flow(request_json: dict) -> http.HTTPFlow:\n    \"\"\"\n    Creates a HTTPFlow object from a given entry in HAR file\n    \"\"\"\n\n    timestamp_start = datetime.fromisoformat(\n        request_json[\"startedDateTime\"].replace(\"Z\", \"+00:00\")\n    ).timestamp()\n    timestamp_end = timestamp_start + request_json[\"time\"]\n    request_method = request_json[\"request\"][\"method\"]\n    request_url = request_json[\"request\"][\"url\"]\n    server_address = request_json.get(\"serverIPAddress\", None)\n    request_headers = fix_headers(request_json[\"request\"][\"headers\"])\n\n    http_version_req = request_json[\"request\"][\"httpVersion\"]\n    http_version_resp = request_json[\"response\"][\"httpVersion\"]\n\n    request_content = \"\"\n    # List contains all the representations of an http request across different HAR files\n    if request_url.startswith(\"http://\"):\n        port = 80\n    else:\n        port = 443\n\n    client_conn = connection.Client(\n        peername=(\"127.0.0.1\", 0),\n        sockname=(\"127.0.0.1\", 0),\n        # TODO Get time info from HAR File\n        timestamp_start=time.time(),\n    )\n\n    if server_address:\n        server_conn = connection.Server(address=(server_address, port))\n    else:\n        server_conn = connection.Server(address=None)\n\n    new_flow = http.HTTPFlow(client_conn, server_conn)\n\n    if \"postData\" in request_json[\"request\"]:\n        request_content = request_json[\"request\"][\"postData\"][\"text\"]\n\n    new_flow.request = http.Request.make(\n        request_method, request_url, request_content, request_headers\n    )\n\n    response_code = request_json[\"response\"][\"status\"]\n\n    # In Firefox HAR files images don't include response bodies\n    response_content = request_json[\"response\"][\"content\"].get(\"text\", \"\")\n    content_encoding = request_json[\"response\"][\"content\"].get(\"encoding\", None)\n    response_headers = fix_headers(request_json[\"response\"][\"headers\"])\n\n    if content_encoding == \"base64\":\n        response_content = base64.b64decode(response_content)\n    elif isinstance(response_content, str):\n        # Convert text to bytes, as in `Response.set_text`\n        try:\n            response_content = http.encoding.encode(\n                response_content,\n                (\n                    content_encoding\n                    or infer_content_encoding(response_headers.get(\"content-type\", \"\"))\n                ),\n            )\n        except ValueError:\n            # Fallback to UTF-8\n            response_content = response_content.encode(\n                \"utf-8\", errors=\"surrogateescape\"\n            )\n\n    # Then encode the content, as in `Response.set_content`\n    response_content = http.encoding.encode(\n        response_content, response_headers.get(\"content-encoding\") or \"identity\"\n    )\n\n    new_flow.response = http.Response(\n        b\"HTTP/1.1\",\n        response_code,\n        http.status_codes.RESPONSES.get(response_code, \"\").encode(),\n        response_headers,\n        response_content,\n        None,\n        timestamp_start,\n        timestamp_end,\n    )\n\n    # Update timestamps\n\n    new_flow.request.timestamp_start = timestamp_start\n    new_flow.request.timestamp_end = timestamp_end\n\n    new_flow.client_conn.timestamp_start = timestamp_start\n    new_flow.client_conn.timestamp_end = timestamp_end\n\n    # Update HTTP version\n\n    match http_version_req:\n        case \"http/2.0\":\n            new_flow.request.http_version = \"HTTP/2\"\n        case \"HTTP/2\":\n            new_flow.request.http_version = \"HTTP/2\"\n        case \"HTTP/3\":\n            new_flow.request.http_version = \"HTTP/3\"\n        case _:\n            new_flow.request.http_version = \"HTTP/1.1\"\n    match http_version_resp:\n        case \"http/2.0\":\n            new_flow.response.http_version = \"HTTP/2\"\n        case \"HTTP/2\":\n            new_flow.response.http_version = \"HTTP/2\"\n        case \"HTTP/3\":\n            new_flow.response.http_version = \"HTTP/3\"\n        case _:\n            new_flow.response.http_version = \"HTTP/1.1\"\n\n    return new_flow\n", "mitmproxy/io/io.py": "import json\nimport os\nfrom collections.abc import Iterable\nfrom io import BufferedReader\nfrom typing import Any\nfrom typing import BinaryIO\nfrom typing import cast\nfrom typing import Union\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import flowfilter\nfrom mitmproxy.io import compat\nfrom mitmproxy.io import tnetstring\nfrom mitmproxy.io.har import request_to_flow\n\n\nclass FlowWriter:\n    def __init__(self, fo):\n        self.fo = fo\n\n    def add(self, f: flow.Flow) -> None:\n        d = f.get_state()\n        tnetstring.dump(d, self.fo)\n\n\nclass FlowReader:\n    fo: BinaryIO\n\n    def __init__(self, fo: BinaryIO):\n        self.fo = fo\n\n    def peek(self, n: int) -> bytes:\n        try:\n            return cast(BufferedReader, self.fo).peek(n)\n        except AttributeError:\n            # https://github.com/python/cpython/issues/90533: io.BytesIO does not have peek()\n            pos = self.fo.tell()\n            ret = self.fo.read(n)\n            self.fo.seek(pos)\n            return ret\n\n    def stream(self) -> Iterable[flow.Flow]:\n        \"\"\"\n        Yields Flow objects from the dump.\n        \"\"\"\n\n        if self.peek(1).startswith(b\"{\"):\n            try:\n                har_file = json.loads(self.fo.read().decode(\"utf-8\"))\n\n                for request_json in har_file[\"log\"][\"entries\"]:\n                    yield request_to_flow(request_json)\n\n            except Exception:\n                raise exceptions.FlowReadException(\n                    \"Unable to read HAR file. Please provide a valid HAR file\"\n                )\n\n        else:\n            try:\n                while True:\n                    # FIXME: This cast hides a lack of dynamic type checking\n                    loaded = cast(\n                        dict[Union[bytes, str], Any],\n                        tnetstring.load(self.fo),\n                    )\n                    try:\n                        yield flow.Flow.from_state(compat.migrate_flow(loaded))\n                    except ValueError as e:\n                        raise exceptions.FlowReadException(e) from e\n            except (ValueError, TypeError, IndexError) as e:\n                if str(e) == \"not a tnetstring: empty file\":\n                    return  # Error is due to EOF\n                raise exceptions.FlowReadException(\"Invalid data format.\") from e\n\n\nclass FilteredFlowWriter:\n    def __init__(self, fo, flt):\n        self.fo = fo\n        self.flt = flt\n\n    def add(self, f: flow.Flow) -> None:\n        if self.flt and not flowfilter.match(self.flt, f):\n            return\n        d = f.get_state()\n        tnetstring.dump(d, self.fo)\n\n\ndef read_flows_from_paths(paths) -> list[flow.Flow]:\n    \"\"\"\n    Given a list of filepaths, read all flows and return a list of them.\n    From a performance perspective, streaming would be advisable -\n    however, if there's an error with one of the files, we want it to be raised immediately.\n\n    Raises:\n        FlowReadException, if any error occurs.\n    \"\"\"\n    try:\n        flows: list[flow.Flow] = []\n        for path in paths:\n            path = os.path.expanduser(path)\n            with open(path, \"rb\") as f:\n                flows.extend(FlowReader(f).stream())\n    except OSError as e:\n        raise exceptions.FlowReadException(e.strerror)\n    return flows\n", "mitmproxy/io/__init__.py": "from .io import FilteredFlowWriter\nfrom .io import FlowReader\nfrom .io import FlowWriter\nfrom .io import read_flows_from_paths\n\n__all__ = [\"FlowWriter\", \"FlowReader\", \"FilteredFlowWriter\", \"read_flows_from_paths\"]\n", "mitmproxy/io/compat.py": "\"\"\"\nThis module handles the import of mitmproxy flows generated by old versions.\n\nThe flow file version is decoupled from the mitmproxy release cycle (since\nv3.0.0dev) and versioning. Every change or migration gets a new flow file\nversion number, this prevents issues with developer builds and snapshots.\n\"\"\"\n\nimport copy\nimport uuid\nfrom typing import Any\n\nfrom mitmproxy import version\nfrom mitmproxy.utils import strutils\n\n\ndef convert_011_012(data):\n    data[b\"version\"] = (0, 12)\n    return data\n\n\ndef convert_012_013(data):\n    data[b\"version\"] = (0, 13)\n    return data\n\n\ndef convert_013_014(data):\n    data[b\"request\"][b\"first_line_format\"] = data[b\"request\"].pop(b\"form_in\")\n    data[b\"request\"][b\"http_version\"] = (\n        b\"HTTP/\"\n        + \".\".join(str(x) for x in data[b\"request\"].pop(b\"httpversion\")).encode()\n    )\n    data[b\"response\"][b\"http_version\"] = (\n        b\"HTTP/\"\n        + \".\".join(str(x) for x in data[b\"response\"].pop(b\"httpversion\")).encode()\n    )\n    data[b\"response\"][b\"status_code\"] = data[b\"response\"].pop(b\"code\")\n    data[b\"response\"][b\"body\"] = data[b\"response\"].pop(b\"content\")\n    data[b\"server_conn\"].pop(b\"state\")\n    data[b\"server_conn\"][b\"via\"] = None\n    data[b\"version\"] = (0, 14)\n    return data\n\n\ndef convert_014_015(data):\n    data[b\"version\"] = (0, 15)\n    return data\n\n\ndef convert_015_016(data):\n    for m in (b\"request\", b\"response\"):\n        if b\"body\" in data[m]:\n            data[m][b\"content\"] = data[m].pop(b\"body\")\n    if b\"msg\" in data[b\"response\"]:\n        data[b\"response\"][b\"reason\"] = data[b\"response\"].pop(b\"msg\")\n    data[b\"request\"].pop(b\"form_out\", None)\n    data[b\"version\"] = (0, 16)\n    return data\n\n\ndef convert_016_017(data):\n    data[b\"server_conn\"][b\"peer_address\"] = None\n    data[b\"version\"] = (0, 17)\n    return data\n\n\ndef convert_017_018(data):\n    # convert_unicode needs to be called for every dual release and the first py3-only release\n    data = convert_unicode(data)\n\n    data[\"server_conn\"][\"ip_address\"] = data[\"server_conn\"].pop(\"peer_address\", None)\n    data[\"marked\"] = False\n    data[\"version\"] = (0, 18)\n    return data\n\n\ndef convert_018_019(data):\n    # convert_unicode needs to be called for every dual release and the first py3-only release\n    data = convert_unicode(data)\n\n    data[\"request\"].pop(\"stickyauth\", None)\n    data[\"request\"].pop(\"stickycookie\", None)\n    data[\"client_conn\"][\"sni\"] = None\n    data[\"client_conn\"][\"alpn_proto_negotiated\"] = None\n    data[\"client_conn\"][\"cipher_name\"] = None\n    data[\"client_conn\"][\"tls_version\"] = None\n    data[\"server_conn\"][\"alpn_proto_negotiated\"] = None\n    if data[\"server_conn\"][\"via\"]:\n        data[\"server_conn\"][\"via\"][\"alpn_proto_negotiated\"] = None\n    data[\"mode\"] = \"regular\"\n    data[\"metadata\"] = dict()\n    data[\"version\"] = (0, 19)\n    return data\n\n\ndef convert_019_100(data):\n    # convert_unicode needs to be called for every dual release and the first py3-only release\n    data = convert_unicode(data)\n\n    data[\"version\"] = (1, 0, 0)\n    return data\n\n\ndef convert_100_200(data):\n    data[\"version\"] = (2, 0, 0)\n    data[\"client_conn\"][\"address\"] = data[\"client_conn\"][\"address\"][\"address\"]\n    data[\"server_conn\"][\"address\"] = data[\"server_conn\"][\"address\"][\"address\"]\n    data[\"server_conn\"][\"source_address\"] = data[\"server_conn\"][\"source_address\"][\n        \"address\"\n    ]\n    if data[\"server_conn\"][\"ip_address\"]:\n        data[\"server_conn\"][\"ip_address\"] = data[\"server_conn\"][\"ip_address\"][\"address\"]\n\n    if data[\"server_conn\"][\"via\"]:\n        data[\"server_conn\"][\"via\"][\"address\"] = data[\"server_conn\"][\"via\"][\"address\"][\n            \"address\"\n        ]\n        data[\"server_conn\"][\"via\"][\"source_address\"] = data[\"server_conn\"][\"via\"][\n            \"source_address\"\n        ][\"address\"]\n        if data[\"server_conn\"][\"via\"][\"ip_address\"]:\n            data[\"server_conn\"][\"via\"][\"ip_address\"] = data[\"server_conn\"][\"via\"][\n                \"ip_address\"\n            ][\"address\"]\n\n    return data\n\n\ndef convert_200_300(data):\n    data[\"version\"] = (3, 0, 0)\n    data[\"client_conn\"][\"mitmcert\"] = None\n    data[\"server_conn\"][\"tls_version\"] = None\n    if data[\"server_conn\"][\"via\"]:\n        data[\"server_conn\"][\"via\"][\"tls_version\"] = None\n    return data\n\n\ndef convert_300_4(data):\n    data[\"version\"] = 4\n    # This is an empty migration to transition to the new versioning scheme.\n    return data\n\n\nclient_connections: dict[tuple[str, ...], str] = {}\nserver_connections: dict[tuple[str, ...], str] = {}\n\n\ndef convert_4_5(data):\n    data[\"version\"] = 5\n    client_conn_key = (\n        data[\"client_conn\"][\"timestamp_start\"],\n        *data[\"client_conn\"][\"address\"],\n    )\n    server_conn_key = (\n        data[\"server_conn\"][\"timestamp_start\"],\n        *data[\"server_conn\"][\"source_address\"],\n    )\n    data[\"client_conn\"][\"id\"] = client_connections.setdefault(\n        client_conn_key, str(uuid.uuid4())\n    )\n    data[\"server_conn\"][\"id\"] = server_connections.setdefault(\n        server_conn_key, str(uuid.uuid4())\n    )\n\n    if data[\"server_conn\"][\"via\"]:\n        server_conn_key = (\n            data[\"server_conn\"][\"via\"][\"timestamp_start\"],\n            *data[\"server_conn\"][\"via\"][\"source_address\"],\n        )\n        data[\"server_conn\"][\"via\"][\"id\"] = server_connections.setdefault(\n            server_conn_key, str(uuid.uuid4())\n        )\n\n    return data\n\n\ndef convert_5_6(data):\n    data[\"version\"] = 6\n    data[\"client_conn\"][\"tls_established\"] = data[\"client_conn\"].pop(\"ssl_established\")\n    data[\"client_conn\"][\"timestamp_tls_setup\"] = data[\"client_conn\"].pop(\n        \"timestamp_ssl_setup\"\n    )\n    data[\"server_conn\"][\"tls_established\"] = data[\"server_conn\"].pop(\"ssl_established\")\n    data[\"server_conn\"][\"timestamp_tls_setup\"] = data[\"server_conn\"].pop(\n        \"timestamp_ssl_setup\"\n    )\n    if data[\"server_conn\"][\"via\"]:\n        data[\"server_conn\"][\"via\"][\"tls_established\"] = data[\"server_conn\"][\"via\"].pop(\n            \"ssl_established\"\n        )\n        data[\"server_conn\"][\"via\"][\"timestamp_tls_setup\"] = data[\"server_conn\"][\n            \"via\"\n        ].pop(\"timestamp_ssl_setup\")\n    return data\n\n\ndef convert_6_7(data):\n    data[\"version\"] = 7\n    data[\"client_conn\"][\"tls_extensions\"] = None\n    return data\n\n\ndef convert_7_8(data):\n    data[\"version\"] = 8\n    if \"request\" in data and data[\"request\"] is not None:\n        data[\"request\"][\"trailers\"] = None\n    if \"response\" in data and data[\"response\"] is not None:\n        data[\"response\"][\"trailers\"] = None\n    return data\n\n\ndef convert_8_9(data):\n    data[\"version\"] = 9\n    is_request_replay = False\n    if \"request\" in data:\n        data[\"request\"].pop(\"first_line_format\")\n        data[\"request\"][\"authority\"] = b\"\"\n        is_request_replay = data[\"request\"].pop(\"is_replay\", False)\n    is_response_replay = False\n    if \"response\" in data and data[\"response\"] is not None:\n        is_response_replay = data[\"response\"].pop(\"is_replay\", False)\n    if is_request_replay:  # pragma: no cover\n        data[\"is_replay\"] = \"request\"\n    elif is_response_replay:  # pragma: no cover\n        data[\"is_replay\"] = \"response\"\n    else:\n        data[\"is_replay\"] = None\n    return data\n\n\ndef convert_9_10(data):\n    data[\"version\"] = 10\n\n    def conv_conn(conn):\n        conn[\"state\"] = 0\n        conn[\"error\"] = None\n        conn[\"tls\"] = conn[\"tls_established\"]\n        alpn = conn[\"alpn_proto_negotiated\"]\n        conn[\"alpn_offers\"] = [alpn] if alpn else None\n        cipher = conn[\"cipher_name\"]\n        conn[\"cipher_list\"] = [cipher] if cipher else None\n\n    def conv_cconn(conn):\n        conn[\"sockname\"] = (\"\", 0)\n        cc = conn.pop(\"clientcert\", None)\n        conn[\"certificate_list\"] = [cc] if cc else []\n        conv_conn(conn)\n\n    def conv_sconn(conn):\n        crt = conn.pop(\"cert\", None)\n        conn[\"certificate_list\"] = [crt] if crt else []\n        conn[\"cipher_name\"] = None\n        conn[\"via2\"] = None\n        conv_conn(conn)\n\n    conv_cconn(data[\"client_conn\"])\n    conv_sconn(data[\"server_conn\"])\n    if data[\"server_conn\"][\"via\"]:\n        conv_sconn(data[\"server_conn\"][\"via\"])\n\n    return data\n\n\ndef convert_10_11(data):\n    data[\"version\"] = 11\n\n    def conv_conn(conn):\n        conn[\"sni\"] = strutils.always_str(conn[\"sni\"], \"ascii\", \"backslashreplace\")\n        conn[\"alpn\"] = conn.pop(\"alpn_proto_negotiated\")\n        conn[\"alpn_offers\"] = conn[\"alpn_offers\"] or []\n        conn[\"cipher_list\"] = conn[\"cipher_list\"] or []\n\n    conv_conn(data[\"client_conn\"])\n    conv_conn(data[\"server_conn\"])\n    if data[\"server_conn\"][\"via\"]:\n        conv_conn(data[\"server_conn\"][\"via\"])\n\n    return data\n\n\n_websocket_handshakes = {}\n\n\ndef convert_11_12(data):\n    data[\"version\"] = 12\n\n    if \"websocket\" in data[\"metadata\"]:\n        _websocket_handshakes[data[\"id\"]] = copy.deepcopy(data)\n\n    if \"websocket_handshake\" in data[\"metadata\"]:\n        ws_flow = data\n        try:\n            data = _websocket_handshakes.pop(data[\"metadata\"][\"websocket_handshake\"])\n        except KeyError:\n            # The handshake flow is missing, which should never really happen. We make up a dummy.\n            data = {\n                \"client_conn\": data[\"client_conn\"],\n                \"error\": data[\"error\"],\n                \"id\": data[\"id\"],\n                \"intercepted\": data[\"intercepted\"],\n                \"is_replay\": data[\"is_replay\"],\n                \"marked\": data[\"marked\"],\n                \"metadata\": {},\n                \"mode\": \"transparent\",\n                \"request\": {\n                    \"authority\": b\"\",\n                    \"content\": None,\n                    \"headers\": [],\n                    \"host\": b\"unknown\",\n                    \"http_version\": b\"HTTP/1.1\",\n                    \"method\": b\"GET\",\n                    \"path\": b\"/\",\n                    \"port\": 80,\n                    \"scheme\": b\"http\",\n                    \"timestamp_end\": 0,\n                    \"timestamp_start\": 0,\n                    \"trailers\": None,\n                },\n                \"response\": None,\n                \"server_conn\": data[\"server_conn\"],\n                \"type\": \"http\",\n                \"version\": 12,\n            }\n        data[\"metadata\"][\"duplicated\"] = (\n            \"This WebSocket flow has been migrated from an old file format version \"\n            \"and may appear duplicated.\"\n        )\n        data[\"websocket\"] = {\n            \"messages\": ws_flow[\"messages\"],\n            \"closed_by_client\": ws_flow[\"close_sender\"] == \"client\",\n            \"close_code\": ws_flow[\"close_code\"],\n            \"close_reason\": ws_flow[\"close_reason\"],\n            \"timestamp_end\": data.get(\"server_conn\", {}).get(\"timestamp_end\", None),\n        }\n\n    else:\n        data[\"websocket\"] = None\n\n    return data\n\n\ndef convert_12_13(data):\n    data[\"version\"] = 13\n    if data[\"marked\"]:\n        data[\"marked\"] = \":default:\"\n    else:\n        data[\"marked\"] = \"\"\n    return data\n\n\ndef convert_13_14(data):\n    data[\"version\"] = 14\n    data[\"comment\"] = \"\"\n    # bugfix for https://github.com/mitmproxy/mitmproxy/issues/4576\n    if data.get(\"response\", None) and data[\"response\"][\"timestamp_start\"] is None:\n        data[\"response\"][\"timestamp_start\"] = data[\"request\"][\"timestamp_end\"]\n        data[\"response\"][\"timestamp_end\"] = data[\"request\"][\"timestamp_end\"] + 1\n    return data\n\n\ndef convert_14_15(data):\n    data[\"version\"] = 15\n    if data.get(\"websocket\", None):\n        # Add \"injected\" attribute.\n        data[\"websocket\"][\"messages\"] = [\n            msg + [False] for msg in data[\"websocket\"][\"messages\"]\n        ]\n    return data\n\n\ndef convert_15_16(data):\n    data[\"version\"] = 16\n    data[\"timestamp_created\"] = data.get(\"request\", data[\"client_conn\"])[\n        \"timestamp_start\"\n    ]\n    return data\n\n\ndef convert_16_17(data):\n    data[\"version\"] = 17\n    data.pop(\"mode\", None)\n    return data\n\n\ndef convert_17_18(data):\n    data[\"version\"] = 18\n    data[\"client_conn\"][\"proxy_mode\"] = \"regular\"\n    return data\n\n\ndef convert_18_19(data):\n    data[\"version\"] = 19\n    data[\"client_conn\"][\"peername\"] = data[\"client_conn\"].pop(\"address\", None)\n    if data[\"client_conn\"].get(\"timestamp_start\") is None:\n        data[\"client_conn\"][\"timestamp_start\"] = 0.0\n    data[\"client_conn\"].pop(\"tls_extensions\")\n\n    data[\"server_conn\"][\"peername\"] = data[\"server_conn\"].pop(\"ip_address\", None)\n    data[\"server_conn\"][\"sockname\"] = data[\"server_conn\"].pop(\"source_address\", None)\n    data[\"server_conn\"][\"via\"] = data[\"server_conn\"].pop(\"via2\", None)\n\n    for conn in [\"client_conn\", \"server_conn\"]:\n        data[conn].pop(\"tls_established\")\n\n        data[conn][\"cipher\"] = data[conn].pop(\"cipher_name\", None)\n        data[conn].setdefault(\"transport_protocol\", \"tcp\")\n\n        for name in [\"peername\", \"sockname\", \"address\"]:\n            if data[conn].get(name) and isinstance(data[conn][name][0], bytes):\n                data[conn][name][0] = data[conn][name][0].decode(\n                    errors=\"backslashreplace\"\n                )\n\n    if data[\"server_conn\"][\"sni\"] is True:\n        data[\"server_conn\"][\"sni\"] = data[\"server_conn\"][\"address\"][0]\n\n    return data\n\n\ndef convert_19_20(data):\n    data[\"version\"] = 20\n    data[\"client_conn\"].pop(\"state\", None)\n    data[\"server_conn\"].pop(\"state\", None)\n    return data\n\n\ndef _convert_dict_keys(o: Any) -> Any:\n    if isinstance(o, dict):\n        return {strutils.always_str(k): _convert_dict_keys(v) for k, v in o.items()}\n    else:\n        return o\n\n\ndef _convert_dict_vals(o: dict, values_to_convert: dict) -> dict:\n    for k, v in values_to_convert.items():\n        if not o or k not in o:\n            continue  # pragma: no cover\n        if v is True:\n            o[k] = strutils.always_str(o[k])\n        else:\n            _convert_dict_vals(o[k], v)\n    return o\n\n\ndef convert_unicode(data: dict) -> dict:\n    \"\"\"\n    This method converts between Python 3 and Python 2 dumpfiles.\n    \"\"\"\n    data = _convert_dict_keys(data)\n    data = _convert_dict_vals(\n        data,\n        {\n            \"type\": True,\n            \"id\": True,\n            \"request\": {\"first_line_format\": True},\n            \"error\": {\"msg\": True},\n        },\n    )\n    return data\n\n\nconverters = {\n    (0, 11): convert_011_012,\n    (0, 12): convert_012_013,\n    (0, 13): convert_013_014,\n    (0, 14): convert_014_015,\n    (0, 15): convert_015_016,\n    (0, 16): convert_016_017,\n    (0, 17): convert_017_018,\n    (0, 18): convert_018_019,\n    (0, 19): convert_019_100,\n    (1, 0): convert_100_200,\n    (2, 0): convert_200_300,\n    (3, 0): convert_300_4,\n    4: convert_4_5,\n    5: convert_5_6,\n    6: convert_6_7,\n    7: convert_7_8,\n    8: convert_8_9,\n    9: convert_9_10,\n    10: convert_10_11,\n    11: convert_11_12,\n    12: convert_12_13,\n    13: convert_13_14,\n    14: convert_14_15,\n    15: convert_15_16,\n    16: convert_16_17,\n    17: convert_17_18,\n    18: convert_18_19,\n    19: convert_19_20,\n}\n\n\ndef migrate_flow(flow_data: dict[bytes | str, Any]) -> dict[bytes | str, Any]:\n    while True:\n        flow_version = flow_data.get(b\"version\", flow_data.get(\"version\"))\n\n        # Historically, we used the mitmproxy minor version tuple as the flow format version.\n        if not isinstance(flow_version, int):\n            flow_version = tuple(flow_version)[:2]\n\n        if flow_version == version.FLOW_FORMAT_VERSION:\n            break\n        elif flow_version in converters:\n            flow_data = converters[flow_version](flow_data)\n        else:\n            should_upgrade = (\n                isinstance(flow_version, int)\n                and flow_version > version.FLOW_FORMAT_VERSION\n            )\n            raise ValueError(\n                \"{} cannot read files with flow format version {}{}.\".format(\n                    version.MITMPROXY,\n                    flow_version,\n                    \", please update mitmproxy\" if should_upgrade else \"\",\n                )\n            )\n    return flow_data\n", "mitmproxy/contrib/imghdr.py": "# A vendored copy of Python's imghdr module, which is slated for removal in Python 3.13.\n#\n# Source: https://github.com/python/cpython/blob/3.12/Lib/imghdr.py\n# SPDX-License-Identifier: PSF-2.0\n\n\"\"\"Recognize image file formats based on their first few bytes.\"\"\"\n\nfrom os import PathLike\nimport warnings\n\n__all__ = [\"what\"]\n\n\n# warnings._deprecated(__name__, remove=(3, 13))\n\n\n#-------------------------#\n# Recognize image headers #\n#-------------------------#\n\ndef what(file, h=None):\n    \"\"\"Return the type of image contained in a file or byte stream.\"\"\"\n    f = None\n    try:\n        if h is None:\n            if isinstance(file, (str, PathLike)):\n                f = open(file, 'rb')\n                h = f.read(32)\n            else:\n                location = file.tell()\n                h = file.read(32)\n                file.seek(location)\n        for tf in tests:\n            res = tf(h, f)\n            if res:\n                return res\n    finally:\n        if f: f.close()\n    return None\n\n\n#---------------------------------#\n# Subroutines per image file type #\n#---------------------------------#\n\ntests = []\n\ndef test_jpeg(h, f):\n    \"\"\"Test for JPEG data with JFIF or Exif markers; and raw JPEG.\"\"\"\n    if h[6:10] in (b'JFIF', b'Exif'):\n        return 'jpeg'\n    elif h[:4] == b'\\xff\\xd8\\xff\\xdb':\n        return 'jpeg'\n\ntests.append(test_jpeg)\n\ndef test_png(h, f):\n    \"\"\"Verify if the image is a PNG.\"\"\"\n    if h.startswith(b'\\211PNG\\r\\n\\032\\n'):\n        return 'png'\n\ntests.append(test_png)\n\ndef test_gif(h, f):\n    \"\"\"Verify if the image is a GIF ('87 or '89 variants).\"\"\"\n    if h[:6] in (b'GIF87a', b'GIF89a'):\n        return 'gif'\n\ntests.append(test_gif)\n\ndef test_tiff(h, f):\n    \"\"\"Verify if the image is a TIFF (can be in Motorola or Intel byte order).\"\"\"\n    if h[:2] in (b'MM', b'II'):\n        return 'tiff'\n\ntests.append(test_tiff)\n\ndef test_rgb(h, f):\n    \"\"\"test for the SGI image library.\"\"\"\n    if h.startswith(b'\\001\\332'):\n        return 'rgb'\n\ntests.append(test_rgb)\n\ndef test_pbm(h, f):\n    \"\"\"Verify if the image is a PBM (portable bitmap).\"\"\"\n    if len(h) >= 3 and \\\n        h[0] == ord(b'P') and h[1] in b'14' and h[2] in b' \\t\\n\\r':\n        return 'pbm'\n\ntests.append(test_pbm)\n\ndef test_pgm(h, f):\n    \"\"\"Verify if the image is a PGM (portable graymap).\"\"\"\n    if len(h) >= 3 and \\\n        h[0] == ord(b'P') and h[1] in b'25' and h[2] in b' \\t\\n\\r':\n        return 'pgm'\n\ntests.append(test_pgm)\n\ndef test_ppm(h, f):\n    \"\"\"Verify if the image is a PPM (portable pixmap).\"\"\"\n    if len(h) >= 3 and \\\n        h[0] == ord(b'P') and h[1] in b'36' and h[2] in b' \\t\\n\\r':\n        return 'ppm'\n\ntests.append(test_ppm)\n\ndef test_rast(h, f):\n    \"\"\"test for the Sun raster file.\"\"\"\n    if h.startswith(b'\\x59\\xA6\\x6A\\x95'):\n        return 'rast'\n\ntests.append(test_rast)\n\ndef test_xbm(h, f):\n    \"\"\"Verify if the image is a X bitmap (X10 or X11).\"\"\"\n    if h.startswith(b'#define '):\n        return 'xbm'\n\ntests.append(test_xbm)\n\ndef test_bmp(h, f):\n    \"\"\"Verify if the image is a BMP file.\"\"\"\n    if h.startswith(b'BM'):\n        return 'bmp'\n\ntests.append(test_bmp)\n\ndef test_webp(h, f):\n    \"\"\"Verify if the image is a WebP.\"\"\"\n    if h.startswith(b'RIFF') and h[8:12] == b'WEBP':\n        return 'webp'\n\ntests.append(test_webp)\n\ndef test_exr(h, f):\n    \"\"\"verify is the image ia a OpenEXR fileOpenEXR.\"\"\"\n    if h.startswith(b'\\x76\\x2f\\x31\\x01'):\n        return 'exr'\n\ntests.append(test_exr)\n", "mitmproxy/contrib/__init__.py": "", "mitmproxy/contrib/kaitaistruct/vlq_base128_le.py": "# This is a generated file! Please edit source .ksy file and use kaitai-struct-compiler to rebuild\n\nimport kaitaistruct\nfrom kaitaistruct import KaitaiStruct\n\n\nif getattr(kaitaistruct, 'API_VERSION', (0, 9)) < (0, 9):\n    raise Exception(\"Incompatible Kaitai Struct Python API: 0.9 or later is required, but you have %s\" % (kaitaistruct.__version__))\n\nclass VlqBase128Le(KaitaiStruct):\n    \"\"\"A variable-length unsigned/signed integer using base128 encoding. 1-byte groups\n    consist of 1-bit flag of continuation and 7-bit value chunk, and are ordered\n    \"least significant group first\", i.e. in \"little-endian\" manner.\n    \n    This particular encoding is specified and used in:\n    \n    * DWARF debug file format, where it's dubbed \"unsigned LEB128\" or \"ULEB128\".\n      http://dwarfstd.org/doc/dwarf-2.0.0.pdf - page 139\n    * Google Protocol Buffers, where it's called \"Base 128 Varints\".\n      https://developers.google.com/protocol-buffers/docs/encoding?csw=1#varints\n    * Apache Lucene, where it's called \"VInt\"\n      https://lucene.apache.org/core/3_5_0/fileformats.html#VInt\n    * Apache Avro uses this as a basis for integer encoding, adding ZigZag on\n      top of it for signed ints\n      https://avro.apache.org/docs/current/spec.html#binary_encode_primitive\n    \n    More information on this encoding is available at https://en.wikipedia.org/wiki/LEB128\n    \n    This particular implementation supports serialized values to up 8 bytes long.\n    \"\"\"\n    def __init__(self, _io, _parent=None, _root=None):\n        self._io = _io\n        self._parent = _parent\n        self._root = _root if _root else self\n        self._read()\n\n    def _read(self):\n        self.groups = []\n        i = 0\n        while True:\n            _ = VlqBase128Le.Group(self._io, self, self._root)\n            self.groups.append(_)\n            if not (_.has_next):\n                break\n            i += 1\n\n    class Group(KaitaiStruct):\n        \"\"\"One byte group, clearly divided into 7-bit \"value\" chunk and 1-bit \"continuation\" flag.\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.b = self._io.read_u1()\n\n        @property\n        def has_next(self):\n            \"\"\"If true, then we have more bytes to read.\"\"\"\n            if hasattr(self, '_m_has_next'):\n                return self._m_has_next\n\n            self._m_has_next = (self.b & 128) != 0\n            return getattr(self, '_m_has_next', None)\n\n        @property\n        def value(self):\n            \"\"\"The 7-bit (base128) numeric value chunk of this group.\"\"\"\n            if hasattr(self, '_m_value'):\n                return self._m_value\n\n            self._m_value = (self.b & 127)\n            return getattr(self, '_m_value', None)\n\n\n    @property\n    def len(self):\n        if hasattr(self, '_m_len'):\n            return self._m_len\n\n        self._m_len = len(self.groups)\n        return getattr(self, '_m_len', None)\n\n    @property\n    def value(self):\n        \"\"\"Resulting unsigned value as normal integer.\"\"\"\n        if hasattr(self, '_m_value'):\n            return self._m_value\n\n        self._m_value = (((((((self.groups[0].value + ((self.groups[1].value << 7) if self.len >= 2 else 0)) + ((self.groups[2].value << 14) if self.len >= 3 else 0)) + ((self.groups[3].value << 21) if self.len >= 4 else 0)) + ((self.groups[4].value << 28) if self.len >= 5 else 0)) + ((self.groups[5].value << 35) if self.len >= 6 else 0)) + ((self.groups[6].value << 42) if self.len >= 7 else 0)) + ((self.groups[7].value << 49) if self.len >= 8 else 0))\n        return getattr(self, '_m_value', None)\n\n    @property\n    def sign_bit(self):\n        if hasattr(self, '_m_sign_bit'):\n            return self._m_sign_bit\n\n        self._m_sign_bit = (1 << ((7 * self.len) - 1))\n        return getattr(self, '_m_sign_bit', None)\n\n    @property\n    def value_signed(self):\n        \"\"\"\n        .. seealso::\n           Source - https://graphics.stanford.edu/~seander/bithacks.html#VariableSignExtend\n        \"\"\"\n        if hasattr(self, '_m_value_signed'):\n            return self._m_value_signed\n\n        self._m_value_signed = ((self.value ^ self.sign_bit) - self.sign_bit)\n        return getattr(self, '_m_value_signed', None)\n\n\n", "mitmproxy/contrib/kaitaistruct/dtls_client_hello.py": "# This is a generated file! Please edit source .ksy file and use kaitai-struct-compiler to rebuild\n\nimport kaitaistruct\nfrom kaitaistruct import KaitaiStruct, KaitaiStream, BytesIO\n\n\nif getattr(kaitaistruct, 'API_VERSION', (0, 9)) < (0, 9):\n    raise Exception(\"Incompatible Kaitai Struct Python API: 0.9 or later is required, but you have %s\" % (kaitaistruct.__version__))\n\nclass DtlsClientHello(KaitaiStruct):\n    def __init__(self, _io, _parent=None, _root=None):\n        self._io = _io\n        self._parent = _parent\n        self._root = _root if _root else self\n        self._read()\n\n    def _read(self):\n        self.version = DtlsClientHello.Version(self._io, self, self._root)\n        self.random = DtlsClientHello.Random(self._io, self, self._root)\n        self.session_id = DtlsClientHello.SessionId(self._io, self, self._root)\n        self.cookie = DtlsClientHello.Cookie(self._io, self, self._root)\n        self.cipher_suites = DtlsClientHello.CipherSuites(self._io, self, self._root)\n        self.compression_methods = DtlsClientHello.CompressionMethods(self._io, self, self._root)\n        if self._io.is_eof() == False:\n            self.extensions = DtlsClientHello.Extensions(self._io, self, self._root)\n\n\n    class ServerName(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.name_type = self._io.read_u1()\n            self.length = self._io.read_u2be()\n            self.host_name = self._io.read_bytes(self.length)\n\n\n    class Random(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.gmt_unix_time = self._io.read_u4be()\n            self.random = self._io.read_bytes(28)\n\n\n    class SessionId(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = self._io.read_u1()\n            self.sid = self._io.read_bytes(self.len)\n\n\n    class Sni(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.list_length = self._io.read_u2be()\n            self.server_names = []\n            i = 0\n            while not self._io.is_eof():\n                self.server_names.append(DtlsClientHello.ServerName(self._io, self, self._root))\n                i += 1\n\n\n\n    class CipherSuites(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = self._io.read_u2be()\n            self.cipher_suites = []\n            for i in range(self.len // 2):\n                self.cipher_suites.append(self._io.read_u2be())\n\n\n\n    class CompressionMethods(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = self._io.read_u1()\n            self.compression_methods = self._io.read_bytes(self.len)\n\n\n    class Alpn(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.ext_len = self._io.read_u2be()\n            self.alpn_protocols = []\n            i = 0\n            while not self._io.is_eof():\n                self.alpn_protocols.append(DtlsClientHello.Protocol(self._io, self, self._root))\n                i += 1\n\n\n\n    class Extensions(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = self._io.read_u2be()\n            self.extensions = []\n            i = 0\n            while not self._io.is_eof():\n                self.extensions.append(DtlsClientHello.Extension(self._io, self, self._root))\n                i += 1\n\n\n\n    class Version(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.major = self._io.read_u1()\n            self.minor = self._io.read_u1()\n\n\n    class Cookie(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = self._io.read_u1()\n            self.cookie = self._io.read_bytes(self.len)\n\n\n    class Protocol(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.strlen = self._io.read_u1()\n            self.name = self._io.read_bytes(self.strlen)\n\n\n    class Extension(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.type = self._io.read_u2be()\n            self.len = self._io.read_u2be()\n            _on = self.type\n            if _on == 0:\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = DtlsClientHello.Sni(_io__raw_body, self, self._root)\n            elif _on == 16:\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = DtlsClientHello.Alpn(_io__raw_body, self, self._root)\n            else:\n                self.body = self._io.read_bytes(self.len)\n\n\n\n", "mitmproxy/contrib/kaitaistruct/ico.py": "# This is a generated file! Please edit source .ksy file and use kaitai-struct-compiler to rebuild\n\nimport kaitaistruct\nfrom kaitaistruct import KaitaiStruct\n\n\nif getattr(kaitaistruct, 'API_VERSION', (0, 9)) < (0, 9):\n    raise Exception(\"Incompatible Kaitai Struct Python API: 0.9 or later is required, but you have %s\" % (kaitaistruct.__version__))\n\nclass Ico(KaitaiStruct):\n    \"\"\"Microsoft Windows uses specific file format to store applications\n    icons - ICO. This is a container that contains one or more image\n    files (effectively, DIB parts of BMP files or full PNG files are\n    contained inside).\n    \n    .. seealso::\n       Source - https://docs.microsoft.com/en-us/previous-versions/ms997538(v=msdn.10)\n    \"\"\"\n    def __init__(self, _io, _parent=None, _root=None):\n        self._io = _io\n        self._parent = _parent\n        self._root = _root if _root else self\n        self._read()\n\n    def _read(self):\n        self.magic = self._io.read_bytes(4)\n        if not self.magic == b\"\\x00\\x00\\x01\\x00\":\n            raise kaitaistruct.ValidationNotEqualError(b\"\\x00\\x00\\x01\\x00\", self.magic, self._io, u\"/seq/0\")\n        self.num_images = self._io.read_u2le()\n        self.images = []\n        for i in range(self.num_images):\n            self.images.append(Ico.IconDirEntry(self._io, self, self._root))\n\n\n    class IconDirEntry(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.width = self._io.read_u1()\n            self.height = self._io.read_u1()\n            self.num_colors = self._io.read_u1()\n            self.reserved = self._io.read_bytes(1)\n            if not self.reserved == b\"\\x00\":\n                raise kaitaistruct.ValidationNotEqualError(b\"\\x00\", self.reserved, self._io, u\"/types/icon_dir_entry/seq/3\")\n            self.num_planes = self._io.read_u2le()\n            self.bpp = self._io.read_u2le()\n            self.len_img = self._io.read_u4le()\n            self.ofs_img = self._io.read_u4le()\n\n        @property\n        def img(self):\n            \"\"\"Raw image data. Use `is_png` to determine whether this is an\n            embedded PNG file (true) or a DIB bitmap (false) and call a\n            relevant parser, if needed to parse image data further.\n            \"\"\"\n            if hasattr(self, '_m_img'):\n                return self._m_img\n\n            _pos = self._io.pos()\n            self._io.seek(self.ofs_img)\n            self._m_img = self._io.read_bytes(self.len_img)\n            self._io.seek(_pos)\n            return getattr(self, '_m_img', None)\n\n        @property\n        def png_header(self):\n            \"\"\"Pre-reads first 8 bytes of the image to determine if it's an\n            embedded PNG file.\n            \"\"\"\n            if hasattr(self, '_m_png_header'):\n                return self._m_png_header\n\n            _pos = self._io.pos()\n            self._io.seek(self.ofs_img)\n            self._m_png_header = self._io.read_bytes(8)\n            self._io.seek(_pos)\n            return getattr(self, '_m_png_header', None)\n\n        @property\n        def is_png(self):\n            \"\"\"True if this image is in PNG format.\"\"\"\n            if hasattr(self, '_m_is_png'):\n                return self._m_is_png\n\n            self._m_is_png = self.png_header == b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\"\n            return getattr(self, '_m_is_png', None)\n\n\n\n", "mitmproxy/contrib/kaitaistruct/exif.py": "# This is a generated file! Please edit source .ksy file and use kaitai-struct-compiler to rebuild\n\nimport kaitaistruct\nfrom kaitaistruct import KaitaiStream, KaitaiStruct\nfrom enum import Enum\n\n\nif getattr(kaitaistruct, 'API_VERSION', (0, 9)) < (0, 9):\n    raise Exception(\"Incompatible Kaitai Struct Python API: 0.9 or later is required, but you have %s\" % (kaitaistruct.__version__))\n\nclass Exif(KaitaiStruct):\n    def __init__(self, _io, _parent=None, _root=None):\n        self._io = _io\n        self._parent = _parent\n        self._root = _root if _root else self\n        self._read()\n\n    def _read(self):\n        self.endianness = self._io.read_u2le()\n        self.body = Exif.ExifBody(self._io, self, self._root)\n\n    class ExifBody(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            _on = self._root.endianness\n            if _on == 18761:\n                self._is_le = True\n            elif _on == 19789:\n                self._is_le = False\n            if not hasattr(self, '_is_le'):\n                raise kaitaistruct.UndecidedEndiannessError(\"/types/exif_body\")\n            elif self._is_le == True:\n                self._read_le()\n            elif self._is_le == False:\n                self._read_be()\n\n        def _read_le(self):\n            self.version = self._io.read_u2le()\n            self.ifd0_ofs = self._io.read_u4le()\n\n        def _read_be(self):\n            self.version = self._io.read_u2be()\n            self.ifd0_ofs = self._io.read_u4be()\n\n        class Ifd(KaitaiStruct):\n            def __init__(self, _io, _parent=None, _root=None, _is_le=None):\n                self._io = _io\n                self._parent = _parent\n                self._root = _root if _root else self\n                self._is_le = _is_le\n                self._read()\n\n            def _read(self):\n                if not hasattr(self, '_is_le'):\n                    raise kaitaistruct.UndecidedEndiannessError(\"/types/exif_body/types/ifd\")\n                elif self._is_le == True:\n                    self._read_le()\n                elif self._is_le == False:\n                    self._read_be()\n\n            def _read_le(self):\n                self.num_fields = self._io.read_u2le()\n                self.fields = []\n                for i in range(self.num_fields):\n                    self.fields.append(Exif.ExifBody.IfdField(self._io, self, self._root, self._is_le))\n\n                self.next_ifd_ofs = self._io.read_u4le()\n\n            def _read_be(self):\n                self.num_fields = self._io.read_u2be()\n                self.fields = []\n                for i in range(self.num_fields):\n                    self.fields.append(Exif.ExifBody.IfdField(self._io, self, self._root, self._is_le))\n\n                self.next_ifd_ofs = self._io.read_u4be()\n\n            @property\n            def next_ifd(self):\n                if hasattr(self, '_m_next_ifd'):\n                    return self._m_next_ifd\n\n                if self.next_ifd_ofs != 0:\n                    _pos = self._io.pos()\n                    self._io.seek(self.next_ifd_ofs)\n                    if self._is_le:\n                        self._m_next_ifd = Exif.ExifBody.Ifd(self._io, self, self._root, self._is_le)\n                    else:\n                        self._m_next_ifd = Exif.ExifBody.Ifd(self._io, self, self._root, self._is_le)\n                    self._io.seek(_pos)\n\n                return getattr(self, '_m_next_ifd', None)\n\n\n        class IfdField(KaitaiStruct):\n\n            class FieldTypeEnum(Enum):\n                byte = 1\n                ascii_string = 2\n                word = 3\n                dword = 4\n                rational = 5\n                undefined = 7\n                slong = 9\n                srational = 10\n\n            class TagEnum(Enum):\n                image_width = 256\n                image_height = 257\n                bits_per_sample = 258\n                compression = 259\n                photometric_interpretation = 262\n                thresholding = 263\n                cell_width = 264\n                cell_length = 265\n                fill_order = 266\n                document_name = 269\n                image_description = 270\n                make = 271\n                model = 272\n                strip_offsets = 273\n                orientation = 274\n                samples_per_pixel = 277\n                rows_per_strip = 278\n                strip_byte_counts = 279\n                min_sample_value = 280\n                max_sample_value = 281\n                x_resolution = 282\n                y_resolution = 283\n                planar_configuration = 284\n                page_name = 285\n                x_position = 286\n                y_position = 287\n                free_offsets = 288\n                free_byte_counts = 289\n                gray_response_unit = 290\n                gray_response_curve = 291\n                t4_options = 292\n                t6_options = 293\n                resolution_unit = 296\n                page_number = 297\n                color_response_unit = 300\n                transfer_function = 301\n                software = 305\n                modify_date = 306\n                artist = 315\n                host_computer = 316\n                predictor = 317\n                white_point = 318\n                primary_chromaticities = 319\n                color_map = 320\n                halftone_hints = 321\n                tile_width = 322\n                tile_length = 323\n                tile_offsets = 324\n                tile_byte_counts = 325\n                bad_fax_lines = 326\n                clean_fax_data = 327\n                consecutive_bad_fax_lines = 328\n                sub_ifd = 330\n                ink_set = 332\n                ink_names = 333\n                numberof_inks = 334\n                dot_range = 336\n                target_printer = 337\n                extra_samples = 338\n                sample_format = 339\n                s_min_sample_value = 340\n                s_max_sample_value = 341\n                transfer_range = 342\n                clip_path = 343\n                x_clip_path_units = 344\n                y_clip_path_units = 345\n                indexed = 346\n                jpeg_tables = 347\n                opi_proxy = 351\n                global_parameters_ifd = 400\n                profile_type = 401\n                fax_profile = 402\n                coding_methods = 403\n                version_year = 404\n                mode_number = 405\n                decode = 433\n                default_image_color = 434\n                t82_options = 435\n                jpeg_tables2 = 437\n                jpeg_proc = 512\n                thumbnail_offset = 513\n                thumbnail_length = 514\n                jpeg_restart_interval = 515\n                jpeg_lossless_predictors = 517\n                jpeg_point_transforms = 518\n                jpegq_tables = 519\n                jpegdc_tables = 520\n                jpegac_tables = 521\n                y_cb_cr_coefficients = 529\n                y_cb_cr_sub_sampling = 530\n                y_cb_cr_positioning = 531\n                reference_black_white = 532\n                strip_row_counts = 559\n                application_notes = 700\n                uspto_miscellaneous = 999\n                related_image_file_format = 4096\n                related_image_width = 4097\n                related_image_height = 4098\n                rating = 18246\n                xp_dip_xml = 18247\n                stitch_info = 18248\n                rating_percent = 18249\n                sony_raw_file_type = 28672\n                light_falloff_params = 28722\n                chromatic_aberration_corr_params = 28725\n                distortion_corr_params = 28727\n                image_id = 32781\n                wang_tag1 = 32931\n                wang_annotation = 32932\n                wang_tag3 = 32933\n                wang_tag4 = 32934\n                image_reference_points = 32953\n                region_xform_tack_point = 32954\n                warp_quadrilateral = 32955\n                affine_transform_mat = 32956\n                matteing = 32995\n                data_type = 32996\n                image_depth = 32997\n                tile_depth = 32998\n                image_full_width = 33300\n                image_full_height = 33301\n                texture_format = 33302\n                wrap_modes = 33303\n                fov_cot = 33304\n                matrix_world_to_screen = 33305\n                matrix_world_to_camera = 33306\n                model2 = 33405\n                cfa_repeat_pattern_dim = 33421\n                cfa_pattern2 = 33422\n                battery_level = 33423\n                kodak_ifd = 33424\n                copyright = 33432\n                exposure_time = 33434\n                f_number = 33437\n                md_file_tag = 33445\n                md_scale_pixel = 33446\n                md_color_table = 33447\n                md_lab_name = 33448\n                md_sample_info = 33449\n                md_prep_date = 33450\n                md_prep_time = 33451\n                md_file_units = 33452\n                pixel_scale = 33550\n                advent_scale = 33589\n                advent_revision = 33590\n                uic1_tag = 33628\n                uic2_tag = 33629\n                uic3_tag = 33630\n                uic4_tag = 33631\n                iptc_naa = 33723\n                intergraph_packet_data = 33918\n                intergraph_flag_registers = 33919\n                intergraph_matrix = 33920\n                ingr_reserved = 33921\n                model_tie_point = 33922\n                site = 34016\n                color_sequence = 34017\n                it8_header = 34018\n                raster_padding = 34019\n                bits_per_run_length = 34020\n                bits_per_extended_run_length = 34021\n                color_table = 34022\n                image_color_indicator = 34023\n                background_color_indicator = 34024\n                image_color_value = 34025\n                background_color_value = 34026\n                pixel_intensity_range = 34027\n                transparency_indicator = 34028\n                color_characterization = 34029\n                hc_usage = 34030\n                trap_indicator = 34031\n                cmyk_equivalent = 34032\n                sem_info = 34118\n                afcp_iptc = 34152\n                pixel_magic_jbig_options = 34232\n                jpl_carto_ifd = 34263\n                model_transform = 34264\n                wb_grgb_levels = 34306\n                leaf_data = 34310\n                photoshop_settings = 34377\n                exif_offset = 34665\n                icc_profile = 34675\n                tiff_fx_extensions = 34687\n                multi_profiles = 34688\n                shared_data = 34689\n                t88_options = 34690\n                image_layer = 34732\n                geo_tiff_directory = 34735\n                geo_tiff_double_params = 34736\n                geo_tiff_ascii_params = 34737\n                jbig_options = 34750\n                exposure_program = 34850\n                spectral_sensitivity = 34852\n                gps_info = 34853\n                iso = 34855\n                opto_electric_conv_factor = 34856\n                interlace = 34857\n                time_zone_offset = 34858\n                self_timer_mode = 34859\n                sensitivity_type = 34864\n                standard_output_sensitivity = 34865\n                recommended_exposure_index = 34866\n                iso_speed = 34867\n                iso_speed_latitudeyyy = 34868\n                iso_speed_latitudezzz = 34869\n                fax_recv_params = 34908\n                fax_sub_address = 34909\n                fax_recv_time = 34910\n                fedex_edr = 34929\n                leaf_sub_ifd = 34954\n                exif_version = 36864\n                date_time_original = 36867\n                create_date = 36868\n                google_plus_upload_code = 36873\n                offset_time = 36880\n                offset_time_original = 36881\n                offset_time_digitized = 36882\n                components_configuration = 37121\n                compressed_bits_per_pixel = 37122\n                shutter_speed_value = 37377\n                aperture_value = 37378\n                brightness_value = 37379\n                exposure_compensation = 37380\n                max_aperture_value = 37381\n                subject_distance = 37382\n                metering_mode = 37383\n                light_source = 37384\n                flash = 37385\n                focal_length = 37386\n                flash_energy = 37387\n                spatial_frequency_response = 37388\n                noise = 37389\n                focal_plane_x_resolution = 37390\n                focal_plane_y_resolution = 37391\n                focal_plane_resolution_unit = 37392\n                image_number = 37393\n                security_classification = 37394\n                image_history = 37395\n                subject_area = 37396\n                exposure_index = 37397\n                tiff_ep_standard_id = 37398\n                sensing_method = 37399\n                cip3_data_file = 37434\n                cip3_sheet = 37435\n                cip3_side = 37436\n                sto_nits = 37439\n                maker_note = 37500\n                user_comment = 37510\n                sub_sec_time = 37520\n                sub_sec_time_original = 37521\n                sub_sec_time_digitized = 37522\n                ms_document_text = 37679\n                ms_property_set_storage = 37680\n                ms_document_text_position = 37681\n                image_source_data = 37724\n                ambient_temperature = 37888\n                humidity = 37889\n                pressure = 37890\n                water_depth = 37891\n                acceleration = 37892\n                camera_elevation_angle = 37893\n                xp_title = 40091\n                xp_comment = 40092\n                xp_author = 40093\n                xp_keywords = 40094\n                xp_subject = 40095\n                flashpix_version = 40960\n                color_space = 40961\n                exif_image_width = 40962\n                exif_image_height = 40963\n                related_sound_file = 40964\n                interop_offset = 40965\n                samsung_raw_pointers_offset = 40976\n                samsung_raw_pointers_length = 40977\n                samsung_raw_byte_order = 41217\n                samsung_raw_unknown = 41218\n                flash_energy2 = 41483\n                spatial_frequency_response2 = 41484\n                noise2 = 41485\n                focal_plane_x_resolution2 = 41486\n                focal_plane_y_resolution2 = 41487\n                focal_plane_resolution_unit2 = 41488\n                image_number2 = 41489\n                security_classification2 = 41490\n                image_history2 = 41491\n                subject_location = 41492\n                exposure_index2 = 41493\n                tiff_ep_standard_id2 = 41494\n                sensing_method2 = 41495\n                file_source = 41728\n                scene_type = 41729\n                cfa_pattern = 41730\n                custom_rendered = 41985\n                exposure_mode = 41986\n                white_balance = 41987\n                digital_zoom_ratio = 41988\n                focal_length_in35mm_format = 41989\n                scene_capture_type = 41990\n                gain_control = 41991\n                contrast = 41992\n                saturation = 41993\n                sharpness = 41994\n                device_setting_description = 41995\n                subject_distance_range = 41996\n                image_unique_id = 42016\n                owner_name = 42032\n                serial_number = 42033\n                lens_info = 42034\n                lens_make = 42035\n                lens_model = 42036\n                lens_serial_number = 42037\n                gdal_metadata = 42112\n                gdal_no_data = 42113\n                gamma = 42240\n                expand_software = 44992\n                expand_lens = 44993\n                expand_film = 44994\n                expand_filter_lens = 44995\n                expand_scanner = 44996\n                expand_flash_lamp = 44997\n                pixel_format = 48129\n                transformation = 48130\n                uncompressed = 48131\n                image_type = 48132\n                image_width2 = 48256\n                image_height2 = 48257\n                width_resolution = 48258\n                height_resolution = 48259\n                image_offset = 48320\n                image_byte_count = 48321\n                alpha_offset = 48322\n                alpha_byte_count = 48323\n                image_data_discard = 48324\n                alpha_data_discard = 48325\n                oce_scanjob_desc = 50215\n                oce_application_selector = 50216\n                oce_id_number = 50217\n                oce_image_logic = 50218\n                annotations = 50255\n                print_im = 50341\n                original_file_name = 50547\n                uspto_original_content_type = 50560\n                dng_version = 50706\n                dng_backward_version = 50707\n                unique_camera_model = 50708\n                localized_camera_model = 50709\n                cfa_plane_color = 50710\n                cfa_layout = 50711\n                linearization_table = 50712\n                black_level_repeat_dim = 50713\n                black_level = 50714\n                black_level_delta_h = 50715\n                black_level_delta_v = 50716\n                white_level = 50717\n                default_scale = 50718\n                default_crop_origin = 50719\n                default_crop_size = 50720\n                color_matrix1 = 50721\n                color_matrix2 = 50722\n                camera_calibration1 = 50723\n                camera_calibration2 = 50724\n                reduction_matrix1 = 50725\n                reduction_matrix2 = 50726\n                analog_balance = 50727\n                as_shot_neutral = 50728\n                as_shot_white_xy = 50729\n                baseline_exposure = 50730\n                baseline_noise = 50731\n                baseline_sharpness = 50732\n                bayer_green_split = 50733\n                linear_response_limit = 50734\n                camera_serial_number = 50735\n                dng_lens_info = 50736\n                chroma_blur_radius = 50737\n                anti_alias_strength = 50738\n                shadow_scale = 50739\n                sr2_private = 50740\n                maker_note_safety = 50741\n                raw_image_segmentation = 50752\n                calibration_illuminant1 = 50778\n                calibration_illuminant2 = 50779\n                best_quality_scale = 50780\n                raw_data_unique_id = 50781\n                alias_layer_metadata = 50784\n                original_raw_file_name = 50827\n                original_raw_file_data = 50828\n                active_area = 50829\n                masked_areas = 50830\n                as_shot_icc_profile = 50831\n                as_shot_pre_profile_matrix = 50832\n                current_icc_profile = 50833\n                current_pre_profile_matrix = 50834\n                colorimetric_reference = 50879\n                s_raw_type = 50885\n                panasonic_title = 50898\n                panasonic_title2 = 50899\n                camera_calibration_sig = 50931\n                profile_calibration_sig = 50932\n                profile_ifd = 50933\n                as_shot_profile_name = 50934\n                noise_reduction_applied = 50935\n                profile_name = 50936\n                profile_hue_sat_map_dims = 50937\n                profile_hue_sat_map_data1 = 50938\n                profile_hue_sat_map_data2 = 50939\n                profile_tone_curve = 50940\n                profile_embed_policy = 50941\n                profile_copyright = 50942\n                forward_matrix1 = 50964\n                forward_matrix2 = 50965\n                preview_application_name = 50966\n                preview_application_version = 50967\n                preview_settings_name = 50968\n                preview_settings_digest = 50969\n                preview_color_space = 50970\n                preview_date_time = 50971\n                raw_image_digest = 50972\n                original_raw_file_digest = 50973\n                sub_tile_block_size = 50974\n                row_interleave_factor = 50975\n                profile_look_table_dims = 50981\n                profile_look_table_data = 50982\n                opcode_list1 = 51008\n                opcode_list2 = 51009\n                opcode_list3 = 51022\n                noise_profile = 51041\n                time_codes = 51043\n                frame_rate = 51044\n                t_stop = 51058\n                reel_name = 51081\n                original_default_final_size = 51089\n                original_best_quality_size = 51090\n                original_default_crop_size = 51091\n                camera_label = 51105\n                profile_hue_sat_map_encoding = 51107\n                profile_look_table_encoding = 51108\n                baseline_exposure_offset = 51109\n                default_black_render = 51110\n                new_raw_image_digest = 51111\n                raw_to_preview_gain = 51112\n                default_user_crop = 51125\n                padding = 59932\n                offset_schema = 59933\n                owner_name2 = 65000\n                serial_number2 = 65001\n                lens = 65002\n                kdc_ifd = 65024\n                raw_file = 65100\n                converter = 65101\n                white_balance2 = 65102\n                exposure = 65105\n                shadows = 65106\n                brightness = 65107\n                contrast2 = 65108\n                saturation2 = 65109\n                sharpness2 = 65110\n                smoothness = 65111\n                moire_filter = 65112\n            def __init__(self, _io, _parent=None, _root=None, _is_le=None):\n                self._io = _io\n                self._parent = _parent\n                self._root = _root if _root else self\n                self._is_le = _is_le\n                self._read()\n\n            def _read(self):\n                if not hasattr(self, '_is_le'):\n                    raise kaitaistruct.UndecidedEndiannessError(\"/types/exif_body/types/ifd_field\")\n                elif self._is_le == True:\n                    self._read_le()\n                elif self._is_le == False:\n                    self._read_be()\n\n            def _read_le(self):\n                self.tag = KaitaiStream.resolve_enum(Exif.ExifBody.IfdField.TagEnum, self._io.read_u2le())\n                self.field_type = KaitaiStream.resolve_enum(Exif.ExifBody.IfdField.FieldTypeEnum, self._io.read_u2le())\n                self.length = self._io.read_u4le()\n                self.ofs_or_data = self._io.read_u4le()\n\n            def _read_be(self):\n                self.tag = KaitaiStream.resolve_enum(Exif.ExifBody.IfdField.TagEnum, self._io.read_u2be())\n                self.field_type = KaitaiStream.resolve_enum(Exif.ExifBody.IfdField.FieldTypeEnum, self._io.read_u2be())\n                self.length = self._io.read_u4be()\n                self.ofs_or_data = self._io.read_u4be()\n\n            @property\n            def type_byte_length(self):\n                if hasattr(self, '_m_type_byte_length'):\n                    return self._m_type_byte_length\n\n                self._m_type_byte_length = (2 if self.field_type == Exif.ExifBody.IfdField.FieldTypeEnum.word else (4 if self.field_type == Exif.ExifBody.IfdField.FieldTypeEnum.dword else 1))\n                return getattr(self, '_m_type_byte_length', None)\n\n            @property\n            def byte_length(self):\n                if hasattr(self, '_m_byte_length'):\n                    return self._m_byte_length\n\n                self._m_byte_length = (self.length * self.type_byte_length)\n                return getattr(self, '_m_byte_length', None)\n\n            @property\n            def is_immediate_data(self):\n                if hasattr(self, '_m_is_immediate_data'):\n                    return self._m_is_immediate_data\n\n                self._m_is_immediate_data = self.byte_length <= 4\n                return getattr(self, '_m_is_immediate_data', None)\n\n            @property\n            def data(self):\n                if hasattr(self, '_m_data'):\n                    return self._m_data\n\n                if not (self.is_immediate_data):\n                    io = self._root._io\n                    _pos = io.pos()\n                    io.seek(self.ofs_or_data)\n                    if self._is_le:\n                        self._m_data = io.read_bytes(self.byte_length)\n                    else:\n                        self._m_data = io.read_bytes(self.byte_length)\n                    io.seek(_pos)\n\n                return getattr(self, '_m_data', None)\n\n\n        @property\n        def ifd0(self):\n            if hasattr(self, '_m_ifd0'):\n                return self._m_ifd0\n\n            _pos = self._io.pos()\n            self._io.seek(self.ifd0_ofs)\n            if self._is_le:\n                self._m_ifd0 = Exif.ExifBody.Ifd(self._io, self, self._root, self._is_le)\n            else:\n                self._m_ifd0 = Exif.ExifBody.Ifd(self._io, self, self._root, self._is_le)\n            self._io.seek(_pos)\n            return getattr(self, '_m_ifd0', None)\n\n\n\n", "mitmproxy/contrib/kaitaistruct/png.py": "# This is a generated file! Please edit source .ksy file and use kaitai-struct-compiler to rebuild\n\nimport kaitaistruct\nfrom kaitaistruct import KaitaiStruct, KaitaiStream, BytesIO\nfrom enum import Enum\nimport zlib\n\n\nif getattr(kaitaistruct, 'API_VERSION', (0, 9)) < (0, 9):\n    raise Exception(\"Incompatible Kaitai Struct Python API: 0.9 or later is required, but you have %s\" % (kaitaistruct.__version__))\n\nclass Png(KaitaiStruct):\n    \"\"\"Test files for APNG can be found at the following locations:\n    \n      * <https://philip.html5.org/tests/apng/tests.html>\n      * <http://littlesvr.ca/apng/>\n    \"\"\"\n\n    class PhysUnit(Enum):\n        unknown = 0\n        meter = 1\n\n    class BlendOpValues(Enum):\n        source = 0\n        over = 1\n\n    class CompressionMethods(Enum):\n        zlib = 0\n\n    class DisposeOpValues(Enum):\n        none = 0\n        background = 1\n        previous = 2\n\n    class ColorType(Enum):\n        greyscale = 0\n        truecolor = 2\n        indexed = 3\n        greyscale_alpha = 4\n        truecolor_alpha = 6\n    def __init__(self, _io, _parent=None, _root=None):\n        self._io = _io\n        self._parent = _parent\n        self._root = _root if _root else self\n        self._read()\n\n    def _read(self):\n        self.magic = self._io.read_bytes(8)\n        if not self.magic == b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\":\n            raise kaitaistruct.ValidationNotEqualError(b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\", self.magic, self._io, u\"/seq/0\")\n        self.ihdr_len = self._io.read_u4be()\n        if not self.ihdr_len == 13:\n            raise kaitaistruct.ValidationNotEqualError(13, self.ihdr_len, self._io, u\"/seq/1\")\n        self.ihdr_type = self._io.read_bytes(4)\n        if not self.ihdr_type == b\"\\x49\\x48\\x44\\x52\":\n            raise kaitaistruct.ValidationNotEqualError(b\"\\x49\\x48\\x44\\x52\", self.ihdr_type, self._io, u\"/seq/2\")\n        self.ihdr = Png.IhdrChunk(self._io, self, self._root)\n        self.ihdr_crc = self._io.read_bytes(4)\n        self.chunks = []\n        i = 0\n        while True:\n            _ = Png.Chunk(self._io, self, self._root)\n            self.chunks.append(_)\n            if  ((_.type == u\"IEND\") or (self._io.is_eof())) :\n                break\n            i += 1\n\n    class Rgb(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.r = self._io.read_u1()\n            self.g = self._io.read_u1()\n            self.b = self._io.read_u1()\n\n\n    class Chunk(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = self._io.read_u4be()\n            self.type = (self._io.read_bytes(4)).decode(u\"UTF-8\")\n            _on = self.type\n            if _on == u\"iTXt\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.InternationalTextChunk(_io__raw_body, self, self._root)\n            elif _on == u\"gAMA\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.GamaChunk(_io__raw_body, self, self._root)\n            elif _on == u\"tIME\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.TimeChunk(_io__raw_body, self, self._root)\n            elif _on == u\"PLTE\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.PlteChunk(_io__raw_body, self, self._root)\n            elif _on == u\"bKGD\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.BkgdChunk(_io__raw_body, self, self._root)\n            elif _on == u\"pHYs\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.PhysChunk(_io__raw_body, self, self._root)\n            elif _on == u\"fdAT\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.FrameDataChunk(_io__raw_body, self, self._root)\n            elif _on == u\"tEXt\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.TextChunk(_io__raw_body, self, self._root)\n            elif _on == u\"cHRM\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.ChrmChunk(_io__raw_body, self, self._root)\n            elif _on == u\"acTL\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.AnimationControlChunk(_io__raw_body, self, self._root)\n            elif _on == u\"sRGB\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.SrgbChunk(_io__raw_body, self, self._root)\n            elif _on == u\"zTXt\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.CompressedTextChunk(_io__raw_body, self, self._root)\n            elif _on == u\"fcTL\":\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = Png.FrameControlChunk(_io__raw_body, self, self._root)\n            else:\n                self.body = self._io.read_bytes(self.len)\n            self.crc = self._io.read_bytes(4)\n\n\n    class BkgdIndexed(KaitaiStruct):\n        \"\"\"Background chunk for images with indexed palette.\"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.palette_index = self._io.read_u1()\n\n\n    class Point(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.x_int = self._io.read_u4be()\n            self.y_int = self._io.read_u4be()\n\n        @property\n        def x(self):\n            if hasattr(self, '_m_x'):\n                return self._m_x\n\n            self._m_x = (self.x_int / 100000.0)\n            return getattr(self, '_m_x', None)\n\n        @property\n        def y(self):\n            if hasattr(self, '_m_y'):\n                return self._m_y\n\n            self._m_y = (self.y_int / 100000.0)\n            return getattr(self, '_m_y', None)\n\n\n    class BkgdGreyscale(KaitaiStruct):\n        \"\"\"Background chunk for greyscale images.\"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.value = self._io.read_u2be()\n\n\n    class ChrmChunk(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11cHRM\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.white_point = Png.Point(self._io, self, self._root)\n            self.red = Png.Point(self._io, self, self._root)\n            self.green = Png.Point(self._io, self, self._root)\n            self.blue = Png.Point(self._io, self, self._root)\n\n\n    class IhdrChunk(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11IHDR\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.width = self._io.read_u4be()\n            self.height = self._io.read_u4be()\n            self.bit_depth = self._io.read_u1()\n            self.color_type = KaitaiStream.resolve_enum(Png.ColorType, self._io.read_u1())\n            self.compression_method = self._io.read_u1()\n            self.filter_method = self._io.read_u1()\n            self.interlace_method = self._io.read_u1()\n\n\n    class PlteChunk(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11PLTE\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.entries = []\n            i = 0\n            while not self._io.is_eof():\n                self.entries.append(Png.Rgb(self._io, self, self._root))\n                i += 1\n\n\n\n    class SrgbChunk(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11sRGB\n        \"\"\"\n\n        class Intent(Enum):\n            perceptual = 0\n            relative_colorimetric = 1\n            saturation = 2\n            absolute_colorimetric = 3\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.render_intent = KaitaiStream.resolve_enum(Png.SrgbChunk.Intent, self._io.read_u1())\n\n\n    class CompressedTextChunk(KaitaiStruct):\n        \"\"\"Compressed text chunk effectively allows to store key-value\n        string pairs in PNG container, compressing \"value\" part (which\n        can be quite lengthy) with zlib compression.\n        \n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11zTXt\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.keyword = (self._io.read_bytes_term(0, False, True, True)).decode(u\"UTF-8\")\n            self.compression_method = KaitaiStream.resolve_enum(Png.CompressionMethods, self._io.read_u1())\n            self._raw_text_datastream = self._io.read_bytes_full()\n            self.text_datastream = zlib.decompress(self._raw_text_datastream)\n\n\n    class FrameDataChunk(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           Source - https://wiki.mozilla.org/APNG_Specification#.60fdAT.60:_The_Frame_Data_Chunk\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.sequence_number = self._io.read_u4be()\n            self.frame_data = self._io.read_bytes_full()\n\n\n    class BkgdTruecolor(KaitaiStruct):\n        \"\"\"Background chunk for truecolor images.\"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.red = self._io.read_u2be()\n            self.green = self._io.read_u2be()\n            self.blue = self._io.read_u2be()\n\n\n    class GamaChunk(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11gAMA\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.gamma_int = self._io.read_u4be()\n\n        @property\n        def gamma_ratio(self):\n            if hasattr(self, '_m_gamma_ratio'):\n                return self._m_gamma_ratio\n\n            self._m_gamma_ratio = (100000.0 / self.gamma_int)\n            return getattr(self, '_m_gamma_ratio', None)\n\n\n    class BkgdChunk(KaitaiStruct):\n        \"\"\"Background chunk stores default background color to display this\n        image against. Contents depend on `color_type` of the image.\n        \n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11bKGD\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            _on = self._root.ihdr.color_type\n            if _on == Png.ColorType.indexed:\n                self.bkgd = Png.BkgdIndexed(self._io, self, self._root)\n            elif _on == Png.ColorType.truecolor_alpha:\n                self.bkgd = Png.BkgdTruecolor(self._io, self, self._root)\n            elif _on == Png.ColorType.greyscale_alpha:\n                self.bkgd = Png.BkgdGreyscale(self._io, self, self._root)\n            elif _on == Png.ColorType.truecolor:\n                self.bkgd = Png.BkgdTruecolor(self._io, self, self._root)\n            elif _on == Png.ColorType.greyscale:\n                self.bkgd = Png.BkgdGreyscale(self._io, self, self._root)\n\n\n    class PhysChunk(KaitaiStruct):\n        \"\"\"\"Physical size\" chunk stores data that allows to translate\n        logical pixels into physical units (meters, etc) and vice-versa.\n        \n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11pHYs\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.pixels_per_unit_x = self._io.read_u4be()\n            self.pixels_per_unit_y = self._io.read_u4be()\n            self.unit = KaitaiStream.resolve_enum(Png.PhysUnit, self._io.read_u1())\n\n\n    class FrameControlChunk(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           Source - https://wiki.mozilla.org/APNG_Specification#.60fcTL.60:_The_Frame_Control_Chunk\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.sequence_number = self._io.read_u4be()\n            self.width = self._io.read_u4be()\n            if not self.width >= 1:\n                raise kaitaistruct.ValidationLessThanError(1, self.width, self._io, u\"/types/frame_control_chunk/seq/1\")\n            if not self.width <= self._root.ihdr.width:\n                raise kaitaistruct.ValidationGreaterThanError(self._root.ihdr.width, self.width, self._io, u\"/types/frame_control_chunk/seq/1\")\n            self.height = self._io.read_u4be()\n            if not self.height >= 1:\n                raise kaitaistruct.ValidationLessThanError(1, self.height, self._io, u\"/types/frame_control_chunk/seq/2\")\n            if not self.height <= self._root.ihdr.height:\n                raise kaitaistruct.ValidationGreaterThanError(self._root.ihdr.height, self.height, self._io, u\"/types/frame_control_chunk/seq/2\")\n            self.x_offset = self._io.read_u4be()\n            if not self.x_offset <= (self._root.ihdr.width - self.width):\n                raise kaitaistruct.ValidationGreaterThanError((self._root.ihdr.width - self.width), self.x_offset, self._io, u\"/types/frame_control_chunk/seq/3\")\n            self.y_offset = self._io.read_u4be()\n            if not self.y_offset <= (self._root.ihdr.height - self.height):\n                raise kaitaistruct.ValidationGreaterThanError((self._root.ihdr.height - self.height), self.y_offset, self._io, u\"/types/frame_control_chunk/seq/4\")\n            self.delay_num = self._io.read_u2be()\n            self.delay_den = self._io.read_u2be()\n            self.dispose_op = KaitaiStream.resolve_enum(Png.DisposeOpValues, self._io.read_u1())\n            self.blend_op = KaitaiStream.resolve_enum(Png.BlendOpValues, self._io.read_u1())\n\n        @property\n        def delay(self):\n            \"\"\"Time to display this frame, in seconds.\"\"\"\n            if hasattr(self, '_m_delay'):\n                return self._m_delay\n\n            self._m_delay = (self.delay_num / (100.0 if self.delay_den == 0 else self.delay_den))\n            return getattr(self, '_m_delay', None)\n\n\n    class InternationalTextChunk(KaitaiStruct):\n        \"\"\"International text chunk effectively allows to store key-value string pairs in\n        PNG container. Both \"key\" (keyword) and \"value\" (text) parts are\n        given in pre-defined subset of iso8859-1 without control\n        characters.\n        \n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11iTXt\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.keyword = (self._io.read_bytes_term(0, False, True, True)).decode(u\"UTF-8\")\n            self.compression_flag = self._io.read_u1()\n            self.compression_method = KaitaiStream.resolve_enum(Png.CompressionMethods, self._io.read_u1())\n            self.language_tag = (self._io.read_bytes_term(0, False, True, True)).decode(u\"ASCII\")\n            self.translated_keyword = (self._io.read_bytes_term(0, False, True, True)).decode(u\"UTF-8\")\n            self.text = (self._io.read_bytes_full()).decode(u\"UTF-8\")\n\n\n    class TextChunk(KaitaiStruct):\n        \"\"\"Text chunk effectively allows to store key-value string pairs in\n        PNG container. Both \"key\" (keyword) and \"value\" (text) parts are\n        given in pre-defined subset of iso8859-1 without control\n        characters.\n        \n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11tEXt\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.keyword = (self._io.read_bytes_term(0, False, True, True)).decode(u\"iso8859-1\")\n            self.text = (self._io.read_bytes_full()).decode(u\"iso8859-1\")\n\n\n    class AnimationControlChunk(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           Source - https://wiki.mozilla.org/APNG_Specification#.60acTL.60:_The_Animation_Control_Chunk\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.num_frames = self._io.read_u4be()\n            self.num_plays = self._io.read_u4be()\n\n\n    class TimeChunk(KaitaiStruct):\n        \"\"\"Time chunk stores time stamp of last modification of this image,\n        up to 1 second precision in UTC timezone.\n        \n        .. seealso::\n           Source - https://www.w3.org/TR/PNG/#11tIME\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.year = self._io.read_u2be()\n            self.month = self._io.read_u1()\n            self.day = self._io.read_u1()\n            self.hour = self._io.read_u1()\n            self.minute = self._io.read_u1()\n            self.second = self._io.read_u1()\n\n\n\n", "mitmproxy/contrib/kaitaistruct/google_protobuf.py": "# This is a generated file! Please edit source .ksy file and use kaitai-struct-compiler to rebuild\n\nimport kaitaistruct\nfrom kaitaistruct import KaitaiStream, KaitaiStruct\nfrom enum import Enum\n\n\nif getattr(kaitaistruct, 'API_VERSION', (0, 9)) < (0, 9):\n    raise Exception(\"Incompatible Kaitai Struct Python API: 0.9 or later is required, but you have %s\" % (kaitaistruct.__version__))\n\nfrom . import vlq_base128_le\nclass GoogleProtobuf(KaitaiStruct):\n    \"\"\"Google Protocol Buffers (AKA protobuf) is a popular data\n    serialization scheme used for communication protocols, data storage,\n    etc. There are implementations are available for almost every\n    popular language. The focus points of this scheme are brevity (data\n    is encoded in a very size-efficient manner) and extensibility (one\n    can add keys to the structure, while keeping it readable in previous\n    version of software).\n    \n    Protobuf uses semi-self-describing encoding scheme for its\n    messages. It means that it is possible to parse overall structure of\n    the message (skipping over fields one can't understand), but to\n    fully understand the message, one needs a protocol definition file\n    (`.proto`). To be specific:\n    \n    * \"Keys\" in key-value pairs provided in the message are identified\n      only with an integer \"field tag\". `.proto` file provides info on\n      which symbolic field names these field tags map to.\n    * \"Keys\" also provide something called \"wire type\". It's not a data\n      type in its common sense (i.e. you can't, for example, distinguish\n      `sint32` vs `uint32` vs some enum, or `string` from `bytes`), but\n      it's enough information to determine how many bytes to\n      parse. Interpretation of the value should be done according to the\n      type specified in `.proto` file.\n    * There's no direct information on which fields are optional /\n      required, which fields may be repeated or constitute a map, what\n      restrictions are placed on fields usage in a single message, what\n      are the fields' default values, etc, etc.\n    \n    .. seealso::\n       Source - https://developers.google.com/protocol-buffers/docs/encoding\n    \"\"\"\n    def __init__(self, _io, _parent=None, _root=None):\n        self._io = _io\n        self._parent = _parent\n        self._root = _root if _root else self\n        self._read()\n\n    def _read(self):\n        self.pairs = []\n        i = 0\n        while not self._io.is_eof():\n            self.pairs.append(GoogleProtobuf.Pair(self._io, self, self._root))\n            i += 1\n\n\n    class Pair(KaitaiStruct):\n        \"\"\"Key-value pair.\"\"\"\n\n        class WireTypes(Enum):\n            varint = 0\n            bit_64 = 1\n            len_delimited = 2\n            group_start = 3\n            group_end = 4\n            bit_32 = 5\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.key = vlq_base128_le.VlqBase128Le(self._io)\n            _on = self.wire_type\n            if _on == GoogleProtobuf.Pair.WireTypes.varint:\n                self.value = vlq_base128_le.VlqBase128Le(self._io)\n            elif _on == GoogleProtobuf.Pair.WireTypes.len_delimited:\n                self.value = GoogleProtobuf.DelimitedBytes(self._io, self, self._root)\n            elif _on == GoogleProtobuf.Pair.WireTypes.bit_64:\n                self.value = self._io.read_u8le()\n            elif _on == GoogleProtobuf.Pair.WireTypes.bit_32:\n                self.value = self._io.read_u4le()\n\n        @property\n        def wire_type(self):\n            \"\"\"\"Wire type\" is a part of the \"key\" that carries enough\n            information to parse value from the wire, i.e. read correct\n            amount of bytes, but there's not enough informaton to\n            interprete in unambiguously. For example, one can't clearly\n            distinguish 64-bit fixed-sized integers from 64-bit floats,\n            signed zigzag-encoded varints from regular unsigned varints,\n            arbitrary bytes from UTF-8 encoded strings, etc.\n            \"\"\"\n            if hasattr(self, '_m_wire_type'):\n                return self._m_wire_type\n\n            self._m_wire_type = KaitaiStream.resolve_enum(GoogleProtobuf.Pair.WireTypes, (self.key.value & 7))\n            return getattr(self, '_m_wire_type', None)\n\n        @property\n        def field_tag(self):\n            \"\"\"Identifies a field of protocol. One can look up symbolic\n            field name in a `.proto` file by this field tag.\n            \"\"\"\n            if hasattr(self, '_m_field_tag'):\n                return self._m_field_tag\n\n            self._m_field_tag = (self.key.value >> 3)\n            return getattr(self, '_m_field_tag', None)\n\n\n    class DelimitedBytes(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = vlq_base128_le.VlqBase128Le(self._io)\n            self.body = self._io.read_bytes(self.len.value)\n\n\n\n", "mitmproxy/contrib/kaitaistruct/tls_client_hello.py": "# This is a generated file! Please edit source .ksy file and use kaitai-struct-compiler to rebuild\n\nimport kaitaistruct\nfrom kaitaistruct import KaitaiStruct, KaitaiStream, BytesIO\n\n\nif getattr(kaitaistruct, 'API_VERSION', (0, 9)) < (0, 9):\n    raise Exception(\"Incompatible Kaitai Struct Python API: 0.9 or later is required, but you have %s\" % (kaitaistruct.__version__))\n\nclass TlsClientHello(KaitaiStruct):\n    def __init__(self, _io, _parent=None, _root=None):\n        self._io = _io\n        self._parent = _parent\n        self._root = _root if _root else self\n        self._read()\n\n    def _read(self):\n        self.version = TlsClientHello.Version(self._io, self, self._root)\n        self.random = TlsClientHello.Random(self._io, self, self._root)\n        self.session_id = TlsClientHello.SessionId(self._io, self, self._root)\n        self.cipher_suites = TlsClientHello.CipherSuites(self._io, self, self._root)\n        self.compression_methods = TlsClientHello.CompressionMethods(self._io, self, self._root)\n        if self._io.is_eof() == False:\n            self.extensions = TlsClientHello.Extensions(self._io, self, self._root)\n\n\n    class ServerName(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.name_type = self._io.read_u1()\n            self.length = self._io.read_u2be()\n            self.host_name = self._io.read_bytes(self.length)\n\n\n    class Random(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.gmt_unix_time = self._io.read_u4be()\n            self.random = self._io.read_bytes(28)\n\n\n    class SessionId(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = self._io.read_u1()\n            self.sid = self._io.read_bytes(self.len)\n\n\n    class Sni(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.list_length = self._io.read_u2be()\n            self.server_names = []\n            i = 0\n            while not self._io.is_eof():\n                self.server_names.append(TlsClientHello.ServerName(self._io, self, self._root))\n                i += 1\n\n\n\n    class CipherSuites(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = self._io.read_u2be()\n            self.cipher_suites = []\n            for i in range(self.len // 2):\n                self.cipher_suites.append(self._io.read_u2be())\n\n\n\n    class CompressionMethods(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = self._io.read_u1()\n            self.compression_methods = self._io.read_bytes(self.len)\n\n\n    class Alpn(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.ext_len = self._io.read_u2be()\n            self.alpn_protocols = []\n            i = 0\n            while not self._io.is_eof():\n                self.alpn_protocols.append(TlsClientHello.Protocol(self._io, self, self._root))\n                i += 1\n\n\n\n    class Extensions(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len = self._io.read_u2be()\n            self.extensions = []\n            i = 0\n            while not self._io.is_eof():\n                self.extensions.append(TlsClientHello.Extension(self._io, self, self._root))\n                i += 1\n\n\n\n    class Version(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.major = self._io.read_u1()\n            self.minor = self._io.read_u1()\n\n\n    class Protocol(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.strlen = self._io.read_u1()\n            self.name = self._io.read_bytes(self.strlen)\n\n\n    class Extension(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.type = self._io.read_u2be()\n            self.len = self._io.read_u2be()\n            _on = self.type\n            if _on == 0:\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = TlsClientHello.Sni(_io__raw_body, self, self._root)\n            elif _on == 16:\n                self._raw_body = self._io.read_bytes(self.len)\n                _io__raw_body = KaitaiStream(BytesIO(self._raw_body))\n                self.body = TlsClientHello.Alpn(_io__raw_body, self, self._root)\n            else:\n                self.body = self._io.read_bytes(self.len)\n\n\n\n", "mitmproxy/contrib/kaitaistruct/__init__.py": "", "mitmproxy/contrib/kaitaistruct/gif.py": "# This is a generated file! Please edit source .ksy file and use kaitai-struct-compiler to rebuild\n\nimport kaitaistruct\nfrom kaitaistruct import KaitaiStruct, KaitaiStream, BytesIO\nfrom enum import Enum\n\n\nif getattr(kaitaistruct, 'API_VERSION', (0, 9)) < (0, 9):\n    raise Exception(\"Incompatible Kaitai Struct Python API: 0.9 or later is required, but you have %s\" % (kaitaistruct.__version__))\n\nclass Gif(KaitaiStruct):\n    \"\"\"GIF (Graphics Interchange Format) is an image file format, developed\n    in 1987. It became popular in 1990s as one of the main image formats\n    used in World Wide Web.\n    \n    GIF format allows encoding of palette-based images up to 256 colors\n    (each of the colors can be chosen from a 24-bit RGB\n    colorspace). Image data stream uses LZW (Lempel-Ziv-Welch) lossless\n    compression.\n    \n    Over the years, several version of the format were published and\n    several extensions to it were made, namely, a popular Netscape\n    extension that allows to store several images in one file, switching\n    between them, which produces crude form of animation.\n    \n    Structurally, format consists of several mandatory headers and then\n    a stream of blocks follows. Blocks can carry additional\n    metainformation or image data.\n    \"\"\"\n\n    class BlockType(Enum):\n        extension = 33\n        local_image_descriptor = 44\n        end_of_file = 59\n\n    class ExtensionLabel(Enum):\n        graphic_control = 249\n        comment = 254\n        application = 255\n    def __init__(self, _io, _parent=None, _root=None):\n        self._io = _io\n        self._parent = _parent\n        self._root = _root if _root else self\n        self._read()\n\n    def _read(self):\n        self.hdr = Gif.Header(self._io, self, self._root)\n        self.logical_screen_descriptor = Gif.LogicalScreenDescriptorStruct(self._io, self, self._root)\n        if self.logical_screen_descriptor.has_color_table:\n            self._raw_global_color_table = self._io.read_bytes((self.logical_screen_descriptor.color_table_size * 3))\n            _io__raw_global_color_table = KaitaiStream(BytesIO(self._raw_global_color_table))\n            self.global_color_table = Gif.ColorTable(_io__raw_global_color_table, self, self._root)\n\n        self.blocks = []\n        i = 0\n        while True:\n            _ = Gif.Block(self._io, self, self._root)\n            self.blocks.append(_)\n            if  ((self._io.is_eof()) or (_.block_type == Gif.BlockType.end_of_file)) :\n                break\n            i += 1\n\n    class ImageData(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           - section 22 - https://www.w3.org/Graphics/GIF/spec-gif89a.txt\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.lzw_min_code_size = self._io.read_u1()\n            self.subblocks = Gif.Subblocks(self._io, self, self._root)\n\n\n    class ColorTableEntry(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.red = self._io.read_u1()\n            self.green = self._io.read_u1()\n            self.blue = self._io.read_u1()\n\n\n    class LogicalScreenDescriptorStruct(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           - section 18 - https://www.w3.org/Graphics/GIF/spec-gif89a.txt\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.screen_width = self._io.read_u2le()\n            self.screen_height = self._io.read_u2le()\n            self.flags = self._io.read_u1()\n            self.bg_color_index = self._io.read_u1()\n            self.pixel_aspect_ratio = self._io.read_u1()\n\n        @property\n        def has_color_table(self):\n            if hasattr(self, '_m_has_color_table'):\n                return self._m_has_color_table\n\n            self._m_has_color_table = (self.flags & 128) != 0\n            return getattr(self, '_m_has_color_table', None)\n\n        @property\n        def color_table_size(self):\n            if hasattr(self, '_m_color_table_size'):\n                return self._m_color_table_size\n\n            self._m_color_table_size = (2 << (self.flags & 7))\n            return getattr(self, '_m_color_table_size', None)\n\n\n    class LocalImageDescriptor(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.left = self._io.read_u2le()\n            self.top = self._io.read_u2le()\n            self.width = self._io.read_u2le()\n            self.height = self._io.read_u2le()\n            self.flags = self._io.read_u1()\n            if self.has_color_table:\n                self._raw_local_color_table = self._io.read_bytes((self.color_table_size * 3))\n                _io__raw_local_color_table = KaitaiStream(BytesIO(self._raw_local_color_table))\n                self.local_color_table = Gif.ColorTable(_io__raw_local_color_table, self, self._root)\n\n            self.image_data = Gif.ImageData(self._io, self, self._root)\n\n        @property\n        def has_color_table(self):\n            if hasattr(self, '_m_has_color_table'):\n                return self._m_has_color_table\n\n            self._m_has_color_table = (self.flags & 128) != 0\n            return getattr(self, '_m_has_color_table', None)\n\n        @property\n        def has_interlace(self):\n            if hasattr(self, '_m_has_interlace'):\n                return self._m_has_interlace\n\n            self._m_has_interlace = (self.flags & 64) != 0\n            return getattr(self, '_m_has_interlace', None)\n\n        @property\n        def has_sorted_color_table(self):\n            if hasattr(self, '_m_has_sorted_color_table'):\n                return self._m_has_sorted_color_table\n\n            self._m_has_sorted_color_table = (self.flags & 32) != 0\n            return getattr(self, '_m_has_sorted_color_table', None)\n\n        @property\n        def color_table_size(self):\n            if hasattr(self, '_m_color_table_size'):\n                return self._m_color_table_size\n\n            self._m_color_table_size = (2 << (self.flags & 7))\n            return getattr(self, '_m_color_table_size', None)\n\n\n    class Block(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.block_type = KaitaiStream.resolve_enum(Gif.BlockType, self._io.read_u1())\n            _on = self.block_type\n            if _on == Gif.BlockType.extension:\n                self.body = Gif.Extension(self._io, self, self._root)\n            elif _on == Gif.BlockType.local_image_descriptor:\n                self.body = Gif.LocalImageDescriptor(self._io, self, self._root)\n\n\n    class ColorTable(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           - section 19 - https://www.w3.org/Graphics/GIF/spec-gif89a.txt\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.entries = []\n            i = 0\n            while not self._io.is_eof():\n                self.entries.append(Gif.ColorTableEntry(self._io, self, self._root))\n                i += 1\n\n\n\n    class Header(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           - section 17 - https://www.w3.org/Graphics/GIF/spec-gif89a.txt\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.magic = self._io.read_bytes(3)\n            if not self.magic == b\"\\x47\\x49\\x46\":\n                raise kaitaistruct.ValidationNotEqualError(b\"\\x47\\x49\\x46\", self.magic, self._io, u\"/types/header/seq/0\")\n            self.version = (self._io.read_bytes(3)).decode(u\"ASCII\")\n\n\n    class ExtGraphicControl(KaitaiStruct):\n        \"\"\"\n        .. seealso::\n           - section 23 - https://www.w3.org/Graphics/GIF/spec-gif89a.txt\n        \"\"\"\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.block_size = self._io.read_bytes(1)\n            if not self.block_size == b\"\\x04\":\n                raise kaitaistruct.ValidationNotEqualError(b\"\\x04\", self.block_size, self._io, u\"/types/ext_graphic_control/seq/0\")\n            self.flags = self._io.read_u1()\n            self.delay_time = self._io.read_u2le()\n            self.transparent_idx = self._io.read_u1()\n            self.terminator = self._io.read_bytes(1)\n            if not self.terminator == b\"\\x00\":\n                raise kaitaistruct.ValidationNotEqualError(b\"\\x00\", self.terminator, self._io, u\"/types/ext_graphic_control/seq/4\")\n\n        @property\n        def transparent_color_flag(self):\n            if hasattr(self, '_m_transparent_color_flag'):\n                return self._m_transparent_color_flag\n\n            self._m_transparent_color_flag = (self.flags & 1) != 0\n            return getattr(self, '_m_transparent_color_flag', None)\n\n        @property\n        def user_input_flag(self):\n            if hasattr(self, '_m_user_input_flag'):\n                return self._m_user_input_flag\n\n            self._m_user_input_flag = (self.flags & 2) != 0\n            return getattr(self, '_m_user_input_flag', None)\n\n\n    class Subblock(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len_bytes = self._io.read_u1()\n            self.bytes = self._io.read_bytes(self.len_bytes)\n\n\n    class ApplicationId(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.len_bytes = self._io.read_u1()\n            if not self.len_bytes == 11:\n                raise kaitaistruct.ValidationNotEqualError(11, self.len_bytes, self._io, u\"/types/application_id/seq/0\")\n            self.application_identifier = (self._io.read_bytes(8)).decode(u\"ASCII\")\n            self.application_auth_code = self._io.read_bytes(3)\n\n\n    class ExtApplication(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.application_id = Gif.ApplicationId(self._io, self, self._root)\n            self.subblocks = []\n            i = 0\n            while True:\n                _ = Gif.Subblock(self._io, self, self._root)\n                self.subblocks.append(_)\n                if _.len_bytes == 0:\n                    break\n                i += 1\n\n\n    class Subblocks(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.entries = []\n            i = 0\n            while True:\n                _ = Gif.Subblock(self._io, self, self._root)\n                self.entries.append(_)\n                if _.len_bytes == 0:\n                    break\n                i += 1\n\n\n    class Extension(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.label = KaitaiStream.resolve_enum(Gif.ExtensionLabel, self._io.read_u1())\n            _on = self.label\n            if _on == Gif.ExtensionLabel.application:\n                self.body = Gif.ExtApplication(self._io, self, self._root)\n            elif _on == Gif.ExtensionLabel.comment:\n                self.body = Gif.Subblocks(self._io, self, self._root)\n            elif _on == Gif.ExtensionLabel.graphic_control:\n                self.body = Gif.ExtGraphicControl(self._io, self, self._root)\n            else:\n                self.body = Gif.Subblocks(self._io, self, self._root)\n\n\n\n", "mitmproxy/contrib/kaitaistruct/jpeg.py": "# This is a generated file! Please edit source .ksy file and use kaitai-struct-compiler to rebuild\n\nimport kaitaistruct\nfrom kaitaistruct import KaitaiStruct, KaitaiStream, BytesIO\nfrom enum import Enum\n\n\nif getattr(kaitaistruct, 'API_VERSION', (0, 9)) < (0, 9):\n    raise Exception(\"Incompatible Kaitai Struct Python API: 0.9 or later is required, but you have %s\" % (kaitaistruct.__version__))\n\nfrom . import exif\nclass Jpeg(KaitaiStruct):\n    \"\"\"JPEG File Interchange Format, or JFIF, or, more colloquially known\n    as just \"JPEG\" or \"JPG\", is a popular 2D bitmap image file format,\n    offering lossy compression which works reasonably well with\n    photographic images.\n    \n    Format is organized as a container format, serving multiple\n    \"segments\", each starting with a magic and a marker. JFIF standard\n    dictates order and mandatory apperance of segments:\n    \n    * SOI\n    * APP0 (with JFIF magic)\n    * APP0 (with JFXX magic, optional)\n    * everything else\n    * SOS\n    * JPEG-compressed stream\n    * EOI\n    \"\"\"\n\n    class ComponentId(Enum):\n        y = 1\n        cb = 2\n        cr = 3\n        i = 4\n        q = 5\n    def __init__(self, _io, _parent=None, _root=None):\n        self._io = _io\n        self._parent = _parent\n        self._root = _root if _root else self\n        self._read()\n\n    def _read(self):\n        self.segments = []\n        i = 0\n        while not self._io.is_eof():\n            self.segments.append(Jpeg.Segment(self._io, self, self._root))\n            i += 1\n\n\n    class Segment(KaitaiStruct):\n\n        class MarkerEnum(Enum):\n            tem = 1\n            sof0 = 192\n            sof1 = 193\n            sof2 = 194\n            sof3 = 195\n            dht = 196\n            sof5 = 197\n            sof6 = 198\n            sof7 = 199\n            soi = 216\n            eoi = 217\n            sos = 218\n            dqt = 219\n            dnl = 220\n            dri = 221\n            dhp = 222\n            app0 = 224\n            app1 = 225\n            app2 = 226\n            app3 = 227\n            app4 = 228\n            app5 = 229\n            app6 = 230\n            app7 = 231\n            app8 = 232\n            app9 = 233\n            app10 = 234\n            app11 = 235\n            app12 = 236\n            app13 = 237\n            app14 = 238\n            app15 = 239\n            com = 254\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.magic = self._io.read_bytes(1)\n            if not self.magic == b\"\\xFF\":\n                raise kaitaistruct.ValidationNotEqualError(b\"\\xFF\", self.magic, self._io, u\"/types/segment/seq/0\")\n            self.marker = KaitaiStream.resolve_enum(Jpeg.Segment.MarkerEnum, self._io.read_u1())\n            if  ((self.marker != Jpeg.Segment.MarkerEnum.soi) and (self.marker != Jpeg.Segment.MarkerEnum.eoi)) :\n                self.length = self._io.read_u2be()\n\n            if  ((self.marker != Jpeg.Segment.MarkerEnum.soi) and (self.marker != Jpeg.Segment.MarkerEnum.eoi)) :\n                _on = self.marker\n                if _on == Jpeg.Segment.MarkerEnum.app1:\n                    self._raw_data = self._io.read_bytes((self.length - 2))\n                    _io__raw_data = KaitaiStream(BytesIO(self._raw_data))\n                    self.data = Jpeg.SegmentApp1(_io__raw_data, self, self._root)\n                elif _on == Jpeg.Segment.MarkerEnum.app0:\n                    self._raw_data = self._io.read_bytes((self.length - 2))\n                    _io__raw_data = KaitaiStream(BytesIO(self._raw_data))\n                    self.data = Jpeg.SegmentApp0(_io__raw_data, self, self._root)\n                elif _on == Jpeg.Segment.MarkerEnum.sof0:\n                    self._raw_data = self._io.read_bytes((self.length - 2))\n                    _io__raw_data = KaitaiStream(BytesIO(self._raw_data))\n                    self.data = Jpeg.SegmentSof0(_io__raw_data, self, self._root)\n                elif _on == Jpeg.Segment.MarkerEnum.sos:\n                    self._raw_data = self._io.read_bytes((self.length - 2))\n                    _io__raw_data = KaitaiStream(BytesIO(self._raw_data))\n                    self.data = Jpeg.SegmentSos(_io__raw_data, self, self._root)\n                else:\n                    self.data = self._io.read_bytes((self.length - 2))\n\n            if self.marker == Jpeg.Segment.MarkerEnum.sos:\n                self.image_data = self._io.read_bytes_full()\n\n\n\n    class SegmentSos(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.num_components = self._io.read_u1()\n            self.components = []\n            for i in range(self.num_components):\n                self.components.append(Jpeg.SegmentSos.Component(self._io, self, self._root))\n\n            self.start_spectral_selection = self._io.read_u1()\n            self.end_spectral = self._io.read_u1()\n            self.appr_bit_pos = self._io.read_u1()\n\n        class Component(KaitaiStruct):\n            def __init__(self, _io, _parent=None, _root=None):\n                self._io = _io\n                self._parent = _parent\n                self._root = _root if _root else self\n                self._read()\n\n            def _read(self):\n                self.id = KaitaiStream.resolve_enum(Jpeg.ComponentId, self._io.read_u1())\n                self.huffman_table = self._io.read_u1()\n\n\n\n    class SegmentApp1(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.magic = (self._io.read_bytes_term(0, False, True, True)).decode(u\"ASCII\")\n            _on = self.magic\n            if _on == u\"Exif\":\n                self.body = Jpeg.ExifInJpeg(self._io, self, self._root)\n\n\n    class SegmentSof0(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.bits_per_sample = self._io.read_u1()\n            self.image_height = self._io.read_u2be()\n            self.image_width = self._io.read_u2be()\n            self.num_components = self._io.read_u1()\n            self.components = []\n            for i in range(self.num_components):\n                self.components.append(Jpeg.SegmentSof0.Component(self._io, self, self._root))\n\n\n        class Component(KaitaiStruct):\n            def __init__(self, _io, _parent=None, _root=None):\n                self._io = _io\n                self._parent = _parent\n                self._root = _root if _root else self\n                self._read()\n\n            def _read(self):\n                self.id = KaitaiStream.resolve_enum(Jpeg.ComponentId, self._io.read_u1())\n                self.sampling_factors = self._io.read_u1()\n                self.quantization_table_id = self._io.read_u1()\n\n            @property\n            def sampling_x(self):\n                if hasattr(self, '_m_sampling_x'):\n                    return self._m_sampling_x\n\n                self._m_sampling_x = ((self.sampling_factors & 240) >> 4)\n                return getattr(self, '_m_sampling_x', None)\n\n            @property\n            def sampling_y(self):\n                if hasattr(self, '_m_sampling_y'):\n                    return self._m_sampling_y\n\n                self._m_sampling_y = (self.sampling_factors & 15)\n                return getattr(self, '_m_sampling_y', None)\n\n\n\n    class ExifInJpeg(KaitaiStruct):\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.extra_zero = self._io.read_bytes(1)\n            if not self.extra_zero == b\"\\x00\":\n                raise kaitaistruct.ValidationNotEqualError(b\"\\x00\", self.extra_zero, self._io, u\"/types/exif_in_jpeg/seq/0\")\n            self._raw_data = self._io.read_bytes_full()\n            _io__raw_data = KaitaiStream(BytesIO(self._raw_data))\n            self.data = exif.Exif(_io__raw_data)\n\n\n    class SegmentApp0(KaitaiStruct):\n\n        class DensityUnit(Enum):\n            no_units = 0\n            pixels_per_inch = 1\n            pixels_per_cm = 2\n        def __init__(self, _io, _parent=None, _root=None):\n            self._io = _io\n            self._parent = _parent\n            self._root = _root if _root else self\n            self._read()\n\n        def _read(self):\n            self.magic = (self._io.read_bytes(5)).decode(u\"ASCII\")\n            self.version_major = self._io.read_u1()\n            self.version_minor = self._io.read_u1()\n            self.density_units = KaitaiStream.resolve_enum(Jpeg.SegmentApp0.DensityUnit, self._io.read_u1())\n            self.density_x = self._io.read_u2be()\n            self.density_y = self._io.read_u2be()\n            self.thumbnail_x = self._io.read_u1()\n            self.thumbnail_y = self._io.read_u1()\n            self.thumbnail = self._io.read_bytes(((self.thumbnail_x * self.thumbnail_y) * 3))\n\n\n\n", "mitmproxy/contrib/wbxml/ASWBXMLCodePage.py": "#!/usr/bin/env python3\n'''\n@author: David Shaw, shawd@vmware.com\n\nInspired by EAS Inspector for Fiddler\nhttps://easinspectorforfiddler.codeplex.com\n\n----- The MIT License (MIT) ----- \nFilename: ASWBXMLCodePage.py\nCopyright (c) 2014, David P. Shaw\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n'''\nclass ASWBXMLCodePage:\n\tdef __init__(self):\n\t\tself.namespace = \"\"\n\t\tself.xmlns = \"\"\n\t\tself.tokenLookup = {}\n\t\tself.tagLookup = {}\n\t\n\tdef addToken(self, token, tag):\n\t\tself.tokenLookup[token] = tag\n\t\tself.tagLookup[tag] = token\n\t\n\tdef getToken(self, tag):\n\t\tif tag in self.tagLookup:\n\t\t\treturn self.tagLookup[tag]\n\t\treturn 0xFF\n\t\n\tdef getTag(self, token):\n\t\tif token in self.tokenLookup:\n\t\t\treturn self.tokenLookup[token]\n\t\treturn None\n\t\n\tdef __repr__(self):\n\t\treturn str(self.tokenLookup)\n", "mitmproxy/contrib/wbxml/ASCommandResponse.py": "#!/usr/bin/env python3\n'''\n@author: David Shaw, shawd@vmware.com\n\nInspired by EAS Inspector for Fiddler\nhttps://easinspectorforfiddler.codeplex.com\n\n----- The MIT License (MIT) ----- \nFilename: ASCommandResponse.py\nCopyright (c) 2014, David P. Shaw\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n'''\nfrom .ASWBXML import ASWBXML\nimport logging\n\nclass ASCommandResponse:\n\n\tdef __init__(self, response):\n\t\tself.wbxmlBody = response\n\t\ttry:\n\t\t\tif ( len(response) > 0):\n\t\t\t\tself.xmlString = self.decodeWBXML(self.wbxmlBody)\n\t\t\telse:\n\t\t\t\traise ValueError(\"Empty WBXML body passed\")\n\t\texcept Exception as e:\n\t\t\tself.xmlString = None\n\t\t\traise ValueError(\"Error: {0}\".format(e))\n\n\tdef getWBXMLBytes(self):\n\t\treturn self.wbxmlBytes\n\t\n\tdef getXMLString(self):\n\t\treturn self.xmlString\n\t\n\tdef decodeWBXML(self, body):\n\t\tself.instance = ASWBXML()\n\t\tself.instance.loadBytes(body)\n\t\treturn self.instance.getXml()\n\nif __name__ == \"__main__\":\n\timport os\t\n\tlogging.basicConfig(level=logging.INFO)\n\n\tprojectDir = os.path.dirname(os.path.realpath(\".\"))\n\tsamplesDir = os.path.join(projectDir, \"Samples/\")\n\tlistOfSamples = os.listdir(samplesDir)\n\n\tfor filename in listOfSamples:\n\t\twith open(samplesDir + os.sep + filename, \"rb\") as f:\n\t\t\tbyteWBXML = f.read()\n\n\t\tlogging.info(\"-\"*100)\n\t\tlogging.info(filename)\n\t\tlogging.info(\"-\"*100)\n\t\tinstance = ASCommandResponse(byteWBXML)\n\t\tlogging.info(instance.xmlString)\n", "mitmproxy/contrib/wbxml/ASWBXML.py": "#!/usr/bin/env python3\n'''\n@author: David Shaw, shawd@vmware.com\n\nInspired by EAS Inspector for Fiddler\nhttps://easinspectorforfiddler.codeplex.com\n\n----- The MIT License (MIT) ----- \nFilename: ASWBXML.py\nCopyright (c) 2014, David P. Shaw\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n'''\nimport xml.dom.minidom\nimport logging\n\nfrom .ASWBXMLCodePage import ASWBXMLCodePage\nfrom .ASWBXMLByteQueue import ASWBXMLByteQueue\nfrom .GlobalTokens import GlobalTokens\nfrom .InvalidDataException import InvalidDataException\n\nclass ASWBXML:\n\tversionByte = 0x03\n\tpublicIdentifierByte = 0x01\n\tcharacterSetByte = 0x6A\n\tstringTableLengthByte = 0x00\n\t\n\tdef __init__(self):\n\t\t\n\t\t# empty on init\n\t\tself.xmlDoc = xml.dom.minidom.Document()\n\t\tself.currentCodePage = 0\n\t\tself.defaultCodePage = -1\n\t\t\n\t\t# Load up code pages\n\t\t# Currently there are 25 code pages as per MS-ASWBXML\n\t\tself.codePages = []\n\n\t\t# region Code Page Initialization\n\t\t# Code Page 0: AirSync\n\t\t# region AirSync Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"AirSync:\"\n\t\tpage.xmlns = \"airsync\"\n\n\t\tpage.addToken(0x05, \"Sync\")\n\t\tpage.addToken(0x06, \"Responses\")\n\t\tpage.addToken(0x07, \"Add\")\n\t\tpage.addToken(0x08, \"Change\")\n\t\tpage.addToken(0x09, \"Delete\")\n\t\tpage.addToken(0x0A, \"Fetch\")\n\t\tpage.addToken(0x0B, \"SyncKey\")\n\t\tpage.addToken(0x0C, \"ClientId\")\n\t\tpage.addToken(0x0D, \"ServerId\")\n\t\tpage.addToken(0x0E, \"Status\")\n\t\tpage.addToken(0x0F, \"Collection\")\n\t\tpage.addToken(0x10, \"Class\")\n\t\tpage.addToken(0x12, \"CollectionId\")\n\t\tpage.addToken(0x13, \"GetChanges\")\n\t\tpage.addToken(0x14, \"MoreAvailable\")\n\t\tpage.addToken(0x15, \"WindowSize\")\n\t\tpage.addToken(0x16, \"Commands\")\n\t\tpage.addToken(0x17, \"Options\")\n\t\tpage.addToken(0x18, \"FilterType\")\n\t\tpage.addToken(0x1B, \"Conflict\")\n\t\tpage.addToken(0x1C, \"Collections\")\n\t\tpage.addToken(0x1D, \"ApplicationData\")\n\t\tpage.addToken(0x1E, \"DeletesAsMoves\")\n\t\tpage.addToken(0x20, \"Supported\")\n\t\tpage.addToken(0x21, \"SoftDelete\")\n\t\tpage.addToken(0x22, \"MIMESupport\")\n\t\tpage.addToken(0x23, \"MIMETruncation\")\n\t\tpage.addToken(0x24, \"Wait\")\n\t\tpage.addToken(0x25, \"Limit\")\n\t\tpage.addToken(0x26, \"Partial\")\n\t\tpage.addToken(0x27, \"ConversationMode\")\n\t\tpage.addToken(0x28, \"MaxItems\")\n\t\tpage.addToken(0x29, \"HeartbeatInterval\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 1: Contacts\n\t\t# region Contacts Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Contacts:\"\n\t\tpage.xmlns = \"contacts\"\n\n\t\tpage.addToken(0x05, \"Anniversary\")\n\t\tpage.addToken(0x06, \"AssistantName\")\n\t\tpage.addToken(0x07, \"AssistantTelephoneNumber\")\n\t\tpage.addToken(0x08, \"Birthday\")\n\t\tpage.addToken(0x0C, \"Business2PhoneNumber\")\n\t\tpage.addToken(0x0D, \"BusinessCity\")\n\t\tpage.addToken(0x0E, \"BusinessCountry\")\n\t\tpage.addToken(0x0F, \"BusinessPostalCode\")\n\t\tpage.addToken(0x10, \"BusinessState\")\n\t\tpage.addToken(0x11, \"BusinessStreet\")\n\t\tpage.addToken(0x12, \"BusinessFaxNumber\")\n\t\tpage.addToken(0x13, \"BusinessPhoneNumber\")\n\t\tpage.addToken(0x14, \"CarPhoneNumber\")\n\t\tpage.addToken(0x15, \"Categories\")\n\t\tpage.addToken(0x16, \"Category\")\n\t\tpage.addToken(0x17, \"Children\")\n\t\tpage.addToken(0x18, \"Child\")\n\t\tpage.addToken(0x19, \"CompanyName\")\n\t\tpage.addToken(0x1A, \"Department\")\n\t\tpage.addToken(0x1B, \"Email1Address\")\n\t\tpage.addToken(0x1C, \"Email2Address\")\n\t\tpage.addToken(0x1D, \"Email3Address\")\n\t\tpage.addToken(0x1E, \"FileAs\")\n\t\tpage.addToken(0x1F, \"FirstName\")\n\t\tpage.addToken(0x20, \"Home2PhoneNumber\")\n\t\tpage.addToken(0x21, \"HomeCity\")\n\t\tpage.addToken(0x22, \"HomeCountry\")\n\t\tpage.addToken(0x23, \"HomePostalCode\")\n\t\tpage.addToken(0x24, \"HomeState\")\n\t\tpage.addToken(0x25, \"HomeStreet\")\n\t\tpage.addToken(0x26, \"HomeFaxNumber\")\n\t\tpage.addToken(0x27, \"HomePhoneNumber\")\n\t\tpage.addToken(0x28, \"JobTitle\")\n\t\tpage.addToken(0x29, \"LastName\")\n\t\tpage.addToken(0x2A, \"MiddleName\")\n\t\tpage.addToken(0x2B, \"MobilePhoneNumber\")\n\t\tpage.addToken(0x2C, \"OfficeLocation\")\n\t\tpage.addToken(0x2D, \"OtherCity\")\n\t\tpage.addToken(0x2E, \"OtherCountry\")\n\t\tpage.addToken(0x2F, \"OtherPostalCode\")\n\t\tpage.addToken(0x30, \"OtherState\")\n\t\tpage.addToken(0x31, \"OtherStreet\")\n\t\tpage.addToken(0x32, \"PagerNumber\")\n\t\tpage.addToken(0x33, \"RadioPhoneNumber\")\n\t\tpage.addToken(0x34, \"Spouse\")\n\t\tpage.addToken(0x35, \"Suffix\")\n\t\tpage.addToken(0x36, \"Title\")\n\t\tpage.addToken(0x37, \"Webpage\")\n\t\tpage.addToken(0x38, \"YomiCompanyName\")\n\t\tpage.addToken(0x39, \"YomiFirstName\")\n\t\tpage.addToken(0x3A, \"YomiLastName\")\n\t\tpage.addToken(0x3C, \"Picture\")\n\t\tpage.addToken(0x3D, \"Alias\")\n\t\tpage.addToken(0x3E, \"WeightedRank\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 2: Email\n\t\t# region Email Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Email:\"\n\t\tpage.xmlns = \"email\"\n\n\t\tpage.addToken(0x0F, \"DateReceived\")\n\t\tpage.addToken(0x11, \"DisplayTo\")\n\t\tpage.addToken(0x12, \"Importance\")\n\t\tpage.addToken(0x13, \"MessageClass\")\n\t\tpage.addToken(0x14, \"Subject\")\n\t\tpage.addToken(0x15, \"Read\")\n\t\tpage.addToken(0x16, \"To\")\n\t\tpage.addToken(0x17, \"CC\")\n\t\tpage.addToken(0x18, \"From\")\n\t\tpage.addToken(0x19, \"ReplyTo\")\n\t\tpage.addToken(0x1A, \"AllDayEvent\")\n\t\tpage.addToken(0x1B, \"Categories\")\n\t\tpage.addToken(0x1C, \"Category\")\n\t\tpage.addToken(0x1D, \"DTStamp\")\n\t\tpage.addToken(0x1E, \"EndTime\")\n\t\tpage.addToken(0x1F, \"InstanceType\")\n\t\tpage.addToken(0x20, \"BusyStatus\")\n\t\tpage.addToken(0x21, \"Location\")\n\t\tpage.addToken(0x22, \"MeetingRequest\")\n\t\tpage.addToken(0x23, \"Organizer\")\n\t\tpage.addToken(0x24, \"RecurrenceId\")\n\t\tpage.addToken(0x25, \"Reminder\")\n\t\tpage.addToken(0x26, \"ResponseRequested\")\n\t\tpage.addToken(0x27, \"Recurrences\")\n\t\tpage.addToken(0x28, \"Recurrence\")\n\t\tpage.addToken(0x29, \"Recurrence_Type\")\n\t\tpage.addToken(0x2A, \"Recurrence_Until\")\n\t\tpage.addToken(0x2B, \"Recurrence_Occurrences\")\n\t\tpage.addToken(0x2C, \"Recurrence_Interval\")\n\t\tpage.addToken(0x2D, \"Recurrence_DayOfWeek\")\n\t\tpage.addToken(0x2E, \"Recurrence_DayOfMonth\")\n\t\tpage.addToken(0x2F, \"Recurrence_WeekOfMonth\")\n\t\tpage.addToken(0x30, \"Recurrence_MonthOfYear\")\n\t\tpage.addToken(0x31, \"StartTime\")\n\t\tpage.addToken(0x32, \"Sensitivity\")\n\t\tpage.addToken(0x33, \"TimeZone\")\n\t\tpage.addToken(0x34, \"GlobalObjId\")\n\t\tpage.addToken(0x35, \"ThreadTopic\")\n\t\tpage.addToken(0x39, \"InternetCPID\")\n\t\tpage.addToken(0x3A, \"Flag\")\n\t\tpage.addToken(0x3B, \"FlagStatus\")\n\t\tpage.addToken(0x3C, \"ContentClass\")\n\t\tpage.addToken(0x3D, \"FlagType\")\n\t\tpage.addToken(0x3E, \"CompleteTime\")\n\t\tpage.addToken(0x3F, \"DisallowNewTimeProposal\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 3: AirNotify - retired\n\t\t# region AirNotify Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"\"\n\t\tpage.xmlns = \"\"\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 4: Calendar\n\t\t# region Calendar Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Calendar:\"\n\t\tpage.xmlns = \"calendar\"\n\n\t\tpage.addToken(0x05, \"TimeZone\")\n\t\tpage.addToken(0x06, \"AllDayEvent\")\n\t\tpage.addToken(0x07, \"Attendees\")\n\t\tpage.addToken(0x08, \"Attendee\")\n\t\tpage.addToken(0x09, \"Attendee_Email\")\n\t\tpage.addToken(0x0A, \"Attendee_Name\")\n\t\tpage.addToken(0x0D, \"BusyStatus\")\n\t\tpage.addToken(0x0E, \"Categories\")\n\t\tpage.addToken(0x0F, \"Category\")\n\t\tpage.addToken(0x11, \"DTStamp\")\n\t\tpage.addToken(0x12, \"EndTime\")\n\t\tpage.addToken(0x13, \"Exception\")\n\t\tpage.addToken(0x14, \"Exceptions\")\n\t\tpage.addToken(0x15, \"Exception_Deleted\")\n\t\tpage.addToken(0x16, \"Exception_StartTime\")\n\t\tpage.addToken(0x17, \"Location\")\n\t\tpage.addToken(0x18, \"MeetingStatus\")\n\t\tpage.addToken(0x19, \"Organizer_Email\")\n\t\tpage.addToken(0x1A, \"Organizer_Name\")\n\t\tpage.addToken(0x1B, \"Recurrence\")\n\t\tpage.addToken(0x1C, \"Recurrence_Type\")\n\t\tpage.addToken(0x1D, \"Recurrence_Until\")\n\t\tpage.addToken(0x1E, \"Recurrence_Occurrences\")\n\t\tpage.addToken(0x1F, \"Recurrence_Interval\")\n\t\tpage.addToken(0x20, \"Recurrence_DayOfWeek\")\n\t\tpage.addToken(0x21, \"Recurrence_DayOfMonth\")\n\t\tpage.addToken(0x22, \"Recurrence_WeekOfMonth\")\n\t\tpage.addToken(0x23, \"Recurrence_MonthOfYear\")\n\t\tpage.addToken(0x24, \"Reminder\")\n\t\tpage.addToken(0x25, \"Sensitivity\")\n\t\tpage.addToken(0x26, \"Subject\")\n\t\tpage.addToken(0x27, \"StartTime\")\n\t\tpage.addToken(0x28, \"UID\")\n\t\tpage.addToken(0x29, \"Attendee_Status\")\n\t\tpage.addToken(0x2A, \"Attendee_Type\")\n\t\tpage.addToken(0x33, \"DisallowNewTimeProposal\")\n\t\tpage.addToken(0x34, \"ResponseRequested\")\n\t\tpage.addToken(0x35, \"AppointmentReplyTime\")\n\t\tpage.addToken(0x36, \"ResponseType\")\n\t\tpage.addToken(0x37, \"CalendarType\")\n\t\tpage.addToken(0x38, \"IsLeapMonth\")\n\t\tpage.addToken(0x39, \"FirstDayOfWeek\")\n\t\tpage.addToken(0x3A, \"OnlineMeetingConfLink\")\n\t\tpage.addToken(0x3B, \"OnlineMeetingExternalLink\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 5: Move\n\t\t# region Move Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Move:\"\n\t\tpage.xmlns = \"move\"\n\n\t\tpage.addToken(0x05, \"MoveItems\")\n\t\tpage.addToken(0x06, \"Move\")\n\t\tpage.addToken(0x07, \"SrcMsgId\")\n\t\tpage.addToken(0x08, \"SrcFldId\")\n\t\tpage.addToken(0x09, \"DstFldId\")\n\t\tpage.addToken(0x0A, \"Response\")\n\t\tpage.addToken(0x0B, \"Status\")\n\t\tpage.addToken(0x0C, \"DstMsgId\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 6: ItemEstimate\n\t\t# region ItemEstimate Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"GetItemEstimate:\"\n\t\tpage.xmlns = \"getitemestimate\"\n\n\t\tpage.addToken(0x05, \"GetItemEstimate\")\n\t\tpage.addToken(0x06, \"Version\")\n\t\tpage.addToken(0x07, \"Collections\")\n\t\tpage.addToken(0x08, \"Collection\")\n\t\tpage.addToken(0x09, \"Class\")\n\t\tpage.addToken(0x0A, \"CollectionId\")\n\t\tpage.addToken(0x0B, \"DateTime\")\n\t\tpage.addToken(0x0C, \"Estimate\")\n\t\tpage.addToken(0x0D, \"Response\")\n\t\tpage.addToken(0x0E, \"Status\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 7: FolderHierarchy\n\t\t# region FolderHierarchy Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"FolderHierarchy:\"\n\t\tpage.xmlns = \"folderhierarchy\"\n\n\t\tpage.addToken(0x07, \"DisplayName\")\n\t\tpage.addToken(0x08, \"ServerId\")\n\t\tpage.addToken(0x09, \"ParentId\")\n\t\tpage.addToken(0x0A, \"Type\")\n\t\tpage.addToken(0x0C, \"Status\")\n\t\tpage.addToken(0x0E, \"Changes\")\n\t\tpage.addToken(0x0F, \"Add\")\n\t\tpage.addToken(0x10, \"Delete\")\n\t\tpage.addToken(0x11, \"Update\")\n\t\tpage.addToken(0x12, \"SyncKey\")\n\t\tpage.addToken(0x13, \"FolderCreate\")\n\t\tpage.addToken(0x14, \"FolderDelete\")\n\t\tpage.addToken(0x15, \"FolderUpdate\")\n\t\tpage.addToken(0x16, \"FolderSync\")\n\t\tpage.addToken(0x17, \"Count\")\n\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 8: MeetingResponse\n\t\t# region MeetingResponse Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"MeetingResponse:\"\n\t\tpage.xmlns = \"meetingresponse\"\n\n\t\tpage.addToken(0x05, \"CalendarId\")\n\t\tpage.addToken(0x06, \"CollectionId\")\n\t\tpage.addToken(0x07, \"MeetingResponse\")\n\t\tpage.addToken(0x08, \"RequestId\")\n\t\tpage.addToken(0x09, \"Request\")\n\t\tpage.addToken(0x0A, \"Result\")\n\t\tpage.addToken(0x0B, \"Status\")\n\t\tpage.addToken(0x0C, \"UserResponse\")\n\t\tpage.addToken(0x0E, \"InstanceId\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 9: Tasks\n\t\t# region Tasks Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Tasks:\"\n\t\tpage.xmlns = \"tasks\"\n\n\t\tpage.addToken(0x08, \"Categories\")\n\t\tpage.addToken(0x09, \"Category\")\n\t\tpage.addToken(0x0A, \"Complete\")\n\t\tpage.addToken(0x0B, \"DateCompleted\")\n\t\tpage.addToken(0x0C, \"DueDate\")\n\t\tpage.addToken(0x0D, \"UTCDueDate\")\n\t\tpage.addToken(0x0E, \"Importance\")\n\t\tpage.addToken(0x0F, \"Recurrence\")\n\t\tpage.addToken(0x10, \"Recurrence_Type\")\n\t\tpage.addToken(0x11, \"Recurrence_Start\")\n\t\tpage.addToken(0x12, \"Recurrence_Until\")\n\t\tpage.addToken(0x13, \"Recurrence_Occurrences\")\n\t\tpage.addToken(0x14, \"Recurrence_Interval\")\n\t\tpage.addToken(0x15, \"Recurrence_DayOfMonth\")\n\t\tpage.addToken(0x16, \"Recurrence_DayOfWeek\")\n\t\tpage.addToken(0x17, \"Recurrence_WeekOfMonth\")\n\t\tpage.addToken(0x18, \"Recurrence_MonthOfYear\")\n\t\tpage.addToken(0x19, \"Recurrence_Regenerate\")\n\t\tpage.addToken(0x1A, \"Recurrence_DeadOccur\")\n\t\tpage.addToken(0x1B, \"ReminderSet\")\n\t\tpage.addToken(0x1C, \"ReminderTime\")\n\t\tpage.addToken(0x1D, \"Sensitivity\")\n\t\tpage.addToken(0x1E, \"StartDate\")\n\t\tpage.addToken(0x1F, \"UTCStartDate\")\n\t\tpage.addToken(0x20, \"Subject\")\n\t\tpage.addToken(0x22, \"OrdinalDate\")\n\t\tpage.addToken(0x23, \"SubOrdinalDate\")\n\t\tpage.addToken(0x24, \"CalendarType\")\n\t\tpage.addToken(0x25, \"IsLeapMonth\")\n\t\tpage.addToken(0x26, \"FirstDayOfWeek\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 10: ResolveRecipients\n\t\t# region ResolveRecipients Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"ResolveRecipients:\"\n\t\tpage.xmlns = \"resolverecipients\"\n\n\t\tpage.addToken(0x05, \"ResolveRecipients\")\n\t\tpage.addToken(0x06, \"Response\")\n\t\tpage.addToken(0x07, \"Status\")\n\t\tpage.addToken(0x08, \"Type\")\n\t\tpage.addToken(0x09, \"Recipient\")\n\t\tpage.addToken(0x0A, \"DisplayName\")\n\t\tpage.addToken(0x0B, \"EmailAddress\")\n\t\tpage.addToken(0x0C, \"Certificates\")\n\t\tpage.addToken(0x0D, \"Certificate\")\n\t\tpage.addToken(0x0E, \"MiniCertificate\")\n\t\tpage.addToken(0x0F, \"Options\")\n\t\tpage.addToken(0x10, \"To\")\n\t\tpage.addToken(0x11, \"CertificateRetrieval\")\n\t\tpage.addToken(0x12, \"RecipientCount\")\n\t\tpage.addToken(0x13, \"MaxCertificates\")\n\t\tpage.addToken(0x14, \"MaxAmbiguousRecipients\")\n\t\tpage.addToken(0x15, \"CertificateCount\")\n\t\tpage.addToken(0x16, \"Availability\")\n\t\tpage.addToken(0x17, \"StartTime\")\n\t\tpage.addToken(0x18, \"EndTime\")\n\t\tpage.addToken(0x19, \"MergedFreeBusy\")\n\t\tpage.addToken(0x1A, \"Picture\")\n\t\tpage.addToken(0x1B, \"MaxSize\")\n\t\tpage.addToken(0x1C, \"Data\")\n\t\tpage.addToken(0x1D, \"MaxPictures\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 11: ValidateCert\n\t\t# region ValidateCert Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"ValidateCert:\"\n\t\tpage.xmlns = \"validatecert\"\n\n\t\tpage.addToken(0x05, \"ValidateCert\")\n\t\tpage.addToken(0x06, \"Certificates\")\n\t\tpage.addToken(0x07, \"Certificate\")\n\t\tpage.addToken(0x08, \"CertificateChain\")\n\t\tpage.addToken(0x09, \"CheckCRL\")\n\t\tpage.addToken(0x0A, \"Status\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 12: Contacts2\n\t\t# region Contacts2 Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Contacts2:\"\n\t\tpage.xmlns = \"contacts2\"\n\n\t\tpage.addToken(0x05, \"CustomerId\")\n\t\tpage.addToken(0x06, \"GovernmentId\")\n\t\tpage.addToken(0x07, \"IMAddress\")\n\t\tpage.addToken(0x08, \"IMAddress2\")\n\t\tpage.addToken(0x09, \"IMAddress3\")\n\t\tpage.addToken(0x0A, \"ManagerName\")\n\t\tpage.addToken(0x0B, \"CompanyMainPhone\")\n\t\tpage.addToken(0x0C, \"AccountName\")\n\t\tpage.addToken(0x0D, \"NickName\")\n\t\tpage.addToken(0x0E, \"MMS\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 13: Ping\n\t\t# region Ping Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Ping:\"\n\t\tpage.xmlns = \"ping\"\n\n\t\tpage.addToken(0x05, \"Ping\")\n\t\tpage.addToken(0x06, \"AutdState\")  # Per MS-ASWBXML, this tag is not used by protocol\n\t\tpage.addToken(0x07, \"Status\")\n\t\tpage.addToken(0x08, \"HeartbeatInterval\")\n\t\tpage.addToken(0x09, \"Folders\")\n\t\tpage.addToken(0x0A, \"Folder\")\n\t\tpage.addToken(0x0B, \"Id\")\n\t\tpage.addToken(0x0C, \"Class\")\n\t\tpage.addToken(0x0D, \"MaxFolders\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 14: Provision\n\t\t# region Provision Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Provision:\"\n\t\tpage.xmlns = \"provision\"\n\n\t\tpage.addToken(0x05, \"Provision\")\n\t\tpage.addToken(0x06, \"Policies\")\n\t\tpage.addToken(0x07, \"Policy\")\n\t\tpage.addToken(0x08, \"PolicyType\")\n\t\tpage.addToken(0x09, \"PolicyKey\")\n\t\tpage.addToken(0x0A, \"Data\")\n\t\tpage.addToken(0x0B, \"Status\")\n\t\tpage.addToken(0x0C, \"RemoteWipe\")\n\t\tpage.addToken(0x0D, \"EASProvisionDoc\")\n\t\tpage.addToken(0x0E, \"DevicePasswordEnabled\")\n\t\tpage.addToken(0x0F, \"AlphanumericDevicePasswordRequired\")\n\t\tpage.addToken(0x10, \"RequireStorageCardEncryption\")\n\t\tpage.addToken(0x11, \"PasswordRecoveryEnabled\")\n\t\tpage.addToken(0x13, \"AttachmentsEnabled\")\n\t\tpage.addToken(0x14, \"MinDevicePasswordLength\")\n\t\tpage.addToken(0x15, \"MaxInactivityTimeDeviceLock\")\n\t\tpage.addToken(0x16, \"MaxDevicePasswordFailedAttempts\")\n\t\tpage.addToken(0x17, \"MaxAttachmentSize\")\n\t\tpage.addToken(0x18, \"AllowSimpleDevicePassword\")\n\t\tpage.addToken(0x19, \"DevicePasswordExpiration\")\n\t\tpage.addToken(0x1A, \"DevicePasswordHistory\")\n\t\tpage.addToken(0x1B, \"AllowStorageCard\")\n\t\tpage.addToken(0x1C, \"AllowCamera\")\n\t\tpage.addToken(0x1D, \"RequireDeviceEncryption\")\n\t\tpage.addToken(0x1E, \"AllowUnsignedApplications\")\n\t\tpage.addToken(0x1F, \"AllowUnsignedInstallationPackages\")\n\t\tpage.addToken(0x20, \"MinDevicePasswordComplexCharacters\")\n\t\tpage.addToken(0x21, \"AllowWiFi\")\n\t\tpage.addToken(0x22, \"AllowTextMessaging\")\n\t\tpage.addToken(0x23, \"AllowPOPIMAPEmail\")\n\t\tpage.addToken(0x24, \"AllowBluetooth\")\n\t\tpage.addToken(0x25, \"AllowIrDA\")\n\t\tpage.addToken(0x26, \"RequireManualSyncWhenRoaming\")\n\t\tpage.addToken(0x27, \"AllowDesktopSync\")\n\t\tpage.addToken(0x28, \"MaxCalendarAgeFilter\")\n\t\tpage.addToken(0x29, \"AllowHTMLEmail\")\n\t\tpage.addToken(0x2A, \"MaxEmailAgeFilter\")\n\t\tpage.addToken(0x2B, \"MaxEmailBodyTruncationSize\")\n\t\tpage.addToken(0x2C, \"MaxEmailHTMLBodyTruncationSize\")\n\t\tpage.addToken(0x2D, \"RequireSignedSMIMEMessages\")\n\t\tpage.addToken(0x2E, \"RequireEncryptedSMIMEMessages\")\n\t\tpage.addToken(0x2F, \"RequireSignedSMIMEAlgorithm\")\n\t\tpage.addToken(0x30, \"RequireEncryptionSMIMEAlgorithm\")\n\t\tpage.addToken(0x31, \"AllowSMIMEEncryptionAlgorithmNegotiation\")\n\t\tpage.addToken(0x32, \"AllowSMIMESoftCerts\")\n\t\tpage.addToken(0x33, \"AllowBrowser\")\n\t\tpage.addToken(0x34, \"AllowConsumerEmail\")\n\t\tpage.addToken(0x35, \"AllowRemoteDesktop\")\n\t\tpage.addToken(0x36, \"AllowInternetSharing\")\n\t\tpage.addToken(0x37, \"UnapprovedInROMApplicationList\")\n\t\tpage.addToken(0x38, \"ApplicationName\")\n\t\tpage.addToken(0x39, \"ApprovedApplicationList\")\n\t\tpage.addToken(0x3A, \"Hash\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 15: Search\n\t\t# region Search Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Search:\"\n\t\tpage.xmlns = \"search\"\n\n\t\tpage.addToken(0x05, \"Search\")\n\t\tpage.addToken(0x07, \"Store\")\n\t\tpage.addToken(0x08, \"Name\")\n\t\tpage.addToken(0x09, \"Query\")\n\t\tpage.addToken(0x0A, \"Options\")\n\t\tpage.addToken(0x0B, \"Range\")\n\t\tpage.addToken(0x0C, \"Status\")\n\t\tpage.addToken(0x0D, \"Response\")\n\t\tpage.addToken(0x0E, \"Result\")\n\t\tpage.addToken(0x0F, \"Properties\")\n\t\tpage.addToken(0x10, \"Total\")\n\t\tpage.addToken(0x11, \"EqualTo\")\n\t\tpage.addToken(0x12, \"Value\")\n\t\tpage.addToken(0x13, \"And\")\n\t\tpage.addToken(0x14, \"Or\")\n\t\tpage.addToken(0x15, \"FreeText\")\n\t\tpage.addToken(0x17, \"DeepTraversal\")\n\t\tpage.addToken(0x18, \"LongId\")\n\t\tpage.addToken(0x19, \"RebuildResults\")\n\t\tpage.addToken(0x1A, \"LessThan\")\n\t\tpage.addToken(0x1B, \"GreaterThan\")\n\t\tpage.addToken(0x1E, \"UserName\")\n\t\tpage.addToken(0x1F, \"Password\")\n\t\tpage.addToken(0x20, \"ConversationId\")\n\t\tpage.addToken(0x21, \"Picture\")\n\t\tpage.addToken(0x22, \"MaxSize\")\n\t\tpage.addToken(0x23, \"MaxPictures\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 16: GAL\n\t\t# region GAL Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"GAL:\"\n\t\tpage.xmlns = \"gal\"\n\n\t\tpage.addToken(0x05, \"DisplayName\")\n\t\tpage.addToken(0x06, \"Phone\")\n\t\tpage.addToken(0x07, \"Office\")\n\t\tpage.addToken(0x08, \"Title\")\n\t\tpage.addToken(0x09, \"Company\")\n\t\tpage.addToken(0x0A, \"Alias\")\n\t\tpage.addToken(0x0B, \"FirstName\")\n\t\tpage.addToken(0x0C, \"LastName\")\n\t\tpage.addToken(0x0D, \"HomePhone\")\n\t\tpage.addToken(0x0E, \"MobilePhone\")\n\t\tpage.addToken(0x0F, \"EmailAddress\")\n\t\tpage.addToken(0x10, \"Picture\")\n\t\tpage.addToken(0x11, \"Status\")\n\t\tpage.addToken(0x12, \"Data\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 17: AirSyncBase\n\t\t# region AirSyncBase Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"AirSyncBase:\"\n\t\tpage.xmlns = \"airsyncbase\"\n\n\t\tpage.addToken(0x05, \"BodyPreference\")\n\t\tpage.addToken(0x06, \"Type\")\n\t\tpage.addToken(0x07, \"TruncationSize\")\n\t\tpage.addToken(0x08, \"AllOrNone\")\n\t\tpage.addToken(0x0A, \"Body\")\n\t\tpage.addToken(0x0B, \"Data\")\n\t\tpage.addToken(0x0C, \"EstimatedDataSize\")\n\t\tpage.addToken(0x0D, \"Truncated\")\n\t\tpage.addToken(0x0E, \"Attachments\")\n\t\tpage.addToken(0x0F, \"Attachment\")\n\t\tpage.addToken(0x10, \"DisplayName\")\n\t\tpage.addToken(0x11, \"FileReference\")\n\t\tpage.addToken(0x12, \"Method\")\n\t\tpage.addToken(0x13, \"ContentId\")\n\t\tpage.addToken(0x14, \"ContentLocation\")\n\t\tpage.addToken(0x15, \"IsInline\")\n\t\tpage.addToken(0x16, \"NativeBodyType\")\n\t\tpage.addToken(0x17, \"ContentType\")\n\t\tpage.addToken(0x18, \"Preview\")\n\t\tpage.addToken(0x19, \"BodyPartPreference\")\n\t\tpage.addToken(0x1A, \"BodyPart\")\n\t\tpage.addToken(0x1B, \"Status\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 18: Settings\n\t\t# region Settings Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Settings:\"\n\t\tpage.xmlns = \"settings\"\n\n\t\tpage.addToken(0x05, \"Settings\")\n\t\tpage.addToken(0x06, \"Status\")\n\t\tpage.addToken(0x07, \"Get\")\n\t\tpage.addToken(0x08, \"Set\")\n\t\tpage.addToken(0x09, \"Oof\")\n\t\tpage.addToken(0x0A, \"OofState\")\n\t\tpage.addToken(0x0B, \"StartTime\")\n\t\tpage.addToken(0x0C, \"EndTime\")\n\t\tpage.addToken(0x0D, \"OofMessage\")\n\t\tpage.addToken(0x0E, \"AppliesToInternal\")\n\t\tpage.addToken(0x0F, \"AppliesToExternalKnown\")\n\t\tpage.addToken(0x10, \"AppliesToExternalUnknown\")\n\t\tpage.addToken(0x11, \"Enabled\")\n\t\tpage.addToken(0x12, \"ReplyMessage\")\n\t\tpage.addToken(0x13, \"BodyType\")\n\t\tpage.addToken(0x14, \"DevicePassword\")\n\t\tpage.addToken(0x15, \"Password\")\n\t\tpage.addToken(0x16, \"DeviceInformation\")\n\t\tpage.addToken(0x17, \"Model\")\n\t\tpage.addToken(0x18, \"IMEI\")\n\t\tpage.addToken(0x19, \"FriendlyName\")\n\t\tpage.addToken(0x1A, \"OS\")\n\t\tpage.addToken(0x1B, \"OSLanguage\")\n\t\tpage.addToken(0x1C, \"PhoneNumber\")\n\t\tpage.addToken(0x1D, \"UserInformation\")\n\t\tpage.addToken(0x1E, \"EmailAddresses\")\n\t\tpage.addToken(0x1F, \"SmtpAddress\")\n\t\tpage.addToken(0x20, \"UserAgent\")\n\t\tpage.addToken(0x21, \"EnableOutboundSMS\")\n\t\tpage.addToken(0x22, \"MobileOperator\")\n\t\tpage.addToken(0x23, \"PrimarySmtpAddress\")\n\t\tpage.addToken(0x24, \"Accounts\")\n\t\tpage.addToken(0x25, \"Account\")\n\t\tpage.addToken(0x26, \"AccountId\")\n\t\tpage.addToken(0x27, \"AccountName\")\n\t\tpage.addToken(0x28, \"UserDisplayName\")\n\t\tpage.addToken(0x29, \"SendDisabled\")\n\t\tpage.addToken(0x2B, \"RightsManagementInformation\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 19: DocumentLibrary\n\t\t# region DocumentLibrary Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"DocumentLibrary:\"\n\t\tpage.xmlns = \"documentlibrary\"\n\n\t\tpage.addToken(0x05, \"LinkId\")\n\t\tpage.addToken(0x06, \"DisplayName\")\n\t\tpage.addToken(0x07, \"IsFolder\")\n\t\tpage.addToken(0x08, \"CreationDate\")\n\t\tpage.addToken(0x09, \"LastModifiedDate\")\n\t\tpage.addToken(0x0A, \"IsHidden\")\n\t\tpage.addToken(0x0B, \"ContentLength\")\n\t\tpage.addToken(0x0C, \"ContentType\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 20: ItemOperations\n\t\t# region ItemOperations Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"ItemOperations:\"\n\t\tpage.xmlns = \"itemoperations\"\n\n\t\tpage.addToken(0x05, \"ItemOperations\")\n\t\tpage.addToken(0x06, \"Fetch\")\n\t\tpage.addToken(0x07, \"Store\")\n\t\tpage.addToken(0x08, \"Options\")\n\t\tpage.addToken(0x09, \"Range\")\n\t\tpage.addToken(0x0A, \"Total\")\n\t\tpage.addToken(0x0B, \"Properties\")\n\t\tpage.addToken(0x0C, \"Data\")\n\t\tpage.addToken(0x0D, \"Status\")\n\t\tpage.addToken(0x0E, \"Response\")\n\t\tpage.addToken(0x0F, \"Version\")\n\t\tpage.addToken(0x10, \"Schema\")\n\t\tpage.addToken(0x11, \"Part\")\n\t\tpage.addToken(0x12, \"EmptyFolderContents\")\n\t\tpage.addToken(0x13, \"DeleteSubFolders\")\n\t\tpage.addToken(0x14, \"UserName\")\n\t\tpage.addToken(0x15, \"Password\")\n\t\tpage.addToken(0x16, \"Move\")\n\t\tpage.addToken(0x17, \"DstFldId\")\n\t\tpage.addToken(0x18, \"ConversationId\")\n\t\tpage.addToken(0x19, \"MoveAlways\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 21: ComposeMail\n\t\t# region ComposeMail Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"ComposeMail:\"\n\t\tpage.xmlns = \"composemail\"\n\n\t\tpage.addToken(0x05, \"SendMail\")\n\t\tpage.addToken(0x06, \"SmartForward\")\n\t\tpage.addToken(0x07, \"SmartReply\")\n\t\tpage.addToken(0x08, \"SaveInSentItems\")\n\t\tpage.addToken(0x09, \"ReplaceMime\")\n\t\tpage.addToken(0x0B, \"Source\")\n\t\tpage.addToken(0x0C, \"FolderId\")\n\t\tpage.addToken(0x0D, \"ItemId\")\n\t\tpage.addToken(0x0E, \"LongId\")\n\t\tpage.addToken(0x0F, \"InstanceId\")\n\t\tpage.addToken(0x10, \"MIME\")\n\t\tpage.addToken(0x11, \"ClientId\")\n\t\tpage.addToken(0x12, \"Status\")\n\t\tpage.addToken(0x13, \"AccountId\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 22: Email2\n\t\t# region Email2 Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Email2:\"\n\t\tpage.xmlns = \"email2\"\n\n\t\tpage.addToken(0x05, \"UmCallerID\")\n\t\tpage.addToken(0x06, \"UmUserNotes\")\n\t\tpage.addToken(0x07, \"UmAttDuration\")\n\t\tpage.addToken(0x08, \"UmAttOrder\")\n\t\tpage.addToken(0x09, \"ConversationId\")\n\t\tpage.addToken(0x0A, \"ConversationIndex\")\n\t\tpage.addToken(0x0B, \"LastVerbExecuted\")\n\t\tpage.addToken(0x0C, \"LastVerbExecutionTime\")\n\t\tpage.addToken(0x0D, \"ReceivedAsBcc\")\n\t\tpage.addToken(0x0E, \"Sender\")\n\t\tpage.addToken(0x0F, \"CalendarType\")\n\t\tpage.addToken(0x10, \"IsLeapMonth\")\n\t\tpage.addToken(0x11, \"AccountId\")\n\t\tpage.addToken(0x12, \"FirstDayOfWeek\")\n\t\tpage.addToken(0x13, \"MeetingMessageType\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 23: Notes\n\t\t# region Notes Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"Notes:\"\n\t\tpage.xmlns = \"notes\"\n\n\t\tpage.addToken(0x05, \"Subject\")\n\t\tpage.addToken(0x06, \"MessageClass\")\n\t\tpage.addToken(0x07, \"LastModifiedDate\")\n\t\tpage.addToken(0x08, \"Categories\")\n\t\tpage.addToken(0x09, \"Category\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\n\t\t# Code Page 24: RightsManagement\n\t\t# region RightsManagement Code Page\n\t\tpage = ASWBXMLCodePage()\n\t\tpage.namespace = \"RightsManagement:\"\n\t\tpage.xmlns = \"rightsmanagement\"\n\n\t\tpage.addToken(0x05, \"RightsManagementSupport\")\n\t\tpage.addToken(0x06, \"RightsManagementTemplates\")\n\t\tpage.addToken(0x07, \"RightsManagementTemplate\")\n\t\tpage.addToken(0x08, \"RightsManagementLicense\")\n\t\tpage.addToken(0x09, \"EditAllowed\")\n\t\tpage.addToken(0x0A, \"ReplyAllowed\")\n\t\tpage.addToken(0x0B, \"ReplyAllAllowed\")\n\t\tpage.addToken(0x0C, \"ForwardAllowed\")\n\t\tpage.addToken(0x0D, \"ModifyRecipientsAllowed\")\n\t\tpage.addToken(0x0E, \"ExtractAllowed\")\n\t\tpage.addToken(0x0F, \"PrintAllowed\")\n\t\tpage.addToken(0x10, \"ExportAllowed\")\n\t\tpage.addToken(0x11, \"ProgrammaticAccessAllowed\")\n\t\tpage.addToken(0x12, \"RMOwner\")\n\t\tpage.addToken(0x13, \"ContentExpiryDate\")\n\t\tpage.addToken(0x14, \"TemplateID\")\n\t\tpage.addToken(0x15, \"TemplateName\")\n\t\tpage.addToken(0x16, \"TemplateDescription\")\n\t\tpage.addToken(0x17, \"ContentOwner\")\n\t\tpage.addToken(0x18, \"RemoveRightsManagementDistribution\")\n\t\tself.codePages.append(page)\n\t\t# endregion\n\t\t# endregion\n\t\n\tdef loadXml(self, strXML):\n\t\t# note xmlDoc has .childNodes and .parentNode\n\t\tself.xmlDoc = xml.dom.minidom.parseString(strXML)\n\n\tdef getXml(self):\n\t\tif (self.xmlDoc != None):\n\t\t\ttry:\n\t\t\t\treturn self.xmlDoc.toprettyxml(indent=\"    \", newl=\"\\n\")\n\t\t\texcept:\n\t\t\t\treturn self.xmlDoc.toxml()\n\t\n\tdef loadBytes(self, byteWBXML):\n\t\t\n\t\tcurrentNode = self.xmlDoc\n\t\t\n\t\twbXMLBytes = ASWBXMLByteQueue(byteWBXML)\n\t\t# Version is ignored\n\t\tversion = wbXMLBytes.dequeueAndLog()\n\n\t\t# Public Identifier is ignored\n\t\tpublicId = wbXMLBytes.dequeueMultibyteInt()\n\t\t\n\t\tlogging.debug(\"Version: %d, Public Identifier: %d\" % (version, publicId))\n\t\t\n\t\t# Character set\n\t\t# Currently only UTF-8 is supported, throw if something else\n\t\tcharset = wbXMLBytes.dequeueMultibyteInt()\n\t\tif (charset != 0x6A):\n\t\t\traise InvalidDataException(\"ASWBXML only supports UTF-8 encoded XML.\")\n\n\t\t# String table length\n\t\t# This should be 0, MS-ASWBXML does not use string tables\n\t\tstringTableLength = wbXMLBytes.dequeueMultibyteInt()\n\t\tif (stringTableLength != 0):\n\t\t\traise InvalidDataException(\"WBXML data contains a string table.\")\n\n\t\t# Now we should be at the body of the data.\n\t\t# Add the declaration\n\t\tunusedArray = [GlobalTokens.ENTITY, GlobalTokens.EXT_0, GlobalTokens.EXT_1, GlobalTokens.EXT_2, GlobalTokens.EXT_I_0, GlobalTokens.EXT_I_1, GlobalTokens.EXT_I_2, GlobalTokens.EXT_T_0, GlobalTokens.EXT_T_1, GlobalTokens.EXT_T_2, GlobalTokens.LITERAL, GlobalTokens.LITERAL_A, GlobalTokens.LITERAL_AC, GlobalTokens.LITERAL_C, GlobalTokens.PI, GlobalTokens.STR_T]\n\t\t\n\t\twhile ( wbXMLBytes.qsize() > 0):\n\t\t\tcurrentByte = wbXMLBytes.dequeueAndLog()\n\t\t\tif ( currentByte == GlobalTokens.SWITCH_PAGE ):\n\t\t\t\tnewCodePage = wbXMLBytes.dequeueAndLog()\n\t\t\t\tif (newCodePage >= 0 and newCodePage < 25):\n\t\t\t\t\tself.currentCodePage = newCodePage\n\t\t\t\telse:\n\t\t\t\t\traise InvalidDataException(\"Unknown code page ID 0x{0:X} encountered in WBXML\".format(currentByte))\n\t\t\telif  ( currentByte == GlobalTokens.END ):\n\t\t\t\tif (currentNode != None and currentNode.parentNode != None):\n\t\t\t\t\tcurrentNode = currentNode.parentNode\n\t\t\t\telse:\n\t\t\t\t\traise InvalidDataException(\"END global token encountered out of sequence\")\n\t\t\t\t\tbreak\n\t\t\telif  ( currentByte == GlobalTokens.OPAQUE ):\n\t\t\t\tCDATALength = wbXMLBytes.dequeueMultibyteInt()\n\t\t\t\tnewOpaqueNode = self.xmlDoc.createCDATASection(wbXMLBytes.dequeueString(CDATALength))\n\t\t\t\tcurrentNode.appendChild(newOpaqueNode)\n\n\t\t\telif  ( currentByte == GlobalTokens.STR_I ):\n\t\t\t\tnewTextNode = self.xmlDoc.createTextNode(wbXMLBytes.dequeueString())\n\t\t\t\tcurrentNode.appendChild(newTextNode)\n\n\t\t\telif ( currentByte in unusedArray):\n\t\t\t\traise InvalidDataException(\"Encountered unknown global token 0x{0:X}.\".format(currentByte))\n\t\t\telse:\n\t\t\t\thasAttributes = (currentByte & 0x80) > 0\n\t\t\t\thasContent = (currentByte & 0x40) > 0\n\n\t\t\t\ttoken = currentByte & 0x3F\n\t\t\t\tif (hasAttributes):\n\t\t\t\t\traise InvalidDataException(\"Token 0x{0:X} has attributes.\".format(token))\n\n\t\t\t\tstrTag = self.codePages[self.currentCodePage].getTag(token)\n\t\t\t\tif (strTag == None):\n\t\t\t\t\tstrTag = \"UNKNOWN_TAG_{0,2:X}\".format(token)\n\n\t\t\t\tnewNode = self.xmlDoc.createElement(strTag)\n\t\t\t\t# not sure if this should be set on every node or not\n\t\t\t\t#newNode.setAttribute(\"xmlns\", self.codePages[self.currentCodePage].xmlns)\n\t\t\t\t\n\t\t\t\tcurrentNode.appendChild(newNode)\n\n\t\t\t\tif (hasContent):\n\t\t\t\t\tcurrentNode = newNode\n\n\t\tlogging.debug(\"Total bytes dequeued: %d\" % wbXMLBytes.bytesDequeued)\n", "mitmproxy/contrib/wbxml/GlobalTokens.py": "#!/usr/bin/env python3\n'''\n@author: David Shaw, shawd@vmware.com\n\nInspired by EAS Inspector for Fiddler\nhttps://easinspectorforfiddler.codeplex.com\n\n----- The MIT License (MIT) ----- \nFilename: GlobalTokens.py\nCopyright (c) 2014, David P. Shaw\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n'''\nclass GlobalTokens:\n    SWITCH_PAGE = 0x00\n    END = 0x01\n    ENTITY = 0x02\n    STR_I = 0x03\n    LITERAL = 0x04\n    EXT_I_0 = 0x40\n    EXT_I_1 = 0x41\n    EXT_I_2 = 0x42\n    PI = 0x43\n    LITERAL_C = 0x44\n    EXT_T_0 = 0x80\n    EXT_T_1 = 0x81\n    EXT_T_2 = 0x82\n    STR_T = 0x83\n    LITERAL_A = 0x84\n    EXT_0 = 0xC0\n    EXT_1 = 0xC1\n    EXT_2 = 0xC2\n    OPAQUE = 0xC3\n    LITERAL_AC = 0xC4\n", "mitmproxy/contrib/wbxml/__init__.py": "", "mitmproxy/contrib/wbxml/ASWBXMLByteQueue.py": "#!/usr/bin/env python3\n'''\n@author: David Shaw, shawd@vmware.com\n\nInspired by EAS Inspector for Fiddler\nhttps://easinspectorforfiddler.codeplex.com\n\n----- The MIT License (MIT) -----\nFilename: ASWBXMLByteQueue.py\nCopyright (c) 2014, David P. Shaw\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n'''\nfrom queue import Queue\nimport logging\n\nclass ASWBXMLByteQueue(Queue):\n\n    def __init__(self, wbxmlBytes):\n\n        self.bytesDequeued = 0\n        self.bytesEnqueued = 0\n\n        Queue.__init__(self)\n\n        for byte in wbxmlBytes:\n            self.put(byte)\n            self.bytesEnqueued += 1\n\n\n        logging.debug(\"Array byte count: %d, enqueued: %d\" % (self.qsize(), self.bytesEnqueued))\n\n    \"\"\"\n    Created to debug the dequeueing of bytes\n    \"\"\"\n    def dequeueAndLog(self):\n        singleByte = self.get()\n        self.bytesDequeued += 1\n        logging.debug(\"Dequeued byte 0x{0:X} ({1} total)\".format(singleByte, self.bytesDequeued))\n        return singleByte\n\n    \"\"\"\n    Return true if the continuation bit is set in the byte\n    \"\"\"\n    def checkContinuationBit(self, byteval):\n        continuationBitmask = 0x80\n        return (continuationBitmask & byteval) != 0\n\n    def dequeueMultibyteInt(self):\n        iReturn = 0\n        singleByte = 0xFF\n\n        while True:\n            iReturn <<= 7\n            if (self.qsize() == 0):\n                break\n            else:\n                singleByte = self.dequeueAndLog()\n            iReturn += int(singleByte & 0x7F)\n            if not self.checkContinuationBit(singleByte):\n                return iReturn\n\n    def dequeueString(self, length=None):\n        if ( length != None):\n            currentByte = 0x00\n            strReturn = \"\"\n            for i in range(0, length):\n                # TODO: Improve this handling. We are technically UTF-8, meaning\n                # that characters could be more than one byte long. This will fail if we have\n                # characters outside of the US-ASCII range\n                if ( self.qsize() == 0 ):\n                    break\n                currentByte = self.dequeueAndLog()\n                strReturn += chr(currentByte)\n\n        else:\n            currentByte = 0x00\n            strReturn = \"\"\n            while True:\n                currentByte = self.dequeueAndLog()\n                if (currentByte != 0x00):\n                    strReturn += chr(currentByte)\n                else:\n                    break\n\n        return strReturn\n", "mitmproxy/contrib/wbxml/InvalidDataException.py": "#!/usr/bin/env python3\n'''\n@author: David Shaw, shawd@vmware.com\n\nInspired by EAS Inspector for Fiddler\nhttps://easinspectorforfiddler.codeplex.com\n\n----- The MIT License (MIT) ----- \nFilename: InvalidDataException.py\nCopyright (c) 2014, David P. Shaw\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n'''\nclass InvalidDataException(Exception):\n    pass\n", "mitmproxy/contrib/click/__init__.py": "\"\"\"\nSPDX-License-Identifier: BSD-3-Clause\n\nA vendored copy of click.style() @ 4f7b255\n\"\"\"\nimport typing as t\n\n_ansi_colors = {\n    \"black\": 30,\n    \"red\": 31,\n    \"green\": 32,\n    \"yellow\": 33,\n    \"blue\": 34,\n    \"magenta\": 35,\n    \"cyan\": 36,\n    \"white\": 37,\n    \"reset\": 39,\n    \"bright_black\": 90,\n    \"bright_red\": 91,\n    \"bright_green\": 92,\n    \"bright_yellow\": 93,\n    \"bright_blue\": 94,\n    \"bright_magenta\": 95,\n    \"bright_cyan\": 96,\n    \"bright_white\": 97,\n}\n_ansi_reset_all = \"\\033[0m\"\n\n\ndef _interpret_color(\n    color: t.Union[int, t.Tuple[int, int, int], str], offset: int = 0\n) -> str:\n    if isinstance(color, int):\n        return f\"{38 + offset};5;{color:d}\"\n\n    if isinstance(color, (tuple, list)):\n        r, g, b = color\n        return f\"{38 + offset};2;{r:d};{g:d};{b:d}\"\n\n    return str(_ansi_colors[color] + offset)\n\n\ndef style(\n    text: t.Any,\n    fg: t.Optional[t.Union[int, t.Tuple[int, int, int], str]] = None,\n    bg: t.Optional[t.Union[int, t.Tuple[int, int, int], str]] = None,\n    bold: t.Optional[bool] = None,\n    dim: t.Optional[bool] = None,\n    underline: t.Optional[bool] = None,\n    overline: t.Optional[bool] = None,\n    italic: t.Optional[bool] = None,\n    blink: t.Optional[bool] = None,\n    reverse: t.Optional[bool] = None,\n    strikethrough: t.Optional[bool] = None,\n    reset: bool = True,\n) -> str:\n    \"\"\"Styles a text with ANSI styles and returns the new string.  By\n    default the styling is self contained which means that at the end\n    of the string a reset code is issued.  This can be prevented by\n    passing ``reset=False``.\n    Examples::\n        click.echo(click.style('Hello World!', fg='green'))\n        click.echo(click.style('ATTENTION!', blink=True))\n        click.echo(click.style('Some things', reverse=True, fg='cyan'))\n        click.echo(click.style('More colors', fg=(255, 12, 128), bg=117))\n    Supported color names:\n    * ``black`` (might be a gray)\n    * ``red``\n    * ``green``\n    * ``yellow`` (might be an orange)\n    * ``blue``\n    * ``magenta``\n    * ``cyan``\n    * ``white`` (might be light gray)\n    * ``bright_black``\n    * ``bright_red``\n    * ``bright_green``\n    * ``bright_yellow``\n    * ``bright_blue``\n    * ``bright_magenta``\n    * ``bright_cyan``\n    * ``bright_white``\n    * ``reset`` (reset the color code only)\n    If the terminal supports it, color may also be specified as:\n    -   An integer in the interval [0, 255]. The terminal must support\n        8-bit/256-color mode.\n    -   An RGB tuple of three integers in [0, 255]. The terminal must\n        support 24-bit/true-color mode.\n    See https://en.wikipedia.org/wiki/ANSI_color and\n    https://gist.github.com/XVilka/8346728 for more information.\n    :param text: the string to style with ansi codes.\n    :param fg: if provided this will become the foreground color.\n    :param bg: if provided this will become the background color.\n    :param bold: if provided this will enable or disable bold mode.\n    :param dim: if provided this will enable or disable dim mode.  This is\n                badly supported.\n    :param underline: if provided this will enable or disable underline.\n    :param overline: if provided this will enable or disable overline.\n    :param italic: if provided this will enable or disable italic.\n    :param blink: if provided this will enable or disable blinking.\n    :param reverse: if provided this will enable or disable inverse\n                    rendering (foreground becomes background and the\n                    other way round).\n    :param strikethrough: if provided this will enable or disable\n        striking through text.\n    :param reset: by default a reset-all code is added at the end of the\n                  string which means that styles do not carry over.  This\n                  can be disabled to compose styles.\n    .. versionchanged:: 8.0\n        A non-string ``message`` is converted to a string.\n    .. versionchanged:: 8.0\n       Added support for 256 and RGB color codes.\n    .. versionchanged:: 8.0\n        Added the ``strikethrough``, ``italic``, and ``overline``\n        parameters.\n    .. versionchanged:: 7.0\n        Added support for bright colors.\n    .. versionadded:: 2.0\n    \"\"\"\n    if not isinstance(text, str):\n        text = str(text)\n\n    bits = []\n\n    if fg:\n        try:\n            bits.append(f\"\\033[{_interpret_color(fg)}m\")\n        except KeyError:\n            raise TypeError(f\"Unknown color {fg!r}\") from None\n\n    if bg:\n        try:\n            bits.append(f\"\\033[{_interpret_color(bg, 10)}m\")\n        except KeyError:\n            raise TypeError(f\"Unknown color {bg!r}\") from None\n\n    if bold is not None:\n        bits.append(f\"\\033[{1 if bold else 22}m\")\n    if dim is not None:\n        bits.append(f\"\\033[{2 if dim else 22}m\")\n    if underline is not None:\n        bits.append(f\"\\033[{4 if underline else 24}m\")\n    if overline is not None:\n        bits.append(f\"\\033[{53 if overline else 55}m\")\n    if italic is not None:\n        bits.append(f\"\\033[{3 if italic else 23}m\")\n    if blink is not None:\n        bits.append(f\"\\033[{5 if blink else 25}m\")\n    if reverse is not None:\n        bits.append(f\"\\033[{7 if reverse else 27}m\")\n    if strikethrough is not None:\n        bits.append(f\"\\033[{9 if strikethrough else 29}m\")\n    bits.append(text)\n    if reset:\n        bits.append(_ansi_reset_all)\n    return \"\".join(bits)\n\n\n__all__ = [\"style\"]\n", "mitmproxy/tools/cmdline.py": "import argparse\n\n\ndef common_options(parser, opts):\n    parser.add_argument(\n        \"--version\",\n        action=\"store_true\",\n        help=\"show version number and exit\",\n        dest=\"version\",\n    )\n    parser.add_argument(\n        \"--options\",\n        action=\"store_true\",\n        help=\"Show all options and their default values\",\n    )\n    parser.add_argument(\n        \"--commands\",\n        action=\"store_true\",\n        help=\"Show all commands and their signatures\",\n    )\n    parser.add_argument(\n        \"--set\",\n        type=str,\n        dest=\"setoptions\",\n        default=[],\n        action=\"append\",\n        metavar=\"option[=value]\",\n        help=\"\"\"\n            Set an option. When the value is omitted, booleans are set to true,\n            strings and integers are set to None (if permitted), and sequences\n            are emptied. Boolean values can be true, false or toggle.\n            Sequences are set using multiple invocations to set for\n            the same option.\n        \"\"\",\n    )\n    parser.add_argument(\n        \"-q\", \"--quiet\", action=\"store_true\", dest=\"quiet\", help=\"Quiet.\"\n    )\n    parser.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_const\",\n        dest=\"verbose\",\n        const=\"debug\",\n        help=\"Increase log verbosity.\",\n    )\n\n    # Basic options\n    opts.make_parser(parser, \"mode\", short=\"m\")\n    opts.make_parser(parser, \"anticache\")\n    opts.make_parser(parser, \"showhost\")\n    opts.make_parser(parser, \"rfile\", metavar=\"PATH\", short=\"r\")\n    opts.make_parser(parser, \"scripts\", metavar=\"SCRIPT\", short=\"s\")\n    opts.make_parser(parser, \"stickycookie\", metavar=\"FILTER\")\n    opts.make_parser(parser, \"stickyauth\", metavar=\"FILTER\")\n    opts.make_parser(parser, \"save_stream_file\", metavar=\"PATH\", short=\"w\")\n    opts.make_parser(parser, \"anticomp\")\n\n    # Proxy options\n    group = parser.add_argument_group(\"Proxy Options\")\n    opts.make_parser(group, \"listen_host\", metavar=\"HOST\")\n    opts.make_parser(group, \"listen_port\", metavar=\"PORT\", short=\"p\")\n    opts.make_parser(group, \"server\", short=\"n\")\n    opts.make_parser(group, \"ignore_hosts\", metavar=\"HOST\")\n    opts.make_parser(group, \"allow_hosts\", metavar=\"HOST\")\n    opts.make_parser(group, \"tcp_hosts\", metavar=\"HOST\")\n    opts.make_parser(group, \"upstream_auth\", metavar=\"USER:PASS\")\n    opts.make_parser(group, \"proxyauth\", metavar=\"SPEC\")\n    opts.make_parser(group, \"rawtcp\")\n    opts.make_parser(group, \"http2\")\n\n    # Proxy SSL options\n    group = parser.add_argument_group(\"SSL\")\n    opts.make_parser(group, \"certs\", metavar=\"SPEC\")\n    opts.make_parser(group, \"cert_passphrase\", metavar=\"PASS\")\n    opts.make_parser(group, \"ssl_insecure\", short=\"k\")\n\n    # Client replay\n    group = parser.add_argument_group(\"Client Replay\")\n    opts.make_parser(group, \"client_replay\", metavar=\"PATH\", short=\"C\")\n\n    # Server replay\n    group = parser.add_argument_group(\"Server Replay\")\n    opts.make_parser(group, \"server_replay\", metavar=\"PATH\", short=\"S\")\n    opts.make_parser(group, \"server_replay_kill_extra\")\n    opts.make_parser(group, \"server_replay_extra\")\n    opts.make_parser(group, \"server_replay_reuse\")\n    opts.make_parser(group, \"server_replay_refresh\")\n\n    # Map Remote\n    group = parser.add_argument_group(\"Map Remote\")\n    opts.make_parser(group, \"map_remote\", metavar=\"PATTERN\", short=\"M\")\n\n    # Map Local\n    group = parser.add_argument_group(\"Map Local\")\n    opts.make_parser(group, \"map_local\", metavar=\"PATTERN\")\n\n    # Modify Body\n    group = parser.add_argument_group(\"Modify Body\")\n    opts.make_parser(group, \"modify_body\", metavar=\"PATTERN\", short=\"B\")\n\n    # Modify headers\n    group = parser.add_argument_group(\"Modify Headers\")\n    opts.make_parser(group, \"modify_headers\", metavar=\"PATTERN\", short=\"H\")\n\n\ndef mitmproxy(opts):\n    parser = argparse.ArgumentParser(usage=\"%(prog)s [options]\")\n    common_options(parser, opts)\n\n    opts.make_parser(parser, \"console_layout\")\n    opts.make_parser(parser, \"console_layout_headers\")\n    group = parser.add_argument_group(\n        \"Filters\", \"See help in mitmproxy for filter expression syntax.\"\n    )\n    opts.make_parser(group, \"intercept\", metavar=\"FILTER\")\n    opts.make_parser(group, \"view_filter\", metavar=\"FILTER\")\n    return parser\n\n\ndef mitmdump(opts):\n    parser = argparse.ArgumentParser(usage=\"%(prog)s [options] [filter]\")\n\n    common_options(parser, opts)\n    opts.make_parser(parser, \"flow_detail\", metavar=\"LEVEL\")\n    parser.add_argument(\n        \"filter_args\",\n        nargs=\"...\",\n        help=\"\"\"\n            Filter expression, equivalent to setting both the view_filter\n            and save_stream_filter options.\n        \"\"\",\n    )\n    return parser\n\n\ndef mitmweb(opts):\n    parser = argparse.ArgumentParser(usage=\"%(prog)s [options]\")\n\n    group = parser.add_argument_group(\"Mitmweb\")\n    opts.make_parser(group, \"web_open_browser\")\n    opts.make_parser(group, \"web_port\", metavar=\"PORT\")\n    opts.make_parser(group, \"web_host\", metavar=\"HOST\")\n\n    common_options(parser, opts)\n    group = parser.add_argument_group(\n        \"Filters\", \"See help in mitmproxy for filter expression syntax.\"\n    )\n    opts.make_parser(group, \"intercept\", metavar=\"FILTER\")\n    return parser\n", "mitmproxy/tools/dump.py": "from mitmproxy import addons\nfrom mitmproxy import master\nfrom mitmproxy import options\nfrom mitmproxy.addons import dumper\nfrom mitmproxy.addons import errorcheck\nfrom mitmproxy.addons import keepserving\nfrom mitmproxy.addons import readfile\n\n\nclass DumpMaster(master.Master):\n    def __init__(\n        self,\n        options: options.Options,\n        loop=None,\n        with_termlog=True,\n        with_dumper=True,\n    ) -> None:\n        super().__init__(options, event_loop=loop, with_termlog=with_termlog)\n        self.addons.add(*addons.default_addons())\n        if with_dumper:\n            self.addons.add(dumper.Dumper())\n        self.addons.add(\n            keepserving.KeepServing(),\n            readfile.ReadFileStdin(),\n            errorcheck.ErrorCheck(),\n        )\n", "mitmproxy/tools/main.py": "from __future__ import annotations\n\nimport argparse\nimport asyncio\nimport logging\nimport os\nimport signal\nimport sys\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom typing import Any\nfrom typing import TypeVar\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import master\nfrom mitmproxy import options\nfrom mitmproxy import optmanager\nfrom mitmproxy.tools import cmdline\nfrom mitmproxy.utils import arg_check\nfrom mitmproxy.utils import debug\n\n\ndef process_options(parser, opts, args):\n    if args.version:\n        print(debug.dump_system_info())\n        sys.exit(0)\n    if args.quiet or args.options or args.commands:\n        # also reduce log verbosity if --options or --commands is passed,\n        # we don't want log messages from regular startup then.\n        args.termlog_verbosity = \"error\"\n        args.flow_detail = 0\n    if args.verbose:\n        args.termlog_verbosity = \"debug\"\n        args.flow_detail = 2\n\n    adict = {\n        key: val for key, val in vars(args).items() if key in opts and val is not None\n    }\n    opts.update(**adict)\n\n\nT = TypeVar(\"T\", bound=master.Master)\n\n\ndef run(\n    master_cls: type[T],\n    make_parser: Callable[[options.Options], argparse.ArgumentParser],\n    arguments: Sequence[str],\n    extra: Callable[[Any], dict] | None = None,\n) -> T:  # pragma: no cover\n    \"\"\"\n    extra: Extra argument processing callable which returns a dict of\n    options.\n    \"\"\"\n\n    async def main() -> T:\n        logging.getLogger().setLevel(logging.DEBUG)\n        logging.getLogger(\"tornado\").setLevel(logging.WARNING)\n        logging.getLogger(\"asyncio\").setLevel(logging.WARNING)\n        logging.getLogger(\"hpack\").setLevel(logging.WARNING)\n        logging.getLogger(\"quic\").setLevel(\n            logging.WARNING\n        )  # aioquic uses a different prefix...\n        debug.register_info_dumpers()\n\n        opts = options.Options()\n        master = master_cls(opts)\n\n        parser = make_parser(opts)\n\n        # To make migration from 2.x to 3.0 bearable.\n        if \"-R\" in sys.argv and sys.argv[sys.argv.index(\"-R\") + 1].startswith(\"http\"):\n            print(\n                \"To use mitmproxy in reverse mode please use --mode reverse:SPEC instead\"\n            )\n\n        try:\n            args = parser.parse_args(arguments)\n        except SystemExit:\n            arg_check.check()\n            sys.exit(1)\n\n        try:\n            opts.set(*args.setoptions, defer=True)\n            optmanager.load_paths(\n                opts,\n                os.path.join(opts.confdir, \"config.yaml\"),\n                os.path.join(opts.confdir, \"config.yml\"),\n            )\n            process_options(parser, opts, args)\n\n            if args.options:\n                optmanager.dump_defaults(opts, sys.stdout)\n                sys.exit(0)\n            if args.commands:\n                master.commands.dump()\n                sys.exit(0)\n            if extra:\n                if args.filter_args:\n                    logging.info(\n                        f\"Only processing flows that match \\\"{' & '.join(args.filter_args)}\\\"\"\n                    )\n                opts.update(**extra(args))\n\n        except exceptions.OptionsError as e:\n            print(f\"{sys.argv[0]}: {e}\", file=sys.stderr)\n            sys.exit(1)\n\n        loop = asyncio.get_running_loop()\n\n        def _sigint(*_):\n            loop.call_soon_threadsafe(\n                getattr(master, \"prompt_for_exit\", master.shutdown)\n            )\n\n        def _sigterm(*_):\n            loop.call_soon_threadsafe(master.shutdown)\n\n        # We can't use loop.add_signal_handler because that's not available on Windows' Proactorloop,\n        # but signal.signal just works fine for our purposes.\n        signal.signal(signal.SIGINT, _sigint)\n        signal.signal(signal.SIGTERM, _sigterm)\n        # to fix the issue mentioned https://github.com/mitmproxy/mitmproxy/issues/6744\n        # by setting SIGPIPE to SIG_IGN, the process will not terminate and continue to run\n        if hasattr(signal, \"SIGPIPE\"):\n            signal.signal(signal.SIGPIPE, signal.SIG_IGN)\n\n        await master.run()\n        return master\n\n    return asyncio.run(main())\n\n\ndef mitmproxy(args=None) -> int | None:  # pragma: no cover\n    from mitmproxy.tools import console\n\n    run(console.master.ConsoleMaster, cmdline.mitmproxy, args)\n    return None\n\n\ndef mitmdump(args=None) -> int | None:  # pragma: no cover\n    from mitmproxy.tools import dump\n\n    def extra(args):\n        if args.filter_args:\n            v = \" \".join(args.filter_args)\n            return dict(\n                save_stream_filter=v,\n                readfile_filter=v,\n                dumper_filter=v,\n            )\n        return {}\n\n    run(dump.DumpMaster, cmdline.mitmdump, args, extra)\n    return None\n\n\ndef mitmweb(args=None) -> int | None:  # pragma: no cover\n    from mitmproxy.tools import web\n\n    run(web.master.WebMaster, cmdline.mitmweb, args)\n    return None\n", "mitmproxy/tools/__init__.py": "", "mitmproxy/tools/console/tabs.py": "import urwid\n\n\nclass Tab(urwid.WidgetWrap):\n    def __init__(self, offset, content, attr, onclick):\n        \"\"\"\n        onclick is called on click with the tab offset as argument\n        \"\"\"\n        p = urwid.Text(content, align=\"center\")\n        p = urwid.Padding(p, align=\"center\", width=(\"relative\", 100))\n        p = urwid.AttrWrap(p, attr)\n        urwid.WidgetWrap.__init__(self, p)\n        self.offset = offset\n        self.onclick = onclick\n\n    def mouse_event(self, size, event, button, col, row, focus):\n        if event == \"mouse press\" and button == 1:\n            self.onclick(self.offset)\n            return True\n\n\nclass Tabs(urwid.WidgetWrap):\n    def __init__(self, tabs, tab_offset=0):\n        super().__init__(\"\")\n        self.tab_offset = tab_offset\n        self.tabs = tabs\n        self.show()\n        self._w = urwid.Pile([])\n\n    def change_tab(self, offset):\n        self.tab_offset = offset\n        self.show()\n\n    def keypress(self, size, key):\n        n = len(self.tabs)\n        if key == \"m_next\":\n            self.change_tab((self.tab_offset + 1) % n)\n        elif key == \"right\":\n            self.change_tab((self.tab_offset + 1) % n)\n        elif key == \"left\":\n            self.change_tab((self.tab_offset - 1) % n)\n        return self._w.keypress(size, key)\n\n    def show(self):\n        if not self.tabs:\n            return\n\n        headers = []\n        for i in range(len(self.tabs)):\n            txt = self.tabs[i][0]()\n            if i == self.tab_offset % len(self.tabs):\n                headers.append(Tab(i, txt, \"heading\", self.change_tab))\n            else:\n                headers.append(Tab(i, txt, \"heading_inactive\", self.change_tab))\n        headers = urwid.Columns(headers, dividechars=1)\n        self._w = urwid.Frame(\n            body=self.tabs[self.tab_offset % len(self.tabs)][1](), header=headers\n        )\n        self._w.set_focus(\"body\")\n", "mitmproxy/tools/console/common.py": "import enum\nimport math\nimport platform\nfrom collections.abc import Iterable\nfrom functools import lru_cache\n\nimport urwid.util\nfrom publicsuffix2 import get_sld\nfrom publicsuffix2 import get_tld\n\nfrom mitmproxy import dns\nfrom mitmproxy import flow\nfrom mitmproxy.dns import DNSFlow\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.tcp import TCPFlow\nfrom mitmproxy.udp import UDPFlow\nfrom mitmproxy.utils import emoji\nfrom mitmproxy.utils import human\n\n# Detect Windows Subsystem for Linux and Windows\nIS_WINDOWS_OR_WSL = (\n    \"Microsoft\" in platform.platform() or \"Windows\" in platform.platform()\n)\n\n\ndef is_keypress(k):\n    \"\"\"\n    Is this input event a keypress?\n    \"\"\"\n    if isinstance(k, str):\n        return True\n\n\ndef highlight_key(text, key, textattr=\"text\", keyattr=\"key\"):\n    lst = []\n    parts = text.split(key, 1)\n    if parts[0]:\n        lst.append((textattr, parts[0]))\n    lst.append((keyattr, key))\n    if parts[1]:\n        lst.append((textattr, parts[1]))\n    return lst\n\n\nKEY_MAX = 30\n\n\ndef format_keyvals(\n    entries: Iterable[tuple[str, None | str | urwid.Widget]],\n    key_format: str = \"key\",\n    value_format: str = \"text\",\n    indent: int = 0,\n) -> list[urwid.Columns]:\n    \"\"\"\n    Format a list of (key, value) tuples.\n\n    Args:\n        entries: The list to format. keys must be strings, values can also be None or urwid widgets.\n            The latter makes it possible to use the result of format_keyvals() as a value.\n        key_format: The display attribute for the key.\n        value_format: The display attribute for the value.\n        indent: Additional indent to apply.\n    \"\"\"\n    max_key_len = max((len(k) for k, v in entries if k is not None), default=0)\n    max_key_len = min(max_key_len, KEY_MAX)\n\n    if indent > 2:\n        indent -= 2  # We use dividechars=2 below, which already adds two empty spaces\n\n    ret = []\n    for k, v in entries:\n        if v is None:\n            v = urwid.Text(\"\")\n        elif not isinstance(v, urwid.Widget):\n            v = urwid.Text([(value_format, v)])\n        ret.append(\n            urwid.Columns(\n                [\n                    (\"fixed\", indent, urwid.Text(\"\")),\n                    (\"fixed\", max_key_len, urwid.Text([(key_format, k)])),\n                    v,\n                ],\n                dividechars=2,\n            )\n        )\n    return ret\n\n\ndef fcol(s: str, attr: str) -> tuple[str, int, urwid.Text]:\n    s = str(s)\n    return (\"fixed\", len(s), urwid.Text([(attr, s)]))\n\n\nif urwid.util.detected_encoding:\n    SYMBOL_REPLAY = \"\\u21ba\"\n    SYMBOL_RETURN = \"\\u2190\"\n    SYMBOL_MARK = \"\\u25cf\"\n    SYMBOL_UP = \"\\u21e7\"\n    SYMBOL_DOWN = \"\\u21e9\"\n    SYMBOL_ELLIPSIS = \"\\u2026\"\n    SYMBOL_FROM_CLIENT = \"\\u21d2\"\n    SYMBOL_TO_CLIENT = \"\\u21d0\"\nelse:\n    SYMBOL_REPLAY = \"[r]\"\n    SYMBOL_RETURN = \"<-\"\n    SYMBOL_MARK = \"#\"\n    SYMBOL_UP = \"^\"\n    SYMBOL_DOWN = \" \"\n    SYMBOL_ELLIPSIS = \"~\"\n    SYMBOL_FROM_CLIENT = \"->\"\n    SYMBOL_TO_CLIENT = \"<-\"\n\nSCHEME_STYLES = {\n    \"http\": \"scheme_http\",\n    \"https\": \"scheme_https\",\n    \"ws\": \"scheme_ws\",\n    \"wss\": \"scheme_wss\",\n    \"tcp\": \"scheme_tcp\",\n    \"udp\": \"scheme_udp\",\n    \"dns\": \"scheme_dns\",\n    \"quic\": \"scheme_quic\",\n}\nHTTP_REQUEST_METHOD_STYLES = {\n    \"GET\": \"method_get\",\n    \"POST\": \"method_post\",\n    \"DELETE\": \"method_delete\",\n    \"HEAD\": \"method_head\",\n    \"PUT\": \"method_put\",\n}\nHTTP_RESPONSE_CODE_STYLE = {\n    2: \"code_200\",\n    3: \"code_300\",\n    4: \"code_400\",\n    5: \"code_500\",\n}\n\n\nclass RenderMode(enum.Enum):\n    TABLE = 1\n    \"\"\"The flow list in table format, i.e. one row per flow.\"\"\"\n    LIST = 2\n    \"\"\"The flow list in list format, i.e. potentially multiple rows per flow.\"\"\"\n    DETAILVIEW = 3\n    \"\"\"The top lines in the detail view.\"\"\"\n\n\ndef fixlen(s: str, maxlen: int) -> str:\n    if len(s) <= maxlen:\n        return s.ljust(maxlen)\n    else:\n        return s[0 : maxlen - len(SYMBOL_ELLIPSIS)] + SYMBOL_ELLIPSIS\n\n\ndef fixlen_r(s: str, maxlen: int) -> str:\n    if len(s) <= maxlen:\n        return s.rjust(maxlen)\n    else:\n        return SYMBOL_ELLIPSIS + s[len(s) - maxlen + len(SYMBOL_ELLIPSIS) :]\n\n\ndef render_marker(marker: str) -> str:\n    rendered = emoji.emoji.get(marker, SYMBOL_MARK)\n\n    # The marker can only be one glyph. Some emoji that use zero-width joiners (ZWJ)\n    # will not be rendered as a single glyph and instead will show\n    # multiple glyphs. Just use the first glyph as a fallback.\n    # https://emojipedia.org/emoji-zwj-sequence/\n    return rendered[0]\n\n\nclass TruncatedText(urwid.Widget):\n    def __init__(self, text, attr, align=\"left\"):\n        self.text = text\n        self.attr = attr\n        self.align = align\n        super().__init__()\n\n    def pack(self, size, focus=False):\n        return (len(self.text), 1)\n\n    def rows(self, size, focus=False):\n        return 1\n\n    def render(self, size, focus=False):\n        text = self.text\n        attr = self.attr\n        if self.align == \"right\":\n            text = text[::-1]\n            attr = attr[::-1]\n\n        text_len = urwid.util.calc_width(text, 0, len(text))\n        if size is not None and len(size) > 0:\n            width = size[0]\n        else:\n            width = text_len\n\n        if width >= text_len:\n            remaining = width - text_len\n            if remaining > 0:\n                c_text = text + \" \" * remaining\n                c_attr = attr + [(\"text\", remaining)]\n            else:\n                c_text = text\n                c_attr = attr\n        else:\n            trim = urwid.util.calc_trim_text(text, 0, width - 1, 0, width - 1)\n            visible_text = text[0 : trim[1]]\n            if trim[3] == 1:\n                visible_text += \" \"\n            c_text = visible_text + SYMBOL_ELLIPSIS\n            c_attr = urwid.util.rle_subseg(attr, 0, len(visible_text.encode())) + [\n                (\"focus\", len(SYMBOL_ELLIPSIS.encode()))\n            ]\n\n        if self.align == \"right\":\n            c_text = c_text[::-1]\n            c_attr = c_attr[::-1]\n\n        return urwid.TextCanvas([c_text.encode()], [c_attr], maxcol=width)\n\n\ndef truncated_plain(text, attr, align=\"left\"):\n    return TruncatedText(text, [(attr, len(text.encode()))], align)\n\n\n# Work around https://github.com/urwid/urwid/pull/330\ndef rle_append_beginning_modify(rle, a_r):\n    \"\"\"\n    Append (a, r) (unpacked from *a_r*) to BEGINNING of rle.\n    Merge with first run when possible\n\n    MODIFIES rle parameter contents. Returns None.\n    \"\"\"\n    a, r = a_r\n    if not rle:\n        rle[:] = [(a, r)]\n    else:\n        al, run = rle[0]\n        if a == al:\n            rle[0] = (a, run + r)\n        else:\n            rle[0:0] = [(a, r)]\n\n\ndef colorize_host(host: str):\n    tld = get_tld(host)\n    sld = get_sld(host)\n\n    attr: list = []\n\n    tld_size = len(tld)\n    sld_size = len(sld) - tld_size\n\n    for letter in reversed(range(len(host))):\n        character = host[letter]\n        if tld_size > 0:\n            style = \"url_domain\"\n            tld_size -= 1\n        elif tld_size == 0:\n            style = \"text\"\n            tld_size -= 1\n        elif sld_size > 0:\n            sld_size -= 1\n            style = \"url_extension\"\n        else:\n            style = \"text\"\n        rle_append_beginning_modify(attr, (style, len(character.encode())))\n    return attr\n\n\ndef colorize_req(s: str):\n    path = s.split(\"?\", 2)[0]\n    i_query = len(path)\n    i_last_slash = path.rfind(\"/\")\n    i_ext = path[i_last_slash + 1 :].rfind(\".\")\n    i_ext = i_last_slash + i_ext if i_ext >= 0 else len(s)\n    in_val = False\n    attr: list = []\n    for i in range(len(s)):\n        c = s[i]\n        if (\n            (i < i_query and c == \"/\")\n            or (i < i_query and i > i_last_slash and c == \".\")\n            or (i == i_query)\n        ):\n            a = \"url_punctuation\"\n        elif i > i_query:\n            if in_val:\n                if c == \"&\":\n                    in_val = False\n                    a = \"url_punctuation\"\n                else:\n                    a = \"url_query_value\"\n            else:\n                if c == \"=\":\n                    in_val = True\n                    a = \"url_punctuation\"\n                else:\n                    a = \"url_query_key\"\n        elif i > i_ext:\n            a = \"url_extension\"\n        elif i > i_last_slash:\n            a = \"url_filename\"\n        else:\n            a = \"text\"\n        urwid.util.rle_append_modify(attr, (a, len(c.encode())))\n    return attr\n\n\ndef colorize_url(url):\n    parts = url.split(\"/\", 3)\n    if len(parts) < 4 or len(parts[1]) > 0 or parts[0][-1:] != \":\":\n        return [(\"error\", len(url))]  # bad URL\n    return (\n        [\n            (SCHEME_STYLES.get(parts[0], \"scheme_other\"), len(parts[0]) - 1),\n            (\"url_punctuation\", 3),  # ://\n        ]\n        + colorize_host(parts[2])\n        + colorize_req(\"/\" + parts[3])\n    )\n\n\ndef format_http_content_type(content_type: str) -> tuple[str, str]:\n    content_type = content_type.split(\";\")[0]\n    if content_type.endswith(\"/javascript\"):\n        style = \"content_script\"\n    elif content_type.startswith(\"text/\"):\n        style = \"content_text\"\n    elif (\n        content_type.startswith(\"image/\")\n        or content_type.startswith(\"video/\")\n        or content_type.startswith(\"font/\")\n        or \"/x-font-\" in content_type\n    ):\n        style = \"content_media\"\n    elif content_type.endswith(\"/json\") or content_type.endswith(\"/xml\"):\n        style = \"content_data\"\n    elif content_type.startswith(\"application/\"):\n        style = \"content_raw\"\n    else:\n        style = \"content_other\"\n    return content_type, style\n\n\ndef format_duration(duration: float) -> tuple[str, str]:\n    pretty_duration = human.pretty_duration(duration)\n    style = \"gradient_%02d\" % int(\n        99 - 100 * min(math.log2(1 + 1000 * duration) / 12, 0.99)\n    )\n    return pretty_duration, style\n\n\ndef format_size(num_bytes: int) -> tuple[str, str]:\n    pretty_size = human.pretty_size(num_bytes)\n    style = \"gradient_%02d\" % int(99 - 100 * min(math.log2(1 + num_bytes) / 20, 0.99))\n    return pretty_size, style\n\n\ndef format_left_indicators(*, focused: bool, intercepted: bool, timestamp: float):\n    indicators: list[str | tuple[str, str]] = []\n    if focused:\n        indicators.append((\"focus\", \">>\"))\n    else:\n        indicators.append(\"  \")\n    pretty_timestamp = human.format_timestamp(timestamp)[-8:]\n    if intercepted:\n        indicators.append((\"intercept\", pretty_timestamp))\n    else:\n        indicators.append((\"text\", pretty_timestamp))\n    return \"fixed\", 10, urwid.Text(indicators)\n\n\ndef format_right_indicators(\n    *,\n    replay: bool,\n    marked: str,\n):\n    indicators: list[str | tuple[str, str]] = []\n    if replay:\n        indicators.append((\"replay\", SYMBOL_REPLAY))\n    else:\n        indicators.append(\" \")\n    if bool(marked):\n        indicators.append((\"mark\", render_marker(marked)))\n    else:\n        indicators.append(\"  \")\n    return \"fixed\", 3, urwid.Text(indicators)\n\n\n@lru_cache(maxsize=800)\ndef format_http_flow_list(\n    *,\n    render_mode: RenderMode,\n    focused: bool,\n    marked: str,\n    is_replay: bool,\n    request_method: str,\n    request_scheme: str,\n    request_host: str,\n    request_path: str,\n    request_url: str,\n    request_http_version: str,\n    request_timestamp: float,\n    request_is_push_promise: bool,\n    intercepted: bool,\n    response_code: int | None,\n    response_reason: str | None,\n    response_content_length: int | None,\n    response_content_type: str | None,\n    duration: float | None,\n    error_message: str | None,\n) -> urwid.Widget:\n    req = []\n\n    if render_mode is RenderMode.DETAILVIEW:\n        req.append(fcol(human.format_timestamp(request_timestamp), \"highlight\"))\n    else:\n        if focused:\n            req.append(fcol(\">>\", \"focus\"))\n        else:\n            req.append(fcol(\"  \", \"focus\"))\n\n    method_style = HTTP_REQUEST_METHOD_STYLES.get(request_method, \"method_other\")\n    req.append(fcol(request_method, method_style))\n\n    if request_is_push_promise:\n        req.append(fcol(\"PUSH_PROMISE\", \"method_http2_push\"))\n\n    preamble_len = sum(x[1] for x in req) + len(req) - 1\n\n    if request_http_version not in (\"HTTP/1.0\", \"HTTP/1.1\"):\n        request_url += \" \" + request_http_version\n    if intercepted and not response_code:\n        url_style = \"intercept\"\n    elif response_code or error_message:\n        url_style = \"text\"\n    else:\n        url_style = \"title\"\n\n    if render_mode is RenderMode.DETAILVIEW:\n        req.append(urwid.Text([(url_style, request_url)]))\n    else:\n        req.append(truncated_plain(request_url, url_style))\n\n    req.append(format_right_indicators(replay=is_replay, marked=marked))\n\n    resp = [(\"fixed\", preamble_len, urwid.Text(\"\"))]\n    if response_code:\n        if intercepted:\n            style = \"intercept\"\n        else:\n            style = \"\"\n\n        status_style = style or HTTP_RESPONSE_CODE_STYLE.get(\n            response_code // 100, \"code_other\"\n        )\n        resp.append(fcol(SYMBOL_RETURN, status_style))\n        resp.append(fcol(str(response_code), status_style))\n        if response_reason and render_mode is RenderMode.DETAILVIEW:\n            resp.append(fcol(response_reason, status_style))\n\n        if response_content_type:\n            ct, ct_style = format_http_content_type(response_content_type)\n            resp.append(fcol(ct, style or ct_style))\n\n        if response_content_length:\n            size, size_style = format_size(response_content_length)\n        elif response_content_length == 0:\n            size = \"[no content]\"\n            size_style = \"text\"\n        else:\n            size = \"[content missing]\"\n            size_style = \"text\"\n        resp.append(fcol(size, style or size_style))\n\n        if duration:\n            dur, dur_style = format_duration(duration)\n            resp.append(fcol(dur, style or dur_style))\n    elif error_message:\n        resp.append(fcol(SYMBOL_RETURN, \"error\"))\n        resp.append(urwid.Text([(\"error\", error_message)]))\n\n    return urwid.Pile(\n        [urwid.Columns(req, dividechars=1), urwid.Columns(resp, dividechars=1)]\n    )\n\n\n@lru_cache(maxsize=800)\ndef format_http_flow_table(\n    *,\n    render_mode: RenderMode,\n    focused: bool,\n    marked: str,\n    is_replay: str | None,\n    request_method: str,\n    request_scheme: str,\n    request_host: str,\n    request_path: str,\n    request_url: str,\n    request_http_version: str,\n    request_timestamp: float,\n    request_is_push_promise: bool,\n    intercepted: bool,\n    response_code: int | None,\n    response_reason: str | None,\n    response_content_length: int | None,\n    response_content_type: str | None,\n    duration: float | None,\n    error_message: str | None,\n) -> urwid.Widget:\n    items = [\n        format_left_indicators(\n            focused=focused, intercepted=intercepted, timestamp=request_timestamp\n        )\n    ]\n\n    if intercepted and not response_code:\n        request_style = \"intercept\"\n    else:\n        request_style = \"\"\n\n    scheme_style = request_style or SCHEME_STYLES.get(request_scheme, \"scheme_other\")\n    items.append(fcol(fixlen(request_scheme.upper(), 5), scheme_style))\n\n    if request_is_push_promise:\n        method_style = \"method_http2_push\"\n    else:\n        method_style = request_style or HTTP_REQUEST_METHOD_STYLES.get(\n            request_method, \"method_other\"\n        )\n    items.append(fcol(fixlen(request_method, 4), method_style))\n\n    items.append(\n        (\n            \"weight\",\n            0.25,\n            TruncatedText(request_host, colorize_host(request_host), \"right\"),\n        )\n    )\n    items.append(\n        (\"weight\", 1.0, TruncatedText(request_path, colorize_req(request_path), \"left\"))\n    )\n\n    if intercepted and response_code:\n        response_style = \"intercept\"\n    else:\n        response_style = \"\"\n\n    if response_code:\n        status = str(response_code)\n        status_style = response_style or HTTP_RESPONSE_CODE_STYLE.get(\n            response_code // 100, \"code_other\"\n        )\n\n        if response_content_length and response_content_type:\n            content, content_style = format_http_content_type(response_content_type)\n            content_style = response_style or content_style\n        elif response_content_length:\n            content = \"\"\n            content_style = \"content_none\"\n        elif response_content_length == 0:\n            content = \"[no content]\"\n            content_style = \"content_none\"\n        else:\n            content = \"[content missing]\"\n            content_style = \"content_none\"\n\n    elif error_message:\n        status = \"err\"\n        status_style = \"error\"\n        content = error_message\n        content_style = \"error\"\n\n    else:\n        status = \"\"\n        status_style = \"text\"\n        content = \"\"\n        content_style = \"\"\n\n    items.append(fcol(fixlen(status, 3), status_style))\n    items.append((\"weight\", 0.15, truncated_plain(content, content_style, \"right\")))\n\n    if response_content_length:\n        size, size_style = format_size(response_content_length)\n        items.append(fcol(fixlen_r(size, 5), response_style or size_style))\n    else:\n        items.append((\"fixed\", 5, urwid.Text(\"\")))\n\n    if duration:\n        duration_pretty, duration_style = format_duration(duration)\n        items.append(\n            fcol(fixlen_r(duration_pretty, 5), response_style or duration_style)\n        )\n    else:\n        items.append((\"fixed\", 5, urwid.Text(\"\")))\n\n    items.append(\n        format_right_indicators(\n            replay=bool(is_replay),\n            marked=marked,\n        )\n    )\n    return urwid.Columns(items, dividechars=1, min_width=15)\n\n\n@lru_cache(maxsize=800)\ndef format_message_flow(\n    *,\n    render_mode: RenderMode,\n    focused: bool,\n    timestamp_start: float,\n    marked: str,\n    protocol: str,\n    client_address,\n    server_address,\n    total_size: int,\n    duration: float | None,\n    error_message: str | None,\n):\n    conn = f\"{human.format_address(client_address)} <-> {human.format_address(server_address)}\"\n\n    items = []\n\n    if render_mode in (RenderMode.TABLE, RenderMode.DETAILVIEW):\n        items.append(\n            format_left_indicators(\n                focused=focused, intercepted=False, timestamp=timestamp_start\n            )\n        )\n    else:\n        if focused:\n            items.append(fcol(\">>\", \"focus\"))\n        else:\n            items.append(fcol(\"  \", \"focus\"))\n\n    if render_mode is RenderMode.TABLE:\n        items.append(fcol(fixlen(protocol.upper(), 5), SCHEME_STYLES[protocol]))\n    else:\n        items.append(fcol(protocol.upper(), SCHEME_STYLES[protocol]))\n\n    items.append((\"weight\", 1.0, truncated_plain(conn, \"text\", \"left\")))\n    if error_message:\n        items.append((\"weight\", 1.0, truncated_plain(error_message, \"error\", \"left\")))\n\n    if total_size:\n        size, size_style = format_size(total_size)\n        items.append(fcol(fixlen_r(size, 5), size_style))\n    else:\n        items.append((\"fixed\", 5, urwid.Text(\"\")))\n\n    if duration:\n        duration_pretty, duration_style = format_duration(duration)\n        items.append(fcol(fixlen_r(duration_pretty, 5), duration_style))\n    else:\n        items.append((\"fixed\", 5, urwid.Text(\"\")))\n\n    items.append(format_right_indicators(replay=False, marked=marked))\n\n    return urwid.Pile([urwid.Columns(items, dividechars=1, min_width=15)])\n\n\n@lru_cache(maxsize=800)\ndef format_dns_flow(\n    *,\n    render_mode: RenderMode,\n    focused: bool,\n    intercepted: bool,\n    marked: str,\n    is_replay: str | None,\n    op_code: str,\n    request_timestamp: float,\n    domain: str,\n    type: str,\n    response_code: str | None,\n    response_code_http_equiv: int,\n    answer: str | None,\n    error_message: str,\n    duration: float | None,\n):\n    items = []\n\n    if render_mode in (RenderMode.TABLE, RenderMode.DETAILVIEW):\n        items.append(\n            format_left_indicators(\n                focused=focused, intercepted=intercepted, timestamp=request_timestamp\n            )\n        )\n    else:\n        items.append(fcol(\">>\" if focused else \"  \", \"focus\"))\n\n    scheme_style = \"intercepted\" if intercepted else SCHEME_STYLES[\"dns\"]\n    t = f\"DNS {op_code}\"\n    if render_mode is RenderMode.TABLE:\n        t = fixlen(t, 10)\n    items.append(fcol(t, scheme_style))\n    items.append((\"weight\", 0.5, TruncatedText(domain, colorize_host(domain), \"right\")))\n    items.append(fcol(\"(\" + fixlen(type, 5)[: len(type)] + \") =\", \"text\"))\n\n    items.append(\n        (\n            \"weight\",\n            1,\n            (\n                truncated_plain(\n                    \"...\" if answer is None else \"?\" if not answer else answer, \"text\"\n                )\n                if error_message is None\n                else truncated_plain(error_message, \"error\")\n            ),\n        )\n    )\n    status_style = (\n        \"intercepted\"\n        if intercepted\n        else HTTP_RESPONSE_CODE_STYLE.get(response_code_http_equiv // 100, \"code_other\")\n    )\n    items.append(\n        fcol(fixlen(\"\" if response_code is None else response_code, 9), status_style)\n    )\n\n    if duration:\n        duration_pretty, duration_style = format_duration(duration)\n        items.append(fcol(fixlen_r(duration_pretty, 5), duration_style))\n    else:\n        items.append((\"fixed\", 5, urwid.Text(\"\")))\n\n    items.append(\n        format_right_indicators(\n            replay=bool(is_replay),\n            marked=marked,\n        )\n    )\n    return urwid.Pile([urwid.Columns(items, dividechars=1, min_width=15)])\n\n\ndef format_flow(\n    f: flow.Flow,\n    *,\n    render_mode: RenderMode,\n    hostheader: bool = False,  # pass options directly if we need more stuff from them\n    focused: bool = True,\n) -> urwid.Widget:\n    \"\"\"\n    This functions calls the proper renderer depending on the flow type.\n    We also want to cache the renderer output, so we extract all attributes\n    relevant for display and call the render with only that. This assures that rows\n    are updated if the flow is changed.\n    \"\"\"\n    duration: float | None\n    error_message: str | None\n    if f.error:\n        error_message = f.error.msg\n    else:\n        error_message = None\n\n    if isinstance(f, (TCPFlow, UDPFlow)):\n        total_size = 0\n        for message in f.messages:\n            total_size += len(message.content)\n        if f.messages:\n            duration = f.messages[-1].timestamp - f.client_conn.timestamp_start\n        else:\n            duration = None\n        if f.client_conn.tls_version == \"QUIC\":\n            protocol = \"quic\"\n        else:\n            protocol = f.type\n        return format_message_flow(\n            render_mode=render_mode,\n            focused=focused,\n            timestamp_start=f.client_conn.timestamp_start,\n            marked=f.marked,\n            protocol=protocol,\n            client_address=f.client_conn.peername,\n            server_address=f.server_conn.address,\n            total_size=total_size,\n            duration=duration,\n            error_message=error_message,\n        )\n    elif isinstance(f, DNSFlow):\n        if f.response:\n            duration = f.response.timestamp - f.request.timestamp\n            response_code_str: str | None = dns.response_codes.to_str(\n                f.response.response_code\n            )\n            response_code_http_equiv = dns.response_codes.http_equiv_status_code(\n                f.response.response_code\n            )\n            answer = \", \".join(str(x) for x in f.response.answers)\n        else:\n            duration = None\n            response_code_str = None\n            response_code_http_equiv = 0\n            answer = None\n        return format_dns_flow(\n            render_mode=render_mode,\n            focused=focused,\n            intercepted=f.intercepted,\n            marked=f.marked,\n            is_replay=f.is_replay,\n            op_code=dns.op_codes.to_str(f.request.op_code),\n            request_timestamp=f.request.timestamp,\n            domain=f.request.questions[0].name if f.request.questions else \"\",\n            type=dns.types.to_str(f.request.questions[0].type)\n            if f.request.questions\n            else \"\",\n            response_code=response_code_str,\n            response_code_http_equiv=response_code_http_equiv,\n            answer=answer,\n            error_message=error_message,\n            duration=duration,\n        )\n    elif isinstance(f, HTTPFlow):\n        intercepted = f.intercepted\n        response_content_length: int | None\n        if f.response:\n            if f.response.raw_content is not None:\n                response_content_length = len(f.response.raw_content)\n            else:\n                response_content_length = None\n            response_code: int | None = f.response.status_code\n            response_reason: str | None = f.response.reason\n            response_content_type = f.response.headers.get(\"content-type\")\n            if f.response.timestamp_end:\n                duration = max(\n                    [f.response.timestamp_end - f.request.timestamp_start, 0]\n                )\n            else:\n                duration = None\n        else:\n            response_content_length = None\n            response_code = None\n            response_reason = None\n            response_content_type = None\n            duration = None\n\n        scheme = f.request.scheme\n        if f.websocket is not None:\n            if scheme == \"https\":\n                scheme = \"wss\"\n            elif scheme == \"http\":\n                scheme = \"ws\"\n\n        if render_mode in (RenderMode.LIST, RenderMode.DETAILVIEW):\n            render_func = format_http_flow_list\n        else:\n            render_func = format_http_flow_table\n        return render_func(\n            render_mode=render_mode,\n            focused=focused,\n            marked=f.marked,\n            is_replay=f.is_replay,\n            request_method=f.request.method,\n            request_scheme=scheme,\n            request_host=f.request.pretty_host if hostheader else f.request.host,\n            request_path=f.request.path,\n            request_url=f.request.pretty_url if hostheader else f.request.url,\n            request_http_version=f.request.http_version,\n            request_timestamp=f.request.timestamp_start,\n            request_is_push_promise=\"h2-pushed-stream\" in f.metadata,\n            intercepted=intercepted,\n            response_code=response_code,\n            response_reason=response_reason,\n            response_content_length=response_content_length,\n            response_content_type=response_content_type,\n            duration=duration,\n            error_message=error_message,\n        )\n\n    else:\n        raise NotImplementedError()\n", "mitmproxy/tools/console/options.py": "from __future__ import annotations\n\nimport pprint\nimport textwrap\nfrom collections.abc import Sequence\nfrom typing import Optional\n\nimport urwid\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import optmanager\nfrom mitmproxy.tools.console import layoutwidget\nfrom mitmproxy.tools.console import overlay\nfrom mitmproxy.tools.console import signals\n\nHELP_HEIGHT = 5\n\n\ndef can_edit_inplace(opt):\n    if opt.choices:\n        return False\n    if opt.typespec in [str, int, Optional[str], Optional[int]]:\n        return True\n\n\ndef fcol(s, width, attr):\n    s = str(s)\n    return (\"fixed\", width, urwid.Text((attr, s)))\n\n\nclass OptionItem(urwid.WidgetWrap):\n    def __init__(self, walker, opt, focused, namewidth, editing):\n        self.walker, self.opt, self.focused = walker, opt, focused\n        self.namewidth = namewidth\n        self.editing = editing\n        super().__init__(None)\n        self._w = self.get_widget()\n\n    def get_widget(self):\n        val = self.opt.current()\n        if self.opt.typespec == bool:\n            displayval = \"true\" if val else \"false\"\n        elif not val:\n            displayval = \"\"\n        elif self.opt.typespec == Sequence[str]:\n            displayval = pprint.pformat(val, indent=1)\n        else:\n            displayval = str(val)\n\n        changed = self.walker.master.options.has_changed(self.opt.name)\n        if self.focused:\n            valstyle = \"option_active_selected\" if changed else \"option_selected\"\n        else:\n            valstyle = \"option_active\" if changed else \"text\"\n\n        if self.editing:\n            valw = urwid.Edit(edit_text=displayval)\n        else:\n            valw = urwid.AttrMap(\n                urwid.Padding(urwid.Text([(valstyle, displayval)])), valstyle\n            )\n\n        return urwid.Columns(\n            [\n                (\n                    self.namewidth,\n                    urwid.Text([(\"title\", self.opt.name.ljust(self.namewidth))]),\n                ),\n                valw,\n            ],\n            dividechars=2,\n            focus_column=1,\n        )\n\n    def get_edit_text(self):\n        return self._w[1].get_edit_text()\n\n    def selectable(self):\n        return True\n\n    def keypress(self, size, key):\n        if self.editing:\n            self._w[1].keypress(size, key)\n            return\n        return key\n\n\nclass OptionListWalker(urwid.ListWalker):\n    def __init__(self, master, help_widget: OptionHelp):\n        self.master = master\n        self.help_widget = help_widget\n\n        self.index = 0\n        self.focusobj = None\n\n        self.opts = sorted(master.options.keys())\n        self.maxlen = max(len(i) for i in self.opts)\n        self.editing = False\n        self.set_focus(0)\n        self.master.options.changed.connect(self.sig_mod)\n\n    def sig_mod(self, *args, **kwargs):\n        self.opts = sorted(self.master.options.keys())\n        self.maxlen = max(len(i) for i in self.opts)\n        self._modified()\n        self.set_focus(self.index)\n\n    def start_editing(self):\n        self.editing = True\n        self.focus_obj = self._get(self.index, True)\n        self._modified()\n\n    def stop_editing(self):\n        self.editing = False\n        self.focus_obj = self._get(self.index, False)\n        self.set_focus(self.index)\n        self._modified()\n\n    def get_edit_text(self):\n        return self.focus_obj.get_edit_text()\n\n    def _get(self, pos, editing):\n        name = self.opts[pos]\n        opt = self.master.options._options[name]\n        return OptionItem(self, opt, pos == self.index, self.maxlen, editing)\n\n    def get_focus(self):\n        return self.focus_obj, self.index\n\n    def set_focus(self, index):\n        self.editing = False\n        name = self.opts[index]\n        opt = self.master.options._options[name]\n        self.index = index\n        self.focus_obj = self._get(self.index, self.editing)\n        self.help_widget.update_help_text(opt.help)\n        self._modified()\n\n    def get_next(self, pos):\n        if pos >= len(self.opts) - 1:\n            return None, None\n        pos = pos + 1\n        return self._get(pos, False), pos\n\n    def get_prev(self, pos):\n        pos = pos - 1\n        if pos < 0:\n            return None, None\n        return self._get(pos, False), pos\n\n    def positions(self, reverse=False):\n        if reverse:\n            return reversed(range(len(self.opts)))\n        else:\n            return range(len(self.opts))\n\n\nclass OptionsList(urwid.ListBox):\n    def __init__(self, master, help_widget: OptionHelp):\n        self.master = master\n        self.walker = OptionListWalker(master, help_widget)\n        super().__init__(self.walker)\n\n    def save_config(self, path):\n        try:\n            optmanager.save(self.master.options, path)\n        except exceptions.OptionsError as e:\n            signals.status_message.send(message=str(e))\n\n    def keypress(self, size, key):\n        if self.walker.editing:\n            if key == \"enter\":\n                foc, idx = self.get_focus()\n                v = self.walker.get_edit_text()\n                try:\n                    self.master.options.set(f\"{foc.opt.name}={v}\")\n                except exceptions.OptionsError as v:\n                    signals.status_message.send(message=str(v))\n                self.walker.stop_editing()\n                return None\n            elif key == \"esc\":\n                self.walker.stop_editing()\n                return None\n        else:\n            if key == \"m_start\":\n                self.set_focus(0)\n                self.walker._modified()\n            elif key == \"m_end\":\n                self.set_focus(len(self.walker.opts) - 1)\n                self.walker._modified()\n            elif key == \"m_select\":\n                foc, idx = self.get_focus()\n                if foc.opt.typespec == bool:\n                    self.master.options.toggler(foc.opt.name)()\n                    # Bust the focus widget cache\n                    self.set_focus(self.walker.index)\n                elif can_edit_inplace(foc.opt):\n                    self.walker.start_editing()\n                    self.walker._modified()\n                elif foc.opt.choices:\n                    self.master.overlay(\n                        overlay.Chooser(\n                            self.master,\n                            foc.opt.name,\n                            foc.opt.choices,\n                            foc.opt.current(),\n                            self.master.options.setter(foc.opt.name),\n                        )\n                    )\n                elif foc.opt.typespec == Sequence[str]:\n                    self.master.overlay(\n                        overlay.OptionsOverlay(\n                            self.master,\n                            foc.opt.name,\n                            foc.opt.current(),\n                            HELP_HEIGHT + 5,\n                        ),\n                        valign=\"top\",\n                    )\n                else:\n                    raise NotImplementedError()\n        return super().keypress(size, key)\n\n\nclass OptionHelp(urwid.Frame):\n    def __init__(self, master):\n        self.master = master\n        super().__init__(self.widget(\"\"))\n        self.set_active(False)\n\n    def set_active(self, val):\n        h = urwid.Text(\"Option Help\")\n        style = \"heading\" if val else \"heading_inactive\"\n        self.header = urwid.AttrWrap(h, style)\n\n    def widget(self, txt):\n        cols, _ = self.master.ui.get_cols_rows()\n        return urwid.ListBox([urwid.Text(i) for i in textwrap.wrap(txt, cols)])\n\n    def update_help_text(self, txt: str) -> None:\n        self.set_body(self.widget(txt))\n\n\nclass Options(urwid.Pile, layoutwidget.LayoutWidget):\n    title = \"Options\"\n    keyctx = \"options\"\n\n    focus_position: int\n\n    def __init__(self, master):\n        oh = OptionHelp(master)\n        self.optionslist = OptionsList(master, oh)\n        super().__init__(\n            [\n                self.optionslist,\n                (HELP_HEIGHT, oh),\n            ]\n        )\n        self.master = master\n\n    def current_name(self):\n        foc, idx = self.optionslist.get_focus()\n        return foc.opt.name\n\n    def keypress(self, size, key):\n        if key == \"m_next\":\n            self.focus_position = (self.focus_position + 1) % len(self.widget_list)\n            self.widget_list[1].set_active(self.focus_position == 1)\n            key = None\n\n        # This is essentially a copypasta from urwid.Pile's keypress handler.\n        # So much for \"closed for modification, but open for extension\".\n        item_rows = None\n        if len(size) == 2:\n            item_rows = self.get_item_rows(size, focus=True)\n        i = self.widget_list.index(self.focus_item)\n        tsize = self.get_item_size(size, i, True, item_rows)\n        return self.focus_item.keypress(tsize, key)\n", "mitmproxy/tools/console/eventlog.py": "import collections\n\nimport urwid\n\nfrom mitmproxy import log\nfrom mitmproxy.tools.console import layoutwidget\n\n\nclass LogBufferWalker(urwid.SimpleListWalker):\n    pass\n\n\nclass EventLog(urwid.ListBox, layoutwidget.LayoutWidget):\n    keyctx = \"eventlog\"\n    title = \"Events\"\n\n    def __init__(self, master):\n        self.master = master\n        self.walker = LogBufferWalker(collections.deque(maxlen=self.master.events.size))\n\n        master.events.sig_add.connect(self.add_event)\n        master.events.sig_refresh.connect(self.refresh_events)\n        self.master.options.subscribe(\n            self.refresh_events, [\"console_eventlog_verbosity\"]\n        )\n        self.refresh_events()\n\n        super().__init__(self.walker)\n\n    def load(self, loader):\n        loader.add_option(\n            \"console_focus_follow\", bool, False, \"Focus follows new flows.\"\n        )\n\n    def set_focus(self, index):\n        if 0 <= index < len(self.walker):\n            super().set_focus(index)\n\n    def keypress(self, size, key):\n        if key == \"m_end\":\n            self.set_focus(len(self.walker) - 1)\n        elif key == \"m_start\":\n            self.set_focus(0)\n        return super().keypress(size, key)\n\n    def add_event(self, entry: log.LogEntry):\n        if log.log_tier(self.master.options.console_eventlog_verbosity) < log.log_tier(\n            entry.level\n        ):\n            return\n        txt = f\"{entry.level}: {str(entry.msg)}\"\n        if entry.level in (\"error\", \"warn\", \"alert\"):\n            e = urwid.Text((entry.level, txt))\n        else:\n            e = urwid.Text(txt)\n        self.walker.append(e)\n        if self.master.options.console_focus_follow:\n            self.walker.set_focus(len(self.walker) - 1)\n\n    def refresh_events(self, *_) -> None:\n        self.walker.clear()\n        for event in self.master.events.data:\n            self.add_event(event)\n", "mitmproxy/tools/console/quickhelp.py": "\"\"\"\nThis module is reponsible for drawing the quick key help at the bottom of mitmproxy.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Union\n\nimport urwid\n\nfrom mitmproxy import flow\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.tools.console.eventlog import EventLog\nfrom mitmproxy.tools.console.flowlist import FlowListBox\nfrom mitmproxy.tools.console.flowview import FlowView\nfrom mitmproxy.tools.console.grideditor.base import FocusEditor\nfrom mitmproxy.tools.console.help import HelpView\nfrom mitmproxy.tools.console.keybindings import KeyBindings\nfrom mitmproxy.tools.console.keymap import Keymap\nfrom mitmproxy.tools.console.options import Options\n\n\n@dataclass\nclass BasicKeyHelp:\n    \"\"\"Quick help for urwid-builtin keybindings (i.e. those keys that do not appear in the keymap)\"\"\"\n\n    key: str\n\n\nHelpItems = dict[str, Union[str, BasicKeyHelp]]\n\"\"\"\nA mapping from the short text that should be displayed in the help bar to the full help text provided for the key\nbinding. The order of the items in the dictionary determines the order in which they are displayed in the help bar.\n\nSome help items explain builtin urwid functionality, so there is no key binding for them. In this case, the value\nis a BasicKeyHelp object.\n\"\"\"\n\n\n@dataclass\nclass QuickHelp:\n    top_label: str\n    top_items: HelpItems\n    bottom_label: str\n    bottom_items: HelpItems\n\n    def make_rows(self, keymap: Keymap) -> tuple[urwid.Columns, urwid.Columns]:\n        top = _make_row(self.top_label, self.top_items, keymap)\n        bottom = _make_row(self.bottom_label, self.bottom_items, keymap)\n        return top, bottom\n\n\ndef make(\n    widget: type[urwid.Widget],\n    focused_flow: flow.Flow | None,\n    is_root_widget: bool,\n) -> QuickHelp:\n    top_label = \"\"\n    top_items: HelpItems = {}\n    if widget in (FlowListBox, FlowView):\n        top_label = \"Flow:\"\n        if focused_flow:\n            if widget == FlowListBox:\n                top_items[\"Select\"] = \"Select\"\n            else:\n                top_items[\"Edit\"] = \"Edit a flow component\"\n            top_items |= {\n                \"Duplicate\": \"Duplicate flow\",\n                \"Replay\": \"Replay this flow\",\n                \"Export\": \"Export this flow to file\",\n                \"Delete\": \"Delete flow from view\",\n            }\n            if widget == FlowListBox:\n                if focused_flow.marked:\n                    top_items[\"Unmark\"] = \"Toggle mark on this flow\"\n                else:\n                    top_items[\"Mark\"] = \"Toggle mark on this flow\"\n                top_items[\"Edit\"] = \"Edit a flow component\"\n            if focused_flow.intercepted:\n                top_items[\"Resume\"] = \"Resume this intercepted flow\"\n            if focused_flow.modified():\n                top_items[\"Restore\"] = \"Revert changes to this flow\"\n            if isinstance(focused_flow, HTTPFlow) and focused_flow.response:\n                top_items[\"Save body\"] = \"Save response body to file\"\n            if widget == FlowView:\n                top_items |= {\n                    \"Next flow\": \"Go to next flow\",\n                    \"Prev flow\": \"Go to previous flow\",\n                }\n        else:\n            top_items |= {\n                \"Load flows\": \"Load flows from file\",\n                \"Create new\": \"Create a new flow\",\n            }\n    elif widget == KeyBindings:\n        top_label = \"Keybindings:\"\n        top_items |= {\n            \"Add\": \"Add a key binding\",\n            \"Edit\": \"Edit the currently focused key binding\",\n            \"Delete\": \"Unbind the currently focused key binding\",\n            \"Execute\": \"Execute the currently focused key binding\",\n        }\n    elif widget == Options:\n        top_label = \"Options:\"\n        top_items |= {\n            \"Edit\": BasicKeyHelp(\"\u23ce\"),\n            \"Reset\": \"Reset this option\",\n            \"Reset all\": \"Reset all options\",\n            \"Load file\": \"Load from file\",\n            \"Save file\": \"Save to file\",\n        }\n    elif widget == HelpView:\n        top_label = \"Help:\"\n        top_items |= {\n            \"Scroll down\": BasicKeyHelp(\"\u2193\"),\n            \"Scroll up\": BasicKeyHelp(\"\u2191\"),\n            \"Exit help\": \"Exit help\",\n            \"Next tab\": BasicKeyHelp(\"tab\"),\n        }\n    elif widget == EventLog:\n        top_label = \"Events:\"\n        top_items |= {\n            \"Scroll down\": BasicKeyHelp(\"\u2193\"),\n            \"Scroll up\": BasicKeyHelp(\"\u2191\"),\n            \"Clear\": \"Clear\",\n        }\n    elif issubclass(widget, FocusEditor):\n        top_label = f\"Edit:\"\n        top_items |= {\n            \"Start edit\": BasicKeyHelp(\"\u23ce\"),\n            \"Stop edit\": BasicKeyHelp(\"esc\"),\n            \"Add row\": \"Add a row after cursor\",\n            \"Delete row\": \"Delete this row\",\n        }\n    else:\n        pass\n\n    bottom_label = \"Proxy:\"\n    bottom_items: HelpItems = {\n        \"Help\": \"View help\",\n    }\n    if is_root_widget:\n        bottom_items[\"Quit\"] = \"Exit the current view\"\n    else:\n        bottom_items[\"Back\"] = \"Exit the current view\"\n    bottom_items |= {\n        \"Events\": \"View event log\",\n        \"Options\": \"View options\",\n        \"Intercept\": \"Set intercept\",\n        \"Filter\": \"Set view filter\",\n    }\n    if focused_flow:\n        bottom_items |= {\n            \"Save flows\": \"Save listed flows to file\",\n            \"Clear list\": \"Clear flow list\",\n        }\n    bottom_items |= {\n        \"Layout\": \"Cycle to next layout\",\n        \"Switch\": \"Focus next layout pane\",\n        \"Follow new\": \"Set focus follow\",\n    }\n\n    label_len = max(len(top_label), len(bottom_label), 8) + 1\n    top_label = top_label.ljust(label_len)\n    bottom_label = bottom_label.ljust(label_len)\n\n    return QuickHelp(top_label, top_items, bottom_label, bottom_items)\n\n\ndef _make_row(label: str, items: HelpItems, keymap: Keymap) -> urwid.Columns:\n    cols = [\n        (len(label), urwid.Text(label)),\n    ]\n    for short, long in items.items():\n        if isinstance(long, BasicKeyHelp):\n            key_short = long.key\n        else:\n            b = keymap.binding_for_help(long)\n            if b is None:\n                continue\n            key_short = b.key_short()\n        txt = urwid.Text(\n            [\n                (\"heading_inactive\", key_short),\n                \" \",\n                short,\n            ],\n            wrap=\"clip\",\n        )\n        cols.append((14, txt))\n\n    return urwid.Columns(cols)\n", "mitmproxy/tools/console/palettes.py": "# Low-color themes should ONLY use the standard foreground and background\n# colours listed here:\n#\n# http://urwid.org/manual/displayattributes.html\n#\nfrom __future__ import annotations\n\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\n\n\nclass Palette:\n    _fields = [\n        \"background\",\n        \"title\",\n        # Status bar & heading\n        \"heading\",\n        \"heading_key\",\n        \"heading_inactive\",\n        # Help\n        \"key\",\n        \"head\",\n        \"text\",\n        # Options\n        \"option_selected\",\n        \"option_active\",\n        \"option_active_selected\",\n        \"option_selected_key\",\n        # List and Connections\n        \"method_get\",\n        \"method_post\",\n        \"method_delete\",\n        \"method_other\",\n        \"method_head\",\n        \"method_put\",\n        \"method_http2_push\",\n        \"scheme_http\",\n        \"scheme_https\",\n        \"scheme_ws\",\n        \"scheme_wss\",\n        \"scheme_tcp\",\n        \"scheme_udp\",\n        \"scheme_dns\",\n        \"scheme_quic\",\n        \"scheme_other\",\n        \"url_punctuation\",\n        \"url_domain\",\n        \"url_filename\",\n        \"url_extension\",\n        \"url_query_key\",\n        \"url_query_value\",\n        \"content_none\",\n        \"content_text\",\n        \"content_script\",\n        \"content_media\",\n        \"content_data\",\n        \"content_raw\",\n        \"content_other\",\n        \"focus\",\n        \"code_200\",\n        \"code_300\",\n        \"code_400\",\n        \"code_500\",\n        \"code_other\",\n        \"error\",\n        \"warn\",\n        \"alert\",\n        \"header\",\n        \"highlight\",\n        \"intercept\",\n        \"replay\",\n        \"mark\",\n        # Hex view\n        \"offset\",\n        # JSON/msgpack view\n        \"Token_Name_Tag\",\n        \"Token_Literal_String\",\n        \"Token_Literal_Number\",\n        \"Token_Keyword_Constant\",\n        # TCP flow details\n        \"from_client\",\n        \"to_client\",\n        # Grid Editor\n        \"focusfield\",\n        \"focusfield_error\",\n        \"field_error\",\n        \"editfield\",\n        # Commander\n        \"commander_command\",\n        \"commander_invalid\",\n        \"commander_hint\",\n    ]\n    _fields.extend([\"gradient_%02d\" % i for i in range(100)])\n    high: Mapping[str, Sequence[str]] | None = None\n    low: Mapping[str, Sequence[str]]\n\n    def palette(self, transparent: bool):\n        lst: list[Sequence[str | None]] = []\n        highback, lowback = None, None\n        if not transparent:\n            if self.high and self.high.get(\"background\"):\n                highback = self.high[\"background\"][1]\n            lowback = self.low[\"background\"][1]\n\n        for i in self._fields:\n            if transparent and i == \"background\":\n                lst.append([\"background\", \"default\", \"default\"])\n            else:\n                v: list[str | None] = [i]\n                low = list(self.low[i])\n                if lowback and low[1] == \"default\":\n                    low[1] = lowback\n                v.extend(low)\n                if self.high and i in self.high:\n                    v.append(None)\n                    high: list[str | None] = list(self.high[i])\n                    if highback and high[1] == \"default\":\n                        high[1] = highback\n                    v.extend(high)\n                elif highback and self.low[i][1] == \"default\":\n                    high = [None, low[0], highback]\n                    v.extend(high)\n                lst.append(tuple(v))\n        return lst\n\n\ndef gen_gradient(palette, cols):\n    for i in range(100):\n        palette[\"gradient_%02d\" % i] = (cols[i * len(cols) // 100], \"default\")\n\n\ndef gen_rgb_gradient(palette, cols):\n    parts = len(cols) - 1\n    for i in range(100):\n        p = i / 100\n        idx = int(p * parts)\n        t0 = cols[idx]\n        t1 = cols[idx + 1]\n        pp = p * parts % 1\n        t = (\n            round(t0[0] + (t1[0] - t0[0]) * pp),\n            round(t0[1] + (t1[1] - t0[1]) * pp),\n            round(t0[2] + (t1[2] - t0[2]) * pp),\n        )\n        palette[\"gradient_%02d\" % i] = (\"#%x%x%x\" % t, \"default\")\n\n\nclass LowDark(Palette):\n    \"\"\"\n    Low-color dark background\n    \"\"\"\n\n    low = dict(\n        background=(\"white\", \"black\"),\n        title=(\"white,bold\", \"default\"),\n        # Status bar & heading\n        heading=(\"white\", \"dark blue\"),\n        heading_key=(\"light cyan\", \"dark blue\"),\n        heading_inactive=(\"dark gray\", \"light gray\"),\n        # Help\n        key=(\"light cyan\", \"default\"),\n        head=(\"white,bold\", \"default\"),\n        text=(\"light gray\", \"default\"),\n        # Options\n        option_selected=(\"black\", \"light gray\"),\n        option_selected_key=(\"light cyan\", \"light gray\"),\n        option_active=(\"light red\", \"default\"),\n        option_active_selected=(\"light red\", \"light gray\"),\n        # List and Connections\n        method_get=(\"light green\", \"default\"),\n        method_post=(\"brown\", \"default\"),\n        method_delete=(\"light red\", \"default\"),\n        method_head=(\"dark cyan\", \"default\"),\n        method_put=(\"dark red\", \"default\"),\n        method_other=(\"dark magenta\", \"default\"),\n        method_http2_push=(\"dark gray\", \"default\"),\n        scheme_http=(\"dark cyan\", \"default\"),\n        scheme_https=(\"dark green\", \"default\"),\n        scheme_ws=(\"brown\", \"default\"),\n        scheme_wss=(\"dark magenta\", \"default\"),\n        scheme_tcp=(\"dark magenta\", \"default\"),\n        scheme_udp=(\"dark magenta\", \"default\"),\n        scheme_dns=(\"dark blue\", \"default\"),\n        scheme_quic=(\"brown\", \"default\"),\n        scheme_other=(\"dark magenta\", \"default\"),\n        url_punctuation=(\"light gray\", \"default\"),\n        url_domain=(\"white\", \"default\"),\n        url_filename=(\"dark cyan\", \"default\"),\n        url_extension=(\"light gray\", \"default\"),\n        url_query_key=(\"white\", \"default\"),\n        url_query_value=(\"light gray\", \"default\"),\n        content_none=(\"dark gray\", \"default\"),\n        content_text=(\"light gray\", \"default\"),\n        content_script=(\"dark green\", \"default\"),\n        content_media=(\"light blue\", \"default\"),\n        content_data=(\"brown\", \"default\"),\n        content_raw=(\"dark red\", \"default\"),\n        content_other=(\"dark magenta\", \"default\"),\n        focus=(\"yellow\", \"default\"),\n        code_200=(\"dark green\", \"default\"),\n        code_300=(\"light blue\", \"default\"),\n        code_400=(\"light red\", \"default\"),\n        code_500=(\"light red\", \"default\"),\n        code_other=(\"dark red\", \"default\"),\n        alert=(\"light magenta\", \"default\"),\n        warn=(\"brown\", \"default\"),\n        error=(\"light red\", \"default\"),\n        header=(\"dark cyan\", \"default\"),\n        highlight=(\"white,bold\", \"default\"),\n        intercept=(\"brown\", \"default\"),\n        replay=(\"light green\", \"default\"),\n        mark=(\"light red\", \"default\"),\n        # Hex view\n        offset=(\"dark cyan\", \"default\"),\n        # JSON/msgpack view\n        Token_Name_Tag=(\"dark green\", \"default\"),\n        Token_Literal_String=(\"dark blue\", \"default\"),\n        Token_Literal_Number=(\"light magenta\", \"default\"),\n        Token_Keyword_Constant=(\"dark magenta\", \"default\"),\n        # TCP flow details\n        from_client=(\"light blue\", \"default\"),\n        to_client=(\"light red\", \"default\"),\n        # Grid Editor\n        focusfield=(\"black\", \"light gray\"),\n        focusfield_error=(\"dark red\", \"light gray\"),\n        field_error=(\"dark red\", \"default\"),\n        editfield=(\"white\", \"default\"),\n        commander_command=(\"white,bold\", \"default\"),\n        commander_invalid=(\"light red\", \"default\"),\n        commander_hint=(\"dark gray\", \"default\"),\n    )\n    gen_gradient(\n        low,\n        [\"light red\", \"yellow\", \"light green\", \"dark green\", \"dark cyan\", \"dark blue\"],\n    )\n\n\nclass Dark(LowDark):\n    high = dict(\n        heading_inactive=(\"g58\", \"g11\"),\n        intercept=(\"#f60\", \"default\"),\n        option_selected=(\"g85\", \"g45\"),\n        option_selected_key=(\"light cyan\", \"g50\"),\n        option_active_selected=(\"light red\", \"g50\"),\n    )\n\n\nclass LowLight(Palette):\n    \"\"\"\n    Low-color light background\n    \"\"\"\n\n    low = dict(\n        background=(\"black\", \"white\"),\n        title=(\"dark magenta\", \"default\"),\n        # Status bar & heading\n        heading=(\"white\", \"black\"),\n        heading_key=(\"dark blue\", \"black\"),\n        heading_inactive=(\"black\", \"light gray\"),\n        # Help\n        key=(\"dark blue\", \"default\"),\n        head=(\"black\", \"default\"),\n        text=(\"dark gray\", \"default\"),\n        # Options\n        option_selected=(\"black\", \"light gray\"),\n        option_selected_key=(\"dark blue\", \"light gray\"),\n        option_active=(\"light red\", \"default\"),\n        option_active_selected=(\"light red\", \"light gray\"),\n        # List and Connections\n        method_get=(\"dark green\", \"default\"),\n        method_post=(\"brown\", \"default\"),\n        method_head=(\"dark cyan\", \"default\"),\n        method_put=(\"light red\", \"default\"),\n        method_delete=(\"dark red\", \"default\"),\n        method_other=(\"light magenta\", \"default\"),\n        method_http2_push=(\"light gray\", \"default\"),\n        scheme_http=(\"dark cyan\", \"default\"),\n        scheme_https=(\"light green\", \"default\"),\n        scheme_ws=(\"brown\", \"default\"),\n        scheme_wss=(\"light magenta\", \"default\"),\n        scheme_tcp=(\"light magenta\", \"default\"),\n        scheme_udp=(\"light magenta\", \"default\"),\n        scheme_dns=(\"light blue\", \"default\"),\n        scheme_quic=(\"brown\", \"default\"),\n        scheme_other=(\"light magenta\", \"default\"),\n        url_punctuation=(\"dark gray\", \"default\"),\n        url_domain=(\"dark gray\", \"default\"),\n        url_filename=(\"black\", \"default\"),\n        url_extension=(\"dark gray\", \"default\"),\n        url_query_key=(\"light blue\", \"default\"),\n        url_query_value=(\"dark blue\", \"default\"),\n        content_none=(\"black\", \"default\"),\n        content_text=(\"dark gray\", \"default\"),\n        content_script=(\"light green\", \"default\"),\n        content_media=(\"light blue\", \"default\"),\n        content_data=(\"brown\", \"default\"),\n        content_raw=(\"light red\", \"default\"),\n        content_other=(\"light magenta\", \"default\"),\n        focus=(\"black\", \"default\"),\n        code_200=(\"dark green\", \"default\"),\n        code_300=(\"light blue\", \"default\"),\n        code_400=(\"dark red\", \"default\"),\n        code_500=(\"dark red\", \"default\"),\n        code_other=(\"light red\", \"default\"),\n        error=(\"light red\", \"default\"),\n        warn=(\"brown\", \"default\"),\n        alert=(\"light magenta\", \"default\"),\n        header=(\"dark blue\", \"default\"),\n        highlight=(\"black,bold\", \"default\"),\n        intercept=(\"brown\", \"default\"),\n        replay=(\"dark green\", \"default\"),\n        mark=(\"dark red\", \"default\"),\n        # Hex view\n        offset=(\"dark blue\", \"default\"),\n        # JSON/msgpack view\n        Token_Name_Tag=(\"dark green\", \"default\"),\n        Token_Literal_String=(\"dark blue\", \"default\"),\n        Token_Literal_Number=(\"light magenta\", \"default\"),\n        Token_Keyword_Constant=(\"dark magenta\", \"default\"),\n        # TCP flow details\n        from_client=(\"dark blue\", \"default\"),\n        to_client=(\"dark red\", \"default\"),\n        # Grid Editor\n        focusfield=(\"black\", \"light gray\"),\n        focusfield_error=(\"dark red\", \"light gray\"),\n        field_error=(\"dark red\", \"black\"),\n        editfield=(\"black\", \"default\"),\n        commander_command=(\"dark magenta\", \"default\"),\n        commander_invalid=(\"light red\", \"default\"),\n        commander_hint=(\"light gray\", \"default\"),\n    )\n    gen_gradient(\n        low,\n        [\"light red\", \"yellow\", \"light green\", \"dark green\", \"dark cyan\", \"dark blue\"],\n    )\n\n\nclass Light(LowLight):\n    high = dict(\n        background=(\"black\", \"g100\"),\n        heading=(\"g99\", \"#08f\"),\n        heading_key=(\"#0ff,bold\", \"#08f\"),\n        heading_inactive=(\"g35\", \"g85\"),\n        replay=(\"#0a0,bold\", \"default\"),\n        option_selected=(\"black\", \"g85\"),\n        option_selected_key=(\"dark blue\", \"g85\"),\n        option_active_selected=(\"light red\", \"g85\"),\n    )\n\n\n# Solarized palette in Urwid-style terminal high-colour offsets\n# See: http://ethanschoonover.com/solarized\nsol_base03 = \"h234\"\nsol_base02 = \"h235\"\nsol_base01 = \"h240\"\nsol_base00 = \"h241\"\nsol_base0 = \"h244\"\nsol_base1 = \"h245\"\nsol_base2 = \"h254\"\nsol_base3 = \"h230\"\nsol_yellow = \"h136\"\nsol_orange = \"h166\"\nsol_red = \"h160\"\nsol_magenta = \"h125\"\nsol_violet = \"h61\"\nsol_blue = \"h33\"\nsol_cyan = \"h37\"\nsol_green = \"h64\"\n\n\nclass SolarizedLight(LowLight):\n    high = dict(\n        background=(sol_base00, sol_base3),\n        title=(sol_cyan, \"default\"),\n        text=(sol_base00, \"default\"),\n        # Status bar & heading\n        heading=(sol_base2, sol_base02),\n        heading_key=(sol_blue, sol_base03),\n        heading_inactive=(sol_base03, sol_base1),\n        # Help\n        key=(\n            sol_blue,\n            \"default\",\n        ),\n        head=(sol_base00, \"default\"),\n        # Options\n        option_selected=(sol_base03, sol_base2),\n        option_selected_key=(sol_blue, sol_base2),\n        option_active=(sol_orange, \"default\"),\n        option_active_selected=(sol_orange, sol_base2),\n        # List and Connections\n        method_get=(sol_green, \"default\"),\n        method_post=(sol_orange, \"default\"),\n        method_head=(sol_cyan, \"default\"),\n        method_put=(sol_red, \"default\"),\n        method_delete=(sol_red, \"default\"),\n        method_other=(sol_magenta, \"default\"),\n        method_http2_push=(\"light gray\", \"default\"),\n        scheme_http=(sol_cyan, \"default\"),\n        scheme_https=(\"light green\", \"default\"),\n        scheme_ws=(sol_orange, \"default\"),\n        scheme_wss=(\"light magenta\", \"default\"),\n        scheme_tcp=(\"light magenta\", \"default\"),\n        scheme_udp=(\"light magenta\", \"default\"),\n        scheme_dns=(\"light blue\", \"default\"),\n        scheme_quic=(sol_orange, \"default\"),\n        scheme_other=(\"light magenta\", \"default\"),\n        url_punctuation=(\"dark gray\", \"default\"),\n        url_domain=(\"dark gray\", \"default\"),\n        url_filename=(\"black\", \"default\"),\n        url_extension=(\"dark gray\", \"default\"),\n        url_query_key=(sol_blue, \"default\"),\n        url_query_value=(\"dark blue\", \"default\"),\n        focus=(sol_base01, \"default\"),\n        code_200=(sol_green, \"default\"),\n        code_300=(sol_blue, \"default\"),\n        code_400=(\n            sol_orange,\n            \"default\",\n        ),\n        code_500=(sol_red, \"default\"),\n        code_other=(sol_magenta, \"default\"),\n        error=(sol_red, \"default\"),\n        warn=(sol_orange, \"default\"),\n        alert=(sol_magenta, \"default\"),\n        header=(sol_blue, \"default\"),\n        highlight=(sol_base01, \"default\"),\n        intercept=(\n            sol_red,\n            \"default\",\n        ),\n        replay=(\n            sol_green,\n            \"default\",\n        ),\n        # Hex view\n        offset=(sol_cyan, \"default\"),\n        # JSON/msgpack view\n        Token_Name_Tag=(sol_green, \"default\"),\n        Token_Literal_String=(sol_cyan, \"default\"),\n        Token_Literal_Number=(sol_blue, \"default\"),\n        Token_Keyword_Constant=(sol_magenta, \"default\"),\n        # TCP flow details\n        from_client=(sol_blue, \"default\"),\n        to_client=(sol_red, \"default\"),\n        # Grid Editor\n        focusfield=(sol_base00, sol_base2),\n        focusfield_error=(sol_red, sol_base2),\n        field_error=(sol_red, \"default\"),\n        editfield=(sol_base01, \"default\"),\n        commander_command=(sol_cyan, \"default\"),\n        commander_invalid=(sol_orange, \"default\"),\n        commander_hint=(sol_base1, \"default\"),\n    )\n\n\nclass SolarizedDark(LowDark):\n    high = dict(\n        background=(sol_base2, sol_base03),\n        title=(sol_blue, \"default\"),\n        text=(sol_base1, \"default\"),\n        # Status bar & heading\n        heading=(sol_base2, sol_base01),\n        heading_key=(sol_blue + \",bold\", sol_base01),\n        heading_inactive=(sol_base1, sol_base02),\n        # Help\n        key=(\n            sol_blue,\n            \"default\",\n        ),\n        head=(sol_base2, \"default\"),\n        # Options\n        option_selected=(sol_base03, sol_base00),\n        option_selected_key=(sol_blue, sol_base00),\n        option_active=(sol_orange, \"default\"),\n        option_active_selected=(sol_orange, sol_base00),\n        # List and Connections\n        focus=(sol_base1, \"default\"),\n        method_get=(sol_green, \"default\"),\n        method_post=(sol_orange, \"default\"),\n        method_delete=(sol_red, \"default\"),\n        method_head=(sol_cyan, \"default\"),\n        method_put=(sol_red, \"default\"),\n        method_other=(sol_magenta, \"default\"),\n        method_http2_push=(sol_base01, \"default\"),\n        url_punctuation=(\"h242\", \"default\"),\n        url_domain=(\"h252\", \"default\"),\n        url_filename=(\"h132\", \"default\"),\n        url_extension=(\"h96\", \"default\"),\n        url_query_key=(\"h37\", \"default\"),\n        url_query_value=(\"h30\", \"default\"),\n        content_none=(sol_base01, \"default\"),\n        content_text=(sol_base1, \"default\"),\n        content_media=(sol_blue, \"default\"),\n        code_200=(sol_green, \"default\"),\n        code_300=(sol_blue, \"default\"),\n        code_400=(\n            sol_orange,\n            \"default\",\n        ),\n        code_500=(sol_red, \"default\"),\n        code_other=(sol_magenta, \"default\"),\n        error=(sol_red, \"default\"),\n        warn=(sol_orange, \"default\"),\n        alert=(sol_magenta, \"default\"),\n        header=(sol_blue, \"default\"),\n        highlight=(sol_base01, \"default\"),\n        intercept=(\n            sol_red,\n            \"default\",\n        ),\n        replay=(\n            sol_green,\n            \"default\",\n        ),\n        # Hex view\n        offset=(sol_cyan, \"default\"),\n        # JSON/msgpack view\n        Token_Name_Tag=(sol_green, \"default\"),\n        Token_Literal_String=(sol_cyan, \"default\"),\n        Token_Literal_Number=(sol_blue, \"default\"),\n        Token_Keyword_Constant=(sol_magenta, \"default\"),\n        # TCP flow details\n        from_client=(sol_blue, \"default\"),\n        to_client=(sol_red, \"default\"),\n        # Grid Editor\n        focusfield=(sol_base0, sol_base02),\n        focusfield_error=(sol_red, sol_base02),\n        field_error=(sol_red, \"default\"),\n        editfield=(sol_base1, \"default\"),\n        commander_command=(sol_blue, \"default\"),\n        commander_invalid=(sol_orange, \"default\"),\n        commander_hint=(sol_base00, \"default\"),\n    )\n    gen_rgb_gradient(\n        high, [(15, 0, 0), (15, 15, 0), (0, 15, 0), (0, 15, 15), (0, 0, 15)]\n    )\n\n\nDEFAULT = \"dark\"\npalettes = {\n    \"lowlight\": LowLight(),\n    \"lowdark\": LowDark(),\n    \"light\": Light(),\n    \"dark\": Dark(),\n    \"solarized_light\": SolarizedLight(),\n    \"solarized_dark\": SolarizedDark(),\n}\n", "mitmproxy/tools/console/commandexecutor.py": "import logging\nfrom collections.abc import Sequence\n\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy.tools.console import overlay\nfrom mitmproxy.tools.console import signals\n\n\nclass CommandExecutor:\n    def __init__(self, master):\n        self.master = master\n\n    def __call__(self, cmd: str) -> None:\n        if cmd.strip():\n            try:\n                ret = self.master.commands.execute(cmd)\n            except exceptions.CommandError as e:\n                logging.error(str(e))\n            else:\n                if ret is not None:\n                    if type(ret) == Sequence[flow.Flow]:\n                        signals.status_message.send(\n                            message=\"Command returned %s flows\" % len(ret)\n                        )\n                    elif type(ret) == flow.Flow:\n                        signals.status_message.send(message=\"Command returned 1 flow\")\n                    else:\n                        self.master.overlay(\n                            overlay.DataViewerOverlay(\n                                self.master,\n                                ret,\n                            ),\n                            valign=\"top\",\n                        )\n", "mitmproxy/tools/console/searchable.py": "import urwid\n\nfrom mitmproxy.tools.console import signals\n\n\nclass Highlight(urwid.AttrMap):\n    def __init__(self, t):\n        urwid.AttrMap.__init__(\n            self,\n            urwid.Text(t.text),\n            \"focusfield\",\n        )\n        self.backup = t\n\n\nclass Searchable(urwid.ListBox):\n    def __init__(self, contents):\n        self.walker = urwid.SimpleFocusListWalker(contents)\n        urwid.ListBox.__init__(self, self.walker)\n        self.search_offset = 0\n        self.current_highlight = None\n        self.search_term = None\n        self.last_search = None\n\n    def keypress(self, size, key: str):\n        if key == \"/\":\n            signals.status_prompt.send(\n                prompt=\"Search for\", text=\"\", callback=self.set_search\n            )\n        elif key == \"n\":\n            self.find_next(False)\n        elif key == \"N\":\n            self.find_next(True)\n        elif key == \"m_start\":\n            self.set_focus(0)\n            self.walker._modified()\n        elif key == \"m_end\":\n            self.set_focus(len(self.walker) - 1)\n            self.walker._modified()\n        else:\n            return super().keypress(size, key)\n\n    def set_search(self, text):\n        self.last_search = text\n        self.search_term = text or None\n        self.find_next(False)\n\n    def set_highlight(self, offset):\n        if self.current_highlight is not None:\n            old = self.body[self.current_highlight]\n            self.body[self.current_highlight] = old.backup\n        if offset is None:\n            self.current_highlight = None\n        else:\n            self.body[offset] = Highlight(self.body[offset])\n            self.current_highlight = offset\n\n    def get_text(self, w):\n        if isinstance(w, urwid.Text):\n            return w.text\n        elif isinstance(w, Highlight):\n            return w.backup.text\n        else:\n            return None\n\n    def find_next(self, backwards: bool):\n        if not self.search_term:\n            if self.last_search:\n                self.search_term = self.last_search\n            else:\n                self.set_highlight(None)\n                return\n        # Start search at focus + 1\n        if backwards:\n            rng = range(len(self.body) - 1, -1, -1)\n        else:\n            rng = range(1, len(self.body) + 1)\n        for i in rng:\n            off = (self.focus_position + i) % len(self.body)\n            w = self.body[off]\n            txt = self.get_text(w)\n            if txt and self.search_term in txt:\n                self.set_highlight(off)\n                self.set_focus(off, coming_from=\"above\")\n                self.body._modified()\n                return\n        else:\n            self.set_highlight(None)\n            signals.status_message.send(message=\"Search not found.\", expire=1)\n", "mitmproxy/tools/console/signals.py": "from __future__ import annotations\n\nfrom collections.abc import Callable\nfrom typing import Union\n\nfrom mitmproxy.utils import signals\n\nStatusMessage = Union[tuple[str, str], str]\n\n\n# Show a status message in the action bar\n# Instead of using this signal directly, consider emitting a log event.\ndef _status_message(message: StatusMessage, expire: int = 5) -> None: ...\n\n\nstatus_message = signals.SyncSignal(_status_message)\n\n\n# Prompt for input\ndef _status_prompt(\n    prompt: str, text: str | None, callback: Callable[[str], None]\n) -> None: ...\n\n\nstatus_prompt = signals.SyncSignal(_status_prompt)\n\n\n# Prompt for a single keystroke\ndef _status_prompt_onekey(\n    prompt: str, keys: list[tuple[str, str]], callback: Callable[[str], None]\n) -> None: ...\n\n\nstatus_prompt_onekey = signals.SyncSignal(_status_prompt_onekey)\n\n\n# Prompt for a command\ndef _status_prompt_command(partial: str = \"\", cursor: int | None = None) -> None: ...\n\n\nstatus_prompt_command = signals.SyncSignal(_status_prompt_command)\n\n\n# Call a callback in N seconds\ndef _call_in(seconds: float, callback: Callable[[], None]) -> None: ...\n\n\ncall_in = signals.SyncSignal(_call_in)\n\n# Focus the body, footer or header of the main window\nfocus = signals.SyncSignal(lambda section: None)\n\n# Fired when settings change\nupdate_settings = signals.SyncSignal(lambda: None)\n\n# Fired when a flow changes\nflow_change = signals.SyncSignal(lambda flow: None)\n\n# Pop and push view state onto a stack\npop_view_state = signals.SyncSignal(lambda: None)\n\n# Fired when the window state changes\nwindow_refresh = signals.SyncSignal(lambda: None)\n\n# Fired when the key bindings change\nkeybindings_change = signals.SyncSignal(lambda: None)\n", "mitmproxy/tools/console/master.py": "import asyncio\nimport contextlib\nimport mimetypes\nimport os.path\nimport shlex\nimport shutil\nimport stat\nimport subprocess\nimport sys\nimport tempfile\nimport threading\nfrom typing import TypeVar\n\nimport urwid\nfrom tornado.platform.asyncio import AddThreadSelectorEventLoop\n\nfrom mitmproxy import addons\nfrom mitmproxy import log\nfrom mitmproxy import master\nfrom mitmproxy import options\nfrom mitmproxy.addons import errorcheck\nfrom mitmproxy.addons import eventstore\nfrom mitmproxy.addons import intercept\nfrom mitmproxy.addons import readfile\nfrom mitmproxy.addons import view\nfrom mitmproxy.tools.console import consoleaddons\nfrom mitmproxy.tools.console import defaultkeys\nfrom mitmproxy.tools.console import keymap\nfrom mitmproxy.tools.console import palettes\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.tools.console import window\nfrom mitmproxy.utils import strutils\n\nT = TypeVar(\"T\", str, bytes)\n\n\nclass ConsoleMaster(master.Master):\n    def __init__(self, opts: options.Options) -> None:\n        super().__init__(opts)\n\n        self.view: view.View = view.View()\n        self.events = eventstore.EventStore()\n        self.events.sig_add.connect(self.sig_add_log)\n\n        self.stream_path = None\n        self.keymap = keymap.Keymap(self)\n        defaultkeys.map(self.keymap)\n        self.options.errored.connect(self.options_error)\n\n        self.addons.add(*addons.default_addons())\n        self.addons.add(\n            intercept.Intercept(),\n            self.view,\n            self.events,\n            readfile.ReadFile(),\n            consoleaddons.ConsoleAddon(self),\n            keymap.KeymapConfig(self),\n            errorcheck.ErrorCheck(repeat_errors_on_stderr=True),\n        )\n\n        self.window: window.Window | None = None\n\n    def __setattr__(self, name, value):\n        super().__setattr__(name, value)\n        signals.update_settings.send()\n\n    def options_error(self, exc) -> None:\n        signals.status_message.send(message=str(exc), expire=1)\n\n    def prompt_for_exit(self) -> None:\n        signals.status_prompt_onekey.send(\n            prompt=\"Quit\",\n            keys=[\n                (\"yes\", \"y\"),\n                (\"no\", \"n\"),\n            ],\n            callback=self.quit,\n        )\n\n    def sig_add_log(self, entry: log.LogEntry):\n        if log.log_tier(self.options.console_eventlog_verbosity) < log.log_tier(\n            entry.level\n        ):\n            return\n        if entry.level in (\"error\", \"warn\", \"alert\"):\n            signals.status_message.send(\n                message=(\n                    entry.level,\n                    f\"{entry.level.title()}: {str(entry.msg).lstrip()}\",\n                ),\n                expire=5,\n            )\n\n    def sig_call_in(self, seconds, callback):\n        def cb(*_):\n            return callback()\n\n        self.loop.set_alarm_in(seconds, cb)\n\n    @contextlib.contextmanager\n    def uistopped(self):\n        self.loop.stop()\n        try:\n            yield\n        finally:\n            self.loop.start()\n            self.loop.screen_size = None\n            self.loop.draw_screen()\n\n    def get_editor(self) -> str:\n        # based upon https://github.com/pallets/click/blob/main/src/click/_termui_impl.py\n        if m := os.environ.get(\"MITMPROXY_EDITOR\"):\n            return m\n        if m := os.environ.get(\"EDITOR\"):\n            return m\n        for editor in \"sensible-editor\", \"nano\", \"vim\":\n            if shutil.which(editor):\n                return editor\n        if os.name == \"nt\":\n            return \"notepad\"\n        else:\n            return \"vi\"\n\n    def get_hex_editor(self) -> str:\n        editors = [\"ghex\", \"bless\", \"hexedit\", \"hxd\", \"hexer\", \"hexcurse\"]\n        for editor in editors:\n            if shutil.which(editor):\n                return editor\n        return self.get_editor()\n\n    def spawn_editor(self, data: T) -> T:\n        text = isinstance(data, str)\n        fd, name = tempfile.mkstemp(\"\", \"mitmproxy\", text=text)\n        with_hexeditor = isinstance(data, bytes) and strutils.is_mostly_bin(data)\n        with open(fd, \"w\" if text else \"wb\") as f:\n            f.write(data)\n        if with_hexeditor:\n            c = self.get_hex_editor()\n        else:\n            c = self.get_editor()\n        cmd = shlex.split(c)\n        cmd.append(name)\n        with self.uistopped():\n            try:\n                subprocess.call(cmd)\n            except Exception:\n                signals.status_message.send(message=\"Can't start editor: %s\" % c)\n            else:\n                with open(name, \"r\" if text else \"rb\") as f:\n                    data = f.read()\n        os.unlink(name)\n        return data\n\n    def spawn_external_viewer(self, data, contenttype):\n        if contenttype:\n            contenttype = contenttype.split(\";\")[0]\n            ext = mimetypes.guess_extension(contenttype) or \"\"\n        else:\n            ext = \"\"\n        fd, name = tempfile.mkstemp(ext, \"mproxy\")\n        os.write(fd, data)\n        os.close(fd)\n\n        # read-only to remind the user that this is a view function\n        os.chmod(name, stat.S_IREAD)\n\n        # hm which one should get priority?\n        c = (\n            os.environ.get(\"MITMPROXY_EDITOR\")\n            or os.environ.get(\"PAGER\")\n            or os.environ.get(\"EDITOR\")\n        )\n        if not c:\n            c = \"less\"\n        cmd = shlex.split(c)\n        cmd.append(name)\n\n        with self.uistopped():\n            try:\n                subprocess.call(cmd, shell=False)\n            except Exception:\n                signals.status_message.send(\n                    message=\"Can't start external viewer: %s\" % \" \".join(c)\n                )\n        # add a small delay before deletion so that the file is not removed before being loaded by the viewer\n        t = threading.Timer(1.0, os.unlink, args=[name])\n        t.start()\n\n    def set_palette(self, *_) -> None:\n        self.ui.register_palette(\n            palettes.palettes[self.options.console_palette].palette(\n                self.options.console_palette_transparent\n            )\n        )\n        self.ui.clear()\n\n    def inject_key(self, key):\n        self.loop.process_input([key])\n\n    async def running(self) -> None:\n        if not sys.stdout.isatty():\n            print(\n                \"Error: mitmproxy's console interface requires a tty. \"\n                \"Please run mitmproxy in an interactive shell environment.\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        detected_encoding = urwid.detected_encoding.lower()\n        if os.name != \"nt\" and detected_encoding and \"utf\" not in detected_encoding:\n            print(\n                f\"mitmproxy expects a UTF-8 console environment, not {urwid.detected_encoding!r}. \"\n                f\"Set your LANG environment variable to something like en_US.UTF-8.\",\n                file=sys.stderr,\n            )\n            # Experimental (04/2022): We just don't exit here and see if/how that affects users.\n            # sys.exit(1)\n        urwid.set_encoding(\"utf8\")\n\n        signals.call_in.connect(self.sig_call_in)\n        self.ui = window.Screen()\n        self.ui.set_terminal_properties(256)\n        self.set_palette(None)\n        self.options.subscribe(\n            self.set_palette, [\"console_palette\", \"console_palette_transparent\"]\n        )\n\n        loop = asyncio.get_running_loop()\n        if isinstance(loop, getattr(asyncio, \"ProactorEventLoop\", tuple())):\n            # fix for https://bugs.python.org/issue37373\n            loop = AddThreadSelectorEventLoop(loop)  # type: ignore\n        self.loop = urwid.MainLoop(\n            urwid.SolidFill(\"x\"),\n            event_loop=urwid.AsyncioEventLoop(loop=loop),\n            screen=self.ui,\n            handle_mouse=self.options.console_mouse,\n        )\n        self.window = window.Window(self)\n        self.loop.widget = self.window\n        self.window.refresh()\n\n        self.loop.start()\n\n        await super().running()\n\n    async def done(self):\n        self.loop.stop()\n        await super().done()\n\n    def overlay(self, widget, **kwargs):\n        assert self.window\n        self.window.set_overlay(widget, **kwargs)\n\n    def switch_view(self, name):\n        assert self.window\n        self.window.push(name)\n\n    def quit(self, a):\n        if a != \"n\":\n            self.shutdown()\n", "mitmproxy/tools/console/flowlist.py": "from functools import lru_cache\n\nimport urwid\n\nimport mitmproxy.tools.console.master\nfrom mitmproxy.tools.console import common\nfrom mitmproxy.tools.console import layoutwidget\n\n\nclass FlowItem(urwid.WidgetWrap):\n    def __init__(self, master, flow):\n        self.master, self.flow = master, flow\n        w = self.get_text()\n        urwid.WidgetWrap.__init__(self, w)\n\n    def get_text(self):\n        cols, _ = self.master.ui.get_cols_rows()\n        layout = self.master.options.console_flowlist_layout\n        if layout == \"list\" or (layout == \"default\" and cols < 100):\n            render_mode = common.RenderMode.LIST\n        else:\n            render_mode = common.RenderMode.TABLE\n\n        return common.format_flow(\n            self.flow,\n            render_mode=render_mode,\n            focused=self.flow is self.master.view.focus.flow,\n            hostheader=self.master.options.showhost,\n        )\n\n    def selectable(self):\n        return True\n\n    def mouse_event(self, size, event, button, col, row, focus):\n        if event == \"mouse press\" and button == 1:\n            self.master.commands.execute(\"console.view.flow @focus\")\n            return True\n\n    def keypress(self, size, key):\n        return key\n\n\nclass FlowListWalker(urwid.ListWalker):\n    master: \"mitmproxy.tools.console.master.ConsoleMaster\"\n\n    def __init__(self, master):\n        self.master = master\n\n    def positions(self, reverse=False):\n        # The stub implementation of positions can go once this issue is resolved:\n        # https://github.com/urwid/urwid/issues/294\n        ret = range(self.master.view.get_length())\n        if reverse:\n            return reversed(ret)\n        return ret\n\n    def view_changed(self):\n        self._modified()\n        self._get.cache_clear()\n\n    def get_focus(self):\n        if not self.master.view.focus.flow:\n            return None, 0\n        f = FlowItem(self.master, self.master.view.focus.flow)\n        return f, self.master.view.focus.index\n\n    def set_focus(self, index):\n        if self.master.commands.execute(\"view.properties.inbounds %d\" % index):\n            self.master.view.focus.index = index\n\n    @lru_cache(maxsize=None)\n    def _get(self, pos: int) -> tuple[FlowItem | None, int | None]:\n        if not self.master.view.inbounds(pos):\n            return None, None\n        return FlowItem(self.master, self.master.view[pos]), pos\n\n    def get_next(self, pos):\n        return self._get(pos + 1)\n\n    def get_prev(self, pos):\n        return self._get(pos - 1)\n\n\nclass FlowListBox(urwid.ListBox, layoutwidget.LayoutWidget):\n    title = \"Flows\"\n    keyctx = \"flowlist\"\n\n    def __init__(self, master: \"mitmproxy.tools.console.master.ConsoleMaster\") -> None:\n        self.master: \"mitmproxy.tools.console.master.ConsoleMaster\" = master\n        super().__init__(FlowListWalker(master))\n        self.master.options.subscribe(\n            self.set_flowlist_layout, [\"console_flowlist_layout\"]\n        )\n\n    def keypress(self, size, key):\n        if key == \"m_start\":\n            self.master.commands.execute(\"view.focus.go 0\")\n        elif key == \"m_end\":\n            self.master.commands.execute(\"view.focus.go -1\")\n        elif key == \"m_select\":\n            self.master.commands.execute(\"console.view.flow @focus\")\n        return urwid.ListBox.keypress(self, size, key)\n\n    def view_changed(self):\n        self.body.view_changed()\n\n    def set_flowlist_layout(self, *_) -> None:\n        self.master.ui.clear()\n", "mitmproxy/tools/console/window.py": "import re\n\nimport urwid\n\nfrom mitmproxy import flow\nfrom mitmproxy.tools.console import commands\nfrom mitmproxy.tools.console import common\nfrom mitmproxy.tools.console import eventlog\nfrom mitmproxy.tools.console import flowlist\nfrom mitmproxy.tools.console import flowview\nfrom mitmproxy.tools.console import grideditor\nfrom mitmproxy.tools.console import help\nfrom mitmproxy.tools.console import keybindings\nfrom mitmproxy.tools.console import options\nfrom mitmproxy.tools.console import overlay\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.tools.console import statusbar\n\n\nclass StackWidget(urwid.Frame):\n    def __init__(self, window, widget, title, focus):\n        self.is_focused = focus\n        self.window = window\n\n        if title:\n            header = urwid.AttrWrap(\n                urwid.Text(title), \"heading\" if focus else \"heading_inactive\"\n            )\n        else:\n            header = None\n        super().__init__(widget, header=header)\n\n    def mouse_event(self, size, event, button, col, row, focus):\n        if event == \"mouse press\" and button == 1 and not self.is_focused:\n            self.window.switch()\n        return super().mouse_event(size, event, button, col, row, focus)\n\n    def keypress(self, size, key):\n        # Make sure that we don't propagate cursor events outside of the widget.\n        # Otherwise, in a horizontal layout, urwid's Pile would change the focused widget\n        # if we cannot scroll any further.\n        ret = super().keypress(size, key)\n        command = self._command_map[\n            ret\n        ]  # awkward as they don't implement a full dict api\n        if command and command.startswith(\"cursor\"):\n            return None\n        return ret\n\n\nclass WindowStack:\n    def __init__(self, master, base):\n        self.master = master\n        self.windows = dict(\n            flowlist=flowlist.FlowListBox(master),\n            flowview=flowview.FlowView(master),\n            commands=commands.Commands(master),\n            keybindings=keybindings.KeyBindings(master),\n            options=options.Options(master),\n            help=help.HelpView(master),\n            eventlog=eventlog.EventLog(master),\n            edit_focus_query=grideditor.QueryEditor(master),\n            edit_focus_cookies=grideditor.CookieEditor(master),\n            edit_focus_setcookies=grideditor.SetCookieEditor(master),\n            edit_focus_setcookie_attrs=grideditor.CookieAttributeEditor(master),\n            edit_focus_multipart_form=grideditor.RequestMultipartEditor(master),\n            edit_focus_urlencoded_form=grideditor.RequestUrlEncodedEditor(master),\n            edit_focus_path=grideditor.PathEditor(master),\n            edit_focus_request_headers=grideditor.RequestHeaderEditor(master),\n            edit_focus_response_headers=grideditor.ResponseHeaderEditor(master),\n        )\n        self.stack = [base]\n        self.overlay = None\n\n    def set_overlay(self, o, **kwargs):\n        self.overlay = overlay.SimpleOverlay(\n            self,\n            o,\n            self.top_widget(),\n            o.width,\n            **kwargs,\n        )\n\n    def top_window(self):\n        \"\"\"\n        The current top window, ignoring overlays.\n        \"\"\"\n        return self.windows[self.stack[-1]]\n\n    def top_widget(self):\n        \"\"\"\n        The current top widget - either a window or the active overlay.\n        \"\"\"\n        if self.overlay:\n            return self.overlay\n        return self.top_window()\n\n    def push(self, wname):\n        if self.stack[-1] == wname:\n            return\n        prev = self.top_window()\n        self.stack.append(wname)\n        self.call(\"layout_pushed\", prev)\n\n    def pop(self, *args, **kwargs):\n        \"\"\"\n        Pop off the stack, return True if we're already at the top.\n        \"\"\"\n        if not self.overlay and len(self.stack) == 1:\n            return True\n        self.call(\"layout_popping\")\n        if self.overlay:\n            self.overlay = None\n        else:\n            self.stack.pop()\n\n    def call(self, name, *args, **kwargs):\n        \"\"\"\n        Call a function on both the top window, and the overlay if there is\n        one. If the widget has a key_responder, we call the function on the\n        responder instead.\n        \"\"\"\n        getattr(self.top_window(), name)(*args, **kwargs)\n        if self.overlay:\n            getattr(self.overlay, name)(*args, **kwargs)\n\n\nclass Window(urwid.Frame):\n    def __init__(self, master):\n        self.statusbar = statusbar.StatusBar(master)\n        super().__init__(\n            None, header=None, footer=urwid.AttrWrap(self.statusbar, \"background\")\n        )\n        self.master = master\n        self.master.view.sig_view_refresh.connect(self.view_changed)\n        self.master.view.sig_view_add.connect(self.view_changed)\n        self.master.view.sig_view_remove.connect(self.view_changed)\n        self.master.view.sig_view_update.connect(self.view_changed)\n        self.master.view.focus.sig_change.connect(self.view_changed)\n        self.master.view.focus.sig_change.connect(self.focus_changed)\n\n        signals.focus.connect(self.sig_focus)\n        signals.flow_change.connect(self.flow_changed)\n        signals.pop_view_state.connect(self.pop)\n\n        self.master.options.subscribe(\n            self.configure, [\"console_layout\", \"console_layout_headers\"]\n        )\n        self.pane = 0\n        self.stacks = [WindowStack(master, \"flowlist\"), WindowStack(master, \"eventlog\")]\n\n    def focus_stack(self):\n        return self.stacks[self.pane]\n\n    def configure(self, options, updated):\n        self.refresh()\n\n    def refresh(self):\n        \"\"\"\n        Redraw the layout.\n        \"\"\"\n        c = self.master.options.console_layout\n        if c == \"single\":\n            self.pane = 0\n\n        def wrapped(idx):\n            widget = self.stacks[idx].top_widget()\n            if self.master.options.console_layout_headers:\n                title = self.stacks[idx].top_window().title\n            else:\n                title = None\n            return StackWidget(self, widget, title, self.pane == idx)\n\n        w = None\n        if c == \"single\":\n            w = wrapped(0)\n        elif c == \"vertical\":\n            w = urwid.Pile(\n                [wrapped(i) for i, s in enumerate(self.stacks)], focus_item=self.pane\n            )\n        else:\n            w = urwid.Columns(\n                [wrapped(i) for i, s in enumerate(self.stacks)],\n                dividechars=1,\n                focus_column=self.pane,\n            )\n\n        self.body = urwid.AttrWrap(w, \"background\")\n        signals.window_refresh.send()\n\n    def flow_changed(self, flow: flow.Flow) -> None:\n        if self.master.view.focus.flow:\n            if flow.id == self.master.view.focus.flow.id:\n                self.focus_changed()\n\n    def focus_changed(self, *args, **kwargs):\n        \"\"\"\n        Triggered when the focus changes - either when it's modified, or\n        when it changes to a different flow altogether.\n        \"\"\"\n        for i in self.stacks:\n            i.call(\"focus_changed\")\n\n    def view_changed(self, *args, **kwargs):\n        \"\"\"\n        Triggered when the view list has changed.\n        \"\"\"\n        for i in self.stacks:\n            i.call(\"view_changed\")\n\n    def set_overlay(self, o, **kwargs):\n        \"\"\"\n        Set an overlay on the currently focused stack.\n        \"\"\"\n        self.focus_stack().set_overlay(o, **kwargs)\n        self.refresh()\n\n    def push(self, wname):\n        \"\"\"\n        Push a window onto the currently focused stack.\n        \"\"\"\n        self.focus_stack().push(wname)\n        self.refresh()\n        self.view_changed()\n        self.focus_changed()\n\n    def pop(self) -> None:\n        \"\"\"\n        Pop a window from the currently focused stack. If there is only one\n        window on the stack, this prompts for exit.\n        \"\"\"\n        if self.focus_stack().pop():\n            self.master.prompt_for_exit()\n        else:\n            self.refresh()\n            self.view_changed()\n            self.focus_changed()\n\n    def stacks_sorted_by_focus(self):\n        \"\"\"\n        Returns:\n            self.stacks, with the focused stack first.\n        \"\"\"\n        stacks = self.stacks.copy()\n        stacks.insert(0, stacks.pop(self.pane))\n        return stacks\n\n    def current(self, keyctx):\n        \"\"\"\n        Returns the active widget with a matching key context, including overlays.\n        If multiple stacks have an active widget with a matching key context,\n        the currently focused stack is preferred.\n        \"\"\"\n        for s in self.stacks_sorted_by_focus():\n            t = s.top_widget()\n            if t.keyctx == keyctx:\n                return t\n\n    def current_window(self, keyctx):\n        \"\"\"\n        Returns the active window with a matching key context, ignoring overlays.\n        If multiple stacks have an active widget with a matching key context,\n        the currently focused stack is preferred.\n        \"\"\"\n        for s in self.stacks_sorted_by_focus():\n            t = s.top_window()\n            if t.keyctx == keyctx:\n                return t\n\n    def sig_focus(self, section):\n        self.focus_position = section\n\n    def switch(self):\n        \"\"\"\n        Switch between the two panes.\n        \"\"\"\n        if self.master.options.console_layout == \"single\":\n            self.pane = 0\n        else:\n            self.pane = (self.pane + 1) % len(self.stacks)\n        self.refresh()\n\n    def mouse_event(self, *args, **kwargs):\n        # args: (size, event, button, col, row)\n        k = super().mouse_event(*args, **kwargs)\n        if not k:\n            if args[1] == \"mouse drag\":\n                signals.status_message.send(\n                    message=\"Hold down fn, shift, alt or ctrl to select text or use the --set console_mouse=false parameter.\",\n                    expire=1,\n                )\n            elif args[1] == \"mouse press\" and args[2] == 4:\n                self.keypress(args[0], \"up\")\n            elif args[1] == \"mouse press\" and args[2] == 5:\n                self.keypress(args[0], \"down\")\n            else:\n                return False\n            return True\n\n    def keypress(self, size, k):\n        k = super().keypress(size, k)\n        if k:\n            return self.master.keymap.handle(self.focus_stack().top_widget().keyctx, k)\n\n\nclass Screen(urwid.raw_display.Screen):\n    def write(self, data):\n        if common.IS_WINDOWS_OR_WSL:\n            # replace urwid's SI/SO, which produce artifacts under WSL.\n            # at some point we may figure out what they actually do.\n            data = re.sub(\"[\\x0e\\x0f]\", \"\", data)\n        super().write(data)\n", "mitmproxy/tools/console/consoleaddons.py": "import csv\nimport logging\nfrom collections.abc import Sequence\n\nimport mitmproxy.types\nfrom mitmproxy import command\nfrom mitmproxy import command_lexer\nfrom mitmproxy import contentviews\nfrom mitmproxy import ctx\nfrom mitmproxy import dns\nfrom mitmproxy import exceptions\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy import log\nfrom mitmproxy import tcp\nfrom mitmproxy import udp\nfrom mitmproxy.log import ALERT\nfrom mitmproxy.tools.console import keymap\nfrom mitmproxy.tools.console import overlay\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.utils import strutils\n\nlogger = logging.getLogger(__name__)\n\n\nconsole_palettes = [\n    \"lowlight\",\n    \"lowdark\",\n    \"light\",\n    \"dark\",\n    \"solarized_light\",\n    \"solarized_dark\",\n]\nview_orders = [\n    \"time\",\n    \"method\",\n    \"url\",\n    \"size\",\n]\nconsole_layouts = [\n    \"single\",\n    \"vertical\",\n    \"horizontal\",\n]\n\nconsole_flowlist_layout = [\"default\", \"table\", \"list\"]\n\n\nclass ConsoleAddon:\n    \"\"\"\n    An addon that exposes console-specific commands, and hooks into required\n    events.\n    \"\"\"\n\n    def __init__(self, master):\n        self.master = master\n        self.started = False\n\n    def load(self, loader):\n        loader.add_option(\n            \"console_default_contentview\",\n            str,\n            \"auto\",\n            \"The default content view mode.\",\n            choices=[i.name.lower() for i in contentviews.views],\n        )\n        loader.add_option(\n            \"console_eventlog_verbosity\",\n            str,\n            \"info\",\n            \"EventLog verbosity.\",\n            choices=log.LogLevels,\n        )\n        loader.add_option(\n            \"console_layout\",\n            str,\n            \"single\",\n            \"Console layout.\",\n            choices=sorted(console_layouts),\n        )\n        loader.add_option(\n            \"console_layout_headers\",\n            bool,\n            True,\n            \"Show layout component headers\",\n        )\n        loader.add_option(\n            \"console_focus_follow\", bool, False, \"Focus follows new flows.\"\n        )\n        loader.add_option(\n            \"console_palette\",\n            str,\n            \"solarized_dark\",\n            \"Color palette.\",\n            choices=sorted(console_palettes),\n        )\n        loader.add_option(\n            \"console_palette_transparent\",\n            bool,\n            True,\n            \"Set transparent background for palette.\",\n        )\n        loader.add_option(\"console_mouse\", bool, True, \"Console mouse interaction.\")\n        loader.add_option(\n            \"console_flowlist_layout\",\n            str,\n            \"default\",\n            \"Set the flowlist layout\",\n            choices=sorted(console_flowlist_layout),\n        )\n        loader.add_option(\n            \"console_strip_trailing_newlines\",\n            bool,\n            False,\n            \"Strip trailing newlines from edited request/response bodies.\",\n        )\n\n    @command.command(\"console.layout.options\")\n    def layout_options(self) -> Sequence[str]:\n        \"\"\"\n        Returns the available options for the console_layout option.\n        \"\"\"\n        return [\"single\", \"vertical\", \"horizontal\"]\n\n    @command.command(\"console.layout.cycle\")\n    def layout_cycle(self) -> None:\n        \"\"\"\n        Cycle through the console layout options.\n        \"\"\"\n        opts = self.layout_options()\n        off = self.layout_options().index(ctx.options.console_layout)\n        ctx.options.update(console_layout=opts[(off + 1) % len(opts)])\n\n    @command.command(\"console.panes.next\")\n    def panes_next(self) -> None:\n        \"\"\"\n        Go to the next layout pane.\n        \"\"\"\n        self.master.window.switch()\n\n    @command.command(\"console.panes.prev\")\n    def panes_prev(self) -> None:\n        \"\"\"\n        Go to the previous layout pane.\n        \"\"\"\n        return self.panes_next()\n\n    @command.command(\"console.options.reset.focus\")\n    def options_reset_current(self) -> None:\n        \"\"\"\n        Reset the current option in the options editor.\n        \"\"\"\n        fv = self.master.window.current(\"options\")\n        if not fv:\n            raise exceptions.CommandError(\"Not viewing options.\")\n        self.master.commands.call_strings(\"options.reset.one\", [fv.current_name()])\n\n    @command.command(\"console.nav.start\")\n    def nav_start(self) -> None:\n        \"\"\"\n        Go to the start of a list or scrollable.\n        \"\"\"\n        self.master.inject_key(\"m_start\")\n\n    @command.command(\"console.nav.end\")\n    def nav_end(self) -> None:\n        \"\"\"\n        Go to the end of a list or scrollable.\n        \"\"\"\n        self.master.inject_key(\"m_end\")\n\n    @command.command(\"console.nav.next\")\n    def nav_next(self) -> None:\n        \"\"\"\n        Go to the next navigatable item.\n        \"\"\"\n        self.master.inject_key(\"m_next\")\n\n    @command.command(\"console.nav.select\")\n    def nav_select(self) -> None:\n        \"\"\"\n        Select a navigable item for viewing or editing.\n        \"\"\"\n        self.master.inject_key(\"m_select\")\n\n    @command.command(\"console.nav.up\")\n    def nav_up(self) -> None:\n        \"\"\"\n        Go up.\n        \"\"\"\n        self.master.inject_key(\"up\")\n\n    @command.command(\"console.nav.down\")\n    def nav_down(self) -> None:\n        \"\"\"\n        Go down.\n        \"\"\"\n        self.master.inject_key(\"down\")\n\n    @command.command(\"console.nav.pageup\")\n    def nav_pageup(self) -> None:\n        \"\"\"\n        Go up.\n        \"\"\"\n        self.master.inject_key(\"page up\")\n\n    @command.command(\"console.nav.pagedown\")\n    def nav_pagedown(self) -> None:\n        \"\"\"\n        Go down.\n        \"\"\"\n        self.master.inject_key(\"page down\")\n\n    @command.command(\"console.nav.left\")\n    def nav_left(self) -> None:\n        \"\"\"\n        Go left.\n        \"\"\"\n        self.master.inject_key(\"left\")\n\n    @command.command(\"console.nav.right\")\n    def nav_right(self) -> None:\n        \"\"\"\n        Go right.\n        \"\"\"\n        self.master.inject_key(\"right\")\n\n    @command.command(\"console.choose\")\n    def console_choose(\n        self,\n        prompt: str,\n        choices: Sequence[str],\n        cmd: mitmproxy.types.Cmd,\n        *args: mitmproxy.types.CmdArgs,\n    ) -> None:\n        \"\"\"\n        Prompt the user to choose from a specified list of strings, then\n        invoke another command with all occurrences of {choice} replaced by\n        the choice the user made.\n        \"\"\"\n\n        def callback(opt):\n            # We're now outside of the call context...\n            repl = [arg.replace(\"{choice}\", opt) for arg in args]\n            try:\n                self.master.commands.call_strings(cmd, repl)\n            except exceptions.CommandError as e:\n                logger.error(str(e))\n\n        self.master.overlay(overlay.Chooser(self.master, prompt, choices, \"\", callback))\n\n    @command.command(\"console.choose.cmd\")\n    def console_choose_cmd(\n        self,\n        prompt: str,\n        choicecmd: mitmproxy.types.Cmd,\n        subcmd: mitmproxy.types.Cmd,\n        *args: mitmproxy.types.CmdArgs,\n    ) -> None:\n        \"\"\"\n        Prompt the user to choose from a list of strings returned by a\n        command, then invoke another command with all occurrences of {choice}\n        replaced by the choice the user made.\n        \"\"\"\n        choices = ctx.master.commands.execute(choicecmd)\n\n        def callback(opt):\n            # We're now outside of the call context...\n            repl = [arg.replace(\"{choice}\", opt) for arg in args]\n            try:\n                self.master.commands.call_strings(subcmd, repl)\n            except exceptions.CommandError as e:\n                logger.error(str(e))\n\n        self.master.overlay(overlay.Chooser(self.master, prompt, choices, \"\", callback))\n\n    @command.command(\"console.command\")\n    def console_command(self, *command_str: str) -> None:\n        \"\"\"\n        Prompt the user to edit a command with a (possibly empty) starting value.\n        \"\"\"\n        quoted = \" \".join(command_lexer.quote(x) for x in command_str)\n        if quoted:\n            quoted += \" \"\n        signals.status_prompt_command.send(partial=quoted)\n\n    @command.command(\"console.command.set\")\n    def console_command_set(self, option_name: str) -> None:\n        \"\"\"\n        Prompt the user to set an option.\n        \"\"\"\n        option_value = getattr(self.master.options, option_name, None) or \"\"\n        set_command = f\"set {option_name} {option_value!r}\"\n        cursor = len(set_command) - 1\n        signals.status_prompt_command.send(partial=set_command, cursor=cursor)\n\n    @command.command(\"console.view.keybindings\")\n    def view_keybindings(self) -> None:\n        \"\"\"View the commands list.\"\"\"\n        self.master.switch_view(\"keybindings\")\n\n    @command.command(\"console.view.commands\")\n    def view_commands(self) -> None:\n        \"\"\"View the commands list.\"\"\"\n        self.master.switch_view(\"commands\")\n\n    @command.command(\"console.view.options\")\n    def view_options(self) -> None:\n        \"\"\"View the options editor.\"\"\"\n        self.master.switch_view(\"options\")\n\n    @command.command(\"console.view.eventlog\")\n    def view_eventlog(self) -> None:\n        \"\"\"View the event log.\"\"\"\n        self.master.switch_view(\"eventlog\")\n\n    @command.command(\"console.view.help\")\n    def view_help(self) -> None:\n        \"\"\"View help.\"\"\"\n        self.master.switch_view(\"help\")\n\n    @command.command(\"console.view.flow\")\n    def view_flow(self, flow: flow.Flow) -> None:\n        \"\"\"View a flow.\"\"\"\n        if isinstance(flow, (http.HTTPFlow, tcp.TCPFlow, udp.UDPFlow, dns.DNSFlow)):\n            self.master.switch_view(\"flowview\")\n        else:\n            logger.warning(f\"No detail view for {type(flow).__name__}.\")\n\n    @command.command(\"console.exit\")\n    def exit(self) -> None:\n        \"\"\"Exit mitmproxy.\"\"\"\n        self.master.shutdown()\n\n    @command.command(\"console.view.pop\")\n    def view_pop(self) -> None:\n        \"\"\"\n        Pop a view off the console stack. At the top level, this prompts the\n        user to exit mitmproxy.\n        \"\"\"\n        signals.pop_view_state.send()\n\n    @command.command(\"console.bodyview\")\n    @command.argument(\"part\", type=mitmproxy.types.Choice(\"console.bodyview.options\"))\n    def bodyview(self, flow: flow.Flow, part: str) -> None:\n        \"\"\"\n        Spawn an external viewer for a flow request or response body based\n        on the detected MIME type. We use the mailcap system to find the\n        correct viewer, and fall back to the programs in $PAGER or $EDITOR\n        if necessary.\n        \"\"\"\n        fpart = getattr(flow, part, None)\n        if not fpart:\n            raise exceptions.CommandError(\n                \"Part must be either request or response, not %s.\" % part\n            )\n        t = fpart.headers.get(\"content-type\")\n        content = fpart.get_content(strict=False)\n        if not content:\n            raise exceptions.CommandError(\"No content to view.\")\n        self.master.spawn_external_viewer(content, t)\n\n    @command.command(\"console.bodyview.options\")\n    def bodyview_options(self) -> Sequence[str]:\n        \"\"\"\n        Possible parts for console.bodyview.\n        \"\"\"\n        return [\"request\", \"response\"]\n\n    @command.command(\"console.edit.focus.options\")\n    def edit_focus_options(self) -> Sequence[str]:\n        \"\"\"\n        Possible components for console.edit.focus.\n        \"\"\"\n        flow = self.master.view.focus.flow\n        focus_options = []\n\n        if flow is None:\n            raise exceptions.CommandError(\"No flow selected.\")\n        elif isinstance(flow, tcp.TCPFlow):\n            focus_options = [\"tcp-message\"]\n        elif isinstance(flow, udp.UDPFlow):\n            focus_options = [\"udp-message\"]\n        elif isinstance(flow, http.HTTPFlow):\n            focus_options = [\n                \"cookies\",\n                \"urlencoded form\",\n                \"multipart form\",\n                \"path\",\n                \"method\",\n                \"query\",\n                \"reason\",\n                \"request-headers\",\n                \"response-headers\",\n                \"request-body\",\n                \"response-body\",\n                \"status_code\",\n                \"set-cookies\",\n                \"url\",\n            ]\n            if flow.websocket:\n                focus_options.append(\"websocket-message\")\n        elif isinstance(flow, dns.DNSFlow):\n            raise exceptions.CommandError(\n                \"Cannot edit DNS flows yet, please submit a patch.\"\n            )\n\n        return focus_options\n\n    @command.command(\"console.edit.focus\")\n    @command.argument(\n        \"flow_part\", type=mitmproxy.types.Choice(\"console.edit.focus.options\")\n    )\n    def edit_focus(self, flow_part: str) -> None:\n        \"\"\"\n        Edit a component of the currently focused flow.\n        \"\"\"\n        flow = self.master.view.focus.flow\n        # This shouldn't be necessary once this command is \"console.edit @focus\",\n        # but for now it is.\n        if not flow:\n            raise exceptions.CommandError(\"No flow selected.\")\n        flow.backup()\n\n        require_dummy_response = (\n            flow_part in (\"response-headers\", \"response-body\", \"set-cookies\")\n            and flow.response is None\n        )\n        if require_dummy_response:\n            flow.response = http.Response.make()\n        if flow_part == \"cookies\":\n            self.master.switch_view(\"edit_focus_cookies\")\n        elif flow_part == \"urlencoded form\":\n            self.master.switch_view(\"edit_focus_urlencoded_form\")\n        elif flow_part == \"multipart form\":\n            self.master.switch_view(\"edit_focus_multipart_form\")\n        elif flow_part == \"path\":\n            self.master.switch_view(\"edit_focus_path\")\n        elif flow_part == \"query\":\n            self.master.switch_view(\"edit_focus_query\")\n        elif flow_part == \"request-headers\":\n            self.master.switch_view(\"edit_focus_request_headers\")\n        elif flow_part == \"response-headers\":\n            self.master.switch_view(\"edit_focus_response_headers\")\n        elif flow_part in (\"request-body\", \"response-body\"):\n            if flow_part == \"request-body\":\n                message = flow.request\n            else:\n                message = flow.response\n            c = self.master.spawn_editor(message.get_content(strict=False) or b\"\")\n            # Many editors make it hard to save a file without a terminating\n            # newline on the last line. When editing message bodies, this can\n            # cause problems. We strip trailing newlines by default, but this\n            # behavior is configurable.\n            if self.master.options.console_strip_trailing_newlines:\n                message.content = c.rstrip(b\"\\n\")\n            else:\n                message.content = c\n        elif flow_part == \"set-cookies\":\n            self.master.switch_view(\"edit_focus_setcookies\")\n        elif flow_part == \"url\":\n            url = flow.request.url.encode()\n            edited_url = self.master.spawn_editor(url)\n            url = edited_url.rstrip(b\"\\n\")\n            flow.request.url = url.decode()\n        elif flow_part in [\"method\", \"status_code\", \"reason\"]:\n            self.master.commands.call_strings(\n                \"console.command\", [\"flow.set\", \"@focus\", flow_part]\n            )\n        elif flow_part in [\"tcp-message\", \"udp-message\"]:\n            message = flow.messages[-1]\n            c = self.master.spawn_editor(message.content or b\"\")\n            message.content = c.rstrip(b\"\\n\")\n        elif flow_part == \"websocket-message\":\n            message = flow.websocket.messages[-1]\n            c = self.master.spawn_editor(message.content or b\"\")\n            message.content = c.rstrip(b\"\\n\")\n\n    def _grideditor(self):\n        gewidget = self.master.window.current(\"grideditor\")\n        if not gewidget:\n            raise exceptions.CommandError(\"Not in a grideditor.\")\n        return gewidget.key_responder()\n\n    @command.command(\"console.grideditor.add\")\n    def grideditor_add(self) -> None:\n        \"\"\"\n        Add a row after the cursor.\n        \"\"\"\n        self._grideditor().cmd_add()\n\n    @command.command(\"console.grideditor.insert\")\n    def grideditor_insert(self) -> None:\n        \"\"\"\n        Insert a row before the cursor.\n        \"\"\"\n        self._grideditor().cmd_insert()\n\n    @command.command(\"console.grideditor.delete\")\n    def grideditor_delete(self) -> None:\n        \"\"\"\n        Delete row\n        \"\"\"\n        self._grideditor().cmd_delete()\n\n    @command.command(\"console.grideditor.load\")\n    def grideditor_load(self, path: mitmproxy.types.Path) -> None:\n        \"\"\"\n        Read a file into the currrent cell.\n        \"\"\"\n        self._grideditor().cmd_read_file(path)\n\n    @command.command(\"console.grideditor.load_escaped\")\n    def grideditor_load_escaped(self, path: mitmproxy.types.Path) -> None:\n        \"\"\"\n        Read a file containing a Python-style escaped string into the\n        currrent cell.\n        \"\"\"\n        self._grideditor().cmd_read_file_escaped(path)\n\n    @command.command(\"console.grideditor.save\")\n    def grideditor_save(self, path: mitmproxy.types.Path) -> None:\n        \"\"\"\n        Save data to file as a CSV.\n        \"\"\"\n        rows = self._grideditor().value\n        try:\n            with open(path, \"w\", newline=\"\", encoding=\"utf8\") as fp:\n                writer = csv.writer(fp)\n                for row in rows:\n                    writer.writerow(\n                        [strutils.always_str(x) or \"\" for x in row]  # type: ignore\n                    )\n            logger.log(ALERT, \"Saved %s rows as CSV.\" % (len(rows)))\n        except OSError as e:\n            logger.error(str(e))\n\n    @command.command(\"console.grideditor.editor\")\n    def grideditor_editor(self) -> None:\n        \"\"\"\n        Spawn an external editor on the current cell.\n        \"\"\"\n        self._grideditor().cmd_spawn_editor()\n\n    @command.command(\"console.flowview.mode.set\")\n    @command.argument(\n        \"mode\", type=mitmproxy.types.Choice(\"console.flowview.mode.options\")\n    )\n    def flowview_mode_set(self, mode: str) -> None:\n        \"\"\"\n        Set the display mode for the current flow view.\n        \"\"\"\n        fv = self.master.window.current_window(\"flowview\")\n        if not fv:\n            raise exceptions.CommandError(\"Not viewing a flow.\")\n        idx = fv.body.tab_offset\n\n        if mode not in [i.name.lower() for i in contentviews.views]:\n            raise exceptions.CommandError(\"Invalid flowview mode.\")\n\n        try:\n            self.master.commands.call_strings(\n                \"view.settings.setval\", [\"@focus\", f\"flowview_mode_{idx}\", mode]\n            )\n        except exceptions.CommandError as e:\n            logger.error(str(e))\n\n    @command.command(\"console.flowview.mode.options\")\n    def flowview_mode_options(self) -> Sequence[str]:\n        \"\"\"\n        Returns the valid options for the flowview mode.\n        \"\"\"\n        return [i.name.lower() for i in contentviews.views]\n\n    @command.command(\"console.flowview.mode\")\n    def flowview_mode(self) -> str:\n        \"\"\"\n        Get the display mode for the current flow view.\n        \"\"\"\n        fv = self.master.window.current_window(\"flowview\")\n        if not fv:\n            raise exceptions.CommandError(\"Not viewing a flow.\")\n        idx = fv.body.tab_offset\n\n        return self.master.commands.call_strings(\n            \"view.settings.getval\",\n            [\n                \"@focus\",\n                f\"flowview_mode_{idx}\",\n                self.master.options.console_default_contentview,\n            ],\n        )\n\n    @command.command(\"console.key.contexts\")\n    def key_contexts(self) -> Sequence[str]:\n        \"\"\"\n        The available contexts for key binding.\n        \"\"\"\n        return list(sorted(keymap.Contexts))\n\n    @command.command(\"console.key.bind\")\n    def key_bind(\n        self,\n        contexts: Sequence[str],\n        key: str,\n        cmd: mitmproxy.types.Cmd,\n        *args: mitmproxy.types.CmdArgs,\n    ) -> None:\n        \"\"\"\n        Bind a shortcut key.\n        \"\"\"\n        try:\n            self.master.keymap.add(key, cmd + \" \" + \" \".join(args), contexts, \"\")\n        except ValueError as v:\n            raise exceptions.CommandError(v)\n\n    @command.command(\"console.key.unbind\")\n    def key_unbind(self, contexts: Sequence[str], key: str) -> None:\n        \"\"\"\n        Un-bind a shortcut key.\n        \"\"\"\n        try:\n            self.master.keymap.remove(key, contexts)\n        except ValueError as v:\n            raise exceptions.CommandError(v)\n\n    def _keyfocus(self):\n        kwidget = self.master.window.current(\"keybindings\")\n        if not kwidget:\n            raise exceptions.CommandError(\"Not viewing key bindings.\")\n        f = kwidget.get_focused_binding()\n        if not f:\n            raise exceptions.CommandError(\"No key binding focused\")\n        return f\n\n    @command.command(\"console.key.unbind.focus\")\n    def key_unbind_focus(self) -> None:\n        \"\"\"\n        Un-bind the shortcut key currently focused in the key binding viewer.\n        \"\"\"\n        b = self._keyfocus()\n        try:\n            self.master.keymap.remove(b.key, b.contexts)\n        except ValueError as v:\n            raise exceptions.CommandError(v)\n\n    @command.command(\"console.key.execute.focus\")\n    def key_execute_focus(self) -> None:\n        \"\"\"\n        Execute the currently focused key binding.\n        \"\"\"\n        b = self._keyfocus()\n        self.console_command(b.command)\n\n    @command.command(\"console.key.edit.focus\")\n    def key_edit_focus(self) -> None:\n        \"\"\"\n        Execute the currently focused key binding.\n        \"\"\"\n        b = self._keyfocus()\n        self.console_command(\n            \"console.key.bind\",\n            \",\".join(b.contexts),\n            b.key,\n            b.command,\n        )\n\n    def running(self):\n        self.started = True\n\n    def update(self, flows) -> None:\n        if not flows:\n            signals.update_settings.send()\n        for f in flows:\n            signals.flow_change.send(flow=f)\n", "mitmproxy/tools/console/flowdetailview.py": "import urwid\n\nimport mitmproxy.flow\nfrom mitmproxy import http\nfrom mitmproxy.tools.console import common\nfrom mitmproxy.tools.console import searchable\nfrom mitmproxy.utils import human\nfrom mitmproxy.utils import strutils\n\n\ndef maybe_timestamp(base, attr):\n    if base is not None and getattr(base, attr):\n        return human.format_timestamp_with_milli(getattr(base, attr))\n    else:\n        # in mitmdump we serialize before a connection is closed.\n        # loading those flows at a later point shouldn't display \"active\".\n        # We also use a ndash (and not a regular dash) so that it is sorted\n        # after other timestamps. We may need to revisit that in the future if it turns out\n        # to render ugly in consoles.\n        return \"\u2013\"\n\n\ndef flowdetails(state, flow: mitmproxy.flow.Flow):\n    text = []\n\n    sc = flow.server_conn\n    cc = flow.client_conn\n    req: http.Request | None\n    resp: http.Response | None\n    if isinstance(flow, http.HTTPFlow):\n        req = flow.request\n        resp = flow.response\n    else:\n        req = None\n        resp = None\n    metadata = flow.metadata\n    comment = flow.comment\n\n    if comment:\n        text.append(urwid.Text([(\"head\", \"Comment: \"), (\"text\", comment)]))\n\n    if metadata is not None and len(metadata) > 0:\n        parts = [(str(k), repr(v)) for k, v in metadata.items()]\n        text.append(urwid.Text([(\"head\", \"Metadata:\")]))\n        text.extend(common.format_keyvals(parts, indent=4))\n\n    if sc is not None and sc.peername:\n        text.append(urwid.Text([(\"head\", \"Server Connection:\")]))\n        parts = [\n            (\"Address\", human.format_address(sc.address)),\n        ]\n        if sc.peername:\n            parts.append((\"Resolved Address\", human.format_address(sc.peername)))\n        if resp:\n            parts.append((\"HTTP Version\", resp.http_version))\n        if sc.alpn:\n            parts.append((\"ALPN\", strutils.bytes_to_escaped_str(sc.alpn)))\n\n        text.extend(common.format_keyvals(parts, indent=4))\n\n        if sc.certificate_list:\n            c = sc.certificate_list[0]\n            text.append(urwid.Text([(\"head\", \"Server Certificate:\")]))\n            parts = [\n                (\"Type\", \"%s, %s bits\" % c.keyinfo),\n                (\"SHA256 digest\", c.fingerprint().hex(\" \")),\n                (\"Valid from\", str(c.notbefore)),\n                (\"Valid to\", str(c.notafter)),\n                (\"Serial\", str(c.serial)),\n                (\n                    \"Subject\",\n                    urwid.Pile(\n                        common.format_keyvals(c.subject, key_format=\"highlight\")\n                    ),\n                ),\n                (\n                    \"Issuer\",\n                    urwid.Pile(common.format_keyvals(c.issuer, key_format=\"highlight\")),\n                ),\n            ]\n\n            if c.altnames:\n                parts.append((\"Alt names\", \", \".join(str(x.value) for x in c.altnames)))\n            text.extend(common.format_keyvals(parts, indent=4))\n\n    if cc is not None:\n        text.append(urwid.Text([(\"head\", \"Client Connection:\")]))\n\n        parts = [\n            (\"Address\", human.format_address(cc.peername)),\n        ]\n        if req:\n            parts.append((\"HTTP Version\", req.http_version))\n        if cc.tls_version:\n            parts.append((\"TLS Version\", cc.tls_version))\n        if cc.sni:\n            parts.append((\"Server Name Indication\", cc.sni))\n        if cc.cipher:\n            parts.append((\"Cipher Name\", cc.cipher))\n        if cc.alpn:\n            parts.append((\"ALPN\", strutils.bytes_to_escaped_str(cc.alpn)))\n\n        text.extend(common.format_keyvals(parts, indent=4))\n\n    parts = []\n\n    if cc is not None and cc.timestamp_start:\n        parts.append(\n            (\"Client conn. established\", maybe_timestamp(cc, \"timestamp_start\"))\n        )\n        if cc.tls_established:\n            parts.append(\n                (\n                    \"Client conn. TLS handshake\",\n                    maybe_timestamp(cc, \"timestamp_tls_setup\"),\n                )\n            )\n        parts.append((\"Client conn. closed\", maybe_timestamp(cc, \"timestamp_end\")))\n\n    if sc is not None and sc.timestamp_start:\n        parts.append((\"Server conn. initiated\", maybe_timestamp(sc, \"timestamp_start\")))\n        parts.append(\n            (\"Server conn. TCP handshake\", maybe_timestamp(sc, \"timestamp_tcp_setup\"))\n        )\n        if sc.tls_established:\n            parts.append(\n                (\n                    \"Server conn. TLS handshake\",\n                    maybe_timestamp(sc, \"timestamp_tls_setup\"),\n                )\n            )\n        parts.append((\"Server conn. closed\", maybe_timestamp(sc, \"timestamp_end\")))\n\n    if req is not None and req.timestamp_start:\n        parts.append((\"First request byte\", maybe_timestamp(req, \"timestamp_start\")))\n        parts.append((\"Request complete\", maybe_timestamp(req, \"timestamp_end\")))\n\n    if resp is not None and resp.timestamp_start:\n        parts.append((\"First response byte\", maybe_timestamp(resp, \"timestamp_start\")))\n        parts.append((\"Response complete\", maybe_timestamp(resp, \"timestamp_end\")))\n\n    if parts:\n        # sort operations by timestamp\n        parts = sorted(parts, key=lambda p: p[1])\n\n        text.append(urwid.Text([(\"head\", \"Timing:\")]))\n        text.extend(common.format_keyvals(parts, indent=4))\n\n    return searchable.Searchable(text)\n", "mitmproxy/tools/console/help.py": "import urwid\n\nfrom mitmproxy import flowfilter\nfrom mitmproxy.tools.console import common\nfrom mitmproxy.tools.console import layoutwidget\nfrom mitmproxy.tools.console import tabs\n\n\nclass CListBox(urwid.ListBox):\n    def __init__(self, contents):\n        self.length = len(contents)\n        contents = contents[:] + [urwid.Text([\"\\n\"])] * 5\n        super().__init__(contents)\n\n    def keypress(self, size, key):\n        if key == \"m_end\":\n            self.set_focus(self.length - 1)\n        elif key == \"m_start\":\n            self.set_focus(0)\n        else:\n            return super().keypress(size, key)\n\n\nclass HelpView(tabs.Tabs, layoutwidget.LayoutWidget):\n    title = \"Help\"\n    keyctx = \"help\"\n\n    def __init__(self, master):\n        self.master = master\n        self.helpctx = \"\"\n        super().__init__(\n            [\n                [self.keybindings_title, self.keybindings],\n                [self.filtexp_title, self.filtexp],\n            ]\n        )\n\n    def keybindings_title(self):\n        return \"Key Bindings\"\n\n    def format_keys(self, binds):\n        kvs = []\n        for b in binds:\n            k = b.key\n            if b.key == \" \":\n                k = \"space\"\n            kvs.append((k, b.help or b.command))\n        return common.format_keyvals(kvs)\n\n    def keybindings(self):\n        text = [urwid.Text([(\"title\", \"Common Keybindings\")])]\n\n        text.extend(self.format_keys(self.master.keymap.list(\"commonkey\")))\n\n        text.append(urwid.Text([\"\\n\", (\"title\", \"Keybindings for this view\")]))\n        if self.helpctx:\n            text.extend(self.format_keys(self.master.keymap.list(self.helpctx)))\n\n        text.append(\n            urwid.Text(\n                [\n                    \"\\n\",\n                    (\"title\", \"Global Keybindings\"),\n                ]\n            )\n        )\n\n        text.extend(self.format_keys(self.master.keymap.list(\"global\")))\n\n        return CListBox(text)\n\n    def filtexp_title(self):\n        return \"Filter Expressions\"\n\n    def filtexp(self):\n        text = []\n        text.extend(common.format_keyvals(flowfilter.help, indent=4))\n        text.append(\n            urwid.Text(\n                [\n                    \"\\n\",\n                    (\"text\", \"    Regexes are Python-style.\\n\"),\n                    (\"text\", \"    Regexes can be specified as quoted strings.\\n\"),\n                    (\n                        \"text\",\n                        '    Header matching (~h, ~hq, ~hs) is against a string of the form \"name: value\".\\n',\n                    ),\n                    (\n                        \"text\",\n                        \"    Expressions with no operators are regex matches against URL.\\n\",\n                    ),\n                    (\"text\", \"    Default binary operator is &.\\n\"),\n                    (\"head\", \"\\n    Examples:\\n\"),\n                ]\n            )\n        )\n        examples = [\n            (r\"google\\.com\", r\"Url containing \\\"google.com\"),\n            (\"~q ~b test\", r\"Requests where body contains \\\"test\\\"\"),\n            (\n                r\"!(~q & ~t \\\"text/html\\\")\",\n                \"Anything but requests with a text/html content type.\",\n            ),\n        ]\n        text.extend(common.format_keyvals(examples, indent=4))\n        return CListBox(text)\n\n    def layout_pushed(self, prev):\n        \"\"\"\n        We are just about to push a window onto the stack.\n        \"\"\"\n        self.helpctx = prev.keyctx\n        self.show()\n", "mitmproxy/tools/console/keymap.py": "import logging\nimport os\nfrom collections import defaultdict\nfrom collections.abc import Sequence\nfrom functools import cache\n\nimport ruamel.yaml.error\n\nimport mitmproxy.types\nfrom mitmproxy import command\nfrom mitmproxy import ctx\nfrom mitmproxy import exceptions\nfrom mitmproxy.tools.console import commandexecutor\nfrom mitmproxy.tools.console import signals\n\n\nclass KeyBindingError(Exception):\n    pass\n\n\nContexts = {\n    \"chooser\",\n    \"commands\",\n    \"commonkey\",\n    \"dataviewer\",\n    \"eventlog\",\n    \"flowlist\",\n    \"flowview\",\n    \"global\",\n    \"grideditor\",\n    \"help\",\n    \"keybindings\",\n    \"options\",\n}\n\n\nnavkeys = [\n    \"m_start\",\n    \"m_end\",\n    \"m_next\",\n    \"m_select\",\n    \"up\",\n    \"down\",\n    \"page_up\",\n    \"page_down\",\n    \"left\",\n    \"right\",\n]\n\n\nclass Binding:\n    def __init__(self, key, command, contexts, help):\n        self.key, self.command, self.contexts = key, command, sorted(contexts)\n        self.help = help\n\n    def keyspec(self):\n        \"\"\"\n        Translate the key spec from a convenient user specification to one\n        Urwid understands.\n        \"\"\"\n        return self.key.replace(\"space\", \" \")\n\n    def key_short(self) -> str:\n        return (\n            self.key.replace(\"enter\", \"\u23ce\").replace(\"right\", \"\u2192\").replace(\"space\", \"\u2423\")\n        )\n\n    def sortkey(self):\n        return self.key + \",\".join(self.contexts)\n\n\nclass Keymap:\n    def __init__(self, master):\n        self.executor = commandexecutor.CommandExecutor(master)\n        self.keys: dict[str, dict[str, Binding]] = defaultdict(dict)\n        self.bindings = []\n\n    def _check_contexts(self, contexts):\n        if not contexts:\n            raise ValueError(\"Must specify at least one context.\")\n        for c in contexts:\n            if c not in Contexts:\n                raise ValueError(\"Unsupported context: %s\" % c)\n\n    def _on_change(self) -> None:\n        signals.keybindings_change.send()\n        self.binding_for_help.cache_clear()\n\n    def add(self, key: str, command: str, contexts: Sequence[str], help=\"\") -> None:\n        \"\"\"\n        Add a key to the key map.\n        \"\"\"\n        self._check_contexts(contexts)\n\n        for b in self.bindings:\n            if b.key == key and b.command.strip() == command.strip():\n                b.contexts = sorted(list(set(b.contexts + contexts)))\n                if help:\n                    b.help = help\n                self.bind(b)\n                break\n        else:\n            self.remove(key, contexts)\n            b = Binding(key=key, command=command, contexts=contexts, help=help)\n            self.bindings.append(b)\n            self.bind(b)\n        self._on_change()\n\n    def remove(self, key: str, contexts: Sequence[str]) -> None:\n        \"\"\"\n        Remove a key from the key map.\n        \"\"\"\n        self._check_contexts(contexts)\n        for c in contexts:\n            b = self.get(c, key)\n            if b:\n                self.unbind(b)\n                b.contexts = [x for x in b.contexts if x != c]\n                if b.contexts:\n                    self.bindings.append(b)\n                    self.bind(b)\n        self._on_change()\n\n    def bind(self, binding: Binding) -> None:\n        for c in binding.contexts:\n            self.keys[c][binding.keyspec()] = binding\n\n    def unbind(self, binding: Binding) -> None:\n        \"\"\"\n        Unbind also removes the binding from the list.\n        \"\"\"\n        for c in binding.contexts:\n            del self.keys[c][binding.keyspec()]\n            self.bindings = [b for b in self.bindings if b != binding]\n        self._on_change()\n\n    def get(self, context: str, key: str) -> Binding | None:\n        if context in self.keys:\n            return self.keys[context].get(key, None)\n        return None\n\n    @cache\n    def binding_for_help(self, help: str) -> Binding | None:\n        for b in self.bindings:\n            if b.help == help:\n                return b\n        return None\n\n    def list(self, context: str) -> Sequence[Binding]:\n        b = [x for x in self.bindings if context in x.contexts or context == \"all\"]\n        single = [x for x in b if len(x.key.split()) == 1]\n        multi = [x for x in b if len(x.key.split()) != 1]\n        single.sort(key=lambda x: x.sortkey())\n        multi.sort(key=lambda x: x.sortkey())\n        return single + multi\n\n    def handle(self, context: str, key: str) -> str | None:\n        \"\"\"\n        Returns the key if it has not been handled, or None.\n        \"\"\"\n        b = self.get(context, key) or self.get(\"global\", key)\n        if b:\n            self.executor(b.command)\n            return None\n        return key\n\n    def handle_only(self, context: str, key: str) -> str | None:\n        \"\"\"\n        Like handle, but ignores global bindings. Returns the key if it has\n        not been handled, or None.\n        \"\"\"\n        b = self.get(context, key)\n        if b:\n            self.executor(b.command)\n            return None\n        return key\n\n\nkeyAttrs = {\n    \"key\": lambda x: isinstance(x, str),\n    \"cmd\": lambda x: isinstance(x, str),\n    \"ctx\": lambda x: isinstance(x, list) and [isinstance(v, str) for v in x],\n    \"help\": lambda x: isinstance(x, str),\n}\nrequiredKeyAttrs = {\"key\", \"cmd\"}\n\n\nclass KeymapConfig:\n    defaultFile = \"keys.yaml\"\n\n    def __init__(self, master):\n        self.master = master\n\n    @command.command(\"console.keymap.load\")\n    def keymap_load_path(self, path: mitmproxy.types.Path) -> None:\n        try:\n            self.load_path(self.master.keymap, path)  # type: ignore\n        except (OSError, KeyBindingError) as e:\n            raise exceptions.CommandError(\"Could not load key bindings - %s\" % e) from e\n\n    def running(self):\n        p = os.path.join(os.path.expanduser(ctx.options.confdir), self.defaultFile)\n        if os.path.exists(p):\n            try:\n                self.load_path(self.master.keymap, p)\n            except KeyBindingError as e:\n                logging.error(e)\n\n    def load_path(self, km, p):\n        if os.path.exists(p) and os.path.isfile(p):\n            with open(p, encoding=\"utf8\") as f:\n                try:\n                    txt = f.read()\n                except UnicodeDecodeError as e:\n                    raise KeyBindingError(f\"Encoding error - expected UTF8: {p}: {e}\")\n            try:\n                vals = self.parse(txt)\n            except KeyBindingError as e:\n                raise KeyBindingError(f\"Error reading {p}: {e}\") from e\n            for v in vals:\n                user_ctxs = v.get(\"ctx\", [\"global\"])\n                try:\n                    km._check_contexts(user_ctxs)\n                    km.remove(v[\"key\"], user_ctxs)\n                    km.add(\n                        key=v[\"key\"],\n                        command=v[\"cmd\"],\n                        contexts=user_ctxs,\n                        help=v.get(\"help\", None),\n                    )\n                except ValueError as e:\n                    raise KeyBindingError(f\"Error reading {p}: {e}\") from e\n\n    def parse(self, text):\n        try:\n            data = ruamel.yaml.YAML(typ=\"safe\", pure=True).load(text)\n        except ruamel.yaml.error.MarkedYAMLError as v:\n            if hasattr(v, \"problem_mark\"):\n                snip = v.problem_mark.get_snippet()\n                raise KeyBindingError(\n                    \"Key binding config error at line %s:\\n%s\\n%s\"\n                    % (v.problem_mark.line + 1, snip, v.problem)\n                )\n            else:\n                raise KeyBindingError(\"Could not parse key bindings.\")\n        if not data:\n            return []\n        if not isinstance(data, list):\n            raise KeyBindingError(\"Invalid keybinding config - expected a list of keys\")\n\n        for k in data:\n            unknown = k.keys() - keyAttrs.keys()\n            if unknown:\n                raise KeyBindingError(\"Unknown key attributes: %s\" % unknown)\n            missing = requiredKeyAttrs - k.keys()\n            if missing:\n                raise KeyBindingError(\"Missing required key attributes: %s\" % unknown)\n            for attr in k.keys():\n                if not keyAttrs[attr](k[attr]):\n                    raise KeyBindingError(\"Invalid type for %s\" % attr)\n\n        return data\n", "mitmproxy/tools/console/commands.py": "import textwrap\n\nimport urwid\n\nfrom mitmproxy import command\nfrom mitmproxy.tools.console import layoutwidget\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.utils import signals as utils_signals\n\nHELP_HEIGHT = 5\n\ncommand_focus_change = utils_signals.SyncSignal(lambda text: None)\n\n\nclass CommandItem(urwid.WidgetWrap):\n    def __init__(self, walker, cmd: command.Command, focused: bool):\n        self.walker, self.cmd, self.focused = walker, cmd, focused\n        super().__init__(None)\n        self._w = self.get_widget()\n\n    def get_widget(self):\n        parts = [(\"focus\", \">> \" if self.focused else \"   \"), (\"title\", self.cmd.name)]\n        if self.cmd.parameters:\n            parts += [\n                (\"text\", \" \"),\n                (\"text\", \" \".join(str(param) for param in self.cmd.parameters)),\n            ]\n        if self.cmd.return_type:\n            parts += [\n                (\"title\", \" -> \"),\n                (\"text\", command.typename(self.cmd.return_type)),\n            ]\n\n        return urwid.AttrMap(urwid.Padding(urwid.Text(parts)), \"text\")\n\n    def get_edit_text(self):\n        return self._w[1].get_edit_text()\n\n    def selectable(self):\n        return True\n\n    def keypress(self, size, key):\n        return key\n\n\nclass CommandListWalker(urwid.ListWalker):\n    def __init__(self, master):\n        self.master = master\n        self.index = 0\n        self.refresh()\n\n    def refresh(self):\n        self.cmds = list(self.master.commands.commands.values())\n        self.cmds.sort(key=lambda x: x.signature_help())\n        self.set_focus(self.index)\n\n    def get_edit_text(self):\n        return self.focus_obj.get_edit_text()\n\n    def _get(self, pos):\n        cmd = self.cmds[pos]\n        return CommandItem(self, cmd, pos == self.index)\n\n    def get_focus(self):\n        return self.focus_obj, self.index\n\n    def set_focus(self, index: int) -> None:\n        cmd = self.cmds[index]\n        self.index = index\n        self.focus_obj = self._get(self.index)\n        command_focus_change.send(cmd.help or \"\")\n\n    def get_next(self, pos):\n        if pos >= len(self.cmds) - 1:\n            return None, None\n        pos = pos + 1\n        return self._get(pos), pos\n\n    def get_prev(self, pos):\n        pos = pos - 1\n        if pos < 0:\n            return None, None\n        return self._get(pos), pos\n\n\nclass CommandsList(urwid.ListBox):\n    def __init__(self, master):\n        self.master = master\n        self.walker = CommandListWalker(master)\n        super().__init__(self.walker)\n\n    def keypress(self, size: int, key: str):\n        if key == \"m_select\":\n            foc, idx = self.get_focus()\n            signals.status_prompt_command.send(partial=foc.cmd.name + \" \")\n        elif key == \"m_start\":\n            self.set_focus(0)\n            self.walker._modified()\n        elif key == \"m_end\":\n            self.set_focus(len(self.walker.cmds) - 1)\n            self.walker._modified()\n        return super().keypress(size, key)\n\n\nclass CommandHelp(urwid.Frame):\n    def __init__(self, master):\n        self.master = master\n        super().__init__(self.widget(\"\"))\n        self.set_active(False)\n        command_focus_change.connect(self.sig_mod)\n\n    def set_active(self, val):\n        h = urwid.Text(\"Command Help\")\n        style = \"heading\" if val else \"heading_inactive\"\n        self.header = urwid.AttrWrap(h, style)\n\n    def widget(self, txt):\n        cols, _ = self.master.ui.get_cols_rows()\n        return urwid.ListBox([urwid.Text(i) for i in textwrap.wrap(txt, cols)])\n\n    def sig_mod(self, txt):\n        self.set_body(self.widget(txt))\n\n\nclass Commands(urwid.Pile, layoutwidget.LayoutWidget):\n    title = \"Command Reference\"\n    keyctx = \"commands\"\n\n    focus_position: int\n\n    def __init__(self, master):\n        oh = CommandHelp(master)\n        super().__init__(\n            [\n                CommandsList(master),\n                (HELP_HEIGHT, oh),\n            ]\n        )\n        self.master = master\n\n    def layout_pushed(self, prev):\n        self.widget_list[0].walker.refresh()\n\n    def keypress(self, size, key):\n        if key == \"m_next\":\n            self.focus_position = (self.focus_position + 1) % len(self.widget_list)\n            self.widget_list[1].set_active(self.focus_position == 1)\n            key = None\n\n        # This is essentially a copypasta from urwid.Pile's keypress handler.\n        # So much for \"closed for modification, but open for extension\".\n        item_rows = None\n        if len(size) == 2:\n            item_rows = self.get_item_rows(size, focus=True)\n        i = self.widget_list.index(self.focus_item)\n        tsize = self.get_item_size(size, i, True, item_rows)\n        return self.focus_item.keypress(tsize, key)\n", "mitmproxy/tools/console/layoutwidget.py": "from typing import ClassVar\n\n\nclass LayoutWidget:\n    \"\"\"\n    All top-level layout widgets and all widgets that may be set in an\n    overlay must comply with this API.\n    \"\"\"\n\n    # Title is only required for windows, not overlay components\n    title = \"\"\n    keyctx: ClassVar[str] = \"\"\n\n    def key_responder(self):\n        \"\"\"\n        Returns the object responding to key input. Usually self, but may be\n        a wrapped object.\n        \"\"\"\n        return self\n\n    def focus_changed(self):\n        \"\"\"\n        The view focus has changed. Layout objects should implement the API\n        rather than directly subscribing to events.\n        \"\"\"\n\n    def view_changed(self):\n        \"\"\"\n        The view list has changed.\n        \"\"\"\n\n    def layout_popping(self):\n        \"\"\"\n        We are just about to pop a window off the stack, or exit an overlay.\n        \"\"\"\n\n    def layout_pushed(self, prev):\n        \"\"\"\n        We have just pushed a window onto the stack.\n        \"\"\"\n", "mitmproxy/tools/console/keybindings.py": "import textwrap\n\nimport urwid\n\nfrom mitmproxy.tools.console import layoutwidget\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.utils import signals as utils_signals\n\nHELP_HEIGHT = 5\n\n\nclass KeyItem(urwid.WidgetWrap):\n    def __init__(self, walker, binding, focused):\n        self.walker, self.binding, self.focused = walker, binding, focused\n        super().__init__(None)\n        self._w = self.get_widget()\n\n    def get_widget(self):\n        cmd = textwrap.dedent(self.binding.command).strip()\n        parts = [\n            (4, urwid.Text([(\"focus\", \">> \" if self.focused else \"   \")])),\n            (10, urwid.Text([(\"title\", self.binding.key)])),\n            (12, urwid.Text([(\"highlight\", \"\\n\".join(self.binding.contexts))])),\n            urwid.Text([(\"text\", cmd)]),\n        ]\n        return urwid.Columns(parts)\n\n    def get_edit_text(self):\n        return self._w[1].get_edit_text()\n\n    def selectable(self):\n        return True\n\n    def keypress(self, size, key):\n        return key\n\n\nclass KeyListWalker(urwid.ListWalker):\n    def __init__(self, master, keybinding_focus_change):\n        self.keybinding_focus_change = keybinding_focus_change\n        self.master = master\n\n        self.index = 0\n        self.focusobj = None\n        self.bindings = list(master.keymap.list(\"all\"))\n        self.set_focus(0)\n        signals.keybindings_change.connect(self.sig_modified)\n\n    def sig_modified(self):\n        self.bindings = list(self.master.keymap.list(\"all\"))\n        self.set_focus(min(self.index, len(self.bindings) - 1))\n        self._modified()\n\n    def get_edit_text(self):\n        return self.focus_obj.get_edit_text()\n\n    def _get(self, pos):\n        binding = self.bindings[pos]\n        return KeyItem(self, binding, pos == self.index)\n\n    def get_focus(self):\n        return self.focus_obj, self.index\n\n    def set_focus(self, index):\n        binding = self.bindings[index]\n        self.index = index\n        self.focus_obj = self._get(self.index)\n        self.keybinding_focus_change.send(binding.help or \"\")\n        self._modified()\n\n    def get_next(self, pos):\n        if pos >= len(self.bindings) - 1:\n            return None, None\n        pos = pos + 1\n        return self._get(pos), pos\n\n    def get_prev(self, pos):\n        pos = pos - 1\n        if pos < 0:\n            return None, None\n        return self._get(pos), pos\n\n    def positions(self, reverse=False):\n        if reverse:\n            return reversed(range(len(self.bindings)))\n        else:\n            return range(len(self.bindings))\n\n\nclass KeyList(urwid.ListBox):\n    def __init__(self, master, keybinding_focus_change):\n        self.master = master\n        self.walker = KeyListWalker(master, keybinding_focus_change)\n        super().__init__(self.walker)\n\n    def keypress(self, size, key):\n        if key == \"m_select\":\n            foc, idx = self.get_focus()\n            # Act here\n        elif key == \"m_start\":\n            self.set_focus(0)\n            self.walker._modified()\n        elif key == \"m_end\":\n            self.set_focus(len(self.walker.bindings) - 1)\n            self.walker._modified()\n        return super().keypress(size, key)\n\n\nclass KeyHelp(urwid.Frame):\n    def __init__(self, master, keybinding_focus_change):\n        self.master = master\n        super().__init__(self.widget(\"\"))\n        self.set_active(False)\n        keybinding_focus_change.connect(self.sig_mod)\n\n    def set_active(self, val):\n        h = urwid.Text(\"Key Binding Help\")\n        style = \"heading\" if val else \"heading_inactive\"\n        self.header = urwid.AttrWrap(h, style)\n\n    def widget(self, txt):\n        cols, _ = self.master.ui.get_cols_rows()\n        return urwid.ListBox([urwid.Text(i) for i in textwrap.wrap(txt, cols)])\n\n    def sig_mod(self, txt):\n        self.set_body(self.widget(txt))\n\n\nclass KeyBindings(urwid.Pile, layoutwidget.LayoutWidget):\n    title = \"Key Bindings\"\n    keyctx = \"keybindings\"\n    focus_position: int\n\n    def __init__(self, master):\n        keybinding_focus_change = utils_signals.SyncSignal(lambda text: None)\n\n        oh = KeyHelp(master, keybinding_focus_change)\n        super().__init__(\n            [\n                KeyList(master, keybinding_focus_change),\n                (HELP_HEIGHT, oh),\n            ]\n        )\n        self.master = master\n\n    def get_focused_binding(self):\n        if self.focus_position != 0:\n            return None\n        f = self.widget_list[0]\n        return f.walker.get_focus()[0].binding\n\n    def keypress(self, size, key):\n        if key == \"m_next\":\n            self.focus_position = (self.focus_position + 1) % len(self.widget_list)\n            self.widget_list[1].set_active(self.focus_position == 1)\n            key = None\n\n        # This is essentially a copypasta from urwid.Pile's keypress handler.\n        # So much for \"closed for modification, but open for extension\".\n        item_rows = None\n        if len(size) == 2:\n            item_rows = self.get_item_rows(size, focus=True)\n        i = self.widget_list.index(self.focus_item)\n        tsize = self.get_item_size(size, i, True, item_rows)\n        return self.focus_item.keypress(tsize, key)\n", "mitmproxy/tools/console/__init__.py": "from mitmproxy.tools.console import master\n\n__all__ = [\"master\"]\n", "mitmproxy/tools/console/defaultkeys.py": "from mitmproxy.tools.console.keymap import Keymap\n\n\ndef map(km: Keymap) -> None:\n    km.add(\":\", \"console.command \", [\"commonkey\", \"global\"], \"Command prompt\")\n    km.add(\n        \";\",\n        \"console.command flow.comment @focus ''\",\n        [\"flowlist\", \"flowview\"],\n        \"Add comment to flow\",\n    )\n    km.add(\"?\", \"console.view.help\", [\"global\"], \"View help\")\n    km.add(\"B\", \"browser.start\", [\"global\"], \"Start an attached browser\")\n    km.add(\"C\", \"console.view.commands\", [\"global\"], \"View commands\")\n    km.add(\"K\", \"console.view.keybindings\", [\"global\"], \"View key bindings\")\n    km.add(\"O\", \"console.view.options\", [\"commonkey\", \"global\"], \"View options\")\n    km.add(\"E\", \"console.view.eventlog\", [\"commonkey\", \"global\"], \"View event log\")\n    km.add(\"Q\", \"console.exit\", [\"global\"], \"Exit immediately\")\n    km.add(\"q\", \"console.view.pop\", [\"commonkey\", \"global\"], \"Exit the current view\")\n    km.add(\"esc\", \"console.view.pop\", [\"commonkey\", \"global\"], \"Exit the current view\")\n    km.add(\"-\", \"console.layout.cycle\", [\"global\"], \"Cycle to next layout\")\n    km.add(\"ctrl right\", \"console.panes.next\", [\"global\"], \"Focus next layout pane\")\n    km.add(\"ctrl left\", \"console.panes.prev\", [\"global\"], \"Focus previous layout pane\")\n    km.add(\"shift tab\", \"console.panes.next\", [\"global\"], \"Focus next layout pane\")\n    km.add(\"P\", \"console.view.flow @focus\", [\"global\"], \"View flow details\")\n\n    km.add(\"?\", \"console.view.pop\", [\"help\"], \"Exit help\")\n\n    km.add(\"g\", \"console.nav.start\", [\"global\"], \"Go to start\")\n    km.add(\"G\", \"console.nav.end\", [\"global\"], \"Go to end\")\n    km.add(\"k\", \"console.nav.up\", [\"global\"], \"Up\")\n    km.add(\"j\", \"console.nav.down\", [\"global\"], \"Down\")\n    km.add(\"l\", \"console.nav.right\", [\"global\"], \"Right\")\n    km.add(\"h\", \"console.nav.left\", [\"global\"], \"Left\")\n    km.add(\"tab\", \"console.nav.next\", [\"commonkey\", \"global\"], \"Next\")\n    km.add(\"enter\", \"console.nav.select\", [\"commonkey\", \"global\"], \"Select\")\n    km.add(\"space\", \"console.nav.pagedown\", [\"global\"], \"Page down\")\n    km.add(\"ctrl f\", \"console.nav.pagedown\", [\"global\"], \"Page down\")\n    km.add(\"ctrl b\", \"console.nav.pageup\", [\"global\"], \"Page up\")\n\n    km.add(\n        \"I\",\n        \"set intercept_active toggle\",\n        [\"global\"],\n        \"Toggle whether the filtering via the intercept option is enabled\",\n    )\n    km.add(\"i\", \"console.command.set intercept\", [\"global\"], \"Set intercept\")\n    km.add(\"W\", \"console.command.set save_stream_file\", [\"global\"], \"Stream to file\")\n    km.add(\n        \"A\",\n        \"flow.resume @all\",\n        [\"flowlist\", \"flowview\"],\n        \"Resume all intercepted flows\",\n    )\n    km.add(\n        \"a\",\n        \"flow.resume @focus\",\n        [\"flowlist\", \"flowview\"],\n        \"Resume this intercepted flow\",\n    )\n    km.add(\n        \"b\",\n        \"console.command cut.save @focus response.content \",\n        [\"flowlist\", \"flowview\"],\n        \"Save response body to file\",\n    )\n    km.add(\n        \"d\",\n        \"view.flows.remove @focus\",\n        [\"flowlist\", \"flowview\"],\n        \"Delete flow from view\",\n    )\n    km.add(\n        \"D\", \"view.flows.duplicate @focus\", [\"flowlist\", \"flowview\"], \"Duplicate flow\"\n    )\n    km.add(\n        \"x\",\n        \"\"\"\n        console.choose.cmd Format export.formats\n        console.command export.file {choice} @focus\n        \"\"\",\n        [\"flowlist\", \"flowview\"],\n        \"Export this flow to file\",\n    )\n    km.add(\"f\", \"console.command.set view_filter\", [\"flowlist\"], \"Set view filter\")\n    km.add(\n        \"F\",\n        \"set console_focus_follow toggle\",\n        [\"flowlist\", \"flowview\"],\n        \"Set focus follow\",\n    )\n    km.add(\n        \"ctrl l\",\n        \"console.command cut.clip \",\n        [\"flowlist\", \"flowview\"],\n        \"Send cuts to clipboard\",\n    )\n    km.add(\n        \"L\", \"console.command view.flows.load \", [\"flowlist\"], \"Load flows from file\"\n    )\n    km.add(\"m\", \"flow.mark.toggle @focus\", [\"flowlist\"], \"Toggle mark on this flow\")\n    km.add(\n        \"M\",\n        \"view.properties.marked.toggle\",\n        [\"flowlist\"],\n        \"Toggle viewing marked flows\",\n    )\n    km.add(\n        \"n\",\n        \"console.command view.flows.create get https://example.com/\",\n        [\"flowlist\"],\n        \"Create a new flow\",\n    )\n    km.add(\n        \"o\",\n        \"\"\"\n        console.choose.cmd Order view.order.options\n        set view_order {choice}\n        \"\"\",\n        [\"flowlist\"],\n        \"Set flow list order\",\n    )\n    km.add(\"r\", \"replay.client @focus\", [\"flowlist\", \"flowview\"], \"Replay this flow\")\n    km.add(\"S\", \"console.command replay.server \", [\"flowlist\"], \"Start server replay\")\n    km.add(\n        \"v\", \"set view_order_reversed toggle\", [\"flowlist\"], \"Reverse flow list order\"\n    )\n    km.add(\"U\", \"flow.mark @all false\", [\"flowlist\"], \"Un-set all marks\")\n    km.add(\n        \"w\",\n        \"console.command save.file @shown \",\n        [\"flowlist\"],\n        \"Save listed flows to file\",\n    )\n    km.add(\n        \"V\",\n        \"flow.revert @focus\",\n        [\"flowlist\", \"flowview\"],\n        \"Revert changes to this flow\",\n    )\n    km.add(\"X\", \"flow.kill @focus\", [\"flowlist\"], \"Kill this flow\")\n    km.add(\"z\", \"view.flows.remove @all\", [\"flowlist\"], \"Clear flow list\")\n    km.add(\n        \"Z\", \"view.flows.remove @hidden\", [\"flowlist\"], \"Purge all flows not showing\"\n    )\n    km.add(\n        \"|\",\n        \"console.command script.run @focus \",\n        [\"flowlist\", \"flowview\"],\n        \"Run a script on this flow\",\n    )\n\n    km.add(\n        \"e\",\n        \"\"\"\n        console.choose.cmd Part console.edit.focus.options\n        console.edit.focus {choice}\n        \"\"\",\n        [\"flowlist\", \"flowview\"],\n        \"Edit a flow component\",\n    )\n    km.add(\n        \"f\",\n        \"view.settings.setval.toggle @focus fullcontents\",\n        [\"flowview\"],\n        \"Toggle viewing full contents on this flow\",\n    )\n    km.add(\"w\", \"console.command save.file @focus \", [\"flowview\"], \"Save flow to file\")\n    km.add(\"space\", \"view.focus.next\", [\"flowview\"], \"Go to next flow\")\n\n    km.add(\n        \"v\",\n        \"\"\"\n        console.choose \"View Part\" request,response\n        console.bodyview @focus {choice}\n        \"\"\",\n        [\"flowview\"],\n        \"View flow body in an external viewer\",\n    )\n    km.add(\"p\", \"view.focus.prev\", [\"flowview\"], \"Go to previous flow\")\n    km.add(\n        \"m\",\n        \"\"\"\n        console.choose.cmd Mode console.flowview.mode.options\n        console.flowview.mode.set {choice}\n        \"\"\",\n        [\"flowview\"],\n        \"Set flow view mode\",\n    )\n    km.add(\n        \"z\",\n        \"\"\"\n        console.choose \"Part\" request,response\n        flow.encode.toggle @focus {choice}\n        \"\"\",\n        [\"flowview\"],\n        \"Encode/decode flow body\",\n    )\n\n    km.add(\"L\", \"console.command options.load \", [\"options\"], \"Load from file\")\n    km.add(\"S\", \"console.command options.save \", [\"options\"], \"Save to file\")\n    km.add(\"D\", \"options.reset\", [\"options\"], \"Reset all options\")\n    km.add(\"d\", \"console.options.reset.focus\", [\"options\"], \"Reset this option\")\n\n    km.add(\"a\", \"console.grideditor.add\", [\"grideditor\"], \"Add a row after cursor\")\n    km.add(\n        \"A\", \"console.grideditor.insert\", [\"grideditor\"], \"Insert a row before cursor\"\n    )\n    km.add(\"d\", \"console.grideditor.delete\", [\"grideditor\"], \"Delete this row\")\n    km.add(\n        \"r\",\n        \"console.command console.grideditor.load\",\n        [\"grideditor\"],\n        \"Read unescaped data into the current cell from file\",\n    )\n    km.add(\n        \"R\",\n        \"console.command console.grideditor.load_escaped\",\n        [\"grideditor\"],\n        \"Load a Python-style escaped string into the current cell from file\",\n    )\n    km.add(\"e\", \"console.grideditor.editor\", [\"grideditor\"], \"Edit in external editor\")\n    km.add(\n        \"w\",\n        \"console.command console.grideditor.save \",\n        [\"grideditor\"],\n        \"Save data to file as CSV\",\n    )\n\n    km.add(\"z\", \"eventstore.clear\", [\"eventlog\"], \"Clear\")\n\n    km.add(\n        \"a\",\n        \"\"\"\n        console.choose.cmd \"Context\" console.key.contexts\n        console.command console.key.bind {choice}\n        \"\"\",\n        [\"keybindings\"],\n        \"Add a key binding\",\n    )\n    km.add(\n        \"d\",\n        \"console.key.unbind.focus\",\n        [\"keybindings\"],\n        \"Unbind the currently focused key binding\",\n    )\n    km.add(\n        \"x\",\n        \"console.key.execute.focus\",\n        [\"keybindings\"],\n        \"Execute the currently focused key binding\",\n    )\n    km.add(\n        \"enter\",\n        \"console.key.edit.focus\",\n        [\"keybindings\"],\n        \"Edit the currently focused key binding\",\n    )\n", "mitmproxy/tools/console/overlay.py": "import math\n\nimport urwid\n\nfrom mitmproxy.tools.console import grideditor\nfrom mitmproxy.tools.console import keymap\nfrom mitmproxy.tools.console import layoutwidget\nfrom mitmproxy.tools.console import signals\n\n\nclass SimpleOverlay(urwid.Overlay, layoutwidget.LayoutWidget):\n    def __init__(self, master, widget, parent, width, valign=\"middle\"):\n        self.widget = widget\n        self.master = master\n        super().__init__(\n            widget, parent, align=\"center\", width=width, valign=valign, height=\"pack\"\n        )\n\n    @property\n    def keyctx(self):\n        return getattr(self.widget, \"keyctx\")\n\n    def key_responder(self):\n        return self.widget.key_responder()\n\n    def focus_changed(self):\n        return self.widget.focus_changed()\n\n    def view_changed(self):\n        return self.widget.view_changed()\n\n    def layout_popping(self):\n        return self.widget.layout_popping()\n\n\nclass Choice(urwid.WidgetWrap):\n    def __init__(self, txt, focus, current, shortcut):\n        if shortcut:\n            selection_type = \"option_selected_key\" if focus else \"key\"\n            txt = [(selection_type, shortcut), \") \", txt]\n        else:\n            txt = \"   \" + txt\n        if current:\n            s = \"option_active_selected\" if focus else \"option_active\"\n        else:\n            s = \"option_selected\" if focus else \"text\"\n        super().__init__(\n            urwid.AttrWrap(\n                urwid.Padding(urwid.Text(txt)),\n                s,\n            )\n        )\n\n    def selectable(self):\n        return True\n\n    def keypress(self, size, key):\n        return key\n\n\nclass ChooserListWalker(urwid.ListWalker):\n    shortcuts = \"123456789abcdefghijklmnoprstuvwxyz\"\n\n    def __init__(self, choices, current):\n        self.index = 0\n        self.choices = choices\n        self.current = current\n\n    def _get(self, idx, focus):\n        c = self.choices[idx]\n        return Choice(c, focus, c == self.current, self.shortcuts[idx : idx + 1])\n\n    def set_focus(self, index):\n        self.index = index\n\n    def get_focus(self):\n        return self._get(self.index, True), self.index\n\n    def get_next(self, pos):\n        if pos >= len(self.choices) - 1:\n            return None, None\n        pos = pos + 1\n        return self._get(pos, False), pos\n\n    def get_prev(self, pos):\n        pos = pos - 1\n        if pos < 0:\n            return None, None\n        return self._get(pos, False), pos\n\n    def choice_by_shortcut(self, shortcut):\n        for i, choice in enumerate(self.choices):\n            if shortcut == self.shortcuts[i : i + 1]:\n                return choice\n        return None\n\n\nclass Chooser(urwid.WidgetWrap, layoutwidget.LayoutWidget):\n    keyctx = \"chooser\"\n\n    def __init__(self, master, title, choices, current, callback):\n        self.master = master\n        self.choices = choices\n        self.callback = callback\n        choicewidth = max(len(i) for i in choices)\n        self.width = max(choicewidth, len(title)) + 7\n\n        self.walker = ChooserListWalker(choices, current)\n        super().__init__(\n            urwid.AttrWrap(\n                urwid.LineBox(\n                    urwid.BoxAdapter(urwid.ListBox(self.walker), len(choices)),\n                    title=title,\n                ),\n                \"background\",\n            )\n        )\n\n    def selectable(self):\n        return True\n\n    def keypress(self, size, key):\n        key = self.master.keymap.handle_only(\"chooser\", key)\n        choice = self.walker.choice_by_shortcut(key)\n        if choice:\n            self.callback(choice)\n            signals.pop_view_state.send()\n            return\n        if key == \"m_select\":\n            self.callback(self.choices[self.walker.index])\n            signals.pop_view_state.send()\n            return\n        elif key in [\"q\", \"esc\"]:\n            signals.pop_view_state.send()\n            return\n\n        binding = self.master.keymap.get(\"global\", key)\n        # This is extremely awkward. We need a better way to match nav keys only.\n        if binding and binding.command.startswith(\"console.nav\"):\n            self.master.keymap.handle(\"global\", key)\n        elif key in keymap.navkeys:\n            return super().keypress(size, key)\n\n\nclass OptionsOverlay(urwid.WidgetWrap, layoutwidget.LayoutWidget):\n    keyctx = \"grideditor\"\n\n    def __init__(self, master, name, vals, vspace):\n        \"\"\"\n        vspace: how much vertical space to keep clear\n        \"\"\"\n        cols, rows = master.ui.get_cols_rows()\n        self.ge = grideditor.OptionsEditor(master, name, vals)\n        super().__init__(\n            urwid.AttrWrap(\n                urwid.LineBox(urwid.BoxAdapter(self.ge, rows - vspace), title=name),\n                \"background\",\n            )\n        )\n        self.width = math.ceil(cols * 0.8)\n\n    def key_responder(self):\n        return self.ge.key_responder()\n\n    def layout_popping(self):\n        return self.ge.layout_popping()\n\n\nclass DataViewerOverlay(urwid.WidgetWrap, layoutwidget.LayoutWidget):\n    keyctx = \"dataviewer\"\n\n    def __init__(self, master, vals):\n        \"\"\"\n        vspace: how much vertical space to keep clear\n        \"\"\"\n        cols, rows = master.ui.get_cols_rows()\n        self.ge = grideditor.DataViewer(master, vals)\n        super().__init__(\n            urwid.AttrWrap(\n                urwid.LineBox(urwid.BoxAdapter(self.ge, rows - 5), title=\"Data viewer\"),\n                \"background\",\n            )\n        )\n        self.width = math.ceil(cols * 0.8)\n\n    def key_responder(self):\n        return self.ge.key_responder()\n\n    def layout_popping(self):\n        return self.ge.layout_popping()\n", "mitmproxy/tools/console/flowview.py": "import logging\nimport math\nimport sys\nfrom functools import lru_cache\n\nimport urwid\n\nimport mitmproxy.flow\nimport mitmproxy.tools.console.master\nfrom mitmproxy import contentviews\nfrom mitmproxy import ctx\nfrom mitmproxy import dns\nfrom mitmproxy import http\nfrom mitmproxy import tcp\nfrom mitmproxy import udp\nfrom mitmproxy.tools.console import common\nfrom mitmproxy.tools.console import flowdetailview\nfrom mitmproxy.tools.console import layoutwidget\nfrom mitmproxy.tools.console import searchable\nfrom mitmproxy.tools.console import tabs\nfrom mitmproxy.utils import strutils\n\n\nclass SearchError(Exception):\n    pass\n\n\nclass FlowViewHeader(urwid.WidgetWrap):\n    def __init__(\n        self,\n        master: \"mitmproxy.tools.console.master.ConsoleMaster\",\n    ) -> None:\n        self.master = master\n        self.focus_changed()\n\n    def focus_changed(self):\n        cols, _ = self.master.ui.get_cols_rows()\n        if self.master.view.focus.flow:\n            self._w = common.format_flow(\n                self.master.view.focus.flow,\n                render_mode=common.RenderMode.DETAILVIEW,\n                hostheader=self.master.options.showhost,\n            )\n        else:\n            self._w = urwid.Pile([])\n\n\nclass FlowDetails(tabs.Tabs):\n    def __init__(self, master):\n        self.master = master\n        super().__init__([])\n        self.show()\n        self.last_displayed_body = None\n        contentviews.on_add.connect(self.contentview_changed)\n        contentviews.on_remove.connect(self.contentview_changed)\n\n    @property\n    def view(self):\n        return self.master.view\n\n    @property\n    def flow(self) -> mitmproxy.flow.Flow:\n        return self.master.view.focus.flow\n\n    def contentview_changed(self, view):\n        # this is called when a contentview addon is live-reloaded.\n        # we clear our cache and then rerender\n        self._get_content_view.cache_clear()\n        if self.master.window.current_window(\"flowview\"):\n            self.show()\n\n    def focus_changed(self):\n        f = self.flow\n        if f:\n            if isinstance(f, http.HTTPFlow):\n                if f.websocket:\n                    self.tabs = [\n                        (self.tab_http_request, self.view_request),\n                        (self.tab_http_response, self.view_response),\n                        (self.tab_websocket_messages, self.view_websocket_messages),\n                        (self.tab_details, self.view_details),\n                    ]\n                else:\n                    self.tabs = [\n                        (self.tab_http_request, self.view_request),\n                        (self.tab_http_response, self.view_response),\n                        (self.tab_details, self.view_details),\n                    ]\n            elif isinstance(f, tcp.TCPFlow):\n                self.tabs = [\n                    (self.tab_tcp_stream, self.view_message_stream),\n                    (self.tab_details, self.view_details),\n                ]\n            elif isinstance(f, udp.UDPFlow):\n                self.tabs = [\n                    (self.tab_udp_stream, self.view_message_stream),\n                    (self.tab_details, self.view_details),\n                ]\n            elif isinstance(f, dns.DNSFlow):\n                self.tabs = [\n                    (self.tab_dns_request, self.view_dns_request),\n                    (self.tab_dns_response, self.view_dns_response),\n                    (self.tab_details, self.view_details),\n                ]\n            self.show()\n        else:\n            self.master.window.pop()\n\n    def tab_http_request(self):\n        flow = self.flow\n        assert isinstance(flow, http.HTTPFlow)\n        if self.flow.intercepted and not flow.response:\n            return \"Request intercepted\"\n        else:\n            return \"Request\"\n\n    def tab_http_response(self):\n        flow = self.flow\n        assert isinstance(flow, http.HTTPFlow)\n\n        # there is no good way to detect what part of the flow is intercepted,\n        # so we apply some heuristics to see if it's the HTTP response.\n        websocket_started = flow.websocket and len(flow.websocket.messages) != 0\n        response_is_intercepted = (\n            self.flow.intercepted and flow.response and not websocket_started\n        )\n        if response_is_intercepted:\n            return \"Response intercepted\"\n        else:\n            return \"Response\"\n\n    def tab_dns_request(self) -> str:\n        flow = self.flow\n        assert isinstance(flow, dns.DNSFlow)\n        if self.flow.intercepted and not flow.response:\n            return \"Request intercepted\"\n        else:\n            return \"Request\"\n\n    def tab_dns_response(self) -> str:\n        flow = self.flow\n        assert isinstance(flow, dns.DNSFlow)\n        if self.flow.intercepted and flow.response:\n            return \"Response intercepted\"\n        else:\n            return \"Response\"\n\n    def tab_tcp_stream(self):\n        return \"TCP Stream\"\n\n    def tab_udp_stream(self):\n        return \"UDP Stream\"\n\n    def tab_websocket_messages(self):\n        flow = self.flow\n        assert isinstance(flow, http.HTTPFlow)\n        assert flow.websocket\n\n        if self.flow.intercepted and len(flow.websocket.messages) != 0:\n            return \"WebSocket Messages intercepted\"\n        else:\n            return \"WebSocket Messages\"\n\n    def tab_details(self):\n        return \"Detail\"\n\n    def view_request(self):\n        flow = self.flow\n        assert isinstance(flow, http.HTTPFlow)\n        return self.conn_text(flow.request)\n\n    def view_response(self):\n        flow = self.flow\n        assert isinstance(flow, http.HTTPFlow)\n        return self.conn_text(flow.response)\n\n    def view_dns_request(self):\n        flow = self.flow\n        assert isinstance(flow, dns.DNSFlow)\n        return self.dns_message_text(\"request\", flow.request)\n\n    def view_dns_response(self):\n        flow = self.flow\n        assert isinstance(flow, dns.DNSFlow)\n        return self.dns_message_text(\"response\", flow.response)\n\n    def _contentview_status_bar(self, description: str, viewmode: str):\n        cols = [\n            urwid.Text(\n                [\n                    (\"heading\", description),\n                ]\n            ),\n            urwid.Text(\n                [\n                    \" \",\n                    (\"heading\", \"[\"),\n                    (\"heading_key\", \"m\"),\n                    (\"heading\", (\":%s]\" % viewmode)),\n                ],\n                align=\"right\",\n            ),\n        ]\n        contentview_status_bar = urwid.AttrWrap(urwid.Columns(cols), \"heading\")\n        return contentview_status_bar\n\n    FROM_CLIENT_MARKER = (\"from_client\", f\"{common.SYMBOL_FROM_CLIENT} \")\n    TO_CLIENT_MARKER = (\"to_client\", f\"{common.SYMBOL_TO_CLIENT} \")\n\n    def view_websocket_messages(self):\n        flow = self.flow\n        assert isinstance(flow, http.HTTPFlow)\n        assert flow.websocket is not None\n\n        if not flow.websocket.messages:\n            return searchable.Searchable([urwid.Text((\"highlight\", \"No messages.\"))])\n\n        viewmode = self.master.commands.call(\"console.flowview.mode\")\n\n        widget_lines = []\n        for m in flow.websocket.messages:\n            _, lines, _ = contentviews.get_message_content_view(viewmode, m, flow)\n\n            for line in lines:\n                if m.from_client:\n                    line.insert(0, self.FROM_CLIENT_MARKER)\n                else:\n                    line.insert(0, self.TO_CLIENT_MARKER)\n\n                widget_lines.append(urwid.Text(line))\n\n        if flow.websocket.closed_by_client is not None:\n            widget_lines.append(\n                urwid.Text(\n                    [\n                        (\n                            self.FROM_CLIENT_MARKER\n                            if flow.websocket.closed_by_client\n                            else self.TO_CLIENT_MARKER\n                        ),\n                        (\n                            \"alert\"\n                            if flow.websocket.close_code in (1000, 1001, 1005)\n                            else \"error\",\n                            f\"Connection closed: {flow.websocket.close_code} {flow.websocket.close_reason}\",\n                        ),\n                    ]\n                )\n            )\n\n        if flow.intercepted:\n            markup = widget_lines[-1].get_text()[0]\n            widget_lines[-1].set_text((\"intercept\", markup))\n\n        widget_lines.insert(\n            0, self._contentview_status_bar(viewmode.capitalize(), viewmode)\n        )\n\n        return searchable.Searchable(widget_lines)\n\n    def view_message_stream(self) -> urwid.Widget:\n        flow = self.flow\n        assert isinstance(flow, (tcp.TCPFlow, udp.UDPFlow))\n\n        if not flow.messages:\n            return searchable.Searchable([urwid.Text((\"highlight\", \"No messages.\"))])\n\n        viewmode = self.master.commands.call(\"console.flowview.mode\")\n\n        widget_lines = []\n        for m in flow.messages:\n            _, lines, _ = contentviews.get_message_content_view(viewmode, m, flow)\n\n            for line in lines:\n                if m.from_client:\n                    line.insert(0, self.FROM_CLIENT_MARKER)\n                else:\n                    line.insert(0, self.TO_CLIENT_MARKER)\n\n                widget_lines.append(urwid.Text(line))\n\n        if flow.intercepted:\n            markup = widget_lines[-1].get_text()[0]\n            widget_lines[-1].set_text((\"intercept\", markup))\n\n        widget_lines.insert(\n            0, self._contentview_status_bar(viewmode.capitalize(), viewmode)\n        )\n\n        return searchable.Searchable(widget_lines)\n\n    def view_details(self):\n        return flowdetailview.flowdetails(self.view, self.flow)\n\n    def content_view(self, viewmode, message):\n        if message.raw_content is None:\n            msg, body = \"\", [urwid.Text([(\"error\", \"[content missing]\")])]\n            return msg, body\n        else:\n            full = self.master.commands.execute(\n                \"view.settings.getval @focus fullcontents false\"\n            )\n            if full == \"true\":\n                limit = sys.maxsize\n            else:\n                limit = ctx.options.content_view_lines_cutoff\n\n            flow_modify_cache_invalidation = hash(\n                (\n                    message.raw_content,\n                    message.headers.fields,\n                    getattr(message, \"path\", None),\n                )\n            )\n            # we need to pass the message off-band because it's not hashable\n            self._get_content_view_message = message\n            return self._get_content_view(\n                viewmode, limit, flow_modify_cache_invalidation\n            )\n\n    @lru_cache(maxsize=200)\n    def _get_content_view(self, viewmode, max_lines, _):\n        message = self._get_content_view_message\n        self._get_content_view_message = None\n        description, lines, error = contentviews.get_message_content_view(\n            viewmode, message, self.flow\n        )\n        if error:\n            logging.debug(error)\n        # Give hint that you have to tab for the response.\n        if description == \"No content\" and isinstance(message, http.Request):\n            description = \"No request content\"\n\n        # If the users has a wide terminal, he gets fewer lines; this should not be an issue.\n        chars_per_line = 80\n        max_chars = max_lines * chars_per_line\n        total_chars = 0\n        text_objects = []\n        for line in lines:\n            txt = []\n            for style, text in line:\n                if total_chars + len(text) > max_chars:\n                    text = text[: max_chars - total_chars]\n                txt.append((style, text))\n                total_chars += len(text)\n                if total_chars == max_chars:\n                    break\n\n            # round up to the next line.\n            total_chars = int(math.ceil(total_chars / chars_per_line) * chars_per_line)\n\n            text_objects.append(urwid.Text(txt))\n            if total_chars == max_chars:\n                text_objects.append(\n                    urwid.Text(\n                        [\n                            (\n                                \"highlight\",\n                                \"Stopped displaying data after %d lines. Press \"\n                                % max_lines,\n                            ),\n                            (\"key\", \"f\"),\n                            (\"highlight\", \" to load all data.\"),\n                        ]\n                    )\n                )\n                break\n\n        return description, text_objects\n\n    def conn_text(self, conn):\n        if conn:\n            hdrs = []\n            for k, v in conn.headers.fields:\n                # This will always force an ascii representation of headers. For example, if the server sends a\n                #\n                #     X-Authors: Made with \u2764 in Hamburg\n                #\n                # header, mitmproxy will display the following:\n                #\n                #     X-Authors: Made with \\xe2\\x9d\\xa4 in Hamburg.\n                #\n                # The alternative would be to just use the header's UTF-8 representation and maybe\n                # do `str.replace(\"\\t\", \"\\\\t\")` to exempt tabs from urwid's special characters escaping [1].\n                # That would in some terminals allow rendering UTF-8 characters, but the mapping\n                # wouldn't be bijective, i.e. a user couldn't distinguish \"\\\\t\" and \"\\t\".\n                # Also, from a security perspective, a mitmproxy user couldn't be fooled by homoglyphs.\n                #\n                # 1) https://github.com/mitmproxy/mitmproxy/issues/1833\n                #    https://github.com/urwid/urwid/blob/6608ee2c9932d264abd1171468d833b7a4082e13/urwid/display_common.py#L35-L36,\n\n                k = strutils.bytes_to_escaped_str(k) + \":\"\n                v = strutils.bytes_to_escaped_str(v)\n                hdrs.append((k, v))\n            txt = common.format_keyvals(hdrs, key_format=\"header\")\n            viewmode = self.master.commands.call(\"console.flowview.mode\")\n            msg, body = self.content_view(viewmode, conn)\n\n            cols = [\n                urwid.Text(\n                    [\n                        (\"heading\", msg),\n                    ]\n                ),\n                urwid.Text(\n                    [\n                        \" \",\n                        (\"heading\", \"[\"),\n                        (\"heading_key\", \"m\"),\n                        (\"heading\", (\":%s]\" % viewmode)),\n                    ],\n                    align=\"right\",\n                ),\n            ]\n            title = urwid.AttrWrap(urwid.Columns(cols), \"heading\")\n\n            txt.append(title)\n            txt.extend(body)\n        else:\n            txt = [\n                urwid.Text(\"\"),\n                urwid.Text(\n                    [\n                        (\"highlight\", \"No response. Press \"),\n                        (\"key\", \"e\"),\n                        (\"highlight\", \" and edit any aspect to add one.\"),\n                    ]\n                ),\n            ]\n        return searchable.Searchable(txt)\n\n    def dns_message_text(\n        self, type: str, message: dns.Message | None\n    ) -> searchable.Searchable:\n        # Keep in sync with web/src/js/components/FlowView/DnsMessages.tsx\n        if message:\n\n            def rr_text(rr: dns.ResourceRecord):\n                return urwid.Text(\n                    f\"  {rr.name} {dns.types.to_str(rr.type)} {dns.classes.to_str(rr.class_)} {rr.ttl} {str(rr)}\"\n                )\n\n            txt = []\n            txt.append(\n                urwid.Text(\n                    \"{recursive}Question\".format(\n                        recursive=\"Recursive \" if message.recursion_desired else \"\",\n                    )\n                )\n            )\n            txt.extend(\n                urwid.Text(\n                    f\"  {q.name} {dns.types.to_str(q.type)} {dns.classes.to_str(q.class_)}\"\n                )\n                for q in message.questions\n            )\n            txt.append(urwid.Text(\"\"))\n            txt.append(\n                urwid.Text(\n                    \"{authoritative}{recursive}Answer\".format(\n                        authoritative=\"Authoritative \"\n                        if message.authoritative_answer\n                        else \"\",\n                        recursive=\"Recursive \" if message.recursion_available else \"\",\n                    )\n                )\n            )\n            txt.extend(map(rr_text, message.answers))\n            txt.append(urwid.Text(\"\"))\n            txt.append(urwid.Text(\"Authority\"))\n            txt.extend(map(rr_text, message.authorities))\n            txt.append(urwid.Text(\"\"))\n            txt.append(urwid.Text(\"Addition\"))\n            txt.extend(map(rr_text, message.additionals))\n            return searchable.Searchable(txt)\n        else:\n            return searchable.Searchable([urwid.Text((\"highlight\", f\"No {type}.\"))])\n\n\nclass FlowView(urwid.Frame, layoutwidget.LayoutWidget):\n    keyctx = \"flowview\"\n    title = \"Flow Details\"\n\n    def __init__(self, master):\n        super().__init__(\n            FlowDetails(master),\n            header=FlowViewHeader(master),\n        )\n        self.master = master\n\n    def focus_changed(self, *args, **kwargs):\n        self.body.focus_changed()\n        self.header.focus_changed()\n", "mitmproxy/tools/console/statusbar.py": "from __future__ import annotations\n\nfrom collections.abc import Callable\nfrom functools import lru_cache\n\nimport urwid\n\nimport mitmproxy.tools.console.master\nfrom mitmproxy.tools.console import commandexecutor\nfrom mitmproxy.tools.console import common\nfrom mitmproxy.tools.console import flowlist\nfrom mitmproxy.tools.console import quickhelp\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.tools.console.commander import commander\nfrom mitmproxy.utils import human\n\n\n@lru_cache\ndef shorten_message(\n    msg: tuple[str, str] | str, max_width: int\n) -> list[tuple[str, str]]:\n    \"\"\"\n    Shorten message so that it fits into a single line in the statusbar.\n    \"\"\"\n    if isinstance(msg, tuple):\n        disp_attr, msg_text = msg\n    elif isinstance(msg, str):\n        msg_text = msg\n        disp_attr = \"\"\n    else:\n        raise AssertionError(f\"Unexpected message type: {type(msg)}\")\n    msg_end = \"\\u2026\"  # unicode ellipsis for the end of shortened message\n    prompt = \"(more in eventlog)\"\n\n    msg_lines = msg_text.split(\"\\n\")\n    first_line = msg_lines[0]\n    if len(msg_lines) > 1:\n        # First line of messages with a few lines must end with prompt.\n        line_length = len(first_line) + len(prompt)\n    else:\n        line_length = len(first_line)\n\n    if line_length > max_width:\n        shortening_index = max(0, max_width - len(prompt) - len(msg_end))\n        first_line = first_line[:shortening_index] + msg_end\n    else:\n        if len(msg_lines) == 1:\n            prompt = \"\"\n\n    return [(disp_attr, first_line), (\"warn\", prompt)]\n\n\nclass ActionBar(urwid.WidgetWrap):\n    def __init__(self, master: mitmproxy.tools.console.master.ConsoleMaster) -> None:\n        self.master = master\n        self.top = urwid.WidgetWrap(urwid.Text(\"\"))\n        self.bottom = urwid.WidgetWrap(urwid.Text(\"\"))\n        super().__init__(urwid.Pile([self.top, self.bottom]))\n        self.show_quickhelp()\n        signals.status_message.connect(self.sig_message)\n        signals.status_prompt.connect(self.sig_prompt)\n        signals.status_prompt_onekey.connect(self.sig_prompt_onekey)\n        signals.status_prompt_command.connect(self.sig_prompt_command)\n        signals.window_refresh.connect(self.sig_update)\n        master.view.focus.sig_change.connect(self.sig_update)\n        master.view.sig_view_update.connect(self.sig_update)\n\n        self.prompting: Callable[[str], None] | None = None\n\n        self.onekey: set[str] | None = None\n\n    def sig_update(self, flow=None) -> None:\n        if not self.prompting and flow is None or flow == self.master.view.focus.flow:\n            self.show_quickhelp()\n\n    def sig_message(\n        self, message: tuple[str, str] | str, expire: int | None = 1\n    ) -> None:\n        if self.prompting:\n            return\n        cols, _ = self.master.ui.get_cols_rows()\n        w = urwid.Text(shorten_message(message, cols))\n        self.top._w = w\n        self.bottom._w = urwid.Text(\"\")\n        if expire:\n\n            def cb():\n                if w == self.top._w:\n                    self.show_quickhelp()\n\n            signals.call_in.send(seconds=expire, callback=cb)\n\n    def sig_prompt(\n        self, prompt: str, text: str | None, callback: Callable[[str], None]\n    ) -> None:\n        signals.focus.send(section=\"footer\")\n        self.top._w = urwid.Edit(f\"{prompt.strip()}: \", text or \"\")\n        self.bottom._w = urwid.Text(\"\")\n        self.prompting = callback\n\n    def sig_prompt_command(self, partial: str = \"\", cursor: int | None = None) -> None:\n        signals.focus.send(section=\"footer\")\n        self.top._w = commander.CommandEdit(\n            self.master,\n            partial,\n        )\n        if cursor is not None:\n            self.top._w.cbuf.cursor = cursor\n        self.bottom._w = urwid.Text(\"\")\n        self.prompting = self.execute_command\n\n    def execute_command(self, txt: str) -> None:\n        if txt.strip():\n            self.master.commands.call(\"commands.history.add\", txt)\n        execute = commandexecutor.CommandExecutor(self.master)\n        execute(txt)\n\n    def sig_prompt_onekey(\n        self, prompt: str, keys: list[tuple[str, str]], callback: Callable[[str], None]\n    ) -> None:\n        \"\"\"\n        Keys are a set of (word, key) tuples. The appropriate key in the\n        word is highlighted.\n        \"\"\"\n        signals.focus.send(section=\"footer\")\n        parts = [prompt, \" (\"]\n        mkup = []\n        for i, e in enumerate(keys):\n            mkup.extend(common.highlight_key(e[0], e[1]))\n            if i < len(keys) - 1:\n                mkup.append(\",\")\n        parts.extend(mkup)\n        parts.append(\")? \")\n        self.onekey = {i[1] for i in keys}\n        self.top._w = urwid.Edit(parts, \"\")\n        self.bottom._w = urwid.Text(\"\")\n        self.prompting = callback\n\n    def selectable(self) -> bool:\n        return True\n\n    def keypress(self, size, k):\n        if self.prompting:\n            if k == \"esc\":\n                self.prompt_done()\n            elif self.onekey:\n                if k == \"enter\":\n                    self.prompt_done()\n                elif k in self.onekey:\n                    self.prompt_execute(k)\n            elif k == \"enter\":\n                text = self.top._w.get_edit_text()\n                self.prompt_execute(text)\n            else:\n                if common.is_keypress(k):\n                    self.top._w.keypress(size, k)\n                else:\n                    return k\n\n    def show_quickhelp(self) -> None:\n        if w := self.master.window:\n            s = w.focus_stack()\n            focused_widget = type(s.top_widget())\n            is_top_widget = len(s.stack) == 1\n        else:  # on startup\n            focused_widget = flowlist.FlowListBox\n            is_top_widget = True\n        focused_flow = self.master.view.focus.flow\n        qh = quickhelp.make(focused_widget, focused_flow, is_top_widget)\n        self.top._w, self.bottom._w = qh.make_rows(self.master.keymap)\n\n    def prompt_done(self) -> None:\n        self.prompting = None\n        self.onekey = None\n        self.show_quickhelp()\n        signals.focus.send(section=\"body\")\n\n    def prompt_execute(self, txt) -> None:\n        callback = self.prompting\n        assert callback is not None\n        self.prompt_done()\n        msg = callback(txt)\n        if msg:\n            signals.status_message.send(message=msg, expire=1)\n\n\nclass StatusBar(urwid.WidgetWrap):\n    REFRESHTIME = 0.5  # Timed refresh time in seconds\n    keyctx = \"\"\n\n    def __init__(self, master: mitmproxy.tools.console.master.ConsoleMaster) -> None:\n        self.master = master\n        self.ib = urwid.WidgetWrap(urwid.Text(\"\"))\n        self.ab = ActionBar(self.master)\n        super().__init__(urwid.Pile([self.ib, self.ab]))\n        signals.flow_change.connect(self.sig_update)\n        signals.update_settings.connect(self.sig_update)\n        master.options.changed.connect(self.sig_update)\n        master.view.focus.sig_change.connect(self.sig_update)\n        master.view.sig_view_add.connect(self.sig_update)\n        self.refresh()\n\n    def refresh(self) -> None:\n        self.redraw()\n        signals.call_in.send(seconds=self.REFRESHTIME, callback=self.refresh)\n\n    def sig_update(self, *args, **kwargs) -> None:\n        self.redraw()\n\n    def keypress(self, *args, **kwargs):\n        return self.ab.keypress(*args, **kwargs)\n\n    def get_status(self) -> list[tuple[str, str] | str]:\n        r: list[tuple[str, str] | str] = []\n\n        sreplay = self.master.commands.call(\"replay.server.count\")\n        creplay = self.master.commands.call(\"replay.client.count\")\n\n        if len(self.master.options.modify_headers):\n            r.append(\"[\")\n            r.append((\"heading_key\", \"H\"))\n            r.append(\"eaders]\")\n        if len(self.master.options.modify_body):\n            r.append(\"[%d body modifications]\" % len(self.master.options.modify_body))\n        if creplay:\n            r.append(\"[\")\n            r.append((\"heading_key\", \"cplayback\"))\n            r.append(\":%s]\" % creplay)\n        if sreplay:\n            r.append(\"[\")\n            r.append((\"heading_key\", \"splayback\"))\n            r.append(\":%s]\" % sreplay)\n        if self.master.options.ignore_hosts:\n            r.append(\"[\")\n            r.append((\"heading_key\", \"I\"))\n            r.append(\"gnore:%d]\" % len(self.master.options.ignore_hosts))\n        elif self.master.options.allow_hosts:\n            r.append(\"[\")\n            r.append((\"heading_key\", \"A\"))\n            r.append(\"llow:%d]\" % len(self.master.options.allow_hosts))\n        if self.master.options.tcp_hosts:\n            r.append(\"[\")\n            r.append((\"heading_key\", \"T\"))\n            r.append(\"CP:%d]\" % len(self.master.options.tcp_hosts))\n        if self.master.options.intercept:\n            r.append(\"[\")\n            if not self.master.options.intercept_active:\n                r.append(\"X\")\n            r.append((\"heading_key\", \"i\"))\n            r.append(\":%s]\" % self.master.options.intercept)\n        if self.master.options.view_filter:\n            r.append(\"[\")\n            r.append((\"heading_key\", \"f\"))\n            r.append(\":%s]\" % self.master.options.view_filter)\n        if self.master.options.stickycookie:\n            r.append(\"[\")\n            r.append((\"heading_key\", \"t\"))\n            r.append(\":%s]\" % self.master.options.stickycookie)\n        if self.master.options.stickyauth:\n            r.append(\"[\")\n            r.append((\"heading_key\", \"u\"))\n            r.append(\":%s]\" % self.master.options.stickyauth)\n        if self.master.options.console_default_contentview != \"auto\":\n            r.append(\n                \"[contentview:%s]\" % (self.master.options.console_default_contentview)\n            )\n        if self.master.options.has_changed(\"view_order\"):\n            r.append(\"[\")\n            r.append((\"heading_key\", \"o\"))\n            r.append(\":%s]\" % self.master.options.view_order)\n\n        opts = []\n        if self.master.options.anticache:\n            opts.append(\"anticache\")\n        if self.master.options.anticomp:\n            opts.append(\"anticomp\")\n        if self.master.options.showhost:\n            opts.append(\"showhost\")\n        if not self.master.options.server_replay_refresh:\n            opts.append(\"norefresh\")\n        if not self.master.options.upstream_cert:\n            opts.append(\"no-upstream-cert\")\n        if self.master.options.console_focus_follow:\n            opts.append(\"following\")\n        if self.master.options.stream_large_bodies:\n            opts.append(self.master.options.stream_large_bodies)\n\n        if opts:\n            r.append(\"[%s]\" % (\":\".join(opts)))\n\n        if self.master.options.mode != [\"regular\"]:\n            if len(self.master.options.mode) == 1:\n                r.append(f\"[{self.master.options.mode[0]}]\")\n            else:\n                r.append(f\"[modes:{len(self.master.options.mode)}]\")\n        if self.master.options.scripts:\n            r.append(\"[scripts:%s]\" % len(self.master.options.scripts))\n\n        if self.master.options.save_stream_file:\n            r.append(\"[W:%s]\" % self.master.options.save_stream_file)\n\n        return r\n\n    def redraw(self) -> None:\n        fc = self.master.commands.execute(\"view.properties.length\")\n        if self.master.view.focus.index is None:\n            offset = 0\n        else:\n            offset = self.master.view.focus.index + 1\n\n        if self.master.options.view_order_reversed:\n            arrow = common.SYMBOL_UP\n        else:\n            arrow = common.SYMBOL_DOWN\n\n        marked = \"\"\n        if self.master.commands.execute(\"view.properties.marked\"):\n            marked = \"M\"\n\n        t: list[tuple[str, str] | str] = [\n            (\"heading\", f\"{arrow} {marked} [{offset}/{fc}]\".ljust(11)),\n        ]\n\n        listen_addrs: list[str] = list(\n            dict.fromkeys(\n                human.format_address(a)\n                for a in self.master.addons.get(\"proxyserver\").listen_addrs()\n            )\n        )\n        if listen_addrs:\n            boundaddr = f\"[{', '.join(listen_addrs)}]\"\n        else:\n            boundaddr = \"\"\n        t.extend(self.get_status())\n        status = urwid.AttrWrap(\n            urwid.Columns(\n                [\n                    urwid.Text(t),\n                    urwid.Text(boundaddr, align=\"right\"),\n                ]\n            ),\n            \"heading\",\n        )\n        self.ib._w = status\n\n    def selectable(self) -> bool:\n        return True\n", "mitmproxy/tools/console/grideditor/col_viewany.py": "\"\"\"\nA display-only column that displays any data type.\n\"\"\"\n\nfrom typing import Any\n\nimport urwid\n\nfrom mitmproxy.tools.console.grideditor import base\nfrom mitmproxy.utils import strutils\n\n\nclass Column(base.Column):\n    def Display(self, data):\n        return Display(data)\n\n    Edit = Display\n\n    def blank(self):\n        return \"\"\n\n\nclass Display(base.Cell):\n    def __init__(self, data: Any) -> None:\n        self.data = data\n        if isinstance(data, bytes):\n            data = strutils.bytes_to_escaped_str(data)\n        if not isinstance(data, str):\n            data = repr(data)\n        w = urwid.Text(data, wrap=\"any\")\n        super().__init__(w)\n\n    def get_data(self) -> Any:\n        return self.data\n", "mitmproxy/tools/console/grideditor/base.py": "import abc\nimport copy\nimport os\nfrom collections.abc import Callable\nfrom collections.abc import Container\nfrom collections.abc import Iterable\nfrom collections.abc import MutableSequence\nfrom collections.abc import Sequence\nfrom typing import Any\nfrom typing import ClassVar\nfrom typing import Literal\nfrom typing import overload\n\nimport urwid\n\nimport mitmproxy.tools.console.master\nfrom mitmproxy import exceptions\nfrom mitmproxy.tools.console import layoutwidget\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.utils import strutils\n\n\n@overload\ndef read_file(filename: str, escaped: Literal[True]) -> bytes: ...\n\n\n@overload\ndef read_file(filename: str, escaped: Literal[False]) -> str: ...\n\n\ndef read_file(filename: str, escaped: bool) -> bytes | str:\n    filename = os.path.expanduser(filename)\n    try:\n        with open(filename, \"r\" if escaped else \"rb\") as f:\n            d = f.read()\n    except OSError as v:\n        raise exceptions.CommandError(v)\n    if escaped:\n        try:\n            d = strutils.escaped_str_to_bytes(d)\n        except ValueError:\n            raise exceptions.CommandError(\"Invalid Python-style string encoding.\")\n    return d\n\n\nclass Cell(urwid.WidgetWrap):\n    def get_data(self):\n        \"\"\"\n        Raises:\n            ValueError, if the current content is invalid.\n        \"\"\"\n        raise NotImplementedError()\n\n    def selectable(self):\n        return True\n\n\nclass Column(metaclass=abc.ABCMeta):\n    subeditor: urwid.Edit = None\n\n    def __init__(self, heading):\n        self.heading = heading\n\n    @abc.abstractmethod\n    def Display(self, data) -> Cell:\n        pass\n\n    @abc.abstractmethod\n    def Edit(self, data) -> Cell:\n        pass\n\n    @abc.abstractmethod\n    def blank(self) -> Any:\n        pass\n\n    def keypress(self, key: str, editor: \"GridEditor\") -> str | None:\n        return key\n\n\nclass GridRow(urwid.WidgetWrap):\n    def __init__(\n        self,\n        focused: int | None,\n        editing: bool,\n        editor: \"GridEditor\",\n        values: tuple[Iterable[bytes], Container[int]],\n    ) -> None:\n        self.focused = focused\n        self.editor = editor\n        self.edit_col: Cell | None = None\n\n        errors = values[1]\n        self.fields: Sequence[Any] = []\n        for i, v in enumerate(values[0]):\n            if focused == i and editing:\n                self.edit_col = self.editor.columns[i].Edit(v)\n                self.fields.append(self.edit_col)\n            else:\n                w = self.editor.columns[i].Display(v)\n                if focused == i:\n                    if i in errors:\n                        w = urwid.AttrWrap(w, \"focusfield_error\")\n                    else:\n                        w = urwid.AttrWrap(w, \"focusfield\")\n                elif i in errors:\n                    w = urwid.AttrWrap(w, \"field_error\")\n                self.fields.append(w)\n\n        fspecs = self.fields[:]\n        if len(self.fields) > 1:\n            fspecs[0] = (\"fixed\", self.editor.first_width + 2, fspecs[0])\n        w = urwid.Columns(fspecs, dividechars=2)\n        if focused is not None:\n            w.set_focus_column(focused)\n        super().__init__(w)\n\n    def keypress(self, s, k):\n        if self.edit_col:\n            w = self._w.column_widths(s)[self.focused]\n            k = self.edit_col.keypress((w,), k)\n        return k\n\n    def selectable(self):\n        return True\n\n\nclass GridWalker(urwid.ListWalker):\n    \"\"\"\n    Stores rows as a list of (rows, errors) tuples, where rows is a list\n    and errors is a set with an entry of each offset in rows that is an\n    error.\n    \"\"\"\n\n    def __init__(self, lst: Iterable[list], editor: \"GridEditor\") -> None:\n        self.lst: MutableSequence[tuple[Any, set]] = [(i, set()) for i in lst]\n        self.editor = editor\n        self.focus = 0\n        self.focus_col = 0\n        self.edit_row: GridRow | None = None\n\n    def _modified(self):\n        self.editor.show_empty_msg()\n        return super()._modified()\n\n    def add_value(self, lst):\n        self.lst.append((lst[:], set()))\n        self._modified()\n\n    def get_current_value(self):\n        if self.lst:\n            return self.lst[self.focus][0][self.focus_col]\n\n    def set_current_value(self, val) -> None:\n        errors = self.lst[self.focus][1]\n        emsg = self.editor.is_error(self.focus_col, val)\n        if emsg:\n            signals.status_message.send(message=emsg)\n            errors.add(self.focus_col)\n        else:\n            errors.discard(self.focus_col)\n        self.set_value(val, self.focus, self.focus_col, errors)\n\n    def set_value(self, val, focus, focus_col, errors=None):\n        if not errors:\n            errors = set()\n        row = list(self.lst[focus][0])\n        row[focus_col] = val\n        self.lst[focus] = [tuple(row), errors]  # type: ignore\n        self._modified()\n\n    def delete_focus(self):\n        if self.lst:\n            del self.lst[self.focus]\n            self.focus = min(len(self.lst) - 1, self.focus)\n            self._modified()\n\n    def _insert(self, pos):\n        self.focus = pos\n        self.lst.insert(self.focus, ([c.blank() for c in self.editor.columns], set()))\n        self.focus_col = 0\n        self.start_edit()\n\n    def insert(self):\n        return self._insert(self.focus)\n\n    def add(self):\n        return self._insert(min(self.focus + 1, len(self.lst)))\n\n    def start_edit(self):\n        col = self.editor.columns[self.focus_col]\n        if self.lst and not col.subeditor:\n            self.edit_row = GridRow(\n                self.focus_col, True, self.editor, self.lst[self.focus]\n            )\n            self._modified()\n\n    def stop_edit(self):\n        if self.edit_row and self.edit_row.edit_col:\n            try:\n                val = self.edit_row.edit_col.get_data()\n            except ValueError:\n                return\n            self.edit_row = None\n            self.set_current_value(val)\n\n    def left(self):\n        self.focus_col = max(self.focus_col - 1, 0)\n        self._modified()\n\n    def right(self):\n        self.focus_col = min(self.focus_col + 1, len(self.editor.columns) - 1)\n        self._modified()\n\n    def tab_next(self):\n        self.stop_edit()\n        if self.focus_col < len(self.editor.columns) - 1:\n            self.focus_col += 1\n        elif self.focus != len(self.lst) - 1:\n            self.focus_col = 0\n            self.focus += 1\n        self._modified()\n\n    def get_focus(self):\n        if self.edit_row:\n            return self.edit_row, self.focus\n        elif self.lst:\n            return (\n                GridRow(self.focus_col, False, self.editor, self.lst[self.focus]),\n                self.focus,\n            )\n        else:\n            return None, None\n\n    def set_focus(self, focus):\n        self.stop_edit()\n        self.focus = focus\n        self._modified()\n\n    def get_next(self, pos):\n        if pos + 1 >= len(self.lst):\n            return None, None\n        return GridRow(None, False, self.editor, self.lst[pos + 1]), pos + 1\n\n    def get_prev(self, pos):\n        if pos - 1 < 0:\n            return None, None\n        return GridRow(None, False, self.editor, self.lst[pos - 1]), pos - 1\n\n\nclass GridListBox(urwid.ListBox):\n    def __init__(self, lw):\n        super().__init__(lw)\n\n\nFIRST_WIDTH_MAX = 40\n\n\nclass BaseGridEditor(urwid.WidgetWrap):\n    title: str = \"\"\n    keyctx: ClassVar[str] = \"grideditor\"\n\n    def __init__(\n        self,\n        master: \"mitmproxy.tools.console.master.ConsoleMaster\",\n        title,\n        columns,\n        value: Any,\n        callback: Callable[..., None],\n        *cb_args,\n        **cb_kwargs,\n    ) -> None:\n        value = self.data_in(copy.deepcopy(value))\n        self.master = master\n        self.title = title\n        self.columns = columns\n        self.value = value\n        self.callback = callback\n        self.cb_args = cb_args\n        self.cb_kwargs = cb_kwargs\n\n        first_width = 20\n        if value:\n            for r in value:\n                assert len(r) == len(self.columns)\n                first_width = max(len(r), first_width)\n        self.first_width = min(first_width, FIRST_WIDTH_MAX)\n\n        h = None\n        if any(col.heading for col in self.columns):\n            headings = []\n            for i, col in enumerate(self.columns):\n                c = urwid.Text(col.heading)\n                if i == 0 and len(self.columns) > 1:\n                    headings.append((\"fixed\", first_width + 2, c))\n                else:\n                    headings.append(c)\n            h = urwid.Columns(headings, dividechars=2)\n            h = urwid.AttrWrap(h, \"heading\")\n\n        self.walker = GridWalker(self.value, self)\n        self.lb = GridListBox(self.walker)\n        w = urwid.Frame(self.lb, header=h)\n\n        super().__init__(w)\n        self.show_empty_msg()\n\n    def layout_popping(self):\n        res = []\n        for i in self.walker.lst:\n            if not i[1] and any([x for x in i[0]]):\n                res.append(i[0])\n        self.callback(self.data_out(res), *self.cb_args, **self.cb_kwargs)\n\n    def show_empty_msg(self):\n        if self.walker.lst:\n            self._w.set_footer(None)\n        else:\n            self._w.set_footer(\n                urwid.Text(\n                    [\n                        (\"highlight\", \"No values - you should add some. Press \"),\n                        (\"key\", \"?\"),\n                        (\"highlight\", \" for help.\"),\n                    ]\n                )\n            )\n\n    def set_subeditor_value(self, val, focus, focus_col):\n        self.walker.set_value(val, focus, focus_col)\n\n    def keypress(self, size, key):\n        if self.walker.edit_row:\n            if key == \"esc\":\n                self.walker.stop_edit()\n            elif key == \"tab\":\n                pf, pfc = self.walker.focus, self.walker.focus_col\n                self.walker.tab_next()\n                if self.walker.focus == pf and self.walker.focus_col != pfc:\n                    self.walker.start_edit()\n            else:\n                self._w.keypress(size, key)\n            return None\n\n        column = self.columns[self.walker.focus_col]\n        if key == \"m_start\":\n            self.walker.set_focus(0)\n        elif key == \"m_next\":\n            self.walker.tab_next()\n        elif key == \"m_end\":\n            self.walker.set_focus(len(self.walker.lst) - 1)\n        elif key == \"left\":\n            self.walker.left()\n        elif key == \"right\":\n            self.walker.right()\n        elif column.keypress(key, self) and not self.handle_key(key):\n            return self._w.keypress(size, key)\n\n    def data_out(self, data: Sequence[list]) -> Any:\n        \"\"\"\n        Called on raw list data, before data is returned through the\n        callback.\n        \"\"\"\n        return data\n\n    def data_in(self, data: Any) -> Iterable[list]:\n        \"\"\"\n        Called to prepare provided data.\n        \"\"\"\n        return data\n\n    def is_error(self, col: int, val: Any) -> str | None:\n        \"\"\"\n        Return None, or a string error message.\n        \"\"\"\n        return None\n\n    def handle_key(self, key):\n        return False\n\n    def cmd_add(self):\n        self.walker.add()\n\n    def cmd_insert(self):\n        self.walker.insert()\n\n    def cmd_delete(self):\n        self.walker.delete_focus()\n\n    def cmd_read_file(self, path):\n        self.walker.set_current_value(read_file(path, False))\n\n    def cmd_read_file_escaped(self, path):\n        self.walker.set_current_value(read_file(path, True))\n\n    def cmd_spawn_editor(self):\n        o = self.walker.get_current_value()\n        if o is not None:\n            n = self.master.spawn_editor(o)\n            n = strutils.clean_hanging_newline(n)\n            self.walker.set_current_value(n)\n\n\nclass GridEditor(BaseGridEditor):\n    title = \"\"\n    columns: Sequence[Column] = ()\n    keyctx: ClassVar[str] = \"grideditor\"\n\n    def __init__(\n        self,\n        master: \"mitmproxy.tools.console.master.ConsoleMaster\",\n        value: Any,\n        callback: Callable[..., None],\n        *cb_args,\n        **cb_kwargs,\n    ) -> None:\n        super().__init__(\n            master, self.title, self.columns, value, callback, *cb_args, **cb_kwargs\n        )\n\n\nclass FocusEditor(urwid.WidgetWrap, layoutwidget.LayoutWidget):\n    \"\"\"\n    A specialised GridEditor that edits the current focused flow.\n    \"\"\"\n\n    keyctx: ClassVar[str] = \"grideditor\"\n\n    def __init__(self, master):\n        self.master = master\n\n    def call(self, v, name, *args, **kwargs):\n        f = getattr(v, name, None)\n        if f:\n            f(*args, **kwargs)\n\n    def get_data(self, flow):\n        \"\"\"\n        Retrieve the data to edit from the current flow.\n        \"\"\"\n        raise NotImplementedError\n\n    def set_data(self, vals, flow):\n        \"\"\"\n        Set the current data on the flow.\n        \"\"\"\n        raise NotImplementedError\n\n    def set_data_update(self, vals, flow) -> None:\n        self.set_data(vals, flow)\n        signals.flow_change.send(flow=flow)\n\n    def key_responder(self):\n        return self._w\n\n    def layout_popping(self):\n        self.call(self._w, \"layout_popping\")\n\n    def layout_pushed(self, prev):\n        if self.master.view.focus.flow:\n            self._w = BaseGridEditor(\n                self.master,\n                self.title,\n                self.columns,\n                self.get_data(self.master.view.focus.flow),\n                self.set_data_update,\n                self.master.view.focus.flow,\n            )\n        else:\n            self._w = urwid.Pile([])\n", "mitmproxy/tools/console/grideditor/col_subgrid.py": "import urwid\n\nfrom mitmproxy.net.http import cookies\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.tools.console.grideditor import base\n\n\nclass Column(base.Column):\n    def __init__(self, heading, subeditor):\n        super().__init__(heading)\n        self.subeditor = subeditor\n\n    def Edit(self, data):\n        raise RuntimeError(\"SubgridColumn should handle edits itself\")\n\n    def Display(self, data):\n        return Display(data)\n\n    def blank(self):\n        return []\n\n    def keypress(self, key: str, editor):\n        if key in \"rRe\":\n            signals.status_message.send(message=\"Press enter to edit this field.\")\n            return\n        elif key == \"m_select\":\n            self.subeditor.grideditor = editor\n            editor.master.switch_view(\"edit_focus_setcookie_attrs\")\n        else:\n            return key\n\n\nclass Display(base.Cell):\n    def __init__(self, data):\n        p = cookies._format_pairs(data, sep=\"\\n\")\n        w = urwid.Text(p)\n        super().__init__(w)\n\n    def get_data(self):\n        pass\n", "mitmproxy/tools/console/grideditor/col_bytes.py": "import urwid\n\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.tools.console.grideditor import base\nfrom mitmproxy.utils import strutils\n\n\nclass Column(base.Column):\n    def Display(self, data):\n        return Display(data)\n\n    def Edit(self, data):\n        return Edit(data)\n\n    def blank(self):\n        return b\"\"\n\n    def keypress(self, key, editor):\n        if key in [\"m_select\"]:\n            editor.walker.start_edit()\n        else:\n            return key\n\n\nclass Display(base.Cell):\n    def __init__(self, data: bytes) -> None:\n        self.data = data\n        escaped = strutils.bytes_to_escaped_str(data)\n        w = urwid.Text(escaped, wrap=\"any\")\n        super().__init__(w)\n\n    def get_data(self) -> bytes:\n        return self.data\n\n\nclass Edit(base.Cell):\n    def __init__(self, data: bytes) -> None:\n        d = strutils.bytes_to_escaped_str(data)\n        w = urwid.Edit(edit_text=d, wrap=\"any\", multiline=True)\n        w = urwid.AttrWrap(w, \"editfield\")\n        super().__init__(w)\n\n    def get_data(self) -> bytes:\n        txt = self._w.get_text()[0].strip()\n        try:\n            return strutils.escaped_str_to_bytes(txt)\n        except ValueError:\n            signals.status_message.send(message=\"Invalid data.\")\n            raise\n", "mitmproxy/tools/console/grideditor/__init__.py": "from . import base\nfrom .editors import CookieAttributeEditor\nfrom .editors import CookieEditor\nfrom .editors import DataViewer\nfrom .editors import OptionsEditor\nfrom .editors import PathEditor\nfrom .editors import QueryEditor\nfrom .editors import RequestHeaderEditor\nfrom .editors import RequestMultipartEditor\nfrom .editors import RequestUrlEncodedEditor\nfrom .editors import ResponseHeaderEditor\nfrom .editors import SetCookieEditor\n\n__all__ = [\n    \"base\",\n    \"QueryEditor\",\n    \"RequestHeaderEditor\",\n    \"ResponseHeaderEditor\",\n    \"RequestMultipartEditor\",\n    \"RequestUrlEncodedEditor\",\n    \"PathEditor\",\n    \"CookieEditor\",\n    \"CookieAttributeEditor\",\n    \"SetCookieEditor\",\n    \"OptionsEditor\",\n    \"DataViewer\",\n]\n", "mitmproxy/tools/console/grideditor/editors.py": "from typing import Any\n\nimport urwid\n\nfrom mitmproxy import exceptions\nfrom mitmproxy.http import Headers\nfrom mitmproxy.tools.console import layoutwidget\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.tools.console.grideditor import base\nfrom mitmproxy.tools.console.grideditor import col_bytes\nfrom mitmproxy.tools.console.grideditor import col_subgrid\nfrom mitmproxy.tools.console.grideditor import col_text\nfrom mitmproxy.tools.console.grideditor import col_viewany\n\n\nclass QueryEditor(base.FocusEditor):\n    title = \"Edit Query\"\n    columns = [col_text.Column(\"Key\"), col_text.Column(\"Value\")]\n\n    def get_data(self, flow):\n        return flow.request.query.items(multi=True)\n\n    def set_data(self, vals, flow):\n        flow.request.query = vals\n\n\nclass HeaderEditor(base.FocusEditor):\n    columns = [col_bytes.Column(\"Key\"), col_bytes.Column(\"Value\")]\n\n\nclass RequestHeaderEditor(HeaderEditor):\n    title = \"Edit Request Headers\"\n\n    def get_data(self, flow):\n        return flow.request.headers.fields\n\n    def set_data(self, vals, flow):\n        flow.request.headers = Headers(vals)\n\n\nclass ResponseHeaderEditor(HeaderEditor):\n    title = \"Edit Response Headers\"\n\n    def get_data(self, flow):\n        return flow.response.headers.fields\n\n    def set_data(self, vals, flow):\n        flow.response.headers = Headers(vals)\n\n\nclass RequestMultipartEditor(base.FocusEditor):\n    title = \"Edit Multipart Form\"\n    columns = [col_bytes.Column(\"Key\"), col_bytes.Column(\"Value\")]\n\n    def get_data(self, flow):\n        return flow.request.multipart_form.items(multi=True)\n\n    def set_data(self, vals, flow):\n        flow.request.multipart_form = vals\n\n\nclass RequestUrlEncodedEditor(base.FocusEditor):\n    title = \"Edit UrlEncoded Form\"\n    columns = [col_text.Column(\"Key\"), col_text.Column(\"Value\")]\n\n    def get_data(self, flow):\n        return flow.request.urlencoded_form.items(multi=True)\n\n    def set_data(self, vals, flow):\n        flow.request.urlencoded_form = vals\n\n\nclass PathEditor(base.FocusEditor):\n    # TODO: Next row on enter?\n    title = \"Edit Path Components\"\n    columns = [\n        col_text.Column(\"Component\"),\n    ]\n\n    def data_in(self, data):\n        return [[i] for i in data]\n\n    def data_out(self, data):\n        return [i[0] for i in data]\n\n    def get_data(self, flow):\n        return self.data_in(flow.request.path_components)\n\n    def set_data(self, vals, flow):\n        flow.request.path_components = self.data_out(vals)\n\n\nclass CookieEditor(base.FocusEditor):\n    title = \"Edit Cookies\"\n    columns = [\n        col_text.Column(\"Name\"),\n        col_text.Column(\"Value\"),\n    ]\n\n    def get_data(self, flow):\n        return flow.request.cookies.items(multi=True)\n\n    def set_data(self, vals, flow):\n        flow.request.cookies = vals\n\n\nclass CookieAttributeEditor(base.FocusEditor):\n    title = \"Editing Set-Cookie attributes\"\n    columns = [\n        col_text.Column(\"Name\"),\n        col_text.Column(\"Value\"),\n    ]\n    grideditor: base.BaseGridEditor\n\n    def data_in(self, data):\n        return [(k, v or \"\") for k, v in data]\n\n    def data_out(self, data):\n        ret = []\n        for i in data:\n            if not i[1]:\n                ret.append([i[0], None])\n            else:\n                ret.append(i)\n        return ret\n\n    def layout_pushed(self, prev):\n        if self.grideditor.master.view.focus.flow:\n            self._w = base.BaseGridEditor(\n                self.grideditor.master,\n                self.title,\n                self.columns,\n                self.grideditor.walker.get_current_value(),\n                self.grideditor.set_subeditor_value,\n                self.grideditor.walker.focus,\n                self.grideditor.walker.focus_col,\n            )\n        else:\n            self._w = urwid.Pile([])\n\n\nclass SetCookieEditor(base.FocusEditor):\n    title = \"Edit SetCookie Header\"\n    columns = [\n        col_text.Column(\"Name\"),\n        col_text.Column(\"Value\"),\n        col_subgrid.Column(\"Attributes\", CookieAttributeEditor),\n    ]\n\n    def data_in(self, data):\n        flattened = []\n        for key, (value, attrs) in data:\n            flattened.append([key, value, attrs.items(multi=True)])\n        return flattened\n\n    def data_out(self, data):\n        vals = []\n        for key, value, attrs in data:\n            vals.append([key, (value, attrs)])\n        return vals\n\n    def get_data(self, flow):\n        return self.data_in(flow.response.cookies.items(multi=True))\n\n    def set_data(self, vals, flow):\n        flow.response.cookies = self.data_out(vals)\n\n\nclass OptionsEditor(base.GridEditor, layoutwidget.LayoutWidget):\n    title = \"\"\n    columns = [col_text.Column(\"\")]\n\n    def __init__(self, master, name, vals):\n        self.name = name\n        super().__init__(master, [[i] for i in vals], self.callback)\n\n    def callback(self, vals) -> None:\n        try:\n            setattr(self.master.options, self.name, [i[0] for i in vals])\n        except exceptions.OptionsError as v:\n            signals.status_message.send(message=str(v))\n\n    def is_error(self, col, val):\n        pass\n\n\nclass DataViewer(base.GridEditor, layoutwidget.LayoutWidget):\n    title = \"\"\n\n    def __init__(\n        self,\n        master,\n        vals: (list[list[Any]] | list[Any] | Any),\n    ) -> None:\n        if vals is not None:\n            # Whatever vals is, make it a list of rows containing lists of column values.\n            if not isinstance(vals, list):\n                vals = [vals]\n            if not isinstance(vals[0], list):\n                vals = [[i] for i in vals]\n\n            self.columns = [col_viewany.Column(\"\")] * len(vals[0])\n        super().__init__(master, vals, self.callback)\n\n    def callback(self, vals):\n        pass\n\n    def is_error(self, col, val):\n        pass\n", "mitmproxy/tools/console/grideditor/col_text.py": "\"\"\"\nWelcome to the encoding dance!\n\nIn a nutshell, text columns are actually a proxy class for byte columns,\nwhich just encode/decodes contents.\n\"\"\"\n\nfrom mitmproxy.tools.console import signals\nfrom mitmproxy.tools.console.grideditor import col_bytes\n\n\nclass Column(col_bytes.Column):\n    def __init__(self, heading, encoding=\"utf8\", errors=\"surrogateescape\"):\n        super().__init__(heading)\n        self.encoding_args = encoding, errors\n\n    def Display(self, data):\n        return TDisplay(data, self.encoding_args)\n\n    def Edit(self, data):\n        return TEdit(data, self.encoding_args)\n\n    def blank(self):\n        return \"\"\n\n\n# This is the same for both edit and display.\nclass EncodingMixin:\n    def __init__(self, data, encoding_args):\n        self.encoding_args = encoding_args\n        super().__init__(str(data).encode(*self.encoding_args))  # type: ignore\n\n    def get_data(self):\n        data = super().get_data()  # type: ignore\n        try:\n            return data.decode(*self.encoding_args)\n        except ValueError:\n            signals.status_message.send(message=\"Invalid encoding.\")\n            raise\n\n\n# urwid forces a different name for a subclass.\nclass TDisplay(EncodingMixin, col_bytes.Display):\n    pass\n\n\nclass TEdit(EncodingMixin, col_bytes.Edit):\n    pass\n", "mitmproxy/tools/console/commander/commander.py": "import abc\nfrom collections.abc import Sequence\nfrom typing import NamedTuple\n\nimport urwid\nfrom urwid.text_layout import calc_coords\n\nimport mitmproxy.command\nimport mitmproxy.flow\nimport mitmproxy.master\nimport mitmproxy.types\n\n\nclass Completer:\n    @abc.abstractmethod\n    def cycle(self, forward: bool = True) -> str:\n        raise NotImplementedError()\n\n\nclass ListCompleter(Completer):\n    def __init__(\n        self,\n        start: str,\n        options: Sequence[str],\n    ) -> None:\n        self.start = start\n        self.options: list[str] = []\n        for o in options:\n            if o.startswith(start):\n                self.options.append(o)\n        self.options.sort()\n        self.pos = -1\n\n    def cycle(self, forward: bool = True) -> str:\n        if not self.options:\n            return self.start\n        if self.pos == -1:\n            self.pos = 0 if forward else len(self.options) - 1\n        else:\n            delta = 1 if forward else -1\n            self.pos = (self.pos + delta) % len(self.options)\n        return self.options[self.pos]\n\n\nclass CompletionState(NamedTuple):\n    completer: Completer\n    parsed: Sequence[mitmproxy.command.ParseResult]\n\n\nclass CommandBuffer:\n    def __init__(self, master: mitmproxy.master.Master, start: str = \"\") -> None:\n        self.master = master\n        self.text = start\n        # Cursor is always within the range [0:len(buffer)].\n        self._cursor = len(self.text)\n        self.completion: CompletionState | None = None\n\n    @property\n    def cursor(self) -> int:\n        return self._cursor\n\n    @cursor.setter\n    def cursor(self, x) -> None:\n        if x < 0:\n            self._cursor = 0\n        elif x > len(self.text):\n            self._cursor = len(self.text)\n        else:\n            self._cursor = x\n\n    def set_text(self, text: str) -> None:\n        self.text = text\n        self._cursor = len(self.text)\n        self.render()\n\n    def render(self):\n        parts, remaining = self.master.commands.parse_partial(self.text)\n        ret = []\n        if not parts:\n            # Means we just received the leader, so we need to give a blank\n            # text to the widget to render or it crashes\n            ret.append((\"text\", \"\"))\n        else:\n            for p in parts:\n                if p.valid:\n                    if p.type == mitmproxy.types.Cmd:\n                        ret.append((\"commander_command\", p.value))\n                    else:\n                        ret.append((\"text\", p.value))\n                elif p.value:\n                    ret.append((\"commander_invalid\", p.value))\n\n            if remaining:\n                if parts[-1].type != mitmproxy.types.Space:\n                    ret.append((\"text\", \" \"))\n                for param in remaining:\n                    ret.append((\"commander_hint\", f\"{param} \"))\n\n        return ret\n\n    def left(self) -> None:\n        self.cursor = self.cursor - 1\n\n    def right(self) -> None:\n        self.cursor = self.cursor + 1\n\n    def cycle_completion(self, forward: bool = True) -> None:\n        if not self.completion:\n            parts, remaining = self.master.commands.parse_partial(\n                self.text[: self.cursor]\n            )\n            if parts and parts[-1].type != mitmproxy.types.Space:\n                type_to_complete = parts[-1].type\n                cycle_prefix = parts[-1].value\n                parsed = parts[:-1]\n            elif remaining:\n                type_to_complete = remaining[0].type\n                cycle_prefix = \"\"\n                parsed = parts\n            else:\n                return\n            ct = mitmproxy.types.CommandTypes.get(type_to_complete, None)\n            if ct:\n                self.completion = CompletionState(\n                    completer=ListCompleter(\n                        cycle_prefix,\n                        ct.completion(\n                            self.master.commands, type_to_complete, cycle_prefix\n                        ),\n                    ),\n                    parsed=parsed,\n                )\n        if self.completion:\n            nxt = self.completion.completer.cycle(forward)\n            buf = \"\".join([i.value for i in self.completion.parsed]) + nxt\n            self.text = buf\n            self.cursor = len(self.text)\n\n    def backspace(self) -> None:\n        if self.cursor == 0:\n            return\n        self.text = self.text[: self.cursor - 1] + self.text[self.cursor :]\n        self.cursor = self.cursor - 1\n        self.completion = None\n\n    def delete(self) -> None:\n        if self.cursor == len(self.text):\n            return\n        self.text = self.text[: self.cursor] + self.text[self.cursor + 1 :]\n        self.completion = None\n\n    def insert(self, k: str) -> None:\n        \"\"\"\n        Inserts text at the cursor.\n        \"\"\"\n\n        # We don't want to insert a space before the command\n        if k == \" \" and self.text[0 : self.cursor].strip() == \"\":\n            return\n\n        self.text = self.text[: self.cursor] + k + self.text[self.cursor :]\n        self.cursor += len(k)\n        self.completion = None\n\n\nclass CommandEdit(urwid.WidgetWrap):\n    leader = \": \"\n\n    def __init__(self, master: mitmproxy.master.Master, text: str) -> None:\n        super().__init__(urwid.Text(self.leader))\n        self.master = master\n        self.active_filter = False\n        self.filter_str = \"\"\n        self.cbuf = CommandBuffer(master, text)\n        self.update()\n\n    def keypress(self, size, key) -> None:\n        if key == \"delete\":\n            self.cbuf.delete()\n        elif key == \"ctrl a\" or key == \"home\":\n            self.cbuf.cursor = 0\n        elif key == \"ctrl e\" or key == \"end\":\n            self.cbuf.cursor = len(self.cbuf.text)\n        elif key == \"meta b\":\n            self.cbuf.cursor = self.cbuf.text.rfind(\" \", 0, self.cbuf.cursor)\n        elif key == \"meta f\":\n            pos = self.cbuf.text.find(\" \", self.cbuf.cursor + 1)\n            if pos == -1:\n                pos = len(self.cbuf.text)\n            self.cbuf.cursor = pos\n        elif key == \"ctrl w\":\n            prev_cursor = self.cbuf.cursor\n            pos = self.cbuf.text.rfind(\" \", 0, self.cbuf.cursor - 1)\n            if pos == -1:\n                new_text = self.cbuf.text[self.cbuf.cursor :]\n                cursor_pos = 0\n            else:\n                txt_after = self.cbuf.text[self.cbuf.cursor :]\n                txt_before = self.cbuf.text[0:pos]\n                new_text = f\"{txt_before} {txt_after}\"\n                cursor_pos = prev_cursor - (prev_cursor - pos) + 1\n            self.cbuf.set_text(new_text)\n            self.cbuf.cursor = cursor_pos\n        elif key == \"backspace\":\n            self.cbuf.backspace()\n            if self.cbuf.text == \"\":\n                self.active_filter = False\n                self.master.commands.call(\"commands.history.filter\", \"\")\n                self.filter_str = \"\"\n        elif key == \"left\" or key == \"ctrl b\":\n            self.cbuf.left()\n        elif key == \"right\" or key == \"ctrl f\":\n            self.cbuf.right()\n        elif key == \"up\" or key == \"ctrl p\":\n            if self.active_filter is False:\n                self.active_filter = True\n                self.filter_str = self.cbuf.text\n                self.master.commands.call(\"commands.history.filter\", self.cbuf.text)\n            cmd = self.master.commands.execute(\"commands.history.prev\")\n            self.cbuf = CommandBuffer(self.master, cmd)\n        elif key == \"down\" or key == \"ctrl n\":\n            prev_cmd = self.cbuf.text\n            cmd = self.master.commands.execute(\"commands.history.next\")\n\n            if cmd == \"\":\n                if prev_cmd == self.filter_str:\n                    self.cbuf = CommandBuffer(self.master, prev_cmd)\n                else:\n                    self.active_filter = False\n                    self.master.commands.call(\"commands.history.filter\", \"\")\n                    self.filter_str = \"\"\n                    self.cbuf = CommandBuffer(self.master, \"\")\n            else:\n                self.cbuf = CommandBuffer(self.master, cmd)\n        elif key == \"shift tab\":\n            self.cbuf.cycle_completion(False)\n        elif key == \"tab\":\n            self.cbuf.cycle_completion()\n        elif len(key) == 1:\n            self.cbuf.insert(key)\n        self.update()\n\n    def update(self) -> None:\n        self._w.set_text([self.leader, self.cbuf.render()])\n\n    def render(self, size, focus=False) -> urwid.Canvas:\n        (maxcol,) = size\n        canv = self._w.render((maxcol,))\n        canv = urwid.CompositeCanvas(canv)\n        canv.cursor = self.get_cursor_coords((maxcol,))\n        return canv\n\n    def get_cursor_coords(self, size) -> tuple[int, int]:\n        p = self.cbuf.cursor + len(self.leader)\n        trans = self._w.get_line_translation(size[0])\n        x, y = calc_coords(self._w.get_text()[0], trans, p)\n        return x, y\n\n    def get_edit_text(self) -> str:\n        return self.cbuf.text\n", "mitmproxy/tools/console/commander/__init__.py": "", "mitmproxy/tools/web/webaddons.py": "import logging\nimport webbrowser\nfrom collections.abc import Sequence\n\nfrom mitmproxy import ctx\n\n\nclass WebAddon:\n    def load(self, loader):\n        loader.add_option(\"web_open_browser\", bool, True, \"Start a browser.\")\n        loader.add_option(\"web_debug\", bool, False, \"Enable mitmweb debugging.\")\n        loader.add_option(\"web_port\", int, 8081, \"Web UI port.\")\n        loader.add_option(\"web_host\", str, \"127.0.0.1\", \"Web UI host.\")\n        loader.add_option(\n            \"web_columns\",\n            Sequence[str],\n            [\"tls\", \"icon\", \"path\", \"method\", \"status\", \"size\", \"time\"],\n            \"Columns to show in the flow list\",\n        )\n\n    def running(self):\n        if hasattr(ctx.options, \"web_open_browser\") and ctx.options.web_open_browser:\n            web_url = f\"http://{ctx.options.web_host}:{ctx.options.web_port}/\"\n            success = open_browser(web_url)\n            if not success:\n                logging.info(\n                    f\"No web browser found. Please open a browser and point it to {web_url}\",\n                )\n\n\ndef open_browser(url: str) -> bool:\n    \"\"\"\n    Open a URL in a browser window.\n    In contrast to webbrowser.open, we limit the list of suitable browsers.\n    This gracefully degrades to a no-op on headless servers, where webbrowser.open\n    would otherwise open lynx.\n\n    Returns:\n        True, if a browser has been opened\n        False, if no suitable browser has been found.\n    \"\"\"\n    browsers = (\n        \"windows-default\",\n        \"macosx\",\n        \"wslview %s\",\n        \"gio\",\n        \"x-www-browser\",\n        \"gnome-open %s\",\n        \"xdg-open\",\n        \"google-chrome\",\n        \"chrome\",\n        \"chromium\",\n        \"chromium-browser\",\n        \"firefox\",\n        \"opera\",\n        \"safari\",\n    )\n    for browser in browsers:\n        try:\n            b = webbrowser.get(browser)\n        except webbrowser.Error:\n            pass\n        else:\n            if b.open(url):\n                return True\n    return False\n", "mitmproxy/tools/web/master.py": "import errno\nimport logging\n\nimport tornado.httpserver\nimport tornado.ioloop\n\nfrom mitmproxy import addons\nfrom mitmproxy import flow\nfrom mitmproxy import log\nfrom mitmproxy import master\nfrom mitmproxy import options\nfrom mitmproxy import optmanager\nfrom mitmproxy.addons import errorcheck\nfrom mitmproxy.addons import eventstore\nfrom mitmproxy.addons import intercept\nfrom mitmproxy.addons import readfile\nfrom mitmproxy.addons import view\nfrom mitmproxy.addons.proxyserver import Proxyserver\nfrom mitmproxy.tools.web import app\nfrom mitmproxy.tools.web import static_viewer\nfrom mitmproxy.tools.web import webaddons\n\nlogger = logging.getLogger(__name__)\n\n\nclass WebMaster(master.Master):\n    def __init__(self, opts: options.Options, with_termlog: bool = True):\n        super().__init__(opts, with_termlog=with_termlog)\n        self.view = view.View()\n        self.view.sig_view_add.connect(self._sig_view_add)\n        self.view.sig_view_remove.connect(self._sig_view_remove)\n        self.view.sig_view_update.connect(self._sig_view_update)\n        self.view.sig_view_refresh.connect(self._sig_view_refresh)\n\n        self.events = eventstore.EventStore()\n        self.events.sig_add.connect(self._sig_events_add)\n        self.events.sig_refresh.connect(self._sig_events_refresh)\n\n        self.options.changed.connect(self._sig_options_update)\n\n        self.addons.add(*addons.default_addons())\n        self.addons.add(\n            webaddons.WebAddon(),\n            intercept.Intercept(),\n            readfile.ReadFileStdin(),\n            static_viewer.StaticViewer(),\n            self.view,\n            self.events,\n            errorcheck.ErrorCheck(),\n        )\n        self.app = app.Application(self, self.options.web_debug)\n        self.proxyserver: Proxyserver = self.addons.get(\"proxyserver\")\n        self.proxyserver.servers.changed.connect(self._sig_servers_changed)\n\n    def _sig_view_add(self, flow: flow.Flow) -> None:\n        app.ClientConnection.broadcast(\n            resource=\"flows\", cmd=\"add\", data=app.flow_to_json(flow)\n        )\n\n    def _sig_view_update(self, flow: flow.Flow) -> None:\n        app.ClientConnection.broadcast(\n            resource=\"flows\", cmd=\"update\", data=app.flow_to_json(flow)\n        )\n\n    def _sig_view_remove(self, flow: flow.Flow, index: int) -> None:\n        app.ClientConnection.broadcast(resource=\"flows\", cmd=\"remove\", data=flow.id)\n\n    def _sig_view_refresh(self) -> None:\n        app.ClientConnection.broadcast(resource=\"flows\", cmd=\"reset\")\n\n    def _sig_events_add(self, entry: log.LogEntry) -> None:\n        app.ClientConnection.broadcast(\n            resource=\"events\", cmd=\"add\", data=app.logentry_to_json(entry)\n        )\n\n    def _sig_events_refresh(self) -> None:\n        app.ClientConnection.broadcast(resource=\"events\", cmd=\"reset\")\n\n    def _sig_options_update(self, updated: set[str]) -> None:\n        options_dict = optmanager.dump_dicts(self.options, updated)\n        app.ClientConnection.broadcast(\n            resource=\"options\", cmd=\"update\", data=options_dict\n        )\n\n    def _sig_servers_changed(self) -> None:\n        app.ClientConnection.broadcast(\n            resource=\"state\",\n            cmd=\"update\",\n            data={\"servers\": [s.to_json() for s in self.proxyserver.servers]},\n        )\n\n    async def running(self):\n        # Register tornado with the current event loop\n        tornado.ioloop.IOLoop.current()\n\n        # Add our web app.\n        http_server = tornado.httpserver.HTTPServer(\n            self.app, max_buffer_size=2**32\n        )  # 4GB\n        try:\n            http_server.listen(self.options.web_port, self.options.web_host)\n        except OSError as e:\n            message = f\"Web server failed to listen on {self.options.web_host or '*'}:{self.options.web_port} with {e}\"\n            if e.errno == errno.EADDRINUSE:\n                message += f\"\\nTry specifying a different port by using `--set web_port={self.options.web_port + 2}`.\"\n            raise OSError(e.errno, message, e.filename) from e\n\n        logger.info(\n            f\"Web server listening at http://{self.options.web_host}:{self.options.web_port}/\",\n        )\n\n        return await super().running()\n", "mitmproxy/tools/web/static_viewer.py": "import json\nimport logging\nimport os.path\nimport pathlib\nimport shutil\nimport time\nfrom collections.abc import Iterable\nfrom typing import Optional\n\nfrom mitmproxy import contentviews\nfrom mitmproxy import ctx\nfrom mitmproxy import flow\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy import io\nfrom mitmproxy import version\nfrom mitmproxy.tools.web.app import flow_to_json\n\nweb_dir = pathlib.Path(__file__).absolute().parent\n\n\ndef save_static(path: pathlib.Path) -> None:\n    \"\"\"\n    Save the files for the static web view.\n    \"\"\"\n    # We want to overwrite the static files to keep track of the update.\n    if (path / \"static\").exists():\n        shutil.rmtree(str(path / \"static\"))\n    shutil.copytree(str(web_dir / \"static\"), str(path / \"static\"))\n    shutil.copyfile(str(web_dir / \"templates\" / \"index.html\"), str(path / \"index.html\"))\n\n    with open(str(path / \"static\" / \"static.js\"), \"w\") as f:\n        f.write(\"MITMWEB_STATIC = true;\")\n\n\ndef save_filter_help(path: pathlib.Path) -> None:\n    with open(str(path / \"filter-help.json\"), \"w\") as f:\n        json.dump(dict(commands=flowfilter.help), f)\n\n\ndef save_settings(path: pathlib.Path) -> None:\n    with open(str(path / \"settings.json\"), \"w\") as f:\n        json.dump(dict(version=version.VERSION), f)\n\n\ndef save_flows(path: pathlib.Path, flows: Iterable[flow.Flow]) -> None:\n    with open(str(path / \"flows.json\"), \"w\") as f:\n        json.dump([flow_to_json(f) for f in flows], f)\n\n\ndef save_flows_content(path: pathlib.Path, flows: Iterable[flow.Flow]) -> None:\n    for f in flows:\n        assert isinstance(f, http.HTTPFlow)\n        for m in (\"request\", \"response\"):\n            message = getattr(f, m)\n            message_path = path / \"flows\" / f.id / m\n            os.makedirs(str(message_path / \"content\"), exist_ok=True)\n\n            with open(str(message_path / \"content.data\"), \"wb\") as content_file:\n                # don't use raw_content here as this is served with a default content type\n                if message:\n                    content_file.write(message.content)\n                else:\n                    content_file.write(b\"No content.\")\n\n            # content_view\n            t = time.time()\n            if message:\n                description, lines, error = contentviews.get_message_content_view(\n                    \"Auto\", message, f\n                )\n            else:\n                description, lines = \"No content.\", []\n            if time.time() - t > 0.1:\n                logging.info(\n                    f\"Slow content view: {description.strip()} took {round(time.time() - t, 1)}s\",\n                )\n            with open(\n                str(message_path / \"content\" / \"Auto.json\"), \"w\"\n            ) as content_view_file:\n                json.dump(\n                    dict(lines=list(lines), description=description), content_view_file\n                )\n\n\nclass StaticViewer:\n    # TODO: make this a command at some point.\n    def load(self, loader):\n        loader.add_option(\n            \"web_static_viewer\",\n            Optional[str],\n            \"\",\n            \"The path to output a static viewer.\",\n        )\n\n    def configure(self, updated):\n        if \"web_static_viewer\" in updated and ctx.options.web_static_viewer:\n            flows = io.read_flows_from_paths([ctx.options.rfile])\n            p = pathlib.Path(ctx.options.web_static_viewer).expanduser()\n            self.export(p, flows)\n\n    def export(self, path: pathlib.Path, flows: Iterable[flow.Flow]) -> None:\n        save_static(path)\n        save_filter_help(path)\n        save_flows(path, flows)\n        save_flows_content(path, flows)\n", "mitmproxy/tools/web/__init__.py": "from mitmproxy.tools.web import master\n\n__all__ = [\"master\"]\n", "mitmproxy/tools/web/app.py": "from __future__ import annotations\n\nimport asyncio\nimport hashlib\nimport json\nimport logging\nimport os.path\nimport re\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom io import BytesIO\nfrom itertools import islice\nfrom typing import ClassVar\n\nimport tornado.escape\nimport tornado.web\nimport tornado.websocket\n\nimport mitmproxy.flow\nimport mitmproxy.tools.web.master\nfrom mitmproxy import certs\nfrom mitmproxy import command\nfrom mitmproxy import contentviews\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy import io\nfrom mitmproxy import log\nfrom mitmproxy import optmanager\nfrom mitmproxy import version\nfrom mitmproxy.dns import DNSFlow\nfrom mitmproxy.http import HTTPFlow\nfrom mitmproxy.tcp import TCPFlow\nfrom mitmproxy.tcp import TCPMessage\nfrom mitmproxy.udp import UDPFlow\nfrom mitmproxy.udp import UDPMessage\nfrom mitmproxy.utils.emoji import emoji\nfrom mitmproxy.utils.strutils import always_str\nfrom mitmproxy.websocket import WebSocketMessage\n\n\ndef cert_to_json(certs: Sequence[certs.Cert]) -> dict | None:\n    if not certs:\n        return None\n    cert = certs[0]\n    return {\n        \"keyinfo\": cert.keyinfo,\n        \"sha256\": cert.fingerprint().hex(),\n        \"notbefore\": int(cert.notbefore.timestamp()),\n        \"notafter\": int(cert.notafter.timestamp()),\n        \"serial\": str(cert.serial),\n        \"subject\": cert.subject,\n        \"issuer\": cert.issuer,\n        \"altnames\": [str(x.value) for x in cert.altnames],\n    }\n\n\ndef flow_to_json(flow: mitmproxy.flow.Flow) -> dict:\n    \"\"\"\n    Remove flow message content and cert to save transmission space.\n    Args:\n        flow: The original flow.\n    Sync with web/src/flow.ts.\n    \"\"\"\n    f = {\n        \"id\": flow.id,\n        \"intercepted\": flow.intercepted,\n        \"is_replay\": flow.is_replay,\n        \"type\": flow.type,\n        \"modified\": flow.modified(),\n        \"marked\": emoji.get(flow.marked, \"\ud83d\udd34\") if flow.marked else \"\",\n        \"comment\": flow.comment,\n        \"timestamp_created\": flow.timestamp_created,\n    }\n\n    if flow.client_conn:\n        f[\"client_conn\"] = {\n            \"id\": flow.client_conn.id,\n            \"peername\": flow.client_conn.peername,\n            \"sockname\": flow.client_conn.sockname,\n            \"tls_established\": flow.client_conn.tls_established,\n            \"cert\": cert_to_json(flow.client_conn.certificate_list),\n            \"sni\": flow.client_conn.sni,\n            \"cipher\": flow.client_conn.cipher,\n            \"alpn\": always_str(flow.client_conn.alpn, \"ascii\", \"backslashreplace\"),\n            \"tls_version\": flow.client_conn.tls_version,\n            \"timestamp_start\": flow.client_conn.timestamp_start,\n            \"timestamp_tls_setup\": flow.client_conn.timestamp_tls_setup,\n            \"timestamp_end\": flow.client_conn.timestamp_end,\n        }\n\n    if flow.server_conn:\n        f[\"server_conn\"] = {\n            \"id\": flow.server_conn.id,\n            \"peername\": flow.server_conn.peername,\n            \"sockname\": flow.server_conn.sockname,\n            \"address\": flow.server_conn.address,\n            \"tls_established\": flow.server_conn.tls_established,\n            \"cert\": cert_to_json(flow.server_conn.certificate_list),\n            \"sni\": flow.server_conn.sni,\n            \"cipher\": flow.server_conn.cipher,\n            \"alpn\": always_str(flow.server_conn.alpn, \"ascii\", \"backslashreplace\"),\n            \"tls_version\": flow.server_conn.tls_version,\n            \"timestamp_start\": flow.server_conn.timestamp_start,\n            \"timestamp_tcp_setup\": flow.server_conn.timestamp_tcp_setup,\n            \"timestamp_tls_setup\": flow.server_conn.timestamp_tls_setup,\n            \"timestamp_end\": flow.server_conn.timestamp_end,\n        }\n    if flow.error:\n        f[\"error\"] = flow.error.get_state()\n\n    if isinstance(flow, HTTPFlow):\n        content_length: int | None\n        content_hash: str | None\n\n        if flow.request.raw_content is not None:\n            content_length = len(flow.request.raw_content)\n            content_hash = hashlib.sha256(flow.request.raw_content).hexdigest()\n        else:\n            content_length = None\n            content_hash = None\n        f[\"request\"] = {\n            \"method\": flow.request.method,\n            \"scheme\": flow.request.scheme,\n            \"host\": flow.request.host,\n            \"port\": flow.request.port,\n            \"path\": flow.request.path,\n            \"http_version\": flow.request.http_version,\n            \"headers\": tuple(flow.request.headers.items(True)),\n            \"contentLength\": content_length,\n            \"contentHash\": content_hash,\n            \"timestamp_start\": flow.request.timestamp_start,\n            \"timestamp_end\": flow.request.timestamp_end,\n            \"pretty_host\": flow.request.pretty_host,\n        }\n        if flow.response:\n            if flow.response.raw_content is not None:\n                content_length = len(flow.response.raw_content)\n                content_hash = hashlib.sha256(flow.response.raw_content).hexdigest()\n            else:\n                content_length = None\n                content_hash = None\n            f[\"response\"] = {\n                \"http_version\": flow.response.http_version,\n                \"status_code\": flow.response.status_code,\n                \"reason\": flow.response.reason,\n                \"headers\": tuple(flow.response.headers.items(True)),\n                \"contentLength\": content_length,\n                \"contentHash\": content_hash,\n                \"timestamp_start\": flow.response.timestamp_start,\n                \"timestamp_end\": flow.response.timestamp_end,\n            }\n            if flow.response.data.trailers:\n                f[\"response\"][\"trailers\"] = tuple(\n                    flow.response.data.trailers.items(True)\n                )\n\n        if flow.websocket:\n            f[\"websocket\"] = {\n                \"messages_meta\": {\n                    \"contentLength\": sum(\n                        len(x.content) for x in flow.websocket.messages\n                    ),\n                    \"count\": len(flow.websocket.messages),\n                    \"timestamp_last\": flow.websocket.messages[-1].timestamp\n                    if flow.websocket.messages\n                    else None,\n                },\n                \"closed_by_client\": flow.websocket.closed_by_client,\n                \"close_code\": flow.websocket.close_code,\n                \"close_reason\": flow.websocket.close_reason,\n                \"timestamp_end\": flow.websocket.timestamp_end,\n            }\n    elif isinstance(flow, (TCPFlow, UDPFlow)):\n        f[\"messages_meta\"] = {\n            \"contentLength\": sum(len(x.content) for x in flow.messages),\n            \"count\": len(flow.messages),\n            \"timestamp_last\": flow.messages[-1].timestamp if flow.messages else None,\n        }\n    elif isinstance(flow, DNSFlow):\n        f[\"request\"] = flow.request.to_json()\n        if flow.response:\n            f[\"response\"] = flow.response.to_json()\n\n    return f\n\n\ndef logentry_to_json(e: log.LogEntry) -> dict:\n    return {\n        \"id\": id(e),  # we just need some kind of id.\n        \"message\": e.msg,\n        \"level\": e.level,\n    }\n\n\nclass APIError(tornado.web.HTTPError):\n    pass\n\n\nclass RequestHandler(tornado.web.RequestHandler):\n    application: Application\n\n    def write(self, chunk: str | bytes | dict | list):\n        # Writing arrays on the top level is ok nowadays.\n        # http://flask.pocoo.org/docs/0.11/security/#json-security\n        if isinstance(chunk, list):\n            chunk = tornado.escape.json_encode(chunk)\n            self.set_header(\"Content-Type\", \"application/json; charset=UTF-8\")\n        super().write(chunk)\n\n    def set_default_headers(self):\n        super().set_default_headers()\n        self.set_header(\"Server\", version.MITMPROXY)\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.add_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.add_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.add_header(\n            \"Content-Security-Policy\",\n            \"default-src 'self'; \"\n            \"connect-src 'self' ws:; \"\n            \"style-src   'self' 'unsafe-inline'\",\n        )\n\n    @property\n    def json(self):\n        if not self.request.headers.get(\"Content-Type\", \"\").startswith(\n            \"application/json\"\n        ):\n            raise APIError(400, \"Invalid Content-Type, expected application/json.\")\n        try:\n            return json.loads(self.request.body.decode())\n        except Exception as e:\n            raise APIError(400, f\"Malformed JSON: {str(e)}\")\n\n    @property\n    def filecontents(self):\n        \"\"\"\n        Accept either a multipart/form file upload or just take the plain request body.\n\n        \"\"\"\n        if self.request.files:\n            return next(iter(self.request.files.values()))[0].body\n        else:\n            return self.request.body\n\n    @property\n    def view(self) -> mitmproxy.addons.view.View:\n        return self.application.master.view\n\n    @property\n    def master(self) -> mitmproxy.tools.web.master.WebMaster:\n        return self.application.master\n\n    @property\n    def flow(self) -> mitmproxy.flow.Flow:\n        flow_id = str(self.path_kwargs[\"flow_id\"])\n        # FIXME: Add a facility to addon.view to safely access the store\n        flow = self.view.get_by_id(flow_id)\n        if flow:\n            return flow\n        else:\n            raise APIError(404, \"Flow not found.\")\n\n    def write_error(self, status_code: int, **kwargs):\n        if \"exc_info\" in kwargs and isinstance(kwargs[\"exc_info\"][1], APIError):\n            self.finish(kwargs[\"exc_info\"][1].log_message)\n        else:\n            super().write_error(status_code, **kwargs)\n\n\nclass IndexHandler(RequestHandler):\n    def get(self):\n        token = self.xsrf_token  # https://github.com/tornadoweb/tornado/issues/645\n        assert token\n        self.render(\"index.html\")\n\n\nclass FilterHelp(RequestHandler):\n    def get(self):\n        self.write(dict(commands=flowfilter.help))\n\n\nclass WebSocketEventBroadcaster(tornado.websocket.WebSocketHandler):\n    # raise an error if inherited class doesn't specify its own instance.\n    connections: ClassVar[set[WebSocketEventBroadcaster]]\n    _send_tasks: ClassVar[set[asyncio.Task]] = set()\n\n    def open(self):\n        self.connections.add(self)\n\n    def on_close(self):\n        self.connections.discard(self)\n\n    @classmethod\n    def send(cls, conn: WebSocketEventBroadcaster, message: bytes) -> None:\n        async def wrapper():\n            try:\n                await conn.write_message(message)\n            except tornado.websocket.WebSocketClosedError:\n                cls.connections.discard(conn)\n\n        t = asyncio.create_task(wrapper())\n        cls._send_tasks.add(t)\n        t.add_done_callback(cls._send_tasks.remove)\n\n    @classmethod\n    def broadcast(cls, **kwargs):\n        message = json.dumps(kwargs, ensure_ascii=False).encode(\n            \"utf8\", \"surrogateescape\"\n        )\n\n        for conn in cls.connections.copy():\n            cls.send(conn, message)\n\n\nclass ClientConnection(WebSocketEventBroadcaster):\n    connections: ClassVar[set] = set()\n\n\nclass Flows(RequestHandler):\n    def get(self):\n        self.write([flow_to_json(f) for f in self.view])\n\n\nclass DumpFlows(RequestHandler):\n    def get(self) -> None:\n        self.set_header(\"Content-Disposition\", \"attachment; filename=flows\")\n        self.set_header(\"Content-Type\", \"application/octet-stream\")\n\n        match: Callable[[mitmproxy.flow.Flow], bool]\n        try:\n            match = flowfilter.parse(self.request.arguments[\"filter\"][0].decode())\n        except ValueError:  # thrown py flowfilter.parse if filter is invalid\n            raise APIError(400, f\"Invalid filter argument / regex\")\n        except (\n            KeyError,\n            IndexError,\n        ):  # Key+Index: [\"filter\"][0] can fail, if it's not set\n\n            def match(_) -> bool:\n                return True\n\n        with BytesIO() as bio:\n            fw = io.FlowWriter(bio)\n            for f in self.view:\n                if match(f):\n                    fw.add(f)\n            self.write(bio.getvalue())\n\n    async def post(self):\n        self.view.clear()\n        bio = BytesIO(self.filecontents)\n        for f in io.FlowReader(bio).stream():\n            await self.master.load_flow(f)\n        bio.close()\n\n\nclass ClearAll(RequestHandler):\n    def post(self):\n        self.view.clear()\n        self.master.events.clear()\n\n\nclass ResumeFlows(RequestHandler):\n    def post(self):\n        for f in self.view:\n            if not f.intercepted:\n                continue\n            f.resume()\n            self.view.update([f])\n\n\nclass KillFlows(RequestHandler):\n    def post(self):\n        for f in self.view:\n            if f.killable:\n                f.kill()\n                self.view.update([f])\n\n\nclass ResumeFlow(RequestHandler):\n    def post(self, flow_id):\n        self.flow.resume()\n        self.view.update([self.flow])\n\n\nclass KillFlow(RequestHandler):\n    def post(self, flow_id):\n        if self.flow.killable:\n            self.flow.kill()\n            self.view.update([self.flow])\n\n\nclass FlowHandler(RequestHandler):\n    def delete(self, flow_id):\n        if self.flow.killable:\n            self.flow.kill()\n        self.view.remove([self.flow])\n\n    def put(self, flow_id) -> None:\n        flow: mitmproxy.flow.Flow = self.flow\n        flow.backup()\n        try:\n            for a, b in self.json.items():\n                if a == \"request\" and hasattr(flow, \"request\"):\n                    request: mitmproxy.http.Request = flow.request\n                    for k, v in b.items():\n                        if k in [\"method\", \"scheme\", \"host\", \"path\", \"http_version\"]:\n                            setattr(request, k, str(v))\n                        elif k == \"port\":\n                            request.port = int(v)\n                        elif k == \"headers\":\n                            request.headers.clear()\n                            for header in v:\n                                request.headers.add(*header)\n                        elif k == \"trailers\":\n                            if request.trailers is not None:\n                                request.trailers.clear()\n                            else:\n                                request.trailers = mitmproxy.http.Headers()\n                            for trailer in v:\n                                request.trailers.add(*trailer)\n                        elif k == \"content\":\n                            request.text = v\n                        else:\n                            raise APIError(400, f\"Unknown update request.{k}: {v}\")\n\n                elif a == \"response\" and hasattr(flow, \"response\"):\n                    response: mitmproxy.http.Response = flow.response\n                    for k, v in b.items():\n                        if k in [\"msg\", \"http_version\"]:\n                            setattr(response, k, str(v))\n                        elif k == \"code\":\n                            response.status_code = int(v)\n                        elif k == \"headers\":\n                            response.headers.clear()\n                            for header in v:\n                                response.headers.add(*header)\n                        elif k == \"trailers\":\n                            if response.trailers is not None:\n                                response.trailers.clear()\n                            else:\n                                response.trailers = mitmproxy.http.Headers()\n                            for trailer in v:\n                                response.trailers.add(*trailer)\n                        elif k == \"content\":\n                            response.text = v\n                        else:\n                            raise APIError(400, f\"Unknown update response.{k}: {v}\")\n                elif a == \"marked\":\n                    flow.marked = b\n                elif a == \"comment\":\n                    flow.comment = b\n                else:\n                    raise APIError(400, f\"Unknown update {a}: {b}\")\n        except APIError:\n            flow.revert()\n            raise\n        self.view.update([flow])\n\n\nclass DuplicateFlow(RequestHandler):\n    def post(self, flow_id):\n        f = self.flow.copy()\n        self.view.add([f])\n        self.write(f.id)\n\n\nclass RevertFlow(RequestHandler):\n    def post(self, flow_id):\n        if self.flow.modified():\n            self.flow.revert()\n            self.view.update([self.flow])\n\n\nclass ReplayFlow(RequestHandler):\n    def post(self, flow_id):\n        self.master.commands.call(\"replay.client\", [self.flow])\n\n\nclass FlowContent(RequestHandler):\n    def post(self, flow_id, message):\n        self.flow.backup()\n        message = getattr(self.flow, message)\n        message.content = self.filecontents\n        self.view.update([self.flow])\n\n    def get(self, flow_id, message):\n        message = getattr(self.flow, message)\n        assert isinstance(self.flow, HTTPFlow)\n\n        original_cd = message.headers.get(\"Content-Disposition\", None)\n        filename = None\n        if original_cd:\n            if m := re.search(r'filename=([-\\w\" .()]+)', original_cd):\n                filename = m.group(1)\n        if not filename:\n            filename = self.flow.request.path.split(\"?\")[0].split(\"/\")[-1]\n\n        filename = re.sub(r'[^-\\w\" .()]', \"\", filename)\n        cd = f\"attachment; filename={filename}\"\n        self.set_header(\"Content-Disposition\", cd)\n        self.set_header(\"Content-Type\", \"application/text\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.write(message.get_content(strict=False))\n\n\nclass FlowContentView(RequestHandler):\n    def message_to_json(\n        self,\n        viewname: str,\n        message: http.Message | TCPMessage | UDPMessage | WebSocketMessage,\n        flow: HTTPFlow | TCPFlow | UDPFlow,\n        max_lines: int | None = None,\n    ):\n        description, lines, error = contentviews.get_message_content_view(\n            viewname, message, flow\n        )\n        if error:\n            logging.error(error)\n        if max_lines:\n            lines = islice(lines, max_lines)\n\n        return dict(\n            lines=list(lines),\n            description=description,\n        )\n\n    def get(self, flow_id, message, content_view) -> None:\n        flow = self.flow\n        assert isinstance(flow, (HTTPFlow, TCPFlow, UDPFlow))\n\n        if self.request.arguments.get(\"lines\"):\n            max_lines = int(self.request.arguments[\"lines\"][0])\n        else:\n            max_lines = None\n\n        if message == \"messages\":\n            messages: list[TCPMessage] | list[UDPMessage] | list[WebSocketMessage]\n            if isinstance(flow, HTTPFlow) and flow.websocket:\n                messages = flow.websocket.messages\n            elif isinstance(flow, (TCPFlow, UDPFlow)):\n                messages = flow.messages\n            else:\n                raise APIError(400, f\"This flow has no messages.\")\n            msgs = []\n            for m in messages:\n                d = self.message_to_json(content_view, m, flow, max_lines)\n                d[\"from_client\"] = m.from_client\n                d[\"timestamp\"] = m.timestamp\n                msgs.append(d)\n                if max_lines:\n                    max_lines -= len(d[\"lines\"])\n                    if max_lines <= 0:\n                        break\n            self.write(msgs)\n        else:\n            message = getattr(self.flow, message)\n            self.write(self.message_to_json(content_view, message, flow, max_lines))\n\n\nclass Commands(RequestHandler):\n    def get(self) -> None:\n        commands = {}\n        for name, cmd in self.master.commands.commands.items():\n            commands[name] = {\n                \"help\": cmd.help,\n                \"parameters\": [\n                    {\n                        \"name\": param.name,\n                        \"type\": command.typename(param.type),\n                        \"kind\": str(param.kind),\n                    }\n                    for param in cmd.parameters\n                ],\n                \"return_type\": command.typename(cmd.return_type)\n                if cmd.return_type\n                else None,\n                \"signature_help\": cmd.signature_help(),\n            }\n        self.write(commands)\n\n\nclass ExecuteCommand(RequestHandler):\n    def post(self, cmd: str):\n        # TODO: We should parse query strings here, this API is painful.\n        try:\n            args = self.json[\"arguments\"]\n        except APIError:\n            args = []\n        try:\n            result = self.master.commands.call_strings(cmd, args)\n        except Exception as e:\n            self.write({\"error\": str(e)})\n        else:\n            self.write(\n                {\n                    \"value\": result,\n                    # \"type\": command.typename(type(result)) if result is not None else \"none\"\n                }\n            )\n\n\nclass Events(RequestHandler):\n    def get(self):\n        self.write([logentry_to_json(e) for e in self.master.events.data])\n\n\nclass Options(RequestHandler):\n    def get(self):\n        self.write(optmanager.dump_dicts(self.master.options))\n\n    def put(self):\n        update = self.json\n        try:\n            self.master.options.update(**update)\n        except Exception as err:\n            raise APIError(400, f\"{err}\")\n\n\nclass SaveOptions(RequestHandler):\n    def post(self):\n        # try:\n        #     optmanager.save(self.master.options, CONFIG_PATH, True)\n        # except Exception as err:\n        #     raise APIError(400, \"{}\".format(err))\n        pass\n\n\nclass DnsRebind(RequestHandler):\n    def get(self):\n        raise tornado.web.HTTPError(\n            403,\n            reason=\"To protect against DNS rebinding, mitmweb can only be accessed by IP at the moment. \"\n            \"(https://github.com/mitmproxy/mitmproxy/issues/3234)\",\n        )\n\n\nclass State(RequestHandler):\n    # Separate method for testability.\n    @staticmethod\n    def get_json(master: mitmproxy.tools.web.master.WebMaster):\n        return {\n            \"version\": version.VERSION,\n            \"contentViews\": [v.name for v in contentviews.views if v.name != \"Query\"],\n            \"servers\": [s.to_json() for s in master.proxyserver.servers],\n        }\n\n    def get(self):\n        self.write(State.get_json(self.master))\n\n\nclass GZipContentAndFlowFiles(tornado.web.GZipContentEncoding):\n    CONTENT_TYPES = {\n        \"application/octet-stream\",\n        *tornado.web.GZipContentEncoding.CONTENT_TYPES,\n    }\n\n\nclass Application(tornado.web.Application):\n    master: mitmproxy.tools.web.master.WebMaster\n\n    def __init__(\n        self, master: mitmproxy.tools.web.master.WebMaster, debug: bool\n    ) -> None:\n        self.master = master\n        super().__init__(\n            default_host=\"dns-rebind-protection\",\n            template_path=os.path.join(os.path.dirname(__file__), \"templates\"),\n            static_path=os.path.join(os.path.dirname(__file__), \"static\"),\n            xsrf_cookies=True,\n            cookie_secret=os.urandom(256),\n            debug=debug,\n            autoreload=False,\n            transforms=[GZipContentAndFlowFiles],\n        )\n\n        self.add_handlers(\"dns-rebind-protection\", [(r\"/.*\", DnsRebind)])\n        self.add_handlers(\n            # make mitmweb accessible by IP only to prevent DNS rebinding.\n            r\"^(localhost|[0-9.]+|\\[[0-9a-fA-F:]+\\])$\",\n            [\n                (r\"/\", IndexHandler),\n                (r\"/filter-help(?:\\.json)?\", FilterHelp),\n                (r\"/updates\", ClientConnection),\n                (r\"/commands(?:\\.json)?\", Commands),\n                (r\"/commands/(?P<cmd>[a-z.]+)\", ExecuteCommand),\n                (r\"/events(?:\\.json)?\", Events),\n                (r\"/flows(?:\\.json)?\", Flows),\n                (r\"/flows/dump\", DumpFlows),\n                (r\"/flows/resume\", ResumeFlows),\n                (r\"/flows/kill\", KillFlows),\n                (r\"/flows/(?P<flow_id>[0-9a-f\\-]+)\", FlowHandler),\n                (r\"/flows/(?P<flow_id>[0-9a-f\\-]+)/resume\", ResumeFlow),\n                (r\"/flows/(?P<flow_id>[0-9a-f\\-]+)/kill\", KillFlow),\n                (r\"/flows/(?P<flow_id>[0-9a-f\\-]+)/duplicate\", DuplicateFlow),\n                (r\"/flows/(?P<flow_id>[0-9a-f\\-]+)/replay\", ReplayFlow),\n                (r\"/flows/(?P<flow_id>[0-9a-f\\-]+)/revert\", RevertFlow),\n                (\n                    r\"/flows/(?P<flow_id>[0-9a-f\\-]+)/(?P<message>request|response|messages)/content.data\",\n                    FlowContent,\n                ),\n                (\n                    r\"/flows/(?P<flow_id>[0-9a-f\\-]+)/(?P<message>request|response|messages)/\"\n                    r\"content/(?P<content_view>[0-9a-zA-Z\\-\\_%]+)(?:\\.json)?\",\n                    FlowContentView,\n                ),\n                (r\"/clear\", ClearAll),\n                (r\"/options(?:\\.json)?\", Options),\n                (r\"/options/save\", SaveOptions),\n                (r\"/state(?:\\.json)?\", State),\n            ],\n        )\n", "mitmproxy/utils/bits.py": "def setbit(byte, offset, value):\n    \"\"\"\n    Set a bit in a byte to 1 if value is truthy, 0 if not.\n    \"\"\"\n    if value:\n        return byte | (1 << offset)\n    else:\n        return byte & ~(1 << offset)\n\n\ndef getbit(byte, offset):\n    mask = 1 << offset\n    return bool(byte & mask)\n", "mitmproxy/utils/debug.py": "import asyncio\nimport gc\nimport linecache\nimport os\nimport platform\nimport signal\nimport sys\nimport threading\nimport traceback\nfrom collections import Counter\nfrom contextlib import redirect_stdout\n\nfrom OpenSSL import SSL\n\nfrom mitmproxy import version\nfrom mitmproxy.utils import asyncio_utils\n\n\ndef dump_system_info():\n    mitmproxy_version = version.get_dev_version()\n    openssl_version: str | bytes = SSL.SSLeay_version(SSL.SSLEAY_VERSION)\n    if isinstance(openssl_version, bytes):\n        openssl_version = openssl_version.decode()\n\n    data = [\n        f\"Mitmproxy: {mitmproxy_version}\",\n        f\"Python:    {platform.python_version()}\",\n        f\"OpenSSL:   {openssl_version}\",\n        f\"Platform:  {platform.platform()}\",\n    ]\n    return \"\\n\".join(data)\n\n\ndef dump_info(signal=None, frame=None, file=sys.stdout):  # pragma: no cover\n    with redirect_stdout(file):\n        print(\"****************************************************\")\n        print(\"Summary\")\n        print(\"=======\")\n\n        try:\n            import psutil\n        except ModuleNotFoundError:\n            print(\"(psutil not installed, skipping some debug info)\")\n        else:\n            p = psutil.Process()\n            print(\"num threads: \", p.num_threads())\n            if hasattr(p, \"num_fds\"):\n                print(\"num fds: \", p.num_fds())\n            print(\"memory: \", p.memory_info())\n\n            print()\n            print(\"Files\")\n            print(\"=====\")\n            for i in p.open_files():\n                print(i)\n\n            print()\n            print(\"Connections\")\n            print(\"===========\")\n            for i in p.connections():\n                print(i)\n\n        print()\n        print(\"Threads\")\n        print(\"=======\")\n        bthreads = []\n        for i in threading.enumerate():\n            if hasattr(i, \"_threadinfo\"):\n                bthreads.append(i)\n            else:\n                print(i.name)\n        bthreads.sort(key=lambda x: x._thread_started)\n        for i in bthreads:\n            print(i._threadinfo())\n\n        print()\n        print(\"Memory\")\n        print(\"======\")\n        gc.collect()\n        objs = Counter(str(type(i)) for i in gc.get_objects())\n\n        for cls, count in objs.most_common(20):\n            print(f\"{count} {cls}\")\n\n        print()\n        print(\"Memory (mitmproxy only)\")\n        print(\"=======================\")\n        mitm_objs = Counter({k: v for k, v in objs.items() if \"mitmproxy\" in k})\n        for cls, count in mitm_objs.most_common(20):\n            print(f\"{count} {cls}\")\n\n        try:\n            asyncio.get_running_loop()\n        except RuntimeError:\n            pass\n        else:\n            print()\n            print(\"Tasks\")\n            print(\"=======\")\n            for task in asyncio.all_tasks():\n                f = task.get_stack(limit=1)[0]\n                line = linecache.getline(\n                    f.f_code.co_filename, f.f_lineno, f.f_globals\n                ).strip()\n                line = f\"{line}  # at {os.path.basename(f.f_code.co_filename)}:{f.f_lineno}\"\n                print(f\"{asyncio_utils.task_repr(task)}\\n\" f\"    {line}\")\n\n        print(\"****************************************************\")\n\n    if os.getenv(\"MITMPROXY_DEBUG_EXIT\"):  # pragma: no cover\n        sys.exit(1)\n\n\ndef dump_stacks(signal=None, frame=None, file=sys.stdout):\n    id2name = {th.ident: th.name for th in threading.enumerate()}\n    code = []\n    for threadId, stack in sys._current_frames().items():\n        code.append(\"\\n# Thread: %s(%d)\" % (id2name.get(threadId, \"\"), threadId))\n        for filename, lineno, name, line in traceback.extract_stack(stack):\n            code.append('File: \"%s\", line %d, in %s' % (filename, lineno, name))\n            if line:\n                code.append(\"  %s\" % (line.strip()))\n    print(\"\\n\".join(code), file=file)\n    if os.getenv(\"MITMPROXY_DEBUG_EXIT\"):  # pragma: no cover\n        sys.exit(1)\n\n\ndef register_info_dumpers():\n    if os.name != \"nt\":  # pragma: windows no cover\n        signal.signal(signal.SIGUSR1, dump_info)\n        signal.signal(signal.SIGUSR2, dump_stacks)\n", "mitmproxy/utils/emoji.py": "#!/usr/bin/env python3\n\"\"\"\nAll of the emoji and characters that can be used as flow markers.\n\"\"\"\n# auto-generated. run this file to refresh.\n\nemoji = {\n    \":+1:\": \"\ud83d\udc4d\",\n    \":-1:\": \"\ud83d\udc4e\",\n    \":100:\": \"\ud83d\udcaf\",\n    \":1234:\": \"\ud83d\udd22\",\n    \":1st_place_medal:\": \"\ud83e\udd47\",\n    \":2nd_place_medal:\": \"\ud83e\udd48\",\n    \":3rd_place_medal:\": \"\ud83e\udd49\",\n    \":8ball:\": \"\ud83c\udfb1\",\n    \":a:\": \"\ud83c\udd70\",\n    \":ab:\": \"\ud83c\udd8e\",\n    \":abacus:\": \"\ud83e\uddee\",\n    \":abc:\": \"\ud83d\udd24\",\n    \":abcd:\": \"\ud83d\udd21\",\n    \":accept:\": \"\ud83c\ude51\",\n    \":adhesive_bandage:\": \"\ud83e\ude79\",\n    \":adult:\": \"\ud83e\uddd1\",\n    \":aerial_tramway:\": \"\ud83d\udea1\",\n    \":afghanistan:\": \"\ud83c\udde6\u200d\ud83c\uddeb\",\n    \":airplane:\": \"\u2708\",\n    \":aland_islands:\": \"\ud83c\udde6\u200d\ud83c\uddfd\",\n    \":alarm_clock:\": \"\u23f0\",\n    \":albania:\": \"\ud83c\udde6\u200d\ud83c\uddf1\",\n    \":alembic:\": \"\u2697\",\n    \":algeria:\": \"\ud83c\udde9\u200d\ud83c\uddff\",\n    \":alien:\": \"\ud83d\udc7d\",\n    \":ambulance:\": \"\ud83d\ude91\",\n    \":american_samoa:\": \"\ud83c\udde6\u200d\ud83c\uddf8\",\n    \":amphora:\": \"\ud83c\udffa\",\n    \":anchor:\": \"\u2693\",\n    \":andorra:\": \"\ud83c\udde6\u200d\ud83c\udde9\",\n    \":angel:\": \"\ud83d\udc7c\",\n    \":anger:\": \"\ud83d\udca2\",\n    \":angola:\": \"\ud83c\udde6\u200d\ud83c\uddf4\",\n    \":angry:\": \"\ud83d\ude20\",\n    \":anguilla:\": \"\ud83c\udde6\u200d\ud83c\uddee\",\n    \":anguished:\": \"\ud83d\ude27\",\n    \":ant:\": \"\ud83d\udc1c\",\n    \":antarctica:\": \"\ud83c\udde6\u200d\ud83c\uddf6\",\n    \":antigua_barbuda:\": \"\ud83c\udde6\u200d\ud83c\uddec\",\n    \":apple:\": \"\ud83c\udf4e\",\n    \":aquarius:\": \"\u2652\",\n    \":argentina:\": \"\ud83c\udde6\u200d\ud83c\uddf7\",\n    \":aries:\": \"\u2648\",\n    \":armenia:\": \"\ud83c\udde6\u200d\ud83c\uddf2\",\n    \":arrow_backward:\": \"\u25c0\",\n    \":arrow_double_down:\": \"\u23ec\",\n    \":arrow_double_up:\": \"\u23eb\",\n    \":arrow_down:\": \"\u2b07\",\n    \":arrow_down_small:\": \"\ud83d\udd3d\",\n    \":arrow_forward:\": \"\u25b6\",\n    \":arrow_heading_down:\": \"\u2935\",\n    \":arrow_heading_up:\": \"\u2934\",\n    \":arrow_left:\": \"\u2b05\",\n    \":arrow_lower_left:\": \"\u2199\",\n    \":arrow_lower_right:\": \"\u2198\",\n    \":arrow_right:\": \"\u27a1\",\n    \":arrow_right_hook:\": \"\u21aa\",\n    \":arrow_up:\": \"\u2b06\",\n    \":arrow_up_down:\": \"\u2195\",\n    \":arrow_up_small:\": \"\ud83d\udd3c\",\n    \":arrow_upper_left:\": \"\u2196\",\n    \":arrow_upper_right:\": \"\u2197\",\n    \":arrows_clockwise:\": \"\ud83d\udd03\",\n    \":arrows_counterclockwise:\": \"\ud83d\udd04\",\n    \":art:\": \"\ud83c\udfa8\",\n    \":articulated_lorry:\": \"\ud83d\ude9b\",\n    \":artificial_satellite:\": \"\ud83d\udef0\",\n    \":artist:\": \"\ud83e\uddd1\u200d\ud83c\udfa8\",\n    \":aruba:\": \"\ud83c\udde6\u200d\ud83c\uddfc\",\n    \":ascension_island:\": \"\ud83c\udde6\u200d\ud83c\udde8\",\n    \":asterisk:\": \"*\u200d\u20e3\",\n    \":astonished:\": \"\ud83d\ude32\",\n    \":astronaut:\": \"\ud83e\uddd1\u200d\ud83d\ude80\",\n    \":athletic_shoe:\": \"\ud83d\udc5f\",\n    \":atm:\": \"\ud83c\udfe7\",\n    \":atom_symbol:\": \"\u269b\",\n    \":australia:\": \"\ud83c\udde6\u200d\ud83c\uddfa\",\n    \":austria:\": \"\ud83c\udde6\u200d\ud83c\uddf9\",\n    \":auto_rickshaw:\": \"\ud83d\udefa\",\n    \":avocado:\": \"\ud83e\udd51\",\n    \":axe:\": \"\ud83e\ude93\",\n    \":azerbaijan:\": \"\ud83c\udde6\u200d\ud83c\uddff\",\n    \":b:\": \"\ud83c\udd71\",\n    \":baby:\": \"\ud83d\udc76\",\n    \":baby_bottle:\": \"\ud83c\udf7c\",\n    \":baby_chick:\": \"\ud83d\udc24\",\n    \":baby_symbol:\": \"\ud83d\udebc\",\n    \":back:\": \"\ud83d\udd19\",\n    \":bacon:\": \"\ud83e\udd53\",\n    \":badger:\": \"\ud83e\udda1\",\n    \":badminton:\": \"\ud83c\udff8\",\n    \":bagel:\": \"\ud83e\udd6f\",\n    \":baggage_claim:\": \"\ud83d\udec4\",\n    \":baguette_bread:\": \"\ud83e\udd56\",\n    \":bahamas:\": \"\ud83c\udde7\u200d\ud83c\uddf8\",\n    \":bahrain:\": \"\ud83c\udde7\u200d\ud83c\udded\",\n    \":balance_scale:\": \"\u2696\",\n    \":bald_man:\": \"\ud83d\udc68\u200d\ud83e\uddb2\",\n    \":bald_woman:\": \"\ud83d\udc69\u200d\ud83e\uddb2\",\n    \":ballet_shoes:\": \"\ud83e\ude70\",\n    \":balloon:\": \"\ud83c\udf88\",\n    \":ballot_box:\": \"\ud83d\uddf3\",\n    \":ballot_box_with_check:\": \"\u2611\",\n    \":bamboo:\": \"\ud83c\udf8d\",\n    \":banana:\": \"\ud83c\udf4c\",\n    \":bangbang:\": \"\u203c\",\n    \":bangladesh:\": \"\ud83c\udde7\u200d\ud83c\udde9\",\n    \":banjo:\": \"\ud83e\ude95\",\n    \":bank:\": \"\ud83c\udfe6\",\n    \":bar_chart:\": \"\ud83d\udcca\",\n    \":barbados:\": \"\ud83c\udde7\u200d\ud83c\udde7\",\n    \":barber:\": \"\ud83d\udc88\",\n    \":baseball:\": \"\u26be\",\n    \":basket:\": \"\ud83e\uddfa\",\n    \":basketball:\": \"\ud83c\udfc0\",\n    \":basketball_man:\": \"\u26f9\u200d\u2642\",\n    \":basketball_woman:\": \"\u26f9\u200d\u2640\",\n    \":bat:\": \"\ud83e\udd87\",\n    \":bath:\": \"\ud83d\udec0\",\n    \":bathtub:\": \"\ud83d\udec1\",\n    \":battery:\": \"\ud83d\udd0b\",\n    \":beach_umbrella:\": \"\ud83c\udfd6\",\n    \":bear:\": \"\ud83d\udc3b\",\n    \":bearded_person:\": \"\ud83e\uddd4\",\n    \":bed:\": \"\ud83d\udecf\",\n    \":bee:\": \"\ud83d\udc1d\",\n    \":beer:\": \"\ud83c\udf7a\",\n    \":beers:\": \"\ud83c\udf7b\",\n    \":beetle:\": \"\ud83d\udc1e\",\n    \":beginner:\": \"\ud83d\udd30\",\n    \":belarus:\": \"\ud83c\udde7\u200d\ud83c\uddfe\",\n    \":belgium:\": \"\ud83c\udde7\u200d\ud83c\uddea\",\n    \":belize:\": \"\ud83c\udde7\u200d\ud83c\uddff\",\n    \":bell:\": \"\ud83d\udd14\",\n    \":bellhop_bell:\": \"\ud83d\udece\",\n    \":benin:\": \"\ud83c\udde7\u200d\ud83c\uddef\",\n    \":bento:\": \"\ud83c\udf71\",\n    \":bermuda:\": \"\ud83c\udde7\u200d\ud83c\uddf2\",\n    \":beverage_box:\": \"\ud83e\uddc3\",\n    \":bhutan:\": \"\ud83c\udde7\u200d\ud83c\uddf9\",\n    \":bicyclist:\": \"\ud83d\udeb4\",\n    \":bike:\": \"\ud83d\udeb2\",\n    \":biking_man:\": \"\ud83d\udeb4\u200d\u2642\",\n    \":biking_woman:\": \"\ud83d\udeb4\u200d\u2640\",\n    \":bikini:\": \"\ud83d\udc59\",\n    \":billed_cap:\": \"\ud83e\udde2\",\n    \":biohazard:\": \"\u2623\",\n    \":bird:\": \"\ud83d\udc26\",\n    \":birthday:\": \"\ud83c\udf82\",\n    \":black_circle:\": \"\u26ab\",\n    \":black_flag:\": \"\ud83c\udff4\",\n    \":black_heart:\": \"\ud83d\udda4\",\n    \":black_joker:\": \"\ud83c\udccf\",\n    \":black_large_square:\": \"\u2b1b\",\n    \":black_medium_small_square:\": \"\u25fe\",\n    \":black_medium_square:\": \"\u25fc\",\n    \":black_nib:\": \"\u2712\",\n    \":black_small_square:\": \"\u25aa\",\n    \":black_square_button:\": \"\ud83d\udd32\",\n    \":blond_haired_man:\": \"\ud83d\udc71\u200d\u2642\",\n    \":blond_haired_person:\": \"\ud83d\udc71\",\n    \":blond_haired_woman:\": \"\ud83d\udc71\u200d\u2640\",\n    \":blonde_woman:\": \"\ud83d\udc71\u200d\u2640\",\n    \":blossom:\": \"\ud83c\udf3c\",\n    \":blowfish:\": \"\ud83d\udc21\",\n    \":blue_book:\": \"\ud83d\udcd8\",\n    \":blue_car:\": \"\ud83d\ude99\",\n    \":blue_heart:\": \"\ud83d\udc99\",\n    \":blue_square:\": \"\ud83d\udfe6\",\n    \":blush:\": \"\ud83d\ude0a\",\n    \":boar:\": \"\ud83d\udc17\",\n    \":boat:\": \"\u26f5\",\n    \":bolivia:\": \"\ud83c\udde7\u200d\ud83c\uddf4\",\n    \":bomb:\": \"\ud83d\udca3\",\n    \":bone:\": \"\ud83e\uddb4\",\n    \":book:\": \"\ud83d\udcd6\",\n    \":bookmark:\": \"\ud83d\udd16\",\n    \":bookmark_tabs:\": \"\ud83d\udcd1\",\n    \":books:\": \"\ud83d\udcda\",\n    \":boom:\": \"\ud83d\udca5\",\n    \":boot:\": \"\ud83d\udc62\",\n    \":bosnia_herzegovina:\": \"\ud83c\udde7\u200d\ud83c\udde6\",\n    \":botswana:\": \"\ud83c\udde7\u200d\ud83c\uddfc\",\n    \":bouncing_ball_man:\": \"\u26f9\u200d\u2642\",\n    \":bouncing_ball_person:\": \"\u26f9\",\n    \":bouncing_ball_woman:\": \"\u26f9\u200d\u2640\",\n    \":bouquet:\": \"\ud83d\udc90\",\n    \":bouvet_island:\": \"\ud83c\udde7\u200d\ud83c\uddfb\",\n    \":bow:\": \"\ud83d\ude47\",\n    \":bow_and_arrow:\": \"\ud83c\udff9\",\n    \":bowing_man:\": \"\ud83d\ude47\u200d\u2642\",\n    \":bowing_woman:\": \"\ud83d\ude47\u200d\u2640\",\n    \":bowl_with_spoon:\": \"\ud83e\udd63\",\n    \":bowling:\": \"\ud83c\udfb3\",\n    \":boxing_glove:\": \"\ud83e\udd4a\",\n    \":boy:\": \"\ud83d\udc66\",\n    \":brain:\": \"\ud83e\udde0\",\n    \":brazil:\": \"\ud83c\udde7\u200d\ud83c\uddf7\",\n    \":bread:\": \"\ud83c\udf5e\",\n    \":breast_feeding:\": \"\ud83e\udd31\",\n    \":bricks:\": \"\ud83e\uddf1\",\n    \":bride_with_veil:\": \"\ud83d\udc70\",\n    \":bridge_at_night:\": \"\ud83c\udf09\",\n    \":briefcase:\": \"\ud83d\udcbc\",\n    \":british_indian_ocean_territory:\": \"\ud83c\uddee\u200d\ud83c\uddf4\",\n    \":british_virgin_islands:\": \"\ud83c\uddfb\u200d\ud83c\uddec\",\n    \":broccoli:\": \"\ud83e\udd66\",\n    \":broken_heart:\": \"\ud83d\udc94\",\n    \":broom:\": \"\ud83e\uddf9\",\n    \":brown_circle:\": \"\ud83d\udfe4\",\n    \":brown_heart:\": \"\ud83e\udd0e\",\n    \":brown_square:\": \"\ud83d\udfeb\",\n    \":brunei:\": \"\ud83c\udde7\u200d\ud83c\uddf3\",\n    \":bug:\": \"\ud83d\udc1b\",\n    \":building_construction:\": \"\ud83c\udfd7\",\n    \":bulb:\": \"\ud83d\udca1\",\n    \":bulgaria:\": \"\ud83c\udde7\u200d\ud83c\uddec\",\n    \":bullettrain_front:\": \"\ud83d\ude85\",\n    \":bullettrain_side:\": \"\ud83d\ude84\",\n    \":burkina_faso:\": \"\ud83c\udde7\u200d\ud83c\uddeb\",\n    \":burrito:\": \"\ud83c\udf2f\",\n    \":burundi:\": \"\ud83c\udde7\u200d\ud83c\uddee\",\n    \":bus:\": \"\ud83d\ude8c\",\n    \":business_suit_levitating:\": \"\ud83d\udd74\",\n    \":busstop:\": \"\ud83d\ude8f\",\n    \":bust_in_silhouette:\": \"\ud83d\udc64\",\n    \":busts_in_silhouette:\": \"\ud83d\udc65\",\n    \":butter:\": \"\ud83e\uddc8\",\n    \":butterfly:\": \"\ud83e\udd8b\",\n    \":cactus:\": \"\ud83c\udf35\",\n    \":cake:\": \"\ud83c\udf70\",\n    \":calendar:\": \"\ud83d\udcc6\",\n    \":call_me_hand:\": \"\ud83e\udd19\",\n    \":calling:\": \"\ud83d\udcf2\",\n    \":cambodia:\": \"\ud83c\uddf0\u200d\ud83c\udded\",\n    \":camel:\": \"\ud83d\udc2b\",\n    \":camera:\": \"\ud83d\udcf7\",\n    \":camera_flash:\": \"\ud83d\udcf8\",\n    \":cameroon:\": \"\ud83c\udde8\u200d\ud83c\uddf2\",\n    \":camping:\": \"\ud83c\udfd5\",\n    \":canada:\": \"\ud83c\udde8\u200d\ud83c\udde6\",\n    \":canary_islands:\": \"\ud83c\uddee\u200d\ud83c\udde8\",\n    \":cancer:\": \"\u264b\",\n    \":candle:\": \"\ud83d\udd6f\",\n    \":candy:\": \"\ud83c\udf6c\",\n    \":canned_food:\": \"\ud83e\udd6b\",\n    \":canoe:\": \"\ud83d\udef6\",\n    \":cape_verde:\": \"\ud83c\udde8\u200d\ud83c\uddfb\",\n    \":capital_abcd:\": \"\ud83d\udd20\",\n    \":capricorn:\": \"\u2651\",\n    \":car:\": \"\ud83d\ude97\",\n    \":card_file_box:\": \"\ud83d\uddc3\",\n    \":card_index:\": \"\ud83d\udcc7\",\n    \":card_index_dividers:\": \"\ud83d\uddc2\",\n    \":caribbean_netherlands:\": \"\ud83c\udde7\u200d\ud83c\uddf6\",\n    \":carousel_horse:\": \"\ud83c\udfa0\",\n    \":carrot:\": \"\ud83e\udd55\",\n    \":cartwheeling:\": \"\ud83e\udd38\",\n    \":cat:\": \"\ud83d\udc31\",\n    \":cat2:\": \"\ud83d\udc08\",\n    \":cayman_islands:\": \"\ud83c\uddf0\u200d\ud83c\uddfe\",\n    \":cd:\": \"\ud83d\udcbf\",\n    \":central_african_republic:\": \"\ud83c\udde8\u200d\ud83c\uddeb\",\n    \":ceuta_melilla:\": \"\ud83c\uddea\u200d\ud83c\udde6\",\n    \":chad:\": \"\ud83c\uddf9\u200d\ud83c\udde9\",\n    \":chains:\": \"\u26d3\",\n    \":chair:\": \"\ud83e\ude91\",\n    \":champagne:\": \"\ud83c\udf7e\",\n    \":chart:\": \"\ud83d\udcb9\",\n    \":chart_with_downwards_trend:\": \"\ud83d\udcc9\",\n    \":chart_with_upwards_trend:\": \"\ud83d\udcc8\",\n    \":checkered_flag:\": \"\ud83c\udfc1\",\n    \":cheese:\": \"\ud83e\uddc0\",\n    \":cherries:\": \"\ud83c\udf52\",\n    \":cherry_blossom:\": \"\ud83c\udf38\",\n    \":chess_pawn:\": \"\u265f\",\n    \":chestnut:\": \"\ud83c\udf30\",\n    \":chicken:\": \"\ud83d\udc14\",\n    \":child:\": \"\ud83e\uddd2\",\n    \":children_crossing:\": \"\ud83d\udeb8\",\n    \":chile:\": \"\ud83c\udde8\u200d\ud83c\uddf1\",\n    \":chipmunk:\": \"\ud83d\udc3f\",\n    \":chocolate_bar:\": \"\ud83c\udf6b\",\n    \":chopsticks:\": \"\ud83e\udd62\",\n    \":christmas_island:\": \"\ud83c\udde8\u200d\ud83c\uddfd\",\n    \":christmas_tree:\": \"\ud83c\udf84\",\n    \":church:\": \"\u26ea\",\n    \":cinema:\": \"\ud83c\udfa6\",\n    \":circus_tent:\": \"\ud83c\udfaa\",\n    \":city_sunrise:\": \"\ud83c\udf07\",\n    \":city_sunset:\": \"\ud83c\udf06\",\n    \":cityscape:\": \"\ud83c\udfd9\",\n    \":cl:\": \"\ud83c\udd91\",\n    \":clamp:\": \"\ud83d\udddc\",\n    \":clap:\": \"\ud83d\udc4f\",\n    \":clapper:\": \"\ud83c\udfac\",\n    \":classical_building:\": \"\ud83c\udfdb\",\n    \":climbing:\": \"\ud83e\uddd7\",\n    \":climbing_man:\": \"\ud83e\uddd7\u200d\u2642\",\n    \":climbing_woman:\": \"\ud83e\uddd7\u200d\u2640\",\n    \":clinking_glasses:\": \"\ud83e\udd42\",\n    \":clipboard:\": \"\ud83d\udccb\",\n    \":clipperton_island:\": \"\ud83c\udde8\u200d\ud83c\uddf5\",\n    \":clock1:\": \"\ud83d\udd50\",\n    \":clock10:\": \"\ud83d\udd59\",\n    \":clock1030:\": \"\ud83d\udd65\",\n    \":clock11:\": \"\ud83d\udd5a\",\n    \":clock1130:\": \"\ud83d\udd66\",\n    \":clock12:\": \"\ud83d\udd5b\",\n    \":clock1230:\": \"\ud83d\udd67\",\n    \":clock130:\": \"\ud83d\udd5c\",\n    \":clock2:\": \"\ud83d\udd51\",\n    \":clock230:\": \"\ud83d\udd5d\",\n    \":clock3:\": \"\ud83d\udd52\",\n    \":clock330:\": \"\ud83d\udd5e\",\n    \":clock4:\": \"\ud83d\udd53\",\n    \":clock430:\": \"\ud83d\udd5f\",\n    \":clock5:\": \"\ud83d\udd54\",\n    \":clock530:\": \"\ud83d\udd60\",\n    \":clock6:\": \"\ud83d\udd55\",\n    \":clock630:\": \"\ud83d\udd61\",\n    \":clock7:\": \"\ud83d\udd56\",\n    \":clock730:\": \"\ud83d\udd62\",\n    \":clock8:\": \"\ud83d\udd57\",\n    \":clock830:\": \"\ud83d\udd63\",\n    \":clock9:\": \"\ud83d\udd58\",\n    \":clock930:\": \"\ud83d\udd64\",\n    \":closed_book:\": \"\ud83d\udcd5\",\n    \":closed_lock_with_key:\": \"\ud83d\udd10\",\n    \":closed_umbrella:\": \"\ud83c\udf02\",\n    \":cloud:\": \"\u2601\",\n    \":cloud_with_lightning:\": \"\ud83c\udf29\",\n    \":cloud_with_lightning_and_rain:\": \"\u26c8\",\n    \":cloud_with_rain:\": \"\ud83c\udf27\",\n    \":cloud_with_snow:\": \"\ud83c\udf28\",\n    \":clown_face:\": \"\ud83e\udd21\",\n    \":clubs:\": \"\u2663\",\n    \":cn:\": \"\ud83c\udde8\u200d\ud83c\uddf3\",\n    \":coat:\": \"\ud83e\udde5\",\n    \":cocktail:\": \"\ud83c\udf78\",\n    \":coconut:\": \"\ud83e\udd65\",\n    \":cocos_islands:\": \"\ud83c\udde8\u200d\ud83c\udde8\",\n    \":coffee:\": \"\u2615\",\n    \":coffin:\": \"\u26b0\",\n    \":cold_face:\": \"\ud83e\udd76\",\n    \":cold_sweat:\": \"\ud83d\ude30\",\n    \":collision:\": \"\ud83d\udca5\",\n    \":colombia:\": \"\ud83c\udde8\u200d\ud83c\uddf4\",\n    \":comet:\": \"\u2604\",\n    \":comoros:\": \"\ud83c\uddf0\u200d\ud83c\uddf2\",\n    \":compass:\": \"\ud83e\udded\",\n    \":computer:\": \"\ud83d\udcbb\",\n    \":computer_mouse:\": \"\ud83d\uddb1\",\n    \":confetti_ball:\": \"\ud83c\udf8a\",\n    \":confounded:\": \"\ud83d\ude16\",\n    \":confused:\": \"\ud83d\ude15\",\n    \":congo_brazzaville:\": \"\ud83c\udde8\u200d\ud83c\uddec\",\n    \":congo_kinshasa:\": \"\ud83c\udde8\u200d\ud83c\udde9\",\n    \":congratulations:\": \"\u3297\",\n    \":construction:\": \"\ud83d\udea7\",\n    \":construction_worker:\": \"\ud83d\udc77\",\n    \":construction_worker_man:\": \"\ud83d\udc77\u200d\u2642\",\n    \":construction_worker_woman:\": \"\ud83d\udc77\u200d\u2640\",\n    \":control_knobs:\": \"\ud83c\udf9b\",\n    \":convenience_store:\": \"\ud83c\udfea\",\n    \":cook:\": \"\ud83e\uddd1\u200d\ud83c\udf73\",\n    \":cook_islands:\": \"\ud83c\udde8\u200d\ud83c\uddf0\",\n    \":cookie:\": \"\ud83c\udf6a\",\n    \":cool:\": \"\ud83c\udd92\",\n    \":cop:\": \"\ud83d\udc6e\",\n    \":copyright:\": \"\u00a9\",\n    \":corn:\": \"\ud83c\udf3d\",\n    \":costa_rica:\": \"\ud83c\udde8\u200d\ud83c\uddf7\",\n    \":cote_divoire:\": \"\ud83c\udde8\u200d\ud83c\uddee\",\n    \":couch_and_lamp:\": \"\ud83d\udecb\",\n    \":couple:\": \"\ud83d\udc6b\",\n    \":couple_with_heart:\": \"\ud83d\udc91\",\n    \":couple_with_heart_man_man:\": \"\ud83d\udc68\u200d\u2764\u200d\ud83d\udc68\",\n    \":couple_with_heart_woman_man:\": \"\ud83d\udc69\u200d\u2764\u200d\ud83d\udc68\",\n    \":couple_with_heart_woman_woman:\": \"\ud83d\udc69\u200d\u2764\u200d\ud83d\udc69\",\n    \":couplekiss:\": \"\ud83d\udc8f\",\n    \":couplekiss_man_man:\": \"\ud83d\udc68\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\",\n    \":couplekiss_man_woman:\": \"\ud83d\udc69\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\",\n    \":couplekiss_woman_woman:\": \"\ud83d\udc69\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\",\n    \":cow:\": \"\ud83d\udc2e\",\n    \":cow2:\": \"\ud83d\udc04\",\n    \":cowboy_hat_face:\": \"\ud83e\udd20\",\n    \":crab:\": \"\ud83e\udd80\",\n    \":crayon:\": \"\ud83d\udd8d\",\n    \":credit_card:\": \"\ud83d\udcb3\",\n    \":crescent_moon:\": \"\ud83c\udf19\",\n    \":cricket:\": \"\ud83e\udd97\",\n    \":cricket_game:\": \"\ud83c\udfcf\",\n    \":croatia:\": \"\ud83c\udded\u200d\ud83c\uddf7\",\n    \":crocodile:\": \"\ud83d\udc0a\",\n    \":croissant:\": \"\ud83e\udd50\",\n    \":crossed_fingers:\": \"\ud83e\udd1e\",\n    \":crossed_flags:\": \"\ud83c\udf8c\",\n    \":crossed_swords:\": \"\u2694\",\n    \":crown:\": \"\ud83d\udc51\",\n    \":cry:\": \"\ud83d\ude22\",\n    \":crying_cat_face:\": \"\ud83d\ude3f\",\n    \":crystal_ball:\": \"\ud83d\udd2e\",\n    \":cuba:\": \"\ud83c\udde8\u200d\ud83c\uddfa\",\n    \":cucumber:\": \"\ud83e\udd52\",\n    \":cup_with_straw:\": \"\ud83e\udd64\",\n    \":cupcake:\": \"\ud83e\uddc1\",\n    \":cupid:\": \"\ud83d\udc98\",\n    \":curacao:\": \"\ud83c\udde8\u200d\ud83c\uddfc\",\n    \":curling_stone:\": \"\ud83e\udd4c\",\n    \":curly_haired_man:\": \"\ud83d\udc68\u200d\ud83e\uddb1\",\n    \":curly_haired_woman:\": \"\ud83d\udc69\u200d\ud83e\uddb1\",\n    \":curly_loop:\": \"\u27b0\",\n    \":currency_exchange:\": \"\ud83d\udcb1\",\n    \":curry:\": \"\ud83c\udf5b\",\n    \":cursing_face:\": \"\ud83e\udd2c\",\n    \":custard:\": \"\ud83c\udf6e\",\n    \":customs:\": \"\ud83d\udec3\",\n    \":cut_of_meat:\": \"\ud83e\udd69\",\n    \":cyclone:\": \"\ud83c\udf00\",\n    \":cyprus:\": \"\ud83c\udde8\u200d\ud83c\uddfe\",\n    \":czech_republic:\": \"\ud83c\udde8\u200d\ud83c\uddff\",\n    \":dagger:\": \"\ud83d\udde1\",\n    \":dancer:\": \"\ud83d\udc83\",\n    \":dancers:\": \"\ud83d\udc6f\",\n    \":dancing_men:\": \"\ud83d\udc6f\u200d\u2642\",\n    \":dancing_women:\": \"\ud83d\udc6f\u200d\u2640\",\n    \":dango:\": \"\ud83c\udf61\",\n    \":dark_sunglasses:\": \"\ud83d\udd76\",\n    \":dart:\": \"\ud83c\udfaf\",\n    \":dash:\": \"\ud83d\udca8\",\n    \":date:\": \"\ud83d\udcc5\",\n    \":de:\": \"\ud83c\udde9\u200d\ud83c\uddea\",\n    \":deaf_man:\": \"\ud83e\uddcf\u200d\u2642\",\n    \":deaf_person:\": \"\ud83e\uddcf\",\n    \":deaf_woman:\": \"\ud83e\uddcf\u200d\u2640\",\n    \":deciduous_tree:\": \"\ud83c\udf33\",\n    \":deer:\": \"\ud83e\udd8c\",\n    \":denmark:\": \"\ud83c\udde9\u200d\ud83c\uddf0\",\n    \":department_store:\": \"\ud83c\udfec\",\n    \":derelict_house:\": \"\ud83c\udfda\",\n    \":desert:\": \"\ud83c\udfdc\",\n    \":desert_island:\": \"\ud83c\udfdd\",\n    \":desktop_computer:\": \"\ud83d\udda5\",\n    \":detective:\": \"\ud83d\udd75\",\n    \":diamond_shape_with_a_dot_inside:\": \"\ud83d\udca0\",\n    \":diamonds:\": \"\u2666\",\n    \":diego_garcia:\": \"\ud83c\udde9\u200d\ud83c\uddec\",\n    \":disappointed:\": \"\ud83d\ude1e\",\n    \":disappointed_relieved:\": \"\ud83d\ude25\",\n    \":diving_mask:\": \"\ud83e\udd3f\",\n    \":diya_lamp:\": \"\ud83e\ude94\",\n    \":dizzy:\": \"\ud83d\udcab\",\n    \":dizzy_face:\": \"\ud83d\ude35\",\n    \":djibouti:\": \"\ud83c\udde9\u200d\ud83c\uddef\",\n    \":dna:\": \"\ud83e\uddec\",\n    \":do_not_litter:\": \"\ud83d\udeaf\",\n    \":dog:\": \"\ud83d\udc36\",\n    \":dog2:\": \"\ud83d\udc15\",\n    \":dollar:\": \"\ud83d\udcb5\",\n    \":dolls:\": \"\ud83c\udf8e\",\n    \":dolphin:\": \"\ud83d\udc2c\",\n    \":dominica:\": \"\ud83c\udde9\u200d\ud83c\uddf2\",\n    \":dominican_republic:\": \"\ud83c\udde9\u200d\ud83c\uddf4\",\n    \":door:\": \"\ud83d\udeaa\",\n    \":doughnut:\": \"\ud83c\udf69\",\n    \":dove:\": \"\ud83d\udd4a\",\n    \":dragon:\": \"\ud83d\udc09\",\n    \":dragon_face:\": \"\ud83d\udc32\",\n    \":dress:\": \"\ud83d\udc57\",\n    \":dromedary_camel:\": \"\ud83d\udc2a\",\n    \":drooling_face:\": \"\ud83e\udd24\",\n    \":drop_of_blood:\": \"\ud83e\ude78\",\n    \":droplet:\": \"\ud83d\udca7\",\n    \":drum:\": \"\ud83e\udd41\",\n    \":duck:\": \"\ud83e\udd86\",\n    \":dumpling:\": \"\ud83e\udd5f\",\n    \":dvd:\": \"\ud83d\udcc0\",\n    \":e-mail:\": \"\ud83d\udce7\",\n    \":eagle:\": \"\ud83e\udd85\",\n    \":ear:\": \"\ud83d\udc42\",\n    \":ear_of_rice:\": \"\ud83c\udf3e\",\n    \":ear_with_hearing_aid:\": \"\ud83e\uddbb\",\n    \":earth_africa:\": \"\ud83c\udf0d\",\n    \":earth_americas:\": \"\ud83c\udf0e\",\n    \":earth_asia:\": \"\ud83c\udf0f\",\n    \":ecuador:\": \"\ud83c\uddea\u200d\ud83c\udde8\",\n    \":egg:\": \"\ud83e\udd5a\",\n    \":eggplant:\": \"\ud83c\udf46\",\n    \":egypt:\": \"\ud83c\uddea\u200d\ud83c\uddec\",\n    \":eight:\": \"8\u200d\u20e3\",\n    \":eight_pointed_black_star:\": \"\u2734\",\n    \":eight_spoked_asterisk:\": \"\u2733\",\n    \":eject_button:\": \"\u23cf\",\n    \":el_salvador:\": \"\ud83c\uddf8\u200d\ud83c\uddfb\",\n    \":electric_plug:\": \"\ud83d\udd0c\",\n    \":elephant:\": \"\ud83d\udc18\",\n    \":elf:\": \"\ud83e\udddd\",\n    \":elf_man:\": \"\ud83e\udddd\u200d\u2642\",\n    \":elf_woman:\": \"\ud83e\udddd\u200d\u2640\",\n    \":email:\": \"\u2709\",\n    \":end:\": \"\ud83d\udd1a\",\n    \":england:\": \"\ud83c\udff4\u200d\udb40\udc67\u200d\udb40\udc62\u200d\udb40\udc65\u200d\udb40\udc6e\u200d\udb40\udc67\u200d\udb40\udc7f\",\n    \":envelope:\": \"\u2709\",\n    \":envelope_with_arrow:\": \"\ud83d\udce9\",\n    \":equatorial_guinea:\": \"\ud83c\uddec\u200d\ud83c\uddf6\",\n    \":eritrea:\": \"\ud83c\uddea\u200d\ud83c\uddf7\",\n    \":es:\": \"\ud83c\uddea\u200d\ud83c\uddf8\",\n    \":estonia:\": \"\ud83c\uddea\u200d\ud83c\uddea\",\n    \":ethiopia:\": \"\ud83c\uddea\u200d\ud83c\uddf9\",\n    \":eu:\": \"\ud83c\uddea\u200d\ud83c\uddfa\",\n    \":euro:\": \"\ud83d\udcb6\",\n    \":european_castle:\": \"\ud83c\udff0\",\n    \":european_post_office:\": \"\ud83c\udfe4\",\n    \":european_union:\": \"\ud83c\uddea\u200d\ud83c\uddfa\",\n    \":evergreen_tree:\": \"\ud83c\udf32\",\n    \":exclamation:\": \"\u2757\",\n    \":exploding_head:\": \"\ud83e\udd2f\",\n    \":expressionless:\": \"\ud83d\ude11\",\n    \":eye:\": \"\ud83d\udc41\",\n    \":eye_speech_bubble:\": \"\ud83d\udc41\u200d\ud83d\udde8\",\n    \":eyeglasses:\": \"\ud83d\udc53\",\n    \":eyes:\": \"\ud83d\udc40\",\n    \":face_with_head_bandage:\": \"\ud83e\udd15\",\n    \":face_with_thermometer:\": \"\ud83e\udd12\",\n    \":facepalm:\": \"\ud83e\udd26\",\n    \":facepunch:\": \"\ud83d\udc4a\",\n    \":factory:\": \"\ud83c\udfed\",\n    \":factory_worker:\": \"\ud83e\uddd1\u200d\ud83c\udfed\",\n    \":fairy:\": \"\ud83e\uddda\",\n    \":fairy_man:\": \"\ud83e\uddda\u200d\u2642\",\n    \":fairy_woman:\": \"\ud83e\uddda\u200d\u2640\",\n    \":falafel:\": \"\ud83e\uddc6\",\n    \":falkland_islands:\": \"\ud83c\uddeb\u200d\ud83c\uddf0\",\n    \":fallen_leaf:\": \"\ud83c\udf42\",\n    \":family:\": \"\ud83d\udc6a\",\n    \":family_man_boy:\": \"\ud83d\udc68\u200d\ud83d\udc66\",\n    \":family_man_boy_boy:\": \"\ud83d\udc68\u200d\ud83d\udc66\u200d\ud83d\udc66\",\n    \":family_man_girl:\": \"\ud83d\udc68\u200d\ud83d\udc67\",\n    \":family_man_girl_boy:\": \"\ud83d\udc68\u200d\ud83d\udc67\u200d\ud83d\udc66\",\n    \":family_man_girl_girl:\": \"\ud83d\udc68\u200d\ud83d\udc67\u200d\ud83d\udc67\",\n    \":family_man_man_boy:\": \"\ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc66\",\n    \":family_man_man_boy_boy:\": \"\ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc66\u200d\ud83d\udc66\",\n    \":family_man_man_girl:\": \"\ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc67\",\n    \":family_man_man_girl_boy:\": \"\ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc67\u200d\ud83d\udc66\",\n    \":family_man_man_girl_girl:\": \"\ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc67\u200d\ud83d\udc67\",\n    \":family_man_woman_boy:\": \"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc66\",\n    \":family_man_woman_boy_boy:\": \"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc66\u200d\ud83d\udc66\",\n    \":family_man_woman_girl:\": \"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\",\n    \":family_man_woman_girl_boy:\": \"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66\",\n    \":family_man_woman_girl_girl:\": \"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc67\",\n    \":family_woman_boy:\": \"\ud83d\udc69\u200d\ud83d\udc66\",\n    \":family_woman_boy_boy:\": \"\ud83d\udc69\u200d\ud83d\udc66\u200d\ud83d\udc66\",\n    \":family_woman_girl:\": \"\ud83d\udc69\u200d\ud83d\udc67\",\n    \":family_woman_girl_boy:\": \"\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66\",\n    \":family_woman_girl_girl:\": \"\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc67\",\n    \":family_woman_woman_boy:\": \"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc66\",\n    \":family_woman_woman_boy_boy:\": \"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc66\u200d\ud83d\udc66\",\n    \":family_woman_woman_girl:\": \"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc67\",\n    \":family_woman_woman_girl_boy:\": \"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66\",\n    \":family_woman_woman_girl_girl:\": \"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc67\",\n    \":farmer:\": \"\ud83e\uddd1\u200d\ud83c\udf3e\",\n    \":faroe_islands:\": \"\ud83c\uddeb\u200d\ud83c\uddf4\",\n    \":fast_forward:\": \"\u23e9\",\n    \":fax:\": \"\ud83d\udce0\",\n    \":fearful:\": \"\ud83d\ude28\",\n    \":feet:\": \"\ud83d\udc3e\",\n    \":female_detective:\": \"\ud83d\udd75\u200d\u2640\",\n    \":female_sign:\": \"\u2640\",\n    \":ferris_wheel:\": \"\ud83c\udfa1\",\n    \":ferry:\": \"\u26f4\",\n    \":field_hockey:\": \"\ud83c\udfd1\",\n    \":fiji:\": \"\ud83c\uddeb\u200d\ud83c\uddef\",\n    \":file_cabinet:\": \"\ud83d\uddc4\",\n    \":file_folder:\": \"\ud83d\udcc1\",\n    \":film_projector:\": \"\ud83d\udcfd\",\n    \":film_strip:\": \"\ud83c\udf9e\",\n    \":finland:\": \"\ud83c\uddeb\u200d\ud83c\uddee\",\n    \":fire:\": \"\ud83d\udd25\",\n    \":fire_engine:\": \"\ud83d\ude92\",\n    \":fire_extinguisher:\": \"\ud83e\uddef\",\n    \":firecracker:\": \"\ud83e\udde8\",\n    \":firefighter:\": \"\ud83e\uddd1\u200d\ud83d\ude92\",\n    \":fireworks:\": \"\ud83c\udf86\",\n    \":first_quarter_moon:\": \"\ud83c\udf13\",\n    \":first_quarter_moon_with_face:\": \"\ud83c\udf1b\",\n    \":fish:\": \"\ud83d\udc1f\",\n    \":fish_cake:\": \"\ud83c\udf65\",\n    \":fishing_pole_and_fish:\": \"\ud83c\udfa3\",\n    \":fist:\": \"\u270a\",\n    \":fist_left:\": \"\ud83e\udd1b\",\n    \":fist_oncoming:\": \"\ud83d\udc4a\",\n    \":fist_raised:\": \"\u270a\",\n    \":fist_right:\": \"\ud83e\udd1c\",\n    \":five:\": \"5\u200d\u20e3\",\n    \":flags:\": \"\ud83c\udf8f\",\n    \":flamingo:\": \"\ud83e\udda9\",\n    \":flashlight:\": \"\ud83d\udd26\",\n    \":flat_shoe:\": \"\ud83e\udd7f\",\n    \":fleur_de_lis:\": \"\u269c\",\n    \":flight_arrival:\": \"\ud83d\udeec\",\n    \":flight_departure:\": \"\ud83d\udeeb\",\n    \":flipper:\": \"\ud83d\udc2c\",\n    \":floppy_disk:\": \"\ud83d\udcbe\",\n    \":flower_playing_cards:\": \"\ud83c\udfb4\",\n    \":flushed:\": \"\ud83d\ude33\",\n    \":flying_disc:\": \"\ud83e\udd4f\",\n    \":flying_saucer:\": \"\ud83d\udef8\",\n    \":fog:\": \"\ud83c\udf2b\",\n    \":foggy:\": \"\ud83c\udf01\",\n    \":foot:\": \"\ud83e\uddb6\",\n    \":football:\": \"\ud83c\udfc8\",\n    \":footprints:\": \"\ud83d\udc63\",\n    \":fork_and_knife:\": \"\ud83c\udf74\",\n    \":fortune_cookie:\": \"\ud83e\udd60\",\n    \":fountain:\": \"\u26f2\",\n    \":fountain_pen:\": \"\ud83d\udd8b\",\n    \":four:\": \"4\u200d\u20e3\",\n    \":four_leaf_clover:\": \"\ud83c\udf40\",\n    \":fox_face:\": \"\ud83e\udd8a\",\n    \":fr:\": \"\ud83c\uddeb\u200d\ud83c\uddf7\",\n    \":framed_picture:\": \"\ud83d\uddbc\",\n    \":free:\": \"\ud83c\udd93\",\n    \":french_guiana:\": \"\ud83c\uddec\u200d\ud83c\uddeb\",\n    \":french_polynesia:\": \"\ud83c\uddf5\u200d\ud83c\uddeb\",\n    \":french_southern_territories:\": \"\ud83c\uddf9\u200d\ud83c\uddeb\",\n    \":fried_egg:\": \"\ud83c\udf73\",\n    \":fried_shrimp:\": \"\ud83c\udf64\",\n    \":fries:\": \"\ud83c\udf5f\",\n    \":frog:\": \"\ud83d\udc38\",\n    \":frowning:\": \"\ud83d\ude26\",\n    \":frowning_face:\": \"\u2639\",\n    \":frowning_man:\": \"\ud83d\ude4d\u200d\u2642\",\n    \":frowning_person:\": \"\ud83d\ude4d\",\n    \":frowning_woman:\": \"\ud83d\ude4d\u200d\u2640\",\n    \":fu:\": \"\ud83d\udd95\",\n    \":fuelpump:\": \"\u26fd\",\n    \":full_moon:\": \"\ud83c\udf15\",\n    \":full_moon_with_face:\": \"\ud83c\udf1d\",\n    \":funeral_urn:\": \"\u26b1\",\n    \":gabon:\": \"\ud83c\uddec\u200d\ud83c\udde6\",\n    \":gambia:\": \"\ud83c\uddec\u200d\ud83c\uddf2\",\n    \":game_die:\": \"\ud83c\udfb2\",\n    \":garlic:\": \"\ud83e\uddc4\",\n    \":gb:\": \"\ud83c\uddec\u200d\ud83c\udde7\",\n    \":gear:\": \"\u2699\",\n    \":gem:\": \"\ud83d\udc8e\",\n    \":gemini:\": \"\u264a\",\n    \":genie:\": \"\ud83e\uddde\",\n    \":genie_man:\": \"\ud83e\uddde\u200d\u2642\",\n    \":genie_woman:\": \"\ud83e\uddde\u200d\u2640\",\n    \":georgia:\": \"\ud83c\uddec\u200d\ud83c\uddea\",\n    \":ghana:\": \"\ud83c\uddec\u200d\ud83c\udded\",\n    \":ghost:\": \"\ud83d\udc7b\",\n    \":gibraltar:\": \"\ud83c\uddec\u200d\ud83c\uddee\",\n    \":gift:\": \"\ud83c\udf81\",\n    \":gift_heart:\": \"\ud83d\udc9d\",\n    \":giraffe:\": \"\ud83e\udd92\",\n    \":girl:\": \"\ud83d\udc67\",\n    \":globe_with_meridians:\": \"\ud83c\udf10\",\n    \":gloves:\": \"\ud83e\udde4\",\n    \":goal_net:\": \"\ud83e\udd45\",\n    \":goat:\": \"\ud83d\udc10\",\n    \":goggles:\": \"\ud83e\udd7d\",\n    \":golf:\": \"\u26f3\",\n    \":golfing:\": \"\ud83c\udfcc\",\n    \":golfing_man:\": \"\ud83c\udfcc\u200d\u2642\",\n    \":golfing_woman:\": \"\ud83c\udfcc\u200d\u2640\",\n    \":gorilla:\": \"\ud83e\udd8d\",\n    \":grapes:\": \"\ud83c\udf47\",\n    \":greece:\": \"\ud83c\uddec\u200d\ud83c\uddf7\",\n    \":green_apple:\": \"\ud83c\udf4f\",\n    \":green_book:\": \"\ud83d\udcd7\",\n    \":green_circle:\": \"\ud83d\udfe2\",\n    \":green_heart:\": \"\ud83d\udc9a\",\n    \":green_salad:\": \"\ud83e\udd57\",\n    \":green_square:\": \"\ud83d\udfe9\",\n    \":greenland:\": \"\ud83c\uddec\u200d\ud83c\uddf1\",\n    \":grenada:\": \"\ud83c\uddec\u200d\ud83c\udde9\",\n    \":grey_exclamation:\": \"\u2755\",\n    \":grey_question:\": \"\u2754\",\n    \":grimacing:\": \"\ud83d\ude2c\",\n    \":grin:\": \"\ud83d\ude01\",\n    \":grinning:\": \"\ud83d\ude00\",\n    \":guadeloupe:\": \"\ud83c\uddec\u200d\ud83c\uddf5\",\n    \":guam:\": \"\ud83c\uddec\u200d\ud83c\uddfa\",\n    \":guard:\": \"\ud83d\udc82\",\n    \":guardsman:\": \"\ud83d\udc82\u200d\u2642\",\n    \":guardswoman:\": \"\ud83d\udc82\u200d\u2640\",\n    \":guatemala:\": \"\ud83c\uddec\u200d\ud83c\uddf9\",\n    \":guernsey:\": \"\ud83c\uddec\u200d\ud83c\uddec\",\n    \":guide_dog:\": \"\ud83e\uddae\",\n    \":guinea:\": \"\ud83c\uddec\u200d\ud83c\uddf3\",\n    \":guinea_bissau:\": \"\ud83c\uddec\u200d\ud83c\uddfc\",\n    \":guitar:\": \"\ud83c\udfb8\",\n    \":gun:\": \"\ud83d\udd2b\",\n    \":guyana:\": \"\ud83c\uddec\u200d\ud83c\uddfe\",\n    \":haircut:\": \"\ud83d\udc87\",\n    \":haircut_man:\": \"\ud83d\udc87\u200d\u2642\",\n    \":haircut_woman:\": \"\ud83d\udc87\u200d\u2640\",\n    \":haiti:\": \"\ud83c\udded\u200d\ud83c\uddf9\",\n    \":hamburger:\": \"\ud83c\udf54\",\n    \":hammer:\": \"\ud83d\udd28\",\n    \":hammer_and_pick:\": \"\u2692\",\n    \":hammer_and_wrench:\": \"\ud83d\udee0\",\n    \":hamster:\": \"\ud83d\udc39\",\n    \":hand:\": \"\u270b\",\n    \":hand_over_mouth:\": \"\ud83e\udd2d\",\n    \":handbag:\": \"\ud83d\udc5c\",\n    \":handball_person:\": \"\ud83e\udd3e\",\n    \":handshake:\": \"\ud83e\udd1d\",\n    \":hankey:\": \"\ud83d\udca9\",\n    \":hash:\": \"#\u200d\u20e3\",\n    \":hatched_chick:\": \"\ud83d\udc25\",\n    \":hatching_chick:\": \"\ud83d\udc23\",\n    \":headphones:\": \"\ud83c\udfa7\",\n    \":health_worker:\": \"\ud83e\uddd1\u200d\u2695\",\n    \":hear_no_evil:\": \"\ud83d\ude49\",\n    \":heard_mcdonald_islands:\": \"\ud83c\udded\u200d\ud83c\uddf2\",\n    \":heart:\": \"\u2764\",\n    \":heart_decoration:\": \"\ud83d\udc9f\",\n    \":heart_eyes:\": \"\ud83d\ude0d\",\n    \":heart_eyes_cat:\": \"\ud83d\ude3b\",\n    \":heartbeat:\": \"\ud83d\udc93\",\n    \":heartpulse:\": \"\ud83d\udc97\",\n    \":hearts:\": \"\u2665\",\n    \":heavy_check_mark:\": \"\u2714\",\n    \":heavy_division_sign:\": \"\u2797\",\n    \":heavy_dollar_sign:\": \"\ud83d\udcb2\",\n    \":heavy_exclamation_mark:\": \"\u2757\",\n    \":heavy_heart_exclamation:\": \"\u2763\",\n    \":heavy_minus_sign:\": \"\u2796\",\n    \":heavy_multiplication_x:\": \"\u2716\",\n    \":heavy_plus_sign:\": \"\u2795\",\n    \":hedgehog:\": \"\ud83e\udd94\",\n    \":helicopter:\": \"\ud83d\ude81\",\n    \":herb:\": \"\ud83c\udf3f\",\n    \":hibiscus:\": \"\ud83c\udf3a\",\n    \":high_brightness:\": \"\ud83d\udd06\",\n    \":high_heel:\": \"\ud83d\udc60\",\n    \":hiking_boot:\": \"\ud83e\udd7e\",\n    \":hindu_temple:\": \"\ud83d\uded5\",\n    \":hippopotamus:\": \"\ud83e\udd9b\",\n    \":hocho:\": \"\ud83d\udd2a\",\n    \":hole:\": \"\ud83d\udd73\",\n    \":honduras:\": \"\ud83c\udded\u200d\ud83c\uddf3\",\n    \":honey_pot:\": \"\ud83c\udf6f\",\n    \":honeybee:\": \"\ud83d\udc1d\",\n    \":hong_kong:\": \"\ud83c\udded\u200d\ud83c\uddf0\",\n    \":horse:\": \"\ud83d\udc34\",\n    \":horse_racing:\": \"\ud83c\udfc7\",\n    \":hospital:\": \"\ud83c\udfe5\",\n    \":hot_face:\": \"\ud83e\udd75\",\n    \":hot_pepper:\": \"\ud83c\udf36\",\n    \":hotdog:\": \"\ud83c\udf2d\",\n    \":hotel:\": \"\ud83c\udfe8\",\n    \":hotsprings:\": \"\u2668\",\n    \":hourglass:\": \"\u231b\",\n    \":hourglass_flowing_sand:\": \"\u23f3\",\n    \":house:\": \"\ud83c\udfe0\",\n    \":house_with_garden:\": \"\ud83c\udfe1\",\n    \":houses:\": \"\ud83c\udfd8\",\n    \":hugs:\": \"\ud83e\udd17\",\n    \":hungary:\": \"\ud83c\udded\u200d\ud83c\uddfa\",\n    \":hushed:\": \"\ud83d\ude2f\",\n    \":ice_cream:\": \"\ud83c\udf68\",\n    \":ice_cube:\": \"\ud83e\uddca\",\n    \":ice_hockey:\": \"\ud83c\udfd2\",\n    \":ice_skate:\": \"\u26f8\",\n    \":icecream:\": \"\ud83c\udf66\",\n    \":iceland:\": \"\ud83c\uddee\u200d\ud83c\uddf8\",\n    \":id:\": \"\ud83c\udd94\",\n    \":ideograph_advantage:\": \"\ud83c\ude50\",\n    \":imp:\": \"\ud83d\udc7f\",\n    \":inbox_tray:\": \"\ud83d\udce5\",\n    \":incoming_envelope:\": \"\ud83d\udce8\",\n    \":india:\": \"\ud83c\uddee\u200d\ud83c\uddf3\",\n    \":indonesia:\": \"\ud83c\uddee\u200d\ud83c\udde9\",\n    \":infinity:\": \"\u267e\",\n    \":information_desk_person:\": \"\ud83d\udc81\",\n    \":information_source:\": \"\u2139\",\n    \":innocent:\": \"\ud83d\ude07\",\n    \":interrobang:\": \"\u2049\",\n    \":iphone:\": \"\ud83d\udcf1\",\n    \":iran:\": \"\ud83c\uddee\u200d\ud83c\uddf7\",\n    \":iraq:\": \"\ud83c\uddee\u200d\ud83c\uddf6\",\n    \":ireland:\": \"\ud83c\uddee\u200d\ud83c\uddea\",\n    \":isle_of_man:\": \"\ud83c\uddee\u200d\ud83c\uddf2\",\n    \":israel:\": \"\ud83c\uddee\u200d\ud83c\uddf1\",\n    \":it:\": \"\ud83c\uddee\u200d\ud83c\uddf9\",\n    \":izakaya_lantern:\": \"\ud83c\udfee\",\n    \":jack_o_lantern:\": \"\ud83c\udf83\",\n    \":jamaica:\": \"\ud83c\uddef\u200d\ud83c\uddf2\",\n    \":japan:\": \"\ud83d\uddfe\",\n    \":japanese_castle:\": \"\ud83c\udfef\",\n    \":japanese_goblin:\": \"\ud83d\udc7a\",\n    \":japanese_ogre:\": \"\ud83d\udc79\",\n    \":jeans:\": \"\ud83d\udc56\",\n    \":jersey:\": \"\ud83c\uddef\u200d\ud83c\uddea\",\n    \":jigsaw:\": \"\ud83e\udde9\",\n    \":jordan:\": \"\ud83c\uddef\u200d\ud83c\uddf4\",\n    \":joy:\": \"\ud83d\ude02\",\n    \":joy_cat:\": \"\ud83d\ude39\",\n    \":joystick:\": \"\ud83d\udd79\",\n    \":jp:\": \"\ud83c\uddef\u200d\ud83c\uddf5\",\n    \":judge:\": \"\ud83e\uddd1\u200d\u2696\",\n    \":juggling_person:\": \"\ud83e\udd39\",\n    \":kaaba:\": \"\ud83d\udd4b\",\n    \":kangaroo:\": \"\ud83e\udd98\",\n    \":kazakhstan:\": \"\ud83c\uddf0\u200d\ud83c\uddff\",\n    \":kenya:\": \"\ud83c\uddf0\u200d\ud83c\uddea\",\n    \":key:\": \"\ud83d\udd11\",\n    \":keyboard:\": \"\u2328\",\n    \":keycap_ten:\": \"\ud83d\udd1f\",\n    \":kick_scooter:\": \"\ud83d\udef4\",\n    \":kimono:\": \"\ud83d\udc58\",\n    \":kiribati:\": \"\ud83c\uddf0\u200d\ud83c\uddee\",\n    \":kiss:\": \"\ud83d\udc8b\",\n    \":kissing:\": \"\ud83d\ude17\",\n    \":kissing_cat:\": \"\ud83d\ude3d\",\n    \":kissing_closed_eyes:\": \"\ud83d\ude1a\",\n    \":kissing_heart:\": \"\ud83d\ude18\",\n    \":kissing_smiling_eyes:\": \"\ud83d\ude19\",\n    \":kite:\": \"\ud83e\ude81\",\n    \":kiwi_fruit:\": \"\ud83e\udd5d\",\n    \":kneeling_man:\": \"\ud83e\uddce\u200d\u2642\",\n    \":kneeling_person:\": \"\ud83e\uddce\",\n    \":kneeling_woman:\": \"\ud83e\uddce\u200d\u2640\",\n    \":knife:\": \"\ud83d\udd2a\",\n    \":koala:\": \"\ud83d\udc28\",\n    \":koko:\": \"\ud83c\ude01\",\n    \":kosovo:\": \"\ud83c\uddfd\u200d\ud83c\uddf0\",\n    \":kr:\": \"\ud83c\uddf0\u200d\ud83c\uddf7\",\n    \":kuwait:\": \"\ud83c\uddf0\u200d\ud83c\uddfc\",\n    \":kyrgyzstan:\": \"\ud83c\uddf0\u200d\ud83c\uddec\",\n    \":lab_coat:\": \"\ud83e\udd7c\",\n    \":label:\": \"\ud83c\udff7\",\n    \":lacrosse:\": \"\ud83e\udd4d\",\n    \":lantern:\": \"\ud83c\udfee\",\n    \":laos:\": \"\ud83c\uddf1\u200d\ud83c\udde6\",\n    \":large_blue_circle:\": \"\ud83d\udd35\",\n    \":large_blue_diamond:\": \"\ud83d\udd37\",\n    \":large_orange_diamond:\": \"\ud83d\udd36\",\n    \":last_quarter_moon:\": \"\ud83c\udf17\",\n    \":last_quarter_moon_with_face:\": \"\ud83c\udf1c\",\n    \":latin_cross:\": \"\u271d\",\n    \":latvia:\": \"\ud83c\uddf1\u200d\ud83c\uddfb\",\n    \":laughing:\": \"\ud83d\ude06\",\n    \":leafy_green:\": \"\ud83e\udd6c\",\n    \":leaves:\": \"\ud83c\udf43\",\n    \":lebanon:\": \"\ud83c\uddf1\u200d\ud83c\udde7\",\n    \":ledger:\": \"\ud83d\udcd2\",\n    \":left_luggage:\": \"\ud83d\udec5\",\n    \":left_right_arrow:\": \"\u2194\",\n    \":left_speech_bubble:\": \"\ud83d\udde8\",\n    \":leftwards_arrow_with_hook:\": \"\u21a9\",\n    \":leg:\": \"\ud83e\uddb5\",\n    \":lemon:\": \"\ud83c\udf4b\",\n    \":leo:\": \"\u264c\",\n    \":leopard:\": \"\ud83d\udc06\",\n    \":lesotho:\": \"\ud83c\uddf1\u200d\ud83c\uddf8\",\n    \":level_slider:\": \"\ud83c\udf9a\",\n    \":liberia:\": \"\ud83c\uddf1\u200d\ud83c\uddf7\",\n    \":libra:\": \"\u264e\",\n    \":libya:\": \"\ud83c\uddf1\u200d\ud83c\uddfe\",\n    \":liechtenstein:\": \"\ud83c\uddf1\u200d\ud83c\uddee\",\n    \":light_rail:\": \"\ud83d\ude88\",\n    \":link:\": \"\ud83d\udd17\",\n    \":lion:\": \"\ud83e\udd81\",\n    \":lips:\": \"\ud83d\udc44\",\n    \":lipstick:\": \"\ud83d\udc84\",\n    \":lithuania:\": \"\ud83c\uddf1\u200d\ud83c\uddf9\",\n    \":lizard:\": \"\ud83e\udd8e\",\n    \":llama:\": \"\ud83e\udd99\",\n    \":lobster:\": \"\ud83e\udd9e\",\n    \":lock:\": \"\ud83d\udd12\",\n    \":lock_with_ink_pen:\": \"\ud83d\udd0f\",\n    \":lollipop:\": \"\ud83c\udf6d\",\n    \":loop:\": \"\u27bf\",\n    \":lotion_bottle:\": \"\ud83e\uddf4\",\n    \":lotus_position:\": \"\ud83e\uddd8\",\n    \":lotus_position_man:\": \"\ud83e\uddd8\u200d\u2642\",\n    \":lotus_position_woman:\": \"\ud83e\uddd8\u200d\u2640\",\n    \":loud_sound:\": \"\ud83d\udd0a\",\n    \":loudspeaker:\": \"\ud83d\udce2\",\n    \":love_hotel:\": \"\ud83c\udfe9\",\n    \":love_letter:\": \"\ud83d\udc8c\",\n    \":love_you_gesture:\": \"\ud83e\udd1f\",\n    \":low_brightness:\": \"\ud83d\udd05\",\n    \":luggage:\": \"\ud83e\uddf3\",\n    \":luxembourg:\": \"\ud83c\uddf1\u200d\ud83c\uddfa\",\n    \":lying_face:\": \"\ud83e\udd25\",\n    \":m:\": \"\u24c2\",\n    \":macau:\": \"\ud83c\uddf2\u200d\ud83c\uddf4\",\n    \":macedonia:\": \"\ud83c\uddf2\u200d\ud83c\uddf0\",\n    \":madagascar:\": \"\ud83c\uddf2\u200d\ud83c\uddec\",\n    \":mag:\": \"\ud83d\udd0d\",\n    \":mag_right:\": \"\ud83d\udd0e\",\n    \":mage:\": \"\ud83e\uddd9\",\n    \":mage_man:\": \"\ud83e\uddd9\u200d\u2642\",\n    \":mage_woman:\": \"\ud83e\uddd9\u200d\u2640\",\n    \":magnet:\": \"\ud83e\uddf2\",\n    \":mahjong:\": \"\ud83c\udc04\",\n    \":mailbox:\": \"\ud83d\udceb\",\n    \":mailbox_closed:\": \"\ud83d\udcea\",\n    \":mailbox_with_mail:\": \"\ud83d\udcec\",\n    \":mailbox_with_no_mail:\": \"\ud83d\udced\",\n    \":malawi:\": \"\ud83c\uddf2\u200d\ud83c\uddfc\",\n    \":malaysia:\": \"\ud83c\uddf2\u200d\ud83c\uddfe\",\n    \":maldives:\": \"\ud83c\uddf2\u200d\ud83c\uddfb\",\n    \":male_detective:\": \"\ud83d\udd75\u200d\u2642\",\n    \":male_sign:\": \"\u2642\",\n    \":mali:\": \"\ud83c\uddf2\u200d\ud83c\uddf1\",\n    \":malta:\": \"\ud83c\uddf2\u200d\ud83c\uddf9\",\n    \":man:\": \"\ud83d\udc68\",\n    \":man_artist:\": \"\ud83d\udc68\u200d\ud83c\udfa8\",\n    \":man_astronaut:\": \"\ud83d\udc68\u200d\ud83d\ude80\",\n    \":man_cartwheeling:\": \"\ud83e\udd38\u200d\u2642\",\n    \":man_cook:\": \"\ud83d\udc68\u200d\ud83c\udf73\",\n    \":man_dancing:\": \"\ud83d\udd7a\",\n    \":man_facepalming:\": \"\ud83e\udd26\u200d\u2642\",\n    \":man_factory_worker:\": \"\ud83d\udc68\u200d\ud83c\udfed\",\n    \":man_farmer:\": \"\ud83d\udc68\u200d\ud83c\udf3e\",\n    \":man_firefighter:\": \"\ud83d\udc68\u200d\ud83d\ude92\",\n    \":man_health_worker:\": \"\ud83d\udc68\u200d\u2695\",\n    \":man_in_manual_wheelchair:\": \"\ud83d\udc68\u200d\ud83e\uddbd\",\n    \":man_in_motorized_wheelchair:\": \"\ud83d\udc68\u200d\ud83e\uddbc\",\n    \":man_in_tuxedo:\": \"\ud83e\udd35\",\n    \":man_judge:\": \"\ud83d\udc68\u200d\u2696\",\n    \":man_juggling:\": \"\ud83e\udd39\u200d\u2642\",\n    \":man_mechanic:\": \"\ud83d\udc68\u200d\ud83d\udd27\",\n    \":man_office_worker:\": \"\ud83d\udc68\u200d\ud83d\udcbc\",\n    \":man_pilot:\": \"\ud83d\udc68\u200d\u2708\",\n    \":man_playing_handball:\": \"\ud83e\udd3e\u200d\u2642\",\n    \":man_playing_water_polo:\": \"\ud83e\udd3d\u200d\u2642\",\n    \":man_scientist:\": \"\ud83d\udc68\u200d\ud83d\udd2c\",\n    \":man_shrugging:\": \"\ud83e\udd37\u200d\u2642\",\n    \":man_singer:\": \"\ud83d\udc68\u200d\ud83c\udfa4\",\n    \":man_student:\": \"\ud83d\udc68\u200d\ud83c\udf93\",\n    \":man_teacher:\": \"\ud83d\udc68\u200d\ud83c\udfeb\",\n    \":man_technologist:\": \"\ud83d\udc68\u200d\ud83d\udcbb\",\n    \":man_with_gua_pi_mao:\": \"\ud83d\udc72\",\n    \":man_with_probing_cane:\": \"\ud83d\udc68\u200d\ud83e\uddaf\",\n    \":man_with_turban:\": \"\ud83d\udc73\u200d\u2642\",\n    \":mandarin:\": \"\ud83c\udf4a\",\n    \":mango:\": \"\ud83e\udd6d\",\n    \":mans_shoe:\": \"\ud83d\udc5e\",\n    \":mantelpiece_clock:\": \"\ud83d\udd70\",\n    \":manual_wheelchair:\": \"\ud83e\uddbd\",\n    \":maple_leaf:\": \"\ud83c\udf41\",\n    \":marshall_islands:\": \"\ud83c\uddf2\u200d\ud83c\udded\",\n    \":martial_arts_uniform:\": \"\ud83e\udd4b\",\n    \":martinique:\": \"\ud83c\uddf2\u200d\ud83c\uddf6\",\n    \":mask:\": \"\ud83d\ude37\",\n    \":massage:\": \"\ud83d\udc86\",\n    \":massage_man:\": \"\ud83d\udc86\u200d\u2642\",\n    \":massage_woman:\": \"\ud83d\udc86\u200d\u2640\",\n    \":mate:\": \"\ud83e\uddc9\",\n    \":mauritania:\": \"\ud83c\uddf2\u200d\ud83c\uddf7\",\n    \":mauritius:\": \"\ud83c\uddf2\u200d\ud83c\uddfa\",\n    \":mayotte:\": \"\ud83c\uddfe\u200d\ud83c\uddf9\",\n    \":meat_on_bone:\": \"\ud83c\udf56\",\n    \":mechanic:\": \"\ud83e\uddd1\u200d\ud83d\udd27\",\n    \":mechanical_arm:\": \"\ud83e\uddbe\",\n    \":mechanical_leg:\": \"\ud83e\uddbf\",\n    \":medal_military:\": \"\ud83c\udf96\",\n    \":medal_sports:\": \"\ud83c\udfc5\",\n    \":medical_symbol:\": \"\u2695\",\n    \":mega:\": \"\ud83d\udce3\",\n    \":melon:\": \"\ud83c\udf48\",\n    \":memo:\": \"\ud83d\udcdd\",\n    \":men_wrestling:\": \"\ud83e\udd3c\u200d\u2642\",\n    \":menorah:\": \"\ud83d\udd4e\",\n    \":mens:\": \"\ud83d\udeb9\",\n    \":mermaid:\": \"\ud83e\udddc\u200d\u2640\",\n    \":merman:\": \"\ud83e\udddc\u200d\u2642\",\n    \":merperson:\": \"\ud83e\udddc\",\n    \":metal:\": \"\ud83e\udd18\",\n    \":metro:\": \"\ud83d\ude87\",\n    \":mexico:\": \"\ud83c\uddf2\u200d\ud83c\uddfd\",\n    \":microbe:\": \"\ud83e\udda0\",\n    \":micronesia:\": \"\ud83c\uddeb\u200d\ud83c\uddf2\",\n    \":microphone:\": \"\ud83c\udfa4\",\n    \":microscope:\": \"\ud83d\udd2c\",\n    \":middle_finger:\": \"\ud83d\udd95\",\n    \":milk_glass:\": \"\ud83e\udd5b\",\n    \":milky_way:\": \"\ud83c\udf0c\",\n    \":minibus:\": \"\ud83d\ude90\",\n    \":minidisc:\": \"\ud83d\udcbd\",\n    \":mobile_phone_off:\": \"\ud83d\udcf4\",\n    \":moldova:\": \"\ud83c\uddf2\u200d\ud83c\udde9\",\n    \":monaco:\": \"\ud83c\uddf2\u200d\ud83c\udde8\",\n    \":money_mouth_face:\": \"\ud83e\udd11\",\n    \":money_with_wings:\": \"\ud83d\udcb8\",\n    \":moneybag:\": \"\ud83d\udcb0\",\n    \":mongolia:\": \"\ud83c\uddf2\u200d\ud83c\uddf3\",\n    \":monkey:\": \"\ud83d\udc12\",\n    \":monkey_face:\": \"\ud83d\udc35\",\n    \":monocle_face:\": \"\ud83e\uddd0\",\n    \":monorail:\": \"\ud83d\ude9d\",\n    \":montenegro:\": \"\ud83c\uddf2\u200d\ud83c\uddea\",\n    \":montserrat:\": \"\ud83c\uddf2\u200d\ud83c\uddf8\",\n    \":moon:\": \"\ud83c\udf14\",\n    \":moon_cake:\": \"\ud83e\udd6e\",\n    \":morocco:\": \"\ud83c\uddf2\u200d\ud83c\udde6\",\n    \":mortar_board:\": \"\ud83c\udf93\",\n    \":mosque:\": \"\ud83d\udd4c\",\n    \":mosquito:\": \"\ud83e\udd9f\",\n    \":motor_boat:\": \"\ud83d\udee5\",\n    \":motor_scooter:\": \"\ud83d\udef5\",\n    \":motorcycle:\": \"\ud83c\udfcd\",\n    \":motorized_wheelchair:\": \"\ud83e\uddbc\",\n    \":motorway:\": \"\ud83d\udee3\",\n    \":mount_fuji:\": \"\ud83d\uddfb\",\n    \":mountain:\": \"\u26f0\",\n    \":mountain_bicyclist:\": \"\ud83d\udeb5\",\n    \":mountain_biking_man:\": \"\ud83d\udeb5\u200d\u2642\",\n    \":mountain_biking_woman:\": \"\ud83d\udeb5\u200d\u2640\",\n    \":mountain_cableway:\": \"\ud83d\udea0\",\n    \":mountain_railway:\": \"\ud83d\ude9e\",\n    \":mountain_snow:\": \"\ud83c\udfd4\",\n    \":mouse:\": \"\ud83d\udc2d\",\n    \":mouse2:\": \"\ud83d\udc01\",\n    \":movie_camera:\": \"\ud83c\udfa5\",\n    \":moyai:\": \"\ud83d\uddff\",\n    \":mozambique:\": \"\ud83c\uddf2\u200d\ud83c\uddff\",\n    \":mrs_claus:\": \"\ud83e\udd36\",\n    \":muscle:\": \"\ud83d\udcaa\",\n    \":mushroom:\": \"\ud83c\udf44\",\n    \":musical_keyboard:\": \"\ud83c\udfb9\",\n    \":musical_note:\": \"\ud83c\udfb5\",\n    \":musical_score:\": \"\ud83c\udfbc\",\n    \":mute:\": \"\ud83d\udd07\",\n    \":myanmar:\": \"\ud83c\uddf2\u200d\ud83c\uddf2\",\n    \":nail_care:\": \"\ud83d\udc85\",\n    \":name_badge:\": \"\ud83d\udcdb\",\n    \":namibia:\": \"\ud83c\uddf3\u200d\ud83c\udde6\",\n    \":national_park:\": \"\ud83c\udfde\",\n    \":nauru:\": \"\ud83c\uddf3\u200d\ud83c\uddf7\",\n    \":nauseated_face:\": \"\ud83e\udd22\",\n    \":nazar_amulet:\": \"\ud83e\uddff\",\n    \":necktie:\": \"\ud83d\udc54\",\n    \":negative_squared_cross_mark:\": \"\u274e\",\n    \":nepal:\": \"\ud83c\uddf3\u200d\ud83c\uddf5\",\n    \":nerd_face:\": \"\ud83e\udd13\",\n    \":netherlands:\": \"\ud83c\uddf3\u200d\ud83c\uddf1\",\n    \":neutral_face:\": \"\ud83d\ude10\",\n    \":new:\": \"\ud83c\udd95\",\n    \":new_caledonia:\": \"\ud83c\uddf3\u200d\ud83c\udde8\",\n    \":new_moon:\": \"\ud83c\udf11\",\n    \":new_moon_with_face:\": \"\ud83c\udf1a\",\n    \":new_zealand:\": \"\ud83c\uddf3\u200d\ud83c\uddff\",\n    \":newspaper:\": \"\ud83d\udcf0\",\n    \":newspaper_roll:\": \"\ud83d\uddde\",\n    \":next_track_button:\": \"\u23ed\",\n    \":ng:\": \"\ud83c\udd96\",\n    \":ng_man:\": \"\ud83d\ude45\u200d\u2642\",\n    \":ng_woman:\": \"\ud83d\ude45\u200d\u2640\",\n    \":nicaragua:\": \"\ud83c\uddf3\u200d\ud83c\uddee\",\n    \":niger:\": \"\ud83c\uddf3\u200d\ud83c\uddea\",\n    \":nigeria:\": \"\ud83c\uddf3\u200d\ud83c\uddec\",\n    \":night_with_stars:\": \"\ud83c\udf03\",\n    \":nine:\": \"9\u200d\u20e3\",\n    \":niue:\": \"\ud83c\uddf3\u200d\ud83c\uddfa\",\n    \":no_bell:\": \"\ud83d\udd15\",\n    \":no_bicycles:\": \"\ud83d\udeb3\",\n    \":no_entry:\": \"\u26d4\",\n    \":no_entry_sign:\": \"\ud83d\udeab\",\n    \":no_good:\": \"\ud83d\ude45\",\n    \":no_good_man:\": \"\ud83d\ude45\u200d\u2642\",\n    \":no_good_woman:\": \"\ud83d\ude45\u200d\u2640\",\n    \":no_mobile_phones:\": \"\ud83d\udcf5\",\n    \":no_mouth:\": \"\ud83d\ude36\",\n    \":no_pedestrians:\": \"\ud83d\udeb7\",\n    \":no_smoking:\": \"\ud83d\udead\",\n    \":non-potable_water:\": \"\ud83d\udeb1\",\n    \":norfolk_island:\": \"\ud83c\uddf3\u200d\ud83c\uddeb\",\n    \":north_korea:\": \"\ud83c\uddf0\u200d\ud83c\uddf5\",\n    \":northern_mariana_islands:\": \"\ud83c\uddf2\u200d\ud83c\uddf5\",\n    \":norway:\": \"\ud83c\uddf3\u200d\ud83c\uddf4\",\n    \":nose:\": \"\ud83d\udc43\",\n    \":notebook:\": \"\ud83d\udcd3\",\n    \":notebook_with_decorative_cover:\": \"\ud83d\udcd4\",\n    \":notes:\": \"\ud83c\udfb6\",\n    \":nut_and_bolt:\": \"\ud83d\udd29\",\n    \":o:\": \"\u2b55\",\n    \":o2:\": \"\ud83c\udd7e\",\n    \":ocean:\": \"\ud83c\udf0a\",\n    \":octopus:\": \"\ud83d\udc19\",\n    \":oden:\": \"\ud83c\udf62\",\n    \":office:\": \"\ud83c\udfe2\",\n    \":office_worker:\": \"\ud83e\uddd1\u200d\ud83d\udcbc\",\n    \":oil_drum:\": \"\ud83d\udee2\",\n    \":ok:\": \"\ud83c\udd97\",\n    \":ok_hand:\": \"\ud83d\udc4c\",\n    \":ok_man:\": \"\ud83d\ude46\u200d\u2642\",\n    \":ok_person:\": \"\ud83d\ude46\",\n    \":ok_woman:\": \"\ud83d\ude46\u200d\u2640\",\n    \":old_key:\": \"\ud83d\udddd\",\n    \":older_adult:\": \"\ud83e\uddd3\",\n    \":older_man:\": \"\ud83d\udc74\",\n    \":older_woman:\": \"\ud83d\udc75\",\n    \":om:\": \"\ud83d\udd49\",\n    \":oman:\": \"\ud83c\uddf4\u200d\ud83c\uddf2\",\n    \":on:\": \"\ud83d\udd1b\",\n    \":oncoming_automobile:\": \"\ud83d\ude98\",\n    \":oncoming_bus:\": \"\ud83d\ude8d\",\n    \":oncoming_police_car:\": \"\ud83d\ude94\",\n    \":oncoming_taxi:\": \"\ud83d\ude96\",\n    \":one:\": \"1\u200d\u20e3\",\n    \":one_piece_swimsuit:\": \"\ud83e\ude71\",\n    \":onion:\": \"\ud83e\uddc5\",\n    \":open_book:\": \"\ud83d\udcd6\",\n    \":open_file_folder:\": \"\ud83d\udcc2\",\n    \":open_hands:\": \"\ud83d\udc50\",\n    \":open_mouth:\": \"\ud83d\ude2e\",\n    \":open_umbrella:\": \"\u2602\",\n    \":ophiuchus:\": \"\u26ce\",\n    \":orange:\": \"\ud83c\udf4a\",\n    \":orange_book:\": \"\ud83d\udcd9\",\n    \":orange_circle:\": \"\ud83d\udfe0\",\n    \":orange_heart:\": \"\ud83e\udde1\",\n    \":orange_square:\": \"\ud83d\udfe7\",\n    \":orangutan:\": \"\ud83e\udda7\",\n    \":orthodox_cross:\": \"\u2626\",\n    \":otter:\": \"\ud83e\udda6\",\n    \":outbox_tray:\": \"\ud83d\udce4\",\n    \":owl:\": \"\ud83e\udd89\",\n    \":ox:\": \"\ud83d\udc02\",\n    \":oyster:\": \"\ud83e\uddaa\",\n    \":package:\": \"\ud83d\udce6\",\n    \":page_facing_up:\": \"\ud83d\udcc4\",\n    \":page_with_curl:\": \"\ud83d\udcc3\",\n    \":pager:\": \"\ud83d\udcdf\",\n    \":paintbrush:\": \"\ud83d\udd8c\",\n    \":pakistan:\": \"\ud83c\uddf5\u200d\ud83c\uddf0\",\n    \":palau:\": \"\ud83c\uddf5\u200d\ud83c\uddfc\",\n    \":palestinian_territories:\": \"\ud83c\uddf5\u200d\ud83c\uddf8\",\n    \":palm_tree:\": \"\ud83c\udf34\",\n    \":palms_up_together:\": \"\ud83e\udd32\",\n    \":panama:\": \"\ud83c\uddf5\u200d\ud83c\udde6\",\n    \":pancakes:\": \"\ud83e\udd5e\",\n    \":panda_face:\": \"\ud83d\udc3c\",\n    \":paperclip:\": \"\ud83d\udcce\",\n    \":paperclips:\": \"\ud83d\udd87\",\n    \":papua_new_guinea:\": \"\ud83c\uddf5\u200d\ud83c\uddec\",\n    \":parachute:\": \"\ud83e\ude82\",\n    \":paraguay:\": \"\ud83c\uddf5\u200d\ud83c\uddfe\",\n    \":parasol_on_ground:\": \"\u26f1\",\n    \":parking:\": \"\ud83c\udd7f\",\n    \":parrot:\": \"\ud83e\udd9c\",\n    \":part_alternation_mark:\": \"\u303d\",\n    \":partly_sunny:\": \"\u26c5\",\n    \":partying_face:\": \"\ud83e\udd73\",\n    \":passenger_ship:\": \"\ud83d\udef3\",\n    \":passport_control:\": \"\ud83d\udec2\",\n    \":pause_button:\": \"\u23f8\",\n    \":paw_prints:\": \"\ud83d\udc3e\",\n    \":peace_symbol:\": \"\u262e\",\n    \":peach:\": \"\ud83c\udf51\",\n    \":peacock:\": \"\ud83e\udd9a\",\n    \":peanuts:\": \"\ud83e\udd5c\",\n    \":pear:\": \"\ud83c\udf50\",\n    \":pen:\": \"\ud83d\udd8a\",\n    \":pencil:\": \"\ud83d\udcdd\",\n    \":pencil2:\": \"\u270f\",\n    \":penguin:\": \"\ud83d\udc27\",\n    \":pensive:\": \"\ud83d\ude14\",\n    \":people_holding_hands:\": \"\ud83e\uddd1\u200d\ud83e\udd1d\u200d\ud83e\uddd1\",\n    \":performing_arts:\": \"\ud83c\udfad\",\n    \":persevere:\": \"\ud83d\ude23\",\n    \":person_bald:\": \"\ud83e\uddd1\u200d\ud83e\uddb2\",\n    \":person_curly_hair:\": \"\ud83e\uddd1\u200d\ud83e\uddb1\",\n    \":person_fencing:\": \"\ud83e\udd3a\",\n    \":person_in_manual_wheelchair:\": \"\ud83e\uddd1\u200d\ud83e\uddbd\",\n    \":person_in_motorized_wheelchair:\": \"\ud83e\uddd1\u200d\ud83e\uddbc\",\n    \":person_red_hair:\": \"\ud83e\uddd1\u200d\ud83e\uddb0\",\n    \":person_white_hair:\": \"\ud83e\uddd1\u200d\ud83e\uddb3\",\n    \":person_with_probing_cane:\": \"\ud83e\uddd1\u200d\ud83e\uddaf\",\n    \":person_with_turban:\": \"\ud83d\udc73\",\n    \":peru:\": \"\ud83c\uddf5\u200d\ud83c\uddea\",\n    \":petri_dish:\": \"\ud83e\uddeb\",\n    \":philippines:\": \"\ud83c\uddf5\u200d\ud83c\udded\",\n    \":phone:\": \"\u260e\",\n    \":pick:\": \"\u26cf\",\n    \":pie:\": \"\ud83e\udd67\",\n    \":pig:\": \"\ud83d\udc37\",\n    \":pig2:\": \"\ud83d\udc16\",\n    \":pig_nose:\": \"\ud83d\udc3d\",\n    \":pill:\": \"\ud83d\udc8a\",\n    \":pilot:\": \"\ud83e\uddd1\u200d\u2708\",\n    \":pinching_hand:\": \"\ud83e\udd0f\",\n    \":pineapple:\": \"\ud83c\udf4d\",\n    \":ping_pong:\": \"\ud83c\udfd3\",\n    \":pirate_flag:\": \"\ud83c\udff4\u200d\u2620\",\n    \":pisces:\": \"\u2653\",\n    \":pitcairn_islands:\": \"\ud83c\uddf5\u200d\ud83c\uddf3\",\n    \":pizza:\": \"\ud83c\udf55\",\n    \":place_of_worship:\": \"\ud83d\uded0\",\n    \":plate_with_cutlery:\": \"\ud83c\udf7d\",\n    \":play_or_pause_button:\": \"\u23ef\",\n    \":pleading_face:\": \"\ud83e\udd7a\",\n    \":point_down:\": \"\ud83d\udc47\",\n    \":point_left:\": \"\ud83d\udc48\",\n    \":point_right:\": \"\ud83d\udc49\",\n    \":point_up:\": \"\u261d\",\n    \":point_up_2:\": \"\ud83d\udc46\",\n    \":poland:\": \"\ud83c\uddf5\u200d\ud83c\uddf1\",\n    \":police_car:\": \"\ud83d\ude93\",\n    \":police_officer:\": \"\ud83d\udc6e\",\n    \":policeman:\": \"\ud83d\udc6e\u200d\u2642\",\n    \":policewoman:\": \"\ud83d\udc6e\u200d\u2640\",\n    \":poodle:\": \"\ud83d\udc29\",\n    \":poop:\": \"\ud83d\udca9\",\n    \":popcorn:\": \"\ud83c\udf7f\",\n    \":portugal:\": \"\ud83c\uddf5\u200d\ud83c\uddf9\",\n    \":post_office:\": \"\ud83c\udfe3\",\n    \":postal_horn:\": \"\ud83d\udcef\",\n    \":postbox:\": \"\ud83d\udcee\",\n    \":potable_water:\": \"\ud83d\udeb0\",\n    \":potato:\": \"\ud83e\udd54\",\n    \":pouch:\": \"\ud83d\udc5d\",\n    \":poultry_leg:\": \"\ud83c\udf57\",\n    \":pound:\": \"\ud83d\udcb7\",\n    \":pout:\": \"\ud83d\ude21\",\n    \":pouting_cat:\": \"\ud83d\ude3e\",\n    \":pouting_face:\": \"\ud83d\ude4e\",\n    \":pouting_man:\": \"\ud83d\ude4e\u200d\u2642\",\n    \":pouting_woman:\": \"\ud83d\ude4e\u200d\u2640\",\n    \":pray:\": \"\ud83d\ude4f\",\n    \":prayer_beads:\": \"\ud83d\udcff\",\n    \":pregnant_woman:\": \"\ud83e\udd30\",\n    \":pretzel:\": \"\ud83e\udd68\",\n    \":previous_track_button:\": \"\u23ee\",\n    \":prince:\": \"\ud83e\udd34\",\n    \":princess:\": \"\ud83d\udc78\",\n    \":printer:\": \"\ud83d\udda8\",\n    \":probing_cane:\": \"\ud83e\uddaf\",\n    \":puerto_rico:\": \"\ud83c\uddf5\u200d\ud83c\uddf7\",\n    \":punch:\": \"\ud83d\udc4a\",\n    \":purple_circle:\": \"\ud83d\udfe3\",\n    \":purple_heart:\": \"\ud83d\udc9c\",\n    \":purple_square:\": \"\ud83d\udfea\",\n    \":purse:\": \"\ud83d\udc5b\",\n    \":pushpin:\": \"\ud83d\udccc\",\n    \":put_litter_in_its_place:\": \"\ud83d\udeae\",\n    \":qatar:\": \"\ud83c\uddf6\u200d\ud83c\udde6\",\n    \":question:\": \"\u2753\",\n    \":rabbit:\": \"\ud83d\udc30\",\n    \":rabbit2:\": \"\ud83d\udc07\",\n    \":raccoon:\": \"\ud83e\udd9d\",\n    \":racehorse:\": \"\ud83d\udc0e\",\n    \":racing_car:\": \"\ud83c\udfce\",\n    \":radio:\": \"\ud83d\udcfb\",\n    \":radio_button:\": \"\ud83d\udd18\",\n    \":radioactive:\": \"\u2622\",\n    \":rage:\": \"\ud83d\ude21\",\n    \":railway_car:\": \"\ud83d\ude83\",\n    \":railway_track:\": \"\ud83d\udee4\",\n    \":rainbow:\": \"\ud83c\udf08\",\n    \":rainbow_flag:\": \"\ud83c\udff3\u200d\ud83c\udf08\",\n    \":raised_back_of_hand:\": \"\ud83e\udd1a\",\n    \":raised_eyebrow:\": \"\ud83e\udd28\",\n    \":raised_hand:\": \"\u270b\",\n    \":raised_hand_with_fingers_splayed:\": \"\ud83d\udd90\",\n    \":raised_hands:\": \"\ud83d\ude4c\",\n    \":raising_hand:\": \"\ud83d\ude4b\",\n    \":raising_hand_man:\": \"\ud83d\ude4b\u200d\u2642\",\n    \":raising_hand_woman:\": \"\ud83d\ude4b\u200d\u2640\",\n    \":ram:\": \"\ud83d\udc0f\",\n    \":ramen:\": \"\ud83c\udf5c\",\n    \":rat:\": \"\ud83d\udc00\",\n    \":razor:\": \"\ud83e\ude92\",\n    \":receipt:\": \"\ud83e\uddfe\",\n    \":record_button:\": \"\u23fa\",\n    \":recycle:\": \"\u267b\",\n    \":red_car:\": \"\ud83d\ude97\",\n    \":red_circle:\": \"\ud83d\udd34\",\n    \":red_envelope:\": \"\ud83e\udde7\",\n    \":red_haired_man:\": \"\ud83d\udc68\u200d\ud83e\uddb0\",\n    \":red_haired_woman:\": \"\ud83d\udc69\u200d\ud83e\uddb0\",\n    \":red_square:\": \"\ud83d\udfe5\",\n    \":registered:\": \"\u00ae\",\n    \":relaxed:\": \"\u263a\",\n    \":relieved:\": \"\ud83d\ude0c\",\n    \":reminder_ribbon:\": \"\ud83c\udf97\",\n    \":repeat:\": \"\ud83d\udd01\",\n    \":repeat_one:\": \"\ud83d\udd02\",\n    \":rescue_worker_helmet:\": \"\u26d1\",\n    \":restroom:\": \"\ud83d\udebb\",\n    \":reunion:\": \"\ud83c\uddf7\u200d\ud83c\uddea\",\n    \":revolving_hearts:\": \"\ud83d\udc9e\",\n    \":rewind:\": \"\u23ea\",\n    \":rhinoceros:\": \"\ud83e\udd8f\",\n    \":ribbon:\": \"\ud83c\udf80\",\n    \":rice:\": \"\ud83c\udf5a\",\n    \":rice_ball:\": \"\ud83c\udf59\",\n    \":rice_cracker:\": \"\ud83c\udf58\",\n    \":rice_scene:\": \"\ud83c\udf91\",\n    \":right_anger_bubble:\": \"\ud83d\uddef\",\n    \":ring:\": \"\ud83d\udc8d\",\n    \":ringed_planet:\": \"\ud83e\ude90\",\n    \":robot:\": \"\ud83e\udd16\",\n    \":rocket:\": \"\ud83d\ude80\",\n    \":rofl:\": \"\ud83e\udd23\",\n    \":roll_eyes:\": \"\ud83d\ude44\",\n    \":roll_of_paper:\": \"\ud83e\uddfb\",\n    \":roller_coaster:\": \"\ud83c\udfa2\",\n    \":romania:\": \"\ud83c\uddf7\u200d\ud83c\uddf4\",\n    \":rooster:\": \"\ud83d\udc13\",\n    \":rose:\": \"\ud83c\udf39\",\n    \":rosette:\": \"\ud83c\udff5\",\n    \":rotating_light:\": \"\ud83d\udea8\",\n    \":round_pushpin:\": \"\ud83d\udccd\",\n    \":rowboat:\": \"\ud83d\udea3\",\n    \":rowing_man:\": \"\ud83d\udea3\u200d\u2642\",\n    \":rowing_woman:\": \"\ud83d\udea3\u200d\u2640\",\n    \":ru:\": \"\ud83c\uddf7\u200d\ud83c\uddfa\",\n    \":rugby_football:\": \"\ud83c\udfc9\",\n    \":runner:\": \"\ud83c\udfc3\",\n    \":running:\": \"\ud83c\udfc3\",\n    \":running_man:\": \"\ud83c\udfc3\u200d\u2642\",\n    \":running_shirt_with_sash:\": \"\ud83c\udfbd\",\n    \":running_woman:\": \"\ud83c\udfc3\u200d\u2640\",\n    \":rwanda:\": \"\ud83c\uddf7\u200d\ud83c\uddfc\",\n    \":sa:\": \"\ud83c\ude02\",\n    \":safety_pin:\": \"\ud83e\uddf7\",\n    \":safety_vest:\": \"\ud83e\uddba\",\n    \":sagittarius:\": \"\u2650\",\n    \":sailboat:\": \"\u26f5\",\n    \":sake:\": \"\ud83c\udf76\",\n    \":salt:\": \"\ud83e\uddc2\",\n    \":samoa:\": \"\ud83c\uddfc\u200d\ud83c\uddf8\",\n    \":san_marino:\": \"\ud83c\uddf8\u200d\ud83c\uddf2\",\n    \":sandal:\": \"\ud83d\udc61\",\n    \":sandwich:\": \"\ud83e\udd6a\",\n    \":santa:\": \"\ud83c\udf85\",\n    \":sao_tome_principe:\": \"\ud83c\uddf8\u200d\ud83c\uddf9\",\n    \":sari:\": \"\ud83e\udd7b\",\n    \":sassy_man:\": \"\ud83d\udc81\u200d\u2642\",\n    \":sassy_woman:\": \"\ud83d\udc81\u200d\u2640\",\n    \":satellite:\": \"\ud83d\udce1\",\n    \":satisfied:\": \"\ud83d\ude06\",\n    \":saudi_arabia:\": \"\ud83c\uddf8\u200d\ud83c\udde6\",\n    \":sauna_man:\": \"\ud83e\uddd6\u200d\u2642\",\n    \":sauna_person:\": \"\ud83e\uddd6\",\n    \":sauna_woman:\": \"\ud83e\uddd6\u200d\u2640\",\n    \":sauropod:\": \"\ud83e\udd95\",\n    \":saxophone:\": \"\ud83c\udfb7\",\n    \":scarf:\": \"\ud83e\udde3\",\n    \":school:\": \"\ud83c\udfeb\",\n    \":school_satchel:\": \"\ud83c\udf92\",\n    \":scientist:\": \"\ud83e\uddd1\u200d\ud83d\udd2c\",\n    \":scissors:\": \"\u2702\",\n    \":scorpion:\": \"\ud83e\udd82\",\n    \":scorpius:\": \"\u264f\",\n    \":scotland:\": \"\ud83c\udff4\u200d\udb40\udc67\u200d\udb40\udc62\u200d\udb40\udc73\u200d\udb40\udc63\u200d\udb40\udc74\u200d\udb40\udc7f\",\n    \":scream:\": \"\ud83d\ude31\",\n    \":scream_cat:\": \"\ud83d\ude40\",\n    \":scroll:\": \"\ud83d\udcdc\",\n    \":seat:\": \"\ud83d\udcba\",\n    \":secret:\": \"\u3299\",\n    \":see_no_evil:\": \"\ud83d\ude48\",\n    \":seedling:\": \"\ud83c\udf31\",\n    \":selfie:\": \"\ud83e\udd33\",\n    \":senegal:\": \"\ud83c\uddf8\u200d\ud83c\uddf3\",\n    \":serbia:\": \"\ud83c\uddf7\u200d\ud83c\uddf8\",\n    \":service_dog:\": \"\ud83d\udc15\u200d\ud83e\uddba\",\n    \":seven:\": \"7\u200d\u20e3\",\n    \":seychelles:\": \"\ud83c\uddf8\u200d\ud83c\udde8\",\n    \":shallow_pan_of_food:\": \"\ud83e\udd58\",\n    \":shamrock:\": \"\u2618\",\n    \":shark:\": \"\ud83e\udd88\",\n    \":shaved_ice:\": \"\ud83c\udf67\",\n    \":sheep:\": \"\ud83d\udc11\",\n    \":shell:\": \"\ud83d\udc1a\",\n    \":shield:\": \"\ud83d\udee1\",\n    \":shinto_shrine:\": \"\u26e9\",\n    \":ship:\": \"\ud83d\udea2\",\n    \":shirt:\": \"\ud83d\udc55\",\n    \":shit:\": \"\ud83d\udca9\",\n    \":shoe:\": \"\ud83d\udc5e\",\n    \":shopping:\": \"\ud83d\udecd\",\n    \":shopping_cart:\": \"\ud83d\uded2\",\n    \":shorts:\": \"\ud83e\ude73\",\n    \":shower:\": \"\ud83d\udebf\",\n    \":shrimp:\": \"\ud83e\udd90\",\n    \":shrug:\": \"\ud83e\udd37\",\n    \":shushing_face:\": \"\ud83e\udd2b\",\n    \":sierra_leone:\": \"\ud83c\uddf8\u200d\ud83c\uddf1\",\n    \":signal_strength:\": \"\ud83d\udcf6\",\n    \":singapore:\": \"\ud83c\uddf8\u200d\ud83c\uddec\",\n    \":singer:\": \"\ud83e\uddd1\u200d\ud83c\udfa4\",\n    \":sint_maarten:\": \"\ud83c\uddf8\u200d\ud83c\uddfd\",\n    \":six:\": \"6\u200d\u20e3\",\n    \":six_pointed_star:\": \"\ud83d\udd2f\",\n    \":skateboard:\": \"\ud83d\udef9\",\n    \":ski:\": \"\ud83c\udfbf\",\n    \":skier:\": \"\u26f7\",\n    \":skull:\": \"\ud83d\udc80\",\n    \":skull_and_crossbones:\": \"\u2620\",\n    \":skunk:\": \"\ud83e\udda8\",\n    \":sled:\": \"\ud83d\udef7\",\n    \":sleeping:\": \"\ud83d\ude34\",\n    \":sleeping_bed:\": \"\ud83d\udecc\",\n    \":sleepy:\": \"\ud83d\ude2a\",\n    \":slightly_frowning_face:\": \"\ud83d\ude41\",\n    \":slightly_smiling_face:\": \"\ud83d\ude42\",\n    \":slot_machine:\": \"\ud83c\udfb0\",\n    \":sloth:\": \"\ud83e\udda5\",\n    \":slovakia:\": \"\ud83c\uddf8\u200d\ud83c\uddf0\",\n    \":slovenia:\": \"\ud83c\uddf8\u200d\ud83c\uddee\",\n    \":small_airplane:\": \"\ud83d\udee9\",\n    \":small_blue_diamond:\": \"\ud83d\udd39\",\n    \":small_orange_diamond:\": \"\ud83d\udd38\",\n    \":small_red_triangle:\": \"\ud83d\udd3a\",\n    \":small_red_triangle_down:\": \"\ud83d\udd3b\",\n    \":smile:\": \"\ud83d\ude04\",\n    \":smile_cat:\": \"\ud83d\ude38\",\n    \":smiley:\": \"\ud83d\ude03\",\n    \":smiley_cat:\": \"\ud83d\ude3a\",\n    \":smiling_face_with_three_hearts:\": \"\ud83e\udd70\",\n    \":smiling_imp:\": \"\ud83d\ude08\",\n    \":smirk:\": \"\ud83d\ude0f\",\n    \":smirk_cat:\": \"\ud83d\ude3c\",\n    \":smoking:\": \"\ud83d\udeac\",\n    \":snail:\": \"\ud83d\udc0c\",\n    \":snake:\": \"\ud83d\udc0d\",\n    \":sneezing_face:\": \"\ud83e\udd27\",\n    \":snowboarder:\": \"\ud83c\udfc2\",\n    \":snowflake:\": \"\u2744\",\n    \":snowman:\": \"\u26c4\",\n    \":snowman_with_snow:\": \"\u2603\",\n    \":soap:\": \"\ud83e\uddfc\",\n    \":sob:\": \"\ud83d\ude2d\",\n    \":soccer:\": \"\u26bd\",\n    \":socks:\": \"\ud83e\udde6\",\n    \":softball:\": \"\ud83e\udd4e\",\n    \":solomon_islands:\": \"\ud83c\uddf8\u200d\ud83c\udde7\",\n    \":somalia:\": \"\ud83c\uddf8\u200d\ud83c\uddf4\",\n    \":soon:\": \"\ud83d\udd1c\",\n    \":sos:\": \"\ud83c\udd98\",\n    \":sound:\": \"\ud83d\udd09\",\n    \":south_africa:\": \"\ud83c\uddff\u200d\ud83c\udde6\",\n    \":south_georgia_south_sandwich_islands:\": \"\ud83c\uddec\u200d\ud83c\uddf8\",\n    \":south_sudan:\": \"\ud83c\uddf8\u200d\ud83c\uddf8\",\n    \":space_invader:\": \"\ud83d\udc7e\",\n    \":spades:\": \"\u2660\",\n    \":spaghetti:\": \"\ud83c\udf5d\",\n    \":sparkle:\": \"\u2747\",\n    \":sparkler:\": \"\ud83c\udf87\",\n    \":sparkles:\": \"\u2728\",\n    \":sparkling_heart:\": \"\ud83d\udc96\",\n    \":speak_no_evil:\": \"\ud83d\ude4a\",\n    \":speaker:\": \"\ud83d\udd08\",\n    \":speaking_head:\": \"\ud83d\udde3\",\n    \":speech_balloon:\": \"\ud83d\udcac\",\n    \":speedboat:\": \"\ud83d\udea4\",\n    \":spider:\": \"\ud83d\udd77\",\n    \":spider_web:\": \"\ud83d\udd78\",\n    \":spiral_calendar:\": \"\ud83d\uddd3\",\n    \":spiral_notepad:\": \"\ud83d\uddd2\",\n    \":sponge:\": \"\ud83e\uddfd\",\n    \":spoon:\": \"\ud83e\udd44\",\n    \":squid:\": \"\ud83e\udd91\",\n    \":sri_lanka:\": \"\ud83c\uddf1\u200d\ud83c\uddf0\",\n    \":st_barthelemy:\": \"\ud83c\udde7\u200d\ud83c\uddf1\",\n    \":st_helena:\": \"\ud83c\uddf8\u200d\ud83c\udded\",\n    \":st_kitts_nevis:\": \"\ud83c\uddf0\u200d\ud83c\uddf3\",\n    \":st_lucia:\": \"\ud83c\uddf1\u200d\ud83c\udde8\",\n    \":st_martin:\": \"\ud83c\uddf2\u200d\ud83c\uddeb\",\n    \":st_pierre_miquelon:\": \"\ud83c\uddf5\u200d\ud83c\uddf2\",\n    \":st_vincent_grenadines:\": \"\ud83c\uddfb\u200d\ud83c\udde8\",\n    \":stadium:\": \"\ud83c\udfdf\",\n    \":standing_man:\": \"\ud83e\uddcd\u200d\u2642\",\n    \":standing_person:\": \"\ud83e\uddcd\",\n    \":standing_woman:\": \"\ud83e\uddcd\u200d\u2640\",\n    \":star:\": \"\u2b50\",\n    \":star2:\": \"\ud83c\udf1f\",\n    \":star_and_crescent:\": \"\u262a\",\n    \":star_of_david:\": \"\u2721\",\n    \":star_struck:\": \"\ud83e\udd29\",\n    \":stars:\": \"\ud83c\udf20\",\n    \":station:\": \"\ud83d\ude89\",\n    \":statue_of_liberty:\": \"\ud83d\uddfd\",\n    \":steam_locomotive:\": \"\ud83d\ude82\",\n    \":stethoscope:\": \"\ud83e\ude7a\",\n    \":stew:\": \"\ud83c\udf72\",\n    \":stop_button:\": \"\u23f9\",\n    \":stop_sign:\": \"\ud83d\uded1\",\n    \":stopwatch:\": \"\u23f1\",\n    \":straight_ruler:\": \"\ud83d\udccf\",\n    \":strawberry:\": \"\ud83c\udf53\",\n    \":stuck_out_tongue:\": \"\ud83d\ude1b\",\n    \":stuck_out_tongue_closed_eyes:\": \"\ud83d\ude1d\",\n    \":stuck_out_tongue_winking_eye:\": \"\ud83d\ude1c\",\n    \":student:\": \"\ud83e\uddd1\u200d\ud83c\udf93\",\n    \":studio_microphone:\": \"\ud83c\udf99\",\n    \":stuffed_flatbread:\": \"\ud83e\udd59\",\n    \":sudan:\": \"\ud83c\uddf8\u200d\ud83c\udde9\",\n    \":sun_behind_large_cloud:\": \"\ud83c\udf25\",\n    \":sun_behind_rain_cloud:\": \"\ud83c\udf26\",\n    \":sun_behind_small_cloud:\": \"\ud83c\udf24\",\n    \":sun_with_face:\": \"\ud83c\udf1e\",\n    \":sunflower:\": \"\ud83c\udf3b\",\n    \":sunglasses:\": \"\ud83d\ude0e\",\n    \":sunny:\": \"\u2600\",\n    \":sunrise:\": \"\ud83c\udf05\",\n    \":sunrise_over_mountains:\": \"\ud83c\udf04\",\n    \":superhero:\": \"\ud83e\uddb8\",\n    \":superhero_man:\": \"\ud83e\uddb8\u200d\u2642\",\n    \":superhero_woman:\": \"\ud83e\uddb8\u200d\u2640\",\n    \":supervillain:\": \"\ud83e\uddb9\",\n    \":supervillain_man:\": \"\ud83e\uddb9\u200d\u2642\",\n    \":supervillain_woman:\": \"\ud83e\uddb9\u200d\u2640\",\n    \":surfer:\": \"\ud83c\udfc4\",\n    \":surfing_man:\": \"\ud83c\udfc4\u200d\u2642\",\n    \":surfing_woman:\": \"\ud83c\udfc4\u200d\u2640\",\n    \":suriname:\": \"\ud83c\uddf8\u200d\ud83c\uddf7\",\n    \":sushi:\": \"\ud83c\udf63\",\n    \":suspension_railway:\": \"\ud83d\ude9f\",\n    \":svalbard_jan_mayen:\": \"\ud83c\uddf8\u200d\ud83c\uddef\",\n    \":swan:\": \"\ud83e\udda2\",\n    \":swaziland:\": \"\ud83c\uddf8\u200d\ud83c\uddff\",\n    \":sweat:\": \"\ud83d\ude13\",\n    \":sweat_drops:\": \"\ud83d\udca6\",\n    \":sweat_smile:\": \"\ud83d\ude05\",\n    \":sweden:\": \"\ud83c\uddf8\u200d\ud83c\uddea\",\n    \":sweet_potato:\": \"\ud83c\udf60\",\n    \":swim_brief:\": \"\ud83e\ude72\",\n    \":swimmer:\": \"\ud83c\udfca\",\n    \":swimming_man:\": \"\ud83c\udfca\u200d\u2642\",\n    \":swimming_woman:\": \"\ud83c\udfca\u200d\u2640\",\n    \":switzerland:\": \"\ud83c\udde8\u200d\ud83c\udded\",\n    \":symbols:\": \"\ud83d\udd23\",\n    \":synagogue:\": \"\ud83d\udd4d\",\n    \":syria:\": \"\ud83c\uddf8\u200d\ud83c\uddfe\",\n    \":syringe:\": \"\ud83d\udc89\",\n    \":t-rex:\": \"\ud83e\udd96\",\n    \":taco:\": \"\ud83c\udf2e\",\n    \":tada:\": \"\ud83c\udf89\",\n    \":taiwan:\": \"\ud83c\uddf9\u200d\ud83c\uddfc\",\n    \":tajikistan:\": \"\ud83c\uddf9\u200d\ud83c\uddef\",\n    \":takeout_box:\": \"\ud83e\udd61\",\n    \":tanabata_tree:\": \"\ud83c\udf8b\",\n    \":tangerine:\": \"\ud83c\udf4a\",\n    \":tanzania:\": \"\ud83c\uddf9\u200d\ud83c\uddff\",\n    \":taurus:\": \"\u2649\",\n    \":taxi:\": \"\ud83d\ude95\",\n    \":tea:\": \"\ud83c\udf75\",\n    \":teacher:\": \"\ud83e\uddd1\u200d\ud83c\udfeb\",\n    \":technologist:\": \"\ud83e\uddd1\u200d\ud83d\udcbb\",\n    \":teddy_bear:\": \"\ud83e\uddf8\",\n    \":telephone:\": \"\u260e\",\n    \":telephone_receiver:\": \"\ud83d\udcde\",\n    \":telescope:\": \"\ud83d\udd2d\",\n    \":tennis:\": \"\ud83c\udfbe\",\n    \":tent:\": \"\u26fa\",\n    \":test_tube:\": \"\ud83e\uddea\",\n    \":thailand:\": \"\ud83c\uddf9\u200d\ud83c\udded\",\n    \":thermometer:\": \"\ud83c\udf21\",\n    \":thinking:\": \"\ud83e\udd14\",\n    \":thought_balloon:\": \"\ud83d\udcad\",\n    \":thread:\": \"\ud83e\uddf5\",\n    \":three:\": \"3\u200d\u20e3\",\n    \":thumbsdown:\": \"\ud83d\udc4e\",\n    \":thumbsup:\": \"\ud83d\udc4d\",\n    \":ticket:\": \"\ud83c\udfab\",\n    \":tickets:\": \"\ud83c\udf9f\",\n    \":tiger:\": \"\ud83d\udc2f\",\n    \":tiger2:\": \"\ud83d\udc05\",\n    \":timer_clock:\": \"\u23f2\",\n    \":timor_leste:\": \"\ud83c\uddf9\u200d\ud83c\uddf1\",\n    \":tipping_hand_man:\": \"\ud83d\udc81\u200d\u2642\",\n    \":tipping_hand_person:\": \"\ud83d\udc81\",\n    \":tipping_hand_woman:\": \"\ud83d\udc81\u200d\u2640\",\n    \":tired_face:\": \"\ud83d\ude2b\",\n    \":tm:\": \"\u2122\",\n    \":togo:\": \"\ud83c\uddf9\u200d\ud83c\uddec\",\n    \":toilet:\": \"\ud83d\udebd\",\n    \":tokelau:\": \"\ud83c\uddf9\u200d\ud83c\uddf0\",\n    \":tokyo_tower:\": \"\ud83d\uddfc\",\n    \":tomato:\": \"\ud83c\udf45\",\n    \":tonga:\": \"\ud83c\uddf9\u200d\ud83c\uddf4\",\n    \":tongue:\": \"\ud83d\udc45\",\n    \":toolbox:\": \"\ud83e\uddf0\",\n    \":tooth:\": \"\ud83e\uddb7\",\n    \":top:\": \"\ud83d\udd1d\",\n    \":tophat:\": \"\ud83c\udfa9\",\n    \":tornado:\": \"\ud83c\udf2a\",\n    \":tr:\": \"\ud83c\uddf9\u200d\ud83c\uddf7\",\n    \":trackball:\": \"\ud83d\uddb2\",\n    \":tractor:\": \"\ud83d\ude9c\",\n    \":traffic_light:\": \"\ud83d\udea5\",\n    \":train:\": \"\ud83d\ude8b\",\n    \":train2:\": \"\ud83d\ude86\",\n    \":tram:\": \"\ud83d\ude8a\",\n    \":triangular_flag_on_post:\": \"\ud83d\udea9\",\n    \":triangular_ruler:\": \"\ud83d\udcd0\",\n    \":trident:\": \"\ud83d\udd31\",\n    \":trinidad_tobago:\": \"\ud83c\uddf9\u200d\ud83c\uddf9\",\n    \":tristan_da_cunha:\": \"\ud83c\uddf9\u200d\ud83c\udde6\",\n    \":triumph:\": \"\ud83d\ude24\",\n    \":trolleybus:\": \"\ud83d\ude8e\",\n    \":trophy:\": \"\ud83c\udfc6\",\n    \":tropical_drink:\": \"\ud83c\udf79\",\n    \":tropical_fish:\": \"\ud83d\udc20\",\n    \":truck:\": \"\ud83d\ude9a\",\n    \":trumpet:\": \"\ud83c\udfba\",\n    \":tshirt:\": \"\ud83d\udc55\",\n    \":tulip:\": \"\ud83c\udf37\",\n    \":tumbler_glass:\": \"\ud83e\udd43\",\n    \":tunisia:\": \"\ud83c\uddf9\u200d\ud83c\uddf3\",\n    \":turkey:\": \"\ud83e\udd83\",\n    \":turkmenistan:\": \"\ud83c\uddf9\u200d\ud83c\uddf2\",\n    \":turks_caicos_islands:\": \"\ud83c\uddf9\u200d\ud83c\udde8\",\n    \":turtle:\": \"\ud83d\udc22\",\n    \":tuvalu:\": \"\ud83c\uddf9\u200d\ud83c\uddfb\",\n    \":tv:\": \"\ud83d\udcfa\",\n    \":twisted_rightwards_arrows:\": \"\ud83d\udd00\",\n    \":two:\": \"2\u200d\u20e3\",\n    \":two_hearts:\": \"\ud83d\udc95\",\n    \":two_men_holding_hands:\": \"\ud83d\udc6c\",\n    \":two_women_holding_hands:\": \"\ud83d\udc6d\",\n    \":u5272:\": \"\ud83c\ude39\",\n    \":u5408:\": \"\ud83c\ude34\",\n    \":u55b6:\": \"\ud83c\ude3a\",\n    \":u6307:\": \"\ud83c\ude2f\",\n    \":u6708:\": \"\ud83c\ude37\",\n    \":u6709:\": \"\ud83c\ude36\",\n    \":u6e80:\": \"\ud83c\ude35\",\n    \":u7121:\": \"\ud83c\ude1a\",\n    \":u7533:\": \"\ud83c\ude38\",\n    \":u7981:\": \"\ud83c\ude32\",\n    \":u7a7a:\": \"\ud83c\ude33\",\n    \":uganda:\": \"\ud83c\uddfa\u200d\ud83c\uddec\",\n    \":uk:\": \"\ud83c\uddec\u200d\ud83c\udde7\",\n    \":ukraine:\": \"\ud83c\uddfa\u200d\ud83c\udde6\",\n    \":umbrella:\": \"\u2614\",\n    \":unamused:\": \"\ud83d\ude12\",\n    \":underage:\": \"\ud83d\udd1e\",\n    \":unicorn:\": \"\ud83e\udd84\",\n    \":united_arab_emirates:\": \"\ud83c\udde6\u200d\ud83c\uddea\",\n    \":united_nations:\": \"\ud83c\uddfa\u200d\ud83c\uddf3\",\n    \":unlock:\": \"\ud83d\udd13\",\n    \":up:\": \"\ud83c\udd99\",\n    \":upside_down_face:\": \"\ud83d\ude43\",\n    \":uruguay:\": \"\ud83c\uddfa\u200d\ud83c\uddfe\",\n    \":us:\": \"\ud83c\uddfa\u200d\ud83c\uddf8\",\n    \":us_outlying_islands:\": \"\ud83c\uddfa\u200d\ud83c\uddf2\",\n    \":us_virgin_islands:\": \"\ud83c\uddfb\u200d\ud83c\uddee\",\n    \":uzbekistan:\": \"\ud83c\uddfa\u200d\ud83c\uddff\",\n    \":v:\": \"\u270c\",\n    \":vampire:\": \"\ud83e\udddb\",\n    \":vampire_man:\": \"\ud83e\udddb\u200d\u2642\",\n    \":vampire_woman:\": \"\ud83e\udddb\u200d\u2640\",\n    \":vanuatu:\": \"\ud83c\uddfb\u200d\ud83c\uddfa\",\n    \":vatican_city:\": \"\ud83c\uddfb\u200d\ud83c\udde6\",\n    \":venezuela:\": \"\ud83c\uddfb\u200d\ud83c\uddea\",\n    \":vertical_traffic_light:\": \"\ud83d\udea6\",\n    \":vhs:\": \"\ud83d\udcfc\",\n    \":vibration_mode:\": \"\ud83d\udcf3\",\n    \":video_camera:\": \"\ud83d\udcf9\",\n    \":video_game:\": \"\ud83c\udfae\",\n    \":vietnam:\": \"\ud83c\uddfb\u200d\ud83c\uddf3\",\n    \":violin:\": \"\ud83c\udfbb\",\n    \":virgo:\": \"\u264d\",\n    \":volcano:\": \"\ud83c\udf0b\",\n    \":volleyball:\": \"\ud83c\udfd0\",\n    \":vomiting_face:\": \"\ud83e\udd2e\",\n    \":vs:\": \"\ud83c\udd9a\",\n    \":vulcan_salute:\": \"\ud83d\udd96\",\n    \":waffle:\": \"\ud83e\uddc7\",\n    \":wales:\": \"\ud83c\udff4\u200d\udb40\udc67\u200d\udb40\udc62\u200d\udb40\udc77\u200d\udb40\udc6c\u200d\udb40\udc73\u200d\udb40\udc7f\",\n    \":walking:\": \"\ud83d\udeb6\",\n    \":walking_man:\": \"\ud83d\udeb6\u200d\u2642\",\n    \":walking_woman:\": \"\ud83d\udeb6\u200d\u2640\",\n    \":wallis_futuna:\": \"\ud83c\uddfc\u200d\ud83c\uddeb\",\n    \":waning_crescent_moon:\": \"\ud83c\udf18\",\n    \":waning_gibbous_moon:\": \"\ud83c\udf16\",\n    \":warning:\": \"\u26a0\",\n    \":wastebasket:\": \"\ud83d\uddd1\",\n    \":watch:\": \"\u231a\",\n    \":water_buffalo:\": \"\ud83d\udc03\",\n    \":water_polo:\": \"\ud83e\udd3d\",\n    \":watermelon:\": \"\ud83c\udf49\",\n    \":wave:\": \"\ud83d\udc4b\",\n    \":wavy_dash:\": \"\u3030\",\n    \":waxing_crescent_moon:\": \"\ud83c\udf12\",\n    \":waxing_gibbous_moon:\": \"\ud83c\udf14\",\n    \":wc:\": \"\ud83d\udebe\",\n    \":weary:\": \"\ud83d\ude29\",\n    \":wedding:\": \"\ud83d\udc92\",\n    \":weight_lifting:\": \"\ud83c\udfcb\",\n    \":weight_lifting_man:\": \"\ud83c\udfcb\u200d\u2642\",\n    \":weight_lifting_woman:\": \"\ud83c\udfcb\u200d\u2640\",\n    \":western_sahara:\": \"\ud83c\uddea\u200d\ud83c\udded\",\n    \":whale:\": \"\ud83d\udc33\",\n    \":whale2:\": \"\ud83d\udc0b\",\n    \":wheel_of_dharma:\": \"\u2638\",\n    \":wheelchair:\": \"\u267f\",\n    \":white_check_mark:\": \"\u2705\",\n    \":white_circle:\": \"\u26aa\",\n    \":white_flag:\": \"\ud83c\udff3\",\n    \":white_flower:\": \"\ud83d\udcae\",\n    \":white_haired_man:\": \"\ud83d\udc68\u200d\ud83e\uddb3\",\n    \":white_haired_woman:\": \"\ud83d\udc69\u200d\ud83e\uddb3\",\n    \":white_heart:\": \"\ud83e\udd0d\",\n    \":white_large_square:\": \"\u2b1c\",\n    \":white_medium_small_square:\": \"\u25fd\",\n    \":white_medium_square:\": \"\u25fb\",\n    \":white_small_square:\": \"\u25ab\",\n    \":white_square_button:\": \"\ud83d\udd33\",\n    \":wilted_flower:\": \"\ud83e\udd40\",\n    \":wind_chime:\": \"\ud83c\udf90\",\n    \":wind_face:\": \"\ud83c\udf2c\",\n    \":wine_glass:\": \"\ud83c\udf77\",\n    \":wink:\": \"\ud83d\ude09\",\n    \":wolf:\": \"\ud83d\udc3a\",\n    \":woman:\": \"\ud83d\udc69\",\n    \":woman_artist:\": \"\ud83d\udc69\u200d\ud83c\udfa8\",\n    \":woman_astronaut:\": \"\ud83d\udc69\u200d\ud83d\ude80\",\n    \":woman_cartwheeling:\": \"\ud83e\udd38\u200d\u2640\",\n    \":woman_cook:\": \"\ud83d\udc69\u200d\ud83c\udf73\",\n    \":woman_dancing:\": \"\ud83d\udc83\",\n    \":woman_facepalming:\": \"\ud83e\udd26\u200d\u2640\",\n    \":woman_factory_worker:\": \"\ud83d\udc69\u200d\ud83c\udfed\",\n    \":woman_farmer:\": \"\ud83d\udc69\u200d\ud83c\udf3e\",\n    \":woman_firefighter:\": \"\ud83d\udc69\u200d\ud83d\ude92\",\n    \":woman_health_worker:\": \"\ud83d\udc69\u200d\u2695\",\n    \":woman_in_manual_wheelchair:\": \"\ud83d\udc69\u200d\ud83e\uddbd\",\n    \":woman_in_motorized_wheelchair:\": \"\ud83d\udc69\u200d\ud83e\uddbc\",\n    \":woman_judge:\": \"\ud83d\udc69\u200d\u2696\",\n    \":woman_juggling:\": \"\ud83e\udd39\u200d\u2640\",\n    \":woman_mechanic:\": \"\ud83d\udc69\u200d\ud83d\udd27\",\n    \":woman_office_worker:\": \"\ud83d\udc69\u200d\ud83d\udcbc\",\n    \":woman_pilot:\": \"\ud83d\udc69\u200d\u2708\",\n    \":woman_playing_handball:\": \"\ud83e\udd3e\u200d\u2640\",\n    \":woman_playing_water_polo:\": \"\ud83e\udd3d\u200d\u2640\",\n    \":woman_scientist:\": \"\ud83d\udc69\u200d\ud83d\udd2c\",\n    \":woman_shrugging:\": \"\ud83e\udd37\u200d\u2640\",\n    \":woman_singer:\": \"\ud83d\udc69\u200d\ud83c\udfa4\",\n    \":woman_student:\": \"\ud83d\udc69\u200d\ud83c\udf93\",\n    \":woman_teacher:\": \"\ud83d\udc69\u200d\ud83c\udfeb\",\n    \":woman_technologist:\": \"\ud83d\udc69\u200d\ud83d\udcbb\",\n    \":woman_with_headscarf:\": \"\ud83e\uddd5\",\n    \":woman_with_probing_cane:\": \"\ud83d\udc69\u200d\ud83e\uddaf\",\n    \":woman_with_turban:\": \"\ud83d\udc73\u200d\u2640\",\n    \":womans_clothes:\": \"\ud83d\udc5a\",\n    \":womans_hat:\": \"\ud83d\udc52\",\n    \":women_wrestling:\": \"\ud83e\udd3c\u200d\u2640\",\n    \":womens:\": \"\ud83d\udeba\",\n    \":woozy_face:\": \"\ud83e\udd74\",\n    \":world_map:\": \"\ud83d\uddfa\",\n    \":worried:\": \"\ud83d\ude1f\",\n    \":wrench:\": \"\ud83d\udd27\",\n    \":wrestling:\": \"\ud83e\udd3c\",\n    \":writing_hand:\": \"\u270d\",\n    \":x:\": \"\u274c\",\n    \":yarn:\": \"\ud83e\uddf6\",\n    \":yawning_face:\": \"\ud83e\udd71\",\n    \":yellow_circle:\": \"\ud83d\udfe1\",\n    \":yellow_heart:\": \"\ud83d\udc9b\",\n    \":yellow_square:\": \"\ud83d\udfe8\",\n    \":yemen:\": \"\ud83c\uddfe\u200d\ud83c\uddea\",\n    \":yen:\": \"\ud83d\udcb4\",\n    \":yin_yang:\": \"\u262f\",\n    \":yo_yo:\": \"\ud83e\ude80\",\n    \":yum:\": \"\ud83d\ude0b\",\n    \":zambia:\": \"\ud83c\uddff\u200d\ud83c\uddf2\",\n    \":zany_face:\": \"\ud83e\udd2a\",\n    \":zap:\": \"\u26a1\",\n    \":zebra:\": \"\ud83e\udd93\",\n    \":zero:\": \"0\u200d\u20e3\",\n    \":zimbabwe:\": \"\ud83c\uddff\u200d\ud83c\uddfc\",\n    \":zipper_mouth_face:\": \"\ud83e\udd10\",\n    \":zombie:\": \"\ud83e\udddf\",\n    \":zombie_man:\": \"\ud83e\udddf\u200d\u2642\",\n    \":zombie_woman:\": \"\ud83e\udddf\u200d\u2640\",\n    \":zzz:\": \"\ud83d\udca4\",\n    \":default:\": \"\u25cf\",\n    \"a\": \"a\",\n    \"b\": \"b\",\n    \"c\": \"c\",\n    \"d\": \"d\",\n    \"e\": \"e\",\n    \"f\": \"f\",\n    \"g\": \"g\",\n    \"h\": \"h\",\n    \"i\": \"i\",\n    \"j\": \"j\",\n    \"k\": \"k\",\n    \"l\": \"l\",\n    \"m\": \"m\",\n    \"n\": \"n\",\n    \"o\": \"o\",\n    \"p\": \"p\",\n    \"q\": \"q\",\n    \"r\": \"r\",\n    \"s\": \"s\",\n    \"t\": \"t\",\n    \"u\": \"u\",\n    \"v\": \"v\",\n    \"w\": \"w\",\n    \"x\": \"x\",\n    \"y\": \"y\",\n    \"z\": \"z\",\n    \"A\": \"A\",\n    \"B\": \"B\",\n    \"C\": \"C\",\n    \"D\": \"D\",\n    \"E\": \"E\",\n    \"F\": \"F\",\n    \"G\": \"G\",\n    \"H\": \"H\",\n    \"I\": \"I\",\n    \"J\": \"J\",\n    \"K\": \"K\",\n    \"L\": \"L\",\n    \"M\": \"M\",\n    \"N\": \"N\",\n    \"O\": \"O\",\n    \"P\": \"P\",\n    \"Q\": \"Q\",\n    \"R\": \"R\",\n    \"S\": \"S\",\n    \"T\": \"T\",\n    \"U\": \"U\",\n    \"V\": \"V\",\n    \"W\": \"W\",\n    \"X\": \"X\",\n    \"Y\": \"Y\",\n    \"Z\": \"Z\",\n    \"0\": \"0\",\n    \"1\": \"1\",\n    \"2\": \"2\",\n    \"3\": \"3\",\n    \"4\": \"4\",\n    \"5\": \"5\",\n    \"6\": \"6\",\n    \"7\": \"7\",\n    \"8\": \"8\",\n    \"9\": \"9\",\n}\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    import io\n    import re\n    import string\n    from pathlib import Path\n\n    import requests\n\n    from mitmproxy.tools.console.common import SYMBOL_MARK\n\n    CHAR_MARKERS = list(string.ascii_letters) + list(string.digits)\n    EMOJI_SRC = '    \":{name}:\": \"{emoji_val}\",'\n    CHAR_SRC = '    \"{name}\": \"{emoji_val}\",'\n\n    out = io.StringIO()\n\n    r = requests.get(\"https://api.github.com/emojis\")\n    for name, url in r.json().items():\n        codepoints = url.rpartition(\"/\")[2].partition(\".png\")[0].split(\"-\")\n        try:\n            emoji_val = \"\\u200d\".join(chr(int(c, 16)) for c in codepoints)\n        except ValueError:\n            continue  # some GitHub-specific emojis, e.g. \"atom\".\n        print(EMOJI_SRC.format(name=name, emoji_val=emoji_val), file=out)\n\n    # add the default marker\n    print(EMOJI_SRC.format(name=\"default\", emoji_val=SYMBOL_MARK), file=out)\n\n    for c in CHAR_MARKERS:\n        print(CHAR_SRC.format(name=c, emoji_val=c), file=out)\n\n    Path(__file__).write_text(\n        re.sub(\n            r\"(?<={\\n)[\\s\\S]*(?=}\\n)\",\n            lambda x: out.getvalue(),\n            Path(__file__).read_text(\"utf8\"),\n            1,\n        ),\n        \"utf8\",\n    )\n", "mitmproxy/utils/strutils.py": "import codecs\nimport io\nimport re\nfrom collections.abc import Iterable\nfrom typing import overload\n\n# https://mypy.readthedocs.io/en/stable/more_types.html#function-overloading\n\n\n@overload\ndef always_bytes(str_or_bytes: None, *encode_args) -> None: ...\n\n\n@overload\ndef always_bytes(str_or_bytes: str | bytes, *encode_args) -> bytes: ...\n\n\ndef always_bytes(str_or_bytes: None | str | bytes, *encode_args) -> None | bytes:\n    if str_or_bytes is None or isinstance(str_or_bytes, bytes):\n        return str_or_bytes\n    elif isinstance(str_or_bytes, str):\n        return str_or_bytes.encode(*encode_args)\n    else:\n        raise TypeError(\n            f\"Expected str or bytes, but got {type(str_or_bytes).__name__}.\"\n        )\n\n\n@overload\ndef always_str(str_or_bytes: None, *encode_args) -> None: ...\n\n\n@overload\ndef always_str(str_or_bytes: str | bytes, *encode_args) -> str: ...\n\n\ndef always_str(str_or_bytes: None | str | bytes, *decode_args) -> None | str:\n    \"\"\"\n    Returns,\n        str_or_bytes unmodified, if\n    \"\"\"\n    if str_or_bytes is None or isinstance(str_or_bytes, str):\n        return str_or_bytes\n    elif isinstance(str_or_bytes, bytes):\n        return str_or_bytes.decode(*decode_args)\n    else:\n        raise TypeError(\n            f\"Expected str or bytes, but got {type(str_or_bytes).__name__}.\"\n        )\n\n\n# Translate control characters to \"safe\" characters. This implementation\n# initially replaced them with the matching control pictures\n# (http://unicode.org/charts/PDF/U2400.pdf), but that turned out to render badly\n# with monospace fonts. We are back to \".\" therefore.\n_control_char_trans = {\n    x: ord(\".\")\n    for x in range(32)  # x + 0x2400 for unicode control group pictures\n}\n_control_char_trans[127] = ord(\".\")  # 0x2421\n_control_char_trans_newline = _control_char_trans.copy()\nfor x in (\"\\r\", \"\\n\", \"\\t\"):\n    del _control_char_trans_newline[ord(x)]\n\n_control_char_trans = str.maketrans(_control_char_trans)\n_control_char_trans_newline = str.maketrans(_control_char_trans_newline)\n\n\ndef escape_control_characters(text: str, keep_spacing=True) -> str:\n    \"\"\"\n    Replace all unicode C1 control characters from the given text with a single \".\"\n\n    Args:\n        keep_spacing: If True, tabs and newlines will not be replaced.\n    \"\"\"\n    if not isinstance(text, str):\n        raise ValueError(f\"text type must be unicode but is {type(text).__name__}\")\n\n    trans = _control_char_trans_newline if keep_spacing else _control_char_trans\n    return text.translate(trans)\n\n\ndef bytes_to_escaped_str(\n    data: bytes, keep_spacing: bool = False, escape_single_quotes: bool = False\n) -> str:\n    \"\"\"\n    Take bytes and return a safe string that can be displayed to the user.\n\n    Single quotes are always escaped, double quotes are never escaped:\n        \"'\" + bytes_to_escaped_str(...) + \"'\"\n    gives a valid Python string.\n\n    Args:\n        keep_spacing: If True, tabs and newlines will not be escaped.\n    \"\"\"\n\n    if not isinstance(data, bytes):\n        raise ValueError(f\"data must be bytes, but is {data.__class__.__name__}\")\n    # We always insert a double-quote here so that we get a single-quoted string back\n    # https://stackoverflow.com/questions/29019340/why-does-python-use-different-quotes-for-representing-strings-depending-on-their\n    ret = repr(b'\"' + data).lstrip(\"b\")[2:-1]\n    if not escape_single_quotes:\n        ret = re.sub(r\"(?<!\\\\)(\\\\\\\\)*\\\\'\", lambda m: (m.group(1) or \"\") + \"'\", ret)\n    if keep_spacing:\n        ret = re.sub(\n            r\"(?<!\\\\)(\\\\\\\\)*\\\\([nrt])\",\n            lambda m: (m.group(1) or \"\") + dict(n=\"\\n\", r=\"\\r\", t=\"\\t\")[m.group(2)],\n            ret,\n        )\n    return ret\n\n\ndef escaped_str_to_bytes(data: str) -> bytes:\n    \"\"\"\n    Take an escaped string and return the unescaped bytes equivalent.\n\n    Raises:\n        ValueError, if the escape sequence is invalid.\n    \"\"\"\n    if not isinstance(data, str):\n        raise ValueError(f\"data must be str, but is {data.__class__.__name__}\")\n\n    # This one is difficult - we use an undocumented Python API here\n    # as per http://stackoverflow.com/a/23151714/934719\n    return codecs.escape_decode(data)[0]  # type: ignore\n\n\ndef is_mostly_bin(s: bytes) -> bool:\n    if not s or len(s) == 0:\n        return False\n\n    return sum(i < 9 or 13 < i < 32 or 126 < i for i in s[:100]) / len(s[:100]) > 0.3\n\n\ndef is_xml(s: bytes) -> bool:\n    for char in s:\n        if char in (9, 10, 32):  # is space?\n            continue\n        return char == 60  # is a \"<\"?\n    return False\n\n\ndef clean_hanging_newline(t):\n    \"\"\"\n    Many editors will silently add a newline to the final line of a\n    document (I'm looking at you, Vim). This function fixes this common\n    problem at the risk of removing a hanging newline in the rare cases\n    where the user actually intends it.\n    \"\"\"\n    if t and t[-1] == \"\\n\":\n        return t[:-1]\n    return t\n\n\ndef hexdump(s):\n    \"\"\"\n    Returns:\n        A generator of (offset, hex, str) tuples\n    \"\"\"\n    for i in range(0, len(s), 16):\n        offset = f\"{i:0=10x}\"\n        part = s[i : i + 16]\n        x = \" \".join(f\"{i:0=2x}\" for i in part)\n        x = x.ljust(47)  # 16*2 + 15\n        part_repr = always_str(\n            escape_control_characters(\n                part.decode(\"ascii\", \"replace\").replace(\"\\ufffd\", \".\"), False\n            )\n        )\n        yield (offset, x, part_repr)\n\n\ndef _move_to_private_code_plane(matchobj):\n    return chr(ord(matchobj.group(0)) + 0xE000)\n\n\ndef _restore_from_private_code_plane(matchobj):\n    return chr(ord(matchobj.group(0)) - 0xE000)\n\n\nNO_ESCAPE = r\"(?<!\\\\)(?:\\\\\\\\)*\"\nMULTILINE_CONTENT = r\"[\\s\\S]*?\"\nSINGLELINE_CONTENT = r\".*?\"\nMULTILINE_CONTENT_LINE_CONTINUATION = r\"(?:.|(?<=\\\\)\\n)*?\"\n\n\ndef split_special_areas(\n    data: str,\n    area_delimiter: Iterable[str],\n):\n    \"\"\"\n    Split a string of code into a [code, special area, code, special area, ..., code] list.\n\n    For example,\n\n    >>> split_special_areas(\n    >>>     \"test /* don't modify me */ foo\",\n    >>>     [r\"/\\\\*[\\\\s\\\\S]*?\\\\*/\"])  # (regex matching comments)\n    [\"test \", \"/* don't modify me */\", \" foo\"]\n\n    \"\".join(split_special_areas(x, ...)) == x always holds true.\n    \"\"\"\n    return re.split(\"({})\".format(\"|\".join(area_delimiter)), data, flags=re.MULTILINE)\n\n\ndef escape_special_areas(\n    data: str,\n    area_delimiter: Iterable[str],\n    control_characters,\n):\n    \"\"\"\n    Escape all control characters present in special areas with UTF8 symbols\n    in the private use plane (U+E000 t+ ord(char)).\n    This is useful so that one can then use regex replacements on the resulting string without\n    interfering with special areas.\n\n    control_characters must be 0 < ord(x) < 256.\n\n    Example:\n\n    >>> print(x)\n    if (true) { console.log('{}'); }\n    >>> x = escape_special_areas(x, \"{\", [\"'\" + SINGLELINE_CONTENT + \"'\"])\n    >>> print(x)\n    if (true) { console.log('\ufffd}'); }\n    >>> x = re.sub(r\"\\\\s*{\\\\s*\", \" {\\n    \", x)\n    >>> x = unescape_special_areas(x)\n    >>> print(x)\n    if (true) {\n        console.log('{}'); }\n    \"\"\"\n    buf = io.StringIO()\n    parts = split_special_areas(data, area_delimiter)\n    rex = re.compile(rf\"[{control_characters}]\")\n    for i, x in enumerate(parts):\n        if i % 2:\n            x = rex.sub(_move_to_private_code_plane, x)\n        buf.write(x)\n    return buf.getvalue()\n\n\ndef unescape_special_areas(data: str):\n    \"\"\"\n    Invert escape_special_areas.\n\n    x == unescape_special_areas(escape_special_areas(x)) always holds true.\n    \"\"\"\n    return re.sub(r\"[\\ue000-\\ue0ff]\", _restore_from_private_code_plane, data)\n", "mitmproxy/utils/typecheck.py": "import typing\nfrom collections import abc\n\ntry:\n    from types import UnionType\nexcept ImportError:  # pragma: no cover\n    UnionType = object()  # type: ignore\n\nType = typing.Union[\n    typing.Any  # anything more elaborate really fails with mypy at the moment.\n]\n\n\ndef check_option_type(name: str, value: typing.Any, typeinfo: Type) -> None:\n    \"\"\"\n    Check if the provided value is an instance of typeinfo and raises a\n    TypeError otherwise. This function supports only those types required for\n    options.\n    \"\"\"\n    e = TypeError(f\"Expected {typeinfo} for {name}, but got {type(value)}.\")\n\n    origin = typing.get_origin(typeinfo)\n\n    if origin is typing.Union or origin is UnionType:\n        for T in typing.get_args(typeinfo):\n            try:\n                check_option_type(name, value, T)\n            except TypeError:\n                pass\n            else:\n                return\n        raise e\n    elif origin is tuple:\n        types = typing.get_args(typeinfo)\n        if not isinstance(value, (tuple, list)):\n            raise e\n        if len(types) != len(value):\n            raise e\n        for i, (x, T) in enumerate(zip(value, types)):\n            check_option_type(f\"{name}[{i}]\", x, T)\n        return\n    elif origin is abc.Sequence:\n        T = typing.get_args(typeinfo)[0]\n        if not isinstance(value, (tuple, list)):\n            raise e\n        for v in value:\n            check_option_type(name, v, T)\n    elif origin is typing.IO or typeinfo in (typing.TextIO, typing.BinaryIO):\n        if hasattr(value, \"read\"):\n            return\n        else:\n            raise e\n    elif typeinfo is typing.Any:\n        return\n    elif not isinstance(value, typeinfo):\n        if typeinfo is float and isinstance(value, int):\n            return\n        raise e\n\n\ndef typespec_to_str(typespec: typing.Any) -> str:\n    if typespec in (str, int, float, bool):\n        t = typespec.__name__\n    elif typespec == typing.Optional[str]:\n        t = \"optional str\"\n    elif typespec in (typing.Sequence[str], abc.Sequence[str]):\n        t = \"sequence of str\"\n    elif typespec == typing.Optional[int]:\n        t = \"optional int\"\n    else:\n        raise NotImplementedError\n    return t\n", "mitmproxy/utils/sliding_window.py": "import itertools\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom typing import TypeVar\n\nT = TypeVar(\"T\")\n\n\ndef window(\n    iterator: Iterable[T], behind: int = 0, ahead: int = 0\n) -> Iterator[tuple[T | None, ...]]:\n    \"\"\"\n    Sliding window for an iterator.\n\n    Example:\n        >>> for prev, i, nxt in window(range(10), 1, 1):\n        >>>     print(prev, i, nxt)\n\n        None 0 1\n        0 1 2\n        1 2 3\n        2 3 None\n    \"\"\"\n    # TODO: move into utils\n    iters: list[Iterator[T | None]] = list(itertools.tee(iterator, behind + 1 + ahead))\n    for i in range(behind):\n        iters[i] = itertools.chain((behind - i) * [None], iters[i])\n    for i in range(ahead):\n        iters[-1 - i] = itertools.islice(\n            itertools.chain(iters[-1 - i], (ahead - i) * [None]), (ahead - i), None\n        )\n    return zip(*iters)\n", "mitmproxy/utils/spec.py": "from mitmproxy import flowfilter\n\n\ndef parse_spec(option: str) -> tuple[flowfilter.TFilter, str, str]:\n    \"\"\"\n    Parse strings in the following format:\n\n        [/flow-filter]/subject/replacement\n\n    \"\"\"\n    sep, rem = option[0], option[1:]\n    parts = rem.split(sep, 2)\n    if len(parts) == 2:\n        subject, replacement = parts\n        return flowfilter.match_all, subject, replacement\n    elif len(parts) == 3:\n        patt, subject, replacement = parts\n        flow_filter = flowfilter.parse(patt)\n        return flow_filter, subject, replacement\n    else:\n        raise ValueError(\"Invalid number of parameters (2 or 3 are expected)\")\n", "mitmproxy/utils/human.py": "import datetime\nimport functools\nimport ipaddress\nimport time\n\nSIZE_UNITS = {\n    \"b\": 1024**0,\n    \"k\": 1024**1,\n    \"m\": 1024**2,\n    \"g\": 1024**3,\n    \"t\": 1024**4,\n}\n\n\ndef pretty_size(size: int) -> str:\n    \"\"\"Convert a number of bytes into a human-readable string.\n\n    len(return value) <= 5 always holds true.\n    \"\"\"\n    s: float = size  # type cast for mypy\n    if s < 1024:\n        return f\"{s}b\"\n    for suffix in [\"k\", \"m\", \"g\", \"t\"]:\n        s /= 1024\n        if s < 99.95:\n            return f\"{s:.1f}{suffix}\"\n        if s < 1024 or suffix == \"t\":\n            return f\"{s:.0f}{suffix}\"\n    raise AssertionError\n\n\n@functools.lru_cache\ndef parse_size(s: str | None) -> int | None:\n    \"\"\"\n    Parse a size with an optional k/m/... suffix.\n    Invalid values raise a ValueError. For added convenience, passing `None` returns `None`.\n    \"\"\"\n    if s is None:\n        return None\n    try:\n        return int(s)\n    except ValueError:\n        pass\n    for i in SIZE_UNITS.keys():\n        if s.endswith(i):\n            try:\n                return int(s[:-1]) * SIZE_UNITS[i]\n            except ValueError:\n                break\n    raise ValueError(\"Invalid size specification.\")\n\n\ndef pretty_duration(secs: float | None) -> str:\n    formatters = [\n        (100, \"{:.0f}s\"),\n        (10, \"{:2.1f}s\"),\n        (1, \"{:1.2f}s\"),\n    ]\n    if secs is None:\n        return \"\"\n\n    for limit, formatter in formatters:\n        if secs >= limit:\n            return formatter.format(secs)\n    # less than 1 sec\n    return f\"{secs * 1000:.0f}ms\"\n\n\ndef format_timestamp(s):\n    s = time.localtime(s)\n    d = datetime.datetime.fromtimestamp(time.mktime(s))\n    return d.strftime(\"%Y-%m-%d %H:%M:%S\")\n\n\ndef format_timestamp_with_milli(s):\n    d = datetime.datetime.fromtimestamp(s)\n    return d.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n\n\n@functools.lru_cache\ndef format_address(address: tuple | None) -> str:\n    \"\"\"\n    This function accepts IPv4/IPv6 tuples and\n    returns the formatted address string with port number\n    \"\"\"\n    if address is None:\n        return \"<no address>\"\n    try:\n        host = ipaddress.ip_address(address[0])\n        if host.is_unspecified:\n            return f\"*:{address[1]}\"\n        if isinstance(host, ipaddress.IPv4Address):\n            return f\"{str(host)}:{address[1]}\"\n        # If IPv6 is mapped to IPv4\n        elif host.ipv4_mapped:\n            return f\"{str(host.ipv4_mapped)}:{address[1]}\"\n        return f\"[{str(host)}]:{address[1]}\"\n    except ValueError:\n        return f\"{address[0]}:{address[1]}\"\n", "mitmproxy/utils/magisk.py": "import hashlib\nimport os\nfrom zipfile import ZipFile\n\nfrom cryptography import x509\nfrom cryptography.hazmat.primitives import serialization\n\nfrom mitmproxy import certs\nfrom mitmproxy import ctx\nfrom mitmproxy.options import CONF_BASENAME\n\n# The following 3 variables are for including in the magisk module as text file\nMODULE_PROP_TEXT = \"\"\"id=mitmproxycert\nname=MITMProxy cert\nversion=v1\nversionCode=1\nauthor=mitmproxy\ndescription=Adds the mitmproxy certificate to the system store\ntemplate=3\"\"\"\n\nCONFIG_SH_TEXT = \"\"\"\nMODID=mitmproxycert\nAUTOMOUNT=true\nPROPFILE=false\nPOSTFSDATA=false\nLATESTARTSERVICE=false\n\nprint_modname() {\n  ui_print \"*******************************\"\n  ui_print \"    MITMProxy cert installer   \"\n  ui_print \"*******************************\"\n}\n\nREPLACE=\"\n\"\n\nset_permissions() {\n  set_perm_recursive  $MODPATH  0  0  0755  0644\n}\n\"\"\"\n\nUPDATE_BINARY_TEXT = \"\"\"\n#!/sbin/sh\n\n#################\n# Initialization\n#################\n\numask 022\n\n# echo before loading util_functions\nui_print() { echo \"$1\"; }\n\nrequire_new_magisk() {\n  ui_print \"*******************************\"\n  ui_print \" Please install Magisk v20.4+! \"\n  ui_print \"*******************************\"\n  exit 1\n}\n\nOUTFD=$2\nZIPFILE=$3\n\nmount /data 2>/dev/null\n[ -f /data/adb/magisk/util_functions.sh ] || require_new_magisk\n. /data/adb/magisk/util_functions.sh\n[ $MAGISK_VER_CODE -lt 20400 ] && require_new_magisk\n\ninstall_module\nexit 0\n\"\"\"\n\n\ndef get_ca_from_files() -> x509.Certificate:\n    # Borrowed from tlsconfig\n    certstore_path = os.path.expanduser(ctx.options.confdir)\n    certstore = certs.CertStore.from_store(\n        path=certstore_path,\n        basename=CONF_BASENAME,\n        key_size=ctx.options.key_size,\n        passphrase=ctx.options.cert_passphrase.encode(\"utf8\")\n        if ctx.options.cert_passphrase\n        else None,\n    )\n    return certstore.default_ca._cert\n\n\ndef subject_hash_old(ca: x509.Certificate) -> str:\n    # Mimics the -subject_hash_old option of openssl used for android certificate names\n    full_hash = hashlib.md5(ca.subject.public_bytes()).digest()\n    sho = full_hash[0] | (full_hash[1] << 8) | (full_hash[2] << 16) | full_hash[3] << 24\n    return hex(sho)[2:]\n\n\ndef write_magisk_module(path: str):\n    # Makes a zip file that can be loaded by Magisk\n    # Android certs are stored as DER files\n    ca = get_ca_from_files()\n    der_cert = ca.public_bytes(serialization.Encoding.DER)\n    with ZipFile(path, \"w\") as zipp:\n        # Main cert file, name is always the old subject hash with a '.0' added\n        zipp.writestr(f\"system/etc/security/cacerts/{subject_hash_old(ca)}.0\", der_cert)\n        zipp.writestr(\"module.prop\", MODULE_PROP_TEXT)\n        zipp.writestr(\"config.sh\", CONFIG_SH_TEXT)\n        zipp.writestr(\"META-INF/com/google/android/updater-script\", \"#MAGISK\")\n        zipp.writestr(\"META-INF/com/google/android/update-binary\", UPDATE_BINARY_TEXT)\n        zipp.writestr(\n            \"common/file_contexts_image\", \"/magisk(/.*)? u:object_r:system_file:s0\"\n        )\n        zipp.writestr(\"common/post-fs-data.sh\", \"MODDIR=${0%/*}\")\n        zipp.writestr(\"common/service.sh\", \"MODDIR=${0%/*}\")\n        zipp.writestr(\"common/system.prop\", \"\")\n", "mitmproxy/utils/signals.py": "\"\"\"\nThis module provides signals, which are a simple dispatching system that allows any number of interested parties\nto subscribe to events (\"signals\").\n\nThis is similar to the Blinker library (https://pypi.org/project/blinker/), with the following changes:\n  - provides only a small subset of Blinker's functionality\n  - supports type hints\n  - supports async receivers.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport inspect\nimport weakref\nfrom collections.abc import Awaitable\nfrom collections.abc import Callable\nfrom typing import Any\nfrom typing import cast\nfrom typing import Generic\nfrom typing import ParamSpec\nfrom typing import TypeVar\n\nP = ParamSpec(\"P\")\nR = TypeVar(\"R\")\n\n\ndef make_weak_ref(obj: Any) -> weakref.ReferenceType:\n    \"\"\"\n    Like weakref.ref(), but using weakref.WeakMethod for bound methods.\n    \"\"\"\n    if hasattr(obj, \"__self__\"):\n        return cast(weakref.ref, weakref.WeakMethod(obj))\n    else:\n        return weakref.ref(obj)\n\n\n# We're running into https://github.com/python/mypy/issues/6073 here,\n# which is why the base class is a mixin and not a generic superclass.\nclass _SignalMixin:\n    def __init__(self) -> None:\n        self.receivers: list[weakref.ref[Callable]] = []\n\n    def connect(self, receiver: Callable) -> None:\n        \"\"\"\n        Register a signal receiver.\n\n        The signal will only hold a weak reference to the receiver function.\n        \"\"\"\n        receiver = make_weak_ref(receiver)\n        self.receivers.append(receiver)\n\n    def disconnect(self, receiver: Callable) -> None:\n        self.receivers = [r for r in self.receivers if r() != receiver]\n\n    def notify(self, *args, **kwargs):\n        cleanup = False\n        for ref in self.receivers:\n            r = ref()\n            if r is not None:\n                yield r(*args, **kwargs)\n            else:\n                cleanup = True\n        if cleanup:\n            self.receivers = [r for r in self.receivers if r() is not None]\n\n\nclass _SyncSignal(Generic[P], _SignalMixin):\n    def connect(self, receiver: Callable[P, None]) -> None:\n        assert not asyncio.iscoroutinefunction(receiver)\n        super().connect(receiver)\n\n    def disconnect(self, receiver: Callable[P, None]) -> None:\n        super().disconnect(receiver)\n\n    def send(self, *args: P.args, **kwargs: P.kwargs) -> None:\n        for ret in super().notify(*args, **kwargs):\n            assert ret is None or not inspect.isawaitable(ret)\n\n\nclass _AsyncSignal(Generic[P], _SignalMixin):\n    def connect(self, receiver: Callable[P, Awaitable[None] | None]) -> None:\n        super().connect(receiver)\n\n    def disconnect(self, receiver: Callable[P, Awaitable[None] | None]) -> None:\n        super().disconnect(receiver)\n\n    async def send(self, *args: P.args, **kwargs: P.kwargs) -> None:\n        await asyncio.gather(\n            *[\n                aws\n                for aws in super().notify(*args, **kwargs)\n                if aws is not None and inspect.isawaitable(aws)\n            ]\n        )\n\n\n# noinspection PyPep8Naming\ndef SyncSignal(receiver_spec: Callable[P, None]) -> _SyncSignal[P]:\n    \"\"\"\n    Create a synchronous signal with the given function signature for receivers.\n\n    Example:\n\n        s = SyncSignal(lambda event: None)  # all receivers must accept a single \"event\" argument.\n        def receiver(event):\n            print(event)\n\n        s.connect(receiver)\n        s.send(\"foo\")  # prints foo\n        s.send(event=\"bar\")  # prints bar\n\n        def receiver2():\n            ...\n\n        s.connect(receiver2)  # mypy complains about receiver2 not having the right signature\n\n        s2 = SyncSignal(lambda: None)  # this signal has no arguments\n        s2.send()\n    \"\"\"\n    return cast(_SyncSignal[P], _SyncSignal())\n\n\n# noinspection PyPep8Naming\ndef AsyncSignal(receiver_spec: Callable[P, Awaitable[None] | None]) -> _AsyncSignal[P]:\n    \"\"\"\n    Create an signal that supports both regular and async receivers:\n\n    Example:\n\n        s = AsyncSignal(lambda event: None)\n        async def receiver(event):\n            print(event)\n        s.connect(receiver)\n        await s.send(\"foo\")  # prints foo\n    \"\"\"\n    return cast(_AsyncSignal[P], _AsyncSignal())\n", "mitmproxy/utils/asyncio_utils.py": "import asyncio\nimport os\nimport sys\nimport time\nfrom collections.abc import Coroutine\nfrom collections.abc import Iterator\nfrom contextlib import contextmanager\n\nfrom mitmproxy.utils import human\n\n\ndef create_task(\n    coro: Coroutine,\n    *,\n    name: str,\n    client: tuple | None = None,\n) -> asyncio.Task:\n    \"\"\"\n    Like asyncio.create_task, but also store some debug info on the task object.\n    \"\"\"\n    t = asyncio.create_task(coro)\n    set_task_debug_info(t, name=name, client=client)\n    return t\n\n\ndef set_task_debug_info(\n    task: asyncio.Task,\n    *,\n    name: str,\n    client: tuple | None = None,\n) -> None:\n    \"\"\"Set debug info for an externally-spawned task.\"\"\"\n    task.created = time.time()  # type: ignore\n    if __debug__ is True and (test := os.environ.get(\"PYTEST_CURRENT_TEST\", None)):\n        name = f\"{name} [created in {test}]\"\n    task.set_name(name)\n    if client:\n        task.client = client  # type: ignore\n\n\ndef set_current_task_debug_info(\n    *,\n    name: str,\n    client: tuple | None = None,\n) -> None:\n    \"\"\"Set debug info for the current task.\"\"\"\n    task = asyncio.current_task()\n    assert task\n    set_task_debug_info(task, name=name, client=client)\n\n\ndef task_repr(task: asyncio.Task) -> str:\n    \"\"\"Get a task representation with debug info.\"\"\"\n    name = task.get_name()\n    a: float = getattr(task, \"created\", 0)\n    if a:\n        age = f\" (age: {time.time() - a:.0f}s)\"\n    else:\n        age = \"\"\n    client = getattr(task, \"client\", \"\")\n    if client:\n        client = f\"{human.format_address(client)}: \"\n    return f\"{client}{name}{age}\"\n\n\n@contextmanager\ndef install_exception_handler(handler) -> Iterator[None]:\n    loop = asyncio.get_running_loop()\n    existing = loop.get_exception_handler()\n    loop.set_exception_handler(handler)\n    try:\n        yield\n    finally:\n        loop.set_exception_handler(existing)\n\n\n@contextmanager\ndef set_eager_task_factory() -> Iterator[None]:\n    loop = asyncio.get_running_loop()\n    if sys.version_info < (3, 12):  # pragma: no cover\n        yield\n    else:\n        existing = loop.get_task_factory()\n        loop.set_task_factory(asyncio.eager_task_factory)  # type: ignore\n        try:\n            yield\n        finally:\n            loop.set_task_factory(existing)\n", "mitmproxy/utils/__init__.py": "", "mitmproxy/utils/arg_check.py": "import re\nimport sys\n\nDEPRECATED = \"\"\"\n--confdir\n-Z\n--body-size-limit\n--stream\n--palette\n--palette-transparent\n--follow\n--order\n--no-mouse\n--reverse\n--http2-priority\n--no-http2-priority\n--no-websocket\n--websocket\n--upstream-bind-address\n--ciphers-client\n--ciphers-server\n--client-certs\n--no-upstream-cert\n--add-upstream-certs-to-client-chain\n--upstream-trusted-confdir\n--upstream-trusted-ca\n--ssl-version-client\n--ssl-version-server\n--no-onboarding\n--onboarding-host\n--onboarding-port\n--server-replay-use-header\n--no-pop\n--replay-ignore-content\n--replay-ignore-payload-param\n--replay-ignore-param\n--replay-ignore-host\n--replace-from-file\n\"\"\"\n\nREPLACED = \"\"\"\n-t\n-u\n--wfile\n-a\n--afile\n-z\n-b\n--bind-address\n--port\n-I\n--ignore\n--tcp\n--cert\n--insecure\n-c\n--replace\n--replacements\n-i\n-f\n--filter\n--socks\n--server-replay-nopop\n\"\"\"\n\nREPLACEMENTS = {\n    \"--stream\": \"stream_large_bodies\",\n    \"--palette\": \"console_palette\",\n    \"--palette-transparent\": \"console_palette_transparent:\",\n    \"--follow\": \"console_focus_follow\",\n    \"--order\": \"view_order\",\n    \"--no-mouse\": \"console_mouse\",\n    \"--reverse\": \"view_order_reversed\",\n    \"--no-websocket\": \"websocket\",\n    \"--no-upstream-cert\": \"upstream_cert\",\n    \"--upstream-trusted-confdir\": \"ssl_verify_upstream_trusted_confdir\",\n    \"--upstream-trusted-ca\": \"ssl_verify_upstream_trusted_ca\",\n    \"--no-onboarding\": \"onboarding\",\n    \"--no-pop\": \"server_replay_reuse\",\n    \"--replay-ignore-content\": \"server_replay_ignore_content\",\n    \"--replay-ignore-payload-param\": \"server_replay_ignore_payload_params\",\n    \"--replay-ignore-param\": \"server_replay_ignore_params\",\n    \"--replay-ignore-host\": \"server_replay_ignore_host\",\n    \"--replace-from-file\": \"replacements (use @ to specify path)\",\n    \"-t\": \"--stickycookie\",\n    \"-u\": \"--stickyauth\",\n    \"--wfile\": \"--save-stream-file\",\n    \"-a\": \"-w  Prefix path with + to append.\",\n    \"--afile\": \"-w  Prefix path with + to append.\",\n    \"-z\": \"--anticomp\",\n    \"-b\": \"--listen-host\",\n    \"--bind-address\": \"--listen-host\",\n    \"--port\": \"--listen-port\",\n    \"-I\": \"--ignore-hosts\",\n    \"--ignore\": \"--ignore-hosts\",\n    \"--tcp\": \"--tcp-hosts\",\n    \"--cert\": \"--certs\",\n    \"--insecure\": \"--ssl-insecure\",\n    \"-c\": \"-C\",\n    \"--replace\": [\"--modify-body\", \"--modify-headers\"],\n    \"--replacements\": [\"--modify-body\", \"--modify-headers\"],\n    \"-i\": \"--intercept\",\n    \"-f\": \"--view-filter\",\n    \"--filter\": \"--view-filter\",\n    \"--socks\": \"--mode socks5\",\n    \"--server-replay-nopop\": \"--server-replay-reuse\",\n}\n\n\ndef check():\n    args = sys.argv[1:]\n    print()\n    if \"-U\" in args:\n        print(\"-U is deprecated, please use --mode upstream:SPEC instead\")\n\n    if \"-T\" in args:\n        print(\"-T is deprecated, please use --mode transparent instead\")\n\n    for option in (\"-e\", \"--eventlog\", \"--norefresh\"):\n        if option in args:\n            print(f\"{option} has been removed.\")\n\n    for option in (\"--nonanonymous\", \"--singleuser\", \"--htpasswd\"):\n        if option in args:\n            print(\n                \"{} is deprecated.\\n\"\n                \"Please use `--proxyauth SPEC` instead.\\n\"\n                'SPEC Format: \"username:pass\", \"any\" to accept any user/pass combination,\\n'\n                '\"@path\" to use an Apache htpasswd file, or\\n'\n                '\"ldap[s]:url_server_ldap[:port]:dn_auth:password:dn_subtree[?search_filter_key=...]\" '\n                \"for LDAP authentication.\".format(option)\n            )\n\n    for option in REPLACED.splitlines():\n        if option in args:\n            r = REPLACEMENTS.get(option)\n            if isinstance(r, list):\n                new_options = r\n            else:\n                new_options = [r]\n            print(\n                \"{} is deprecated.\\n\" \"Please use `{}` instead.\".format(\n                    option, \"` or `\".join(new_options)\n                )\n            )\n\n    for option in DEPRECATED.splitlines():\n        if option in args:\n            print(\n                \"{} is deprecated.\\n\"\n                \"Please use `--set {}=value` instead.\\n\"\n                \"To show all options and their default values use --options\".format(\n                    option,\n                    REPLACEMENTS.get(option, None)\n                    or option.lstrip(\"-\").replace(\"-\", \"_\"),\n                )\n            )\n\n    # Check for underscores in the options. Options always follow '--'.\n    for argument in args:\n        underscoreParam = re.search(r\"[-]{2}((.*?_)(.*?(\\s|$)))+\", argument)\n        if underscoreParam is not None:\n            print(\n                \"{} uses underscores, please use hyphens {}\".format(\n                    argument, argument.replace(\"_\", \"-\")\n                )\n            )\n", "mitmproxy/utils/vt_codes.py": "\"\"\"\nThis module provides a method to detect if a given file object supports virtual terminal escape codes.\n\"\"\"\n\nimport os\nimport sys\nfrom typing import IO\n\nif os.name == \"nt\":\n    from ctypes import byref  # type: ignore\n    from ctypes import windll  # type: ignore\n    from ctypes.wintypes import BOOL\n    from ctypes.wintypes import DWORD\n    from ctypes.wintypes import HANDLE\n    from ctypes.wintypes import LPDWORD\n\n    ENABLE_VIRTUAL_TERMINAL_PROCESSING = 0x0004\n    STD_OUTPUT_HANDLE = -11\n    STD_ERROR_HANDLE = -12\n\n    # https://docs.microsoft.com/de-de/windows/console/getstdhandle\n    GetStdHandle = windll.kernel32.GetStdHandle\n    GetStdHandle.argtypes = [DWORD]\n    GetStdHandle.restype = HANDLE\n\n    # https://docs.microsoft.com/de-de/windows/console/getconsolemode\n    GetConsoleMode = windll.kernel32.GetConsoleMode\n    GetConsoleMode.argtypes = [HANDLE, LPDWORD]\n    GetConsoleMode.restype = BOOL\n\n    # https://docs.microsoft.com/de-de/windows/console/setconsolemode\n    SetConsoleMode = windll.kernel32.SetConsoleMode\n    SetConsoleMode.argtypes = [HANDLE, DWORD]\n    SetConsoleMode.restype = BOOL\n\n    def ensure_supported(f: IO[str]) -> bool:\n        if not f.isatty():\n            return False\n        if f == sys.stdout:\n            h = STD_OUTPUT_HANDLE\n        elif f == sys.stderr:\n            h = STD_ERROR_HANDLE\n        else:\n            return False\n\n        handle = GetStdHandle(h)\n        console_mode = DWORD()\n        ok = GetConsoleMode(handle, byref(console_mode))\n        if not ok:\n            return False\n\n        ok = SetConsoleMode(\n            handle, console_mode.value | ENABLE_VIRTUAL_TERMINAL_PROCESSING\n        )\n        return ok\n\nelse:\n\n    def ensure_supported(f: IO[str]) -> bool:\n        return f.isatty()\n", "mitmproxy/utils/data.py": "import importlib\nimport inspect\nimport os.path\n\n\nclass Data:\n    def __init__(self, name):\n        self.name = name\n        m = importlib.import_module(name)\n        f = inspect.getsourcefile(m)\n        assert f is not None\n        dirname = os.path.dirname(f)\n        self.dirname = os.path.abspath(dirname)\n\n    def push(self, subpath):\n        \"\"\"\n        Change the data object to a path relative to the module.\n        \"\"\"\n        dirname = os.path.normpath(os.path.join(self.dirname, subpath))\n        ret = Data(self.name)\n        ret.dirname = dirname\n        return ret\n\n    def path(self, path):\n        \"\"\"\n        Returns a path to the package data housed at 'path' under this\n        module.Path can be a path to a file, or to a directory.\n\n        This function will raise ValueError if the path does not exist.\n        \"\"\"\n        fullpath = os.path.normpath(os.path.join(self.dirname, path))\n        if not os.path.exists(fullpath):\n            raise ValueError(\"dataPath: %s does not exist.\" % fullpath)\n        return fullpath\n\n\npkg_data = Data(__name__).push(\"..\")\n", "mitmproxy/utils/pyinstaller/hook-mitmproxy.addons.onboardingapp.py": "from PyInstaller.utils.hooks import collect_data_files\n\ndatas = collect_data_files(\"mitmproxy.addons.onboardingapp\")\n", "mitmproxy/utils/pyinstaller/hook-mitmproxy.tools.web.py": "from PyInstaller.utils.hooks import collect_data_files\n\ndatas = collect_data_files(\"mitmproxy.tools.web\")\n", "mitmproxy/utils/pyinstaller/hook-mitmproxy.py": "hiddenimports = [\"mitmproxy.script\"]\n", "mitmproxy/utils/pyinstaller/__init__.py": "from pathlib import Path\n\nhere = Path(__file__).parent.absolute()\n\n\ndef hook_dirs() -> list[str]:\n    return [str(here)]\n", "mitmproxy/script/__init__.py": "from .concurrent import concurrent\n\n__all__ = [\n    \"concurrent\",\n]\n", "mitmproxy/script/concurrent.py": "\"\"\"\nThis module provides a @concurrent decorator primitive to\noffload computations from mitmproxy's main master thread.\n\"\"\"\n\nimport asyncio\nimport inspect\n\nfrom mitmproxy import hooks\n\n\ndef concurrent(fn):\n    if fn.__name__ not in set(hooks.all_hooks.keys()) - {\"load\", \"configure\"}:\n        raise NotImplementedError(\n            \"Concurrent decorator not supported for '%s' method.\" % fn.__name__\n        )\n\n    async def _concurrent(*args):\n        def run():\n            if inspect.iscoroutinefunction(fn):\n                # Run the async function in a new event loop\n                loop = asyncio.new_event_loop()\n                try:\n                    loop.run_until_complete(fn(*args))\n                finally:\n                    loop.close()\n            else:\n                fn(*args)\n\n        await asyncio.get_running_loop().run_in_executor(None, run)\n\n    return _concurrent\n", "mitmproxy/platform/pf.py": "import re\nimport sys\n\n\ndef lookup(address, port, s):\n    \"\"\"\n    Parse the pfctl state output s, to look up the destination host\n    matching the client (address, port).\n\n    Returns an (address, port) tuple, or None.\n    \"\"\"\n    # We may get an ipv4-mapped ipv6 address here, e.g. ::ffff:127.0.0.1.\n    # Those still appear as \"127.0.0.1\" in the table, so we need to strip the prefix.\n    address = re.sub(r\"^::ffff:(?=\\d+.\\d+.\\d+.\\d+$)\", \"\", address)\n    s = s.decode()\n\n    # ALL tcp 192.168.1.13:57474 -> 23.205.82.58:443       ESTABLISHED:ESTABLISHED\n    specv4 = f\"{address}:{port}\"\n\n    # ALL tcp 2a01:e35:8bae:50f0:9d9b:ef0d:2de3:b733[58505] -> 2606:4700:30::681f:4ad0[443]       ESTABLISHED:ESTABLISHED\n    specv6 = f\"{address}[{port}]\"\n\n    for i in s.split(\"\\n\"):\n        if \"ESTABLISHED:ESTABLISHED\" in i and specv4 in i:\n            s = i.split()\n            if len(s) > 4:\n                if sys.platform.startswith(\"freebsd\"):\n                    # strip parentheses for FreeBSD pfctl\n                    s = s[3][1:-1].split(\":\")\n                else:\n                    s = s[4].split(\":\")\n\n                if len(s) == 2:\n                    return s[0], int(s[1])\n        elif \"ESTABLISHED:ESTABLISHED\" in i and specv6 in i:\n            s = i.split()\n            if len(s) > 4:\n                s = s[4].split(\"[\")\n                port = s[1].split(\"]\")\n                port = port[0]\n                return s[0], int(port)\n    raise RuntimeError(\"Could not resolve original destination.\")\n", "mitmproxy/platform/linux.py": "import socket\nimport struct\n\n# Python's socket module does not have these constants\nSO_ORIGINAL_DST = 80\nSOL_IPV6 = 41\n\n\ndef original_addr(csock: socket.socket) -> tuple[str, int]:\n    # Get the original destination on Linux.\n    # In theory, this can be done using the following syscalls:\n    #     sock.getsockopt(socket.SOL_IP, SO_ORIGINAL_DST, 16)\n    #     sock.getsockopt(SOL_IPV6, SO_ORIGINAL_DST, 28)\n    #\n    # In practice, it is a bit more complex:\n    #  1. We cannot rely on sock.family to decide which syscall to use because of IPv4-mapped\n    #     IPv6 addresses. If sock.family is AF_INET6 while sock.getsockname() is ::ffff:127.0.0.1,\n    #     we need to call the IPv4 version to get a result.\n    #  2. We can't just try the IPv4 syscall and then do IPv6 if that doesn't work,\n    #     because doing the wrong syscall can apparently crash the whole Python runtime.\n    # As such, we use a heuristic to check which syscall to do.\n    is_ipv4 = \".\" in csock.getsockname()[0]  # either 127.0.0.1 or ::ffff:127.0.0.1\n    if is_ipv4:\n        # the struct returned here should only have 8 bytes, but invoking sock.getsockopt\n        # with buflen=8 doesn't work.\n        dst = csock.getsockopt(socket.SOL_IP, SO_ORIGINAL_DST, 16)\n        port, raw_ip = struct.unpack_from(\"!2xH4s\", dst)\n        ip = socket.inet_ntop(socket.AF_INET, raw_ip)\n    else:\n        dst = csock.getsockopt(SOL_IPV6, SO_ORIGINAL_DST, 28)\n        port, raw_ip = struct.unpack_from(\"!2xH4x16s\", dst)\n        ip = socket.inet_ntop(socket.AF_INET6, raw_ip)\n    return ip, port\n", "mitmproxy/platform/windows.py": "from __future__ import annotations\n\nimport collections.abc\nimport contextlib\nimport ctypes.wintypes\nimport json\nimport logging\nimport os\nimport re\nimport socket\nimport socketserver\nimport threading\nimport time\nfrom collections.abc import Callable\nfrom typing import Any\nfrom typing import cast\nfrom typing import ClassVar\nfrom typing import IO\n\nimport pydivert.consts\n\nfrom mitmproxy.net.local_ip import get_local_ip\nfrom mitmproxy.net.local_ip import get_local_ip6\n\nREDIRECT_API_HOST = \"127.0.0.1\"\nREDIRECT_API_PORT = 8085\n\n\nlogger = logging.getLogger(__name__)\n\n\n##########################\n# Resolver\n\n\ndef read(rfile: IO[bytes]) -> Any:\n    x = rfile.readline().strip()\n    if not x:\n        return None\n    return json.loads(x)\n\n\ndef write(data, wfile: IO[bytes]) -> None:\n    wfile.write(json.dumps(data).encode() + b\"\\n\")\n    wfile.flush()\n\n\nclass Resolver:\n    sock: socket.socket | None\n    lock: threading.RLock\n\n    def __init__(self):\n        self.sock = None\n        self.lock = threading.RLock()\n\n    def setup(self):\n        with self.lock:\n            TransparentProxy.setup()\n            self._connect()\n\n    def _connect(self):\n        if self.sock:\n            self.sock.close()\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.connect((REDIRECT_API_HOST, REDIRECT_API_PORT))\n\n        self.wfile = self.sock.makefile(\"wb\")\n        self.rfile = self.sock.makefile(\"rb\")\n        write(os.getpid(), self.wfile)\n\n    def original_addr(self, csock: socket.socket):\n        ip, port = csock.getpeername()[:2]\n        ip = re.sub(r\"^::ffff:(?=\\d+.\\d+.\\d+.\\d+$)\", \"\", ip)\n        ip = ip.split(\"%\", 1)[0]\n        with self.lock:\n            try:\n                write((ip, port), self.wfile)\n                addr = read(self.rfile)\n                if addr is None:\n                    raise RuntimeError(\"Cannot resolve original destination.\")\n                return tuple(addr)\n            except (EOFError, OSError, AttributeError):\n                self._connect()\n                return self.original_addr(csock)\n\n\nclass APIRequestHandler(socketserver.StreamRequestHandler):\n    \"\"\"\n    TransparentProxy API: Returns the pickled server address, port tuple\n    for each received pickled client address, port tuple.\n    \"\"\"\n\n    server: APIServer\n\n    def handle(self) -> None:\n        proxifier: TransparentProxy = self.server.proxifier\n        try:\n            pid: int = read(self.rfile)\n            if pid is None:\n                return\n            with proxifier.exempt(pid):\n                while True:\n                    c = read(self.rfile)\n                    if c is None:\n                        return\n                    try:\n                        server = proxifier.client_server_map[\n                            cast(tuple[str, int], tuple(c))\n                        ]\n                    except KeyError:\n                        server = None\n                    write(server, self.wfile)\n        except (EOFError, OSError):\n            pass\n\n\nclass APIServer(socketserver.ThreadingMixIn, socketserver.TCPServer):\n    def __init__(self, proxifier, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.proxifier = proxifier\n        self.daemon_threads = True\n\n\n##########################\n# Windows API\n\n# from Windows' error.h\nERROR_INSUFFICIENT_BUFFER = 0x7A\n\nIN6_ADDR = ctypes.c_ubyte * 16\nIN4_ADDR = ctypes.c_ubyte * 4\n\n\n#\n# IPv6\n#\n\n\n# https://msdn.microsoft.com/en-us/library/windows/desktop/aa366896(v=vs.85).aspx\nclass MIB_TCP6ROW_OWNER_PID(ctypes.Structure):\n    _fields_ = [\n        (\"ucLocalAddr\", IN6_ADDR),\n        (\"dwLocalScopeId\", ctypes.wintypes.DWORD),\n        (\"dwLocalPort\", ctypes.wintypes.DWORD),\n        (\"ucRemoteAddr\", IN6_ADDR),\n        (\"dwRemoteScopeId\", ctypes.wintypes.DWORD),\n        (\"dwRemotePort\", ctypes.wintypes.DWORD),\n        (\"dwState\", ctypes.wintypes.DWORD),\n        (\"dwOwningPid\", ctypes.wintypes.DWORD),\n    ]\n\n\n# https://msdn.microsoft.com/en-us/library/windows/desktop/aa366905(v=vs.85).aspx\ndef MIB_TCP6TABLE_OWNER_PID(size):\n    class _MIB_TCP6TABLE_OWNER_PID(ctypes.Structure):\n        _fields_ = [\n            (\"dwNumEntries\", ctypes.wintypes.DWORD),\n            (\"table\", MIB_TCP6ROW_OWNER_PID * size),\n        ]\n\n    return _MIB_TCP6TABLE_OWNER_PID()\n\n\n#\n# IPv4\n#\n\n\n# https://msdn.microsoft.com/en-us/library/windows/desktop/aa366913(v=vs.85).aspx\nclass MIB_TCPROW_OWNER_PID(ctypes.Structure):\n    _fields_ = [\n        (\"dwState\", ctypes.wintypes.DWORD),\n        (\"ucLocalAddr\", IN4_ADDR),\n        (\"dwLocalPort\", ctypes.wintypes.DWORD),\n        (\"ucRemoteAddr\", IN4_ADDR),\n        (\"dwRemotePort\", ctypes.wintypes.DWORD),\n        (\"dwOwningPid\", ctypes.wintypes.DWORD),\n    ]\n\n\n# https://msdn.microsoft.com/en-us/library/windows/desktop/aa366921(v=vs.85).aspx\ndef MIB_TCPTABLE_OWNER_PID(size):\n    class _MIB_TCPTABLE_OWNER_PID(ctypes.Structure):\n        _fields_ = [\n            (\"dwNumEntries\", ctypes.wintypes.DWORD),\n            (\"table\", MIB_TCPROW_OWNER_PID * size),\n        ]\n\n    return _MIB_TCPTABLE_OWNER_PID()\n\n\nTCP_TABLE_OWNER_PID_CONNECTIONS = 4\n\n\nclass TcpConnectionTable(collections.abc.Mapping):\n    DEFAULT_TABLE_SIZE = 4096\n\n    def __init__(self):\n        self._tcp = MIB_TCPTABLE_OWNER_PID(self.DEFAULT_TABLE_SIZE)\n        self._tcp_size = ctypes.wintypes.DWORD(self.DEFAULT_TABLE_SIZE)\n        self._tcp6 = MIB_TCP6TABLE_OWNER_PID(self.DEFAULT_TABLE_SIZE)\n        self._tcp6_size = ctypes.wintypes.DWORD(self.DEFAULT_TABLE_SIZE)\n        self._map = {}\n\n    def __getitem__(self, item):\n        return self._map[item]\n\n    def __iter__(self):\n        return self._map.__iter__()\n\n    def __len__(self):\n        return self._map.__len__()\n\n    def refresh(self):\n        self._map = {}\n        self._refresh_ipv4()\n        self._refresh_ipv6()\n\n    def _refresh_ipv4(self):\n        ret = ctypes.windll.iphlpapi.GetExtendedTcpTable(  # type: ignore\n            ctypes.byref(self._tcp),\n            ctypes.byref(self._tcp_size),\n            False,\n            socket.AF_INET,\n            TCP_TABLE_OWNER_PID_CONNECTIONS,\n            0,\n        )\n        if ret == 0:\n            for row in self._tcp.table[: self._tcp.dwNumEntries]:\n                local_ip = socket.inet_ntop(socket.AF_INET, bytes(row.ucLocalAddr))\n                local_port = socket.htons(row.dwLocalPort)\n                self._map[(local_ip, local_port)] = row.dwOwningPid\n        elif ret == ERROR_INSUFFICIENT_BUFFER:\n            self._tcp = MIB_TCPTABLE_OWNER_PID(self._tcp_size.value)\n            # no need to update size, that's already done.\n            self._refresh_ipv4()\n        else:\n            raise RuntimeError(\n                \"[IPv4] Unknown GetExtendedTcpTable return code: %s\" % ret\n            )\n\n    def _refresh_ipv6(self):\n        ret = ctypes.windll.iphlpapi.GetExtendedTcpTable(  # type: ignore\n            ctypes.byref(self._tcp6),\n            ctypes.byref(self._tcp6_size),\n            False,\n            socket.AF_INET6,\n            TCP_TABLE_OWNER_PID_CONNECTIONS,\n            0,\n        )\n        if ret == 0:\n            for row in self._tcp6.table[: self._tcp6.dwNumEntries]:\n                local_ip = socket.inet_ntop(socket.AF_INET6, bytes(row.ucLocalAddr))\n                local_port = socket.htons(row.dwLocalPort)\n                self._map[(local_ip, local_port)] = row.dwOwningPid\n        elif ret == ERROR_INSUFFICIENT_BUFFER:\n            self._tcp6 = MIB_TCP6TABLE_OWNER_PID(self._tcp6_size.value)\n            # no need to update size, that's already done.\n            self._refresh_ipv6()\n        else:\n            raise RuntimeError(\n                \"[IPv6] Unknown GetExtendedTcpTable return code: %s\" % ret\n            )\n\n\nclass Redirect(threading.Thread):\n    daemon = True\n    windivert: pydivert.WinDivert\n\n    def __init__(\n        self,\n        handle: Callable[[pydivert.Packet], None],\n        filter: str,\n        layer: pydivert.Layer = pydivert.Layer.NETWORK,\n        flags: pydivert.Flag = 0,\n    ) -> None:\n        self.handle = handle\n        self.windivert = pydivert.WinDivert(filter, layer, flags=flags)\n        super().__init__()\n\n    def start(self):\n        self.windivert.open()\n        super().start()\n\n    def run(self):\n        while True:\n            try:\n                packet = self.windivert.recv()\n            except OSError as e:\n                if getattr(e, \"winerror\", None) == 995:\n                    return\n                else:\n                    raise\n            else:\n                self.handle(packet)\n\n    def shutdown(self):\n        self.windivert.close()\n\n    def recv(self) -> pydivert.Packet | None:\n        \"\"\"\n        Convenience function that receives a packet from the passed handler and handles error codes.\n        If the process has been shut down, None is returned.\n        \"\"\"\n        try:\n            return self.windivert.recv()\n        except OSError as e:\n            if e.winerror == 995:  # type: ignore\n                return None\n            else:\n                raise\n\n\nclass RedirectLocal(Redirect):\n    trusted_pids: set[int]\n\n    def __init__(\n        self, redirect_request: Callable[[pydivert.Packet], None], filter: str\n    ) -> None:\n        self.tcp_connections = TcpConnectionTable()\n        self.trusted_pids = set()\n        self.redirect_request = redirect_request\n        super().__init__(self.handle, filter)\n\n    def handle(self, packet):\n        client = (packet.src_addr, packet.src_port)\n\n        if client not in self.tcp_connections:\n            self.tcp_connections.refresh()\n\n        # If this fails, we most likely have a connection from an external client.\n        # In this, case we always want to proxy the request.\n        pid = self.tcp_connections.get(client, None)\n\n        if pid not in self.trusted_pids:\n            self.redirect_request(packet)\n        else:\n            # It's not really clear why we need to recalculate the checksum here,\n            # but this was identified as necessary in https://github.com/mitmproxy/mitmproxy/pull/3174.\n            self.windivert.send(packet, recalculate_checksum=True)\n\n\nTConnection = tuple[str, int]\n\n\nclass ClientServerMap:\n    \"\"\"A thread-safe LRU dict.\"\"\"\n\n    connection_cache_size: ClassVar[int] = 65536\n\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._map = collections.OrderedDict()\n\n    def __getitem__(self, item: TConnection) -> TConnection:\n        with self._lock:\n            return self._map[item]\n\n    def __setitem__(self, key: TConnection, value: TConnection) -> None:\n        with self._lock:\n            self._map[key] = value\n            self._map.move_to_end(key)\n            while len(self._map) > self.connection_cache_size:\n                self._map.popitem(False)\n\n\nclass TransparentProxy:\n    \"\"\"\n    Transparent Windows Proxy for mitmproxy based on WinDivert/PyDivert. This module can be used to\n    redirect both traffic that is forwarded by the host and traffic originating from the host itself.\n\n    Requires elevated (admin) privileges. Can be started separately by manually running the file.\n\n    How it works:\n\n    (1) First, we intercept all packages that match our filter.\n    We both consider traffic that is forwarded by the OS (WinDivert's NETWORK_FORWARD layer) as well\n    as traffic sent from the local machine (WinDivert's NETWORK layer). In the case of traffic from\n    the local machine, we need to exempt packets sent from the proxy to not create a redirect loop.\n    To accomplish this, we use Windows' GetExtendedTcpTable syscall and determine the source\n    application's PID.\n\n    For each intercepted package, we\n        1. Store the source -> destination mapping (address and port)\n        2. Remove the package from the network (by not reinjecting it).\n        3. Re-inject the package into the local network stack, but with the destination address\n           changed to the proxy.\n\n    (2) Next, the proxy receives the forwarded packet, but does not know the real destination yet\n    (which we overwrote with the proxy's address). On Linux, we would now call\n    getsockopt(SO_ORIGINAL_DST). We now access the redirect module's API (see APIRequestHandler),\n    submit the source information and get the actual destination back (which we stored in 1.1).\n\n    (3) The proxy now establishes the upstream connection as usual.\n\n    (4) Finally, the proxy sends the response back to the client. To make it work, we need to change\n    the packet's source address back to the original destination (using the mapping from 1.1),\n    to which the client believes it is talking to.\n\n    Limitations:\n\n    - We assume that ephemeral TCP ports are not re-used for multiple connections at the same time.\n    The proxy will fail if an application connects to example.com and example.org from\n    192.168.0.42:4242 simultaneously. This could be mitigated by introducing unique \"meta-addresses\"\n    which mitmproxy sees, but this would remove the correct client info from mitmproxy.\n    \"\"\"\n\n    local: RedirectLocal | None = None\n    # really weird linting error here.\n    forward: Redirect | None = None\n    response: Redirect\n    icmp: Redirect\n\n    proxy_port: int\n    filter: str\n\n    client_server_map: ClientServerMap\n\n    def __init__(\n        self,\n        local: bool = True,\n        forward: bool = True,\n        proxy_port: int = 8080,\n        filter: str | None = \"tcp.DstPort == 80 or tcp.DstPort == 443\",\n    ) -> None:\n        self.proxy_port = proxy_port\n        self.filter = (\n            filter\n            or f\"tcp.DstPort != {proxy_port} and tcp.DstPort != {REDIRECT_API_PORT} and tcp.DstPort < 49152\"\n        )\n\n        self.ipv4_address = get_local_ip()\n        self.ipv6_address = get_local_ip6()\n        # print(f\"IPv4: {self.ipv4_address}, IPv6: {self.ipv6_address}\")\n        self.client_server_map = ClientServerMap()\n\n        self.api = APIServer(\n            self, (REDIRECT_API_HOST, REDIRECT_API_PORT), APIRequestHandler\n        )\n        self.api_thread = threading.Thread(target=self.api.serve_forever)\n        self.api_thread.daemon = True\n\n        if forward:\n            self.forward = Redirect(\n                self.redirect_request, self.filter, pydivert.Layer.NETWORK_FORWARD\n            )\n        if local:\n            self.local = RedirectLocal(self.redirect_request, self.filter)\n\n        # The proxy server responds to the client. To the client,\n        # this response should look like it has been sent by the real target\n        self.response = Redirect(\n            self.redirect_response,\n            f\"outbound and tcp.SrcPort == {proxy_port}\",\n        )\n\n        # Block all ICMP requests (which are sent on Windows by default).\n        # If we don't do this, our proxy machine may send an ICMP redirect to the client,\n        # which instructs the client to directly connect to the real gateway\n        # if they are on the same network.\n        self.icmp = Redirect(lambda _: None, \"icmp\", flags=pydivert.Flag.DROP)\n\n    @classmethod\n    def setup(cls):\n        # TODO: Make sure that server can be killed cleanly. That's a bit difficult as we don't have access to\n        # controller.should_exit when this is called.\n        logger.warning(\n            \"Transparent mode on Windows is unsupported and flaky. Consider using local redirect mode or WireGuard mode instead.\"\n        )\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        server_unavailable = s.connect_ex((REDIRECT_API_HOST, REDIRECT_API_PORT))\n        if server_unavailable:\n            proxifier = TransparentProxy()\n            proxifier.start()\n\n    def start(self):\n        self.api_thread.start()\n        self.icmp.start()\n        self.response.start()\n        if self.forward:\n            self.forward.start()\n        if self.local:\n            self.local.start()\n\n    def shutdown(self):\n        if self.local:\n            self.local.shutdown()\n        if self.forward:\n            self.forward.shutdown()\n        self.response.shutdown()\n        self.icmp.shutdown()\n        self.api.shutdown()\n\n    def redirect_request(self, packet: pydivert.Packet):\n        # print(\" * Redirect client -> server to proxy\")\n        # print(f\"{packet.src_addr}:{packet.src_port} -> {packet.dst_addr}:{packet.dst_port}\")\n        client = (packet.src_addr, packet.src_port)\n\n        self.client_server_map[client] = (packet.dst_addr, packet.dst_port)\n\n        # We do need to inject to an external IP here, 127.0.0.1 does not work.\n        if packet.address_family == socket.AF_INET:\n            assert self.ipv4_address\n            packet.dst_addr = self.ipv4_address\n        elif packet.address_family == socket.AF_INET6:\n            if not self.ipv6_address:\n                self.ipv6_address = get_local_ip6(packet.src_addr)\n            assert self.ipv6_address\n            packet.dst_addr = self.ipv6_address\n        else:\n            raise RuntimeError(\"Unknown address family\")\n        packet.dst_port = self.proxy_port\n        packet.direction = pydivert.consts.Direction.INBOUND\n\n        # We need a handle on the NETWORK layer. the local handle is not guaranteed to exist,\n        # so we use the response handle.\n        self.response.windivert.send(packet)\n\n    def redirect_response(self, packet: pydivert.Packet):\n        \"\"\"\n        If the proxy responds to the client, let the client believe the target server sent the\n        packets.\n        \"\"\"\n        # print(\" * Adjust proxy -> client\")\n        client = (packet.dst_addr, packet.dst_port)\n        try:\n            packet.src_addr, packet.src_port = self.client_server_map[client]\n        except KeyError:\n            print(f\"Warning: Previously unseen connection from proxy to {client}\")\n        else:\n            packet.recalculate_checksums()\n\n        self.response.windivert.send(packet, recalculate_checksum=False)\n\n    @contextlib.contextmanager\n    def exempt(self, pid: int):\n        if self.local:\n            self.local.trusted_pids.add(pid)\n        try:\n            yield\n        finally:\n            if self.local:\n                self.local.trusted_pids.remove(pid)\n\n\nif __name__ == \"__main__\":\n    import click\n\n    @click.group()\n    def cli():\n        pass\n\n    @cli.command()\n    @click.option(\n        \"--local/--no-local\", default=True, help=\"Redirect the host's own traffic.\"\n    )\n    @click.option(\n        \"--forward/--no-forward\",\n        default=True,\n        help=\"Redirect traffic that's forwarded by the host.\",\n    )\n    @click.option(\n        \"--filter\",\n        type=str,\n        metavar=\"WINDIVERT_FILTER\",\n        help=\"Custom WinDivert interception rule.\",\n    )\n    @click.option(\n        \"-p\",\n        \"--proxy-port\",\n        type=int,\n        metavar=\"8080\",\n        default=8080,\n        help=\"The port mitmproxy is listening on.\",\n    )\n    def redirect(**options):\n        \"\"\"Redirect flows to mitmproxy.\"\"\"\n        proxy = TransparentProxy(**options)\n        proxy.start()\n        print(f\" * Redirection active.\")\n        print(f\"   Filter: {proxy.filter}\")\n        try:\n            while True:\n                time.sleep(1)\n        except KeyboardInterrupt:\n            print(\" * Shutting down...\")\n            proxy.shutdown()\n            print(\" * Shut down.\")\n\n    @cli.command()\n    def connections():\n        \"\"\"List all TCP connections and the associated PIDs.\"\"\"\n        connections = TcpConnectionTable()\n        connections.refresh()\n        for (ip, port), pid in connections.items():\n            print(f\"{ip}:{port} -> {pid}\")\n\n    cli()\n", "mitmproxy/platform/osx.py": "import subprocess\n\nfrom . import pf\n\n\"\"\"\n    Doing this the \"right\" way by using DIOCNATLOOK on the pf device turns out\n    to be a pain. Apple has made a number of modifications to the data\n    structures returned, and compiling userspace tools to test and work with\n    this turns out to be a pain in the ass. Parsing pfctl output is short,\n    simple, and works.\n\n    Note: Also Tested with FreeBSD 10 pkgng Python 2.7.x.\n    Should work almost exactly as on Mac OS X and except with some changes to\n    the output processing of pfctl (see pf.py).\n\"\"\"\n\nSTATECMD = (\"sudo\", \"-n\", \"/sbin/pfctl\", \"-s\", \"state\")\n\n\ndef original_addr(csock):\n    peer = csock.getpeername()\n    try:\n        stxt = subprocess.check_output(STATECMD, stderr=subprocess.STDOUT)\n    except subprocess.CalledProcessError as e:\n        if \"sudo: a password is required\" in e.output.decode(errors=\"replace\"):\n            insufficient_priv = True\n        else:\n            raise RuntimeError(\"Error getting pfctl state: \" + repr(e))\n    else:\n        insufficient_priv = \"sudo: a password is required\" in stxt.decode(\n            errors=\"replace\"\n        )\n\n    if insufficient_priv:\n        raise RuntimeError(\n            \"Insufficient privileges to access pfctl. \"\n            \"See https://mitmproxy.org/docs/latest/howto-transparent/#macos for details.\"\n        )\n    return pf.lookup(peer[0], peer[1], stxt)\n", "mitmproxy/platform/openbsd.py": "def original_addr(csock):\n    return csock.getsockname()\n", "mitmproxy/platform/__init__.py": "import re\nimport socket\nimport sys\nfrom collections.abc import Callable\n\n\ndef init_transparent_mode() -> None:\n    \"\"\"\n    Initialize transparent mode.\n    \"\"\"\n\n\noriginal_addr: Callable[[socket.socket], tuple[str, int]] | None\n\"\"\"\nGet the original destination for the given socket.\nThis function will be None if transparent mode is not supported.\n\"\"\"\n\nif re.match(r\"linux(?:2)?\", sys.platform):\n    from . import linux\n\n    original_addr = linux.original_addr\nelif sys.platform == \"darwin\" or sys.platform.startswith(\"freebsd\"):\n    from . import osx\n\n    original_addr = osx.original_addr\nelif sys.platform.startswith(\"openbsd\"):\n    from . import openbsd\n\n    original_addr = openbsd.original_addr\nelif sys.platform == \"win32\":\n    from . import windows\n\n    resolver = windows.Resolver()\n    init_transparent_mode = resolver.setup  # noqa\n    original_addr = resolver.original_addr\nelse:\n    original_addr = None\n\n__all__ = [\"original_addr\", \"init_transparent_mode\"]\n", "mitmproxy/test/tutils.py": "from mitmproxy import dns\nfrom mitmproxy import http\n\n\ndef tdnsreq(**kwargs) -> dns.Message:\n    \"\"\"\n    Returns:\n        mitmproxy.dns.Message\n    \"\"\"\n    default = dict(\n        timestamp=946681200,\n        id=42,\n        query=True,\n        op_code=dns.op_codes.QUERY,\n        authoritative_answer=False,\n        truncation=False,\n        recursion_desired=True,\n        recursion_available=False,\n        reserved=0,\n        response_code=dns.response_codes.NOERROR,\n        questions=[dns.Question(\"dns.google\", dns.types.A, dns.classes.IN)],\n        answers=[],\n        authorities=[],\n        additionals=[],\n    )\n    default.update(kwargs)\n    return dns.Message(**default)  # type: ignore\n\n\ndef tdnsresp(**kwargs) -> dns.Message:\n    \"\"\"\n    Returns:\n        mitmproxy.dns.Message\n    \"\"\"\n    default = dict(\n        timestamp=946681201,\n        id=42,\n        query=False,\n        op_code=dns.op_codes.QUERY,\n        authoritative_answer=False,\n        truncation=False,\n        recursion_desired=True,\n        recursion_available=True,\n        reserved=0,\n        response_code=dns.response_codes.NOERROR,\n        questions=[dns.Question(\"dns.google\", dns.types.A, dns.classes.IN)],\n        answers=[\n            dns.ResourceRecord(\n                \"dns.google\", dns.types.A, dns.classes.IN, 32, b\"\\x08\\x08\\x08\\x08\"\n            ),\n            dns.ResourceRecord(\n                \"dns.google\", dns.types.A, dns.classes.IN, 32, b\"\\x08\\x08\\x04\\x04\"\n            ),\n        ],\n        authorities=[],\n        additionals=[],\n    )\n    default.update(kwargs)\n    return dns.Message(**default)  # type: ignore\n\n\ndef treq(**kwargs) -> http.Request:\n    \"\"\"\n    Returns:\n        mitmproxy.net.http.Request\n    \"\"\"\n    default = dict(\n        host=\"address\",\n        port=22,\n        method=b\"GET\",\n        scheme=b\"http\",\n        authority=b\"\",\n        path=b\"/path\",\n        http_version=b\"HTTP/1.1\",\n        headers=http.Headers(((b\"header\", b\"qvalue\"), (b\"content-length\", b\"7\"))),\n        content=b\"content\",\n        trailers=None,\n        timestamp_start=946681200,\n        timestamp_end=946681201,\n    )\n    default.update(kwargs)\n    return http.Request(**default)  # type: ignore\n\n\ndef tresp(**kwargs) -> http.Response:\n    \"\"\"\n    Returns:\n        mitmproxy.net.http.Response\n    \"\"\"\n    default = dict(\n        http_version=b\"HTTP/1.1\",\n        status_code=200,\n        reason=b\"OK\",\n        headers=http.Headers(\n            ((b\"header-response\", b\"svalue\"), (b\"content-length\", b\"7\"))\n        ),\n        content=b\"message\",\n        trailers=None,\n        timestamp_start=946681202,\n        timestamp_end=946681203,\n    )\n    default.update(kwargs)\n    return http.Response(**default)  # type: ignore\n", "mitmproxy/test/taddons.py": "import asyncio\n\nimport mitmproxy.master\nimport mitmproxy.options\nfrom mitmproxy import command\nfrom mitmproxy import eventsequence\nfrom mitmproxy import hooks\nfrom mitmproxy.addons import core\nfrom mitmproxy.addons import script\n\n\nclass context:\n    \"\"\"\n    A context for testing addons, which sets up the mitmproxy.ctx module so\n    handlers can run as they would within mitmproxy. The context also\n    provides a number of helper methods for common testing scenarios.\n    \"\"\"\n\n    def __init__(self, *addons, options=None, loadcore=True):\n        try:\n            loop = asyncio.get_running_loop()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n\n        options = options or mitmproxy.options.Options()\n        self.master = mitmproxy.master.Master(options, event_loop=loop)\n        self.options = self.master.options\n\n        if loadcore:\n            self.master.addons.add(core.Core())\n\n        for a in addons:\n            self.master.addons.add(a)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        return False\n\n    async def cycle(self, addon, f):\n        \"\"\"\n        Cycles the flow through the events for the flow. Stops if the flow\n        is intercepted.\n        \"\"\"\n        for evt in eventsequence.iterate(f):\n            await self.master.addons.invoke_addon(addon, evt)\n            if f.intercepted:\n                return\n\n    def configure(self, addon, **kwargs):\n        \"\"\"\n        A helper for testing configure methods. Modifies the registered\n        Options object with the given keyword arguments, then calls the\n        configure method on the addon with the updated value.\n        \"\"\"\n        if addon not in self.master.addons:\n            self.master.addons.register(addon)\n        with self.options.rollback(kwargs.keys(), reraise=True):\n            if kwargs:\n                self.options.update(**kwargs)\n            else:\n                self.master.addons.invoke_addon_sync(addon, hooks.ConfigureHook(set()))\n\n    def script(self, path):\n        \"\"\"\n        Loads a script from path, and returns the enclosed addon.\n        \"\"\"\n        sc = script.Script(path, False)\n        return sc.addons[0] if sc.addons else None\n\n    def command(self, func, *args):\n        \"\"\"\n        Invoke a command function with a list of string arguments within a command context, mimicking the actual command environment.\n        \"\"\"\n        cmd = command.Command(self.master.commands, \"test.command\", func)\n        return cmd.call(args)\n", "mitmproxy/test/tflow.py": "import uuid\n\nfrom wsproto.frame_protocol import Opcode\n\nfrom mitmproxy import connection\nfrom mitmproxy import dns\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy import tcp\nfrom mitmproxy import udp\nfrom mitmproxy import websocket\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.proxy.mode_specs import ProxyMode\nfrom mitmproxy.test.tutils import tdnsreq\nfrom mitmproxy.test.tutils import tdnsresp\nfrom mitmproxy.test.tutils import treq\nfrom mitmproxy.test.tutils import tresp\n\n\ndef ttcpflow(\n    client_conn=True, server_conn=True, messages=True, err=None\n) -> tcp.TCPFlow:\n    if client_conn is True:\n        client_conn = tclient_conn()\n    if server_conn is True:\n        server_conn = tserver_conn()\n    if messages is True:\n        messages = [\n            tcp.TCPMessage(True, b\"hello\", 946681204.2),\n            tcp.TCPMessage(False, b\"it's me\", 946681204.5),\n        ]\n    if err is True:\n        err = terr()\n\n    f = tcp.TCPFlow(client_conn, server_conn)\n    f.timestamp_created = client_conn.timestamp_start\n    f.messages = messages\n    f.error = err\n    f.live = True\n    return f\n\n\ndef tudpflow(\n    client_conn=True, server_conn=True, messages=True, err=None\n) -> udp.UDPFlow:\n    if client_conn is True:\n        client_conn = tclient_conn()\n    if server_conn is True:\n        server_conn = tserver_conn()\n    if messages is True:\n        messages = [\n            udp.UDPMessage(True, b\"hello\", 946681204.2),\n            udp.UDPMessage(False, b\"it's me\", 946681204.5),\n        ]\n    if err is True:\n        err = terr()\n\n    f = udp.UDPFlow(client_conn, server_conn)\n    f.timestamp_created = client_conn.timestamp_start\n    f.messages = messages\n    f.error = err\n    f.live = True\n    return f\n\n\ndef twebsocketflow(\n    messages=True, err=None, close_code=None, close_reason=\"\"\n) -> http.HTTPFlow:\n    flow = http.HTTPFlow(tclient_conn(), tserver_conn())\n    flow.request = http.Request(\n        \"example.com\",\n        80,\n        b\"GET\",\n        b\"http\",\n        b\"example.com\",\n        b\"/ws\",\n        b\"HTTP/1.1\",\n        headers=http.Headers(\n            connection=\"upgrade\",\n            upgrade=\"websocket\",\n            sec_websocket_version=\"13\",\n            sec_websocket_key=\"1234\",\n        ),\n        content=b\"\",\n        trailers=None,\n        timestamp_start=946681200,\n        timestamp_end=946681201,\n    )\n    flow.response = http.Response(\n        b\"HTTP/1.1\",\n        101,\n        reason=b\"Switching Protocols\",\n        headers=http.Headers(\n            connection=\"upgrade\",\n            upgrade=\"websocket\",\n            sec_websocket_accept=b\"\",\n        ),\n        content=b\"\",\n        trailers=None,\n        timestamp_start=946681202,\n        timestamp_end=946681203,\n    )\n\n    flow.websocket = twebsocket()\n\n    flow.websocket.close_reason = close_reason\n\n    if close_code is not None:\n        flow.websocket.close_code = close_code\n    else:\n        if err is True:\n            # ABNORMAL_CLOSURE\n            flow.websocket.close_code = 1006\n        else:\n            # NORMAL_CLOSURE\n            flow.websocket.close_code = 1000\n\n    flow.live = True\n    return flow\n\n\ndef tdnsflow(\n    *,\n    client_conn: connection.Client | None = None,\n    server_conn: connection.Server | None = None,\n    req: dns.Message | None = None,\n    resp: bool | dns.Message = False,\n    err: bool | flow.Error = False,\n    live: bool = True,\n) -> dns.DNSFlow:\n    \"\"\"Create a DNS flow for testing.\"\"\"\n    if client_conn is None:\n        client_conn = tclient_conn()\n        client_conn.proxy_mode = ProxyMode.parse(\"dns\")\n        client_conn.transport_protocol = \"udp\"\n    if server_conn is None:\n        server_conn = tserver_conn()\n        server_conn.transport_protocol = \"udp\"\n    if req is None:\n        req = tdnsreq()\n\n    if resp is True:\n        resp = tdnsresp()\n    if err is True:\n        err = terr()\n\n    assert resp is False or isinstance(resp, dns.Message)\n    assert err is False or isinstance(err, flow.Error)\n\n    f = dns.DNSFlow(client_conn, server_conn)\n    f.timestamp_created = req.timestamp\n    f.request = req\n    f.response = resp or None\n    f.error = err or None\n    f.live = live\n    return f\n\n\ndef tflow(\n    *,\n    client_conn: connection.Client | None = None,\n    server_conn: connection.Server | None = None,\n    req: http.Request | None = None,\n    resp: bool | http.Response = False,\n    err: bool | flow.Error = False,\n    ws: bool | websocket.WebSocketData = False,\n    live: bool = True,\n) -> http.HTTPFlow:\n    \"\"\"Create a flow for testing.\"\"\"\n    if client_conn is None:\n        client_conn = tclient_conn()\n    if server_conn is None:\n        server_conn = tserver_conn()\n    if req is None:\n        req = treq()\n\n    if resp is True:\n        resp = tresp()\n    if err is True:\n        err = terr()\n    if ws is True:\n        ws = twebsocket()\n\n    assert resp is False or isinstance(resp, http.Response)\n    assert err is False or isinstance(err, flow.Error)\n    assert ws is False or isinstance(ws, websocket.WebSocketData)\n\n    f = http.HTTPFlow(client_conn, server_conn)\n    f.timestamp_created = req.timestamp_start\n    f.request = req\n    f.response = resp or None\n    f.error = err or None\n    f.websocket = ws or None\n    f.live = live\n    return f\n\n\nclass DummyFlow(flow.Flow):\n    \"\"\"A flow that is neither HTTP nor TCP.\"\"\"\n\n\ndef tdummyflow(client_conn=True, server_conn=True, err=None) -> DummyFlow:\n    if client_conn is True:\n        client_conn = tclient_conn()\n    if server_conn is True:\n        server_conn = tserver_conn()\n    if err is True:\n        err = terr()\n\n    f = DummyFlow(client_conn, server_conn)\n    f.error = err\n    f.live = True\n    return f\n\n\ndef tclient_conn() -> connection.Client:\n    c = connection.Client(\n        id=str(uuid.uuid4()),\n        peername=(\"127.0.0.1\", 22),\n        sockname=(\"\", 0),\n        mitmcert=None,\n        timestamp_start=946681200,\n        timestamp_tls_setup=946681201,\n        timestamp_end=946681206,\n        sni=\"address\",\n        cipher=\"cipher\",\n        alpn=b\"http/1.1\",\n        tls_version=\"TLSv1.2\",\n        state=ConnectionState.OPEN,\n        error=None,\n        tls=False,\n        certificate_list=[],\n        alpn_offers=[],\n        cipher_list=[],\n        proxy_mode=ProxyMode.parse(\"regular\"),\n    )\n    return c\n\n\ndef tserver_conn() -> connection.Server:\n    c = connection.Server(\n        id=str(uuid.uuid4()),\n        address=(\"address\", 22),\n        peername=(\"192.168.0.1\", 22),\n        sockname=(\"address\", 22),\n        timestamp_start=946681202,\n        timestamp_tcp_setup=946681203,\n        timestamp_tls_setup=946681204,\n        timestamp_end=946681205,\n        sni=\"address\",\n        alpn=None,\n        tls_version=\"TLSv1.2\",\n        via=None,\n        state=ConnectionState.CLOSED,\n        error=None,\n        tls=False,\n        certificate_list=[],\n        alpn_offers=[],\n        cipher=None,\n        cipher_list=[],\n    )\n    return c\n\n\ndef terr(content: str = \"error\") -> flow.Error:\n    err = flow.Error(content, 946681207)\n    return err\n\n\ndef twebsocket(messages: bool = True) -> websocket.WebSocketData:\n    ws = websocket.WebSocketData()\n\n    if messages:\n        ws.messages = [\n            websocket.WebSocketMessage(Opcode.BINARY, True, b\"hello binary\", 946681203),\n            websocket.WebSocketMessage(Opcode.TEXT, True, b\"hello text\", 946681204),\n            websocket.WebSocketMessage(Opcode.TEXT, False, b\"it's me\", 946681205),\n        ]\n    ws.close_reason = \"Close Reason\"\n    ws.close_code = 1000\n    ws.closed_by_client = False\n    ws.timestamp_end = 946681205\n\n    return ws\n\n\ndef tflows() -> list[flow.Flow]:\n    return [\n        tflow(resp=True),\n        tflow(err=True),\n        tflow(ws=True),\n        ttcpflow(),\n        ttcpflow(err=True),\n        tudpflow(),\n        tudpflow(err=True),\n        tdnsflow(resp=True),\n        tdnsflow(err=True),\n    ]\n", "mitmproxy/coretypes/multidict.py": "from abc import ABCMeta\nfrom abc import abstractmethod\nfrom collections.abc import Iterator\nfrom collections.abc import MutableMapping\nfrom collections.abc import Sequence\nfrom typing import TypeVar\n\nfrom mitmproxy.coretypes import serializable\n\nKT = TypeVar(\"KT\")\nVT = TypeVar(\"VT\")\n\n\nclass _MultiDict(MutableMapping[KT, VT], metaclass=ABCMeta):\n    \"\"\"\n    A MultiDict is a dictionary-like data structure that supports multiple values per key.\n    \"\"\"\n\n    fields: tuple[tuple[KT, VT], ...]\n    \"\"\"The underlying raw datastructure.\"\"\"\n\n    def __repr__(self):\n        fields = (repr(field) for field in self.fields)\n        return \"{cls}[{fields}]\".format(\n            cls=type(self).__name__, fields=\", \".join(fields)\n        )\n\n    @staticmethod\n    @abstractmethod\n    def _reduce_values(values: Sequence[VT]) -> VT:\n        \"\"\"\n        If a user accesses multidict[\"foo\"], this method\n        reduces all values for \"foo\" to a single value that is returned.\n        For example, HTTP headers are folded, whereas we will just take\n        the first cookie we found with that name.\n        \"\"\"\n\n    @staticmethod\n    @abstractmethod\n    def _kconv(key: KT) -> KT:\n        \"\"\"\n        This method converts a key to its canonical representation.\n        For example, HTTP headers are case-insensitive, so this method returns key.lower().\n        \"\"\"\n\n    def __getitem__(self, key: KT) -> VT:\n        values = self.get_all(key)\n        if not values:\n            raise KeyError(key)\n        return self._reduce_values(values)\n\n    def __setitem__(self, key: KT, value: VT) -> None:\n        self.set_all(key, [value])\n\n    def __delitem__(self, key: KT) -> None:\n        if key not in self:\n            raise KeyError(key)\n        key = self._kconv(key)\n        self.fields = tuple(\n            field for field in self.fields if key != self._kconv(field[0])\n        )\n\n    def __iter__(self) -> Iterator[KT]:\n        seen = set()\n        for key, _ in self.fields:\n            key_kconv = self._kconv(key)\n            if key_kconv not in seen:\n                seen.add(key_kconv)\n                yield key\n\n    def __len__(self) -> int:\n        return len({self._kconv(key) for key, _ in self.fields})\n\n    def __eq__(self, other) -> bool:\n        if isinstance(other, MultiDict):\n            return self.fields == other.fields\n        return False\n\n    def get_all(self, key: KT) -> list[VT]:\n        \"\"\"\n        Return the list of all values for a given key.\n        If that key is not in the MultiDict, the return value will be an empty list.\n        \"\"\"\n        key = self._kconv(key)\n        return [value for k, value in self.fields if self._kconv(k) == key]\n\n    def set_all(self, key: KT, values: list[VT]) -> None:\n        \"\"\"\n        Remove the old values for a key and add new ones.\n        \"\"\"\n        key_kconv = self._kconv(key)\n\n        new_fields: list[tuple[KT, VT]] = []\n        for field in self.fields:\n            if self._kconv(field[0]) == key_kconv:\n                if values:\n                    new_fields.append((field[0], values.pop(0)))\n            else:\n                new_fields.append(field)\n        while values:\n            new_fields.append((key, values.pop(0)))\n        self.fields = tuple(new_fields)\n\n    def add(self, key: KT, value: VT) -> None:\n        \"\"\"\n        Add an additional value for the given key at the bottom.\n        \"\"\"\n        self.insert(len(self.fields), key, value)\n\n    def insert(self, index: int, key: KT, value: VT) -> None:\n        \"\"\"\n        Insert an additional value for the given key at the specified position.\n        \"\"\"\n        item = (key, value)\n        self.fields = self.fields[:index] + (item,) + self.fields[index:]\n\n    def keys(self, multi: bool = False):\n        \"\"\"\n        Get all keys.\n\n        If `multi` is True, one key per value will be returned.\n        If `multi` is False, duplicate keys will only be returned once.\n        \"\"\"\n        return (k for k, _ in self.items(multi))\n\n    def values(self, multi: bool = False):\n        \"\"\"\n        Get all values.\n\n        If `multi` is True, all values will be returned.\n        If `multi` is False, only the first value per key will be returned.\n        \"\"\"\n        return (v for _, v in self.items(multi))\n\n    def items(self, multi: bool = False):\n        \"\"\"\n        Get all (key, value) tuples.\n\n        If `multi` is True, all `(key, value)` pairs will be returned.\n        If False, only one tuple per key is returned.\n        \"\"\"\n        if multi:\n            return self.fields\n        else:\n            return super().items()\n\n\nclass MultiDict(_MultiDict[KT, VT], serializable.Serializable):\n    \"\"\"A concrete MultiDict, storing its own data.\"\"\"\n\n    def __init__(self, fields=()):\n        super().__init__()\n        self.fields = tuple(tuple(i) for i in fields)  # type: ignore\n\n    @staticmethod\n    def _reduce_values(values):\n        return values[0]\n\n    @staticmethod\n    def _kconv(key):\n        return key\n\n    def get_state(self):\n        return self.fields\n\n    def set_state(self, state):\n        self.fields = tuple(tuple(x) for x in state)  # type: ignore\n\n    @classmethod\n    def from_state(cls, state):\n        return cls(state)\n\n\nclass MultiDictView(_MultiDict[KT, VT]):\n    \"\"\"\n    The MultiDictView provides the MultiDict interface over calculated data.\n    The view itself contains no state - data is retrieved from the parent on\n    request, and stored back to the parent on change.\n    \"\"\"\n\n    def __init__(self, getter, setter):\n        self._getter = getter\n        self._setter = setter\n        super().__init__()\n\n    @staticmethod\n    def _kconv(key):\n        # All request-attributes are case-sensitive.\n        return key\n\n    @staticmethod\n    def _reduce_values(values):\n        # We just return the first element if\n        # multiple elements exist with the same key.\n        return values[0]\n\n    @property  # type: ignore\n    def fields(self):\n        return self._getter()\n\n    @fields.setter\n    def fields(self, value):\n        self._setter(value)\n\n    def copy(self) -> \"MultiDict[KT,VT]\":\n        return MultiDict(self.fields)\n", "mitmproxy/coretypes/bidi.py": "class BiDi:\n    \"\"\"\n    A wee utility class for keeping bi-directional mappings, like field\n    constants in protocols. Names are attributes on the object, dict-like\n    access maps values to names:\n\n    CONST = BiDi(a=1, b=2)\n    assert CONST.a == 1\n    assert CONST.get_name(1) == \"a\"\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        self.names = kwargs\n        self.values = {}\n        for k, v in kwargs.items():\n            self.values[v] = k\n        if len(self.names) != len(self.values):\n            raise ValueError(\"Duplicate values not allowed.\")\n\n    def __getattr__(self, k):\n        if k in self.names:\n            return self.names[k]\n        raise AttributeError(\"No such attribute: %s\", k)\n\n    def get_name(self, n, default=None):\n        return self.values.get(n, default)\n", "mitmproxy/coretypes/__init__.py": "", "mitmproxy/coretypes/serializable.py": "import abc\nimport collections.abc\nimport dataclasses\nimport enum\nimport typing\nimport uuid\nfrom functools import cache\nfrom typing import TypeVar\n\ntry:\n    from types import NoneType\n    from types import UnionType\nexcept ImportError:  # pragma: no cover\n\n    class UnionType:  # type: ignore\n        pass\n\n    NoneType = type(None)  # type: ignore\n\nT = TypeVar(\"T\", bound=\"Serializable\")\n\nState = typing.Any\n\n\nclass Serializable(metaclass=abc.ABCMeta):\n    \"\"\"\n    Abstract Base Class that defines an API to save an object's state and restore it later on.\n    \"\"\"\n\n    @classmethod\n    @abc.abstractmethod\n    def from_state(cls: type[T], state) -> T:\n        \"\"\"\n        Create a new object from the given state.\n        Consumes the passed state.\n        \"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def get_state(self) -> State:\n        \"\"\"\n        Retrieve object state.\n        \"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def set_state(self, state):\n        \"\"\"\n        Set object state to the given state. Consumes the passed state.\n        May return a `dataclasses.FrozenInstanceError` if the object is immutable.\n        \"\"\"\n        raise NotImplementedError()\n\n    def copy(self: T) -> T:\n        state = self.get_state()\n        if isinstance(state, dict) and \"id\" in state:\n            state[\"id\"] = str(uuid.uuid4())\n        return self.from_state(state)\n\n\nU = TypeVar(\"U\", bound=\"SerializableDataclass\")\n\n\nclass SerializableDataclass(Serializable):\n    @classmethod\n    @cache\n    def __fields(cls) -> tuple[dataclasses.Field, ...]:\n        # with from __future__ import annotations, `field.type` is a string,\n        # see https://github.com/python/cpython/issues/83623.\n        hints = typing.get_type_hints(cls)\n        fields = []\n        # noinspection PyDataclass\n        for field in dataclasses.fields(cls):  # type: ignore[arg-type]\n            if field.metadata.get(\"serialize\", True) is False:\n                continue\n            if isinstance(field.type, str):\n                field.type = hints[field.name]\n            fields.append(field)\n        return tuple(fields)\n\n    def get_state(self) -> State:\n        state = {}\n        for field in self.__fields():\n            val = getattr(self, field.name)\n            state[field.name] = _to_state(val, field.type, field.name)\n        return state\n\n    @classmethod\n    def from_state(cls: type[U], state) -> U:\n        # state = state.copy()\n        for field in cls.__fields():\n            state[field.name] = _to_val(state[field.name], field.type, field.name)\n        try:\n            return cls(**state)  # type: ignore\n        except TypeError as e:\n            raise ValueError(f\"Invalid state for {cls}: {e} ({state=})\") from e\n\n    def set_state(self, state: State) -> None:\n        for field in self.__fields():\n            current = getattr(self, field.name)\n            f_state = state.pop(field.name)\n            if isinstance(current, Serializable) and f_state is not None:\n                try:\n                    current.set_state(f_state)\n                    continue\n                except dataclasses.FrozenInstanceError:\n                    pass\n            val = _to_val(f_state, field.type, field.name)\n            try:\n                setattr(self, field.name, val)\n            except dataclasses.FrozenInstanceError:\n                state[field.name] = f_state  # restore state dict.\n                raise\n\n        if state:\n            raise ValueError(\n                f\"Unexpected fields in {type(self).__name__}.set_state: {state}\"\n            )\n\n\nV = TypeVar(\"V\")\n\n\ndef _process(attr_val: typing.Any, attr_type: type[V], attr_name: str, make: bool) -> V:\n    origin = typing.get_origin(attr_type)\n    if origin is typing.Literal:\n        if attr_val not in typing.get_args(attr_type):\n            raise ValueError(\n                f\"Invalid value for {attr_name}: {attr_val!r} does not match any literal value.\"\n            )\n        return attr_val\n    if origin in (UnionType, typing.Union):\n        attr_type, nt = typing.get_args(attr_type)\n        assert (\n            nt is NoneType\n        ), f\"{attr_name}: only `x | None` union types are supported`\"\n        if attr_val is None:\n            return None  # type: ignore\n        else:\n            return _process(attr_val, attr_type, attr_name, make)\n    else:\n        if attr_val is None:\n            raise ValueError(f\"Attribute {attr_name} must not be None.\")\n\n    if make and hasattr(attr_type, \"from_state\"):\n        return attr_type.from_state(attr_val)  # type: ignore\n    elif not make and hasattr(attr_type, \"get_state\"):\n        return attr_val.get_state()\n\n    if origin in (list, collections.abc.Sequence):\n        (T,) = typing.get_args(attr_type)\n        return [_process(x, T, attr_name, make) for x in attr_val]  # type: ignore\n    elif origin is tuple:\n        # We don't have a good way to represent tuple[str,int] | tuple[str,int,int,int], so we do a dirty hack here.\n        if attr_name in (\"peername\", \"sockname\"):\n            return tuple(\n                _process(x, T, attr_name, make)\n                for x, T in zip(attr_val, [str, int, int, int])\n            )  # type: ignore\n        Ts = typing.get_args(attr_type)\n        if len(Ts) != len(attr_val):\n            raise ValueError(\n                f\"Invalid data for {attr_name}. Expected {Ts}, got {attr_val}.\"\n            )\n        return tuple(_process(x, T, attr_name, make) for T, x in zip(Ts, attr_val))  # type: ignore\n    elif origin is dict:\n        k_cls, v_cls = typing.get_args(attr_type)\n        return {\n            _process(k, k_cls, attr_name, make): _process(v, v_cls, attr_name, make)\n            for k, v in attr_val.items()\n        }  # type: ignore\n    elif attr_type in (int, float):\n        if not isinstance(attr_val, (int, float)):\n            raise ValueError(\n                f\"Invalid value for {attr_name}. Expected {attr_type}, got {attr_val} ({type(attr_val)}).\"\n            )\n        return attr_type(attr_val)  # type: ignore\n    elif attr_type in (str, bytes, bool):\n        if not isinstance(attr_val, attr_type):\n            raise ValueError(\n                f\"Invalid value for {attr_name}. Expected {attr_type}, got {attr_val} ({type(attr_val)}).\"\n            )\n        return attr_type(attr_val)  # type: ignore\n    elif isinstance(attr_type, type) and issubclass(attr_type, enum.Enum):\n        if make:\n            return attr_type(attr_val)  # type: ignore\n        else:\n            return attr_val.value\n    else:\n        raise TypeError(f\"Unexpected type for {attr_name}: {attr_type!r}\")\n\n\ndef _to_val(state: typing.Any, attr_type: type[U], attr_name: str) -> U:\n    \"\"\"Create an object based on the state given in val.\"\"\"\n    return _process(state, attr_type, attr_name, True)\n\n\ndef _to_state(value: typing.Any, attr_type: type[U], attr_name: str) -> U:\n    \"\"\"Get the state of the object given as val.\"\"\"\n    return _process(value, attr_type, attr_name, False)\n", "mitmproxy/contentviews/javascript.py": "import io\nimport re\n\nfrom mitmproxy.contentviews import base\nfrom mitmproxy.utils import strutils\n\nDELIMITERS = \"{};\\n\"\nSPECIAL_AREAS = (\n    r\"(?<=[^\\w\\s)])\\s*/(?:[^\\n/]|(?<!\\\\)(?:\\\\\\\\)*\\\\/)+?/(?=[gimsuy]{0,6}\\s*(?:[;,).\\n]|$))\",\n    r\"'\" + strutils.MULTILINE_CONTENT_LINE_CONTINUATION + strutils.NO_ESCAPE + \"'\",\n    r'\"' + strutils.MULTILINE_CONTENT_LINE_CONTINUATION + strutils.NO_ESCAPE + '\"',\n    r\"`\" + strutils.MULTILINE_CONTENT + strutils.NO_ESCAPE + \"`\",\n    r\"/\\*\" + strutils.MULTILINE_CONTENT + r\"\\*/\",\n    r\"//\" + strutils.SINGLELINE_CONTENT + \"$\",\n    r\"for\\(\" + strutils.SINGLELINE_CONTENT + r\"\\)\",\n)\n\n\ndef beautify(data):\n    data = strutils.escape_special_areas(data, SPECIAL_AREAS, DELIMITERS)\n\n    data = re.sub(r\"\\s*{\\s*(?!};)\", \" {\\n\", data)\n    data = re.sub(r\"\\s*;\\s*\", \";\\n\", data)\n    data = re.sub(r\"(?<!{)\\s*}(;)?\\s*\", r\"\\n}\\1\\n\", data)\n\n    beautified = io.StringIO()\n    indent_level = 0\n\n    for line in data.splitlines(True):\n        if line.endswith(\"{\\n\"):\n            beautified.write(\" \" * 2 * indent_level + line)\n            indent_level += 1\n        elif line.startswith(\"}\"):\n            indent_level -= 1\n            beautified.write(\" \" * 2 * indent_level + line)\n        else:\n            beautified.write(\" \" * 2 * indent_level + line)\n\n    data = strutils.unescape_special_areas(beautified.getvalue())\n    return data\n\n\nclass ViewJavaScript(base.View):\n    name = \"JavaScript\"\n    __content_types = (\n        \"application/x-javascript\",\n        \"application/javascript\",\n        \"text/javascript\",\n    )\n\n    def __call__(self, data, **metadata):\n        data = data.decode(\"utf-8\", \"replace\")\n        res = beautify(data)\n        return \"JavaScript\", base.format_text(res)\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        return float(bool(data) and content_type in self.__content_types)\n", "mitmproxy/contentviews/wbxml.py": "from . import base\nfrom mitmproxy.contrib.wbxml import ASCommandResponse\n\n\nclass ViewWBXML(base.View):\n    name = \"WBXML\"\n    __content_types = (\"application/vnd.wap.wbxml\", \"application/vnd.ms-sync.wbxml\")\n\n    def __call__(self, data, **metadata):\n        try:\n            parser = ASCommandResponse.ASCommandResponse(data)\n            parsedContent = parser.xmlString\n            if parsedContent:\n                return \"WBXML\", base.format_text(parsedContent)\n        except Exception:\n            return None\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        return float(bool(data) and content_type in self.__content_types)\n", "mitmproxy/contentviews/raw.py": "from . import base\n\n\nclass ViewRaw(base.View):\n    name = \"Raw\"\n\n    def __call__(self, data, **metadata):\n        return \"Raw\", base.format_text(data)\n\n    def render_priority(self, data: bytes, **metadata) -> float:\n        return 0.1 * float(bool(data))\n", "mitmproxy/contentviews/multipart.py": "from .. import http\nfrom . import base\nfrom mitmproxy.coretypes import multidict\nfrom mitmproxy.net.http import multipart\n\n\nclass ViewMultipart(base.View):\n    name = \"Multipart Form\"\n\n    @staticmethod\n    def _format(v):\n        yield [(\"highlight\", \"Form data:\\n\")]\n        yield from base.format_dict(multidict.MultiDict(v))\n\n    def __call__(\n        self,\n        data: bytes,\n        content_type: str | None = None,\n        http_message: http.Message | None = None,\n        **metadata,\n    ):\n        # The content_type doesn't have the boundary, so we get it from the header again\n        headers = getattr(http_message, \"headers\", None)\n        if headers:\n            content_type = headers.get(\"content-type\")\n        if content_type is None:\n            return\n        v = multipart.decode_multipart(content_type, data)\n        if v:\n            return \"Multipart form\", self._format(v)\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        return float(bool(data) and content_type == \"multipart/form-data\")\n", "mitmproxy/contentviews/http3.py": "from collections import defaultdict\nfrom collections.abc import Iterator\nfrom dataclasses import dataclass\nfrom dataclasses import field\n\nimport pylsqpack\nfrom aioquic.buffer import Buffer\nfrom aioquic.buffer import BufferReadError\nfrom aioquic.h3.connection import parse_settings\nfrom aioquic.h3.connection import Setting\n\nfrom ..proxy.layers.http import is_h3_alpn\nfrom . import base\nfrom .hex import ViewHexDump\nfrom mitmproxy import flow\nfrom mitmproxy import tcp\n\n\n@dataclass(frozen=True)\nclass Frame:\n    \"\"\"Representation of an HTTP/3 frame.\"\"\"\n\n    type: int\n    data: bytes\n\n    def pretty(self):\n        frame_name = f\"0x{self.type:x} Frame\"\n        if self.type == 0:\n            frame_name = \"DATA Frame\"\n        elif self.type == 1:\n            try:\n                hdrs = pylsqpack.Decoder(4096, 16).feed_header(0, self.data)[1]\n                return [[(\"header\", \"HEADERS Frame\")], *base.format_pairs(hdrs)]\n            except Exception as e:\n                frame_name = f\"HEADERS Frame (error: {e})\"\n        elif self.type == 4:\n            settings = []\n            try:\n                s = parse_settings(self.data)\n            except Exception as e:\n                frame_name = f\"SETTINGS Frame (error: {e})\"\n            else:\n                for k, v in s.items():\n                    try:\n                        key = Setting(k).name\n                    except ValueError:\n                        key = f\"0x{k:x}\"\n                    settings.append((key, f\"0x{v:x}\"))\n                return [[(\"header\", \"SETTINGS Frame\")], *base.format_pairs(settings)]\n        return [\n            [(\"header\", frame_name)],\n            *ViewHexDump._format(self.data),\n        ]\n\n\n@dataclass(frozen=True)\nclass StreamType:\n    \"\"\"Representation of an HTTP/3 stream types.\"\"\"\n\n    type: int\n\n    def pretty(self):\n        stream_type = {\n            0x00: \"Control Stream\",\n            0x01: \"Push Stream\",\n            0x02: \"QPACK Encoder Stream\",\n            0x03: \"QPACK Decoder Stream\",\n        }.get(self.type, f\"0x{self.type:x} Stream\")\n        return [[(\"header\", stream_type)]]\n\n\n@dataclass\nclass ConnectionState:\n    message_count: int = 0\n    frames: dict[int, list[Frame | StreamType]] = field(default_factory=dict)\n    client_buf: bytearray = field(default_factory=bytearray)\n    server_buf: bytearray = field(default_factory=bytearray)\n\n\nclass ViewHttp3(base.View):\n    name = \"HTTP/3 Frames\"\n\n    def __init__(self) -> None:\n        self.connections: defaultdict[tcp.TCPFlow, ConnectionState] = defaultdict(\n            ConnectionState\n        )\n\n    def __call__(\n        self,\n        data,\n        flow: flow.Flow | None = None,\n        tcp_message: tcp.TCPMessage | None = None,\n        **metadata,\n    ):\n        assert isinstance(flow, tcp.TCPFlow)\n        assert tcp_message\n\n        state = self.connections[flow]\n\n        for message in flow.messages[state.message_count :]:\n            if message.from_client:\n                buf = state.client_buf\n            else:\n                buf = state.server_buf\n            buf += message.content\n\n            if state.message_count == 0 and flow.metadata[\"quic_is_unidirectional\"]:\n                h3_buf = Buffer(data=bytes(buf[:8]))\n                stream_type = h3_buf.pull_uint_var()\n                consumed = h3_buf.tell()\n                del buf[:consumed]\n                state.frames[0] = [StreamType(stream_type)]\n\n            while True:\n                h3_buf = Buffer(data=bytes(buf[:16]))\n                try:\n                    frame_type = h3_buf.pull_uint_var()\n                    frame_size = h3_buf.pull_uint_var()\n                except BufferReadError:\n                    break\n\n                consumed = h3_buf.tell()\n\n                if len(buf) < consumed + frame_size:\n                    break\n\n                frame_data = bytes(buf[consumed : consumed + frame_size])\n\n                frame = Frame(frame_type, frame_data)\n\n                state.frames.setdefault(state.message_count, []).append(frame)\n\n                del buf[: consumed + frame_size]\n\n            state.message_count += 1\n\n        frames = state.frames.get(flow.messages.index(tcp_message), [])\n        if not frames:\n            return (\n                \"HTTP/3\",\n                [],\n            )  # base.format_text(f\"(no complete frames here, {state=})\")\n        else:\n            return \"HTTP/3\", fmt_frames(frames)\n\n    def render_priority(\n        self, data: bytes, flow: flow.Flow | None = None, **metadata\n    ) -> float:\n        return (\n            2\n            * float(bool(flow and is_h3_alpn(flow.client_conn.alpn)))\n            * float(isinstance(flow, tcp.TCPFlow))\n        )\n\n\ndef fmt_frames(frames: list[Frame | StreamType]) -> Iterator[base.TViewLine]:\n    for i, frame in enumerate(frames):\n        if i > 0:\n            yield [(\"text\", \"\")]\n        yield from frame.pretty()\n", "mitmproxy/contentviews/protobuf.py": "import io\n\nfrom kaitaistruct import KaitaiStream\n\nfrom . import base\nfrom mitmproxy.contrib.kaitaistruct import google_protobuf\n\n\ndef write_buf(out, field_tag, body, indent_level):\n    if body is not None:\n        out.write(\n            \"{: <{level}}{}: {}\\n\".format(\n                \"\",\n                field_tag,\n                body if isinstance(body, int) else str(body, \"utf-8\"),\n                level=indent_level,\n            )\n        )\n    elif field_tag is not None:\n        out.write(\" \" * indent_level + str(field_tag) + \" {\\n\")\n    else:\n        out.write(\" \" * indent_level + \"}\\n\")\n\n\ndef _parse_proto(raw: bytes) -> list[google_protobuf.GoogleProtobuf.Pair]:\n    \"\"\"Parse a bytestring into protobuf pairs and make sure that all pairs have a valid wire type.\"\"\"\n    buf = google_protobuf.GoogleProtobuf(KaitaiStream(io.BytesIO(raw)))\n    for pair in buf.pairs:\n        if not isinstance(\n            pair.wire_type, google_protobuf.GoogleProtobuf.Pair.WireTypes\n        ):\n            raise ValueError(\"Not a protobuf.\")\n    return buf.pairs\n\n\ndef format_pbuf(raw):\n    out = io.StringIO()\n    stack = []\n\n    try:\n        pairs = _parse_proto(raw)\n    except Exception:\n        return False\n    stack.extend([(pair, 0) for pair in pairs[::-1]])\n\n    while len(stack):\n        pair, indent_level = stack.pop()\n\n        if pair.wire_type == pair.WireTypes.group_start:\n            body = None\n        elif pair.wire_type == pair.WireTypes.group_end:\n            body = None\n            pair._m_field_tag = None\n        elif pair.wire_type == pair.WireTypes.len_delimited:\n            body = pair.value.body\n        elif pair.wire_type == pair.WireTypes.varint:\n            body = pair.value.value\n        else:\n            body = pair.value\n\n        try:\n            pairs = _parse_proto(body)  # type: ignore\n            stack.extend([(pair, indent_level + 2) for pair in pairs[::-1]])\n            write_buf(out, pair.field_tag, None, indent_level)\n        except Exception:\n            write_buf(out, pair.field_tag, body, indent_level)\n\n        if stack:\n            prev_level = stack[-1][1]\n        else:\n            prev_level = 0\n\n        if prev_level < indent_level:\n            levels = int((indent_level - prev_level) / 2)\n            for i in range(1, levels + 1):\n                write_buf(out, None, None, indent_level - i * 2)\n\n    return out.getvalue()\n\n\nclass ViewProtobuf(base.View):\n    \"\"\"Human friendly view of protocol buffers\n    The view uses the protoc compiler to decode the binary\n    \"\"\"\n\n    name = \"Protocol Buffer\"\n    __content_types = [\n        \"application/x-protobuf\",\n        \"application/x-protobuffer\",\n    ]\n\n    def __call__(self, data, **metadata):\n        decoded = format_pbuf(data)\n        if not decoded:\n            raise ValueError(\"Failed to parse input.\")\n\n        return \"Protobuf\", base.format_text(decoded)\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        return float(bool(data) and content_type in self.__content_types)\n", "mitmproxy/contentviews/graphql.py": "import json\nfrom typing import Any\n\nfrom mitmproxy.contentviews import base\nfrom mitmproxy.contentviews.json import PARSE_ERROR\nfrom mitmproxy.contentviews.json import parse_json\n\n\ndef format_graphql(data):\n    query = data[\"query\"]\n    header_data = data.copy()\n    header_data[\"query\"] = \"...\"\n    return \"\"\"{header}\n---\n{query}\n\"\"\".format(header=json.dumps(header_data, indent=2), query=query)\n\n\ndef format_query_list(data: list[Any]):\n    num_queries = len(data) - 1\n    result = \"\"\n    for i, op in enumerate(data):\n        result += f\"--- {i}/{num_queries}\\n\"\n        result += format_graphql(op)\n    return result\n\n\ndef is_graphql_query(data):\n    return isinstance(data, dict) and \"query\" in data and \"\\n\" in data[\"query\"]\n\n\ndef is_graphql_batch_query(data):\n    return (\n        isinstance(data, list)\n        and len(data) > 0\n        and isinstance(data[0], dict)\n        and \"query\" in data[0]\n    )\n\n\nclass ViewGraphQL(base.View):\n    name = \"GraphQL\"\n\n    def __call__(self, data, **metadata):\n        data = parse_json(data)\n        if data is not PARSE_ERROR:\n            if is_graphql_query(data):\n                return \"GraphQL\", base.format_text(format_graphql(data))\n            elif is_graphql_batch_query(data):\n                return \"GraphQL\", base.format_text(format_query_list(data))\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        if content_type != \"application/json\" or not data:\n            return 0\n\n        data = parse_json(data)\n\n        if data is not PARSE_ERROR:\n            if is_graphql_query(data) or is_graphql_batch_query(data):\n                return 2\n\n        return 0\n", "mitmproxy/contentviews/auto.py": "from . import base\nfrom mitmproxy import contentviews\n\n\nclass ViewAuto(base.View):\n    name = \"Auto\"\n\n    def __call__(self, data, **metadata):\n        # TODO: The auto view has little justification now that views implement render_priority,\n        # but we keep it around for now to not touch more parts.\n        priority, view = max(\n            (v.render_priority(data, **metadata), v) for v in contentviews.views\n        )\n        if priority == 0 and not data:\n            return \"No content\", []\n        return view(data, **metadata)\n\n    def render_priority(self, data: bytes, **metadata) -> float:\n        return -1  # don't recurse.\n", "mitmproxy/contentviews/query.py": "from .. import http\nfrom . import base\n\n\nclass ViewQuery(base.View):\n    name = \"Query\"\n\n    def __call__(\n        self, data: bytes, http_message: http.Message | None = None, **metadata\n    ):\n        query = getattr(http_message, \"query\", None)\n        if query:\n            return \"Query\", base.format_pairs(query.items(multi=True))\n        else:\n            return \"Query\", base.format_text(\"\")\n\n    def render_priority(\n        self, data: bytes, *, http_message: http.Message | None = None, **metadata\n    ) -> float:\n        return 0.3 * float(bool(getattr(http_message, \"query\", False) and not data))\n", "mitmproxy/contentviews/mqtt.py": "import struct\n\nfrom mitmproxy.contentviews import base\nfrom mitmproxy.utils import strutils\n\n# from https://github.com/nikitastupin/mitmproxy-mqtt-script\n\n\nclass MQTTControlPacket:\n    # Packet types\n    (\n        CONNECT,\n        CONNACK,\n        PUBLISH,\n        PUBACK,\n        PUBREC,\n        PUBREL,\n        PUBCOMP,\n        SUBSCRIBE,\n        SUBACK,\n        UNSUBSCRIBE,\n        UNSUBACK,\n        PINGREQ,\n        PINGRESP,\n        DISCONNECT,\n    ) = range(1, 15)\n\n    # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Table_2.1_-\n    Names = [\n        \"reserved\",\n        \"CONNECT\",\n        \"CONNACK\",\n        \"PUBLISH\",\n        \"PUBACK\",\n        \"PUBREC\",\n        \"PUBREL\",\n        \"PUBCOMP\",\n        \"SUBSCRIBE\",\n        \"SUBACK\",\n        \"UNSUBSCRIBE\",\n        \"UNSUBACK\",\n        \"PINGREQ\",\n        \"PINGRESP\",\n        \"DISCONNECT\",\n        \"reserved\",\n    ]\n\n    PACKETS_WITH_IDENTIFIER = [\n        PUBACK,\n        PUBREC,\n        PUBREL,\n        PUBCOMP,\n        SUBSCRIBE,\n        SUBACK,\n        UNSUBSCRIBE,\n        UNSUBACK,\n    ]\n\n    def __init__(self, packet):\n        self._packet = packet\n        # Fixed header\n        # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718020\n        self.packet_type = self._parse_packet_type()\n        self.packet_type_human = self.Names[self.packet_type]\n        self.dup, self.qos, self.retain = self._parse_flags()\n        self.remaining_length = self._parse_remaining_length()\n        # Variable header & Payload\n        # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718024\n        # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718026\n        if self.packet_type == self.CONNECT:\n            self._parse_connect_variable_headers()\n            self._parse_connect_payload()\n        elif self.packet_type == self.PUBLISH:\n            self._parse_publish_variable_headers()\n            self._parse_publish_payload()\n        elif self.packet_type == self.SUBSCRIBE:\n            self._parse_subscribe_variable_headers()\n            self._parse_subscribe_payload()\n        elif self.packet_type == self.SUBACK:\n            pass\n        elif self.packet_type == self.UNSUBSCRIBE:\n            pass\n        else:\n            self.payload = None\n\n    def pprint(self):\n        s = f\"[{self.Names[self.packet_type]}]\"\n\n        if self.packet_type == self.CONNECT:\n            assert self.payload\n            s += f\"\"\"\n\nClient Id: {self.payload['ClientId']}\nWill Topic: {self.payload.get('WillTopic')}\nWill Message: {strutils.bytes_to_escaped_str(self.payload.get('WillMessage', b'None'))}\nUser Name: {self.payload.get('UserName')}\nPassword: {strutils.bytes_to_escaped_str(self.payload.get('Password', b'None'))}\n\"\"\"\n        elif self.packet_type == self.SUBSCRIBE:\n            s += \" sent topic filters: \"\n            s += \", \".join([f\"'{tf}'\" for tf in self.topic_filters])\n        elif self.packet_type == self.PUBLISH:\n            assert self.payload\n            topic_name = strutils.bytes_to_escaped_str(self.topic_name)\n            payload = strutils.bytes_to_escaped_str(self.payload)\n\n            s += f\" '{payload}' to topic '{topic_name}'\"\n        elif self.packet_type in [self.PINGREQ, self.PINGRESP]:\n            pass\n        else:\n            s = f\"Packet type {self.Names[self.packet_type]} is not supported yet!\"\n\n        return s\n\n    def _parse_length_prefixed_bytes(self, offset):\n        field_length_bytes = self._packet[offset : offset + 2]\n        field_length = struct.unpack(\"!H\", field_length_bytes)[0]\n\n        field_content_bytes = self._packet[offset + 2 : offset + 2 + field_length]\n\n        return field_length + 2, field_content_bytes\n\n    def _parse_publish_variable_headers(self):\n        offset = len(self._packet) - self.remaining_length\n\n        field_length, field_content_bytes = self._parse_length_prefixed_bytes(offset)\n        self.topic_name = field_content_bytes\n\n        if self.qos in [0x01, 0x02]:\n            offset += field_length\n            self.packet_identifier = self._packet[offset : offset + 2]\n\n    def _parse_publish_payload(self):\n        fixed_header_length = len(self._packet) - self.remaining_length\n        variable_header_length = 2 + len(self.topic_name)\n\n        if self.qos in [0x01, 0x02]:\n            variable_header_length += 2\n\n        offset = fixed_header_length + variable_header_length\n\n        self.payload = self._packet[offset:]\n\n    def _parse_subscribe_variable_headers(self):\n        self._parse_packet_identifier()\n\n    def _parse_subscribe_payload(self):\n        offset = len(self._packet) - self.remaining_length + 2\n\n        self.topic_filters = {}\n\n        while len(self._packet) - offset > 0:\n            field_length, topic_filter_bytes = self._parse_length_prefixed_bytes(offset)\n            offset += field_length\n\n            qos = self._packet[offset : offset + 1]\n            offset += 1\n\n            topic_filter = topic_filter_bytes.decode(\"utf-8\")\n            self.topic_filters[topic_filter] = {\"qos\": qos}\n\n    # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718030\n    def _parse_connect_variable_headers(self):\n        offset = len(self._packet) - self.remaining_length\n\n        self.variable_headers = {}\n        self.connect_flags = {}\n\n        self.variable_headers[\"ProtocolName\"] = self._packet[offset : offset + 6]\n        self.variable_headers[\"ProtocolLevel\"] = self._packet[offset + 6 : offset + 7]\n        self.variable_headers[\"ConnectFlags\"] = self._packet[offset + 7 : offset + 8]\n        self.variable_headers[\"KeepAlive\"] = self._packet[offset + 8 : offset + 10]\n        # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc385349229\n        self.connect_flags[\"CleanSession\"] = bool(\n            self.variable_headers[\"ConnectFlags\"][0] & 0x02\n        )\n        self.connect_flags[\"Will\"] = bool(\n            self.variable_headers[\"ConnectFlags\"][0] & 0x04\n        )\n        self.will_qos = (self.variable_headers[\"ConnectFlags\"][0] >> 3) & 0x03\n        self.connect_flags[\"WillRetain\"] = bool(\n            self.variable_headers[\"ConnectFlags\"][0] & 0x20\n        )\n        self.connect_flags[\"Password\"] = bool(\n            self.variable_headers[\"ConnectFlags\"][0] & 0x40\n        )\n        self.connect_flags[\"UserName\"] = bool(\n            self.variable_headers[\"ConnectFlags\"][0] & 0x80\n        )\n\n    # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718031\n    def _parse_connect_payload(self):\n        fields = []\n        offset = len(self._packet) - self.remaining_length + 10\n\n        while len(self._packet) - offset > 0:\n            field_length, field_content = self._parse_length_prefixed_bytes(offset)\n            fields.append(field_content)\n            offset += field_length\n\n        self.payload = {}\n\n        for f in fields:\n            # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc385349242\n            if \"ClientId\" not in self.payload:\n                self.payload[\"ClientId\"] = f.decode(\"utf-8\")\n            # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc385349243\n            elif self.connect_flags[\"Will\"] and \"WillTopic\" not in self.payload:\n                self.payload[\"WillTopic\"] = f.decode(\"utf-8\")\n            elif self.connect_flags[\"Will\"] and \"WillMessage\" not in self.payload:\n                self.payload[\"WillMessage\"] = f\n            elif (\n                self.connect_flags[\"UserName\"] and \"UserName\" not in self.payload\n            ):  # pragma: no cover\n                self.payload[\"UserName\"] = f.decode(\"utf-8\")\n            elif (\n                self.connect_flags[\"Password\"] and \"Password\" not in self.payload\n            ):  # pragma: no cover\n                self.payload[\"Password\"] = f\n            else:\n                raise AssertionError(f\"Unknown field in CONNECT payload: {f}\")\n\n    def _parse_packet_type(self):\n        return self._packet[0] >> 4\n\n    # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718022\n    def _parse_flags(self):\n        dup = None\n        qos = None\n        retain = None\n\n        if self.packet_type == self.PUBLISH:\n            dup = (self._packet[0] >> 3) & 0x01\n            qos = (self._packet[0] >> 1) & 0x03\n            retain = self._packet[0] & 0x01\n\n        return dup, qos, retain\n\n    # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Table_2.4_Size\n    def _parse_remaining_length(self):\n        multiplier = 1\n        value = 0\n        i = 1\n\n        while True:\n            encodedByte = self._packet[i]\n            value += (encodedByte & 127) * multiplier\n            multiplier *= 128\n\n            if multiplier > 128 * 128 * 128:\n                raise ValueError(\"Malformed Remaining Length\")\n\n            if encodedByte & 128 == 0:\n                break\n\n            i += 1\n\n        return value\n\n    # http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Table_2.5_-\n    def _parse_packet_identifier(self):\n        offset = len(self._packet) - self.remaining_length\n        self.packet_identifier = self._packet[offset : offset + 2]\n\n\nclass ViewMQTT(base.View):\n    name = \"MQTT\"\n\n    def __call__(self, data, **metadata):\n        mqtt_packet = MQTTControlPacket(data)\n        text = mqtt_packet.pprint()\n        return \"MQTT\", base.format_text(text)\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        return 0\n", "mitmproxy/contentviews/base.py": "# Default view cutoff *in lines*\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Mapping\nfrom typing import ClassVar\nfrom typing import Union\n\nfrom mitmproxy import flow\nfrom mitmproxy import http\n\nKEY_MAX = 30\n\nTTextType = Union[str, bytes]  # FIXME: This should be either bytes or str ultimately.\nTViewLine = list[tuple[str, TTextType]]\nTViewResult = tuple[str, Iterator[TViewLine]]\n\n\nclass View(ABC):\n    name: ClassVar[str]\n\n    @abstractmethod\n    def __call__(\n        self,\n        data: bytes,\n        *,\n        content_type: str | None = None,\n        flow: flow.Flow | None = None,\n        http_message: http.Message | None = None,\n        **unknown_metadata,\n    ) -> TViewResult:\n        \"\"\"\n        Transform raw data into human-readable output.\n\n        Returns a (description, content generator) tuple.\n        The content generator yields lists of (style, text) tuples, where each list represents\n        a single line. ``text`` is a unfiltered string which may need to be escaped,\n        depending on the used output. For example, it may contain terminal control sequences\n        or unfiltered HTML.\n\n        Except for `data`, implementations must not rely on any given argument to be present.\n        To ensure compatibility with future mitmproxy versions, unknown keyword arguments should be ignored.\n\n        The content generator must not yield tuples of tuples, because urwid cannot process that.\n        You have to yield a *list* of tuples per line.\n        \"\"\"\n        raise NotImplementedError()  # pragma: no cover\n\n    def render_priority(\n        self,\n        data: bytes,\n        *,\n        content_type: str | None = None,\n        flow: flow.Flow | None = None,\n        http_message: http.Message | None = None,\n        **unknown_metadata,\n    ) -> float:\n        \"\"\"\n        Return the priority of this view for rendering `data`.\n        If no particular view is chosen by the user, the view with the highest priority is selected.\n\n        Except for `data`, implementations must not rely on any given argument to be present.\n        To ensure compatibility with future mitmproxy versions, unknown keyword arguments should be ignored.\n        \"\"\"\n        return 0\n\n    def __lt__(self, other):\n        assert isinstance(other, View)\n        return self.name.__lt__(other.name)\n\n\ndef format_pairs(items: Iterable[tuple[TTextType, TTextType]]) -> Iterator[TViewLine]:\n    \"\"\"\n    Helper function that accepts a list of (k,v) pairs into a list of\n    [\n        (\"key\", key    )\n        (\"value\", value)\n    ]\n    where key is padded to a uniform width\n    \"\"\"\n\n    max_key_len = max((len(k[0]) for k in items), default=0)\n    max_key_len = min((max_key_len, KEY_MAX), default=0)\n\n    for key, value in items:\n        if isinstance(key, bytes):\n            key += b\":\"\n        else:\n            key += \":\"\n\n        key = key.ljust(max_key_len + 2)\n\n        yield [(\"header\", key), (\"text\", value)]\n\n\ndef format_dict(d: Mapping[TTextType, TTextType]) -> Iterator[TViewLine]:\n    \"\"\"\n    Helper function that transforms the given dictionary into a list of\n    [\n        (\"key\",   key  )\n        (\"value\", value)\n    ]\n    entries, where key is padded to a uniform width.\n    \"\"\"\n\n    return format_pairs(d.items())\n\n\ndef format_text(text: TTextType) -> Iterator[TViewLine]:\n    \"\"\"\n    Helper function that transforms bytes into the view output format.\n    \"\"\"\n    for line in text.splitlines():\n        yield [(\"text\", line)]\n", "mitmproxy/contentviews/hex.py": "from . import base\nfrom mitmproxy.utils import strutils\n\n\nclass ViewHexDump(base.View):\n    name = \"Hex Dump\"\n\n    @staticmethod\n    def _format(data):\n        for offset, hexa, s in strutils.hexdump(data):\n            yield [(\"offset\", offset + \" \"), (\"text\", hexa + \"   \"), (\"text\", s)]\n\n    def __call__(self, data, **metadata):\n        return \"Hexdump\", self._format(data)\n\n    def render_priority(self, data: bytes, **metadata) -> float:\n        return 0.2 * strutils.is_mostly_bin(data)\n\n\nclass ViewHexStream(base.View):\n    name = \"Raw Hex Stream\"\n\n    def __call__(self, data, **metadata):\n        return \"Raw Hex Stream\", base.format_text(data.hex())\n\n    def render_priority(self, data: bytes, **metadata) -> float:\n        return 0.15 * strutils.is_mostly_bin(data)\n", "mitmproxy/contentviews/grpc.py": "from __future__ import annotations\n\nimport logging\nimport struct\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom enum import Enum\n\nfrom mitmproxy import contentviews\nfrom mitmproxy import flow\nfrom mitmproxy import flowfilter\nfrom mitmproxy import http\nfrom mitmproxy.contentviews import base\nfrom mitmproxy.net.encoding import decode\n\n\nclass ProtoParser:\n    @dataclass\n    class ParserRule:\n        \"\"\"\n        A parser rule lists Field definitions which are applied if the filter rule matches the flow.\n\n        Matching on flow-level also means, a match applies to request AND response messages.\n        To restrict a rule to a requests only use 'ParserRuleRequest', instead.\n        To restrict a rule to a responses only use 'ParserRuleResponse', instead.\n        \"\"\"\n\n        field_definitions: list[ProtoParser.ParserFieldDefinition]\n        \"\"\"List of field definitions for this rule \"\"\"\n\n        name: str = \"\"\n        \"\"\"Name of this rule, only used for debugging\"\"\"\n\n        filter: str = \"\"\n        \"\"\"\n        Flowfilter to select which flows to apply to ('~q' and '~s' can not be used to distinguish\n        if the rule should apply to the request or response of a flow. To do so, use ParserRuleRequest\n        or ParserRuleResponse. ParserRule always applies to request and response.)\n        \"\"\"\n\n    @dataclass\n    class ParserRuleResponse(ParserRule):\n        \"\"\"\n        A parser rule lists Field definitions which are applied if the filter rule matches the flow.\n\n        The rule only applies if the processed message is a server response.\n        \"\"\"\n\n    @dataclass\n    class ParserRuleRequest(ParserRule):\n        \"\"\"\n        A parser rule lists Field definitions which are applied if the filter rule matches the flow.\n\n        The rule only applies if the processed message is a client request.\n        \"\"\"\n\n    @dataclass\n    class ParserFieldDefinition:\n        \"\"\"\n        Defines how to parse a field (or multiple fields with the same tag) in a protobuf messages.\n\n        This allows to apply an intended decoding (f.e. decode uint64 as double instead) and to assign\n        a descriptive name to a field. Field definitions are aggregated into rules, which also holds\n        a filter to match selected HTTP messages.\n\n        The most natural way to use this, is to describe known parts of a single protobuf message\n        in a set of field descriptors, pack them into a rule and set the filter of the rule in a way,\n        that it only applies to proper protobuf messages (f.e. to request traffic against an API endpoint\n        matched by an URL flowfilter)\n        \"\"\"\n\n        # A 'tag' could be considered as \"absolute path\" to match a unique field, yet\n        # protobuf allows to uses the same nested message in different positions of the parent message\n        # The 'tag_prefixes' parameter allows to apply the field definition to different \"leafs nodes\"\n        # of a message.\n        #\n        # Example 1: match a single, absolute tag\n        # ----------\n        # tag = '1.2'\n        # tag_prefixes = [] (default)\n        #\n        # applies to: tag '1.2'\n        #\n        # Example 2: match multiple tags with same ending\n        # ----------\n        # tag = '1.3'\n        # tag_prefixes = ['1.2.', '2.5.']\n        #\n        # applies to: tag '1.2.1.3' and tag '2.5.1.3'\n        # does not apply to: '1.3', unless tag_prefixes is extended to tag_prefixes = ['1.2', '2.5', '']\n        #\n        # Example 3: match multiple tags\n        # ----------\n        # tag = ''\n        # tag_prefixes = ['1.2', '2.5']\n        #\n        # applies to: tag '1.2' and tag '1.5'\n\n        tag: str\n        \"\"\"Field tag for which this description applies (including flattened tag path, f.e. '1.2.2.4')\"\"\"\n\n        tag_prefixes: list[str] = field(default_factory=list)\n        \"\"\"List of prefixes for tag matching (f.e. tag_prefixes=['1.2.', '2.2.'] with tag='1' matches '1.2.1' and '2.2.1')\"\"\"\n\n        intended_decoding: ProtoParser.DecodedTypes | None = None\n        \"\"\"optional: intended decoding for visualization (parser fails over to alternate decoding if not possible)\"\"\"\n\n        name: str | None = None\n        \"\"\"optional: intended field for visualization (parser fails over to alternate decoding if not possible)\"\"\"\n\n        as_packed: bool | None = False\n        \"\"\"optional: if set to true, the field is considered to be repeated and packed\"\"\"\n\n    @dataclass\n    class ParserOptions:\n        # output should contain wiretype of fields\n        include_wiretype: bool = False\n\n        # output should contain the fields which describe nested messages\n        # (the nested messages bodies are always included, but the \"header fields\" could\n        # add unnecessary output overhead)\n        exclude_message_headers: bool = False\n\n        # optional: rules\n        # rules: List[ProtoParser.ParserRule] = field(default_factory=list)\n\n    class DecodedTypes(Enum):\n        # varint\n        int32 = 0\n        int64 = 1\n        uint32 = 2\n        uint64 = 3\n        sint32 = 4  # ZigZag encoding\n        sint64 = 5  # ZigZag encoding\n        bool = 6\n        enum = 7\n        # bit_32\n        fixed32 = 8\n        sfixed32 = 9\n        float = 10\n        # bit_64\n        fixed64 = 11\n        sfixed64 = 12\n        double = 13\n        # len_delimited\n        string = 14\n        bytes = 15\n        message = 16\n\n        # helper\n        unknown = 17\n\n    @staticmethod\n    def _read_base128le(data: bytes) -> tuple[int, int]:\n        res = 0\n        offset = 0\n        while offset < len(data):\n            o = data[offset]\n            res += (o & 0x7F) << (7 * offset)\n            offset += 1\n            if o < 0x80:\n                # the Kaitai parser for protobuf support base128 le values up\n                # to 8 groups (bytes). Due to the nature of the encoding, each\n                # group attributes 7bit to the resulting value, which give\n                # a 56 bit value at maximum.\n                # The values which get encoded into protobuf variable length integers,\n                # on the other hand, include full 64bit types (int64, uint64, sint64).\n                # This means, the Kaitai encoder can not cover the full range of\n                # possible values\n                #\n                # This decoder puts no limitation on the maximum value of variable\n                # length integers. Values exceeding 64bit have to be handled externally\n                return offset, res\n        raise ValueError(\"varint exceeds bounds of provided data\")\n\n    @staticmethod\n    def _read_u32(data: bytes) -> tuple[int, int]:\n        return 4, struct.unpack(\"<I\", data[:4])[0]\n\n    @staticmethod\n    def _read_u64(data: bytes) -> tuple[int, int]:\n        return 8, struct.unpack(\"<Q\", data[:8])[0]\n\n    class WireTypes(Enum):\n        varint = 0\n        bit_64 = 1\n        len_delimited = 2\n        group_start = 3\n        group_end = 4\n        bit_32 = 5\n\n    @staticmethod\n    def read_fields(\n        wire_data: bytes,\n        parent_field: ProtoParser.Field | None,\n        options: ProtoParser.ParserOptions,\n        rules: list[ProtoParser.ParserRule],\n    ) -> list[ProtoParser.Field]:\n        res: list[ProtoParser.Field] = []\n        pos = 0\n        while pos < len(wire_data):\n            # read field key (tag and wire_type)\n            offset, key = ProtoParser._read_base128le(wire_data[pos:])\n            # casting raises exception for invalid WireTypes\n            wt = ProtoParser.WireTypes(key & 7)\n            tag = key >> 3\n            pos += offset\n\n            val: bytes | int\n            preferred_decoding: ProtoParser.DecodedTypes\n            if wt == ProtoParser.WireTypes.varint:\n                offset, val = ProtoParser._read_base128le(wire_data[pos:])\n                pos += offset\n                bl = val.bit_length()\n                if bl > 64:\n                    preferred_decoding = ProtoParser.DecodedTypes.unknown\n                if bl > 32:\n                    preferred_decoding = ProtoParser.DecodedTypes.uint64\n                else:\n                    preferred_decoding = ProtoParser.DecodedTypes.uint32\n            elif wt == ProtoParser.WireTypes.bit_64:\n                offset, val = ProtoParser._read_u64(wire_data[pos:])\n                pos += offset\n                preferred_decoding = ProtoParser.DecodedTypes.fixed64\n            elif wt == ProtoParser.WireTypes.len_delimited:\n                offset, length = ProtoParser._read_base128le(wire_data[pos:])\n                pos += offset\n                if length > len(wire_data[pos:]):\n                    raise ValueError(\"length delimited field exceeds data size\")\n                val = wire_data[pos : pos + length]\n                pos += length\n                preferred_decoding = ProtoParser.DecodedTypes.message\n            elif (\n                wt == ProtoParser.WireTypes.group_start\n                or wt == ProtoParser.WireTypes.group_end\n            ):\n                raise ValueError(f\"deprecated field: {wt}\")\n            elif wt == ProtoParser.WireTypes.bit_32:\n                offset, val = ProtoParser._read_u32(wire_data[pos:])\n                pos += offset\n                preferred_decoding = ProtoParser.DecodedTypes.fixed32\n            else:\n                # not reachable as if-else statements contain all possible WireTypes\n                # wrong types raise Exception during typecasting in `wt = ProtoParser.WireTypes((key & 7))`\n                raise ValueError(\"invalid WireType for protobuf messsage field\")\n\n            field = ProtoParser.Field(\n                wire_type=wt,\n                preferred_decoding=preferred_decoding,\n                options=options,\n                rules=rules,\n                tag=tag,\n                wire_value=val,\n                parent_field=parent_field,\n            )\n            res.append(field)\n\n        return res\n\n    @staticmethod\n    def read_packed_fields(\n        packed_field: ProtoParser.Field,\n    ) -> list[ProtoParser.Field]:\n        if not isinstance(packed_field.wire_value, bytes):\n            raise ValueError(\n                f\"can not unpack field with data other than bytes: {type(packed_field.wire_value)}\"\n            )\n        wire_data: bytes = packed_field.wire_value\n        tag: int = packed_field.tag\n        options: ProtoParser.ParserOptions = packed_field.options\n        rules: list[ProtoParser.ParserRule] = packed_field.rules\n        intended_decoding: ProtoParser.DecodedTypes = packed_field.preferred_decoding\n\n        # the packed field has to have WireType length delimited, whereas the contained\n        # individual types have to have a different WireType, which is derived from\n        # the intended decoding\n        if (\n            packed_field.wire_type != ProtoParser.WireTypes.len_delimited\n            or not isinstance(packed_field.wire_value, bytes)\n        ):\n            raise ValueError(\n                \"packed fields have to be embedded in a length delimited message\"\n            )\n        # wiretype to read has to be determined from intended decoding\n        packed_wire_type: ProtoParser.WireTypes\n        if (\n            intended_decoding == ProtoParser.DecodedTypes.int32\n            or intended_decoding == ProtoParser.DecodedTypes.int64\n            or intended_decoding == ProtoParser.DecodedTypes.uint32\n            or intended_decoding == ProtoParser.DecodedTypes.uint64\n            or intended_decoding == ProtoParser.DecodedTypes.sint32\n            or intended_decoding == ProtoParser.DecodedTypes.sint64\n            or intended_decoding == ProtoParser.DecodedTypes.bool\n            or intended_decoding == ProtoParser.DecodedTypes.enum\n        ):\n            packed_wire_type = ProtoParser.WireTypes.varint\n        elif (\n            intended_decoding == ProtoParser.DecodedTypes.fixed32\n            or intended_decoding == ProtoParser.DecodedTypes.sfixed32\n            or intended_decoding == ProtoParser.DecodedTypes.float\n        ):\n            packed_wire_type = ProtoParser.WireTypes.bit_32\n        elif (\n            intended_decoding == ProtoParser.DecodedTypes.fixed64\n            or intended_decoding == ProtoParser.DecodedTypes.sfixed64\n            or intended_decoding == ProtoParser.DecodedTypes.double\n        ):\n            packed_wire_type = ProtoParser.WireTypes.bit_64\n        elif (\n            intended_decoding == ProtoParser.DecodedTypes.string\n            or intended_decoding == ProtoParser.DecodedTypes.bytes\n            or intended_decoding == ProtoParser.DecodedTypes.message\n        ):\n            packed_wire_type = ProtoParser.WireTypes.len_delimited\n        else:\n            # should never happen, no test\n            raise TypeError(\n                \"Wire type could not be determined from packed decoding type\"\n            )\n\n        res: list[ProtoParser.Field] = []\n        pos = 0\n        val: bytes | int\n        if packed_wire_type == ProtoParser.WireTypes.varint:\n            while pos < len(wire_data):\n                offset, val = ProtoParser._read_base128le(wire_data[pos:])\n                pos += offset\n                res.append(\n                    ProtoParser.Field(\n                        options=options,\n                        preferred_decoding=intended_decoding,\n                        rules=rules,\n                        tag=tag,\n                        wire_type=packed_wire_type,\n                        wire_value=val,\n                        parent_field=packed_field.parent_field,\n                        is_unpacked_children=True,\n                    )\n                )\n        elif packed_wire_type == ProtoParser.WireTypes.bit_64:\n            if len(wire_data) % 8 != 0:\n                raise ValueError(\"can not parse as packed bit64\")\n            while pos < len(wire_data):\n                offset, val = ProtoParser._read_u64(wire_data[pos:])\n                pos += offset\n                res.append(\n                    ProtoParser.Field(\n                        options=options,\n                        preferred_decoding=intended_decoding,\n                        rules=rules,\n                        tag=tag,\n                        wire_type=packed_wire_type,\n                        wire_value=val,\n                        parent_field=packed_field.parent_field,\n                        is_unpacked_children=True,\n                    )\n                )\n        elif packed_wire_type == ProtoParser.WireTypes.len_delimited:\n            while pos < len(wire_data):\n                offset, length = ProtoParser._read_base128le(wire_data[pos:])\n                pos += offset\n                val = wire_data[pos : pos + length]\n                if length > len(wire_data[pos:]):\n                    raise ValueError(\"packed length delimited field exceeds data size\")\n                res.append(\n                    ProtoParser.Field(\n                        options=options,\n                        preferred_decoding=intended_decoding,\n                        rules=rules,\n                        tag=tag,\n                        wire_type=packed_wire_type,\n                        wire_value=val,\n                        parent_field=packed_field.parent_field,\n                        is_unpacked_children=True,\n                    )\n                )\n                pos += length\n        elif (\n            packed_wire_type == ProtoParser.WireTypes.group_start\n            or packed_wire_type == ProtoParser.WireTypes.group_end\n        ):\n            raise ValueError(\"group tags can not be encoded packed\")\n        elif packed_wire_type == ProtoParser.WireTypes.bit_32:\n            if len(wire_data) % 4 != 0:\n                raise ValueError(\"can not parse as packed bit32\")\n            while pos < len(wire_data):\n                offset, val = ProtoParser._read_u32(wire_data[pos:])\n                pos += offset\n                res.append(\n                    ProtoParser.Field(\n                        options=options,\n                        preferred_decoding=intended_decoding,\n                        rules=rules,\n                        tag=tag,\n                        wire_type=packed_wire_type,\n                        wire_value=val,\n                        parent_field=packed_field.parent_field,\n                        is_unpacked_children=True,\n                    )\n                )\n        else:\n            # should never happen\n            raise ValueError(\"invalid WireType for protobuf messsage field\")\n\n        # mark parent field as packed parent (if we got here, unpacking succeeded)\n        packed_field.is_packed_parent = True\n        return res\n\n    class Field:\n        \"\"\"\n        Represents a single field of a protobuf message and handles the varios encodings.\n\n        As mitmproxy sees the data passing by as raw protobuf message, it only knows the\n        WireTypes. Each of the WireTypes could represent different Protobuf field types.\n        The exact Protobuf field type can not be determined from the wire format, thus different\n        options for decoding have to be supported.\n        In addition the parsed WireTypes are (intermediary) stored in Python types, which adds\n        some additional overhead type conversions.\n\n        WireType            represented Protobuf Types                 Python type (intermediary)\n\n        0: varint           int32, int64, uint32, uint64, enum,        int (*)\n                            sint32, sint64 (both ZigZag encoded),      int\n                            bool                                       bool\n                                                                       float (**)\n\n        1: bit_64           fixed64, sfixed64,                         int (*)\n                            double                                     float\n\n        2: len_delimited    string,                                    str\n                            message,                                   class 'Message'\n                            bytes,                                     bytes (*)\n                            packed_repeated_field                      class 'Message' (fields with same tag)\n\n        3: group_start      unused (deprecated)                        -\n        4: group_end        unused (deprecated)                        -\n\n        5: bit_32           fixed32, sfixed32,                         int (*)\n                            float                                      float\n\n        (*) Note 1:  Conversion between WireType and intermediary python representation\n                     is handled by Kaitai protobuf decoder and always uses the python\n                     representation marked with (*). Converting to alternative representations\n                     is handled inside this class.\n        (**) Note 2: Varint is not used to represent floating point values, but some applications\n                     store native floats in uint32 protobuf types (or native double in uint64).\n                     Thus we allow conversion of varint to floating point values for convenience\n                     (A well known APIs \"hide\" GPS latitude and longitude values in varint types,\n                     much easier to spot such things when rendered as float)\n\n        Ref: - https://developers.google.com/protocol-buffers/docs/proto3\n             - https://developers.google.com/protocol-buffers/docs/encoding\n        \"\"\"\n\n        def __init__(\n            self,\n            wire_type: ProtoParser.WireTypes,\n            preferred_decoding: ProtoParser.DecodedTypes,\n            tag: int,\n            parent_field: ProtoParser.Field | None,\n            wire_value: int | bytes,\n            options: ProtoParser.ParserOptions,\n            rules: list[ProtoParser.ParserRule],\n            is_unpacked_children: bool = False,\n        ) -> None:\n            self.wire_type: ProtoParser.WireTypes = wire_type\n            self.preferred_decoding: ProtoParser.DecodedTypes = preferred_decoding\n            self.wire_value: int | bytes = wire_value\n            self.tag: int = tag\n            self.options: ProtoParser.ParserOptions = options\n            self.name: str = \"\"\n            self.rules: list[ProtoParser.ParserRule] = rules\n            self.parent_field: ProtoParser.Field | None = parent_field\n            self.is_unpacked_children: bool = (\n                is_unpacked_children  # marks field as being a result of unpacking\n            )\n            self.is_packed_parent: bool = (\n                False  # marks field as being parent of successfully unpacked children\n            )\n            self.parent_tags: list[int] = []\n            if self.parent_field is not None:\n                self.parent_tags = self.parent_field.parent_tags[:]\n                self.parent_tags.append(self.parent_field.tag)\n            self.try_unpack = False\n\n            # rules can overwrite self.try_unpack\n            self.apply_rules()\n            # do not unpack fields which are the result of unpacking\n            if parent_field is not None and self.is_unpacked_children:\n                self.try_unpack = False\n\n        # no tests for only_first_hit=False, as not user-changable\n        def apply_rules(self, only_first_hit=True):\n            tag_str = self._gen_tag_str()\n            name = None\n            decoding = None\n            as_packed = False\n            try:\n                for rule in self.rules:\n                    for fd in rule.field_definitions:\n                        match = False\n                        if len(fd.tag_prefixes) == 0 and fd.tag == tag_str:\n                            match = True\n                        else:\n                            for rt in fd.tag_prefixes:\n                                if rt + fd.tag == tag_str:\n                                    match = True\n                                    break\n                        if match:\n                            if only_first_hit:\n                                # only first match\n                                if fd.name is not None:\n                                    self.name = fd.name\n                                if fd.intended_decoding is not None:\n                                    self.preferred_decoding = fd.intended_decoding\n                                self.try_unpack = bool(fd.as_packed)\n                                return\n                            else:\n                                # overwrite matches till last rule was inspected\n                                # (f.e. allows to define name in one rule and intended_decoding in another one)\n                                name = fd.name if fd.name else name\n                                decoding = (\n                                    fd.intended_decoding\n                                    if fd.intended_decoding\n                                    else decoding\n                                )\n                                if fd.as_packed:\n                                    as_packed = True\n\n                if name:\n                    self.name = name\n                if decoding:\n                    self.preferred_decoding = decoding\n                self.try_unpack = as_packed\n            except Exception as e:\n                logging.warning(e)\n\n        def _gen_tag_str(self):\n            tags = self.parent_tags[:]\n            tags.append(self.tag)\n            return \".\".join([str(tag) for tag in tags])\n\n        def safe_decode_as(\n            self,\n            intended_decoding: ProtoParser.DecodedTypes,\n            try_as_packed: bool = False,\n        ) -> tuple[\n            ProtoParser.DecodedTypes,\n            bool | float | int | bytes | str | list[ProtoParser.Field],\n        ]:\n            \"\"\"\n            Tries to decode as intended, applies failover, if not possible\n\n            Returns selected decoding and decoded value\n            \"\"\"\n            if self.wire_type == ProtoParser.WireTypes.varint:\n                try:\n                    return intended_decoding, self.decode_as(\n                        intended_decoding, try_as_packed\n                    )\n                except Exception:\n                    if int(self.wire_value).bit_length() > 32:\n                        # ignore the fact that varint could exceed 64bit (would violate the specs)\n                        return ProtoParser.DecodedTypes.uint64, self.wire_value\n                    else:\n                        return ProtoParser.DecodedTypes.uint32, self.wire_value\n            elif self.wire_type == ProtoParser.WireTypes.bit_64:\n                try:\n                    return intended_decoding, self.decode_as(\n                        intended_decoding, try_as_packed\n                    )\n                except Exception:\n                    return ProtoParser.DecodedTypes.fixed64, self.wire_value\n            elif self.wire_type == ProtoParser.WireTypes.bit_32:\n                try:\n                    return intended_decoding, self.decode_as(\n                        intended_decoding, try_as_packed\n                    )\n                except Exception:\n                    return ProtoParser.DecodedTypes.fixed32, self.wire_value\n            elif self.wire_type == ProtoParser.WireTypes.len_delimited:\n                try:\n                    return intended_decoding, self.decode_as(\n                        intended_decoding, try_as_packed\n                    )\n                except Exception:\n                    # failover strategy: message --> string (valid UTF-8) --> bytes\n                    len_delimited_strategy: list[ProtoParser.DecodedTypes] = [\n                        ProtoParser.DecodedTypes.message,\n                        ProtoParser.DecodedTypes.string,\n                        ProtoParser.DecodedTypes.bytes,  # should always work\n                    ]\n                    for failover_decoding in len_delimited_strategy:\n                        if failover_decoding == intended_decoding and not try_as_packed:\n                            # don't try same decoding twice, unless first attempt was packed\n                            continue\n                        try:\n                            return failover_decoding, self.decode_as(\n                                failover_decoding, False\n                            )\n                        except Exception:\n                            pass\n\n            # we should never get here (could not be added to tests)\n            return ProtoParser.DecodedTypes.unknown, self.wire_value\n\n        def decode_as(\n            self, intended_decoding: ProtoParser.DecodedTypes, as_packed: bool = False\n        ) -> bool | int | float | bytes | str | list[ProtoParser.Field]:\n            if as_packed is True:\n                return ProtoParser.read_packed_fields(packed_field=self)\n\n            if self.wire_type == ProtoParser.WireTypes.varint:\n                assert isinstance(self.wire_value, int)\n                if intended_decoding == ProtoParser.DecodedTypes.bool:\n                    # clamp result to 64bit\n                    return self.wire_value & 0xFFFFFFFFFFFFFFFF != 0\n                elif intended_decoding == ProtoParser.DecodedTypes.int32:\n                    if self.wire_value.bit_length() > 32:\n                        raise TypeError(\"wire value too large for int32\")\n                    return struct.unpack(\"!i\", struct.pack(\"!I\", self.wire_value))[0]\n                elif intended_decoding == ProtoParser.DecodedTypes.int64:\n                    if self.wire_value.bit_length() > 64:\n                        raise TypeError(\"wire value too large for int64\")\n                    return struct.unpack(\"!q\", struct.pack(\"!Q\", self.wire_value))[0]\n                elif intended_decoding == ProtoParser.DecodedTypes.uint32:\n                    if self.wire_value.bit_length() > 32:\n                        raise TypeError(\"wire value too large for uint32\")\n                    return self.wire_value  # already 'int' which was parsed as unsigned\n                elif (\n                    intended_decoding == ProtoParser.DecodedTypes.uint64\n                    or intended_decoding == ProtoParser.DecodedTypes.enum\n                ):\n                    if self.wire_value.bit_length() > 64:\n                        raise TypeError(\"wire value too large\")\n                    return self.wire_value  # already 'int' which was parsed as unsigned\n                elif intended_decoding == ProtoParser.DecodedTypes.sint32:\n                    if self.wire_value.bit_length() > 32:\n                        raise TypeError(\"wire value too large for sint32\")\n                    return (self.wire_value >> 1) ^ -(\n                        self.wire_value & 1\n                    )  # zigzag_decode\n                elif intended_decoding == ProtoParser.DecodedTypes.sint64:\n                    if self.wire_value.bit_length() > 64:\n                        raise TypeError(\"wire value too large for sint64\")\n                    # ZigZag decode\n                    # Ref: https://gist.github.com/mfuerstenau/ba870a29e16536fdbaba\n                    return (self.wire_value >> 1) ^ -(self.wire_value & 1)\n                elif (\n                    intended_decoding == ProtoParser.DecodedTypes.float\n                    or intended_decoding == ProtoParser.DecodedTypes.double\n                ):\n                    # special case, not complying to protobuf specs\n                    return self._wire_value_as_float()\n            elif self.wire_type == ProtoParser.WireTypes.bit_64:\n                if intended_decoding == ProtoParser.DecodedTypes.fixed64:\n                    return self.wire_value\n                elif intended_decoding == ProtoParser.DecodedTypes.sfixed64:\n                    return struct.unpack(\"!q\", struct.pack(\"!Q\", self.wire_value))[0]\n                elif intended_decoding == ProtoParser.DecodedTypes.double:\n                    return self._wire_value_as_float()\n            elif self.wire_type == ProtoParser.WireTypes.bit_32:\n                if intended_decoding == ProtoParser.DecodedTypes.fixed32:\n                    return self.wire_value\n                elif intended_decoding == ProtoParser.DecodedTypes.sfixed32:\n                    return struct.unpack(\"!i\", struct.pack(\"!I\", self.wire_value))[0]\n                elif intended_decoding == ProtoParser.DecodedTypes.float:\n                    return self._wire_value_as_float()\n            elif self.wire_type == ProtoParser.WireTypes.len_delimited:\n                assert isinstance(self.wire_value, bytes)\n                if intended_decoding == ProtoParser.DecodedTypes.string:\n                    # According to specs, a protobuf string HAS TO be UTF-8 parsable\n                    # throw exception on invalid UTF-8 chars, but escape linebreaks\n                    return self.wire_value_as_utf8(escape_newline=True)\n                elif intended_decoding == ProtoParser.DecodedTypes.bytes:\n                    # always works, assure to hand back a copy\n                    return self.wire_value[:]\n                elif intended_decoding == ProtoParser.DecodedTypes.message:\n                    return ProtoParser.read_fields(\n                        wire_data=self.wire_value,\n                        parent_field=self,\n                        options=self.options,\n                        rules=self.rules,\n                    )\n\n            # if here, there is no valid decoding\n            raise TypeError(\"intended decoding mismatches wire type\")\n\n        def encode_from(inputval, intended_encoding: ProtoParser.DecodedTypes):\n            raise NotImplementedError(\n                \"Future work, needed to manipulate and re-encode protobuf message, with respect to given wire types\"\n            )\n\n        def _wire_value_as_float(self) -> float:\n            \"\"\"\n            Handles double (64bit) and float (32bit).\n            Assumes Network Byte Order (big endian).\n\n            Usable for:\n\n               WireType --> Protobuf Type):\n               ----------------------------\n               varint        --> double/float (not intended by ProtoBuf, but used in the wild)\n               bit_32        --> float\n               bit_64        --> double\n               len_delimited --> 4 bytes: float / 8 bytes: double / other sizes return NaN\n            \"\"\"\n            v = self._value_as_bytes()\n            if len(v) == 4:\n                return struct.unpack(\"!f\", v)[0]\n            elif len(v) == 8:\n                return struct.unpack(\"!d\", v)[0]\n            # no need to raise an Exception\n            raise TypeError(\"can not be converted to floatingpoint representation\")\n\n        def _value_as_bytes(self) -> bytes:\n            if isinstance(self.wire_value, bytes):\n                return self.wire_value\n            elif isinstance(self.wire_value, int):\n                if self.wire_value.bit_length() > 64:\n                    # source for a python int are wiretypes varint/bit_32/bit64 and should never convert to int values 64bit\n                    # currently avoided by kaitai decoder (can not be added to tests)\n                    raise ValueError(\"value exceeds 64bit, violating protobuf specs\")\n                elif self.wire_value.bit_length() > 32:\n                    # packing uses network byte order (to assure consistent results across architectures)\n                    return struct.pack(\"!Q\", self.wire_value)\n                else:\n                    # packing uses network byte order (to assure consistent results across architectures)\n                    return struct.pack(\"!I\", self.wire_value)\n            else:\n                # should never happen, no tests\n                raise ValueError(\"can not be converted to bytes\")\n\n        def _wire_type_str(self):\n            return str(self.wire_type).split(\".\")[-1]\n\n        def _decoding_str(self, decoding: ProtoParser.DecodedTypes):\n            return str(decoding).split(\".\")[-1]\n\n        def wire_value_as_utf8(self, escape_newline=True) -> str:\n            if isinstance(self.wire_value, bytes):\n                res = self.wire_value.decode(\"utf-8\")\n                return res.replace(\"\\n\", \"\\\\n\") if escape_newline else res\n            return str(self.wire_value)\n\n        def gen_flat_decoded_field_dicts(self) -> Generator[dict, None, None]:\n            \"\"\"\n            Returns a generator which passes the field as a dict.\n\n            In order to return the field value it gets decoded (based on a failover strategy and\n            provided ParserRules).\n            If the field holds a nested message, the fields contained in the message are appended.\n            Ultimately this flattens all fields recursively.\n            \"\"\"\n            selected_decoding, decoded_val = self.safe_decode_as(\n                self.preferred_decoding, self.try_unpack\n            )\n            field_desc_dict = {\n                \"tag\": self._gen_tag_str(),\n                \"wireType\": self._wire_type_str(),\n                \"decoding\": self._decoding_str(selected_decoding),\n                \"name\": self.name,\n            }\n            if isinstance(decoded_val, list):\n                if (\n                    selected_decoding\n                    == ProtoParser.DecodedTypes.message  # field is a message with subfields\n                    and not self.is_packed_parent  # field is a message, but replaced by packed fields\n                ):\n                    # Field is a message, not packed, thus include it as message header\n                    field_desc_dict[\"val\"] = \"\"\n                    yield field_desc_dict\n                # add sub-fields of messages or packed fields\n                for f in decoded_val:\n                    yield from f.gen_flat_decoded_field_dicts()\n            else:\n                field_desc_dict[\"val\"] = decoded_val\n                yield field_desc_dict\n\n    def __init__(\n        self,\n        data: bytes,\n        rules: list[ProtoParser.ParserRule] | None = None,\n        parser_options: ParserOptions | None = None,\n    ) -> None:\n        self.data: bytes = data\n        if parser_options is None:\n            parser_options = ProtoParser.ParserOptions()\n        self.options = parser_options\n        if rules is None:\n            rules = []\n        self.rules = rules\n\n        try:\n            self.root_fields: list[ProtoParser.Field] = ProtoParser.read_fields(\n                wire_data=self.data,\n                options=self.options,\n                parent_field=None,\n                rules=self.rules,\n            )\n        except Exception as e:\n            raise ValueError(\"not a valid protobuf message\") from e\n\n    def gen_flat_decoded_field_dicts(self) -> Generator[dict, None, None]:\n        for f in self.root_fields:\n            yield from f.gen_flat_decoded_field_dicts()\n\n    def gen_str_rows(self) -> Generator[tuple[str, ...], None, None]:\n        for field_dict in self.gen_flat_decoded_field_dicts():\n            if (\n                self.options.exclude_message_headers\n                and field_dict[\"decoding\"] == \"message\"\n            ):\n                continue\n\n            if self.options.include_wiretype:\n                col1 = \"[{}->{}]\".format(field_dict[\"wireType\"], field_dict[\"decoding\"])\n            else:\n                col1 = \"[{}]\".format(field_dict[\"decoding\"])\n            col2 = field_dict[\"name\"]  # empty string if not set (consumes no space)\n            col3 = field_dict[\"tag\"]\n            col4 = str(field_dict[\"val\"])\n            yield col1, col2, col3, col4\n\n\n# Note: all content view formating functionality is kept out of the ProtoParser class, to\n#       allow it to be use independently.\n#       This function is generic enough, to consider moving it to mitmproxy.contentviews.base\ndef format_table(\n    table_rows: Iterable[tuple[str, ...]],\n    max_col_width=100,\n) -> Iterator[base.TViewLine]:\n    \"\"\"\n    Helper function to render tables with variable column count (move to contentview base, if needed elsewhere)\n\n    Note: The function has to convert generators to a list, as all rows have to be processed twice (to determine\n    the column widths first).\n    \"\"\"\n    rows: list[tuple[str, ...]] = []\n    col_count = 0\n    cols_width: list[int] = []\n    for row in table_rows:\n        col_count = max(col_count, len(row))\n        while len(cols_width) < col_count:\n            cols_width.append(0)\n        for col_num in range(len(row)):\n            cols_width[col_num] = max(len(row[col_num]), cols_width[col_num])\n\n        # store row in list\n        rows.append(row)\n\n    for i in range(len(cols_width)):\n        cols_width[i] = min(cols_width[i], max_col_width)\n\n    for row in rows:\n        line: base.TViewLine = []\n        for col_num in range(len(row)):\n            col_val = row[col_num].ljust(cols_width[col_num] + 2)\n            line.append((\"text\", col_val))\n        yield line\n\n\ndef parse_grpc_messages(\n    data, compression_scheme\n) -> Generator[tuple[bool, bytes], None, None]:\n    \"\"\"Generator iterates over body data and returns a boolean indicating if the messages\n    was compressed, along with the raw message data (decompressed) for each gRPC message\n    contained in the body data\"\"\"\n    while data:\n        try:\n            msg_is_compressed, length = struct.unpack(\"!?i\", data[:5])\n            decoded_message = struct.unpack(\"!%is\" % length, data[5 : 5 + length])[0]\n        except Exception as e:\n            raise ValueError(\"invalid gRPC message\") from e\n\n        if msg_is_compressed:\n            try:\n                decoded_message = decode(\n                    encoded=decoded_message, encoding=compression_scheme\n                )\n            except Exception as e:\n                raise ValueError(\"Failed to decompress gRPC message with gzip\") from e\n\n        yield msg_is_compressed, decoded_message\n        data = data[5 + length :]\n\n\n# hacky fix for mitmproxy issue:\n#\n# mitmproxy handles Exceptions in the contenview's __call__ function, by\n# failing over to 'Raw' view. The intention was to use this behavior to\n# pass up Exceptions thrown inside the generator function ('format_pbuf'\n# and 'format_grpc') to the __call__ function.\n# This usually works fine if the contentview is initialized on a flow\n# with invalid data.\n# When the flow data gets invalidated in the edit mode, mitmproxy re-calls\n# the generator functions outside the contentviews '__call__' method.\n#\n# This happens in the 'safe_to_print' function of 'mitmproxy/contentvies/__init__.py'\n#\n#  def safe_to_print(lines, encoding=\"utf8\"):\n#    \"\"\"\n#    Wraps a content generator so that each text portion is a *safe to print* unicode string.\n#    \"\"\"\n#    for line in lines:  # <------ this code re-iterates lines and thus calls generators, without using the views __call__ function\n#        clean_line = []\n#        for (style, text) in line:\n#            if isinstance(text, bytes):\n#                text = text.decode(encoding, \"replace\")\n#            text = strutils.escape_control_characters(text)\n#            clean_line.append((style, text))\n#        yield clean_line\n#\n# In result, mitmproxy crashes if the generator functions raise Exception to indicate\n# data parsing errors.\n# To deal with this, the generator function gets converted into a list inside the\n# __call__ function. Ultimately, exceptions are raised directly from within __call__\n# instead in cases where the generator is accessed externally without exception handling.\ndef hack_generator_to_list(generator_func):\n    return list(generator_func)\n\n\ndef format_pbuf(\n    message: bytes,\n    parser_options: ProtoParser.ParserOptions,\n    rules: list[ProtoParser.ParserRule],\n):\n    yield from format_table(\n        ProtoParser(\n            data=message, parser_options=parser_options, rules=rules\n        ).gen_str_rows()\n    )\n\n\ndef format_grpc(\n    data: bytes,\n    parser_options: ProtoParser.ParserOptions,\n    rules: list[ProtoParser.ParserRule],\n    compression_scheme=\"gzip\",\n):\n    message_count = 0\n    for compressed, pb_message in parse_grpc_messages(\n        data=data, compression_scheme=compression_scheme\n    ):\n        headline = (\n            \"gRPC message \"\n            + str(message_count)\n            + \" (compressed \"\n            + str(compression_scheme if compressed else compressed)\n            + \")\"\n        )\n\n        yield [(\"text\", headline)]\n        yield from format_pbuf(\n            message=pb_message, parser_options=parser_options, rules=rules\n        )\n\n\n@dataclass\nclass ViewConfig:\n    parser_options: ProtoParser.ParserOptions = field(\n        default_factory=ProtoParser.ParserOptions\n    )\n    parser_rules: list[ProtoParser.ParserRule] = field(default_factory=list)\n\n\nclass ViewGrpcProtobuf(base.View):\n    \"\"\"Human friendly view of protocol buffers\"\"\"\n\n    name = \"gRPC/Protocol Buffer\"\n    __content_types_pb = [\n        \"application/x-protobuf\",\n        \"application/x-protobuffer\",\n        \"application/grpc-proto\",\n    ]\n    __content_types_grpc = [\n        \"application/grpc\",\n        # seems specific to chromium infra tooling\n        # https://chromium.googlesource.com/infra/luci/luci-go/+/refs/heads/main/grpc/prpc/\n        \"application/prpc\",\n    ]\n\n    # first value serves as default algorithm for compressed messages, if 'grpc-encoding' header is missing\n    __valid_grpc_encodings = [\n        \"gzip\",\n        \"identity\",\n        \"deflate\",\n        \"zstd\",\n    ]\n\n    # allows to take external ParserOptions object. goes with defaults otherwise\n    def __init__(self, config: ViewConfig | None = None) -> None:\n        super().__init__()\n        if config is None:\n            config = ViewConfig()\n        self.config = config\n\n    def _matching_rules(\n        self,\n        rules: list[ProtoParser.ParserRule],\n        message: http.Message | None,\n        flow: flow.Flow | None,\n    ) -> list[ProtoParser.ParserRule]:\n        \"\"\"\n        Checks which of the give rules applies and returns a List only containing those rules\n\n        Each rule defines a flow filter in rule.filter which is usually matched against a flow.\n        When it comes to protobuf parsing, in most cases request messages differ from response messages.\n        Thus, it has to be possible to apply a rule to a http.Request or a http.Response, only.\n\n        As the name flowfilter suggests, filters are working on a flow-level, not on message-level.\n        This means:\n\n        - the filter expression '~q' matches all flows with a request, but no response\n        - the filter expression '~s' matches all flows with a response\n\n        In result, for complete flows (with a gRPC message in the request and the response), ParserRules would\n        either be applied to request and response at the same time ('~s') or neither would match request, nor\n        response (~q).\n\n        To distinguish between rules which should be applied to response messages, request messages or both\n        (while being applied to the whole flow), different classes with same behavior are used to wrap rules:\n\n            - ParserRule: applies to requests and responses\n            - ParserRuleRequest: applies to requests only\n            - ParserRuleResponse: applies to responses only\n        \"\"\"\n        res: list[ProtoParser.ParserRule] = []\n        if not flow:\n            return res\n        is_request = isinstance(message, http.Request)\n        for rule in rules:\n            # message based rule matching\n            if is_request and isinstance(rule, ProtoParser.ParserRuleResponse):\n                continue\n            elif not is_request and isinstance(rule, ProtoParser.ParserRuleRequest):\n                continue\n            # flow based rule matching\n            if flowfilter.match(rule.filter, flow=flow):\n                res.append(rule)\n        return res\n\n    def __call__(\n        self,\n        data: bytes,\n        *,\n        content_type: str | None = None,\n        flow: flow.Flow | None = None,\n        http_message: http.Message | None = None,\n        **unknown_metadata,\n    ) -> contentviews.TViewResult:\n        applicabble_rules = self._matching_rules(\n            rules=self.config.parser_rules, flow=flow, message=http_message\n        )\n        if content_type in self.__content_types_grpc:\n            # If gRPC messages are flagged to be compressed, the compression algorithm is expressed in the\n            # 'grpc-encoding' header.\n            #\n            # The following code tries to determine the compression algorithm base on this header.\n            # If the header is not present or contains an unsupported compression, the logic falls back to\n            # 'gzip'.\n            #\n            # If a compressed gRPC message is found in the body data (compressed flag set), the information\n            # on the compression scheme is needed (even if not set by a header), in order to process the message.\n            # Thus we assure there is always an encoding selected. An encoding of 'Identity' would not make\n            # sense, if a message is flagged as being compressed, that's why a default is chosen.\n            try:\n                assert http_message is not None\n                h = http_message.headers[\"grpc-encoding\"]\n                grpc_encoding = (\n                    h\n                    if h in self.__valid_grpc_encodings\n                    else self.__valid_grpc_encodings[0]\n                )\n            except Exception:\n                grpc_encoding = self.__valid_grpc_encodings[0]\n\n            text_iter = format_grpc(\n                data=data,\n                parser_options=self.config.parser_options,\n                compression_scheme=grpc_encoding,\n                rules=applicabble_rules,\n            )\n            title = \"gRPC\"\n        else:\n            text_iter = format_pbuf(\n                message=data,\n                parser_options=self.config.parser_options,\n                rules=applicabble_rules,\n            )\n            title = \"Protobuf (flattened)\"\n\n        # hacky bugfix, see description above generator functions format_pbuf/format_grpc\n        try:\n            text_iter = hack_generator_to_list(text_iter)\n        except Exception as e:\n            # hook to log exception tracebacks on iterators\n\n            # import traceback\n            # logging.warning(\"gRPC contentview: {}\".format(traceback.format_exc()))\n            raise e\n\n        return title, text_iter\n\n    def render_priority(\n        self,\n        data: bytes,\n        *,\n        content_type: str | None = None,\n        flow: flow.Flow | None = None,\n        http_message: http.Message | None = None,\n        **unknown_metadata,\n    ) -> float:\n        if bool(data) and content_type in self.__content_types_grpc:\n            return 1\n        if bool(data) and content_type in self.__content_types_pb:\n            # replace existing protobuf renderer preference (adjust by option)\n            return 1.5\n        else:\n            return 0\n", "mitmproxy/contentviews/urlencoded.py": "from . import base\nfrom mitmproxy.net.http import url\n\n\nclass ViewURLEncoded(base.View):\n    name = \"URL-encoded\"\n\n    def __call__(self, data, **metadata):\n        try:\n            data = data.decode(\"ascii\", \"strict\")\n        except ValueError:\n            return None\n        d = url.decode(data)\n        return \"URLEncoded form\", base.format_pairs(d)\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        return float(bool(data) and content_type == \"application/x-www-form-urlencoded\")\n", "mitmproxy/contentviews/json.py": "import json\nimport re\nfrom collections.abc import Iterator\nfrom functools import lru_cache\nfrom typing import Any\n\nfrom mitmproxy.contentviews import base\n\nPARSE_ERROR = object()\n\n\n@lru_cache(1)\ndef parse_json(s: bytes) -> Any:\n    try:\n        return json.loads(s.decode(\"utf-8\"))\n    except ValueError:\n        return PARSE_ERROR\n\n\ndef format_json(data: Any) -> Iterator[base.TViewLine]:\n    encoder = json.JSONEncoder(indent=4, sort_keys=True, ensure_ascii=False)\n    current_line: base.TViewLine = []\n    for chunk in encoder.iterencode(data):\n        if \"\\n\" in chunk:\n            rest_of_last_line, chunk = chunk.split(\"\\n\", maxsplit=1)\n            # rest_of_last_line is a delimiter such as , or [\n            current_line.append((\"text\", rest_of_last_line))\n            yield current_line\n            current_line = []\n        if re.match(r'\\s*\"', chunk):\n            if (\n                len(current_line) == 1\n                and current_line[0][0] == \"text\"\n                and current_line[0][1].isspace()\n            ):\n                current_line.append((\"Token_Name_Tag\", chunk))\n            else:\n                current_line.append((\"Token_Literal_String\", chunk))\n        elif re.match(r\"\\s*\\d\", chunk):\n            current_line.append((\"Token_Literal_Number\", chunk))\n        elif re.match(r\"\\s*(true|null|false)\", chunk):\n            current_line.append((\"Token_Keyword_Constant\", chunk))\n        else:\n            current_line.append((\"text\", chunk))\n    yield current_line\n\n\nclass ViewJSON(base.View):\n    name = \"JSON\"\n\n    def __call__(self, data, **metadata):\n        data = parse_json(data)\n        if data is not PARSE_ERROR:\n            return \"JSON\", format_json(data)\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        if not data:\n            return 0\n        if content_type in (\n            \"application/json\",\n            \"application/json-rpc\",\n        ):\n            return 1\n        if (\n            content_type\n            and content_type.startswith(\"application/\")\n            and content_type.endswith(\"+json\")\n        ):\n            return 1\n        return 0\n", "mitmproxy/contentviews/dns.py": "from mitmproxy.contentviews import base\nfrom mitmproxy.contentviews.json import format_json\nfrom mitmproxy.dns import Message\n\n\nclass ViewDns(base.View):\n    name = \"DNS-over-HTTPS\"\n\n    def __call__(self, data, **metadata):\n        try:\n            message = Message.unpack(data)\n        except Exception:\n            pass\n        else:\n            return \"DoH\", format_json(message.to_json())\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        return float(content_type == \"application/dns-message\")\n", "mitmproxy/contentviews/css.py": "import re\nimport time\n\nfrom mitmproxy.contentviews import base\nfrom mitmproxy.utils import strutils\n\n\"\"\"\nA custom CSS prettifier. Compared to other prettifiers, its main features are:\n\n- Implemented in pure Python.\n- Modifies whitespace only.\n- Works with any input.\n- Considerably faster than e.g. cssutils.\n\"\"\"\n\nCSS_SPECIAL_AREAS = (\n    \"'\" + strutils.SINGLELINE_CONTENT + strutils.NO_ESCAPE + \"'\",\n    '\"' + strutils.SINGLELINE_CONTENT + strutils.NO_ESCAPE + '\"',\n    r\"/\\*\" + strutils.MULTILINE_CONTENT + r\"\\*/\",\n    \"//\" + strutils.SINGLELINE_CONTENT + \"$\",\n)\nCSS_SPECIAL_CHARS = \"{};:\"\n\n\ndef beautify(data: str, indent: str = \"    \"):\n    \"\"\"Beautify a string containing CSS code\"\"\"\n    data = strutils.escape_special_areas(\n        data.strip(),\n        CSS_SPECIAL_AREAS,\n        CSS_SPECIAL_CHARS,\n    )\n\n    # Add newlines\n    data = re.sub(r\"\\s*;\\s*\", \";\\n\", data)\n    data = re.sub(r\"\\s*{\\s*\", \" {\\n\", data)\n    data = re.sub(r\"\\s*}\\s*\", \"\\n}\\n\\n\", data)\n\n    # Fix incorrect \":\" placement\n    data = re.sub(r\"\\s*:\\s*(?=[^{]+})\", \": \", data)\n    # Fix no space after \",\"\n    data = re.sub(r\"\\s*,\\s*\", \", \", data)\n\n    # indent\n    data = re.sub(\"\\n[ \\t]+\", \"\\n\", data)\n    data = re.sub(\"\\n(?![}\\n])(?=[^{]*})\", \"\\n\" + indent, data)\n\n    data = strutils.unescape_special_areas(data)\n    return data.rstrip(\"\\n\") + \"\\n\"\n\n\nclass ViewCSS(base.View):\n    name = \"CSS\"\n\n    def __call__(self, data, **metadata):\n        data = data.decode(\"utf8\", \"surrogateescape\")\n        beautified = beautify(data)\n        return \"CSS\", base.format_text(beautified)\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        return float(bool(data) and content_type == \"text/css\")\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    with open(\"../tools/web/static/vendor.css\") as f:\n        data = f.read()\n\n    t = time.time()\n    x = beautify(data)\n    print(f\"Beautifying vendor.css took {time.time() - t:.2}s\")\n", "mitmproxy/contentviews/xml_html.py": "import io\nimport re\nimport textwrap\nfrom collections.abc import Iterable\n\nfrom mitmproxy.contentviews import base\nfrom mitmproxy.utils import sliding_window\nfrom mitmproxy.utils import strutils\n\n\"\"\"\nA custom XML/HTML prettifier. Compared to other prettifiers, its main features are:\n\n- Implemented in pure Python.\n- Modifies whitespace only.\n- Works with any input.\n- Lazy evaluation.\n\nThe implementation is split into two main parts: tokenization and formatting of tokens.\n\"\"\"\n\n# http://www.xml.com/pub/a/2001/07/25/namingparts.html - this is close enough for what we do.\nREGEX_TAG = re.compile(r\"[a-zA-Z0-9._:\\-]+(?!=)\")\n# https://www.w3.org/TR/html5/syntax.html#void-elements\nHTML_VOID_ELEMENTS = {\n    \"area\",\n    \"base\",\n    \"br\",\n    \"col\",\n    \"embed\",\n    \"hr\",\n    \"img\",\n    \"input\",\n    \"keygen\",\n    \"link\",\n    \"meta\",\n    \"param\",\n    \"source\",\n    \"track\",\n    \"wbr\",\n}\nNO_INDENT_TAGS = {\"xml\", \"doctype\", \"html\"}\nINDENT = 2\n\n\nclass Token:\n    def __init__(self, data):\n        self.data = data\n\n    def __repr__(self):\n        return f\"{type(self).__name__}({self.data})\"\n\n\nclass Text(Token):\n    @property\n    def text(self):\n        return self.data.strip()\n\n\nclass Tag(Token):\n    @property\n    def tag(self):\n        t = REGEX_TAG.search(self.data)\n        if t is not None:\n            return t.group(0).lower()\n        return \"<empty>\"\n\n    @property\n    def is_comment(self) -> bool:\n        return self.data.startswith(\"<!--\")\n\n    @property\n    def is_cdata(self) -> bool:\n        return self.data.startswith(\"<![CDATA[\")\n\n    @property\n    def is_closing(self):\n        return self.data.startswith(\"</\")\n\n    @property\n    def is_self_closing(self):\n        return (\n            self.is_comment\n            or self.is_cdata\n            or self.data.endswith(\"/>\")\n            or self.tag in HTML_VOID_ELEMENTS\n        )\n\n    @property\n    def is_opening(self):\n        return not self.is_closing and not self.is_self_closing\n\n    @property\n    def done(self):\n        if self.is_comment:\n            return self.data.endswith(\"-->\")\n        elif self.is_cdata:\n            return self.data.endswith(\"]]>\")\n        else:\n            # This fails for attributes that contain an unescaped \">\"\n            return self.data.endswith(\">\")\n\n\ndef tokenize(data: str) -> Iterable[Token]:\n    token: Token = Text(\"\")\n\n    i = 0\n\n    def readuntil(char, start, include=1):\n        nonlocal i\n        end = data.find(char, start)\n        if end == -1:\n            end = len(data)\n        ret = data[i : end + include]\n        i = end + include\n        return ret\n\n    while i < len(data):\n        if isinstance(token, Text):\n            token.data = readuntil(\"<\", i, 0)\n            if token.text:\n                yield token\n            token = Tag(\"\")\n        elif isinstance(token, Tag):\n            token.data += readuntil(\">\", i, 1)\n            if token.done:\n                yield token\n                token = Text(\"\")\n    if token.data.strip():\n        yield token\n\n\ndef indent_text(data: str, prefix: str) -> str:\n    # Add spacing to first line so that we dedent in cases like this:\n    # <li>This is\n    #     example text\n    #     over multiple lines\n    # </li>\n    dedented = textwrap.dedent(\" \" * 32 + data).strip()\n    return textwrap.indent(dedented, prefix[:32])\n\n\ndef is_inline_text(a: Token | None, b: Token | None, c: Token | None) -> bool:\n    if isinstance(a, Tag) and isinstance(b, Text) and isinstance(c, Tag):\n        if a.is_opening and \"\\n\" not in b.data and c.is_closing and a.tag == c.tag:\n            return True\n    return False\n\n\ndef is_inline(\n    prev2: Token | None,\n    prev1: Token | None,\n    t: Token | None,\n    next1: Token | None,\n    next2: Token | None,\n) -> bool:\n    if isinstance(t, Text):\n        return is_inline_text(prev1, t, next1)\n    elif isinstance(t, Tag):\n        if is_inline_text(prev2, prev1, t) or is_inline_text(t, next1, next2):\n            return True\n        if (\n            isinstance(next1, Tag)\n            and t.is_opening\n            and next1.is_closing\n            and t.tag == next1.tag\n        ):\n            return True  # <div></div> (start tag)\n        if (\n            isinstance(prev1, Tag)\n            and prev1.is_opening\n            and t.is_closing\n            and prev1.tag == t.tag\n        ):\n            return True  # <div></div> (end tag)\n    return False\n\n\nclass ElementStack:\n    \"\"\"\n    Keep track of how deeply nested our document is.\n    \"\"\"\n\n    def __init__(self):\n        self.open_tags = []\n        self.indent = \"\"\n\n    def push_tag(self, tag: str):\n        if len(self.open_tags) > 16:\n            return\n        self.open_tags.append(tag)\n        if tag not in NO_INDENT_TAGS:\n            self.indent += \" \" * INDENT\n\n    def pop_tag(self, tag: str):\n        if tag in self.open_tags:\n            remove_indent = 0\n            while True:\n                t = self.open_tags.pop()\n                if t not in NO_INDENT_TAGS:\n                    remove_indent += INDENT\n                if t == tag:\n                    break\n            self.indent = self.indent[:-remove_indent]\n        else:\n            pass  # this closing tag has no start tag. let's keep indentation as-is.\n\n\ndef format_xml(tokens: Iterable[Token]) -> str:\n    out = io.StringIO()\n\n    context = ElementStack()\n\n    for prev2, prev1, token, next1, next2 in sliding_window.window(tokens, 2, 2):\n        if isinstance(token, Tag):\n            if token.is_opening:\n                out.write(indent_text(token.data, context.indent))\n\n                if not is_inline(prev2, prev1, token, next1, next2):\n                    out.write(\"\\n\")\n\n                context.push_tag(token.tag)\n            elif token.is_closing:\n                context.pop_tag(token.tag)\n\n                if is_inline(prev2, prev1, token, next1, next2):\n                    out.write(token.data)\n                else:\n                    out.write(indent_text(token.data, context.indent))\n                out.write(\"\\n\")\n\n            else:  # self-closing\n                out.write(indent_text(token.data, context.indent))\n                out.write(\"\\n\")\n        elif isinstance(token, Text):\n            if is_inline(prev2, prev1, token, next1, next2):\n                out.write(token.text)\n            else:\n                out.write(indent_text(token.data, context.indent))\n                out.write(\"\\n\")\n        else:  # pragma: no cover\n            raise RuntimeError()\n\n    return out.getvalue()\n\n\nclass ViewXmlHtml(base.View):\n    name = \"XML/HTML\"\n    __content_types = (\"text/xml\", \"text/html\")\n\n    def __call__(self, data, **metadata):\n        # TODO:\n        # We should really have the message text as str here,\n        # not the message content as bytes.\n        # https://github.com/mitmproxy/mitmproxy/issues/1662#issuecomment-266192578\n        data = data.decode(\"utf8\", \"xmlcharrefreplace\")\n        tokens = tokenize(data)\n        # TODO:\n        # Performance: Don't render the whole document right away.\n        # Let's wait with this until we have a sequence-like interface,\n        # this thing is reasonably fast right now anyway.\n        pretty = base.format_text(format_xml(tokens))\n        if \"html\" in data.lower():\n            t = \"HTML\"\n        else:\n            t = \"XML\"\n        return t, pretty\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        if not data:\n            return 0\n        if content_type in self.__content_types:\n            return 1\n        elif strutils.is_xml(data):\n            return 0.4\n        return 0\n", "mitmproxy/contentviews/msgpack.py": "from typing import Any\n\nimport msgpack\n\nfrom mitmproxy.contentviews import base\n\nPARSE_ERROR = object()\n\n\ndef parse_msgpack(s: bytes) -> Any:\n    try:\n        return msgpack.unpackb(s, raw=False)\n    except (ValueError, msgpack.ExtraData, msgpack.FormatError, msgpack.StackError):\n        return PARSE_ERROR\n\n\ndef format_msgpack(\n    data: Any, output=None, indent_count: int = 0\n) -> list[base.TViewLine]:\n    if output is None:\n        output = [[]]\n\n    indent = (\"text\", \"    \" * indent_count)\n\n    if isinstance(data, str):\n        token = [(\"Token_Literal_String\", f'\"{data}\"')]\n        output[-1] += token\n\n        # Need to return if single value, but return is discarded in dict/list loop\n        return output\n\n    elif isinstance(data, bool):\n        token = [(\"Token_Keyword_Constant\", repr(data))]\n        output[-1] += token\n\n        return output\n\n    elif isinstance(data, float | int):\n        token = [(\"Token_Literal_Number\", repr(data))]\n        output[-1] += token\n\n        return output\n\n    elif isinstance(data, dict):\n        output[-1] += [(\"text\", \"{\")]\n        for key in data:\n            output.append(\n                [\n                    indent,\n                    (\"text\", \"    \"),\n                    (\"Token_Name_Tag\", f'\"{key}\"'),\n                    (\"text\", \": \"),\n                ]\n            )\n            format_msgpack(data[key], output, indent_count + 1)\n\n            if key != list(data)[-1]:\n                output[-1] += [(\"text\", \",\")]\n\n        output.append([indent, (\"text\", \"}\")])\n\n        return output\n\n    elif isinstance(data, list):\n        output[-1] += [(\"text\", \"[\")]\n\n        for count, item in enumerate(data):\n            output.append([indent, (\"text\", \"    \")])\n            format_msgpack(item, output, indent_count + 1)\n            if count != len(data) - 1:\n                output[-1] += [(\"text\", \",\")]\n\n        output.append([indent, (\"text\", \"]\")])\n\n        return output\n\n    else:\n        token = [(\"text\", repr(data))]\n        output[-1] += token\n\n        return output\n\n\nclass ViewMsgPack(base.View):\n    name = \"MsgPack\"\n    __content_types = (\n        \"application/msgpack\",\n        \"application/x-msgpack\",\n    )\n\n    def __call__(self, data, **metadata):\n        data = parse_msgpack(data)\n        if data is not PARSE_ERROR:\n            return \"MsgPack\", format_msgpack(data)\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        return float(bool(data) and content_type in self.__content_types)\n", "mitmproxy/contentviews/__init__.py": "\"\"\"\nMitmproxy Content Views\n=======================\n\nmitmproxy includes a set of content views which can be used to\nformat/decode/highlight data. While they are mostly used for HTTP message\nbodies, the may be used in other contexts, e.g. to decode WebSocket messages.\n\nThus, the View API is very minimalistic. The only arguments are `data` and\n`**metadata`, where `data` is the actual content (as bytes). The contents on\nmetadata depend on the protocol in use. Known attributes can be found in\n`base.View`.\n\"\"\"\n\nimport traceback\n\nfrom ..tcp import TCPMessage\nfrom ..udp import UDPMessage\nfrom ..websocket import WebSocketMessage\nfrom . import auto\nfrom . import css\nfrom . import dns\nfrom . import graphql\nfrom . import grpc\nfrom . import hex\nfrom . import http3\nfrom . import image\nfrom . import javascript\nfrom . import json\nfrom . import mqtt\nfrom . import msgpack\nfrom . import multipart\nfrom . import protobuf\nfrom . import query\nfrom . import raw\nfrom . import urlencoded\nfrom . import wbxml\nfrom . import xml_html\nfrom .base import format_dict\nfrom .base import format_text\nfrom .base import KEY_MAX\nfrom .base import TViewResult\nfrom .base import View\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy import tcp\nfrom mitmproxy import udp\nfrom mitmproxy.utils import signals\nfrom mitmproxy.utils import strutils\n\nviews: list[View] = []\n\n\ndef _update(view: View) -> None: ...\n\n\non_add = signals.SyncSignal(_update)\n\"\"\"A new contentview has been added.\"\"\"\non_remove = signals.SyncSignal(_update)\n\"\"\"A contentview has been removed.\"\"\"\n\n\ndef get(name: str) -> View | None:\n    for i in views:\n        if i.name.lower() == name.lower():\n            return i\n    return None\n\n\ndef add(view: View) -> None:\n    # TODO: auto-select a different name (append an integer?)\n    for i in views:\n        if i.name == view.name:\n            raise ValueError(\"Duplicate view: \" + view.name)\n\n    views.append(view)\n    on_add.send(view)\n\n\ndef remove(view: View) -> None:\n    views.remove(view)\n    on_remove.send(view)\n\n\ndef safe_to_print(lines, encoding=\"utf8\"):\n    \"\"\"\n    Wraps a content generator so that each text portion is a *safe to print* unicode string.\n    \"\"\"\n    for line in lines:\n        clean_line = []\n        for style, text in line:\n            if isinstance(text, bytes):\n                text = text.decode(encoding, \"replace\")\n            text = strutils.escape_control_characters(text)\n            clean_line.append((style, text))\n        yield clean_line\n\n\ndef get_message_content_view(\n    viewname: str,\n    message: http.Message | TCPMessage | UDPMessage | WebSocketMessage,\n    flow: flow.Flow,\n):\n    \"\"\"\n    Like get_content_view, but also handles message encoding.\n    \"\"\"\n    viewmode = get(viewname)\n    if not viewmode:\n        viewmode = get(\"auto\")\n    assert viewmode\n\n    content: bytes | None\n    try:\n        content = message.content\n    except ValueError:\n        assert isinstance(message, http.Message)\n        content = message.raw_content\n        enc = \"[cannot decode]\"\n    else:\n        if isinstance(message, http.Message) and content != message.raw_content:\n            enc = \"[decoded {}]\".format(message.headers.get(\"content-encoding\"))\n        else:\n            enc = \"\"\n\n    if content is None:\n        return \"\", iter([[(\"error\", \"content missing\")]]), None\n\n    content_type = None\n    http_message = None\n    if isinstance(message, http.Message):\n        http_message = message\n        if ctype := message.headers.get(\"content-type\"):\n            if ct := http.parse_content_type(ctype):\n                content_type = f\"{ct[0]}/{ct[1]}\"\n\n    tcp_message = None\n    if isinstance(message, TCPMessage):\n        tcp_message = message\n\n    udp_message = None\n    if isinstance(message, UDPMessage):\n        udp_message = message\n\n    description, lines, error = get_content_view(\n        viewmode,\n        content,\n        content_type=content_type,\n        flow=flow,\n        http_message=http_message,\n        tcp_message=tcp_message,\n        udp_message=udp_message,\n    )\n\n    if enc:\n        description = f\"{enc} {description}\"\n\n    return description, lines, error\n\n\ndef get_content_view(\n    viewmode: View,\n    data: bytes,\n    *,\n    content_type: str | None = None,\n    flow: flow.Flow | None = None,\n    http_message: http.Message | None = None,\n    tcp_message: tcp.TCPMessage | None = None,\n    udp_message: udp.UDPMessage | None = None,\n):\n    \"\"\"\n    Args:\n        viewmode: the view to use.\n        data, **metadata: arguments passed to View instance.\n\n    Returns:\n        A (description, content generator, error) tuple.\n        If the content view raised an exception generating the view,\n        the exception is returned in error and the flow is formatted in raw mode.\n        In contrast to calling the views directly, text is always safe-to-print unicode.\n    \"\"\"\n    try:\n        ret = viewmode(\n            data,\n            content_type=content_type,\n            flow=flow,\n            http_message=http_message,\n            tcp_message=tcp_message,\n            udp_message=udp_message,\n        )\n        if ret is None:\n            ret = (\n                \"Couldn't parse: falling back to Raw\",\n                get(\"Raw\")(\n                    data,\n                    content_type=content_type,\n                    flow=flow,\n                    http_message=http_message,\n                    tcp_message=tcp_message,\n                    udp_message=udp_message,\n                )[1],\n            )\n        desc, content = ret\n        error = None\n    # Third-party viewers can fail in unexpected ways...\n    except Exception:\n        desc = \"Couldn't parse: falling back to Raw\"\n        raw = get(\"Raw\")\n        assert raw\n        content = raw(\n            data,\n            content_type=content_type,\n            flow=flow,\n            http_message=http_message,\n            tcp_message=tcp_message,\n            udp_message=udp_message,\n        )[1]\n        error = f\"{getattr(viewmode, 'name')} content viewer failed: \\n{traceback.format_exc()}\"\n\n    return desc, safe_to_print(content), error\n\n\n# The order in which ContentViews are added is important!\nadd(auto.ViewAuto())\nadd(raw.ViewRaw())\nadd(hex.ViewHexStream())\nadd(hex.ViewHexDump())\nadd(graphql.ViewGraphQL())\nadd(json.ViewJSON())\nadd(xml_html.ViewXmlHtml())\nadd(wbxml.ViewWBXML())\nadd(javascript.ViewJavaScript())\nadd(css.ViewCSS())\nadd(urlencoded.ViewURLEncoded())\nadd(multipart.ViewMultipart())\nadd(image.ViewImage())\nadd(query.ViewQuery())\nadd(protobuf.ViewProtobuf())\nadd(msgpack.ViewMsgPack())\nadd(grpc.ViewGrpcProtobuf())\nadd(mqtt.ViewMQTT())\nadd(http3.ViewHttp3())\nadd(dns.ViewDns())\n\n__all__ = [\n    \"View\",\n    \"KEY_MAX\",\n    \"format_text\",\n    \"format_dict\",\n    \"TViewResult\",\n    \"get\",\n    \"add\",\n    \"remove\",\n    \"get_content_view\",\n    \"get_message_content_view\",\n]\n", "mitmproxy/contentviews/image/image_parser.py": "import io\n\nfrom kaitaistruct import KaitaiStream\n\nfrom mitmproxy.contrib.kaitaistruct import gif\nfrom mitmproxy.contrib.kaitaistruct import ico\nfrom mitmproxy.contrib.kaitaistruct import jpeg\nfrom mitmproxy.contrib.kaitaistruct import png\n\nMetadata = list[tuple[str, str]]\n\n\ndef parse_png(data: bytes) -> Metadata:\n    img = png.Png(KaitaiStream(io.BytesIO(data)))\n    parts = [\n        (\"Format\", \"Portable network graphics\"),\n        (\"Size\", f\"{img.ihdr.width} x {img.ihdr.height} px\"),\n    ]\n    for chunk in img.chunks:\n        if chunk.type == \"gAMA\":\n            parts.append((\"gamma\", str(chunk.body.gamma_int / 100000)))\n        elif chunk.type == \"pHYs\":\n            aspectx = chunk.body.pixels_per_unit_x\n            aspecty = chunk.body.pixels_per_unit_y\n            parts.append((\"aspect\", f\"{aspectx} x {aspecty}\"))\n        elif chunk.type == \"tEXt\":\n            parts.append((chunk.body.keyword, chunk.body.text))\n        elif chunk.type == \"iTXt\":\n            parts.append((chunk.body.keyword, chunk.body.text))\n        elif chunk.type == \"zTXt\":\n            parts.append(\n                (chunk.body.keyword, chunk.body.text_datastream.decode(\"iso8859-1\"))\n            )\n    return parts\n\n\ndef parse_gif(data: bytes) -> Metadata:\n    img = gif.Gif(KaitaiStream(io.BytesIO(data)))\n    descriptor = img.logical_screen_descriptor\n    parts = [\n        (\"Format\", \"Compuserve GIF\"),\n        (\"Version\", f\"GIF{img.hdr.version}\"),\n        (\"Size\", f\"{descriptor.screen_width} x {descriptor.screen_height} px\"),\n        (\"background\", str(descriptor.bg_color_index)),\n    ]\n    ext_blocks = []\n    for block in img.blocks:\n        if block.block_type.name == \"extension\":\n            ext_blocks.append(block)\n    comment_blocks = []\n    for block in ext_blocks:\n        if block.body.label._name_ == \"comment\":\n            comment_blocks.append(block)\n    for block in comment_blocks:\n        entries = block.body.body.entries\n        for entry in entries:\n            comment = entry.bytes\n            if comment != b\"\":\n                parts.append((\"comment\", str(comment)))\n    return parts\n\n\ndef parse_jpeg(data: bytes) -> Metadata:\n    img = jpeg.Jpeg(KaitaiStream(io.BytesIO(data)))\n    parts = [(\"Format\", \"JPEG (ISO 10918)\")]\n    for segment in img.segments:\n        if segment.marker._name_ == \"sof0\":\n            parts.append(\n                (\"Size\", f\"{segment.data.image_width} x {segment.data.image_height} px\")\n            )\n        if segment.marker._name_ == \"app0\":\n            parts.append(\n                (\n                    \"jfif_version\",\n                    f\"({segment.data.version_major}, {segment.data.version_minor})\",\n                )\n            )\n            parts.append(\n                (\n                    \"jfif_density\",\n                    f\"({segment.data.density_x}, {segment.data.density_y})\",\n                )\n            )\n            parts.append((\"jfif_unit\", str(segment.data.density_units._value_)))\n        if segment.marker._name_ == \"com\":\n            parts.append((\"comment\", str(segment.data)))\n        if segment.marker._name_ == \"app1\":\n            if hasattr(segment.data, \"body\"):\n                for field in segment.data.body.data.body.ifd0.fields:\n                    if field.data is not None:\n                        parts.append(\n                            (field.tag._name_, field.data.decode(\"UTF-8\").strip(\"\\x00\"))\n                        )\n    return parts\n\n\ndef parse_ico(data: bytes) -> Metadata:\n    img = ico.Ico(KaitaiStream(io.BytesIO(data)))\n    parts = [\n        (\"Format\", \"ICO\"),\n        (\"Number of images\", str(img.num_images)),\n    ]\n\n    for i, image in enumerate(img.images):\n        parts.append(\n            (\n                f\"Image {i + 1}\",\n                \"Size: {} x {}\\n\" \"{: >18}Bits per pixel: {}\\n\" \"{: >18}PNG: {}\".format(\n                    256 if not image.width else image.width,\n                    256 if not image.height else image.height,\n                    \"\",\n                    image.bpp,\n                    \"\",\n                    image.is_png,\n                ),\n            )\n        )\n\n    return parts\n", "mitmproxy/contentviews/image/view.py": "from . import image_parser\nfrom mitmproxy.contentviews import base\nfrom mitmproxy.contrib import imghdr\nfrom mitmproxy.coretypes import multidict\n\n\ndef test_ico(h, f):\n    if h.startswith(b\"\\x00\\x00\\x01\\x00\"):\n        return \"ico\"\n\n\nimghdr.tests.append(test_ico)\n\n\nclass ViewImage(base.View):\n    name = \"Image\"\n\n    def __call__(self, data, **metadata):\n        image_type = imghdr.what(\"\", h=data)\n        if image_type == \"png\":\n            image_metadata = image_parser.parse_png(data)\n        elif image_type == \"gif\":\n            image_metadata = image_parser.parse_gif(data)\n        elif image_type == \"jpeg\":\n            image_metadata = image_parser.parse_jpeg(data)\n        elif image_type == \"ico\":\n            image_metadata = image_parser.parse_ico(data)\n        else:\n            image_metadata = [(\"Image Format\", image_type or \"unknown\")]\n        if image_type:\n            view_name = f\"{image_type.upper()} Image\"\n        else:\n            view_name = \"Unknown Image\"\n        return view_name, base.format_dict(multidict.MultiDict(image_metadata))\n\n    def render_priority(\n        self, data: bytes, *, content_type: str | None = None, **metadata\n    ) -> float:\n        return float(\n            bool(\n                content_type\n                and content_type.startswith(\"image/\")\n                and content_type != \"image/svg+xml\"\n            )\n        )\n", "mitmproxy/contentviews/image/__init__.py": "from .view import ViewImage\n\n__all__ = [\"ViewImage\"]\n", "mitmproxy/net/tls.py": "import os\nimport threading\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom enum import Enum\nfrom functools import lru_cache\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import BinaryIO\n\nimport certifi\nfrom OpenSSL import crypto\nfrom OpenSSL import SSL\nfrom OpenSSL.crypto import X509\n\nfrom mitmproxy import certs\n\n# Remove once pyOpenSSL 23.3.0 is released and bump version in pyproject.toml.\ntry:  # pragma: no cover\n    from OpenSSL.SSL import OP_LEGACY_SERVER_CONNECT  # type: ignore\nexcept ImportError:\n    OP_LEGACY_SERVER_CONNECT = 0x4\n\n\n# redeclared here for strict type checking\nclass Method(Enum):\n    TLS_SERVER_METHOD = SSL.TLS_SERVER_METHOD\n    TLS_CLIENT_METHOD = SSL.TLS_CLIENT_METHOD\n    # Type-pyopenssl does not know about these DTLS constants.\n    DTLS_SERVER_METHOD = SSL.DTLS_SERVER_METHOD  # type: ignore\n    DTLS_CLIENT_METHOD = SSL.DTLS_CLIENT_METHOD  # type: ignore\n\n\ntry:\n    SSL._lib.TLS_server_method  # type: ignore\nexcept AttributeError as e:  # pragma: no cover\n    raise RuntimeError(\n        \"Your installation of the cryptography Python package is outdated.\"\n    ) from e\n\n\nclass Version(Enum):\n    UNBOUNDED = 0\n    SSL3 = SSL.SSL3_VERSION\n    TLS1 = SSL.TLS1_VERSION\n    TLS1_1 = SSL.TLS1_1_VERSION\n    TLS1_2 = SSL.TLS1_2_VERSION\n    TLS1_3 = SSL.TLS1_3_VERSION\n\n\nclass Verify(Enum):\n    VERIFY_NONE = SSL.VERIFY_NONE\n    VERIFY_PEER = SSL.VERIFY_PEER\n\n\nDEFAULT_MIN_VERSION = Version.TLS1_2\nDEFAULT_MAX_VERSION = Version.UNBOUNDED\nDEFAULT_OPTIONS = SSL.OP_CIPHER_SERVER_PREFERENCE | SSL.OP_NO_COMPRESSION\n\n\nclass MasterSecretLogger:\n    def __init__(self, filename: Path):\n        self.filename = filename.expanduser()\n        self.f: BinaryIO | None = None\n        self.lock = threading.Lock()\n\n    # required for functools.wraps, which pyOpenSSL uses.\n    __name__ = \"MasterSecretLogger\"\n\n    def __call__(self, connection: SSL.Connection, keymaterial: bytes) -> None:\n        with self.lock:\n            if self.f is None:\n                self.filename.parent.mkdir(parents=True, exist_ok=True)\n                self.f = self.filename.open(\"ab\")\n                self.f.write(b\"\\n\")\n            self.f.write(keymaterial + b\"\\n\")\n            self.f.flush()\n\n    def close(self):\n        with self.lock:\n            if self.f is not None:\n                self.f.close()\n\n\ndef make_master_secret_logger(filename: str | None) -> MasterSecretLogger | None:\n    if filename:\n        return MasterSecretLogger(Path(filename))\n    return None\n\n\nlog_master_secret = make_master_secret_logger(\n    os.getenv(\"MITMPROXY_SSLKEYLOGFILE\") or os.getenv(\"SSLKEYLOGFILE\")\n)\n\n\ndef _create_ssl_context(\n    *,\n    method: Method,\n    min_version: Version,\n    max_version: Version,\n    cipher_list: Iterable[str] | None,\n    ecdh_curve: str | None,\n) -> SSL.Context:\n    context = SSL.Context(method.value)\n\n    ok = SSL._lib.SSL_CTX_set_min_proto_version(context._context, min_version.value)  # type: ignore\n    ok += SSL._lib.SSL_CTX_set_max_proto_version(context._context, max_version.value)  # type: ignore\n    if ok != 2:\n        raise RuntimeError(\n            f\"Error setting TLS versions ({min_version=}, {max_version=}). \"\n            \"The version you specified may be unavailable in your libssl.\"\n        )\n\n    # Options\n    context.set_options(DEFAULT_OPTIONS)\n\n    # ECDHE for Key exchange\n    if ecdh_curve is not None:\n        try:\n            context.set_tmp_ecdh(crypto.get_elliptic_curve(ecdh_curve))\n        except ValueError as e:\n            raise RuntimeError(f\"Elliptic curve specification error: {e}\") from e\n\n    # Cipher List\n    if cipher_list is not None:\n        try:\n            context.set_cipher_list(b\":\".join(x.encode() for x in cipher_list))\n        except SSL.Error as e:\n            raise RuntimeError(f\"SSL cipher specification error: {e}\") from e\n\n    # SSLKEYLOGFILE\n    if log_master_secret:\n        context.set_keylog_callback(log_master_secret)\n\n    return context\n\n\n@lru_cache(256)\ndef create_proxy_server_context(\n    *,\n    method: Method,\n    min_version: Version,\n    max_version: Version,\n    cipher_list: tuple[str, ...] | None,\n    ecdh_curve: str | None,\n    verify: Verify,\n    ca_path: str | None,\n    ca_pemfile: str | None,\n    client_cert: str | None,\n    legacy_server_connect: bool,\n) -> SSL.Context:\n    context: SSL.Context = _create_ssl_context(\n        method=method,\n        min_version=min_version,\n        max_version=max_version,\n        cipher_list=cipher_list,\n        ecdh_curve=ecdh_curve,\n    )\n    context.set_verify(verify.value, None)\n\n    if ca_path is None and ca_pemfile is None:\n        ca_pemfile = certifi.where()\n    try:\n        context.load_verify_locations(ca_pemfile, ca_path)\n    except SSL.Error as e:\n        raise RuntimeError(\n            f\"Cannot load trusted certificates ({ca_pemfile=}, {ca_path=}).\"\n        ) from e\n\n    # Client Certs\n    if client_cert:\n        try:\n            context.use_privatekey_file(client_cert)\n            context.use_certificate_chain_file(client_cert)\n        except SSL.Error as e:\n            raise RuntimeError(f\"Cannot load TLS client certificate: {e}\") from e\n\n    if legacy_server_connect:\n        context.set_options(OP_LEGACY_SERVER_CONNECT)\n\n    return context\n\n\n@lru_cache(256)\ndef create_client_proxy_context(\n    *,\n    method: Method,\n    min_version: Version,\n    max_version: Version,\n    cipher_list: tuple[str, ...] | None,\n    ecdh_curve: str | None,\n    chain_file: Path | None,\n    alpn_select_callback: Callable[[SSL.Connection, list[bytes]], Any] | None,\n    request_client_cert: bool,\n    extra_chain_certs: tuple[certs.Cert, ...],\n    dhparams: certs.DHParams,\n) -> SSL.Context:\n    context: SSL.Context = _create_ssl_context(\n        method=method,\n        min_version=min_version,\n        max_version=max_version,\n        cipher_list=cipher_list,\n        ecdh_curve=ecdh_curve,\n    )\n\n    if chain_file is not None:\n        try:\n            context.load_verify_locations(str(chain_file), None)\n        except SSL.Error as e:\n            raise RuntimeError(f\"Cannot load certificate chain ({chain_file}).\") from e\n\n    if alpn_select_callback is not None:\n        assert callable(alpn_select_callback)\n        context.set_alpn_select_callback(alpn_select_callback)\n\n    if request_client_cert:\n        # The request_client_cert argument requires some explanation. We're\n        # supposed to be able to do this with no negative effects - if the\n        # client has no cert to present, we're notified and proceed as usual.\n        # Unfortunately, Android seems to have a bug (tested on 4.2.2) - when\n        # an Android client is asked to present a certificate it does not\n        # have, it hangs up, which is frankly bogus. Some time down the track\n        # we may be able to make the proper behaviour the default again, but\n        # until then we're conservative.\n        context.set_verify(Verify.VERIFY_PEER.value, accept_all)\n    else:\n        context.set_verify(Verify.VERIFY_NONE.value, None)\n\n    for i in extra_chain_certs:\n        context.add_extra_chain_cert(i.to_pyopenssl())\n\n    if dhparams:\n        res = SSL._lib.SSL_CTX_set_tmp_dh(context._context, dhparams)  # type: ignore\n        SSL._openssl_assert(res == 1)  # type: ignore\n\n    return context\n\n\ndef accept_all(\n    conn_: SSL.Connection,\n    x509: X509,\n    errno: int,\n    err_depth: int,\n    is_cert_verified: int,\n) -> bool:\n    # Return true to prevent cert verification error\n    return True\n\n\ndef starts_like_tls_record(d: bytes) -> bool:\n    \"\"\"\n    Returns:\n        True, if the passed bytes could be the start of a TLS record\n        False, otherwise.\n    \"\"\"\n    # TLS ClientHello magic, works for SSLv3, TLSv1.0, TLSv1.1, TLSv1.2, and TLSv1.3\n    # http://www.moserware.com/2009/06/first-few-milliseconds-of-https.html#client-hello\n    # https://tls13.ulfheim.net/\n    # We assume that a client sending less than 3 bytes initially is not a TLS client.\n    return len(d) > 2 and d[0] == 0x16 and d[1] == 0x03 and 0x00 <= d[2] <= 0x03\n\n\ndef starts_like_dtls_record(d: bytes) -> bool:\n    \"\"\"\n    Returns:\n        True, if the passed bytes could be the start of a DTLS record\n        False, otherwise.\n    \"\"\"\n    # TLS ClientHello magic, works for DTLS 1.1, DTLS 1.2, and DTLS 1.3.\n    # https://www.rfc-editor.org/rfc/rfc4347#section-4.1\n    # https://www.rfc-editor.org/rfc/rfc6347#section-4.1\n    # https://www.rfc-editor.org/rfc/rfc9147#section-4-6.2\n    # We assume that a client sending less than 3 bytes initially is not a DTLS client.\n    return len(d) > 2 and d[0] == 0x16 and d[1] == 0xFE and 0xFD <= d[2] <= 0xFE\n", "mitmproxy/net/__init__.py": "", "mitmproxy/net/check.py": "import ipaddress\nimport re\nfrom typing import AnyStr\n\n# Allow underscore in host name\n# Note: This could be a DNS label, a hostname, a FQDN, or an IP\n\n_label_valid = re.compile(rb\"[A-Z\\d\\-_]{1,63}$\", re.IGNORECASE)\n\n\ndef is_valid_host(host: AnyStr) -> bool:\n    \"\"\"\n    Checks if the passed bytes are a valid DNS hostname or an IPv4/IPv6 address.\n    \"\"\"\n    if isinstance(host, str):\n        try:\n            host_bytes = host.encode(\"idna\")\n        except UnicodeError:\n            return False\n    else:\n        host_bytes = host\n    try:\n        host_bytes.decode(\"idna\")\n    except ValueError:\n        return False\n    # RFC1035: 255 bytes or less.\n    if len(host_bytes) > 255:\n        return False\n    if host_bytes and host_bytes.endswith(b\".\"):\n        host_bytes = host_bytes[:-1]\n    # DNS hostname\n    if all(_label_valid.match(x) for x in host_bytes.split(b\".\")):\n        return True\n    # IPv4/IPv6 address\n    try:\n        ipaddress.ip_address(host_bytes.decode(\"idna\"))\n        return True\n    except ValueError:\n        return False\n\n\ndef is_valid_port(port: int) -> bool:\n    return 0 <= port <= 65535\n", "mitmproxy/net/encoding.py": "\"\"\"\nUtility functions for decoding response bodies.\n\"\"\"\n\nimport codecs\nimport collections\nimport gzip\nimport zlib\nfrom io import BytesIO\nfrom typing import overload\n\nimport brotli\nimport zstandard as zstd\n\n# We have a shared single-element cache for encoding and decoding.\n# This is quite useful in practice, e.g.\n# flow.request.content = flow.request.content.replace(b\"foo\", b\"bar\")\n# does not require an .encode() call if content does not contain b\"foo\"\nCachedDecode = collections.namedtuple(\"CachedDecode\", \"encoded encoding errors decoded\")\n_cache = CachedDecode(None, None, None, None)\n\n\n@overload\ndef decode(encoded: None, encoding: str, errors: str = \"strict\") -> None: ...\n\n\n@overload\ndef decode(encoded: str, encoding: str, errors: str = \"strict\") -> str: ...\n\n\n@overload\ndef decode(encoded: bytes, encoding: str, errors: str = \"strict\") -> str | bytes: ...\n\n\ndef decode(\n    encoded: None | str | bytes, encoding: str, errors: str = \"strict\"\n) -> None | str | bytes:\n    \"\"\"\n    Decode the given input object\n\n    Returns:\n        The decoded value\n\n    Raises:\n        ValueError, if decoding fails.\n    \"\"\"\n    if encoded is None:\n        return None\n    encoding = encoding.lower()\n\n    global _cache\n    cached = (\n        isinstance(encoded, bytes)\n        and _cache.encoded == encoded\n        and _cache.encoding == encoding\n        and _cache.errors == errors\n    )\n    if cached:\n        return _cache.decoded\n    try:\n        try:\n            decoded = custom_decode[encoding](encoded)\n        except KeyError:\n            decoded = codecs.decode(encoded, encoding, errors)  # type: ignore\n        if encoding in (\"gzip\", \"deflate\", \"deflateraw\", \"br\", \"zstd\"):\n            _cache = CachedDecode(encoded, encoding, errors, decoded)\n        return decoded\n    except TypeError:\n        raise\n    except Exception as e:\n        raise ValueError(\n            \"{} when decoding {} with {}: {}\".format(\n                type(e).__name__,\n                repr(encoded)[:10],\n                repr(encoding),\n                repr(e),\n            )\n        )\n\n\n@overload\ndef encode(decoded: None, encoding: str, errors: str = \"strict\") -> None: ...\n\n\n@overload\ndef encode(decoded: str, encoding: str, errors: str = \"strict\") -> str | bytes: ...\n\n\n@overload\ndef encode(decoded: bytes, encoding: str, errors: str = \"strict\") -> bytes: ...\n\n\ndef encode(\n    decoded: None | str | bytes, encoding, errors=\"strict\"\n) -> None | str | bytes:\n    \"\"\"\n    Encode the given input object\n\n    Returns:\n        The encoded value\n\n    Raises:\n        ValueError, if encoding fails.\n    \"\"\"\n    if decoded is None:\n        return None\n    encoding = encoding.lower()\n\n    global _cache\n    cached = (\n        isinstance(decoded, bytes)\n        and _cache.decoded == decoded\n        and _cache.encoding == encoding\n        and _cache.errors == errors\n    )\n    if cached:\n        return _cache.encoded\n    try:\n        try:\n            encoded = custom_encode[encoding](decoded)\n        except KeyError:\n            encoded = codecs.encode(decoded, encoding, errors)  # type: ignore\n        if encoding in (\"gzip\", \"deflate\", \"deflateraw\", \"br\", \"zstd\"):\n            _cache = CachedDecode(encoded, encoding, errors, decoded)\n        return encoded\n    except TypeError:\n        raise\n    except Exception as e:\n        raise ValueError(\n            \"{} when encoding {} with {}: {}\".format(\n                type(e).__name__,\n                repr(decoded)[:10],\n                repr(encoding),\n                repr(e),\n            )\n        )\n\n\ndef identity(content):\n    \"\"\"\n    Returns content unchanged. Identity is the default value of\n    Accept-Encoding headers.\n    \"\"\"\n    return content\n\n\ndef decode_gzip(content: bytes) -> bytes:\n    if not content:\n        return b\"\"\n    gfile = gzip.GzipFile(fileobj=BytesIO(content))\n    return gfile.read()\n\n\ndef encode_gzip(content: bytes) -> bytes:\n    s = BytesIO()\n    # set mtime to 0 so that gzip encoding is deterministic.\n    gf = gzip.GzipFile(fileobj=s, mode=\"wb\", mtime=0)\n    gf.write(content)\n    gf.close()\n    return s.getvalue()\n\n\ndef decode_brotli(content: bytes) -> bytes:\n    if not content:\n        return b\"\"\n    return brotli.decompress(content)\n\n\ndef encode_brotli(content: bytes) -> bytes:\n    return brotli.compress(content)\n\n\ndef decode_zstd(content: bytes) -> bytes:\n    if not content:\n        return b\"\"\n    zstd_ctx = zstd.ZstdDecompressor()\n    return zstd_ctx.stream_reader(BytesIO(content), read_across_frames=True).read()\n\n\ndef encode_zstd(content: bytes) -> bytes:\n    zstd_ctx = zstd.ZstdCompressor()\n    return zstd_ctx.compress(content)\n\n\ndef decode_deflate(content: bytes) -> bytes:\n    \"\"\"\n    Returns decompressed data for DEFLATE. Some servers may respond with\n    compressed data without a zlib header or checksum. An undocumented\n    feature of zlib permits the lenient decompression of data missing both\n    values.\n\n    http://bugs.python.org/issue5784\n    \"\"\"\n    if not content:\n        return b\"\"\n    try:\n        return zlib.decompress(content)\n    except zlib.error:\n        return zlib.decompress(content, -15)\n\n\ndef encode_deflate(content: bytes) -> bytes:\n    \"\"\"\n    Returns compressed content, always including zlib header and checksum.\n    \"\"\"\n    return zlib.compress(content)\n\n\ncustom_decode = {\n    \"none\": identity,\n    \"identity\": identity,\n    \"gzip\": decode_gzip,\n    \"deflate\": decode_deflate,\n    \"deflateraw\": decode_deflate,\n    \"br\": decode_brotli,\n    \"zstd\": decode_zstd,\n}\ncustom_encode = {\n    \"none\": identity,\n    \"identity\": identity,\n    \"gzip\": encode_gzip,\n    \"deflate\": encode_deflate,\n    \"deflateraw\": encode_deflate,\n    \"br\": encode_brotli,\n    \"zstd\": encode_zstd,\n}\n\n__all__ = [\"encode\", \"decode\"]\n", "mitmproxy/net/local_ip.py": "from __future__ import annotations\n\nimport socket\n\n\ndef get_local_ip(reachable: str = \"8.8.8.8\") -> str | None:\n    \"\"\"\n    Get the default local outgoing IPv4 address without sending any packets.\n    This will fail if the target address is known to be unreachable.\n    We use Google DNS's IPv4 address as the default.\n    \"\"\"\n    # https://stackoverflow.com/questions/166506/finding-local-ip-addresses-using-pythons-stdlib\n    s = None\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        s.connect((reachable, 80))\n        return s.getsockname()[0]  # pragma: no cover\n    except OSError:\n        return None  # pragma: no cover\n    finally:\n        if s is not None:\n            s.close()\n\n\ndef get_local_ip6(reachable: str = \"2001:4860:4860::8888\") -> str | None:\n    \"\"\"\n    Get the default local outgoing IPv6 address without sending any packets.\n    This will fail if the target address is known to be unreachable.\n    We use Google DNS's IPv6 address as the default.\n    \"\"\"\n    s = None\n    try:\n        s = socket.socket(socket.AF_INET6, socket.SOCK_DGRAM)\n        s.connect((reachable, 80))\n        return s.getsockname()[0]  # pragma: no cover\n    except OSError:\n        return None  # pragma: no cover\n    finally:\n        if s is not None:\n            s.close()\n", "mitmproxy/net/server_spec.py": "\"\"\"\nServer specs are used to describe an upstream proxy or server.\n\"\"\"\n\nimport re\nfrom functools import cache\nfrom typing import Literal\n\nfrom mitmproxy.net import check\n\nServerSpec = tuple[\n    Literal[\"http\", \"https\", \"http3\", \"tls\", \"dtls\", \"tcp\", \"udp\", \"dns\", \"quic\"],\n    tuple[str, int],\n]\n\nserver_spec_re = re.compile(\n    r\"\"\"\n        ^\n        (?:(?P<scheme>\\w+)://)?  # scheme is optional\n        (?P<host>[^:/]+|\\[.+\\])  # hostname can be DNS name, IPv4, or IPv6 address.\n        (?::(?P<port>\\d+))?  #  port is optional\n        /?  #  we allow a trailing backslash, but no path\n        $\n        \"\"\",\n    re.VERBOSE,\n)\n\n\n@cache\ndef parse(server_spec: str, default_scheme: str) -> ServerSpec:\n    \"\"\"\n    Parses a server mode specification, e.g.:\n\n     - http://example.com/\n     - example.org\n     - example.com:443\n\n    *Raises:*\n     - ValueError, if the server specification is invalid.\n    \"\"\"\n    m = server_spec_re.match(server_spec)\n    if not m:\n        raise ValueError(f\"Invalid server specification: {server_spec}\")\n\n    if m.group(\"scheme\"):\n        scheme = m.group(\"scheme\")\n    else:\n        scheme = default_scheme\n    if scheme not in (\n        \"http\",\n        \"https\",\n        \"http3\",\n        \"tls\",\n        \"dtls\",\n        \"tcp\",\n        \"udp\",\n        \"dns\",\n        \"quic\",\n    ):\n        raise ValueError(f\"Invalid server scheme: {scheme}\")\n\n    host = m.group(\"host\")\n    # IPv6 brackets\n    if host.startswith(\"[\") and host.endswith(\"]\"):\n        host = host[1:-1]\n    if not check.is_valid_host(host):\n        raise ValueError(f\"Invalid hostname: {host}\")\n\n    if m.group(\"port\"):\n        port = int(m.group(\"port\"))\n    else:\n        try:\n            port = {\n                \"http\": 80,\n                \"https\": 443,\n                \"quic\": 443,\n                \"http3\": 443,\n                \"dns\": 53,\n            }[scheme]\n        except KeyError:\n            raise ValueError(f\"Port specification missing.\")\n    if not check.is_valid_port(port):\n        raise ValueError(f\"Invalid port: {port}\")\n\n    return scheme, (host, port)  # type: ignore\n", "mitmproxy/net/dns/domain_names.py": "import struct\nfrom typing import Optional\n\n_LABEL_SIZE = struct.Struct(\"!B\")\n_POINTER_OFFSET = struct.Struct(\"!H\")\n_POINTER_INDICATOR = 0b11000000\n\n\nCache = dict[int, Optional[tuple[str, int]]]\n\n\ndef cache() -> Cache:\n    return dict()\n\n\ndef _unpack_label_into(labels: list[str], buffer: bytes, offset: int) -> int:\n    (size,) = _LABEL_SIZE.unpack_from(buffer, offset)\n    if size >= 64:\n        raise struct.error(f\"unpack encountered a label of length {size}\")\n    elif size == 0:\n        return _LABEL_SIZE.size\n    else:\n        offset += _LABEL_SIZE.size\n        end_label = offset + size\n        if len(buffer) < end_label:\n            raise struct.error(f\"unpack requires a label buffer of {size} bytes\")\n        try:\n            labels.append(buffer[offset:end_label].decode(\"idna\"))\n        except UnicodeDecodeError:\n            raise struct.error(\n                f\"unpack encountered an illegal characters at offset {offset}\"\n            )\n        return _LABEL_SIZE.size + size\n\n\ndef unpack_from_with_compression(\n    buffer: bytes, offset: int, cache: Cache\n) -> tuple[str, int]:\n    if offset in cache:\n        result = cache[offset]\n        if result is None:\n            raise struct.error(f\"unpack encountered domain name loop\")\n    else:\n        cache[offset] = None  # this will indicate that the offset is being unpacked\n        start_offset = offset\n        labels = []\n        while True:\n            (size,) = _LABEL_SIZE.unpack_from(buffer, offset)\n            if size & _POINTER_INDICATOR == _POINTER_INDICATOR:\n                (pointer,) = _POINTER_OFFSET.unpack_from(buffer, offset)\n                offset += _POINTER_OFFSET.size\n                label, _ = unpack_from_with_compression(\n                    buffer, pointer & ~(_POINTER_INDICATOR << 8), cache\n                )\n                labels.append(label)\n                break\n            else:\n                offset += _unpack_label_into(labels, buffer, offset)\n                if size == 0:\n                    break\n        result = \".\".join(labels), (offset - start_offset)\n        cache[start_offset] = result\n    return result\n\n\ndef unpack_from(buffer: bytes, offset: int) -> tuple[str, int]:\n    \"\"\"Converts RDATA into a domain name without pointer compression from a given offset and also returns the binary size.\"\"\"\n    labels: list[str] = []\n    while True:\n        (size,) = _LABEL_SIZE.unpack_from(buffer, offset)\n        if size & _POINTER_INDICATOR == _POINTER_INDICATOR:\n            raise struct.error(\n                f\"unpack encountered a pointer which is not supported in RDATA\"\n            )\n        else:\n            offset += _unpack_label_into(labels, buffer, offset)\n            if size == 0:\n                break\n    return \".\".join(labels), offset\n\n\ndef unpack(buffer: bytes) -> str:\n    \"\"\"Converts RDATA into a domain name without pointer compression.\"\"\"\n    name, length = unpack_from(buffer, 0)\n    if length != len(buffer):\n        raise struct.error(f\"unpack requires a buffer of {length} bytes\")\n    return name\n\n\ndef pack(name: str) -> bytes:\n    \"\"\"Converts a domain name into RDATA without pointer compression.\"\"\"\n    buffer = bytearray()\n    if len(name) > 0:\n        for part in name.split(\".\"):\n            label = part.encode(\"idna\")\n            size = len(label)\n            if size == 0:\n                raise ValueError(f\"domain name '{name}' contains empty labels\")\n            if size >= 64:  # pragma: no cover\n                # encoding with 'idna' will already have raised an exception earlier\n                raise ValueError(\n                    f\"encoded label '{part}' of domain name '{name}' is too long ({size} bytes)\"\n                )\n            buffer.extend(_LABEL_SIZE.pack(size))\n            buffer.extend(label)\n    buffer.extend(_LABEL_SIZE.pack(0))\n    return bytes(buffer)\n", "mitmproxy/net/dns/https_records.py": "import enum\nimport struct\nfrom dataclasses import dataclass\n\nfrom . import domain_names\n\n\"\"\"\nHTTPS records are formatted as follows (as per RFC9460):\n- a 2-octet field for SvcPriority as an integer in network byte order.\n- the uncompressed, fully qualified TargetName, represented as a sequence of length-prefixed labels per Section 3.1 of [RFC1035].\n- the SvcParams, consuming the remainder of the record (so smaller than 65535 octets and constrained by the RDATA and DNS message sizes).\n\nWhen the list of SvcParams is non-empty, it contains a series of SvcParamKey=SvcParamValue pairs, represented as:\n- a 2-octet field containing the SvcParamKey as an integer in network byte order. (See Section 14.3.2 for the defined values.)\n- a 2-octet field containing the length of the SvcParamValue as an integer between 0 and 65535 in network byte order.\n- an octet string of this length whose contents are the SvcParamValue in a format determined by the SvcParamKey.\n\n    https://datatracker.ietf.org/doc/rfc9460/\n    https://datatracker.ietf.org/doc/rfc1035/\n\"\"\"\n\n\nclass SVCParamKeys(enum.Enum):\n    MANDATORY = 0\n    ALPN = 1\n    NO_DEFAULT_ALPN = 2\n    PORT = 3\n    IPV4HINT = 4\n    ECH = 5\n    IPV6HINT = 6\n\n\n@dataclass\nclass HTTPSRecord:\n    priority: int\n    target_name: str\n    params: dict[int, bytes]\n\n    def __repr__(self):\n        params = {}\n        for param_type, param_value in self.params.items():\n            try:\n                name = SVCParamKeys(param_type).name.lower()\n            except ValueError:\n                name = f\"key{param_type}\"\n            params[name] = param_value\n        return f\"priority: {self.priority} target_name: '{self.target_name}' {params}\"\n\n\ndef _unpack_params(data: bytes, offset: int) -> dict[int, bytes]:\n    \"\"\"Unpacks the service parameters from the given offset.\"\"\"\n    params = {}\n    while offset < len(data):\n        param_type = struct.unpack(\"!H\", data[offset : offset + 2])[0]\n        offset += 2\n        param_length = struct.unpack(\"!H\", data[offset : offset + 2])[0]\n        offset += 2\n        if offset + param_length > len(data):\n            raise struct.error(\n                \"unpack requires a buffer of %i bytes\" % (offset + param_length)\n            )\n        param_value = data[offset : offset + param_length]\n        offset += param_length\n        params[param_type] = param_value\n    return params\n\n\ndef unpack(data: bytes) -> HTTPSRecord:\n    \"\"\"\n    Unpacks HTTPS RDATA from byte data.\n\n    Raises:\n        struct.error if the record is malformed.\n    \"\"\"\n    offset = 0\n\n    # Priority (2 bytes)\n    priority = struct.unpack(\"!h\", data[offset : offset + 2])[0]\n    offset += 2\n\n    # TargetName (variable length)\n    target_name, offset = domain_names.unpack_from(data, offset)\n\n    # Service Parameters (remaining bytes)\n    params = _unpack_params(data, offset)\n\n    return HTTPSRecord(priority=priority, target_name=target_name, params=params)\n\n\ndef _pack_params(params: dict[int, bytes]) -> bytes:\n    \"\"\"Converts the service parameters into the raw byte format\"\"\"\n    buffer = bytearray()\n\n    for k, v in params.items():\n        buffer.extend(struct.pack(\"!H\", k))\n        buffer.extend(struct.pack(\"!H\", len(v)))\n        buffer.extend(v)\n\n    return bytes(buffer)\n\n\ndef pack(record: HTTPSRecord) -> bytes:\n    \"\"\"Packs the HTTPS record into its bytes form.\"\"\"\n    buffer = bytearray()\n    buffer.extend(struct.pack(\"!h\", record.priority))\n    buffer.extend(domain_names.pack(record.target_name))\n    buffer.extend(_pack_params(record.params))\n    return bytes(buffer)\n", "mitmproxy/net/dns/types.py": "A = 1\nNS = 2\nMD = 3\nMF = 4\nCNAME = 5\nSOA = 6\nMB = 7\nMG = 8\nMR = 9\nNULL = 10\nWKS = 11\nPTR = 12\nHINFO = 13\nMINFO = 14\nMX = 15\nTXT = 16\nRP = 17\nAFSDB = 18\nX25 = 19\nISDN = 20\nRT = 21\nNSAP = 22\nNSAP_PTR = 23\nSIG = 24\nKEY = 25\nPX = 26\nGPOS = 27\nAAAA = 28\nLOC = 29\nNXT = 30\nEID = 31\nNIMLOC = 32\nSRV = 33\nATMA = 34\nNAPTR = 35\nKX = 36\nCERT = 37\nA6 = 38\nDNAME = 39\nSINK = 40\nOPT = 41\nAPL = 42\nDS = 43\nSSHFP = 44\nIPSECKEY = 45\nRRSIG = 46\nNSEC = 47\nDNSKEY = 48\nDHCID = 49\nNSEC3 = 50\nNSEC3PARAM = 51\nTLSA = 52\nSMIMEA = 53\nHIP = 55\nNINFO = 56\nRKEY = 57\nTALINK = 58\nCDS = 59\nCDNSKEY = 60\nOPENPGPKEY = 61\nCSYNC = 62\nZONEMD = 63\nSVCB = 64\nHTTPS = 65\nSPF = 99\nUINFO = 100\nUID = 101\nGID = 102\nUNSPEC = 103\nNID = 104\nL32 = 105\nL64 = 106\nLP = 107\nEUI48 = 108\nEUI64 = 109\nTKEY = 249\nTSIG = 250\nIXFR = 251\nAXFR = 252\nMAILB = 253\nMAILA = 254\nANY = 255\nURI = 256\nCAA = 257\nAVC = 258\nDOA = 259\nAMTRELAY = 260\nTA = 32768\nDLV = 32769\n\n_STRINGS = {\n    A: \"A\",\n    NS: \"NS\",\n    MD: \"MD\",\n    MF: \"MF\",\n    CNAME: \"CNAME\",\n    SOA: \"SOA\",\n    MB: \"MB\",\n    MG: \"MG\",\n    MR: \"MR\",\n    NULL: \"NULL\",\n    WKS: \"WKS\",\n    PTR: \"PTR\",\n    HINFO: \"HINFO\",\n    MINFO: \"MINFO\",\n    MX: \"MX\",\n    TXT: \"TXT\",\n    RP: \"RP\",\n    AFSDB: \"AFSDB\",\n    X25: \"X25\",\n    ISDN: \"ISDN\",\n    RT: \"RT\",\n    NSAP: \"NSAP\",\n    NSAP_PTR: \"NSAP_PTR\",\n    SIG: \"SIG\",\n    KEY: \"KEY\",\n    PX: \"PX\",\n    GPOS: \"GPOS\",\n    AAAA: \"AAAA\",\n    LOC: \"LOC\",\n    NXT: \"NXT\",\n    EID: \"EID\",\n    NIMLOC: \"NIMLOC\",\n    SRV: \"SRV\",\n    ATMA: \"ATMA\",\n    NAPTR: \"NAPTR\",\n    KX: \"KX\",\n    CERT: \"CERT\",\n    A6: \"A6\",\n    DNAME: \"DNAME\",\n    SINK: \"SINK\",\n    OPT: \"OPT\",\n    APL: \"APL\",\n    DS: \"DS\",\n    SSHFP: \"SSHFP\",\n    IPSECKEY: \"IPSECKEY\",\n    RRSIG: \"RRSIG\",\n    NSEC: \"NSEC\",\n    DNSKEY: \"DNSKEY\",\n    DHCID: \"DHCID\",\n    NSEC3: \"NSEC3\",\n    NSEC3PARAM: \"NSEC3PARAM\",\n    TLSA: \"TLSA\",\n    SMIMEA: \"SMIMEA\",\n    HIP: \"HIP\",\n    NINFO: \"NINFO\",\n    RKEY: \"RKEY\",\n    TALINK: \"TALINK\",\n    CDS: \"CDS\",\n    CDNSKEY: \"CDNSKEY\",\n    OPENPGPKEY: \"OPENPGPKEY\",\n    CSYNC: \"CSYNC\",\n    ZONEMD: \"ZONEMD\",\n    SVCB: \"SVCB\",\n    HTTPS: \"HTTPS\",\n    SPF: \"SPF\",\n    UINFO: \"UINFO\",\n    UID: \"UID\",\n    GID: \"GID\",\n    UNSPEC: \"UNSPEC\",\n    NID: \"NID\",\n    L32: \"L32\",\n    L64: \"L64\",\n    LP: \"LP\",\n    EUI48: \"EUI48\",\n    EUI64: \"EUI64\",\n    TKEY: \"TKEY\",\n    TSIG: \"TSIG\",\n    IXFR: \"IXFR\",\n    AXFR: \"AXFR\",\n    MAILB: \"MAILB\",\n    MAILA: \"MAILA\",\n    ANY: \"ANY\",\n    URI: \"URI\",\n    CAA: \"CAA\",\n    AVC: \"AVC\",\n    DOA: \"DOA\",\n    AMTRELAY: \"AMTRELAY\",\n    TA: \"TA\",\n    DLV: \"DLV\",\n}\n\n\ndef to_str(type: int) -> str:\n    return _STRINGS.get(type, f\"TYPE({type})\")\n", "mitmproxy/net/dns/classes.py": "IN = 1\nCH = 3\nHS = 4\nNONE = 254\nANY = 255\n\n_STRINGS = {IN: \"IN\", CH: \"CH\", HS: \"HS\", NONE: \"NONE\", ANY: \"ANY\"}\n\n\ndef to_str(class_: int) -> str:\n    return _STRINGS.get(class_, f\"CLASS({class_})\")\n", "mitmproxy/net/dns/__init__.py": "", "mitmproxy/net/dns/op_codes.py": "QUERY = 0\nIQUERY = 1\nSTATUS = 2\nNOTIFY = 4\nUPDATE = 5\nDSO = 6\n\n_STRINGS = {\n    QUERY: \"QUERY\",\n    IQUERY: \"IQUERY\",\n    STATUS: \"STATUS\",\n    NOTIFY: \"NOTIFY\",\n    UPDATE: \"UPDATE\",\n    DSO: \"DSO\",\n}\n\n\ndef to_str(op_code: int) -> str:\n    return _STRINGS.get(op_code, f\"OPCODE({op_code})\")\n", "mitmproxy/net/dns/response_codes.py": "NOERROR = 0\nFORMERR = 1\nSERVFAIL = 2\nNXDOMAIN = 3\nNOTIMP = 4\nREFUSED = 5\nYXDOMAIN = 6\nYXRRSET = 7\nNXRRSET = 8\nNOTAUTH = 9\nNOTZONE = 10\nDSOTYPENI = 11\n\n_CODES = {\n    NOERROR: 200,\n    FORMERR: 400,\n    SERVFAIL: 500,\n    NXDOMAIN: 404,\n    NOTIMP: 501,\n    REFUSED: 403,\n    YXDOMAIN: 409,\n    YXRRSET: 409,\n    NXRRSET: 410,\n    NOTAUTH: 401,\n    NOTZONE: 404,\n    DSOTYPENI: 501,\n}\n\n_STRINGS = {\n    NOERROR: \"NOERROR\",\n    FORMERR: \"FORMERR\",\n    SERVFAIL: \"SERVFAIL\",\n    NXDOMAIN: \"NXDOMAIN\",\n    NOTIMP: \"NOTIMP\",\n    REFUSED: \"REFUSED\",\n    YXDOMAIN: \"YXDOMAIN\",\n    YXRRSET: \"YXRRSET\",\n    NXRRSET: \"NXRRSET\",\n    NOTAUTH: \"NOTAUTH\",\n    NOTZONE: \"NOTZONE\",\n    DSOTYPENI: \"DSOTYPENI\",\n}\n\n\ndef http_equiv_status_code(response_code: int) -> int:\n    return _CODES.get(response_code, 500)\n\n\ndef to_str(response_code: int) -> str:\n    return _STRINGS.get(response_code, f\"RCODE({response_code})\")\n", "mitmproxy/net/http/multipart.py": "from __future__ import annotations\n\nimport mimetypes\nimport re\nimport warnings\nfrom urllib.parse import quote\n\nfrom mitmproxy.net.http import headers\n\n\ndef encode_multipart(content_type: str, parts: list[tuple[bytes, bytes]]) -> bytes:\n    if content_type:\n        ct = headers.parse_content_type(content_type)\n        if ct is not None:\n            try:\n                raw_boundary = ct[2][\"boundary\"].encode(\"ascii\")\n                boundary = quote(raw_boundary)\n            except (KeyError, UnicodeError):\n                return b\"\"\n            hdrs = []\n            for key, value in parts:\n                file_type = (\n                    mimetypes.guess_type(str(key))[0] or \"text/plain; charset=utf-8\"\n                )\n\n                if key:\n                    hdrs.append(b\"--%b\" % boundary.encode(\"utf-8\"))\n                    disposition = b'form-data; name=\"%b\"' % key\n                    hdrs.append(b\"Content-Disposition: %b\" % disposition)\n                    hdrs.append(b\"Content-Type: %b\" % file_type.encode(\"utf-8\"))\n                    hdrs.append(b\"\")\n                    hdrs.append(value)\n                hdrs.append(b\"\")\n\n                if value is not None:\n                    # If boundary is found in value then raise ValueError\n                    if re.search(\n                        rb\"^--%b$\" % re.escape(boundary.encode(\"utf-8\")), value\n                    ):\n                        raise ValueError(b\"boundary found in encoded string\")\n\n            hdrs.append(b\"--%b--\\r\\n\" % boundary.encode(\"utf-8\"))\n            temp = b\"\\r\\n\".join(hdrs)\n            return temp\n    return b\"\"\n\n\ndef decode_multipart(\n    content_type: str | None, content: bytes\n) -> list[tuple[bytes, bytes]]:\n    \"\"\"\n    Takes a multipart boundary encoded string and returns list of (key, value) tuples.\n    \"\"\"\n    if content_type:\n        ct = headers.parse_content_type(content_type)\n        if not ct:\n            return []\n        try:\n            boundary = ct[2][\"boundary\"].encode(\"ascii\")\n        except (KeyError, UnicodeError):\n            return []\n\n        rx = re.compile(rb'\\bname=\"([^\"]+)\"')\n        r = []\n        if content is not None:\n            for i in content.split(b\"--\" + boundary):\n                parts = i.splitlines()\n                if len(parts) > 1 and parts[0][0:2] != b\"--\":\n                    match = rx.search(parts[1])\n                    if match:\n                        key = match.group(1)\n                        value = b\"\".join(parts[3 + parts[2:].index(b\"\") :])\n                        r.append((key, value))\n        return r\n    return []\n\n\ndef encode(ct, parts):  # pragma: no cover\n    # 2023-02\n    warnings.warn(\n        \"multipart.encode is deprecated, use multipart.encode_multipart instead.\",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    return encode_multipart(ct, parts)\n\n\ndef decode(ct, content):  # pragma: no cover\n    # 2023-02\n    warnings.warn(\n        \"multipart.decode is deprecated, use multipart.decode_multipart instead.\",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    return encode_multipart(ct, content)\n", "mitmproxy/net/http/status_codes.py": "CONTINUE = 100\nSWITCHING = 101\nPROCESSING = 102\nEARLY_HINTS = 103\n\nOK = 200\nCREATED = 201\nACCEPTED = 202\nNON_AUTHORITATIVE_INFORMATION = 203\nNO_CONTENT = 204\nRESET_CONTENT = 205\nPARTIAL_CONTENT = 206\nMULTI_STATUS = 207\n\nMULTIPLE_CHOICE = 300\nMOVED_PERMANENTLY = 301\nFOUND = 302\nSEE_OTHER = 303\nNOT_MODIFIED = 304\nUSE_PROXY = 305\nTEMPORARY_REDIRECT = 307\n\nBAD_REQUEST = 400\nUNAUTHORIZED = 401\nPAYMENT_REQUIRED = 402\nFORBIDDEN = 403\nNOT_FOUND = 404\nNOT_ALLOWED = 405\nNOT_ACCEPTABLE = 406\nPROXY_AUTH_REQUIRED = 407\nREQUEST_TIMEOUT = 408\nCONFLICT = 409\nGONE = 410\nLENGTH_REQUIRED = 411\nPRECONDITION_FAILED = 412\nPAYLOAD_TOO_LARGE = 413\nREQUEST_URI_TOO_LONG = 414\nUNSUPPORTED_MEDIA_TYPE = 415\nREQUESTED_RANGE_NOT_SATISFIABLE = 416\nEXPECTATION_FAILED = 417\nIM_A_TEAPOT = 418\nNO_RESPONSE = 444\nCLIENT_CLOSED_REQUEST = 499\n\nINTERNAL_SERVER_ERROR = 500\nNOT_IMPLEMENTED = 501\nBAD_GATEWAY = 502\nSERVICE_UNAVAILABLE = 503\nGATEWAY_TIMEOUT = 504\nHTTP_VERSION_NOT_SUPPORTED = 505\nINSUFFICIENT_STORAGE_SPACE = 507\nNOT_EXTENDED = 510\n\nRESPONSES = {\n    # 100\n    CONTINUE: \"Continue\",\n    SWITCHING: \"Switching Protocols\",\n    PROCESSING: \"Processing\",\n    EARLY_HINTS: \"Early Hints\",\n    # 200\n    OK: \"OK\",\n    CREATED: \"Created\",\n    ACCEPTED: \"Accepted\",\n    NON_AUTHORITATIVE_INFORMATION: \"Non-Authoritative Information\",\n    NO_CONTENT: \"No Content\",\n    RESET_CONTENT: \"Reset Content.\",\n    PARTIAL_CONTENT: \"Partial Content\",\n    MULTI_STATUS: \"Multi-Status\",\n    # 300\n    MULTIPLE_CHOICE: \"Multiple Choices\",\n    MOVED_PERMANENTLY: \"Moved Permanently\",\n    FOUND: \"Found\",\n    SEE_OTHER: \"See Other\",\n    NOT_MODIFIED: \"Not Modified\",\n    USE_PROXY: \"Use Proxy\",\n    # 306 not defined??\n    TEMPORARY_REDIRECT: \"Temporary Redirect\",\n    # 400\n    BAD_REQUEST: \"Bad Request\",\n    UNAUTHORIZED: \"Unauthorized\",\n    PAYMENT_REQUIRED: \"Payment Required\",\n    FORBIDDEN: \"Forbidden\",\n    NOT_FOUND: \"Not Found\",\n    NOT_ALLOWED: \"Method Not Allowed\",\n    NOT_ACCEPTABLE: \"Not Acceptable\",\n    PROXY_AUTH_REQUIRED: \"Proxy Authentication Required\",\n    REQUEST_TIMEOUT: \"Request Time-out\",\n    CONFLICT: \"Conflict\",\n    GONE: \"Gone\",\n    LENGTH_REQUIRED: \"Length Required\",\n    PRECONDITION_FAILED: \"Precondition Failed\",\n    PAYLOAD_TOO_LARGE: \"Payload Too Large\",\n    REQUEST_URI_TOO_LONG: \"Request-URI Too Long\",\n    UNSUPPORTED_MEDIA_TYPE: \"Unsupported Media Type\",\n    REQUESTED_RANGE_NOT_SATISFIABLE: \"Requested Range not satisfiable\",\n    EXPECTATION_FAILED: \"Expectation Failed\",\n    IM_A_TEAPOT: \"I'm a teapot\",\n    NO_RESPONSE: \"No Response\",\n    CLIENT_CLOSED_REQUEST: \"Client Closed Request\",\n    # 500\n    INTERNAL_SERVER_ERROR: \"Internal Server Error\",\n    NOT_IMPLEMENTED: \"Not Implemented\",\n    BAD_GATEWAY: \"Bad Gateway\",\n    SERVICE_UNAVAILABLE: \"Service Unavailable\",\n    GATEWAY_TIMEOUT: \"Gateway Time-out\",\n    HTTP_VERSION_NOT_SUPPORTED: \"HTTP Version not supported\",\n    INSUFFICIENT_STORAGE_SPACE: \"Insufficient Storage Space\",\n    NOT_EXTENDED: \"Not Extended\",\n}\n", "mitmproxy/net/http/user_agents.py": "\"\"\"\nA small collection of useful user-agent header strings. These should be\nkept reasonably current to reflect common usage.\n\"\"\"\n# pylint: line-too-long\n# A collection of (name, shortcut, string) tuples.\n\nUASTRINGS = [\n    (\n        \"android\",\n        \"a\",\n        \"Mozilla/5.0 (Linux; U; Android 4.1.1; en-gb; Nexus 7 Build/JRO03D) AFL/01.04.02\",\n    ),\n    (\n        \"blackberry\",\n        \"l\",\n        \"Mozilla/5.0 (BlackBerry; U; BlackBerry 9900; en) AppleWebKit/534.11+ (KHTML, like Gecko) Version/7.1.0.346 Mobile Safari/534.11+\",\n    ),\n    (\n        \"bingbot\",\n        \"b\",\n        \"Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)\",\n    ),\n    (\n        \"chrome\",\n        \"c\",\n        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\",\n    ),\n    (\n        \"firefox\",\n        \"f\",\n        \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:14.0) Gecko/20120405 Firefox/14.0a1\",\n    ),\n    (\"googlebot\", \"g\", \"Googlebot/2.1 (+http://www.googlebot.com/bot.html)\"),\n    (\"ie9\", \"i\", \"Mozilla/5.0 (Windows; U; MSIE 9.0; WIndows NT 9.0; en-US)\"),\n    (\n        \"ipad\",\n        \"p\",\n        \"Mozilla/5.0 (iPad; CPU OS 5_1 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9B176 Safari/7534.48.3\",\n    ),\n    (\n        \"iphone\",\n        \"h\",\n        \"Mozilla/5.0 (iPhone; CPU iPhone OS 4_2_1 like Mac OS X) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8C148a Safari/6533.18.5\",  # noqa\n    ),\n    (\n        \"safari\",\n        \"s\",\n        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/534.55.3 (KHTML, like Gecko) Version/5.1.3 Safari/534.53.10\",\n    ),\n]\n\n\ndef get_by_shortcut(s):\n    \"\"\"\n    Retrieve a user agent entry by shortcut.\n    \"\"\"\n    for i in UASTRINGS:\n        if s == i[1]:\n            return i\n", "mitmproxy/net/http/headers.py": "import collections\nimport re\n\n\ndef parse_content_type(c: str) -> tuple[str, str, dict[str, str]] | None:\n    \"\"\"\n    A simple parser for content-type values. Returns a (type, subtype,\n    parameters) tuple, where type and subtype are strings, and parameters\n    is a dict. If the string could not be parsed, return None.\n\n    E.g. the following string:\n\n        text/html; charset=UTF-8\n\n    Returns:\n\n        (\"text\", \"html\", {\"charset\": \"UTF-8\"})\n    \"\"\"\n    parts = c.split(\";\", 1)\n    ts = parts[0].split(\"/\", 1)\n    if len(ts) != 2:\n        return None\n    d = collections.OrderedDict()\n    if len(parts) == 2:\n        for i in parts[1].split(\";\"):\n            clause = i.split(\"=\", 1)\n            if len(clause) == 2:\n                d[clause[0].strip()] = clause[1].strip()\n    return ts[0].lower(), ts[1].lower(), d\n\n\ndef assemble_content_type(type, subtype, parameters):\n    if not parameters:\n        return f\"{type}/{subtype}\"\n    params = \"; \".join(f\"{k}={v}\" for k, v in parameters.items())\n    return f\"{type}/{subtype}; {params}\"\n\n\ndef infer_content_encoding(content_type: str, content: bytes = b\"\") -> str:\n    \"\"\"\n    Infer the encoding of content from the content-type header.\n    \"\"\"\n    # Use the charset from the header if possible\n    parsed_content_type = parse_content_type(content_type)\n    enc = parsed_content_type[2].get(\"charset\") if parsed_content_type else None\n\n    # Otherwise, infer the encoding\n    if not enc and \"json\" in content_type:\n        enc = \"utf8\"\n\n    if not enc and \"html\" in content_type:\n        meta_charset = re.search(\n            rb\"\"\"<meta[^>]+charset=['\"]?([^'\">]+)\"\"\", content, re.IGNORECASE\n        )\n        if meta_charset:\n            enc = meta_charset.group(1).decode(\"ascii\", \"ignore\")\n\n    if not enc and \"text/css\" in content_type:\n        # @charset rule must be the very first thing.\n        css_charset = re.match(rb\"\"\"@charset \"([^\"]+)\";\"\"\", content, re.IGNORECASE)\n        if css_charset:\n            enc = css_charset.group(1).decode(\"ascii\", \"ignore\")\n\n    # Fallback to latin-1\n    if not enc:\n        enc = \"latin-1\"\n\n    # Use GB 18030 as the superset of GB2312 and GBK to fix common encoding problems on Chinese websites.\n    if enc.lower() in (\"gb2312\", \"gbk\"):\n        enc = \"gb18030\"\n\n    return enc\n", "mitmproxy/net/http/url.py": "from __future__ import annotations\n\nimport re\nimport urllib.parse\nfrom collections.abc import Sequence\nfrom typing import AnyStr\n\nfrom mitmproxy.net import check\nfrom mitmproxy.net.check import is_valid_host\nfrom mitmproxy.net.check import is_valid_port\nfrom mitmproxy.utils.strutils import always_str\n\n# This regex extracts & splits the host header into host and port.\n# Handles the edge case of IPv6 addresses containing colons.\n# https://bugzilla.mozilla.org/show_bug.cgi?id=45891\n\n_authority_re = re.compile(r\"^(?P<host>[^:]+|\\[.+\\])(?::(?P<port>\\d+))?$\")\n\n\ndef parse(url):\n    \"\"\"\n    URL-parsing function that checks that\n        - port is an integer 0-65535\n        - host is a valid IDNA-encoded hostname with no null-bytes\n        - path is valid ASCII\n\n    Args:\n        A URL (as bytes or as unicode)\n\n    Returns:\n        A (scheme, host, port, path) tuple\n\n    Raises:\n        ValueError, if the URL is not properly formatted.\n    \"\"\"\n    # FIXME: We shouldn't rely on urllib here.\n\n    # Size of Ascii character after encoding is 1 byte which is same as its size\n    # But non-Ascii character's size after encoding will be more than its size\n    def ascii_check(x):\n        if len(x) == len(str(x).encode()):\n            return True\n        return False\n\n    if isinstance(url, bytes):\n        url = url.decode()\n        if not ascii_check(url):\n            url = urllib.parse.urlsplit(url)\n            url = list(url)\n            url[3] = urllib.parse.quote(url[3])\n            url = urllib.parse.urlunsplit(url)\n\n    parsed = urllib.parse.urlparse(url)\n    if not parsed.hostname:\n        raise ValueError(\"No hostname given\")\n\n    else:\n        host = parsed.hostname.encode(\"idna\")\n        if isinstance(parsed, urllib.parse.ParseResult):\n            parsed = parsed.encode(\"ascii\")\n\n    port = parsed.port\n    if not port:\n        port = 443 if parsed.scheme == b\"https\" else 80\n\n    full_path = urllib.parse.urlunparse(\n        (b\"\", b\"\", parsed.path, parsed.params, parsed.query, parsed.fragment)\n    )\n    if not full_path.startswith(b\"/\"):\n        full_path = b\"/\" + full_path\n\n    if not check.is_valid_host(host):\n        raise ValueError(\"Invalid Host\")\n\n    return parsed.scheme, host, port, full_path\n\n\ndef unparse(scheme: str, host: str, port: int, path: str = \"\") -> str:\n    \"\"\"\n    Returns a URL string, constructed from the specified components.\n\n    Args:\n        All args must be str.\n    \"\"\"\n    if path == \"*\":\n        path = \"\"\n    authority = hostport(scheme, host, port)\n    return f\"{scheme}://{authority}{path}\"\n\n\ndef encode(s: Sequence[tuple[str, str]], similar_to: str | None = None) -> str:\n    \"\"\"\n    Takes a list of (key, value) tuples and returns a urlencoded string.\n    If similar_to is passed, the output is formatted similar to the provided urlencoded string.\n    \"\"\"\n\n    remove_trailing_equal = False\n    if similar_to:\n        remove_trailing_equal = any(\"=\" not in param for param in similar_to.split(\"&\"))\n\n    encoded = urllib.parse.urlencode(s, False, errors=\"surrogateescape\")\n\n    if encoded and remove_trailing_equal:\n        encoded = encoded.replace(\"=&\", \"&\")\n        if encoded[-1] == \"=\":\n            encoded = encoded[:-1]\n\n    return encoded\n\n\ndef decode(s):\n    \"\"\"\n    Takes a urlencoded string and returns a list of surrogate-escaped (key, value) tuples.\n    \"\"\"\n    return urllib.parse.parse_qsl(s, keep_blank_values=True, errors=\"surrogateescape\")\n\n\ndef quote(b: str, safe: str = \"/\") -> str:\n    \"\"\"\n    Returns:\n        An ascii-encodable str.\n    \"\"\"\n    return urllib.parse.quote(b, safe=safe, errors=\"surrogateescape\")\n\n\ndef unquote(s: str) -> str:\n    \"\"\"\n    Args:\n        s: A surrogate-escaped str\n    Returns:\n        A surrogate-escaped str\n    \"\"\"\n    return urllib.parse.unquote(s, errors=\"surrogateescape\")\n\n\ndef hostport(scheme: AnyStr, host: AnyStr, port: int) -> AnyStr:\n    \"\"\"\n    Returns the host component, with a port specification if needed.\n    \"\"\"\n    if default_port(scheme) == port:\n        return host\n    else:\n        if isinstance(host, bytes):\n            return b\"%s:%d\" % (host, port)\n        else:\n            return \"%s:%d\" % (host, port)\n\n\ndef default_port(scheme: AnyStr) -> int | None:\n    return {\n        \"http\": 80,\n        b\"http\": 80,\n        \"https\": 443,\n        b\"https\": 443,\n    }.get(scheme, None)\n\n\ndef parse_authority(authority: AnyStr, check: bool) -> tuple[str, int | None]:\n    \"\"\"Extract the host and port from host header/authority information\n\n    Raises:\n        ValueError, if check is True and the authority information is malformed.\n    \"\"\"\n    try:\n        if isinstance(authority, bytes):\n            m = _authority_re.match(authority.decode(\"utf-8\"))\n            if not m:\n                raise ValueError\n            host = m[\"host\"].encode(\"utf-8\").decode(\"idna\")\n        else:\n            m = _authority_re.match(authority)\n            if not m:\n                raise ValueError\n            host = m.group(\"host\")\n\n        if host.startswith(\"[\") and host.endswith(\"]\"):\n            host = host[1:-1]\n        if not is_valid_host(host):\n            raise ValueError\n\n        if m.group(\"port\"):\n            port = int(m.group(\"port\"))\n            if not is_valid_port(port):\n                raise ValueError\n            return host, port\n        else:\n            return host, None\n\n    except ValueError:\n        if check:\n            raise\n        else:\n            return always_str(authority, \"utf-8\", \"surrogateescape\"), None\n", "mitmproxy/net/http/__init__.py": "", "mitmproxy/net/http/cookies.py": "import email.utils\nimport re\nimport time\nfrom collections.abc import Iterable\n\nfrom mitmproxy.coretypes import multidict\n\n\"\"\"\nA flexible module for cookie parsing and manipulation.\n\nThis module differs from usual standards-compliant cookie modules in a number\nof ways. We try to be as permissive as possible, and to retain even mal-formed\ninformation. Duplicate cookies are preserved in parsing, and can be set in\nformatting. We do attempt to escape and quote values where needed, but will not\nreject data that violate the specs.\n\nParsing accepts the formats in RFC6265 and partially RFC2109 and RFC2965. We\nalso parse the comma-separated variant of Set-Cookie that allows multiple\ncookies to be set in a single header. Serialization follows RFC6265.\n\n    http://tools.ietf.org/html/rfc6265\n    http://tools.ietf.org/html/rfc2109\n    http://tools.ietf.org/html/rfc2965\n\"\"\"\n\n_cookie_params = {\n    \"expires\",\n    \"path\",\n    \"comment\",\n    \"max-age\",\n    \"secure\",\n    \"httponly\",\n    \"version\",\n}\n\nESCAPE = re.compile(r\"([\\\"\\\\])\")\n\n\nclass CookieAttrs(multidict.MultiDict):\n    @staticmethod\n    def _kconv(key):\n        return key.lower()\n\n    @staticmethod\n    def _reduce_values(values):\n        # See the StickyCookieTest for a weird cookie that only makes sense\n        # if we take the last part.\n        return values[-1]\n\n\nTSetCookie = tuple[str, str | None, CookieAttrs]\nTPairs = list[tuple[str, str | None]]\n\n\ndef _read_until(s, start, term):\n    \"\"\"\n    Read until one of the characters in term is reached.\n    \"\"\"\n    if start == len(s):\n        return \"\", start + 1\n    for i in range(start, len(s)):\n        if s[i] in term:\n            return s[start:i], i\n    return s[start : i + 1], i + 1\n\n\ndef _read_quoted_string(s, start):\n    \"\"\"\n    start: offset to the first quote of the string to be read\n\n    A sort of loose super-set of the various quoted string specifications.\n\n    RFC6265 disallows backslashes or double quotes within quoted strings.\n    Prior RFCs use backslashes to escape. This leaves us free to apply\n    backslash escaping by default and be compatible with everything.\n    \"\"\"\n    escaping = False\n    ret = []\n    # Skip the first quote\n    i = start  # initialize in case the loop doesn't run.\n    for i in range(start + 1, len(s)):\n        if escaping:\n            ret.append(s[i])\n            escaping = False\n        elif s[i] == '\"':\n            break\n        elif s[i] == \"\\\\\":\n            escaping = True\n        else:\n            ret.append(s[i])\n    return \"\".join(ret), i + 1\n\n\ndef _read_key(s, start, delims=\";=\"):\n    \"\"\"\n    Read a key - the LHS of a token/value pair in a cookie.\n    \"\"\"\n    return _read_until(s, start, delims)\n\n\ndef _read_value(s, start, delims):\n    \"\"\"\n    Reads a value - the RHS of a token/value pair in a cookie.\n    \"\"\"\n    if start >= len(s):\n        return \"\", start\n    elif s[start] == '\"':\n        return _read_quoted_string(s, start)\n    else:\n        return _read_until(s, start, delims)\n\n\ndef _read_cookie_pairs(s, off=0):\n    \"\"\"\n    Read pairs of lhs=rhs values from Cookie headers.\n\n    off: start offset\n    \"\"\"\n    pairs = []\n\n    while True:\n        lhs, off = _read_key(s, off)\n        lhs = lhs.lstrip()\n\n        rhs = \"\"\n        if off < len(s) and s[off] == \"=\":\n            rhs, off = _read_value(s, off + 1, \";\")\n        if rhs or lhs:\n            pairs.append([lhs, rhs])\n\n        off += 1\n\n        if not off < len(s):\n            break\n\n    return pairs, off\n\n\ndef _read_set_cookie_pairs(s: str, off=0) -> tuple[list[TPairs], int]:\n    \"\"\"\n    Read pairs of lhs=rhs values from SetCookie headers while handling multiple cookies.\n\n    off: start offset\n    specials: attributes that are treated specially\n    \"\"\"\n    cookies: list[TPairs] = []\n    pairs: TPairs = []\n\n    while True:\n        lhs, off = _read_key(s, off, \";=,\")\n        lhs = lhs.lstrip()\n\n        rhs = \"\"\n        if off < len(s) and s[off] == \"=\":\n            rhs, off = _read_value(s, off + 1, \";,\")\n\n            # Special handling of attributes\n            if lhs.lower() == \"expires\":\n                # 'expires' values can contain commas in them so they need to\n                # be handled separately.\n\n                # We actually bank on the fact that the expires value WILL\n                # contain a comma. Things will fail, if they don't.\n\n                # '3' is just a heuristic we use to determine whether we've\n                # only read a part of the expires value and we should read more.\n                if len(rhs) <= 3:\n                    trail, off = _read_value(s, off + 1, \";,\")\n                    rhs = rhs + \",\" + trail\n\n            # as long as there's a \"=\", we consider it a pair\n            pairs.append((lhs, rhs))\n\n        elif lhs:\n            pairs.append((lhs, None))\n\n        # comma marks the beginning of a new cookie\n        if off < len(s) and s[off] == \",\":\n            cookies.append(pairs)\n            pairs = []\n\n        off += 1\n\n        if not off < len(s):\n            break\n\n    if pairs or not cookies:\n        cookies.append(pairs)\n\n    return cookies, off\n\n\ndef _has_special(s: str) -> bool:\n    for i in s:\n        if i in '\",;\\\\':\n            return True\n        o = ord(i)\n        if o < 0x21 or o > 0x7E:\n            return True\n    return False\n\n\ndef _format_pairs(pairs, specials=(), sep=\"; \"):\n    \"\"\"\n    specials: A lower-cased list of keys that will not be quoted.\n    \"\"\"\n    vals = []\n    for k, v in pairs:\n        if v is None:\n            val = k\n        elif k.lower() not in specials and _has_special(v):\n            v = ESCAPE.sub(r\"\\\\\\1\", v)\n            v = '\"%s\"' % v\n            val = f\"{k}={v}\"\n        else:\n            val = f\"{k}={v}\"\n        vals.append(val)\n    return sep.join(vals)\n\n\ndef _format_set_cookie_pairs(lst):\n    return _format_pairs(lst, specials=(\"expires\", \"path\"))\n\n\ndef parse_cookie_header(line):\n    \"\"\"\n    Parse a Cookie header value.\n    Returns a list of (lhs, rhs) tuples.\n    \"\"\"\n    pairs, off_ = _read_cookie_pairs(line)\n    return pairs\n\n\ndef parse_cookie_headers(cookie_headers):\n    cookie_list = []\n    for header in cookie_headers:\n        cookie_list.extend(parse_cookie_header(header))\n    return cookie_list\n\n\ndef format_cookie_header(lst):\n    \"\"\"\n    Formats a Cookie header value.\n    \"\"\"\n    return _format_pairs(lst)\n\n\ndef parse_set_cookie_header(line: str) -> list[TSetCookie]:\n    \"\"\"\n    Parse a Set-Cookie header value\n\n    Returns:\n        A list of (name, value, attrs) tuples, where attrs is a\n        CookieAttrs dict of attributes. No attempt is made to parse attribute\n        values - they are treated purely as strings.\n    \"\"\"\n    cookie_pairs, off = _read_set_cookie_pairs(line)\n    cookies = []\n    for pairs in cookie_pairs:\n        if pairs:\n            cookie, *attrs = pairs\n            cookies.append((cookie[0], cookie[1], CookieAttrs(attrs)))\n    return cookies\n\n\ndef parse_set_cookie_headers(headers: Iterable[str]) -> list[TSetCookie]:\n    rv = []\n    for header in headers:\n        cookies = parse_set_cookie_header(header)\n        rv.extend(cookies)\n    return rv\n\n\ndef format_set_cookie_header(set_cookies: list[TSetCookie]) -> str:\n    \"\"\"\n    Formats a Set-Cookie header value.\n    \"\"\"\n\n    rv = []\n\n    for name, value, attrs in set_cookies:\n        pairs = [(name, value)]\n        pairs.extend(attrs.fields if hasattr(attrs, \"fields\") else attrs)\n\n        rv.append(_format_set_cookie_pairs(pairs))\n\n    return \", \".join(rv)\n\n\ndef refresh_set_cookie_header(c: str, delta: int) -> str:\n    \"\"\"\n    Args:\n        c: A Set-Cookie string\n        delta: Time delta in seconds\n    Returns:\n        A refreshed Set-Cookie string\n    Raises:\n        ValueError, if the cookie is invalid.\n    \"\"\"\n    cookies = parse_set_cookie_header(c)\n    for cookie in cookies:\n        name, value, attrs = cookie\n        if not name or not value:\n            raise ValueError(\"Invalid Cookie\")\n\n        if \"expires\" in attrs:\n            e = email.utils.parsedate_tz(attrs[\"expires\"])\n            if e:\n                f = email.utils.mktime_tz(e) + delta\n                attrs.set_all(\"expires\", [email.utils.formatdate(f, usegmt=True)])\n            else:\n                # This can happen when the expires tag is invalid.\n                # reddit.com sends a an expires tag like this: \"Thu, 31 Dec\n                # 2037 23:59:59 GMT\", which is valid RFC 1123, but not\n                # strictly correct according to the cookie spec. Browsers\n                # appear to parse this tolerantly - maybe we should too.\n                # For now, we just ignore this.\n                del attrs[\"expires\"]\n    return format_set_cookie_header(cookies)\n\n\ndef get_expiration_ts(cookie_attrs):\n    \"\"\"\n    Determines the time when the cookie will be expired.\n\n    Considering both 'expires' and 'max-age' parameters.\n\n    Returns: timestamp of when the cookie will expire.\n             None, if no expiration time is set.\n    \"\"\"\n    if \"expires\" in cookie_attrs:\n        e = email.utils.parsedate_tz(cookie_attrs[\"expires\"])\n        if e:\n            return email.utils.mktime_tz(e)\n\n    elif \"max-age\" in cookie_attrs:\n        try:\n            max_age = int(cookie_attrs[\"Max-Age\"])\n        except ValueError:\n            pass\n        else:\n            now_ts = time.time()\n            return now_ts + max_age\n\n    return None\n\n\ndef is_expired(cookie_attrs):\n    \"\"\"\n    Determines whether a cookie has expired.\n\n    Returns: boolean\n    \"\"\"\n\n    exp_ts = get_expiration_ts(cookie_attrs)\n    now_ts = time.time()\n\n    # If no expiration information was provided with the cookie\n    if exp_ts is None:\n        return False\n    else:\n        return exp_ts <= now_ts\n\n\ndef group_cookies(pairs):\n    \"\"\"\n    Converts a list of pairs to a (name, value, attrs) for each cookie.\n    \"\"\"\n\n    if not pairs:\n        return []\n\n    cookie_list = []\n\n    # First pair is always a new cookie\n    name, value = pairs[0]\n    attrs = []\n\n    for k, v in pairs[1:]:\n        if k.lower() in _cookie_params:\n            attrs.append((k, v))\n        else:\n            cookie_list.append((name, value, CookieAttrs(attrs)))\n            name, value, attrs = k, v, []\n\n    cookie_list.append((name, value, CookieAttrs(attrs)))\n    return cookie_list\n", "mitmproxy/net/http/http1/assemble.py": "def assemble_request(request):\n    if request.data.content is None:\n        raise ValueError(\"Cannot assemble flow with missing content\")\n    head = assemble_request_head(request)\n    body = b\"\".join(\n        assemble_body(\n            request.data.headers, [request.data.content], request.data.trailers\n        )\n    )\n    return head + body\n\n\ndef assemble_request_head(request):\n    first_line = _assemble_request_line(request.data)\n    headers = _assemble_request_headers(request.data)\n    return b\"%s\\r\\n%s\\r\\n\" % (first_line, headers)\n\n\ndef assemble_response(response):\n    if response.data.content is None:\n        raise ValueError(\"Cannot assemble flow with missing content\")\n    head = assemble_response_head(response)\n    body = b\"\".join(\n        assemble_body(\n            response.data.headers, [response.data.content], response.data.trailers\n        )\n    )\n    return head + body\n\n\ndef assemble_response_head(response):\n    first_line = _assemble_response_line(response.data)\n    headers = _assemble_response_headers(response.data)\n    return b\"%s\\r\\n%s\\r\\n\" % (first_line, headers)\n\n\ndef assemble_body(headers, body_chunks, trailers):\n    if \"chunked\" in headers.get(\"transfer-encoding\", \"\").lower():\n        for chunk in body_chunks:\n            if chunk:\n                yield b\"%x\\r\\n%s\\r\\n\" % (len(chunk), chunk)\n        if trailers:\n            yield b\"0\\r\\n%s\\r\\n\" % trailers\n        else:\n            yield b\"0\\r\\n\\r\\n\"\n    else:\n        if trailers:\n            raise ValueError(\n                \"Sending HTTP/1.1 trailer headers requires transfer-encoding: chunked\"\n            )\n        for chunk in body_chunks:\n            yield chunk\n\n\ndef _assemble_request_line(request_data):\n    \"\"\"\n    Args:\n        request_data (mitmproxy.net.http.request.RequestData)\n    \"\"\"\n    if request_data.method.upper() == b\"CONNECT\":\n        return b\"%s %s %s\" % (\n            request_data.method,\n            request_data.authority,\n            request_data.http_version,\n        )\n    elif request_data.authority:\n        return b\"%s %s://%s%s %s\" % (\n            request_data.method,\n            request_data.scheme,\n            request_data.authority,\n            request_data.path,\n            request_data.http_version,\n        )\n    else:\n        return b\"%s %s %s\" % (\n            request_data.method,\n            request_data.path,\n            request_data.http_version,\n        )\n\n\ndef _assemble_request_headers(request_data):\n    \"\"\"\n    Args:\n        request_data (mitmproxy.net.http.request.RequestData)\n    \"\"\"\n    return bytes(request_data.headers)\n\n\ndef _assemble_response_line(response_data):\n    return b\"%s %d %s\" % (\n        response_data.http_version,\n        response_data.status_code,\n        response_data.reason,\n    )\n\n\ndef _assemble_response_headers(response):\n    return bytes(response.headers)\n", "mitmproxy/net/http/http1/__init__.py": "from .assemble import assemble_body\nfrom .assemble import assemble_request\nfrom .assemble import assemble_request_head\nfrom .assemble import assemble_response\nfrom .assemble import assemble_response_head\nfrom .read import connection_close\nfrom .read import expected_http_body_size\nfrom .read import read_request_head\nfrom .read import read_response_head\nfrom .read import validate_headers\n\n__all__ = [\n    \"read_request_head\",\n    \"read_response_head\",\n    \"connection_close\",\n    \"expected_http_body_size\",\n    \"validate_headers\",\n    \"assemble_request\",\n    \"assemble_request_head\",\n    \"assemble_response\",\n    \"assemble_response_head\",\n    \"assemble_body\",\n]\n", "mitmproxy/net/http/http1/read.py": "import re\nimport time\nfrom collections.abc import Iterable\n\nfrom mitmproxy.http import Headers\nfrom mitmproxy.http import Request\nfrom mitmproxy.http import Response\nfrom mitmproxy.net.http import url\n\n\ndef get_header_tokens(headers, key):\n    \"\"\"\n    Retrieve all tokens for a header key. A number of different headers\n    follow a pattern where each header line can containe comma-separated\n    tokens, and headers can be set multiple times.\n    \"\"\"\n    if key not in headers:\n        return []\n    tokens = headers[key].split(\",\")\n    return [token.strip() for token in tokens]\n\n\ndef connection_close(http_version, headers):\n    \"\"\"\n    Checks the message to see if the client connection should be closed\n    according to RFC 2616 Section 8.1.\n    If we don't have a Connection header, HTTP 1.1 connections are assumed\n    to be persistent.\n    \"\"\"\n    if \"connection\" in headers:\n        tokens = get_header_tokens(headers, \"connection\")\n        if \"close\" in tokens:\n            return True\n        elif \"keep-alive\" in tokens:\n            return False\n\n    return http_version not in (\n        \"HTTP/1.1\",\n        b\"HTTP/1.1\",\n        \"HTTP/2.0\",\n        b\"HTTP/2.0\",\n    )\n\n\n# https://datatracker.ietf.org/doc/html/rfc7230#section-3.2: Header fields are tokens.\n# \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\" / \"+\" / \"-\" / \".\" /  \"^\" / \"_\" / \"`\" / \"|\" / \"~\" / DIGIT / ALPHA\n_valid_header_name = re.compile(rb\"^[!#$%&'*+\\-.^_`|~0-9a-zA-Z]+$\")\n\n\ndef validate_headers(headers: Headers) -> None:\n    \"\"\"\n    Validate headers to avoid request smuggling attacks. Raises a ValueError if they are malformed.\n    \"\"\"\n\n    te_found = False\n    cl_found = False\n\n    for name, value in headers.fields:\n        if not _valid_header_name.match(name):\n            raise ValueError(\n                f\"Received an invalid header name: {name!r}. Invalid header names may introduce \"\n                f\"request smuggling vulnerabilities. Disable the validate_inbound_headers option \"\n                f\"to skip this security check.\"\n            )\n\n        name_lower = name.lower()\n        te_found = te_found or name_lower == b\"transfer-encoding\"\n        cl_found = cl_found or name_lower == b\"content-length\"\n\n    if te_found and cl_found:\n        raise ValueError(\n            \"Received both a Transfer-Encoding and a Content-Length header, \"\n            \"refusing as recommended in RFC 7230 Section 3.3.3. \"\n            \"See https://github.com/mitmproxy/mitmproxy/issues/4799 for details. \"\n            \"Disable the validate_inbound_headers option to skip this security check.\"\n        )\n\n\ndef expected_http_body_size(\n    request: Request, response: Response | None = None\n) -> int | None:\n    \"\"\"\n    Returns:\n        The expected body length:\n        - a positive integer, if the size is known in advance\n        - None, if the size in unknown in advance (chunked encoding)\n        - -1, if all data should be read until end of stream.\n\n    Raises:\n        ValueError, if the content length header is invalid\n    \"\"\"\n    # Determine response size according to http://tools.ietf.org/html/rfc7230#section-3.3, which is inlined below.\n    if not response:\n        headers = request.headers\n    else:\n        headers = response.headers\n\n        #    1.  Any response to a HEAD request and any response with a 1xx\n        #        (Informational), 204 (No Content), or 304 (Not Modified) status\n        #        code is always terminated by the first empty line after the\n        #        header fields, regardless of the header fields present in the\n        #        message, and thus cannot contain a message body.\n        if request.method.upper() == \"HEAD\":\n            return 0\n        if 100 <= response.status_code <= 199:\n            return 0\n        if response.status_code in (204, 304):\n            return 0\n\n        #    2.  Any 2xx (Successful) response to a CONNECT request implies that\n        #        the connection will become a tunnel immediately after the empty\n        #        line that concludes the header fields.  A client MUST ignore any\n        #        Content-Length or Transfer-Encoding header fields received in\n        #        such a message.\n        if 200 <= response.status_code <= 299 and request.method.upper() == \"CONNECT\":\n            return 0\n\n    #    3.  If a Transfer-Encoding header field is present and the chunked\n    #        transfer coding (Section 4.1) is the final encoding, the message\n    #        body length is determined by reading and decoding the chunked\n    #        data until the transfer coding indicates the data is complete.\n    #\n    #        If a Transfer-Encoding header field is present in a response and\n    #        the chunked transfer coding is not the final encoding, the\n    #        message body length is determined by reading the connection until\n    #        it is closed by the server.  If a Transfer-Encoding header field\n    #        is present in a request and the chunked transfer coding is not\n    #        the final encoding, the message body length cannot be determined\n    #        reliably; the server MUST respond with the 400 (Bad Request)\n    #        status code and then close the connection.\n    #\n    #        If a message is received with both a Transfer-Encoding and a\n    #        Content-Length header field, the Transfer-Encoding overrides the\n    #        Content-Length.  Such a message might indicate an attempt to\n    #        perform request smuggling (Section 9.5) or response splitting\n    #        (Section 9.4) and ought to be handled as an error.  A sender MUST\n    #        remove the received Content-Length field prior to forwarding such\n    #        a message downstream.\n    #\n    if \"transfer-encoding\" in headers:\n        # we should make sure that there isn't also a content-length header.\n        # this is already handled in validate_headers.\n\n        te: str = headers[\"transfer-encoding\"]\n        if not te.isascii():\n            # guard against .lower() transforming non-ascii to ascii\n            raise ValueError(f\"Invalid transfer encoding: {te!r}\")\n        te = te.lower().strip(\"\\t \")\n        te = re.sub(r\"[\\t ]*,[\\t ]*\", \",\", te)\n        if te in (\n            \"chunked\",\n            \"compress,chunked\",\n            \"deflate,chunked\",\n            \"gzip,chunked\",\n        ):\n            return None\n        elif te in (\n            \"compress\",\n            \"deflate\",\n            \"gzip\",\n            \"identity\",\n        ):\n            if response:\n                return -1\n            else:\n                raise ValueError(\n                    f\"Invalid request transfer encoding, message body cannot be determined reliably.\"\n                )\n        else:\n            raise ValueError(\n                f\"Unknown transfer encoding: {headers['transfer-encoding']!r}\"\n            )\n\n    #    4.  If a message is received without Transfer-Encoding and with\n    #        either multiple Content-Length header fields having differing\n    #        field-values or a single Content-Length header field having an\n    #        invalid value, then the message framing is invalid and the\n    #        recipient MUST treat it as an unrecoverable error.  If this is a\n    #        request message, the server MUST respond with a 400 (Bad Request)\n    #        status code and then close the connection.  If this is a response\n    #        message received by a proxy, the proxy MUST close the connection\n    #        to the server, discard the received response, and send a 502 (Bad\n    #        Gateway) response to the client.  If this is a response message\n    #        received by a user agent, the user agent MUST close the\n    #        connection to the server and discard the received response.\n    #\n    #    5.  If a valid Content-Length header field is present without\n    #        Transfer-Encoding, its decimal value defines the expected message\n    #        body length in octets.  If the sender closes the connection or\n    #        the recipient times out before the indicated number of octets are\n    #        received, the recipient MUST consider the message to be\n    #        incomplete and close the connection.\n    if \"content-length\" in headers:\n        sizes = headers.get_all(\"content-length\")\n        different_content_length_headers = any(x != sizes[0] for x in sizes)\n        if different_content_length_headers:\n            raise ValueError(f\"Conflicting Content-Length headers: {sizes!r}\")\n        try:\n            size = int(sizes[0])\n        except ValueError:\n            raise ValueError(f\"Invalid Content-Length header: {sizes[0]!r}\")\n        if size < 0:\n            raise ValueError(f\"Negative Content-Length header: {sizes[0]!r}\")\n        return size\n\n    #    6.  If this is a request message and none of the above are true, then\n    #        the message body length is zero (no message body is present).\n    if not response:\n        return 0\n\n    #    7.  Otherwise, this is a response message without a declared message\n    #        body length, so the message body length is determined by the\n    #        number of octets received prior to the server closing the\n    #        connection.\n    return -1\n\n\ndef raise_if_http_version_unknown(http_version: bytes) -> None:\n    if not re.match(rb\"^HTTP/\\d\\.\\d$\", http_version):\n        raise ValueError(f\"Unknown HTTP version: {http_version!r}\")\n\n\ndef _read_request_line(\n    line: bytes,\n) -> tuple[str, int, bytes, bytes, bytes, bytes, bytes]:\n    try:\n        method, target, http_version = line.split()\n        port: int | None\n\n        if target == b\"*\" or target.startswith(b\"/\"):\n            scheme, authority, path = b\"\", b\"\", target\n            host, port = \"\", 0\n        elif method == b\"CONNECT\":\n            scheme, authority, path = b\"\", target, b\"\"\n            host, port = url.parse_authority(authority, check=True)\n            if not port:\n                raise ValueError\n        else:\n            scheme, rest = target.split(b\"://\", maxsplit=1)\n            authority, _, path_ = rest.partition(b\"/\")\n            path = b\"/\" + path_\n            host, port = url.parse_authority(authority, check=True)\n            port = port or url.default_port(scheme)\n            if not port:\n                raise ValueError\n            # TODO: we can probably get rid of this check?\n            url.parse(target)\n\n        raise_if_http_version_unknown(http_version)\n    except ValueError as e:\n        raise ValueError(f\"Bad HTTP request line: {line!r}\") from e\n\n    return host, port, method, scheme, authority, path, http_version\n\n\ndef _read_response_line(line: bytes) -> tuple[bytes, int, bytes]:\n    try:\n        parts = line.split(None, 2)\n        if len(parts) == 2:  # handle missing message gracefully\n            parts.append(b\"\")\n\n        http_version, status_code_str, reason = parts\n        status_code = int(status_code_str)\n        raise_if_http_version_unknown(http_version)\n    except ValueError as e:\n        raise ValueError(f\"Bad HTTP response line: {line!r}\") from e\n\n    return http_version, status_code, reason\n\n\ndef _read_headers(lines: Iterable[bytes]) -> Headers:\n    \"\"\"\n    Read a set of headers.\n    Stop once a blank line is reached.\n\n    Returns:\n        A headers object\n\n    Raises:\n        exceptions.HttpSyntaxException\n    \"\"\"\n    ret: list[tuple[bytes, bytes]] = []\n    for line in lines:\n        if line[0] in b\" \\t\":\n            if not ret:\n                raise ValueError(\"Invalid headers\")\n            # continued header\n            ret[-1] = (ret[-1][0], ret[-1][1] + b\"\\r\\n \" + line.strip())\n        else:\n            try:\n                name, value = line.split(b\":\", 1)\n                value = value.strip()\n                if not name:\n                    raise ValueError()\n                ret.append((name, value))\n            except ValueError:\n                raise ValueError(f\"Invalid header line: {line!r}\")\n    return Headers(ret)\n\n\ndef read_request_head(lines: list[bytes]) -> Request:\n    \"\"\"\n    Parse an HTTP request head (request line + headers) from an iterable of lines\n\n    Args:\n        lines: The input lines\n\n    Returns:\n        The HTTP request object (without body)\n\n    Raises:\n        ValueError: The input is malformed.\n    \"\"\"\n    host, port, method, scheme, authority, path, http_version = _read_request_line(\n        lines[0]\n    )\n    headers = _read_headers(lines[1:])\n\n    return Request(\n        host=host,\n        port=port,\n        method=method,\n        scheme=scheme,\n        authority=authority,\n        path=path,\n        http_version=http_version,\n        headers=headers,\n        content=None,\n        trailers=None,\n        timestamp_start=time.time(),\n        timestamp_end=None,\n    )\n\n\ndef read_response_head(lines: list[bytes]) -> Response:\n    \"\"\"\n    Parse an HTTP response head (response line + headers) from an iterable of lines\n\n    Args:\n        lines: The input lines\n\n    Returns:\n        The HTTP response object (without body)\n\n    Raises:\n        ValueError: The input is malformed.\n    \"\"\"\n    http_version, status_code, reason = _read_response_line(lines[0])\n    headers = _read_headers(lines[1:])\n\n    return Response(\n        http_version=http_version,\n        status_code=status_code,\n        reason=reason,\n        headers=headers,\n        content=None,\n        trailers=None,\n        timestamp_start=time.time(),\n        timestamp_end=None,\n    )\n", "mitmproxy/proxy/mode_specs.py": "\"\"\"\nThis module is responsible for parsing proxy mode specifications such as\n`\"regular\"`, `\"reverse:https://example.com\"`, or `\"socks5@1234\"`. The general syntax is\n\n    mode [: mode_configuration] [@ [listen_addr:]listen_port]\n\nFor a full example, consider `reverse:https://example.com@127.0.0.1:443`.\nThis would spawn a reverse proxy on port 443 bound to localhost.\nThe mode is `reverse`, and the mode data is `https://example.com`.\nExamples:\n\n    mode = ProxyMode.parse(\"regular@1234\")\n    assert mode.listen_port == 1234\n    assert isinstance(mode, RegularMode)\n\n    ProxyMode.parse(\"reverse:example.com@invalid-port\")  # ValueError\n\n    RegularMode.parse(\"regular\")  # ok\n    RegularMode.parse(\"socks5\")  # ValueError\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport dataclasses\nimport sys\nfrom abc import ABCMeta\nfrom abc import abstractmethod\nfrom dataclasses import dataclass\nfrom functools import cache\nfrom typing import ClassVar\nfrom typing import Literal\n\nimport mitmproxy_rs\n\nfrom mitmproxy.coretypes.serializable import Serializable\nfrom mitmproxy.net import server_spec\n\nif sys.version_info < (3, 11):\n    from typing_extensions import Self  # pragma: no cover\nelse:\n    from typing import Self\n\n\n@dataclass(frozen=True)  # type: ignore\nclass ProxyMode(Serializable, metaclass=ABCMeta):\n    \"\"\"\n    Parsed representation of a proxy mode spec. Subclassed for each specific mode,\n    which then does its own data validation.\n    \"\"\"\n\n    full_spec: str\n    \"\"\"The full proxy mode spec as entered by the user.\"\"\"\n    data: str\n    \"\"\"The (raw) mode data, i.e. the part after the mode name.\"\"\"\n    custom_listen_host: str | None\n    \"\"\"A custom listen host, if specified in the spec.\"\"\"\n    custom_listen_port: int | None\n    \"\"\"A custom listen port, if specified in the spec.\"\"\"\n\n    type_name: ClassVar[\n        str\n    ]  # automatically derived from the class name in __init_subclass__\n    \"\"\"The unique name for this proxy mode, e.g. \"regular\" or \"reverse\".\"\"\"\n    __types: ClassVar[dict[str, type[ProxyMode]]] = {}\n\n    def __init_subclass__(cls, **kwargs):\n        cls.type_name = cls.__name__.removesuffix(\"Mode\").lower()\n        assert cls.type_name not in ProxyMode.__types\n        ProxyMode.__types[cls.type_name] = cls\n\n    def __repr__(self):\n        return f\"ProxyMode.parse({self.full_spec!r})\"\n\n    @abstractmethod\n    def __post_init__(self) -> None:\n        \"\"\"Validation of data happens here.\"\"\"\n\n    @property\n    @abstractmethod\n    def description(self) -> str:\n        \"\"\"The mode description that will be used in server logs and UI.\"\"\"\n\n    @property\n    def default_port(self) -> int:\n        \"\"\"\n        Default listen port of servers for this mode, see `ProxyMode.listen_port()`.\n        \"\"\"\n        return 8080\n\n    @property\n    @abstractmethod\n    def transport_protocol(self) -> Literal[\"tcp\", \"udp\", \"both\"] | None:\n        \"\"\"The transport protocol used by this mode's server.\"\"\"\n\n    @classmethod\n    @cache\n    def parse(cls, spec: str) -> Self:\n        \"\"\"\n        Parse a proxy mode specification and return the corresponding `ProxyMode` instance.\n        \"\"\"\n        head, _, listen_at = spec.rpartition(\"@\")\n        if not head:\n            head = listen_at\n            listen_at = \"\"\n\n        mode, _, data = head.partition(\":\")\n\n        if listen_at:\n            if \":\" in listen_at:\n                host, _, port_str = listen_at.rpartition(\":\")\n            else:\n                host = None\n                port_str = listen_at\n            try:\n                port = int(port_str)\n                if port < 0 or 65535 < port:\n                    raise ValueError\n            except ValueError:\n                raise ValueError(f\"invalid port: {port_str}\")\n        else:\n            host = None\n            port = None\n\n        try:\n            mode_cls = ProxyMode.__types[mode.lower()]\n        except KeyError:\n            raise ValueError(f\"unknown mode\")\n\n        if not issubclass(mode_cls, cls):\n            raise ValueError(f\"{mode!r} is not a spec for a {cls.type_name} mode\")\n\n        return mode_cls(\n            full_spec=spec, data=data, custom_listen_host=host, custom_listen_port=port\n        )\n\n    def listen_host(self, default: str | None = None) -> str:\n        \"\"\"\n        Return the address a server for this mode should listen on. This can be either directly\n        specified in the spec or taken from a user-configured global default (`options.listen_host`).\n        By default, return an empty string to listen on all hosts.\n        \"\"\"\n        if self.custom_listen_host is not None:\n            return self.custom_listen_host\n        elif default is not None:\n            return default\n        else:\n            return \"\"\n\n    def listen_port(self, default: int | None = None) -> int:\n        \"\"\"\n        Return the port a server for this mode should listen on. This can be either directly\n        specified in the spec, taken from a user-configured global default (`options.listen_port`),\n        or from `ProxyMode.default_port`.\n        \"\"\"\n        if self.custom_listen_port is not None:\n            return self.custom_listen_port\n        elif default is not None:\n            return default\n        else:\n            return self.default_port\n\n    @classmethod\n    def from_state(cls, state):\n        return ProxyMode.parse(state)\n\n    def get_state(self):\n        return self.full_spec\n\n    def set_state(self, state):\n        if state != self.full_spec:\n            raise dataclasses.FrozenInstanceError(\"Proxy modes are immutable.\")\n\n\nTCP: Literal[\"tcp\", \"udp\", \"both\"] = \"tcp\"\nUDP: Literal[\"tcp\", \"udp\", \"both\"] = \"udp\"\nBOTH: Literal[\"tcp\", \"udp\", \"both\"] = \"both\"\n\n\ndef _check_empty(data):\n    if data:\n        raise ValueError(\"mode takes no arguments\")\n\n\nclass RegularMode(ProxyMode):\n    \"\"\"A regular HTTP(S) proxy that is interfaced with `HTTP CONNECT` calls (or absolute-form HTTP requests).\"\"\"\n\n    description = \"HTTP(S) proxy\"\n    transport_protocol = TCP\n\n    def __post_init__(self) -> None:\n        _check_empty(self.data)\n\n\nclass TransparentMode(ProxyMode):\n    \"\"\"A transparent proxy, see https://docs.mitmproxy.org/dev/howto-transparent/\"\"\"\n\n    description = \"Transparent Proxy\"\n    transport_protocol = TCP\n\n    def __post_init__(self) -> None:\n        _check_empty(self.data)\n\n\nclass UpstreamMode(ProxyMode):\n    \"\"\"A regular HTTP(S) proxy, but all connections are forwarded to a second upstream HTTP(S) proxy.\"\"\"\n\n    description = \"HTTP(S) proxy (upstream mode)\"\n    transport_protocol = TCP\n    scheme: Literal[\"http\", \"https\"]\n    address: tuple[str, int]\n\n    # noinspection PyDataclass\n    def __post_init__(self) -> None:\n        scheme, self.address = server_spec.parse(self.data, default_scheme=\"http\")\n        if scheme != \"http\" and scheme != \"https\":\n            raise ValueError(\"invalid upstream proxy scheme\")\n        self.scheme = scheme\n\n\nclass ReverseMode(ProxyMode):\n    \"\"\"A reverse proxy. This acts like a normal server, but redirects all requests to a fixed target.\"\"\"\n\n    description = \"reverse proxy\"\n    transport_protocol = TCP\n    scheme: Literal[\n        \"http\", \"https\", \"http3\", \"tls\", \"dtls\", \"tcp\", \"udp\", \"dns\", \"quic\"\n    ]\n    address: tuple[str, int]\n\n    # noinspection PyDataclass\n    def __post_init__(self) -> None:\n        self.scheme, self.address = server_spec.parse(self.data, default_scheme=\"https\")\n        if self.scheme in (\"http3\", \"dtls\", \"udp\", \"quic\"):\n            self.transport_protocol = UDP\n        elif self.scheme == \"dns\":\n            self.transport_protocol = BOTH\n        self.description = f\"{self.description} to {self.data}\"\n\n    @property\n    def default_port(self) -> int:\n        if self.scheme == \"dns\":\n            return 53\n        return super().default_port\n\n\nclass Socks5Mode(ProxyMode):\n    \"\"\"A SOCKSv5 proxy.\"\"\"\n\n    description = \"SOCKS v5 proxy\"\n    default_port = 1080\n    transport_protocol = TCP\n\n    def __post_init__(self) -> None:\n        _check_empty(self.data)\n\n\nclass DnsMode(ProxyMode):\n    \"\"\"A DNS server.\"\"\"\n\n    description = \"DNS server\"\n    default_port = 53\n    transport_protocol = BOTH\n\n    def __post_init__(self) -> None:\n        _check_empty(self.data)\n\n\n# class Http3Mode(ProxyMode):\n#     \"\"\"\n#     A regular HTTP3 proxy that is interfaced with absolute-form HTTP requests.\n#     (This class will be merged into `RegularMode` once the UDP implementation is deemed stable enough.)\n#     \"\"\"\n#\n#     description = \"HTTP3 proxy\"\n#     transport_protocol = UDP\n#\n#     def __post_init__(self) -> None:\n#         _check_empty(self.data)\n\n\nclass WireGuardMode(ProxyMode):\n    \"\"\"Proxy Server based on WireGuard\"\"\"\n\n    description = \"WireGuard server\"\n    default_port = 51820\n    transport_protocol = UDP\n\n    def __post_init__(self) -> None:\n        pass\n\n\nclass LocalMode(ProxyMode):\n    \"\"\"OS-level transparent proxy.\"\"\"\n\n    description = \"Local redirector\"\n    transport_protocol = None\n\n    def __post_init__(self) -> None:\n        # should not raise\n        mitmproxy_rs.LocalRedirector.describe_spec(self.data)\n\n\nclass OsProxyMode(ProxyMode):  # pragma: no cover\n    \"\"\"Deprecated alias for LocalMode\"\"\"\n\n    description = \"Deprecated alias for LocalMode\"\n    transport_protocol = None\n\n    def __post_init__(self) -> None:\n        raise ValueError(\n            \"osproxy mode has been renamed to local mode. Thanks for trying our experimental features!\"\n        )\n", "mitmproxy/proxy/server_hooks.py": "from dataclasses import dataclass\n\nfrom . import commands\nfrom mitmproxy import connection\n\n\n@dataclass\nclass ClientConnectedHook(commands.StartHook):\n    \"\"\"\n    A client has connected to mitmproxy. Note that a connection can\n    correspond to multiple HTTP requests.\n\n    Setting client.error kills the connection.\n    \"\"\"\n\n    client: connection.Client\n\n\n@dataclass\nclass ClientDisconnectedHook(commands.StartHook):\n    \"\"\"\n    A client connection has been closed (either by us or the client).\n    \"\"\"\n\n    client: connection.Client\n\n\n@dataclass\nclass ServerConnectionHookData:\n    \"\"\"Event data for server connection event hooks.\"\"\"\n\n    server: connection.Server\n    \"\"\"The server connection this hook is about.\"\"\"\n    client: connection.Client\n    \"\"\"The client on the other end.\"\"\"\n\n\n@dataclass\nclass ServerConnectHook(commands.StartHook):\n    \"\"\"\n    Mitmproxy is about to connect to a server.\n    Note that a connection can correspond to multiple requests.\n\n    Setting data.server.error kills the connection.\n    \"\"\"\n\n    data: ServerConnectionHookData\n\n\n@dataclass\nclass ServerConnectedHook(commands.StartHook):\n    \"\"\"\n    Mitmproxy has connected to a server.\n    \"\"\"\n\n    data: ServerConnectionHookData\n\n\n@dataclass\nclass ServerDisconnectedHook(commands.StartHook):\n    \"\"\"\n    A server connection has been closed (either by us or the server).\n    \"\"\"\n\n    data: ServerConnectionHookData\n\n\n@dataclass\nclass ServerConnectErrorHook(commands.StartHook):\n    \"\"\"\n    Mitmproxy failed to connect to a server.\n\n    Every server connection will receive either a server_connected or a server_connect_error event, but not both.\n    \"\"\"\n\n    data: ServerConnectionHookData\n", "mitmproxy/proxy/events.py": "\"\"\"\nWhen IO actions occur at the proxy server, they are passed down to layers as events.\nEvents represent the only way for layers to receive new data from sockets.\nThe counterpart to events are commands.\n\"\"\"\n\nimport typing\nimport warnings\nfrom dataclasses import dataclass\nfrom dataclasses import is_dataclass\nfrom typing import Any\nfrom typing import Generic\nfrom typing import TypeVar\n\nfrom mitmproxy import flow\nfrom mitmproxy.connection import Connection\nfrom mitmproxy.proxy import commands\n\n\nclass Event:\n    \"\"\"\n    Base class for all events.\n    \"\"\"\n\n    def __repr__(self):\n        return f\"{type(self).__name__}({repr(self.__dict__)})\"\n\n\nclass Start(Event):\n    \"\"\"\n    Every layer initially receives a start event.\n    This is useful to emit events on startup.\n    \"\"\"\n\n\n@dataclass\nclass ConnectionEvent(Event):\n    \"\"\"\n    All events involving connection IO.\n    \"\"\"\n\n    connection: Connection\n\n\n@dataclass\nclass DataReceived(ConnectionEvent):\n    \"\"\"\n    Remote has sent some data.\n    \"\"\"\n\n    data: bytes\n\n    def __repr__(self):\n        target = type(self.connection).__name__.lower()\n        return f\"DataReceived({target}, {self.data!r})\"\n\n\nclass ConnectionClosed(ConnectionEvent):\n    \"\"\"\n    Remote has closed a connection.\n    \"\"\"\n\n\nclass CommandCompleted(Event):\n    \"\"\"\n    Emitted when a command has been finished, e.g.\n    when the master has replied or when we have established a server connection.\n    \"\"\"\n\n    command: commands.Command\n    reply: Any\n\n    def __new__(cls, *args, **kwargs):\n        if cls is CommandCompleted:\n            raise TypeError(\"CommandCompleted may not be instantiated directly.\")\n        assert is_dataclass(cls)\n        return super().__new__(cls)\n\n    def __init_subclass__(cls, **kwargs):\n        command_cls = typing.get_type_hints(cls).get(\"command\", None)\n        valid_command_subclass = (\n            isinstance(command_cls, type)\n            and issubclass(command_cls, commands.Command)\n            and command_cls is not commands.Command\n        )\n        if not valid_command_subclass:\n            warnings.warn(\n                f\"{cls} needs a properly annotated command attribute.\",\n                RuntimeWarning,\n            )\n        if command_cls in command_reply_subclasses:\n            other = command_reply_subclasses[command_cls]\n            warnings.warn(\n                f\"Two conflicting subclasses for {command_cls}: {cls} and {other}\",\n                RuntimeWarning,\n            )\n        command_reply_subclasses[command_cls] = cls\n\n    def __repr__(self):\n        return f\"Reply({repr(self.command)}, {repr(self.reply)})\"\n\n\ncommand_reply_subclasses: dict[commands.Command, type[CommandCompleted]] = {}\n\n\n@dataclass(repr=False)\nclass OpenConnectionCompleted(CommandCompleted):\n    command: commands.OpenConnection\n    reply: str | None\n    \"\"\"error message\"\"\"\n\n\n@dataclass(repr=False)\nclass HookCompleted(CommandCompleted):\n    command: commands.StartHook\n    reply: None = None\n\n\nT = TypeVar(\"T\")\n\n\n@dataclass\nclass MessageInjected(Event, Generic[T]):\n    \"\"\"\n    The user has injected a custom WebSocket/TCP/... message.\n    \"\"\"\n\n    flow: flow.Flow\n    message: T\n\n\n@dataclass\nclass Wakeup(CommandCompleted):\n    \"\"\"\n    Event sent to layers that requested a wakeup using RequestWakeup.\n    \"\"\"\n\n    command: commands.RequestWakeup\n", "mitmproxy/proxy/mode_servers.py": "\"\"\"\nThis module defines \"server instances\", which manage\nthe TCP/UDP servers spawned by mitmproxy as specified by the proxy mode.\n\nExample:\n\n    mode = ProxyMode.parse(\"reverse:https://example.com\")\n    inst = ServerInstance.make(mode, manager_that_handles_callbacks)\n    await inst.start()\n    # TCP server is running now.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport errno\nimport json\nimport logging\nimport os\nimport socket\nimport sys\nimport textwrap\nimport typing\nfrom abc import ABCMeta\nfrom abc import abstractmethod\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom typing import cast\nfrom typing import ClassVar\nfrom typing import Generic\nfrom typing import get_args\nfrom typing import TYPE_CHECKING\nfrom typing import TypeVar\n\nimport mitmproxy_rs\n\nfrom mitmproxy import ctx\nfrom mitmproxy import flow\nfrom mitmproxy import platform\nfrom mitmproxy.connection import Address\nfrom mitmproxy.net import local_ip\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import layers\nfrom mitmproxy.proxy import mode_specs\nfrom mitmproxy.proxy import server\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.layer import Layer\nfrom mitmproxy.utils import human\n\nif sys.version_info < (3, 11):\n    from typing_extensions import Self  # pragma: no cover\nelse:\n    from typing import Self\n\nif TYPE_CHECKING:\n    from mitmproxy.master import Master\n\nlogger = logging.getLogger(__name__)\n\n\nclass ProxyConnectionHandler(server.LiveConnectionHandler):\n    master: Master\n\n    def __init__(self, master, r, w, options, mode):\n        self.master = master\n        super().__init__(r, w, options, mode)\n        self.log_prefix = f\"{human.format_address(self.client.peername)}: \"\n\n    async def handle_hook(self, hook: commands.StartHook) -> None:\n        with self.timeout_watchdog.disarm():\n            # We currently only support single-argument hooks.\n            (data,) = hook.args()\n            await self.master.addons.handle_lifecycle(hook)\n            if isinstance(data, flow.Flow):\n                await data.wait_for_resume()  # pragma: no cover\n\n\nM = TypeVar(\"M\", bound=mode_specs.ProxyMode)\n\n\nclass ServerManager(typing.Protocol):\n    # temporary workaround: for UDP, we use the 4-tuple because we don't have a uuid.\n    connections: dict[tuple | str, ProxyConnectionHandler]\n\n    @contextmanager\n    def register_connection(\n        self, connection_id: tuple | str, handler: ProxyConnectionHandler\n    ): ...  # pragma: no cover\n\n\nclass ServerInstance(Generic[M], metaclass=ABCMeta):\n    __modes: ClassVar[dict[str, type[ServerInstance]]] = {}\n\n    last_exception: Exception | None = None\n\n    def __init__(self, mode: M, manager: ServerManager):\n        self.mode: M = mode\n        self.manager: ServerManager = manager\n\n    def __init_subclass__(cls, **kwargs):\n        \"\"\"Register all subclasses so that make() finds them.\"\"\"\n        # extract mode from Generic[Mode].\n        mode = get_args(cls.__orig_bases__[0])[0]  # type: ignore\n        if not isinstance(mode, TypeVar):\n            assert issubclass(mode, mode_specs.ProxyMode)\n            assert mode.type_name not in ServerInstance.__modes\n            ServerInstance.__modes[mode.type_name] = cls\n\n    @classmethod\n    def make(\n        cls,\n        mode: mode_specs.ProxyMode | str,\n        manager: ServerManager,\n    ) -> Self:\n        if isinstance(mode, str):\n            mode = mode_specs.ProxyMode.parse(mode)\n        inst = ServerInstance.__modes[mode.type_name](mode, manager)\n\n        if not isinstance(inst, cls):\n            raise ValueError(f\"{mode!r} is not a spec for a {cls.__name__} server.\")\n\n        return inst\n\n    @property\n    @abstractmethod\n    def is_running(self) -> bool:\n        pass\n\n    async def start(self) -> None:\n        try:\n            await self._start()\n        except Exception as e:\n            self.last_exception = e\n            raise\n        else:\n            self.last_exception = None\n        if self.listen_addrs:\n            addrs = \" and \".join({human.format_address(a) for a in self.listen_addrs})\n            logger.info(f\"{self.mode.description} listening at {addrs}.\")\n        else:\n            logger.info(f\"{self.mode.description} started.\")\n\n    async def stop(self) -> None:\n        listen_addrs = self.listen_addrs\n        try:\n            await self._stop()\n        except Exception as e:\n            self.last_exception = e\n            raise\n        else:\n            self.last_exception = None\n        if listen_addrs:\n            addrs = \" and \".join({human.format_address(a) for a in listen_addrs})\n            logger.info(f\"{self.mode.description} at {addrs} stopped.\")\n        else:\n            logger.info(f\"{self.mode.description} stopped.\")\n\n    @abstractmethod\n    async def _start(self) -> None:\n        pass\n\n    @abstractmethod\n    async def _stop(self) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def listen_addrs(self) -> tuple[Address, ...]:\n        pass\n\n    @abstractmethod\n    def make_top_layer(self, context: Context) -> Layer:\n        pass\n\n    def to_json(self) -> dict:\n        return {\n            \"type\": self.mode.type_name,\n            \"description\": self.mode.description,\n            \"full_spec\": self.mode.full_spec,\n            \"is_running\": self.is_running,\n            \"last_exception\": str(self.last_exception) if self.last_exception else None,\n            \"listen_addrs\": self.listen_addrs,\n        }\n\n    async def handle_stream(\n        self,\n        reader: asyncio.StreamReader | mitmproxy_rs.Stream,\n        writer: asyncio.StreamWriter | mitmproxy_rs.Stream,\n    ) -> None:\n        handler = ProxyConnectionHandler(\n            ctx.master, reader, writer, ctx.options, self.mode\n        )\n        handler.layer = self.make_top_layer(handler.layer.context)\n        if isinstance(self.mode, mode_specs.TransparentMode):\n            assert isinstance(writer, asyncio.StreamWriter)\n            s = cast(socket.socket, writer.get_extra_info(\"socket\"))\n            try:\n                assert platform.original_addr\n                original_dst = platform.original_addr(s)\n            except Exception as e:\n                logger.error(f\"Transparent mode failure: {e!r}\")\n                writer.close()\n                return\n            else:\n                handler.layer.context.client.sockname = original_dst\n                handler.layer.context.server.address = original_dst\n        elif isinstance(\n            self.mode, (mode_specs.WireGuardMode, mode_specs.LocalMode)\n        ):  # pragma: no cover on platforms without wg-test-client\n            handler.layer.context.server.address = writer.get_extra_info(\n                \"remote_endpoint\", handler.layer.context.client.sockname\n            )\n\n        with self.manager.register_connection(handler.layer.context.client.id, handler):\n            await handler.handle_client()\n\n    async def handle_udp_stream(self, stream: mitmproxy_rs.Stream) -> None:\n        await self.handle_stream(stream, stream)\n\n\nclass AsyncioServerInstance(ServerInstance[M], metaclass=ABCMeta):\n    _servers: list[asyncio.Server | mitmproxy_rs.UdpServer]\n\n    def __init__(self, *args, **kwargs) -> None:\n        self._servers = []\n        super().__init__(*args, **kwargs)\n\n    @property\n    def is_running(self) -> bool:\n        return bool(self._servers)\n\n    @property\n    def listen_addrs(self) -> tuple[Address, ...]:\n        addrs = []\n        for s in self._servers:\n            if isinstance(s, mitmproxy_rs.UdpServer):\n                addrs.append(s.getsockname())\n            else:\n                try:\n                    addrs.extend(sock.getsockname() for sock in s.sockets)\n                except OSError:  # pragma: no cover\n                    pass  # this can fail during shutdown, see https://github.com/mitmproxy/mitmproxy/issues/6529\n        return tuple(addrs)\n\n    async def _start(self) -> None:\n        assert not self._servers\n        host = self.mode.listen_host(ctx.options.listen_host)\n        port = self.mode.listen_port(ctx.options.listen_port)\n        try:\n            self._servers = await self.listen(host, port)\n        except OSError as e:\n            message = f\"{self.mode.description} failed to listen on {host or '*'}:{port} with {e}\"\n            if e.errno == errno.EADDRINUSE and self.mode.custom_listen_port is None:\n                assert (\n                    self.mode.custom_listen_host is None\n                )  # since [@ [listen_addr:]listen_port]\n                message += f\"\\nTry specifying a different port by using `--mode {self.mode.full_spec}@{port + 2}`.\"\n            raise OSError(e.errno, message, e.filename) from e\n\n    async def _stop(self) -> None:\n        assert self._servers\n        try:\n            for s in self._servers:\n                s.close()\n            # https://github.com/python/cpython/issues/104344\n            # await asyncio.gather(*[s.wait_closed() for s in self._servers])\n        finally:\n            # we always reset _server and ignore failures\n            self._servers = []\n\n    async def listen(\n        self, host: str, port: int\n    ) -> list[asyncio.Server | mitmproxy_rs.UdpServer]:\n        if self.mode.transport_protocol not in (\"tcp\", \"udp\", \"both\"):\n            raise AssertionError(self.mode.transport_protocol)\n\n        servers: list[asyncio.Server | mitmproxy_rs.UdpServer] = []\n        if self.mode.transport_protocol in (\"tcp\", \"both\"):\n            # workaround for https://github.com/python/cpython/issues/89856:\n            # We want both IPv4 and IPv6 sockets to bind to the same port.\n            # This may fail (https://github.com/mitmproxy/mitmproxy/pull/5542#issuecomment-1222803291),\n            # so we try to cover the 99% case and then give up and fall back to what asyncio does.\n            if port == 0:\n                try:\n                    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                    s.bind((\"\", 0))\n                    port = s.getsockname()[1]\n                    s.close()\n                    servers.append(\n                        await asyncio.start_server(self.handle_stream, host, port)\n                    )\n                except Exception as e:\n                    logger.debug(\n                        f\"Failed to listen on a single port ({e!r}), falling back to default behavior.\"\n                    )\n                    port = 0\n                    servers.append(\n                        await asyncio.start_server(self.handle_stream, host, port)\n                    )\n            else:\n                servers.append(\n                    await asyncio.start_server(self.handle_stream, host, port)\n                )\n        if self.mode.transport_protocol in (\"udp\", \"both\"):\n            # we start two servers for dual-stack support.\n            # On Linux, this would also be achievable by toggling IPV6_V6ONLY off, but this here works cross-platform.\n            if host == \"\":\n                ipv4 = await mitmproxy_rs.start_udp_server(\n                    \"0.0.0.0\",\n                    port,\n                    self.handle_udp_stream,\n                )\n                servers.append(ipv4)\n                try:\n                    ipv6 = await mitmproxy_rs.start_udp_server(\n                        \"::\",\n                        ipv4.getsockname()[1],\n                        self.handle_udp_stream,\n                    )\n                    servers.append(ipv6)  # pragma: no cover\n                except Exception:  # pragma: no cover\n                    logger.debug(\"Failed to listen on '::', listening on IPv4 only.\")\n            else:\n                servers.append(\n                    await mitmproxy_rs.start_udp_server(\n                        host,\n                        port,\n                        self.handle_udp_stream,\n                    )\n                )\n\n        return servers\n\n\nclass WireGuardServerInstance(ServerInstance[mode_specs.WireGuardMode]):\n    _server: mitmproxy_rs.WireGuardServer | None = None\n\n    server_key: str\n    client_key: str\n\n    def make_top_layer(\n        self, context: Context\n    ) -> Layer:  # pragma: no cover on platforms without wg-test-client\n        return layers.modes.TransparentProxy(context)\n\n    @property\n    def is_running(self) -> bool:\n        return self._server is not None\n\n    @property\n    def listen_addrs(self) -> tuple[Address, ...]:\n        if self._server:\n            return (self._server.getsockname(),)\n        else:\n            return tuple()\n\n    async def _start(self) -> None:\n        assert self._server is None\n        host = self.mode.listen_host(ctx.options.listen_host)\n        port = self.mode.listen_port(ctx.options.listen_port)\n\n        if self.mode.data:\n            conf_path = Path(self.mode.data).expanduser()\n        else:\n            conf_path = Path(ctx.options.confdir).expanduser() / \"wireguard.conf\"\n\n        if not conf_path.exists():\n            conf_path.parent.mkdir(parents=True, exist_ok=True)\n            conf_path.write_text(\n                json.dumps(\n                    {\n                        \"server_key\": mitmproxy_rs.genkey(),\n                        \"client_key\": mitmproxy_rs.genkey(),\n                    },\n                    indent=4,\n                )\n            )\n\n        try:\n            c = json.loads(conf_path.read_text())\n            self.server_key = c[\"server_key\"]\n            self.client_key = c[\"client_key\"]\n        except Exception as e:\n            raise ValueError(f\"Invalid configuration file ({conf_path}): {e}\") from e\n        # error early on invalid keys\n        p = mitmproxy_rs.pubkey(self.client_key)\n        _ = mitmproxy_rs.pubkey(self.server_key)\n\n        self._server = await mitmproxy_rs.start_wireguard_server(\n            host or \"0.0.0.0\",\n            port,\n            self.server_key,\n            [p],\n            self.wg_handle_stream,\n            self.wg_handle_stream,\n        )\n\n        conf = self.client_conf()\n        assert conf\n        logger.info(\"-\" * 60 + \"\\n\" + conf + \"\\n\" + \"-\" * 60)\n\n    def client_conf(self) -> str | None:\n        if not self._server:\n            return None\n        host = (\n            self.mode.listen_host(ctx.options.listen_host)\n            or local_ip.get_local_ip()\n            or local_ip.get_local_ip6()\n        )\n        port = self.mode.listen_port(ctx.options.listen_port)\n        return textwrap.dedent(\n            f\"\"\"\n            [Interface]\n            PrivateKey = {self.client_key}\n            Address = 10.0.0.1/32\n            DNS = 10.0.0.53\n\n            [Peer]\n            PublicKey = {mitmproxy_rs.pubkey(self.server_key)}\n            AllowedIPs = 0.0.0.0/0\n            Endpoint = {host}:{port}\n            \"\"\"\n        ).strip()\n\n    def to_json(self) -> dict:\n        return {\"wireguard_conf\": self.client_conf(), **super().to_json()}\n\n    async def _stop(self) -> None:\n        assert self._server is not None\n        try:\n            self._server.close()\n            await self._server.wait_closed()\n        finally:\n            self._server = None\n\n    async def wg_handle_stream(\n        self, stream: mitmproxy_rs.Stream\n    ) -> None:  # pragma: no cover on platforms without wg-test-client\n        await self.handle_stream(stream, stream)\n\n\nclass LocalRedirectorInstance(ServerInstance[mode_specs.LocalMode]):\n    _server: ClassVar[mitmproxy_rs.LocalRedirector | None] = None\n    \"\"\"The local redirector daemon. Will be started once and then reused for all future instances.\"\"\"\n    _instance: ClassVar[LocalRedirectorInstance | None] = None\n    \"\"\"The current LocalRedirectorInstance. Will be unset again if an instance is stopped.\"\"\"\n    listen_addrs = ()\n\n    @property\n    def is_running(self) -> bool:\n        return self._instance is not None\n\n    def make_top_layer(self, context: Context) -> Layer:\n        return layers.modes.TransparentProxy(context)\n\n    @classmethod\n    async def redirector_handle_stream(\n        cls,\n        stream: mitmproxy_rs.Stream,\n    ) -> None:\n        if cls._instance is not None:\n            await cls._instance.handle_stream(stream, stream)\n\n    async def _start(self) -> None:\n        if self._instance:\n            raise RuntimeError(\"Cannot spawn more than one local redirector.\")\n\n        if self.mode.data.startswith(\"!\"):\n            spec = f\"{self.mode.data},{os.getpid()}\"\n        elif self.mode.data:\n            spec = self.mode.data\n        else:\n            spec = f\"!{os.getpid()}\"\n\n        cls = self.__class__\n        cls._instance = self  # assign before awaiting to avoid races\n        if cls._server is None:\n            try:\n                cls._server = await mitmproxy_rs.start_local_redirector(\n                    cls.redirector_handle_stream,\n                    cls.redirector_handle_stream,\n                )\n            except Exception:\n                cls._instance = None\n                raise\n\n        cls._server.set_intercept(spec)\n\n    async def _stop(self) -> None:\n        assert self._instance\n        assert self._server\n        self.__class__._instance = None\n        # We're not shutting down the server because we want to avoid additional UAC prompts.\n        self._server.set_intercept(\"\")\n\n\nclass RegularInstance(AsyncioServerInstance[mode_specs.RegularMode]):\n    def make_top_layer(self, context: Context) -> Layer:\n        return layers.modes.HttpProxy(context)\n\n\nclass UpstreamInstance(AsyncioServerInstance[mode_specs.UpstreamMode]):\n    def make_top_layer(self, context: Context) -> Layer:\n        return layers.modes.HttpUpstreamProxy(context)\n\n\nclass TransparentInstance(AsyncioServerInstance[mode_specs.TransparentMode]):\n    def make_top_layer(self, context: Context) -> Layer:\n        return layers.modes.TransparentProxy(context)\n\n\nclass ReverseInstance(AsyncioServerInstance[mode_specs.ReverseMode]):\n    def make_top_layer(self, context: Context) -> Layer:\n        return layers.modes.ReverseProxy(context)\n\n\nclass Socks5Instance(AsyncioServerInstance[mode_specs.Socks5Mode]):\n    def make_top_layer(self, context: Context) -> Layer:\n        return layers.modes.Socks5Proxy(context)\n\n\nclass DnsInstance(AsyncioServerInstance[mode_specs.DnsMode]):\n    def make_top_layer(self, context: Context) -> Layer:\n        return layers.DNSLayer(context)\n\n\n# class Http3Instance(AsyncioServerInstance[mode_specs.Http3Mode]):\n#     def make_top_layer(self, context: Context) -> Layer:\n#         return layers.modes.HttpProxy(context)\n", "mitmproxy/proxy/utils.py": "\"\"\"\nUtility decorators that help build state machines\n\"\"\"\n\nimport functools\n\nfrom mitmproxy.proxy import events\n\n\ndef expect(*event_types):\n    \"\"\"\n    Only allow the given event type.\n    If another event is passed, an AssertionError is raised.\n    \"\"\"\n\n    def decorator(f):\n        if __debug__ is True:\n\n            @functools.wraps(f)\n            def _check_event_type(self, event: events.Event):\n                if isinstance(event, event_types):\n                    return f(self, event)\n                else:\n                    event_types_str = (\n                        \"|\".join(e.__name__ for e in event_types) or \"no events\"\n                    )\n                    raise AssertionError(\n                        f\"Unexpected event type at {f.__qualname__}: \"\n                        f\"Expected {event_types_str}, got {event}.\"\n                    )\n\n            return _check_event_type\n        else:  # pragma: no cover\n            return f\n\n    return decorator\n\n\nclass ReceiveBuffer:\n    \"\"\"\n    A data structure to collect stream contents efficiently in O(n).\n    \"\"\"\n\n    _chunks: list[bytes]\n    _len: int\n\n    def __init__(self):\n        self._chunks = []\n        self._len = 0\n\n    def __iadd__(self, other: bytes):\n        assert isinstance(other, bytes)\n        self._chunks.append(other)\n        self._len += len(other)\n        return self\n\n    def __len__(self):\n        return self._len\n\n    def __bytes__(self):\n        return b\"\".join(self._chunks)\n\n    def __bool__(self):\n        return self._len > 0\n\n    def clear(self):\n        self._chunks.clear()\n        self._len = 0\n", "mitmproxy/proxy/tunnel.py": "import time\nfrom enum import auto\nfrom enum import Enum\nfrom typing import Union\n\nfrom mitmproxy import connection\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.layer import Layer\n\n\nclass TunnelState(Enum):\n    INACTIVE = auto()\n    ESTABLISHING = auto()\n    OPEN = auto()\n    CLOSED = auto()\n\n\nclass TunnelLayer(layer.Layer):\n    \"\"\"\n    A specialized layer that simplifies the implementation of tunneling protocols such as SOCKS, upstream HTTP proxies,\n    or TLS.\n    \"\"\"\n\n    child_layer: layer.Layer\n    tunnel_connection: connection.Connection\n    \"\"\"The 'outer' connection which provides the tunnel protocol I/O\"\"\"\n    conn: connection.Connection\n    \"\"\"The 'inner' connection which provides data I/O\"\"\"\n    tunnel_state: TunnelState = TunnelState.INACTIVE\n    command_to_reply_to: commands.OpenConnection | None = None\n    _event_queue: list[events.Event]\n    \"\"\"\n    If the connection already exists when we receive the start event,\n    we buffer commands until we have established the tunnel.\n    \"\"\"\n\n    def __init__(\n        self,\n        context: context.Context,\n        tunnel_connection: connection.Connection,\n        conn: connection.Connection,\n    ):\n        super().__init__(context)\n        self.tunnel_connection = tunnel_connection\n        self.conn = conn\n        self.child_layer = layer.NextLayer(self.context)\n        self._event_queue = []\n\n    def __repr__(self):\n        return f\"{type(self).__name__}({self.tunnel_state.name.lower()})\"\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, events.Start):\n            if self.tunnel_connection.state is not connection.ConnectionState.CLOSED:\n                # we might be in the interesting state here where the connection is already half-closed,\n                # for example because next_layer buffered events and the client disconnected in the meantime.\n                # we still expect a close event to arrive, so we carry on here as normal for now.\n                self.tunnel_state = TunnelState.ESTABLISHING\n                yield from self.start_handshake()\n            yield from self.event_to_child(event)\n        elif (\n            isinstance(event, events.ConnectionEvent)\n            and event.connection == self.tunnel_connection\n        ):\n            if isinstance(event, events.DataReceived):\n                if self.tunnel_state is TunnelState.ESTABLISHING:\n                    done, err = yield from self.receive_handshake_data(event.data)\n                    if done:\n                        if self.conn != self.tunnel_connection:\n                            self.conn.state = connection.ConnectionState.OPEN\n                            self.conn.timestamp_start = time.time()\n                    if err:\n                        if self.conn != self.tunnel_connection:\n                            self.conn.state = connection.ConnectionState.CLOSED\n                            self.conn.timestamp_start = time.time()\n                        yield from self.on_handshake_error(err)\n                    if done or err:\n                        yield from self._handshake_finished(err)\n                else:\n                    yield from self.receive_data(event.data)\n            elif isinstance(event, events.ConnectionClosed):\n                if self.conn != self.tunnel_connection:\n                    self.conn.state &= ~connection.ConnectionState.CAN_READ\n                    self.conn.timestamp_end = time.time()\n                if self.tunnel_state is TunnelState.OPEN:\n                    yield from self.receive_close()\n                elif self.tunnel_state is TunnelState.ESTABLISHING:\n                    err = \"connection closed\"\n                    yield from self.on_handshake_error(err)\n                    yield from self._handshake_finished(err)\n                self.tunnel_state = TunnelState.CLOSED\n            else:  # pragma: no cover\n                raise AssertionError(f\"Unexpected event: {event}\")\n        else:\n            yield from self.event_to_child(event)\n\n    def _handshake_finished(self, err: str | None) -> layer.CommandGenerator[None]:\n        if err:\n            self.tunnel_state = TunnelState.CLOSED\n        else:\n            self.tunnel_state = TunnelState.OPEN\n        if self.command_to_reply_to:\n            yield from self.event_to_child(\n                events.OpenConnectionCompleted(self.command_to_reply_to, err)\n            )\n            self.command_to_reply_to = None\n        else:\n            for evt in self._event_queue:\n                yield from self.event_to_child(evt)\n            self._event_queue.clear()\n\n    def _handle_command(\n        self, command: commands.Command\n    ) -> layer.CommandGenerator[None]:\n        if (\n            isinstance(command, commands.ConnectionCommand)\n            and command.connection == self.conn\n        ):\n            if isinstance(command, commands.SendData):\n                yield from self.send_data(command.data)\n            elif isinstance(command, commands.CloseConnection):\n                if self.conn != self.tunnel_connection:\n                    self.conn.state &= ~connection.ConnectionState.CAN_WRITE\n                    command.connection = self.tunnel_connection\n                yield from self.send_close(command)\n            elif isinstance(command, commands.OpenConnection):\n                # create our own OpenConnection command object that blocks here.\n                self.command_to_reply_to = command\n                self.tunnel_state = TunnelState.ESTABLISHING\n                err = yield commands.OpenConnection(self.tunnel_connection)\n                if err:\n                    yield from self.event_to_child(\n                        events.OpenConnectionCompleted(command, err)\n                    )\n                    self.tunnel_state = TunnelState.CLOSED\n                else:\n                    yield from self.start_handshake()\n            else:  # pragma: no cover\n                raise AssertionError(f\"Unexpected command: {command}\")\n        else:\n            yield command\n\n    def event_to_child(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if (\n            self.tunnel_state is TunnelState.ESTABLISHING\n            and not self.command_to_reply_to\n        ):\n            self._event_queue.append(event)\n            return\n        for command in self.child_layer.handle_event(event):\n            yield from self._handle_command(command)\n\n    def start_handshake(self) -> layer.CommandGenerator[None]:\n        yield from self._handle_event(events.DataReceived(self.tunnel_connection, b\"\"))\n\n    def receive_handshake_data(\n        self, data: bytes\n    ) -> layer.CommandGenerator[tuple[bool, str | None]]:\n        \"\"\"returns a (done, err) tuple\"\"\"\n        yield from ()\n        return True, None\n\n    def on_handshake_error(self, err: str) -> layer.CommandGenerator[None]:\n        \"\"\"Called if either receive_handshake_data returns an error or we receive a close during handshake.\"\"\"\n        yield commands.CloseConnection(self.tunnel_connection)\n\n    def receive_data(self, data: bytes) -> layer.CommandGenerator[None]:\n        yield from self.event_to_child(events.DataReceived(self.conn, data))\n\n    def receive_close(self) -> layer.CommandGenerator[None]:\n        yield from self.event_to_child(events.ConnectionClosed(self.conn))\n\n    def send_data(self, data: bytes) -> layer.CommandGenerator[None]:\n        yield commands.SendData(self.tunnel_connection, data)\n\n    def send_close(\n        self, command: commands.CloseConnection\n    ) -> layer.CommandGenerator[None]:\n        yield command\n\n\nclass LayerStack:\n    def __init__(self) -> None:\n        self._stack: list[Layer] = []\n\n    def __getitem__(self, item: int) -> Layer:\n        return self._stack.__getitem__(item)\n\n    def __truediv__(self, other: Union[Layer, \"LayerStack\"]) -> \"LayerStack\":\n        if isinstance(other, Layer):\n            if self._stack:\n                self._stack[-1].child_layer = other  # type: ignore\n            self._stack.append(other)\n        else:\n            if self._stack:\n                self._stack[-1].child_layer = other[0]  # type: ignore\n            self._stack.extend(other._stack)\n        return self\n", "mitmproxy/proxy/layer.py": "\"\"\"\nBase class for protocol layers.\n\"\"\"\n\nimport collections\nimport textwrap\nfrom abc import abstractmethod\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom dataclasses import dataclass\nfrom logging import DEBUG\nfrom typing import Any\nfrom typing import ClassVar\nfrom typing import NamedTuple\nfrom typing import TypeVar\n\nfrom mitmproxy.connection import Connection\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy.commands import Command\nfrom mitmproxy.proxy.commands import StartHook\nfrom mitmproxy.proxy.context import Context\n\nT = TypeVar(\"T\")\nCommandGenerator = Generator[Command, Any, T]\n\"\"\"\nA function annotated with CommandGenerator[bool] may yield commands and ultimately return a boolean value.\n\"\"\"\n\n\nMAX_LOG_STATEMENT_SIZE = 512\n\"\"\"Maximum size of individual log statements before they will be truncated.\"\"\"\n\n\nclass Paused(NamedTuple):\n    \"\"\"\n    State of a layer that's paused because it is waiting for a command reply.\n    \"\"\"\n\n    command: commands.Command\n    generator: CommandGenerator\n\n\nclass Layer:\n    \"\"\"\n    The base class for all protocol layers.\n\n    Layers interface with their child layer(s) by calling .handle_event(event),\n    which returns a list (more precisely: a generator) of commands.\n    Most layers do not implement .directly, but instead implement ._handle_event, which\n    is called by the default implementation of .handle_event.\n    The default implementation of .handle_event allows layers to emulate blocking code:\n    When ._handle_event yields a command that has its blocking attribute set to True, .handle_event pauses\n    the execution of ._handle_event and waits until it is called with the corresponding CommandCompleted event.\n    All events encountered in the meantime are buffered and replayed after execution is resumed.\n\n    The result is code that looks like blocking code, but is not blocking:\n\n        def _handle_event(self, event):\n            err = yield OpenConnection(server)  # execution continues here after a connection has been established.\n\n    Technically this is very similar to how coroutines are implemented.\n    \"\"\"\n\n    __last_debug_message: ClassVar[str] = \"\"\n    context: Context\n    _paused: Paused | None\n    \"\"\"\n    If execution is currently paused, this attribute stores the paused coroutine\n    and the command for which we are expecting a reply.\n    \"\"\"\n    _paused_event_queue: collections.deque[events.Event]\n    \"\"\"\n    All events that have occurred since execution was paused.\n    These will be replayed to ._child_layer once we resume.\n    \"\"\"\n    debug: str | None = None\n    \"\"\"\n    Enable debug logging by assigning a prefix string for log messages.\n    Different amounts of whitespace for different layers work well.\n    \"\"\"\n\n    def __init__(self, context: Context) -> None:\n        self.context = context\n        self.context.layers.append(self)\n        self._paused = None\n        self._paused_event_queue = collections.deque()\n\n        show_debug_output = getattr(context.options, \"proxy_debug\", False)\n        if show_debug_output:  # pragma: no cover\n            self.debug = \"  \" * len(context.layers)\n\n    def __repr__(self):\n        statefun = getattr(self, \"state\", self._handle_event)\n        state = getattr(statefun, \"__name__\", \"\")\n        state = state.replace(\"state_\", \"\")\n        if state == \"_handle_event\":\n            state = \"\"\n        else:\n            state = f\"state: {state}\"\n        return f\"{type(self).__name__}({state})\"\n\n    def __debug(self, message):\n        \"\"\"yield a Log command indicating what message is passing through this layer.\"\"\"\n        if len(message) > MAX_LOG_STATEMENT_SIZE:\n            message = message[:MAX_LOG_STATEMENT_SIZE] + \"\u2026\"\n        if Layer.__last_debug_message == message:\n            message = message.split(\"\\n\", 1)[0].strip()\n            if len(message) > 256:\n                message = message[:256] + \"\u2026\"\n        else:\n            Layer.__last_debug_message = message\n        assert self.debug is not None\n        return commands.Log(textwrap.indent(message, self.debug), DEBUG)\n\n    @property\n    def stack_pos(self) -> str:\n        \"\"\"repr() for this layer and all its parent layers, only useful for debugging.\"\"\"\n        try:\n            idx = self.context.layers.index(self)\n        except ValueError:\n            return repr(self)\n        else:\n            return \" >> \".join(repr(x) for x in self.context.layers[: idx + 1])\n\n    @abstractmethod\n    def _handle_event(self, event: events.Event) -> CommandGenerator[None]:\n        \"\"\"Handle a proxy server event\"\"\"\n        yield from ()  # pragma: no cover\n\n    def handle_event(self, event: events.Event) -> CommandGenerator[None]:\n        if self._paused:\n            # did we just receive the reply we were waiting for?\n            pause_finished = (\n                isinstance(event, events.CommandCompleted)\n                and event.command is self._paused.command\n            )\n            if self.debug is not None:\n                yield self.__debug(f\"{'>>' if pause_finished else '>!'} {event}\")\n            if pause_finished:\n                assert isinstance(event, events.CommandCompleted)\n                yield from self.__continue(event)\n            else:\n                self._paused_event_queue.append(event)\n        else:\n            if self.debug is not None:\n                yield self.__debug(f\">> {event}\")\n            command_generator = self._handle_event(event)\n            send = None\n\n            # inlined copy of __process to reduce call stack.\n            # <\u2702\u2702\u2702>\n            try:\n                # Run ._handle_event to the next yield statement.\n                # If you are not familiar with generators and their .send() method,\n                # https://stackoverflow.com/a/12638313/934719 has a good explanation.\n                command = command_generator.send(send)\n            except StopIteration:\n                return\n\n            while True:\n                if self.debug is not None:\n                    if not isinstance(command, commands.Log):\n                        yield self.__debug(f\"<< {command}\")\n                if command.blocking is True:\n                    # We only want this layer to block, the outer layers should not block.\n                    # For example, take an HTTP/2 connection: If we intercept one particular request,\n                    # we don't want all other requests in the connection to be blocked a well.\n                    # We signal to outer layers that this command is already handled by assigning our layer to\n                    # `.blocking` here (upper layers explicitly check for `is True`).\n                    command.blocking = self\n                    self._paused = Paused(\n                        command,\n                        command_generator,\n                    )\n                    yield command\n                    return\n                else:\n                    yield command\n                    try:\n                        command = next(command_generator)\n                    except StopIteration:\n                        return\n            # </\u2702\u2702\u2702>\n\n    def __process(self, command_generator: CommandGenerator, send=None):\n        \"\"\"\n        Yield commands from a generator.\n        If a command is blocking, execution is paused and this function returns without\n        processing any further commands.\n        \"\"\"\n        try:\n            # Run ._handle_event to the next yield statement.\n            # If you are not familiar with generators and their .send() method,\n            # https://stackoverflow.com/a/12638313/934719 has a good explanation.\n            command = command_generator.send(send)\n        except StopIteration:\n            return\n\n        while True:\n            if self.debug is not None:\n                if not isinstance(command, commands.Log):\n                    yield self.__debug(f\"<< {command}\")\n            if command.blocking is True:\n                # We only want this layer to block, the outer layers should not block.\n                # For example, take an HTTP/2 connection: If we intercept one particular request,\n                # we don't want all other requests in the connection to be blocked a well.\n                # We signal to outer layers that this command is already handled by assigning our layer to\n                # `.blocking` here (upper layers explicitly check for `is True`).\n                command.blocking = self\n                self._paused = Paused(\n                    command,\n                    command_generator,\n                )\n                yield command\n                return\n            else:\n                yield command\n                try:\n                    command = next(command_generator)\n                except StopIteration:\n                    return\n\n    def __continue(self, event: events.CommandCompleted):\n        \"\"\"\n        Continue processing events after being paused.\n        The tricky part here is that events in the event queue may trigger commands which again pause the execution,\n        so we may not be able to process the entire queue.\n        \"\"\"\n        assert self._paused is not None\n        command_generator = self._paused.generator\n        self._paused = None\n        yield from self.__process(command_generator, event.reply)\n\n        while not self._paused and self._paused_event_queue:\n            ev = self._paused_event_queue.popleft()\n            if self.debug is not None:\n                yield self.__debug(f\"!> {ev}\")\n            command_generator = self._handle_event(ev)\n            yield from self.__process(command_generator)\n\n\nmevents = (\n    events  # alias here because autocomplete above should not have aliased version.\n)\n\n\nclass NextLayer(Layer):\n    layer: Layer | None\n    \"\"\"The next layer. To be set by an addon.\"\"\"\n\n    events: list[mevents.Event]\n    \"\"\"All events that happened before a decision was made.\"\"\"\n\n    _ask_on_start: bool\n\n    def __init__(self, context: Context, ask_on_start: bool = False) -> None:\n        super().__init__(context)\n        self.context.layers.remove(self)\n        self.layer = None\n        self.events = []\n        self._ask_on_start = ask_on_start\n        self._handle: Callable[[mevents.Event], CommandGenerator[None]] | None = None\n\n    def __repr__(self):\n        return f\"NextLayer:{repr(self.layer)}\"\n\n    def handle_event(self, event: mevents.Event):\n        if self._handle is not None:\n            yield from self._handle(event)\n        else:\n            yield from super().handle_event(event)\n\n    def _handle_event(self, event: mevents.Event):\n        self.events.append(event)\n\n        # We receive new data. Let's find out if we can determine the next layer now?\n        if self._ask_on_start and isinstance(event, events.Start):\n            yield from self._ask()\n        elif (\n            isinstance(event, mevents.ConnectionClosed)\n            and event.connection == self.context.client\n        ):\n            # If we have not determined the next protocol yet and the client already closes the connection,\n            # we abort everything.\n            yield commands.CloseConnection(self.context.client)\n        elif isinstance(event, mevents.DataReceived):\n            # For now, we only ask if we have received new data to reduce hook noise.\n            yield from self._ask()\n\n    def _ask(self):\n        \"\"\"\n        Manually trigger a next_layer hook.\n        The only use at the moment is to make sure that the top layer is initialized.\n        \"\"\"\n        yield NextLayerHook(self)\n\n        # Has an addon decided on the next layer yet?\n        if self.layer:\n            if self.debug:\n                yield commands.Log(f\"{self.debug}[nextlayer] {self.layer!r}\", DEBUG)\n            for e in self.events:\n                yield from self.layer.handle_event(e)\n            self.events.clear()\n\n            # Why do we need three assignments here?\n            #  1. When this function here is invoked we may have paused events. Those should be\n            #     forwarded to the sublayer right away, so we reassign ._handle_event.\n            #  2. This layer is not needed anymore, so we directly reassign .handle_event.\n            #  3. Some layers may however still have a reference to the old .handle_event.\n            #     ._handle is just an optimization to reduce the callstack in these cases.\n            self.handle_event = self.layer.handle_event  # type: ignore\n            self._handle_event = self.layer.handle_event  # type: ignore\n            self._handle = self.layer.handle_event\n\n    # Utility methods for whoever decides what the next layer is going to be.\n    def data_client(self):\n        return self._data(self.context.client)\n\n    def data_server(self):\n        return self._data(self.context.server)\n\n    def _data(self, connection: Connection):\n        data = (\n            e.data\n            for e in self.events\n            if isinstance(e, mevents.DataReceived) and e.connection == connection\n        )\n        return b\"\".join(data)\n\n\n@dataclass\nclass NextLayerHook(StartHook):\n    \"\"\"\n    Network layers are being switched. You may change which layer will be used by setting data.layer.\n\n    (by default, this is done by mitmproxy.addons.NextLayer)\n    \"\"\"\n\n    data: NextLayer\n", "mitmproxy/proxy/commands.py": "\"\"\"\nCommands make it possible for layers to communicate with the \"outer world\",\ne.g. to perform IO or to ask the master.\nA command is issued by a proxy layer and is then passed upwards to the proxy server, and from there\npossibly to the master and addons.\n\nThe counterpart to commands are events.\n\"\"\"\n\nimport logging\nimport warnings\nfrom typing import TYPE_CHECKING\nfrom typing import Union\n\nimport mitmproxy.hooks\nfrom mitmproxy.connection import Connection\nfrom mitmproxy.connection import Server\n\nif TYPE_CHECKING:\n    import mitmproxy.proxy.layer\n\n\nclass Command:\n    \"\"\"\n    Base class for all commands\n    \"\"\"\n\n    blocking: Union[bool, \"mitmproxy.proxy.layer.Layer\"] = False\n    \"\"\"\n    Determines if the command blocks until it has been completed.\n    For practical purposes, this attribute should be thought of as a boolean value,\n    layers may swap out `True` with a reference to themselves to signal to outer layers\n    that they do not need to block as well.\n\n    Example:\n\n        reply = yield Hook(\"requestheaders\", flow)  # blocking command\n        yield Log(\"hello world\", \"info\")            # non-blocking\n    \"\"\"\n\n    def __repr__(self):\n        x = self.__dict__.copy()\n        x.pop(\"blocking\", None)\n        return f\"{type(self).__name__}({repr(x)})\"\n\n\nclass RequestWakeup(Command):\n    \"\"\"\n    Request a `Wakeup` event after the specified amount of seconds.\n    \"\"\"\n\n    delay: float\n\n    def __init__(self, delay: float):\n        self.delay = delay\n\n\nclass ConnectionCommand(Command):\n    \"\"\"\n    Commands involving a specific connection\n    \"\"\"\n\n    connection: Connection\n\n    def __init__(self, connection: Connection):\n        self.connection = connection\n\n\nclass SendData(ConnectionCommand):\n    \"\"\"\n    Send data to a remote peer\n    \"\"\"\n\n    data: bytes\n\n    def __init__(self, connection: Connection, data: bytes):\n        super().__init__(connection)\n        self.data = data\n\n    def __repr__(self):\n        target = str(self.connection).split(\"(\", 1)[0].lower()\n        return f\"SendData({target}, {self.data!r})\"\n\n\nclass OpenConnection(ConnectionCommand):\n    \"\"\"\n    Open a new connection\n    \"\"\"\n\n    connection: Server\n    blocking = True\n\n\nclass CloseConnection(ConnectionCommand):\n    \"\"\"\n    Close a connection. If the client connection is closed,\n    all other connections will ultimately be closed during cleanup.\n    \"\"\"\n\n\nclass CloseTcpConnection(CloseConnection):\n    half_close: bool\n    \"\"\"\n    If True, only close our half of the connection by sending a FIN packet.\n    This is required from some protocols which close their end to signal completion and then continue reading,\n    for example HTTP/1.0 without Content-Length header.\n    \"\"\"\n\n    def __init__(self, connection: Connection, half_close: bool = False):\n        super().__init__(connection)\n        self.half_close = half_close\n\n\nclass StartHook(Command, mitmproxy.hooks.Hook):\n    \"\"\"\n    Start an event hook in the mitmproxy core.\n    This triggers a particular function (derived from the class name) in all addons.\n    \"\"\"\n\n    name = \"\"\n    blocking = True\n\n    def __new__(cls, *args, **kwargs):\n        if cls is StartHook:\n            raise TypeError(\"StartHook may not be instantiated directly.\")\n        return super().__new__(cls, *args, **kwargs)\n\n\nclass Log(Command):\n    \"\"\"\n    Log a message.\n\n    Layers could technically call `logging.log` directly, but the use of a command allows us to\n    write more expressive playbook tests. Put differently, by using commands we can assert that\n    a specific log message is a direct consequence of a particular I/O event.\n    This could also be implemented with some more playbook magic in the future,\n    but for now we keep the current approach as the fully sans-io one.\n    \"\"\"\n\n    message: str\n    level: int\n\n    def __init__(\n        self,\n        message: str,\n        level: int = logging.INFO,\n    ):\n        if isinstance(level, str):  # pragma: no cover\n            warnings.warn(\n                \"commands.Log() now expects an integer log level, not a string.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            level = getattr(logging, level.upper())\n        self.message = message\n        self.level = level\n\n    def __repr__(self):\n        return f\"Log({self.message!r}, {logging.getLevelName(self.level).lower()})\"\n", "mitmproxy/proxy/__init__.py": "\"\"\"\nThis module contains mitmproxy's core network proxy.\n\nThe most important primitives are:\n\n    - Layers: represent protocol layers, e.g. one for TCP, TLS, and so on. Layers are nested, so\n      a typical configuration might be ReverseProxy/TLS/TCP.\n      Most importantly, layers are implemented using the sans-io pattern (https://sans-io.readthedocs.io/).\n      This means that calls return immediately, there is no blocking sync or async code.\n    - Server: the proxy server handles all I/O. This is implemented using `asyncio`, but could be done any other way.\n      The `ConnectionHandler` is subclassed in the `Proxyserver` addon, which handles the communication with the\n      rest of mitmproxy.\n    - Events: When I/O actions occur at the proxy server, they are passed to the outermost layer as events,\n      e.g. `DataReceived` or `ConnectionClosed`.\n    - Commands: In the other direction, layers can emit commands to higher layers or the proxy server.\n      This is used to e.g. send data, request for new connections to be opened, or to call mitmproxy's\n      event hooks.\n    - Context: The context is the connection context each layer is provided with, which is always a client connection\n      and sometimes also a server connection.\n\"\"\"\n", "mitmproxy/proxy/context.py": "from typing import TYPE_CHECKING\n\nfrom mitmproxy import connection\nfrom mitmproxy.options import Options\n\nif TYPE_CHECKING:\n    import mitmproxy.proxy.layer\n\n\nclass Context:\n    \"\"\"\n    The context object provided to each protocol layer in the proxy core.\n    \"\"\"\n\n    client: connection.Client\n    \"\"\"The client connection.\"\"\"\n    server: connection.Server\n    \"\"\"\n    The server connection.\n\n    For practical reasons this attribute is always set, even if there is not server connection yet.\n    In this case the server address is `None`.\n    \"\"\"\n    options: Options\n    \"\"\"\n    Provides access to options for proxy layers. Not intended for use by addons, use `mitmproxy.ctx.options` instead.\n    \"\"\"\n    layers: list[\"mitmproxy.proxy.layer.Layer\"]\n    \"\"\"\n    The protocol layer stack.\n    \"\"\"\n\n    def __init__(\n        self,\n        client: connection.Client,\n        options: Options,\n    ) -> None:\n        self.client = client\n        self.options = options\n        self.server = connection.Server(\n            address=None, transport_protocol=client.transport_protocol\n        )\n        self.layers = []\n\n    def fork(self) -> \"Context\":\n        ret = Context(self.client, self.options)\n        ret.server = self.server\n        ret.layers = self.layers.copy()\n        return ret\n\n    def __repr__(self):\n        return (\n            f\"Context(\\n\"\n            f\"  {self.client!r},\\n\"\n            f\"  {self.server!r},\\n\"\n            f\"  layers=[{self.layers!r}]\\n\"\n            f\")\"\n        )\n", "mitmproxy/proxy/server.py": "\"\"\"\nProxy Server Implementation using asyncio.\nThe very high level overview is as follows:\n\n    - Spawn one coroutine per client connection and create a reverse proxy layer to example.com\n    - Process any commands from layer (such as opening a server connection)\n    - Wait for any IO and send it as events to top layer.\n\"\"\"\n\nimport abc\nimport asyncio\nimport collections\nimport logging\nimport time\nfrom collections.abc import Awaitable\nfrom collections.abc import Callable\nfrom collections.abc import MutableMapping\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom types import TracebackType\nfrom typing import Literal\n\nimport mitmproxy_rs\nfrom OpenSSL import SSL\n\nfrom mitmproxy import http\nfrom mitmproxy import options as moptions\nfrom mitmproxy import tls\nfrom mitmproxy.connection import Address\nfrom mitmproxy.connection import Client\nfrom mitmproxy.connection import Connection\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy import layers\nfrom mitmproxy.proxy import mode_specs\nfrom mitmproxy.proxy import server_hooks\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.layers.http import HTTPMode\nfrom mitmproxy.utils import asyncio_utils\nfrom mitmproxy.utils import human\nfrom mitmproxy.utils.data import pkg_data\n\nlogger = logging.getLogger(__name__)\n\nTCP_TIMEOUT = 60 * 10\nUDP_TIMEOUT = 20\n\n\nclass TimeoutWatchdog:\n    last_activity: float\n    timeout: int\n    can_timeout: asyncio.Event\n    blocker: int\n\n    def __init__(self, timeout: int, callback: Callable[[], Awaitable]):\n        self.timeout = timeout\n        self.callback = callback\n        self.last_activity = time.time()\n        self.can_timeout = asyncio.Event()\n        self.can_timeout.set()\n        self.blocker = 0\n\n    def register_activity(self):\n        self.last_activity = time.time()\n\n    async def watch(self):\n        try:\n            while True:\n                await self.can_timeout.wait()\n                await asyncio.sleep(self.timeout - (time.time() - self.last_activity))\n                if self.last_activity + self.timeout < time.time():\n                    await self.callback()\n                    return\n        except asyncio.CancelledError:\n            return\n\n    @contextmanager\n    def disarm(self):\n        self.can_timeout.clear()\n        self.blocker += 1\n        try:\n            yield\n        finally:\n            self.blocker -= 1\n            if self.blocker == 0:\n                self.register_activity()\n                self.can_timeout.set()\n\n\n@dataclass\nclass ConnectionIO:\n    handler: asyncio.Task | None = None\n    reader: asyncio.StreamReader | mitmproxy_rs.Stream | None = None\n    writer: asyncio.StreamWriter | mitmproxy_rs.Stream | None = None\n\n\nclass ConnectionHandler(metaclass=abc.ABCMeta):\n    transports: MutableMapping[Connection, ConnectionIO]\n    timeout_watchdog: TimeoutWatchdog\n    client: Client\n    max_conns: collections.defaultdict[Address, asyncio.Semaphore]\n    layer: \"layer.Layer\"\n    wakeup_timer: set[asyncio.Task]\n    hook_tasks: set[asyncio.Task]\n\n    def __init__(self, context: Context) -> None:\n        self.client = context.client\n        self.transports = {}\n        self.max_conns = collections.defaultdict(lambda: asyncio.Semaphore(5))\n        self.wakeup_timer = set()\n        self.hook_tasks = set()\n\n        # Ask for the first layer right away.\n        # In a reverse proxy scenario, this is necessary as we would otherwise hang\n        # on protocols that start with a server greeting.\n        self.layer = layer.NextLayer(context, ask_on_start=True)\n        if self.client.transport_protocol == \"tcp\":\n            timeout = TCP_TIMEOUT\n        else:\n            timeout = UDP_TIMEOUT\n        self.timeout_watchdog = TimeoutWatchdog(timeout, self.on_timeout)\n\n        # workaround for https://bugs.python.org/issue40124 / https://bugs.python.org/issue29930\n        self._drain_lock = asyncio.Lock()\n\n    async def handle_client(self) -> None:\n        asyncio_utils.set_current_task_debug_info(\n            name=f\"client handler\",\n            client=self.client.peername,\n        )\n        watch = asyncio_utils.create_task(\n            self.timeout_watchdog.watch(),\n            name=\"timeout watchdog\",\n            client=self.client.peername,\n        )\n\n        self.log(\"client connect\")\n        await self.handle_hook(server_hooks.ClientConnectedHook(self.client))\n        if self.client.error:\n            self.log(\"client kill connection\")\n            writer = self.transports.pop(self.client).writer\n            assert writer\n            writer.close()\n        else:\n            self.server_event(events.Start())\n            handler = asyncio_utils.create_task(\n                self.handle_connection(self.client),\n                name=f\"client connection handler\",\n                client=self.client.peername,\n            )\n            self.transports[self.client].handler = handler\n            await asyncio.wait([handler])\n            if not handler.cancelled() and (e := handler.exception()):\n                self.log(\n                    f\"connection handler has crashed: {e}\",\n                    logging.ERROR,\n                    exc_info=(type(e), e, e.__traceback__),\n                )\n\n        watch.cancel()\n        while self.wakeup_timer:\n            timer = self.wakeup_timer.pop()\n            timer.cancel()\n\n        self.log(\"client disconnect\")\n        self.client.timestamp_end = time.time()\n        await self.handle_hook(server_hooks.ClientDisconnectedHook(self.client))\n\n        if self.transports:\n            self.log(\"closing transports...\", logging.DEBUG)\n            for io in self.transports.values():\n                if io.handler:\n                    io.handler.cancel(\"client disconnected\")\n            await asyncio.wait(\n                [x.handler for x in self.transports.values() if x.handler]\n            )\n            self.log(\"transports closed!\", logging.DEBUG)\n\n    async def open_connection(self, command: commands.OpenConnection) -> None:\n        if not command.connection.address:\n            self.log(f\"Cannot open connection, no hostname given.\")\n            self.server_event(\n                events.OpenConnectionCompleted(\n                    command, f\"Cannot open connection, no hostname given.\"\n                )\n            )\n            return\n\n        hook_data = server_hooks.ServerConnectionHookData(\n            client=self.client, server=command.connection\n        )\n        await self.handle_hook(server_hooks.ServerConnectHook(hook_data))\n        if err := command.connection.error:\n            self.log(\n                f\"server connection to {human.format_address(command.connection.address)} killed before connect: {err}\"\n            )\n            await self.handle_hook(server_hooks.ServerConnectErrorHook(hook_data))\n            self.server_event(\n                events.OpenConnectionCompleted(command, f\"Connection killed: {err}\")\n            )\n            return\n\n        async with self.max_conns[command.connection.address]:\n            reader: asyncio.StreamReader | mitmproxy_rs.Stream\n            writer: asyncio.StreamWriter | mitmproxy_rs.Stream\n            try:\n                command.connection.timestamp_start = time.time()\n                if command.connection.transport_protocol == \"tcp\":\n                    reader, writer = await asyncio.open_connection(\n                        *command.connection.address,\n                        local_addr=command.connection.sockname,\n                    )\n                elif command.connection.transport_protocol == \"udp\":\n                    reader = writer = await mitmproxy_rs.open_udp_connection(\n                        *command.connection.address,\n                        local_addr=command.connection.sockname,\n                    )\n                else:\n                    raise AssertionError(command.connection.transport_protocol)\n            except (OSError, asyncio.CancelledError) as e:\n                err = str(e)\n                if not err:  # str(CancelledError()) returns empty string.\n                    err = \"connection cancelled\"\n                self.log(f\"error establishing server connection: {err}\")\n                command.connection.error = err\n                await self.handle_hook(server_hooks.ServerConnectErrorHook(hook_data))\n                self.server_event(events.OpenConnectionCompleted(command, err))\n                if isinstance(e, asyncio.CancelledError):\n                    # From https://docs.python.org/3/library/asyncio-exceptions.html#asyncio.CancelledError:\n                    # > In almost all situations the exception must be re-raised.\n                    # It is not really defined what almost means here, but we play safe.\n                    raise\n            else:\n                if command.connection.transport_protocol == \"tcp\":\n                    # TODO: Rename to `timestamp_setup` and make it agnostic for both TCP (SYN/ACK) and UDP (DNS resl.)\n                    command.connection.timestamp_tcp_setup = time.time()\n                command.connection.state = ConnectionState.OPEN\n                command.connection.peername = writer.get_extra_info(\"peername\")\n                command.connection.sockname = writer.get_extra_info(\"sockname\")\n                self.transports[command.connection] = ConnectionIO(\n                    handler=asyncio.current_task(),\n                    reader=reader,\n                    writer=writer,\n                )\n\n                assert command.connection.peername\n                if command.connection.address[0] != command.connection.peername[0]:\n                    addr = f\"{human.format_address(command.connection.address)} ({human.format_address(command.connection.peername)})\"\n                else:\n                    addr = human.format_address(command.connection.address)\n                self.log(f\"server connect {addr}\")\n                await self.handle_hook(server_hooks.ServerConnectedHook(hook_data))\n                self.server_event(events.OpenConnectionCompleted(command, None))\n\n                try:\n                    await self.handle_connection(command.connection)\n                finally:\n                    self.log(f\"server disconnect {addr}\")\n                    command.connection.timestamp_end = time.time()\n                    await self.handle_hook(\n                        server_hooks.ServerDisconnectedHook(hook_data)\n                    )\n\n    async def wakeup(self, request: commands.RequestWakeup) -> None:\n        await asyncio.sleep(request.delay)\n        task = asyncio.current_task()\n        assert task is not None\n        self.wakeup_timer.discard(task)\n        self.server_event(events.Wakeup(request))\n\n    async def handle_connection(self, connection: Connection) -> None:\n        \"\"\"\n        Handle a connection for its entire lifetime.\n        This means we read until EOF,\n        but then possibly also keep on waiting for our side of the connection to be closed.\n        \"\"\"\n        cancelled = None\n        reader = self.transports[connection].reader\n        assert reader\n        while True:\n            try:\n                data = await reader.read(65535)\n                if not data:\n                    raise OSError(\"Connection closed by peer.\")\n            except OSError:\n                break\n            except asyncio.CancelledError as e:\n                cancelled = e\n                break\n\n            self.server_event(events.DataReceived(connection, data))\n\n            try:\n                await self.drain_writers()\n            except asyncio.CancelledError as e:\n                cancelled = e\n                break\n\n        if cancelled is None and connection.transport_protocol == \"tcp\":\n            # TCP connections can be half-closed.\n            connection.state &= ~ConnectionState.CAN_READ\n        else:\n            connection.state = ConnectionState.CLOSED\n\n        self.server_event(events.ConnectionClosed(connection))\n\n        if connection.state is ConnectionState.CAN_WRITE:\n            # we may still use this connection to *send* stuff,\n            # even though the remote has closed their side of the connection.\n            # to make this work we keep this task running and wait for cancellation.\n            try:\n                await asyncio.Event().wait()\n            except asyncio.CancelledError as e:\n                cancelled = e\n\n        try:\n            writer = self.transports[connection].writer\n            assert writer\n            writer.close()\n        except OSError:\n            pass\n        self.transports.pop(connection)\n\n        if cancelled:\n            raise cancelled\n\n    async def drain_writers(self):\n        \"\"\"\n        Drain all writers to create some backpressure. We won't continue reading until there's space available in our\n        write buffers, so if we cannot write fast enough our own read buffers run full and the TCP recv stream is throttled.\n        \"\"\"\n        async with self._drain_lock:\n            for transport in list(self.transports.values()):\n                if transport.writer is not None:\n                    try:\n                        await transport.writer.drain()\n                    except OSError as e:\n                        if transport.handler is not None:\n                            transport.handler.cancel(f\"Error sending data: {e}\")\n\n    async def on_timeout(self) -> None:\n        try:\n            handler = self.transports[self.client].handler\n        except KeyError:  # pragma: no cover\n            # there is a super short window between connection close and watchdog cancellation\n            pass\n        else:\n            if self.client.transport_protocol == \"tcp\":\n                self.log(f\"Closing connection due to inactivity: {self.client}\")\n            assert handler\n            handler.cancel(\"timeout\")\n\n    async def hook_task(self, hook: commands.StartHook) -> None:\n        await self.handle_hook(hook)\n        if hook.blocking:\n            self.server_event(events.HookCompleted(hook))\n\n    @abc.abstractmethod\n    async def handle_hook(self, hook: commands.StartHook) -> None:\n        pass\n\n    def log(\n        self,\n        message: str,\n        level: int = logging.INFO,\n        exc_info: Literal[True]\n        | tuple[type[BaseException], BaseException, TracebackType | None]\n        | None = None,\n    ) -> None:\n        logger.log(\n            level, message, extra={\"client\": self.client.peername}, exc_info=exc_info\n        )\n\n    def server_event(self, event: events.Event) -> None:\n        self.timeout_watchdog.register_activity()\n        try:\n            layer_commands = self.layer.handle_event(event)\n            for command in layer_commands:\n                if isinstance(command, commands.OpenConnection):\n                    assert command.connection not in self.transports\n                    handler = asyncio_utils.create_task(\n                        self.open_connection(command),\n                        name=f\"server connection handler {command.connection.address}\",\n                        client=self.client.peername,\n                    )\n                    self.transports[command.connection] = ConnectionIO(handler=handler)\n                elif isinstance(command, commands.RequestWakeup):\n                    task = asyncio_utils.create_task(\n                        self.wakeup(command),\n                        name=f\"wakeup timer ({command.delay:.1f}s)\",\n                        client=self.client.peername,\n                    )\n                    assert task is not None\n                    self.wakeup_timer.add(task)\n                elif (\n                    isinstance(command, commands.ConnectionCommand)\n                    and command.connection not in self.transports\n                ):\n                    pass  # The connection has already been closed.\n                elif isinstance(command, commands.SendData):\n                    writer = self.transports[command.connection].writer\n                    assert writer\n                    if not writer.is_closing():\n                        writer.write(command.data)\n                elif isinstance(command, commands.CloseTcpConnection):\n                    self.close_connection(command.connection, command.half_close)\n                elif isinstance(command, commands.CloseConnection):\n                    self.close_connection(command.connection, False)\n                elif isinstance(command, commands.StartHook):\n                    t = asyncio_utils.create_task(\n                        self.hook_task(command),\n                        name=f\"handle_hook({command.name})\",\n                        client=self.client.peername,\n                    )\n                    # Python 3.11 Use TaskGroup instead.\n                    self.hook_tasks.add(t)\n                    t.add_done_callback(self.hook_tasks.remove)\n                elif isinstance(command, commands.Log):\n                    self.log(command.message, command.level)\n                else:\n                    raise RuntimeError(f\"Unexpected command: {command}\")\n        except Exception:\n            self.log(f\"mitmproxy has crashed!\", logging.ERROR, exc_info=True)\n\n    def close_connection(\n        self, connection: Connection, half_close: bool = False\n    ) -> None:\n        if half_close:\n            if not connection.state & ConnectionState.CAN_WRITE:\n                return\n            self.log(f\"half-closing {connection}\", logging.DEBUG)\n            try:\n                writer = self.transports[connection].writer\n                assert writer\n                if not writer.is_closing():\n                    writer.write_eof()\n            except OSError:\n                # if we can't write to the socket anymore we presume it completely dead.\n                connection.state = ConnectionState.CLOSED\n            else:\n                connection.state &= ~ConnectionState.CAN_WRITE\n        else:\n            connection.state = ConnectionState.CLOSED\n\n        if connection.state is ConnectionState.CLOSED:\n            handler = self.transports[connection].handler\n            assert handler\n            handler.cancel(\"closed by command\")\n\n\nclass LiveConnectionHandler(ConnectionHandler, metaclass=abc.ABCMeta):\n    def __init__(\n        self,\n        reader: asyncio.StreamReader | mitmproxy_rs.Stream,\n        writer: asyncio.StreamWriter | mitmproxy_rs.Stream,\n        options: moptions.Options,\n        mode: mode_specs.ProxyMode,\n    ) -> None:\n        client = Client(\n            transport_protocol=writer.get_extra_info(\"transport_protocol\", \"tcp\"),\n            peername=writer.get_extra_info(\"peername\"),\n            sockname=writer.get_extra_info(\"sockname\"),\n            timestamp_start=time.time(),\n            proxy_mode=mode,\n            state=ConnectionState.OPEN,\n        )\n        context = Context(client, options)\n        super().__init__(context)\n        self.transports[client] = ConnectionIO(\n            handler=None, reader=reader, writer=writer\n        )\n\n\nclass SimpleConnectionHandler(LiveConnectionHandler):  # pragma: no cover\n    \"\"\"Simple handler that does not really process any hooks.\"\"\"\n\n    hook_handlers: dict[str, Callable]\n\n    def __init__(self, reader, writer, options, mode, hooks):\n        super().__init__(reader, writer, options, mode)\n        self.hook_handlers = hooks\n\n    async def handle_hook(self, hook: commands.StartHook) -> None:\n        if hook.name in self.hook_handlers:\n            self.hook_handlers[hook.name](*hook.args())\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    # simple standalone implementation for testing.\n    loop = asyncio.get_event_loop()\n\n    opts = moptions.Options()\n    # options duplicated here to simplify testing setup\n    opts.add_option(\n        \"connection_strategy\",\n        str,\n        \"lazy\",\n        \"Determine when server connections should be established.\",\n        choices=(\"eager\", \"lazy\"),\n    )\n    opts.add_option(\n        \"keep_host_header\",\n        bool,\n        False,\n        \"\"\"\n        Reverse Proxy: Keep the original host header instead of rewriting it\n        to the reverse proxy target.\n        \"\"\",\n    )\n\n    async def handle(reader, writer):\n        layer_stack = [\n            # lambda ctx: layers.ServerTLSLayer(ctx),\n            # lambda ctx: layers.HttpLayer(ctx, HTTPMode.regular),\n            # lambda ctx: setattr(ctx.server, \"tls\", True) or layers.ServerTLSLayer(ctx),\n            # lambda ctx: layers.ClientTLSLayer(ctx),\n            lambda ctx: layers.modes.ReverseProxy(ctx),\n            lambda ctx: layers.HttpLayer(ctx, HTTPMode.transparent),\n        ]\n\n        def next_layer(nl: layer.NextLayer):\n            layr = layer_stack.pop(0)(nl.context)\n            layr.debug = \"  \" * len(nl.context.layers)\n            nl.layer = layr\n\n        def request(flow: http.HTTPFlow):\n            if \"cached\" in flow.request.path:\n                flow.response = http.Response.make(418, f\"(cached) {flow.request.text}\")\n            if \"toggle-tls\" in flow.request.path:\n                if flow.request.url.startswith(\"https://\"):\n                    flow.request.url = flow.request.url.replace(\"https://\", \"http://\")\n                else:\n                    flow.request.url = flow.request.url.replace(\"http://\", \"https://\")\n            if \"redirect\" in flow.request.path:\n                flow.request.host = \"httpbin.org\"\n\n        def tls_start_client(tls_start: tls.TlsData):\n            # INSECURE\n            ssl_context = SSL.Context(SSL.SSLv23_METHOD)\n            ssl_context.use_privatekey_file(\n                pkg_data.path(\n                    \"../test/mitmproxy/data/verificationcerts/trusted-leaf.key\"\n                )\n            )\n            ssl_context.use_certificate_chain_file(\n                pkg_data.path(\n                    \"../test/mitmproxy/data/verificationcerts/trusted-leaf.crt\"\n                )\n            )\n            tls_start.ssl_conn = SSL.Connection(ssl_context)\n            tls_start.ssl_conn.set_accept_state()\n\n        def tls_start_server(tls_start: tls.TlsData):\n            # INSECURE\n            ssl_context = SSL.Context(SSL.SSLv23_METHOD)\n            tls_start.ssl_conn = SSL.Connection(ssl_context)\n            tls_start.ssl_conn.set_connect_state()\n            if tls_start.context.client.sni is not None:\n                tls_start.ssl_conn.set_tlsext_host_name(\n                    tls_start.context.client.sni.encode()\n                )\n\n        await SimpleConnectionHandler(\n            reader,\n            writer,\n            opts,\n            mode_specs.ProxyMode.parse(\"reverse:http://127.0.0.1:3000/\"),\n            {\n                \"next_layer\": next_layer,\n                \"request\": request,\n                \"tls_start_client\": tls_start_client,\n                \"tls_start_server\": tls_start_server,\n            },\n        ).handle_client()\n\n    coro = asyncio.start_server(handle, \"127.0.0.1\", 8080, loop=loop)\n    server = loop.run_until_complete(coro)\n\n    # Serve requests until Ctrl+C is pressed\n    assert server.sockets\n    print(f\"Serving on {human.format_address(server.sockets[0].getsockname())}\")\n    try:\n        loop.run_forever()\n    except KeyboardInterrupt:\n        pass\n\n    # Close the server\n    server.close()\n    loop.run_until_complete(server.wait_closed())\n    loop.close()\n", "mitmproxy/proxy/layers/quic.py": "from __future__ import annotations\n\nimport time\nfrom collections.abc import Callable\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom logging import DEBUG\nfrom logging import ERROR\nfrom logging import WARNING\nfrom ssl import VerifyMode\n\nfrom aioquic.buffer import Buffer as QuicBuffer\nfrom aioquic.h3.connection import ErrorCode as H3ErrorCode\nfrom aioquic.quic import events as quic_events\nfrom aioquic.quic.configuration import QuicConfiguration\nfrom aioquic.quic.connection import QuicConnection\nfrom aioquic.quic.connection import QuicConnectionError\nfrom aioquic.quic.connection import QuicConnectionState\nfrom aioquic.quic.connection import QuicErrorCode\nfrom aioquic.quic.connection import stream_is_client_initiated\nfrom aioquic.quic.connection import stream_is_unidirectional\nfrom aioquic.quic.packet import encode_quic_version_negotiation\nfrom aioquic.quic.packet import PACKET_TYPE_INITIAL\nfrom aioquic.quic.packet import pull_quic_header\nfrom aioquic.quic.packet import QuicProtocolVersion\nfrom aioquic.tls import CipherSuite\nfrom aioquic.tls import HandshakeType\nfrom cryptography import x509\nfrom cryptography.hazmat.primitives.asymmetric import dsa\nfrom cryptography.hazmat.primitives.asymmetric import ec\nfrom cryptography.hazmat.primitives.asymmetric import rsa\n\nfrom mitmproxy import certs\nfrom mitmproxy import connection\nfrom mitmproxy import ctx\nfrom mitmproxy.net import tls\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy import tunnel\nfrom mitmproxy.proxy.layers.modes import TransparentProxy\nfrom mitmproxy.proxy.layers.tcp import TCPLayer\nfrom mitmproxy.proxy.layers.tls import TlsClienthelloHook\nfrom mitmproxy.proxy.layers.tls import TlsEstablishedClientHook\nfrom mitmproxy.proxy.layers.tls import TlsEstablishedServerHook\nfrom mitmproxy.proxy.layers.tls import TlsFailedClientHook\nfrom mitmproxy.proxy.layers.tls import TlsFailedServerHook\nfrom mitmproxy.proxy.layers.udp import UDPLayer\nfrom mitmproxy.tls import ClientHello\nfrom mitmproxy.tls import ClientHelloData\nfrom mitmproxy.tls import TlsData\n\n\n@dataclass\nclass QuicTlsSettings:\n    \"\"\"\n    Settings necessary to establish QUIC's TLS context.\n    \"\"\"\n\n    alpn_protocols: list[str] | None = None\n    \"\"\"A list of supported ALPN protocols.\"\"\"\n    certificate: x509.Certificate | None = None\n    \"\"\"The certificate to use for the connection.\"\"\"\n    certificate_chain: list[x509.Certificate] = field(default_factory=list)\n    \"\"\"A list of additional certificates to send to the peer.\"\"\"\n    certificate_private_key: (\n        dsa.DSAPrivateKey | ec.EllipticCurvePrivateKey | rsa.RSAPrivateKey | None\n    ) = None\n    \"\"\"The certificate's private key.\"\"\"\n    cipher_suites: list[CipherSuite] | None = None\n    \"\"\"An optional list of allowed/advertised cipher suites.\"\"\"\n    ca_path: str | None = None\n    \"\"\"An optional path to a directory that contains the necessary information to verify the peer certificate.\"\"\"\n    ca_file: str | None = None\n    \"\"\"An optional path to a PEM file that will be used to verify the peer certificate.\"\"\"\n    verify_mode: VerifyMode | None = None\n    \"\"\"An optional flag that specifies how/if the peer's certificate should be validated.\"\"\"\n\n\n@dataclass\nclass QuicTlsData(TlsData):\n    \"\"\"\n    Event data for `quic_start_client` and `quic_start_server` event hooks.\n    \"\"\"\n\n    settings: QuicTlsSettings | None = None\n    \"\"\"\n    The associated `QuicTlsSettings` object.\n    This will be set by an addon in the `quic_start_*` event hooks.\n    \"\"\"\n\n\n@dataclass\nclass QuicStartClientHook(commands.StartHook):\n    \"\"\"\n    TLS negotiation between mitmproxy and a client over QUIC is about to start.\n\n    An addon is expected to initialize data.settings.\n    (by default, this is done by `mitmproxy.addons.tlsconfig`)\n    \"\"\"\n\n    data: QuicTlsData\n\n\n@dataclass\nclass QuicStartServerHook(commands.StartHook):\n    \"\"\"\n    TLS negotiation between mitmproxy and a server over QUIC is about to start.\n\n    An addon is expected to initialize data.settings.\n    (by default, this is done by `mitmproxy.addons.tlsconfig`)\n    \"\"\"\n\n    data: QuicTlsData\n\n\n@dataclass\nclass QuicStreamEvent(events.ConnectionEvent):\n    \"\"\"Base class for all QUIC stream events.\"\"\"\n\n    stream_id: int\n    \"\"\"The ID of the stream the event was fired for.\"\"\"\n\n\n@dataclass\nclass QuicStreamDataReceived(QuicStreamEvent):\n    \"\"\"Event that is fired whenever data is received on a stream.\"\"\"\n\n    data: bytes\n    \"\"\"The data which was received.\"\"\"\n    end_stream: bool\n    \"\"\"Whether the STREAM frame had the FIN bit set.\"\"\"\n\n    def __repr__(self):\n        target = type(self.connection).__name__.lower()\n        end_stream = \"[end_stream] \" if self.end_stream else \"\"\n        return f\"QuicStreamDataReceived({target} on {self.stream_id}, {end_stream}{self.data!r})\"\n\n\n@dataclass\nclass QuicStreamReset(QuicStreamEvent):\n    \"\"\"Event that is fired when the remote peer resets a stream.\"\"\"\n\n    error_code: int\n    \"\"\"The error code that triggered the reset.\"\"\"\n\n\nclass QuicStreamCommand(commands.ConnectionCommand):\n    \"\"\"Base class for all QUIC stream commands.\"\"\"\n\n    stream_id: int\n    \"\"\"The ID of the stream the command was issued for.\"\"\"\n\n    def __init__(self, connection: connection.Connection, stream_id: int) -> None:\n        super().__init__(connection)\n        self.stream_id = stream_id\n\n\nclass SendQuicStreamData(QuicStreamCommand):\n    \"\"\"Command that sends data on a stream.\"\"\"\n\n    data: bytes\n    \"\"\"The data which should be sent.\"\"\"\n    end_stream: bool\n    \"\"\"Whether the FIN bit should be set in the STREAM frame.\"\"\"\n\n    def __init__(\n        self,\n        connection: connection.Connection,\n        stream_id: int,\n        data: bytes,\n        end_stream: bool = False,\n    ) -> None:\n        super().__init__(connection, stream_id)\n        self.data = data\n        self.end_stream = end_stream\n\n    def __repr__(self):\n        target = type(self.connection).__name__.lower()\n        end_stream = \"[end_stream] \" if self.end_stream else \"\"\n        return f\"SendQuicStreamData({target} on {self.stream_id}, {end_stream}{self.data!r})\"\n\n\nclass ResetQuicStream(QuicStreamCommand):\n    \"\"\"Abruptly terminate the sending part of a stream.\"\"\"\n\n    error_code: int\n    \"\"\"An error code indicating why the stream is being reset.\"\"\"\n\n    def __init__(\n        self, connection: connection.Connection, stream_id: int, error_code: int\n    ) -> None:\n        super().__init__(connection, stream_id)\n        self.error_code = error_code\n\n\nclass StopQuicStream(QuicStreamCommand):\n    \"\"\"Request termination of the receiving part of a stream.\"\"\"\n\n    error_code: int\n    \"\"\"An error code indicating why the stream is being stopped.\"\"\"\n\n    def __init__(\n        self, connection: connection.Connection, stream_id: int, error_code: int\n    ) -> None:\n        super().__init__(connection, stream_id)\n        self.error_code = error_code\n\n\nclass CloseQuicConnection(commands.CloseConnection):\n    \"\"\"Close a QUIC connection.\"\"\"\n\n    error_code: int\n    \"The error code which was specified when closing the connection.\"\n\n    frame_type: int | None\n    \"The frame type which caused the connection to be closed, or `None`.\"\n\n    reason_phrase: str\n    \"The human-readable reason for which the connection was closed.\"\n\n    # XXX: A bit much boilerplate right now. Should switch to dataclasses.\n    def __init__(\n        self,\n        conn: connection.Connection,\n        error_code: int,\n        frame_type: int | None,\n        reason_phrase: str,\n    ) -> None:\n        super().__init__(conn)\n        self.error_code = error_code\n        self.frame_type = frame_type\n        self.reason_phrase = reason_phrase\n\n\nclass QuicConnectionClosed(events.ConnectionClosed):\n    \"\"\"QUIC connection has been closed.\"\"\"\n\n    error_code: int\n    \"The error code which was specified when closing the connection.\"\n\n    frame_type: int | None\n    \"The frame type which caused the connection to be closed, or `None`.\"\n\n    reason_phrase: str\n    \"The human-readable reason for which the connection was closed.\"\n\n    def __init__(\n        self,\n        conn: connection.Connection,\n        error_code: int,\n        frame_type: int | None,\n        reason_phrase: str,\n    ) -> None:\n        super().__init__(conn)\n        self.error_code = error_code\n        self.frame_type = frame_type\n        self.reason_phrase = reason_phrase\n\n\nclass QuicSecretsLogger:\n    logger: tls.MasterSecretLogger\n\n    def __init__(self, logger: tls.MasterSecretLogger) -> None:\n        super().__init__()\n        self.logger = logger\n\n    def write(self, s: str) -> int:\n        if s[-1:] == \"\\n\":\n            s = s[:-1]\n        data = s.encode(\"ascii\")\n        self.logger(None, data)  # type: ignore\n        return len(data) + 1\n\n    def flush(self) -> None:\n        # done by the logger during write\n        pass\n\n\ndef error_code_to_str(error_code: int) -> str:\n    \"\"\"Returns the corresponding name of the given error code or a string containing its numeric value.\"\"\"\n\n    try:\n        return H3ErrorCode(error_code).name\n    except ValueError:\n        try:\n            return QuicErrorCode(error_code).name\n        except ValueError:\n            return f\"unknown error (0x{error_code:x})\"\n\n\ndef is_success_error_code(error_code: int) -> bool:\n    \"\"\"Returns whether the given error code actually indicates no error.\"\"\"\n\n    return error_code in (QuicErrorCode.NO_ERROR, H3ErrorCode.H3_NO_ERROR)\n\n\ndef tls_settings_to_configuration(\n    settings: QuicTlsSettings,\n    is_client: bool,\n    server_name: str | None = None,\n) -> QuicConfiguration:\n    \"\"\"Converts `QuicTlsSettings` to `QuicConfiguration`.\"\"\"\n\n    return QuicConfiguration(\n        alpn_protocols=settings.alpn_protocols,\n        is_client=is_client,\n        secrets_log_file=(\n            QuicSecretsLogger(tls.log_master_secret)  # type: ignore\n            if tls.log_master_secret is not None\n            else None\n        ),\n        server_name=server_name,\n        cafile=settings.ca_file,\n        capath=settings.ca_path,\n        certificate=settings.certificate,\n        certificate_chain=settings.certificate_chain,\n        cipher_suites=settings.cipher_suites,\n        private_key=settings.certificate_private_key,\n        verify_mode=settings.verify_mode,\n        max_datagram_frame_size=65536,\n    )\n\n\n@dataclass\nclass QuicClientHello(Exception):\n    \"\"\"Helper error only used in `quic_parse_client_hello`.\"\"\"\n\n    data: bytes\n\n\ndef quic_parse_client_hello(data: bytes) -> ClientHello:\n    \"\"\"Helper function that parses a client hello packet.\"\"\"\n\n    # ensure the first packet is indeed the initial one\n    buffer = QuicBuffer(data=data)\n    header = pull_quic_header(buffer, 8)\n    if header.packet_type != PACKET_TYPE_INITIAL:\n        raise ValueError(\"Packet is not initial one.\")\n\n    # patch aioquic to intercept the client hello\n    quic = QuicConnection(\n        configuration=QuicConfiguration(\n            is_client=False,\n            certificate=\"\",\n            private_key=\"\",\n        ),\n        original_destination_connection_id=header.destination_cid,\n    )\n    _initialize = quic._initialize\n\n    def server_handle_hello_replacement(\n        input_buf: QuicBuffer,\n        initial_buf: QuicBuffer,\n        handshake_buf: QuicBuffer,\n        onertt_buf: QuicBuffer,\n    ) -> None:\n        assert input_buf.pull_uint8() == HandshakeType.CLIENT_HELLO\n        length = 0\n        for b in input_buf.pull_bytes(3):\n            length = (length << 8) | b\n        offset = input_buf.tell()\n        raise QuicClientHello(input_buf.data_slice(offset, offset + length))\n\n    def initialize_replacement(peer_cid: bytes) -> None:\n        try:\n            return _initialize(peer_cid)\n        finally:\n            quic.tls._server_handle_hello = server_handle_hello_replacement  # type: ignore\n\n    quic._initialize = initialize_replacement  # type: ignore\n    try:\n        quic.receive_datagram(data, (\"0.0.0.0\", 0), now=0)\n    except QuicClientHello as hello:\n        try:\n            return ClientHello(hello.data)\n        except EOFError as e:\n            raise ValueError(\"Invalid ClientHello data.\") from e\n    except QuicConnectionError as e:\n        raise ValueError(e.reason_phrase) from e\n    raise ValueError(\"No ClientHello returned.\")\n\n\nclass QuicStreamNextLayer(layer.NextLayer):\n    \"\"\"`NextLayer` variant that callbacks `QuicStreamLayer` after layer decision.\"\"\"\n\n    def __init__(\n        self,\n        context: context.Context,\n        stream: QuicStreamLayer,\n        ask_on_start: bool = False,\n    ) -> None:\n        super().__init__(context, ask_on_start)\n        self._stream = stream\n        self._layer: layer.Layer | None = None\n\n    @property  # type: ignore\n    def layer(self) -> layer.Layer | None:  # type: ignore\n        return self._layer\n\n    @layer.setter\n    def layer(self, value: layer.Layer | None) -> None:\n        self._layer = value\n        if self._layer:\n            self._stream.refresh_metadata()\n\n\nclass QuicStreamLayer(layer.Layer):\n    \"\"\"\n    Layer for QUIC streams.\n    Serves as a marker for NextLayer and keeps track of the connection states.\n    \"\"\"\n\n    client: connection.Client\n    \"\"\"Virtual client connection for this stream. Use this in QuicRawLayer instead of `context.client`.\"\"\"\n    server: connection.Server\n    \"\"\"Virtual server connection for this stream. Use this in QuicRawLayer instead of `context.server`.\"\"\"\n    child_layer: layer.Layer\n    \"\"\"The stream's child layer.\"\"\"\n\n    def __init__(self, context: context.Context, ignore: bool, stream_id: int) -> None:\n        # we mustn't reuse the client from the QUIC connection, as the state and protocol differs\n        self.client = context.client = context.client.copy()\n        self.client.transport_protocol = \"tcp\"\n        self.client.state = connection.ConnectionState.OPEN\n\n        # unidirectional client streams are not fully open, set the appropriate state\n        if stream_is_unidirectional(stream_id):\n            self.client.state = (\n                connection.ConnectionState.CAN_READ\n                if stream_is_client_initiated(stream_id)\n                else connection.ConnectionState.CAN_WRITE\n            )\n        self._client_stream_id = stream_id\n\n        # start with a closed server\n        self.server = context.server = connection.Server(\n            address=context.server.address,\n            transport_protocol=\"tcp\",\n        )\n        self._server_stream_id: int | None = None\n\n        # ignored connections will be assigned a TCPLayer immediately\n        super().__init__(context)\n        self.child_layer = (\n            TCPLayer(context, ignore=True)\n            if ignore\n            else QuicStreamNextLayer(context, self)\n        )\n        self.refresh_metadata()\n\n        # we don't handle any events, pass everything to the child layer\n        self.handle_event = self.child_layer.handle_event  # type: ignore\n        self._handle_event = self.child_layer._handle_event  # type: ignore\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        raise AssertionError  # pragma: no cover\n\n    def open_server_stream(self, server_stream_id) -> None:\n        assert self._server_stream_id is None\n        self._server_stream_id = server_stream_id\n        self.server.timestamp_start = time.time()\n        self.server.state = (\n            (\n                connection.ConnectionState.CAN_WRITE\n                if stream_is_client_initiated(server_stream_id)\n                else connection.ConnectionState.CAN_READ\n            )\n            if stream_is_unidirectional(server_stream_id)\n            else connection.ConnectionState.OPEN\n        )\n        self.refresh_metadata()\n\n    def refresh_metadata(self) -> None:\n        # find the first transport layer\n        child_layer: layer.Layer | None = self.child_layer\n        while True:\n            if isinstance(child_layer, layer.NextLayer):\n                child_layer = child_layer.layer\n            elif isinstance(child_layer, tunnel.TunnelLayer):\n                child_layer = child_layer.child_layer\n            else:\n                break  # pragma: no cover\n        if isinstance(child_layer, (UDPLayer, TCPLayer)) and child_layer.flow:\n            child_layer.flow.metadata[\"quic_is_unidirectional\"] = (\n                stream_is_unidirectional(self._client_stream_id)\n            )\n            child_layer.flow.metadata[\"quic_initiator\"] = (\n                \"client\"\n                if stream_is_client_initiated(self._client_stream_id)\n                else \"server\"\n            )\n            child_layer.flow.metadata[\"quic_stream_id_client\"] = self._client_stream_id\n            child_layer.flow.metadata[\"quic_stream_id_server\"] = self._server_stream_id\n\n    def stream_id(self, client: bool) -> int | None:\n        return self._client_stream_id if client else self._server_stream_id\n\n\nclass RawQuicLayer(layer.Layer):\n    \"\"\"\n    This layer is responsible for de-multiplexing QUIC streams into an individual layer stack per stream.\n    \"\"\"\n\n    ignore: bool\n    \"\"\"Indicates whether traffic should be routed as-is.\"\"\"\n    datagram_layer: layer.Layer\n    \"\"\"\n    The layer that is handling datagrams over QUIC. It's like a child_layer, but with a forked context.\n    Instead of having a datagram-equivalent for all `QuicStream*` classes, we use `SendData` and `DataReceived` instead.\n    There is also no need for another `NextLayer` marker, as a missing `QuicStreamLayer` implies UDP,\n    and the connection state is the same as the one of the underlying QUIC connection.\n    \"\"\"\n    client_stream_ids: dict[int, QuicStreamLayer]\n    \"\"\"Maps stream IDs from the client connection to stream layers.\"\"\"\n    server_stream_ids: dict[int, QuicStreamLayer]\n    \"\"\"Maps stream IDs from the server connection to stream layers.\"\"\"\n    connections: dict[connection.Connection, layer.Layer]\n    \"\"\"Maps connections to layers.\"\"\"\n    command_sources: dict[commands.Command, layer.Layer]\n    \"\"\"Keeps track of blocking commands and wakeup requests.\"\"\"\n    next_stream_id: list[int]\n    \"\"\"List containing the next stream ID for all four is_unidirectional/is_client combinations.\"\"\"\n\n    def __init__(self, context: context.Context, ignore: bool = False) -> None:\n        super().__init__(context)\n        self.ignore = ignore\n        self.datagram_layer = (\n            UDPLayer(self.context.fork(), ignore=True)\n            if ignore\n            else layer.NextLayer(self.context.fork())\n        )\n        self.client_stream_ids = {}\n        self.server_stream_ids = {}\n        self.connections = {\n            context.client: self.datagram_layer,\n            context.server: self.datagram_layer,\n        }\n        self.command_sources = {}\n        self.next_stream_id = [0, 1, 2, 3]\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        # we treat the datagram layer as child layer, so forward Start\n        if isinstance(event, events.Start):\n            if self.context.server.timestamp_start is None:\n                err = yield commands.OpenConnection(self.context.server)\n                if err:\n                    yield commands.CloseConnection(self.context.client)\n                    self._handle_event = self.done  # type: ignore\n                    return\n            yield from self.event_to_child(self.datagram_layer, event)\n\n        # properly forward completion events based on their command\n        elif isinstance(event, events.CommandCompleted):\n            yield from self.event_to_child(\n                self.command_sources.pop(event.command), event\n            )\n\n        # route injected messages based on their connections (prefer client, fallback to server)\n        elif isinstance(event, events.MessageInjected):\n            if event.flow.client_conn in self.connections:\n                yield from self.event_to_child(\n                    self.connections[event.flow.client_conn], event\n                )\n            elif event.flow.server_conn in self.connections:\n                yield from self.event_to_child(\n                    self.connections[event.flow.server_conn], event\n                )\n            else:\n                raise AssertionError(f\"Flow not associated: {event.flow!r}\")\n\n        # handle stream events targeting this context\n        elif isinstance(event, QuicStreamEvent) and (\n            event.connection is self.context.client\n            or event.connection is self.context.server\n        ):\n            from_client = event.connection is self.context.client\n\n            # fetch or create the layer\n            stream_ids = (\n                self.client_stream_ids if from_client else self.server_stream_ids\n            )\n            if event.stream_id in stream_ids:\n                stream_layer = stream_ids[event.stream_id]\n            else:\n                # ensure we haven't just forgotten to register the ID\n                assert stream_is_client_initiated(event.stream_id) == from_client\n\n                # for server-initiated streams we need to open the client as well\n                if from_client:\n                    client_stream_id = event.stream_id\n                    server_stream_id = None\n                else:\n                    client_stream_id = self.get_next_available_stream_id(\n                        is_client=False,\n                        is_unidirectional=stream_is_unidirectional(event.stream_id),\n                    )\n                    server_stream_id = event.stream_id\n\n                # create, register and start the layer\n                stream_layer = QuicStreamLayer(\n                    self.context.fork(), self.ignore, client_stream_id\n                )\n                self.client_stream_ids[client_stream_id] = stream_layer\n                if server_stream_id is not None:\n                    stream_layer.open_server_stream(server_stream_id)\n                    self.server_stream_ids[server_stream_id] = stream_layer\n                self.connections[stream_layer.client] = stream_layer\n                self.connections[stream_layer.server] = stream_layer\n                yield from self.event_to_child(stream_layer, events.Start())\n\n            # forward data and close events\n            conn = stream_layer.client if from_client else stream_layer.server\n            if isinstance(event, QuicStreamDataReceived):\n                if event.data:\n                    yield from self.event_to_child(\n                        stream_layer, events.DataReceived(conn, event.data)\n                    )\n                if event.end_stream:\n                    yield from self.close_stream_layer(stream_layer, from_client)\n            elif isinstance(event, QuicStreamReset):\n                # preserve stream resets\n                for command in self.close_stream_layer(stream_layer, from_client):\n                    if (\n                        isinstance(command, SendQuicStreamData)\n                        and command.stream_id == stream_layer.stream_id(not from_client)\n                        and command.end_stream\n                        and not command.data\n                    ):\n                        yield ResetQuicStream(\n                            command.connection, command.stream_id, event.error_code\n                        )\n                    else:\n                        yield command\n            else:\n                raise AssertionError(f\"Unexpected stream event: {event!r}\")\n\n        # handle close events that target this context\n        elif isinstance(event, QuicConnectionClosed) and (\n            event.connection is self.context.client\n            or event.connection is self.context.server\n        ):\n            from_client = event.connection is self.context.client\n            other_conn = self.context.server if from_client else self.context.client\n\n            # be done if both connections are closed\n            if other_conn.connected:\n                yield CloseQuicConnection(\n                    other_conn, event.error_code, event.frame_type, event.reason_phrase\n                )\n            else:\n                self._handle_event = self.done  # type: ignore\n\n            # always forward to the datagram layer and swallow `CloseConnection` commands\n            for command in self.event_to_child(self.datagram_layer, event):\n                if (\n                    not isinstance(command, commands.CloseConnection)\n                    or command.connection is not other_conn\n                ):\n                    yield command\n\n            # forward to either the client or server connection of stream layers and swallow empty stream end\n            for conn, child_layer in self.connections.items():\n                if isinstance(child_layer, QuicStreamLayer) and (\n                    (conn is child_layer.client)\n                    if from_client\n                    else (conn is child_layer.server)\n                ):\n                    conn.state &= ~connection.ConnectionState.CAN_WRITE\n                    for command in self.close_stream_layer(child_layer, from_client):\n                        if not isinstance(command, SendQuicStreamData) or command.data:\n                            yield command\n\n        # all other connection events are routed to their corresponding layer\n        elif isinstance(event, events.ConnectionEvent):\n            yield from self.event_to_child(self.connections[event.connection], event)\n\n        else:\n            raise AssertionError(f\"Unexpected event: {event!r}\")\n\n    def close_stream_layer(\n        self, stream_layer: QuicStreamLayer, client: bool\n    ) -> layer.CommandGenerator[None]:\n        \"\"\"Closes the incoming part of a connection.\"\"\"\n\n        conn = stream_layer.client if client else stream_layer.server\n        conn.state &= ~connection.ConnectionState.CAN_READ\n        assert conn.timestamp_start is not None\n        if conn.timestamp_end is None:\n            conn.timestamp_end = time.time()\n            yield from self.event_to_child(stream_layer, events.ConnectionClosed(conn))\n\n    def event_to_child(\n        self, child_layer: layer.Layer, event: events.Event\n    ) -> layer.CommandGenerator[None]:\n        \"\"\"Forwards events to child layers and translates commands.\"\"\"\n\n        for command in child_layer.handle_event(event):\n            # intercept commands for streams connections\n            if (\n                isinstance(child_layer, QuicStreamLayer)\n                and isinstance(command, commands.ConnectionCommand)\n                and (\n                    command.connection is child_layer.client\n                    or command.connection is child_layer.server\n                )\n            ):\n                # get the target connection and stream ID\n                to_client = command.connection is child_layer.client\n                quic_conn = self.context.client if to_client else self.context.server\n                stream_id = child_layer.stream_id(to_client)\n\n                # write data and check CloseConnection wasn't called before\n                if isinstance(command, commands.SendData):\n                    assert stream_id is not None\n                    if command.connection.state & connection.ConnectionState.CAN_WRITE:\n                        yield SendQuicStreamData(quic_conn, stream_id, command.data)\n\n                # send a FIN and optionally also a STOP frame\n                elif isinstance(command, commands.CloseConnection):\n                    assert stream_id is not None\n                    if command.connection.state & connection.ConnectionState.CAN_WRITE:\n                        command.connection.state &= (\n                            ~connection.ConnectionState.CAN_WRITE\n                        )\n                        yield SendQuicStreamData(\n                            quic_conn, stream_id, b\"\", end_stream=True\n                        )\n                    # XXX: Use `command.connection.state & connection.ConnectionState.CAN_READ` instead?\n                    only_close_our_half = (\n                        isinstance(command, commands.CloseTcpConnection)\n                        and command.half_close\n                    )\n                    if not only_close_our_half:\n                        if stream_is_client_initiated(\n                            stream_id\n                        ) == to_client or not stream_is_unidirectional(stream_id):\n                            yield StopQuicStream(\n                                quic_conn, stream_id, QuicErrorCode.NO_ERROR\n                            )\n                        yield from self.close_stream_layer(child_layer, to_client)\n\n                # open server connections by reserving the next stream ID\n                elif isinstance(command, commands.OpenConnection):\n                    assert not to_client\n                    assert stream_id is None\n                    client_stream_id = child_layer.stream_id(client=True)\n                    assert client_stream_id is not None\n                    stream_id = self.get_next_available_stream_id(\n                        is_client=True,\n                        is_unidirectional=stream_is_unidirectional(client_stream_id),\n                    )\n                    child_layer.open_server_stream(stream_id)\n                    self.server_stream_ids[stream_id] = child_layer\n                    yield from self.event_to_child(\n                        child_layer, events.OpenConnectionCompleted(command, None)\n                    )\n\n                else:\n                    raise AssertionError(\n                        f\"Unexpected stream connection command: {command!r}\"\n                    )\n\n            # remember blocking and wakeup commands\n            else:\n                if command.blocking or isinstance(command, commands.RequestWakeup):\n                    self.command_sources[command] = child_layer\n                if isinstance(command, commands.OpenConnection):\n                    self.connections[command.connection] = child_layer\n                yield command\n\n    def get_next_available_stream_id(\n        self, is_client: bool, is_unidirectional: bool = False\n    ) -> int:\n        index = (int(is_unidirectional) << 1) | int(not is_client)\n        stream_id = self.next_stream_id[index]\n        self.next_stream_id[index] = stream_id + 4\n        return stream_id\n\n    def done(self, _) -> layer.CommandGenerator[None]:  # pragma: no cover\n        yield from ()\n\n\nclass QuicLayer(tunnel.TunnelLayer):\n    quic: QuicConnection | None = None\n    tls: QuicTlsSettings | None = None\n\n    def __init__(\n        self,\n        context: context.Context,\n        conn: connection.Connection,\n        time: Callable[[], float] | None,\n    ) -> None:\n        super().__init__(context, tunnel_connection=conn, conn=conn)\n        self.child_layer = layer.NextLayer(self.context, ask_on_start=True)\n        self._time = time or ctx.master.event_loop.time\n        self._wakeup_commands: dict[commands.RequestWakeup, float] = dict()\n        conn.tls = True\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, events.Wakeup) and event.command in self._wakeup_commands:\n            # TunnelLayer has no understanding of wakeups, so we turn this into an empty DataReceived event\n            # which TunnelLayer recognizes as belonging to our connection.\n            assert self.quic\n            scheduled_time = self._wakeup_commands.pop(event.command)\n            if self.quic._state is not QuicConnectionState.TERMINATED:\n                # weird quirk: asyncio sometimes returns a bit ahead of time.\n                now = max(scheduled_time, self._time())\n                self.quic.handle_timer(now)\n                yield from super()._handle_event(\n                    events.DataReceived(self.tunnel_connection, b\"\")\n                )\n        else:\n            yield from super()._handle_event(event)\n\n    def event_to_child(self, event: events.Event) -> layer.CommandGenerator[None]:\n        # the parent will call _handle_command multiple times, we transmit cumulative afterwards\n        # this will reduce the number of sends, especially if data=b\"\" and end_stream=True\n        yield from super().event_to_child(event)\n        if self.quic:\n            yield from self.tls_interact()\n\n    def _handle_command(\n        self, command: commands.Command\n    ) -> layer.CommandGenerator[None]:\n        \"\"\"Turns stream commands into aioquic connection invocations.\"\"\"\n        if isinstance(command, QuicStreamCommand) and command.connection is self.conn:\n            assert self.quic\n            if isinstance(command, SendQuicStreamData):\n                self.quic.send_stream_data(\n                    command.stream_id, command.data, command.end_stream\n                )\n            elif isinstance(command, ResetQuicStream):\n                self.quic.reset_stream(command.stream_id, command.error_code)\n            elif isinstance(command, StopQuicStream):\n                # the stream might have already been closed, check before stopping\n                if command.stream_id in self.quic._streams:\n                    self.quic.stop_stream(command.stream_id, command.error_code)\n            else:\n                raise AssertionError(f\"Unexpected stream command: {command!r}\")\n        else:\n            yield from super()._handle_command(command)\n\n    def start_tls(\n        self, original_destination_connection_id: bytes | None\n    ) -> layer.CommandGenerator[None]:\n        \"\"\"Initiates the aioquic connection.\"\"\"\n\n        # must only be called if QUIC is uninitialized\n        assert not self.quic\n        assert not self.tls\n\n        # query addons to provide the necessary TLS settings\n        tls_data = QuicTlsData(self.conn, self.context)\n        if self.conn is self.context.client:\n            yield QuicStartClientHook(tls_data)\n        else:\n            yield QuicStartServerHook(tls_data)\n        if not tls_data.settings:\n            yield commands.Log(\n                f\"No QUIC context was provided, failing connection.\", ERROR\n            )\n            yield commands.CloseConnection(self.conn)\n            return\n\n        # build the aioquic connection\n        configuration = tls_settings_to_configuration(\n            settings=tls_data.settings,\n            is_client=self.conn is self.context.server,\n            server_name=self.conn.sni,\n        )\n        self.quic = QuicConnection(\n            configuration=configuration,\n            original_destination_connection_id=original_destination_connection_id,\n        )\n        self.tls = tls_data.settings\n\n        # if we act as client, connect to upstream\n        if original_destination_connection_id is None:\n            self.quic.connect(self.conn.peername, now=self._time())\n            yield from self.tls_interact()\n\n    def tls_interact(self) -> layer.CommandGenerator[None]:\n        \"\"\"Retrieves all pending outgoing packets from aioquic and sends the data.\"\"\"\n\n        # send all queued datagrams\n        assert self.quic\n        now = self._time()\n\n        for data, addr in self.quic.datagrams_to_send(now=now):\n            assert addr == self.conn.peername\n            yield commands.SendData(self.tunnel_connection, data)\n\n        timer = self.quic.get_timer()\n        if timer is not None:\n            # smooth wakeups a bit.\n            smoothed = timer + 0.002\n            # request a new wakeup if all pending requests trigger at a later time\n            if not any(\n                existing <= smoothed for existing in self._wakeup_commands.values()\n            ):\n                command = commands.RequestWakeup(timer - now)\n                self._wakeup_commands[command] = timer\n                yield command\n\n    def receive_handshake_data(\n        self, data: bytes\n    ) -> layer.CommandGenerator[tuple[bool, str | None]]:\n        assert self.quic\n\n        # forward incoming data to aioquic\n        if data:\n            self.quic.receive_datagram(data, self.conn.peername, now=self._time())\n\n        # handle pre-handshake events\n        while event := self.quic.next_event():\n            if isinstance(event, quic_events.ConnectionTerminated):\n                err = event.reason_phrase or error_code_to_str(event.error_code)\n                return False, err\n            elif isinstance(event, quic_events.HandshakeCompleted):\n                # concatenate all peer certificates\n                all_certs: list[x509.Certificate] = []\n                if self.quic.tls._peer_certificate:\n                    all_certs.append(self.quic.tls._peer_certificate)\n                all_certs.extend(self.quic.tls._peer_certificate_chain)\n\n                # set the connection's TLS properties\n                self.conn.timestamp_tls_setup = time.time()\n                if event.alpn_protocol:\n                    self.conn.alpn = event.alpn_protocol.encode(\"ascii\")\n                self.conn.certificate_list = [certs.Cert(cert) for cert in all_certs]\n                assert self.quic.tls.key_schedule\n                self.conn.cipher = self.quic.tls.key_schedule.cipher_suite.name\n                self.conn.tls_version = \"QUIC\"\n\n                # log the result and report the success to addons\n                if self.debug:\n                    yield commands.Log(\n                        f\"{self.debug}[quic] tls established: {self.conn}\", DEBUG\n                    )\n                if self.conn is self.context.client:\n                    yield TlsEstablishedClientHook(\n                        QuicTlsData(self.conn, self.context, settings=self.tls)\n                    )\n                else:\n                    yield TlsEstablishedServerHook(\n                        QuicTlsData(self.conn, self.context, settings=self.tls)\n                    )\n\n                yield from self.tls_interact()\n                return True, None\n            elif isinstance(\n                event,\n                (\n                    quic_events.ConnectionIdIssued,\n                    quic_events.ConnectionIdRetired,\n                    quic_events.PingAcknowledged,\n                    quic_events.ProtocolNegotiated,\n                ),\n            ):\n                pass\n            else:\n                raise AssertionError(f\"Unexpected event: {event!r}\")\n\n        # transmit buffered data and re-arm timer\n        yield from self.tls_interact()\n        return False, None\n\n    def on_handshake_error(self, err: str) -> layer.CommandGenerator[None]:\n        self.conn.error = err\n        if self.conn is self.context.client:\n            yield TlsFailedClientHook(\n                QuicTlsData(self.conn, self.context, settings=self.tls)\n            )\n        else:\n            yield TlsFailedServerHook(\n                QuicTlsData(self.conn, self.context, settings=self.tls)\n            )\n        yield from super().on_handshake_error(err)\n\n    def receive_data(self, data: bytes) -> layer.CommandGenerator[None]:\n        assert self.quic\n\n        # forward incoming data to aioquic\n        if data:\n            self.quic.receive_datagram(data, self.conn.peername, now=self._time())\n\n        # handle post-handshake events\n        while event := self.quic.next_event():\n            if isinstance(event, quic_events.ConnectionTerminated):\n                if self.debug:\n                    reason = event.reason_phrase or error_code_to_str(event.error_code)\n                    yield commands.Log(\n                        f\"{self.debug}[quic] close_notify {self.conn} (reason={reason})\",\n                        DEBUG,\n                    )\n                # We don't rely on `ConnectionTerminated` to dispatch `QuicConnectionClosed`, because\n                # after aioquic receives a termination frame, it still waits for the next `handle_timer`\n                # before returning `ConnectionTerminated` in `next_event`. In the meantime, the underlying\n                # connection could be closed. Therefore, we instead dispatch on `ConnectionClosed` and simply\n                # close the connection here.\n                yield commands.CloseConnection(self.tunnel_connection)\n                return  # we don't handle any further events, nor do/can we transmit data, so exit\n            elif isinstance(event, quic_events.DatagramFrameReceived):\n                yield from self.event_to_child(\n                    events.DataReceived(self.conn, event.data)\n                )\n            elif isinstance(event, quic_events.StreamDataReceived):\n                yield from self.event_to_child(\n                    QuicStreamDataReceived(\n                        self.conn, event.stream_id, event.data, event.end_stream\n                    )\n                )\n            elif isinstance(event, quic_events.StreamReset):\n                yield from self.event_to_child(\n                    QuicStreamReset(self.conn, event.stream_id, event.error_code)\n                )\n            elif isinstance(\n                event,\n                (\n                    quic_events.ConnectionIdIssued,\n                    quic_events.ConnectionIdRetired,\n                    quic_events.PingAcknowledged,\n                    quic_events.ProtocolNegotiated,\n                ),\n            ):\n                pass\n            else:\n                raise AssertionError(f\"Unexpected event: {event!r}\")\n\n        # transmit buffered data and re-arm timer\n        yield from self.tls_interact()\n\n    def receive_close(self) -> layer.CommandGenerator[None]:\n        assert self.quic\n        # if `_close_event` is not set, the underlying connection has been closed\n        # we turn this into a QUIC close event as well\n        close_event = self.quic._close_event or quic_events.ConnectionTerminated(\n            QuicErrorCode.NO_ERROR, None, \"Connection closed.\"\n        )\n        yield from self.event_to_child(\n            QuicConnectionClosed(\n                self.conn,\n                close_event.error_code,\n                close_event.frame_type,\n                close_event.reason_phrase,\n            )\n        )\n\n    def send_data(self, data: bytes) -> layer.CommandGenerator[None]:\n        # non-stream data uses datagram frames\n        assert self.quic\n        if data:\n            self.quic.send_datagram_frame(data)\n        yield from self.tls_interact()\n\n    def send_close(\n        self, command: commands.CloseConnection\n    ) -> layer.CommandGenerator[None]:\n        # properly close the QUIC connection\n        if self.quic:\n            if isinstance(command, CloseQuicConnection):\n                self.quic.close(\n                    command.error_code, command.frame_type, command.reason_phrase\n                )\n            else:\n                self.quic.close()\n            yield from self.tls_interact()\n        yield from super().send_close(command)\n\n\nclass ServerQuicLayer(QuicLayer):\n    \"\"\"\n    This layer establishes QUIC for a single server connection.\n    \"\"\"\n\n    wait_for_clienthello: bool = False\n\n    def __init__(\n        self,\n        context: context.Context,\n        conn: connection.Server | None = None,\n        time: Callable[[], float] | None = None,\n    ):\n        super().__init__(context, conn or context.server, time)\n\n    def start_handshake(self) -> layer.CommandGenerator[None]:\n        wait_for_clienthello = not self.command_to_reply_to and isinstance(\n            self.child_layer, ClientQuicLayer\n        )\n        if wait_for_clienthello:\n            self.wait_for_clienthello = True\n            self.tunnel_state = tunnel.TunnelState.CLOSED\n        else:\n            yield from self.start_tls(None)\n\n    def event_to_child(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if self.wait_for_clienthello:\n            for command in super().event_to_child(event):\n                if (\n                    isinstance(command, commands.OpenConnection)\n                    and command.connection == self.conn\n                ):\n                    self.wait_for_clienthello = False\n                else:\n                    yield command\n        else:\n            yield from super().event_to_child(event)\n\n    def on_handshake_error(self, err: str) -> layer.CommandGenerator[None]:\n        yield commands.Log(f\"Server QUIC handshake failed. {err}\", level=WARNING)\n        yield from super().on_handshake_error(err)\n\n\nclass ClientQuicLayer(QuicLayer):\n    \"\"\"\n    This layer establishes QUIC on a single client connection.\n    \"\"\"\n\n    server_tls_available: bool\n    \"\"\"Indicates whether the parent layer is a ServerQuicLayer.\"\"\"\n\n    def __init__(\n        self, context: context.Context, time: Callable[[], float] | None = None\n    ) -> None:\n        # same as ClientTLSLayer, we might be nested in some other transport\n        if context.client.tls:\n            context.client.alpn = None\n            context.client.cipher = None\n            context.client.sni = None\n            context.client.timestamp_tls_setup = None\n            context.client.tls_version = None\n            context.client.certificate_list = []\n            context.client.mitmcert = None\n            context.client.alpn_offers = []\n            context.client.cipher_list = []\n\n        super().__init__(context, context.client, time)\n        self.server_tls_available = len(self.context.layers) >= 2 and isinstance(\n            self.context.layers[-2], ServerQuicLayer\n        )\n\n    def start_handshake(self) -> layer.CommandGenerator[None]:\n        yield from ()\n\n    def receive_handshake_data(\n        self, data: bytes\n    ) -> layer.CommandGenerator[tuple[bool, str | None]]:\n        if isinstance(self.context.layers[0], TransparentProxy):  # pragma: no cover\n            yield commands.Log(\n                f\"Swallowing QUIC handshake because HTTP/3 does not support transparent mode yet.\",\n                DEBUG,\n            )\n            return False, None\n        if not self.context.options.http3:\n            yield commands.Log(\n                f\"Swallowing QUIC handshake because HTTP/3 is disabled.\", DEBUG\n            )\n            return False, None\n\n        # if we already had a valid client hello, don't process further packets\n        if self.tls:\n            return (yield from super().receive_handshake_data(data))\n\n        # fail if the received data is not a QUIC packet\n        buffer = QuicBuffer(data=data)\n        try:\n            header = pull_quic_header(buffer)\n        except TypeError:\n            return False, f\"Cannot parse QUIC header: Malformed head ({data.hex()})\"\n        except ValueError as e:\n            return False, f\"Cannot parse QUIC header: {e} ({data.hex()})\"\n\n        # negotiate version, support all versions known to aioquic\n        supported_versions = [\n            version.value\n            for version in QuicProtocolVersion\n            if version is not QuicProtocolVersion.NEGOTIATION\n        ]\n        if header.version is not None and header.version not in supported_versions:\n            yield commands.SendData(\n                self.tunnel_connection,\n                encode_quic_version_negotiation(\n                    source_cid=header.destination_cid,\n                    destination_cid=header.source_cid,\n                    supported_versions=supported_versions,\n                ),\n            )\n            return False, None\n\n        # ensure it's (likely) a client handshake packet\n        if len(data) < 1200 or header.packet_type != PACKET_TYPE_INITIAL:\n            return (\n                False,\n                f\"Invalid handshake received, roaming not supported. ({data.hex()})\",\n            )\n\n        # extract the client hello\n        try:\n            client_hello = quic_parse_client_hello(data)\n        except ValueError as e:\n            return False, f\"Cannot parse ClientHello: {str(e)} ({data.hex()})\"\n\n        # copy the client hello information\n        self.conn.sni = client_hello.sni\n        self.conn.alpn_offers = client_hello.alpn_protocols\n\n        # check with addons what we shall do\n        tls_clienthello = ClientHelloData(self.context, client_hello)\n        yield TlsClienthelloHook(tls_clienthello)\n\n        # replace the QUIC layer with an UDP layer if requested\n        if tls_clienthello.ignore_connection:\n            self.conn = self.tunnel_connection = connection.Client(\n                peername=(\"ignore-conn\", 0),\n                sockname=(\"ignore-conn\", 0),\n                transport_protocol=\"udp\",\n                state=connection.ConnectionState.OPEN,\n            )\n\n            # we need to replace the server layer as well, if there is one\n            parent_layer = self.context.layers[self.context.layers.index(self) - 1]\n            if isinstance(parent_layer, ServerQuicLayer):\n                parent_layer.conn = parent_layer.tunnel_connection = connection.Server(\n                    address=None\n                )\n            replacement_layer = UDPLayer(self.context, ignore=True)\n            parent_layer.handle_event = replacement_layer.handle_event  # type: ignore\n            parent_layer._handle_event = replacement_layer._handle_event  # type: ignore\n            yield from parent_layer.handle_event(events.Start())\n            yield from parent_layer.handle_event(\n                events.DataReceived(self.context.client, data)\n            )\n            return True, None\n\n        # start the server QUIC connection if demanded and available\n        if (\n            tls_clienthello.establish_server_tls_first\n            and not self.context.server.tls_established\n        ):\n            err = yield from self.start_server_tls()\n            if err:\n                yield commands.Log(\n                    f\"Unable to establish QUIC connection with server ({err}). \"\n                    f\"Trying to establish QUIC with client anyway. \"\n                    f\"If you plan to redirect requests away from this server, \"\n                    f\"consider setting `connection_strategy` to `lazy` to suppress early connections.\"\n                )\n\n        # start the client QUIC connection\n        yield from self.start_tls(header.destination_cid)\n        # XXX copied from TLS, we assume that `CloseConnection` in `start_tls` takes effect immediately\n        if not self.conn.connected:\n            return False, \"connection closed early\"\n\n        # send the client hello to aioquic\n        return (yield from super().receive_handshake_data(data))\n\n    def start_server_tls(self) -> layer.CommandGenerator[str | None]:\n        if not self.server_tls_available:\n            return f\"No server QUIC available.\"\n        err = yield commands.OpenConnection(self.context.server)\n        return err\n\n    def on_handshake_error(self, err: str) -> layer.CommandGenerator[None]:\n        yield commands.Log(f\"Client QUIC handshake failed. {err}\", level=WARNING)\n        yield from super().on_handshake_error(err)\n        self.event_to_child = self.errored  # type: ignore\n\n    def errored(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if self.debug is not None:\n            yield commands.Log(\n                f\"{self.debug}[quic] Swallowing {event} as handshake failed.\", DEBUG\n            )\n", "mitmproxy/proxy/layers/modes.py": "from __future__ import annotations\n\nimport socket\nimport struct\nimport sys\nfrom abc import ABCMeta\nfrom collections.abc import Callable\nfrom dataclasses import dataclass\n\nfrom mitmproxy import connection\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.commands import StartHook\nfrom mitmproxy.proxy.mode_specs import ReverseMode\nfrom mitmproxy.proxy.utils import expect\n\nif sys.version_info < (3, 11):\n    from typing_extensions import assert_never\nelse:\n    from typing import assert_never\n\n\nclass HttpProxy(layer.Layer):\n    @expect(events.Start)\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        child_layer = layer.NextLayer(self.context)\n        self._handle_event = child_layer.handle_event\n        yield from child_layer.handle_event(event)\n\n\nclass HttpUpstreamProxy(layer.Layer):\n    @expect(events.Start)\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        child_layer = layer.NextLayer(self.context)\n        self._handle_event = child_layer.handle_event\n        yield from child_layer.handle_event(event)\n\n\nclass DestinationKnown(layer.Layer, metaclass=ABCMeta):\n    \"\"\"Base layer for layers that gather connection destination info and then delegate.\"\"\"\n\n    child_layer: layer.Layer\n\n    def finish_start(self) -> layer.CommandGenerator[str | None]:\n        if (\n            self.context.options.connection_strategy == \"eager\"\n            and self.context.server.address\n            and self.context.server.transport_protocol == \"tcp\"\n        ):\n            err = yield commands.OpenConnection(self.context.server)\n            if err:\n                self._handle_event = self.done  # type: ignore\n                return err\n\n        self._handle_event = self.child_layer.handle_event  # type: ignore\n        yield from self.child_layer.handle_event(events.Start())\n        return None\n\n    @expect(events.DataReceived, events.ConnectionClosed)\n    def done(self, _) -> layer.CommandGenerator[None]:\n        yield from ()\n\n\nclass ReverseProxy(DestinationKnown):\n    @expect(events.Start)\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        spec = self.context.client.proxy_mode\n        assert isinstance(spec, ReverseMode)\n        self.context.server.address = spec.address\n\n        self.child_layer = layer.NextLayer(self.context)\n\n        # For secure protocols, set SNI if keep_host_header is false\n        match spec.scheme:\n            case \"http3\" | \"quic\" | \"https\" | \"tls\" | \"dtls\":\n                if not self.context.options.keep_host_header:\n                    self.context.server.sni = spec.address[0]\n            case \"tcp\" | \"http\" | \"udp\" | \"dns\":\n                pass\n            case _:  # pragma: no cover\n                assert_never(spec.scheme)\n\n        err = yield from self.finish_start()\n        if err:\n            yield commands.CloseConnection(self.context.client)\n\n\nclass TransparentProxy(DestinationKnown):\n    @expect(events.Start)\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        assert self.context.server.address, \"No server address set.\"\n        self.child_layer = layer.NextLayer(self.context)\n        err = yield from self.finish_start()\n        if err:\n            yield commands.CloseConnection(self.context.client)\n\n\nSOCKS5_VERSION = 0x05\n\nSOCKS5_METHOD_NO_AUTHENTICATION_REQUIRED = 0x00\nSOCKS5_METHOD_USER_PASSWORD_AUTHENTICATION = 0x02\nSOCKS5_METHOD_NO_ACCEPTABLE_METHODS = 0xFF\n\nSOCKS5_ATYP_IPV4_ADDRESS = 0x01\nSOCKS5_ATYP_DOMAINNAME = 0x03\nSOCKS5_ATYP_IPV6_ADDRESS = 0x04\n\nSOCKS5_REP_HOST_UNREACHABLE = 0x04\nSOCKS5_REP_COMMAND_NOT_SUPPORTED = 0x07\nSOCKS5_REP_ADDRESS_TYPE_NOT_SUPPORTED = 0x08\n\n\n@dataclass\nclass Socks5AuthData:\n    client_conn: connection.Client\n    username: str\n    password: str\n    valid: bool = False\n\n\n@dataclass\nclass Socks5AuthHook(StartHook):\n    \"\"\"\n    Mitmproxy has received username/password SOCKS5 credentials.\n\n    This hook decides whether they are valid by setting `data.valid`.\n    \"\"\"\n\n    data: Socks5AuthData\n\n\nclass Socks5Proxy(DestinationKnown):\n    buf: bytes = b\"\"\n\n    def socks_err(\n        self,\n        message: str,\n        reply_code: int | None = None,\n    ) -> layer.CommandGenerator[None]:\n        if reply_code is not None:\n            yield commands.SendData(\n                self.context.client,\n                bytes([SOCKS5_VERSION, reply_code])\n                + b\"\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\",\n            )\n        yield commands.CloseConnection(self.context.client)\n        yield commands.Log(message)\n        self._handle_event = self.done\n\n    @expect(events.Start, events.DataReceived, events.ConnectionClosed)\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, events.Start):\n            pass\n        elif isinstance(event, events.DataReceived):\n            self.buf += event.data\n            yield from self.state()\n        elif isinstance(event, events.ConnectionClosed):\n            if self.buf:\n                yield commands.Log(\n                    f\"Client closed connection before completing SOCKS5 handshake: {self.buf!r}\"\n                )\n            yield commands.CloseConnection(event.connection)\n        else:\n            raise AssertionError(f\"Unknown event: {event}\")\n\n    def state_greet(self) -> layer.CommandGenerator[None]:\n        if len(self.buf) < 2:\n            return\n\n        if self.buf[0] != SOCKS5_VERSION:\n            if self.buf[:3].isupper():\n                guess = \"Probably not a SOCKS request but a regular HTTP request. \"\n            else:\n                guess = \"\"\n            yield from self.socks_err(\n                guess + \"Invalid SOCKS version. Expected 0x05, got 0x%x\" % self.buf[0]\n            )\n            return\n\n        n_methods = self.buf[1]\n        if len(self.buf) < 2 + n_methods:\n            return\n\n        if \"proxyauth\" in self.context.options and self.context.options.proxyauth:\n            method = SOCKS5_METHOD_USER_PASSWORD_AUTHENTICATION\n            self.state = self.state_auth\n        else:\n            method = SOCKS5_METHOD_NO_AUTHENTICATION_REQUIRED\n            self.state = self.state_connect\n\n        if method not in self.buf[2 : 2 + n_methods]:\n            method_str = (\n                \"user/password\"\n                if method == SOCKS5_METHOD_USER_PASSWORD_AUTHENTICATION\n                else \"no\"\n            )\n            yield from self.socks_err(\n                f\"Client does not support SOCKS5 with {method_str} authentication.\",\n                SOCKS5_METHOD_NO_ACCEPTABLE_METHODS,\n            )\n            return\n        yield commands.SendData(self.context.client, bytes([SOCKS5_VERSION, method]))\n        self.buf = self.buf[2 + n_methods :]\n        yield from self.state()\n\n    state: Callable[..., layer.CommandGenerator[None]] = state_greet\n\n    def state_auth(self) -> layer.CommandGenerator[None]:\n        if len(self.buf) < 3:\n            return\n\n        # Parsing username and password, which is somewhat atrocious\n        user_len = self.buf[1]\n        if len(self.buf) < 3 + user_len:\n            return\n        pass_len = self.buf[2 + user_len]\n        if len(self.buf) < 3 + user_len + pass_len:\n            return\n        user = self.buf[2 : (2 + user_len)].decode(\"utf-8\", \"backslashreplace\")\n        password = self.buf[(3 + user_len) : (3 + user_len + pass_len)].decode(\n            \"utf-8\", \"backslashreplace\"\n        )\n\n        data = Socks5AuthData(self.context.client, user, password)\n        yield Socks5AuthHook(data)\n        if not data.valid:\n            # The VER field contains the current **version of the subnegotiation**, which is X'01'.\n            yield commands.SendData(self.context.client, b\"\\x01\\x01\")\n            yield from self.socks_err(\"authentication failed\")\n            return\n\n        yield commands.SendData(self.context.client, b\"\\x01\\x00\")\n        self.buf = self.buf[3 + user_len + pass_len :]\n        self.state = self.state_connect\n        yield from self.state()\n\n    def state_connect(self) -> layer.CommandGenerator[None]:\n        # Parse Connect Request\n        if len(self.buf) < 5:\n            return\n\n        if self.buf[:3] != b\"\\x05\\x01\\x00\":\n            yield from self.socks_err(\n                f\"Unsupported SOCKS5 request: {self.buf!r}\",\n                SOCKS5_REP_COMMAND_NOT_SUPPORTED,\n            )\n            return\n\n        # Determine message length\n        atyp = self.buf[3]\n        message_len: int\n        if atyp == SOCKS5_ATYP_IPV4_ADDRESS:\n            message_len = 4 + 4 + 2\n        elif atyp == SOCKS5_ATYP_IPV6_ADDRESS:\n            message_len = 4 + 16 + 2\n        elif atyp == SOCKS5_ATYP_DOMAINNAME:\n            message_len = 4 + 1 + self.buf[4] + 2\n        else:\n            yield from self.socks_err(\n                f\"Unknown address type: {atyp}\", SOCKS5_REP_ADDRESS_TYPE_NOT_SUPPORTED\n            )\n            return\n\n        # Do we have enough bytes yet?\n        if len(self.buf) < message_len:\n            return\n\n        # Parse host and port\n        msg, self.buf = self.buf[:message_len], self.buf[message_len:]\n\n        host: str\n        if atyp == SOCKS5_ATYP_IPV4_ADDRESS:\n            host = socket.inet_ntop(socket.AF_INET, msg[4:-2])\n        elif atyp == SOCKS5_ATYP_IPV6_ADDRESS:\n            host = socket.inet_ntop(socket.AF_INET6, msg[4:-2])\n        else:\n            host_bytes = msg[5:-2]\n            host = host_bytes.decode(\"ascii\", \"replace\")\n\n        (port,) = struct.unpack(\"!H\", msg[-2:])\n\n        # We now have all we need, let's get going.\n        self.context.server.address = (host, port)\n        self.child_layer = layer.NextLayer(self.context)\n\n        # this already triggers the child layer's Start event,\n        # but that's not a problem in practice...\n        err = yield from self.finish_start()\n        if err:\n            yield commands.SendData(\n                self.context.client, b\"\\x05\\x04\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\"\n            )\n            yield commands.CloseConnection(self.context.client)\n        else:\n            yield commands.SendData(\n                self.context.client, b\"\\x05\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\"\n            )\n            if self.buf:\n                yield from self.child_layer.handle_event(\n                    events.DataReceived(self.context.client, self.buf)\n                )\n                del self.buf\n", "mitmproxy/proxy/layers/tcp.py": "from dataclasses import dataclass\n\nfrom mitmproxy import flow\nfrom mitmproxy import tcp\nfrom mitmproxy.connection import Connection\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.commands import StartHook\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.events import MessageInjected\nfrom mitmproxy.proxy.utils import expect\n\n\n@dataclass\nclass TcpStartHook(StartHook):\n    \"\"\"\n    A TCP connection has started.\n    \"\"\"\n\n    flow: tcp.TCPFlow\n\n\n@dataclass\nclass TcpMessageHook(StartHook):\n    \"\"\"\n    A TCP connection has received a message. The most recent message\n    will be flow.messages[-1]. The message is user-modifiable.\n    \"\"\"\n\n    flow: tcp.TCPFlow\n\n\n@dataclass\nclass TcpEndHook(StartHook):\n    \"\"\"\n    A TCP connection has ended.\n    \"\"\"\n\n    flow: tcp.TCPFlow\n\n\n@dataclass\nclass TcpErrorHook(StartHook):\n    \"\"\"\n    A TCP error has occurred.\n\n    Every TCP flow will receive either a tcp_error or a tcp_end event, but not both.\n    \"\"\"\n\n    flow: tcp.TCPFlow\n\n\nclass TcpMessageInjected(MessageInjected[tcp.TCPMessage]):\n    \"\"\"\n    The user has injected a custom TCP message.\n    \"\"\"\n\n\nclass TCPLayer(layer.Layer):\n    \"\"\"\n    Simple TCP layer that just relays messages right now.\n    \"\"\"\n\n    flow: tcp.TCPFlow | None\n\n    def __init__(self, context: Context, ignore: bool = False):\n        super().__init__(context)\n        if ignore:\n            self.flow = None\n        else:\n            self.flow = tcp.TCPFlow(self.context.client, self.context.server, True)\n\n    @expect(events.Start)\n    def start(self, _) -> layer.CommandGenerator[None]:\n        if self.flow:\n            yield TcpStartHook(self.flow)\n\n        if self.context.server.timestamp_start is None:\n            err = yield commands.OpenConnection(self.context.server)\n            if err:\n                if self.flow:\n                    self.flow.error = flow.Error(str(err))\n                    yield TcpErrorHook(self.flow)\n                yield commands.CloseConnection(self.context.client)\n                self._handle_event = self.done\n                return\n        self._handle_event = self.relay_messages\n\n    _handle_event = start\n\n    @expect(events.DataReceived, events.ConnectionClosed, TcpMessageInjected)\n    def relay_messages(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, TcpMessageInjected):\n            # we just spoof that we received data here and then process that regularly.\n            event = events.DataReceived(\n                self.context.client\n                if event.message.from_client\n                else self.context.server,\n                event.message.content,\n            )\n\n        assert isinstance(event, events.ConnectionEvent)\n\n        from_client = event.connection == self.context.client\n        send_to: Connection\n        if from_client:\n            send_to = self.context.server\n        else:\n            send_to = self.context.client\n\n        if isinstance(event, events.DataReceived):\n            if self.flow:\n                tcp_message = tcp.TCPMessage(from_client, event.data)\n                self.flow.messages.append(tcp_message)\n                yield TcpMessageHook(self.flow)\n                yield commands.SendData(send_to, tcp_message.content)\n            else:\n                yield commands.SendData(send_to, event.data)\n\n        elif isinstance(event, events.ConnectionClosed):\n            all_done = not (\n                (self.context.client.state & ConnectionState.CAN_READ)\n                or (self.context.server.state & ConnectionState.CAN_READ)\n            )\n            if all_done:\n                self._handle_event = self.done\n                if self.context.server.state is not ConnectionState.CLOSED:\n                    yield commands.CloseConnection(self.context.server)\n                if self.context.client.state is not ConnectionState.CLOSED:\n                    yield commands.CloseConnection(self.context.client)\n                if self.flow:\n                    yield TcpEndHook(self.flow)\n                    self.flow.live = False\n            else:\n                yield commands.CloseTcpConnection(send_to, half_close=True)\n        else:\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n    @expect(events.DataReceived, events.ConnectionClosed, TcpMessageInjected)\n    def done(self, _) -> layer.CommandGenerator[None]:\n        yield from ()\n", "mitmproxy/proxy/layers/dns.py": "import struct\nfrom dataclasses import dataclass\nfrom typing import List\nfrom typing import Literal\n\nfrom mitmproxy import dns\nfrom mitmproxy import flow as mflow\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.utils import expect\n\n_LENGTH_LABEL = struct.Struct(\"!H\")\n\n\n@dataclass\nclass DnsRequestHook(commands.StartHook):\n    \"\"\"\n    A DNS query has been received.\n    \"\"\"\n\n    flow: dns.DNSFlow\n\n\n@dataclass\nclass DnsResponseHook(commands.StartHook):\n    \"\"\"\n    A DNS response has been received or set.\n    \"\"\"\n\n    flow: dns.DNSFlow\n\n\n@dataclass\nclass DnsErrorHook(commands.StartHook):\n    \"\"\"\n    A DNS error has occurred.\n    \"\"\"\n\n    flow: dns.DNSFlow\n\n\ndef pack_message(\n    message: dns.Message, transport_protocol: Literal[\"tcp\", \"udp\"]\n) -> bytes:\n    packed = message.packed\n    if transport_protocol == \"tcp\":\n        return struct.pack(\"!H\", len(packed)) + packed\n    else:\n        return packed\n\n\nclass DNSLayer(layer.Layer):\n    \"\"\"\n    Layer that handles resolving DNS queries.\n    \"\"\"\n\n    flows: dict[int, dns.DNSFlow]\n    req_buf: bytearray\n    resp_buf: bytearray\n\n    def __init__(self, context: Context):\n        super().__init__(context)\n        self.flows = {}\n        self.req_buf = bytearray()\n        self.resp_buf = bytearray()\n\n    def handle_request(\n        self, flow: dns.DNSFlow, msg: dns.Message\n    ) -> layer.CommandGenerator[None]:\n        flow.request = msg  # if already set, continue and query upstream again\n        yield DnsRequestHook(flow)\n        if flow.response:\n            yield from self.handle_response(flow, flow.response)\n        elif not self.context.server.address:\n            yield from self.handle_error(\n                flow, \"No hook has set a response and there is no upstream server.\"\n            )\n        else:\n            if not self.context.server.connected:\n                err = yield commands.OpenConnection(self.context.server)\n                if err:\n                    yield from self.handle_error(flow, str(err))\n                    # cannot recover from this\n                    return\n            packed = pack_message(flow.request, flow.server_conn.transport_protocol)\n            yield commands.SendData(self.context.server, packed)\n\n    def handle_response(\n        self, flow: dns.DNSFlow, msg: dns.Message\n    ) -> layer.CommandGenerator[None]:\n        flow.response = msg\n        yield DnsResponseHook(flow)\n        if flow.response:\n            packed = pack_message(flow.response, flow.client_conn.transport_protocol)\n            yield commands.SendData(self.context.client, packed)\n\n    def handle_error(self, flow: dns.DNSFlow, err: str) -> layer.CommandGenerator[None]:\n        flow.error = mflow.Error(err)\n        yield DnsErrorHook(flow)\n\n    def unpack_message(self, data: bytes, from_client: bool) -> List[dns.Message]:\n        msgs: List[dns.Message] = []\n\n        buf = self.req_buf if from_client else self.resp_buf\n\n        if self.context.client.transport_protocol == \"udp\":\n            msgs.append(dns.Message.unpack(data))\n        elif self.context.client.transport_protocol == \"tcp\":\n            buf.extend(data)\n            size = len(buf)\n            offset = 0\n\n            while True:\n                if size - offset < _LENGTH_LABEL.size:\n                    break\n                (expected_size,) = _LENGTH_LABEL.unpack_from(buf, offset)\n                offset += _LENGTH_LABEL.size\n                if expected_size == 0:\n                    raise struct.error(\"Message length field cannot be zero\")\n\n                if size - offset < expected_size:\n                    offset -= _LENGTH_LABEL.size\n                    break\n\n                data = bytes(buf[offset : expected_size + offset])\n                offset += expected_size\n                msgs.append(dns.Message.unpack(data))\n                expected_size = 0\n\n            del buf[:offset]\n        return msgs\n\n    @expect(events.Start)\n    def state_start(self, _) -> layer.CommandGenerator[None]:\n        self._handle_event = self.state_query\n        yield from ()\n\n    @expect(events.DataReceived, events.ConnectionClosed)\n    def state_query(self, event: events.Event) -> layer.CommandGenerator[None]:\n        assert isinstance(event, events.ConnectionEvent)\n        from_client = event.connection is self.context.client\n\n        if isinstance(event, events.DataReceived):\n            msgs: List[dns.Message] = []\n            try:\n                msgs = self.unpack_message(event.data, from_client)\n            except struct.error as e:\n                yield commands.Log(f\"{event.connection} sent an invalid message: {e}\")\n                yield commands.CloseConnection(event.connection)\n                self._handle_event = self.state_done\n            else:\n                for msg in msgs:\n                    try:\n                        flow = self.flows[msg.id]\n                    except KeyError:\n                        flow = dns.DNSFlow(\n                            self.context.client, self.context.server, live=True\n                        )\n                        self.flows[msg.id] = flow\n                    if from_client:\n                        yield from self.handle_request(flow, msg)\n                    else:\n                        yield from self.handle_response(flow, msg)\n\n        elif isinstance(event, events.ConnectionClosed):\n            other_conn = self.context.server if from_client else self.context.client\n            if other_conn.connected:\n                yield commands.CloseConnection(other_conn)\n            self._handle_event = self.state_done\n            for flow in self.flows.values():\n                flow.live = False\n\n        else:\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n    @expect(events.DataReceived, events.ConnectionClosed)\n    def state_done(self, _) -> layer.CommandGenerator[None]:\n        yield from ()\n\n    _handle_event = state_start\n", "mitmproxy/proxy/layers/tls.py": "import struct\nimport time\nfrom collections.abc import Iterator\nfrom dataclasses import dataclass\nfrom logging import DEBUG\nfrom logging import ERROR\nfrom logging import INFO\nfrom logging import WARNING\n\nfrom OpenSSL import SSL\n\nfrom mitmproxy import certs\nfrom mitmproxy import connection\nfrom mitmproxy.net.tls import starts_like_dtls_record\nfrom mitmproxy.net.tls import starts_like_tls_record\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy import tunnel\nfrom mitmproxy.proxy.commands import StartHook\nfrom mitmproxy.proxy.layers import tcp\nfrom mitmproxy.proxy.layers import udp\nfrom mitmproxy.tls import ClientHello\nfrom mitmproxy.tls import ClientHelloData\nfrom mitmproxy.tls import TlsData\nfrom mitmproxy.utils import human\n\n\ndef handshake_record_contents(data: bytes) -> Iterator[bytes]:\n    \"\"\"\n    Returns a generator that yields the bytes contained in each handshake record.\n    This will raise an error on the first non-handshake record, so fully exhausting this\n    generator is a bad idea.\n    \"\"\"\n    offset = 0\n    while True:\n        if len(data) < offset + 5:\n            return\n        record_header = data[offset : offset + 5]\n        if not starts_like_tls_record(record_header):\n            raise ValueError(f\"Expected TLS record, got {record_header!r} instead.\")\n        record_size = struct.unpack(\"!H\", record_header[3:])[0]\n        if record_size == 0:\n            raise ValueError(\"Record must not be empty.\")\n        offset += 5\n\n        if len(data) < offset + record_size:\n            return\n        record_body = data[offset : offset + record_size]\n        yield record_body\n        offset += record_size\n\n\ndef get_client_hello(data: bytes) -> bytes | None:\n    \"\"\"\n    Read all TLS records that contain the initial ClientHello.\n    Returns the raw handshake packet bytes, without TLS record headers.\n    \"\"\"\n    client_hello = b\"\"\n    for d in handshake_record_contents(data):\n        client_hello += d\n        if len(client_hello) >= 4:\n            client_hello_size = struct.unpack(\"!I\", b\"\\x00\" + client_hello[1:4])[0] + 4\n            if len(client_hello) >= client_hello_size:\n                return client_hello[:client_hello_size]\n    return None\n\n\ndef parse_client_hello(data: bytes) -> ClientHello | None:\n    \"\"\"\n    Check if the supplied bytes contain a full ClientHello message,\n    and if so, parse it.\n\n    Returns:\n        - A ClientHello object on success\n        - None, if the TLS record is not complete\n\n    Raises:\n        - A ValueError, if the passed ClientHello is invalid\n    \"\"\"\n    # Check if ClientHello is complete\n    client_hello = get_client_hello(data)\n    if client_hello:\n        try:\n            return ClientHello(client_hello[4:])\n        except EOFError as e:\n            raise ValueError(\"Invalid ClientHello\") from e\n    return None\n\n\ndef dtls_handshake_record_contents(data: bytes) -> Iterator[bytes]:\n    \"\"\"\n    Returns a generator that yields the bytes contained in each handshake record.\n    This will raise an error on the first non-handshake record, so fully exhausting this\n    generator is a bad idea.\n    \"\"\"\n    offset = 0\n    while True:\n        # DTLS includes two new fields, totaling 8 bytes, between Version and Length\n        if len(data) < offset + 13:\n            return\n        record_header = data[offset : offset + 13]\n        if not starts_like_dtls_record(record_header):\n            raise ValueError(f\"Expected DTLS record, got {record_header!r} instead.\")\n        # Length fields starts at 11\n        record_size = struct.unpack(\"!H\", record_header[11:])[0]\n        if record_size == 0:\n            raise ValueError(\"Record must not be empty.\")\n        offset += 13\n\n        if len(data) < offset + record_size:\n            return\n        record_body = data[offset : offset + record_size]\n        yield record_body\n        offset += record_size\n\n\ndef get_dtls_client_hello(data: bytes) -> bytes | None:\n    \"\"\"\n    Read all DTLS records that contain the initial ClientHello.\n    Returns the raw handshake packet bytes, without TLS record headers.\n    \"\"\"\n    client_hello = b\"\"\n    for d in dtls_handshake_record_contents(data):\n        client_hello += d\n        if len(client_hello) >= 13:\n            # comment about slicing: we skip the epoch and sequence number\n            client_hello_size = (\n                struct.unpack(\"!I\", b\"\\x00\" + client_hello[9:12])[0] + 12\n            )\n            if len(client_hello) >= client_hello_size:\n                return client_hello[:client_hello_size]\n    return None\n\n\ndef dtls_parse_client_hello(data: bytes) -> ClientHello | None:\n    \"\"\"\n    Check if the supplied bytes contain a full ClientHello message,\n    and if so, parse it.\n\n    Returns:\n        - A ClientHello object on success\n        - None, if the TLS record is not complete\n\n    Raises:\n        - A ValueError, if the passed ClientHello is invalid\n    \"\"\"\n    # Check if ClientHello is complete\n    client_hello = get_dtls_client_hello(data)\n    if client_hello:\n        try:\n            return ClientHello(client_hello[12:], dtls=True)\n        except EOFError as e:\n            raise ValueError(\"Invalid ClientHello\") from e\n    return None\n\n\nHTTP1_ALPNS = (b\"http/1.1\", b\"http/1.0\", b\"http/0.9\")\nHTTP_ALPNS = (b\"h2\",) + HTTP1_ALPNS\n\n\n# We need these classes as hooks can only have one argument at the moment.\n\n\n@dataclass\nclass TlsClienthelloHook(StartHook):\n    \"\"\"\n    Mitmproxy has received a TLS ClientHello message.\n\n    This hook decides whether a server connection is needed\n    to negotiate TLS with the client (data.establish_server_tls_first)\n    \"\"\"\n\n    data: ClientHelloData\n\n\n@dataclass\nclass TlsStartClientHook(StartHook):\n    \"\"\"\n    TLS negotation between mitmproxy and a client is about to start.\n\n    An addon is expected to initialize data.ssl_conn.\n    (by default, this is done by `mitmproxy.addons.tlsconfig`)\n    \"\"\"\n\n    data: TlsData\n\n\n@dataclass\nclass TlsStartServerHook(StartHook):\n    \"\"\"\n    TLS negotation between mitmproxy and a server is about to start.\n\n    An addon is expected to initialize data.ssl_conn.\n    (by default, this is done by `mitmproxy.addons.tlsconfig`)\n    \"\"\"\n\n    data: TlsData\n\n\n@dataclass\nclass TlsEstablishedClientHook(StartHook):\n    \"\"\"\n    The TLS handshake with the client has been completed successfully.\n    \"\"\"\n\n    data: TlsData\n\n\n@dataclass\nclass TlsEstablishedServerHook(StartHook):\n    \"\"\"\n    The TLS handshake with the server has been completed successfully.\n    \"\"\"\n\n    data: TlsData\n\n\n@dataclass\nclass TlsFailedClientHook(StartHook):\n    \"\"\"\n    The TLS handshake with the client has failed.\n    \"\"\"\n\n    data: TlsData\n\n\n@dataclass\nclass TlsFailedServerHook(StartHook):\n    \"\"\"\n    The TLS handshake with the server has failed.\n    \"\"\"\n\n    data: TlsData\n\n\nclass TLSLayer(tunnel.TunnelLayer):\n    tls: SSL.Connection = None  # type: ignore\n    \"\"\"The OpenSSL connection object\"\"\"\n\n    def __init__(self, context: context.Context, conn: connection.Connection):\n        super().__init__(\n            context,\n            tunnel_connection=conn,\n            conn=conn,\n        )\n\n        conn.tls = True\n\n    def __repr__(self):\n        return (\n            super().__repr__().replace(\")\", f\" {self.conn.sni!r} {self.conn.alpn!r})\")\n        )\n\n    @property\n    def is_dtls(self):\n        return self.conn.transport_protocol == \"udp\"\n\n    @property\n    def proto_name(self):\n        return \"DTLS\" if self.is_dtls else \"TLS\"\n\n    def start_tls(self) -> layer.CommandGenerator[None]:\n        assert not self.tls\n\n        tls_start = TlsData(self.conn, self.context, is_dtls=self.is_dtls)\n        if self.conn == self.context.client:\n            yield TlsStartClientHook(tls_start)\n        else:\n            yield TlsStartServerHook(tls_start)\n        if not tls_start.ssl_conn:\n            yield commands.Log(\n                f\"No {self.proto_name} context was provided, failing connection.\", ERROR\n            )\n            yield commands.CloseConnection(self.conn)\n            return\n        assert tls_start.ssl_conn\n        self.tls = tls_start.ssl_conn\n\n    def tls_interact(self) -> layer.CommandGenerator[None]:\n        while True:\n            try:\n                data = self.tls.bio_read(65535)\n            except SSL.WantReadError:\n                return  # Okay, nothing more waiting to be sent.\n            else:\n                yield commands.SendData(self.conn, data)\n\n    def receive_handshake_data(\n        self, data: bytes\n    ) -> layer.CommandGenerator[tuple[bool, str | None]]:\n        # bio_write errors for b\"\", so we need to check first if we actually received something.\n        if data:\n            self.tls.bio_write(data)\n        try:\n            self.tls.do_handshake()\n        except SSL.WantReadError:\n            yield from self.tls_interact()\n            return False, None\n        except SSL.Error as e:\n            # provide more detailed information for some errors.\n            last_err = (\n                e.args and isinstance(e.args[0], list) and e.args[0] and e.args[0][-1]\n            )\n            if last_err in [\n                (\n                    \"SSL routines\",\n                    \"tls_process_server_certificate\",\n                    \"certificate verify failed\",\n                ),\n                (\"SSL routines\", \"\", \"certificate verify failed\"),  # OpenSSL 3+\n            ]:\n                verify_result = SSL._lib.SSL_get_verify_result(self.tls._ssl)  # type: ignore\n                error = SSL._ffi.string(  # type: ignore\n                    SSL._lib.X509_verify_cert_error_string(verify_result)  # type: ignore\n                ).decode()\n                err = f\"Certificate verify failed: {error}\"\n            elif last_err in [\n                (\"SSL routines\", \"ssl3_read_bytes\", \"tlsv1 alert unknown ca\"),\n                (\"SSL routines\", \"ssl3_read_bytes\", \"sslv3 alert bad certificate\"),\n                (\"SSL routines\", \"ssl3_read_bytes\", \"ssl/tls alert bad certificate\"),\n                (\"SSL routines\", \"\", \"tlsv1 alert unknown ca\"),  # OpenSSL 3+\n                (\"SSL routines\", \"\", \"sslv3 alert bad certificate\"),  # OpenSSL 3+\n                (\"SSL routines\", \"\", \"ssl/tls alert bad certificate\"),  # OpenSSL 3.2+\n            ]:\n                assert isinstance(last_err, tuple)\n                err = last_err[2]\n            elif (\n                last_err\n                in [\n                    (\"SSL routines\", \"ssl3_get_record\", \"wrong version number\"),\n                    (\"SSL routines\", \"\", \"wrong version number\"),  # OpenSSL 3+\n                    (\"SSL routines\", \"\", \"packet length too long\"),  # OpenSSL 3+\n                    (\"SSL routines\", \"\", \"record layer failure\"),  # OpenSSL 3+\n                ]\n                and data[:4].isascii()\n            ):\n                err = f\"The remote server does not speak TLS.\"\n            elif last_err in [\n                (\"SSL routines\", \"ssl3_read_bytes\", \"tlsv1 alert protocol version\"),\n                (\"SSL routines\", \"\", \"tlsv1 alert protocol version\"),  # OpenSSL 3+\n            ]:\n                err = (\n                    f\"The remote server and mitmproxy cannot agree on a TLS version to use. \"\n                    f\"You may need to adjust mitmproxy's tls_version_server_min option.\"\n                )\n            else:\n                err = f\"OpenSSL {e!r}\"\n            return False, err\n        else:\n            # Here we set all attributes that are only known *after* the handshake.\n\n            # Get all peer certificates.\n            # https://www.openssl.org/docs/man1.1.1/man3/SSL_get_peer_cert_chain.html\n            # If called on the client side, the stack also contains the peer's certificate; if called on the server\n            # side, the peer's certificate must be obtained separately using SSL_get_peer_certificate(3).\n            all_certs = self.tls.get_peer_cert_chain() or []\n            if self.conn == self.context.client:\n                cert = self.tls.get_peer_certificate()\n                if cert:\n                    all_certs.insert(0, cert)\n\n            self.conn.timestamp_tls_setup = time.time()\n            self.conn.alpn = self.tls.get_alpn_proto_negotiated()\n            self.conn.certificate_list = [\n                certs.Cert.from_pyopenssl(x) for x in all_certs\n            ]\n            self.conn.cipher = self.tls.get_cipher_name()\n            self.conn.tls_version = self.tls.get_protocol_version_name()\n            if self.debug:\n                yield commands.Log(\n                    f\"{self.debug}[tls] tls established: {self.conn}\", DEBUG\n                )\n            if self.conn == self.context.client:\n                yield TlsEstablishedClientHook(\n                    TlsData(self.conn, self.context, self.tls)\n                )\n            else:\n                yield TlsEstablishedServerHook(\n                    TlsData(self.conn, self.context, self.tls)\n                )\n            yield from self.receive_data(b\"\")\n            return True, None\n\n    def on_handshake_error(self, err: str) -> layer.CommandGenerator[None]:\n        self.conn.error = err\n        if self.conn == self.context.client:\n            yield TlsFailedClientHook(TlsData(self.conn, self.context, self.tls))\n        else:\n            yield TlsFailedServerHook(TlsData(self.conn, self.context, self.tls))\n        yield from super().on_handshake_error(err)\n\n    def receive_data(self, data: bytes) -> layer.CommandGenerator[None]:\n        if data:\n            self.tls.bio_write(data)\n        yield from self.tls_interact()\n\n        plaintext = bytearray()\n        close = False\n        while True:\n            try:\n                plaintext.extend(self.tls.recv(65535))\n            except SSL.WantReadError:\n                break\n            except SSL.ZeroReturnError:\n                close = True\n                break\n            except SSL.Error as e:\n                # This may be happening because the other side send an alert.\n                # There's somewhat ugly behavior with Firefox on Android here,\n                # which upon mistrusting a certificate still completes the handshake\n                # and then sends an alert in the next packet. At this point we have unfortunately\n                # already fired out `tls_established_client` hook.\n                yield commands.Log(f\"TLS Error: {e}\", WARNING)\n                break\n        if plaintext:\n            yield from self.event_to_child(\n                events.DataReceived(self.conn, bytes(plaintext))\n            )\n        if close:\n            self.conn.state &= ~connection.ConnectionState.CAN_READ\n            if self.debug:\n                yield commands.Log(f\"{self.debug}[tls] close_notify {self.conn}\", DEBUG)\n            yield from self.event_to_child(events.ConnectionClosed(self.conn))\n\n    def receive_close(self) -> layer.CommandGenerator[None]:\n        if self.tls.get_shutdown() & SSL.RECEIVED_SHUTDOWN:\n            pass  # We have already dispatched a ConnectionClosed to the child layer.\n        else:\n            yield from super().receive_close()\n\n    def send_data(self, data: bytes) -> layer.CommandGenerator[None]:\n        try:\n            self.tls.sendall(data)\n        except (SSL.ZeroReturnError, SSL.SysCallError):\n            # The other peer may still be trying to send data over, which we discard here.\n            pass\n        yield from self.tls_interact()\n\n    def send_close(\n        self, command: commands.CloseConnection\n    ) -> layer.CommandGenerator[None]:\n        # We should probably shutdown the TLS connection properly here.\n        yield from super().send_close(command)\n\n\nclass ServerTLSLayer(TLSLayer):\n    \"\"\"\n    This layer establishes TLS for a single server connection.\n    \"\"\"\n\n    wait_for_clienthello: bool = False\n\n    def __init__(self, context: context.Context, conn: connection.Server | None = None):\n        super().__init__(context, conn or context.server)\n\n    def start_handshake(self) -> layer.CommandGenerator[None]:\n        wait_for_clienthello = (\n            # if command_to_reply_to is set, we've been instructed to open the connection from the child layer.\n            # in that case any potential ClientHello is already parsed (by the ClientTLS child layer).\n            not self.command_to_reply_to\n            # if command_to_reply_to is not set, the connection was already open when this layer received its Start\n            # event (eager connection strategy). We now want to establish TLS right away, _unless_ we already know\n            # that there's TLS on the client side as well (we check if our immediate child layer is set to be ClientTLS)\n            # In this case want to wait for ClientHello to be parsed, so that we can incorporate SNI/ALPN from there.\n            and isinstance(self.child_layer, ClientTLSLayer)\n        )\n        if wait_for_clienthello:\n            self.wait_for_clienthello = True\n            self.tunnel_state = tunnel.TunnelState.CLOSED\n        else:\n            yield from self.start_tls()\n            if self.tls:\n                yield from self.receive_handshake_data(b\"\")\n\n    def event_to_child(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if self.wait_for_clienthello:\n            for command in super().event_to_child(event):\n                if (\n                    isinstance(command, commands.OpenConnection)\n                    and command.connection == self.conn\n                ):\n                    self.wait_for_clienthello = False\n                    # swallow OpenConnection here by not re-yielding it.\n                else:\n                    yield command\n        else:\n            yield from super().event_to_child(event)\n\n    def on_handshake_error(self, err: str) -> layer.CommandGenerator[None]:\n        yield commands.Log(f\"Server TLS handshake failed. {err}\", level=WARNING)\n        yield from super().on_handshake_error(err)\n\n\nclass ClientTLSLayer(TLSLayer):\n    \"\"\"\n    This layer establishes TLS on a single client connection.\n\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502Start\u2502\n    \u2514\u252c\u2500\u2500\u2500\u2500\u2518\n     \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502Wait for ClientHello\u2502\n    \u2514\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502Process messages\u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n    \"\"\"\n\n    recv_buffer: bytearray\n    server_tls_available: bool\n    client_hello_parsed: bool = False\n\n    def __init__(self, context: context.Context):\n        if context.client.tls:\n            # In the case of TLS-over-TLS, we already have client TLS. As the outer TLS connection between client\n            # and proxy isn't that interesting to us, we just unset the attributes here and keep the inner TLS\n            # session's attributes.\n            # Alternatively we could create a new Client instance,\n            # but for now we keep it simple. There is a proof-of-concept at\n            # https://github.com/mitmproxy/mitmproxy/commit/9b6e2a716888b7787514733b76a5936afa485352.\n            context.client.alpn = None\n            context.client.cipher = None\n            context.client.sni = None\n            context.client.timestamp_tls_setup = None\n            context.client.tls_version = None\n            context.client.certificate_list = []\n            context.client.mitmcert = None\n            context.client.alpn_offers = []\n            context.client.cipher_list = []\n\n        super().__init__(context, context.client)\n        self.server_tls_available = isinstance(self.context.layers[-2], ServerTLSLayer)\n        self.recv_buffer = bytearray()\n\n    def start_handshake(self) -> layer.CommandGenerator[None]:\n        yield from ()\n\n    def receive_handshake_data(\n        self, data: bytes\n    ) -> layer.CommandGenerator[tuple[bool, str | None]]:\n        if self.client_hello_parsed:\n            return (yield from super().receive_handshake_data(data))\n        self.recv_buffer.extend(data)\n        try:\n            if self.is_dtls:\n                client_hello = dtls_parse_client_hello(self.recv_buffer)\n            else:\n                client_hello = parse_client_hello(self.recv_buffer)\n        except ValueError:\n            return False, f\"Cannot parse ClientHello: {self.recv_buffer.hex()}\"\n\n        if client_hello:\n            self.client_hello_parsed = True\n        else:\n            return False, None\n\n        self.conn.sni = client_hello.sni\n        self.conn.alpn_offers = client_hello.alpn_protocols\n        tls_clienthello = ClientHelloData(self.context, client_hello)\n        yield TlsClienthelloHook(tls_clienthello)\n\n        if tls_clienthello.ignore_connection:\n            # we've figured out that we don't want to intercept this connection, so we assign fake connection objects\n            # to all TLS layers. This makes the real connection contents just go through.\n            self.conn = self.tunnel_connection = connection.Client(\n                peername=(\"ignore-conn\", 0), sockname=(\"ignore-conn\", 0)\n            )\n            parent_layer = self.context.layers[self.context.layers.index(self) - 1]\n            if isinstance(parent_layer, ServerTLSLayer):\n                parent_layer.conn = parent_layer.tunnel_connection = connection.Server(\n                    address=None\n                )\n            if self.is_dtls:\n                self.child_layer = udp.UDPLayer(self.context, ignore=True)\n            else:\n                self.child_layer = tcp.TCPLayer(self.context, ignore=True)\n            yield from self.event_to_child(\n                events.DataReceived(self.context.client, bytes(self.recv_buffer))\n            )\n            self.recv_buffer.clear()\n            return True, None\n        if (\n            tls_clienthello.establish_server_tls_first\n            and not self.context.server.tls_established\n        ):\n            err = yield from self.start_server_tls()\n            if err:\n                yield commands.Log(\n                    f\"Unable to establish {self.proto_name} connection with server ({err}). \"\n                    f\"Trying to establish {self.proto_name} with client anyway. \"\n                    f\"If you plan to redirect requests away from this server, \"\n                    f\"consider setting `connection_strategy` to `lazy` to suppress early connections.\"\n                )\n\n        yield from self.start_tls()\n        if not self.conn.connected:\n            return False, \"connection closed early\"\n\n        ret = yield from super().receive_handshake_data(bytes(self.recv_buffer))\n        self.recv_buffer.clear()\n        return ret\n\n    def start_server_tls(self) -> layer.CommandGenerator[str | None]:\n        \"\"\"\n        We often need information from the upstream connection to establish TLS with the client.\n        For example, we need to check if the client does ALPN or not.\n        \"\"\"\n        if not self.server_tls_available:\n            return f\"No server {self.proto_name} available.\"\n        err = yield commands.OpenConnection(self.context.server)\n        return err\n\n    def on_handshake_error(self, err: str) -> layer.CommandGenerator[None]:\n        if self.conn.sni:\n            dest = self.conn.sni\n        else:\n            dest = human.format_address(self.context.server.address)\n        level: int = WARNING\n        if err.startswith(\"Cannot parse ClientHello\"):\n            pass\n        elif (\n            \"('SSL routines', 'tls_early_post_process_client_hello', 'unsupported protocol')\"\n            in err\n            or \"('SSL routines', '', 'unsupported protocol')\" in err  # OpenSSL 3+\n        ):\n            err = (\n                f\"Client and mitmproxy cannot agree on a TLS version to use. \"\n                f\"You may need to adjust mitmproxy's tls_version_client_min option.\"\n            )\n        elif (\n            \"unknown ca\" in err\n            or \"bad certificate\" in err\n            or \"certificate unknown\" in err\n        ):\n            err = (\n                f\"The client does not trust the proxy's certificate for {dest} ({err})\"\n            )\n        elif err == \"connection closed\":\n            err = (\n                f\"The client disconnected during the handshake. If this happens consistently for {dest}, \"\n                f\"this may indicate that the client does not trust the proxy's certificate.\"\n            )\n            level = INFO\n        elif err == \"connection closed early\":\n            pass\n        else:\n            err = f\"The client may not trust the proxy's certificate for {dest} ({err})\"\n        if err != \"connection closed early\":\n            yield commands.Log(f\"Client TLS handshake failed. {err}\", level=level)\n        yield from super().on_handshake_error(err)\n        self.event_to_child = self.errored  # type: ignore\n\n    def errored(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if self.debug is not None:\n            yield commands.Log(\n                f\"{self.debug}[tls] Swallowing {event} as handshake failed.\", DEBUG\n            )\n\n\nclass MockTLSLayer(TLSLayer):\n    \"\"\"Mock layer to disable actual TLS and use cleartext in tests.\n\n    Use like so:\n        monkeypatch.setattr(tls, \"ServerTLSLayer\", tls.MockTLSLayer)\n    \"\"\"\n\n    def __init__(self, ctx: context.Context):\n        super().__init__(ctx, connection.Server(address=None))\n", "mitmproxy/proxy/layers/udp.py": "from dataclasses import dataclass\n\nfrom mitmproxy import flow\nfrom mitmproxy import udp\nfrom mitmproxy.connection import Connection\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.commands import StartHook\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.events import MessageInjected\nfrom mitmproxy.proxy.utils import expect\n\n\n@dataclass\nclass UdpStartHook(StartHook):\n    \"\"\"\n    A UDP connection has started.\n    \"\"\"\n\n    flow: udp.UDPFlow\n\n\n@dataclass\nclass UdpMessageHook(StartHook):\n    \"\"\"\n    A UDP connection has received a message. The most recent message\n    will be flow.messages[-1]. The message is user-modifiable.\n    \"\"\"\n\n    flow: udp.UDPFlow\n\n\n@dataclass\nclass UdpEndHook(StartHook):\n    \"\"\"\n    A UDP connection has ended.\n    \"\"\"\n\n    flow: udp.UDPFlow\n\n\n@dataclass\nclass UdpErrorHook(StartHook):\n    \"\"\"\n    A UDP error has occurred.\n\n    Every UDP flow will receive either a udp_error or a udp_end event, but not both.\n    \"\"\"\n\n    flow: udp.UDPFlow\n\n\nclass UdpMessageInjected(MessageInjected[udp.UDPMessage]):\n    \"\"\"\n    The user has injected a custom UDP message.\n    \"\"\"\n\n\nclass UDPLayer(layer.Layer):\n    \"\"\"\n    Simple UDP layer that just relays messages right now.\n    \"\"\"\n\n    flow: udp.UDPFlow | None\n\n    def __init__(self, context: Context, ignore: bool = False):\n        super().__init__(context)\n        if ignore:\n            self.flow = None\n        else:\n            self.flow = udp.UDPFlow(self.context.client, self.context.server, True)\n\n    @expect(events.Start)\n    def start(self, _) -> layer.CommandGenerator[None]:\n        if self.flow:\n            yield UdpStartHook(self.flow)\n\n        if self.context.server.timestamp_start is None:\n            err = yield commands.OpenConnection(self.context.server)\n            if err:\n                if self.flow:\n                    self.flow.error = flow.Error(str(err))\n                    yield UdpErrorHook(self.flow)\n                yield commands.CloseConnection(self.context.client)\n                self._handle_event = self.done\n                return\n        self._handle_event = self.relay_messages\n\n    _handle_event = start\n\n    @expect(events.DataReceived, events.ConnectionClosed, UdpMessageInjected)\n    def relay_messages(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, UdpMessageInjected):\n            # we just spoof that we received data here and then process that regularly.\n            event = events.DataReceived(\n                self.context.client\n                if event.message.from_client\n                else self.context.server,\n                event.message.content,\n            )\n\n        assert isinstance(event, events.ConnectionEvent)\n\n        from_client = event.connection == self.context.client\n        send_to: Connection\n        if from_client:\n            send_to = self.context.server\n        else:\n            send_to = self.context.client\n\n        if isinstance(event, events.DataReceived):\n            if self.flow:\n                udp_message = udp.UDPMessage(from_client, event.data)\n                self.flow.messages.append(udp_message)\n                yield UdpMessageHook(self.flow)\n                yield commands.SendData(send_to, udp_message.content)\n            else:\n                yield commands.SendData(send_to, event.data)\n\n        elif isinstance(event, events.ConnectionClosed):\n            self._handle_event = self.done\n            yield commands.CloseConnection(send_to)\n            if self.flow:\n                yield UdpEndHook(self.flow)\n                self.flow.live = False\n        else:\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n    @expect(events.DataReceived, events.ConnectionClosed, UdpMessageInjected)\n    def done(self, _) -> layer.CommandGenerator[None]:\n        yield from ()\n", "mitmproxy/proxy/layers/__init__.py": "from . import modes\nfrom .dns import DNSLayer\nfrom .http import HttpLayer\nfrom .quic import ClientQuicLayer\nfrom .quic import QuicStreamLayer\nfrom .quic import RawQuicLayer\nfrom .quic import ServerQuicLayer\nfrom .tcp import TCPLayer\nfrom .tls import ClientTLSLayer\nfrom .tls import ServerTLSLayer\nfrom .udp import UDPLayer\nfrom .websocket import WebsocketLayer\n\n__all__ = [\n    \"modes\",\n    \"DNSLayer\",\n    \"HttpLayer\",\n    \"QuicStreamLayer\",\n    \"RawQuicLayer\",\n    \"TCPLayer\",\n    \"UDPLayer\",\n    \"ClientQuicLayer\",\n    \"ClientTLSLayer\",\n    \"ServerQuicLayer\",\n    \"ServerTLSLayer\",\n    \"WebsocketLayer\",\n]\n", "mitmproxy/proxy/layers/websocket.py": "import time\nfrom collections.abc import Iterator\nfrom dataclasses import dataclass\n\nimport wsproto.extensions\nimport wsproto.frame_protocol\nimport wsproto.utilities\nfrom wsproto import ConnectionState\nfrom wsproto.frame_protocol import Opcode\n\nfrom mitmproxy import connection\nfrom mitmproxy import http\nfrom mitmproxy import websocket\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.commands import StartHook\nfrom mitmproxy.proxy.context import Context\nfrom mitmproxy.proxy.events import MessageInjected\nfrom mitmproxy.proxy.utils import expect\n\n\n@dataclass\nclass WebsocketStartHook(StartHook):\n    \"\"\"\n    A WebSocket connection has commenced.\n    \"\"\"\n\n    flow: http.HTTPFlow\n\n\n@dataclass\nclass WebsocketMessageHook(StartHook):\n    \"\"\"\n    Called when a WebSocket message is received from the client or\n    server. The most recent message will be flow.messages[-1]. The\n    message is user-modifiable. Currently there are two types of\n    messages, corresponding to the BINARY and TEXT frame types.\n    \"\"\"\n\n    flow: http.HTTPFlow\n\n\n@dataclass\nclass WebsocketEndHook(StartHook):\n    \"\"\"\n    A WebSocket connection has ended.\n    You can check `flow.websocket.close_code` to determine why it ended.\n    \"\"\"\n\n    flow: http.HTTPFlow\n\n\nclass WebSocketMessageInjected(MessageInjected[websocket.WebSocketMessage]):\n    \"\"\"\n    The user has injected a custom WebSocket message.\n    \"\"\"\n\n\nclass WebsocketConnection(wsproto.Connection):\n    \"\"\"\n    A very thin wrapper around wsproto.Connection:\n\n     - we keep the underlying connection as an attribute for easy access.\n     - we add a framebuffer for incomplete messages\n     - we wrap .send() so that we can directly yield it.\n    \"\"\"\n\n    conn: connection.Connection\n    frame_buf: list[bytes]\n\n    def __init__(self, *args, conn: connection.Connection, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.conn = conn\n        self.frame_buf = [b\"\"]\n\n    def send2(self, event: wsproto.events.Event) -> commands.SendData:\n        data = self.send(event)\n        return commands.SendData(self.conn, data)\n\n    def __repr__(self):\n        return f\"WebsocketConnection<{self.state.name}, {self.conn}>\"\n\n\nclass WebsocketLayer(layer.Layer):\n    \"\"\"\n    WebSocket layer that intercepts and relays messages.\n    \"\"\"\n\n    flow: http.HTTPFlow\n    client_ws: WebsocketConnection\n    server_ws: WebsocketConnection\n\n    def __init__(self, context: Context, flow: http.HTTPFlow):\n        super().__init__(context)\n        self.flow = flow\n\n    @expect(events.Start)\n    def start(self, _) -> layer.CommandGenerator[None]:\n        client_extensions = []\n        server_extensions = []\n\n        # Parse extension headers. We only support deflate at the moment and ignore everything else.\n        assert self.flow.response  # satisfy type checker\n        ext_header = self.flow.response.headers.get(\"Sec-WebSocket-Extensions\", \"\")\n        if ext_header:\n            for ext in wsproto.utilities.split_comma_header(\n                ext_header.encode(\"ascii\", \"replace\")\n            ):\n                ext_name = ext.split(\";\", 1)[0].strip()\n                if ext_name == wsproto.extensions.PerMessageDeflate.name:\n                    client_deflate = wsproto.extensions.PerMessageDeflate()\n                    client_deflate.finalize(ext)\n                    client_extensions.append(client_deflate)\n                    server_deflate = wsproto.extensions.PerMessageDeflate()\n                    server_deflate.finalize(ext)\n                    server_extensions.append(server_deflate)\n                else:\n                    yield commands.Log(\n                        f\"Ignoring unknown WebSocket extension {ext_name!r}.\"\n                    )\n\n        self.client_ws = WebsocketConnection(\n            wsproto.ConnectionType.SERVER, client_extensions, conn=self.context.client\n        )\n        self.server_ws = WebsocketConnection(\n            wsproto.ConnectionType.CLIENT, server_extensions, conn=self.context.server\n        )\n\n        yield WebsocketStartHook(self.flow)\n\n        self._handle_event = self.relay_messages\n\n    _handle_event = start\n\n    @expect(events.DataReceived, events.ConnectionClosed, WebSocketMessageInjected)\n    def relay_messages(self, event: events.Event) -> layer.CommandGenerator[None]:\n        assert self.flow.websocket  # satisfy type checker\n\n        if isinstance(event, events.ConnectionEvent):\n            from_client = event.connection == self.context.client\n            injected = False\n        elif isinstance(event, WebSocketMessageInjected):\n            from_client = event.message.from_client\n            injected = True\n        else:\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n        from_str = \"client\" if from_client else \"server\"\n        if from_client:\n            src_ws = self.client_ws\n            dst_ws = self.server_ws\n        else:\n            src_ws = self.server_ws\n            dst_ws = self.client_ws\n\n        if isinstance(event, events.DataReceived):\n            src_ws.receive_data(event.data)\n        elif isinstance(event, events.ConnectionClosed):\n            src_ws.receive_data(None)\n        elif isinstance(event, WebSocketMessageInjected):\n            fragmentizer = Fragmentizer([], event.message.type == Opcode.TEXT)\n            src_ws._events.extend(fragmentizer(event.message.content))\n        else:  # pragma: no cover\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n        for ws_event in src_ws.events():\n            if isinstance(ws_event, wsproto.events.Message):\n                is_text = isinstance(ws_event.data, str)\n                if is_text:\n                    typ = Opcode.TEXT\n                    src_ws.frame_buf[-1] += ws_event.data.encode()\n                else:\n                    typ = Opcode.BINARY\n                    src_ws.frame_buf[-1] += ws_event.data\n\n                if ws_event.message_finished:\n                    content = b\"\".join(src_ws.frame_buf)\n\n                    fragmentizer = Fragmentizer(src_ws.frame_buf, is_text)\n                    src_ws.frame_buf = [b\"\"]\n\n                    message = websocket.WebSocketMessage(\n                        typ, from_client, content, injected=injected\n                    )\n                    self.flow.websocket.messages.append(message)\n                    yield WebsocketMessageHook(self.flow)\n\n                    if not message.dropped:\n                        for msg in fragmentizer(message.content):\n                            yield dst_ws.send2(msg)\n\n                elif ws_event.frame_finished:\n                    src_ws.frame_buf.append(b\"\")\n\n            elif isinstance(ws_event, (wsproto.events.Ping, wsproto.events.Pong)):\n                yield commands.Log(\n                    f\"Received WebSocket {ws_event.__class__.__name__.lower()} from {from_str} \"\n                    f\"(payload: {bytes(ws_event.payload)!r})\"\n                )\n                yield dst_ws.send2(ws_event)\n            elif isinstance(ws_event, wsproto.events.CloseConnection):\n                self.flow.websocket.timestamp_end = time.time()\n                self.flow.websocket.closed_by_client = from_client\n                self.flow.websocket.close_code = ws_event.code\n                self.flow.websocket.close_reason = ws_event.reason\n\n                for ws in [self.server_ws, self.client_ws]:\n                    if ws.state in {\n                        ConnectionState.OPEN,\n                        ConnectionState.REMOTE_CLOSING,\n                    }:\n                        # response == original event, so no need to differentiate here.\n                        yield ws.send2(ws_event)\n                    yield commands.CloseConnection(ws.conn)\n                yield WebsocketEndHook(self.flow)\n                self.flow.live = False\n                self._handle_event = self.done\n            else:  # pragma: no cover\n                raise AssertionError(f\"Unexpected WebSocket event: {ws_event}\")\n\n    @expect(events.DataReceived, events.ConnectionClosed, WebSocketMessageInjected)\n    def done(self, _) -> layer.CommandGenerator[None]:\n        yield from ()\n\n\nclass Fragmentizer:\n    \"\"\"\n    Theory (RFC 6455):\n       Unless specified otherwise by an extension, frames have no semantic\n       meaning.  An intermediary might coalesce and/or split frames, [...]\n\n    Practice:\n        Some WebSocket servers reject large payload sizes.\n        Other WebSocket servers reject CONTINUATION frames.\n\n    As a workaround, we either retain the original chunking or, if the payload has been modified, use ~4kB chunks.\n    If one deals with web servers that do not support CONTINUATION frames, addons need to monkeypatch FRAGMENT_SIZE\n    if they need to modify the message.\n    \"\"\"\n\n    # A bit less than 4kb to accommodate for headers.\n    FRAGMENT_SIZE = 4000\n\n    def __init__(self, fragments: list[bytes], is_text: bool):\n        self.fragment_lengths = [len(x) for x in fragments]\n        self.is_text = is_text\n\n    def msg(self, data: bytes, message_finished: bool):\n        if self.is_text:\n            data_str = data.decode(errors=\"replace\")\n            return wsproto.events.TextMessage(\n                data_str, message_finished=message_finished\n            )\n        else:\n            return wsproto.events.BytesMessage(data, message_finished=message_finished)\n\n    def __call__(self, content: bytes) -> Iterator[wsproto.events.Message]:\n        if len(content) == sum(self.fragment_lengths):\n            # message has the same length, we can reuse the same sizes\n            offset = 0\n            for fl in self.fragment_lengths[:-1]:\n                yield self.msg(content[offset : offset + fl], False)\n                offset += fl\n            yield self.msg(content[offset:], True)\n        else:\n            offset = 0\n            total = len(content) - self.FRAGMENT_SIZE\n            while offset < total:\n                yield self.msg(content[offset : offset + self.FRAGMENT_SIZE], False)\n                offset += self.FRAGMENT_SIZE\n            yield self.msg(content[offset:], True)\n", "mitmproxy/proxy/layers/http/_hooks.py": "from dataclasses import dataclass\n\nfrom mitmproxy import http\nfrom mitmproxy.proxy import commands\n\n\n@dataclass\nclass HttpRequestHeadersHook(commands.StartHook):\n    \"\"\"\n    HTTP request headers were successfully read. At this point, the body is empty.\n    \"\"\"\n\n    name = \"requestheaders\"\n    flow: http.HTTPFlow\n\n\n@dataclass\nclass HttpRequestHook(commands.StartHook):\n    \"\"\"\n    The full HTTP request has been read.\n\n    Note: If request streaming is active, this event fires after the entire body has been streamed.\n    HTTP trailers, if present, have not been transmitted to the server yet and can still be modified.\n    Enabling streaming may cause unexpected event sequences: For example, `response` may now occur\n    before `request` because the server replied with \"413 Payload Too Large\" during upload.\n    \"\"\"\n\n    name = \"request\"\n    flow: http.HTTPFlow\n\n\n@dataclass\nclass HttpResponseHeadersHook(commands.StartHook):\n    \"\"\"\n    HTTP response headers were successfully read. At this point, the body is empty.\n    \"\"\"\n\n    name = \"responseheaders\"\n    flow: http.HTTPFlow\n\n\n@dataclass\nclass HttpResponseHook(commands.StartHook):\n    \"\"\"\n    The full HTTP response has been read.\n\n    Note: If response streaming is active, this event fires after the entire body has been streamed.\n    HTTP trailers, if present, have not been transmitted to the client yet and can still be modified.\n    \"\"\"\n\n    name = \"response\"\n    flow: http.HTTPFlow\n\n\n@dataclass\nclass HttpErrorHook(commands.StartHook):\n    \"\"\"\n    An HTTP error has occurred, e.g. invalid server responses, or\n    interrupted connections. This is distinct from a valid server HTTP\n    error response, which is simply a response with an HTTP error code.\n\n    Every flow will receive either an error or an response event, but not both.\n    \"\"\"\n\n    name = \"error\"\n    flow: http.HTTPFlow\n\n\n@dataclass\nclass HttpConnectHook(commands.StartHook):\n    \"\"\"\n    An HTTP CONNECT request was received. This event can be ignored for most practical purposes.\n\n    This event only occurs in regular and upstream proxy modes\n    when the client instructs mitmproxy to open a connection to an upstream host.\n    Setting a non 2xx response on the flow will return the response to the client and abort the connection.\n\n    CONNECT requests are HTTP proxy instructions for mitmproxy itself\n    and not forwarded. They do not generate the usual HTTP handler events,\n    but all requests going over the newly opened connection will.\n    \"\"\"\n\n    flow: http.HTTPFlow\n\n\n@dataclass\nclass HttpConnectUpstreamHook(commands.StartHook):\n    \"\"\"\n    An HTTP CONNECT request is about to be sent to an upstream proxy.\n    This event can be ignored for most practical purposes.\n\n    This event can be used to set custom authentication headers for upstream proxies.\n\n    CONNECT requests do not generate the usual HTTP handler events,\n    but all requests going over the newly opened connection will.\n    \"\"\"\n\n    flow: http.HTTPFlow\n\n\n@dataclass\nclass HttpConnectedHook(commands.StartHook):\n    \"\"\"\n    HTTP CONNECT was successful\n\n    .. warning::\n    This may fire before an upstream connection has been established\n    if `connection_strategy` is set to `lazy` (default)\n    \"\"\"\n\n    flow: http.HTTPFlow\n\n\n@dataclass\nclass HttpConnectErrorHook(commands.StartHook):\n    \"\"\"\n    HTTP CONNECT has failed.\n    This can happen when the upstream server is unreachable or proxy authentication is required.\n    In contrast to the `error` hook, `flow.error` is not guaranteed to be set.\n    \"\"\"\n\n    flow: http.HTTPFlow\n", "mitmproxy/proxy/layers/http/_http_h2.py": "import collections\nimport logging\nfrom typing import NamedTuple\n\nimport h2.config\nimport h2.connection\nimport h2.events\nimport h2.exceptions\nimport h2.settings\nimport h2.stream\n\nlogger = logging.getLogger(__name__)\n\n\nclass H2ConnectionLogger(h2.config.DummyLogger):\n    def __init__(self, peername: tuple, conn_type: str):\n        super().__init__()\n        self.peername = peername\n        self.conn_type = conn_type\n\n    def debug(self, fmtstr, *args):\n        logger.debug(\n            f\"{self.conn_type} {fmtstr}\", *args, extra={\"client\": self.peername}\n        )\n\n    def trace(self, fmtstr, *args):\n        logger.log(\n            logging.DEBUG - 1,\n            f\"{self.conn_type} {fmtstr}\",\n            *args,\n            extra={\"client\": self.peername},\n        )\n\n\nclass SendH2Data(NamedTuple):\n    data: bytes\n    end_stream: bool\n\n\nclass BufferedH2Connection(h2.connection.H2Connection):\n    \"\"\"\n    This class wrap's hyper-h2's H2Connection and adds internal send buffers.\n\n    To simplify implementation, padding is unsupported.\n    \"\"\"\n\n    stream_buffers: collections.defaultdict[int, collections.deque[SendH2Data]]\n    stream_trailers: dict[int, list[tuple[bytes, bytes]]]\n\n    def __init__(self, config: h2.config.H2Configuration):\n        super().__init__(config)\n        self.stream_buffers = collections.defaultdict(collections.deque)\n        self.stream_trailers = {}\n\n    def send_data(\n        self,\n        stream_id: int,\n        data: bytes,\n        end_stream: bool = False,\n        pad_length: None = None,\n    ) -> None:\n        \"\"\"\n        Send data on a given stream.\n\n        In contrast to plain hyper-h2, this method will not raise if the data cannot be sent immediately.\n        Data is split up and buffered internally.\n        \"\"\"\n        frame_size = len(data)\n        assert pad_length is None\n\n        if frame_size > self.max_outbound_frame_size:\n            for start in range(0, frame_size, self.max_outbound_frame_size):\n                chunk = data[start : start + self.max_outbound_frame_size]\n                self.send_data(stream_id, chunk, end_stream=False)\n\n            return\n\n        if self.stream_buffers.get(stream_id, None):\n            # We already have some data buffered, let's append.\n            self.stream_buffers[stream_id].append(SendH2Data(data, end_stream))\n        else:\n            available_window = self.local_flow_control_window(stream_id)\n            if frame_size <= available_window:\n                super().send_data(stream_id, data, end_stream)\n            else:\n                if available_window:\n                    can_send_now = data[:available_window]\n                    super().send_data(stream_id, can_send_now, end_stream=False)\n                    data = data[available_window:]\n                # We can't send right now, so we buffer.\n                self.stream_buffers[stream_id].append(SendH2Data(data, end_stream))\n\n    def send_trailers(self, stream_id: int, trailers: list[tuple[bytes, bytes]]):\n        if self.stream_buffers.get(stream_id, None):\n            # Though trailers are not subject to flow control, we need to queue them and send strictly after data frames\n            self.stream_trailers[stream_id] = trailers\n        else:\n            self.send_headers(stream_id, trailers, end_stream=True)\n\n    def end_stream(self, stream_id: int) -> None:\n        if stream_id in self.stream_trailers:\n            return  # we already have trailers queued up that will end the stream.\n        self.send_data(stream_id, b\"\", end_stream=True)\n\n    def reset_stream(self, stream_id: int, error_code: int = 0) -> None:\n        self.stream_buffers.pop(stream_id, None)\n        super().reset_stream(stream_id, error_code)\n\n    def receive_data(self, data: bytes):\n        events = super().receive_data(data)\n        ret = []\n        for event in events:\n            if isinstance(event, h2.events.WindowUpdated):\n                if event.stream_id == 0:\n                    self.connection_window_updated()\n                else:\n                    self.stream_window_updated(event.stream_id)\n                continue\n            elif isinstance(event, h2.events.RemoteSettingsChanged):\n                if (\n                    h2.settings.SettingCodes.INITIAL_WINDOW_SIZE\n                    in event.changed_settings\n                ):\n                    self.connection_window_updated()\n            elif isinstance(event, h2.events.StreamReset):\n                self.stream_buffers.pop(event.stream_id, None)\n            elif isinstance(event, h2.events.ConnectionTerminated):\n                self.stream_buffers.clear()\n            ret.append(event)\n        return ret\n\n    def stream_window_updated(self, stream_id: int) -> bool:\n        \"\"\"\n        The window for a specific stream has updated. Send as much buffered data as possible.\n        \"\"\"\n        # If the stream has been reset in the meantime, we just clear the buffer.\n        try:\n            stream: h2.stream.H2Stream = self.streams[stream_id]\n        except KeyError:\n            stream_was_reset = True\n        else:\n            stream_was_reset = stream.state_machine.state not in (\n                h2.stream.StreamState.OPEN,\n                h2.stream.StreamState.HALF_CLOSED_REMOTE,\n            )\n        if stream_was_reset:\n            self.stream_buffers.pop(stream_id, None)\n            return False\n\n        available_window = self.local_flow_control_window(stream_id)\n        sent_any_data = False\n        while available_window > 0 and stream_id in self.stream_buffers:\n            chunk: SendH2Data = self.stream_buffers[stream_id].popleft()\n            if len(chunk.data) > available_window:\n                # We can't send the entire chunk, so we have to put some bytes back into the buffer.\n                self.stream_buffers[stream_id].appendleft(\n                    SendH2Data(\n                        data=chunk.data[available_window:],\n                        end_stream=chunk.end_stream,\n                    )\n                )\n                chunk = SendH2Data(\n                    data=chunk.data[:available_window],\n                    end_stream=False,\n                )\n\n            super().send_data(stream_id, data=chunk.data, end_stream=chunk.end_stream)\n\n            available_window -= len(chunk.data)\n            if not self.stream_buffers[stream_id]:\n                del self.stream_buffers[stream_id]\n                if stream_id in self.stream_trailers:\n                    self.send_headers(\n                        stream_id, self.stream_trailers.pop(stream_id), end_stream=True\n                    )\n            sent_any_data = True\n\n        return sent_any_data\n\n    def connection_window_updated(self) -> None:\n        \"\"\"\n        The connection window has updated. Send data from buffers in a round-robin fashion.\n        \"\"\"\n        sent_any_data = True\n        while sent_any_data:\n            sent_any_data = False\n            for stream_id in list(self.stream_buffers):\n                self.stream_buffers[stream_id] = self.stream_buffers.pop(\n                    stream_id\n                )  # move to end of dict\n                if self.stream_window_updated(stream_id):\n                    sent_any_data = True\n                    if self.outbound_flow_control_window == 0:\n                        return\n", "mitmproxy/proxy/layers/http/_http1.py": "import abc\nfrom collections.abc import Callable\nfrom typing import Union\n\nimport h11\nfrom h11._readers import ChunkedReader\nfrom h11._readers import ContentLengthReader\nfrom h11._readers import Http10Reader\nfrom h11._receivebuffer import ReceiveBuffer\n\nfrom ...context import Context\nfrom ._base import format_error\nfrom ._base import HttpConnection\nfrom ._events import HttpEvent\nfrom ._events import RequestData\nfrom ._events import RequestEndOfMessage\nfrom ._events import RequestHeaders\nfrom ._events import RequestProtocolError\nfrom ._events import ResponseData\nfrom ._events import ResponseEndOfMessage\nfrom ._events import ResponseHeaders\nfrom ._events import ResponseProtocolError\nfrom mitmproxy import http\nfrom mitmproxy import version\nfrom mitmproxy.connection import Connection\nfrom mitmproxy.connection import ConnectionState\nfrom mitmproxy.net.http import http1\nfrom mitmproxy.net.http import status_codes\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.layers.http._base import ReceiveHttp\nfrom mitmproxy.proxy.layers.http._base import StreamId\nfrom mitmproxy.proxy.utils import expect\nfrom mitmproxy.utils import human\n\nTBodyReader = Union[ChunkedReader, Http10Reader, ContentLengthReader]\n\n\nclass Http1Connection(HttpConnection, metaclass=abc.ABCMeta):\n    stream_id: StreamId | None = None\n    request: http.Request | None = None\n    response: http.Response | None = None\n    request_done: bool = False\n    response_done: bool = False\n    # this is a bit of a hack to make both mypy and PyCharm happy.\n    state: Callable[[events.Event], layer.CommandGenerator[None]] | Callable\n    body_reader: TBodyReader\n    buf: ReceiveBuffer\n\n    ReceiveProtocolError: type[RequestProtocolError | ResponseProtocolError]\n    ReceiveData: type[RequestData | ResponseData]\n    ReceiveEndOfMessage: type[RequestEndOfMessage | ResponseEndOfMessage]\n\n    def __init__(self, context: Context, conn: Connection):\n        super().__init__(context, conn)\n        self.buf = ReceiveBuffer()\n\n    @abc.abstractmethod\n    def send(self, event: HttpEvent) -> layer.CommandGenerator[None]:\n        yield from ()  # pragma: no cover\n\n    @abc.abstractmethod\n    def read_headers(\n        self, event: events.ConnectionEvent\n    ) -> layer.CommandGenerator[None]:\n        yield from ()  # pragma: no cover\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, HttpEvent):\n            yield from self.send(event)\n        else:\n            if (\n                isinstance(event, events.DataReceived)\n                and self.state != self.passthrough\n            ):\n                self.buf += event.data\n            yield from self.state(event)\n\n    @expect(events.Start)\n    def start(self, _) -> layer.CommandGenerator[None]:\n        self.state = self.read_headers\n        yield from ()\n\n    state = start\n\n    def read_body(self, event: events.Event) -> layer.CommandGenerator[None]:\n        assert self.stream_id is not None\n        while True:\n            try:\n                if isinstance(event, events.DataReceived):\n                    h11_event = self.body_reader(self.buf)\n                elif isinstance(event, events.ConnectionClosed):\n                    h11_event = self.body_reader.read_eof()\n                else:\n                    raise AssertionError(f\"Unexpected event: {event}\")\n            except h11.ProtocolError as e:\n                yield commands.CloseConnection(self.conn)\n                yield ReceiveHttp(\n                    self.ReceiveProtocolError(\n                        self.stream_id, f\"HTTP/1 protocol error: {e}\"\n                    )\n                )\n                return\n\n            if h11_event is None:\n                return\n            elif isinstance(h11_event, h11.Data):\n                data: bytes = bytes(h11_event.data)\n                if data:\n                    yield ReceiveHttp(self.ReceiveData(self.stream_id, data))\n            elif isinstance(h11_event, h11.EndOfMessage):\n                assert self.request\n                if h11_event.headers:\n                    raise NotImplementedError(f\"HTTP trailers are not implemented yet.\")\n                if self.request.data.method.upper() != b\"CONNECT\":\n                    yield ReceiveHttp(self.ReceiveEndOfMessage(self.stream_id))\n                is_request = isinstance(self, Http1Server)\n                yield from self.mark_done(request=is_request, response=not is_request)\n                return\n\n    def wait(self, event: events.Event) -> layer.CommandGenerator[None]:\n        \"\"\"\n        We wait for the current flow to be finished before parsing the next message,\n        as we may want to upgrade to WebSocket or plain TCP before that.\n        \"\"\"\n        assert self.stream_id\n        if isinstance(event, events.DataReceived):\n            return\n        elif isinstance(event, events.ConnectionClosed):\n            # for practical purposes, we assume that a peer which sent at least a FIN\n            # is not interested in any more data from us, see\n            # see https://github.com/httpwg/http-core/issues/22\n            if event.connection.state is not ConnectionState.CLOSED:\n                yield commands.CloseConnection(event.connection)\n            yield ReceiveHttp(\n                self.ReceiveProtocolError(\n                    self.stream_id,\n                    f\"Client disconnected.\",\n                    code=status_codes.CLIENT_CLOSED_REQUEST,\n                )\n            )\n        else:  # pragma: no cover\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n    def done(self, event: events.ConnectionEvent) -> layer.CommandGenerator[None]:\n        yield from ()  # pragma: no cover\n\n    def make_pipe(self) -> layer.CommandGenerator[None]:\n        self.state = self.passthrough\n        if self.buf:\n            already_received = self.buf.maybe_extract_at_most(len(self.buf)) or b\"\"\n            # Some clients send superfluous newlines after CONNECT, we want to eat those.\n            already_received = already_received.lstrip(b\"\\r\\n\")\n            if already_received:\n                yield from self.state(events.DataReceived(self.conn, already_received))\n\n    def passthrough(self, event: events.Event) -> layer.CommandGenerator[None]:\n        assert self.stream_id\n        if isinstance(event, events.DataReceived):\n            yield ReceiveHttp(self.ReceiveData(self.stream_id, event.data))\n        elif isinstance(event, events.ConnectionClosed):\n            if isinstance(self, Http1Server):\n                yield ReceiveHttp(RequestEndOfMessage(self.stream_id))\n            else:\n                yield ReceiveHttp(ResponseEndOfMessage(self.stream_id))\n\n    def mark_done(\n        self, *, request: bool = False, response: bool = False\n    ) -> layer.CommandGenerator[None]:\n        if request:\n            self.request_done = True\n        if response:\n            self.response_done = True\n        if self.request_done and self.response_done:\n            assert self.request\n            assert self.response\n            if should_make_pipe(self.request, self.response):\n                yield from self.make_pipe()\n                return\n            try:\n                read_until_eof_semantics = (\n                    http1.expected_http_body_size(self.request, self.response) == -1\n                )\n            except ValueError:\n                # this may raise only now (and not earlier) because an addon set invalid headers,\n                # in which case it's not really clear what we are supposed to do.\n                read_until_eof_semantics = False\n            connection_done = (\n                read_until_eof_semantics\n                or http1.connection_close(\n                    self.request.http_version, self.request.headers\n                )\n                or http1.connection_close(\n                    self.response.http_version, self.response.headers\n                )\n                # If we proxy HTTP/2 to HTTP/1, we only use upstream connections for one request.\n                # This simplifies our connection management quite a bit as we can rely on\n                # the proxyserver's max-connection-per-server throttling.\n                or (\n                    (self.request.is_http2 or self.request.is_http3)\n                    and isinstance(self, Http1Client)\n                )\n            )\n            if connection_done:\n                yield commands.CloseConnection(self.conn)\n                self.state = self.done\n                return\n            self.request_done = self.response_done = False\n            self.request = self.response = None\n            if isinstance(self, Http1Server):\n                self.stream_id += 2\n            else:\n                self.stream_id = None\n            self.state = self.read_headers\n            if self.buf:\n                yield from self.state(events.DataReceived(self.conn, b\"\"))\n\n\nclass Http1Server(Http1Connection):\n    \"\"\"A simple HTTP/1 server with no pipelining support.\"\"\"\n\n    ReceiveProtocolError = RequestProtocolError\n    ReceiveData = RequestData\n    ReceiveEndOfMessage = RequestEndOfMessage\n    stream_id: int\n\n    def __init__(self, context: Context):\n        super().__init__(context, context.client)\n        self.stream_id = 1\n\n    def send(self, event: HttpEvent) -> layer.CommandGenerator[None]:\n        assert event.stream_id == self.stream_id\n        if isinstance(event, ResponseHeaders):\n            self.response = response = event.response\n\n            if response.is_http2 or response.is_http3:\n                response = response.copy()\n                # Convert to an HTTP/1 response.\n                response.http_version = \"HTTP/1.1\"\n                # not everyone supports empty reason phrases, so we better make up one.\n                response.reason = status_codes.RESPONSES.get(response.status_code, \"\")\n                # Shall we set a Content-Length header here if there is none?\n                # For now, let's try to modify as little as possible.\n\n            raw = http1.assemble_response_head(response)\n            yield commands.SendData(self.conn, raw)\n        elif isinstance(event, ResponseData):\n            assert self.response\n            if \"chunked\" in self.response.headers.get(\"transfer-encoding\", \"\").lower():\n                raw = b\"%x\\r\\n%s\\r\\n\" % (len(event.data), event.data)\n            else:\n                raw = event.data\n            if raw:\n                yield commands.SendData(self.conn, raw)\n        elif isinstance(event, ResponseEndOfMessage):\n            assert self.request\n            assert self.response\n            if (\n                self.request.method.upper() != \"HEAD\"\n                and \"chunked\"\n                in self.response.headers.get(\"transfer-encoding\", \"\").lower()\n            ):\n                yield commands.SendData(self.conn, b\"0\\r\\n\\r\\n\")\n            yield from self.mark_done(response=True)\n        elif isinstance(event, ResponseProtocolError):\n            if not self.response and event.code != status_codes.NO_RESPONSE:\n                yield commands.SendData(\n                    self.conn, make_error_response(event.code, event.message)\n                )\n            if self.conn.state & ConnectionState.CAN_WRITE:\n                yield commands.CloseConnection(self.conn)\n        else:\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n    def read_headers(\n        self, event: events.ConnectionEvent\n    ) -> layer.CommandGenerator[None]:\n        if isinstance(event, events.DataReceived):\n            request_head = self.buf.maybe_extract_lines()\n            if request_head:\n                try:\n                    self.request = http1.read_request_head(\n                        [bytes(x) for x in request_head]\n                    )\n                    if self.context.options.validate_inbound_headers:\n                        http1.validate_headers(self.request.headers)\n                    expected_body_size = http1.expected_http_body_size(self.request)\n                except ValueError as e:\n                    yield commands.SendData(self.conn, make_error_response(400, str(e)))\n                    yield commands.CloseConnection(self.conn)\n                    if self.request:\n                        # we have headers that we can show in the ui\n                        yield ReceiveHttp(\n                            RequestHeaders(self.stream_id, self.request, False)\n                        )\n                        yield ReceiveHttp(\n                            RequestProtocolError(self.stream_id, str(e), 400)\n                        )\n                    else:\n                        yield commands.Log(\n                            f\"{human.format_address(self.conn.peername)}: {e}\"\n                        )\n                    self.state = self.done\n                    return\n                yield ReceiveHttp(\n                    RequestHeaders(\n                        self.stream_id, self.request, expected_body_size == 0\n                    )\n                )\n                self.body_reader = make_body_reader(expected_body_size)\n                self.state = self.read_body\n                yield from self.state(event)\n            else:\n                pass  # FIXME: protect against header size DoS\n        elif isinstance(event, events.ConnectionClosed):\n            buf = bytes(self.buf)\n            if buf.strip():\n                yield commands.Log(\n                    f\"Client closed connection before completing request headers: {buf!r}\"\n                )\n            yield commands.CloseConnection(self.conn)\n        else:\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n    def mark_done(\n        self, *, request: bool = False, response: bool = False\n    ) -> layer.CommandGenerator[None]:\n        yield from super().mark_done(request=request, response=response)\n        if self.request_done and not self.response_done:\n            self.state = self.wait\n\n\nclass Http1Client(Http1Connection):\n    \"\"\"A simple HTTP/1 client with no pipelining support.\"\"\"\n\n    ReceiveProtocolError = ResponseProtocolError\n    ReceiveData = ResponseData\n    ReceiveEndOfMessage = ResponseEndOfMessage\n\n    def __init__(self, context: Context):\n        super().__init__(context, context.server)\n\n    def send(self, event: HttpEvent) -> layer.CommandGenerator[None]:\n        if isinstance(event, RequestProtocolError):\n            yield commands.CloseConnection(self.conn)\n            return\n\n        if self.stream_id is None:\n            assert isinstance(event, RequestHeaders)\n            self.stream_id = event.stream_id\n            self.request = event.request\n        assert self.stream_id == event.stream_id\n\n        if isinstance(event, RequestHeaders):\n            request = event.request\n            if request.is_http2 or request.is_http3:\n                # Convert to an HTTP/1 request.\n                request = (\n                    request.copy()\n                )  # (we could probably be a bit more efficient here.)\n                request.http_version = \"HTTP/1.1\"\n                if \"Host\" not in request.headers and request.authority:\n                    request.headers.insert(0, \"Host\", request.authority)\n                request.authority = \"\"\n                cookie_headers = request.headers.get_all(\"Cookie\")\n                if len(cookie_headers) > 1:\n                    # Only HTTP/2 supports multiple cookie headers, HTTP/1.x does not.\n                    # see: https://www.rfc-editor.org/rfc/rfc6265#section-5.4\n                    #      https://www.rfc-editor.org/rfc/rfc7540#section-8.1.2.5\n                    request.headers[\"Cookie\"] = \"; \".join(cookie_headers)\n            raw = http1.assemble_request_head(request)\n            yield commands.SendData(self.conn, raw)\n        elif isinstance(event, RequestData):\n            assert self.request\n            if \"chunked\" in self.request.headers.get(\"transfer-encoding\", \"\").lower():\n                raw = b\"%x\\r\\n%s\\r\\n\" % (len(event.data), event.data)\n            else:\n                raw = event.data\n            if raw:\n                yield commands.SendData(self.conn, raw)\n        elif isinstance(event, RequestEndOfMessage):\n            assert self.request\n            if \"chunked\" in self.request.headers.get(\"transfer-encoding\", \"\").lower():\n                yield commands.SendData(self.conn, b\"0\\r\\n\\r\\n\")\n            elif http1.expected_http_body_size(self.request, self.response) == -1:\n                yield commands.CloseTcpConnection(self.conn, half_close=True)\n            yield from self.mark_done(request=True)\n        else:\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n    def read_headers(\n        self, event: events.ConnectionEvent\n    ) -> layer.CommandGenerator[None]:\n        if isinstance(event, events.DataReceived):\n            if not self.request:\n                # we just received some data for an unknown request.\n                yield commands.Log(f\"Unexpected data from server: {bytes(self.buf)!r}\")\n                yield commands.CloseConnection(self.conn)\n                return\n            assert self.stream_id is not None\n\n            response_head = self.buf.maybe_extract_lines()\n            if response_head:\n                try:\n                    self.response = http1.read_response_head(\n                        [bytes(x) for x in response_head]\n                    )\n                    if self.context.options.validate_inbound_headers:\n                        http1.validate_headers(self.response.headers)\n                    expected_size = http1.expected_http_body_size(\n                        self.request, self.response\n                    )\n                except ValueError as e:\n                    yield commands.CloseConnection(self.conn)\n                    yield ReceiveHttp(\n                        ResponseProtocolError(\n                            self.stream_id, f\"Cannot parse HTTP response: {e}\"\n                        )\n                    )\n                    return\n                yield ReceiveHttp(\n                    ResponseHeaders(self.stream_id, self.response, expected_size == 0)\n                )\n                self.body_reader = make_body_reader(expected_size)\n\n                self.state = self.read_body\n                yield from self.state(event)\n            else:\n                pass  # FIXME: protect against header size DoS\n        elif isinstance(event, events.ConnectionClosed):\n            if self.conn.state & ConnectionState.CAN_WRITE:\n                yield commands.CloseConnection(self.conn)\n            if self.stream_id:\n                if self.buf:\n                    yield ReceiveHttp(\n                        ResponseProtocolError(\n                            self.stream_id,\n                            f\"unexpected server response: {bytes(self.buf)!r}\",\n                        )\n                    )\n                else:\n                    # The server has closed the connection to prevent us from continuing.\n                    # We need to signal that to the stream.\n                    # https://tools.ietf.org/html/rfc7231#section-6.5.11\n                    yield ReceiveHttp(\n                        ResponseProtocolError(\n                            self.stream_id, \"server closed connection\"\n                        )\n                    )\n            else:\n                return\n        else:\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n\ndef should_make_pipe(request: http.Request, response: http.Response) -> bool:\n    if response.status_code == 101:\n        return True\n    elif response.status_code == 200 and request.method.upper() == \"CONNECT\":\n        return True\n    else:\n        return False\n\n\ndef make_body_reader(expected_size: int | None) -> TBodyReader:\n    if expected_size is None:\n        return ChunkedReader()\n    elif expected_size == -1:\n        return Http10Reader()\n    else:\n        return ContentLengthReader(expected_size)\n\n\ndef make_error_response(\n    status_code: int,\n    message: str = \"\",\n) -> bytes:\n    resp = http.Response.make(\n        status_code,\n        format_error(status_code, message),\n        http.Headers(\n            Server=version.MITMPROXY,\n            Connection=\"close\",\n            Content_Type=\"text/html\",\n        ),\n    )\n    return http1.assemble_response(resp)\n\n\n__all__ = [\n    \"Http1Client\",\n    \"Http1Server\",\n]\n", "mitmproxy/proxy/layers/http/_base.py": "import html\nimport textwrap\nfrom dataclasses import dataclass\n\nfrom mitmproxy import http\nfrom mitmproxy.connection import Connection\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.context import Context\n\nStreamId = int\n\n\n@dataclass\nclass HttpEvent(events.Event):\n    # we need stream ids on every event to avoid race conditions\n    stream_id: StreamId\n\n\nclass HttpConnection(layer.Layer):\n    conn: Connection\n\n    def __init__(self, context: Context, conn: Connection):\n        super().__init__(context)\n        self.conn = conn\n\n\nclass HttpCommand(commands.Command):\n    pass\n\n\nclass ReceiveHttp(HttpCommand):\n    event: HttpEvent\n\n    def __init__(self, event: HttpEvent):\n        self.event = event\n\n    def __repr__(self) -> str:\n        return f\"Receive({self.event})\"\n\n\ndef format_error(status_code: int, message: str) -> bytes:\n    reason = http.status_codes.RESPONSES.get(status_code, \"Unknown\")\n    return (\n        textwrap.dedent(\n            f\"\"\"\n    <html>\n    <head>\n        <title>{status_code} {reason}</title>\n    </head>\n    <body>\n        <h1>{status_code} {reason}</h1>\n        <p>{html.escape(message)}</p>\n    </body>\n    </html>\n    \"\"\"\n        )\n        .strip()\n        .encode(\"utf8\", \"replace\")\n    )\n", "mitmproxy/proxy/layers/http/_http2.py": "import collections\nimport time\nfrom collections.abc import Sequence\nfrom enum import Enum\nfrom logging import DEBUG\nfrom logging import ERROR\nfrom typing import ClassVar\n\nimport h2.config\nimport h2.connection\nimport h2.errors\nimport h2.events\nimport h2.exceptions\nimport h2.settings\nimport h2.stream\nimport h2.utilities\n\nfrom ...commands import CloseConnection\nfrom ...commands import Log\nfrom ...commands import RequestWakeup\nfrom ...commands import SendData\nfrom ...context import Context\nfrom ...events import ConnectionClosed\nfrom ...events import DataReceived\nfrom ...events import Event\nfrom ...events import Start\nfrom ...events import Wakeup\nfrom ...layer import CommandGenerator\nfrom ...utils import expect\nfrom . import RequestData\nfrom . import RequestEndOfMessage\nfrom . import RequestHeaders\nfrom . import RequestProtocolError\nfrom . import RequestTrailers\nfrom . import ResponseData\nfrom . import ResponseEndOfMessage\nfrom . import ResponseHeaders\nfrom . import ResponseProtocolError\nfrom . import ResponseTrailers\nfrom ._base import format_error\nfrom ._base import HttpConnection\nfrom ._base import HttpEvent\nfrom ._base import ReceiveHttp\nfrom ._http_h2 import BufferedH2Connection\nfrom ._http_h2 import H2ConnectionLogger\nfrom mitmproxy import http\nfrom mitmproxy import version\nfrom mitmproxy.connection import Connection\nfrom mitmproxy.net.http import status_codes\nfrom mitmproxy.net.http import url\nfrom mitmproxy.utils import human\n\n\nclass StreamState(Enum):\n    EXPECTING_HEADERS = 1\n    HEADERS_RECEIVED = 2\n\n\nCATCH_HYPER_H2_ERRORS = (ValueError, IndexError)\n\n\nclass Http2Connection(HttpConnection):\n    h2_conf: ClassVar[h2.config.H2Configuration]\n    h2_conf_defaults = dict(\n        header_encoding=False,\n        validate_outbound_headers=False,\n        # validate_inbound_headers is controlled by the validate_inbound_headers option.\n        normalize_inbound_headers=False,  # changing this to True is required to pass h2spec\n        normalize_outbound_headers=False,\n    )\n    h2_conn: BufferedH2Connection\n    streams: dict[int, StreamState]\n    \"\"\"keep track of all active stream ids to send protocol errors on teardown\"\"\"\n\n    ReceiveProtocolError: type[RequestProtocolError | ResponseProtocolError]\n    ReceiveData: type[RequestData | ResponseData]\n    ReceiveTrailers: type[RequestTrailers | ResponseTrailers]\n    ReceiveEndOfMessage: type[RequestEndOfMessage | ResponseEndOfMessage]\n\n    def __init__(self, context: Context, conn: Connection):\n        super().__init__(context, conn)\n        if self.debug:\n            self.h2_conf.logger = H2ConnectionLogger(\n                self.context.client.peername, self.__class__.__name__\n            )\n        self.h2_conf.validate_inbound_headers = (\n            self.context.options.validate_inbound_headers\n        )\n        self.h2_conn = BufferedH2Connection(self.h2_conf)\n        self.streams = {}\n\n    def is_closed(self, stream_id: int) -> bool:\n        \"\"\"Check if a non-idle stream is closed\"\"\"\n        stream = self.h2_conn.streams.get(stream_id, None)\n        if (\n            stream is not None\n            and stream.state_machine.state is not h2.stream.StreamState.CLOSED\n            and self.h2_conn.state_machine.state\n            is not h2.connection.ConnectionState.CLOSED\n        ):\n            return False\n        else:\n            return True\n\n    def is_open_for_us(self, stream_id: int) -> bool:\n        \"\"\"Check if we can write to a non-idle stream.\"\"\"\n        stream = self.h2_conn.streams.get(stream_id, None)\n        if (\n            stream is not None\n            and stream.state_machine.state\n            is not h2.stream.StreamState.HALF_CLOSED_LOCAL\n            and stream.state_machine.state is not h2.stream.StreamState.CLOSED\n            and self.h2_conn.state_machine.state\n            is not h2.connection.ConnectionState.CLOSED\n        ):\n            return True\n        else:\n            return False\n\n    def _handle_event(self, event: Event) -> CommandGenerator[None]:\n        if isinstance(event, Start):\n            self.h2_conn.initiate_connection()\n            yield SendData(self.conn, self.h2_conn.data_to_send())\n\n        elif isinstance(event, HttpEvent):\n            if isinstance(event, (RequestData, ResponseData)):\n                if self.is_open_for_us(event.stream_id):\n                    self.h2_conn.send_data(event.stream_id, event.data)\n            elif isinstance(event, (RequestTrailers, ResponseTrailers)):\n                if self.is_open_for_us(event.stream_id):\n                    trailers = [*event.trailers.fields]\n                    self.h2_conn.send_trailers(event.stream_id, trailers)\n            elif isinstance(event, (RequestEndOfMessage, ResponseEndOfMessage)):\n                if self.is_open_for_us(event.stream_id):\n                    self.h2_conn.end_stream(event.stream_id)\n            elif isinstance(event, (RequestProtocolError, ResponseProtocolError)):\n                if not self.is_closed(event.stream_id):\n                    code = {\n                        status_codes.CLIENT_CLOSED_REQUEST: h2.errors.ErrorCodes.CANCEL,\n                    }.get(event.code, h2.errors.ErrorCodes.INTERNAL_ERROR)\n                    stream: h2.stream.H2Stream = self.h2_conn.streams[event.stream_id]\n                    send_error_message = (\n                        isinstance(event, ResponseProtocolError)\n                        and self.is_open_for_us(event.stream_id)\n                        and not stream.state_machine.headers_sent\n                        and event.code != status_codes.NO_RESPONSE\n                    )\n                    if send_error_message:\n                        self.h2_conn.send_headers(\n                            event.stream_id,\n                            [\n                                (b\":status\", b\"%d\" % event.code),\n                                (b\"server\", version.MITMPROXY.encode()),\n                                (b\"content-type\", b\"text/html\"),\n                            ],\n                        )\n                        self.h2_conn.send_data(\n                            event.stream_id,\n                            format_error(event.code, event.message),\n                            end_stream=True,\n                        )\n                    else:\n                        self.h2_conn.reset_stream(event.stream_id, code)\n            else:\n                raise AssertionError(f\"Unexpected event: {event}\")\n            data_to_send = self.h2_conn.data_to_send()\n            if data_to_send:\n                yield SendData(self.conn, data_to_send)\n\n        elif isinstance(event, DataReceived):\n            try:\n                try:\n                    events = self.h2_conn.receive_data(event.data)\n                except CATCH_HYPER_H2_ERRORS as e:  # pragma: no cover\n                    # this should never raise a ValueError, but we triggered one while fuzzing:\n                    # https://github.com/python-hyper/hyper-h2/issues/1231\n                    # this stays here as defense-in-depth.\n                    raise h2.exceptions.ProtocolError(\n                        f\"uncaught hyper-h2 error: {e}\"\n                    ) from e\n            except h2.exceptions.ProtocolError as e:\n                events = [e]\n\n            for h2_event in events:\n                if self.debug:\n                    yield Log(f\"{self.debug}[h2] {h2_event}\", DEBUG)\n                if (yield from self.handle_h2_event(h2_event)):\n                    if self.debug:\n                        yield Log(f\"{self.debug}[h2] done\", DEBUG)\n                    return\n\n            data_to_send = self.h2_conn.data_to_send()\n            if data_to_send:\n                yield SendData(self.conn, data_to_send)\n\n        elif isinstance(event, ConnectionClosed):\n            yield from self.close_connection(\"peer closed connection\")\n        else:\n            raise AssertionError(f\"Unexpected event: {event!r}\")\n\n    def handle_h2_event(self, event: h2.events.Event) -> CommandGenerator[bool]:\n        \"\"\"returns true if further processing should be stopped.\"\"\"\n        if isinstance(event, h2.events.DataReceived):\n            state = self.streams.get(event.stream_id, None)\n            if state is StreamState.HEADERS_RECEIVED:\n                yield ReceiveHttp(self.ReceiveData(event.stream_id, event.data))\n            elif state is StreamState.EXPECTING_HEADERS:\n                yield from self.protocol_error(\n                    f\"Received HTTP/2 data frame, expected headers.\"\n                )\n                return True\n            self.h2_conn.acknowledge_received_data(\n                event.flow_controlled_length, event.stream_id\n            )\n        elif isinstance(event, h2.events.TrailersReceived):\n            trailers = http.Headers(event.headers)\n            yield ReceiveHttp(self.ReceiveTrailers(event.stream_id, trailers))\n        elif isinstance(event, h2.events.StreamEnded):\n            state = self.streams.get(event.stream_id, None)\n            if state is StreamState.HEADERS_RECEIVED:\n                yield ReceiveHttp(self.ReceiveEndOfMessage(event.stream_id))\n            elif state is StreamState.EXPECTING_HEADERS:\n                raise AssertionError(\"unreachable\")\n            if self.is_closed(event.stream_id):\n                self.streams.pop(event.stream_id, None)\n        elif isinstance(event, h2.events.StreamReset):\n            if event.stream_id in self.streams:\n                try:\n                    err_str = h2.errors.ErrorCodes(event.error_code).name\n                except ValueError:\n                    err_str = str(event.error_code)\n                err_code = {\n                    h2.errors.ErrorCodes.CANCEL: status_codes.CLIENT_CLOSED_REQUEST,\n                }.get(event.error_code, self.ReceiveProtocolError.code)\n                yield ReceiveHttp(\n                    self.ReceiveProtocolError(\n                        event.stream_id,\n                        f\"stream reset by client ({err_str})\",\n                        code=err_code,\n                    )\n                )\n                self.streams.pop(event.stream_id)\n            else:\n                pass  # We don't track priority frames which could be followed by a stream reset here.\n        elif isinstance(event, h2.exceptions.ProtocolError):\n            yield from self.protocol_error(f\"HTTP/2 protocol error: {event}\")\n            return True\n        elif isinstance(event, h2.events.ConnectionTerminated):\n            yield from self.close_connection(f\"HTTP/2 connection closed: {event!r}\")\n            return True\n            # The implementation above isn't really ideal, we should probably only terminate streams > last_stream_id?\n            # We currently lack a mechanism to signal that connections are still active but cannot be reused.\n            # for stream_id in self.streams:\n            #    if stream_id > event.last_stream_id:\n            #        yield ReceiveHttp(self.ReceiveProtocolError(stream_id, f\"HTTP/2 connection closed: {event!r}\"))\n            #        self.streams.pop(stream_id)\n        elif isinstance(event, h2.events.RemoteSettingsChanged):\n            pass\n        elif isinstance(event, h2.events.SettingsAcknowledged):\n            pass\n        elif isinstance(event, h2.events.PriorityUpdated):\n            pass\n        elif isinstance(event, h2.events.PingReceived):\n            pass\n        elif isinstance(event, h2.events.PingAckReceived):\n            pass\n        elif isinstance(event, h2.events.PushedStreamReceived):\n            yield Log(\n                \"Received HTTP/2 push promise, even though we signalled no support.\",\n                ERROR,\n            )\n        elif isinstance(event, h2.events.UnknownFrameReceived):\n            # https://http2.github.io/http2-spec/#rfc.section.4.1\n            # Implementations MUST ignore and discard any frame that has a type that is unknown.\n            yield Log(f\"Ignoring unknown HTTP/2 frame type: {event.frame.type}\")\n        elif isinstance(event, h2.events.AlternativeServiceAvailable):\n            yield Log(\n                \"Received HTTP/2 Alt-Svc frame, which will not be forwarded.\", DEBUG\n            )\n        else:\n            raise AssertionError(f\"Unexpected event: {event!r}\")\n        return False\n\n    def protocol_error(\n        self,\n        message: str,\n        error_code: int = h2.errors.ErrorCodes.PROTOCOL_ERROR,\n    ) -> CommandGenerator[None]:\n        yield Log(f\"{human.format_address(self.conn.peername)}: {message}\")\n        self.h2_conn.close_connection(error_code, message.encode())\n        yield SendData(self.conn, self.h2_conn.data_to_send())\n        yield from self.close_connection(message)\n\n    def close_connection(self, msg: str) -> CommandGenerator[None]:\n        yield CloseConnection(self.conn)\n        for stream_id in self.streams:\n            yield ReceiveHttp(self.ReceiveProtocolError(stream_id, msg))\n        self.streams.clear()\n        self._handle_event = self.done  # type: ignore\n\n    @expect(DataReceived, HttpEvent, ConnectionClosed, Wakeup)\n    def done(self, _) -> CommandGenerator[None]:\n        yield from ()\n\n\ndef normalize_h1_headers(\n    headers: list[tuple[bytes, bytes]], is_client: bool\n) -> list[tuple[bytes, bytes]]:\n    # HTTP/1 servers commonly send capitalized headers (Content-Length vs content-length),\n    # which isn't valid HTTP/2. As such we normalize.\n    headers = h2.utilities.normalize_outbound_headers(\n        headers,\n        h2.utilities.HeaderValidationFlags(is_client, False, not is_client, False),\n    )\n    # make sure that this is not just an iterator but an iterable,\n    # otherwise hyper-h2 will silently drop headers.\n    headers = list(headers)\n    return headers\n\n\ndef normalize_h2_headers(headers: list[tuple[bytes, bytes]]) -> CommandGenerator[None]:\n    for i in range(len(headers)):\n        if not headers[i][0].islower():\n            yield Log(\n                f\"Lowercased {repr(headers[i][0]).lstrip('b')} header as uppercase is not allowed with HTTP/2.\"\n            )\n            headers[i] = (headers[i][0].lower(), headers[i][1])\n\n\ndef format_h2_request_headers(\n    context: Context,\n    event: RequestHeaders,\n) -> CommandGenerator[list[tuple[bytes, bytes]]]:\n    pseudo_headers = [\n        (b\":method\", event.request.data.method),\n        (b\":scheme\", event.request.data.scheme),\n        (b\":path\", event.request.data.path),\n    ]\n    if event.request.authority:\n        pseudo_headers.append((b\":authority\", event.request.data.authority))\n\n    if event.request.is_http2 or event.request.is_http3:\n        hdrs = list(event.request.headers.fields)\n        if context.options.normalize_outbound_headers:\n            yield from normalize_h2_headers(hdrs)\n    else:\n        headers = event.request.headers\n        if not event.request.authority and \"host\" in headers:\n            headers = headers.copy()\n            pseudo_headers.append((b\":authority\", headers.pop(b\"host\")))\n        hdrs = normalize_h1_headers(list(headers.fields), True)\n\n    return pseudo_headers + hdrs\n\n\ndef format_h2_response_headers(\n    context: Context,\n    event: ResponseHeaders,\n) -> CommandGenerator[list[tuple[bytes, bytes]]]:\n    headers = [\n        (b\":status\", b\"%d\" % event.response.status_code),\n        *event.response.headers.fields,\n    ]\n    if event.response.is_http2 or event.response.is_http3:\n        if context.options.normalize_outbound_headers:\n            yield from normalize_h2_headers(headers)\n    else:\n        headers = normalize_h1_headers(headers, False)\n    return headers\n\n\nclass Http2Server(Http2Connection):\n    h2_conf = h2.config.H2Configuration(\n        **Http2Connection.h2_conf_defaults,\n        client_side=False,\n    )\n\n    ReceiveProtocolError = RequestProtocolError\n    ReceiveData = RequestData\n    ReceiveTrailers = RequestTrailers\n    ReceiveEndOfMessage = RequestEndOfMessage\n\n    def __init__(self, context: Context):\n        super().__init__(context, context.client)\n\n    def _handle_event(self, event: Event) -> CommandGenerator[None]:\n        if isinstance(event, ResponseHeaders):\n            if self.is_open_for_us(event.stream_id):\n                self.h2_conn.send_headers(\n                    event.stream_id,\n                    headers=(\n                        yield from format_h2_response_headers(self.context, event)\n                    ),\n                    end_stream=event.end_stream,\n                )\n                yield SendData(self.conn, self.h2_conn.data_to_send())\n        else:\n            yield from super()._handle_event(event)\n\n    def handle_h2_event(self, event: h2.events.Event) -> CommandGenerator[bool]:\n        if isinstance(event, h2.events.RequestReceived):\n            try:\n                (\n                    host,\n                    port,\n                    method,\n                    scheme,\n                    authority,\n                    path,\n                    headers,\n                ) = parse_h2_request_headers(event.headers)\n            except ValueError as e:\n                yield from self.protocol_error(f\"Invalid HTTP/2 request headers: {e}\")\n                return True\n            request = http.Request(\n                host=host,\n                port=port,\n                method=method,\n                scheme=scheme,\n                authority=authority,\n                path=path,\n                http_version=b\"HTTP/2.0\",\n                headers=headers,\n                content=None,\n                trailers=None,\n                timestamp_start=time.time(),\n                timestamp_end=None,\n            )\n            self.streams[event.stream_id] = StreamState.HEADERS_RECEIVED\n            yield ReceiveHttp(\n                RequestHeaders(\n                    event.stream_id, request, end_stream=bool(event.stream_ended)\n                )\n            )\n            return False\n        else:\n            return (yield from super().handle_h2_event(event))\n\n\nclass Http2Client(Http2Connection):\n    h2_conf = h2.config.H2Configuration(\n        **Http2Connection.h2_conf_defaults,\n        client_side=True,\n    )\n\n    ReceiveProtocolError = ResponseProtocolError\n    ReceiveData = ResponseData\n    ReceiveTrailers = ResponseTrailers\n    ReceiveEndOfMessage = ResponseEndOfMessage\n\n    our_stream_id: dict[int, int]\n    their_stream_id: dict[int, int]\n    stream_queue: collections.defaultdict[int, list[Event]]\n    \"\"\"Queue of streams that we haven't sent yet because we have reached MAX_CONCURRENT_STREAMS\"\"\"\n    provisional_max_concurrency: int | None = 10\n    \"\"\"A provisional currency limit before we get the server's first settings frame.\"\"\"\n    last_activity: float\n    \"\"\"Timestamp of when we've last seen network activity on this connection.\"\"\"\n\n    def __init__(self, context: Context):\n        super().__init__(context, context.server)\n        # Disable HTTP/2 push for now to keep things simple.\n        # don't send here, that is done as part of initiate_connection().\n        self.h2_conn.local_settings.enable_push = 0\n        # hyper-h2 pitfall: we need to acknowledge here, otherwise its sends out the old settings.\n        self.h2_conn.local_settings.acknowledge()\n        self.our_stream_id = {}\n        self.their_stream_id = {}\n        self.stream_queue = collections.defaultdict(list)\n\n    def _handle_event(self, event: Event) -> CommandGenerator[None]:\n        # We can't reuse stream ids from the client because they may arrived reordered here\n        # and HTTP/2 forbids opening a stream on a lower id than what was previously sent (see test_stream_concurrency).\n        # To mitigate this, we transparently map the outside's stream id to our stream id.\n        if isinstance(event, HttpEvent):\n            ours = self.our_stream_id.get(event.stream_id, None)\n            if ours is None:\n                no_free_streams = self.h2_conn.open_outbound_streams >= (\n                    self.provisional_max_concurrency\n                    or self.h2_conn.remote_settings.max_concurrent_streams\n                )\n                if no_free_streams:\n                    self.stream_queue[event.stream_id].append(event)\n                    return\n                ours = self.h2_conn.get_next_available_stream_id()\n                self.our_stream_id[event.stream_id] = ours\n                self.their_stream_id[ours] = event.stream_id\n            event.stream_id = ours\n\n        for cmd in self._handle_event2(event):\n            if isinstance(cmd, ReceiveHttp):\n                cmd.event.stream_id = self.their_stream_id[cmd.event.stream_id]\n            yield cmd\n\n        can_resume_queue = self.stream_queue and self.h2_conn.open_outbound_streams < (\n            self.provisional_max_concurrency\n            or self.h2_conn.remote_settings.max_concurrent_streams\n        )\n        if can_resume_queue:\n            # popitem would be LIFO, but we want FIFO.\n            events = self.stream_queue.pop(next(iter(self.stream_queue)))\n            for event in events:\n                yield from self._handle_event(event)\n\n    def _handle_event2(self, event: Event) -> CommandGenerator[None]:\n        if isinstance(event, Wakeup):\n            send_ping_now = (\n                # add one second to avoid unnecessary roundtrip, we don't need to be super correct here.\n                time.time() - self.last_activity + 1\n                > self.context.options.http2_ping_keepalive\n            )\n            if send_ping_now:\n                # PING frames MUST contain 8 octets of opaque data in the payload.\n                # A sender can include any value it chooses and use those octets in any fashion.\n                self.last_activity = time.time()\n                self.h2_conn.ping(b\"0\" * 8)\n                data = self.h2_conn.data_to_send()\n                if data is not None:\n                    yield Log(\n                        f\"Send HTTP/2 keep-alive PING to {human.format_address(self.conn.peername)}\",\n                        DEBUG,\n                    )\n                    yield SendData(self.conn, data)\n            time_until_next_ping = self.context.options.http2_ping_keepalive - (\n                time.time() - self.last_activity\n            )\n            yield RequestWakeup(time_until_next_ping)\n            return\n\n        self.last_activity = time.time()\n        if isinstance(event, Start):\n            if self.context.options.http2_ping_keepalive > 0:\n                yield RequestWakeup(self.context.options.http2_ping_keepalive)\n            yield from super()._handle_event(event)\n        elif isinstance(event, RequestHeaders):\n            self.h2_conn.send_headers(\n                event.stream_id,\n                headers=(yield from format_h2_request_headers(self.context, event)),\n                end_stream=event.end_stream,\n            )\n            self.streams[event.stream_id] = StreamState.EXPECTING_HEADERS\n            yield SendData(self.conn, self.h2_conn.data_to_send())\n        else:\n            yield from super()._handle_event(event)\n\n    def handle_h2_event(self, event: h2.events.Event) -> CommandGenerator[bool]:\n        if isinstance(event, h2.events.ResponseReceived):\n            if (\n                self.streams.get(event.stream_id, None)\n                is not StreamState.EXPECTING_HEADERS\n            ):\n                yield from self.protocol_error(f\"Received unexpected HTTP/2 response.\")\n                return True\n\n            try:\n                status_code, headers = parse_h2_response_headers(event.headers)\n            except ValueError as e:\n                yield from self.protocol_error(f\"Invalid HTTP/2 response headers: {e}\")\n                return True\n\n            response = http.Response(\n                http_version=b\"HTTP/2.0\",\n                status_code=status_code,\n                reason=b\"\",\n                headers=headers,\n                content=None,\n                trailers=None,\n                timestamp_start=time.time(),\n                timestamp_end=None,\n            )\n            self.streams[event.stream_id] = StreamState.HEADERS_RECEIVED\n            yield ReceiveHttp(\n                ResponseHeaders(event.stream_id, response, bool(event.stream_ended))\n            )\n            return False\n        elif isinstance(event, h2.events.InformationalResponseReceived):\n            # We violate the spec here (\"A proxy MUST forward 1xx responses\", RFC 7231),\n            # but that's probably fine:\n            # - 100 Continue is sent by mitmproxy to clients (irrespective of what the server does).\n            # - 101 Switching Protocols is not allowed for HTTP/2.\n            # - 102 Processing is WebDAV only and also ignorable.\n            # - 103 Early Hints is not mission-critical.\n            headers = http.Headers(event.headers)\n            status: str | int = \"<unknown status>\"\n            try:\n                status = int(headers[\":status\"])\n                reason = status_codes.RESPONSES.get(status, \"\")\n            except (KeyError, ValueError):\n                reason = \"\"\n            yield Log(f\"Swallowing HTTP/2 informational response: {status} {reason}\")\n            return False\n        elif isinstance(event, h2.events.RequestReceived):\n            yield from self.protocol_error(\n                f\"HTTP/2 protocol error: received request from server\"\n            )\n            return True\n        elif isinstance(event, h2.events.RemoteSettingsChanged):\n            # We have received at least one settings from now,\n            # which means we can rely on the max concurrency in remote_settings\n            self.provisional_max_concurrency = None\n            return (yield from super().handle_h2_event(event))\n        else:\n            return (yield from super().handle_h2_event(event))\n\n\ndef split_pseudo_headers(\n    h2_headers: Sequence[tuple[bytes, bytes]],\n) -> tuple[dict[bytes, bytes], http.Headers]:\n    pseudo_headers: dict[bytes, bytes] = {}\n    i = 0\n    for header, value in h2_headers:\n        if header.startswith(b\":\"):\n            if header in pseudo_headers:\n                raise ValueError(f\"Duplicate HTTP/2 pseudo header: {header!r}\")\n            pseudo_headers[header] = value\n            i += 1\n        else:\n            # Pseudo-headers must be at the start, we are done here.\n            break\n\n    headers = http.Headers(h2_headers[i:])\n\n    return pseudo_headers, headers\n\n\ndef parse_h2_request_headers(\n    h2_headers: Sequence[tuple[bytes, bytes]],\n) -> tuple[str, int, bytes, bytes, bytes, bytes, http.Headers]:\n    \"\"\"Split HTTP/2 pseudo-headers from the actual headers and parse them.\"\"\"\n    pseudo_headers, headers = split_pseudo_headers(h2_headers)\n\n    try:\n        method: bytes = pseudo_headers.pop(b\":method\")\n        scheme: bytes = pseudo_headers.pop(\n            b\":scheme\"\n        )  # this raises for HTTP/2 CONNECT requests\n        path: bytes = pseudo_headers.pop(b\":path\")\n        authority: bytes = pseudo_headers.pop(b\":authority\", b\"\")\n    except KeyError as e:\n        raise ValueError(f\"Required pseudo header is missing: {e}\")\n\n    if pseudo_headers:\n        raise ValueError(f\"Unknown pseudo headers: {pseudo_headers}\")\n\n    if authority:\n        host, port = url.parse_authority(authority, check=True)\n        if port is None:\n            port = 80 if scheme == b\"http\" else 443\n    else:\n        host = \"\"\n        port = 0\n\n    return host, port, method, scheme, authority, path, headers\n\n\ndef parse_h2_response_headers(\n    h2_headers: Sequence[tuple[bytes, bytes]],\n) -> tuple[int, http.Headers]:\n    \"\"\"Split HTTP/2 pseudo-headers from the actual headers and parse them.\"\"\"\n    pseudo_headers, headers = split_pseudo_headers(h2_headers)\n\n    try:\n        status_code: int = int(pseudo_headers.pop(b\":status\"))\n    except KeyError as e:\n        raise ValueError(f\"Required pseudo header is missing: {e}\")\n\n    if pseudo_headers:\n        raise ValueError(f\"Unknown pseudo headers: {pseudo_headers}\")\n\n    return status_code, headers\n\n\n__all__ = [\n    \"format_h2_request_headers\",\n    \"format_h2_response_headers\",\n    \"parse_h2_request_headers\",\n    \"parse_h2_response_headers\",\n    \"Http2Client\",\n    \"Http2Server\",\n]\n", "mitmproxy/proxy/layers/http/_upstream_proxy.py": "import time\nfrom logging import DEBUG\n\nfrom h11._receivebuffer import ReceiveBuffer\n\nfrom mitmproxy import connection\nfrom mitmproxy import http\nfrom mitmproxy.net.http import http1\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy import tunnel\nfrom mitmproxy.proxy.layers import tls\nfrom mitmproxy.proxy.layers.http._hooks import HttpConnectUpstreamHook\nfrom mitmproxy.utils import human\n\n\nclass HttpUpstreamProxy(tunnel.TunnelLayer):\n    buf: ReceiveBuffer\n    send_connect: bool\n    conn: connection.Server\n    tunnel_connection: connection.Server\n\n    def __init__(\n        self, ctx: context.Context, tunnel_conn: connection.Server, send_connect: bool\n    ):\n        super().__init__(ctx, tunnel_connection=tunnel_conn, conn=ctx.server)\n        self.buf = ReceiveBuffer()\n        self.send_connect = send_connect\n\n    @classmethod\n    def make(cls, ctx: context.Context, send_connect: bool) -> tunnel.LayerStack:\n        assert ctx.server.via\n        scheme, address = ctx.server.via\n        assert scheme in (\"http\", \"https\")\n\n        http_proxy = connection.Server(address=address)\n\n        stack = tunnel.LayerStack()\n        if scheme == \"https\":\n            http_proxy.alpn_offers = tls.HTTP1_ALPNS\n            http_proxy.sni = address[0]\n            stack /= tls.ServerTLSLayer(ctx, http_proxy)\n        stack /= cls(ctx, http_proxy, send_connect)\n\n        return stack\n\n    def start_handshake(self) -> layer.CommandGenerator[None]:\n        if not self.send_connect:\n            return (yield from super().start_handshake())\n        assert self.conn.address\n        flow = http.HTTPFlow(self.context.client, self.tunnel_connection)\n        authority = (\n            self.conn.address[0].encode(\"idna\") + f\":{self.conn.address[1]}\".encode()\n        )\n        flow.request = http.Request(\n            host=self.conn.address[0],\n            port=self.conn.address[1],\n            method=b\"CONNECT\",\n            scheme=b\"\",\n            authority=authority,\n            path=b\"\",\n            http_version=b\"HTTP/1.1\",\n            headers=http.Headers(),\n            content=b\"\",\n            trailers=None,\n            timestamp_start=time.time(),\n            timestamp_end=time.time(),\n        )\n        yield HttpConnectUpstreamHook(flow)\n        raw = http1.assemble_request(flow.request)\n        yield commands.SendData(self.tunnel_connection, raw)\n\n    def receive_handshake_data(\n        self, data: bytes\n    ) -> layer.CommandGenerator[tuple[bool, str | None]]:\n        if not self.send_connect:\n            return (yield from super().receive_handshake_data(data))\n        self.buf += data\n        response_head = self.buf.maybe_extract_lines()\n        if response_head:\n            try:\n                response = http1.read_response_head([bytes(x) for x in response_head])\n            except ValueError as e:\n                proxyaddr = human.format_address(self.tunnel_connection.address)\n                yield commands.Log(f\"{proxyaddr}: {e}\")\n                return False, f\"Error connecting to {proxyaddr}: {e}\"\n            if 200 <= response.status_code < 300:\n                if self.buf:\n                    yield from self.receive_data(bytes(self.buf))\n                    del self.buf\n                return True, None\n            else:\n                proxyaddr = human.format_address(self.tunnel_connection.address)\n                raw_resp = b\"\\n\".join(response_head)\n                yield commands.Log(f\"{proxyaddr}: {raw_resp!r}\", DEBUG)\n                return (\n                    False,\n                    f\"Upstream proxy {proxyaddr} refused HTTP CONNECT request: {response.status_code} {response.reason}\",\n                )\n        else:\n            return False, None\n", "mitmproxy/proxy/layers/http/_http_h3.py": "from collections.abc import Iterable\nfrom dataclasses import dataclass\n\nfrom aioquic.h3.connection import FrameUnexpected\nfrom aioquic.h3.connection import H3Connection\nfrom aioquic.h3.connection import H3Event\nfrom aioquic.h3.connection import H3Stream\nfrom aioquic.h3.connection import Headers\nfrom aioquic.h3.connection import HeadersState\nfrom aioquic.h3.connection import StreamType\nfrom aioquic.h3.events import HeadersReceived\nfrom aioquic.quic.configuration import QuicConfiguration\nfrom aioquic.quic.events import StreamDataReceived\nfrom aioquic.quic.packet import QuicErrorCode\n\nfrom mitmproxy import connection\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.layers.quic import CloseQuicConnection\nfrom mitmproxy.proxy.layers.quic import QuicConnectionClosed\nfrom mitmproxy.proxy.layers.quic import QuicStreamDataReceived\nfrom mitmproxy.proxy.layers.quic import QuicStreamEvent\nfrom mitmproxy.proxy.layers.quic import QuicStreamReset\nfrom mitmproxy.proxy.layers.quic import ResetQuicStream\nfrom mitmproxy.proxy.layers.quic import SendQuicStreamData\n\n\n@dataclass\nclass TrailersReceived(H3Event):\n    \"\"\"\n    The TrailersReceived event is fired whenever trailers are received.\n    \"\"\"\n\n    trailers: Headers\n    \"The trailers.\"\n\n    stream_id: int\n    \"The ID of the stream the trailers were received for.\"\n\n    stream_ended: bool\n    \"Whether the STREAM frame had the FIN bit set.\"\n\n    push_id: int | None = None\n    \"The Push ID or `None` if this is not a push.\"\n\n\n@dataclass\nclass StreamReset(H3Event):\n    \"\"\"\n    The StreamReset event is fired whenever a stream is reset by the peer.\n    \"\"\"\n\n    stream_id: int\n    \"The ID of the stream that was reset.\"\n\n    error_code: int\n    \"\"\"The error code indicating why the stream was reset.\"\"\"\n\n    push_id: int | None = None\n    \"The Push ID or `None` if this is not a push.\"\n\n\nclass MockQuic:\n    \"\"\"\n    aioquic intermingles QUIC and HTTP/3. This is something we don't want to do because that makes testing much harder.\n    Instead, we mock our QUIC connection object here and then take out the wire data to be sent.\n    \"\"\"\n\n    def __init__(self, conn: connection.Connection, is_client: bool) -> None:\n        self.conn = conn\n        self.pending_commands: list[commands.Command] = []\n        self._next_stream_id: list[int] = [0, 1, 2, 3]\n        self._is_client = is_client\n\n        # the following fields are accessed by H3Connection\n        self.configuration = QuicConfiguration(is_client=is_client)\n        self._quic_logger = None\n        self._remote_max_datagram_frame_size = 0\n\n    def close(\n        self,\n        error_code: int = QuicErrorCode.NO_ERROR,\n        frame_type: int | None = None,\n        reason_phrase: str = \"\",\n    ) -> None:\n        # we'll get closed if a protocol error occurs in `H3Connection.handle_event`\n        # we note the error on the connection and yield a CloseConnection\n        # this will then call `QuicConnection.close` with the proper values\n        # once the `Http3Connection` receives `ConnectionClosed`, it will send out `ProtocolError`\n        self.pending_commands.append(\n            CloseQuicConnection(self.conn, error_code, frame_type, reason_phrase)\n        )\n\n    def get_next_available_stream_id(self, is_unidirectional: bool = False) -> int:\n        # since we always reserve the ID, we have to \"find\" the next ID like `QuicConnection` does\n        index = (int(is_unidirectional) << 1) | int(not self._is_client)\n        stream_id = self._next_stream_id[index]\n        self._next_stream_id[index] = stream_id + 4\n        return stream_id\n\n    def reset_stream(self, stream_id: int, error_code: int) -> None:\n        self.pending_commands.append(ResetQuicStream(self.conn, stream_id, error_code))\n\n    def send_stream_data(\n        self, stream_id: int, data: bytes, end_stream: bool = False\n    ) -> None:\n        self.pending_commands.append(\n            SendQuicStreamData(self.conn, stream_id, data, end_stream)\n        )\n\n\nclass LayeredH3Connection(H3Connection):\n    \"\"\"\n    Creates a H3 connection using a fake QUIC connection, which allows layer separation.\n    Also ensures that headers, data and trailers are sent in that order.\n    \"\"\"\n\n    def __init__(\n        self,\n        conn: connection.Connection,\n        is_client: bool,\n        enable_webtransport: bool = False,\n    ) -> None:\n        self._mock = MockQuic(conn, is_client)\n        super().__init__(self._mock, enable_webtransport)  # type: ignore\n\n    def _after_send(self, stream_id: int, end_stream: bool) -> None:\n        # if the stream ended, `QuicConnection` has an assert that no further data is being sent\n        # to catch this more early on, we set the header state on the `H3Stream`\n        if end_stream:\n            self._stream[stream_id].headers_send_state = HeadersState.AFTER_TRAILERS\n\n    def _handle_request_or_push_frame(\n        self,\n        frame_type: int,\n        frame_data: bytes | None,\n        stream: H3Stream,\n        stream_ended: bool,\n    ) -> list[H3Event]:\n        # turn HeadersReceived into TrailersReceived for trailers\n        events = super()._handle_request_or_push_frame(\n            frame_type, frame_data, stream, stream_ended\n        )\n        for index, event in enumerate(events):\n            if (\n                isinstance(event, HeadersReceived)\n                and self._stream[event.stream_id].headers_recv_state\n                == HeadersState.AFTER_TRAILERS\n            ):\n                events[index] = TrailersReceived(\n                    event.headers, event.stream_id, event.stream_ended, event.push_id\n                )\n        return events\n\n    def close_connection(\n        self,\n        error_code: int = QuicErrorCode.NO_ERROR,\n        frame_type: int | None = None,\n        reason_phrase: str = \"\",\n    ) -> None:\n        \"\"\"Closes the underlying QUIC connection and ignores any incoming events.\"\"\"\n\n        self._is_done = True\n        self._quic.close(error_code, frame_type, reason_phrase)\n\n    def end_stream(self, stream_id: int) -> None:\n        \"\"\"Ends the given stream if not already done so.\"\"\"\n\n        stream = self._get_or_create_stream(stream_id)\n        if stream.headers_send_state != HeadersState.AFTER_TRAILERS:\n            super().send_data(stream_id, b\"\", end_stream=True)\n            stream.headers_send_state = HeadersState.AFTER_TRAILERS\n\n    def get_next_available_stream_id(self, is_unidirectional: bool = False):\n        \"\"\"Reserves and returns the next available stream ID.\"\"\"\n\n        return self._quic.get_next_available_stream_id(is_unidirectional)\n\n    def get_open_stream_ids(self, push_id: int | None) -> Iterable[int]:\n        \"\"\"Iterates over all non-special open streams, optionally for a given push id.\"\"\"\n\n        return (\n            stream.stream_id\n            for stream in self._stream.values()\n            if (\n                stream.push_id == push_id\n                and stream.stream_type == (None if push_id is None else StreamType.PUSH)\n                and not (\n                    stream.headers_recv_state == HeadersState.AFTER_TRAILERS\n                    and stream.headers_send_state == HeadersState.AFTER_TRAILERS\n                )\n            )\n        )\n\n    def handle_connection_closed(self, event: QuicConnectionClosed) -> None:\n        self._is_done = True\n\n    def handle_stream_event(self, event: QuicStreamEvent) -> list[H3Event]:\n        # don't do anything if we're done\n        if self._is_done:\n            return []\n\n        # treat reset events similar to data events with end_stream=True\n        # We can receive multiple reset events as long as the final size does not change.\n        elif isinstance(event, QuicStreamReset):\n            stream = self._get_or_create_stream(event.stream_id)\n            stream.ended = True\n            stream.headers_recv_state = HeadersState.AFTER_TRAILERS\n            return [StreamReset(event.stream_id, event.error_code, stream.push_id)]\n\n        # convert data events from the QUIC layer back to aioquic events\n        elif isinstance(event, QuicStreamDataReceived):\n            if self._get_or_create_stream(event.stream_id).ended:\n                # aioquic will not send us any data events once a stream has ended.\n                # Instead, it will close the connection. We simulate this here for H3 tests.\n                self.close_connection(\n                    error_code=QuicErrorCode.PROTOCOL_VIOLATION,\n                    reason_phrase=\"stream already ended\",\n                )\n                return []\n            else:\n                return self.handle_event(\n                    StreamDataReceived(event.data, event.end_stream, event.stream_id)\n                )\n\n        # should never happen\n        else:  # pragma: no cover\n            raise AssertionError(f\"Unexpected event: {event!r}\")\n\n    def has_sent_headers(self, stream_id: int) -> bool:\n        \"\"\"Indicates whether headers have been sent over the given stream.\"\"\"\n\n        try:\n            return self._stream[stream_id].headers_send_state != HeadersState.INITIAL\n        except KeyError:\n            return False\n\n    def reset_stream(self, stream_id: int, error_code: int) -> None:\n        \"\"\"Resets a stream that hasn't been ended locally yet.\"\"\"\n\n        # set the header state and queue a reset event\n        stream = self._get_or_create_stream(stream_id)\n        stream.headers_send_state = HeadersState.AFTER_TRAILERS\n        self._quic.reset_stream(stream_id, error_code)\n\n    def send_data(self, stream_id: int, data: bytes, end_stream: bool = False) -> None:\n        \"\"\"Sends data over the given stream.\"\"\"\n\n        super().send_data(stream_id, data, end_stream)\n        self._after_send(stream_id, end_stream)\n\n    def send_datagram(self, flow_id: int, data: bytes) -> None:\n        # supporting datagrams would require additional information from the underlying QUIC connection\n        raise NotImplementedError()  # pragma: no cover\n\n    def send_headers(\n        self, stream_id: int, headers: Headers, end_stream: bool = False\n    ) -> None:\n        \"\"\"Sends headers over the given stream.\"\"\"\n\n        # ensure we haven't sent something before\n        stream = self._get_or_create_stream(stream_id)\n        if stream.headers_send_state != HeadersState.INITIAL:\n            raise FrameUnexpected(\"initial HEADERS frame is not allowed in this state\")\n        super().send_headers(stream_id, headers, end_stream)\n        self._after_send(stream_id, end_stream)\n\n    def send_trailers(self, stream_id: int, trailers: Headers) -> None:\n        \"\"\"Sends trailers over the given stream and ends it.\"\"\"\n\n        # ensure we got some headers first\n        stream = self._get_or_create_stream(stream_id)\n        if stream.headers_send_state != HeadersState.AFTER_HEADERS:\n            raise FrameUnexpected(\"trailing HEADERS frame is not allowed in this state\")\n        super().send_headers(stream_id, trailers, end_stream=True)\n        self._after_send(stream_id, end_stream=True)\n\n    def transmit(self) -> layer.CommandGenerator[None]:\n        \"\"\"Yields all pending commands for the upper QUIC layer.\"\"\"\n\n        while self._mock.pending_commands:\n            yield self._mock.pending_commands.pop(0)\n\n\n__all__ = [\n    \"LayeredH3Connection\",\n    \"StreamReset\",\n    \"TrailersReceived\",\n]\n", "mitmproxy/proxy/layers/http/_events.py": "from dataclasses import dataclass\n\nfrom ._base import HttpEvent\nfrom mitmproxy import http\nfrom mitmproxy.http import HTTPFlow\n\n\n@dataclass\nclass RequestHeaders(HttpEvent):\n    request: http.Request\n    end_stream: bool\n    \"\"\"\n    If True, we already know at this point that there is no message body. This is useful for HTTP/2, where it allows\n    us to set END_STREAM on headers already (and some servers - Akamai - implicitly expect that).\n    In either case, this event will nonetheless be followed by RequestEndOfMessage.\n    \"\"\"\n    replay_flow: HTTPFlow | None = None\n    \"\"\"If set, the current request headers belong to a replayed flow, which should be reused.\"\"\"\n\n\n@dataclass\nclass ResponseHeaders(HttpEvent):\n    response: http.Response\n    end_stream: bool = False\n\n\n# explicit constructors below to facilitate type checking in _http1/_http2\n\n\n@dataclass\nclass RequestData(HttpEvent):\n    data: bytes\n\n    def __init__(self, stream_id: int, data: bytes):\n        self.stream_id = stream_id\n        self.data = data\n\n\n@dataclass\nclass ResponseData(HttpEvent):\n    data: bytes\n\n    def __init__(self, stream_id: int, data: bytes):\n        self.stream_id = stream_id\n        self.data = data\n\n\n@dataclass\nclass RequestTrailers(HttpEvent):\n    trailers: http.Headers\n\n    def __init__(self, stream_id: int, trailers: http.Headers):\n        self.stream_id = stream_id\n        self.trailers = trailers\n\n\n@dataclass\nclass ResponseTrailers(HttpEvent):\n    trailers: http.Headers\n\n    def __init__(self, stream_id: int, trailers: http.Headers):\n        self.stream_id = stream_id\n        self.trailers = trailers\n\n\n@dataclass\nclass RequestEndOfMessage(HttpEvent):\n    def __init__(self, stream_id: int):\n        self.stream_id = stream_id\n\n\n@dataclass\nclass ResponseEndOfMessage(HttpEvent):\n    def __init__(self, stream_id: int):\n        self.stream_id = stream_id\n\n\n@dataclass\nclass RequestProtocolError(HttpEvent):\n    message: str\n    code: int = 400\n\n    def __init__(self, stream_id: int, message: str, code: int = 400):\n        self.stream_id = stream_id\n        self.message = message\n        self.code = code\n\n\n@dataclass\nclass ResponseProtocolError(HttpEvent):\n    message: str\n    code: int = 502\n\n    def __init__(self, stream_id: int, message: str, code: int = 502):\n        self.stream_id = stream_id\n        self.message = message\n        self.code = code\n\n\n__all__ = [\n    \"HttpEvent\",\n    \"RequestHeaders\",\n    \"RequestData\",\n    \"RequestEndOfMessage\",\n    \"ResponseHeaders\",\n    \"ResponseData\",\n    \"RequestTrailers\",\n    \"ResponseTrailers\",\n    \"ResponseEndOfMessage\",\n    \"RequestProtocolError\",\n    \"ResponseProtocolError\",\n]\n", "mitmproxy/proxy/layers/http/__init__.py": "import collections\nimport enum\nimport time\nfrom dataclasses import dataclass\nfrom functools import cached_property\nfrom logging import DEBUG\nfrom logging import WARNING\n\nimport wsproto.handshake\n\nfrom ...context import Context\nfrom ...mode_specs import ReverseMode\nfrom ...mode_specs import UpstreamMode\nfrom ..quic import QuicStreamEvent\nfrom ._base import HttpCommand\nfrom ._base import HttpConnection\nfrom ._base import ReceiveHttp\nfrom ._base import StreamId\nfrom ._events import HttpEvent\nfrom ._events import RequestData\nfrom ._events import RequestEndOfMessage\nfrom ._events import RequestHeaders\nfrom ._events import RequestProtocolError\nfrom ._events import RequestTrailers\nfrom ._events import ResponseData\nfrom ._events import ResponseEndOfMessage\nfrom ._events import ResponseHeaders\nfrom ._events import ResponseProtocolError\nfrom ._events import ResponseTrailers\nfrom ._hooks import HttpConnectedHook\nfrom ._hooks import HttpConnectErrorHook\nfrom ._hooks import HttpConnectHook\nfrom ._hooks import HttpErrorHook\nfrom ._hooks import HttpRequestHeadersHook\nfrom ._hooks import HttpRequestHook\nfrom ._hooks import HttpResponseHeadersHook\nfrom ._hooks import HttpResponseHook\nfrom ._http1 import Http1Client\nfrom ._http1 import Http1Connection\nfrom ._http1 import Http1Server\nfrom ._http2 import Http2Client\nfrom ._http2 import Http2Server\nfrom ._http3 import Http3Client\nfrom ._http3 import Http3Server\nfrom mitmproxy import flow\nfrom mitmproxy import http\nfrom mitmproxy.connection import Connection\nfrom mitmproxy.connection import Server\nfrom mitmproxy.connection import TransportProtocol\nfrom mitmproxy.net import server_spec\nfrom mitmproxy.net.http import status_codes\nfrom mitmproxy.net.http import url\nfrom mitmproxy.net.http.http1 import expected_http_body_size\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy import tunnel\nfrom mitmproxy.proxy.layers import quic\nfrom mitmproxy.proxy.layers import tcp\nfrom mitmproxy.proxy.layers import tls\nfrom mitmproxy.proxy.layers import websocket\nfrom mitmproxy.proxy.layers.http import _upstream_proxy\nfrom mitmproxy.proxy.utils import expect\nfrom mitmproxy.proxy.utils import ReceiveBuffer\nfrom mitmproxy.utils import human\nfrom mitmproxy.websocket import WebSocketData\n\n\nclass HTTPMode(enum.Enum):\n    regular = 1\n    transparent = 2\n    upstream = 3\n\n\ndef validate_request(mode: HTTPMode, request: http.Request) -> str | None:\n    if request.scheme not in (\"http\", \"https\", \"\"):\n        return f\"Invalid request scheme: {request.scheme}\"\n    if mode is HTTPMode.transparent and request.method == \"CONNECT\":\n        return (\n            f\"mitmproxy received an HTTP CONNECT request even though it is not running in regular/upstream mode. \"\n            f\"This usually indicates a misconfiguration, please see the mitmproxy mode documentation for details.\"\n        )\n    return None\n\n\ndef is_h3_alpn(alpn: bytes | None) -> bool:\n    return alpn == b\"h3\" or (alpn is not None and alpn.startswith(b\"h3-\"))\n\n\n@dataclass\nclass GetHttpConnection(HttpCommand):\n    \"\"\"\n    Open an HTTP Connection. This may not actually open a connection, but return an existing HTTP connection instead.\n    \"\"\"\n\n    blocking = True\n    address: tuple[str, int]\n    tls: bool\n    via: server_spec.ServerSpec | None\n    transport_protocol: TransportProtocol = \"tcp\"\n\n    def __hash__(self):\n        return id(self)\n\n    def connection_spec_matches(self, connection: Connection) -> bool:\n        return (\n            isinstance(connection, Server)\n            and self.address == connection.address\n            and self.tls == connection.tls\n            and self.via == connection.via\n            and self.transport_protocol == connection.transport_protocol\n        )\n\n\n@dataclass\nclass GetHttpConnectionCompleted(events.CommandCompleted):\n    command: GetHttpConnection\n    reply: tuple[None, str] | tuple[Connection, None]\n    \"\"\"connection object, error message\"\"\"\n\n\n@dataclass\nclass RegisterHttpConnection(HttpCommand):\n    \"\"\"\n    Register that a HTTP connection attempt has been completed.\n    \"\"\"\n\n    connection: Connection\n    err: str | None\n\n\n@dataclass\nclass SendHttp(HttpCommand):\n    event: HttpEvent\n    connection: Connection\n\n    def __repr__(self) -> str:\n        return f\"Send({self.event})\"\n\n\n@dataclass\nclass DropStream(HttpCommand):\n    \"\"\"Signal to the HTTP layer that this stream is done processing and can be dropped from memory.\"\"\"\n\n    stream_id: StreamId\n\n\nclass HttpStream(layer.Layer):\n    request_body_buf: ReceiveBuffer\n    response_body_buf: ReceiveBuffer\n    flow: http.HTTPFlow\n    stream_id: StreamId\n    child_layer: layer.Layer | None = None\n\n    @cached_property\n    def mode(self) -> HTTPMode:\n        i = self.context.layers.index(self)\n        parent = self.context.layers[i - 1]\n        assert isinstance(parent, HttpLayer)\n        return parent.mode\n\n    def __init__(self, context: Context, stream_id: int) -> None:\n        super().__init__(context)\n        self.request_body_buf = ReceiveBuffer()\n        self.response_body_buf = ReceiveBuffer()\n        self.client_state = self.state_uninitialized\n        self.server_state = self.state_uninitialized\n        self.stream_id = stream_id\n\n    def __repr__(self):\n        if self._handle_event == self.passthrough:\n            return f\"HttpStream(id={self.stream_id}, passthrough)\"\n        else:\n            return (\n                f\"HttpStream(\"\n                f\"id={self.stream_id}, \"\n                f\"client_state={self.client_state.__name__}, \"\n                f\"server_state={self.server_state.__name__}\"\n                f\")\"\n            )\n\n    @expect(events.Start, HttpEvent)\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, events.Start):\n            self.client_state = self.state_wait_for_request_headers\n        elif isinstance(event, (RequestProtocolError, ResponseProtocolError)):\n            yield from self.handle_protocol_error(event)\n        elif isinstance(\n            event, (RequestHeaders, RequestData, RequestTrailers, RequestEndOfMessage)\n        ):\n            yield from self.client_state(event)\n        else:\n            yield from self.server_state(event)\n\n    @expect(RequestHeaders)\n    def state_wait_for_request_headers(\n        self, event: RequestHeaders\n    ) -> layer.CommandGenerator[None]:\n        if not event.replay_flow:\n            self.flow = http.HTTPFlow(self.context.client, self.context.server)\n\n        else:\n            self.flow = event.replay_flow\n        self.flow.request = event.request\n        self.flow.live = True\n\n        if err := validate_request(self.mode, self.flow.request):\n            self.flow.response = http.Response.make(502, str(err))\n            self.client_state = self.state_errored\n            return (yield from self.send_response())\n\n        if self.flow.request.method == \"CONNECT\":\n            return (yield from self.handle_connect())\n\n        if self.mode is HTTPMode.transparent:\n            # Determine .scheme, .host and .port attributes for transparent requests\n            assert self.context.server.address\n            self.flow.request.data.host = self.context.server.address[0]\n            self.flow.request.data.port = self.context.server.address[1]\n            self.flow.request.scheme = \"https\" if self.context.server.tls else \"http\"\n        elif not self.flow.request.host:\n            # We need to extract destination information from the host header.\n            try:\n                host, port = url.parse_authority(\n                    self.flow.request.host_header or \"\", check=True\n                )\n            except ValueError:\n                yield SendHttp(\n                    ResponseProtocolError(\n                        self.stream_id,\n                        \"HTTP request has no host header, destination unknown.\",\n                        400,\n                    ),\n                    self.context.client,\n                )\n                self.client_state = self.state_errored\n                return\n            else:\n                if port is None:\n                    port = 443 if self.context.client.tls else 80\n                self.flow.request.data.host = host\n                self.flow.request.data.port = port\n                self.flow.request.scheme = (\n                    \"https\" if self.context.client.tls else \"http\"\n                )\n\n        if self.mode is HTTPMode.regular and not (\n            self.flow.request.is_http2 or self.flow.request.is_http3\n        ):\n            # Set the request target to origin-form for HTTP/1, some servers don't support absolute-form requests.\n            # see https://github.com/mitmproxy/mitmproxy/issues/1759\n            self.flow.request.authority = \"\"\n\n        # update host header in reverse proxy mode\n        if (\n            isinstance(self.context.client.proxy_mode, ReverseMode)\n            and not self.context.options.keep_host_header\n        ):\n            assert self.context.server.address\n            self.flow.request.host_header = url.hostport(\n                \"https\" if self.context.server.tls else \"http\",\n                self.context.server.address[0],\n                self.context.server.address[1],\n            )\n\n        if not event.end_stream and (yield from self.check_body_size(True)):\n            return\n\n        yield HttpRequestHeadersHook(self.flow)\n        if (yield from self.check_killed(True)):\n            return\n\n        if self.flow.request.headers.get(\"expect\", \"\").lower() == \"100-continue\":\n            continue_response = http.Response.make(100)\n            continue_response.headers.clear()\n            yield SendHttp(\n                ResponseHeaders(self.stream_id, continue_response), self.context.client\n            )\n            self.flow.request.headers.pop(\"expect\")\n\n        if self.flow.request.stream:\n            yield from self.start_request_stream()\n        else:\n            self.client_state = self.state_consume_request_body\n        self.server_state = self.state_wait_for_response_headers\n\n    def start_request_stream(self) -> layer.CommandGenerator[None]:\n        if self.flow.response:\n            raise NotImplementedError(\n                \"Can't set a response and enable streaming at the same time.\"\n            )\n        ok = yield from self.make_server_connection()\n        if not ok:\n            self.client_state = self.state_errored\n            return\n        yield SendHttp(\n            RequestHeaders(self.stream_id, self.flow.request, end_stream=False),\n            self.context.server,\n        )\n        yield commands.Log(f\"Streaming request to {self.flow.request.host}.\")\n        self.client_state = self.state_stream_request_body\n\n    @expect(RequestData, RequestTrailers, RequestEndOfMessage)\n    def state_stream_request_body(\n        self, event: RequestData | RequestEndOfMessage\n    ) -> layer.CommandGenerator[None]:\n        if isinstance(event, RequestData):\n            if callable(self.flow.request.stream):\n                chunks = self.flow.request.stream(event.data)\n                if isinstance(chunks, bytes):\n                    chunks = [chunks]\n            else:\n                chunks = [event.data]\n            for chunk in chunks:\n                yield SendHttp(RequestData(self.stream_id, chunk), self.context.server)\n        elif isinstance(event, RequestTrailers):\n            # we don't do anything further here, we wait for RequestEndOfMessage first to trigger the request hook.\n            self.flow.request.trailers = event.trailers\n        elif isinstance(event, RequestEndOfMessage):\n            if callable(self.flow.request.stream):\n                chunks = self.flow.request.stream(b\"\")\n                if chunks == b\"\":\n                    chunks = []\n                elif isinstance(chunks, bytes):\n                    chunks = [chunks]\n                for chunk in chunks:\n                    yield SendHttp(\n                        RequestData(self.stream_id, chunk), self.context.server\n                    )\n\n            self.flow.request.timestamp_end = time.time()\n            yield HttpRequestHook(self.flow)\n            self.client_state = self.state_done\n\n            if self.flow.request.trailers:\n                # we've delayed sending trailers until after `request` has been triggered.\n                yield SendHttp(\n                    RequestTrailers(self.stream_id, self.flow.request.trailers),\n                    self.context.server,\n                )\n            yield SendHttp(event, self.context.server)\n\n            if self.server_state == self.state_done:\n                yield from self.flow_done()\n\n    @expect(RequestData, RequestTrailers, RequestEndOfMessage)\n    def state_consume_request_body(\n        self, event: events.Event\n    ) -> layer.CommandGenerator[None]:\n        if isinstance(event, RequestData):\n            self.request_body_buf += event.data\n            yield from self.check_body_size(True)\n        elif isinstance(event, RequestTrailers):\n            assert self.flow.request\n            self.flow.request.trailers = event.trailers\n        elif isinstance(event, RequestEndOfMessage):\n            self.flow.request.timestamp_end = time.time()\n            self.flow.request.data.content = bytes(self.request_body_buf)\n            self.request_body_buf.clear()\n            self.client_state = self.state_done\n            yield HttpRequestHook(self.flow)\n            if (yield from self.check_killed(True)):\n                return\n            elif self.flow.response:\n                # response was set by an inline script.\n                # we now need to emulate the responseheaders hook.\n                self.flow.response.timestamp_start = time.time()\n                yield HttpResponseHeadersHook(self.flow)\n                if (yield from self.check_killed(True)):\n                    return\n                yield from self.send_response()\n            else:\n                ok = yield from self.make_server_connection()\n                if not ok:\n                    return\n\n                content = self.flow.request.raw_content\n                done_after_headers = not (content or self.flow.request.trailers)\n                yield SendHttp(\n                    RequestHeaders(\n                        self.stream_id, self.flow.request, done_after_headers\n                    ),\n                    self.context.server,\n                )\n                if content:\n                    yield SendHttp(\n                        RequestData(self.stream_id, content), self.context.server\n                    )\n                if self.flow.request.trailers:\n                    yield SendHttp(\n                        RequestTrailers(self.stream_id, self.flow.request.trailers),\n                        self.context.server,\n                    )\n                yield SendHttp(RequestEndOfMessage(self.stream_id), self.context.server)\n\n    @expect(ResponseHeaders)\n    def state_wait_for_response_headers(\n        self, event: ResponseHeaders\n    ) -> layer.CommandGenerator[None]:\n        self.flow.response = event.response\n\n        if not event.end_stream and (yield from self.check_body_size(False)):\n            return\n\n        yield HttpResponseHeadersHook(self.flow)\n        if (yield from self.check_killed(True)):\n            return\n\n        elif self.flow.response.stream:\n            yield from self.start_response_stream()\n        else:\n            self.server_state = self.state_consume_response_body\n\n    def start_response_stream(self) -> layer.CommandGenerator[None]:\n        assert self.flow.response\n        yield SendHttp(\n            ResponseHeaders(self.stream_id, self.flow.response, end_stream=False),\n            self.context.client,\n        )\n        yield commands.Log(f\"Streaming response from {self.flow.request.host}.\")\n        self.server_state = self.state_stream_response_body\n\n    @expect(ResponseData, ResponseTrailers, ResponseEndOfMessage)\n    def state_stream_response_body(\n        self, event: events.Event\n    ) -> layer.CommandGenerator[None]:\n        assert self.flow.response\n        if isinstance(event, ResponseData):\n            if callable(self.flow.response.stream):\n                chunks = self.flow.response.stream(event.data)\n                if isinstance(chunks, bytes):\n                    chunks = [chunks]\n            else:\n                chunks = [event.data]\n            for chunk in chunks:\n                yield SendHttp(ResponseData(self.stream_id, chunk), self.context.client)\n        elif isinstance(event, ResponseTrailers):\n            self.flow.response.trailers = event.trailers\n            # will be sent in send_response() after the response hook.\n        elif isinstance(event, ResponseEndOfMessage):\n            if callable(self.flow.response.stream):\n                chunks = self.flow.response.stream(b\"\")\n                if chunks == b\"\":\n                    chunks = []\n                elif isinstance(chunks, bytes):\n                    chunks = [chunks]\n                for chunk in chunks:\n                    yield SendHttp(\n                        ResponseData(self.stream_id, chunk), self.context.client\n                    )\n            yield from self.send_response(already_streamed=True)\n\n    @expect(ResponseData, ResponseTrailers, ResponseEndOfMessage)\n    def state_consume_response_body(\n        self, event: events.Event\n    ) -> layer.CommandGenerator[None]:\n        if isinstance(event, ResponseData):\n            self.response_body_buf += event.data\n            yield from self.check_body_size(False)\n        elif isinstance(event, ResponseTrailers):\n            assert self.flow.response\n            self.flow.response.trailers = event.trailers\n        elif isinstance(event, ResponseEndOfMessage):\n            assert self.flow.response\n            self.flow.response.data.content = bytes(self.response_body_buf)\n            self.response_body_buf.clear()\n            yield from self.send_response()\n\n    def send_response(self, already_streamed: bool = False):\n        \"\"\"We have either consumed the entire response from the server or the response was set by an addon.\"\"\"\n        assert self.flow.response\n        self.flow.response.timestamp_end = time.time()\n\n        is_websocket = (\n            self.flow.response.status_code == 101\n            and self.flow.response.headers.get(\"upgrade\", \"\").lower() == \"websocket\"\n            and self.flow.request.headers.get(\"Sec-WebSocket-Version\", \"\").encode()\n            == wsproto.handshake.WEBSOCKET_VERSION\n            and self.context.options.websocket\n        )\n        if is_websocket:\n            # We need to set this before calling the response hook\n            # so that addons can determine if a WebSocket connection is following up.\n            self.flow.websocket = WebSocketData()\n\n        yield HttpResponseHook(self.flow)\n        self.server_state = self.state_done\n        if (yield from self.check_killed(False)):\n            return\n\n        if not already_streamed:\n            content = self.flow.response.raw_content\n            done_after_headers = not (content or self.flow.response.trailers)\n            yield SendHttp(\n                ResponseHeaders(self.stream_id, self.flow.response, done_after_headers),\n                self.context.client,\n            )\n            if content:\n                yield SendHttp(\n                    ResponseData(self.stream_id, content), self.context.client\n                )\n\n        if self.flow.response.trailers:\n            yield SendHttp(\n                ResponseTrailers(self.stream_id, self.flow.response.trailers),\n                self.context.client,\n            )\n\n        if self.client_state == self.state_done:\n            yield from self.flow_done()\n\n    def flow_done(self) -> layer.CommandGenerator[None]:\n        if not self.flow.websocket:\n            self.flow.live = False\n\n        assert self.flow.response\n        if self.flow.response.status_code == 101:\n            if self.flow.websocket:\n                self.child_layer = websocket.WebsocketLayer(self.context, self.flow)\n            elif self.context.options.rawtcp:\n                self.child_layer = tcp.TCPLayer(self.context)\n            else:\n                yield commands.Log(\n                    f\"Sent HTTP 101 response, but no protocol is enabled to upgrade to.\",\n                    WARNING,\n                )\n                yield commands.CloseConnection(self.context.client)\n                self.client_state = self.server_state = self.state_errored\n                return\n            if self.debug:\n                yield commands.Log(\n                    f\"{self.debug}[http] upgrading to {self.child_layer}\", DEBUG\n                )\n            self._handle_event = self.passthrough\n            yield from self.child_layer.handle_event(events.Start())\n        else:\n            yield DropStream(self.stream_id)\n\n        # delay sending EOM until the child layer is set up,\n        # we may get data immediately and need to be prepared to handle it.\n        yield SendHttp(ResponseEndOfMessage(self.stream_id), self.context.client)\n\n    def check_body_size(self, request: bool) -> layer.CommandGenerator[bool]:\n        \"\"\"\n        Check if the body size exceeds limits imposed by stream_large_bodies or body_size_limit.\n\n        Returns `True` if the body size exceeds body_size_limit and further processing should be stopped.\n        \"\"\"\n        if not (\n            self.context.options.stream_large_bodies\n            or self.context.options.body_size_limit\n        ):\n            return False\n\n        # Step 1: Determine the expected body size. This can either come from a known content-length header,\n        # or from the amount of currently buffered bytes (e.g. for chunked encoding).\n        response = not request\n        expected_size: int | None\n        # the 'late' case: we already started consuming the body\n        if request and self.request_body_buf:\n            expected_size = len(self.request_body_buf)\n        elif response and self.response_body_buf:\n            expected_size = len(self.response_body_buf)\n        else:\n            # the 'early' case: we have not started consuming the body\n            try:\n                expected_size = expected_http_body_size(\n                    self.flow.request, self.flow.response if response else None\n                )\n            except ValueError:  # pragma: no cover\n                # we just don't stream/kill malformed content-length headers.\n                expected_size = None\n\n        if expected_size is None or expected_size <= 0:\n            return False\n\n        # Step 2: Do we need to abort this?\n        max_total_size = human.parse_size(self.context.options.body_size_limit)\n        if max_total_size is not None and expected_size > max_total_size:\n            if request and not self.request_body_buf:\n                yield HttpRequestHeadersHook(self.flow)\n            if response and not self.response_body_buf:\n                yield HttpResponseHeadersHook(self.flow)\n\n            err_msg = f\"{'Request' if request else 'Response'} body exceeds mitmproxy's body_size_limit.\"\n            err_code = 413 if request else 502\n\n            self.flow.error = flow.Error(err_msg)\n            yield HttpErrorHook(self.flow)\n            yield SendHttp(\n                ResponseProtocolError(self.stream_id, err_msg, err_code),\n                self.context.client,\n            )\n            self.client_state = self.state_errored\n            if response:\n                yield SendHttp(\n                    RequestProtocolError(self.stream_id, err_msg, err_code),\n                    self.context.server,\n                )\n                self.server_state = self.state_errored\n            self.flow.live = False\n            return True\n\n        # Step 3: Do we need to stream this?\n        max_stream_size = human.parse_size(self.context.options.stream_large_bodies)\n        if max_stream_size is not None and expected_size > max_stream_size:\n            if request:\n                self.flow.request.stream = True\n                if self.request_body_buf:\n                    # clear buffer and then fake a DataReceived event with everything we had in the buffer so far.\n                    body_buf = bytes(self.request_body_buf)\n                    self.request_body_buf.clear()\n                    yield from self.start_request_stream()\n                    yield from self.handle_event(RequestData(self.stream_id, body_buf))\n            if response:\n                assert self.flow.response\n                self.flow.response.stream = True\n                if self.response_body_buf:\n                    body_buf = bytes(self.response_body_buf)\n                    self.response_body_buf.clear()\n                    yield from self.start_response_stream()\n                    yield from self.handle_event(ResponseData(self.stream_id, body_buf))\n        return False\n\n    def check_killed(self, emit_error_hook: bool) -> layer.CommandGenerator[bool]:\n        killed_by_us = (\n            self.flow.error and self.flow.error.msg == flow.Error.KILLED_MESSAGE\n        )\n        # The client may have closed the connection while we were waiting for the hook to complete.\n        # We peek into the event queue to see if that is the case.\n        killed_by_remote = None\n        for evt in self._paused_event_queue:\n            if isinstance(evt, RequestProtocolError):\n                killed_by_remote = evt.message\n                break\n\n        if killed_by_remote:\n            if not self.flow.error:\n                self.flow.error = flow.Error(killed_by_remote)\n        if killed_by_us or killed_by_remote:\n            if emit_error_hook:\n                yield HttpErrorHook(self.flow)\n            # Use the special NO_RESPONSE status code to make sure that no error message is sent to the client.\n            yield SendHttp(\n                ResponseProtocolError(\n                    self.stream_id, \"killed\", status_codes.NO_RESPONSE\n                ),\n                self.context.client,\n            )\n            self.flow.live = False\n            self.client_state = self.server_state = self.state_errored\n            return True\n        return False\n\n    def handle_protocol_error(\n        self, event: RequestProtocolError | ResponseProtocolError\n    ) -> layer.CommandGenerator[None]:\n        is_client_error_but_we_already_talk_upstream = (\n            isinstance(event, RequestProtocolError)\n            and self.client_state in (self.state_stream_request_body, self.state_done)\n            and self.server_state not in (self.state_done, self.state_errored)\n        )\n        need_error_hook = not (\n            self.client_state == self.state_errored\n            or self.server_state in (self.state_done, self.state_errored)\n        )\n\n        if is_client_error_but_we_already_talk_upstream:\n            yield SendHttp(event, self.context.server)\n            self.client_state = self.state_errored\n\n        if need_error_hook:\n            # We don't want to trigger both a response hook and an error hook,\n            # so we need to check if the response is done yet or not.\n            self.flow.error = flow.Error(event.message)\n            yield HttpErrorHook(self.flow)\n\n        if (yield from self.check_killed(False)):\n            return\n\n        if isinstance(event, ResponseProtocolError):\n            if self.client_state != self.state_errored:\n                yield SendHttp(event, self.context.client)\n            self.server_state = self.state_errored\n\n        self.flow.live = False\n        yield DropStream(self.stream_id)\n\n    def make_server_connection(self) -> layer.CommandGenerator[bool]:\n        connection, err = yield GetHttpConnection(\n            (self.flow.request.host, self.flow.request.port),\n            self.flow.request.scheme == \"https\",\n            self.flow.server_conn.via,\n            self.flow.server_conn.transport_protocol,\n        )\n        if err:\n            yield from self.handle_protocol_error(\n                ResponseProtocolError(self.stream_id, err)\n            )\n            return False\n        else:\n            self.context.server = self.flow.server_conn = connection\n            return True\n\n    def handle_connect(self) -> layer.CommandGenerator[None]:\n        self.client_state = self.state_done\n        yield HttpConnectHook(self.flow)\n        if (yield from self.check_killed(False)):\n            return\n\n        self.context.server.address = (self.flow.request.host, self.flow.request.port)\n\n        if self.mode == HTTPMode.regular:\n            yield from self.handle_connect_regular()\n        else:\n            yield from self.handle_connect_upstream()\n\n    def handle_connect_regular(self):\n        if (\n            not self.flow.response\n            and self.context.options.connection_strategy == \"eager\"\n        ):\n            err = yield commands.OpenConnection(self.context.server)\n            if err:\n                self.flow.response = http.Response.make(\n                    502,\n                    f\"Cannot connect to {human.format_address(self.context.server.address)}: {err} \"\n                    f\"If you plan to redirect requests away from this server, \"\n                    f\"consider setting `connection_strategy` to `lazy` to suppress early connections.\",\n                )\n        self.child_layer = layer.NextLayer(self.context)\n        yield from self.handle_connect_finish()\n\n    def handle_connect_upstream(self):\n        self.child_layer = _upstream_proxy.HttpUpstreamProxy.make(self.context, True)[0]\n        yield from self.handle_connect_finish()\n\n    def handle_connect_finish(self):\n        if not self.flow.response:\n            # Do not send any response headers as it breaks proxying non-80 ports on\n            # Android emulators using the -http-proxy option.\n            self.flow.response = http.Response(\n                self.flow.request.data.http_version,\n                200,\n                b\"Connection established\",\n                http.Headers(),\n                b\"\",\n                None,\n                time.time(),\n                time.time(),\n            )\n\n        if 200 <= self.flow.response.status_code < 300:\n            yield HttpConnectedHook(self.flow)\n            self.child_layer = self.child_layer or layer.NextLayer(self.context)\n            self._handle_event = self.passthrough\n            yield from self.child_layer.handle_event(events.Start())\n        else:\n            yield HttpConnectErrorHook(self.flow)\n            self.client_state = self.state_errored\n            self.flow.live = False\n\n        content = self.flow.response.raw_content\n        done_after_headers = not (content or self.flow.response.trailers)\n        yield SendHttp(\n            ResponseHeaders(self.stream_id, self.flow.response, done_after_headers),\n            self.context.client,\n        )\n        if content:\n            yield SendHttp(ResponseData(self.stream_id, content), self.context.client)\n\n        if self.flow.response.trailers:\n            yield SendHttp(\n                ResponseTrailers(self.stream_id, self.flow.response.trailers),\n                self.context.client,\n            )\n        yield SendHttp(ResponseEndOfMessage(self.stream_id), self.context.client)\n\n    @expect(RequestData, RequestEndOfMessage, events.Event)\n    def passthrough(self, event: events.Event) -> layer.CommandGenerator[None]:\n        assert self.flow.response\n        assert self.child_layer\n        # HTTP events -> normal connection events\n        if isinstance(event, RequestData):\n            event = events.DataReceived(self.context.client, event.data)\n        elif isinstance(event, ResponseData):\n            event = events.DataReceived(self.context.server, event.data)\n        elif isinstance(event, RequestEndOfMessage):\n            event = events.ConnectionClosed(self.context.client)\n        elif isinstance(event, ResponseEndOfMessage):\n            event = events.ConnectionClosed(self.context.server)\n\n        for command in self.child_layer.handle_event(event):\n            # normal connection events -> HTTP events\n            if isinstance(command, commands.SendData):\n                if command.connection == self.context.client:\n                    yield SendHttp(\n                        ResponseData(self.stream_id, command.data), self.context.client\n                    )\n                elif (\n                    command.connection == self.context.server\n                    and self.flow.response.status_code == 101\n                ):\n                    # there only is a HTTP server connection if we have switched protocols,\n                    # not if a connection is established via CONNECT.\n                    yield SendHttp(\n                        RequestData(self.stream_id, command.data), self.context.server\n                    )\n                else:\n                    yield command\n            elif isinstance(command, commands.CloseConnection):\n                if command.connection == self.context.client:\n                    yield SendHttp(\n                        ResponseProtocolError(self.stream_id, \"EOF\"),\n                        self.context.client,\n                    )\n                elif (\n                    command.connection == self.context.server\n                    and self.flow.response.status_code == 101\n                ):\n                    yield SendHttp(\n                        RequestProtocolError(self.stream_id, \"EOF\"), self.context.server\n                    )\n                else:\n                    # If we are running TCP over HTTP we want to be consistent with half-closes.\n                    # The easiest approach for this is to just always full close for now.\n                    # Alternatively, we could signal that we want a half close only through ResponseProtocolError,\n                    # but that is more complex to implement.\n                    if isinstance(command, commands.CloseTcpConnection):\n                        command = commands.CloseConnection(command.connection)\n                    yield command\n            else:\n                yield command\n\n    @expect()\n    def state_uninitialized(self, _) -> layer.CommandGenerator[None]:\n        yield from ()\n\n    @expect()\n    def state_done(self, _) -> layer.CommandGenerator[None]:\n        yield from ()\n\n    def state_errored(self, _) -> layer.CommandGenerator[None]:\n        # silently consume every event.\n        yield from ()\n\n\nclass HttpLayer(layer.Layer):\n    \"\"\"\n    ConnectionEvent: We have received b\"GET /\\r\\n\\r\\n\" from the client.\n    HttpEvent: We have received request headers\n    HttpCommand: Send request headers to X\n    ConnectionCommand: Send b\"GET /\\r\\n\\r\\n\" to server.\n\n    ConnectionEvent -> HttpEvent -> HttpCommand -> ConnectionCommand\n    \"\"\"\n\n    mode: HTTPMode\n    command_sources: dict[commands.Command, layer.Layer]\n    streams: dict[int, HttpStream]\n    connections: dict[Connection, layer.Layer]\n    waiting_for_establishment: collections.defaultdict[\n        Connection, list[GetHttpConnection]\n    ]\n\n    def __init__(self, context: Context, mode: HTTPMode):\n        super().__init__(context)\n        self.mode = mode\n\n        self.waiting_for_establishment = collections.defaultdict(list)\n        self.streams = {}\n        self.command_sources = {}\n        self.connections = {}\n\n    def __repr__(self):\n        return f\"HttpLayer({self.mode.name}, conns: {len(self.connections)})\"\n\n    def _handle_event(self, event: events.Event):\n        if isinstance(event, events.Start):\n            http_conn: HttpConnection\n            if is_h3_alpn(self.context.client.alpn):\n                http_conn = Http3Server(self.context.fork())\n            elif self.context.client.alpn == b\"h2\":\n                http_conn = Http2Server(self.context.fork())\n            else:\n                http_conn = Http1Server(self.context.fork())\n\n            # may have been set by client playback.\n            self.connections.setdefault(self.context.client, http_conn)\n            yield from self.event_to_child(self.connections[self.context.client], event)\n            if self.mode is HTTPMode.upstream:\n                proxy_mode = self.context.client.proxy_mode\n                assert isinstance(proxy_mode, UpstreamMode)\n                self.context.server.via = (proxy_mode.scheme, proxy_mode.address)\n        elif isinstance(event, events.CommandCompleted):\n            stream = self.command_sources.pop(event.command)\n            yield from self.event_to_child(stream, event)\n        elif isinstance(event, events.MessageInjected):\n            # For injected messages we pass the HTTP stacks entirely and directly address the stream.\n            try:\n                conn = self.connections[event.flow.server_conn]\n            except KeyError:\n                # We have a miss for the server connection, which means we're looking at a connection object\n                # that is tunneled over another connection (for example: over an upstream HTTP proxy).\n                # We now take the stream associated with the client connection. That won't work for HTTP/2,\n                # but it's good enough for HTTP/1.\n                conn = self.connections[event.flow.client_conn]\n            if isinstance(conn, HttpStream):\n                stream_id = conn.stream_id\n            else:\n                # We reach to the end of the connection's child stack to get the HTTP/1 client layer,\n                # which tells us which stream we are dealing with.\n                conn = conn.context.layers[-1]\n                assert isinstance(conn, Http1Connection)\n                assert conn.stream_id\n                stream_id = conn.stream_id\n            yield from self.event_to_child(self.streams[stream_id], event)\n        elif isinstance(event, events.ConnectionEvent):\n            if (\n                event.connection == self.context.server\n                and self.context.server not in self.connections\n            ):\n                # We didn't do anything with this connection yet, now the peer is doing something.\n                if isinstance(event, events.ConnectionClosed):\n                    # The peer has closed it - let's close it too!\n                    yield commands.CloseConnection(event.connection)\n                elif isinstance(event, (events.DataReceived, QuicStreamEvent)):\n                    # The peer has sent data or another connection activity occurred.\n                    # This can happen with HTTP/2 servers that already send a settings frame.\n                    child_layer: HttpConnection\n                    if is_h3_alpn(self.context.server.alpn):\n                        child_layer = Http3Client(self.context.fork())\n                    elif self.context.server.alpn == b\"h2\":\n                        child_layer = Http2Client(self.context.fork())\n                    else:\n                        child_layer = Http1Client(self.context.fork())\n                    self.connections[self.context.server] = child_layer\n                    yield from self.event_to_child(child_layer, events.Start())\n                    yield from self.event_to_child(child_layer, event)\n                else:\n                    raise AssertionError(f\"Unexpected event: {event}\")\n            else:\n                handler = self.connections[event.connection]\n                yield from self.event_to_child(handler, event)\n        else:\n            raise AssertionError(f\"Unexpected event: {event}\")\n\n    def event_to_child(\n        self,\n        child: layer.Layer | HttpStream,\n        event: events.Event,\n    ) -> layer.CommandGenerator[None]:\n        for command in child.handle_event(event):\n            assert isinstance(command, commands.Command)\n            # Streams may yield blocking commands, which ultimately generate CommandCompleted events.\n            # Those need to be routed back to the correct stream, so we need to keep track of that.\n\n            if command.blocking or isinstance(command, commands.RequestWakeup):\n                self.command_sources[command] = child\n\n            if isinstance(command, ReceiveHttp):\n                if isinstance(command.event, RequestHeaders):\n                    yield from self.make_stream(command.event.stream_id)\n                try:\n                    stream = self.streams[command.event.stream_id]\n                except KeyError:\n                    # We may be getting data or errors for a stream even though we've already finished handling it,\n                    # see for example https://github.com/mitmproxy/mitmproxy/issues/5343.\n                    pass\n                else:\n                    yield from self.event_to_child(stream, command.event)\n            elif isinstance(command, SendHttp):\n                conn = self.connections[command.connection]\n                yield from self.event_to_child(conn, command.event)\n            elif isinstance(command, DropStream):\n                self.streams.pop(command.stream_id, None)\n            elif isinstance(command, GetHttpConnection):\n                yield from self.get_connection(command)\n            elif isinstance(command, RegisterHttpConnection):\n                yield from self.register_connection(command)\n            elif isinstance(command, commands.OpenConnection):\n                self.connections[command.connection] = child\n                yield command\n            elif isinstance(command, commands.Command):\n                yield command\n            else:\n                raise AssertionError(f\"Not a command: {event}\")\n\n    def make_stream(self, stream_id: int) -> layer.CommandGenerator[None]:\n        ctx = self.context.fork()\n        self.streams[stream_id] = HttpStream(ctx, stream_id)\n        yield from self.event_to_child(self.streams[stream_id], events.Start())\n\n    def get_connection(\n        self, event: GetHttpConnection, *, reuse: bool = True\n    ) -> layer.CommandGenerator[None]:\n        # Do we already have a connection we can re-use?\n        if reuse:\n            for connection in self.connections:\n                connection_suitable = event.connection_spec_matches(connection)\n                if connection_suitable:\n                    if connection in self.waiting_for_establishment:\n                        self.waiting_for_establishment[connection].append(event)\n                        return\n                    elif connection.error:\n                        stream = self.command_sources.pop(event)\n                        yield from self.event_to_child(\n                            stream,\n                            GetHttpConnectionCompleted(event, (None, connection.error)),\n                        )\n                        return\n                    elif connection.connected:\n                        # see \"tricky multiplexing edge case\" in make_http_connection for an explanation\n                        h2_to_h1 = (\n                            self.context.client.alpn == b\"h2\"\n                            and connection.alpn != b\"h2\"\n                        )\n                        if not h2_to_h1:\n                            stream = self.command_sources.pop(event)\n                            yield from self.event_to_child(\n                                stream,\n                                GetHttpConnectionCompleted(event, (connection, None)),\n                            )\n                            return\n                    else:\n                        pass  # the connection is at least half-closed already, we want a new one.\n\n        context_connection_matches = (\n            self.context.server not in self.connections\n            and event.connection_spec_matches(self.context.server)\n        )\n        can_use_context_connection = (\n            context_connection_matches and self.context.server.connected\n        )\n        if context_connection_matches and self.context.server.error:\n            stream = self.command_sources.pop(event)\n            yield from self.event_to_child(\n                stream,\n                GetHttpConnectionCompleted(event, (None, self.context.server.error)),\n            )\n            return\n\n        context = self.context.fork()\n\n        stack = tunnel.LayerStack()\n\n        if not can_use_context_connection:\n            context.server = Server(\n                address=event.address, transport_protocol=event.transport_protocol\n            )\n\n            if event.via:\n                context.server.via = event.via\n                # We always send a CONNECT request, *except* for plaintext absolute-form HTTP requests in upstream mode.\n                send_connect = event.tls or self.mode != HTTPMode.upstream\n                stack /= _upstream_proxy.HttpUpstreamProxy.make(context, send_connect)\n            if event.tls:\n                # Assume that we are in transparent mode and lazily did not open a connection yet.\n                # We don't want the IP (which is the address) as the upstream SNI, but the client's SNI instead.\n                if (\n                    self.mode == HTTPMode.transparent\n                    and event.address == self.context.server.address\n                ):\n                    # reverse proxy mode may set self.context.server.sni, which takes precedence.\n                    context.server.sni = (\n                        self.context.server.sni\n                        or self.context.client.sni\n                        or event.address[0]\n                    )\n                else:\n                    context.server.sni = event.address[0]\n                if context.server.transport_protocol == \"tcp\":\n                    stack /= tls.ServerTLSLayer(context)\n                elif context.server.transport_protocol == \"udp\":\n                    stack /= quic.ServerQuicLayer(context)\n                else:\n                    raise AssertionError(\n                        context.server.transport_protocol\n                    )  # pragma: no cover\n\n        stack /= HttpClient(context)\n\n        self.connections[context.server] = stack[0]\n        self.waiting_for_establishment[context.server].append(event)\n\n        yield from self.event_to_child(stack[0], events.Start())\n\n    def register_connection(\n        self, command: RegisterHttpConnection\n    ) -> layer.CommandGenerator[None]:\n        waiting = self.waiting_for_establishment.pop(command.connection)\n\n        reply: tuple[None, str] | tuple[Connection, None]\n        if command.err:\n            reply = (None, command.err)\n        else:\n            reply = (command.connection, None)\n\n        for cmd in waiting:\n            stream = self.command_sources.pop(cmd)\n            yield from self.event_to_child(\n                stream, GetHttpConnectionCompleted(cmd, reply)\n            )\n\n            # Tricky multiplexing edge case: Assume we are doing HTTP/2 -> HTTP/1 proxying and the destination server\n            # only serves responses with HTTP read-until-EOF semantics. In this case we can't process two flows on the\n            # same connection. The only workaround left is to open a separate connection for each flow.\n            if (\n                not command.err\n                and self.context.client.alpn == b\"h2\"\n                and command.connection.alpn != b\"h2\"\n            ):\n                for cmd in waiting[1:]:\n                    yield from self.get_connection(cmd, reuse=False)\n                break\n\n\nclass HttpClient(layer.Layer):\n    child_layer: layer.Layer\n\n    @expect(events.Start)\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        err: str | None\n        if self.context.server.connected:\n            err = None\n        else:\n            err = yield commands.OpenConnection(self.context.server)\n        if not err:\n            if is_h3_alpn(self.context.server.alpn):\n                self.child_layer = Http3Client(self.context)\n            elif self.context.server.alpn == b\"h2\":\n                self.child_layer = Http2Client(self.context)\n            else:\n                self.child_layer = Http1Client(self.context)\n            self._handle_event = self.child_layer.handle_event\n            yield from self._handle_event(event)\n        yield RegisterHttpConnection(self.context.server, err)\n", "mitmproxy/proxy/layers/http/_http3.py": "import time\nfrom abc import abstractmethod\n\nfrom aioquic.h3.connection import ErrorCode as H3ErrorCode\nfrom aioquic.h3.connection import FrameUnexpected as H3FrameUnexpected\nfrom aioquic.h3.events import DataReceived\nfrom aioquic.h3.events import HeadersReceived\nfrom aioquic.h3.events import PushPromiseReceived\n\nfrom . import RequestData\nfrom . import RequestEndOfMessage\nfrom . import RequestHeaders\nfrom . import RequestProtocolError\nfrom . import RequestTrailers\nfrom . import ResponseData\nfrom . import ResponseEndOfMessage\nfrom . import ResponseHeaders\nfrom . import ResponseProtocolError\nfrom . import ResponseTrailers\nfrom ._base import format_error\nfrom ._base import HttpConnection\nfrom ._base import HttpEvent\nfrom ._base import ReceiveHttp\nfrom ._http2 import format_h2_request_headers\nfrom ._http2 import format_h2_response_headers\nfrom ._http2 import parse_h2_request_headers\nfrom ._http2 import parse_h2_response_headers\nfrom ._http_h3 import LayeredH3Connection\nfrom ._http_h3 import StreamReset\nfrom ._http_h3 import TrailersReceived\nfrom mitmproxy import connection\nfrom mitmproxy import http\nfrom mitmproxy import version\nfrom mitmproxy.net.http import status_codes\nfrom mitmproxy.proxy import commands\nfrom mitmproxy.proxy import context\nfrom mitmproxy.proxy import events\nfrom mitmproxy.proxy import layer\nfrom mitmproxy.proxy.layers.quic import error_code_to_str\nfrom mitmproxy.proxy.layers.quic import QuicConnectionClosed\nfrom mitmproxy.proxy.layers.quic import QuicStreamEvent\nfrom mitmproxy.proxy.layers.quic import StopQuicStream\nfrom mitmproxy.proxy.utils import expect\n\n\nclass Http3Connection(HttpConnection):\n    h3_conn: LayeredH3Connection\n\n    ReceiveData: type[RequestData | ResponseData]\n    ReceiveEndOfMessage: type[RequestEndOfMessage | ResponseEndOfMessage]\n    ReceiveProtocolError: type[RequestProtocolError | ResponseProtocolError]\n    ReceiveTrailers: type[RequestTrailers | ResponseTrailers]\n\n    def __init__(self, context: context.Context, conn: connection.Connection):\n        super().__init__(context, conn)\n        self.h3_conn = LayeredH3Connection(\n            self.conn, is_client=self.conn is self.context.server\n        )\n        self._stream_protocol_errors: dict[int, int] = {}\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        if isinstance(event, events.Start):\n            yield from self.h3_conn.transmit()\n\n        # send mitmproxy HTTP events over the H3 connection\n        elif isinstance(event, HttpEvent):\n            try:\n                if isinstance(event, (RequestData, ResponseData)):\n                    self.h3_conn.send_data(event.stream_id, event.data)\n                elif isinstance(event, (RequestHeaders, ResponseHeaders)):\n                    headers = yield from (\n                        format_h2_request_headers(self.context, event)\n                        if isinstance(event, RequestHeaders)\n                        else format_h2_response_headers(self.context, event)\n                    )\n                    self.h3_conn.send_headers(\n                        event.stream_id, headers, end_stream=event.end_stream\n                    )\n                elif isinstance(event, (RequestTrailers, ResponseTrailers)):\n                    self.h3_conn.send_trailers(\n                        event.stream_id, [*event.trailers.fields]\n                    )\n                elif isinstance(event, (RequestEndOfMessage, ResponseEndOfMessage)):\n                    self.h3_conn.end_stream(event.stream_id)\n                elif isinstance(event, (RequestProtocolError, ResponseProtocolError)):\n                    code = {\n                        status_codes.CLIENT_CLOSED_REQUEST: H3ErrorCode.H3_REQUEST_CANCELLED.value,\n                    }.get(event.code, H3ErrorCode.H3_INTERNAL_ERROR.value)\n                    self._stream_protocol_errors[event.stream_id] = code\n                    send_error_message = (\n                        isinstance(event, ResponseProtocolError)\n                        and not self.h3_conn.has_sent_headers(event.stream_id)\n                        and event.code != status_codes.NO_RESPONSE\n                    )\n                    if send_error_message:\n                        self.h3_conn.send_headers(\n                            event.stream_id,\n                            [\n                                (b\":status\", b\"%d\" % event.code),\n                                (b\"server\", version.MITMPROXY.encode()),\n                                (b\"content-type\", b\"text/html\"),\n                            ],\n                        )\n                        self.h3_conn.send_data(\n                            event.stream_id,\n                            format_error(event.code, event.message),\n                            end_stream=True,\n                        )\n                    else:\n                        self.h3_conn.reset_stream(event.stream_id, code)\n                else:  # pragma: no cover\n                    raise AssertionError(f\"Unexpected event: {event!r}\")\n\n            except H3FrameUnexpected as e:\n                # Http2Connection also ignores HttpEvents that violate the current stream state\n                yield commands.Log(f\"Received {event!r} unexpectedly: {e}\")\n\n            else:\n                # transmit buffered data\n                yield from self.h3_conn.transmit()\n\n        # forward stream messages from the QUIC layer to the H3 connection\n        elif isinstance(event, QuicStreamEvent):\n            h3_events = self.h3_conn.handle_stream_event(event)\n            if event.stream_id in self._stream_protocol_errors:\n                # we already reset or ended the stream, tell the peer to stop\n                # (this is a noop if the peer already did the same)\n                yield StopQuicStream(\n                    self.conn,\n                    event.stream_id,\n                    self._stream_protocol_errors[event.stream_id],\n                )\n            else:\n                for h3_event in h3_events:\n                    if isinstance(h3_event, StreamReset):\n                        if h3_event.push_id is None:\n                            err_str = error_code_to_str(h3_event.error_code)\n                            err_code = {\n                                H3ErrorCode.H3_REQUEST_CANCELLED.value: status_codes.CLIENT_CLOSED_REQUEST,\n                            }.get(h3_event.error_code, self.ReceiveProtocolError.code)\n                            yield ReceiveHttp(\n                                self.ReceiveProtocolError(\n                                    h3_event.stream_id,\n                                    f\"stream reset by client ({err_str})\",\n                                    code=err_code,\n                                )\n                            )\n                    elif isinstance(h3_event, DataReceived):\n                        if h3_event.push_id is None:\n                            if h3_event.data:\n                                yield ReceiveHttp(\n                                    self.ReceiveData(h3_event.stream_id, h3_event.data)\n                                )\n                            if h3_event.stream_ended:\n                                yield ReceiveHttp(\n                                    self.ReceiveEndOfMessage(h3_event.stream_id)\n                                )\n                    elif isinstance(h3_event, HeadersReceived):\n                        if h3_event.push_id is None:\n                            try:\n                                receive_event = self.parse_headers(h3_event)\n                            except ValueError as e:\n                                self.h3_conn.close_connection(\n                                    error_code=H3ErrorCode.H3_GENERAL_PROTOCOL_ERROR,\n                                    reason_phrase=f\"Invalid HTTP/3 request headers: {e}\",\n                                )\n                            else:\n                                yield ReceiveHttp(receive_event)\n                                if h3_event.stream_ended:\n                                    yield ReceiveHttp(\n                                        self.ReceiveEndOfMessage(h3_event.stream_id)\n                                    )\n                    elif isinstance(h3_event, TrailersReceived):\n                        if h3_event.push_id is None:\n                            yield ReceiveHttp(\n                                self.ReceiveTrailers(\n                                    h3_event.stream_id, http.Headers(h3_event.trailers)\n                                )\n                            )\n                            if h3_event.stream_ended:\n                                yield ReceiveHttp(\n                                    self.ReceiveEndOfMessage(h3_event.stream_id)\n                                )\n                    elif isinstance(h3_event, PushPromiseReceived):  # pragma: no cover\n                        # we don't support push\n                        pass\n                    else:  # pragma: no cover\n                        raise AssertionError(f\"Unexpected event: {event!r}\")\n            yield from self.h3_conn.transmit()\n\n        # report a protocol error for all remaining open streams when a connection is closed\n        elif isinstance(event, QuicConnectionClosed):\n            self._handle_event = self.done  # type: ignore\n            self.h3_conn.handle_connection_closed(event)\n            msg = event.reason_phrase or error_code_to_str(event.error_code)\n            for stream_id in self.h3_conn.get_open_stream_ids(push_id=None):\n                yield ReceiveHttp(self.ReceiveProtocolError(stream_id, msg))\n\n        else:  # pragma: no cover\n            raise AssertionError(f\"Unexpected event: {event!r}\")\n\n    @expect(HttpEvent, QuicStreamEvent, QuicConnectionClosed)\n    def done(self, _) -> layer.CommandGenerator[None]:\n        yield from ()\n\n    @abstractmethod\n    def parse_headers(self, event: HeadersReceived) -> RequestHeaders | ResponseHeaders:\n        pass  # pragma: no cover\n\n\nclass Http3Server(Http3Connection):\n    ReceiveData = RequestData\n    ReceiveEndOfMessage = RequestEndOfMessage\n    ReceiveProtocolError = RequestProtocolError\n    ReceiveTrailers = RequestTrailers\n\n    def __init__(self, context: context.Context):\n        super().__init__(context, context.client)\n\n    def parse_headers(self, event: HeadersReceived) -> RequestHeaders | ResponseHeaders:\n        # same as HTTP/2\n        (\n            host,\n            port,\n            method,\n            scheme,\n            authority,\n            path,\n            headers,\n        ) = parse_h2_request_headers(event.headers)\n        request = http.Request(\n            host=host,\n            port=port,\n            method=method,\n            scheme=scheme,\n            authority=authority,\n            path=path,\n            http_version=b\"HTTP/3\",\n            headers=headers,\n            content=None,\n            trailers=None,\n            timestamp_start=time.time(),\n            timestamp_end=None,\n        )\n        return RequestHeaders(event.stream_id, request, end_stream=event.stream_ended)\n\n\nclass Http3Client(Http3Connection):\n    ReceiveData = ResponseData\n    ReceiveEndOfMessage = ResponseEndOfMessage\n    ReceiveProtocolError = ResponseProtocolError\n    ReceiveTrailers = ResponseTrailers\n\n    our_stream_id: dict[int, int]\n    their_stream_id: dict[int, int]\n\n    def __init__(self, context: context.Context):\n        super().__init__(context, context.server)\n        self.our_stream_id = {}\n        self.their_stream_id = {}\n\n    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:\n        # QUIC and HTTP/3 would actually allow for direct stream ID mapping, but since we want\n        # to support H2<->H3, we need to translate IDs.\n        # NOTE: We always create bidirectional streams, as we can't safely infer unidirectionality.\n        if isinstance(event, HttpEvent):\n            ours = self.our_stream_id.get(event.stream_id, None)\n            if ours is None:\n                ours = self.h3_conn.get_next_available_stream_id()\n                self.our_stream_id[event.stream_id] = ours\n                self.their_stream_id[ours] = event.stream_id\n            event.stream_id = ours\n\n        for cmd in super()._handle_event(event):\n            if isinstance(cmd, ReceiveHttp):\n                cmd.event.stream_id = self.their_stream_id[cmd.event.stream_id]\n            yield cmd\n\n    def parse_headers(self, event: HeadersReceived) -> RequestHeaders | ResponseHeaders:\n        # same as HTTP/2\n        status_code, headers = parse_h2_response_headers(event.headers)\n        response = http.Response(\n            http_version=b\"HTTP/3\",\n            status_code=status_code,\n            reason=b\"\",\n            headers=headers,\n            content=None,\n            trailers=None,\n            timestamp_start=time.time(),\n            timestamp_end=None,\n        )\n        return ResponseHeaders(event.stream_id, response, event.stream_ended)\n\n\n__all__ = [\n    \"Http3Client\",\n    \"Http3Server\",\n]\n"}