{"versioninfo.py": "import io\nimport os\nimport re\nimport sys\n\n__LXML_VERSION = None\n\n\ndef version():\n    global __LXML_VERSION\n    if __LXML_VERSION is None:\n        with open(os.path.join(get_base_dir(), 'src', 'lxml', '__init__.py')) as f:\n            __LXML_VERSION = re.search(r'__version__\\s*=\\s*\"([^\"]+)\"', f.read(250)).group(1)\n            assert __LXML_VERSION\n    return __LXML_VERSION\n\n\ndef branch_version():\n    return version()[:3]\n\n\ndef is_pre_release():\n    version_string = version()\n    return \"a\" in version_string or \"b\" in version_string\n\n\ndef dev_status():\n    _version = version()\n    if 'a' in _version:\n        return 'Development Status :: 3 - Alpha'\n    elif 'b' in _version or 'c' in _version:\n        return 'Development Status :: 4 - Beta'\n    else:\n        return 'Development Status :: 5 - Production/Stable'\n\n\ndef changes():\n    \"\"\"Extract part of changelog pertaining to version.\n    \"\"\"\n    _version = version()\n    with io.open(os.path.join(get_base_dir(), \"CHANGES.txt\"), 'r', encoding='utf8') as f:\n        lines = []\n        for line in f:\n            if line.startswith('====='):\n                if len(lines) > 1:\n                    break\n            if lines:\n                lines.append(line)\n            elif line.startswith(_version):\n                lines.append(line)\n    return ''.join(lines[:-1])\n\n\ndef create_version_h():\n    \"\"\"Create lxml-version.h\n    \"\"\"\n    lxml_version = version()\n    # make sure we have a triple part version number\n    parts = lxml_version.split('-')\n    while parts[0].count('.') < 2:\n        parts[0] += '.0'\n    lxml_version = '-'.join(parts).replace('a', '.alpha').replace('b', '.beta')\n\n    file_path = os.path.join(get_base_dir(), 'src', 'lxml', 'includes', 'lxml-version.h')\n\n    # Avoid changing file timestamp if content didn't change.\n    if os.path.isfile(file_path):\n        with open(file_path, 'r') as version_h:\n            if ('\"%s\"' % lxml_version) in version_h.read(100):\n                return\n\n    with open(file_path, 'w') as version_h:\n        version_h.write('''\\\n#ifndef LXML_VERSION_STRING\n#define LXML_VERSION_STRING \"%s\"\n#endif\n''' % lxml_version)\n\n\ndef get_base_dir():\n    return os.path.abspath(os.path.dirname(sys.argv[0]))\n", "update-error-constants.py": "#!/usr/bin/env python\n\nimport operator\nimport os.path\nimport sys\nimport xml.etree.ElementTree as ET\n\nBUILD_SOURCE_FILE = os.path.join(\"src\", \"lxml\", \"xmlerror.pxi\")\nBUILD_DEF_FILE    = os.path.join(\"src\", \"lxml\", \"includes\", \"xmlerror.pxd\")\n\n# map enum name to Python variable name and alignment for constant name\nENUM_MAP = {\n    'xmlErrorLevel'       : ('__ERROR_LEVELS',  'XML_ERR_'),\n    'xmlErrorDomain'      : ('__ERROR_DOMAINS', 'XML_FROM_'),\n    'xmlParserErrors'     : ('__PARSER_ERROR_TYPES',   'XML_'),\n#    'xmlXPathError'       : ('__XPATH_ERROR_TYPES',   ''),\n#    'xmlSchemaValidError' : ('__XMLSCHEMA_ERROR_TYPES',   'XML_'),\n    'xmlRelaxNGValidErr'  : ('__RELAXNG_ERROR_TYPES',   'XML_'),\n    }\n\nENUM_ORDER = (\n    'xmlErrorLevel',\n    'xmlErrorDomain',\n    'xmlParserErrors',\n#    'xmlXPathError',\n#    'xmlSchemaValidError',\n    'xmlRelaxNGValidErr')\n\nCOMMENT = \"\"\"\n# This section is generated by the script '%s'.\n\n\"\"\" % os.path.basename(sys.argv[0])\n\n\ndef split(lines):\n    lines = iter(lines)\n    pre = []\n    for line in lines:\n        pre.append(line)\n        if line.startswith('#') and \"BEGIN: GENERATED CONSTANTS\" in line:\n            break\n    pre.append('')\n    old = []\n    for line in lines:\n        if line.startswith('#') and \"END: GENERATED CONSTANTS\" in line:\n            break\n        old.append(line.rstrip('\\n'))\n    post = ['', line]\n    post.extend(lines)\n    post.append('')\n    return pre, old, post\n\n\ndef regenerate_file(filename, result):\n    new = COMMENT + '\\n'.join(result)\n\n    # read .pxi source file\n    with open(filename, 'r', encoding=\"utf-8\") as f:\n        pre, old, post = split(f)\n\n    if new.strip() == '\\n'.join(old).strip():\n        # no changes\n        return False\n\n    # write .pxi source file\n    with open(filename, 'w', encoding=\"utf-8\") as f:\n        f.write(''.join(pre))\n        f.write(new)\n        f.write(''.join(post))\n\n    return True\n\n\ndef parse_enums(doc_dir, api_filename, enum_dict):\n    tree = ET.parse(os.path.join(doc_dir, api_filename))\n    for enum in tree.iterfind('symbols/enum'):\n        enum_type = enum.get('type')\n        if enum_type not in ENUM_MAP:\n            continue\n        entries = enum_dict.get(enum_type)\n        if not entries:\n            print(\"Found enum\", enum_type)\n            entries = enum_dict[enum_type] = []\n        entries.append((\n            enum.get('name'),\n            int(enum.get('value')),\n            enum.get('info', '').strip(),\n        ))\n\n\ndef main(doc_dir):\n    enum_dict = {}\n    parse_enums(doc_dir, 'libxml2-api.xml',   enum_dict)\n    #parse_enums(doc_dir, 'libxml-xmlerror.html',   enum_dict)\n    #parse_enums(doc_dir, 'libxml-xpath.html',      enum_dict)\n    #parse_enums(doc_dir, 'libxml-xmlschemas.html', enum_dict)\n    #parse_enums(doc_dir, 'libxml-relaxng.html',    enum_dict)\n\n    # regenerate source files\n    pxi_result = []\n    append_pxi = pxi_result.append\n    pxd_result = []\n    append_pxd = pxd_result.append\n\n    append_pxd('cdef extern from \"libxml/xmlerror.h\":')\n\n    ctypedef_indent = ' '*4\n    constant_indent = ctypedef_indent*2\n\n    for enum_name in ENUM_ORDER:\n        constants = enum_dict[enum_name]\n        constants.sort(key=operator.itemgetter(1))\n        pxi_name, prefix = ENUM_MAP[enum_name]\n\n        append_pxd(ctypedef_indent + 'ctypedef enum %s:' % enum_name)\n        append_pxi('cdef object %s = \"\"\"\\\\' % pxi_name)\n\n        prefix_len = len(prefix)\n        length = 2  # each string ends with '\\n\\0'\n        for name, val, descr in constants:\n            if descr and descr != str(val):\n                line = '%-50s = %7d # %s' % (name, val, descr)\n            else:\n                line = '%-50s = %7d' % (name, val)\n            append_pxd(constant_indent + line)\n\n            if name[:prefix_len] == prefix and len(name) > prefix_len:\n                name = name[prefix_len:]\n            line = '%s=%d' % (name, val)\n            append_pxi(line)\n            length += len(line) + 2  # + '\\n\\0'\n\n        append_pxd('')\n        append_pxi('\"\"\"')\n        append_pxi('')\n\n    # write source files\n    print(\"Updating file %s\" % BUILD_SOURCE_FILE)\n    updated = regenerate_file(BUILD_SOURCE_FILE, pxi_result)\n    if not updated:\n        print(\"No changes.\")\n\n    print(\"Updating file %s\" % BUILD_DEF_FILE)\n    updated = regenerate_file(BUILD_DEF_FILE,    pxd_result)\n    if not updated:\n        print(\"No changes.\")\n\n    print(\"Done\")\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) < 2 or sys.argv[1].lower() in ('-h', '--help'):\n        print(\"This script generates the constants in file %s\" % BUILD_SOURCE_FILE)\n        print(\"Call as\")\n        print(sys.argv[0], \"/path/to/libxml2-doc-dir\")\n        sys.exit(len(sys.argv) > 1)\n\n    main(sys.argv[1])\n", "download_artefacts.py": "#!/usr/bin/python3\n\nimport json\nimport logging\nimport shutil\nimport datetime\n\nfrom concurrent.futures import ProcessPoolExecutor as Pool, as_completed\nfrom pathlib import Path\nfrom urllib.request import urlopen, Request\nfrom urllib.parse import urljoin\n\nlogger = logging.getLogger()\n\nPARALLEL_DOWNLOADS = 6\nGITHUB_API_URL = \"https://api.github.com/repos/lxml/lxml\"\nAPPVEYOR_PACKAGE_URL = \"https://ci.appveyor.com/api/projects/scoder/lxml\"\nAPPVEYOR_BUILDJOBS_URL = \"https://ci.appveyor.com/api/buildjobs\"\n\n\ndef find_github_files(version, api_url=GITHUB_API_URL):\n    url = f\"{api_url}/releases/tags/lxml-{version}\"\n    release, _ = read_url(url, accept=\"application/vnd.github+json\", as_json=True)\n\n    for asset in release.get('assets', ()):\n        yield asset['browser_download_url']\n\n\ndef find_appveyor_files(version, base_package_url=APPVEYOR_PACKAGE_URL, base_job_url=APPVEYOR_BUILDJOBS_URL):\n    url = f\"{base_package_url}/history?recordsNumber=20\"\n    with urlopen(url) as p:\n        builds = json.load(p)[\"builds\"]\n\n    tag = f\"lxml-{version}\"\n    for build in builds:\n        if build['isTag'] and build['tag'] == tag:\n            build_id = build['buildId']\n            break\n    else:\n        logger.warning(f\"No appveyor build found for tag '{tag}'\")\n        return\n\n    build_url = f\"{base_package_url}/builds/{build_id}\"\n    with urlopen(build_url) as p:\n        jobs = json.load(p)[\"build\"][\"jobs\"]\n\n    for job in jobs:\n        artifacts_url = f\"{base_job_url}/{job['jobId']}/artifacts/\"\n\n        with urlopen(artifacts_url) as p:\n            for artifact in json.load(p):\n                yield urljoin(artifacts_url, artifact['fileName'])\n\n\ndef read_url(url, decode=True, accept=None, as_json=False):\n    if accept:\n        request = Request(url, headers={'Accept': accept})\n    else:\n        request = Request(url)\n\n    with urlopen(request) as res:\n        charset = _find_content_encoding(res)\n        content_type = res.headers.get('Content-Type')\n        data = res.read()\n\n    if decode:\n        data = data.decode(charset)\n    if as_json:\n        data = json.loads(data)\n    return data, content_type\n\n\ndef _find_content_encoding(response, default='iso8859-1'):\n    from email.message import Message\n    content_type = response.headers.get('Content-Type')\n    if content_type:\n        msg = Message()\n        msg.add_header('Content-Type', content_type)\n        charset = msg.get_content_charset(default)\n    else:\n        charset = default\n    return charset\n\n\ndef download1(wheel_url, dest_dir):\n    wheel_name = wheel_url.rsplit(\"/\", 1)[1]\n    logger.info(f\"Downloading {wheel_url} ...\")\n    with urlopen(wheel_url) as w:\n        file_path = dest_dir / wheel_name\n        if (file_path.exists()\n                and \"Content-Length\" in w.headers\n                and file_path.stat().st_size == int(w.headers[\"Content-Length\"])):\n            logger.info(f\"Already have {wheel_name}\")\n        else:\n            temp_file_path = file_path.with_suffix(\".tmp\")\n            try:\n                with open(temp_file_path, \"wb\") as f:\n                    shutil.copyfileobj(w, f)\n            except:\n                if temp_file_path.exists():\n                    temp_file_path.unlink()\n                raise\n            else:\n                temp_file_path.replace(file_path)\n                logger.info(f\"Finished downloading {wheel_name}\")\n    return wheel_name\n\n\ndef download(urls, dest_dir, jobs=PARALLEL_DOWNLOADS):\n    with Pool(max_workers=jobs) as pool:\n        futures = [pool.submit(download1, url, dest_dir) for url in urls]\n        try:\n            for future in as_completed(futures):\n                wheel_name = future.result()\n                yield wheel_name\n        except KeyboardInterrupt:\n            for future in futures:\n                future.cancel()\n            raise\n\n\ndef dedup(it):\n    seen = set()\n    for value in it:\n        if value not in seen:\n            seen.add(value)\n            yield value\n\n\ndef roundrobin(*iterables):\n    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n    # Recipe credited to George Sakkis\n    from itertools import cycle, islice\n    num_active = len(iterables)\n    nexts = cycle(iter(it).__next__ for it in iterables)\n    while num_active:\n        try:\n            for next in nexts:\n                yield next()\n        except StopIteration:\n            # Remove the iterator we just exhausted from the cycle.\n            num_active -= 1\n            nexts = cycle(islice(nexts, num_active))\n\n\ndef main(*args):\n    if not args:\n        print(\"Please pass the version to download\")\n        return\n\n    version = args[0]\n    dest_dir = Path(\"dist\") / version\n    if not dest_dir.is_dir():\n        dest_dir.mkdir()\n\n    start_time = datetime.datetime.now().replace(microsecond=0)\n    urls = roundrobin(*map(dedup, [\n        find_github_files(version),\n        find_appveyor_files(version),\n    ]))\n    count = sum(1 for _ in enumerate(download(urls, dest_dir)))\n    duration = datetime.datetime.now().replace(microsecond=0) - start_time\n    logger.info(f\"Downloaded {count} files in {duration}.\")\n\n\nif __name__ == \"__main__\":\n    import sys\n    logging.basicConfig(\n        stream=sys.stderr,\n        level=logging.INFO,\n        format=\"%(asctime)-15s  %(message)s\",\n    )\n    main(*sys.argv[1:])\n", "setup.py": "import os\nimport re\nimport sys\nimport fnmatch\nimport os.path\n\n# for command line options and supported environment variables, please\n# see the end of 'setupinfo.py'\n\nif sys.version_info[:2] < (3, 6):\n    print(\"This lxml version requires Python 3.6 or later.\")\n    sys.exit(1)\n\ntry:\n    from setuptools import setup\nexcept ImportError:\n    from distutils.core import setup\n\n# make sure Cython finds include files in the project directory and not outside\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nimport versioninfo\nimport setupinfo\n\n# override these and pass --static for a static build. See\n# doc/build.txt for more information. If you do not pass --static\n# changing this will have no effect.\ndef static_env_list(name, separator=None):\n    return [x.strip() for x in os.environ.get(name, \"\").split(separator) if x.strip()]\n\nSTATIC_INCLUDE_DIRS = static_env_list(\"LXML_STATIC_INCLUDE_DIRS\", separator=os.pathsep)\nSTATIC_LIBRARY_DIRS = static_env_list(\"LXML_STATIC_LIBRARY_DIRS\", separator=os.pathsep)\nSTATIC_CFLAGS = static_env_list(\"LXML_STATIC_CFLAGS\")\nSTATIC_BINARIES = static_env_list(\"LXML_STATIC_BINARIES\", separator=os.pathsep)\n\n# create lxml-version.h file\nversioninfo.create_version_h()\nlxml_version = versioninfo.version()\nprint(\"Building lxml version %s.\" % lxml_version)\n\nOPTION_RUN_TESTS = setupinfo.has_option('run-tests')\n\nbranch_link = \"\"\"\nAfter an official release of a new stable series, bug fixes may become\navailable at\nhttps://github.com/lxml/lxml/tree/lxml-%(branch_version)s .\nRunning ``easy_install lxml==%(branch_version)sbugfix`` will install\nthe unreleased branch state from\nhttps://github.com/lxml/lxml/tarball/lxml-%(branch_version)s#egg=lxml-%(branch_version)sbugfix\nas soon as a maintenance branch has been established.  Note that this\nrequires Cython to be installed at an appropriate version for the build.\n\n\"\"\"\n\nif versioninfo.is_pre_release():\n    branch_link = \"\"\n\n\nextra_options = {}\nif 'setuptools' in sys.modules:\n    extra_options['zip_safe'] = False\n    extra_options['python_requires'] = (\n        # NOTE: keep in sync with Trove classifier list below.\n        '>=3.6')\n\n    try:\n        import pkg_resources\n    except ImportError:\n        pass\n    else:\n        f = open(\"requirements.txt\", \"r\")\n        try:\n            deps = [str(req) for req in pkg_resources.parse_requirements(f)]\n        finally:\n            f.close()\n        extra_options['extras_require'] = {\n            'source': deps,\n            'cssselect': 'cssselect>=0.7',\n            'html5': 'html5lib',\n            'htmlsoup': 'BeautifulSoup4',\n            'html_clean': 'lxml_html_clean',\n        }\n\nextra_options.update(setupinfo.extra_setup_args())\n\nextra_options['package_data'] = {\n    'lxml': [\n        'etree.h',\n        'etree_api.h',\n        'lxml.etree.h',\n        'lxml.etree_api.h',\n        # Include Cython source files for better traceback output.\n        '*.pyx',\n        '*.pxi',\n    ],\n    'lxml.includes': [\n        '*.pxd', '*.h'\n        ],\n    'lxml.isoschematron':  [\n        'resources/rng/iso-schematron.rng',\n        'resources/xsl/*.xsl',\n        'resources/xsl/iso-schematron-xslt1/*.xsl',\n        'resources/xsl/iso-schematron-xslt1/readme.txt'\n        ],\n    }\n\nextra_options['package_dir'] = {\n        '': 'src'\n    }\n\nextra_options['packages'] = [\n        'lxml', 'lxml.includes', 'lxml.html', 'lxml.isoschematron'\n    ]\n\n\ndef setup_extra_options():\n    is_interesting_package = re.compile('^(libxml|libxslt|libexslt)$').match\n    is_interesting_header = re.compile(r'^(zconf|zlib|.*charset)\\.h$').match\n\n    def extract_files(directories, pattern='*'):\n        def get_files(root, dir_path, files):\n            return [ (root, dir_path, filename)\n                     for filename in fnmatch.filter(files, pattern) ]\n\n        file_list = []\n        for dir_path in directories:\n            dir_path = os.path.realpath(dir_path)\n            for root, dirs, files in os.walk(dir_path):\n                rel_dir = root[len(dir_path)+1:]\n                if is_interesting_package(rel_dir):\n                    file_list.extend(get_files(root, rel_dir, files))\n                elif not rel_dir:\n                    # include also top-level header files (zlib/iconv)\n                    file_list.extend(\n                        item for item in get_files(root, rel_dir, files)\n                        if is_interesting_header(item[-1])\n                    )\n        return file_list\n\n    def build_packages(files):\n        packages = {}\n        seen = set()\n        for root_path, rel_path, filename in files:\n            if filename in seen:\n                # libxml2/libxslt header filenames are unique\n                continue\n            seen.add(filename)\n            package_path = '.'.join(rel_path.split(os.sep))\n            if package_path in packages:\n                root, package_files = packages[package_path]\n                if root != root_path:\n                    print(\"WARNING: conflicting directories found for include package '%s': %s and %s\"\n                          % (package_path, root_path, root))\n                    continue\n            else:\n                package_files = []\n                packages[package_path] = (root_path, package_files)\n            package_files.append(filename)\n\n        return packages\n\n    # Copy Global Extra Options\n    extra_opts = dict(extra_options)\n\n    # Build ext modules\n    ext_modules = setupinfo.ext_modules(\n                    STATIC_INCLUDE_DIRS, STATIC_LIBRARY_DIRS,\n                    STATIC_CFLAGS, STATIC_BINARIES)\n    extra_opts['ext_modules'] = ext_modules\n\n    packages = extra_opts.get('packages', list())\n    package_dir = extra_opts.get('package_dir', dict())\n    package_data = extra_opts.get('package_data', dict())\n\n    # Add lxml.include with (lxml, libxslt headers...)\n    #   python setup.py build --static --static-deps install\n    #   python setup.py bdist_wininst --static\n    if setupinfo.OPTION_STATIC:\n        include_dirs = [] # keep them in order\n        for extension in ext_modules:\n            for inc_dir in extension.include_dirs:\n                if inc_dir not in include_dirs:\n                    include_dirs.append(inc_dir)\n\n        header_packages = build_packages(extract_files(include_dirs))\n\n        package_filename = \"__init__.py\"\n        for package_path, (root_path, filenames) in header_packages.items():\n            if not package_path:\n                # lxml.includes -> lxml.includes.extlibs\n                package_path = \"extlibs\"\n            package = 'lxml.includes.' + package_path\n            packages.append(package)\n\n            # create '__init__.py' to make sure it's considered a package\n            if package_filename not in filenames:\n                with open(os.path.join(root_path, package_filename), 'wb') as f:\n                    pass\n                filenames.append(package_filename)\n\n            assert package not in package_data\n            package_data[package] = filenames\n            assert package not in package_dir\n            package_dir[package] = root_path\n\n    return extra_opts\n\nsetup(\n    name = \"lxml\",\n    version = lxml_version,\n    author=\"lxml dev team\",\n    author_email=\"lxml-dev@lxml.de\",\n    maintainer=\"lxml dev team\",\n    maintainer_email=\"lxml-dev@lxml.de\",\n    license=\"BSD-3-Clause\",\n    url=\"https://lxml.de/\",\n    # Commented out because this causes distutils to emit warnings\n    # `Unknown distribution option: 'bugtrack_url'`\n    # which distract folks from real causes of problems when troubleshooting\n    # bugtrack_url=\"https://bugs.launchpad.net/lxml\",\n    project_urls={\n        \"Source\": \"https://github.com/lxml/lxml\",\n    },\n    description=(\n        \"Powerful and Pythonic XML processing library\"\n        \" combining libxml2/libxslt with the ElementTree API.\"\n    ),\n    long_description=(((\"\"\"\\\nlxml is a Pythonic, mature binding for the libxml2 and libxslt libraries.  It\nprovides safe and convenient access to these libraries using the ElementTree\nAPI.\n\nIt extends the ElementTree API significantly to offer support for XPath,\nRelaxNG, XML Schema, XSLT, C14N and much more.\n\nTo contact the project, go to the `project home page\n<https://lxml.de/>`_ or see our bug tracker at\nhttps://launchpad.net/lxml\n\nIn case you want to use the current in-development version of lxml,\nyou can get it from the github repository at\nhttps://github.com/lxml/lxml .  Note that this requires Cython to\nbuild the sources, see the build instructions on the project home\npage.  To the same end, running ``easy_install lxml==dev`` will\ninstall lxml from\nhttps://github.com/lxml/lxml/tarball/master#egg=lxml-dev if you have\nan appropriate version of Cython installed.\n\n\"\"\" + branch_link) % {\"branch_version\": versioninfo.branch_version()}) +\n                      versioninfo.changes()),\n    classifiers=[\n        versioninfo.dev_status(),\n        'Intended Audience :: Developers',\n        'Intended Audience :: Information Technology',\n        'License :: OSI Approved :: BSD License',\n        'Programming Language :: Cython',\n        # NOTE: keep in sync with 'python_requires' list above.\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.6',\n        'Programming Language :: Python :: 3.7',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n        'Programming Language :: C',\n        'Operating System :: OS Independent',\n        'Topic :: Text Processing :: Markup :: HTML',\n        'Topic :: Text Processing :: Markup :: XML',\n        'Topic :: Software Development :: Libraries :: Python Modules'\n    ],\n\n    **setup_extra_options()\n)\n\nif OPTION_RUN_TESTS:\n    print(\"Running tests.\")\n    import test\n    try:\n        sys.exit( test.main(sys.argv[:1]) )\n    except ImportError:\n        pass  # we assume that the binaries were not built with this setup.py run\n", "setupinfo.py": "import sys\nimport io\nimport os\nimport os.path\nimport subprocess\n\nfrom setuptools.command.build_ext import build_ext as _build_ext\nfrom distutils.core import Extension\nfrom distutils.errors import CompileError, DistutilsOptionError\nfrom versioninfo import get_base_dir\n\ntry:\n    import Cython.Compiler.Version\n    CYTHON_INSTALLED = True\nexcept ImportError:\n    CYTHON_INSTALLED = False\n\nEXT_MODULES = [\"lxml.etree\", \"lxml.objectify\"]\nCOMPILED_MODULES = [\n    \"lxml.builder\",\n    \"lxml._elementpath\",\n    \"lxml.html.diff\",\n    \"lxml.sax\",\n]\nHEADER_FILES = ['etree.h', 'etree_api.h']\n\nif hasattr(sys, 'pypy_version_info') or (\n        getattr(sys, 'implementation', None) and sys.implementation.name != 'cpython'):\n    # disable Cython compilation of Python modules in PyPy and other non-CPythons\n    del COMPILED_MODULES[:]\n\nSOURCE_PATH = \"src\"\nINCLUDE_PACKAGE_PATH = os.path.join(SOURCE_PATH, 'lxml', 'includes')\n\n_system_encoding = sys.getdefaultencoding()\nif _system_encoding is None:\n    _system_encoding = \"iso-8859-1\" # :-)\n\ndef decode_input(data):\n    if isinstance(data, str):\n        return data\n    return data.decode(_system_encoding)\n\ndef env_var(name):\n    value = os.getenv(name)\n    if value:\n        value = decode_input(value)\n        if sys.platform == 'win32' and ';' in value:\n            return value.split(';')\n        else:\n            return value.split()\n    else:\n        return []\n\n\ndef _prefer_reldirs(base_dir, dirs):\n    return [\n        os.path.relpath(path) if path.startswith(base_dir) else path\n        for path in dirs\n    ]\n\ndef ext_modules(static_include_dirs, static_library_dirs,\n                static_cflags, static_binaries):\n    global XML2_CONFIG, XSLT_CONFIG\n    if OPTION_BUILD_LIBXML2XSLT:\n        from buildlibxml import build_libxml2xslt, get_prebuilt_libxml2xslt\n        if sys.platform.startswith('win'):\n            get_prebuilt_libxml2xslt(\n                OPTION_DOWNLOAD_DIR, static_include_dirs, static_library_dirs)\n        else:\n            XML2_CONFIG, XSLT_CONFIG = build_libxml2xslt(\n                OPTION_DOWNLOAD_DIR, 'build/tmp',\n                static_include_dirs, static_library_dirs,\n                static_cflags, static_binaries,\n                libiconv_version=OPTION_LIBICONV_VERSION,\n                libxml2_version=OPTION_LIBXML2_VERSION,\n                libxslt_version=OPTION_LIBXSLT_VERSION,\n                zlib_version=OPTION_ZLIB_VERSION,\n                multicore=OPTION_MULTICORE)\n\n    modules = EXT_MODULES + COMPILED_MODULES\n    if OPTION_WITHOUT_OBJECTIFY:\n        modules = [entry for entry in modules if 'objectify' not in entry]\n\n    module_files = list(os.path.join(SOURCE_PATH, *module.split('.')) for module in modules)\n    c_files_exist = [os.path.exists(module + '.c') for module in module_files]\n\n    use_cython = True\n    if CYTHON_INSTALLED and (OPTION_WITH_CYTHON or not all(c_files_exist)):\n        print(\"Building with Cython %s.\" % Cython.Compiler.Version.version)\n        # generate module cleanup code\n        from Cython.Compiler import Options\n        Options.generate_cleanup_code = 3\n        Options.clear_to_none = False\n    elif not OPTION_WITHOUT_CYTHON and not all(c_files_exist):\n        for exists, module in zip(c_files_exist, module_files):\n            if not exists:\n                raise RuntimeError(\n                    \"ERROR: Trying to build without Cython, but pre-generated '%s.c' \"\n                    \"is not available (to ignore this error, pass --without-cython or \"\n                    \"set environment variable WITHOUT_CYTHON=true).\" % module)\n    else:\n        if not all(c_files_exist):\n            for exists, module in zip(c_files_exist, module_files):\n                if not exists:\n                    print(\"WARNING: Trying to build without Cython, but pre-generated \"\n                          \"'%s.c' is not available.\" % module)\n        use_cython = False\n        print(\"Building without Cython.\")\n\n    if not check_build_dependencies():\n        raise RuntimeError(\"Dependency missing\")\n\n    base_dir = get_base_dir()\n    _include_dirs = _prefer_reldirs(\n        base_dir, include_dirs(static_include_dirs) + [\n            SOURCE_PATH,\n            INCLUDE_PACKAGE_PATH,\n        ])\n    _library_dirs = _prefer_reldirs(base_dir, library_dirs(static_library_dirs))\n    _cflags = cflags(static_cflags)\n    _ldflags = ['-isysroot', get_xcode_isysroot()] if sys.platform == 'darwin' else None\n    _define_macros = define_macros()\n    _libraries = libraries()\n\n    if _library_dirs:\n        message = \"Building against libxml2/libxslt in \"\n        if len(_library_dirs) > 1:\n            print(message + \"one of the following directories:\")\n            for dir in _library_dirs:\n                print(\"  \" + dir)\n        else:\n            print(message + \"the following directory: \" +\n                  _library_dirs[0])\n\n    if OPTION_AUTO_RPATH:\n        runtime_library_dirs = _library_dirs\n    else:\n        runtime_library_dirs = []\n\n    if CYTHON_INSTALLED and OPTION_SHOW_WARNINGS:\n        from Cython.Compiler import Errors\n        Errors.LEVEL = 0\n\n    cythonize_directives = {\n        'binding': True,\n    }\n    if OPTION_WITH_COVERAGE:\n        cythonize_directives['linetrace'] = True\n\n    result = []\n    for module, src_file in zip(modules, module_files):\n        is_py = module in COMPILED_MODULES\n        main_module_source = src_file + (\n            '.c' if not use_cython else '.py' if is_py else '.pyx')\n        result.append(\n            Extension(\n                module,\n                sources = [main_module_source],\n                depends = find_dependencies(module),\n                extra_compile_args = _cflags,\n                extra_link_args = None if is_py else _ldflags,\n                extra_objects = None if is_py else static_binaries,\n                define_macros = _define_macros,\n                include_dirs = _include_dirs,\n                library_dirs = None if is_py else _library_dirs,\n                runtime_library_dirs = None if is_py else runtime_library_dirs,\n                libraries = None if is_py else _libraries,\n            ))\n    if CYTHON_INSTALLED and OPTION_WITH_CYTHON_GDB:\n        for ext in result:\n            ext.cython_gdb = True\n\n    if CYTHON_INSTALLED and use_cython:\n        # build .c files right now and convert Extension() objects\n        from Cython.Build import cythonize\n        result = cythonize(result, compiler_directives=cythonize_directives)\n\n        # Fix compiler warning due to missing pragma-push in Cython 3.0.9.\n        for ext in result:\n            for source_file in ext.sources:\n                if not source_file.endswith('.c'):\n                    continue\n                with open(source_file, 'rb') as f:\n                    lines = f.readlines()\n                if b'Generated by Cython 3.0.9' not in lines[0]:\n                    continue\n\n                modified = False\n                temp_file = source_file + \".tmp\"\n                with open(temp_file, 'wb') as f:\n                    last_was_push = False\n                    for line in lines:\n                        if b'#pragma GCC diagnostic ignored \"-Wincompatible-pointer-types\"' in line and not last_was_push:\n                            f.write(b\"#pragma GCC diagnostic push\\n\")\n                            modified = True\n                        last_was_push = b'#pragma GCC diagnostic push' in line\n                        f.write(line)\n\n                if modified:\n                    print(\"Fixed Cython 3.0.9 generated source file \" + source_file)\n                    os.unlink(source_file)\n                    os.rename(temp_file, source_file)\n                else:\n                    os.unlink(temp_file)\n\n    # for backwards compatibility reasons, provide \"etree[_api].h\" also as \"lxml.etree[_api].h\"\n    for header_filename in HEADER_FILES:\n        src_file = os.path.join(SOURCE_PATH, 'lxml', header_filename)\n        dst_file = os.path.join(SOURCE_PATH, 'lxml', 'lxml.' + header_filename)\n        if not os.path.exists(src_file):\n            continue\n        if os.path.exists(dst_file) and os.path.getmtime(dst_file) >= os.path.getmtime(src_file):\n            continue\n\n        with io.open(src_file, 'r', encoding='iso8859-1') as f:\n            content = f.read()\n        for filename in HEADER_FILES:\n            content = content.replace('\"%s\"' % filename, '\"lxml.%s\"' % filename)\n        with io.open(dst_file, 'w', encoding='iso8859-1') as f:\n            f.write(content)\n\n    return result\n\n\ndef find_dependencies(module):\n    if not CYTHON_INSTALLED or 'lxml.html' in module:\n        return []\n    base_dir = get_base_dir()\n    package_dir = os.path.join(base_dir, SOURCE_PATH, 'lxml')\n    includes_dir = os.path.join(base_dir, INCLUDE_PACKAGE_PATH)\n\n    pxd_files = [\n        os.path.join(INCLUDE_PACKAGE_PATH, filename)\n        for filename in os.listdir(includes_dir)\n        if filename.endswith('.pxd')\n    ]\n\n    if module == 'lxml.etree':\n        pxi_files = [\n            os.path.join(SOURCE_PATH, 'lxml', filename)\n            for filename in os.listdir(package_dir)\n            if filename.endswith('.pxi') and 'objectpath' not in filename\n        ]\n        pxd_files = [\n            filename for filename in pxd_files\n            if 'etreepublic' not in filename\n        ]\n    elif module == 'lxml.objectify':\n        pxi_files = [os.path.join(SOURCE_PATH, 'lxml', 'objectpath.pxi')]\n    else:\n        pxi_files = pxd_files = []\n\n    return pxd_files + pxi_files\n\n\ndef extra_setup_args():\n    class CheckLibxml2BuildExt(_build_ext):\n        \"\"\"Subclass to check whether libxml2 is really available if the build fails\"\"\"\n        def run(self):\n            try:\n                _build_ext.run(self)  # old-style class in Py2\n            except CompileError as e:\n                print('Compile failed: %s' % e)\n                if not seems_to_have_libxml2():\n                    print_libxml_error()\n                raise\n    result = {'cmdclass': {'build_ext': CheckLibxml2BuildExt}}\n    return result\n\n\ndef seems_to_have_libxml2():\n    from distutils import ccompiler\n    compiler = ccompiler.new_compiler()\n    return compiler.has_function(\n        'xmlXPathInit',\n        include_dirs=include_dirs([]) + ['/usr/include/libxml2'],\n        includes=['libxml/xpath.h'],\n        library_dirs=library_dirs([]),\n        libraries=['xml2'])\n\n\ndef print_libxml_error():\n    print('*********************************************************************************')\n    print('Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?')\n    if sys.platform in ('darwin',):\n        print('Perhaps try: xcode-select --install')\n    print('*********************************************************************************')\n\n\ndef libraries():\n    standard_libs = []\n    if 'linux' in sys.platform:\n        standard_libs.append('rt')\n    if not OPTION_BUILD_LIBXML2XSLT:\n        standard_libs.append('z')\n    standard_libs.append('m')\n\n    if sys.platform in ('win32',):\n        libs = ['libxslt', 'libexslt', 'libxml2', 'iconv']\n        if OPTION_STATIC:\n            libs = ['%s_a' % lib for lib in libs]\n        libs.extend(['zlib', 'WS2_32'])\n    elif OPTION_STATIC:\n        libs = standard_libs\n    else:\n        libs = ['xslt', 'exslt', 'xml2'] + standard_libs\n    return libs\n\ndef library_dirs(static_library_dirs):\n    if OPTION_STATIC:\n        if not static_library_dirs:\n            static_library_dirs = env_var('LIBRARY')\n        assert static_library_dirs, \"Static build not configured, see doc/build.txt\"\n        return static_library_dirs\n    # filter them from xslt-config --libs\n    result = []\n    possible_library_dirs = flags('libs')\n    for possible_library_dir in possible_library_dirs:\n        if possible_library_dir.startswith('-L'):\n            result.append(possible_library_dir[2:])\n    return result\n\ndef include_dirs(static_include_dirs):\n    if OPTION_STATIC:\n        if not static_include_dirs:\n            static_include_dirs = env_var('INCLUDE')\n        return static_include_dirs\n    # filter them from xslt-config --cflags\n    result = []\n    possible_include_dirs = flags('cflags')\n    for possible_include_dir in possible_include_dirs:\n        if possible_include_dir.startswith('-I'):\n            result.append(possible_include_dir[2:])\n    return result\n\ndef cflags(static_cflags):\n    result = []\n    if not OPTION_SHOW_WARNINGS:\n        result.append('-w')\n    if OPTION_DEBUG_GCC:\n        result.append('-g2')\n\n    if OPTION_STATIC:\n        if not static_cflags:\n            static_cflags = env_var('CFLAGS')\n        result.extend(static_cflags)\n    else:\n        # anything from xslt-config --cflags that doesn't start with -I\n        possible_cflags = flags('cflags')\n        for possible_cflag in possible_cflags:\n            if not possible_cflag.startswith('-I'):\n                result.append(possible_cflag)\n\n    if sys.platform in ('darwin',):\n        for opt in result:\n            if 'flat_namespace' in opt:\n                break\n        else:\n            result.append('-flat_namespace')\n\n    return result\n\ndef define_macros():\n    macros = []\n    if OPTION_WITHOUT_ASSERT:\n        macros.append(('PYREX_WITHOUT_ASSERTIONS', None))\n    if OPTION_WITHOUT_THREADING:\n        macros.append(('WITHOUT_THREADING', None))\n    if OPTION_WITH_REFNANNY:\n        macros.append(('CYTHON_REFNANNY', None))\n    if OPTION_WITH_UNICODE_STRINGS:\n        macros.append(('LXML_UNICODE_STRINGS', '1'))\n    if OPTION_WITH_COVERAGE:\n        macros.append(('CYTHON_TRACE_NOGIL', '1'))\n    if OPTION_BUILD_LIBXML2XSLT:\n        macros.append(('LIBXML_STATIC', None))\n        macros.append(('LIBXSLT_STATIC', None))\n        macros.append(('LIBEXSLT_STATIC', None))\n    # Disable showing C lines in tracebacks, unless explicitly requested.\n    macros.append(('CYTHON_CLINE_IN_TRACEBACK', '1' if OPTION_WITH_CLINES else '0'))\n    return macros\n\n\ndef run_command(cmd, *args):\n    if not cmd:\n        return ''\n    if args:\n        cmd = ' '.join((cmd,) + args)\n\n    p = subprocess.Popen(cmd, shell=True,\n                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout_data, errors = p.communicate()\n\n    if p.returncode != 0 and errors:\n        return ''\n    return decode_input(stdout_data).strip()\n\n\ndef check_min_version(version, min_version, libname):\n    if not version:\n        # this is ok for targets like sdist etc.\n        return True\n    lib_version = tuple(map(int, version.split('.')[:3]))\n    req_version = tuple(map(int, min_version.split('.')[:3]))\n    if lib_version < req_version:\n        print(\"Minimum required version of %s is %s. Your system has version %s.\" % (\n            libname, min_version, version))\n        return False\n    return True\n\n\ndef get_library_version(prog, libname=None):\n    if libname:\n        return run_command(prog, '--modversion %s' % libname)\n    else:\n        return run_command(prog, '--version')\n\n\nPKG_CONFIG = None\nXML2_CONFIG = None\nXSLT_CONFIG = None\n\ndef get_library_versions():\n    global XML2_CONFIG, XSLT_CONFIG\n\n    # Pre-built libraries\n    if XML2_CONFIG and XSLT_CONFIG:\n        xml2_version = get_library_version(XML2_CONFIG)\n        xslt_version = get_library_version(XSLT_CONFIG)\n        return xml2_version, xslt_version\n\n    # Path to xml2-config and xslt-config specified on the command line\n    if OPTION_WITH_XML2_CONFIG:\n        xml2_version = get_library_version(OPTION_WITH_XML2_CONFIG)\n        if xml2_version and OPTION_WITH_XSLT_CONFIG:\n            xslt_version = get_library_version(OPTION_WITH_XSLT_CONFIG)\n            if xslt_version:\n                XML2_CONFIG = OPTION_WITH_XML2_CONFIG\n                XSLT_CONFIG = OPTION_WITH_XSLT_CONFIG\n                return xml2_version, xslt_version\n\n    # Try pkg-config\n    global PKG_CONFIG\n    PKG_CONFIG = os.getenv('PKG_CONFIG', 'pkg-config')\n    xml2_version = get_library_version(PKG_CONFIG, 'libxml-2.0')\n    if xml2_version:\n        xslt_version = get_library_version(PKG_CONFIG, 'libxslt')\n        if xml2_version and xslt_version:\n            return xml2_version, xslt_version\n\n    # Try xml2-config and xslt-config\n    XML2_CONFIG = os.getenv('XML2_CONFIG', 'xml2-config')\n    xml2_version = get_library_version(XML2_CONFIG)\n    if xml2_version:\n        XSLT_CONFIG = os.getenv('XSLT_CONFIG', 'xslt-config')\n        xslt_version = get_library_version(XSLT_CONFIG)\n        if xml2_version and xslt_version:\n            return xml2_version, xslt_version\n\n    # One or both build dependencies not found. Fail on Linux platforms only.\n    if sys.platform.startswith('win'):\n        return '', ''\n    print(\"Error: Please make sure the libxml2 and libxslt development packages are installed.\")\n    sys.exit(1)\n\n\ndef check_build_dependencies():\n    xml2_version, xslt_version = get_library_versions()\n\n    xml2_ok = check_min_version(xml2_version, '2.7.0', 'libxml2')\n    xslt_ok = check_min_version(xslt_version, '1.1.23', 'libxslt')\n\n    if not OPTION_BUILD_LIBXML2XSLT and xml2_version in ('2.9.11', '2.9.12'):\n        print(\"\\n\"\n              \"WARNING: The stock libxml2 versions 2.9.11 and 2.9.12 are incompatible\"\n              \" with this lxml version. \"\n              \"They produce excess content on serialisation. \"\n              \"Use a different library version or a static build.\"\n              \"\\n\")\n\n    if xml2_version and xslt_version:\n        print(\"Building against libxml2 %s and libxslt %s\" % (xml2_version, xslt_version))\n    else:\n        print(\"Building against pre-built libxml2 andl libxslt libraries\")\n\n    return (xml2_ok and xslt_ok)\n\n\ndef get_flags(prog, option, libname=None):\n    if libname:\n        return run_command(prog, '--%s %s' % (option, libname))\n    else:\n        return run_command(prog, '--%s' % option)\n\n\ndef flags(option):\n    if XML2_CONFIG:\n        xml2_flags = get_flags(XML2_CONFIG, option)\n        xslt_flags = get_flags(XSLT_CONFIG, option)\n    else:\n        xml2_flags = get_flags(PKG_CONFIG, option, 'libxml-2.0')\n        xslt_flags = get_flags(PKG_CONFIG, option, 'libxslt')\n\n    flag_list = xml2_flags.split()\n    for flag in xslt_flags.split():\n        if flag not in flag_list:\n            flag_list.append(flag)\n    return flag_list\n\n\ndef get_xcode_isysroot():\n    return run_command('xcrun', '--show-sdk-path')\n\n\n## Option handling:\n\ndef has_option(name):\n    try:\n        sys.argv.remove('--%s' % name)\n        return True\n    except ValueError:\n        pass\n    # allow passing all cmd line options also as environment variables\n    env_val = os.getenv(name.upper().replace('-', '_'), 'false').lower()\n    if env_val == \"true\":\n        return True\n    return False\n\n\ndef option_value(name, deprecated_for=None):\n    for index, option in enumerate(sys.argv):\n        if option == '--' + name:\n            if index+1 >= len(sys.argv):\n                raise DistutilsOptionError(\n                    'The option %s requires a value' % option)\n            value = sys.argv[index+1]\n            sys.argv[index:index+2] = []\n            if deprecated_for:\n                print_deprecated_option(name, deprecated_for)\n            return value\n        if option.startswith('--' + name + '='):\n            value = option[len(name)+3:]\n            sys.argv[index:index+1] = []\n            if deprecated_for:\n                print_deprecated_option(name, deprecated_for)\n            return value\n    env_name = name.upper().replace('-', '_')\n    env_val = os.getenv(env_name)\n    if env_val and deprecated_for:\n        print_deprecated_option(env_name, deprecated_for.upper().replace('-', '_'))\n    return env_val\n\n\ndef print_deprecated_option(name, new_name):\n    print(\"WARN: Option '%s' is deprecated. Use '%s' instead.\" % (name, new_name))\n\n\nstaticbuild = bool(os.environ.get('STATICBUILD', ''))\n# pick up any commandline options and/or env variables\nOPTION_WITHOUT_OBJECTIFY = has_option('without-objectify')\nOPTION_WITH_UNICODE_STRINGS = has_option('with-unicode-strings')\nOPTION_WITHOUT_ASSERT = has_option('without-assert')\nOPTION_WITHOUT_THREADING = has_option('without-threading')\nOPTION_WITHOUT_CYTHON = has_option('without-cython')\nOPTION_WITH_CYTHON = has_option('with-cython')\nOPTION_WITH_CYTHON_GDB = has_option('cython-gdb')\nOPTION_WITH_REFNANNY = has_option('with-refnanny')\nOPTION_WITH_COVERAGE = has_option('with-coverage')\nOPTION_WITH_CLINES = has_option('with-clines')\nif OPTION_WITHOUT_CYTHON:\n    CYTHON_INSTALLED = False\nOPTION_STATIC = staticbuild or has_option('static')\nOPTION_DEBUG_GCC = has_option('debug-gcc')\nOPTION_SHOW_WARNINGS = has_option('warnings')\nOPTION_AUTO_RPATH = has_option('auto-rpath')\nOPTION_BUILD_LIBXML2XSLT = staticbuild or has_option('static-deps')\nif OPTION_BUILD_LIBXML2XSLT:\n    OPTION_STATIC = True\nOPTION_WITH_XML2_CONFIG = option_value('with-xml2-config') or option_value('xml2-config', deprecated_for='with-xml2-config')\nOPTION_WITH_XSLT_CONFIG = option_value('with-xslt-config') or option_value('xslt-config', deprecated_for='with-xslt-config')\nOPTION_LIBXML2_VERSION = option_value('libxml2-version')\nOPTION_LIBXSLT_VERSION = option_value('libxslt-version')\nOPTION_LIBICONV_VERSION = option_value('libiconv-version')\nOPTION_ZLIB_VERSION = option_value('zlib-version')\nOPTION_MULTICORE = option_value('multicore')\nOPTION_DOWNLOAD_DIR = option_value('download-dir')\nif OPTION_DOWNLOAD_DIR is None:\n    OPTION_DOWNLOAD_DIR = 'libs'\n", "buildlibxml.py": "import json\nimport os, re, sys, subprocess, platform\nimport tarfile\nfrom distutils import log\nfrom contextlib import closing, contextmanager\nfrom ftplib import FTP\n\nfrom urllib.parse import urljoin, unquote, urlparse\nfrom urllib.request import urlretrieve, urlopen, Request\n\nmulti_make_options = []\ntry:\n    import multiprocessing\n    cpus = multiprocessing.cpu_count()\n    if cpus > 1:\n        if cpus > 5:\n            cpus = 5\n        multi_make_options = ['-j%d' % (cpus+1)]\nexcept:\n    pass\n\n\n# overridable to control script usage\nsys_platform = sys.platform\n\n\n# use pre-built libraries on Windows\n\ndef download_and_extract_windows_binaries(destdir):\n    url = \"https://api.github.com/repos/lxml/libxml2-win-binaries/releases?per_page=5\"\n    releases, _ = read_url(\n        url,\n        accept=\"application/vnd.github+json\",\n        as_json=True,\n        github_api_token=os.environ.get(\"GITHUB_API_TOKEN\"),\n    )\n\n    max_release = {'tag_name': ''}\n    for release in releases:\n        if max_release['tag_name'] < release.get('tag_name', ''):\n            max_release = release\n\n    url = \"https://github.com/lxml/libxml2-win-binaries/releases/download/%s/\" % max_release['tag_name']\n    filenames = [asset['name'] for asset in max_release.get('assets', ())]\n\n    # Check for native ARM64 build or the environment variable that is set by\n    # Visual Studio for cross-compilation (same variable as setuptools uses)\n    if platform.machine() == 'ARM64' or os.getenv('VSCMD_ARG_TGT_ARCH') == 'arm64':\n        arch = \"win-arm64\"\n    elif sys.maxsize > 2**32:\n        arch = \"win64\"\n    else:\n        arch = \"win32\"\n\n    if sys.version_info < (3, 5):\n        arch = 'vs2008.' + arch\n\n    arch_part = '.' + arch + '.'\n    filenames = [filename for filename in filenames if arch_part in filename]\n\n    libs = {}\n    for libname in ['libxml2', 'libxslt', 'zlib', 'iconv']:\n        libs[libname] = \"%s-%s.%s.zip\" % (\n            libname,\n            find_max_version(libname, filenames),\n            arch,\n        )\n\n    if not os.path.exists(destdir):\n        os.makedirs(destdir)\n\n    for libname, libfn in libs.items():\n        srcfile = urljoin(url, libfn)\n        destfile = os.path.join(destdir, libfn)\n        if os.path.exists(destfile + \".keep\"):\n            print('Using local copy of  \"{}\"'.format(srcfile))\n        else:\n            print('Retrieving \"%s\" to \"%s\"' % (srcfile, destfile))\n            urlretrieve(srcfile, destfile)\n        d = unpack_zipfile(destfile, destdir)\n        libs[libname] = d\n\n    return libs\n\n\ndef find_top_dir_of_zipfile(zipfile):\n    topdir = None\n    files = [f.filename for f in zipfile.filelist]\n    dirs = [d for d in files if d.endswith('/')]\n    if dirs:\n        dirs.sort(key=len)\n        topdir = dirs[0]\n        topdir = topdir[:topdir.index(\"/\")+1]\n        for path in files:\n            if not path.startswith(topdir):\n                topdir = None\n                break\n    assert topdir, (\n        \"cannot determine single top-level directory in zip file %s\" %\n        zipfile.filename)\n    return topdir.rstrip('/')\n\n\ndef unpack_zipfile(zipfn, destdir):\n    assert zipfn.endswith('.zip')\n    import zipfile\n    print('Unpacking %s into %s' % (os.path.basename(zipfn), destdir))\n    f = zipfile.ZipFile(zipfn)\n    try:\n        extracted_dir = os.path.join(destdir, find_top_dir_of_zipfile(f))\n        f.extractall(path=destdir)\n    finally:\n        f.close()\n    assert os.path.exists(extracted_dir), 'missing: %s' % extracted_dir\n    return extracted_dir\n\n\ndef get_prebuilt_libxml2xslt(download_dir, static_include_dirs, static_library_dirs):\n    assert sys_platform.startswith('win')\n    libs = download_and_extract_windows_binaries(download_dir)\n    for libname, path in libs.items():\n        i = os.path.join(path, 'include')\n        l = os.path.join(path, 'lib')\n        assert os.path.exists(i), 'does not exist: %s' % i\n        assert os.path.exists(l), 'does not exist: %s' % l\n        static_include_dirs.append(i)\n        static_library_dirs.append(l)\n\n\n## Routines to download and build libxml2/xslt from sources:\n\nLIBXML2_LOCATION = 'https://download.gnome.org/sources/libxml2/'\nLIBXSLT_LOCATION = 'https://download.gnome.org/sources/libxslt/'\nLIBICONV_LOCATION = 'https://ftp.gnu.org/pub/gnu/libiconv/'\nZLIB_LOCATION = 'https://zlib.net/'\nmatch_libfile_version = re.compile('^[^-]*-([.0-9-]+)[.].*').match\n\n\ndef _find_content_encoding(response, default='iso8859-1'):\n    from email.message import Message\n    content_type = response.headers.get('Content-Type')\n    if content_type:\n        msg = Message()\n        msg.add_header('Content-Type', content_type)\n        charset = msg.get_content_charset(default)\n    else:\n        charset = default\n    return charset\n\n\ndef remote_listdir(url):\n    try:\n        return _list_dir_urllib(url)\n    except IOError:\n        assert url.lower().startswith('ftp://')\n        print(\"Requesting with urllib failed. Falling back to ftplib. \"\n              \"Proxy argument will be ignored for %s\" % url)\n        return _list_dir_ftplib(url)\n\n\ndef _list_dir_ftplib(url):\n    parts = urlparse(url)\n    ftp = FTP(parts.netloc)\n    try:\n        ftp.login()\n        ftp.cwd(parts.path)\n        data = []\n        ftp.dir(data.append)\n    finally:\n        ftp.quit()\n    return parse_text_ftplist(\"\\n\".join(data))\n\n\ndef read_url(url, decode=True, accept=None, as_json=False, github_api_token=None):\n    headers = {'User-Agent': 'https://github.com/lxml/lxml'}\n    if accept:\n        headers['Accept'] = accept\n    if github_api_token:\n        headers['authorization'] = \"Bearer \" + github_api_token\n    request = Request(url, headers=headers)\n\n    with closing(urlopen(request)) as res:\n        charset = _find_content_encoding(res)\n        content_type = res.headers.get('Content-Type')\n        data = res.read()\n\n    if decode:\n        data = data.decode(charset)\n    if as_json:\n        data = json.loads(data)\n    return data, content_type\n\n\ndef _list_dir_urllib(url):\n    data, content_type = read_url(url)\n    if content_type and content_type.startswith('text/html'):\n        files = parse_html_filelist(data)\n    else:\n        files = parse_text_ftplist(data)\n    return files\n\n\ndef http_find_latest_version_directory(url, version=None):\n    data, _ = read_url(url)\n    # e.g. <a href=\"1.0/\">\n    directories = [\n        (int(v[0]), int(v[1]))\n        for v in re.findall(r' href=[\"\\']([0-9]+)\\.([0-9]+)/?[\"\\']', data)\n    ]\n    if not directories:\n        return url\n    best_version = max(directories)\n    if version:\n        major, minor, _ = version.split(\".\", 2)\n        major, minor = int(major), int(minor)\n        if (major, minor) in directories:\n            best_version = (major, minor)\n    latest_dir = \"%s.%s\" % best_version\n    return urljoin(url, latest_dir) + \"/\"\n\n\ndef http_listfiles(url, re_pattern):\n    data, _ = read_url(url)\n    files = re.findall(re_pattern, data)\n    return files\n\n\ndef parse_text_ftplist(s):\n    for line in s.splitlines():\n        if not line.startswith('d'):\n            # -rw-r--r--   1 ftp      ftp           476 Sep  1  2011 md5sum.txt\n            # Last (9th) element is 'md5sum.txt' in the above example, but there\n            # may be variations, so we discard only the first 8 entries.\n            yield line.split(None, 8)[-1]\n\n\ndef parse_html_filelist(s):\n    re_href = re.compile(\n        r'''<a[^>]*\\shref=[\"']([^;?\"']+?)[;?\"']''',\n        re.I|re.M)\n    links = set(re_href.findall(s))\n    for link in links:\n        if not link.endswith('/'):\n            yield unquote(link)\n\n\ndef tryint(s):\n    try:\n        return int(s)\n    except ValueError:\n        return s\n\n\n@contextmanager\ndef py2_tarxz(filename):\n    import tempfile\n    with tempfile.TemporaryFile() as tmp:\n        subprocess.check_call([\"xz\", \"-dc\", filename], stdout=tmp.fileno())\n        tmp.seek(0)\n        with closing(tarfile.TarFile(fileobj=tmp)) as tf:\n            yield tf\n\n\ndef download_libxml2(dest_dir, version=None):\n    \"\"\"Downloads libxml2, returning the filename where the library was downloaded\"\"\"\n    #version_re = re.compile(r'LATEST_LIBXML2_IS_([0-9.]+[0-9](?:-[abrc0-9]+)?)')\n    version_re = re.compile(r'libxml2-([0-9.]+[0-9]).tar.xz')\n    filename = 'libxml2-%s.tar.xz'\n\n    if version == \"2.9.12\":\n        # Temporarily using the latest master (2.9.12+) until there is a release that supports lxml again.\n        from_location = \"https://gitlab.gnome.org/GNOME/libxml2/-/archive/dea91c97debeac7c1aaf9c19f79029809e23a353/\"\n        version = \"dea91c97debeac7c1aaf9c19f79029809e23a353\"\n    else:\n        from_location = http_find_latest_version_directory(LIBXML2_LOCATION, version=version)\n\n    return download_library(dest_dir, from_location, 'libxml2',\n                            version_re, filename, version=version)\n\n\ndef download_libxslt(dest_dir, version=None):\n    \"\"\"Downloads libxslt, returning the filename where the library was downloaded\"\"\"\n    #version_re = re.compile(r'LATEST_LIBXSLT_IS_([0-9.]+[0-9](?:-[abrc0-9]+)?)')\n    version_re = re.compile(r'libxslt-([0-9.]+[0-9]).tar.xz')\n    filename = 'libxslt-%s.tar.xz'\n    from_location = http_find_latest_version_directory(LIBXSLT_LOCATION, version=version)\n    return download_library(dest_dir, from_location, 'libxslt',\n                            version_re, filename, version=version)\n\n\ndef download_libiconv(dest_dir, version=None):\n    \"\"\"Downloads libiconv, returning the filename where the library was downloaded\"\"\"\n    version_re = re.compile(r'libiconv-([0-9.]+[0-9]).tar.gz')\n    filename = 'libiconv-%s.tar.gz'\n    return download_library(dest_dir, LIBICONV_LOCATION, 'libiconv',\n                            version_re, filename, version=version)\n\n\ndef download_zlib(dest_dir, version):\n    \"\"\"Downloads zlib, returning the filename where the library was downloaded\"\"\"\n    version_re = re.compile(r'zlib-([0-9.]+[0-9]).tar.gz')\n    filename = 'zlib-%s.tar.gz'\n    return download_library(dest_dir, ZLIB_LOCATION, 'zlib',\n                            version_re, filename, version=version)\n\n\ndef find_max_version(libname, filenames, version_re=None):\n    if version_re is None:\n        version_re = re.compile(r'%s-([0-9.]+[0-9](?:-[abrc0-9]+)?)' % libname)\n    versions = []\n    for fn in filenames:\n        match = version_re.search(fn)\n        if match:\n            version_string = match.group(1)\n            versions.append((tuple(map(tryint, version_string.replace(\"-\", \".-\").split('.'))),\n                             version_string))\n    if not versions:\n        raise Exception(\n            \"Could not find the most current version of %s from the files: %s\" % (\n                libname, filenames))\n    versions.sort()\n    version_string = versions[-1][-1]\n    print('Latest version of %s is %s' % (libname, version_string))\n    return version_string\n\n\ndef download_library(dest_dir, location, name, version_re, filename, version=None):\n    if version is None:\n        try:\n            if location.startswith('ftp://'):\n                fns = remote_listdir(location)\n            else:\n                print(location)\n                fns = http_listfiles(location, '(%s)' % filename.replace('%s', '(?:[0-9.]+[0-9])'))\n            version = find_max_version(name, fns, version_re)\n        except IOError:\n            # network failure - maybe we have the files already?\n            latest = (0,0,0)\n            fns = os.listdir(dest_dir)\n            for fn in fns:\n                if fn.startswith(name+'-'):\n                    match = match_libfile_version(fn)\n                    if match:\n                        version_tuple = tuple(map(tryint, match.group(1).split('.')))\n                        if version_tuple > latest:\n                            latest = version_tuple\n                            filename = fn\n                            version = None\n            if latest == (0,0,0):\n                raise\n    if version:\n        filename = filename % version\n\n    full_url = urljoin(location, filename)\n    dest_filename = os.path.join(dest_dir, filename)\n    if os.path.exists(dest_filename):\n        print(('Using existing %s downloaded into %s '\n               '(delete this file if you want to re-download the package)') % (\n            name, dest_filename))\n        return dest_filename\n\n    print('Downloading %s into %s from %s' % (name, dest_filename, full_url))\n    urlretrieve(full_url, dest_filename)\n    return dest_filename\n\n\ndef unpack_tarball(tar_filename, dest):\n    print('Unpacking %s into %s' % (os.path.basename(tar_filename), dest))\n    if sys.version_info[0] < 3 and tar_filename.endswith('.xz'):\n        # Py 2.7 lacks lzma support\n        tar_cm = py2_tarxz(tar_filename)\n    else:\n        tar_cm = closing(tarfile.open(tar_filename))\n\n    base_dir = None\n    with tar_cm as tar:\n        for member in tar:\n            base_name = member.name.split('/')[0]\n            if base_dir is None:\n                base_dir = base_name\n            elif base_dir != base_name:\n                print('Unexpected path in %s: %s' % (tar_filename, base_name))\n        tar.extractall(dest)\n    return os.path.join(dest, base_dir)\n\n\ndef call_subprocess(cmd, **kw):\n    import subprocess\n    cwd = kw.get('cwd', '.')\n    cmd_desc = ' '.join(cmd)\n    log.info('Running \"%s\" in %s' % (cmd_desc, cwd))\n    returncode = subprocess.call(cmd, **kw)\n    if returncode:\n        raise Exception('Command \"%s\" returned code %s' % (cmd_desc, returncode))\n\n\ndef safe_mkdir(dir):\n    if not os.path.exists(dir):\n        os.makedirs(dir)\n\n\ndef cmmi(configure_cmd, build_dir, multicore=None, **call_setup):\n    print('Starting build in %s' % build_dir)\n    call_subprocess(configure_cmd, cwd=build_dir, **call_setup)\n    if not multicore:\n        make_jobs = multi_make_options\n    elif int(multicore) > 1:\n        make_jobs = ['-j%s' % multicore]\n    else:\n        make_jobs = []\n    call_subprocess(\n        ['make'] + make_jobs,\n        cwd=build_dir, **call_setup)\n    call_subprocess(\n        ['make'] + make_jobs + ['install'],\n        cwd=build_dir, **call_setup)\n\n\ndef configure_darwin_env(env_setup):\n    import platform\n    # configure target architectures on MacOS-X (x86_64 + Arm64, by default)\n    major_version, minor_version = tuple(map(int, platform.mac_ver()[0].split('.')[:2]))\n    if major_version >= 11:\n        env_default = {\n            'CFLAGS': \"-arch x86_64 -arch arm64 -O3\",\n            'LDFLAGS': \"-arch x86_64 -arch arm64\",\n            'MACOSX_DEPLOYMENT_TARGET': \"11.0\"\n        }\n        env_default.update(os.environ)\n        env_setup['env'] = env_default\n\n\ndef build_libxml2xslt(download_dir, build_dir,\n                      static_include_dirs, static_library_dirs,\n                      static_cflags, static_binaries,\n                      libxml2_version=None,\n                      libxslt_version=None,\n                      libiconv_version=None,\n                      zlib_version=None,\n                      multicore=None):\n    safe_mkdir(download_dir)\n    safe_mkdir(build_dir)\n    zlib_dir = unpack_tarball(download_zlib(download_dir, zlib_version), build_dir)\n    libiconv_dir = unpack_tarball(download_libiconv(download_dir, libiconv_version), build_dir)\n    libxml2_dir  = unpack_tarball(download_libxml2(download_dir, libxml2_version), build_dir)\n    libxslt_dir  = unpack_tarball(download_libxslt(download_dir, libxslt_version), build_dir)\n    prefix = os.path.join(os.path.abspath(build_dir), 'libxml2')\n    lib_dir = os.path.join(prefix, 'lib')\n    safe_mkdir(prefix)\n\n    lib_names = ['libxml2', 'libexslt', 'libxslt', 'iconv', 'libz']\n    existing_libs = {\n        lib: os.path.join(lib_dir, filename)\n        for lib in lib_names\n        for filename in os.listdir(lib_dir)\n        if lib in filename and filename.endswith('.a')\n    } if os.path.isdir(lib_dir) else {}\n\n    def has_current_lib(name, build_dir, _build_all_following=[False]):\n        if _build_all_following[0]:\n            return False  # a dependency was rebuilt => rebuilt this lib as well\n        lib_file = existing_libs.get(name)\n        found = lib_file and os.path.getmtime(lib_file) > os.path.getmtime(build_dir)\n        if found:\n            print(\"Found pre-built '%s'\" % name)\n        else:\n            # also rebuild all following libs (which may depend on this one)\n            _build_all_following[0] = True\n        return found\n\n    call_setup = {}\n    if sys_platform == 'darwin':\n        configure_darwin_env(call_setup)\n\n    configure_cmd = ['./configure',\n                     '--disable-dependency-tracking',\n                     '--disable-shared',\n                     '--prefix=%s' % prefix,\n                     ]\n\n    # build zlib\n    zlib_configure_cmd = [\n        './configure',\n        '--prefix=%s' % prefix,\n    ]\n    if not has_current_lib(\"libz\", zlib_dir):\n        cmmi(zlib_configure_cmd, zlib_dir, multicore, **call_setup)\n\n    # build libiconv\n    if not has_current_lib(\"iconv\", libiconv_dir):\n        cmmi(configure_cmd, libiconv_dir, multicore, **call_setup)\n\n    # build libxml2\n    libxml2_configure_cmd = configure_cmd + [\n        '--without-python',\n        '--with-iconv=%s' % prefix,\n        '--with-zlib=%s' % prefix,\n    ]\n\n    if not libxml2_version:\n        libxml2_version = os.path.basename(libxml2_dir).split('-', 1)[-1]\n\n    if tuple(map(tryint, libxml2_version.split('-', 1)[0].split('.'))) >= (2, 9, 5):\n        libxml2_configure_cmd.append('--without-lzma')  # can't currently build that\n\n    try:\n        if tuple(map(tryint, libxml2_version.split('-', 1)[0].split('.'))) >= (2, 7, 3):\n            libxml2_configure_cmd.append('--enable-rebuild-docs=no')\n    except Exception:\n        pass # this isn't required, so ignore any errors\n    if not has_current_lib(\"libxml2\", libxml2_dir):\n        if not os.path.exists(os.path.join(libxml2_dir, \"configure\")):\n            # Allow building from git sources by running autoconf etc.\n            libxml2_configure_cmd[0] = \"./autogen.sh\"\n        cmmi(libxml2_configure_cmd, libxml2_dir, multicore, **call_setup)\n\n    # Fix up libxslt configure script (needed up to and including 1.1.34)\n    # https://gitlab.gnome.org/GNOME/libxslt/-/commit/90c34c8bb90e095a8a8fe8b2ce368bd9ff1837cc\n    with open(os.path.join(libxslt_dir, \"configure\"), 'rb') as f:\n        config_script = f.read()\n    if b' --libs print ' in config_script:\n        config_script = config_script.replace(b' --libs print ', b' --libs ')\n        with open(os.path.join(libxslt_dir, \"configure\"), 'wb') as f:\n            f.write(config_script)\n\n    # build libxslt\n    libxslt_configure_cmd = configure_cmd + [\n        '--without-python',\n        '--with-libxml-prefix=%s' % prefix,\n        '--without-crypto',\n    ]\n    if not (has_current_lib(\"libxslt\", libxslt_dir) and has_current_lib(\"libexslt\", libxslt_dir)):\n        cmmi(libxslt_configure_cmd, libxslt_dir, multicore, **call_setup)\n\n    # collect build setup for lxml\n    xslt_config = os.path.join(prefix, 'bin', 'xslt-config')\n    xml2_config = os.path.join(prefix, 'bin', 'xml2-config')\n\n    static_include_dirs.extend([\n            os.path.join(prefix, 'include'),\n            os.path.join(prefix, 'include', 'libxml2'),\n            os.path.join(prefix, 'include', 'libxslt'),\n            os.path.join(prefix, 'include', 'libexslt')])\n    static_library_dirs.append(lib_dir)\n\n    listdir = os.listdir(lib_dir)\n    static_binaries += [os.path.join(lib_dir, filename)\n        for lib in lib_names\n        for filename in listdir\n        if lib in filename and filename.endswith('.a')]\n\n    return xml2_config, xslt_config\n\n\ndef main():\n    static_include_dirs = []\n    static_library_dirs = []\n    download_dir = \"libs\"\n\n    if sys_platform.startswith('win'):\n        return get_prebuilt_libxml2xslt(\n            download_dir, static_include_dirs, static_library_dirs)\n    else:\n        return build_libxml2xslt(\n            download_dir, 'build/tmp',\n            static_include_dirs, static_library_dirs,\n            static_cflags=[],\n            static_binaries=[]\n        )\n\n\nif __name__ == '__main__':\n    if len(sys.argv) > 1:\n        # change global sys_platform setting\n        sys_platform = sys.argv[1]\n    main()\n", "tools/xpathgrep.py": "#!/usr/bin/env python\n\nimport sys\nimport os.path\n\ndef error(message, *args):\n    if args:\n        message = message % args\n    sys.stderr.write('ERROR: %s\\n' % message)\n\ntry:\n    import lxml.etree as et\nexcept ImportError:\n    error(sys.exc_info()[1])\n    sys.exit(5)\n\ntry:\n    basestring\nexcept NameError:\n    basestring = (str, bytes)\n\ntry:\n    unicode\nexcept NameError:\n    unicode = str\n\nSHORT_DESCRIPTION = \"An XPath file finder for XML files.\"\n\n__doc__ = SHORT_DESCRIPTION + '''\n\nEvaluates an XPath expression against a series of files and prints the\nmatching subtrees to stdout.\n\nExamples::\n\n  $ cat test.xml\n  <root>\n    <a num=\"1234\" notnum=\"1234abc\"/>\n    <b text=\"abc\"/>\n    <c text=\"aBc\"/>\n    <d xmlns=\"http://www.example.org/ns/example\" num=\"2\"/>\n    <d xmlns=\"http://www.example.org/ns/example\" num=\"4\"/>\n  </root>\n\n  # find all leaf elements:\n  $ SCRIPT '//*[not(*)]' test.xml\n  <a num=\"1234\" notnum=\"1234abc\"/>\n  <b text=\"abc\"/>\n  <c text=\"aBc\"/>\n\n  # find all elements with attribute values containing \"abc\" ignoring case:\n  $ SCRIPT '//*[@*[contains(py:lower(.), \"abc\")]]' test.xml\n  <a num=\"1234\" notnum=\"1234abc\"/>\n  <b text=\"abc\"/>\n  <c text=\"aBc\"/>\n\n  # find all numeric attribute values:\n  $ SCRIPT '//@*[re:match(., \"^[0-9]+$\")]' test.xml\n  1234\n\n  * find all elements with numeric attribute values:\n  $ SCRIPT '//*[@*[re:match(., \"^[0-9]+$\")]]' test.xml\n  <a num=\"1234\" notnum=\"1234abc\"/>\n\n  * find all elements with numeric attribute values in more than one file:\n  $ SCRIPT '//*[@*[re:match(., \"^[0-9]+$\")]]' test.xml test.xml test.xml\n  >> test.xml\n  <a num=\"1234\" notnum=\"1234abc\"/>\n  >> test.xml\n  <a num=\"1234\" notnum=\"1234abc\"/>\n  >> test.xml\n  <a num=\"1234\" notnum=\"1234abc\"/>\n\n  * find XML files that have non-empty root nodes:\n  $ SCRIPT -q '*' test.xml test.xml test.xml\n  >> test.xml\n  >> test.xml\n  >> test.xml\n\n  * find out if an XML file has at most depth three:\n  $ SCRIPT 'not(/*/*/*)' test.xml\n  True\n\n  * find all elements that belong to a specific namespace and have @num=2\n  $ SCRIPT --ns e=http://www.example.org/ns/example '//e:*[@num=\"2\"]' test.xml\n  <d xmlns=\"http://www.example.org/ns/example\" num=\"2\"/>\n\nBy default, all Python builtins and string methods are available as\nXPath functions through the ``py`` prefix.  There is also a string\ncomparison function ``py:within(x, a, b)`` that tests the string x for\nbeing lexicographically within the interval ``a <= x <= b``.\n'''.replace('SCRIPT', os.path.basename(sys.argv[0]))\n\nREGEXP_NS = \"http://exslt.org/regular-expressions\"\nPYTHON_BUILTINS_NS = \"PYTHON-BUILTINS\"\n\ndef make_parser(remove_blank_text=True, **kwargs):\n    return et.XMLParser(remove_blank_text=remove_blank_text, **kwargs)\n\ndef print_result(result, pretty_print, encoding=None, _is_py3=sys.version_info[0] >= 3):\n    stdout = sys.stdout\n    if not stdout.isatty() and not encoding:\n        encoding = 'utf8'\n    if et.iselement(result):\n        result = et.tostring(result, xml_declaration=False, with_tail=False,\n                             pretty_print=pretty_print, encoding=encoding)\n        if not pretty_print:\n            # pretty printing appends newline, otherwise we do it\n            if isinstance(result, unicode):\n                result += '\\n'\n            else:\n                result += '\\n'.encode('ascii')\n    elif isinstance(result, basestring):\n        result += '\\n'\n    else:\n        result = '%r\\n' % result # '%r' for better number formatting\n\n    if encoding and encoding != 'unicode' and isinstance(result, unicode):\n        result = result.encode(encoding)\n\n    if _is_py3 and not isinstance(result, unicode):\n        stdout.buffer.write(result)\n    else:\n        stdout.write(result)\n\ndef print_results(results, pretty_print):\n    if isinstance(results, list):\n        for result in results:\n            print_result(result, pretty_print)\n    else:\n        print_result(results, pretty_print)\n\ndef iter_input(input, filename, parser, line_by_line):\n    if isinstance(input, basestring):\n        with open(input, 'rb') as f:\n            for tree in iter_input(f, filename, parser, line_by_line):\n                yield tree\n    else:\n        try:\n            if line_by_line:\n                for line in input:\n                    if line:\n                        yield et.ElementTree(et.fromstring(line, parser))\n            else:\n                yield et.parse(input, parser)\n        except IOError:\n            e = sys.exc_info()[1]\n            error(\"parsing %r failed: %s: %s\",\n                  filename, e.__class__.__name__, e)\n\ndef find_in_file(f, xpath, print_name=True, xinclude=False, pretty_print=True, line_by_line=False,\n                 encoding=None, verbose=True):\n    try:\n        filename = f.name\n    except AttributeError:\n        filename = f\n\n    xml_parser = et.XMLParser(encoding=encoding)\n\n    try:\n        if not callable(xpath):\n            xpath = et.XPath(xpath)\n\n        found = False\n        for tree in iter_input(f, filename, xml_parser, line_by_line):\n            try:\n                if xinclude:\n                    tree.xinclude()\n            except IOError:\n                e = sys.exc_info()[1]\n                error(\"XInclude for %r failed: %s: %s\",\n                      filename, e.__class__.__name__, e)\n\n            results = xpath(tree)\n            if results is not None and results != []:\n                found = True\n                if verbose:\n                    print_results(results, pretty_print)\n\n        if not found:\n            return False\n        if not verbose and print_name:\n            print(filename)\n        return True\n    except Exception:\n        e = sys.exc_info()[1]\n        error(\"%r: %s: %s\",\n              filename, e.__class__.__name__, e)\n        return False\n\ndef register_builtins():\n    ns = et.FunctionNamespace(PYTHON_BUILTINS_NS)\n    tostring = et.tostring\n\n    def make_string(s):\n        if isinstance(s, list):\n            if not s:\n                return ''\n            s = s[0]\n        if not isinstance(s, unicode):\n            if et.iselement(s):\n                s = tostring(s, method=\"text\", encoding='unicode')\n            else:\n                s = unicode(s)\n        return s\n\n    def wrap_builtin(b):\n        def wrapped_builtin(_, *args):\n            return b(*args)\n        return wrapped_builtin\n\n    for (name, builtin) in vars(__builtins__).items():\n        if callable(builtin):\n            if not name.startswith('_') and name == name.lower():\n                ns[name] = wrap_builtin(builtin)\n\n    def wrap_str_method(b):\n        def wrapped_method(_, *args):\n            args = tuple(map(make_string, args))\n            return b(*args)\n        return wrapped_method\n\n    for (name, method) in vars(unicode).items():\n        if callable(method):\n            if not name.startswith('_'):\n                ns[name] = wrap_str_method(method)\n\n    def within(_, s, a, b):\n        return make_string(a) <= make_string(s) <= make_string(b)\n    ns[\"within\"] = within\n\n\ndef parse_options():\n    from optparse import OptionParser\n\n    usage = \"usage: %prog [options] XPATH [FILE ...]\"\n\n    parser = OptionParser(\n        usage       = usage,\n        version     = \"%prog using lxml.etree \" + et.__version__,\n        description = SHORT_DESCRIPTION)\n    parser.add_option(\"-H\", \"--long-help\",\n                      action=\"store_true\", dest=\"long_help\", default=False,\n                      help=\"a longer help text including usage examples\")\n    parser.add_option(\"-i\", \"--xinclude\",\n                      action=\"store_true\", dest=\"xinclude\", default=False,\n                      help=\"run XInclude on the file before XPath\")\n    parser.add_option(\"--no-python\", \n                      action=\"store_false\", dest=\"python\", default=True,\n                      help=\"disable Python builtins and functions (prefix 'py')\")\n    parser.add_option(\"--no-regexp\", \n                      action=\"store_false\", dest=\"regexp\", default=True,\n                      help=\"disable regular expressions (prefix 're')\")\n    parser.add_option(\"-q\", \"--quiet\",\n                      action=\"store_false\", dest=\"verbose\", default=True,\n                      help=\"don't print status messages to stdout\")\n    parser.add_option(\"-t\", \"--root-tag\",\n                      dest=\"root_tag\", metavar=\"TAG\",\n                      help=\"surround output with <TAG>...</TAG> to produce a well-formed XML document\")\n    parser.add_option(\"-p\", \"--plain\",\n                      action=\"store_false\", dest=\"pretty_print\", default=True,\n                      help=\"do not pretty-print the output\")\n    parser.add_option(\"-l\", \"--lines\",\n                      action=\"store_true\", dest=\"line_by_line\", default=False,\n                      help=\"parse each line of input separately (e.g. grep output)\")\n    parser.add_option(\"-e\", \"--encoding\",\n                      dest=\"encoding\",\n                      help=\"use a specific encoding for parsing (may be required with --lines)\")\n    parser.add_option(\"-N\", \"--ns\", metavar=\"PREFIX=NS\",\n                      action=\"append\", dest=\"namespaces\", default=[],\n                      help=\"add a namespace declaration\")\n\n    options, args = parser.parse_args()\n\n    if options.long_help:\n        parser.print_help()\n        print(__doc__[__doc__.find('\\n\\n')+1:])\n        sys.exit(0)\n\n    if len(args) < 1:\n        parser.error(\"first argument must be an XPath expression\")\n\n    return options, args\n\n\ndef main(options, args):\n    namespaces = {}\n    if options.regexp:\n        namespaces[\"re\"] = REGEXP_NS\n    if options.python:\n        register_builtins()\n        namespaces[\"py\"] = PYTHON_BUILTINS_NS\n\n    for ns in options.namespaces:\n        prefix, NS = ns.split(\"=\", 1)\n        namespaces[prefix.strip()] = NS.strip()\n\n    xpath = et.XPath(args[0], namespaces=namespaces)\n    files = args[1:] or [sys.stdin]\n\n    if options.root_tag and options.verbose:\n        print('<%s>' % options.root_tag)\n\n    found = False\n    print_name = len(files) > 1 and not options.root_tag\n    for input in files:\n        found |= find_in_file(\n            input, xpath,\n            print_name=print_name,\n            xinclude=options.xinclude,\n            pretty_print=options.pretty_print,\n            line_by_line=options.line_by_line,\n            encoding=options.encoding,\n            verbose=options.verbose,\n        )\n\n    if options.root_tag and options.verbose:\n        print('</%s>' % options.root_tag)\n\n    return found\n\nif __name__ == \"__main__\":\n    try:\n        options, args = parse_options()\n        found = main(options, args)\n        if found:\n            sys.exit(0)\n        else:\n            sys.exit(1)\n    except et.XPathSyntaxError:\n        error(sys.exc_info()[1])\n        sys.exit(4)\n    except KeyboardInterrupt:\n        pass\n", "tools/pypistats.py": "#!/usr/bin/env python3\nimport json\nfrom collections import defaultdict\nfrom urllib.request import urlopen\nimport ssl\n\nPACKAGE = \"lxml\"\n\n\ndef get_stats(stats_type, package=PACKAGE, period=\"month\"):\n    stats_url = f\"https://www.pypistats.org/api/packages/{package}/{stats_type}?period={period}\"\n\n    ctx = ssl.create_default_context()\n    ctx.check_hostname = False\n    ctx.verify_mode = ssl.CERT_NONE\n\n    with urlopen(stats_url, context=ctx) as stats:\n        data = json.load(stats)\n    return data\n\n\ndef aggregate(stats):\n    counts = defaultdict(int)\n    days = defaultdict(int)\n    for entry in stats['data']:\n        category = entry['category']\n        counts[category] += entry['downloads']\n        days[category] += 1\n    return {category: counts[category] / days[category] for category in counts}\n\n\ndef version_sorter(version_and_count):\n    version = version_and_count[0]\n    return tuple(map(int, version.split(\".\"))) if version.replace(\".\", \"\").isdigit() else (2**32,)\n\n\ndef system_sorter(name_and_count):\n    order = ('linux', 'windows', 'darwin')\n    system = name_and_count[0]\n    try:\n        return order.index(system.lower())\n    except ValueError:\n        return len(order)\n\n\ndef print_agg_stats(stats, sort_key=None):\n    total = sum(stats.values())\n    max_len = max(len(category) for category in stats)\n    agg_sum = 0.0\n    for category, count in sorted(stats.items(), key=sort_key, reverse=True):\n        agg_sum += count\n        print(f\"  {category:{max_len}}: {count:-12.1f} / day ({agg_sum / total * 100:-5.1f}%)\")\n\n\ndef main():\n    import sys\n    package_name = sys.argv[1] if len(sys.argv) > 1 else PACKAGE\n\n    counts = get_stats(\"python_minor\", package=package_name)\n    stats = aggregate(counts)\n    print(\"Downloads by Python version:\")\n    print_agg_stats(stats, sort_key=version_sorter)\n\n    print()\n    counts = get_stats(\"system\", package=package_name)\n    stats = aggregate(counts)\n    print(\"Downloads by system:\")\n    print_agg_stats(stats, sort_key=system_sorter)\n\n    total = sum(stats.values())\n    days = {\"month\": 30, \"week\": 7, \"day\": 1}\n    print(f\"Total downloads: {total * days['month']:-12,.1f}\")\n\n\nif __name__ == '__main__':\n    main()\n", "benchmark/bench_objectify.py": "from itertools import *\n\nimport benchbase\nfrom benchbase import (with_text, children, nochange)\n\n############################################################\n# Benchmarks\n############################################################\n\nclass BenchMark(benchbase.TreeBenchMark):\n    repeat100  = range(100)\n    repeat1000 = range(1000)\n    repeat3000 = range(3000)\n\n    def __init__(self, lib):\n        from lxml import etree, objectify\n        self.objectify = objectify\n        parser = etree.XMLParser(remove_blank_text=True)\n        lookup = objectify.ObjectifyElementClassLookup()\n        parser.setElementClassLookup(lookup)\n        super(BenchMark, self).__init__(etree, parser)\n\n    @nochange\n    def bench_attribute(self, root):\n        \"1 2 4\"\n        for i in self.repeat3000:\n            root.zzzzz\n\n    def bench_attribute_assign_int(self, root):\n        \"1 2 4\"\n        for i in self.repeat3000:\n            root.XYZ = 5\n\n    def bench_attribute_assign_string(self, root):\n        \"1 2 4\"\n        for i in self.repeat3000:\n            root.XYZ = \"5\"\n\n    @nochange\n    def bench_attribute_cached(self, root):\n        \"1 2 4\"\n        cache = root.zzzzz\n        for i in self.repeat3000:\n            root.zzzzz\n\n    @nochange\n    def bench_attributes_deep(self, root):\n        \"1 2 4\"\n        for i in self.repeat3000:\n            root.zzzzz['{cdefg}a00001']\n\n    @nochange\n    def bench_attributes_deep_cached(self, root):\n        \"1 2 4\"\n        cache1 = root.zzzzz\n        cache2 = cache1['{cdefg}a00001']\n        for i in self.repeat3000:\n            root.zzzzz['{cdefg}a00001']\n\n    @nochange\n    def bench_objectpath(self, root):\n        \"1 2 4\"\n        path = self.objectify.ObjectPath(\".zzzzz\")\n        for i in self.repeat3000:\n            path(root)\n\n    @nochange\n    def bench_objectpath_deep(self, root):\n        \"1 2 4\"\n        path = self.objectify.ObjectPath(\".zzzzz.{cdefg}a00001\")\n        for i in self.repeat3000:\n            path(root)\n\n    @nochange\n    def bench_objectpath_deep_cached(self, root):\n        \"1 2 4\"\n        cache1 = root.zzzzz\n        cache2 = cache1['{cdefg}a00001']\n        path = self.objectify.ObjectPath(\".zzzzz.{cdefg}a00001\")\n        for i in self.repeat3000:\n            path(root)\n\n    @with_text(text=True, utext=True, no_text=True)\n    def bench_annotate(self, root):\n        self.objectify.annotate(root)\n\n    @nochange\n    def bench_descendantpaths(self, root):\n        root.descendantpaths()\n\n    @nochange\n    @with_text(text=True)\n    def bench_type_inference(self, root):\n        \"1 2 4\"\n        el = root.aaaaa\n        for i in self.repeat1000:\n            el.getchildren()\n\n    @nochange\n    @with_text(text=True)\n    def bench_type_inference_annotated(self, root):\n        \"1 2 4\"\n        el = root.aaaaa\n        self.objectify.annotate(el)\n        for i in self.repeat1000:\n            el.getchildren()\n\n    @nochange\n    @children\n    def bench_elementmaker(self, children):\n        E = self.objectify.E\n        for child in children:\n            root = E.this(\n                \"test\",\n                E.will(\n                    E.do(\"nothing\"),\n                    E.special,\n                    )\n                )\n\nif __name__ == '__main__':\n    benchbase.main(BenchMark)\n", "benchmark/bench_etree.py": "import copy\nfrom io import BytesIO\nfrom itertools import *\n\nimport benchbase\nfrom benchbase import (with_attributes, with_text, onlylib,\n                       serialized, children, nochange)\n\nTEXT  = \"some ASCII text\"\nUTEXT = u\"some klingon: \\uF8D2\"\n\n############################################################\n# Benchmarks\n############################################################\n\nclass BenchMark(benchbase.TreeBenchMark):\n    @nochange\n    def bench_iter_children(self, root):\n        for child in root:\n            pass\n\n    @nochange\n    def bench_iter_children_reversed(self, root):\n        for child in reversed(root):\n            pass\n\n    @nochange\n    def bench_first_child(self, root):\n        for i in self.repeat1000:\n            child = root[0]\n\n    @nochange\n    def bench_last_child(self, root):\n        for i in self.repeat1000:\n            child = root[-1]\n\n    @nochange\n    def bench_middle_child(self, root):\n        pos = len(root) // 2\n        for i in self.repeat1000:\n            child = root[pos]\n\n    @nochange\n    @with_attributes(False)\n    @with_text(text=True)\n    def bench_tostring_text_ascii(self, root):\n        self.etree.tostring(root, method=\"text\")\n\n    @nochange\n    @with_attributes(False)\n    @with_text(text=True, utext=True)\n    def bench_tostring_text_unicode(self, root):\n        self.etree.tostring(root, method=\"text\", encoding='unicode')\n\n    @nochange\n    @with_attributes(False)\n    @with_text(text=True, utext=True)\n    def bench_tostring_text_utf16(self, root):\n        self.etree.tostring(root, method=\"text\", encoding='UTF-16')\n\n    @nochange\n    @with_attributes(False)\n    @with_text(text=True, utext=True)\n    @onlylib('lxe')\n    @children\n    def bench_tostring_text_utf8_with_tail(self, children):\n        for child in children:\n            self.etree.tostring(child, method=\"text\",\n                                encoding='UTF-8', with_tail=True)\n\n    @nochange\n    @with_attributes(True, False)\n    @with_text(text=True, utext=True)\n    def bench_tostring_utf8(self, root):\n        self.etree.tostring(root, encoding='UTF-8')\n\n    @nochange\n    @with_attributes(True, False)\n    @with_text(text=True, utext=True)\n    def bench_tostring_utf16(self, root):\n        self.etree.tostring(root, encoding='UTF-16')\n\n    @nochange\n    @with_attributes(True, False)\n    @with_text(text=True, utext=True)\n    def bench_tostring_utf8_unicode_XML(self, root):\n        xml = self.etree.tostring(root, encoding='UTF-8').decode('UTF-8')\n        self.etree.XML(xml)\n\n    @nochange\n    @with_attributes(True, False)\n    @with_text(text=True, utext=True)\n    def bench_write_utf8_parse_bytesIO(self, root):\n        f = BytesIO()\n        self.etree.ElementTree(root).write(f, encoding='UTF-8')\n        f.seek(0)\n        self.etree.parse(f)\n\n    @with_attributes(True, False)\n    @with_text(text=True, utext=True)\n    @serialized\n    def bench_parse_bytesIO(self, root_xml):\n        f = BytesIO(root_xml)\n        self.etree.parse(f)\n\n    @with_attributes(True, False)\n    @with_text(text=True, utext=True)\n    @serialized\n    def bench_XML(self, root_xml):\n        self.etree.XML(root_xml)\n\n    @with_attributes(True, False)\n    @with_text(text=True, utext=True)\n    @serialized\n    def bench_iterparse_bytesIO(self, root_xml):\n        f = BytesIO(root_xml)\n        for event, element in self.etree.iterparse(f):\n            pass\n\n    @with_attributes(True, False)\n    @with_text(text=True, utext=True)\n    @serialized\n    def bench_iterparse_bytesIO_clear(self, root_xml):\n        f = BytesIO(root_xml)\n        for event, element in self.etree.iterparse(f):\n            element.clear()\n\n    def bench_append_from_document(self, root1, root2):\n        # == \"1,2 2,3 1,3 3,1 3,2 2,1\" # trees 1 and 2, or 2 and 3, or ...\n        for el in root2:\n            root1.append(el)\n\n    def bench_insert_from_document(self, root1, root2):\n        pos = len(root1)//2\n        for el in root2:\n            root1.insert(pos, el)\n            pos = pos + 1\n\n    def bench_rotate_children(self, root):\n        # == \"1 2 3\" # runs on any single tree independently\n        for i in range(100):\n            el = root[0]\n            del root[0]\n            root.append(el)\n\n    def bench_reorder(self, root):\n        for i in range(1,len(root)//2):\n            el = root[0]\n            del root[0]\n            root[-i:-i] = [ el ]\n\n    def bench_reorder_slice(self, root):\n        for i in range(1,len(root)//2):\n            els = root[0:1]\n            del root[0]\n            root[-i:-i] = els\n\n    def bench_clear(self, root):\n        root.clear()\n\n    @nochange\n    @children\n    def bench_has_children(self, children):\n        for child in children:\n            if child and child and child and child and child:\n                pass\n\n    @nochange\n    @children\n    def bench_len(self, children):\n        for child in children:\n            map(len, repeat(child, 20))\n\n    @children\n    def bench_create_subelements(self, children):\n        SubElement = self.etree.SubElement\n        for child in children:\n            SubElement(child, '{test}test')\n\n    def bench_append_elements(self, root):\n        Element = self.etree.Element\n        for child in root:\n            el = Element('{test}test')\n            child.append(el)\n\n    @nochange\n    @children\n    def bench_makeelement(self, children):\n        empty_attrib = {}\n        for child in children:\n            child.makeelement('{test}test', empty_attrib)\n\n    @nochange\n    @children\n    def bench_create_elements(self, children):\n        Element = self.etree.Element\n        for child in children:\n            Element('{test}test')\n\n    @children\n    def bench_replace_children_element(self, children):\n        Element = self.etree.Element\n        for child in children:\n            el = Element('{test}test')\n            child[:] = [el]\n\n    @children\n    def bench_replace_children(self, children):\n        els = [ self.etree.Element(\"newchild\") ]\n        for child in children:\n            child[:] = els\n\n    def bench_remove_children(self, root):\n        for child in root:\n            root.remove(child)\n\n    def bench_remove_children_reversed(self, root):\n        for child in reversed(root):\n            root.remove(child)\n\n    @children\n    def bench_set_attributes(self, children):\n        for child in children:\n            child.set('a', 'bla')\n\n    @with_attributes(True)\n    @children\n    @nochange\n    def bench_get_attributes(self, children):\n        for child in children:\n            child.get('bla1')\n            child.get('{attr}test1')\n\n    @children\n    def bench_setget_attributes(self, children):\n        for child in children:\n            child.set('a', 'bla')\n        for child in children:\n            child.get('a')\n\n    @nochange\n    def bench_root_getchildren(self, root):\n        root.getchildren()\n\n    @nochange\n    def bench_root_list_children(self, root):\n        list(root)\n\n    @nochange\n    @children\n    def bench_getchildren(self, children):\n        for child in children:\n            child.getchildren()\n\n    @nochange\n    @children\n    def bench_get_children_slice(self, children):\n        for child in children:\n            child[:]\n\n    @nochange\n    @children\n    def bench_get_children_slice_2x(self, children):\n        for child in children:\n            child[:]\n            child[:]\n\n    @nochange\n    @children\n    @with_attributes(True, False)\n    @with_text(utext=True, text=True, no_text=True)\n    def bench_deepcopy(self, children):\n        for child in children:\n            copy.deepcopy(child)\n\n    @nochange\n    @with_attributes(True, False)\n    @with_text(utext=True, text=True, no_text=True)\n    def bench_deepcopy_all(self, root):\n        copy.deepcopy(root)\n\n    @nochange\n    @children\n    def bench_tag(self, children):\n        for child in children:\n            child.tag\n\n    @nochange\n    @children\n    def bench_tag_repeat(self, children):\n        for child in children:\n            for i in self.repeat100:\n                child.tag\n\n    @nochange\n    @with_text(utext=True, text=True, no_text=True)\n    @children\n    def bench_text(self, children):\n        for child in children:\n            child.text\n\n    @nochange\n    @with_text(utext=True, text=True, no_text=True)\n    @children\n    def bench_text_repeat(self, children):\n        for child in children:\n            for i in self.repeat500:\n                child.text\n\n    @children\n    def bench_set_text(self, children):\n        text = TEXT\n        for child in children:\n            child.text = text\n\n    @children\n    def bench_set_utext(self, children):\n        text = UTEXT\n        for child in children:\n            child.text = text\n\n    @nochange\n    @onlylib('lxe')\n    def bench_index(self, root):\n        for child in root:\n            root.index(child)\n\n    @nochange\n    @onlylib('lxe')\n    def bench_index_slice(self, root):\n        for child in root[5:100]:\n            root.index(child, 5, 100)\n\n    @nochange\n    @onlylib('lxe')\n    def bench_index_slice_neg(self, root):\n        for child in root[-100:-5]:\n            root.index(child, start=-100, stop=-5)\n\n    @nochange\n    def bench_iter_all(self, root):\n        list(root.iter())\n\n    @nochange\n    def bench_iter_one_at_a_time(self, root):\n        list(islice(root.iter(), 2**30, None))\n\n    @nochange\n    def bench_iter_islice(self, root):\n        list(islice(root.iter(), 10, 110))\n\n    @nochange\n    def bench_iter_tag(self, root):\n        list(islice(root.iter(self.SEARCH_TAG), 3, 10))\n\n    @nochange\n    def bench_iter_tag_all(self, root):\n        list(root.iter(self.SEARCH_TAG))\n\n    @nochange\n    def bench_iter_tag_one_at_a_time(self, root):\n        list(islice(root.iter(self.SEARCH_TAG), 2**30, None))\n\n    @nochange\n    def bench_iter_tag_none(self, root):\n        list(root.iter(\"{ThisShould}NeverExist\"))\n\n    @nochange\n    def bench_iter_tag_text(self, root):\n        [ e.text for e in root.iter(self.SEARCH_TAG) ]\n\n    @nochange\n    def bench_findall(self, root):\n        root.findall(\".//*\")\n\n    @nochange\n    def bench_findall_child(self, root):\n        root.findall(\".//*/\" + self.SEARCH_TAG)\n\n    @nochange\n    def bench_findall_tag(self, root):\n        root.findall(\".//\" + self.SEARCH_TAG)\n\n    @nochange\n    def bench_findall_path(self, root):\n        root.findall(\".//*[%s]/./%s/./*\" % (self.SEARCH_TAG, self.SEARCH_TAG))\n\n    @nochange\n    @onlylib('lxe')\n    def bench_xpath_path(self, root):\n        ns, tag = self.SEARCH_TAG[1:].split('}')\n        root.xpath(\".//*[p:%s]/./p:%s/./*\" % (tag,tag),\n                   namespaces = {'p':ns})\n\n    @nochange\n    def bench_iterfind(self, root):\n        list(root.iterfind(\".//*\"))\n\n    @nochange\n    def bench_iterfind_tag(self, root):\n        list(root.iterfind(\".//\" + self.SEARCH_TAG))\n\n    @nochange\n    def bench_iterfind_islice(self, root):\n        list(islice(root.iterfind(\".//*\"), 10, 110))\n\n    _bench_xpath_single_xpath = None\n\n    @nochange\n    @onlylib('lxe')\n    def bench_xpath_single(self, root):\n        xpath = self._bench_xpath_single_xpath\n        if xpath is None:\n            ns, tag = self.SEARCH_TAG[1:].split('}')\n            xpath = self._bench_xpath_single_xpath = self.etree.XPath(\n                './/p:%s[1]' % tag, namespaces={'p': ns})\n        xpath(root)\n\n    @nochange\n    def bench_find_single(self, root):\n        root.find(\".//%s\" % self.SEARCH_TAG)\n\n    @nochange\n    def bench_iter_single(self, root):\n        next(root.iter(self.SEARCH_TAG))\n\n    _bench_xpath_two_xpath = None\n\n    @nochange\n    @onlylib('lxe')\n    def bench_xpath_two(self, root):\n        xpath = self._bench_xpath_two_xpath\n        if xpath is None:\n            ns, tag = self.SEARCH_TAG[1:].split('}')\n            xpath = self._bench_xpath_two_xpath = self.etree.XPath(\n                './/p:%s[position() < 3]' % tag, namespaces={'p': ns})\n        xpath(root)\n\n    @nochange\n    def bench_iterfind_two(self, root):\n        it = root.iterfind(\".//%s\" % self.SEARCH_TAG)\n        next(it)\n        next(it)\n\n    @nochange\n    def bench_iter_two(self, root):\n        it = root.iter(self.SEARCH_TAG)\n        next(it)\n        next(it)\n\n\nif __name__ == '__main__':\n    benchbase.main(BenchMark)\n", "benchmark/bench_xslt.py": "from itertools import *\n\nimport benchbase\nfrom benchbase import onlylib\n\n############################################################\n# Benchmarks\n############################################################\n\nclass XSLTBenchMark(benchbase.TreeBenchMark):\n    @onlylib('lxe')\n    def bench_xslt_extensions_old(self, root):\n        tree = self.etree.XML(\"\"\"\\\n<xsl:stylesheet version=\"1.0\"\n   xmlns:l=\"test\"\n   xmlns:testns=\"testns\"\n   xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n  <l:data>TEST</l:data>\n  <xsl:template match=\"/\">\n    <l:result>\n      <xsl:for-each select=\"*/*\">\n        <xsl:copy-of select=\"testns:child(.)\"/>\n      </xsl:for-each>\n    </l:result>\n  </xsl:template>\n</xsl:stylesheet>\n\"\"\")\n        def return_child(_, elements):\n            return elements[0][0]\n\n        extensions = {('testns', 'child') : return_child}\n\n        transform = self.etree.XSLT(tree, extensions)\n        for i in range(10):\n            transform(root)\n\n    @onlylib('lxe')\n    def bench_xslt_document(self, root):\n        transform = self.etree.XSLT(self.etree.XML(\"\"\"\\\n<xsl:stylesheet version=\"1.0\"\n   xmlns:l=\"test\"\n   xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n  <l:data>TEST</l:data>\n  <xsl:template match=\"/\">\n    <l:result>\n      <xsl:for-each select=\"*/*\">\n        <l:test><xsl:copy-of select=\"document('')//l:data/text()\"/></l:test>\n      </xsl:for-each>\n    </l:result>\n  </xsl:template>\n</xsl:stylesheet>\n\"\"\"))\n        transform(root)\n\nif __name__ == '__main__':\n    benchbase.main(XSLTBenchMark)\n", "benchmark/bench_xpath.py": "from itertools import *\n\nimport benchbase\nfrom benchbase import onlylib, children, nochange\n\n############################################################\n# Benchmarks\n############################################################\n\nclass XPathBenchMark(benchbase.TreeBenchMark):\n    @nochange\n    @onlylib('lxe')\n    @children\n    def bench_xpath_class(self, children):\n        xpath = self.etree.XPath(\"./*[1]\")\n        for child in children:\n            xpath(child)\n\n    @nochange\n    @onlylib('lxe')\n    @children\n    def bench_xpath_class_repeat(self, children):\n        for child in children:\n            xpath = self.etree.XPath(\"./*[1]\")\n            xpath(child)\n\n    @nochange\n    @onlylib('lxe')\n    def bench_xpath_element(self, root):\n        xpath = self.etree.XPathElementEvaluator(root)\n        for child in root:\n            xpath.evaluate(\"./*[1]\")\n\n    @nochange\n    @onlylib('lxe')\n    @children\n    def bench_xpath_method(self, children):\n        for child in children:\n            child.xpath(\"./*[1]\")\n\n    @nochange\n    @onlylib('lxe')\n    @children\n    def bench_multiple_xpath_or(self, children):\n        xpath = self.etree.XPath(\".//p:a00001|.//p:b00001|.//p:c00001\",\n                                 namespaces={'p':'cdefg'})\n        for child in children:\n            xpath(child)\n\n    @nochange\n    @onlylib('lxe')\n    @children\n    def bench_multiple_iter_tag(self, children):\n        for child in children:\n            list(child.iter(\"{cdefg}a00001\"))\n            list(child.iter(\"{cdefg}b00001\"))\n            list(child.iter(\"{cdefg}c00001\"))\n\n    @nochange\n    @onlylib('lxe')\n    @children\n    def bench_xpath_old_extensions(self, children):\n        def return_child(_, elements):\n            if elements:\n                return elements[0][0]\n            else:\n                return ()\n        extensions = {(\"test\", \"child\") : return_child}\n        xpath = self.etree.XPath(\"t:child(.)\", namespaces={\"t\":\"test\"},\n                                 extensions=extensions)\n        for child in children:\n            xpath(child)\n\n    @nochange\n    @onlylib('lxe')\n    @children\n    def bench_xpath_extensions(self, children):\n        def return_child(_, elements):\n            if elements:\n                return elements[0][0]\n            else:\n                return ()\n        self.etree.FunctionNamespace(\"testns\")[\"t\"] = return_child\n\n        try:\n            xpath = self.etree.XPath(\"test:t(.)\", namespaces={\"test\":\"testns\"})\n            for child in children:\n                xpath(child)\n        finally:\n            del self.etree.FunctionNamespace(\"testns\")[\"t\"]\n\nif __name__ == '__main__':\n    benchbase.main(XPathBenchMark)\n", "benchmark/benchbase.py": "import sys, re, string, copy, gc\nfrom itertools import *\nimport time\n\ntry:\n    izip\nexcept NameError:\n    izip = zip  # Py3\n\ndef exec_(code, glob):\n    if sys.version_info[0] >= 3:\n        exec(code, glob)\n    else:\n        exec(\"exec code in glob\")\n\n\nTREE_FACTOR = 1 # increase tree size with '-l / '-L' cmd option\n\n_TEXT  = \"some ASCII text\" * TREE_FACTOR\n_UTEXT = u\"some klingon: \\uF8D2\" * TREE_FACTOR\n_ATTRIBUTES = {\n    '{attr}test1' : _TEXT,\n    '{attr}test2' : _TEXT,\n    'bla1'        : _TEXT,\n    'bla2'        : _TEXT,\n    'bla3'        : _TEXT\n    }\n\n\ndef initArgs(argv):\n    global TREE_FACTOR\n    try:\n        argv.remove('-l')\n        # use large trees\n        TREE_FACTOR *= 2\n    except ValueError:\n        pass\n\n    try:\n        argv.remove('-L')\n        # use LARGE trees\n        TREE_FACTOR *= 2\n    except ValueError:\n        pass\n\n############################################################\n# benchmark decorators\n############################################################\n\ndef with_attributes(*use_attributes):\n    \"Decorator for benchmarks that use attributes\"\n    vmap = {False : 0, True : 1}\n    values = [ vmap[bool(v)] for v in use_attributes ]\n    def set_value(function):\n        try:\n            function.ATTRIBUTES.update(values)\n        except AttributeError:\n            function.ATTRIBUTES = set(values)\n        return function\n    return set_value\n\ndef with_text(no_text=False, text=False, utext=False):\n    \"Decorator for benchmarks that use text\"\n    values = []\n    if no_text:\n        values.append(0)\n    if text:\n        values.append(1)\n    if utext:\n        values.append(2)\n    def set_value(function):\n        try:\n            function.TEXT.add(values)\n        except AttributeError:\n            function.TEXT = set(values)\n        return function\n    return set_value\n\ndef onlylib(*libs):\n    \"Decorator to restrict benchmarks to specific libraries\"\n    def set_libs(function):\n        if libs:\n            function.LIBS = libs\n        return function\n    return set_libs\n\ndef serialized(function):\n    \"Decorator for benchmarks that require serialized XML data\"\n    function.STRING = True\n    return function\n\ndef children(function):\n    \"Decorator for benchmarks that require a list of root children\"\n    function.CHILDREN = True\n    return function\n\ndef nochange(function):\n    \"Decorator for benchmarks that do not change the XML tree\"\n    function.NO_CHANGE = True\n    return function\n\n############################################################\n# benchmark baseclass\n############################################################\n\nclass SkippedTest(Exception):\n    pass\n\nclass TreeBenchMark(object):\n    atoz = string.ascii_lowercase\n    repeat100  = range(100)\n    repeat500  = range(500)\n    repeat1000 = range(1000)\n\n    _LIB_NAME_MAP = {\n        'etree'        : 'lxe',\n        'ElementTree'  : 'ET',\n        'cElementTree' : 'cET'\n        }\n\n    SEARCH_TAG = \"{cdefg}a00001\"\n\n    def __init__(self, etree, etree_parser=None):\n        self.etree = etree\n        libname = etree.__name__.split('.')[-1]\n        self.lib_name = self._LIB_NAME_MAP.get(libname, libname)\n\n        if libname == 'etree':\n            deepcopy = copy.deepcopy\n            def set_property(root, fname):\n                xml = self._serialize_tree(root)\n                if etree_parser is not None:\n                    setattr(self, fname, lambda : etree.XML(xml, etree_parser))\n                else:\n                    setattr(self, fname, lambda : deepcopy(root))\n                setattr(self, fname + '_xml', lambda : xml)\n                setattr(self, fname + '_children', lambda : root[:])\n        else:\n            def set_property(root, fname):\n                setattr(self, fname, self.et_make_clone_factory(root))\n                xml = self._serialize_tree(root)\n                setattr(self, fname + '_xml', lambda : xml)\n                setattr(self, fname + '_children', lambda : root[:])\n\n        attribute_list = list(enumerate( [{}, _ATTRIBUTES] ))\n        text_list = list(enumerate( [None, _TEXT, _UTEXT] ))\n        build_name = self._tree_builder_name\n\n        self.setup_times = []\n        for tree in self._all_trees():\n            times = []\n            self.setup_times.append(times)\n            setup = getattr(self, '_setup_tree%d' % tree)\n            for an, attributes in attribute_list:\n                for tn, text in text_list:\n                    root, t = setup(text, attributes)\n                    times.append(t)\n                    set_property(root, build_name(tree, tn, an))\n\n    def _tree_builder_name(self, tree, tn, an):\n        return '_root%d_T%d_A%d' % (tree, tn, an)\n\n    def tree_builder(self, tree, tn, an, serial, children):\n        name = self._tree_builder_name(tree, tn, an)\n        if serial:\n            name += '_xml'\n        elif children:\n            name += '_children'\n        return getattr(self, name)\n\n    def _serialize_tree(self, root):\n        return self.etree.tostring(root, encoding='UTF-8')\n\n    def et_make_clone_factory(self, elem):\n        def generate_elem(append, elem, level):\n            var = \"e\" + str(level)\n            arg = repr(elem.tag)\n            if elem.attrib:\n                arg += \", **%r\" % elem.attrib\n            if level == 1:\n                append(\" e1 = Element(%s)\" % arg)\n            else:\n                append(\" %s = SubElement(e%d, %s)\" % (var, level-1, arg))\n            if elem.text:\n                append(\" %s.text = %r\" % (var, elem.text))\n            if elem.tail:\n                append(\" %s.tail = %r\" % (var, elem.tail))\n            for e in elem:\n                generate_elem(append, e, level+1)\n        # generate code for a function that creates a tree\n        output = [\"def element_factory():\"]\n        generate_elem(output.append, elem, 1)\n        output.append(\" return e1\")\n        # setup global function namespace\n        namespace = {\n            \"Element\"    : self.etree.Element,\n            \"SubElement\" : self.etree.SubElement\n            }\n\n        # create function object\n        exec_(\"\\n\".join(output), namespace)\n        return namespace[\"element_factory\"]\n\n    def _all_trees(self):\n        all_trees = []\n        for name in dir(self):\n            if name.startswith('_setup_tree'):\n                all_trees.append(int(name[11:]))\n        return all_trees\n\n    def _setup_tree1(self, text, attributes):\n        \"tree with 26 2nd level and 520 * TREE_FACTOR 3rd level children\"\n        atoz = self.atoz\n        SubElement = self.etree.SubElement\n        current_time = time.time\n        t = current_time()\n        root = self.etree.Element('{abc}rootnode')\n        for ch1 in atoz:\n            el = SubElement(root, \"{abc}\"+ch1*5, attributes)\n            el.text = text\n            for ch2 in atoz:\n                tag = \"{cdefg}%s00001\" % ch2\n                for i in range(20 * TREE_FACTOR):\n                    SubElement(el, tag).tail = text\n        t = current_time() - t\n        return root, t\n\n    def _setup_tree2(self, text, attributes):\n        \"tree with 520 * TREE_FACTOR 2nd level and 26 3rd level children\"\n        atoz = self.atoz\n        SubElement = self.etree.SubElement\n        current_time = time.time\n        t = current_time()\n        root = self.etree.Element('{abc}rootnode')\n        for ch1 in atoz:\n            for i in range(20 * TREE_FACTOR):\n                el = SubElement(root, \"{abc}\"+ch1*5, attributes)\n                el.text = text\n                for ch2 in atoz:\n                    SubElement(el, \"{cdefg}%s00001\" % ch2).tail = text\n        t = current_time() - t\n        return root, t\n\n    def _setup_tree3(self, text, attributes):\n        \"tree of depth 8 + TREE_FACTOR with 3 children per node\"\n        SubElement = self.etree.SubElement\n        current_time = time.time\n        t = current_time()\n        root = self.etree.Element('{abc}rootnode')\n        children = [root]\n        for i in range(6 + TREE_FACTOR):\n            children = [ SubElement(c, \"{cdefg}a%05d\" % (i%8), attributes)\n                         for i,c in enumerate(chain(children, children, children)) ]\n        for child in children:\n            child.text = text\n            child.tail = text\n        t = current_time() - t\n        return root, t\n\n    def _setup_tree4(self, text, attributes):\n        \"small tree with 26 2nd level and 2 3rd level children\"\n        SubElement = self.etree.SubElement\n        current_time = time.time\n        t = current_time()\n        root = self.etree.Element('{abc}rootnode')\n        for ch1 in self.atoz:\n            el = SubElement(root, \"{abc}\"+ch1*5, attributes)\n            el.text = text\n            SubElement(el, \"{cdefg}a00001\", attributes).tail = text\n            SubElement(el, \"{cdefg}z00000\", attributes).tail = text\n        t = current_time() - t\n        return root, t\n\n    def benchmarks(self):\n        \"\"\"Returns a list of all benchmarks.\n\n        A benchmark is a tuple containing a method name and a list of tree\n        numbers.  Trees are prepared by the setup function.\n        \"\"\"\n        all_trees = self._all_trees()\n        benchmarks = []\n        for name in dir(self):\n            if not name.startswith('bench_'):\n                continue\n            method = getattr(self, name)\n            if hasattr(method, 'LIBS') and self.lib_name not in method.LIBS:\n                method_call = None\n            else:\n                method_call = method\n            if method.__doc__:\n                tree_sets = method.__doc__.split()\n            else:\n                tree_sets = ()\n            if tree_sets:\n                tree_tuples = [list(map(int, tree_set.split(',')))\n                               for tree_set in tree_sets]\n            else:\n                try:\n                    arg_count = method.func_code.co_argcount - 1\n                except AttributeError:\n                    try:\n                        arg_count = method.__code__.co_argcount - 1\n                    except AttributeError:\n                        arg_count = 1\n                tree_tuples = self._permutations(all_trees, arg_count)\n\n            serialized = getattr(method, 'STRING',   False)\n            children   = getattr(method, 'CHILDREN', False)\n            no_change  = getattr(method, 'NO_CHANGE', False)\n\n            for tree_tuple in tree_tuples:\n                for tn in sorted(getattr(method, 'TEXT', (0,))):\n                    for an in sorted(getattr(method, 'ATTRIBUTES', (0,))):\n                        benchmarks.append((name, method_call, tree_tuple,\n                                           tn, an, serialized, children,\n                                           no_change))\n\n        return benchmarks\n\n    def _permutations(self, seq, count):\n        def _permutations(prefix, remainder, count):\n            if count == 0:\n                return [ prefix[:] ]\n            count -= 1\n            perms = []\n            prefix.append(None)\n            for pos, el in enumerate(remainder):\n                new_remainder = remainder[:pos] + remainder[pos+1:]\n                prefix[-1] = el\n                perms.extend( _permutations(prefix, new_remainder, count) )\n            prefix.pop()\n            return perms\n        return _permutations([], seq, count)\n\n############################################################\n# Prepare and run benchmark suites\n############################################################\n\ndef buildSuites(benchmark_class, etrees, selected):\n    benchmark_suites = list(map(benchmark_class, etrees))\n\n    # sorted by name and tree tuple\n    benchmarks = [ sorted(b.benchmarks()) for b in benchmark_suites ]\n\n    selected = [ re.compile(r).search for r in selected ]\n\n    if selected:\n        benchmarks = [ [ b for b in bs\n                         if [ match for match in selected\n                              if match(b[0]) ] ]\n                       for bs in benchmarks ]\n\n    return benchmark_suites, benchmarks\n\ndef build_treeset_name(trees, tn, an, serialized, children):\n    text = {0:'-', 1:'S', 2:'U'}[tn]\n    attr = {0:'-', 1:'A'}[an]\n    ser  = {True:'X', False:'T'}[serialized]\n    chd  = {True:'C', False:'R'}[children]\n    return \"%s%s%s%s T%s\" % (text, attr, ser, chd, ',T'.join(map(str, trees))[:6])\n\ndef printSetupTimes(benchmark_suites):\n    print(\"Setup times for trees in seconds:\")\n    for b in benchmark_suites:\n        sys.stdout.write(\"%-3s:     \" % b.lib_name)\n        for an in (0,1):\n            for tn in (0,1,2):\n                sys.stdout.write('  %s   ' %\n                    build_treeset_name((), tn, an, False, False)[:2])\n        print('')\n        for i, tree_times in enumerate(b.setup_times):\n            print(\"     T%d: %s\" % (i+1, ' '.join(\"%6.4f\" % t for t in tree_times)))\n    print('')\n\ndef runBench(suite, method_name, method_call, tree_set, tn, an,\n             serial, children, no_change):\n    if method_call is None:\n        raise SkippedTest\n\n    current_time = time.time\n    call_repeat = range(10)\n\n    tree_builders = [ suite.tree_builder(tree, tn, an, serial, children)\n                      for tree in tree_set ]\n\n    rebuild_trees = not no_change and not serial\n\n    args = tuple([ build() for build in tree_builders ])\n    method_call(*args) # run once to skip setup overhead\n\n    times = []\n    for i in range(3):\n        gc.collect()\n        gc.disable()\n        t = -1\n        for i in call_repeat:\n            if rebuild_trees:\n                args = [ build() for build in tree_builders ]\n            t_one_call = current_time()\n            method_call(*args)\n            t_one_call = current_time() - t_one_call\n            if t < 0:\n                t = t_one_call\n            else:\n                t = min(t, t_one_call)\n        times.append(1000.0 * t)\n        gc.enable()\n        if rebuild_trees:\n            args = ()\n    args = ()\n    gc.collect()\n    return times\n\n\ndef runBenchmarks(benchmark_suites, benchmarks):\n    for bench_calls in izip(*benchmarks):\n        for lib, (bench, benchmark_setup) in enumerate(izip(benchmark_suites, bench_calls)):\n            bench_name = benchmark_setup[0]\n            tree_set_name = build_treeset_name(*benchmark_setup[-6:-1])\n            sys.stdout.write(\"%-3s: %-28s (%-10s) \" % (\n                bench.lib_name, bench_name[6:34], tree_set_name))\n            sys.stdout.flush()\n\n            try:\n                result = runBench(bench, *benchmark_setup)\n            except SkippedTest:\n                print(\"skipped\")\n            except KeyboardInterrupt:\n                print(\"interrupted by user\")\n                sys.exit(1)\n            except Exception:\n                exc_type, exc_value = sys.exc_info()[:2]\n                print(\"failed: %s: %s\" % (exc_type.__name__, exc_value))\n                exc_type = exc_value = None\n            else:\n                print(\"%9.4f msec/pass, best of (%s)\" % (\n                      min(result), ' '.join(\"%9.4f\" % t for t in result)))\n\n        if len(benchmark_suites) > 1:\n            print('')  # empty line between different benchmarks\n\n############################################################\n# Main program\n############################################################\n\ndef main(benchmark_class):\n    import_lxml = True\n    callgrind_zero = False\n    if len(sys.argv) > 1:\n        try:\n            sys.argv.remove('-i')\n            # run benchmark 'inplace'\n            sys.path.insert(0, 'src')\n        except ValueError:\n            pass\n\n        try:\n            sys.argv.remove('-nolxml')\n            # run without lxml\n            import_lxml = False\n        except ValueError:\n            pass\n\n        try:\n            sys.argv.remove('-z')\n            # reset callgrind after tree setup\n            callgrind_zero = True\n        except ValueError:\n            pass\n\n        initArgs(sys.argv)\n\n    _etrees = []\n    if import_lxml:\n        from lxml import etree\n        _etrees.append(etree)\n        print(\"Using lxml %s (with libxml2 %s)\" % (\n            etree.__version__, '.'.join(map(str, etree.LIBXML_VERSION))))\n\n        try:\n            sys.argv.remove('-fel')\n        except ValueError:\n            pass\n        else:\n            # use fast element creation in lxml.etree\n            etree.set_element_class_lookup(\n                etree.ElementDefaultClassLookup())\n\n    if len(sys.argv) > 1:\n        if '-a' in sys.argv or '-c' in sys.argv:\n            # 'all' or 'C-implementations' ?\n            try:\n                sys.argv.remove('-c')\n            except ValueError:\n                pass\n            try:\n                import cElementTree as cET\n                _etrees.append(cET)\n            except ImportError:\n                try:\n                    import xml.etree.cElementTree as cET\n                    _etrees.append(cET)\n                except ImportError:\n                    pass\n\n        try:\n            # 'all' ?\n            sys.argv.remove('-a')\n        except ValueError:\n            pass\n        else:\n            try:\n                from elementtree import ElementTree as ET\n                _etrees.append(ET)\n            except ImportError:\n                try:\n                    from xml.etree import ElementTree as ET\n                    _etrees.append(ET)\n                except ImportError:\n                    pass\n\n    if not _etrees:\n        print(\"No library to test. Exiting.\")\n        sys.exit(1)\n\n    print(\"Running benchmarks in Python %s\" % (sys.version_info,))\n\n    print(\"Preparing test suites and trees ...\")\n    selected = set( sys.argv[1:] )\n    benchmark_suites, benchmarks = \\\n                      buildSuites(benchmark_class, _etrees, selected)\n\n    print(\"Running benchmark on\", ', '.join(b.lib_name\n                                            for b in benchmark_suites))\n    print('')\n\n    printSetupTimes(benchmark_suites)\n\n    if callgrind_zero:\n        cmd = open(\"callgrind.cmd\", 'w')\n        cmd.write('+Instrumentation\\n')\n        cmd.write('Zero\\n')\n        cmd.close()\n\n    runBenchmarks(benchmark_suites, benchmarks)\n", "src/lxml/sax.py": "# cython: language_level=2\n\n\"\"\"\nSAX-based adapter to copy trees from/to the Python standard library.\n\nUse the `ElementTreeContentHandler` class to build an ElementTree from\nSAX events.\n\nUse the `ElementTreeProducer` class or the `saxify()` function to fire\nthe SAX events of an ElementTree against a SAX ContentHandler.\n\nSee https://lxml.de/sax.html\n\"\"\"\n\n\nfrom xml.sax.handler import ContentHandler\nfrom lxml import etree\nfrom lxml.etree import ElementTree, SubElement\nfrom lxml.etree import Comment, ProcessingInstruction\n\n\nclass SaxError(etree.LxmlError):\n    \"\"\"General SAX error.\n    \"\"\"\n\n\ndef _getNsTag(tag):\n    if tag[0] == '{':\n        return tuple(tag[1:].split('}', 1))\n    else:\n        return None, tag\n\n\nclass ElementTreeContentHandler(ContentHandler):\n    \"\"\"Build an lxml ElementTree from SAX events.\n    \"\"\"\n    def __init__(self, makeelement=None):\n        ContentHandler.__init__(self)\n        self._root = None\n        self._root_siblings = []\n        self._element_stack = []\n        self._default_ns = None\n        self._ns_mapping = { None : [None] }\n        self._new_mappings = {}\n        if makeelement is None:\n            makeelement = etree.Element\n        self._makeelement = makeelement\n\n    def _get_etree(self):\n        \"Contains the generated ElementTree after parsing is finished.\"\n        return ElementTree(self._root)\n\n    etree = property(_get_etree, doc=_get_etree.__doc__)\n\n    def setDocumentLocator(self, locator):\n        pass\n\n    def startDocument(self):\n        pass\n\n    def endDocument(self):\n        pass\n\n    def startPrefixMapping(self, prefix, uri):\n        self._new_mappings[prefix] = uri\n        try:\n            self._ns_mapping[prefix].append(uri)\n        except KeyError:\n            self._ns_mapping[prefix] = [uri]\n        if prefix is None:\n            self._default_ns = uri\n\n    def endPrefixMapping(self, prefix):\n        ns_uri_list = self._ns_mapping[prefix]\n        ns_uri_list.pop()\n        if prefix is None:\n            self._default_ns = ns_uri_list[-1]\n\n    def _buildTag(self, ns_name_tuple):\n        ns_uri, local_name = ns_name_tuple\n        if ns_uri:\n            el_tag = \"{%s}%s\" % ns_name_tuple\n        elif self._default_ns:\n            el_tag = \"{%s}%s\" % (self._default_ns, local_name)\n        else:\n            el_tag = local_name\n        return el_tag\n\n    def startElementNS(self, ns_name, qname, attributes=None):\n        el_name = self._buildTag(ns_name)\n        if attributes:\n            attrs = {}\n            try:\n                iter_attributes = attributes.iteritems()\n            except AttributeError:\n                iter_attributes = attributes.items()\n\n            for name_tuple, value in iter_attributes:\n                if name_tuple[0]:\n                    attr_name = \"{%s}%s\" % name_tuple\n                else:\n                    attr_name = name_tuple[1]\n                attrs[attr_name] = value\n        else:\n            attrs = None\n\n        element_stack = self._element_stack\n        if self._root is None:\n            element = self._root = \\\n                      self._makeelement(el_name, attrs, self._new_mappings)\n            if self._root_siblings and hasattr(element, 'addprevious'):\n                for sibling in self._root_siblings:\n                    element.addprevious(sibling)\n            del self._root_siblings[:]\n        else:\n            element = SubElement(element_stack[-1], el_name,\n                                 attrs, self._new_mappings)\n        element_stack.append(element)\n\n        self._new_mappings.clear()\n\n    def processingInstruction(self, target, data):\n        pi = ProcessingInstruction(target, data)\n        if self._root is None:\n            self._root_siblings.append(pi)\n        else:\n            self._element_stack[-1].append(pi)\n\n    def endElementNS(self, ns_name, qname):\n        element = self._element_stack.pop()\n        el_tag = self._buildTag(ns_name)\n        if el_tag != element.tag:\n            raise SaxError(\"Unexpected element closed: \" + el_tag)\n\n    def startElement(self, name, attributes=None):\n        if attributes:\n            attributes = {(None, k): v for k, v in attributes.items()}\n        self.startElementNS((None, name), name, attributes)\n\n    def endElement(self, name):\n        self.endElementNS((None, name), name)\n\n    def characters(self, data):\n        last_element = self._element_stack[-1]\n        try:\n            # if there already is a child element, we must append to its tail\n            last_element = last_element[-1]\n            last_element.tail = (last_element.tail or '') + data\n        except IndexError:\n            # otherwise: append to the text\n            last_element.text = (last_element.text or '') + data\n\n    ignorableWhitespace = characters\n\n\nclass ElementTreeProducer:\n    \"\"\"Produces SAX events for an element and children.\n    \"\"\"\n    def __init__(self, element_or_tree, content_handler):\n        try:\n            element = element_or_tree.getroot()\n        except AttributeError:\n            element = element_or_tree\n        self._element = element\n        self._content_handler = content_handler\n        from xml.sax.xmlreader import AttributesNSImpl as attr_class\n        self._attr_class = attr_class\n        self._empty_attributes = attr_class({}, {})\n\n    def saxify(self):\n        self._content_handler.startDocument()\n\n        element = self._element\n        if hasattr(element, 'getprevious'):\n            siblings = []\n            sibling = element.getprevious()\n            while getattr(sibling, 'tag', None) is ProcessingInstruction:\n                siblings.append(sibling)\n                sibling = sibling.getprevious()\n            for sibling in siblings[::-1]:\n                self._recursive_saxify(sibling, {})\n\n        self._recursive_saxify(element, {})\n\n        if hasattr(element, 'getnext'):\n            sibling = element.getnext()\n            while getattr(sibling, 'tag', None) is ProcessingInstruction:\n                self._recursive_saxify(sibling, {})\n                sibling = sibling.getnext()\n\n        self._content_handler.endDocument()\n\n    def _recursive_saxify(self, element, parent_nsmap):\n        content_handler = self._content_handler\n        tag = element.tag\n        if tag is Comment or tag is ProcessingInstruction:\n            if tag is ProcessingInstruction:\n                content_handler.processingInstruction(\n                    element.target, element.text)\n            tail = element.tail\n            if tail:\n                content_handler.characters(tail)\n            return\n\n        element_nsmap = element.nsmap\n        new_prefixes = []\n        if element_nsmap != parent_nsmap:\n            # There have been updates to the namespace\n            for prefix, ns_uri in element_nsmap.items():\n                if parent_nsmap.get(prefix) != ns_uri:\n                    new_prefixes.append( (prefix, ns_uri) )\n\n        attribs = element.items()\n        if attribs:\n            attr_values = {}\n            attr_qnames = {}\n            for attr_ns_name, value in attribs:\n                attr_ns_tuple = _getNsTag(attr_ns_name)\n                attr_values[attr_ns_tuple] = value\n                attr_qnames[attr_ns_tuple] = self._build_qname(\n                    attr_ns_tuple[0], attr_ns_tuple[1], element_nsmap,\n                    preferred_prefix=None, is_attribute=True)\n            sax_attributes = self._attr_class(attr_values, attr_qnames)\n        else:\n            sax_attributes = self._empty_attributes\n\n        ns_uri, local_name = _getNsTag(tag)\n        qname = self._build_qname(\n            ns_uri, local_name, element_nsmap, element.prefix, is_attribute=False)\n\n        for prefix, uri in new_prefixes:\n            content_handler.startPrefixMapping(prefix, uri)\n        content_handler.startElementNS(\n            (ns_uri, local_name), qname, sax_attributes)\n        text = element.text\n        if text:\n            content_handler.characters(text)\n        for child in element:\n            self._recursive_saxify(child, element_nsmap)\n        content_handler.endElementNS((ns_uri, local_name), qname)\n        for prefix, uri in new_prefixes:\n            content_handler.endPrefixMapping(prefix)\n        tail = element.tail\n        if tail:\n            content_handler.characters(tail)\n\n    def _build_qname(self, ns_uri, local_name, nsmap, preferred_prefix, is_attribute):\n        if ns_uri is None:\n            return local_name\n\n        if not is_attribute and nsmap.get(preferred_prefix) == ns_uri:\n            prefix = preferred_prefix\n        else:\n            # Pick the first matching prefix, in alphabetical order.\n            candidates = [\n                pfx for (pfx, uri) in nsmap.items()\n                if pfx is not None and uri == ns_uri\n            ]\n            prefix = (\n                candidates[0] if len(candidates) == 1\n                else min(candidates) if candidates\n                else None\n            )\n\n        if prefix is None:\n            # Default namespace\n            return local_name\n        return prefix + ':' + local_name\n\n\ndef saxify(element_or_tree, content_handler):\n    \"\"\"One-shot helper to generate SAX events from an XML tree and fire\n    them against a SAX ContentHandler.\n    \"\"\"\n    return ElementTreeProducer(element_or_tree, content_handler).saxify()\n", "src/lxml/pyclasslookup.py": "# dummy module for backwards compatibility\n\nfrom lxml.etree import PythonElementClassLookup\n", "src/lxml/ElementInclude.py": "#\n# ElementTree\n# $Id: ElementInclude.py 1862 2004-06-18 07:31:02Z Fredrik $\n#\n# limited xinclude support for element trees\n#\n# history:\n# 2003-08-15 fl   created\n# 2003-11-14 fl   fixed default loader\n#\n# Copyright (c) 2003-2004 by Fredrik Lundh.  All rights reserved.\n#\n# fredrik@pythonware.com\n# http://www.pythonware.com\n#\n# --------------------------------------------------------------------\n# The ElementTree toolkit is\n#\n# Copyright (c) 1999-2004 by Fredrik Lundh\n#\n# By obtaining, using, and/or copying this software and/or its\n# associated documentation, you agree that you have read, understood,\n# and will comply with the following terms and conditions:\n#\n# Permission to use, copy, modify, and distribute this software and\n# its associated documentation for any purpose and without fee is\n# hereby granted, provided that the above copyright notice appears in\n# all copies, and that both that copyright notice and this permission\n# notice appear in supporting documentation, and that the name of\n# Secret Labs AB or the author not be used in advertising or publicity\n# pertaining to distribution of the software without specific, written\n# prior permission.\n#\n# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD\n# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-\n# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR\n# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY\n# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,\n# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE\n# OF THIS SOFTWARE.\n# --------------------------------------------------------------------\n\n\"\"\"\nLimited XInclude support for the ElementTree package.\n\nWhile lxml.etree has full support for XInclude (see\n`etree.ElementTree.xinclude()`), this module provides a simpler, pure\nPython, ElementTree compatible implementation that supports a simple\nform of custom URL resolvers.\n\"\"\"\n\nfrom lxml import etree\ntry:\n    from urlparse import urljoin\n    from urllib2 import urlopen\nexcept ImportError:\n    # Python 3\n    from urllib.parse import urljoin\n    from urllib.request import urlopen\n\nXINCLUDE = \"{http://www.w3.org/2001/XInclude}\"\n\nXINCLUDE_INCLUDE = XINCLUDE + \"include\"\nXINCLUDE_FALLBACK = XINCLUDE + \"fallback\"\nXINCLUDE_ITER_TAG = XINCLUDE + \"*\"\n\n# For security reasons, the inclusion depth is limited to this read-only value by default.\nDEFAULT_MAX_INCLUSION_DEPTH = 6\n\n\n##\n# Fatal include error.\n\nclass FatalIncludeError(etree.LxmlSyntaxError):\n    pass\n\n\nclass LimitedRecursiveIncludeError(FatalIncludeError):\n    pass\n\n\n##\n# ET compatible default loader.\n# This loader reads an included resource from disk.\n#\n# @param href Resource reference.\n# @param parse Parse mode.  Either \"xml\" or \"text\".\n# @param encoding Optional text encoding.\n# @return The expanded resource.  If the parse mode is \"xml\", this\n#    is an ElementTree instance.  If the parse mode is \"text\", this\n#    is a Unicode string.  If the loader fails, it can return None\n#    or raise an IOError exception.\n# @throws IOError If the loader fails to load the resource.\n\ndef default_loader(href, parse, encoding=None):\n    file = open(href, 'rb')\n    if parse == \"xml\":\n        data = etree.parse(file).getroot()\n    else:\n        data = file.read()\n        if not encoding:\n            encoding = 'utf-8'\n        data = data.decode(encoding)\n    file.close()\n    return data\n\n\n##\n# Default loader used by lxml.etree - handles custom resolvers properly\n# \n\ndef _lxml_default_loader(href, parse, encoding=None, parser=None):\n    if parse == \"xml\":\n        data = etree.parse(href, parser).getroot()\n    else:\n        if \"://\" in href:\n            f = urlopen(href)\n        else:\n            f = open(href, 'rb')\n        data = f.read()\n        f.close()\n        if not encoding:\n            encoding = 'utf-8'\n        data = data.decode(encoding)\n    return data\n\n\n##\n# Wrapper for ET compatibility - drops the parser\n\ndef _wrap_et_loader(loader):\n    def load(href, parse, encoding=None, parser=None):\n        return loader(href, parse, encoding)\n    return load\n\n\n##\n# Expand XInclude directives.\n#\n# @param elem Root element.\n# @param loader Optional resource loader.  If omitted, it defaults\n#     to {@link default_loader}.  If given, it should be a callable\n#     that implements the same interface as <b>default_loader</b>.\n# @param base_url The base URL of the original file, to resolve\n#     relative include file references.\n# @param max_depth The maximum number of recursive inclusions.\n#     Limited to reduce the risk of malicious content explosion.\n#     Pass None to disable the limitation.\n# @throws LimitedRecursiveIncludeError If the {@link max_depth} was exceeded.\n# @throws FatalIncludeError If the function fails to include a given\n#     resource, or if the tree contains malformed XInclude elements.\n# @throws IOError If the function fails to load a given resource.\n# @returns the node or its replacement if it was an XInclude node\n\ndef include(elem, loader=None, base_url=None,\n            max_depth=DEFAULT_MAX_INCLUSION_DEPTH):\n    if max_depth is None:\n        max_depth = -1\n    elif max_depth < 0:\n        raise ValueError(\"expected non-negative depth or None for 'max_depth', got %r\" % max_depth)\n\n    if base_url is None:\n        if hasattr(elem, 'getroot'):\n            tree = elem\n            elem = elem.getroot()\n        else:\n            tree = elem.getroottree()\n        if hasattr(tree, 'docinfo'):\n            base_url = tree.docinfo.URL\n    elif hasattr(elem, 'getroot'):\n        elem = elem.getroot()\n    _include(elem, loader, base_url, max_depth)\n\n\ndef _include(elem, loader=None, base_url=None,\n             max_depth=DEFAULT_MAX_INCLUSION_DEPTH, _parent_hrefs=None):\n    if loader is not None:\n        load_include = _wrap_et_loader(loader)\n    else:\n        load_include = _lxml_default_loader\n\n    if _parent_hrefs is None:\n        _parent_hrefs = set()\n\n    parser = elem.getroottree().parser\n\n    include_elements = list(\n        elem.iter(XINCLUDE_ITER_TAG))\n\n    for e in include_elements:\n        if e.tag == XINCLUDE_INCLUDE:\n            # process xinclude directive\n            href = urljoin(base_url, e.get(\"href\"))\n            parse = e.get(\"parse\", \"xml\")\n            parent = e.getparent()\n            if parse == \"xml\":\n                if href in _parent_hrefs:\n                    raise FatalIncludeError(\n                        \"recursive include of %r detected\" % href\n                        )\n                if max_depth == 0:\n                    raise LimitedRecursiveIncludeError(\n                        \"maximum xinclude depth reached when including file %s\" % href)\n                node = load_include(href, parse, parser=parser)\n                if node is None:\n                    raise FatalIncludeError(\n                        \"cannot load %r as %r\" % (href, parse)\n                        )\n                node = _include(node, loader, href, max_depth - 1, {href} | _parent_hrefs)\n                if e.tail:\n                    node.tail = (node.tail or \"\") + e.tail\n                if parent is None:\n                    return node # replaced the root node!\n                parent.replace(e, node)\n            elif parse == \"text\":\n                text = load_include(href, parse, encoding=e.get(\"encoding\"))\n                if text is None:\n                    raise FatalIncludeError(\n                        \"cannot load %r as %r\" % (href, parse)\n                        )\n                predecessor = e.getprevious()\n                if predecessor is not None:\n                    predecessor.tail = (predecessor.tail or \"\") + text\n                elif parent is None:\n                    return text # replaced the root node!\n                else:\n                    parent.text = (parent.text or \"\") + text + (e.tail or \"\")\n                parent.remove(e)\n            else:\n                raise FatalIncludeError(\n                    \"unknown parse type in xi:include tag (%r)\" % parse\n                )\n        elif e.tag == XINCLUDE_FALLBACK:\n            parent = e.getparent()\n            if parent is not None and parent.tag != XINCLUDE_INCLUDE:\n                raise FatalIncludeError(\n                    \"xi:fallback tag must be child of xi:include (%r)\" % e.tag\n                    )\n        else:\n            raise FatalIncludeError(\n                \"Invalid element found in XInclude namespace (%r)\" % e.tag\n                )\n    return elem\n", "src/lxml/cssselect.py": "\"\"\"CSS Selectors based on XPath.\n\nThis module supports selecting XML/HTML tags based on CSS selectors.\nSee the `CSSSelector` class for details.\n\nThis is a thin wrapper around cssselect 0.7 or later.\n\"\"\"\n\n\nfrom . import etree\ntry:\n    import cssselect as external_cssselect\nexcept ImportError:\n    raise ImportError(\n        'cssselect does not seem to be installed. '\n        'See https://pypi.org/project/cssselect/')\n\n\nSelectorSyntaxError = external_cssselect.SelectorSyntaxError\nExpressionError = external_cssselect.ExpressionError\nSelectorError = external_cssselect.SelectorError\n\n\n__all__ = ['SelectorSyntaxError', 'ExpressionError', 'SelectorError',\n           'CSSSelector']\n\n\nclass LxmlTranslator(external_cssselect.GenericTranslator):\n    \"\"\"\n    A custom CSS selector to XPath translator with lxml-specific extensions.\n    \"\"\"\n    def xpath_contains_function(self, xpath, function):\n        # Defined there, removed in later drafts:\n        # http://www.w3.org/TR/2001/CR-css3-selectors-20011113/#content-selectors\n        if function.argument_types() not in (['STRING'], ['IDENT']):\n            raise ExpressionError(\n                \"Expected a single string or ident for :contains(), got %r\"\n                % function.arguments)\n        value = function.arguments[0].value\n        return xpath.add_condition(\n            'contains(__lxml_internal_css:lower-case(string(.)), %s)'\n            % self.xpath_literal(value.lower()))\n\n\nclass LxmlHTMLTranslator(LxmlTranslator, external_cssselect.HTMLTranslator):\n    \"\"\"\n    lxml extensions + HTML support.\n    \"\"\"\n\n\ndef _make_lower_case(context, s):\n    return s.lower()\n\nns = etree.FunctionNamespace('http://codespeak.net/lxml/css/')\nns.prefix = '__lxml_internal_css'\nns['lower-case'] = _make_lower_case\n\n\nclass CSSSelector(etree.XPath):\n    \"\"\"A CSS selector.\n\n    Usage::\n\n        >>> from lxml import etree, cssselect\n        >>> select = cssselect.CSSSelector(\"a tag > child\")\n\n        >>> root = etree.XML(\"<a><b><c/><tag><child>TEXT</child></tag></b></a>\")\n        >>> [ el.tag for el in select(root) ]\n        ['child']\n\n    To use CSS namespaces, you need to pass a prefix-to-namespace\n    mapping as ``namespaces`` keyword argument::\n\n        >>> rdfns = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#'\n        >>> select_ns = cssselect.CSSSelector('root > rdf|Description',\n        ...                                   namespaces={'rdf': rdfns})\n\n        >>> rdf = etree.XML((\n        ...     '<root xmlns:rdf=\"%s\">'\n        ...       '<rdf:Description>blah</rdf:Description>'\n        ...     '</root>') % rdfns)\n        >>> [(el.tag, el.text) for el in select_ns(rdf)]\n        [('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}Description', 'blah')]\n\n    \"\"\"\n    def __init__(self, css, namespaces=None, translator='xml'):\n        if translator == 'xml':\n            translator = LxmlTranslator()\n        elif translator == 'html':\n            translator = LxmlHTMLTranslator()\n        elif translator == 'xhtml':\n            translator = LxmlHTMLTranslator(xhtml=True)\n        path = translator.css_to_xpath(css)\n        super().__init__(path, namespaces=namespaces)\n        self.css = css\n\n    def __repr__(self):\n        return '<%s %x for %r>' % (\n            self.__class__.__name__,\n            abs(id(self)),\n            self.css)\n", "src/lxml/__init__.py": "# this is a package\n\n__version__ = \"5.2.2\"\n\n\ndef get_include():\n    \"\"\"\n    Returns a list of header include paths (for lxml itself, libxml2\n    and libxslt) needed to compile C code against lxml if it was built\n    with statically linked libraries.\n    \"\"\"\n    import os\n    lxml_path = __path__[0]\n    include_path = os.path.join(lxml_path, 'includes')\n    includes = [include_path, lxml_path]\n\n    for name in os.listdir(include_path):\n        path = os.path.join(include_path, name)\n        if os.path.isdir(path):\n            includes.append(path)\n\n    return includes\n", "src/lxml/builder.py": "# cython: language_level=2\n\n#\n# Element generator factory by Fredrik Lundh.\n#\n# Source:\n#    http://online.effbot.org/2006_11_01_archive.htm#et-builder\n#    http://effbot.python-hosting.com/file/stuff/sandbox/elementlib/builder.py\n#\n# --------------------------------------------------------------------\n# The ElementTree toolkit is\n#\n# Copyright (c) 1999-2004 by Fredrik Lundh\n#\n# By obtaining, using, and/or copying this software and/or its\n# associated documentation, you agree that you have read, understood,\n# and will comply with the following terms and conditions:\n#\n# Permission to use, copy, modify, and distribute this software and\n# its associated documentation for any purpose and without fee is\n# hereby granted, provided that the above copyright notice appears in\n# all copies, and that both that copyright notice and this permission\n# notice appear in supporting documentation, and that the name of\n# Secret Labs AB or the author not be used in advertising or publicity\n# pertaining to distribution of the software without specific, written\n# prior permission.\n#\n# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD\n# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-\n# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR\n# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY\n# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,\n# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE\n# OF THIS SOFTWARE.\n# --------------------------------------------------------------------\n\n\"\"\"\nThe ``E`` Element factory for generating XML documents.\n\"\"\"\n\n\nimport lxml.etree as ET\n_QName = ET.QName\n\nfrom functools import partial\n\ntry:\n    basestring\nexcept NameError:\n    basestring = str\n\ntry:\n    unicode\nexcept NameError:\n    unicode = str\n\n\nclass ElementMaker:\n    \"\"\"Element generator factory.\n\n    Unlike the ordinary Element factory, the E factory allows you to pass in\n    more than just a tag and some optional attributes; you can also pass in\n    text and other elements.  The text is added as either text or tail\n    attributes, and elements are inserted at the right spot.  Some small\n    examples::\n\n        >>> from lxml import etree as ET\n        >>> from lxml.builder import E\n\n        >>> ET.tostring(E(\"tag\"))\n        '<tag/>'\n        >>> ET.tostring(E(\"tag\", \"text\"))\n        '<tag>text</tag>'\n        >>> ET.tostring(E(\"tag\", \"text\", key=\"value\"))\n        '<tag key=\"value\">text</tag>'\n        >>> ET.tostring(E(\"tag\", E(\"subtag\", \"text\"), \"tail\"))\n        '<tag><subtag>text</subtag>tail</tag>'\n\n    For simple tags, the factory also allows you to write ``E.tag(...)`` instead\n    of ``E('tag', ...)``::\n\n        >>> ET.tostring(E.tag())\n        '<tag/>'\n        >>> ET.tostring(E.tag(\"text\"))\n        '<tag>text</tag>'\n        >>> ET.tostring(E.tag(E.subtag(\"text\"), \"tail\"))\n        '<tag><subtag>text</subtag>tail</tag>'\n\n    Here's a somewhat larger example; this shows how to generate HTML\n    documents, using a mix of prepared factory functions for inline elements,\n    nested ``E.tag`` calls, and embedded XHTML fragments::\n\n        # some common inline elements\n        A = E.a\n        I = E.i\n        B = E.b\n\n        def CLASS(v):\n            # helper function, 'class' is a reserved word\n            return {'class': v}\n\n        page = (\n            E.html(\n                E.head(\n                    E.title(\"This is a sample document\")\n                ),\n                E.body(\n                    E.h1(\"Hello!\", CLASS(\"title\")),\n                    E.p(\"This is a paragraph with \", B(\"bold\"), \" text in it!\"),\n                    E.p(\"This is another paragraph, with a \",\n                        A(\"link\", href=\"http://www.python.org\"), \".\"),\n                    E.p(\"Here are some reserved characters: <spam&egg>.\"),\n                    ET.XML(\"<p>And finally, here is an embedded XHTML fragment.</p>\"),\n                )\n            )\n        )\n\n        print ET.tostring(page)\n\n    Here's a prettyprinted version of the output from the above script::\n\n        <html>\n          <head>\n            <title>This is a sample document</title>\n          </head>\n          <body>\n            <h1 class=\"title\">Hello!</h1>\n            <p>This is a paragraph with <b>bold</b> text in it!</p>\n            <p>This is another paragraph, with <a href=\"http://www.python.org\">link</a>.</p>\n            <p>Here are some reserved characters: &lt;spam&amp;egg&gt;.</p>\n            <p>And finally, here is an embedded XHTML fragment.</p>\n          </body>\n        </html>\n\n    For namespace support, you can pass a namespace map (``nsmap``)\n    and/or a specific target ``namespace`` to the ElementMaker class::\n\n        >>> E = ElementMaker(namespace=\"http://my.ns/\")\n        >>> print(ET.tostring( E.test ))\n        <test xmlns=\"http://my.ns/\"/>\n\n        >>> E = ElementMaker(namespace=\"http://my.ns/\", nsmap={'p':'http://my.ns/'})\n        >>> print(ET.tostring( E.test ))\n        <p:test xmlns:p=\"http://my.ns/\"/>\n    \"\"\"\n\n    def __init__(self, typemap=None,\n                 namespace=None, nsmap=None, makeelement=None):\n        self._namespace = '{' + namespace + '}' if namespace is not None else None\n        self._nsmap = dict(nsmap) if nsmap else None\n\n        assert makeelement is None or callable(makeelement)\n        self._makeelement = makeelement if makeelement is not None else ET.Element\n\n        # initialize the default type map functions for this element factory\n        typemap = dict(typemap) if typemap else {}\n\n        def add_text(elem, item):\n            try:\n                last_child = elem[-1]\n            except IndexError:\n                elem.text = (elem.text or \"\") + item\n            else:\n                last_child.tail = (last_child.tail or \"\") + item\n\n        def add_cdata(elem, cdata):\n            if elem.text:\n                raise ValueError(\"Can't add a CDATA section. Element already has some text: %r\" % elem.text)\n            elem.text = cdata\n\n        if str not in typemap:\n            typemap[str] = add_text\n        if unicode not in typemap:\n            typemap[unicode] = add_text\n        if ET.CDATA not in typemap:\n            typemap[ET.CDATA] = add_cdata\n\n        def add_dict(elem, item):\n            attrib = elem.attrib\n            for k, v in item.items():\n                if isinstance(v, basestring):\n                    attrib[k] = v\n                else:\n                    attrib[k] = typemap[type(v)](None, v)\n\n        if dict not in typemap:\n            typemap[dict] = add_dict\n\n        self._typemap = typemap\n\n    def __call__(self, tag, *children, **attrib):\n        typemap = self._typemap\n\n        # We'll usually get a 'str', and the compiled type check is very fast.\n        if not isinstance(tag, str) and isinstance(tag, _QName):\n            # A QName is explicitly qualified, do not look at self._namespace.\n            tag = tag.text\n        elif self._namespace is not None and tag[0] != '{':\n            tag = self._namespace + tag\n        elem = self._makeelement(tag, nsmap=self._nsmap)\n        if attrib:\n            typemap[dict](elem, attrib)\n\n        for item in children:\n            if callable(item):\n                item = item()\n            t = typemap.get(type(item))\n            if t is None:\n                if ET.iselement(item):\n                    elem.append(item)\n                    continue\n                for basetype in type(item).__mro__:\n                    # See if the typemap knows of any of this type's bases.\n                    t = typemap.get(basetype)\n                    if t is not None:\n                        break\n                else:\n                    raise TypeError(\"bad argument type: %s(%r)\" %\n                                    (type(item).__name__, item))\n            v = t(elem, item)\n            if v:\n                typemap.get(type(v))(elem, v)\n\n        return elem\n\n    def __getattr__(self, tag):\n        return partial(self, tag)\n\n\n# create factory object\nE = ElementMaker()\n", "src/lxml/_elementpath.py": "# cython: language_level=2\n\n#\n# ElementTree\n# $Id: ElementPath.py 3375 2008-02-13 08:05:08Z fredrik $\n#\n# limited xpath support for element trees\n#\n# history:\n# 2003-05-23 fl   created\n# 2003-05-28 fl   added support for // etc\n# 2003-08-27 fl   fixed parsing of periods in element names\n# 2007-09-10 fl   new selection engine\n# 2007-09-12 fl   fixed parent selector\n# 2007-09-13 fl   added iterfind; changed findall to return a list\n# 2007-11-30 fl   added namespaces support\n# 2009-10-30 fl   added child element value filter\n#\n# Copyright (c) 2003-2009 by Fredrik Lundh.  All rights reserved.\n#\n# fredrik@pythonware.com\n# http://www.pythonware.com\n#\n# --------------------------------------------------------------------\n# The ElementTree toolkit is\n#\n# Copyright (c) 1999-2009 by Fredrik Lundh\n#\n# By obtaining, using, and/or copying this software and/or its\n# associated documentation, you agree that you have read, understood,\n# and will comply with the following terms and conditions:\n#\n# Permission to use, copy, modify, and distribute this software and\n# its associated documentation for any purpose and without fee is\n# hereby granted, provided that the above copyright notice appears in\n# all copies, and that both that copyright notice and this permission\n# notice appear in supporting documentation, and that the name of\n# Secret Labs AB or the author not be used in advertising or publicity\n# pertaining to distribution of the software without specific, written\n# prior permission.\n#\n# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD\n# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-\n# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR\n# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY\n# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,\n# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE\n# OF THIS SOFTWARE.\n# --------------------------------------------------------------------\n\n##\n# Implementation module for XPath support.  There's usually no reason\n# to import this module directly; the <b>ElementTree</b> does this for\n# you, if needed.\n##\n\n\nimport re\n\nxpath_tokenizer_re = re.compile(\n    \"(\"\n    \"'[^']*'|\\\"[^\\\"]*\\\"|\"\n    \"::|\"\n    \"//?|\"\n    r\"\\.\\.|\"\n    r\"\\(\\)|\"\n    r\"[/.*:\\[\\]\\(\\)@=])|\"\n    r\"((?:\\{[^}]+\\})?[^/\\[\\]\\(\\)@=\\s]+)|\"\n    r\"\\s+\"\n    )\n\ndef xpath_tokenizer(pattern, namespaces=None, with_prefixes=True):\n    # ElementTree uses '', lxml used None originally.\n    default_namespace = (namespaces.get(None) or namespaces.get('')) if namespaces else None\n    parsing_attribute = False\n    for token in xpath_tokenizer_re.findall(pattern):\n        ttype, tag = token\n        if tag and tag[0] != \"{\":\n            if \":\" in tag and with_prefixes:\n                prefix, uri = tag.split(\":\", 1)\n                try:\n                    if not namespaces:\n                        raise KeyError\n                    yield ttype, \"{%s}%s\" % (namespaces[prefix], uri)\n                except KeyError:\n                    raise SyntaxError(\"prefix %r not found in prefix map\" % prefix)\n            elif default_namespace and not parsing_attribute:\n                yield ttype, \"{%s}%s\" % (default_namespace, tag)\n            else:\n                yield token\n            parsing_attribute = False\n        else:\n            yield token\n            parsing_attribute = ttype == '@'\n\n\ndef prepare_child(next, token):\n    tag = token[1]\n    def select(result):\n        for elem in result:\n            yield from elem.iterchildren(tag)\n    return select\n\ndef prepare_star(next, token):\n    def select(result):\n        for elem in result:\n            yield from elem.iterchildren('*')\n    return select\n\ndef prepare_self(next, token):\n    def select(result):\n        return result\n    return select\n\ndef prepare_descendant(next, token):\n    token = next()\n    if token[0] == \"*\":\n        tag = \"*\"\n    elif not token[0]:\n        tag = token[1]\n    else:\n        raise SyntaxError(\"invalid descendant\")\n    def select(result):\n        for elem in result:\n            yield from elem.iterdescendants(tag)\n    return select\n\ndef prepare_parent(next, token):\n    def select(result):\n        for elem in result:\n            parent = elem.getparent()\n            if parent is not None:\n                yield parent\n    return select\n\ndef prepare_predicate(next, token):\n    # FIXME: replace with real parser!!! refs:\n    # http://effbot.org/zone/simple-iterator-parser.htm\n    # http://javascript.crockford.com/tdop/tdop.html\n    signature = ''\n    predicate = []\n    while 1:\n        token = next()\n        if token[0] == \"]\":\n            break\n        if token == ('', ''):\n            # ignore whitespace\n            continue\n        if token[0] and token[0][:1] in \"'\\\"\":\n            token = \"'\", token[0][1:-1]\n        signature += token[0] or \"-\"\n        predicate.append(token[1])\n\n    # use signature to determine predicate type\n    if signature == \"@-\":\n        # [@attribute] predicate\n        key = predicate[1]\n        def select(result):\n            for elem in result:\n                if elem.get(key) is not None:\n                    yield elem\n        return select\n    if signature == \"@-='\":\n        # [@attribute='value']\n        key = predicate[1]\n        value = predicate[-1]\n        def select(result):\n            for elem in result:\n                if elem.get(key) == value:\n                    yield elem\n        return select\n    if signature == \"-\" and not re.match(r\"-?\\d+$\", predicate[0]):\n        # [tag]\n        tag = predicate[0]\n        def select(result):\n            for elem in result:\n                for _ in elem.iterchildren(tag):\n                    yield elem\n                    break\n        return select\n    if signature == \".='\" or (signature == \"-='\" and not re.match(r\"-?\\d+$\", predicate[0])):\n        # [.='value'] or [tag='value']\n        tag = predicate[0]\n        value = predicate[-1]\n        if tag:\n            def select(result):\n                for elem in result:\n                    for e in elem.iterchildren(tag):\n                        if \"\".join(e.itertext()) == value:\n                            yield elem\n                            break\n        else:\n            def select(result):\n                for elem in result:\n                    if \"\".join(elem.itertext()) == value:\n                        yield elem\n        return select\n    if signature == \"-\" or signature == \"-()\" or signature == \"-()-\":\n        # [index] or [last()] or [last()-index]\n        if signature == \"-\":\n            # [index]\n            index = int(predicate[0]) - 1\n            if index < 0:\n                if index == -1:\n                    raise SyntaxError(\n                        \"indices in path predicates are 1-based, not 0-based\")\n                else:\n                    raise SyntaxError(\"path index >= 1 expected\")\n        else:\n            if predicate[0] != \"last\":\n                raise SyntaxError(\"unsupported function\")\n            if signature == \"-()-\":\n                try:\n                    index = int(predicate[2]) - 1\n                except ValueError:\n                    raise SyntaxError(\"unsupported expression\")\n            else:\n                index = -1\n        def select(result):\n            for elem in result:\n                parent = elem.getparent()\n                if parent is None:\n                    continue\n                try:\n                    # FIXME: what if the selector is \"*\" ?\n                    elems = list(parent.iterchildren(elem.tag))\n                    if elems[index] is elem:\n                        yield elem\n                except IndexError:\n                    pass\n        return select\n    raise SyntaxError(\"invalid predicate\")\n\nops = {\n    \"\": prepare_child,\n    \"*\": prepare_star,\n    \".\": prepare_self,\n    \"..\": prepare_parent,\n    \"//\": prepare_descendant,\n    \"[\": prepare_predicate,\n}\n\n\n# --------------------------------------------------------------------\n\n_cache = {}\n\n\ndef _build_path_iterator(path, namespaces, with_prefixes=True):\n    \"\"\"compile selector pattern\"\"\"\n    if path[-1:] == \"/\":\n        path += \"*\"  # implicit all (FIXME: keep this?)\n\n    cache_key = (path,)\n    if namespaces:\n        # lxml originally used None for the default namespace but ElementTree uses the\n        # more convenient (all-strings-dict) empty string, so we support both here,\n        # preferring the more convenient '', as long as they aren't ambiguous.\n        if None in namespaces:\n            if '' in namespaces and namespaces[None] != namespaces['']:\n                raise ValueError(\"Ambiguous default namespace provided: %r versus %r\" % (\n                    namespaces[None], namespaces['']))\n            cache_key += (namespaces[None],) + tuple(sorted(\n                item for item in namespaces.items() if item[0] is not None))\n        else:\n            cache_key += tuple(sorted(namespaces.items()))\n\n    try:\n        return _cache[cache_key]\n    except KeyError:\n        pass\n    if len(_cache) > 100:\n        _cache.clear()\n\n    if path[:1] == \"/\":\n        raise SyntaxError(\"cannot use absolute path on element\")\n    stream = iter(xpath_tokenizer(path, namespaces, with_prefixes=with_prefixes))\n    try:\n        _next = stream.next\n    except AttributeError:\n        # Python 3\n        _next = stream.__next__\n    try:\n        token = _next()\n    except StopIteration:\n        raise SyntaxError(\"empty path expression\")\n    selector = []\n    while 1:\n        try:\n            selector.append(ops[token[0]](_next, token))\n        except StopIteration:\n            raise SyntaxError(\"invalid path\")\n        try:\n            token = _next()\n            if token[0] == \"/\":\n                token = _next()\n        except StopIteration:\n            break\n    _cache[cache_key] = selector\n    return selector\n\n\n##\n# Iterate over the matching nodes\n\ndef iterfind(elem, path, namespaces=None, with_prefixes=True):\n    selector = _build_path_iterator(path, namespaces, with_prefixes=with_prefixes)\n    result = iter((elem,))\n    for select in selector:\n        result = select(result)\n    return result\n\n\n##\n# Find first matching object.\n\ndef find(elem, path, namespaces=None, with_prefixes=True):\n    it = iterfind(elem, path, namespaces, with_prefixes=with_prefixes)\n    try:\n        return next(it)\n    except StopIteration:\n        return None\n\n\n##\n# Find all matching objects.\n\ndef findall(elem, path, namespaces=None, with_prefixes=True):\n    return list(iterfind(elem, path, namespaces))\n\n\n##\n# Find text for first matching object.\n\ndef findtext(elem, path, default=None, namespaces=None, with_prefixes=True):\n    el = find(elem, path, namespaces, with_prefixes=with_prefixes)\n    if el is None:\n        return default\n    else:\n        return el.text or ''\n", "src/lxml/isoschematron/__init__.py": "\"\"\"The ``lxml.isoschematron`` package implements ISO Schematron support on top\nof the pure-xslt 'skeleton' implementation.\n\"\"\"\n\nimport sys\nimport os.path\nfrom lxml import etree as _etree # due to validator __init__ signature\n\n\n# some compat stuff, borrowed from lxml.html\ntry:\n    unicode\nexcept NameError:\n    # Python 3\n    unicode = str\ntry:\n    basestring\nexcept NameError:\n    # Python 3\n    basestring = str\n\n\n__all__ = ['extract_xsd', 'extract_rng', 'iso_dsdl_include',\n           'iso_abstract_expand', 'iso_svrl_for_xslt1',\n           'svrl_validation_errors', 'schematron_schema_valid',\n           'stylesheet_params', 'Schematron']\n\n\n# some namespaces\n#FIXME: Maybe lxml should provide a dedicated place for common namespace\n#FIXME: definitions?\nXML_SCHEMA_NS = \"http://www.w3.org/2001/XMLSchema\"\nRELAXNG_NS = \"http://relaxng.org/ns/structure/1.0\"\nSCHEMATRON_NS = \"http://purl.oclc.org/dsdl/schematron\"\nSVRL_NS = \"http://purl.oclc.org/dsdl/svrl\"\n\n\n# some helpers\n_schematron_root = '{%s}schema' % SCHEMATRON_NS\n_xml_schema_root = '{%s}schema' % XML_SCHEMA_NS\n_resources_dir = os.path.join(os.path.dirname(__file__), 'resources')\n\n\n# the iso-schematron skeleton implementation steps aka xsl transformations\nextract_xsd = _etree.XSLT(_etree.parse(\n    os.path.join(_resources_dir, 'xsl', 'XSD2Schtrn.xsl')))\nextract_rng = _etree.XSLT(_etree.parse(\n    os.path.join(_resources_dir, 'xsl', 'RNG2Schtrn.xsl')))\niso_dsdl_include = _etree.XSLT(_etree.parse(\n    os.path.join(_resources_dir, 'xsl', 'iso-schematron-xslt1',\n                 'iso_dsdl_include.xsl')))\niso_abstract_expand = _etree.XSLT(_etree.parse(\n    os.path.join(_resources_dir, 'xsl', 'iso-schematron-xslt1',\n                 'iso_abstract_expand.xsl')))\niso_svrl_for_xslt1 = _etree.XSLT(_etree.parse(\n    os.path.join(_resources_dir,\n                 'xsl', 'iso-schematron-xslt1', 'iso_svrl_for_xslt1.xsl')))\n\n\n# svrl result accessors\nsvrl_validation_errors = _etree.XPath(\n    '//svrl:failed-assert', namespaces={'svrl': SVRL_NS})\n\n# RelaxNG validator for schematron schemas\nschematron_schema_valid_supported = False\ntry:\n    schematron_schema_valid = _etree.RelaxNG(\n        file=os.path.join(_resources_dir, 'rng', 'iso-schematron.rng'))\n    schematron_schema_valid_supported = True\nexcept _etree.RelaxNGParseError:\n    # Some distributions delete the file due to licensing issues.\n    def schematron_schema_valid(arg):\n        raise NotImplementedError(\"Validating the ISO schematron requires iso-schematron.rng\")\n\n\ndef stylesheet_params(**kwargs):\n    \"\"\"Convert keyword args to a dictionary of stylesheet parameters.\n    XSL stylesheet parameters must be XPath expressions, i.e.:\n\n    * string expressions, like \"'5'\"\n    * simple (number) expressions, like \"5\"\n    * valid XPath expressions, like \"/a/b/text()\"\n\n    This function converts native Python keyword arguments to stylesheet\n    parameters following these rules:\n    If an arg is a string wrap it with XSLT.strparam().\n    If an arg is an XPath object use its path string.\n    If arg is None raise TypeError.\n    Else convert arg to string.\n    \"\"\"\n    result = {}\n    for key, val in kwargs.items():\n        if isinstance(val, basestring):\n            val = _etree.XSLT.strparam(val)\n        elif val is None:\n            raise TypeError('None not allowed as a stylesheet parameter')\n        elif not isinstance(val, _etree.XPath):\n            val = unicode(val)\n        result[key] = val\n    return result\n\n\n# helper function for use in Schematron __init__\ndef _stylesheet_param_dict(paramsDict, kwargsDict):\n    \"\"\"Return a copy of paramsDict, updated with kwargsDict entries, wrapped as\n    stylesheet arguments.\n    kwargsDict entries with a value of None are ignored.\n    \"\"\"\n    # beware of changing mutable default arg\n    paramsDict = dict(paramsDict)\n    for k, v in kwargsDict.items():\n        if v is not None: # None values do not override\n            paramsDict[k] = v\n    paramsDict = stylesheet_params(**paramsDict)\n    return paramsDict\n\n\nclass Schematron(_etree._Validator):\n    \"\"\"An ISO Schematron validator.\n\n    Pass a root Element or an ElementTree to turn it into a validator.\n    Alternatively, pass a filename as keyword argument 'file' to parse from\n    the file system.\n\n    Schematron is a less well known, but very powerful schema language.\n    The main idea is to use the capabilities of XPath to put restrictions on\n    the structure and the content of XML documents.\n\n    The standard behaviour is to fail on ``failed-assert`` findings only\n    (``ASSERTS_ONLY``).  To change this, you can either pass a report filter\n    function to the ``error_finder`` parameter (e.g. ``ASSERTS_AND_REPORTS``\n    or a custom ``XPath`` object), or subclass isoschematron.Schematron for\n    complete control of the validation process.\n\n    Built on the Schematron language 'reference' skeleton pure-xslt\n    implementation, the validator is created as an XSLT 1.0 stylesheet using\n    these steps:\n\n     0) (Extract from XML Schema or RelaxNG schema)\n     1) Process inclusions\n     2) Process abstract patterns\n     3) Compile the schematron schema to XSLT\n\n    The ``include`` and ``expand`` keyword arguments can be used to switch off\n    steps 1) and 2).\n    To set parameters for steps 1), 2) and 3) hand parameter dictionaries to the\n    keyword arguments ``include_params``, ``expand_params`` or\n    ``compile_params``.\n    For convenience, the compile-step parameter ``phase`` is also exposed as a\n    keyword argument ``phase``. This takes precedence if the parameter is also\n    given in the parameter dictionary.\n\n    If ``store_schematron`` is set to True, the (included-and-expanded)\n    schematron document tree is stored and available through the ``schematron``\n    property.\n    If ``store_xslt`` is set to True, the validation XSLT document tree will be\n    stored and can be retrieved through the ``validator_xslt`` property.\n    With ``store_report`` set to True (default: False), the resulting validation\n    report document gets stored and can be accessed as the ``validation_report``\n    property.\n\n    If ``validate_schema`` is set to False, the validation of the schema file\n    itself is disabled.  Validation happens by default after building the full\n    schema, unless the schema validation file cannot be found at import time,\n    in which case the validation gets disabled.  Some lxml distributions exclude\n    this file due to licensing issues.  ISO-Schematron validation can then still\n    be used normally, but the schemas themselves cannot be validated.\n\n    Here is a usage example::\n\n      >>> from lxml import etree\n      >>> from lxml.isoschematron import Schematron\n\n      >>> schematron = Schematron(etree.XML('''\n      ... <schema xmlns=\"http://purl.oclc.org/dsdl/schematron\" >\n      ...   <pattern id=\"id_only_attribute\">\n      ...     <title>id is the only permitted attribute name</title>\n      ...     <rule context=\"*\">\n      ...       <report test=\"@*[not(name()='id')]\">Attribute\n      ...         <name path=\"@*[not(name()='id')]\"/> is forbidden<name/>\n      ...       </report>\n      ...     </rule>\n      ...   </pattern>\n      ... </schema>'''),\n      ... error_finder=Schematron.ASSERTS_AND_REPORTS)\n\n      >>> xml = etree.XML('''\n      ... <AAA name=\"aaa\">\n      ...   <BBB id=\"bbb\"/>\n      ...   <CCC color=\"ccc\"/>\n      ... </AAA>\n      ... ''')\n\n      >>> schematron.validate(xml)\n      False\n\n      >>> xml = etree.XML('''\n      ... <AAA id=\"aaa\">\n      ...   <BBB id=\"bbb\"/>\n      ...   <CCC/>\n      ... </AAA>\n      ... ''')\n\n      >>> schematron.validate(xml)\n      True\n    \"\"\"\n\n    # libxml2 error categorization for validation errors\n    _domain = _etree.ErrorDomains.SCHEMATRONV\n    _level = _etree.ErrorLevels.ERROR\n    _error_type = _etree.ErrorTypes.SCHEMATRONV_ASSERT\n\n    # convenience definitions for common behaviours\n    ASSERTS_ONLY = svrl_validation_errors  # Default\n    ASSERTS_AND_REPORTS = _etree.XPath(\n        '//svrl:failed-assert | //svrl:successful-report',\n        namespaces={'svrl': SVRL_NS})\n\n    def _extract(self, element):\n        \"\"\"Extract embedded schematron schema from non-schematron host schema.\n        This method will only be called by __init__ if the given schema document\n        is not a schematron schema by itself.\n        Must return a schematron schema document tree or None.\n        \"\"\"\n        schematron = None\n        if element.tag == _xml_schema_root:\n            schematron = self._extract_xsd(element)\n        elif element.nsmap.get(element.prefix) == RELAXNG_NS:\n            # RelaxNG does not have a single unique root element\n            schematron = self._extract_rng(element)\n        return schematron\n\n    # customization points\n    # etree.XSLT objects that provide the extract, include, expand, compile\n    # steps\n    _extract_xsd = extract_xsd\n    _extract_rng = extract_rng\n    _include = iso_dsdl_include\n    _expand = iso_abstract_expand\n    _compile = iso_svrl_for_xslt1\n\n    # etree.xpath object that determines input document validity when applied to\n    # the svrl result report; must return a list of result elements (empty if\n    # valid)\n    _validation_errors = ASSERTS_ONLY\n\n    def __init__(self, etree=None, file=None, include=True, expand=True,\n                 include_params={}, expand_params={}, compile_params={},\n                 store_schematron=False, store_xslt=False, store_report=False,\n                 phase=None, error_finder=ASSERTS_ONLY,\n                 validate_schema=schematron_schema_valid_supported):\n        super().__init__()\n\n        self._store_report = store_report\n        self._schematron = None\n        self._validator_xslt = None\n        self._validation_report = None\n        if error_finder is not self.ASSERTS_ONLY:\n            self._validation_errors = error_finder\n\n        # parse schema document, may be a schematron schema or an XML Schema or\n        # a RelaxNG schema with embedded schematron rules\n        root = None\n        try:\n            if etree is not None:\n                if _etree.iselement(etree):\n                    root = etree\n                else:\n                    root = etree.getroot()\n            elif file is not None:\n                root = _etree.parse(file).getroot()\n        except Exception:\n            raise _etree.SchematronParseError(\n                \"No tree or file given: %s\" % sys.exc_info()[1])\n        if root is None:\n            raise ValueError(\"Empty tree\")\n        if root.tag == _schematron_root:\n            schematron = root\n        else:\n            schematron = self._extract(root)\n        if schematron is None:\n            raise _etree.SchematronParseError(\n                \"Document is not a schematron schema or schematron-extractable\")\n        # perform the iso-schematron skeleton implementation steps to get a\n        # validating xslt\n        if include:\n            schematron = self._include(schematron, **include_params)\n        if expand:\n            schematron = self._expand(schematron, **expand_params)\n        if validate_schema and not schematron_schema_valid(schematron):\n            raise _etree.SchematronParseError(\n                \"invalid schematron schema: %s\" %\n                schematron_schema_valid.error_log)\n        if store_schematron:\n            self._schematron = schematron\n        # add new compile keyword args here if exposing them\n        compile_kwargs = {'phase': phase}\n        compile_params = _stylesheet_param_dict(compile_params, compile_kwargs)\n        validator_xslt = self._compile(schematron, **compile_params)\n        if store_xslt:\n            self._validator_xslt = validator_xslt\n        self._validator = _etree.XSLT(validator_xslt)\n\n    def __call__(self, etree):\n        \"\"\"Validate doc using Schematron.\n\n        Returns true if document is valid, false if not.\n        \"\"\"\n        self._clear_error_log()\n        result = self._validator(etree)\n        if self._store_report:\n            self._validation_report = result\n        errors = self._validation_errors(result)\n        if errors:\n            if _etree.iselement(etree):\n                fname = etree.getroottree().docinfo.URL or '<file>'\n            else:\n                fname = etree.docinfo.URL or '<file>'\n            for error in errors:\n                # Does svrl report the line number, anywhere? Don't think so.\n                self._append_log_message(\n                    domain=self._domain, type=self._error_type,\n                    level=self._level, line=0,\n                    message=_etree.tostring(error, encoding='unicode'),\n                    filename=fname)\n            return False\n        return True\n\n    @property\n    def schematron(self):\n        \"\"\"ISO-schematron schema document (None if object has been initialized\n        with store_schematron=False).\n        \"\"\"\n        return self._schematron\n\n    @property\n    def validator_xslt(self):\n        \"\"\"ISO-schematron skeleton implementation XSLT validator document (None\n        if object has been initialized with store_xslt=False).\n        \"\"\"\n        return self._validator_xslt\n\n    @property\n    def validation_report(self):\n        \"\"\"ISO-schematron validation result report (None if result-storing has\n        been turned off).\n        \"\"\"\n        return self._validation_report\n", "src/lxml/includes/__init__.py": "", "src/lxml/html/html5parser.py": "\"\"\"\nAn interface to html5lib that mimics the lxml.html interface.\n\"\"\"\nimport sys\nimport string\n\nfrom html5lib import HTMLParser as _HTMLParser\nfrom html5lib.treebuilders.etree_lxml import TreeBuilder\nfrom lxml import etree\nfrom lxml.html import Element, XHTML_NAMESPACE, _contains_block_level_tag\n\n# python3 compatibility\ntry:\n    _strings = basestring\nexcept NameError:\n    _strings = (bytes, str)\ntry:\n    from urllib2 import urlopen\nexcept ImportError:\n    from urllib.request import urlopen\ntry:\n    from urlparse import urlparse\nexcept ImportError:\n    from urllib.parse import urlparse\n\n\nclass HTMLParser(_HTMLParser):\n    \"\"\"An html5lib HTML parser with lxml as tree.\"\"\"\n\n    def __init__(self, strict=False, **kwargs):\n        _HTMLParser.__init__(self, strict=strict, tree=TreeBuilder, **kwargs)\n\n\ntry:\n    from html5lib import XHTMLParser as _XHTMLParser\nexcept ImportError:\n    pass\nelse:\n    class XHTMLParser(_XHTMLParser):\n        \"\"\"An html5lib XHTML Parser with lxml as tree.\"\"\"\n\n        def __init__(self, strict=False, **kwargs):\n            _XHTMLParser.__init__(self, strict=strict, tree=TreeBuilder, **kwargs)\n\n    xhtml_parser = XHTMLParser()\n\n\ndef _find_tag(tree, tag):\n    elem = tree.find(tag)\n    if elem is not None:\n        return elem\n    return tree.find('{%s}%s' % (XHTML_NAMESPACE, tag))\n\n\ndef document_fromstring(html, guess_charset=None, parser=None):\n    \"\"\"\n    Parse a whole document into a string.\n\n    If `guess_charset` is true, or if the input is not Unicode but a\n    byte string, the `chardet` library will perform charset guessing\n    on the string.\n    \"\"\"\n    if not isinstance(html, _strings):\n        raise TypeError('string required')\n\n    if parser is None:\n        parser = html_parser\n\n    options = {}\n    if guess_charset is None and isinstance(html, bytes):\n        # html5lib does not accept useChardet as an argument, if it\n        # detected the html argument would produce unicode objects.\n        guess_charset = True\n    if guess_charset is not None:\n        options['useChardet'] = guess_charset\n    return parser.parse(html, **options).getroot()\n\n\ndef fragments_fromstring(html, no_leading_text=False,\n                         guess_charset=None, parser=None):\n    \"\"\"Parses several HTML elements, returning a list of elements.\n\n    The first item in the list may be a string.  If no_leading_text is true,\n    then it will be an error if there is leading text, and it will always be\n    a list of only elements.\n\n    If `guess_charset` is true, the `chardet` library will perform charset\n    guessing on the string.\n    \"\"\"\n    if not isinstance(html, _strings):\n        raise TypeError('string required')\n\n    if parser is None:\n        parser = html_parser\n\n    options = {}\n    if guess_charset is None and isinstance(html, bytes):\n        # html5lib does not accept useChardet as an argument, if it\n        # detected the html argument would produce unicode objects.\n        guess_charset = False\n    if guess_charset is not None:\n        options['useChardet'] = guess_charset\n    children = parser.parseFragment(html, 'div', **options)\n    if children and isinstance(children[0], _strings):\n        if no_leading_text:\n            if children[0].strip():\n                raise etree.ParserError('There is leading text: %r' %\n                                        children[0])\n            del children[0]\n    return children\n\n\ndef fragment_fromstring(html, create_parent=False,\n                        guess_charset=None, parser=None):\n    \"\"\"Parses a single HTML element; it is an error if there is more than\n    one element, or if anything but whitespace precedes or follows the\n    element.\n\n    If 'create_parent' is true (or is a tag name) then a parent node\n    will be created to encapsulate the HTML in a single element.  In\n    this case, leading or trailing text is allowed.\n\n    If `guess_charset` is true, the `chardet` library will perform charset\n    guessing on the string.\n    \"\"\"\n    if not isinstance(html, _strings):\n        raise TypeError('string required')\n\n    accept_leading_text = bool(create_parent)\n\n    elements = fragments_fromstring(\n        html, guess_charset=guess_charset, parser=parser,\n        no_leading_text=not accept_leading_text)\n\n    if create_parent:\n        if not isinstance(create_parent, _strings):\n            create_parent = 'div'\n        new_root = Element(create_parent)\n        if elements:\n            if isinstance(elements[0], _strings):\n                new_root.text = elements[0]\n                del elements[0]\n            new_root.extend(elements)\n        return new_root\n\n    if not elements:\n        raise etree.ParserError('No elements found')\n    if len(elements) > 1:\n        raise etree.ParserError('Multiple elements found')\n    result = elements[0]\n    if result.tail and result.tail.strip():\n        raise etree.ParserError('Element followed by text: %r' % result.tail)\n    result.tail = None\n    return result\n\n\ndef fromstring(html, guess_charset=None, parser=None):\n    \"\"\"Parse the html, returning a single element/document.\n\n    This tries to minimally parse the chunk of text, without knowing if it\n    is a fragment or a document.\n\n    'base_url' will set the document's base_url attribute (and the tree's\n    docinfo.URL)\n\n    If `guess_charset` is true, or if the input is not Unicode but a\n    byte string, the `chardet` library will perform charset guessing\n    on the string.\n    \"\"\"\n    if not isinstance(html, _strings):\n        raise TypeError('string required')\n    doc = document_fromstring(html, parser=parser,\n                              guess_charset=guess_charset)\n\n    # document starts with doctype or <html>, full document!\n    start = html[:50]\n    if isinstance(start, bytes):\n        # Allow text comparison in python3.\n        # Decode as ascii, that also covers latin-1 and utf-8 for the\n        # characters we need.\n        start = start.decode('ascii', 'replace')\n\n    start = start.lstrip().lower()\n    if start.startswith('<html') or start.startswith('<!doctype'):\n        return doc\n\n    head = _find_tag(doc, 'head')\n\n    # if the head is not empty we have a full document\n    if len(head):\n        return doc\n\n    body = _find_tag(doc, 'body')\n\n    # The body has just one element, so it was probably a single\n    # element passed in\n    if (len(body) == 1 and (not body.text or not body.text.strip())\n        and (not body[-1].tail or not body[-1].tail.strip())):\n        return body[0]\n\n    # Now we have a body which represents a bunch of tags which have the\n    # content that was passed in.  We will create a fake container, which\n    # is the body tag, except <body> implies too much structure.\n    if _contains_block_level_tag(body):\n        body.tag = 'div'\n    else:\n        body.tag = 'span'\n    return body\n\n\ndef parse(filename_url_or_file, guess_charset=None, parser=None):\n    \"\"\"Parse a filename, URL, or file-like object into an HTML document\n    tree.  Note: this returns a tree, not an element.  Use\n    ``parse(...).getroot()`` to get the document root.\n\n    If ``guess_charset`` is true, the ``useChardet`` option is passed into\n    html5lib to enable character detection.  This option is on by default\n    when parsing from URLs, off by default when parsing from file(-like)\n    objects (which tend to return Unicode more often than not), and on by\n    default when parsing from a file path (which is read in binary mode).\n    \"\"\"\n    if parser is None:\n        parser = html_parser\n    if not isinstance(filename_url_or_file, _strings):\n        fp = filename_url_or_file\n        if guess_charset is None:\n            # assume that file-like objects return Unicode more often than bytes\n            guess_charset = False\n    elif _looks_like_url(filename_url_or_file):\n        fp = urlopen(filename_url_or_file)\n        if guess_charset is None:\n            # assume that URLs return bytes\n            guess_charset = True\n    else:\n        fp = open(filename_url_or_file, 'rb')\n        if guess_charset is None:\n            guess_charset = True\n\n    options = {}\n    # html5lib does not accept useChardet as an argument, if it\n    # detected the html argument would produce unicode objects.\n    if guess_charset:\n        options['useChardet'] = guess_charset\n    return parser.parse(fp, **options)\n\n\ndef _looks_like_url(str):\n    scheme = urlparse(str)[0]\n    if not scheme:\n        return False\n    elif (sys.platform == 'win32' and\n            scheme in string.ascii_letters\n            and len(scheme) == 1):\n        # looks like a 'normal' absolute path\n        return False\n    else:\n        return True\n\n\nhtml_parser = HTMLParser()\n", "src/lxml/html/ElementSoup.py": "__doc__ = \"\"\"Legacy interface to the BeautifulSoup HTML parser.\n\"\"\"\n\n__all__ = [\"parse\", \"convert_tree\"]\n\nfrom .soupparser import convert_tree, parse as _parse\n\ndef parse(file, beautifulsoup=None, makeelement=None):\n    root = _parse(file, beautifulsoup=beautifulsoup, makeelement=makeelement)\n    return root.getroot()\n", "src/lxml/html/_html5builder.py": "\"\"\"\nLegacy module - don't use in new code!\n\nhtml5lib now has its own proper implementation.\n\nThis module implements a tree builder for html5lib that generates lxml\nhtml element trees.  This module uses camelCase as it follows the\nhtml5lib style guide.\n\"\"\"\n\nfrom html5lib.treebuilders import _base, etree as etree_builders\nfrom lxml import html, etree\n\n\nclass DocumentType:\n\n    def __init__(self, name, publicId, systemId):\n        self.name = name\n        self.publicId = publicId\n        self.systemId = systemId\n\nclass Document:\n\n    def __init__(self):\n        self._elementTree = None\n        self.childNodes = []\n\n    def appendChild(self, element):\n        self._elementTree.getroot().addnext(element._element)\n\n\nclass TreeBuilder(_base.TreeBuilder):\n    documentClass = Document\n    doctypeClass = DocumentType\n    elementClass = None\n    commentClass = None\n    fragmentClass = Document\n\n    def __init__(self, *args, **kwargs):\n        html_builder = etree_builders.getETreeModule(html, fullTree=False)\n        etree_builder = etree_builders.getETreeModule(etree, fullTree=False)\n        self.elementClass = html_builder.Element\n        self.commentClass = etree_builder.Comment\n        _base.TreeBuilder.__init__(self, *args, **kwargs)\n\n    def reset(self):\n        _base.TreeBuilder.reset(self)\n        self.rootInserted = False\n        self.initialComments = []\n        self.doctype = None\n\n    def getDocument(self):\n        return self.document._elementTree\n\n    def getFragment(self):\n        fragment = []\n        element = self.openElements[0]._element\n        if element.text:\n            fragment.append(element.text)\n        fragment.extend(element.getchildren())\n        if element.tail:\n            fragment.append(element.tail)\n        return fragment\n\n    def insertDoctype(self, name, publicId, systemId):\n        doctype = self.doctypeClass(name, publicId, systemId)\n        self.doctype = doctype\n\n    def insertComment(self, data, parent=None):\n        if not self.rootInserted:\n            self.initialComments.append(data)\n        else:\n            _base.TreeBuilder.insertComment(self, data, parent)\n\n    def insertRoot(self, name):\n        buf = []\n        if self.doctype and self.doctype.name:\n            buf.append('<!DOCTYPE %s' % self.doctype.name)\n            if self.doctype.publicId is not None or self.doctype.systemId is not None:\n                buf.append(' PUBLIC \"%s\" \"%s\"' % (self.doctype.publicId,\n                                                  self.doctype.systemId))\n            buf.append('>')\n        buf.append('<html></html>')\n        root = html.fromstring(''.join(buf))\n\n        # Append the initial comments:\n        for comment in self.initialComments:\n            root.addprevious(etree.Comment(comment))\n\n        # Create the root document and add the ElementTree to it\n        self.document = self.documentClass()\n        self.document._elementTree = root.getroottree()\n\n        # Add the root element to the internal child/open data structures\n        root_element = self.elementClass(name)\n        root_element._element = root\n        self.document.childNodes.append(root_element)\n        self.openElements.append(root_element)\n\n        self.rootInserted = True\n", "src/lxml/html/diff.py": "# cython: language_level=3\n\n\nimport difflib\nfrom lxml import etree\nfrom lxml.html import fragment_fromstring\nimport re\n\n__all__ = ['html_annotate', 'htmldiff']\n\ntry:\n    from html import escape as html_escape\nexcept ImportError:\n    from cgi import escape as html_escape\ntry:\n    _unicode = unicode\nexcept NameError:\n    # Python 3\n    _unicode = str\ntry:\n    basestring\nexcept NameError:\n    # Python 3\n    basestring = str\n\n############################################################\n## Annotation\n############################################################\n\ndef default_markup(text, version):\n    return '<span title=\"%s\">%s</span>' % (\n        html_escape(_unicode(version), 1), text)\n\ndef html_annotate(doclist, markup=default_markup):\n    \"\"\"\n    doclist should be ordered from oldest to newest, like::\n\n        >>> version1 = 'Hello World'\n        >>> version2 = 'Goodbye World'\n        >>> print(html_annotate([(version1, 'version 1'),\n        ...                      (version2, 'version 2')]))\n        <span title=\"version 2\">Goodbye</span> <span title=\"version 1\">World</span>\n\n    The documents must be *fragments* (str/UTF8 or unicode), not\n    complete documents\n\n    The markup argument is a function to markup the spans of words.\n    This function is called like markup('Hello', 'version 2'), and\n    returns HTML.  The first argument is text and never includes any\n    markup.  The default uses a span with a title:\n\n        >>> print(default_markup('Some Text', 'by Joe'))\n        <span title=\"by Joe\">Some Text</span>\n    \"\"\"\n    # The basic strategy we have is to split the documents up into\n    # logical tokens (which are words with attached markup).  We then\n    # do diffs of each of the versions to track when a token first\n    # appeared in the document; the annotation attached to the token\n    # is the version where it first appeared.\n    tokenlist = [tokenize_annotated(doc, version)\n                 for doc, version in doclist]\n    cur_tokens = tokenlist[0]\n    for tokens in tokenlist[1:]:\n        html_annotate_merge_annotations(cur_tokens, tokens)\n        cur_tokens = tokens\n\n    # After we've tracked all the tokens, we can combine spans of text\n    # that are adjacent and have the same annotation\n    cur_tokens = compress_tokens(cur_tokens)\n    # And finally add markup\n    result = markup_serialize_tokens(cur_tokens, markup)\n    return ''.join(result).strip()\n\ndef tokenize_annotated(doc, annotation): \n    \"\"\"Tokenize a document and add an annotation attribute to each token\n    \"\"\"\n    tokens = tokenize(doc, include_hrefs=False)\n    for tok in tokens: \n        tok.annotation = annotation\n    return tokens\n\ndef html_annotate_merge_annotations(tokens_old, tokens_new): \n    \"\"\"Merge the annotations from tokens_old into tokens_new, when the\n    tokens in the new document already existed in the old document.\n    \"\"\"\n    s = InsensitiveSequenceMatcher(a=tokens_old, b=tokens_new)\n    commands = s.get_opcodes()\n\n    for command, i1, i2, j1, j2 in commands:\n        if command == 'equal': \n            eq_old = tokens_old[i1:i2]\n            eq_new = tokens_new[j1:j2]\n            copy_annotations(eq_old, eq_new)\n\ndef copy_annotations(src, dest): \n    \"\"\"\n    Copy annotations from the tokens listed in src to the tokens in dest\n    \"\"\"\n    assert len(src) == len(dest)\n    for src_tok, dest_tok in zip(src, dest): \n        dest_tok.annotation = src_tok.annotation\n\ndef compress_tokens(tokens):\n    \"\"\"\n    Combine adjacent tokens when there is no HTML between the tokens, \n    and they share an annotation\n    \"\"\"\n    result = [tokens[0]] \n    for tok in tokens[1:]: \n        if (not result[-1].post_tags and \n            not tok.pre_tags and \n            result[-1].annotation == tok.annotation): \n            compress_merge_back(result, tok)\n        else: \n            result.append(tok)\n    return result\n\ndef compress_merge_back(tokens, tok): \n    \"\"\" Merge tok into the last element of tokens (modifying the list of\n    tokens in-place).  \"\"\"\n    last = tokens[-1]\n    if type(last) is not token or type(tok) is not token: \n        tokens.append(tok)\n    else:\n        text = _unicode(last)\n        if last.trailing_whitespace:\n            text += last.trailing_whitespace\n        text += tok\n        merged = token(text,\n                       pre_tags=last.pre_tags,\n                       post_tags=tok.post_tags,\n                       trailing_whitespace=tok.trailing_whitespace)\n        merged.annotation = last.annotation\n        tokens[-1] = merged\n    \ndef markup_serialize_tokens(tokens, markup_func):\n    \"\"\"\n    Serialize the list of tokens into a list of text chunks, calling\n    markup_func around text to add annotations.\n    \"\"\"\n    for token in tokens:\n        yield from token.pre_tags\n        html = token.html()\n        html = markup_func(html, token.annotation)\n        if token.trailing_whitespace:\n            html += token.trailing_whitespace\n        yield html\n        yield from token.post_tags\n\n\n############################################################\n## HTML Diffs\n############################################################\n\ndef htmldiff(old_html, new_html):\n    ## FIXME: this should take parsed documents too, and use their body\n    ## or other content.\n    \"\"\" Do a diff of the old and new document.  The documents are HTML\n    *fragments* (str/UTF8 or unicode), they are not complete documents\n    (i.e., no <html> tag).\n\n    Returns HTML with <ins> and <del> tags added around the\n    appropriate text.  \n\n    Markup is generally ignored, with the markup from new_html\n    preserved, and possibly some markup from old_html (though it is\n    considered acceptable to lose some of the old markup).  Only the\n    words in the HTML are diffed.  The exception is <img> tags, which\n    are treated like words, and the href attribute of <a> tags, which\n    are noted inside the tag itself when there are changes.\n    \"\"\" \n    old_html_tokens = tokenize(old_html)\n    new_html_tokens = tokenize(new_html)\n    result = htmldiff_tokens(old_html_tokens, new_html_tokens)\n    result = ''.join(result).strip()\n    return fixup_ins_del_tags(result)\n\ndef htmldiff_tokens(html1_tokens, html2_tokens):\n    \"\"\" Does a diff on the tokens themselves, returning a list of text\n    chunks (not tokens).\n    \"\"\"\n    # There are several passes as we do the differences.  The tokens\n    # isolate the portion of the content we care to diff; difflib does\n    # all the actual hard work at that point.  \n    #\n    # Then we must create a valid document from pieces of both the old\n    # document and the new document.  We generally prefer to take\n    # markup from the new document, and only do a best effort attempt\n    # to keep markup from the old document; anything that we can't\n    # resolve we throw away.  Also we try to put the deletes as close\n    # to the location where we think they would have been -- because\n    # we are only keeping the markup from the new document, it can be\n    # fuzzy where in the new document the old text would have gone.\n    # Again we just do a best effort attempt.\n    s = InsensitiveSequenceMatcher(a=html1_tokens, b=html2_tokens)\n    commands = s.get_opcodes()\n    result = []\n    for command, i1, i2, j1, j2 in commands:\n        if command == 'equal':\n            result.extend(expand_tokens(html2_tokens[j1:j2], equal=True))\n            continue\n        if command == 'insert' or command == 'replace':\n            ins_tokens = expand_tokens(html2_tokens[j1:j2])\n            merge_insert(ins_tokens, result)\n        if command == 'delete' or command == 'replace':\n            del_tokens = expand_tokens(html1_tokens[i1:i2])\n            merge_delete(del_tokens, result)\n    # If deletes were inserted directly as <del> then we'd have an\n    # invalid document at this point.  Instead we put in special\n    # markers, and when the complete diffed document has been created\n    # we try to move the deletes around and resolve any problems.\n    result = cleanup_delete(result)\n\n    return result\n\ndef expand_tokens(tokens, equal=False):\n    \"\"\"Given a list of tokens, return a generator of the chunks of\n    text for the data in the tokens.\n    \"\"\"\n    for token in tokens:\n        yield from token.pre_tags\n        if not equal or not token.hide_when_equal:\n            if token.trailing_whitespace:\n                yield token.html() + token.trailing_whitespace\n            else:\n                yield token.html()\n        yield from token.post_tags\n\ndef merge_insert(ins_chunks, doc):\n    \"\"\" doc is the already-handled document (as a list of text chunks);\n    here we add <ins>ins_chunks</ins> to the end of that.  \"\"\"\n    # Though we don't throw away unbalanced_start or unbalanced_end\n    # (we assume there is accompanying markup later or earlier in the\n    # document), we only put <ins> around the balanced portion.\n    unbalanced_start, balanced, unbalanced_end = split_unbalanced(ins_chunks)\n    doc.extend(unbalanced_start)\n    if doc and not doc[-1].endswith(' '):\n        # Fix up the case where the word before the insert didn't end with \n        # a space\n        doc[-1] += ' '\n    doc.append('<ins>')\n    if balanced and balanced[-1].endswith(' '):\n        # We move space outside of </ins>\n        balanced[-1] = balanced[-1][:-1]\n    doc.extend(balanced)\n    doc.append('</ins> ')\n    doc.extend(unbalanced_end)\n\n# These are sentinels to represent the start and end of a <del>\n# segment, until we do the cleanup phase to turn them into proper\n# markup:\nclass DEL_START:\n    pass\nclass DEL_END:\n    pass\n\nclass NoDeletes(Exception):\n    \"\"\" Raised when the document no longer contains any pending deletes\n    (DEL_START/DEL_END) \"\"\"\n\ndef merge_delete(del_chunks, doc):\n    \"\"\" Adds the text chunks in del_chunks to the document doc (another\n    list of text chunks) with marker to show it is a delete.\n    cleanup_delete later resolves these markers into <del> tags.\"\"\"\n    doc.append(DEL_START)\n    doc.extend(del_chunks)\n    doc.append(DEL_END)\n\ndef cleanup_delete(chunks):\n    \"\"\" Cleans up any DEL_START/DEL_END markers in the document, replacing\n    them with <del></del>.  To do this while keeping the document\n    valid, it may need to drop some tags (either start or end tags).\n\n    It may also move the del into adjacent tags to try to move it to a\n    similar location where it was originally located (e.g., moving a\n    delete into preceding <div> tag, if the del looks like (DEL_START,\n    'Text</div>', DEL_END)\"\"\"\n    while 1:\n        # Find a pending DEL_START/DEL_END, splitting the document\n        # into stuff-preceding-DEL_START, stuff-inside, and\n        # stuff-following-DEL_END\n        try:\n            pre_delete, delete, post_delete = split_delete(chunks)\n        except NoDeletes:\n            # Nothing found, we've cleaned up the entire doc\n            break\n        # The stuff-inside-DEL_START/END may not be well balanced\n        # markup.  First we figure out what unbalanced portions there are:\n        unbalanced_start, balanced, unbalanced_end = split_unbalanced(delete)\n        # Then we move the span forward and/or backward based on these\n        # unbalanced portions:\n        locate_unbalanced_start(unbalanced_start, pre_delete, post_delete)\n        locate_unbalanced_end(unbalanced_end, pre_delete, post_delete)\n        doc = pre_delete\n        if doc and not doc[-1].endswith(' '):\n            # Fix up case where the word before us didn't have a trailing space\n            doc[-1] += ' '\n        doc.append('<del>')\n        if balanced and balanced[-1].endswith(' '):\n            # We move space outside of </del>\n            balanced[-1] = balanced[-1][:-1]\n        doc.extend(balanced)\n        doc.append('</del> ')\n        doc.extend(post_delete)\n        chunks = doc\n    return chunks\n\ndef split_unbalanced(chunks):\n    \"\"\"Return (unbalanced_start, balanced, unbalanced_end), where each is\n    a list of text and tag chunks.\n\n    unbalanced_start is a list of all the tags that are opened, but\n    not closed in this span.  Similarly, unbalanced_end is a list of\n    tags that are closed but were not opened.  Extracting these might\n    mean some reordering of the chunks.\"\"\"\n    start = []\n    end = []\n    tag_stack = []\n    balanced = []\n    for chunk in chunks:\n        if not chunk.startswith('<'):\n            balanced.append(chunk)\n            continue\n        endtag = chunk[1] == '/'\n        name = chunk.split()[0].strip('<>/')\n        if name in empty_tags:\n            balanced.append(chunk)\n            continue\n        if endtag:\n            if tag_stack and tag_stack[-1][0] == name:\n                balanced.append(chunk)\n                name, pos, tag = tag_stack.pop()\n                balanced[pos] = tag\n            elif tag_stack:\n                start.extend([tag for name, pos, tag in tag_stack])\n                tag_stack = []\n                end.append(chunk)\n            else:\n                end.append(chunk)\n        else:\n            tag_stack.append((name, len(balanced), chunk))\n            balanced.append(None)\n    start.extend(\n        [chunk for name, pos, chunk in tag_stack])\n    balanced = [chunk for chunk in balanced if chunk is not None]\n    return start, balanced, end\n\ndef split_delete(chunks):\n    \"\"\" Returns (stuff_before_DEL_START, stuff_inside_DEL_START_END,\n    stuff_after_DEL_END).  Returns the first case found (there may be\n    more DEL_STARTs in stuff_after_DEL_END).  Raises NoDeletes if\n    there's no DEL_START found. \"\"\"\n    try:\n        pos = chunks.index(DEL_START)\n    except ValueError:\n        raise NoDeletes\n    pos2 = chunks.index(DEL_END)\n    return chunks[:pos], chunks[pos+1:pos2], chunks[pos2+1:]\n\ndef locate_unbalanced_start(unbalanced_start, pre_delete, post_delete):\n    \"\"\" pre_delete and post_delete implicitly point to a place in the\n    document (where the two were split).  This moves that point (by\n    popping items from one and pushing them onto the other).  It moves\n    the point to try to find a place where unbalanced_start applies.\n\n    As an example::\n\n        >>> unbalanced_start = ['<div>']\n        >>> doc = ['<p>', 'Text', '</p>', '<div>', 'More Text', '</div>']\n        >>> pre, post = doc[:3], doc[3:]\n        >>> pre, post\n        (['<p>', 'Text', '</p>'], ['<div>', 'More Text', '</div>'])\n        >>> locate_unbalanced_start(unbalanced_start, pre, post)\n        >>> pre, post\n        (['<p>', 'Text', '</p>', '<div>'], ['More Text', '</div>'])\n\n    As you can see, we moved the point so that the dangling <div> that\n    we found will be effectively replaced by the div in the original\n    document.  If this doesn't work out, we just throw away\n    unbalanced_start without doing anything.\n    \"\"\"\n    while 1:\n        if not unbalanced_start:\n            # We have totally succeeded in finding the position\n            break\n        finding = unbalanced_start[0]\n        finding_name = finding.split()[0].strip('<>')\n        if not post_delete:\n            break\n        next = post_delete[0]\n        if next is DEL_START or not next.startswith('<'):\n            # Reached a word, we can't move the delete text forward\n            break\n        if next[1] == '/':\n            # Reached a closing tag, can we go further?  Maybe not...\n            break\n        name = next.split()[0].strip('<>')\n        if name == 'ins':\n            # Can't move into an insert\n            break\n        assert name != 'del', (\n            \"Unexpected delete tag: %r\" % next)\n        if name == finding_name:\n            unbalanced_start.pop(0)\n            pre_delete.append(post_delete.pop(0))\n        else:\n            # Found a tag that doesn't match\n            break\n\ndef locate_unbalanced_end(unbalanced_end, pre_delete, post_delete):\n    \"\"\" like locate_unbalanced_start, except handling end tags and\n    possibly moving the point earlier in the document.  \"\"\"\n    while 1:\n        if not unbalanced_end:\n            # Success\n            break\n        finding = unbalanced_end[-1]\n        finding_name = finding.split()[0].strip('<>/')\n        if not pre_delete:\n            break\n        next = pre_delete[-1]\n        if next is DEL_END or not next.startswith('</'):\n            # A word or a start tag\n            break\n        name = next.split()[0].strip('<>/')\n        if name == 'ins' or name == 'del':\n            # Can't move into an insert or delete\n            break\n        if name == finding_name:\n            unbalanced_end.pop()\n            post_delete.insert(0, pre_delete.pop())\n        else:\n            # Found a tag that doesn't match\n            break\n\nclass token(_unicode):\n    \"\"\" Represents a diffable token, generally a word that is displayed to\n    the user.  Opening tags are attached to this token when they are\n    adjacent (pre_tags) and closing tags that follow the word\n    (post_tags).  Some exceptions occur when there are empty tags\n    adjacent to a word, so there may be close tags in pre_tags, or\n    open tags in post_tags.\n\n    We also keep track of whether the word was originally followed by\n    whitespace, even though we do not want to treat the word as\n    equivalent to a similar word that does not have a trailing\n    space.\"\"\"\n\n    # When this is true, the token will be eliminated from the\n    # displayed diff if no change has occurred:\n    hide_when_equal = False\n\n    def __new__(cls, text, pre_tags=None, post_tags=None, trailing_whitespace=\"\"):\n        obj = _unicode.__new__(cls, text)\n\n        if pre_tags is not None:\n            obj.pre_tags = pre_tags\n        else:\n            obj.pre_tags = []\n\n        if post_tags is not None:\n            obj.post_tags = post_tags\n        else:\n            obj.post_tags = []\n\n        obj.trailing_whitespace = trailing_whitespace\n\n        return obj\n\n    def __repr__(self):\n        return 'token(%s, %r, %r, %r)' % (_unicode.__repr__(self), self.pre_tags,\n                                          self.post_tags, self.trailing_whitespace)\n\n    def html(self):\n        return _unicode(self)\n\nclass tag_token(token):\n\n    \"\"\" Represents a token that is actually a tag.  Currently this is just\n    the <img> tag, which takes up visible space just like a word but\n    is only represented in a document by a tag.  \"\"\"\n\n    def __new__(cls, tag, data, html_repr, pre_tags=None, \n                post_tags=None, trailing_whitespace=\"\"):\n        obj = token.__new__(cls, \"%s: %s\" % (type, data), \n                            pre_tags=pre_tags, \n                            post_tags=post_tags, \n                            trailing_whitespace=trailing_whitespace)\n        obj.tag = tag\n        obj.data = data\n        obj.html_repr = html_repr\n        return obj\n\n    def __repr__(self):\n        return 'tag_token(%s, %s, html_repr=%s, post_tags=%r, pre_tags=%r, trailing_whitespace=%r)' % (\n            self.tag, \n            self.data, \n            self.html_repr, \n            self.pre_tags, \n            self.post_tags, \n            self.trailing_whitespace)\n    def html(self):\n        return self.html_repr\n\nclass href_token(token):\n\n    \"\"\" Represents the href in an anchor tag.  Unlike other words, we only\n    show the href when it changes.  \"\"\"\n\n    hide_when_equal = True\n\n    def html(self):\n        return ' Link: %s' % self\n\ndef tokenize(html, include_hrefs=True):\n    \"\"\"\n    Parse the given HTML and returns token objects (words with attached tags).\n\n    This parses only the content of a page; anything in the head is\n    ignored, and the <head> and <body> elements are themselves\n    optional.  The content is then parsed by lxml, which ensures the\n    validity of the resulting parsed document (though lxml may make\n    incorrect guesses when the markup is particular bad).\n\n    <ins> and <del> tags are also eliminated from the document, as\n    that gets confusing.\n\n    If include_hrefs is true, then the href attribute of <a> tags is\n    included as a special kind of diffable token.\"\"\"\n    if etree.iselement(html):\n        body_el = html\n    else:\n        body_el = parse_html(html, cleanup=True)\n    # Then we split the document into text chunks for each tag, word, and end tag:\n    chunks = flatten_el(body_el, skip_tag=True, include_hrefs=include_hrefs)\n    # Finally re-joining them into token objects:\n    return fixup_chunks(chunks)\n\ndef parse_html(html, cleanup=True):\n    \"\"\"\n    Parses an HTML fragment, returning an lxml element.  Note that the HTML will be\n    wrapped in a <div> tag that was not in the original document.\n\n    If cleanup is true, make sure there's no <head> or <body>, and get\n    rid of any <ins> and <del> tags.\n    \"\"\"\n    if cleanup:\n        # This removes any extra markup or structure like <head>:\n        html = cleanup_html(html)\n    return fragment_fromstring(html, create_parent=True)\n\n_body_re = re.compile(r'<body.*?>', re.I|re.S)\n_end_body_re = re.compile(r'</body.*?>', re.I|re.S)\n_ins_del_re = re.compile(r'</?(ins|del).*?>', re.I|re.S)\n\ndef cleanup_html(html):\n    \"\"\" This 'cleans' the HTML, meaning that any page structure is removed\n    (only the contents of <body> are used, if there is any <body).\n    Also <ins> and <del> tags are removed.  \"\"\"\n    match = _body_re.search(html)\n    if match:\n        html = html[match.end():]\n    match = _end_body_re.search(html)\n    if match:\n        html = html[:match.start()]\n    html = _ins_del_re.sub('', html)\n    return html\n    \n\nend_whitespace_re = re.compile(r'[ \\t\\n\\r]$')\n\ndef split_trailing_whitespace(word):\n    \"\"\"\n    This function takes a word, such as 'test\\n\\n' and returns ('test','\\n\\n')\n    \"\"\"\n    stripped_length = len(word.rstrip())\n    return word[0:stripped_length], word[stripped_length:]\n\n\ndef fixup_chunks(chunks):\n    \"\"\"\n    This function takes a list of chunks and produces a list of tokens.\n    \"\"\"\n    tag_accum = []\n    cur_word = None\n    result = []\n    for chunk in chunks:\n        if isinstance(chunk, tuple):\n            if chunk[0] == 'img':\n                src = chunk[1]\n                tag, trailing_whitespace = split_trailing_whitespace(chunk[2])\n                cur_word = tag_token('img', src, html_repr=tag,\n                                     pre_tags=tag_accum,\n                                     trailing_whitespace=trailing_whitespace)\n                tag_accum = []\n                result.append(cur_word)\n\n            elif chunk[0] == 'href':\n                href = chunk[1]\n                cur_word = href_token(href, pre_tags=tag_accum, trailing_whitespace=\" \")\n                tag_accum = []\n                result.append(cur_word)\n            continue\n\n        if is_word(chunk):\n            chunk, trailing_whitespace = split_trailing_whitespace(chunk)\n            cur_word = token(chunk, pre_tags=tag_accum, trailing_whitespace=trailing_whitespace)\n            tag_accum = []\n            result.append(cur_word)\n\n        elif is_start_tag(chunk):\n            tag_accum.append(chunk)\n\n        elif is_end_tag(chunk):\n            if tag_accum:\n                tag_accum.append(chunk)\n            else:\n                assert cur_word, (\n                    \"Weird state, cur_word=%r, result=%r, chunks=%r of %r\"\n                    % (cur_word, result, chunk, chunks))\n                cur_word.post_tags.append(chunk)\n        else:\n            assert False\n\n    if not result:\n        return [token('', pre_tags=tag_accum)]\n    else:\n        result[-1].post_tags.extend(tag_accum)\n\n    return result\n\n\n# All the tags in HTML that don't require end tags:\nempty_tags = (\n    'param', 'img', 'area', 'br', 'basefont', 'input',\n    'base', 'meta', 'link', 'col')\n\nblock_level_tags = (\n    'address',\n    'blockquote',\n    'center',\n    'dir',\n    'div',\n    'dl',\n    'fieldset',\n    'form',\n    'h1',\n    'h2',\n    'h3',\n    'h4',\n    'h5',\n    'h6',\n    'hr',\n    'isindex',\n    'menu',\n    'noframes',\n    'noscript',\n    'ol',\n    'p',\n    'pre',\n    'table',\n    'ul',\n    )\n\nblock_level_container_tags = (\n    'dd',\n    'dt',\n    'frameset',\n    'li',\n    'tbody',\n    'td',\n    'tfoot',\n    'th',\n    'thead',\n    'tr',\n    )\n\n\ndef flatten_el(el, include_hrefs, skip_tag=False):\n    \"\"\" Takes an lxml element el, and generates all the text chunks for\n    that tag.  Each start tag is a chunk, each word is a chunk, and each\n    end tag is a chunk.\n\n    If skip_tag is true, then the outermost container tag is\n    not returned (just its contents).\"\"\"\n    if not skip_tag:\n        if el.tag == 'img':\n            yield ('img', el.get('src'), start_tag(el))\n        else:\n            yield start_tag(el)\n    if el.tag in empty_tags and not el.text and not len(el) and not el.tail:\n        return\n    start_words = split_words(el.text)\n    for word in start_words:\n        yield html_escape(word)\n    for child in el:\n        yield from flatten_el(child, include_hrefs=include_hrefs)\n    if el.tag == 'a' and el.get('href') and include_hrefs:\n        yield ('href', el.get('href'))\n    if not skip_tag:\n        yield end_tag(el)\n        end_words = split_words(el.tail)\n        for word in end_words:\n            yield html_escape(word)\n\nsplit_words_re = re.compile(r'\\S+(?:\\s+|$)', re.U)\n\ndef split_words(text):\n    \"\"\" Splits some text into words. Includes trailing whitespace\n    on each word when appropriate.  \"\"\"\n    if not text or not text.strip():\n        return []\n\n    words = split_words_re.findall(text)\n    return words\n\nstart_whitespace_re = re.compile(r'^[ \\t\\n\\r]')\n\ndef start_tag(el):\n    \"\"\"\n    The text representation of the start tag for a tag.\n    \"\"\"\n    return '<%s%s>' % (\n        el.tag, ''.join([' %s=\"%s\"' % (name, html_escape(value, True))\n                         for name, value in el.attrib.items()]))\n\ndef end_tag(el):\n    \"\"\" The text representation of an end tag for a tag.  Includes\n    trailing whitespace when appropriate.  \"\"\"\n    if el.tail and start_whitespace_re.search(el.tail):\n        extra = ' '\n    else:\n        extra = ''\n    return '</%s>%s' % (el.tag, extra)\n\ndef is_word(tok):\n    return not tok.startswith('<')\n\ndef is_end_tag(tok):\n    return tok.startswith('</')\n\ndef is_start_tag(tok):\n    return tok.startswith('<') and not tok.startswith('</')\n\ndef fixup_ins_del_tags(html):\n    \"\"\" Given an html string, move any <ins> or <del> tags inside of any\n    block-level elements, e.g. transform <ins><p>word</p></ins> to\n    <p><ins>word</ins></p> \"\"\"\n    doc = parse_html(html, cleanup=False)\n    _fixup_ins_del_tags(doc)\n    html = serialize_html_fragment(doc, skip_outer=True)\n    return html\n\ndef serialize_html_fragment(el, skip_outer=False):\n    \"\"\" Serialize a single lxml element as HTML.  The serialized form\n    includes the elements tail.  \n\n    If skip_outer is true, then don't serialize the outermost tag\n    \"\"\"\n    assert not isinstance(el, basestring), (\n        \"You should pass in an element, not a string like %r\" % el)\n    html = etree.tostring(el, method=\"html\", encoding=_unicode)\n    if skip_outer:\n        # Get rid of the extra starting tag:\n        html = html[html.find('>')+1:]\n        # Get rid of the extra end tag:\n        html = html[:html.rfind('<')]\n        return html.strip()\n    else:\n        return html\n\ndef _fixup_ins_del_tags(doc):\n    \"\"\"fixup_ins_del_tags that works on an lxml document in-place\n    \"\"\"\n    for tag in ['ins', 'del']:\n        for el in doc.xpath('descendant-or-self::%s' % tag):\n            if not _contains_block_level_tag(el):\n                continue\n            _move_el_inside_block(el, tag=tag)\n            el.drop_tag()\n            #_merge_element_contents(el)\n\ndef _contains_block_level_tag(el):\n    \"\"\"True if the element contains any block-level elements, like <p>, <td>, etc.\n    \"\"\"\n    if el.tag in block_level_tags or el.tag in block_level_container_tags:\n        return True\n    for child in el:\n        if _contains_block_level_tag(child):\n            return True\n    return False\n\ndef _move_el_inside_block(el, tag):\n    \"\"\" helper for _fixup_ins_del_tags; actually takes the <ins> etc tags\n    and moves them inside any block-level tags.  \"\"\"\n    for child in el:\n        if _contains_block_level_tag(child):\n            break\n    else:\n        # No block-level tags in any child\n        children_tag = etree.Element(tag)\n        children_tag.text = el.text\n        el.text = None\n        children_tag.extend(list(el))\n        el[:] = [children_tag]\n        return\n    for child in list(el):\n        if _contains_block_level_tag(child):\n            _move_el_inside_block(child, tag)\n            if child.tail:\n                tail_tag = etree.Element(tag)\n                tail_tag.text = child.tail\n                child.tail = None\n                el.insert(el.index(child)+1, tail_tag)\n        else:\n            child_tag = etree.Element(tag)\n            el.replace(child, child_tag)\n            child_tag.append(child)\n    if el.text:\n        text_tag = etree.Element(tag)\n        text_tag.text = el.text\n        el.text = None\n        el.insert(0, text_tag)\n            \ndef _merge_element_contents(el):\n    \"\"\"\n    Removes an element, but merges its contents into its place, e.g.,\n    given <p>Hi <i>there!</i></p>, if you remove the <i> element you get\n    <p>Hi there!</p>\n    \"\"\"\n    parent = el.getparent()\n    text = el.text or ''\n    if el.tail:\n        if not len(el):\n            text += el.tail\n        else:\n            if el[-1].tail:\n                el[-1].tail += el.tail\n            else:\n                el[-1].tail = el.tail\n    index = parent.index(el)\n    if text:\n        if index == 0:\n            previous = None\n        else:\n            previous = parent[index-1]\n        if previous is None:\n            if parent.text:\n                parent.text += text\n            else:\n                parent.text = text\n        else:\n            if previous.tail:\n                previous.tail += text\n            else:\n                previous.tail = text\n    parent[index:index+1] = el.getchildren()\n\nclass InsensitiveSequenceMatcher(difflib.SequenceMatcher):\n    \"\"\"\n    Acts like SequenceMatcher, but tries not to find very small equal\n    blocks amidst large spans of changes\n    \"\"\"\n\n    threshold = 2\n    \n    def get_matching_blocks(self):\n        size = min(len(self.b), len(self.b))\n        threshold = min(self.threshold, size / 4)\n        actual = difflib.SequenceMatcher.get_matching_blocks(self)\n        return [item for item in actual\n                if item[2] > threshold\n                or not item[2]]\n\nif __name__ == '__main__':\n    from lxml.html import _diffcommand\n    _diffcommand.main()\n    \n", "src/lxml/html/_diffcommand.py": "import optparse\nimport sys\nimport re\nimport os\nfrom .diff import htmldiff\n\ndescription = \"\"\"\\\n\"\"\"\n\nparser = optparse.OptionParser(\n    usage=\"%prog [OPTIONS] FILE1 FILE2\\n\"\n    \"%prog --annotate [OPTIONS] INFO1 FILE1 INFO2 FILE2 ...\",\n    description=description,\n    )\n\nparser.add_option(\n    '-o', '--output',\n    metavar=\"FILE\",\n    dest=\"output\",\n    default=\"-\",\n    help=\"File to write the difference to\",\n    )\n\nparser.add_option(\n    '-a', '--annotation',\n    action=\"store_true\",\n    dest=\"annotation\",\n    help=\"Do an annotation\")\n\ndef main(args=None):\n    if args is None:\n        args = sys.argv[1:]\n    options, args = parser.parse_args(args)\n    if options.annotation:\n        return annotate(options, args)\n    if len(args) != 2:\n        print('Error: you must give two files')\n        parser.print_help()\n        sys.exit(1)\n    file1, file2 = args\n    input1 = read_file(file1)\n    input2 = read_file(file2)\n    body1 = split_body(input1)[1]\n    pre, body2, post = split_body(input2)\n    result = htmldiff(body1, body2)\n    result = pre + result + post\n    if options.output == '-':\n        if not result.endswith('\\n'):\n            result += '\\n'\n        sys.stdout.write(result)\n    else:\n        with open(options.output, 'wb') as f:\n            f.write(result)\n\ndef read_file(filename):\n    if filename == '-':\n        c = sys.stdin.read()\n    elif not os.path.exists(filename):\n        raise OSError(\n            \"Input file %s does not exist\" % filename)\n    else:\n        with open(filename, 'rb') as f:\n            c = f.read()\n    return c\n\nbody_start_re = re.compile(\n    r\"<body.*?>\", re.I|re.S)\nbody_end_re = re.compile(\n    r\"</body.*?>\", re.I|re.S)\n    \ndef split_body(html):\n    pre = post = ''\n    match = body_start_re.search(html)\n    if match:\n        pre = html[:match.end()]\n        html = html[match.end():]\n    match = body_end_re.search(html)\n    if match:\n        post = html[match.start():]\n        html = html[:match.start()]\n    return pre, html, post\n\ndef annotate(options, args):\n    print(\"Not yet implemented\")\n    sys.exit(1)\n    \n", "src/lxml/html/_setmixin.py": "try:\n    from collections.abc import MutableSet\nexcept ImportError:\n    from collections.abc import MutableSet\n\n\nclass SetMixin(MutableSet):\n\n    \"\"\"\n    Mix-in for sets.  You must define __iter__, add, remove\n    \"\"\"\n\n    def __len__(self):\n        length = 0\n        for item in self:\n            length += 1\n        return length\n\n    def __contains__(self, item):\n        for has_item in self:\n            if item == has_item:\n                return True\n        return False\n\n    issubset = MutableSet.__le__\n    issuperset = MutableSet.__ge__\n\n    union = MutableSet.__or__\n    intersection = MutableSet.__and__\n    difference = MutableSet.__sub__\n    symmetric_difference = MutableSet.__xor__\n\n    def copy(self):\n        return set(self)\n\n    def update(self, other):\n        self |= other\n\n    def intersection_update(self, other):\n        self &= other\n\n    def difference_update(self, other):\n        self -= other\n\n    def symmetric_difference_update(self, other):\n        self ^= other\n\n    def discard(self, item):\n        try:\n            self.remove(item)\n        except KeyError:\n            pass\n\n    @classmethod\n    def _from_iterable(cls, it):\n        return set(it)\n", "src/lxml/html/formfill.py": "from lxml.etree import XPath, ElementBase\nfrom lxml.html import fromstring, XHTML_NAMESPACE\nfrom lxml.html import _forms_xpath, _options_xpath, _nons, _transform_result\nfrom lxml.html import defs\nimport copy\n\ntry:\n    basestring\nexcept NameError:\n    # Python 3\n    basestring = str\n\n__all__ = ['FormNotFound', 'fill_form', 'fill_form_html',\n           'insert_errors', 'insert_errors_html',\n           'DefaultErrorCreator']\n\nclass FormNotFound(LookupError):\n    \"\"\"\n    Raised when no form can be found\n    \"\"\"\n\n_form_name_xpath = XPath('descendant-or-self::form[name=$name]|descendant-or-self::x:form[name=$name]', namespaces={'x':XHTML_NAMESPACE})\n_input_xpath = XPath('|'.join(['descendant-or-self::'+_tag for _tag in ('input','select','textarea','x:input','x:select','x:textarea')]),\n                               namespaces={'x':XHTML_NAMESPACE})\n_label_for_xpath = XPath('//label[@for=$for_id]|//x:label[@for=$for_id]',\n                               namespaces={'x':XHTML_NAMESPACE})\n_name_xpath = XPath('descendant-or-self::*[@name=$name]')\n\ndef fill_form(\n    el,\n    values,\n    form_id=None,\n    form_index=None,\n    ):\n    el = _find_form(el, form_id=form_id, form_index=form_index)\n    _fill_form(el, values)\n\ndef fill_form_html(html, values, form_id=None, form_index=None):\n    result_type = type(html)\n    if isinstance(html, basestring):\n        doc = fromstring(html)\n    else:\n        doc = copy.deepcopy(html)\n    fill_form(doc, values, form_id=form_id, form_index=form_index)\n    return _transform_result(result_type, doc)\n\ndef _fill_form(el, values):\n    counts = {}\n    if hasattr(values, 'mixed'):\n        # For Paste request parameters\n        values = values.mixed()\n    inputs = _input_xpath(el)\n    for input in inputs:\n        name = input.get('name')\n        if not name:\n            continue\n        if _takes_multiple(input):\n            value = values.get(name, [])\n            if not isinstance(value, (list, tuple)):\n                value = [value]\n            _fill_multiple(input, value)\n        elif name not in values:\n            continue\n        else:\n            index = counts.get(name, 0)\n            counts[name] = index + 1\n            value = values[name]\n            if isinstance(value, (list, tuple)):\n                try:\n                    value = value[index]\n                except IndexError:\n                    continue\n            elif index > 0:\n                continue\n            _fill_single(input, value)\n\ndef _takes_multiple(input):\n    if _nons(input.tag) == 'select' and input.get('multiple'):\n        # FIXME: multiple=\"0\"?\n        return True\n    type = input.get('type', '').lower()\n    if type in ('radio', 'checkbox'):\n        return True\n    return False\n\ndef _fill_multiple(input, value):\n    type = input.get('type', '').lower()\n    if type == 'checkbox':\n        v = input.get('value')\n        if v is None:\n            if not value:\n                result = False\n            else:\n                result = value[0]\n                if isinstance(value, basestring):\n                    # The only valid \"on\" value for an unnamed checkbox is 'on'\n                    result = result == 'on'\n            _check(input, result)\n        else:\n            _check(input, v in value)\n    elif type == 'radio':\n        v = input.get('value')\n        _check(input, v in value)\n    else:\n        assert _nons(input.tag) == 'select'\n        for option in _options_xpath(input):\n            v = option.get('value')\n            if v is None:\n                # This seems to be the default, at least on IE\n                # FIXME: but I'm not sure\n                v = option.text_content()\n            _select(option, v in value)\n\ndef _check(el, check):\n    if check:\n        el.set('checked', '')\n    else:\n        if 'checked' in el.attrib:\n            del el.attrib['checked']\n\ndef _select(el, select):\n    if select:\n        el.set('selected', '')\n    else:\n        if 'selected' in el.attrib:\n            del el.attrib['selected']\n\ndef _fill_single(input, value):\n    if _nons(input.tag) == 'textarea':\n        input.text = value\n    else:\n        input.set('value', value)\n\ndef _find_form(el, form_id=None, form_index=None):\n    if form_id is None and form_index is None:\n        forms = _forms_xpath(el)\n        for form in forms:\n            return form\n        raise FormNotFound(\n            \"No forms in page\")\n    if form_id is not None:\n        form = el.get_element_by_id(form_id)\n        if form is not None:\n            return form\n        forms = _form_name_xpath(el, name=form_id)\n        if forms:\n            return forms[0]\n        else:\n            raise FormNotFound(\n                \"No form with the name or id of %r (forms: %s)\"\n                % (id, ', '.join(_find_form_ids(el))))               \n    if form_index is not None:\n        forms = _forms_xpath(el)\n        try:\n            return forms[form_index]\n        except IndexError:\n            raise FormNotFound(\n                \"There is no form with the index %r (%i forms found)\"\n                % (form_index, len(forms)))\n\ndef _find_form_ids(el):\n    forms = _forms_xpath(el)\n    if not forms:\n        yield '(no forms)'\n        return\n    for index, form in enumerate(forms):\n        if form.get('id'):\n            if form.get('name'):\n                yield '%s or %s' % (form.get('id'),\n                                     form.get('name'))\n            else:\n                yield form.get('id')\n        elif form.get('name'):\n            yield form.get('name')\n        else:\n            yield '(unnamed form %s)' % index\n\n############################################################\n## Error filling\n############################################################\n\nclass DefaultErrorCreator:\n    insert_before = True\n    block_inside = True\n    error_container_tag = 'div'\n    error_message_class = 'error-message'\n    error_block_class = 'error-block'\n    default_message = \"Invalid\"\n\n    def __init__(self, **kw):\n        for name, value in kw.items():\n            if not hasattr(self, name):\n                raise TypeError(\n                    \"Unexpected keyword argument: %s\" % name)\n            setattr(self, name, value)\n\n    def __call__(self, el, is_block, message):\n        error_el = el.makeelement(self.error_container_tag)\n        if self.error_message_class:\n            error_el.set('class', self.error_message_class)\n        if is_block and self.error_block_class:\n            error_el.set('class', error_el.get('class', '')+' '+self.error_block_class)\n        if message is None or message == '':\n            message = self.default_message\n        if isinstance(message, ElementBase):\n            error_el.append(message)\n        else:\n            assert isinstance(message, basestring), (\n                \"Bad message; should be a string or element: %r\" % message)\n            error_el.text = message or self.default_message\n        if is_block and self.block_inside:\n            if self.insert_before:\n                error_el.tail = el.text\n                el.text = None\n                el.insert(0, error_el)\n            else:\n                el.append(error_el)\n        else:\n            parent = el.getparent()\n            pos = parent.index(el)\n            if self.insert_before:\n                parent.insert(pos, error_el)\n            else:\n                error_el.tail = el.tail\n                el.tail = None\n                parent.insert(pos+1, error_el)\n\ndefault_error_creator = DefaultErrorCreator()\n    \n\ndef insert_errors(\n    el,\n    errors,\n    form_id=None,\n    form_index=None,\n    error_class=\"error\",\n    error_creator=default_error_creator,\n    ):\n    el = _find_form(el, form_id=form_id, form_index=form_index)\n    for name, error in errors.items():\n        if error is None:\n            continue\n        for error_el, message in _find_elements_for_name(el, name, error):\n            assert isinstance(message, (basestring, type(None), ElementBase)), (\n                \"Bad message: %r\" % message)\n            _insert_error(error_el, message, error_class, error_creator)\n\ndef insert_errors_html(html, values, **kw):\n    result_type = type(html)\n    if isinstance(html, basestring):\n        doc = fromstring(html)\n    else:\n        doc = copy.deepcopy(html)\n    insert_errors(doc, values, **kw)\n    return _transform_result(result_type, doc)\n\ndef _insert_error(el, error, error_class, error_creator):\n    if _nons(el.tag) in defs.empty_tags or _nons(el.tag) == 'textarea':\n        is_block = False\n    else:\n        is_block = True\n    if _nons(el.tag) != 'form' and error_class:\n        _add_class(el, error_class)\n    if el.get('id'):\n        labels = _label_for_xpath(el, for_id=el.get('id'))\n        if labels:\n            for label in labels:\n                _add_class(label, error_class)\n    error_creator(el, is_block, error)\n\ndef _add_class(el, class_name):\n    if el.get('class'):\n        el.set('class', el.get('class')+' '+class_name)\n    else:\n        el.set('class', class_name)\n\ndef _find_elements_for_name(form, name, error):\n    if name is None:\n        # An error for the entire form\n        yield form, error\n        return\n    if name.startswith('#'):\n        # By id\n        el = form.get_element_by_id(name[1:])\n        if el is not None:\n            yield el, error\n        return\n    els = _name_xpath(form, name=name)\n    if not els:\n        # FIXME: should this raise an exception?\n        return\n    if not isinstance(error, (list, tuple)):\n        yield els[0], error\n        return\n    # FIXME: if error is longer than els, should it raise an error?\n    for el, err in zip(els, error):\n        if err is None:\n            continue\n        yield el, err\n", "src/lxml/html/defs.py": "# FIXME: this should all be confirmed against what a DTD says\n# (probably in a test; this may not match the DTD exactly, but we\n# should document just how it differs).\n\n\"\"\"\nData taken from https://www.w3.org/TR/html401/index/elements.html\nand https://www.w3.org/community/webed/wiki/HTML/New_HTML5_Elements\nfor html5_tags.\n\"\"\"\n\nempty_tags = frozenset([\n    'area', 'base', 'basefont', 'br', 'col', 'frame', 'hr',\n    'img', 'input', 'isindex', 'link', 'meta', 'param', 'source', 'track'])\n\ndeprecated_tags = frozenset([\n    'applet', 'basefont', 'center', 'dir', 'font', 'isindex',\n    'menu', 's', 'strike', 'u'])\n\n# archive actually takes a space-separated list of URIs\nlink_attrs = frozenset([\n    'action', 'archive', 'background', 'cite', 'classid',\n    'codebase', 'data', 'href', 'longdesc', 'profile', 'src',\n    'usemap',\n    # Not standard:\n    'dynsrc', 'lowsrc',\n    # HTML5 formaction\n    'formaction'\n    ])\n\n# Not in the HTML 4 spec:\n# onerror, onresize\nevent_attrs = frozenset([\n    'onblur', 'onchange', 'onclick', 'ondblclick', 'onerror',\n    'onfocus', 'onkeydown', 'onkeypress', 'onkeyup', 'onload',\n    'onmousedown', 'onmousemove', 'onmouseout', 'onmouseover',\n    'onmouseup', 'onreset', 'onresize', 'onselect', 'onsubmit',\n    'onunload',\n    ])\n\nsafe_attrs = frozenset([\n    'abbr', 'accept', 'accept-charset', 'accesskey', 'action', 'align',\n    'alt', 'axis', 'border', 'cellpadding', 'cellspacing', 'char', 'charoff',\n    'charset', 'checked', 'cite', 'class', 'clear', 'cols', 'colspan',\n    'color', 'compact', 'coords', 'datetime', 'dir', 'disabled', 'enctype',\n    'for', 'frame', 'headers', 'height', 'href', 'hreflang', 'hspace', 'id',\n    'ismap', 'label', 'lang', 'longdesc', 'maxlength', 'media', 'method',\n    'multiple', 'name', 'nohref', 'noshade', 'nowrap', 'prompt', 'readonly',\n    'rel', 'rev', 'rows', 'rowspan', 'rules', 'scope', 'selected', 'shape',\n    'size', 'span', 'src', 'start', 'summary', 'tabindex', 'target', 'title',\n    'type', 'usemap', 'valign', 'value', 'vspace', 'width'])\n\n# From http://htmlhelp.com/reference/html40/olist.html\ntop_level_tags = frozenset([\n    'html', 'head', 'body', 'frameset',\n    ])\n\nhead_tags = frozenset([\n    'base', 'isindex', 'link', 'meta', 'script', 'style', 'title',\n    ])\n\ngeneral_block_tags = frozenset([\n    'address',\n    'blockquote',\n    'center',\n    'del',\n    'div',\n    'h1',\n    'h2',\n    'h3',\n    'h4',\n    'h5',\n    'h6',\n    'hr',\n    'ins',\n    'isindex',\n    'noscript',\n    'p',\n    'pre',\n    ])\n\nlist_tags = frozenset([\n    'dir', 'dl', 'dt', 'dd', 'li', 'menu', 'ol', 'ul',\n    ])\n\ntable_tags = frozenset([\n    'table', 'caption', 'colgroup', 'col',\n    'thead', 'tfoot', 'tbody', 'tr', 'td', 'th',\n    ])\n\n# just this one from\n# http://www.georgehernandez.com/h/XComputers/HTML/2BlockLevel.htm\nblock_tags = general_block_tags | list_tags | table_tags | frozenset([\n    # Partial form tags\n    'fieldset', 'form', 'legend', 'optgroup', 'option',\n    ])\n\nform_tags = frozenset([\n    'form', 'button', 'fieldset', 'legend', 'input', 'label',\n    'select', 'optgroup', 'option', 'textarea',\n    ])\n\nspecial_inline_tags = frozenset([\n    'a', 'applet', 'basefont', 'bdo', 'br', 'embed', 'font', 'iframe',\n    'img', 'map', 'area', 'object', 'param', 'q', 'script',\n    'span', 'sub', 'sup',\n    ])\n\nphrase_tags = frozenset([\n    'abbr', 'acronym', 'cite', 'code', 'del', 'dfn', 'em',\n    'ins', 'kbd', 'samp', 'strong', 'var',\n    ])\n\nfont_style_tags = frozenset([\n    'b', 'big', 'i', 's', 'small', 'strike', 'tt', 'u',\n    ])\n\nframe_tags = frozenset([\n    'frameset', 'frame', 'noframes',\n    ])\n    \nhtml5_tags = frozenset([\n    'article', 'aside', 'audio', 'canvas', 'command', 'datalist',\n    'details', 'embed', 'figcaption', 'figure', 'footer', 'header',\n    'hgroup', 'keygen', 'mark', 'math', 'meter', 'nav', 'output',\n    'progress', 'rp', 'rt', 'ruby', 'section', 'source', 'summary',\n    'svg', 'time', 'track', 'video', 'wbr'\n    ])\n\n# These tags aren't standard\nnonstandard_tags = frozenset(['blink', 'marquee'])\n\n\ntags = (top_level_tags | head_tags | general_block_tags | list_tags\n        | table_tags | form_tags | special_inline_tags | phrase_tags\n        | font_style_tags | nonstandard_tags | html5_tags)\n", "src/lxml/html/soupparser.py": "\"\"\"External interface to the BeautifulSoup HTML parser.\n\"\"\"\n\n__all__ = [\"fromstring\", \"parse\", \"convert_tree\"]\n\nimport re\nfrom lxml import etree, html\n\ntry:\n    from bs4 import (\n        BeautifulSoup, Tag, Comment, ProcessingInstruction, NavigableString,\n        Declaration, Doctype)\n    _DECLARATION_OR_DOCTYPE = (Declaration, Doctype)\nexcept ImportError:\n    from BeautifulSoup import (\n        BeautifulSoup, Tag, Comment, ProcessingInstruction, NavigableString,\n        Declaration)\n    _DECLARATION_OR_DOCTYPE = Declaration\n\n\ndef fromstring(data, beautifulsoup=None, makeelement=None, **bsargs):\n    \"\"\"Parse a string of HTML data into an Element tree using the\n    BeautifulSoup parser.\n\n    Returns the root ``<html>`` Element of the tree.\n\n    You can pass a different BeautifulSoup parser through the\n    `beautifulsoup` keyword, and a diffent Element factory function\n    through the `makeelement` keyword.  By default, the standard\n    ``BeautifulSoup`` class and the default factory of `lxml.html` are\n    used.\n    \"\"\"\n    return _parse(data, beautifulsoup, makeelement, **bsargs)\n\n\ndef parse(file, beautifulsoup=None, makeelement=None, **bsargs):\n    \"\"\"Parse a file into an ElemenTree using the BeautifulSoup parser.\n\n    You can pass a different BeautifulSoup parser through the\n    `beautifulsoup` keyword, and a diffent Element factory function\n    through the `makeelement` keyword.  By default, the standard\n    ``BeautifulSoup`` class and the default factory of `lxml.html` are\n    used.\n    \"\"\"\n    if not hasattr(file, 'read'):\n        file = open(file)\n    root = _parse(file, beautifulsoup, makeelement, **bsargs)\n    return etree.ElementTree(root)\n\n\ndef convert_tree(beautiful_soup_tree, makeelement=None):\n    \"\"\"Convert a BeautifulSoup tree to a list of Element trees.\n\n    Returns a list instead of a single root Element to support\n    HTML-like soup with more than one root element.\n\n    You can pass a different Element factory through the `makeelement`\n    keyword.\n    \"\"\"\n    root = _convert_tree(beautiful_soup_tree, makeelement)\n    children = root.getchildren()\n    for child in children:\n        root.remove(child)\n    return children\n\n\n# helpers\n\ndef _parse(source, beautifulsoup, makeelement, **bsargs):\n    if beautifulsoup is None:\n        beautifulsoup = BeautifulSoup\n    if hasattr(beautifulsoup, \"HTML_ENTITIES\"):  # bs3\n        if 'convertEntities' not in bsargs:\n            bsargs['convertEntities'] = 'html'\n    if hasattr(beautifulsoup, \"DEFAULT_BUILDER_FEATURES\"):  # bs4\n        if 'features' not in bsargs:\n            bsargs['features'] = 'html.parser'  # use Python html parser\n    tree = beautifulsoup(source, **bsargs)\n    root = _convert_tree(tree, makeelement)\n    # from ET: wrap the document in a html root element, if necessary\n    if len(root) == 1 and root[0].tag == \"html\":\n        return root[0]\n    root.tag = \"html\"\n    return root\n\n\n_parse_doctype_declaration = re.compile(\n    r'(?:\\s|[<!])*DOCTYPE\\s*HTML'\n    r'(?:\\s+PUBLIC)?(?:\\s+(\\'[^\\']*\\'|\"[^\"]*\"))?'\n    r'(?:\\s+(\\'[^\\']*\\'|\"[^\"]*\"))?',\n    re.IGNORECASE).match\n\n\nclass _PseudoTag:\n    # Minimal imitation of BeautifulSoup.Tag\n    def __init__(self, contents):\n        self.name = 'html'\n        self.attrs = []\n        self.contents = contents\n\n    def __iter__(self):\n        return self.contents.__iter__()\n\n\ndef _convert_tree(beautiful_soup_tree, makeelement):\n    if makeelement is None:\n        makeelement = html.html_parser.makeelement\n\n    # Split the tree into three parts:\n    # i) everything before the root element: document type\n    # declaration, comments, processing instructions, whitespace\n    # ii) the root(s),\n    # iii) everything after the root: comments, processing\n    # instructions, whitespace\n    first_element_idx = last_element_idx = None\n    html_root = declaration = None\n    for i, e in enumerate(beautiful_soup_tree):\n        if isinstance(e, Tag):\n            if first_element_idx is None:\n                first_element_idx = i\n            last_element_idx = i\n            if html_root is None and e.name and e.name.lower() == 'html':\n                html_root = e\n        elif declaration is None and isinstance(e, _DECLARATION_OR_DOCTYPE):\n            declaration = e\n\n    # For a nice, well-formatted document, the variable roots below is\n    # a list consisting of a single <html> element. However, the document\n    # may be a soup like '<meta><head><title>Hello</head><body>Hi\n    # all<\\p>'. In this example roots is a list containing meta, head\n    # and body elements.\n    if first_element_idx is None:\n        pre_root = post_root = []\n        roots = beautiful_soup_tree.contents\n    else:\n        pre_root = beautiful_soup_tree.contents[:first_element_idx]\n        roots = beautiful_soup_tree.contents[first_element_idx:last_element_idx+1]\n        post_root = beautiful_soup_tree.contents[last_element_idx+1:]\n\n    # Reorganize so that there is one <html> root...\n    if html_root is not None:\n        # ... use existing one if possible, ...\n        i = roots.index(html_root)\n        html_root.contents = roots[:i] + html_root.contents + roots[i+1:]\n    else:\n        # ... otherwise create a new one.\n        html_root = _PseudoTag(roots)\n\n    convert_node = _init_node_converters(makeelement)\n\n    # Process pre_root\n    res_root = convert_node(html_root)\n    prev = res_root\n    for e in reversed(pre_root):\n        converted = convert_node(e)\n        if converted is not None:\n            prev.addprevious(converted)\n            prev = converted\n\n    # ditto for post_root\n    prev = res_root\n    for e in post_root:\n        converted = convert_node(e)\n        if converted is not None:\n            prev.addnext(converted)\n            prev = converted\n\n    if declaration is not None:\n        try:\n            # bs4 provides full Doctype string\n            doctype_string = declaration.output_ready()\n        except AttributeError:\n            doctype_string = declaration.string\n\n        match = _parse_doctype_declaration(doctype_string)\n        if not match:\n            # Something is wrong if we end up in here. Since soupparser should\n            # tolerate errors, do not raise Exception, just let it pass.\n            pass\n        else:\n            external_id, sys_uri = match.groups()\n            docinfo = res_root.getroottree().docinfo\n            # strip quotes and update DOCTYPE values (any of None, '', '...')\n            docinfo.public_id = external_id and external_id[1:-1]\n            docinfo.system_url = sys_uri and sys_uri[1:-1]\n\n    return res_root\n\n\ndef _init_node_converters(makeelement):\n    converters = {}\n    ordered_node_types = []\n\n    def converter(*types):\n        def add(handler):\n            for t in types:\n                converters[t] = handler\n                ordered_node_types.append(t)\n            return handler\n        return add\n\n    def find_best_converter(node):\n        for t in ordered_node_types:\n            if isinstance(node, t):\n                return converters[t]\n        return None\n\n    def convert_node(bs_node, parent=None):\n        # duplicated in convert_tag() below\n        try:\n            handler = converters[type(bs_node)]\n        except KeyError:\n            handler = converters[type(bs_node)] = find_best_converter(bs_node)\n        if handler is None:\n            return None\n        return handler(bs_node, parent)\n\n    def map_attrs(bs_attrs):\n        if isinstance(bs_attrs, dict):  # bs4\n            attribs = {}\n            for k, v in bs_attrs.items():\n                if isinstance(v, list):\n                    v = \" \".join(v)\n                attribs[k] = unescape(v)\n        else:\n            attribs = {k: unescape(v) for k, v in bs_attrs}\n        return attribs\n\n    def append_text(parent, text):\n        if len(parent) == 0:\n            parent.text = (parent.text or '') + text\n        else:\n            parent[-1].tail = (parent[-1].tail or '') + text\n\n    # converters are tried in order of their definition\n\n    @converter(Tag, _PseudoTag)\n    def convert_tag(bs_node, parent):\n        attrs = bs_node.attrs\n        if parent is not None:\n            attribs = map_attrs(attrs) if attrs else None\n            res = etree.SubElement(parent, bs_node.name, attrib=attribs)\n        else:\n            attribs = map_attrs(attrs) if attrs else {}\n            res = makeelement(bs_node.name, attrib=attribs)\n\n        for child in bs_node:\n            # avoid double recursion by inlining convert_node(), see above\n            try:\n                handler = converters[type(child)]\n            except KeyError:\n                pass\n            else:\n                if handler is not None:\n                    handler(child, res)\n                continue\n            convert_node(child, res)\n        return res\n\n    @converter(Comment)\n    def convert_comment(bs_node, parent):\n        res = html.HtmlComment(bs_node)\n        if parent is not None:\n            parent.append(res)\n        return res\n\n    @converter(ProcessingInstruction)\n    def convert_pi(bs_node, parent):\n        if bs_node.endswith('?'):\n            # The PI is of XML style (<?as df?>) but BeautifulSoup\n            # interpreted it as being SGML style (<?as df>). Fix.\n            bs_node = bs_node[:-1]\n        res = etree.ProcessingInstruction(*bs_node.split(' ', 1))\n        if parent is not None:\n            parent.append(res)\n        return res\n\n    @converter(NavigableString)\n    def convert_text(bs_node, parent):\n        if parent is not None:\n            append_text(parent, unescape(bs_node))\n        return None\n\n    return convert_node\n\n\n# copied from ET's ElementSoup\n\ntry:\n    from html.entities import name2codepoint  # Python 3\nexcept ImportError:\n    from htmlentitydefs import name2codepoint\n\n\nhandle_entities = re.compile(r\"&(\\w+);\").sub\n\n\ntry:\n    unichr\nexcept NameError:\n    # Python 3\n    unichr = chr\n\n\ndef unescape(string):\n    if not string:\n        return ''\n    # work around oddities in BeautifulSoup's entity handling\n    def unescape_entity(m):\n        try:\n            return unichr(name2codepoint[m.group(1)])\n        except KeyError:\n            return m.group(0)  # use as is\n    return handle_entities(unescape_entity, string)\n", "src/lxml/html/clean.py": "# cython: language_level=3str\n\n\"\"\"Backward-compatibility module for lxml_html_clean\"\"\"\n\ntry:\n    from lxml_html_clean import *\n\n    __all__ = [\n        \"clean_html\",\n        \"clean\",\n        \"Cleaner\",\n        \"autolink\",\n        \"autolink_html\",\n        \"word_break\",\n        \"word_break_html\",\n    ]\nexcept ImportError:\n    raise ImportError(\n        \"lxml.html.clean module is now a separate project lxml_html_clean.\\n\"\n        \"Install lxml[html_clean] or lxml_html_clean directly.\"\n    ) from None\n", "src/lxml/html/__init__.py": "# Copyright (c) 2004 Ian Bicking. All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are\n# met:\n#\n# 1. Redistributions of source code must retain the above copyright\n# notice, this list of conditions and the following disclaimer.\n#\n# 2. Redistributions in binary form must reproduce the above copyright\n# notice, this list of conditions and the following disclaimer in\n# the documentation and/or other materials provided with the\n# distribution.\n#\n# 3. Neither the name of Ian Bicking nor the names of its contributors may\n# be used to endorse or promote products derived from this software\n# without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL IAN BICKING OR\n# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n# LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\"\"\"The ``lxml.html`` tool set for HTML handling.\n\"\"\"\n\n\n__all__ = [\n    'document_fromstring', 'fragment_fromstring', 'fragments_fromstring', 'fromstring',\n    'tostring', 'Element', 'defs', 'open_in_browser', 'submit_form',\n    'find_rel_links', 'find_class', 'make_links_absolute',\n    'resolve_base_href', 'iterlinks', 'rewrite_links', 'parse']\n\n\nimport copy\nimport re\n\nfrom collections.abc import MutableMapping, MutableSet\nfrom functools import partial\nfrom urllib.parse import urljoin\n\nfrom .. import etree\nfrom . import defs\nfrom ._setmixin import SetMixin\n\n\ndef __fix_docstring(s):\n    # TODO: remove and clean up doctests\n    if not s:\n        return s\n    sub = re.compile(r\"^(\\s*)u'\", re.M).sub\n    return sub(r\"\\1'\", s)\n\n\nXHTML_NAMESPACE = \"http://www.w3.org/1999/xhtml\"\n\n_rel_links_xpath = etree.XPath(\"descendant-or-self::a[@rel]|descendant-or-self::x:a[@rel]\",\n                               namespaces={'x':XHTML_NAMESPACE})\n_options_xpath = etree.XPath(\"descendant-or-self::option|descendant-or-self::x:option\",\n                             namespaces={'x':XHTML_NAMESPACE})\n_forms_xpath = etree.XPath(\"descendant-or-self::form|descendant-or-self::x:form\",\n                           namespaces={'x':XHTML_NAMESPACE})\n#_class_xpath = etree.XPath(r\"descendant-or-self::*[regexp:match(@class, concat('\\b', $class_name, '\\b'))]\", {'regexp': 'http://exslt.org/regular-expressions'})\n_class_xpath = etree.XPath(\"descendant-or-self::*[@class and contains(concat(' ', normalize-space(@class), ' '), concat(' ', $class_name, ' '))]\")\n_id_xpath = etree.XPath(\"descendant-or-self::*[@id=$id]\")\n_collect_string_content = etree.XPath(\"string()\")\n_iter_css_urls = re.compile(r'url\\(('+'[\"][^\"]*[\"]|'+\"['][^']*[']|\"+r'[^)]*)\\)', re.I).finditer\n_iter_css_imports = re.compile(r'@import \"(.*?)\"').finditer\n_label_xpath = etree.XPath(\"//label[@for=$id]|//x:label[@for=$id]\",\n                           namespaces={'x':XHTML_NAMESPACE})\n_archive_re = re.compile(r'[^ ]+')\n_parse_meta_refresh_url = re.compile(\n    r'[^;=]*;\\s*(?:url\\s*=\\s*)?(?P<url>.*)$', re.I).search\n\n\ndef _unquote_match(s, pos):\n    if s[:1] == '\"' and s[-1:] == '\"' or s[:1] == \"'\" and s[-1:] == \"'\":\n        return s[1:-1], pos+1\n    else:\n        return s,pos\n\n\ndef _transform_result(typ, result):\n    \"\"\"Convert the result back into the input type.\n    \"\"\"\n    if issubclass(typ, bytes):\n        return tostring(result, encoding='utf-8')\n    elif issubclass(typ, str):\n        return tostring(result, encoding='unicode')\n    else:\n        return result\n\n\ndef _nons(tag):\n    if isinstance(tag, str):\n        if tag[0] == '{' and tag[1:len(XHTML_NAMESPACE)+1] == XHTML_NAMESPACE:\n            return tag.split('}')[-1]\n    return tag\n\n\nclass Classes(MutableSet):\n    \"\"\"Provides access to an element's class attribute as a set-like collection.\n    Usage::\n\n        >>> el = fromstring('<p class=\"hidden large\">Text</p>')\n        >>> classes = el.classes  # or: classes = Classes(el.attrib)\n        >>> classes |= ['block', 'paragraph']\n        >>> el.get('class')\n        'hidden large block paragraph'\n        >>> classes.toggle('hidden')\n        False\n        >>> el.get('class')\n        'large block paragraph'\n        >>> classes -= ('some', 'classes', 'block')\n        >>> el.get('class')\n        'large paragraph'\n    \"\"\"\n    def __init__(self, attributes):\n        self._attributes = attributes\n        self._get_class_value = partial(attributes.get, 'class', '')\n\n    def add(self, value):\n        \"\"\"\n        Add a class.\n\n        This has no effect if the class is already present.\n        \"\"\"\n        if not value or re.search(r'\\s', value):\n            raise ValueError(\"Invalid class name: %r\" % value)\n        classes = self._get_class_value().split()\n        if value in classes:\n            return\n        classes.append(value)\n        self._attributes['class'] = ' '.join(classes)\n\n    def discard(self, value):\n        \"\"\"\n        Remove a class if it is currently present.\n\n        If the class is not present, do nothing.\n        \"\"\"\n        if not value or re.search(r'\\s', value):\n            raise ValueError(\"Invalid class name: %r\" % value)\n        classes = [name for name in self._get_class_value().split()\n                   if name != value]\n        if classes:\n            self._attributes['class'] = ' '.join(classes)\n        elif 'class' in self._attributes:\n            del self._attributes['class']\n\n    def remove(self, value):\n        \"\"\"\n        Remove a class; it must currently be present.\n\n        If the class is not present, raise a KeyError.\n        \"\"\"\n        if not value or re.search(r'\\s', value):\n            raise ValueError(\"Invalid class name: %r\" % value)\n        super().remove(value)\n\n    def __contains__(self, name):\n        classes = self._get_class_value()\n        return name in classes and name in classes.split()\n\n    def __iter__(self):\n        return iter(self._get_class_value().split())\n\n    def __len__(self):\n        return len(self._get_class_value().split())\n\n    # non-standard methods\n\n    def update(self, values):\n        \"\"\"\n        Add all names from 'values'.\n        \"\"\"\n        classes = self._get_class_value().split()\n        extended = False\n        for value in values:\n            if value not in classes:\n                classes.append(value)\n                extended = True\n        if extended:\n            self._attributes['class'] = ' '.join(classes)\n\n    def toggle(self, value):\n        \"\"\"\n        Add a class name if it isn't there yet, or remove it if it exists.\n\n        Returns true if the class was added (and is now enabled) and\n        false if it was removed (and is now disabled).\n        \"\"\"\n        if not value or re.search(r'\\s', value):\n            raise ValueError(\"Invalid class name: %r\" % value)\n        classes = self._get_class_value().split()\n        try:\n            classes.remove(value)\n            enabled = False\n        except ValueError:\n            classes.append(value)\n            enabled = True\n        if classes:\n            self._attributes['class'] = ' '.join(classes)\n        else:\n            del self._attributes['class']\n        return enabled\n\n\nclass HtmlMixin:\n\n    def set(self, key, value=None):\n        \"\"\"set(self, key, value=None)\n\n        Sets an element attribute.  If no value is provided, or if the value is None,\n        creates a 'boolean' attribute without value, e.g. \"<form novalidate></form>\"\n        for ``form.set('novalidate')``.\n        \"\"\"\n        super().set(key, value)\n\n    @property\n    def classes(self):\n        \"\"\"\n        A set-like wrapper around the 'class' attribute.\n        \"\"\"\n        return Classes(self.attrib)\n\n    @classes.setter\n    def classes(self, classes):\n        assert isinstance(classes, Classes)  # only allow \"el.classes |= ...\" etc.\n        value = classes._get_class_value()\n        if value:\n            self.set('class', value)\n        elif self.get('class') is not None:\n            del self.attrib['class']\n\n    @property\n    def base_url(self):\n        \"\"\"\n        Returns the base URL, given when the page was parsed.\n\n        Use with ``urlparse.urljoin(el.base_url, href)`` to get\n        absolute URLs.\n        \"\"\"\n        return self.getroottree().docinfo.URL\n\n    @property\n    def forms(self):\n        \"\"\"\n        Return a list of all the forms\n        \"\"\"\n        return _forms_xpath(self)\n\n    @property\n    def body(self):\n        \"\"\"\n        Return the <body> element.  Can be called from a child element\n        to get the document's head.\n        \"\"\"\n        return self.xpath('//body|//x:body', namespaces={'x':XHTML_NAMESPACE})[0]\n\n    @property\n    def head(self):\n        \"\"\"\n        Returns the <head> element.  Can be called from a child\n        element to get the document's head.\n        \"\"\"\n        return self.xpath('//head|//x:head', namespaces={'x':XHTML_NAMESPACE})[0]\n\n    @property\n    def label(self):\n        \"\"\"\n        Get or set any <label> element associated with this element.\n        \"\"\"\n        id = self.get('id')\n        if not id:\n            return None\n        result = _label_xpath(self, id=id)\n        if not result:\n            return None\n        else:\n            return result[0]\n\n    @label.setter\n    def label(self, label):\n        id = self.get('id')\n        if not id:\n            raise TypeError(\n                \"You cannot set a label for an element (%r) that has no id\"\n                % self)\n        if _nons(label.tag) != 'label':\n            raise TypeError(\n                \"You can only assign label to a label element (not %r)\"\n                % label)\n        label.set('for', id)\n\n    @label.deleter\n    def label(self):\n        label = self.label\n        if label is not None:\n            del label.attrib['for']\n\n    def drop_tree(self):\n        \"\"\"\n        Removes this element from the tree, including its children and\n        text.  The tail text is joined to the previous element or\n        parent.\n        \"\"\"\n        parent = self.getparent()\n        assert parent is not None\n        if self.tail:\n            previous = self.getprevious()\n            if previous is None:\n                parent.text = (parent.text or '') + self.tail\n            else:\n                previous.tail = (previous.tail or '') + self.tail\n        parent.remove(self)\n\n    def drop_tag(self):\n        \"\"\"\n        Remove the tag, but not its children or text.  The children and text\n        are merged into the parent.\n\n        Example::\n\n            >>> h = fragment_fromstring('<div>Hello <b>World!</b></div>')\n            >>> h.find('.//b').drop_tag()\n            >>> print(tostring(h, encoding='unicode'))\n            <div>Hello World!</div>\n        \"\"\"\n        parent = self.getparent()\n        assert parent is not None\n        previous = self.getprevious()\n        if self.text and isinstance(self.tag, str):\n            # not a Comment, etc.\n            if previous is None:\n                parent.text = (parent.text or '') + self.text\n            else:\n                previous.tail = (previous.tail or '') + self.text\n        if self.tail:\n            if len(self):\n                last = self[-1]\n                last.tail = (last.tail or '') + self.tail\n            elif previous is None:\n                parent.text = (parent.text or '') + self.tail\n            else:\n                previous.tail = (previous.tail or '') + self.tail\n        index = parent.index(self)\n        parent[index:index+1] = self[:]\n\n    def find_rel_links(self, rel):\n        \"\"\"\n        Find any links like ``<a rel=\"{rel}\">...</a>``; returns a list of elements.\n        \"\"\"\n        rel = rel.lower()\n        return [el for el in _rel_links_xpath(self)\n                if el.get('rel').lower() == rel]\n\n    def find_class(self, class_name):\n        \"\"\"\n        Find any elements with the given class name.\n        \"\"\"\n        return _class_xpath(self, class_name=class_name)\n\n    def get_element_by_id(self, id, *default):\n        \"\"\"\n        Get the first element in a document with the given id.  If none is\n        found, return the default argument if provided or raise KeyError\n        otherwise.\n\n        Note that there can be more than one element with the same id,\n        and this isn't uncommon in HTML documents found in the wild.\n        Browsers return only the first match, and this function does\n        the same.\n        \"\"\"\n        try:\n            # FIXME: should this check for multiple matches?\n            # browsers just return the first one\n            return _id_xpath(self, id=id)[0]\n        except IndexError:\n            if default:\n                return default[0]\n            else:\n                raise KeyError(id)\n\n    def text_content(self):\n        \"\"\"\n        Return the text content of the tag (and the text in any children).\n        \"\"\"\n        return _collect_string_content(self)\n\n    def cssselect(self, expr, translator='html'):\n        \"\"\"\n        Run the CSS expression on this element and its children,\n        returning a list of the results.\n\n        Equivalent to lxml.cssselect.CSSSelect(expr, translator='html')(self)\n        -- note that pre-compiling the expression can provide a substantial\n        speedup.\n        \"\"\"\n        # Do the import here to make the dependency optional.\n        from lxml.cssselect import CSSSelector\n        return CSSSelector(expr, translator=translator)(self)\n\n    ########################################\n    ## Link functions\n    ########################################\n\n    def make_links_absolute(self, base_url=None, resolve_base_href=True,\n                            handle_failures=None):\n        \"\"\"\n        Make all links in the document absolute, given the\n        ``base_url`` for the document (the full URL where the document\n        came from), or if no ``base_url`` is given, then the ``.base_url``\n        of the document.\n\n        If ``resolve_base_href`` is true, then any ``<base href>``\n        tags in the document are used *and* removed from the document.\n        If it is false then any such tag is ignored.\n\n        If ``handle_failures`` is None (default), a failure to process\n        a URL will abort the processing.  If set to 'ignore', errors\n        are ignored.  If set to 'discard', failing URLs will be removed.\n        \"\"\"\n        if base_url is None:\n            base_url = self.base_url\n            if base_url is None:\n                raise TypeError(\n                    \"No base_url given, and the document has no base_url\")\n        if resolve_base_href:\n            self.resolve_base_href()\n\n        if handle_failures == 'ignore':\n            def link_repl(href):\n                try:\n                    return urljoin(base_url, href)\n                except ValueError:\n                    return href\n        elif handle_failures == 'discard':\n            def link_repl(href):\n                try:\n                    return urljoin(base_url, href)\n                except ValueError:\n                    return None\n        elif handle_failures is None:\n            def link_repl(href):\n                return urljoin(base_url, href)\n        else:\n            raise ValueError(\n                \"unexpected value for handle_failures: %r\" % handle_failures)\n\n        self.rewrite_links(link_repl)\n\n    def resolve_base_href(self, handle_failures=None):\n        \"\"\"\n        Find any ``<base href>`` tag in the document, and apply its\n        values to all links found in the document.  Also remove the\n        tag once it has been applied.\n\n        If ``handle_failures`` is None (default), a failure to process\n        a URL will abort the processing.  If set to 'ignore', errors\n        are ignored.  If set to 'discard', failing URLs will be removed.\n        \"\"\"\n        base_href = None\n        basetags = self.xpath('//base[@href]|//x:base[@href]',\n                              namespaces={'x': XHTML_NAMESPACE})\n        for b in basetags:\n            base_href = b.get('href')\n            b.drop_tree()\n        if not base_href:\n            return\n        self.make_links_absolute(base_href, resolve_base_href=False,\n                                 handle_failures=handle_failures)\n\n    def iterlinks(self):\n        \"\"\"\n        Yield (element, attribute, link, pos), where attribute may be None\n        (indicating the link is in the text).  ``pos`` is the position\n        where the link occurs; often 0, but sometimes something else in\n        the case of links in stylesheets or style tags.\n\n        Note: <base href> is *not* taken into account in any way.  The\n        link you get is exactly the link in the document.\n\n        Note: multiple links inside of a single text string or\n        attribute value are returned in reversed order.  This makes it\n        possible to replace or delete them from the text string value\n        based on their reported text positions.  Otherwise, a\n        modification at one text position can change the positions of\n        links reported later on.\n        \"\"\"\n        link_attrs = defs.link_attrs\n        for el in self.iter(etree.Element):\n            attribs = el.attrib\n            tag = _nons(el.tag)\n            if tag == 'object':\n                codebase = None\n                ## <object> tags have attributes that are relative to\n                ## codebase\n                if 'codebase' in attribs:\n                    codebase = el.get('codebase')\n                    yield (el, 'codebase', codebase, 0)\n                for attrib in ('classid', 'data'):\n                    if attrib in attribs:\n                        value = el.get(attrib)\n                        if codebase is not None:\n                            value = urljoin(codebase, value)\n                        yield (el, attrib, value, 0)\n                if 'archive' in attribs:\n                    for match in _archive_re.finditer(el.get('archive')):\n                        value = match.group(0)\n                        if codebase is not None:\n                            value = urljoin(codebase, value)\n                        yield (el, 'archive', value, match.start())\n            else:\n                for attrib in link_attrs:\n                    if attrib in attribs:\n                        yield (el, attrib, attribs[attrib], 0)\n            if tag == 'meta':\n                http_equiv = attribs.get('http-equiv', '').lower()\n                if http_equiv == 'refresh':\n                    content = attribs.get('content', '')\n                    match = _parse_meta_refresh_url(content)\n                    url = (match.group('url') if match else content).strip()\n                    # unexpected content means the redirect won't work, but we might\n                    # as well be permissive and return the entire string.\n                    if url:\n                        url, pos = _unquote_match(\n                            url, match.start('url') if match else content.find(url))\n                        yield (el, 'content', url, pos)\n            elif tag == 'param':\n                valuetype = el.get('valuetype') or ''\n                if valuetype.lower() == 'ref':\n                    ## FIXME: while it's fine we *find* this link,\n                    ## according to the spec we aren't supposed to\n                    ## actually change the value, including resolving\n                    ## it.  It can also still be a link, even if it\n                    ## doesn't have a valuetype=\"ref\" (which seems to be the norm)\n                    ## http://www.w3.org/TR/html401/struct/objects.html#adef-valuetype\n                    yield (el, 'value', el.get('value'), 0)\n            elif tag == 'style' and el.text:\n                urls = [\n                    # (start_pos, url)\n                    _unquote_match(match.group(1), match.start(1))[::-1]\n                    for match in _iter_css_urls(el.text)\n                    ] + [\n                    (match.start(1), match.group(1))\n                    for match in _iter_css_imports(el.text)\n                    ]\n                if urls:\n                    # sort by start pos to bring both match sets back into order\n                    # and reverse the list to report correct positions despite\n                    # modifications\n                    urls.sort(reverse=True)\n                    for start, url in urls:\n                        yield (el, None, url, start)\n            if 'style' in attribs:\n                urls = list(_iter_css_urls(attribs['style']))\n                if urls:\n                    # return in reversed order to simplify in-place modifications\n                    for match in urls[::-1]:\n                        url, start = _unquote_match(match.group(1), match.start(1))\n                        yield (el, 'style', url, start)\n\n    def rewrite_links(self, link_repl_func, resolve_base_href=True,\n                      base_href=None):\n        \"\"\"\n        Rewrite all the links in the document.  For each link\n        ``link_repl_func(link)`` will be called, and the return value\n        will replace the old link.\n\n        Note that links may not be absolute (unless you first called\n        ``make_links_absolute()``), and may be internal (e.g.,\n        ``'#anchor'``).  They can also be values like\n        ``'mailto:email'`` or ``'javascript:expr'``.\n\n        If you give ``base_href`` then all links passed to\n        ``link_repl_func()`` will take that into account.\n\n        If the ``link_repl_func`` returns None, the attribute or\n        tag text will be removed completely.\n        \"\"\"\n        if base_href is not None:\n            # FIXME: this can be done in one pass with a wrapper\n            # around link_repl_func\n            self.make_links_absolute(\n                base_href, resolve_base_href=resolve_base_href)\n        elif resolve_base_href:\n            self.resolve_base_href()\n\n        for el, attrib, link, pos in self.iterlinks():\n            new_link = link_repl_func(link.strip())\n            if new_link == link:\n                continue\n            if new_link is None:\n                # Remove the attribute or element content\n                if attrib is None:\n                    el.text = ''\n                else:\n                    del el.attrib[attrib]\n                continue\n\n            if attrib is None:\n                new = el.text[:pos] + new_link + el.text[pos+len(link):]\n                el.text = new\n            else:\n                cur = el.get(attrib)\n                if not pos and len(cur) == len(link):\n                    new = new_link  # most common case\n                else:\n                    new = cur[:pos] + new_link + cur[pos+len(link):]\n                el.set(attrib, new)\n\n\nclass _MethodFunc:\n    \"\"\"\n    An object that represents a method on an element as a function;\n    the function takes either an element or an HTML string.  It\n    returns whatever the function normally returns, or if the function\n    works in-place (and so returns None) it returns a serialized form\n    of the resulting document.\n    \"\"\"\n    def __init__(self, name, copy=False, source_class=HtmlMixin):\n        self.name = name\n        self.copy = copy\n        self.__doc__ = getattr(source_class, self.name).__doc__\n    def __call__(self, doc, *args, **kw):\n        result_type = type(doc)\n        if isinstance(doc, (str, bytes)):\n            if 'copy' in kw:\n                raise TypeError(\n                    \"The keyword 'copy' can only be used with element inputs to %s, not a string input\" % self.name)\n            doc = fromstring(doc, **kw)\n        else:\n            if 'copy' in kw:\n                make_a_copy = kw.pop('copy')\n            else:\n                make_a_copy = self.copy\n            if make_a_copy:\n                doc = copy.deepcopy(doc)\n        meth = getattr(doc, self.name)\n        result = meth(*args, **kw)\n        # FIXME: this None test is a bit sloppy\n        if result is None:\n            # Then return what we got in\n            return _transform_result(result_type, doc)\n        else:\n            return result\n\n\nfind_rel_links = _MethodFunc('find_rel_links', copy=False)\nfind_class = _MethodFunc('find_class', copy=False)\nmake_links_absolute = _MethodFunc('make_links_absolute', copy=True)\nresolve_base_href = _MethodFunc('resolve_base_href', copy=True)\niterlinks = _MethodFunc('iterlinks', copy=False)\nrewrite_links = _MethodFunc('rewrite_links', copy=True)\n\n\nclass HtmlComment(HtmlMixin, etree.CommentBase):\n    pass\n\n\nclass HtmlElement(HtmlMixin, etree.ElementBase):\n    pass\n\n\nclass HtmlProcessingInstruction(HtmlMixin, etree.PIBase):\n    pass\n\n\nclass HtmlEntity(HtmlMixin, etree.EntityBase):\n    pass\n\n\nclass HtmlElementClassLookup(etree.CustomElementClassLookup):\n    \"\"\"A lookup scheme for HTML Element classes.\n\n    To create a lookup instance with different Element classes, pass a tag\n    name mapping of Element classes in the ``classes`` keyword argument and/or\n    a tag name mapping of Mixin classes in the ``mixins`` keyword argument.\n    The special key '*' denotes a Mixin class that should be mixed into all\n    Element classes.\n    \"\"\"\n    _default_element_classes = {}\n\n    def __init__(self, classes=None, mixins=None):\n        etree.CustomElementClassLookup.__init__(self)\n        if classes is None:\n            classes = self._default_element_classes.copy()\n        if mixins:\n            mixers = {}\n            for name, value in mixins:\n                if name == '*':\n                    for n in classes.keys():\n                        mixers.setdefault(n, []).append(value)\n                else:\n                    mixers.setdefault(name, []).append(value)\n            for name, mix_bases in mixers.items():\n                cur = classes.get(name, HtmlElement)\n                bases = tuple(mix_bases + [cur])\n                classes[name] = type(cur.__name__, bases, {})\n        self._element_classes = classes\n\n    def lookup(self, node_type, document, namespace, name):\n        if node_type == 'element':\n            return self._element_classes.get(name.lower(), HtmlElement)\n        elif node_type == 'comment':\n            return HtmlComment\n        elif node_type == 'PI':\n            return HtmlProcessingInstruction\n        elif node_type == 'entity':\n            return HtmlEntity\n        # Otherwise normal lookup\n        return None\n\n\n################################################################################\n# parsing\n################################################################################\n\n_looks_like_full_html_unicode = re.compile(\n    r'^\\s*<(?:html|!doctype)', re.I).match\n_looks_like_full_html_bytes = re.compile(\n    br'^\\s*<(?:html|!doctype)', re.I).match\n\n\ndef document_fromstring(html, parser=None, ensure_head_body=False, **kw):\n    if parser is None:\n        parser = html_parser\n    value = etree.fromstring(html, parser, **kw)\n    if value is None:\n        raise etree.ParserError(\n            \"Document is empty\")\n    if ensure_head_body and value.find('head') is None:\n        value.insert(0, Element('head'))\n    if ensure_head_body and value.find('body') is None:\n        value.append(Element('body'))\n    return value\n\n\ndef fragments_fromstring(html, no_leading_text=False, base_url=None,\n                         parser=None, **kw):\n    \"\"\"Parses several HTML elements, returning a list of elements.\n\n    The first item in the list may be a string.\n    If no_leading_text is true, then it will be an error if there is\n    leading text, and it will always be a list of only elements.\n\n    base_url will set the document's base_url attribute\n    (and the tree's docinfo.URL).\n    \"\"\"\n    if parser is None:\n        parser = html_parser\n    # FIXME: check what happens when you give html with a body, head, etc.\n    if isinstance(html, bytes):\n        if not _looks_like_full_html_bytes(html):\n            # can't use %-formatting in early Py3 versions\n            html = (b'<html><body>' + html +\n                    b'</body></html>')\n    else:\n        if not _looks_like_full_html_unicode(html):\n            html = '<html><body>%s</body></html>' % html\n    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n    assert _nons(doc.tag) == 'html'\n    bodies = [e for e in doc if _nons(e.tag) == 'body']\n    assert len(bodies) == 1, (\"too many bodies: %r in %r\" % (bodies, html))\n    body = bodies[0]\n    elements = []\n    if no_leading_text and body.text and body.text.strip():\n        raise etree.ParserError(\n            \"There is leading text: %r\" % body.text)\n    if body.text and body.text.strip():\n        elements.append(body.text)\n    elements.extend(body)\n    # FIXME: removing the reference to the parent artificial document\n    # would be nice\n    return elements\n\n\ndef fragment_fromstring(html, create_parent=False, base_url=None,\n                        parser=None, **kw):\n    \"\"\"\n    Parses a single HTML element; it is an error if there is more than\n    one element, or if anything but whitespace precedes or follows the\n    element.\n\n    If ``create_parent`` is true (or is a tag name) then a parent node\n    will be created to encapsulate the HTML in a single element.  In this\n    case, leading or trailing text is also allowed, as are multiple elements\n    as result of the parsing.\n\n    Passing a ``base_url`` will set the document's ``base_url`` attribute\n    (and the tree's docinfo.URL).\n    \"\"\"\n    if parser is None:\n        parser = html_parser\n\n    accept_leading_text = bool(create_parent)\n\n    elements = fragments_fromstring(\n        html, parser=parser, no_leading_text=not accept_leading_text,\n        base_url=base_url, **kw)\n\n    if create_parent:\n        if not isinstance(create_parent, str):\n            create_parent = 'div'\n        new_root = Element(create_parent)\n        if elements:\n            if isinstance(elements[0], str):\n                new_root.text = elements[0]\n                del elements[0]\n            new_root.extend(elements)\n        return new_root\n\n    if not elements:\n        raise etree.ParserError('No elements found')\n    if len(elements) > 1:\n        raise etree.ParserError(\n            \"Multiple elements found (%s)\"\n            % ', '.join([_element_name(e) for e in elements]))\n    el = elements[0]\n    if el.tail and el.tail.strip():\n        raise etree.ParserError(\n            \"Element followed by text: %r\" % el.tail)\n    el.tail = None\n    return el\n\n\ndef fromstring(html, base_url=None, parser=None, **kw):\n    \"\"\"\n    Parse the html, returning a single element/document.\n\n    This tries to minimally parse the chunk of text, without knowing if it\n    is a fragment or a document.\n\n    base_url will set the document's base_url attribute (and the tree's docinfo.URL)\n    \"\"\"\n    if parser is None:\n        parser = html_parser\n    if isinstance(html, bytes):\n        is_full_html = _looks_like_full_html_bytes(html)\n    else:\n        is_full_html = _looks_like_full_html_unicode(html)\n    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n    if is_full_html:\n        return doc\n    # otherwise, lets parse it out...\n    bodies = doc.findall('body')\n    if not bodies:\n        bodies = doc.findall('{%s}body' % XHTML_NAMESPACE)\n    if bodies:\n        body = bodies[0]\n        if len(bodies) > 1:\n            # Somehow there are multiple bodies, which is bad, but just\n            # smash them into one body\n            for other_body in bodies[1:]:\n                if other_body.text:\n                    if len(body):\n                        body[-1].tail = (body[-1].tail or '') + other_body.text\n                    else:\n                        body.text = (body.text or '') + other_body.text\n                body.extend(other_body)\n                # We'll ignore tail\n                # I guess we are ignoring attributes too\n                other_body.drop_tree()\n    else:\n        body = None\n    heads = doc.findall('head')\n    if not heads:\n        heads = doc.findall('{%s}head' % XHTML_NAMESPACE)\n    if heads:\n        # Well, we have some sort of structure, so lets keep it all\n        head = heads[0]\n        if len(heads) > 1:\n            for other_head in heads[1:]:\n                head.extend(other_head)\n                # We don't care about text or tail in a head\n                other_head.drop_tree()\n        return doc\n    if body is None:\n        return doc\n    if (len(body) == 1 and (not body.text or not body.text.strip())\n        and (not body[-1].tail or not body[-1].tail.strip())):\n        # The body has just one element, so it was probably a single\n        # element passed in\n        return body[0]\n    # Now we have a body which represents a bunch of tags which have the\n    # content that was passed in.  We will create a fake container, which\n    # is the body tag, except <body> implies too much structure.\n    if _contains_block_level_tag(body):\n        body.tag = 'div'\n    else:\n        body.tag = 'span'\n    return body\n\n\ndef parse(filename_or_url, parser=None, base_url=None, **kw):\n    \"\"\"\n    Parse a filename, URL, or file-like object into an HTML document\n    tree.  Note: this returns a tree, not an element.  Use\n    ``parse(...).getroot()`` to get the document root.\n\n    You can override the base URL with the ``base_url`` keyword.  This\n    is most useful when parsing from a file-like object.\n    \"\"\"\n    if parser is None:\n        parser = html_parser\n    return etree.parse(filename_or_url, parser, base_url=base_url, **kw)\n\n\ndef _contains_block_level_tag(el):\n    # FIXME: I could do this with XPath, but would that just be\n    # unnecessarily slow?\n    for el in el.iter(etree.Element):\n        if _nons(el.tag) in defs.block_tags:\n            return True\n    return False\n\n\ndef _element_name(el):\n    if isinstance(el, etree.CommentBase):\n        return 'comment'\n    elif isinstance(el, str):\n        return 'string'\n    else:\n        return _nons(el.tag)\n\n\n################################################################################\n# form handling\n################################################################################\n\nclass FormElement(HtmlElement):\n    \"\"\"\n    Represents a <form> element.\n    \"\"\"\n\n    @property\n    def inputs(self):\n        \"\"\"\n        Returns an accessor for all the input elements in the form.\n\n        See `InputGetter` for more information about the object.\n        \"\"\"\n        return InputGetter(self)\n\n    @property\n    def fields(self):\n        \"\"\"\n        Dictionary-like object that represents all the fields in this\n        form.  You can set values in this dictionary to effect the\n        form.\n        \"\"\"\n        return FieldsDict(self.inputs)\n\n    @fields.setter\n    def fields(self, value):\n        fields = self.fields\n        prev_keys = fields.keys()\n        for key, value in value.items():\n            if key in prev_keys:\n                prev_keys.remove(key)\n            fields[key] = value\n        for key in prev_keys:\n            if key is None:\n                # Case of an unnamed input; these aren't really\n                # expressed in form_values() anyway.\n                continue\n            fields[key] = None\n\n    def _name(self):\n        if self.get('name'):\n            return self.get('name')\n        elif self.get('id'):\n            return '#' + self.get('id')\n        iter_tags = self.body.iter\n        forms = list(iter_tags('form'))\n        if not forms:\n            forms = list(iter_tags('{%s}form' % XHTML_NAMESPACE))\n        return str(forms.index(self))\n\n    def form_values(self):\n        \"\"\"\n        Return a list of tuples of the field values for the form.\n        This is suitable to be passed to ``urllib.urlencode()``.\n        \"\"\"\n        results = []\n        for el in self.inputs:\n            name = el.name\n            if not name or 'disabled' in el.attrib:\n                continue\n            tag = _nons(el.tag)\n            if tag == 'textarea':\n                results.append((name, el.value))\n            elif tag == 'select':\n                value = el.value\n                if el.multiple:\n                    for v in value:\n                        results.append((name, v))\n                elif value is not None:\n                    results.append((name, el.value))\n            else:\n                assert tag == 'input', (\n                    \"Unexpected tag: %r\" % el)\n                if el.checkable and not el.checked:\n                    continue\n                if el.type in ('submit', 'image', 'reset', 'file'):\n                    continue\n                value = el.value\n                if value is not None:\n                    results.append((name, el.value))\n        return results\n\n    @property\n    def action(self):\n        \"\"\"\n        Get/set the form's ``action`` attribute.\n        \"\"\"\n        base_url = self.base_url\n        action = self.get('action')\n        if base_url and action is not None:\n            return urljoin(base_url, action)\n        else:\n            return action\n\n    @action.setter\n    def action(self, value):\n        self.set('action', value)\n\n    @action.deleter\n    def action(self):\n        attrib = self.attrib\n        if 'action' in attrib:\n            del attrib['action']\n\n    @property\n    def method(self):\n        \"\"\"\n        Get/set the form's method.  Always returns a capitalized\n        string, and defaults to ``'GET'``\n        \"\"\"\n        return self.get('method', 'GET').upper()\n\n    @method.setter\n    def method(self, value):\n        self.set('method', value.upper())\n\n\nHtmlElementClassLookup._default_element_classes['form'] = FormElement\n\n\ndef submit_form(form, extra_values=None, open_http=None):\n    \"\"\"\n    Helper function to submit a form.  Returns a file-like object, as from\n    ``urllib.urlopen()``.  This object also has a ``.geturl()`` function,\n    which shows the URL if there were any redirects.\n\n    You can use this like::\n\n        form = doc.forms[0]\n        form.inputs['foo'].value = 'bar' # etc\n        response = form.submit()\n        doc = parse(response)\n        doc.make_links_absolute(response.geturl())\n\n    To change the HTTP requester, pass a function as ``open_http`` keyword\n    argument that opens the URL for you.  The function must have the following\n    signature::\n\n        open_http(method, URL, values)\n\n    The action is one of 'GET' or 'POST', the URL is the target URL as a\n    string, and the values are a sequence of ``(name, value)`` tuples with the\n    form data.\n    \"\"\"\n    values = form.form_values()\n    if extra_values:\n        if hasattr(extra_values, 'items'):\n            extra_values = extra_values.items()\n        values.extend(extra_values)\n    if open_http is None:\n        open_http = open_http_urllib\n    if form.action:\n        url = form.action\n    else:\n        url = form.base_url\n    return open_http(form.method, url, values)\n\n\ndef open_http_urllib(method, url, values):\n    if not url:\n        raise ValueError(\"cannot submit, no URL provided\")\n    ## FIXME: should test that it's not a relative URL or something\n    try:\n        from urllib import urlencode, urlopen\n    except ImportError: # Python 3\n        from urllib.request import urlopen\n        from urllib.parse import urlencode\n    if method == 'GET':\n        if '?' in url:\n            url += '&'\n        else:\n            url += '?'\n        url += urlencode(values)\n        data = None\n    else:\n        data = urlencode(values)\n        if not isinstance(data, bytes):\n            data = data.encode('ASCII')\n    return urlopen(url, data)\n\n\nclass FieldsDict(MutableMapping):\n\n    def __init__(self, inputs):\n        self.inputs = inputs\n    def __getitem__(self, item):\n        return self.inputs[item].value\n    def __setitem__(self, item, value):\n        self.inputs[item].value = value\n    def __delitem__(self, item):\n        raise KeyError(\n            \"You cannot remove keys from ElementDict\")\n    def keys(self):\n        return self.inputs.keys()\n    def __contains__(self, item):\n        return item in self.inputs\n    def __iter__(self):\n        return iter(self.inputs.keys())\n    def __len__(self):\n        return len(self.inputs)\n\n    def __repr__(self):\n        return '<%s for form %s>' % (\n            self.__class__.__name__,\n            self.inputs.form._name())\n\n\nclass InputGetter:\n\n    \"\"\"\n    An accessor that represents all the input fields in a form.\n\n    You can get fields by name from this, with\n    ``form.inputs['field_name']``.  If there are a set of checkboxes\n    with the same name, they are returned as a list (a `CheckboxGroup`\n    which also allows value setting).  Radio inputs are handled\n    similarly.  Use ``.keys()`` and ``.items()`` to process all fields\n    in this way.\n\n    You can also iterate over this to get all input elements.  This\n    won't return the same thing as if you get all the names, as\n    checkboxes and radio elements are returned individually.\n    \"\"\"\n\n    def __init__(self, form):\n        self.form = form\n\n    def __repr__(self):\n        return '<%s for form %s>' % (\n            self.__class__.__name__,\n            self.form._name())\n\n    ## FIXME: there should be more methods, and it's unclear if this is\n    ## a dictionary-like object or list-like object\n\n    def __getitem__(self, name):\n        fields = [field for field in self if field.name == name]\n        if not fields:\n            raise KeyError(\"No input element with the name %r\" % name)\n\n        input_type = fields[0].get('type')\n        if input_type == 'radio' and len(fields) > 1:\n            group = RadioGroup(fields)\n            group.name = name\n            return group\n        elif input_type == 'checkbox' and len(fields) > 1:\n            group = CheckboxGroup(fields)\n            group.name = name\n            return group\n        else:\n            # I don't like throwing away elements like this\n            return fields[0]\n\n    def __contains__(self, name):\n        for field in self:\n            if field.name == name:\n                return True\n        return False\n\n    def keys(self):\n        \"\"\"\n        Returns all unique field names, in document order.\n\n        :return: A list of all unique field names.\n        \"\"\"\n        names = []\n        seen = {None}\n        for el in self:\n            name = el.name\n            if name not in seen:\n                names.append(name)\n                seen.add(name)\n        return names\n\n    def items(self):\n        \"\"\"\n        Returns all fields with their names, similar to dict.items().\n\n        :return: A list of (name, field) tuples.\n        \"\"\"\n        items = []\n        seen = set()\n        for el in self:\n            name = el.name\n            if name not in seen:\n                seen.add(name)\n                items.append((name, self[name]))\n        return items\n\n    def __iter__(self):\n        return self.form.iter('select', 'input', 'textarea')\n\n    def __len__(self):\n        return sum(1 for _ in self)\n\n\nclass InputMixin:\n    \"\"\"\n    Mix-in for all input elements (input, select, and textarea)\n    \"\"\"\n    @property\n    def name(self):\n        \"\"\"\n        Get/set the name of the element\n        \"\"\"\n        return self.get('name')\n\n    @name.setter\n    def name(self, value):\n        self.set('name', value)\n\n    @name.deleter\n    def name(self):\n        attrib = self.attrib\n        if 'name' in attrib:\n            del attrib['name']\n\n    def __repr__(self):\n        type_name = getattr(self, 'type', None)\n        if type_name:\n            type_name = ' type=%r' % type_name\n        else:\n            type_name = ''\n        return '<%s %x name=%r%s>' % (\n            self.__class__.__name__, id(self), self.name, type_name)\n\n\nclass TextareaElement(InputMixin, HtmlElement):\n    \"\"\"\n    ``<textarea>`` element.  You can get the name with ``.name`` and\n    get/set the value with ``.value``\n    \"\"\"\n    @property\n    def value(self):\n        \"\"\"\n        Get/set the value (which is the contents of this element)\n        \"\"\"\n        content = self.text or ''\n        if self.tag.startswith(\"{%s}\" % XHTML_NAMESPACE):\n            serialisation_method = 'xml'\n        else:\n            serialisation_method = 'html'\n        for el in self:\n            # it's rare that we actually get here, so let's not use ''.join()\n            content += etree.tostring(\n                el, method=serialisation_method, encoding='unicode')\n        return content\n\n    @value.setter\n    def value(self, value):\n        del self[:]\n        self.text = value\n\n    @value.deleter\n    def value(self):\n        self.text = ''\n        del self[:]\n\n\nHtmlElementClassLookup._default_element_classes['textarea'] = TextareaElement\n\n\nclass SelectElement(InputMixin, HtmlElement):\n    \"\"\"\n    ``<select>`` element.  You can get the name with ``.name``.\n\n    ``.value`` will be the value of the selected option, unless this\n    is a multi-select element (``<select multiple>``), in which case\n    it will be a set-like object.  In either case ``.value_options``\n    gives the possible values.\n\n    The boolean attribute ``.multiple`` shows if this is a\n    multi-select.\n    \"\"\"\n    @property\n    def value(self):\n        \"\"\"\n        Get/set the value of this select (the selected option).\n\n        If this is a multi-select, this is a set-like object that\n        represents all the selected options.\n        \"\"\"\n        if self.multiple:\n            return MultipleSelectOptions(self)\n        options = _options_xpath(self)\n\n        try:\n            selected_option = next(el for el in reversed(options) if el.get('selected') is not None)\n        except StopIteration:\n            try:\n                selected_option = next(el for el in options if el.get('disabled') is None)\n            except StopIteration:\n                return None\n        value = selected_option.get('value')\n        if value is None:\n            value = (selected_option.text or '').strip()\n        return value\n\n    @value.setter\n    def value(self, value):\n        if self.multiple:\n            if isinstance(value, str):\n                raise TypeError(\"You must pass in a sequence\")\n            values = self.value\n            values.clear()\n            values.update(value)\n            return\n        checked_option = None\n        if value is not None:\n            for el in _options_xpath(self):\n                opt_value = el.get('value')\n                if opt_value is None:\n                    opt_value = (el.text or '').strip()\n                if opt_value == value:\n                    checked_option = el\n                    break\n            else:\n                raise ValueError(\n                    \"There is no option with the value of %r\" % value)\n        for el in _options_xpath(self):\n            if 'selected' in el.attrib:\n                del el.attrib['selected']\n        if checked_option is not None:\n            checked_option.set('selected', '')\n\n    @value.deleter\n    def value(self):\n        # FIXME: should del be allowed at all?\n        if self.multiple:\n            self.value.clear()\n        else:\n            self.value = None\n\n    @property\n    def value_options(self):\n        \"\"\"\n        All the possible values this select can have (the ``value``\n        attribute of all the ``<option>`` elements.\n        \"\"\"\n        options = []\n        for el in _options_xpath(self):\n            value = el.get('value')\n            if value is None:\n                value = (el.text or '').strip()\n            options.append(value)\n        return options\n\n    @property\n    def multiple(self):\n        \"\"\"\n        Boolean attribute: is there a ``multiple`` attribute on this element.\n        \"\"\"\n        return 'multiple' in self.attrib\n\n    @multiple.setter\n    def multiple(self, value):\n        if value:\n            self.set('multiple', '')\n        elif 'multiple' in self.attrib:\n            del self.attrib['multiple']\n\n\nHtmlElementClassLookup._default_element_classes['select'] = SelectElement\n\n\nclass MultipleSelectOptions(SetMixin):\n    \"\"\"\n    Represents all the selected options in a ``<select multiple>`` element.\n\n    You can add to this set-like option to select an option, or remove\n    to unselect the option.\n    \"\"\"\n\n    def __init__(self, select):\n        self.select = select\n\n    @property\n    def options(self):\n        \"\"\"\n        Iterator of all the ``<option>`` elements.\n        \"\"\"\n        return iter(_options_xpath(self.select))\n\n    def __iter__(self):\n        for option in self.options:\n            if 'selected' in option.attrib:\n                opt_value = option.get('value')\n                if opt_value is None:\n                    opt_value = (option.text or '').strip()\n                yield opt_value\n\n    def add(self, item):\n        for option in self.options:\n            opt_value = option.get('value')\n            if opt_value is None:\n                opt_value = (option.text or '').strip()\n            if opt_value == item:\n                option.set('selected', '')\n                break\n        else:\n            raise ValueError(\n                \"There is no option with the value %r\" % item)\n\n    def remove(self, item):\n        for option in self.options:\n            opt_value = option.get('value')\n            if opt_value is None:\n                opt_value = (option.text or '').strip()\n            if opt_value == item:\n                if 'selected' in option.attrib:\n                    del option.attrib['selected']\n                else:\n                    raise ValueError(\n                        \"The option %r is not currently selected\" % item)\n                break\n        else:\n            raise ValueError(\n                \"There is not option with the value %r\" % item)\n\n    def __repr__(self):\n        return '<%s {%s} for select name=%r>' % (\n            self.__class__.__name__,\n            ', '.join([repr(v) for v in self]),\n            self.select.name)\n\n\nclass RadioGroup(list):\n    \"\"\"\n    This object represents several ``<input type=radio>`` elements\n    that have the same name.\n\n    You can use this like a list, but also use the property\n    ``.value`` to check/uncheck inputs.  Also you can use\n    ``.value_options`` to get the possible values.\n    \"\"\"\n    @property\n    def value(self):\n        \"\"\"\n        Get/set the value, which checks the radio with that value (and\n        unchecks any other value).\n        \"\"\"\n        for el in self:\n            if 'checked' in el.attrib:\n                return el.get('value')\n        return None\n\n    @value.setter\n    def value(self, value):\n        checked_option = None\n        if value is not None:\n            for el in self:\n                if el.get('value') == value:\n                    checked_option = el\n                    break\n            else:\n                raise ValueError(\"There is no radio input with the value %r\" % value)\n        for el in self:\n            if 'checked' in el.attrib:\n                del el.attrib['checked']\n        if checked_option is not None:\n            checked_option.set('checked', '')\n\n    @value.deleter\n    def value(self):\n        self.value = None\n\n    @property\n    def value_options(self):\n        \"\"\"\n        Returns a list of all the possible values.\n        \"\"\"\n        return [el.get('value') for el in self]\n\n    def __repr__(self):\n        return '%s(%s)' % (\n            self.__class__.__name__,\n            list.__repr__(self))\n\n\nclass CheckboxGroup(list):\n    \"\"\"\n    Represents a group of checkboxes (``<input type=checkbox>``) that\n    have the same name.\n\n    In addition to using this like a list, the ``.value`` attribute\n    returns a set-like object that you can add to or remove from to\n    check and uncheck checkboxes.  You can also use ``.value_options``\n    to get the possible values.\n    \"\"\"\n    @property\n    def value(self):\n        \"\"\"\n        Return a set-like object that can be modified to check or\n        uncheck individual checkboxes according to their value.\n        \"\"\"\n        return CheckboxValues(self)\n\n    @value.setter\n    def value(self, value):\n        values = self.value\n        values.clear()\n        if not hasattr(value, '__iter__'):\n            raise ValueError(\n                \"A CheckboxGroup (name=%r) must be set to a sequence (not %r)\"\n                % (self[0].name, value))\n        values.update(value)\n\n    @value.deleter\n    def value(self):\n        self.value.clear()\n\n    @property\n    def value_options(self):\n        \"\"\"\n        Returns a list of all the possible values.\n        \"\"\"\n        return [el.get('value') for el in self]\n\n    def __repr__(self):\n        return '%s(%s)' % (\n            self.__class__.__name__, list.__repr__(self))\n\n\nclass CheckboxValues(SetMixin):\n    \"\"\"\n    Represents the values of the checked checkboxes in a group of\n    checkboxes with the same name.\n    \"\"\"\n\n    def __init__(self, group):\n        self.group = group\n\n    def __iter__(self):\n        return iter([\n            el.get('value')\n            for el in self.group\n            if 'checked' in el.attrib])\n\n    def add(self, value):\n        for el in self.group:\n            if el.get('value') == value:\n                el.set('checked', '')\n                break\n        else:\n            raise KeyError(\"No checkbox with value %r\" % value)\n\n    def remove(self, value):\n        for el in self.group:\n            if el.get('value') == value:\n                if 'checked' in el.attrib:\n                    del el.attrib['checked']\n                else:\n                    raise KeyError(\n                        \"The checkbox with value %r was already unchecked\" % value)\n                break\n        else:\n            raise KeyError(\n                \"No checkbox with value %r\" % value)\n\n    def __repr__(self):\n        return '<%s {%s} for checkboxes name=%r>' % (\n            self.__class__.__name__,\n            ', '.join([repr(v) for v in self]),\n            self.group.name)\n\n\nclass InputElement(InputMixin, HtmlElement):\n    \"\"\"\n    Represents an ``<input>`` element.\n\n    You can get the type with ``.type`` (which is lower-cased and\n    defaults to ``'text'``).\n\n    Also you can get and set the value with ``.value``\n\n    Checkboxes and radios have the attribute ``input.checkable ==\n    True`` (for all others it is false) and a boolean attribute\n    ``.checked``.\n\n    \"\"\"\n\n    ## FIXME: I'm a little uncomfortable with the use of .checked\n    @property\n    def value(self):\n        \"\"\"\n        Get/set the value of this element, using the ``value`` attribute.\n\n        Also, if this is a checkbox and it has no value, this defaults\n        to ``'on'``.  If it is a checkbox or radio that is not\n        checked, this returns None.\n        \"\"\"\n        if self.checkable:\n            if self.checked:\n                return self.get('value') or 'on'\n            else:\n                return None\n        return self.get('value')\n\n    @value.setter\n    def value(self, value):\n        if self.checkable:\n            if not value:\n                self.checked = False\n            else:\n                self.checked = True\n                if isinstance(value, str):\n                    self.set('value', value)\n        else:\n            self.set('value', value)\n\n    @value.deleter\n    def value(self):\n        if self.checkable:\n            self.checked = False\n        else:\n            if 'value' in self.attrib:\n                del self.attrib['value']\n\n    @property\n    def type(self):\n        \"\"\"\n        Return the type of this element (using the type attribute).\n        \"\"\"\n        return self.get('type', 'text').lower()\n\n    @type.setter\n    def type(self, value):\n        self.set('type', value)\n\n    @property\n    def checkable(self):\n        \"\"\"\n        Boolean: can this element be checked?\n        \"\"\"\n        return self.type in ('checkbox', 'radio')\n\n    @property\n    def checked(self):\n        \"\"\"\n        Boolean attribute to get/set the presence of the ``checked``\n        attribute.\n\n        You can only use this on checkable input types.\n        \"\"\"\n        if not self.checkable:\n            raise AttributeError('Not a checkable input type')\n        return 'checked' in self.attrib\n\n    @checked.setter\n    def checked(self, value):\n        if not self.checkable:\n            raise AttributeError('Not a checkable input type')\n        if value:\n            self.set('checked', '')\n        else:\n            attrib = self.attrib\n            if 'checked' in attrib:\n                del attrib['checked']\n\n\nHtmlElementClassLookup._default_element_classes['input'] = InputElement\n\n\nclass LabelElement(HtmlElement):\n    \"\"\"\n    Represents a ``<label>`` element.\n\n    Label elements are linked to other elements with their ``for``\n    attribute.  You can access this element with ``label.for_element``.\n    \"\"\"\n    @property\n    def for_element(self):\n        \"\"\"\n        Get/set the element this label points to.  Return None if it\n        can't be found.\n        \"\"\"\n        id = self.get('for')\n        if not id:\n            return None\n        return self.body.get_element_by_id(id)\n\n    @for_element.setter\n    def for_element(self, other):\n        id = other.get('id')\n        if not id:\n            raise TypeError(\n                \"Element %r has no id attribute\" % other)\n        self.set('for', id)\n\n    @for_element.deleter\n    def for_element(self):\n        attrib = self.attrib\n        if 'id' in attrib:\n            del attrib['id']\n\n\nHtmlElementClassLookup._default_element_classes['label'] = LabelElement\n\n\n############################################################\n## Serialization\n############################################################\n\ndef html_to_xhtml(html):\n    \"\"\"Convert all tags in an HTML tree to XHTML by moving them to the\n    XHTML namespace.\n    \"\"\"\n    try:\n        html = html.getroot()\n    except AttributeError:\n        pass\n    prefix = \"{%s}\" % XHTML_NAMESPACE\n    for el in html.iter(etree.Element):\n        tag = el.tag\n        if tag[0] != '{':\n            el.tag = prefix + tag\n\n\ndef xhtml_to_html(xhtml):\n    \"\"\"Convert all tags in an XHTML tree to HTML by removing their\n    XHTML namespace.\n    \"\"\"\n    try:\n        xhtml = xhtml.getroot()\n    except AttributeError:\n        pass\n    prefix = \"{%s}\" % XHTML_NAMESPACE\n    prefix_len = len(prefix)\n    for el in xhtml.iter(prefix + \"*\"):\n        el.tag = el.tag[prefix_len:]\n\n\n# This isn't a general match, but it's a match for what libxml2\n# specifically serialises:\n__str_replace_meta_content_type = re.compile(\n    r'<meta http-equiv=\"Content-Type\"[^>]*>').sub\n__bytes_replace_meta_content_type = re.compile(\n    br'<meta http-equiv=\"Content-Type\"[^>]*>').sub\n\n\ndef tostring(doc, pretty_print=False, include_meta_content_type=False,\n             encoding=None, method=\"html\", with_tail=True, doctype=None):\n    \"\"\"Return an HTML string representation of the document.\n\n    Note: if include_meta_content_type is true this will create a\n    ``<meta http-equiv=\"Content-Type\" ...>`` tag in the head;\n    regardless of the value of include_meta_content_type any existing\n    ``<meta http-equiv=\"Content-Type\" ...>`` tag will be removed\n\n    The ``encoding`` argument controls the output encoding (defaults to\n    ASCII, with &#...; character references for any characters outside\n    of ASCII).  Note that you can pass the name ``'unicode'`` as\n    ``encoding`` argument to serialise to a Unicode string.\n\n    The ``method`` argument defines the output method.  It defaults to\n    'html', but can also be 'xml' for xhtml output, or 'text' to\n    serialise to plain text without markup.\n\n    To leave out the tail text of the top-level element that is being\n    serialised, pass ``with_tail=False``.\n\n    The ``doctype`` option allows passing in a plain string that will\n    be serialised before the XML tree.  Note that passing in non\n    well-formed content here will make the XML output non well-formed.\n    Also, an existing doctype in the document tree will not be removed\n    when serialising an ElementTree instance.\n\n    Example::\n\n        >>> from lxml import html\n        >>> root = html.fragment_fromstring('<p>Hello<br>world!</p>')\n\n        >>> html.tostring(root)\n        b'<p>Hello<br>world!</p>'\n        >>> html.tostring(root, method='html')\n        b'<p>Hello<br>world!</p>'\n\n        >>> html.tostring(root, method='xml')\n        b'<p>Hello<br/>world!</p>'\n\n        >>> html.tostring(root, method='text')\n        b'Helloworld!'\n\n        >>> html.tostring(root, method='text', encoding='unicode')\n        u'Helloworld!'\n\n        >>> root = html.fragment_fromstring('<div><p>Hello<br>world!</p>TAIL</div>')\n        >>> html.tostring(root[0], method='text', encoding='unicode')\n        u'Helloworld!TAIL'\n\n        >>> html.tostring(root[0], method='text', encoding='unicode', with_tail=False)\n        u'Helloworld!'\n\n        >>> doc = html.document_fromstring('<p>Hello<br>world!</p>')\n        >>> html.tostring(doc, method='html', encoding='unicode')\n        u'<html><body><p>Hello<br>world!</p></body></html>'\n\n        >>> print(html.tostring(doc, method='html', encoding='unicode',\n        ...          doctype='<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\"'\n        ...                  ' \"http://www.w3.org/TR/html4/strict.dtd\">'))\n        <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n        <html><body><p>Hello<br>world!</p></body></html>\n    \"\"\"\n    html = etree.tostring(doc, method=method, pretty_print=pretty_print,\n                          encoding=encoding, with_tail=with_tail,\n                          doctype=doctype)\n    if method == 'html' and not include_meta_content_type:\n        if isinstance(html, str):\n            html = __str_replace_meta_content_type('', html)\n        else:\n            html = __bytes_replace_meta_content_type(b'', html)\n    return html\n\n\ntostring.__doc__ = __fix_docstring(tostring.__doc__)\n\n\ndef open_in_browser(doc, encoding=None):\n    \"\"\"\n    Open the HTML document in a web browser, saving it to a temporary\n    file to open it.  Note that this does not delete the file after\n    use.  This is mainly meant for debugging.\n    \"\"\"\n    import os\n    import webbrowser\n    import tempfile\n    if not isinstance(doc, etree._ElementTree):\n        doc = etree.ElementTree(doc)\n    handle, fn = tempfile.mkstemp(suffix='.html')\n    f = os.fdopen(handle, 'wb')\n    try:\n        doc.write(f, method=\"html\", encoding=encoding or doc.docinfo.encoding or \"UTF-8\")\n    finally:\n        # we leak the file itself here, but we should at least close it\n        f.close()\n    url = 'file://' + fn.replace(os.path.sep, '/')\n    print(url)\n    webbrowser.open(url)\n\n\n################################################################################\n# configure Element class lookup\n################################################################################\n\nclass HTMLParser(etree.HTMLParser):\n    \"\"\"An HTML parser that is configured to return lxml.html Element\n    objects.\n    \"\"\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_element_class_lookup(HtmlElementClassLookup())\n\n\nclass XHTMLParser(etree.XMLParser):\n    \"\"\"An XML parser that is configured to return lxml.html Element\n    objects.\n\n    Note that this parser is not really XHTML aware unless you let it\n    load a DTD that declares the HTML entities.  To do this, make sure\n    you have the XHTML DTDs installed in your catalogs, and create the\n    parser like this::\n\n        >>> parser = XHTMLParser(load_dtd=True)\n\n    If you additionally want to validate the document, use this::\n\n        >>> parser = XHTMLParser(dtd_validation=True)\n\n    For catalog support, see http://www.xmlsoft.org/catalog.html.\n    \"\"\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_element_class_lookup(HtmlElementClassLookup())\n\n\ndef Element(*args, **kw):\n    \"\"\"Create a new HTML Element.\n\n    This can also be used for XHTML documents.\n    \"\"\"\n    v = html_parser.makeelement(*args, **kw)\n    return v\n\n\nhtml_parser = HTMLParser()\nxhtml_parser = XHTMLParser()\n", "src/lxml/html/builder.py": "# --------------------------------------------------------------------\n# The ElementTree toolkit is\n# Copyright (c) 1999-2004 by Fredrik Lundh\n# --------------------------------------------------------------------\n\n\"\"\"\nA set of HTML generator tags for building HTML documents.\n\nUsage::\n\n    >>> from lxml.html.builder import *\n    >>> html = HTML(\n    ...            HEAD( TITLE(\"Hello World\") ),\n    ...            BODY( CLASS(\"main\"),\n    ...                  H1(\"Hello World !\")\n    ...            )\n    ...        )\n\n    >>> import lxml.etree\n    >>> print lxml.etree.tostring(html, pretty_print=True)\n    <html>\n      <head>\n        <title>Hello World</title>\n      </head>\n      <body class=\"main\">\n        <h1>Hello World !</h1>\n      </body>\n    </html>\n\n\"\"\"\n\nfrom lxml.builder import ElementMaker\nfrom lxml.html import html_parser\n\nE = ElementMaker(makeelement=html_parser.makeelement)\n\n# elements\nA = E.a  #: anchor\nABBR = E.abbr  #: abbreviated form (e.g., WWW, HTTP, etc.)\nACRONYM = E.acronym  #: \nADDRESS = E.address  #: information on author\nAPPLET = E.applet  #: Java applet (DEPRECATED)\nAREA = E.area  #: client-side image map area\nB = E.b  #: bold text style\nBASE = E.base  #: document base URI\nBASEFONT = E.basefont  #: base font size (DEPRECATED)\nBDO = E.bdo  #: I18N BiDi over-ride\nBIG = E.big  #: large text style\nBLOCKQUOTE = E.blockquote  #: long quotation\nBODY = E.body  #: document body\nBR = E.br  #: forced line break\nBUTTON = E.button  #: push button\nCAPTION = E.caption  #: table caption\nCENTER = E.center  #: shorthand for DIV align=center (DEPRECATED)\nCITE = E.cite  #: citation\nCODE = E.code  #: computer code fragment\nCOL = E.col  #: table column\nCOLGROUP = E.colgroup  #: table column group\nDD = E.dd  #: definition description\nDEL = getattr(E, 'del')  #: deleted text\nDFN = E.dfn  #: instance definition\nDIR = E.dir  #: directory list (DEPRECATED)\nDIV = E.div  #: generic language/style container\nDL = E.dl  #: definition list\nDT = E.dt  #: definition term\nEM = E.em  #: emphasis\nFIELDSET = E.fieldset  #: form control group\nFONT = E.font  #: local change to font (DEPRECATED)\nFORM = E.form  #: interactive form\nFRAME = E.frame  #: subwindow\nFRAMESET = E.frameset  #: window subdivision\nH1 = E.h1  #: heading\nH2 = E.h2  #: heading\nH3 = E.h3  #: heading\nH4 = E.h4  #: heading\nH5 = E.h5  #: heading\nH6 = E.h6  #: heading\nHEAD = E.head  #: document head\nHR = E.hr  #: horizontal rule\nHTML = E.html  #: document root element\nI = E.i  #: italic text style\nIFRAME = E.iframe  #: inline subwindow\nIMG = E.img  #: Embedded image\nINPUT = E.input  #: form control\nINS = E.ins  #: inserted text\nISINDEX = E.isindex  #: single line prompt (DEPRECATED)\nKBD = E.kbd  #: text to be entered by the user\nLABEL = E.label  #: form field label text\nLEGEND = E.legend  #: fieldset legend\nLI = E.li  #: list item\nLINK = E.link  #: a media-independent link\nMAP = E.map  #: client-side image map\nMENU = E.menu  #: menu list (DEPRECATED)\nMETA = E.meta  #: generic metainformation\nNOFRAMES = E.noframes  #: alternate content container for non frame-based rendering\nNOSCRIPT = E.noscript  #: alternate content container for non script-based rendering\nOBJECT = E.object  #: generic embedded object\nOL = E.ol  #: ordered list\nOPTGROUP = E.optgroup  #: option group\nOPTION = E.option  #: selectable choice\nP = E.p  #: paragraph\nPARAM = E.param  #: named property value\nPRE = E.pre  #: preformatted text\nQ = E.q  #: short inline quotation\nS = E.s  #: strike-through text style (DEPRECATED)\nSAMP = E.samp  #: sample program output, scripts, etc.\nSCRIPT = E.script  #: script statements\nSELECT = E.select  #: option selector\nSMALL = E.small  #: small text style\nSPAN = E.span  #: generic language/style container\nSTRIKE = E.strike  #: strike-through text (DEPRECATED)\nSTRONG = E.strong  #: strong emphasis\nSTYLE = E.style  #: style info\nSUB = E.sub  #: subscript\nSUP = E.sup  #: superscript\nTABLE = E.table  #: \nTBODY = E.tbody  #: table body\nTD = E.td  #: table data cell\nTEXTAREA = E.textarea  #: multi-line text field\nTFOOT = E.tfoot  #: table footer\nTH = E.th  #: table header cell\nTHEAD = E.thead  #: table header\nTITLE = E.title  #: document title\nTR = E.tr  #: table row\nTT = E.tt  #: teletype or monospaced text style\nU = E.u  #: underlined text style (DEPRECATED)\nUL = E.ul  #: unordered list\nVAR = E.var  #: instance of a variable or program argument\n\n# attributes (only reserved words are included here)\nATTR = dict\ndef CLASS(v): return {'class': v}\ndef FOR(v): return {'for': v}\n"}