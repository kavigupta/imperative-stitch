{"setup.py": "from setuptools import setup\n\nsetup()\n", "docs/conf.py": "import pathlib\nimport sys\n\nsrc_directory = (pathlib.Path(__file__).parent.parent / \"src\").resolve()\nsys.path.insert(0, str(src_directory))\n\n\n# Extract the current version from the source.\ndef get_version():\n    \"\"\"Get the version and release from the source code.\"\"\"\n\n    text = (src_directory / \"cachetools/__init__.py\").read_text()\n    for line in text.splitlines():\n        if not line.strip().startswith(\"__version__\"):\n            continue\n        full_version = line.partition(\"=\")[2].strip().strip(\"\\\"'\")\n        partial_version = \".\".join(full_version.split(\".\")[:2])\n        return full_version, partial_version\n\n\nproject = \"cachetools\"\ncopyright = \"2014-2024 Thomas Kemmer\"\nrelease, version = get_version()\n\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.coverage\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.todo\",\n]\nexclude_patterns = [\"_build\"]\nmaster_doc = \"index\"\nhtml_theme = \"classic\"\n", "tests/test_cached.py": "import unittest\n\nimport cachetools\nimport cachetools.keys\n\n\nclass CountedLock:\n    def __init__(self):\n        self.count = 0\n\n    def __enter__(self):\n        self.count += 1\n\n    def __exit__(self, *exc):\n        pass\n\n\nclass DecoratorTestMixin:\n    def cache(self, minsize):\n        raise NotImplementedError\n\n    def func(self, *args, **kwargs):\n        if hasattr(self, \"count\"):\n            self.count += 1\n        else:\n            self.count = 0\n        return self.count\n\n    def test_decorator(self):\n        cache = self.cache(2)\n        wrapper = cachetools.cached(cache)(self.func)\n\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(len(cache), 1)\n        self.assertIn(cachetools.keys.hashkey(0), cache)\n        self.assertNotIn(cachetools.keys.hashkey(1), cache)\n        self.assertNotIn(cachetools.keys.hashkey(1.0), cache)\n\n        self.assertEqual(wrapper(1), 1)\n        self.assertEqual(len(cache), 2)\n        self.assertIn(cachetools.keys.hashkey(0), cache)\n        self.assertIn(cachetools.keys.hashkey(1), cache)\n        self.assertIn(cachetools.keys.hashkey(1.0), cache)\n\n        self.assertEqual(wrapper(1), 1)\n        self.assertEqual(len(cache), 2)\n\n        self.assertEqual(wrapper(1.0), 1)\n        self.assertEqual(len(cache), 2)\n\n        self.assertEqual(wrapper(1.0), 1)\n        self.assertEqual(len(cache), 2)\n\n    def test_decorator_typed(self):\n        cache = self.cache(3)\n        key = cachetools.keys.typedkey\n        wrapper = cachetools.cached(cache, key=key)(self.func)\n\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(len(cache), 1)\n        self.assertIn(cachetools.keys.typedkey(0), cache)\n        self.assertNotIn(cachetools.keys.typedkey(1), cache)\n        self.assertNotIn(cachetools.keys.typedkey(1.0), cache)\n\n        self.assertEqual(wrapper(1), 1)\n        self.assertEqual(len(cache), 2)\n        self.assertIn(cachetools.keys.typedkey(0), cache)\n        self.assertIn(cachetools.keys.typedkey(1), cache)\n        self.assertNotIn(cachetools.keys.typedkey(1.0), cache)\n\n        self.assertEqual(wrapper(1), 1)\n        self.assertEqual(len(cache), 2)\n\n        self.assertEqual(wrapper(1.0), 2)\n        self.assertEqual(len(cache), 3)\n        self.assertIn(cachetools.keys.typedkey(0), cache)\n        self.assertIn(cachetools.keys.typedkey(1), cache)\n        self.assertIn(cachetools.keys.typedkey(1.0), cache)\n\n        self.assertEqual(wrapper(1.0), 2)\n        self.assertEqual(len(cache), 3)\n\n    def test_decorator_lock(self):\n        cache = self.cache(2)\n        lock = CountedLock()\n        wrapper = cachetools.cached(cache, lock=lock)(self.func)\n\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(lock.count, 2)\n        self.assertEqual(wrapper(1), 1)\n        self.assertEqual(lock.count, 4)\n        self.assertEqual(wrapper(1), 1)\n        self.assertEqual(lock.count, 5)\n\n    def test_decorator_wrapped(self):\n        cache = self.cache(2)\n        wrapper = cachetools.cached(cache)(self.func)\n\n        self.assertEqual(wrapper.__wrapped__, self.func)\n\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper.__wrapped__(0), 0)\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper(0), 1)\n        self.assertEqual(len(cache), 1)\n        self.assertEqual(wrapper(0), 1)\n        self.assertEqual(len(cache), 1)\n\n    def test_decorator_attributes(self):\n        cache = self.cache(2)\n        wrapper = cachetools.cached(cache)(self.func)\n\n        self.assertIs(wrapper.cache, cache)\n        self.assertIs(wrapper.cache_key, cachetools.keys.hashkey)\n        self.assertIs(wrapper.cache_lock, None)\n\n    def test_decorator_attributes_lock(self):\n        cache = self.cache(2)\n        lock = CountedLock()\n        wrapper = cachetools.cached(cache, lock=lock)(self.func)\n\n        self.assertIs(wrapper.cache, cache)\n        self.assertIs(wrapper.cache_key, cachetools.keys.hashkey)\n        self.assertIs(wrapper.cache_lock, lock)\n\n    def test_decorator_clear(self):\n        cache = self.cache(2)\n        wrapper = cachetools.cached(cache)(self.func)\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(len(cache), 1)\n        wrapper.cache_clear()\n        self.assertEqual(len(cache), 0)\n\n    def test_decorator_clear_lock(self):\n        cache = self.cache(2)\n        lock = CountedLock()\n        wrapper = cachetools.cached(cache, lock=lock)(self.func)\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(len(cache), 1)\n        self.assertEqual(lock.count, 2)\n        wrapper.cache_clear()\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(lock.count, 3)\n\n\nclass CacheWrapperTest(unittest.TestCase, DecoratorTestMixin):\n    def cache(self, minsize):\n        return cachetools.Cache(maxsize=minsize)\n\n    def test_decorator_info(self):\n        cache = self.cache(2)\n        wrapper = cachetools.cached(cache, info=True)(self.func)\n        self.assertEqual(wrapper.cache_info(), (0, 0, 2, 0))\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(wrapper.cache_info(), (0, 1, 2, 1))\n        self.assertEqual(wrapper(1), 1)\n        self.assertEqual(wrapper.cache_info(), (0, 2, 2, 2))\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(wrapper.cache_info(), (1, 2, 2, 2))\n        wrapper.cache_clear()\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper.cache_info(), (0, 0, 2, 0))\n\n    def test_zero_size_cache_decorator(self):\n        cache = self.cache(0)\n        wrapper = cachetools.cached(cache)(self.func)\n\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(len(cache), 0)\n\n    def test_zero_size_cache_decorator_lock(self):\n        cache = self.cache(0)\n        lock = CountedLock()\n        wrapper = cachetools.cached(cache, lock=lock)(self.func)\n\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(lock.count, 2)\n\n    def test_zero_size_cache_decorator_info(self):\n        cache = self.cache(0)\n        wrapper = cachetools.cached(cache, info=True)(self.func)\n\n        self.assertEqual(wrapper.cache_info(), (0, 0, 0, 0))\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(wrapper.cache_info(), (0, 1, 0, 0))\n\n\nclass DictWrapperTest(unittest.TestCase, DecoratorTestMixin):\n    def cache(self, minsize):\n        return dict()\n\n    def test_decorator_info(self):\n        cache = self.cache(2)\n        wrapper = cachetools.cached(cache, info=True)(self.func)\n        self.assertEqual(wrapper.cache_info(), (0, 0, None, 0))\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(wrapper.cache_info(), (0, 1, None, 1))\n        self.assertEqual(wrapper(1), 1)\n        self.assertEqual(wrapper.cache_info(), (0, 2, None, 2))\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(wrapper.cache_info(), (1, 2, None, 2))\n        wrapper.cache_clear()\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper.cache_info(), (0, 0, None, 0))\n\n\nclass NoneWrapperTest(unittest.TestCase):\n    def func(self, *args, **kwargs):\n        return args + tuple(kwargs.items())\n\n    def test_decorator(self):\n        wrapper = cachetools.cached(None)(self.func)\n\n        self.assertEqual(wrapper(0), (0,))\n        self.assertEqual(wrapper(1), (1,))\n        self.assertEqual(wrapper(1, foo=\"bar\"), (1, (\"foo\", \"bar\")))\n\n    def test_decorator_attributes(self):\n        wrapper = cachetools.cached(None)(self.func)\n\n        self.assertIs(wrapper.cache, None)\n        self.assertIs(wrapper.cache_key, cachetools.keys.hashkey)\n        self.assertIs(wrapper.cache_lock, None)\n\n    def test_decorator_clear(self):\n        wrapper = cachetools.cached(None)(self.func)\n\n        wrapper.cache_clear()  # no-op\n\n    def test_decorator_info(self):\n        wrapper = cachetools.cached(None, info=True)(self.func)\n\n        self.assertEqual(wrapper.cache_info(), (0, 0, 0, 0))\n        self.assertEqual(wrapper(0), (0,))\n        self.assertEqual(wrapper.cache_info(), (0, 1, 0, 0))\n        self.assertEqual(wrapper(1), (1,))\n        self.assertEqual(wrapper.cache_info(), (0, 2, 0, 0))\n        wrapper.cache_clear()\n        self.assertEqual(wrapper.cache_info(), (0, 0, 0, 0))\n", "tests/test_lru.py": "import unittest\n\nfrom cachetools import LRUCache\n\nfrom . import CacheTestMixin\n\n\nclass LRUCacheTest(unittest.TestCase, CacheTestMixin):\n\n    Cache = LRUCache\n\n    def test_lru(self):\n        cache = LRUCache(maxsize=2)\n\n        cache[1] = 1\n        cache[2] = 2\n        cache[3] = 3\n\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[2], 2)\n        self.assertEqual(cache[3], 3)\n        self.assertNotIn(1, cache)\n\n        cache[2]\n        cache[4] = 4\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[2], 2)\n        self.assertEqual(cache[4], 4)\n        self.assertNotIn(3, cache)\n\n        cache[5] = 5\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[4], 4)\n        self.assertEqual(cache[5], 5)\n        self.assertNotIn(2, cache)\n\n    def test_lru_getsizeof(self):\n        cache = LRUCache(maxsize=3, getsizeof=lambda x: x)\n\n        cache[1] = 1\n        cache[2] = 2\n\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[1], 1)\n        self.assertEqual(cache[2], 2)\n\n        cache[3] = 3\n\n        self.assertEqual(len(cache), 1)\n        self.assertEqual(cache[3], 3)\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n\n        with self.assertRaises(ValueError):\n            cache[4] = 4\n        self.assertEqual(len(cache), 1)\n        self.assertEqual(cache[3], 3)\n", "tests/test_cachedmethod.py": "import unittest\n\nfrom cachetools import LRUCache, cachedmethod, keys\n\n\nclass Cached:\n    def __init__(self, cache, count=0):\n        self.cache = cache\n        self.count = count\n\n    @cachedmethod(lambda self: self.cache)\n    def get(self, value):\n        count = self.count\n        self.count += 1\n        return count\n\n    @cachedmethod(lambda self: self.cache, key=keys.typedkey)\n    def get_typed(self, value):\n        count = self.count\n        self.count += 1\n        return count\n\n\nclass Locked:\n    def __init__(self, cache):\n        self.cache = cache\n        self.count = 0\n\n    @cachedmethod(lambda self: self.cache, lock=lambda self: self)\n    def get(self, value):\n        return self.count\n\n    def __enter__(self):\n        self.count += 1\n\n    def __exit__(self, *exc):\n        pass\n\n\nclass Unhashable:\n    def __init__(self, cache):\n        self.cache = cache\n\n    @cachedmethod(lambda self: self.cache)\n    def get_default(self, value):\n        return value\n\n    @cachedmethod(lambda self: self.cache, key=keys.hashkey)\n    def get_hashkey(self, value):\n        return value\n\n    # https://github.com/tkem/cachetools/issues/107\n    def __hash__(self):\n        raise TypeError(\"unhashable type\")\n\n\nclass CachedMethodTest(unittest.TestCase):\n    def test_dict(self):\n        cached = Cached({})\n\n        self.assertEqual(cached.get(0), 0)\n        self.assertEqual(cached.get(1), 1)\n        self.assertEqual(cached.get(1), 1)\n        self.assertEqual(cached.get(1.0), 1)\n        self.assertEqual(cached.get(1.0), 1)\n\n        cached.cache.clear()\n        self.assertEqual(cached.get(1), 2)\n\n    def test_typed_dict(self):\n        cached = Cached(LRUCache(maxsize=2))\n\n        self.assertEqual(cached.get_typed(0), 0)\n        self.assertEqual(cached.get_typed(1), 1)\n        self.assertEqual(cached.get_typed(1), 1)\n        self.assertEqual(cached.get_typed(1.0), 2)\n        self.assertEqual(cached.get_typed(1.0), 2)\n        self.assertEqual(cached.get_typed(0.0), 3)\n        self.assertEqual(cached.get_typed(0), 4)\n\n    def test_lru(self):\n        cached = Cached(LRUCache(maxsize=2))\n\n        self.assertEqual(cached.get(0), 0)\n        self.assertEqual(cached.get(1), 1)\n        self.assertEqual(cached.get(1), 1)\n        self.assertEqual(cached.get(1.0), 1)\n        self.assertEqual(cached.get(1.0), 1)\n\n        cached.cache.clear()\n        self.assertEqual(cached.get(1), 2)\n\n    def test_typed_lru(self):\n        cached = Cached(LRUCache(maxsize=2))\n\n        self.assertEqual(cached.get_typed(0), 0)\n        self.assertEqual(cached.get_typed(1), 1)\n        self.assertEqual(cached.get_typed(1), 1)\n        self.assertEqual(cached.get_typed(1.0), 2)\n        self.assertEqual(cached.get_typed(1.0), 2)\n        self.assertEqual(cached.get_typed(0.0), 3)\n        self.assertEqual(cached.get_typed(0), 4)\n\n    def test_nospace(self):\n        cached = Cached(LRUCache(maxsize=0))\n\n        self.assertEqual(cached.get(0), 0)\n        self.assertEqual(cached.get(1), 1)\n        self.assertEqual(cached.get(1), 2)\n        self.assertEqual(cached.get(1.0), 3)\n        self.assertEqual(cached.get(1.0), 4)\n\n    def test_nocache(self):\n        cached = Cached(None)\n\n        self.assertEqual(cached.get(0), 0)\n        self.assertEqual(cached.get(1), 1)\n        self.assertEqual(cached.get(1), 2)\n        self.assertEqual(cached.get(1.0), 3)\n        self.assertEqual(cached.get(1.0), 4)\n\n    def test_weakref(self):\n        import weakref\n        import fractions\n        import gc\n\n        # in Python 3.7, `int` does not support weak references even\n        # when subclassed, but Fraction apparently does...\n        class Int(fractions.Fraction):\n            def __add__(self, other):\n                return Int(fractions.Fraction.__add__(self, other))\n\n        cached = Cached(weakref.WeakValueDictionary(), count=Int(0))\n\n        self.assertEqual(cached.get(0), 0)\n        gc.collect()\n        self.assertEqual(cached.get(0), 1)\n\n        ref = cached.get(1)\n        self.assertEqual(ref, 2)\n        self.assertEqual(cached.get(1), 2)\n        self.assertEqual(cached.get(1.0), 2)\n\n        ref = cached.get_typed(1)\n        self.assertEqual(ref, 3)\n        self.assertEqual(cached.get_typed(1), 3)\n        self.assertEqual(cached.get_typed(1.0), 4)\n\n        cached.cache.clear()\n        self.assertEqual(cached.get(1), 5)\n\n    def test_locked_dict(self):\n        cached = Locked({})\n\n        self.assertEqual(cached.get(0), 1)\n        self.assertEqual(cached.get(1), 3)\n        self.assertEqual(cached.get(1), 3)\n        self.assertEqual(cached.get(1.0), 3)\n        self.assertEqual(cached.get(2.0), 7)\n\n    def test_locked_nocache(self):\n        cached = Locked(None)\n\n        self.assertEqual(cached.get(0), 0)\n        self.assertEqual(cached.get(1), 0)\n        self.assertEqual(cached.get(1), 0)\n        self.assertEqual(cached.get(1.0), 0)\n        self.assertEqual(cached.get(1.0), 0)\n\n    def test_locked_nospace(self):\n        cached = Locked(LRUCache(maxsize=0))\n\n        self.assertEqual(cached.get(0), 1)\n        self.assertEqual(cached.get(1), 3)\n        self.assertEqual(cached.get(1), 5)\n        self.assertEqual(cached.get(1.0), 7)\n        self.assertEqual(cached.get(1.0), 9)\n\n    def test_unhashable(self):\n        cached = Unhashable(LRUCache(maxsize=0))\n\n        self.assertEqual(cached.get_default(0), 0)\n        self.assertEqual(cached.get_default(1), 1)\n\n        with self.assertRaises(TypeError):\n            cached.get_hashkey(0)\n\n    def test_wrapped(self):\n        cache = {}\n        cached = Cached(cache)\n\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(cached.get.__wrapped__(cached, 0), 0)\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(cached.get(0), 1)\n        self.assertEqual(len(cache), 1)\n        self.assertEqual(cached.get(0), 1)\n        self.assertEqual(len(cache), 1)\n\n    def test_attributes(self):\n        cache = {}\n        cached = Cached(cache)\n\n        self.assertIs(cached.get.cache(cached), cache)\n        self.assertIs(cached.get.cache_key, keys.methodkey)\n        self.assertIs(cached.get.cache_lock, None)\n\n    def test_attributes_lock(self):\n        cache = {}\n        cached = Locked(cache)\n\n        self.assertIs(cached.get.cache(cached), cache)\n        self.assertIs(cached.get.cache_key, keys.methodkey)\n        self.assertIs(cached.get.cache_lock(cached), cached)\n\n    def test_clear(self):\n        cache = {}\n        cached = Cached(cache)\n\n        self.assertEqual(cached.get(0), 0)\n        self.assertEqual(len(cache), 1)\n        cached.get.cache_clear(cached)\n        self.assertEqual(len(cache), 0)\n\n    def test_clear_locked(self):\n        cache = {}\n        cached = Locked(cache)\n\n        self.assertEqual(cached.get(0), 1)\n        self.assertEqual(len(cache), 1)\n        self.assertEqual(cached.count, 2)\n        cached.get.cache_clear(cached)\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(cached.count, 3)\n", "tests/test_rr.py": "import unittest\n\nfrom cachetools import RRCache\n\nfrom . import CacheTestMixin\n\n\nclass RRCacheTest(unittest.TestCase, CacheTestMixin):\n\n    Cache = RRCache\n\n    def test_rr(self):\n        cache = RRCache(maxsize=2, choice=min)\n        self.assertEqual(min, cache.choice)\n\n        cache[1] = 1\n        cache[2] = 2\n        cache[3] = 3\n\n        self.assertEqual(2, len(cache))\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n        self.assertNotIn(1, cache)\n\n        cache[0] = 0\n        self.assertEqual(2, len(cache))\n        self.assertEqual(0, cache[0])\n        self.assertEqual(3, cache[3])\n        self.assertNotIn(2, cache)\n\n        cache[4] = 4\n        self.assertEqual(2, len(cache))\n        self.assertEqual(3, cache[3])\n        self.assertEqual(4, cache[4])\n        self.assertNotIn(0, cache)\n", "tests/test_func.py": "import unittest\n\nimport cachetools.func\n\n\nclass DecoratorTestMixin:\n    def decorator(self, maxsize, **kwargs):\n        return self.DECORATOR(maxsize, **kwargs)\n\n    def test_decorator(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n        self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\n        self.assertEqual(cached.cache_info(), (0, 0, 2, 0))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (0, 1, 2, 1))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (1, 1, 2, 1))\n        self.assertEqual(cached(1.0), 1.0)\n        self.assertEqual(cached.cache_info(), (2, 1, 2, 1))\n\n    def test_decorator_clear(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n        self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\n        self.assertEqual(cached.cache_info(), (0, 0, 2, 0))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (0, 1, 2, 1))\n        cached.cache_clear()\n        self.assertEqual(cached.cache_info(), (0, 0, 2, 0))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (0, 1, 2, 1))\n\n    def test_decorator_nocache(self):\n        cached = self.decorator(maxsize=0)(lambda n: n)\n        self.assertEqual(cached.cache_parameters(), {\"maxsize\": 0, \"typed\": False})\n        self.assertEqual(cached.cache_info(), (0, 0, 0, 0))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (0, 1, 0, 0))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (0, 2, 0, 0))\n        self.assertEqual(cached(1.0), 1.0)\n        self.assertEqual(cached.cache_info(), (0, 3, 0, 0))\n\n    def test_decorator_unbound(self):\n        cached = self.decorator(maxsize=None)(lambda n: n)\n        self.assertEqual(cached.cache_parameters(), {\"maxsize\": None, \"typed\": False})\n        self.assertEqual(cached.cache_info(), (0, 0, None, 0))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (0, 1, None, 1))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (1, 1, None, 1))\n        self.assertEqual(cached(1.0), 1.0)\n        self.assertEqual(cached.cache_info(), (2, 1, None, 1))\n\n    def test_decorator_typed(self):\n        cached = self.decorator(maxsize=2, typed=True)(lambda n: n)\n        self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": True})\n        self.assertEqual(cached.cache_info(), (0, 0, 2, 0))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (0, 1, 2, 1))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (1, 1, 2, 1))\n        self.assertEqual(cached(1.0), 1.0)\n        self.assertEqual(cached.cache_info(), (1, 2, 2, 2))\n        self.assertEqual(cached(1.0), 1.0)\n        self.assertEqual(cached.cache_info(), (2, 2, 2, 2))\n\n    def test_decorator_user_function(self):\n        cached = self.decorator(lambda n: n)\n        self.assertEqual(cached.cache_parameters(), {\"maxsize\": 128, \"typed\": False})\n        self.assertEqual(cached.cache_info(), (0, 0, 128, 0))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (0, 1, 128, 1))\n        self.assertEqual(cached(1), 1)\n        self.assertEqual(cached.cache_info(), (1, 1, 128, 1))\n        self.assertEqual(cached(1.0), 1.0)\n        self.assertEqual(cached.cache_info(), (2, 1, 128, 1))\n\n    def test_decorator_needs_rlock(self):\n        cached = self.decorator(lambda n: n)\n\n        class RecursiveEquals:\n            def __init__(self, use_cache):\n                self._use_cache = use_cache\n\n            def __hash__(self):\n                return hash(self._use_cache)\n\n            def __eq__(self, other):\n                if self._use_cache:\n                    # This call will happen while the cache-lock is held,\n                    # requiring a reentrant lock to avoid deadlock.\n                    cached(self)\n                return self._use_cache == other._use_cache\n\n        # Prime the cache.\n        cached(RecursiveEquals(False))\n        cached(RecursiveEquals(True))\n        # Then do a call which will cause a deadlock with a non-reentrant lock.\n        self.assertEqual(cached(RecursiveEquals(True)), RecursiveEquals(True))\n\n\nclass FIFODecoratorTest(unittest.TestCase, DecoratorTestMixin):\n\n    DECORATOR = staticmethod(cachetools.func.fifo_cache)\n\n\nclass LFUDecoratorTest(unittest.TestCase, DecoratorTestMixin):\n\n    DECORATOR = staticmethod(cachetools.func.lfu_cache)\n\n\nclass LRUDecoratorTest(unittest.TestCase, DecoratorTestMixin):\n\n    DECORATOR = staticmethod(cachetools.func.lru_cache)\n\n\nclass MRUDecoratorTest(unittest.TestCase, DecoratorTestMixin):\n\n    DECORATOR = staticmethod(cachetools.func.mru_cache)\n\n\nclass RRDecoratorTest(unittest.TestCase, DecoratorTestMixin):\n\n    DECORATOR = staticmethod(cachetools.func.rr_cache)\n\n\nclass TTLDecoratorTest(unittest.TestCase, DecoratorTestMixin):\n\n    DECORATOR = staticmethod(cachetools.func.ttl_cache)\n", "tests/test_fifo.py": "import unittest\n\nfrom cachetools import FIFOCache\n\nfrom . import CacheTestMixin\n\n\nclass LRUCacheTest(unittest.TestCase, CacheTestMixin):\n\n    Cache = FIFOCache\n\n    def test_fifo(self):\n        cache = FIFOCache(maxsize=2)\n\n        cache[1] = 1\n        cache[2] = 2\n        cache[3] = 3\n\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[2], 2)\n        self.assertEqual(cache[3], 3)\n        self.assertNotIn(1, cache)\n\n        cache[2]\n        cache[4] = 4\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[3], 3)\n        self.assertEqual(cache[4], 4)\n        self.assertNotIn(2, cache)\n\n        cache[5] = 5\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[4], 4)\n        self.assertEqual(cache[5], 5)\n        self.assertNotIn(3, cache)\n\n    def test_fifo_getsizeof(self):\n        cache = FIFOCache(maxsize=3, getsizeof=lambda x: x)\n\n        cache[1] = 1\n        cache[2] = 2\n\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[1], 1)\n        self.assertEqual(cache[2], 2)\n\n        cache[3] = 3\n\n        self.assertEqual(len(cache), 1)\n        self.assertEqual(cache[3], 3)\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n\n        with self.assertRaises(ValueError):\n            cache[4] = 4\n        self.assertEqual(len(cache), 1)\n        self.assertEqual(cache[3], 3)\n", "tests/test_keys.py": "import unittest\n\nimport cachetools.keys\n\n\nclass CacheKeysTest(unittest.TestCase):\n    def test_hashkey(self, key=cachetools.keys.hashkey):\n        self.assertEqual(key(), key())\n        self.assertEqual(hash(key()), hash(key()))\n        self.assertEqual(key(1, 2, 3), key(1, 2, 3))\n        self.assertEqual(hash(key(1, 2, 3)), hash(key(1, 2, 3)))\n        self.assertEqual(key(1, 2, 3, x=0), key(1, 2, 3, x=0))\n        self.assertEqual(hash(key(1, 2, 3, x=0)), hash(key(1, 2, 3, x=0)))\n        self.assertNotEqual(key(1, 2, 3), key(3, 2, 1))\n        self.assertNotEqual(key(1, 2, 3), key(1, 2, 3, x=None))\n        self.assertNotEqual(key(1, 2, 3, x=0), key(1, 2, 3, x=None))\n        self.assertNotEqual(key(1, 2, 3, x=0), key(1, 2, 3, y=0))\n        with self.assertRaises(TypeError):\n            hash(key({}))\n        # untyped keys compare equal\n        self.assertEqual(key(1, 2, 3), key(1.0, 2.0, 3.0))\n        self.assertEqual(hash(key(1, 2, 3)), hash(key(1.0, 2.0, 3.0)))\n\n    def test_typedkey(self, key=cachetools.keys.typedkey):\n        self.assertEqual(key(), key())\n        self.assertEqual(hash(key()), hash(key()))\n        self.assertEqual(key(1, 2, 3), key(1, 2, 3))\n        self.assertEqual(hash(key(1, 2, 3)), hash(key(1, 2, 3)))\n        self.assertEqual(key(1, 2, 3, x=0), key(1, 2, 3, x=0))\n        self.assertEqual(hash(key(1, 2, 3, x=0)), hash(key(1, 2, 3, x=0)))\n        self.assertNotEqual(key(1, 2, 3), key(3, 2, 1))\n        self.assertNotEqual(key(1, 2, 3), key(1, 2, 3, x=None))\n        self.assertNotEqual(key(1, 2, 3, x=0), key(1, 2, 3, x=None))\n        self.assertNotEqual(key(1, 2, 3, x=0), key(1, 2, 3, y=0))\n        with self.assertRaises(TypeError):\n            hash(key({}))\n        # typed keys compare unequal\n        self.assertNotEqual(key(1, 2, 3), key(1.0, 2.0, 3.0))\n\n    def test_addkeys(self, key=cachetools.keys.hashkey):\n        self.assertIsInstance(key(), tuple)\n        self.assertIsInstance(key(1, 2, 3) + key(4, 5, 6), type(key()))\n        self.assertIsInstance(key(1, 2, 3) + (4, 5, 6), type(key()))\n        self.assertIsInstance((1, 2, 3) + key(4, 5, 6), type(key()))\n\n    def test_pickle(self, key=cachetools.keys.hashkey):\n        import pickle\n\n        for k in [key(), key(\"abc\"), key(\"abc\", 123), key(\"abc\", q=\"abc\")]:\n            # white-box test: assert cached hash value is not pickled\n            self.assertEqual(len(k.__dict__), 0)\n            h = hash(k)\n            self.assertEqual(len(k.__dict__), 1)\n            pickled = pickle.loads(pickle.dumps(k))\n            self.assertEqual(len(pickled.__dict__), 0)\n            self.assertEqual(k, pickled)\n            self.assertEqual(h, hash(pickled))\n", "tests/test_lfu.py": "import unittest\n\nfrom cachetools import LFUCache\n\nfrom . import CacheTestMixin\n\n\nclass LFUCacheTest(unittest.TestCase, CacheTestMixin):\n\n    Cache = LFUCache\n\n    def test_lfu(self):\n        cache = LFUCache(maxsize=2)\n\n        cache[1] = 1\n        cache[1]\n        cache[2] = 2\n        cache[3] = 3\n\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[1], 1)\n        self.assertTrue(2 in cache or 3 in cache)\n        self.assertTrue(2 not in cache or 3 not in cache)\n\n        cache[4] = 4\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[4], 4)\n        self.assertEqual(cache[1], 1)\n\n    def test_lfu_getsizeof(self):\n        cache = LFUCache(maxsize=3, getsizeof=lambda x: x)\n\n        cache[1] = 1\n        cache[2] = 2\n\n        self.assertEqual(len(cache), 2)\n        self.assertEqual(cache[1], 1)\n        self.assertEqual(cache[2], 2)\n\n        cache[3] = 3\n\n        self.assertEqual(len(cache), 1)\n        self.assertEqual(cache[3], 3)\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n\n        with self.assertRaises(ValueError):\n            cache[4] = 4\n        self.assertEqual(len(cache), 1)\n        self.assertEqual(cache[3], 3)\n", "tests/test_ttl.py": "import math\nimport unittest\n\nfrom cachetools import TTLCache\n\nfrom . import CacheTestMixin\n\n\nclass Timer:\n    def __init__(self, auto=False):\n        self.auto = auto\n        self.time = 0\n\n    def __call__(self):\n        if self.auto:\n            self.time += 1\n        return self.time\n\n    def tick(self):\n        self.time += 1\n\n\nclass TTLTestCache(TTLCache):\n    def __init__(self, maxsize, ttl=math.inf, **kwargs):\n        TTLCache.__init__(self, maxsize, ttl=ttl, timer=Timer(), **kwargs)\n\n\nclass TTLCacheTest(unittest.TestCase, CacheTestMixin):\n\n    Cache = TTLTestCache\n\n    def test_ttl(self):\n        cache = TTLCache(maxsize=2, ttl=2, timer=Timer())\n        self.assertEqual(0, cache.timer())\n        self.assertEqual(2, cache.ttl)\n\n        cache[1] = 1\n        self.assertEqual(1, cache[1])\n        self.assertEqual(1, len(cache))\n        self.assertEqual({1}, set(cache))\n\n        cache.timer.tick()\n        self.assertEqual(1, cache[1])\n        self.assertEqual(1, len(cache))\n        self.assertEqual({1}, set(cache))\n\n        cache[2] = 2\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n        self.assertEqual(2, len(cache))\n        self.assertEqual({1, 2}, set(cache))\n\n        cache.timer.tick()\n        self.assertNotIn(1, cache)\n        self.assertEqual(2, cache[2])\n        self.assertEqual(1, len(cache))\n        self.assertEqual({2}, set(cache))\n\n        cache[3] = 3\n        self.assertNotIn(1, cache)\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n        self.assertEqual(2, len(cache))\n        self.assertEqual({2, 3}, set(cache))\n\n        cache.timer.tick()\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertEqual(3, cache[3])\n        self.assertEqual(1, len(cache))\n        self.assertEqual({3}, set(cache))\n\n        cache.timer.tick()\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertNotIn(3, cache)\n\n        with self.assertRaises(KeyError):\n            del cache[1]\n        with self.assertRaises(KeyError):\n            cache.pop(2)\n        with self.assertRaises(KeyError):\n            del cache[3]\n\n        self.assertEqual(0, len(cache))\n        self.assertEqual(set(), set(cache))\n\n    def test_ttl_lru(self):\n        cache = TTLCache(maxsize=2, ttl=1, timer=Timer())\n\n        cache[1] = 1\n        cache[2] = 2\n        cache[3] = 3\n\n        self.assertEqual(len(cache), 2)\n        self.assertNotIn(1, cache)\n        self.assertEqual(cache[2], 2)\n        self.assertEqual(cache[3], 3)\n\n        cache[2]\n        cache[4] = 4\n        self.assertEqual(len(cache), 2)\n        self.assertNotIn(1, cache)\n        self.assertEqual(cache[2], 2)\n        self.assertNotIn(3, cache)\n        self.assertEqual(cache[4], 4)\n\n        cache[5] = 5\n        self.assertEqual(len(cache), 2)\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertNotIn(3, cache)\n        self.assertEqual(cache[4], 4)\n        self.assertEqual(cache[5], 5)\n\n    def test_ttl_expire(self):\n        cache = TTLCache(maxsize=3, ttl=3, timer=Timer())\n        with cache.timer as time:\n            self.assertEqual(time, cache.timer())\n        self.assertEqual(3, cache.ttl)\n\n        cache[1] = 1\n        cache.timer.tick()\n        cache[2] = 2\n        cache.timer.tick()\n        cache[3] = 3\n        self.assertEqual(2, cache.timer())\n\n        self.assertEqual({1, 2, 3}, set(cache))\n        self.assertEqual(3, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n\n        cache.expire()\n        self.assertEqual({1, 2, 3}, set(cache))\n        self.assertEqual(3, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n\n        cache.expire(3)\n        self.assertEqual({2, 3}, set(cache))\n        self.assertEqual(2, len(cache))\n        self.assertNotIn(1, cache)\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n\n        cache.expire(4)\n        self.assertEqual({3}, set(cache))\n        self.assertEqual(1, len(cache))\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertEqual(3, cache[3])\n\n        cache.expire(5)\n        self.assertEqual(set(), set(cache))\n        self.assertEqual(0, len(cache))\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertNotIn(3, cache)\n\n    def test_ttl_atomic(self):\n        cache = TTLCache(maxsize=1, ttl=2, timer=Timer(auto=True))\n        cache[1] = 1\n        self.assertEqual(1, cache[1])\n        cache[1] = 1\n        self.assertEqual(1, cache.get(1))\n        cache[1] = 1\n        self.assertEqual(1, cache.pop(1))\n        cache[1] = 1\n        self.assertEqual(1, cache.setdefault(1))\n        cache[1] = 1\n        cache.clear()\n        self.assertEqual(0, len(cache))\n\n    def test_ttl_tuple_key(self):\n        cache = TTLCache(maxsize=1, ttl=1, timer=Timer())\n        self.assertEqual(1, cache.ttl)\n\n        cache[(1, 2, 3)] = 42\n        self.assertEqual(42, cache[(1, 2, 3)])\n        cache.timer.tick()\n        with self.assertRaises(KeyError):\n            cache[(1, 2, 3)]\n        self.assertNotIn((1, 2, 3), cache)\n\n    def test_ttl_datetime(self):\n        from datetime import datetime, timedelta\n\n        cache = TTLCache(maxsize=1, ttl=timedelta(days=1), timer=datetime.now)\n\n        cache[1] = 1\n        self.assertEqual(1, len(cache))\n        cache.expire(datetime.now())\n        self.assertEqual(1, len(cache))\n        cache.expire(datetime.now() + timedelta(days=1))\n        self.assertEqual(0, len(cache))\n", "tests/__init__.py": "import unittest\n\n\nclass CacheTestMixin:\n\n    Cache = None\n\n    def test_defaults(self):\n        cache = self.Cache(maxsize=1)\n        self.assertEqual(0, len(cache))\n        self.assertEqual(1, cache.maxsize)\n        self.assertEqual(0, cache.currsize)\n        self.assertEqual(1, cache.getsizeof(None))\n        self.assertEqual(1, cache.getsizeof(\"\"))\n        self.assertEqual(1, cache.getsizeof(0))\n        self.assertTrue(repr(cache).startswith(cache.__class__.__name__))\n\n    def test_insert(self):\n        cache = self.Cache(maxsize=2)\n\n        cache.update({1: 1, 2: 2})\n        self.assertEqual(2, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n\n        cache[3] = 3\n        self.assertEqual(2, len(cache))\n        self.assertEqual(3, cache[3])\n        self.assertTrue(1 in cache or 2 in cache)\n\n        cache[4] = 4\n        self.assertEqual(2, len(cache))\n        self.assertEqual(4, cache[4])\n        self.assertTrue(1 in cache or 2 in cache or 3 in cache)\n\n    def test_update(self):\n        cache = self.Cache(maxsize=2)\n\n        cache.update({1: 1, 2: 2})\n        self.assertEqual(2, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n\n        cache.update({1: 1, 2: 2})\n        self.assertEqual(2, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n\n        cache.update({1: \"a\", 2: \"b\"})\n        self.assertEqual(2, len(cache))\n        self.assertEqual(\"a\", cache[1])\n        self.assertEqual(\"b\", cache[2])\n\n    def test_delete(self):\n        cache = self.Cache(maxsize=2)\n\n        cache.update({1: 1, 2: 2})\n        self.assertEqual(2, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n\n        del cache[2]\n        self.assertEqual(1, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertNotIn(2, cache)\n\n        del cache[1]\n        self.assertEqual(0, len(cache))\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n\n        with self.assertRaises(KeyError):\n            del cache[1]\n        self.assertEqual(0, len(cache))\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n\n    def test_pop(self):\n        cache = self.Cache(maxsize=2)\n\n        cache.update({1: 1, 2: 2})\n        self.assertEqual(2, cache.pop(2))\n        self.assertEqual(1, len(cache))\n        self.assertEqual(1, cache.pop(1))\n        self.assertEqual(0, len(cache))\n\n        with self.assertRaises(KeyError):\n            cache.pop(2)\n        with self.assertRaises(KeyError):\n            cache.pop(1)\n        with self.assertRaises(KeyError):\n            cache.pop(0)\n\n        self.assertEqual(None, cache.pop(2, None))\n        self.assertEqual(None, cache.pop(1, None))\n        self.assertEqual(None, cache.pop(0, None))\n\n    def test_popitem(self):\n        cache = self.Cache(maxsize=2)\n\n        cache.update({1: 1, 2: 2})\n        self.assertIn(cache.pop(1), {1: 1, 2: 2})\n        self.assertEqual(1, len(cache))\n        self.assertIn(cache.pop(2), {1: 1, 2: 2})\n        self.assertEqual(0, len(cache))\n\n        with self.assertRaises(KeyError):\n            cache.popitem()\n\n    def test_popitem_exception_context(self):\n        # since Python 3.7, MutableMapping.popitem() suppresses\n        # exception context as implementation detail\n        exception = None\n        try:\n            self.Cache(maxsize=2).popitem()\n        except Exception as e:\n            exception = e\n        self.assertIsNone(exception.__cause__)\n        self.assertTrue(exception.__suppress_context__)\n\n    def test_missing(self):\n        class DefaultCache(self.Cache):\n            def __missing__(self, key):\n                self[key] = key\n                return key\n\n        cache = DefaultCache(maxsize=2)\n\n        self.assertEqual(0, cache.currsize)\n        self.assertEqual(2, cache.maxsize)\n        self.assertEqual(0, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n        self.assertEqual(2, len(cache))\n        self.assertTrue(1 in cache and 2 in cache)\n\n        self.assertEqual(3, cache[3])\n        self.assertEqual(2, len(cache))\n        self.assertTrue(3 in cache)\n        self.assertTrue(1 in cache or 2 in cache)\n        self.assertTrue(1 not in cache or 2 not in cache)\n\n        self.assertEqual(4, cache[4])\n        self.assertEqual(2, len(cache))\n        self.assertTrue(4 in cache)\n        self.assertTrue(1 in cache or 2 in cache or 3 in cache)\n\n        # verify __missing__() is *not* called for any operations\n        # besides __getitem__()\n\n        self.assertEqual(4, cache.get(4))\n        self.assertEqual(None, cache.get(5))\n        self.assertEqual(5 * 5, cache.get(5, 5 * 5))\n        self.assertEqual(2, len(cache))\n\n        self.assertEqual(4, cache.pop(4))\n        with self.assertRaises(KeyError):\n            cache.pop(5)\n        self.assertEqual(None, cache.pop(5, None))\n        self.assertEqual(5 * 5, cache.pop(5, 5 * 5))\n        self.assertEqual(1, len(cache))\n\n        cache.clear()\n        cache[1] = 1 + 1\n        self.assertEqual(1 + 1, cache.setdefault(1))\n        self.assertEqual(1 + 1, cache.setdefault(1, 1))\n        self.assertEqual(1 + 1, cache[1])\n        self.assertEqual(2 + 2, cache.setdefault(2, 2 + 2))\n        self.assertEqual(2 + 2, cache.setdefault(2, None))\n        self.assertEqual(2 + 2, cache.setdefault(2))\n        self.assertEqual(2 + 2, cache[2])\n        self.assertEqual(2, len(cache))\n        self.assertTrue(1 in cache and 2 in cache)\n        self.assertEqual(None, cache.setdefault(3))\n        self.assertEqual(2, len(cache))\n        self.assertTrue(3 in cache)\n        self.assertTrue(1 in cache or 2 in cache)\n        self.assertTrue(1 not in cache or 2 not in cache)\n\n    def test_missing_getsizeof(self):\n        class DefaultCache(self.Cache):\n            def __missing__(self, key):\n                try:\n                    self[key] = key\n                except ValueError:\n                    pass  # not stored\n                return key\n\n        cache = DefaultCache(maxsize=2, getsizeof=lambda x: x)\n\n        self.assertEqual(0, cache.currsize)\n        self.assertEqual(2, cache.maxsize)\n\n        self.assertEqual(1, cache[1])\n        self.assertEqual(1, len(cache))\n        self.assertEqual(1, cache.currsize)\n        self.assertIn(1, cache)\n\n        self.assertEqual(2, cache[2])\n        self.assertEqual(1, len(cache))\n        self.assertEqual(2, cache.currsize)\n        self.assertNotIn(1, cache)\n        self.assertIn(2, cache)\n\n        self.assertEqual(3, cache[3])  # not stored\n        self.assertEqual(1, len(cache))\n        self.assertEqual(2, cache.currsize)\n        self.assertEqual(1, cache[1])\n        self.assertEqual(1, len(cache))\n        self.assertEqual(1, cache.currsize)\n        self.assertEqual((1, 1), cache.popitem())\n\n    def _test_getsizeof(self, cache):\n        self.assertEqual(0, cache.currsize)\n        self.assertEqual(3, cache.maxsize)\n        self.assertEqual(1, cache.getsizeof(1))\n        self.assertEqual(2, cache.getsizeof(2))\n        self.assertEqual(3, cache.getsizeof(3))\n\n        cache.update({1: 1, 2: 2})\n        self.assertEqual(2, len(cache))\n        self.assertEqual(3, cache.currsize)\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n\n        cache[1] = 2\n        self.assertEqual(1, len(cache))\n        self.assertEqual(2, cache.currsize)\n        self.assertEqual(2, cache[1])\n        self.assertNotIn(2, cache)\n\n        cache.update({1: 1, 2: 2})\n        self.assertEqual(2, len(cache))\n        self.assertEqual(3, cache.currsize)\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n\n        cache[3] = 3\n        self.assertEqual(1, len(cache))\n        self.assertEqual(3, cache.currsize)\n        self.assertEqual(3, cache[3])\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n\n        with self.assertRaises(ValueError):\n            cache[3] = 4\n        self.assertEqual(1, len(cache))\n        self.assertEqual(3, cache.currsize)\n        self.assertEqual(3, cache[3])\n\n        with self.assertRaises(ValueError):\n            cache[4] = 4\n        self.assertEqual(1, len(cache))\n        self.assertEqual(3, cache.currsize)\n        self.assertEqual(3, cache[3])\n\n    def test_getsizeof_param(self):\n        self._test_getsizeof(self.Cache(maxsize=3, getsizeof=lambda x: x))\n\n    def test_getsizeof_subclass(self):\n        class Cache(self.Cache):\n            def getsizeof(self, value):\n                return value\n\n        self._test_getsizeof(Cache(maxsize=3))\n\n    def test_pickle(self):\n        import pickle\n\n        source = self.Cache(maxsize=2)\n        source.update({1: 1, 2: 2})\n\n        cache = pickle.loads(pickle.dumps(source))\n        self.assertEqual(source, cache)\n\n        self.assertEqual(2, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n\n        cache[3] = 3\n        self.assertEqual(2, len(cache))\n        self.assertEqual(3, cache[3])\n        self.assertTrue(1 in cache or 2 in cache)\n\n        cache[4] = 4\n        self.assertEqual(2, len(cache))\n        self.assertEqual(4, cache[4])\n        self.assertTrue(1 in cache or 2 in cache or 3 in cache)\n\n        self.assertEqual(cache, pickle.loads(pickle.dumps(cache)))\n\n    def test_pickle_maxsize(self):\n        import pickle\n        import sys\n\n        # test empty cache, single element, large cache (recursion limit)\n        for n in [0, 1, sys.getrecursionlimit() * 2]:\n            source = self.Cache(maxsize=n)\n            source.update((i, i) for i in range(n))\n            cache = pickle.loads(pickle.dumps(source))\n            self.assertEqual(n, len(cache))\n            self.assertEqual(source, cache)\n", "tests/test_mru.py": "import unittest\n\nfrom cachetools import MRUCache\n\nfrom . import CacheTestMixin\n\n\nclass MRUCacheTest(unittest.TestCase, CacheTestMixin):\n\n    Cache = MRUCache\n\n    def test_evict__writes_only(self):\n        cache = MRUCache(maxsize=2)\n\n        cache[1] = 1\n        cache[2] = 2\n        cache[3] = 3  # Evicts 1 because nothing's been used yet\n\n        assert len(cache) == 2\n        assert 1 not in cache, \"Wrong key was evicted. Should have been '1'.\"\n        assert 2 in cache\n        assert 3 in cache\n\n    def test_evict__with_access(self):\n        cache = MRUCache(maxsize=2)\n\n        cache[1] = 1\n        cache[2] = 2\n        cache[1]\n        cache[2]\n        cache[3] = 3  # Evicts 2\n        assert 2 not in cache, \"Wrong key was evicted. Should have been '2'.\"\n        assert 1 in cache\n        assert 3 in cache\n\n    def test_evict__with_delete(self):\n        cache = MRUCache(maxsize=2)\n\n        cache[1] = 1\n        cache[2] = 2\n        del cache[2]\n        cache[3] = 3  # Doesn't evict anything because we just deleted 2\n\n        assert 2 not in cache\n        assert 1 in cache\n\n        cache[4] = 4  # Should evict 1 as we just accessed it with __contains__\n        assert 1 not in cache\n        assert 3 in cache\n        assert 4 in cache\n", "tests/test_cache.py": "import unittest\n\nimport cachetools\n\nfrom . import CacheTestMixin\n\n\nclass CacheTest(unittest.TestCase, CacheTestMixin):\n\n    Cache = cachetools.Cache\n", "tests/test_tlru.py": "import math\nimport unittest\n\nfrom cachetools import TLRUCache\n\nfrom . import CacheTestMixin\n\n\nclass Timer:\n    def __init__(self, auto=False):\n        self.auto = auto\n        self.time = 0\n\n    def __call__(self):\n        if self.auto:\n            self.time += 1\n        return self.time\n\n    def tick(self):\n        self.time += 1\n\n\nclass TLRUTestCache(TLRUCache):\n    def default_ttu(_key, _value, _time):\n        return math.inf\n\n    def __init__(self, maxsize, ttu=default_ttu, **kwargs):\n        TLRUCache.__init__(self, maxsize, ttu, timer=Timer(), **kwargs)\n\n\nclass TLRUCacheTest(unittest.TestCase, CacheTestMixin):\n\n    Cache = TLRUTestCache\n\n    def test_ttu(self):\n        cache = TLRUCache(maxsize=6, ttu=lambda _, v, t: t + v + 1, timer=Timer())\n        self.assertEqual(0, cache.timer())\n        self.assertEqual(3, cache.ttu(None, 1, 1))\n\n        cache[1] = 1\n        self.assertEqual(1, cache[1])\n        self.assertEqual(1, len(cache))\n        self.assertEqual({1}, set(cache))\n\n        cache.timer.tick()\n        self.assertEqual(1, cache[1])\n        self.assertEqual(1, len(cache))\n        self.assertEqual({1}, set(cache))\n\n        cache[2] = 2\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n        self.assertEqual(2, len(cache))\n        self.assertEqual({1, 2}, set(cache))\n\n        cache.timer.tick()\n        self.assertNotIn(1, cache)\n        self.assertEqual(2, cache[2])\n        self.assertEqual(1, len(cache))\n        self.assertEqual({2}, set(cache))\n\n        cache[3] = 3\n        self.assertNotIn(1, cache)\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n        self.assertEqual(2, len(cache))\n        self.assertEqual({2, 3}, set(cache))\n\n        cache.timer.tick()\n        self.assertNotIn(1, cache)\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n        self.assertEqual(2, len(cache))\n        self.assertEqual({2, 3}, set(cache))\n\n        cache[1] = 1\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n        self.assertEqual(3, len(cache))\n        self.assertEqual({1, 2, 3}, set(cache))\n\n        cache.timer.tick()\n        self.assertEqual(1, cache[1])\n        self.assertNotIn(2, cache)\n        self.assertEqual(3, cache[3])\n        self.assertEqual(2, len(cache))\n        self.assertEqual({1, 3}, set(cache))\n\n        cache.timer.tick()\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertEqual(3, cache[3])\n        self.assertEqual(1, len(cache))\n        self.assertEqual({3}, set(cache))\n\n        cache.timer.tick()\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertNotIn(3, cache)\n\n        with self.assertRaises(KeyError):\n            del cache[1]\n        with self.assertRaises(KeyError):\n            cache.pop(2)\n        with self.assertRaises(KeyError):\n            del cache[3]\n\n        self.assertEqual(0, len(cache))\n        self.assertEqual(set(), set(cache))\n\n    def test_ttu_lru(self):\n        cache = TLRUCache(maxsize=2, ttu=lambda k, v, t: t + 1, timer=Timer())\n        self.assertEqual(0, cache.timer())\n        self.assertEqual(2, cache.ttu(None, None, 1))\n\n        cache[1] = 1\n        cache[2] = 2\n        cache[3] = 3\n\n        self.assertEqual(len(cache), 2)\n        self.assertNotIn(1, cache)\n        self.assertEqual(cache[2], 2)\n        self.assertEqual(cache[3], 3)\n\n        cache[2]\n        cache[4] = 4\n        self.assertEqual(len(cache), 2)\n        self.assertNotIn(1, cache)\n        self.assertEqual(cache[2], 2)\n        self.assertNotIn(3, cache)\n        self.assertEqual(cache[4], 4)\n\n        cache[5] = 5\n        self.assertEqual(len(cache), 2)\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertNotIn(3, cache)\n        self.assertEqual(cache[4], 4)\n        self.assertEqual(cache[5], 5)\n\n    def test_ttu_expire(self):\n        cache = TLRUCache(maxsize=3, ttu=lambda k, v, t: t + 3, timer=Timer())\n        with cache.timer as time:\n            self.assertEqual(time, cache.timer())\n\n        cache[1] = 1\n        cache.timer.tick()\n        cache[2] = 2\n        cache.timer.tick()\n        cache[3] = 3\n        self.assertEqual(2, cache.timer())\n\n        self.assertEqual({1, 2, 3}, set(cache))\n        self.assertEqual(3, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n\n        cache.expire()\n        self.assertEqual({1, 2, 3}, set(cache))\n        self.assertEqual(3, len(cache))\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n\n        cache.expire(3)\n        self.assertEqual({2, 3}, set(cache))\n        self.assertEqual(2, len(cache))\n        self.assertNotIn(1, cache)\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n\n        cache.expire(4)\n        self.assertEqual({3}, set(cache))\n        self.assertEqual(1, len(cache))\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertEqual(3, cache[3])\n\n        cache.expire(5)\n        self.assertEqual(set(), set(cache))\n        self.assertEqual(0, len(cache))\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertNotIn(3, cache)\n\n    def test_ttu_expired(self):\n        cache = TLRUCache(maxsize=1, ttu=lambda k, _, t: t + k, timer=Timer())\n        cache[1] = None\n        self.assertEqual(cache[1], None)\n        self.assertEqual(1, len(cache))\n        cache[0] = None\n        self.assertNotIn(0, cache)\n        self.assertEqual(cache[1], None)\n        self.assertEqual(1, len(cache))\n        cache[-1] = None\n        self.assertNotIn(-1, cache)\n        self.assertNotIn(0, cache)\n        self.assertEqual(cache[1], None)\n        self.assertEqual(1, len(cache))\n\n    def test_ttu_atomic(self):\n        cache = TLRUCache(maxsize=1, ttu=lambda k, v, t: t + 2, timer=Timer(auto=True))\n        cache[1] = 1\n        self.assertEqual(1, cache[1])\n        cache[1] = 1\n        self.assertEqual(1, cache.get(1))\n        cache[1] = 1\n        self.assertEqual(1, cache.pop(1))\n        cache[1] = 1\n        self.assertEqual(1, cache.setdefault(1))\n        cache[1] = 1\n        cache.clear()\n        self.assertEqual(0, len(cache))\n\n    def test_ttu_tuple_key(self):\n        cache = TLRUCache(maxsize=1, ttu=lambda k, v, t: t + 1, timer=Timer())\n\n        cache[(1, 2, 3)] = 42\n        self.assertEqual(42, cache[(1, 2, 3)])\n        cache.timer.tick()\n        with self.assertRaises(KeyError):\n            cache[(1, 2, 3)]\n        self.assertNotIn((1, 2, 3), cache)\n\n    def test_ttu_reverse_insert(self):\n        cache = TLRUCache(maxsize=4, ttu=lambda k, v, t: t + v, timer=Timer())\n        self.assertEqual(0, cache.timer())\n\n        cache[3] = 3\n        cache[2] = 2\n        cache[1] = 1\n        cache[0] = 0\n\n        self.assertEqual({1, 2, 3}, set(cache))\n        self.assertEqual(3, len(cache))\n        self.assertNotIn(0, cache)\n        self.assertEqual(1, cache[1])\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n\n        cache.timer.tick()\n\n        self.assertEqual({2, 3}, set(cache))\n        self.assertEqual(2, len(cache))\n        self.assertNotIn(0, cache)\n        self.assertNotIn(1, cache)\n        self.assertEqual(2, cache[2])\n        self.assertEqual(3, cache[3])\n\n        cache.timer.tick()\n\n        self.assertEqual({3}, set(cache))\n        self.assertEqual(1, len(cache))\n        self.assertNotIn(0, cache)\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertEqual(3, cache[3])\n\n        cache.timer.tick()\n\n        self.assertEqual(set(), set(cache))\n        self.assertEqual(0, len(cache))\n        self.assertNotIn(0, cache)\n        self.assertNotIn(1, cache)\n        self.assertNotIn(2, cache)\n        self.assertNotIn(3, cache)\n", "src/cachetools/func.py": "\"\"\"`functools.lru_cache` compatible memoizing function decorators.\"\"\"\n\n__all__ = (\"fifo_cache\", \"lfu_cache\", \"lru_cache\", \"mru_cache\", \"rr_cache\", \"ttl_cache\")\n\nimport math\nimport random\nimport time\n\ntry:\n    from threading import RLock\nexcept ImportError:  # pragma: no cover\n    from dummy_threading import RLock\n\nfrom . import FIFOCache, LFUCache, LRUCache, MRUCache, RRCache, TTLCache\nfrom . import cached\nfrom . import keys\n\n\nclass _UnboundTTLCache(TTLCache):\n    def __init__(self, ttl, timer):\n        TTLCache.__init__(self, math.inf, ttl, timer)\n\n    @property\n    def maxsize(self):\n        return None\n\n\ndef _cache(cache, maxsize, typed):\n    def decorator(func):\n        key = keys.typedkey if typed else keys.hashkey\n        wrapper = cached(cache=cache, key=key, lock=RLock(), info=True)(func)\n        wrapper.cache_parameters = lambda: {\"maxsize\": maxsize, \"typed\": typed}\n        return wrapper\n\n    return decorator\n\n\ndef fifo_cache(maxsize=128, typed=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    up to `maxsize` results based on a First In First Out (FIFO)\n    algorithm.\n\n    \"\"\"\n    if maxsize is None:\n        return _cache({}, None, typed)\n    elif callable(maxsize):\n        return _cache(FIFOCache(128), 128, typed)(maxsize)\n    else:\n        return _cache(FIFOCache(maxsize), maxsize, typed)\n\n\ndef lfu_cache(maxsize=128, typed=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    up to `maxsize` results based on a Least Frequently Used (LFU)\n    algorithm.\n\n    \"\"\"\n    if maxsize is None:\n        return _cache({}, None, typed)\n    elif callable(maxsize):\n        return _cache(LFUCache(128), 128, typed)(maxsize)\n    else:\n        return _cache(LFUCache(maxsize), maxsize, typed)\n\n\ndef lru_cache(maxsize=128, typed=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    up to `maxsize` results based on a Least Recently Used (LRU)\n    algorithm.\n\n    \"\"\"\n    if maxsize is None:\n        return _cache({}, None, typed)\n    elif callable(maxsize):\n        return _cache(LRUCache(128), 128, typed)(maxsize)\n    else:\n        return _cache(LRUCache(maxsize), maxsize, typed)\n\n\ndef mru_cache(maxsize=128, typed=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    up to `maxsize` results based on a Most Recently Used (MRU)\n    algorithm.\n    \"\"\"\n    if maxsize is None:\n        return _cache({}, None, typed)\n    elif callable(maxsize):\n        return _cache(MRUCache(128), 128, typed)(maxsize)\n    else:\n        return _cache(MRUCache(maxsize), maxsize, typed)\n\n\ndef rr_cache(maxsize=128, choice=random.choice, typed=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    up to `maxsize` results based on a Random Replacement (RR)\n    algorithm.\n\n    \"\"\"\n    if maxsize is None:\n        return _cache({}, None, typed)\n    elif callable(maxsize):\n        return _cache(RRCache(128, choice), 128, typed)(maxsize)\n    else:\n        return _cache(RRCache(maxsize, choice), maxsize, typed)\n\n\ndef ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    up to `maxsize` results based on a Least Recently Used (LRU)\n    algorithm with a per-item time-to-live (TTL) value.\n    \"\"\"\n    if maxsize is None:\n        return _cache(_UnboundTTLCache(ttl, timer), None, typed)\n    elif callable(maxsize):\n        return _cache(TTLCache(128, ttl, timer), 128, typed)(maxsize)\n    else:\n        return _cache(TTLCache(maxsize, ttl, timer), maxsize, typed)\n", "src/cachetools/keys.py": "\"\"\"Key functions for memoizing decorators.\"\"\"\n\n__all__ = (\"hashkey\", \"methodkey\", \"typedkey\")\n\n\nclass _HashedTuple(tuple):\n    \"\"\"A tuple that ensures that hash() will be called no more than once\n    per element, since cache decorators will hash the key multiple\n    times on a cache miss.  See also _HashedSeq in the standard\n    library functools implementation.\n\n    \"\"\"\n\n    __hashvalue = None\n\n    def __hash__(self, hash=tuple.__hash__):\n        hashvalue = self.__hashvalue\n        if hashvalue is None:\n            self.__hashvalue = hashvalue = hash(self)\n        return hashvalue\n\n    def __add__(self, other, add=tuple.__add__):\n        return _HashedTuple(add(self, other))\n\n    def __radd__(self, other, add=tuple.__add__):\n        return _HashedTuple(add(other, self))\n\n    def __getstate__(self):\n        return {}\n\n\n# used for separating keyword arguments; we do not use an object\n# instance here so identity is preserved when pickling/unpickling\n_kwmark = (_HashedTuple,)\n\n\ndef hashkey(*args, **kwargs):\n    \"\"\"Return a cache key for the specified hashable arguments.\"\"\"\n\n    if kwargs:\n        return _HashedTuple(args + sum(sorted(kwargs.items()), _kwmark))\n    else:\n        return _HashedTuple(args)\n\n\ndef methodkey(self, *args, **kwargs):\n    \"\"\"Return a cache key for use with cached methods.\"\"\"\n    return hashkey(*args, **kwargs)\n\n\ndef typedkey(*args, **kwargs):\n    \"\"\"Return a typed cache key for the specified hashable arguments.\"\"\"\n\n    key = hashkey(*args, **kwargs)\n    key += tuple(type(v) for v in args)\n    key += tuple(type(v) for _, v in sorted(kwargs.items()))\n    return key\n", "src/cachetools/__init__.py": "\"\"\"Extensible memoizing collections and decorators.\"\"\"\n\n__all__ = (\n    \"Cache\",\n    \"FIFOCache\",\n    \"LFUCache\",\n    \"LRUCache\",\n    \"MRUCache\",\n    \"RRCache\",\n    \"TLRUCache\",\n    \"TTLCache\",\n    \"cached\",\n    \"cachedmethod\",\n)\n\n__version__ = \"5.3.3\"\n\nimport collections\nimport collections.abc\nimport functools\nimport heapq\nimport random\nimport time\n\nfrom . import keys\n\n\nclass _DefaultSize:\n\n    __slots__ = ()\n\n    def __getitem__(self, _):\n        return 1\n\n    def __setitem__(self, _, value):\n        assert value == 1\n\n    def pop(self, _):\n        return 1\n\n\nclass Cache(collections.abc.MutableMapping):\n    \"\"\"Mutable mapping to serve as a simple cache or cache base class.\"\"\"\n\n    __marker = object()\n\n    __size = _DefaultSize()\n\n    def __init__(self, maxsize, getsizeof=None):\n        if getsizeof:\n            self.getsizeof = getsizeof\n        if self.getsizeof is not Cache.getsizeof:\n            self.__size = dict()\n        self.__data = dict()\n        self.__currsize = 0\n        self.__maxsize = maxsize\n\n    def __repr__(self):\n        return \"%s(%s, maxsize=%r, currsize=%r)\" % (\n            self.__class__.__name__,\n            repr(self.__data),\n            self.__maxsize,\n            self.__currsize,\n        )\n\n    def __getitem__(self, key):\n        try:\n            return self.__data[key]\n        except KeyError:\n            return self.__missing__(key)\n\n    def __setitem__(self, key, value):\n        maxsize = self.__maxsize\n        size = self.getsizeof(value)\n        if size > maxsize:\n            raise ValueError(\"value too large\")\n        if key not in self.__data or self.__size[key] < size:\n            while self.__currsize + size > maxsize:\n                self.popitem()\n        if key in self.__data:\n            diffsize = size - self.__size[key]\n        else:\n            diffsize = size\n        self.__data[key] = value\n        self.__size[key] = size\n        self.__currsize += diffsize\n\n    def __delitem__(self, key):\n        size = self.__size.pop(key)\n        del self.__data[key]\n        self.__currsize -= size\n\n    def __contains__(self, key):\n        return key in self.__data\n\n    def __missing__(self, key):\n        raise KeyError(key)\n\n    def __iter__(self):\n        return iter(self.__data)\n\n    def __len__(self):\n        return len(self.__data)\n\n    def get(self, key, default=None):\n        if key in self:\n            return self[key]\n        else:\n            return default\n\n    def pop(self, key, default=__marker):\n        if key in self:\n            value = self[key]\n            del self[key]\n        elif default is self.__marker:\n            raise KeyError(key)\n        else:\n            value = default\n        return value\n\n    def setdefault(self, key, default=None):\n        if key in self:\n            value = self[key]\n        else:\n            self[key] = value = default\n        return value\n\n    @property\n    def maxsize(self):\n        \"\"\"The maximum size of the cache.\"\"\"\n        return self.__maxsize\n\n    @property\n    def currsize(self):\n        \"\"\"The current size of the cache.\"\"\"\n        return self.__currsize\n\n    @staticmethod\n    def getsizeof(value):\n        \"\"\"Return the size of a cache element's value.\"\"\"\n        return 1\n\n\nclass FIFOCache(Cache):\n    \"\"\"First In First Out (FIFO) cache implementation.\"\"\"\n\n    def __init__(self, maxsize, getsizeof=None):\n        Cache.__init__(self, maxsize, getsizeof)\n        self.__order = collections.OrderedDict()\n\n    def __setitem__(self, key, value, cache_setitem=Cache.__setitem__):\n        cache_setitem(self, key, value)\n        try:\n            self.__order.move_to_end(key)\n        except KeyError:\n            self.__order[key] = None\n\n    def __delitem__(self, key, cache_delitem=Cache.__delitem__):\n        cache_delitem(self, key)\n        del self.__order[key]\n\n    def popitem(self):\n        \"\"\"Remove and return the `(key, value)` pair first inserted.\"\"\"\n        try:\n            key = next(iter(self.__order))\n        except StopIteration:\n            raise KeyError(\"%s is empty\" % type(self).__name__) from None\n        else:\n            return (key, self.pop(key))\n\n\nclass LFUCache(Cache):\n    \"\"\"Least Frequently Used (LFU) cache implementation.\"\"\"\n\n    def __init__(self, maxsize, getsizeof=None):\n        Cache.__init__(self, maxsize, getsizeof)\n        self.__counter = collections.Counter()\n\n    def __getitem__(self, key, cache_getitem=Cache.__getitem__):\n        value = cache_getitem(self, key)\n        if key in self:  # __missing__ may not store item\n            self.__counter[key] -= 1\n        return value\n\n    def __setitem__(self, key, value, cache_setitem=Cache.__setitem__):\n        cache_setitem(self, key, value)\n        self.__counter[key] -= 1\n\n    def __delitem__(self, key, cache_delitem=Cache.__delitem__):\n        cache_delitem(self, key)\n        del self.__counter[key]\n\n    def popitem(self):\n        \"\"\"Remove and return the `(key, value)` pair least frequently used.\"\"\"\n        try:\n            ((key, _),) = self.__counter.most_common(1)\n        except ValueError:\n            raise KeyError(\"%s is empty\" % type(self).__name__) from None\n        else:\n            return (key, self.pop(key))\n\n\nclass LRUCache(Cache):\n    \"\"\"Least Recently Used (LRU) cache implementation.\"\"\"\n\n    def __init__(self, maxsize, getsizeof=None):\n        Cache.__init__(self, maxsize, getsizeof)\n        self.__order = collections.OrderedDict()\n\n    def __getitem__(self, key, cache_getitem=Cache.__getitem__):\n        value = cache_getitem(self, key)\n        if key in self:  # __missing__ may not store item\n            self.__update(key)\n        return value\n\n    def __setitem__(self, key, value, cache_setitem=Cache.__setitem__):\n        cache_setitem(self, key, value)\n        self.__update(key)\n\n    def __delitem__(self, key, cache_delitem=Cache.__delitem__):\n        cache_delitem(self, key)\n        del self.__order[key]\n\n    def popitem(self):\n        \"\"\"Remove and return the `(key, value)` pair least recently used.\"\"\"\n        try:\n            key = next(iter(self.__order))\n        except StopIteration:\n            raise KeyError(\"%s is empty\" % type(self).__name__) from None\n        else:\n            return (key, self.pop(key))\n\n    def __update(self, key):\n        try:\n            self.__order.move_to_end(key)\n        except KeyError:\n            self.__order[key] = None\n\n\nclass MRUCache(Cache):\n    \"\"\"Most Recently Used (MRU) cache implementation.\"\"\"\n\n    def __init__(self, maxsize, getsizeof=None):\n        Cache.__init__(self, maxsize, getsizeof)\n        self.__order = collections.OrderedDict()\n\n    def __getitem__(self, key, cache_getitem=Cache.__getitem__):\n        value = cache_getitem(self, key)\n        if key in self:  # __missing__ may not store item\n            self.__update(key)\n        return value\n\n    def __setitem__(self, key, value, cache_setitem=Cache.__setitem__):\n        cache_setitem(self, key, value)\n        self.__update(key)\n\n    def __delitem__(self, key, cache_delitem=Cache.__delitem__):\n        cache_delitem(self, key)\n        del self.__order[key]\n\n    def popitem(self):\n        \"\"\"Remove and return the `(key, value)` pair most recently used.\"\"\"\n        try:\n            key = next(iter(self.__order))\n        except StopIteration:\n            raise KeyError(\"%s is empty\" % type(self).__name__) from None\n        else:\n            return (key, self.pop(key))\n\n    def __update(self, key):\n        try:\n            self.__order.move_to_end(key, last=False)\n        except KeyError:\n            self.__order[key] = None\n\n\nclass RRCache(Cache):\n    \"\"\"Random Replacement (RR) cache implementation.\"\"\"\n\n    def __init__(self, maxsize, choice=random.choice, getsizeof=None):\n        Cache.__init__(self, maxsize, getsizeof)\n        self.__choice = choice\n\n    @property\n    def choice(self):\n        \"\"\"The `choice` function used by the cache.\"\"\"\n        return self.__choice\n\n    def popitem(self):\n        \"\"\"Remove and return a random `(key, value)` pair.\"\"\"\n        try:\n            key = self.__choice(list(self))\n        except IndexError:\n            raise KeyError(\"%s is empty\" % type(self).__name__) from None\n        else:\n            return (key, self.pop(key))\n\n\nclass _TimedCache(Cache):\n    \"\"\"Base class for time aware cache implementations.\"\"\"\n\n    class _Timer:\n        def __init__(self, timer):\n            self.__timer = timer\n            self.__nesting = 0\n\n        def __call__(self):\n            if self.__nesting == 0:\n                return self.__timer()\n            else:\n                return self.__time\n\n        def __enter__(self):\n            if self.__nesting == 0:\n                self.__time = time = self.__timer()\n            else:\n                time = self.__time\n            self.__nesting += 1\n            return time\n\n        def __exit__(self, *exc):\n            self.__nesting -= 1\n\n        def __reduce__(self):\n            return _TimedCache._Timer, (self.__timer,)\n\n        def __getattr__(self, name):\n            return getattr(self.__timer, name)\n\n    def __init__(self, maxsize, timer=time.monotonic, getsizeof=None):\n        Cache.__init__(self, maxsize, getsizeof)\n        self.__timer = _TimedCache._Timer(timer)\n\n    def __repr__(self, cache_repr=Cache.__repr__):\n        with self.__timer as time:\n            self.expire(time)\n            return cache_repr(self)\n\n    def __len__(self, cache_len=Cache.__len__):\n        with self.__timer as time:\n            self.expire(time)\n            return cache_len(self)\n\n    @property\n    def currsize(self):\n        with self.__timer as time:\n            self.expire(time)\n            return super().currsize\n\n    @property\n    def timer(self):\n        \"\"\"The timer function used by the cache.\"\"\"\n        return self.__timer\n\n    def clear(self):\n        with self.__timer as time:\n            self.expire(time)\n            Cache.clear(self)\n\n    def get(self, *args, **kwargs):\n        with self.__timer:\n            return Cache.get(self, *args, **kwargs)\n\n    def pop(self, *args, **kwargs):\n        with self.__timer:\n            return Cache.pop(self, *args, **kwargs)\n\n    def setdefault(self, *args, **kwargs):\n        with self.__timer:\n            return Cache.setdefault(self, *args, **kwargs)\n\n\nclass TTLCache(_TimedCache):\n    \"\"\"LRU Cache implementation with per-item time-to-live (TTL) value.\"\"\"\n\n    class _Link:\n\n        __slots__ = (\"key\", \"expires\", \"next\", \"prev\")\n\n        def __init__(self, key=None, expires=None):\n            self.key = key\n            self.expires = expires\n\n        def __reduce__(self):\n            return TTLCache._Link, (self.key, self.expires)\n\n        def unlink(self):\n            next = self.next\n            prev = self.prev\n            prev.next = next\n            next.prev = prev\n\n    def __init__(self, maxsize, ttl, timer=time.monotonic, getsizeof=None):\n        _TimedCache.__init__(self, maxsize, timer, getsizeof)\n        self.__root = root = TTLCache._Link()\n        root.prev = root.next = root\n        self.__links = collections.OrderedDict()\n        self.__ttl = ttl\n\n    def __contains__(self, key):\n        try:\n            link = self.__links[key]  # no reordering\n        except KeyError:\n            return False\n        else:\n            return self.timer() < link.expires\n\n    def __getitem__(self, key, cache_getitem=Cache.__getitem__):\n        try:\n            link = self.__getlink(key)\n        except KeyError:\n            expired = False\n        else:\n            expired = not (self.timer() < link.expires)\n        if expired:\n            return self.__missing__(key)\n        else:\n            return cache_getitem(self, key)\n\n    def __setitem__(self, key, value, cache_setitem=Cache.__setitem__):\n        with self.timer as time:\n            self.expire(time)\n            cache_setitem(self, key, value)\n        try:\n            link = self.__getlink(key)\n        except KeyError:\n            self.__links[key] = link = TTLCache._Link(key)\n        else:\n            link.unlink()\n        link.expires = time + self.__ttl\n        link.next = root = self.__root\n        link.prev = prev = root.prev\n        prev.next = root.prev = link\n\n    def __delitem__(self, key, cache_delitem=Cache.__delitem__):\n        cache_delitem(self, key)\n        link = self.__links.pop(key)\n        link.unlink()\n        if not (self.timer() < link.expires):\n            raise KeyError(key)\n\n    def __iter__(self):\n        root = self.__root\n        curr = root.next\n        while curr is not root:\n            # \"freeze\" time for iterator access\n            with self.timer as time:\n                if time < curr.expires:\n                    yield curr.key\n            curr = curr.next\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        root = self.__root\n        root.prev = root.next = root\n        for link in sorted(self.__links.values(), key=lambda obj: obj.expires):\n            link.next = root\n            link.prev = prev = root.prev\n            prev.next = root.prev = link\n        self.expire(self.timer())\n\n    @property\n    def ttl(self):\n        \"\"\"The time-to-live value of the cache's items.\"\"\"\n        return self.__ttl\n\n    def expire(self, time=None):\n        \"\"\"Remove expired items from the cache.\"\"\"\n        if time is None:\n            time = self.timer()\n        root = self.__root\n        curr = root.next\n        links = self.__links\n        cache_delitem = Cache.__delitem__\n        while curr is not root and not (time < curr.expires):\n            cache_delitem(self, curr.key)\n            del links[curr.key]\n            next = curr.next\n            curr.unlink()\n            curr = next\n\n    def popitem(self):\n        \"\"\"Remove and return the `(key, value)` pair least recently used that\n        has not already expired.\n\n        \"\"\"\n        with self.timer as time:\n            self.expire(time)\n            try:\n                key = next(iter(self.__links))\n            except StopIteration:\n                raise KeyError(\"%s is empty\" % type(self).__name__) from None\n            else:\n                return (key, self.pop(key))\n\n    def __getlink(self, key):\n        value = self.__links[key]\n        self.__links.move_to_end(key)\n        return value\n\n\nclass TLRUCache(_TimedCache):\n    \"\"\"Time aware Least Recently Used (TLRU) cache implementation.\"\"\"\n\n    @functools.total_ordering\n    class _Item:\n\n        __slots__ = (\"key\", \"expires\", \"removed\")\n\n        def __init__(self, key=None, expires=None):\n            self.key = key\n            self.expires = expires\n            self.removed = False\n\n        def __lt__(self, other):\n            return self.expires < other.expires\n\n    def __init__(self, maxsize, ttu, timer=time.monotonic, getsizeof=None):\n        _TimedCache.__init__(self, maxsize, timer, getsizeof)\n        self.__items = collections.OrderedDict()\n        self.__order = []\n        self.__ttu = ttu\n\n    def __contains__(self, key):\n        try:\n            item = self.__items[key]  # no reordering\n        except KeyError:\n            return False\n        else:\n            return self.timer() < item.expires\n\n    def __getitem__(self, key, cache_getitem=Cache.__getitem__):\n        try:\n            item = self.__getitem(key)\n        except KeyError:\n            expired = False\n        else:\n            expired = not (self.timer() < item.expires)\n        if expired:\n            return self.__missing__(key)\n        else:\n            return cache_getitem(self, key)\n\n    def __setitem__(self, key, value, cache_setitem=Cache.__setitem__):\n        with self.timer as time:\n            expires = self.__ttu(key, value, time)\n            if not (time < expires):\n                return  # skip expired items\n            self.expire(time)\n            cache_setitem(self, key, value)\n        # removing an existing item would break the heap structure, so\n        # only mark it as removed for now\n        try:\n            self.__getitem(key).removed = True\n        except KeyError:\n            pass\n        self.__items[key] = item = TLRUCache._Item(key, expires)\n        heapq.heappush(self.__order, item)\n\n    def __delitem__(self, key, cache_delitem=Cache.__delitem__):\n        with self.timer as time:\n            # no self.expire() for performance reasons, e.g. self.clear() [#67]\n            cache_delitem(self, key)\n        item = self.__items.pop(key)\n        item.removed = True\n        if not (time < item.expires):\n            raise KeyError(key)\n\n    def __iter__(self):\n        for curr in self.__order:\n            # \"freeze\" time for iterator access\n            with self.timer as time:\n                if time < curr.expires and not curr.removed:\n                    yield curr.key\n\n    @property\n    def ttu(self):\n        \"\"\"The local time-to-use function used by the cache.\"\"\"\n        return self.__ttu\n\n    def expire(self, time=None):\n        \"\"\"Remove expired items from the cache.\"\"\"\n        if time is None:\n            time = self.timer()\n        items = self.__items\n        order = self.__order\n        # clean up the heap if too many items are marked as removed\n        if len(order) > len(items) * 2:\n            self.__order = order = [item for item in order if not item.removed]\n            heapq.heapify(order)\n        cache_delitem = Cache.__delitem__\n        while order and (order[0].removed or not (time < order[0].expires)):\n            item = heapq.heappop(order)\n            if not item.removed:\n                cache_delitem(self, item.key)\n                del items[item.key]\n\n    def popitem(self):\n        \"\"\"Remove and return the `(key, value)` pair least recently used that\n        has not already expired.\n\n        \"\"\"\n        with self.timer as time:\n            self.expire(time)\n            try:\n                key = next(iter(self.__items))\n            except StopIteration:\n                raise KeyError(\"%s is empty\" % self.__class__.__name__) from None\n            else:\n                return (key, self.pop(key))\n\n    def __getitem(self, key):\n        value = self.__items[key]\n        self.__items.move_to_end(key)\n        return value\n\n\n_CacheInfo = collections.namedtuple(\n    \"CacheInfo\", [\"hits\", \"misses\", \"maxsize\", \"currsize\"]\n)\n\n\ndef cached(cache, key=keys.hashkey, lock=None, info=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    results in a cache.\n\n    \"\"\"\n\n    def decorator(func):\n        if info:\n            hits = misses = 0\n\n            if isinstance(cache, Cache):\n\n                def getinfo():\n                    nonlocal hits, misses\n                    return _CacheInfo(hits, misses, cache.maxsize, cache.currsize)\n\n            elif isinstance(cache, collections.abc.Mapping):\n\n                def getinfo():\n                    nonlocal hits, misses\n                    return _CacheInfo(hits, misses, None, len(cache))\n\n            else:\n\n                def getinfo():\n                    nonlocal hits, misses\n                    return _CacheInfo(hits, misses, 0, 0)\n\n            if cache is None:\n\n                def wrapper(*args, **kwargs):\n                    nonlocal misses\n                    misses += 1\n                    return func(*args, **kwargs)\n\n                def cache_clear():\n                    nonlocal hits, misses\n                    hits = misses = 0\n\n                cache_info = getinfo\n\n            elif lock is None:\n\n                def wrapper(*args, **kwargs):\n                    nonlocal hits, misses\n                    k = key(*args, **kwargs)\n                    try:\n                        result = cache[k]\n                        hits += 1\n                        return result\n                    except KeyError:\n                        misses += 1\n                    v = func(*args, **kwargs)\n                    try:\n                        cache[k] = v\n                    except ValueError:\n                        pass  # value too large\n                    return v\n\n                def cache_clear():\n                    nonlocal hits, misses\n                    cache.clear()\n                    hits = misses = 0\n\n                cache_info = getinfo\n\n            else:\n\n                def wrapper(*args, **kwargs):\n                    nonlocal hits, misses\n                    k = key(*args, **kwargs)\n                    try:\n                        with lock:\n                            result = cache[k]\n                            hits += 1\n                            return result\n                    except KeyError:\n                        with lock:\n                            misses += 1\n                    v = func(*args, **kwargs)\n                    # in case of a race, prefer the item already in the cache\n                    try:\n                        with lock:\n                            return cache.setdefault(k, v)\n                    except ValueError:\n                        return v  # value too large\n\n                def cache_clear():\n                    nonlocal hits, misses\n                    with lock:\n                        cache.clear()\n                        hits = misses = 0\n\n                def cache_info():\n                    with lock:\n                        return getinfo()\n\n        else:\n            if cache is None:\n\n                def wrapper(*args, **kwargs):\n                    return func(*args, **kwargs)\n\n                def cache_clear():\n                    pass\n\n            elif lock is None:\n\n                def wrapper(*args, **kwargs):\n                    k = key(*args, **kwargs)\n                    try:\n                        return cache[k]\n                    except KeyError:\n                        pass  # key not found\n                    v = func(*args, **kwargs)\n                    try:\n                        cache[k] = v\n                    except ValueError:\n                        pass  # value too large\n                    return v\n\n                def cache_clear():\n                    cache.clear()\n\n            else:\n\n                def wrapper(*args, **kwargs):\n                    k = key(*args, **kwargs)\n                    try:\n                        with lock:\n                            return cache[k]\n                    except KeyError:\n                        pass  # key not found\n                    v = func(*args, **kwargs)\n                    # in case of a race, prefer the item already in the cache\n                    try:\n                        with lock:\n                            return cache.setdefault(k, v)\n                    except ValueError:\n                        return v  # value too large\n\n                def cache_clear():\n                    with lock:\n                        cache.clear()\n\n            cache_info = None\n\n        wrapper.cache = cache\n        wrapper.cache_key = key\n        wrapper.cache_lock = lock\n        wrapper.cache_clear = cache_clear\n        wrapper.cache_info = cache_info\n\n        return functools.update_wrapper(wrapper, func)\n\n    return decorator\n\n\ndef cachedmethod(cache, key=keys.methodkey, lock=None):\n    \"\"\"Decorator to wrap a class or instance method with a memoizing\n    callable that saves results in a cache.\n\n    \"\"\"\n\n    def decorator(method):\n        if lock is None:\n\n            def wrapper(self, *args, **kwargs):\n                c = cache(self)\n                if c is None:\n                    return method(self, *args, **kwargs)\n                k = key(self, *args, **kwargs)\n                try:\n                    return c[k]\n                except KeyError:\n                    pass  # key not found\n                v = method(self, *args, **kwargs)\n                try:\n                    c[k] = v\n                except ValueError:\n                    pass  # value too large\n                return v\n\n            def clear(self):\n                c = cache(self)\n                if c is not None:\n                    c.clear()\n\n        else:\n\n            def wrapper(self, *args, **kwargs):\n                c = cache(self)\n                if c is None:\n                    return method(self, *args, **kwargs)\n                k = key(self, *args, **kwargs)\n                try:\n                    with lock(self):\n                        return c[k]\n                except KeyError:\n                    pass  # key not found\n                v = method(self, *args, **kwargs)\n                # in case of a race, prefer the item already in the cache\n                try:\n                    with lock(self):\n                        return c.setdefault(k, v)\n                except ValueError:\n                    return v  # value too large\n\n            def clear(self):\n                c = cache(self)\n                if c is not None:\n                    with lock(self):\n                        c.clear()\n\n        wrapper.cache = cache\n        wrapper.cache_key = key\n        wrapper.cache_lock = lock\n        wrapper.cache_clear = clear\n\n        return functools.update_wrapper(wrapper, method)\n\n    return decorator\n"}