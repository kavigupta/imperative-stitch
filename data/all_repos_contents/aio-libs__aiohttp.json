{"setup.py": "import os\nimport pathlib\nimport sys\n\nfrom setuptools import Extension, setup\n\nif sys.version_info < (3, 8):\n    raise RuntimeError(\"aiohttp 4.x requires Python 3.8+\")\n\n\nNO_EXTENSIONS: bool = bool(os.environ.get(\"AIOHTTP_NO_EXTENSIONS\"))\nHERE = pathlib.Path(__file__).parent\nIS_GIT_REPO = (HERE / \".git\").exists()\n\n\nif sys.implementation.name != \"cpython\":\n    NO_EXTENSIONS = True\n\n\nif IS_GIT_REPO and not (HERE / \"vendor/llhttp/README.md\").exists():\n    print(\"Install submodules when building from git clone\", file=sys.stderr)\n    print(\"Hint:\", file=sys.stderr)\n    print(\"  git submodule update --init\", file=sys.stderr)\n    sys.exit(2)\n\n\n# NOTE: makefile cythonizes all Cython modules\n\nextensions = [\n    Extension(\"aiohttp._websocket\", [\"aiohttp/_websocket.c\"]),\n    Extension(\n        \"aiohttp._http_parser\",\n        [\n            \"aiohttp/_http_parser.c\",\n            \"aiohttp/_find_header.c\",\n            \"vendor/llhttp/build/c/llhttp.c\",\n            \"vendor/llhttp/src/native/api.c\",\n            \"vendor/llhttp/src/native/http.c\",\n        ],\n        define_macros=[(\"LLHTTP_STRICT_MODE\", 0)],\n        include_dirs=[\"vendor/llhttp/build\"],\n    ),\n    Extension(\"aiohttp._helpers\", [\"aiohttp/_helpers.c\"]),\n    Extension(\"aiohttp._http_writer\", [\"aiohttp/_http_writer.c\"]),\n]\n\n\nbuild_type = \"Pure\" if NO_EXTENSIONS else \"Accelerated\"\nsetup_kwargs = {} if NO_EXTENSIONS else {\"ext_modules\": extensions}\n\nprint(\"*********************\", file=sys.stderr)\nprint(\"* {build_type} build *\".format_map(locals()), file=sys.stderr)\nprint(\"*********************\", file=sys.stderr)\nsetup(**setup_kwargs)\n", "tools/cleanup_changes.py": "#!/usr/bin/env python\n\n# Run me after the backport branch release to cleanup CHANGES records\n# that was backported and published.\n\nimport re\nimport subprocess\nfrom pathlib import Path\n\nALLOWED_SUFFIXES = (\n    \"bugfix\",\n    \"feature\",\n    \"deprecation\",\n    \"breaking\",\n    \"doc\",\n    \"packaging\",\n    \"contrib\",\n    \"misc\",\n)\nPATTERN = re.compile(\n    r\"(\\d+|[0-9a-f]{8}|[0-9a-f]{7}|[0-9a-f]{40})\\.(\"\n    + \"|\".join(ALLOWED_SUFFIXES)\n    + r\")(\\.\\d+)?(\\.rst)?\",\n)\n\n\ndef main():\n    root = Path(__file__).parent.parent\n    delete = []\n    changes = (root / \"CHANGES.rst\").read_text()\n    for fname in (root / \"CHANGES\").iterdir():\n        match = PATTERN.match(fname.name)\n        if match is not None:\n            commit_issue_or_pr = match.group(1)\n            tst_issue_or_pr = f\":issue:`{commit_issue_or_pr}`\"\n            tst_commit = f\":commit:`{commit_issue_or_pr}`\"\n            if tst_issue_or_pr in changes or tst_commit in changes:\n                subprocess.run([\"git\", \"rm\", fname])\n                delete.append(fname.name)\n    print(\"Deleted CHANGES records:\", \" \".join(delete))\n    print(\"Please verify and commit\")\n\n\nif __name__ == \"__main__\":\n    main()\n", "tools/gen.py": "#!/usr/bin/env python\n\nimport io\nimport pathlib\nfrom collections import defaultdict\n\nimport multidict\n\nROOT = pathlib.Path.cwd()\nwhile ROOT.parent != ROOT and not (ROOT / \".git\").exists():\n    ROOT = ROOT.parent\n\n\ndef calc_headers(root):\n    hdrs_file = root / \"aiohttp/hdrs.py\"\n    code = compile(hdrs_file.read_text(), str(hdrs_file), \"exec\")\n    globs = {}\n    exec(code, globs)\n    headers = [val for val in globs.values() if isinstance(val, multidict.istr)]\n    return sorted(headers)\n\n\nheaders = calc_headers(ROOT)\n\n\ndef factory():\n    return defaultdict(factory)\n\n\nTERMINAL = object()\n\n\ndef build(headers):\n    dct = defaultdict(factory)\n    for hdr in headers:\n        d = dct\n        for ch in hdr:\n            d = d[ch]\n        d[TERMINAL] = hdr\n    return dct\n\n\ndct = build(headers)\n\n\nHEADER = \"\"\"\\\n/*  The file is autogenerated from aiohttp/hdrs.py\nRun ./tools/gen.py to update it after the origin changing. */\n\n#include \"_find_header.h\"\n\n#define NEXT_CHAR() \\\\\n{ \\\\\n    count++; \\\\\n    if (count == size) { \\\\\n        /* end of search */ \\\\\n        return -1; \\\\\n    } \\\\\n    pchar++; \\\\\n    ch = *pchar; \\\\\n    last = (count == size -1); \\\\\n} while(0);\n\nint\nfind_header(const char *str, int size)\n{\n    char *pchar = str;\n    int last;\n    char ch;\n    int count = -1;\n    pchar--;\n\"\"\"\n\nBLOCK = \"\"\"\n{label}\n    NEXT_CHAR();\n    switch (ch) {{\n{cases}\n        default:\n            return -1;\n    }}\n\"\"\"\n\nCASE = \"\"\"\\\n        case '{char}':\n            if (last) {{\n                return {index};\n            }}\n            goto {next};\"\"\"\n\nFOOTER = \"\"\"\n{missing}\nmissing:\n    /* nothing found */\n    return -1;\n}}\n\"\"\"\n\n\ndef gen_prefix(prefix, k):\n    if k == \"-\":\n        return prefix + \"_\"\n    else:\n        return prefix + k.upper()\n\n\ndef gen_block(dct, prefix, used_blocks, missing, out):\n    cases = {}\n    for k, v in dct.items():\n        if k is TERMINAL:\n            continue\n        next_prefix = gen_prefix(prefix, k)\n        term = v.get(TERMINAL)\n        if term is not None:\n            index = headers.index(term)\n        else:\n            index = -1\n        hi = k.upper()\n        lo = k.lower()\n        case = CASE.format(char=hi, index=index, next=next_prefix)\n        cases[hi] = case\n        if lo != hi:\n            case = CASE.format(char=lo, index=index, next=next_prefix)\n            cases[lo] = case\n    label = prefix + \":\" if prefix else \"\"\n    if cases:\n        block = BLOCK.format(label=label, cases=\"\\n\".join(cases.values()))\n        out.write(block)\n    else:\n        missing.add(label)\n    for k, v in dct.items():\n        if not isinstance(v, defaultdict):\n            continue\n        block_name = gen_prefix(prefix, k)\n        if block_name in used_blocks:\n            continue\n        used_blocks.add(block_name)\n        gen_block(v, block_name, used_blocks, missing, out)\n\n\ndef gen(dct):\n    out = io.StringIO()\n    out.write(HEADER)\n    missing = set()\n    gen_block(dct, \"\", set(), missing, out)\n    missing_labels = \"\\n\".join(sorted(missing))\n    out.write(FOOTER.format(missing=missing_labels))\n    return out\n\n\ndef gen_headers(headers):\n    out = io.StringIO()\n    out.write(\"# The file is autogenerated from aiohttp/hdrs.py\\n\")\n    out.write(\"# Run ./tools/gen.py to update it after the origin changing.\")\n    out.write(\"\\n\\n\")\n    out.write(\"from . import hdrs\\n\")\n    out.write(\"cdef tuple headers = (\\n\")\n    for hdr in headers:\n        out.write(\"    hdrs.{},\\n\".format(hdr.upper().replace(\"-\", \"_\")))\n    out.write(\")\\n\")\n    return out\n\n\n# print(gen(dct).getvalue())\n# print(gen_headers(headers).getvalue())\n\n\nfolder = ROOT / \"aiohttp\"\n\nwith (folder / \"_find_header.c\").open(\"w\") as f:\n    f.write(gen(dct).getvalue())\n\nwith (folder / \"_headers.pxi\").open(\"w\") as f:\n    f.write(gen_headers(headers).getvalue())\n", "tools/check_changes.py": "#!/usr/bin/env python3\n\nimport re\nimport sys\nfrom pathlib import Path\n\nALLOWED_SUFFIXES = (\n    \"bugfix\",\n    \"feature\",\n    \"deprecation\",\n    \"breaking\",\n    \"doc\",\n    \"packaging\",\n    \"contrib\",\n    \"misc\",\n)\nPATTERN = re.compile(\n    r\"(\\d+|[0-9a-f]{8}|[0-9a-f]{7}|[0-9a-f]{40})\\.(\"\n    + \"|\".join(ALLOWED_SUFFIXES)\n    + r\")(\\.\\d+)?(\\.rst)?\",\n)\n\n\ndef get_root(script_path):\n    folder = script_path.resolve().parent\n    while not (folder / \".git\").exists():\n        folder = folder.parent\n        if folder == folder.anchor:\n            raise RuntimeError(\"git repo not found\")\n    return folder\n\n\ndef main(argv):\n    print('Check \"CHANGES\" folder... ', end=\"\", flush=True)\n    here = Path(argv[0])\n    root = get_root(here)\n    changes = root / \"CHANGES\"\n    failed = False\n    for fname in changes.iterdir():\n        if fname.name in (\".gitignore\", \".TEMPLATE.rst\", \"README.rst\"):\n            continue\n        if not PATTERN.match(fname.name):\n            if not failed:\n                print(\"\")\n            print(\"Illegal CHANGES record\", fname, file=sys.stderr)\n            failed = True\n\n    if failed:\n        print(\"\", file=sys.stderr)\n        print(\"See ./CHANGES/README.rst for the naming instructions\", file=sys.stderr)\n        print(\"\", file=sys.stderr)\n    else:\n        print(\"OK\")\n\n    return int(failed)\n\n\nif __name__ == \"__main__\":\n    sys.exit(main(sys.argv))\n", "tools/check_sum.py": "#!/usr/bin/env python\n\nimport argparse\nimport hashlib\nimport pathlib\nimport sys\n\nPARSER = argparse.ArgumentParser(\n    description=\"Helper for check file hashes in Makefile instead of bare timestamps\"\n)\nPARSER.add_argument(\"dst\", metavar=\"DST\", type=pathlib.Path)\nPARSER.add_argument(\"-d\", \"--debug\", action=\"store_true\", default=False)\n\n\ndef main(argv):\n    args = PARSER.parse_args(argv)\n    dst = args.dst\n    assert dst.suffix == \".hash\"\n    dirname = dst.parent\n    if dirname.name != \".hash\":\n        if args.debug:\n            print(f\"Invalid name {dst} -> dirname {dirname}\", file=sys.stderr)\n        return 0\n    dirname.mkdir(exist_ok=True)\n    src_dir = dirname.parent\n    src_name = dst.stem  # drop .hash\n    full_src = src_dir / src_name\n    hasher = hashlib.sha256()\n    try:\n        hasher.update(full_src.read_bytes())\n    except OSError:\n        if args.debug:\n            print(f\"Cannot open {full_src}\", file=sys.stderr)\n        return 0\n    src_hash = hasher.hexdigest()\n    if dst.exists():\n        dst_hash = dst.read_text()\n    else:\n        dst_hash = \"\"\n    if src_hash != dst_hash:\n        dst.write_text(src_hash)\n        print(f\"re-hash {src_hash}\")\n    else:\n        if args.debug:\n            print(f\"Skip {src_hash} checksum, up-to-date\")\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main(sys.argv[1:]))\n", "tools/bench-asyncio-write.py": "import asyncio\nimport atexit\nimport math\nimport os\nimport signal\nfrom typing import List, Tuple\n\nPORT = 8888\n\nserver = os.fork()\nif server == 0:\n    loop = asyncio.get_event_loop()\n    coro = asyncio.start_server(lambda *_: None, port=PORT)\n    loop.run_until_complete(coro)\n    loop.run_forever()\nelse:\n    atexit.register(os.kill, server, signal.SIGTERM)\n\n\nasync def write_joined_bytearray(writer, chunks):\n    body = bytearray(chunks[0])\n    for c in chunks[1:]:\n        body += c\n    writer.write(body)\n\n\nasync def write_joined_list(writer, chunks):\n    body = b\"\".join(chunks)\n    writer.write(body)\n\n\nasync def write_separately(writer, chunks):\n    for c in chunks:\n        writer.write(c)\n\n\ndef fm_size(s, _fms=(\"\", \"K\", \"M\", \"G\")):\n    i = 0\n    while s >= 1024:\n        s /= 1024\n        i += 1\n    return f\"{s:.0f}{_fms[i]}B\"\n\n\ndef fm_time(s, _fms=(\"\", \"m\", \"\u00b5\", \"n\")):\n    if s == 0:\n        return \"0\"\n    i = 0\n    while s < 1:\n        s *= 1000\n        i += 1\n    return f\"{s:.2f}{_fms[i]}s\"\n\n\ndef _job(j: List[int]) -> Tuple[str, List[bytes]]:\n    # Always start with a 256B headers chunk\n    body = [b\"0\" * s for s in [256] + list(j)]\n    job_title = f\"{fm_size(sum(j))} / {len(j)}\"\n    return (job_title, body)\n\n\nwrites = [\n    (\"b''.join\", write_joined_list),\n    (\"bytearray\", write_joined_bytearray),\n    (\"multiple writes\", write_separately),\n]\n\nbodies = (\n    [],\n    [10 * 2**0],\n    [10 * 2**7],\n    [10 * 2**17],\n    [10 * 2**27],\n    [50 * 2**27],\n    [1 * 2**0 for _ in range(10)],\n    [1 * 2**7 for _ in range(10)],\n    [1 * 2**17 for _ in range(10)],\n    [1 * 2**27 for _ in range(10)],\n    [10 * 2**27 for _ in range(5)],\n)\n\n\njobs = [_job(j) for j in bodies]\n\n\nasync def time(loop, fn, *args):\n    spent = []\n    while not spent or sum(spent) < 0.2:\n        s = loop.time()\n        await fn(*args)\n        e = loop.time()\n        spent.append(e - s)\n    mean = sum(spent) / len(spent)\n    sd = sum((x - mean) ** 2 for x in spent) / len(spent)\n    return len(spent), mean, math.sqrt(sd)\n\n\nasync def main(loop):\n    _, writer = await asyncio.open_connection(port=PORT)\n    print(\"Loop:\", loop)\n    print(\"Transport:\", writer._transport)\n    res = [\n        (\"size/chunks\", \"Write option\", \"Mean\", \"Std dev\", \"loops\", \"Variation\"),\n    ]\n    res.append([\":---\", \":---\", \"---:\", \"---:\", \"---:\", \"---:\"])\n\n    async def bench(job_title, w, body, base=None):\n        it, mean, sd = await time(loop, w[1], writer, c)\n        res.append(\n            (\n                job_title,\n                w[0],\n                fm_time(mean),\n                fm_time(sd),\n                str(it),\n                f\"{mean / base - 1:.2%}\" if base is not None else \"\",\n            )\n        )\n        return mean\n\n    for t, c in jobs:\n        print(\"Doing\", t)\n        base = await bench(t, writes[0], c)\n        for w in writes[1:]:\n            await bench(\"\", w, c, base)\n    return res\n\n\nloop = asyncio.get_event_loop()\nresults = loop.run_until_complete(main(loop))\nwith open(\"bench.md\", \"w\") as f:\n    for line in results:\n        f.write(\"| {} |\\n\".format(\" | \".join(line)))\n", "docs/conf.py": "#!/usr/bin/env python3\n#\n# aiohttp documentation build configuration file, created by\n# sphinx-quickstart on Wed Mar  5 12:35:35 2014.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport os\nimport re\nfrom pathlib import Path\n\nPROJECT_ROOT_DIR = Path(__file__).parents[1].resolve()\nIS_RELEASE_ON_RTD = (\n    os.getenv(\"READTHEDOCS\", \"False\") == \"True\"\n    and os.environ[\"READTHEDOCS_VERSION_TYPE\"] == \"tag\"\n)\nif IS_RELEASE_ON_RTD:\n    tags.add(\"is_release\")\n\n_docs_path = os.path.dirname(__file__)\n_version_path = os.path.abspath(\n    os.path.join(_docs_path, \"..\", \"aiohttp\", \"__init__.py\")\n)\nwith open(_version_path, encoding=\"latin1\") as fp:\n    try:\n        _version_info = re.search(\n            r'^__version__ = \"'\n            r\"(?P<major>\\d+)\"\n            r\"\\.(?P<minor>\\d+)\"\n            r\"\\.(?P<patch>\\d+)\"\n            r'(?P<tag>.*)?\"$',\n            fp.read(),\n            re.M,\n        ).groupdict()\n    except IndexError:\n        raise RuntimeError(\"Unable to determine version.\")\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    # stdlib-party extensions:\n    \"sphinx.ext.extlinks\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.viewcode\",\n    # Third-party extensions:\n    \"sphinxcontrib.blockdiag\",\n    \"sphinxcontrib.towncrier\",  # provides `towncrier-draft-entries` directive\n]\n\n\ntry:\n    import sphinxcontrib.spelling  # noqa\n\n    extensions.append(\"sphinxcontrib.spelling\")\nexcept ImportError:\n    pass\n\n\nintersphinx_mapping = {\n    \"pytest\": (\"http://docs.pytest.org/en/latest/\", None),\n    \"python\": (\"http://docs.python.org/3\", None),\n    \"multidict\": (\"https://multidict.readthedocs.io/en/stable/\", None),\n    \"yarl\": (\"https://yarl.readthedocs.io/en/stable/\", None),\n    \"aiosignal\": (\"https://aiosignal.readthedocs.io/en/stable/\", None),\n    \"aiohttpjinja2\": (\"https://aiohttp-jinja2.readthedocs.io/en/stable/\", None),\n    \"aiohttpremotes\": (\"https://aiohttp-remotes.readthedocs.io/en/stable/\", None),\n    \"aiohttpsession\": (\"https://aiohttp-session.readthedocs.io/en/stable/\", None),\n    \"aiohttpdemos\": (\"https://aiohttp-demos.readthedocs.io/en/latest/\", None),\n    \"aiojobs\": (\"https://aiojobs.readthedocs.io/en/stable/\", None),\n}\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# The suffix of source filenames.\nsource_suffix = \".rst\"\n\n# The encoding of source files.\n# source_encoding = 'utf-8-sig'\n\n# The master toctree document.\nmaster_doc = \"index\"\n\n# -- Project information -----------------------------------------------------\n\ngithub_url = \"https://github.com\"\ngithub_repo_org = \"aio-libs\"\ngithub_repo_name = \"aiohttp\"\ngithub_repo_slug = f\"{github_repo_org}/{github_repo_name}\"\ngithub_repo_url = f\"{github_url}/{github_repo_slug}\"\ngithub_sponsors_url = f\"{github_url}/sponsors\"\n\nproject = github_repo_name\ncopyright = f\"{project} contributors\"\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = \"{major}.{minor}\".format(**_version_info)\n# The full version, including alpha/beta/rc tags.\nrelease = \"{major}.{minor}.{patch}{tag}\".format(**_version_info)\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n# language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n# today = ''\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = '%B %d, %Y'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\"_build\"]\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n# default_role = None\n\n# If true, '()' will be appended to :func: etc. cross-reference text.\n# add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\n# pygments_style = 'sphinx'\n\n# The default language to highlight source code in.\nhighlight_language = \"python3\"\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as \"system message\" paragraphs in the built documents.\n# keep_warnings = False\n\n\n# -- Extension configuration -------------------------------------------------\n\n# -- Options for extlinks extension ---------------------------------------\nextlinks = {\n    \"issue\": (f\"{github_repo_url}/issues/%s\", \"#%s\"),\n    \"pr\": (f\"{github_repo_url}/pull/%s\", \"PR #%s\"),\n    \"commit\": (f\"{github_repo_url}/commit/%s\", \"%s\"),\n    \"gh\": (f\"{github_url}/%s\", \"GitHub: %s\"),\n    \"user\": (f\"{github_sponsors_url}/%s\", \"@%s\"),\n}\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \"aiohttp_theme\"\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\nhtml_theme_options = {\n    \"description\": \"Async HTTP client/server for asyncio and Python\",\n    \"canonical_url\": \"http://docs.aiohttp.org/en/stable/\",\n    \"github_user\": github_repo_org,\n    \"github_repo\": github_repo_name,\n    \"github_button\": True,\n    \"github_type\": \"star\",\n    \"github_banner\": True,\n    \"badges\": [\n        {\n            \"image\": f\"{github_repo_url}/workflows/CI/badge.svg\",\n            \"target\": f\"{github_repo_url}/actions?query=workflow%3ACI\",\n            \"height\": \"20\",\n            \"alt\": \"Azure Pipelines CI status\",\n        },\n        {\n            \"image\": f\"https://codecov.io/github/{github_repo_slug}/coverage.svg?branch=master\",\n            \"target\": f\"https://codecov.io/github/{github_repo_slug}\",\n            \"height\": \"20\",\n            \"alt\": \"Code coverage status\",\n        },\n        {\n            \"image\": f\"https://badge.fury.io/py/{project}.svg\",\n            \"target\": f\"https://badge.fury.io/py/{project}\",\n            \"height\": \"20\",\n            \"alt\": \"Latest PyPI package version\",\n        },\n        {\n            \"image\": \"https://badges.gitter.im/Join%20Chat.svg\",\n            \"target\": f\"https://gitter.im/{github_repo_org}/Lobby\",\n            \"height\": \"20\",\n            \"alt\": \"Chat on Gitter\",\n        },\n    ],\n}\n\nhtml_css_files = [\n    \"css/logo-adjustments.css\",\n]\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = [alabaster.get_path()]\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n# html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\nhtml_logo = \"aiohttp-plain.svg\"\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\nhtml_favicon = \"favicon.ico\"\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n# html_extra_path = []\n\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n# html_last_updated_fmt = '%b %d, %Y'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\nhtml_sidebars = {\n    \"**\": [\n        \"about.html\",\n        \"navigation.html\",\n        \"searchbox.html\",\n    ]\n}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n# html_show_sourcelink = True\n\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n# html_show_sphinx = True\n\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n# html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = ''\n\n# This is the file name suffix for HTML files (e.g. \".xhtml\").\n# html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = f\"{project}doc\"\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    # 'preamble': '',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (\n        \"index\",\n        f\"{project}.tex\",\n        f\"{project} Documentation\",\n        f\"{project} contributors\",\n        \"manual\",\n    ),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# If false, no module index is generated.\n# latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(\"index\", project, f\"{project} Documentation\", [project], 1)]\n\n# If true, show URL addresses after external links.\n# man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        \"index\",\n        project,\n        f\"{project} Documentation\",\n        \"Aiohttp contributors\",\n        project,\n        \"One line description of project.\",\n        \"Miscellaneous\",\n    ),\n]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n# texinfo_show_urls = 'footnote'\n\n# If true, do not generate a @detailmenu in the \"Top\" node's menu.\n# texinfo_no_detailmenu = False\n\n\n# -------------------------------------------------------------------------\nnitpicky = True\nnitpick_ignore = [\n    (\"py:mod\", \"aiohttp\"),  # undocumented, no `.. currentmodule:: aiohttp` in docs\n    (\"py:class\", \"aiohttp.SimpleCookie\"),  # undocumented\n    (\"py:class\", \"aiohttp.web.RequestHandler\"),  # undocumented\n    (\"py:class\", \"aiohttp.NamedPipeConnector\"),  # undocumented\n    (\"py:class\", \"aiohttp.protocol.HttpVersion\"),  # undocumented\n    (\"py:class\", \"aiohttp.ClientRequest\"),  # undocumented\n    (\"py:class\", \"aiohttp.payload.Payload\"),  # undocumented\n    (\"py:class\", \"aiohttp.resolver.AsyncResolver\"),  # undocumented\n    (\"py:class\", \"aiohttp.resolver.ThreadedResolver\"),  # undocumented\n    (\"py:func\", \"aiohttp.ws_connect\"),  # undocumented\n    (\"py:meth\", \"start\"),  # undocumented\n    (\"py:exc\", \"aiohttp.ClientHttpProxyError\"),  # undocumented\n    (\"py:class\", \"asyncio.AbstractServer\"),  # undocumented\n    (\"py:mod\", \"aiohttp.test_tools\"),  # undocumented\n    (\"py:class\", \"list of pairs\"),  # undocumented\n    (\"py:class\", \"aiohttp.protocol.HttpVersion\"),  # undocumented\n    (\"py:meth\", \"aiohttp.ClientSession.request\"),  # undocumented\n    (\"py:class\", \"aiohttp.StreamWriter\"),  # undocumented\n    (\"py:attr\", \"aiohttp.StreamResponse.body\"),  # undocumented\n    (\"py:class\", \"aiohttp.payload.StringPayload\"),  # undocumented\n    (\"py:meth\", \"aiohttp.web.Application.copy\"),  # undocumented\n    (\"py:meth\", \"asyncio.AbstractEventLoop.create_server\"),  # undocumented\n    (\"py:data\", \"aiohttp.log.server_logger\"),  # undocumented\n    (\"py:data\", \"aiohttp.log.access_logger\"),  # undocumented\n    (\"py:data\", \"aiohttp.helpers.AccessLogger\"),  # undocumented\n    (\"py:attr\", \"helpers.AccessLogger.LOG_FORMAT\"),  # undocumented\n    (\"py:meth\", \"aiohttp.web.AbstractRoute.url\"),  # undocumented\n    (\"py:class\", \"aiohttp.web.MatchedSubAppResource\"),  # undocumented\n    (\"py:attr\", \"body\"),  # undocumented\n    (\"py:class\", \"socket.socket\"),  # undocumented\n    (\"py:class\", \"socket.AddressFamily\"),  # undocumented\n    (\"py:obj\", \"logging.DEBUG\"),  # undocumented\n    (\"py:class\", \"aiohttp.abc.AbstractAsyncAccessLogger\"),  # undocumented\n    (\"py:meth\", \"aiohttp.web.Response.write_eof\"),  # undocumented\n    (\"py:meth\", \"aiohttp.payload.Payload.set_content_disposition\"),  # undocumented\n    (\"py:class\", \"cgi.FieldStorage\"),  # undocumented\n    (\"py:meth\", \"aiohttp.web.UrlDispatcher.register_resource\"),  # undocumented\n    (\"py:func\", \"aiohttp_debugtoolbar.setup\"),  # undocumented\n]\n\n# -- Options for towncrier_draft extension -----------------------------------\n\ntowncrier_draft_autoversion_mode = \"draft\"  # or: 'sphinx-version', 'sphinx-release'\ntowncrier_draft_include_empty = True\ntowncrier_draft_working_directory = PROJECT_ROOT_DIR\n# Not yet supported: towncrier_draft_config_path = 'pyproject.toml'  # relative to cwd\n", "tests/test_proxy_functional.py": "# type: ignore\nimport asyncio\nimport os\nimport pathlib\nimport ssl\nimport sys\nfrom re import match as match_regex\nfrom typing import Any\nfrom unittest import mock\nfrom uuid import uuid4\n\nimport proxy\nimport pytest\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp import web\nfrom aiohttp.client_exceptions import ClientConnectionError\n\nASYNCIO_SUPPORTS_TLS_IN_TLS = sys.version_info >= (3, 11)\n\n\n@pytest.fixture\ndef secure_proxy_url(tls_certificate_pem_path):\n    \"\"\"Return the URL of an instance of a running secure proxy.\n\n    This fixture also spawns that instance and tears it down after the test.\n    \"\"\"\n    proxypy_args = [\n        # --threadless does not work on windows, see\n        # https://github.com/abhinavsingh/proxy.py/issues/492\n        \"--threaded\" if os.name == \"nt\" else \"--threadless\",\n        \"--num-workers\",\n        \"1\",  # the tests only send one query anyway\n        \"--hostname\",\n        \"127.0.0.1\",  # network interface to listen to\n        \"--port\",\n        0,  # ephemeral port, so that kernel allocates a free one\n        \"--cert-file\",\n        tls_certificate_pem_path,  # contains both key and cert\n        \"--key-file\",\n        tls_certificate_pem_path,  # contains both key and cert\n    ]\n\n    with proxy.Proxy(input_args=proxypy_args) as proxy_instance:\n        yield URL.build(\n            scheme=\"https\",\n            host=str(proxy_instance.flags.hostname),\n            port=proxy_instance.flags.port,\n        )\n\n\n@pytest.fixture\ndef web_server_endpoint_payload():\n    return str(uuid4())\n\n\n@pytest.fixture(params=(\"http\", \"https\"))\ndef web_server_endpoint_type(request):\n    return request.param\n\n\n@pytest.fixture\nasync def web_server_endpoint_url(\n    aiohttp_server,\n    ssl_ctx,\n    web_server_endpoint_payload,\n    web_server_endpoint_type,\n):\n    server_kwargs = (\n        {\n            \"ssl\": ssl_ctx,\n        }\n        if web_server_endpoint_type == \"https\"\n        else {}\n    )\n\n    async def handler(*args, **kwargs):\n        return web.Response(text=web_server_endpoint_payload)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app, **server_kwargs)\n\n    return URL.build(\n        scheme=web_server_endpoint_type,\n        host=server.host,\n        port=server.port,\n    )\n\n\n@pytest.mark.skipif(\n    not ASYNCIO_SUPPORTS_TLS_IN_TLS,\n    reason=\"asyncio on this python does not support TLS in TLS\",\n)\n@pytest.mark.parametrize(\"web_server_endpoint_type\", (\"http\", \"https\"))\n@pytest.mark.filterwarnings(r\"ignore:.*ssl.OP_NO_SSL*\")\n# Filter out the warning from\n# https://github.com/abhinavsingh/proxy.py/blob/30574fd0414005dfa8792a6e797023e862bdcf43/proxy/common/utils.py#L226\n# otherwise this test will fail because the proxy will die with an error.\nasync def test_secure_https_proxy_absolute_path(\n    client_ssl_ctx: ssl.SSLContext,\n    secure_proxy_url: URL,\n    web_server_endpoint_url: str,\n    web_server_endpoint_payload: str,\n) -> None:\n    \"\"\"Ensure HTTP(S) sites are accessible through a secure proxy.\"\"\"\n    conn = aiohttp.TCPConnector()\n    sess = aiohttp.ClientSession(connector=conn)\n\n    async with sess.get(\n        web_server_endpoint_url,\n        proxy=secure_proxy_url,\n        ssl=client_ssl_ctx,  # used for both proxy and endpoint connections\n    ) as response:\n        assert response.status == 200\n        assert await response.text() == web_server_endpoint_payload\n\n    await sess.close()\n    await conn.close()\n\n\n@pytest.mark.parametrize(\"web_server_endpoint_type\", (\"https\",))\n@pytest.mark.usefixtures(\"loop\")\n@pytest.mark.skipif(\n    ASYNCIO_SUPPORTS_TLS_IN_TLS, reason=\"asyncio on this python supports TLS in TLS\"\n)\n@pytest.mark.filterwarnings(r\"ignore:.*ssl.OP_NO_SSL*\")\n# Filter out the warning from\n# https://github.com/abhinavsingh/proxy.py/blob/30574fd0414005dfa8792a6e797023e862bdcf43/proxy/common/utils.py#L226\n# otherwise this test will fail because the proxy will die with an error.\nasync def test_https_proxy_unsupported_tls_in_tls(\n    client_ssl_ctx: ssl.SSLContext,\n    secure_proxy_url: URL,\n    web_server_endpoint_type: str,\n) -> None:\n    \"\"\"Ensure connecting to TLS endpoints w/ HTTPS proxy needs patching.\n\n    This also checks that a helpful warning on how to patch the env\n    is displayed.\n    \"\"\"\n    url = URL.build(scheme=web_server_endpoint_type, host=\"python.org\")\n\n    escaped_host_port = \":\".join((url.host.replace(\".\", r\"\\.\"), str(url.port)))\n    escaped_proxy_url = str(secure_proxy_url).replace(\".\", r\"\\.\")\n\n    conn = aiohttp.TCPConnector()\n    sess = aiohttp.ClientSession(connector=conn)\n\n    expected_warning_text = (\n        r\"^\"\n        r\"An HTTPS request is being sent through an HTTPS proxy\\. \"\n        \"This support for TLS in TLS is known to be disabled \"\n        r\"in the stdlib asyncio\\. This is why you'll probably see \"\n        r\"an error in the log below\\.\\n\\n\"\n        r\"It is possible to enable it via monkeypatching\\. \"\n        r\"For more details, see:\\n\"\n        r\"\\* https://bugs\\.python\\.org/issue37179\\n\"\n        r\"\\* https://github\\.com/python/cpython/pull/28073\\n\\n\"\n        r\"You can temporarily patch this as follows:\\n\"\n        r\"\\* https://docs\\.aiohttp\\.org/en/stable/client_advanced\\.html#proxy-support\\n\"\n        r\"\\* https://github\\.com/aio-libs/aiohttp/discussions/6044\\n$\"\n    )\n    type_err = (\n        r\"transport <asyncio\\.sslproto\\._SSLProtocolTransport object at \"\n        r\"0x[\\d\\w]+> is not supported by start_tls\\(\\)\"\n    )\n    expected_exception_reason = (\n        r\"^\"\n        \"Cannot initialize a TLS-in-TLS connection to host \"\n        f\"{escaped_host_port!s} through an underlying connection \"\n        f\"to an HTTPS proxy {escaped_proxy_url!s} ssl:{client_ssl_ctx!s} \"\n        f\"[{type_err!s}]\"\n        r\"$\"\n    )\n\n    with pytest.warns(\n        RuntimeWarning,\n        match=expected_warning_text,\n    ), pytest.raises(\n        ClientConnectionError,\n        match=expected_exception_reason,\n    ) as conn_err:\n        async with sess.get(url, proxy=secure_proxy_url, ssl=client_ssl_ctx):\n            pass\n\n    assert isinstance(conn_err.value.__cause__, TypeError)\n    assert match_regex(f\"^{type_err!s}$\", str(conn_err.value.__cause__))\n\n    await sess.close()\n    await conn.close()\n\n\n@pytest.fixture\ndef proxy_test_server(aiohttp_raw_server: Any, loop: Any, monkeypatch: Any):\n    # Handle all proxy requests and imitate remote server response.\n\n    _patch_ssl_transport(monkeypatch)\n\n    default_response = dict(status=200, headers=None, body=None)\n\n    proxy_mock = mock.Mock()\n\n    async def proxy_handler(request):\n        proxy_mock.request = request\n        proxy_mock.requests_list.append(request)\n\n        response = default_response.copy()\n        if isinstance(proxy_mock.return_value, dict):\n            response.update(proxy_mock.return_value)\n\n        headers = response[\"headers\"]\n        if not headers:\n            headers = {}\n\n        if request.method == \"CONNECT\":\n            response[\"body\"] = None\n\n        response[\"headers\"] = headers\n\n        resp = web.Response(**response)\n        await resp.prepare(request)\n        await resp.write_eof()\n        return resp\n\n    async def proxy_server():\n        proxy_mock.request = None\n        proxy_mock.auth = None\n        proxy_mock.requests_list = []\n\n        server = await aiohttp_raw_server(proxy_handler)\n\n        proxy_mock.server = server\n        proxy_mock.url = server.make_url(\"/\")\n\n        return proxy_mock\n\n    return proxy_server\n\n\n@pytest.fixture()\ndef get_request(loop: Any):\n    async def _request(method=\"GET\", *, url, trust_env=False, **kwargs):\n        connector = aiohttp.TCPConnector(ssl=False)\n        async with aiohttp.ClientSession(\n            connector=connector, trust_env=trust_env\n        ) as client:\n            async with client.request(method, url, **kwargs) as resp:\n                return resp\n\n    return _request\n\n\nasync def test_proxy_http_absolute_path(\n    proxy_test_server: Any, get_request: Any\n) -> None:\n    url = \"http://aiohttp.io/path?query=yes\"\n    proxy = await proxy_test_server()\n\n    await get_request(url=url, proxy=proxy.url)\n\n    assert len(proxy.requests_list) == 1\n    assert proxy.request.method == \"GET\"\n    assert proxy.request.host == \"aiohttp.io\"\n    assert proxy.request.path_qs == \"/path?query=yes\"\n\n\nasync def test_proxy_http_raw_path(proxy_test_server: Any, get_request: Any) -> None:\n    url = \"http://aiohttp.io:2561/space sheep?q=can:fly\"\n    raw_url = \"/space%20sheep?q=can:fly\"\n    proxy = await proxy_test_server()\n\n    await get_request(url=url, proxy=proxy.url)\n\n    assert proxy.request.host == \"aiohttp.io\"\n    assert proxy.request.path_qs == raw_url\n\n\nasync def test_proxy_http_idna_support(\n    proxy_test_server: Any, get_request: Any\n) -> None:\n    url = \"http://\u00e9\u00e9.com/\"\n    proxy = await proxy_test_server()\n\n    await get_request(url=url, proxy=proxy.url)\n\n    assert proxy.request.host == \"\u00e9\u00e9.com\"\n    assert proxy.request.path_qs == \"/\"\n\n\nasync def test_proxy_http_connection_error(get_request: Any) -> None:\n    url = \"http://aiohttp.io/path\"\n    proxy_url = \"http://localhost:2242/\"\n\n    with pytest.raises(aiohttp.ClientConnectorError):\n        await get_request(url=url, proxy=proxy_url)\n\n\nasync def test_proxy_http_bad_response(\n    proxy_test_server: Any, get_request: Any\n) -> None:\n    url = \"http://aiohttp.io/path\"\n    proxy = await proxy_test_server()\n    proxy.return_value = dict(status=502, headers={\"Proxy-Agent\": \"TestProxy\"})\n\n    resp = await get_request(url=url, proxy=proxy.url)\n\n    assert resp.status == 502\n    assert resp.headers[\"Proxy-Agent\"] == \"TestProxy\"\n\n\nasync def test_proxy_http_auth(proxy_test_server: Any, get_request: Any) -> None:\n    url = \"http://aiohttp.io/path\"\n    proxy = await proxy_test_server()\n\n    await get_request(url=url, proxy=proxy.url)\n\n    assert \"Authorization\" not in proxy.request.headers\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n    auth = aiohttp.BasicAuth(\"user\", \"pass\")\n    await get_request(url=url, auth=auth, proxy=proxy.url)\n\n    assert \"Authorization\" in proxy.request.headers\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n    await get_request(url=url, proxy_auth=auth, proxy=proxy.url)\n\n    assert \"Authorization\" not in proxy.request.headers\n    assert \"Proxy-Authorization\" in proxy.request.headers\n\n    await get_request(url=url, auth=auth, proxy_auth=auth, proxy=proxy.url)\n\n    assert \"Authorization\" in proxy.request.headers\n    assert \"Proxy-Authorization\" in proxy.request.headers\n\n\nasync def test_proxy_http_auth_utf8(proxy_test_server: Any, get_request: Any) -> None:\n    url = \"http://aiohttp.io/path\"\n    auth = aiohttp.BasicAuth(\"\u044e\u0437\u0435\u0440\", \"\u043f\u0430\u0441\u0441\", \"utf-8\")\n    proxy = await proxy_test_server()\n\n    await get_request(url=url, auth=auth, proxy=proxy.url)\n\n    assert \"Authorization\" in proxy.request.headers\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n\nasync def test_proxy_http_auth_from_url(\n    proxy_test_server: Any, get_request: Any\n) -> None:\n    url = \"http://aiohttp.io/path\"\n    proxy = await proxy_test_server()\n\n    auth_url = URL(url).with_user(\"user\").with_password(\"pass\")\n    await get_request(url=auth_url, proxy=proxy.url)\n\n    assert \"Authorization\" in proxy.request.headers\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n    proxy_url = URL(proxy.url).with_user(\"user\").with_password(\"pass\")\n    await get_request(url=url, proxy=proxy_url)\n\n    assert \"Authorization\" not in proxy.request.headers\n    assert \"Proxy-Authorization\" in proxy.request.headers\n\n\nasync def test_proxy_http_acquired_cleanup(proxy_test_server: Any, loop: Any) -> None:\n    url = \"http://aiohttp.io/path\"\n\n    conn = aiohttp.TCPConnector()\n    sess = aiohttp.ClientSession(connector=conn)\n    proxy = await proxy_test_server()\n\n    assert 0 == len(conn._acquired)\n\n    async with sess.get(url, proxy=proxy.url) as resp:\n        pass\n    assert resp.closed\n\n    assert 0 == len(conn._acquired)\n\n    await sess.close()\n\n\n@pytest.mark.skip(\"we need to reconsider how we test this\")\nasync def test_proxy_http_acquired_cleanup_force(\n    proxy_test_server: Any, loop: Any\n) -> None:\n    url = \"http://aiohttp.io/path\"\n\n    conn = aiohttp.TCPConnector(force_close=True)\n    sess = aiohttp.ClientSession(connector=conn)\n    proxy = await proxy_test_server()\n\n    assert 0 == len(conn._acquired)\n\n    async def request():\n        async with sess.get(url, proxy=proxy.url):\n            assert 1 == len(conn._acquired)\n\n    await request()\n\n    assert 0 == len(conn._acquired)\n\n    await sess.close()\n\n\n@pytest.mark.skip(\"we need to reconsider how we test this\")\nasync def test_proxy_http_multi_conn_limit(proxy_test_server: Any, loop: Any) -> None:\n    url = \"http://aiohttp.io/path\"\n    limit, multi_conn_num = 1, 5\n\n    conn = aiohttp.TCPConnector(limit=limit)\n    sess = aiohttp.ClientSession(connector=conn)\n    proxy = await proxy_test_server()\n\n    current_pid = None\n\n    async def request(pid):\n        # process requests only one by one\n        nonlocal current_pid\n\n        async with sess.get(url, proxy=proxy.url) as resp:\n            current_pid = pid\n            await asyncio.sleep(0.2)\n            assert current_pid == pid\n\n        return resp\n\n    requests = [request(pid) for pid in range(multi_conn_num)]\n    responses = await asyncio.gather(*requests)\n\n    assert len(responses) == multi_conn_num\n    assert {resp.status for resp in responses} == {200}\n\n    await sess.close()\n\n\n@pytest.mark.xfail\nasync def xtest_proxy_https_connect(proxy_test_server: Any, get_request: Any) -> None:\n    proxy = await proxy_test_server()\n    url = \"https://www.google.com.ua/search?q=aiohttp proxy\"\n\n    await get_request(url=url, proxy=proxy.url)\n\n    connect = proxy.requests_list[0]\n    assert connect.method == \"CONNECT\"\n    assert connect.path == \"www.google.com.ua:443\"\n    assert connect.host == \"www.google.com.ua\"\n\n    assert proxy.request.host == \"www.google.com.ua\"\n    assert proxy.request.path_qs == \"/search?q=aiohttp+proxy\"\n\n\n@pytest.mark.xfail\nasync def xtest_proxy_https_connect_with_port(\n    proxy_test_server: Any, get_request: Any\n) -> None:\n    proxy = await proxy_test_server()\n    url = \"https://secure.aiohttp.io:2242/path\"\n\n    await get_request(url=url, proxy=proxy.url)\n\n    connect = proxy.requests_list[0]\n    assert connect.method == \"CONNECT\"\n    assert connect.path == \"secure.aiohttp.io:2242\"\n    assert connect.host == \"secure.aiohttp.io:2242\"\n\n    assert proxy.request.host == \"secure.aiohttp.io:2242\"\n    assert proxy.request.path_qs == \"/path\"\n\n\n@pytest.mark.xfail\nasync def xtest_proxy_https_send_body(proxy_test_server: Any, loop: Any) -> None:\n    sess = aiohttp.ClientSession()\n    proxy = await proxy_test_server()\n    proxy.return_value = {\"status\": 200, \"body\": b\"1\" * (2**20)}\n    url = \"https://www.google.com.ua/search?q=aiohttp proxy\"\n\n    async with sess.get(url, proxy=proxy.url) as resp:\n        body = await resp.read()\n    await sess.close()\n\n    assert body == b\"1\" * (2**20)\n\n\n@pytest.mark.xfail\nasync def xtest_proxy_https_idna_support(\n    proxy_test_server: Any, get_request: Any\n) -> None:\n    url = \"https://\u00e9\u00e9.com/\"\n    proxy = await proxy_test_server()\n\n    await get_request(url=url, proxy=proxy.url)\n\n    connect = proxy.requests_list[0]\n    assert connect.method == \"CONNECT\"\n    assert connect.path == \"xn--9caa.com:443\"\n    assert connect.host == \"xn--9caa.com\"\n\n\nasync def test_proxy_https_connection_error(get_request: Any) -> None:\n    url = \"https://secure.aiohttp.io/path\"\n    proxy_url = \"http://localhost:2242/\"\n\n    with pytest.raises(aiohttp.ClientConnectorError):\n        await get_request(url=url, proxy=proxy_url)\n\n\nasync def test_proxy_https_bad_response(\n    proxy_test_server: Any, get_request: Any\n) -> None:\n    url = \"https://secure.aiohttp.io/path\"\n    proxy = await proxy_test_server()\n    proxy.return_value = dict(status=502, headers={\"Proxy-Agent\": \"TestProxy\"})\n\n    with pytest.raises(aiohttp.ClientHttpProxyError):\n        await get_request(url=url, proxy=proxy.url)\n\n    assert len(proxy.requests_list) == 1\n    assert proxy.request.method == \"CONNECT\"\n    # The following check fails on MacOS\n    # assert proxy.request.path == 'secure.aiohttp.io:443'\n\n\n@pytest.mark.xfail\nasync def xtest_proxy_https_auth(proxy_test_server: Any, get_request: Any) -> None:\n    url = \"https://secure.aiohttp.io/path\"\n    auth = aiohttp.BasicAuth(\"user\", \"pass\")\n\n    proxy = await proxy_test_server()\n    await get_request(url=url, proxy=proxy.url)\n\n    connect = proxy.requests_list[0]\n    assert \"Authorization\" not in connect.headers\n    assert \"Proxy-Authorization\" not in connect.headers\n    assert \"Authorization\" not in proxy.request.headers\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n    proxy = await proxy_test_server()\n    await get_request(url=url, auth=auth, proxy=proxy.url)\n\n    connect = proxy.requests_list[0]\n    assert \"Authorization\" not in connect.headers\n    assert \"Proxy-Authorization\" not in connect.headers\n    assert \"Authorization\" in proxy.request.headers\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n    proxy = await proxy_test_server()\n    await get_request(url=url, proxy_auth=auth, proxy=proxy.url)\n\n    connect = proxy.requests_list[0]\n    assert \"Authorization\" not in connect.headers\n    assert \"Proxy-Authorization\" in connect.headers\n    assert \"Authorization\" not in proxy.request.headers\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n    proxy = await proxy_test_server()\n    await get_request(url=url, auth=auth, proxy_auth=auth, proxy=proxy.url)\n\n    connect = proxy.requests_list[0]\n    assert \"Authorization\" not in connect.headers\n    assert \"Proxy-Authorization\" in connect.headers\n    assert \"Authorization\" in proxy.request.headers\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n\n@pytest.mark.xfail\nasync def xtest_proxy_https_acquired_cleanup(proxy_test_server: Any, loop: Any) -> None:\n    url = \"https://secure.aiohttp.io/path\"\n\n    conn = aiohttp.TCPConnector()\n    sess = aiohttp.ClientSession(connector=conn)\n    proxy = await proxy_test_server()\n\n    assert 0 == len(conn._acquired)\n\n    async def request():\n        async with sess.get(url, proxy=proxy.url):\n            assert 1 == len(conn._acquired)\n\n    await request()\n\n    assert 0 == len(conn._acquired)\n\n    await sess.close()\n\n\n@pytest.mark.xfail\nasync def xtest_proxy_https_acquired_cleanup_force(\n    proxy_test_server: Any, loop: Any\n) -> None:\n    url = \"https://secure.aiohttp.io/path\"\n\n    conn = aiohttp.TCPConnector(force_close=True)\n    sess = aiohttp.ClientSession(connector=conn)\n    proxy = await proxy_test_server()\n\n    assert 0 == len(conn._acquired)\n\n    async def request():\n        async with sess.get(url, proxy=proxy.url):\n            assert 1 == len(conn._acquired)\n\n    await request()\n\n    assert 0 == len(conn._acquired)\n\n    await sess.close()\n\n\n@pytest.mark.xfail\nasync def xtest_proxy_https_multi_conn_limit(proxy_test_server: Any, loop: Any):\n    url = \"https://secure.aiohttp.io/path\"\n    limit, multi_conn_num = 1, 5\n\n    conn = aiohttp.TCPConnector(limit=limit)\n    sess = aiohttp.ClientSession(connector=conn)\n    proxy = await proxy_test_server()\n\n    current_pid = None\n\n    async def request(pid):\n        # process requests only one by one\n        nonlocal current_pid\n\n        async with sess.get(url, proxy=proxy.url) as resp:\n            current_pid = pid\n            await asyncio.sleep(0.2)\n            assert current_pid == pid\n\n        return resp\n\n    requests = [request(pid) for pid in range(multi_conn_num)]\n    responses = await asyncio.gather(*requests)\n\n    assert len(responses) == multi_conn_num\n    assert {resp.status for resp in responses} == {200}\n\n    await sess.close()\n\n\ndef _patch_ssl_transport(monkeypatch):\n    # Make ssl transport substitution to prevent ssl handshake.\n    def _make_ssl_transport_dummy(\n        self, rawsock, protocol, sslcontext, waiter=None, **kwargs\n    ):\n        return self._make_socket_transport(\n            rawsock,\n            protocol,\n            waiter,\n            extra=kwargs.get(\"extra\"),\n            server=kwargs.get(\"server\"),\n        )\n\n    monkeypatch.setattr(\n        \"asyncio.selector_events.BaseSelectorEventLoop._make_ssl_transport\",\n        _make_ssl_transport_dummy,\n    )\n\n\noriginal_is_file: Any = pathlib.Path.is_file\n\n\ndef mock_is_file(self):\n    # make real netrc file invisible in home dir\n    if self.name in [\"_netrc\", \".netrc\"] and self.parent == self.home():\n        return False\n    else:\n        return original_is_file(self)\n\n\nasync def test_proxy_from_env_http(\n    proxy_test_server: Any, get_request: Any, mocker: Any\n) -> None:\n    url = \"http://aiohttp.io/path\"\n    proxy = await proxy_test_server()\n    mocker.patch.dict(os.environ, {\"http_proxy\": str(proxy.url)})\n    mocker.patch(\"pathlib.Path.is_file\", mock_is_file)\n\n    await get_request(url=url, trust_env=True)\n\n    assert len(proxy.requests_list) == 1\n    assert proxy.request.method == \"GET\"\n    assert proxy.request.host == \"aiohttp.io\"\n    assert proxy.request.path_qs == \"/path\"\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n\nasync def test_proxy_from_env_http_with_auth(\n    proxy_test_server: Any, get_request: Any, mocker: Any\n) -> None:\n    url = \"http://aiohttp.io/path\"\n    proxy = await proxy_test_server()\n    auth = aiohttp.BasicAuth(\"user\", \"pass\")\n    mocker.patch.dict(\n        os.environ,\n        {\n            \"http_proxy\": str(\n                proxy.url.with_user(auth.login).with_password(auth.password)\n            )\n        },\n    )\n\n    await get_request(url=url, trust_env=True)\n\n    assert len(proxy.requests_list) == 1\n    assert proxy.request.method == \"GET\"\n    assert proxy.request.host == \"aiohttp.io\"\n    assert proxy.request.path_qs == \"/path\"\n    assert proxy.request.headers[\"Proxy-Authorization\"] == auth.encode()\n\n\nasync def test_proxy_from_env_http_with_auth_from_netrc(\n    proxy_test_server: Any, get_request: Any, tmp_path: Any, mocker: Any\n) -> None:\n    url = \"http://aiohttp.io/path\"\n    proxy = await proxy_test_server()\n    auth = aiohttp.BasicAuth(\"user\", \"pass\")\n    netrc_file = tmp_path / \"test_netrc\"\n    netrc_file_data = \"machine 127.0.0.1 login {} password {}\".format(\n        auth.login,\n        auth.password,\n    )\n    with netrc_file.open(\"w\") as f:\n        f.write(netrc_file_data)\n    mocker.patch.dict(\n        os.environ, {\"http_proxy\": str(proxy.url), \"NETRC\": str(netrc_file)}\n    )\n\n    await get_request(url=url, trust_env=True)\n\n    assert len(proxy.requests_list) == 1\n    assert proxy.request.method == \"GET\"\n    assert proxy.request.host == \"aiohttp.io\"\n    assert proxy.request.path_qs == \"/path\"\n    assert proxy.request.headers[\"Proxy-Authorization\"] == auth.encode()\n\n\nasync def test_proxy_from_env_http_without_auth_from_netrc(\n    proxy_test_server: Any, get_request: Any, tmp_path: Any, mocker: Any\n) -> None:\n    url = \"http://aiohttp.io/path\"\n    proxy = await proxy_test_server()\n    auth = aiohttp.BasicAuth(\"user\", \"pass\")\n    netrc_file = tmp_path / \"test_netrc\"\n    netrc_file_data = \"machine 127.0.0.2 login {} password {}\".format(\n        auth.login,\n        auth.password,\n    )\n    with netrc_file.open(\"w\") as f:\n        f.write(netrc_file_data)\n    mocker.patch.dict(\n        os.environ, {\"http_proxy\": str(proxy.url), \"NETRC\": str(netrc_file)}\n    )\n\n    await get_request(url=url, trust_env=True)\n\n    assert len(proxy.requests_list) == 1\n    assert proxy.request.method == \"GET\"\n    assert proxy.request.host == \"aiohttp.io\"\n    assert proxy.request.path_qs == \"/path\"\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n\nasync def test_proxy_from_env_http_without_auth_from_wrong_netrc(\n    proxy_test_server: Any, get_request: Any, tmp_path: Any, mocker: Any\n) -> None:\n    url = \"http://aiohttp.io/path\"\n    proxy = await proxy_test_server()\n    auth = aiohttp.BasicAuth(\"user\", \"pass\")\n    netrc_file = tmp_path / \"test_netrc\"\n    invalid_data = f\"machine 127.0.0.1 {auth.login} pass {auth.password}\"\n    with netrc_file.open(\"w\") as f:\n        f.write(invalid_data)\n\n    mocker.patch.dict(\n        os.environ, {\"http_proxy\": str(proxy.url), \"NETRC\": str(netrc_file)}\n    )\n\n    await get_request(url=url, trust_env=True)\n\n    assert len(proxy.requests_list) == 1\n    assert proxy.request.method == \"GET\"\n    assert proxy.request.host == \"aiohttp.io\"\n    assert proxy.request.path_qs == \"/path\"\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n\n@pytest.mark.xfail\nasync def xtest_proxy_from_env_https(\n    proxy_test_server: Any, get_request: Any, mocker: Any\n) -> None:\n    url = \"https://aiohttp.io/path\"\n    proxy = await proxy_test_server()\n    mocker.patch.dict(os.environ, {\"https_proxy\": str(proxy.url)})\n    mock.patch(\"pathlib.Path.is_file\", mock_is_file)\n\n    await get_request(url=url, trust_env=True)\n\n    assert len(proxy.requests_list) == 2\n    assert proxy.request.method == \"GET\"\n    assert proxy.request.host == \"aiohttp.io\"\n    assert proxy.request.path_qs == \"/path\"\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n\n@pytest.mark.xfail\nasync def xtest_proxy_from_env_https_with_auth(\n    proxy_test_server: Any, get_request: Any, mocker: Any\n) -> None:\n    url = \"https://aiohttp.io/path\"\n    proxy = await proxy_test_server()\n    auth = aiohttp.BasicAuth(\"user\", \"pass\")\n    mocker.patch.dict(\n        os.environ,\n        {\n            \"https_proxy\": str(\n                proxy.url.with_user(auth.login).with_password(auth.password)\n            )\n        },\n    )\n\n    await get_request(url=url, trust_env=True)\n\n    assert len(proxy.requests_list) == 2\n\n    assert proxy.request.method == \"GET\"\n    assert proxy.request.host == \"aiohttp.io\"\n    assert proxy.request.path_qs == \"/path\"\n    assert \"Proxy-Authorization\" not in proxy.request.headers\n\n    r2 = proxy.requests_list[0]\n    assert r2.method == \"CONNECT\"\n    assert r2.host == \"aiohttp.io\"\n    assert r2.path_qs == \"/path\"\n    assert r2.headers[\"Proxy-Authorization\"] == auth.encode()\n\n\nasync def test_proxy_auth() -> None:\n    async with aiohttp.ClientSession() as session:\n        with pytest.raises(\n            ValueError, match=r\"proxy_auth must be None or BasicAuth\\(\\) tuple\"\n        ):\n            async with session.get(\n                \"http://python.org\",\n                proxy=\"http://proxy.example.com\",\n                proxy_auth=(\"user\", \"pass\"),\n            ):\n                pass\n", "tests/test_web_app.py": "import asyncio\nfrom typing import Any, AsyncIterator, Callable, Iterator, NoReturn\nfrom unittest import mock\n\nimport pytest\n\nfrom aiohttp import log, web\nfrom aiohttp.test_utils import make_mocked_coro\nfrom aiohttp.typedefs import Handler\n\n\nasync def test_app_ctor() -> None:\n    app = web.Application()\n    assert app.logger is log.web_logger\n\n\ndef test_app_call() -> None:\n    app = web.Application()\n    assert app is app()\n\n\nasync def test_app_register_on_finish() -> None:\n    app = web.Application()\n    cb1 = make_mocked_coro(None)\n    cb2 = make_mocked_coro(None)\n    app.on_cleanup.append(cb1)\n    app.on_cleanup.append(cb2)\n    app.freeze()\n    await app.cleanup()\n    cb1.assert_called_once_with(app)\n    cb2.assert_called_once_with(app)\n\n\nasync def test_app_register_coro() -> None:\n    app = web.Application()\n    fut = asyncio.get_event_loop().create_future()\n\n    async def cb(app: web.Application) -> None:\n        await asyncio.sleep(0.001)\n        fut.set_result(123)\n\n    app.on_cleanup.append(cb)\n    app.freeze()\n    await app.cleanup()\n    assert fut.done()\n    assert 123 == fut.result()\n\n\ndef test_logging() -> None:\n    logger = mock.Mock()\n    app = web.Application()\n    app.logger = logger\n    assert app.logger is logger\n\n\nasync def test_on_shutdown() -> None:\n    app = web.Application()\n    called = False\n\n    async def on_shutdown(app_param: web.Application) -> None:\n        nonlocal called\n        assert app is app_param\n        called = True\n\n    app.on_shutdown.append(on_shutdown)\n    app.freeze()\n    await app.shutdown()\n    assert called\n\n\nasync def test_on_startup() -> None:\n    app = web.Application()\n\n    long_running1_called = False\n    long_running2_called = False\n    all_long_running_called = False\n\n    async def long_running1(app_param: web.Application) -> None:\n        nonlocal long_running1_called\n        assert app is app_param\n        long_running1_called = True\n\n    async def long_running2(app_param: web.Application) -> None:\n        nonlocal long_running2_called\n        assert app is app_param\n        long_running2_called = True\n\n    async def on_startup_all_long_running(app_param: web.Application) -> None:\n        nonlocal all_long_running_called\n        assert app is app_param\n        all_long_running_called = True\n        await asyncio.gather(long_running1(app_param), long_running2(app_param))\n\n    app.on_startup.append(on_startup_all_long_running)\n    app.freeze()\n\n    await app.startup()\n    assert long_running1_called\n    assert long_running2_called\n    assert all_long_running_called\n\n\ndef test_appkey() -> None:\n    key = web.AppKey(\"key\", str)\n    app = web.Application()\n    app[key] = \"value\"\n    assert app[key] == \"value\"\n    assert len(app) == 1\n    del app[key]\n    assert len(app) == 0\n\n\ndef test_appkey_repr_concrete() -> None:\n    key = web.AppKey(\"key\", int)\n    assert repr(key) in (\n        \"<AppKey(__channelexec__.key, type=int)>\",  # pytest-xdist\n        \"<AppKey(__main__.key, type=int)>\",\n    )\n    key2 = web.AppKey(\"key\", web.Request)\n    assert repr(key2) in (\n        # pytest-xdist:\n        \"<AppKey(__channelexec__.key, type=aiohttp.web_request.Request)>\",\n        \"<AppKey(__main__.key, type=aiohttp.web_request.Request)>\",\n    )\n\n\ndef test_appkey_repr_nonconcrete() -> None:\n    key = web.AppKey(\"key\", Iterator[int])\n    assert repr(key) in (\n        # pytest-xdist:\n        \"<AppKey(__channelexec__.key, type=typing.Iterator[int])>\",\n        \"<AppKey(__main__.key, type=typing.Iterator[int])>\",\n    )\n\n\ndef test_appkey_repr_annotated() -> None:\n    key = web.AppKey[Iterator[int]](\"key\")\n    assert repr(key) in (\n        # pytest-xdist:\n        \"<AppKey(__channelexec__.key, type=typing.Iterator[int])>\",\n        \"<AppKey(__main__.key, type=typing.Iterator[int])>\",\n    )\n\n\ndef test_app_str_keys() -> None:\n    app = web.Application()\n    with pytest.warns(\n        UserWarning, match=r\"web_advanced\\.html#application-s-config\"\n    ) as checker:\n        app[\"key\"] = \"value\"\n        # Check that the error is emitted at the call site (stacklevel=2)\n        assert checker[0].filename == __file__\n    assert app[\"key\"] == \"value\"\n\n\ndef test_app_get() -> None:\n    key = web.AppKey(\"key\", int)\n    app = web.Application()\n    assert app.get(key, \"foo\") == \"foo\"\n    app[key] = 5\n    assert app.get(key, \"foo\") == 5\n\n\ndef test_app_freeze() -> None:\n    app = web.Application()\n    subapp = mock.Mock()\n    subapp._middlewares = ()\n    app._subapps.append(subapp)\n\n    app.freeze()\n    assert subapp.freeze.called\n\n    app.freeze()\n    assert len(subapp.freeze.call_args_list) == 1\n\n\ndef test_equality() -> None:\n    app1 = web.Application()\n    app2 = web.Application()\n\n    assert app1 == app1\n    assert app1 != app2\n\n\ndef test_app_run_middlewares() -> None:\n    root = web.Application()\n    sub = web.Application()\n    root.add_subapp(\"/sub\", sub)\n    root.freeze()\n    assert root._run_middlewares is False\n\n    async def middleware(request: web.Request, handler: Handler) -> web.StreamResponse:\n        return await handler(request)  # pragma: no cover\n\n    root = web.Application(middlewares=[middleware])\n    sub = web.Application()\n    root.add_subapp(\"/sub\", sub)\n    root.freeze()\n    assert root._run_middlewares is True\n\n    root = web.Application()\n    sub = web.Application(middlewares=[middleware])\n    root.add_subapp(\"/sub\", sub)\n    root.freeze()\n    assert root._run_middlewares is True\n\n\ndef test_subapp_pre_frozen_after_adding() -> None:\n    app = web.Application()\n    subapp = web.Application()\n\n    app.add_subapp(\"/prefix\", subapp)\n    assert subapp.pre_frozen\n    assert not subapp.frozen\n\n\ndef test_app_inheritance() -> None:\n    with pytest.raises(TypeError):\n\n        class A(web.Application):  # type: ignore[misc]\n            pass\n\n\ndef test_app_custom_attr() -> None:\n    app = web.Application()\n    with pytest.raises(AttributeError):\n        app.custom = None  # type: ignore[attr-defined]\n\n\nasync def test_cleanup_ctx() -> None:\n    app = web.Application()\n    out = []\n\n    def f(num: int) -> Callable[[web.Application], AsyncIterator[None]]:\n        async def inner(app: web.Application) -> AsyncIterator[None]:\n            out.append(\"pre_\" + str(num))\n            yield None\n            out.append(\"post_\" + str(num))\n\n        return inner\n\n    app.cleanup_ctx.append(f(1))\n    app.cleanup_ctx.append(f(2))\n    app.freeze()\n    await app.startup()\n    assert out == [\"pre_1\", \"pre_2\"]\n    await app.cleanup()\n    assert out == [\"pre_1\", \"pre_2\", \"post_2\", \"post_1\"]\n\n\nasync def test_cleanup_ctx_exception_on_startup() -> None:\n    app = web.Application()\n    out = []\n\n    exc = Exception(\"fail\")\n\n    def f(\n        num: int, fail: bool = False\n    ) -> Callable[[web.Application], AsyncIterator[None]]:\n        async def inner(app: web.Application) -> AsyncIterator[None]:\n            out.append(\"pre_\" + str(num))\n            if fail:\n                raise exc\n            yield None\n            out.append(\"post_\" + str(num))\n\n        return inner\n\n    app.cleanup_ctx.append(f(1))\n    app.cleanup_ctx.append(f(2, True))\n    app.cleanup_ctx.append(f(3))\n    app.freeze()\n    with pytest.raises(Exception) as ctx:\n        await app.startup()\n    assert ctx.value is exc\n    assert out == [\"pre_1\", \"pre_2\"]\n    await app.cleanup()\n    assert out == [\"pre_1\", \"pre_2\", \"post_1\"]\n\n\nasync def test_cleanup_ctx_exception_on_cleanup() -> None:\n    app = web.Application()\n    out = []\n\n    exc = Exception(\"fail\")\n\n    def f(\n        num: int, fail: bool = False\n    ) -> Callable[[web.Application], AsyncIterator[None]]:\n        async def inner(app: web.Application) -> AsyncIterator[None]:\n            out.append(\"pre_\" + str(num))\n            yield None\n            out.append(\"post_\" + str(num))\n            if fail:\n                raise exc\n\n        return inner\n\n    app.cleanup_ctx.append(f(1))\n    app.cleanup_ctx.append(f(2, True))\n    app.cleanup_ctx.append(f(3))\n    app.freeze()\n    await app.startup()\n    assert out == [\"pre_1\", \"pre_2\", \"pre_3\"]\n    with pytest.raises(Exception) as ctx:\n        await app.cleanup()\n    assert ctx.value is exc\n    assert out == [\"pre_1\", \"pre_2\", \"pre_3\", \"post_3\", \"post_2\", \"post_1\"]\n\n\nasync def test_cleanup_ctx_cleanup_after_exception() -> None:\n    app = web.Application()\n    ctx_state = None\n\n    async def success_ctx(app: web.Application) -> AsyncIterator[None]:\n        nonlocal ctx_state\n        ctx_state = \"START\"\n        yield\n        ctx_state = \"CLEAN\"\n\n    async def fail_ctx(app: web.Application) -> AsyncIterator[NoReturn]:\n        raise Exception()\n        yield\n\n    app.cleanup_ctx.append(success_ctx)\n    app.cleanup_ctx.append(fail_ctx)\n    runner = web.AppRunner(app)\n    try:\n        with pytest.raises(Exception):\n            await runner.setup()\n    finally:\n        await runner.cleanup()\n\n    assert ctx_state == \"CLEAN\"\n\n\nasync def test_cleanup_ctx_exception_on_cleanup_multiple() -> None:\n    app = web.Application()\n    out = []\n\n    def f(\n        num: int, fail: bool = False\n    ) -> Callable[[web.Application], AsyncIterator[None]]:\n        async def inner(app: web.Application) -> AsyncIterator[None]:\n            out.append(\"pre_\" + str(num))\n            yield None\n            out.append(\"post_\" + str(num))\n            if fail:\n                raise Exception(\"fail_\" + str(num))\n\n        return inner\n\n    app.cleanup_ctx.append(f(1))\n    app.cleanup_ctx.append(f(2, True))\n    app.cleanup_ctx.append(f(3, True))\n    app.freeze()\n    await app.startup()\n    assert out == [\"pre_1\", \"pre_2\", \"pre_3\"]\n    with pytest.raises(web.CleanupError) as ctx:\n        await app.cleanup()\n    exc = ctx.value\n    assert len(exc.exceptions) == 2\n    assert str(exc.exceptions[0]) == \"fail_3\"\n    assert str(exc.exceptions[1]) == \"fail_2\"\n    assert out == [\"pre_1\", \"pre_2\", \"pre_3\", \"post_3\", \"post_2\", \"post_1\"]\n\n\nasync def test_cleanup_ctx_multiple_yields() -> None:\n    app = web.Application()\n    out = []\n\n    def f(num: int) -> Callable[[web.Application], AsyncIterator[None]]:\n        async def inner(app: web.Application) -> AsyncIterator[None]:\n            out.append(\"pre_\" + str(num))\n            yield None\n            out.append(\"post_\" + str(num))\n            yield None\n\n        return inner\n\n    app.cleanup_ctx.append(f(1))\n    app.freeze()\n    await app.startup()\n    assert out == [\"pre_1\"]\n    with pytest.raises(RuntimeError) as ctx:\n        await app.cleanup()\n    assert \"has more than one 'yield'\" in str(ctx.value)\n    assert out == [\"pre_1\", \"post_1\"]\n\n\nasync def test_subapp_chained_config_dict_visibility(aiohttp_client: Any) -> None:\n    key1 = web.AppKey(\"key1\", str)\n    key2 = web.AppKey(\"key2\", str)\n\n    async def main_handler(request: web.Request) -> web.Response:\n        assert request.config_dict[key1] == \"val1\"\n        assert key2 not in request.config_dict\n        return web.Response(status=200)\n\n    root = web.Application()\n    root[key1] = \"val1\"\n    root.add_routes([web.get(\"/\", main_handler)])\n\n    async def sub_handler(request: web.Request) -> web.Response:\n        assert request.config_dict[key1] == \"val1\"\n        assert request.config_dict[key2] == \"val2\"\n        return web.Response(status=201)\n\n    sub = web.Application()\n    sub[key2] = \"val2\"\n    sub.add_routes([web.get(\"/\", sub_handler)])\n    root.add_subapp(\"/sub\", sub)\n\n    client = await aiohttp_client(root)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    resp = await client.get(\"/sub/\")\n    assert resp.status == 201\n\n\nasync def test_subapp_chained_config_dict_overriding(aiohttp_client: Any) -> None:\n    key = web.AppKey(\"key\", str)\n\n    async def main_handler(request: web.Request) -> web.Response:\n        assert request.config_dict[key] == \"val1\"\n        return web.Response(status=200)\n\n    root = web.Application()\n    root[key] = \"val1\"\n    root.add_routes([web.get(\"/\", main_handler)])\n\n    async def sub_handler(request: web.Request) -> web.Response:\n        assert request.config_dict[key] == \"val2\"\n        return web.Response(status=201)\n\n    sub = web.Application()\n    sub[key] = \"val2\"\n    sub.add_routes([web.get(\"/\", sub_handler)])\n    root.add_subapp(\"/sub\", sub)\n\n    client = await aiohttp_client(root)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    resp = await client.get(\"/sub/\")\n    assert resp.status == 201\n\n\nasync def test_subapp_on_startup(aiohttp_client: Any) -> None:\n    subapp = web.Application()\n    startup = web.AppKey(\"startup\", bool)\n    cleanup = web.AppKey(\"cleanup\", bool)\n\n    startup_called = False\n\n    async def on_startup(app: web.Application) -> None:\n        nonlocal startup_called\n        startup_called = True\n        app[startup] = True\n\n    subapp.on_startup.append(on_startup)\n\n    ctx_pre_called = False\n    ctx_post_called = False\n\n    async def cleanup_ctx(app: web.Application) -> AsyncIterator[None]:\n        nonlocal ctx_pre_called, ctx_post_called\n        ctx_pre_called = True\n        app[cleanup] = True\n        yield None\n        ctx_post_called = True\n\n    subapp.cleanup_ctx.append(cleanup_ctx)\n\n    shutdown_called = False\n\n    async def on_shutdown(app: web.Application) -> None:\n        nonlocal shutdown_called\n        shutdown_called = True\n\n    subapp.on_shutdown.append(on_shutdown)\n\n    cleanup_called = False\n\n    async def on_cleanup(app: web.Application) -> None:\n        nonlocal cleanup_called\n        cleanup_called = True\n\n    subapp.on_cleanup.append(on_cleanup)\n\n    app = web.Application()\n\n    app.add_subapp(\"/subapp\", subapp)\n\n    assert not startup_called\n    assert not ctx_pre_called\n    assert not ctx_post_called\n    assert not shutdown_called\n    assert not cleanup_called\n\n    assert subapp.on_startup.frozen\n    assert subapp.cleanup_ctx.frozen\n    assert subapp.on_shutdown.frozen\n    assert subapp.on_cleanup.frozen\n    assert subapp.router.frozen\n\n    client = await aiohttp_client(app)\n\n    assert startup_called\n    assert ctx_pre_called\n    assert not ctx_post_called\n    assert not shutdown_called\n    assert not cleanup_called\n\n    await client.close()\n\n    assert startup_called\n    assert ctx_pre_called\n    assert ctx_post_called\n    assert shutdown_called\n    assert cleanup_called\n\n\n@pytest.mark.filterwarnings(r\"ignore:.*web\\.AppKey:UserWarning\")\ndef test_app_iter() -> None:\n    app = web.Application()\n    b = web.AppKey(\"b\", str)\n    c = web.AppKey(\"c\", str)\n    app[\"a\"] = \"0\"\n    app[b] = \"1\"\n    app[c] = \"2\"\n    app[\"d\"] = \"4\"\n    assert sorted(list(app)) == [b, c, \"a\", \"d\"]\n\n\ndef test_app_forbid_nonslot_attr() -> None:\n    app = web.Application()\n    with pytest.raises(AttributeError):\n        app.unknow_attr  # type: ignore[attr-defined]\n    with pytest.raises(AttributeError):\n        app.unknow_attr = 1  # type: ignore[attr-defined]\n\n\ndef test_forbid_changing_frozen_app() -> None:\n    app = web.Application()\n    app.freeze()\n    with pytest.raises(RuntimeError):\n        app[\"key\"] = \"value\"\n\n\ndef test_app_boolean() -> None:\n    app = web.Application()\n    assert app\n", "tests/test_web_sendfile.py": "from pathlib import Path\nfrom typing import Any\nfrom unittest import mock\n\nfrom aiohttp import hdrs\nfrom aiohttp.test_utils import make_mocked_coro, make_mocked_request\nfrom aiohttp.web_fileresponse import FileResponse\n\n\ndef test_using_gzip_if_header_present_and_file_available(loop: Any) -> None:\n    request = make_mocked_request(\n        \"GET\",\n        \"http://python.org/logo.png\",\n        # Header uses some uppercase to ensure case-insensitive treatment\n        headers={hdrs.ACCEPT_ENCODING: \"GZip\"},\n    )\n\n    gz_filepath = mock.create_autospec(Path, spec_set=True)\n    gz_filepath.stat.return_value.st_size = 1024\n    gz_filepath.stat.return_value.st_mtime_ns = 1603733507222449291\n\n    filepath = mock.create_autospec(Path, spec_set=True)\n    filepath.name = \"logo.png\"\n    filepath.with_suffix.return_value = gz_filepath\n\n    file_sender = FileResponse(filepath)\n    file_sender._path = filepath\n    file_sender._sendfile = make_mocked_coro(None)  # type: ignore[method-assign]\n\n    loop.run_until_complete(file_sender.prepare(request))\n\n    assert not filepath.open.called\n    assert gz_filepath.open.called\n\n\ndef test_gzip_if_header_not_present_and_file_available(loop: Any) -> None:\n    request = make_mocked_request(\"GET\", \"http://python.org/logo.png\", headers={})\n\n    gz_filepath = mock.create_autospec(Path, spec_set=True)\n    gz_filepath.stat.return_value.st_size = 1024\n    gz_filepath.stat.return_value.st_mtime_ns = 1603733507222449291\n\n    filepath = mock.create_autospec(Path, spec_set=True)\n    filepath.name = \"logo.png\"\n    filepath.with_suffix.return_value = gz_filepath\n    filepath.stat.return_value.st_size = 1024\n    filepath.stat.return_value.st_mtime_ns = 1603733507222449291\n\n    file_sender = FileResponse(filepath)\n    file_sender._path = filepath\n    file_sender._sendfile = make_mocked_coro(None)  # type: ignore[method-assign]\n\n    loop.run_until_complete(file_sender.prepare(request))\n\n    assert filepath.open.called\n    assert not gz_filepath.open.called\n\n\ndef test_gzip_if_header_not_present_and_file_not_available(loop: Any) -> None:\n    request = make_mocked_request(\"GET\", \"http://python.org/logo.png\", headers={})\n\n    gz_filepath = mock.create_autospec(Path, spec_set=True)\n    gz_filepath.stat.side_effect = OSError(2, \"No such file or directory\")\n\n    filepath = mock.create_autospec(Path, spec_set=True)\n    filepath.name = \"logo.png\"\n    filepath.with_suffix.return_value = gz_filepath\n    filepath.stat.return_value.st_size = 1024\n    filepath.stat.return_value.st_mtime_ns = 1603733507222449291\n\n    file_sender = FileResponse(filepath)\n    file_sender._path = filepath\n    file_sender._sendfile = make_mocked_coro(None)  # type: ignore[method-assign]\n\n    loop.run_until_complete(file_sender.prepare(request))\n\n    assert filepath.open.called\n    assert not gz_filepath.open.called\n\n\ndef test_gzip_if_header_present_and_file_not_available(loop: Any) -> None:\n    request = make_mocked_request(\n        \"GET\", \"http://python.org/logo.png\", headers={hdrs.ACCEPT_ENCODING: \"gzip\"}\n    )\n\n    gz_filepath = mock.create_autospec(Path, spec_set=True)\n    gz_filepath.stat.side_effect = OSError(2, \"No such file or directory\")\n\n    filepath = mock.create_autospec(Path, spec_set=True)\n    filepath.name = \"logo.png\"\n    filepath.with_suffix.return_value = gz_filepath\n    filepath.stat.return_value.st_size = 1024\n    filepath.stat.return_value.st_mtime_ns = 1603733507222449291\n\n    file_sender = FileResponse(filepath)\n    file_sender._path = filepath\n    file_sender._sendfile = make_mocked_coro(None)  # type: ignore[method-assign]\n\n    loop.run_until_complete(file_sender.prepare(request))\n\n    assert filepath.open.called\n    assert not gz_filepath.open.called\n\n\ndef test_status_controlled_by_user(loop: Any) -> None:\n    request = make_mocked_request(\"GET\", \"http://python.org/logo.png\", headers={})\n\n    filepath = mock.create_autospec(Path, spec_set=True)\n    filepath.name = \"logo.png\"\n    filepath.stat.return_value.st_size = 1024\n    filepath.stat.return_value.st_mtime_ns = 1603733507222449291\n\n    file_sender = FileResponse(filepath, status=203)\n    file_sender._path = filepath\n    file_sender._sendfile = make_mocked_coro(None)  # type: ignore[method-assign]\n\n    loop.run_until_complete(file_sender.prepare(request))\n\n    assert file_sender._status == 203\n", "tests/test_circular_imports.py": "\"\"\"Tests for circular imports in all local packages and modules.\n\nThis ensures all internal packages can be imported right away without\nany need to import some other module before doing so.\n\nThis module is based on an idea that pytest uses for self-testing:\n* https://github.com/sanitizers/octomachinery/blob/be18b54/tests/circular_imports_test.py\n* https://github.com/pytest-dev/pytest/blob/d18c75b/testing/test_meta.py\n* https://twitter.com/codewithanthony/status/1229445110510735361\n\"\"\"\n\nimport os\nimport pkgutil\nimport socket\nimport subprocess\nimport sys\nfrom itertools import chain\nfrom pathlib import Path\nfrom types import ModuleType\nfrom typing import TYPE_CHECKING, Generator, List, Union\n\nimport pytest\n\nif TYPE_CHECKING:\n    from _pytest.mark.structures import ParameterSet\n\nimport aiohttp\n\n\ndef _mark_aiohttp_worker_for_skipping(\n    importables: List[str],\n) -> List[Union[str, \"ParameterSet\"]]:\n    return [\n        (\n            pytest.param(\n                importable,\n                marks=pytest.mark.skipif(\n                    not hasattr(socket, \"AF_UNIX\"), reason=\"It's a UNIX-only module\"\n                ),\n            )\n            if importable == \"aiohttp.worker\"\n            else importable\n        )\n        for importable in importables\n    ]\n\n\ndef _find_all_importables(pkg: ModuleType) -> List[str]:\n    \"\"\"Find all importables in the project.\n\n    Return them in order.\n    \"\"\"\n    return sorted(\n        set(\n            chain.from_iterable(\n                _discover_path_importables(Path(p), pkg.__name__) for p in pkg.__path__\n            ),\n        ),\n    )\n\n\ndef _discover_path_importables(\n    pkg_pth: Path,\n    pkg_name: str,\n) -> Generator[str, None, None]:\n    \"\"\"Yield all importables under a given path and package.\"\"\"\n    for dir_path, _d, file_names in os.walk(pkg_pth):\n        pkg_dir_path = Path(dir_path)\n\n        if pkg_dir_path.parts[-1] == \"__pycache__\":\n            continue\n\n        if all(Path(_).suffix != \".py\" for _ in file_names):\n            continue\n\n        rel_pt = pkg_dir_path.relative_to(pkg_pth)\n        pkg_pref = \".\".join((pkg_name,) + rel_pt.parts)\n        yield from (\n            pkg_path\n            for _, pkg_path, _ in pkgutil.walk_packages(\n                (str(pkg_dir_path),),\n                prefix=f\"{pkg_pref}.\",\n            )\n        )\n\n\n@pytest.mark.parametrize(\n    \"import_path\",\n    _mark_aiohttp_worker_for_skipping(_find_all_importables(aiohttp)),\n)\ndef test_no_warnings(import_path: str) -> None:\n    \"\"\"Verify that exploding importables doesn't explode.\n\n    This is seeking for any import errors including ones caused\n    by circular imports.\n    \"\"\"\n    imp_cmd = (\n        # fmt: off\n        sys.executable,\n        \"-W\", \"error\",\n        # The following deprecation warning is triggered by importing\n        # `gunicorn.util`. Hopefully, it'll get fixed in the future. See\n        # https://github.com/benoitc/gunicorn/issues/2840 for detail.\n        \"-W\", \"ignore:module 'sre_constants' is \"\n        \"deprecated:DeprecationWarning:pkg_resources._vendor.pyparsing\",\n        # Also caused by `gunicorn.util` importing `pkg_resources`:\n        \"-W\", \"ignore:Creating a LegacyVersion has been deprecated and \"\n        \"will be removed in the next major release:\"\n        \"DeprecationWarning:\",\n        # Deprecation warning emitted by setuptools v67.5.0+ triggered by importing\n        # `gunicorn.util`.\n        \"-W\", \"ignore:pkg_resources is deprecated as an API:\"\n        \"DeprecationWarning\",\n        \"-c\", f\"import {import_path!s}\",\n        # fmt: on\n    )\n\n    subprocess.check_call(imp_cmd)\n", "tests/test_web_websocket.py": "# type: ignore\nimport asyncio\nimport time\nfrom typing import Any\nfrom unittest import mock\n\nimport aiosignal\nimport pytest\nfrom multidict import CIMultiDict\n\nfrom aiohttp import WSMsgType\nfrom aiohttp.streams import EofStream\nfrom aiohttp.test_utils import make_mocked_coro, make_mocked_request\nfrom aiohttp.web import HTTPBadRequest, WebSocketResponse\nfrom aiohttp.web_ws import WS_CLOSED_MESSAGE, WebSocketReady, WSMessage\n\n\n@pytest.fixture\ndef app(loop: Any):\n    ret = mock.Mock()\n    ret.loop = loop\n    ret._debug = False\n    ret.on_response_prepare = aiosignal.Signal(ret)\n    ret.on_response_prepare.freeze()\n    return ret\n\n\n@pytest.fixture\ndef protocol():\n    ret = mock.Mock()\n    ret.set_parser.return_value = ret\n    return ret\n\n\n@pytest.fixture\ndef make_request(app: Any, protocol: Any):\n    def maker(method, path, headers=None, protocols=False):\n        if headers is None:\n            headers = CIMultiDict(\n                {\n                    \"HOST\": \"server.example.com\",\n                    \"UPGRADE\": \"websocket\",\n                    \"CONNECTION\": \"Upgrade\",\n                    \"SEC-WEBSOCKET-KEY\": \"dGhlIHNhbXBsZSBub25jZQ==\",\n                    \"ORIGIN\": \"http://example.com\",\n                    \"SEC-WEBSOCKET-VERSION\": \"13\",\n                }\n            )\n        if protocols:\n            headers[\"SEC-WEBSOCKET-PROTOCOL\"] = \"chat, superchat\"\n\n        return make_mocked_request(\n            method, path, headers, app=app, protocol=protocol, loop=app.loop\n        )\n\n    return maker\n\n\nasync def test_nonstarted_ping() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.ping()\n\n\nasync def test_nonstarted_pong() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.pong()\n\n\nasync def test_nonstarted_send_str() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.send_str(\"string\")\n\n\nasync def test_nonstarted_send_bytes() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.send_bytes(b\"bytes\")\n\n\nasync def test_nonstarted_send_json() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.send_json({\"type\": \"json\"})\n\n\nasync def test_nonstarted_close() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.close()\n\n\nasync def test_nonstarted_receive_str() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.receive_str()\n\n\nasync def test_nonstarted_receive_bytes() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.receive_bytes()\n\n\nasync def test_nonstarted_receive_json() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.receive_json()\n\n\nasync def test_send_str_nonstring(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    with pytest.raises(TypeError):\n        await ws.send_str(b\"bytes\")\n\n\nasync def test_send_bytes_nonbytes(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    with pytest.raises(TypeError):\n        await ws.send_bytes(\"string\")\n\n\nasync def test_send_json_nonjson(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    with pytest.raises(TypeError):\n        await ws.send_json(set())\n\n\nasync def test_write_non_prepared() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.write(b\"data\")\n\n\nasync def test_heartbeat_timeout(make_request: Any) -> None:\n    \"\"\"Verify the transport is closed when the heartbeat timeout is reached.\"\"\"\n    loop = asyncio.get_running_loop()\n    future = loop.create_future()\n    req = make_request(\"GET\", \"/\")\n    lowest_time = time.get_clock_info(\"monotonic\").resolution\n    req._protocol._timeout_ceil_threshold = lowest_time\n    ws = WebSocketResponse(heartbeat=lowest_time, timeout=lowest_time)\n    await ws.prepare(req)\n    ws._req.transport.close.side_effect = lambda: future.set_result(None)\n    await future\n    assert ws.closed\n\n\ndef test_websocket_ready() -> None:\n    websocket_ready = WebSocketReady(True, \"chat\")\n    assert websocket_ready.ok is True\n    assert websocket_ready.protocol == \"chat\"\n\n\ndef test_websocket_not_ready() -> None:\n    websocket_ready = WebSocketReady(False, None)\n    assert websocket_ready.ok is False\n    assert websocket_ready.protocol is None\n\n\ndef test_websocket_ready_unknown_protocol() -> None:\n    websocket_ready = WebSocketReady(True, None)\n    assert websocket_ready.ok is True\n    assert websocket_ready.protocol is None\n\n\ndef test_bool_websocket_ready() -> None:\n    websocket_ready = WebSocketReady(True, None)\n    assert bool(websocket_ready) is True\n\n\ndef test_bool_websocket_not_ready() -> None:\n    websocket_ready = WebSocketReady(False, None)\n    assert bool(websocket_ready) is False\n\n\ndef test_can_prepare_ok(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\", protocols=True)\n    ws = WebSocketResponse(protocols=(\"chat\",))\n    assert WebSocketReady(True, \"chat\") == ws.can_prepare(req)\n\n\ndef test_can_prepare_unknown_protocol(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    assert WebSocketReady(True, None) == ws.can_prepare(req)\n\n\ndef test_can_prepare_without_upgrade(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\", headers=CIMultiDict({}))\n    ws = WebSocketResponse()\n    assert WebSocketReady(False, None) == ws.can_prepare(req)\n\n\nasync def test_can_prepare_started(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    with pytest.raises(RuntimeError) as ctx:\n        ws.can_prepare(req)\n\n    assert \"Already started\" in str(ctx.value)\n\n\ndef test_closed_after_ctor() -> None:\n    ws = WebSocketResponse()\n    assert not ws.closed\n    assert ws.close_code is None\n\n\nasync def test_send_str_closed(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    ws._reader.feed_data(WS_CLOSED_MESSAGE)\n    await ws.close()\n    assert len(ws._req.transport.close.mock_calls) == 1\n\n    with pytest.raises(ConnectionError):\n        await ws.send_str(\"string\")\n\n\nasync def test_send_bytes_closed(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    ws._reader.feed_data(WS_CLOSED_MESSAGE)\n    await ws.close()\n\n    with pytest.raises(ConnectionError):\n        await ws.send_bytes(b\"bytes\")\n\n\nasync def test_send_json_closed(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    ws._reader.feed_data(WS_CLOSED_MESSAGE)\n    await ws.close()\n\n    with pytest.raises(ConnectionError):\n        await ws.send_json({\"type\": \"json\"})\n\n\nasync def test_ping_closed(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    ws._reader.feed_data(WS_CLOSED_MESSAGE)\n    await ws.close()\n\n    with pytest.raises(ConnectionError):\n        await ws.ping()\n\n\nasync def test_pong_closed(make_request: Any, mocker: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    ws._reader.feed_data(WS_CLOSED_MESSAGE)\n    await ws.close()\n\n    with pytest.raises(ConnectionError):\n        await ws.pong()\n\n\nasync def test_close_idempotent(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    ws._reader.feed_data(WS_CLOSED_MESSAGE)\n    assert await ws.close(code=1, message=\"message1\")\n    assert ws.closed\n    assert len(ws._req.transport.close.mock_calls) == 1\n\n    assert not (await ws.close(code=2, message=\"message2\"))\n\n\nasync def test_prepare_post_method_ok(make_request: Any) -> None:\n    req = make_request(\"POST\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    assert ws.prepared\n\n\nasync def test_prepare_without_upgrade(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\", headers=CIMultiDict({}))\n    ws = WebSocketResponse()\n    with pytest.raises(HTTPBadRequest):\n        await ws.prepare(req)\n\n\nasync def test_wait_closed_before_start() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.close()\n\n\nasync def test_write_eof_not_started() -> None:\n    ws = WebSocketResponse()\n    with pytest.raises(RuntimeError):\n        await ws.write_eof()\n\n\nasync def test_write_eof_idempotent(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    assert len(ws._req.transport.close.mock_calls) == 0\n\n    ws._reader.feed_data(WS_CLOSED_MESSAGE)\n    await ws.close()\n\n    await ws.write_eof()\n    await ws.write_eof()\n    await ws.write_eof()\n    assert len(ws._req.transport.close.mock_calls) == 1\n\n\nasync def test_receive_eofstream_in_reader(make_request: Any, loop: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n\n    ws._reader = mock.Mock()\n    exc = EofStream()\n    res = loop.create_future()\n    res.set_exception(exc)\n    ws._reader.read = make_mocked_coro(res)\n    ws._payload_writer.drain = mock.Mock()\n    ws._payload_writer.drain.return_value = loop.create_future()\n    ws._payload_writer.drain.return_value.set_result(True)\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSED\n    assert ws.closed\n\n\nasync def test_receive_exception_in_reader(make_request: Any, loop: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n\n    ws._reader = mock.Mock()\n    exc = Exception()\n    res = loop.create_future()\n    res.set_exception(exc)\n    ws._reader.read = make_mocked_coro(res)\n    ws._payload_writer.drain = mock.Mock()\n    ws._payload_writer.drain.return_value = loop.create_future()\n    ws._payload_writer.drain.return_value.set_result(True)\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.ERROR\n    assert ws.closed\n    assert len(ws._req.transport.close.mock_calls) == 1\n\n\nasync def test_receive_close_but_left_open(make_request: Any, loop: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    close_message = WSMessage(WSMsgType.CLOSE, 1000, \"close\")\n\n    ws._reader = mock.Mock()\n    ws._reader.read = mock.AsyncMock(return_value=close_message)\n    ws._payload_writer.drain = mock.Mock()\n    ws._payload_writer.drain.return_value = loop.create_future()\n    ws._payload_writer.drain.return_value.set_result(True)\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSE\n    assert ws.closed\n    assert len(ws._req.transport.close.mock_calls) == 1\n\n\nasync def test_receive_closing(make_request: Any, loop: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    closing_message = WSMessage(WSMsgType.CLOSING, 1000, \"closing\")\n\n    ws._reader = mock.Mock()\n    read_mock = mock.AsyncMock(return_value=closing_message)\n    ws._reader.read = read_mock\n    ws._payload_writer.drain = mock.Mock()\n    ws._payload_writer.drain.return_value = loop.create_future()\n    ws._payload_writer.drain.return_value.set_result(True)\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSING\n    assert not ws.closed\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSING\n    assert not ws.closed\n\n    ws._cancel(ConnectionResetError(\"Connection lost\"))\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSING\n\n\nasync def test_close_after_closing(make_request: Any, loop: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    closing_message = WSMessage(WSMsgType.CLOSING, 1000, \"closing\")\n\n    ws._reader = mock.Mock()\n    ws._reader.read = mock.AsyncMock(return_value=closing_message)\n    ws._payload_writer.drain = mock.Mock()\n    ws._payload_writer.drain.return_value = loop.create_future()\n    ws._payload_writer.drain.return_value.set_result(True)\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSING\n    assert not ws.closed\n    assert len(ws._req.transport.close.mock_calls) == 0\n\n    await ws.close()\n    assert ws.closed\n    assert len(ws._req.transport.close.mock_calls) == 1\n\n\nasync def test_receive_timeouterror(make_request: Any, loop: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    assert len(ws._req.transport.close.mock_calls) == 0\n\n    ws._reader = mock.Mock()\n    res = loop.create_future()\n    res.set_exception(asyncio.TimeoutError())\n    ws._reader.read = make_mocked_coro(res)\n\n    with pytest.raises(asyncio.TimeoutError):\n        await ws.receive()\n\n    # Should not close the connection on timeout\n    assert len(ws._req.transport.close.mock_calls) == 0\n\n\nasync def test_multiple_receive_on_close_connection(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    ws._reader.feed_data(WS_CLOSED_MESSAGE)\n    await ws.close()\n\n    await ws.receive()\n    await ws.receive()\n    await ws.receive()\n    await ws.receive()\n\n    with pytest.raises(RuntimeError):\n        await ws.receive()\n\n\nasync def test_concurrent_receive(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    ws._waiting = True\n\n    with pytest.raises(RuntimeError):\n        await ws.receive()\n\n\nasync def test_close_exc(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    assert len(ws._req.transport.close.mock_calls) == 0\n\n    exc = ValueError()\n    ws._writer = mock.Mock()\n    ws._writer.close.side_effect = exc\n    await ws.close()\n    assert ws.closed\n    assert ws.exception() is exc\n    assert len(ws._req.transport.close.mock_calls) == 1\n\n    ws._closed = False\n    ws._writer.close.side_effect = asyncio.CancelledError()\n    with pytest.raises(asyncio.CancelledError):\n        await ws.close()\n\n\nasync def test_prepare_twice_idempotent(make_request: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n\n    impl1 = await ws.prepare(req)\n    impl2 = await ws.prepare(req)\n    assert impl1 is impl2\n\n\nasync def test_send_with_per_message_deflate(make_request: Any, mocker: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws.prepare(req)\n    writer_send = ws._writer.send = make_mocked_coro()\n\n    await ws.send_str(\"string\", compress=15)\n    writer_send.assert_called_with(\"string\", binary=False, compress=15)\n\n    await ws.send_bytes(b\"bytes\", compress=0)\n    writer_send.assert_called_with(b\"bytes\", binary=True, compress=0)\n\n    await ws.send_json(\"[{}]\", compress=9)\n    writer_send.assert_called_with('\"[{}]\"', binary=False, compress=9)\n\n\nasync def test_no_transfer_encoding_header(make_request: Any, mocker: Any) -> None:\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n    await ws._start(req)\n\n    assert \"Transfer-Encoding\" not in ws.headers\n\n\n@pytest.mark.parametrize(\n    \"ws_transport, expected_result\",\n    [\n        (\n            mock.MagicMock(\n                transport=mock.MagicMock(\n                    get_extra_info=lambda name, default=None: {\"test\": \"existent\"}.get(\n                        name, default\n                    )\n                )\n            ),\n            \"existent\",\n        ),\n        (None, \"default\"),\n        (mock.MagicMock(transport=None), \"default\"),\n    ],\n)\nasync def test_get_extra_info(\n    make_request: Any, mocker: Any, ws_transport: Any, expected_result: Any\n) -> None:\n    valid_key = \"test\"\n    default_value = \"default\"\n\n    req = make_request(\"GET\", \"/\")\n    ws = WebSocketResponse()\n\n    await ws.prepare(req)\n    ws._writer = ws_transport\n\n    assert ws.get_extra_info(valid_key, default_value) == expected_result\n", "tests/test_urldispatch.py": "# type: ignore\nimport pathlib\nimport re\nfrom collections.abc import Container, Iterable, Mapping, MutableMapping, Sized\nfrom functools import partial\nfrom typing import Any\nfrom urllib.parse import unquote\n\nimport pytest\nfrom re_assert import Matches\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp import hdrs, web\nfrom aiohttp.test_utils import make_mocked_request\nfrom aiohttp.web import HTTPMethodNotAllowed, HTTPNotFound, Response\nfrom aiohttp.web_urldispatcher import (\n    PATH_SEP,\n    AbstractResource,\n    Domain,\n    DynamicResource,\n    MaskDomain,\n    PlainResource,\n    ResourceRoute,\n    StaticResource,\n    SystemRoute,\n    View,\n    _default_expect_handler,\n)\n\n\ndef make_handler():\n    async def handler(request):\n        return Response(request)  # pragma: no cover\n\n    return handler\n\n\ndef make_partial_handler():\n    async def handler(a, request):\n        return Response(request)  # pragma: no cover\n\n    return partial(handler, 5)\n\n\n@pytest.fixture\ndef app():\n    return web.Application()\n\n\n@pytest.fixture\ndef router(app: Any):\n    return app.router\n\n\n@pytest.fixture\ndef fill_routes(router: Any):\n    def go():\n        route1 = router.add_route(\"GET\", \"/plain\", make_handler())\n        route2 = router.add_route(\"GET\", \"/variable/{name}\", make_handler())\n        resource = router.add_static(\"/static\", pathlib.Path(aiohttp.__file__).parent)\n        return [route1, route2] + list(resource)\n\n    return go\n\n\ndef test_register_uncommon_http_methods(router: Any) -> None:\n    uncommon_http_methods = {\n        \"PROPFIND\",\n        \"PROPPATCH\",\n        \"COPY\",\n        \"LOCK\",\n        \"UNLOCK\",\n        \"MOVE\",\n        \"SUBSCRIBE\",\n        \"UNSUBSCRIBE\",\n        \"NOTIFY\",\n    }\n\n    for method in uncommon_http_methods:\n        router.add_route(method, \"/handler/to/path\", make_handler())\n\n\nasync def test_add_partial_handler(router: Any) -> None:\n    handler = make_partial_handler()\n    router.add_get(\"/handler/to/path\", handler)\n\n\nasync def test_add_sync_handler(router: Any) -> None:\n    def handler(request):\n        pass\n\n    with pytest.raises(TypeError):\n        router.add_get(\"/handler/to/path\", handler)\n\n\nasync def test_add_route_root(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/\", handler)\n    req = make_mocked_request(\"GET\", \"/\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert 0 == len(info)\n    assert handler is info.handler\n    assert info.route.name is None\n\n\nasync def test_add_route_simple(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/handler/to/path\", handler)\n    req = make_mocked_request(\"GET\", \"/handler/to/path\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert 0 == len(info)\n    assert handler is info.handler\n    assert info.route.name is None\n\n\nasync def test_add_with_matchdict(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/handler/{to}\", handler)\n    req = make_mocked_request(\"GET\", \"/handler/tail\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert {\"to\": \"tail\"} == info\n    assert handler is info.handler\n    assert info.route.name is None\n\n\nasync def test_add_with_matchdict_with_colon(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/handler/{to}\", handler)\n    req = make_mocked_request(\"GET\", \"/handler/1:2:3\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert {\"to\": \"1:2:3\"} == info\n    assert handler is info.handler\n    assert info.route.name is None\n\n\nasync def test_add_route_with_add_get_shortcut(router: Any) -> None:\n    handler = make_handler()\n    router.add_get(\"/handler/to/path\", handler)\n    req = make_mocked_request(\"GET\", \"/handler/to/path\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert 0 == len(info)\n    assert handler is info.handler\n    assert info.route.name is None\n\n\nasync def test_add_route_with_add_post_shortcut(router: Any) -> None:\n    handler = make_handler()\n    router.add_post(\"/handler/to/path\", handler)\n    req = make_mocked_request(\"POST\", \"/handler/to/path\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert 0 == len(info)\n    assert handler is info.handler\n    assert info.route.name is None\n\n\nasync def test_add_route_with_add_put_shortcut(router: Any) -> None:\n    handler = make_handler()\n    router.add_put(\"/handler/to/path\", handler)\n    req = make_mocked_request(\"PUT\", \"/handler/to/path\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert 0 == len(info)\n    assert handler is info.handler\n    assert info.route.name is None\n\n\nasync def test_add_route_with_add_patch_shortcut(router: Any) -> None:\n    handler = make_handler()\n    router.add_patch(\"/handler/to/path\", handler)\n    req = make_mocked_request(\"PATCH\", \"/handler/to/path\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert 0 == len(info)\n    assert handler is info.handler\n    assert info.route.name is None\n\n\nasync def test_add_route_with_add_delete_shortcut(router: Any) -> None:\n    handler = make_handler()\n    router.add_delete(\"/handler/to/path\", handler)\n    req = make_mocked_request(\"DELETE\", \"/handler/to/path\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert 0 == len(info)\n    assert handler is info.handler\n    assert info.route.name is None\n\n\nasync def test_add_route_with_add_head_shortcut(router: Any) -> None:\n    handler = make_handler()\n    router.add_head(\"/handler/to/path\", handler)\n    req = make_mocked_request(\"HEAD\", \"/handler/to/path\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert 0 == len(info)\n    assert handler is info.handler\n    assert info.route.name is None\n\n\nasync def test_add_with_name(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/handler/to/path\", handler, name=\"name\")\n    req = make_mocked_request(\"GET\", \"/handler/to/path\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert \"name\" == info.route.name\n\n\nasync def test_add_with_tailing_slash(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/handler/to/path/\", handler)\n    req = make_mocked_request(\"GET\", \"/handler/to/path/\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert {} == info\n    assert handler is info.handler\n\n\ndef test_add_invalid_path(router: Any) -> None:\n    handler = make_handler()\n    with pytest.raises(ValueError):\n        router.add_route(\"GET\", \"/{/\", handler)\n\n\ndef test_add_url_invalid1(router: Any) -> None:\n    handler = make_handler()\n    with pytest.raises(ValueError):\n        router.add_route(\"post\", \"/post/{id\", handler)\n\n\ndef test_add_url_invalid2(router: Any) -> None:\n    handler = make_handler()\n    with pytest.raises(ValueError):\n        router.add_route(\"post\", \"/post/{id{}}\", handler)\n\n\ndef test_add_url_invalid3(router: Any) -> None:\n    handler = make_handler()\n    with pytest.raises(ValueError):\n        router.add_route(\"post\", \"/post/{id{}\", handler)\n\n\ndef test_add_url_invalid4(router: Any) -> None:\n    handler = make_handler()\n    with pytest.raises(ValueError):\n        router.add_route(\"post\", '/post/{id\"}', handler)\n\n\nasync def test_add_url_escaping(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/+$\", handler)\n\n    req = make_mocked_request(\"GET\", \"/+$\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert handler is info.handler\n\n\nasync def test_any_method(router: Any) -> None:\n    handler = make_handler()\n    route = router.add_route(hdrs.METH_ANY, \"/\", handler)\n\n    req = make_mocked_request(\"GET\", \"/\")\n    info1 = await router.resolve(req)\n    assert info1 is not None\n    assert route is info1.route\n\n    req = make_mocked_request(\"POST\", \"/\")\n    info2 = await router.resolve(req)\n    assert info2 is not None\n\n    assert info1.route is info2.route\n\n\nasync def test_match_second_result_in_table(router: Any) -> None:\n    handler1 = make_handler()\n    handler2 = make_handler()\n    router.add_route(\"GET\", \"/h1\", handler1)\n    router.add_route(\"POST\", \"/h2\", handler2)\n    req = make_mocked_request(\"POST\", \"/h2\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert {} == info\n    assert handler2 is info.handler\n\n\nasync def test_raise_method_not_allowed(router: Any) -> None:\n    handler1 = make_handler()\n    handler2 = make_handler()\n    router.add_route(\"GET\", \"/\", handler1)\n    router.add_route(\"POST\", \"/\", handler2)\n    req = make_mocked_request(\"PUT\", \"/\")\n\n    match_info = await router.resolve(req)\n    assert isinstance(match_info.route, SystemRoute)\n    assert {} == match_info\n\n    with pytest.raises(HTTPMethodNotAllowed) as ctx:\n        await match_info.handler(req)\n\n    exc = ctx.value\n    assert \"PUT\" == exc.method\n    assert 405 == exc.status\n    assert {\"POST\", \"GET\"} == exc.allowed_methods\n\n\nasync def test_raise_method_not_found(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/a\", handler)\n    req = make_mocked_request(\"GET\", \"/b\")\n\n    match_info = await router.resolve(req)\n    assert isinstance(match_info.route, SystemRoute)\n    assert {} == match_info\n\n    with pytest.raises(HTTPNotFound) as ctx:\n        await match_info.handler(req)\n\n    exc = ctx.value\n    assert 404 == exc.status\n\n\ndef test_double_add_url_with_the_same_name(router: Any) -> None:\n    handler1 = make_handler()\n    handler2 = make_handler()\n    router.add_route(\"GET\", \"/get\", handler1, name=\"name\")\n\n    regexp = \"Duplicate 'name', already handled by\"\n    with pytest.raises(ValueError) as ctx:\n        router.add_route(\"GET\", \"/get_other\", handler2, name=\"name\")\n    assert Matches(regexp) == str(ctx.value)\n\n\ndef test_route_plain(router: Any) -> None:\n    handler = make_handler()\n    route = router.add_route(\"GET\", \"/get\", handler, name=\"name\")\n    route2 = next(iter(router[\"name\"]))\n    url = route2.url_for()\n    assert \"/get\" == str(url)\n    assert route is route2\n\n\ndef test_route_unknown_route_name(router: Any) -> None:\n    with pytest.raises(KeyError):\n        router[\"unknown\"]\n\n\ndef test_route_dynamic(router: Any) -> None:\n    handler = make_handler()\n    route = router.add_route(\"GET\", \"/get/{name}\", handler, name=\"name\")\n\n    route2 = next(iter(router[\"name\"]))\n    url = route2.url_for(name=\"John\")\n    assert \"/get/John\" == str(url)\n    assert route is route2\n\n\ndef test_add_static(router: Any) -> None:\n    resource = router.add_static(\n        \"/st\", pathlib.Path(aiohttp.__file__).parent, name=\"static\"\n    )\n    assert router[\"static\"] is resource\n    url = resource.url_for(filename=\"/dir/a.txt\")\n    assert \"/st/dir/a.txt\" == str(url)\n    assert len(resource) == 2\n\n\ndef test_add_static_append_version(router: Any) -> None:\n    resource = router.add_static(\"/st\", pathlib.Path(__file__).parent, name=\"static\")\n    url = resource.url_for(filename=\"/data.unknown_mime_type\", append_version=True)\n    expect_url = (\n        \"/st/data.unknown_mime_type?\" \"v=aUsn8CHEhhszc81d28QmlcBW0KQpfS2F4trgQKhOYd8%3D\"\n    )\n    assert expect_url == str(url)\n\n\ndef test_add_static_append_version_set_from_constructor(router: Any) -> None:\n    resource = router.add_static(\n        \"/st\", pathlib.Path(__file__).parent, append_version=True, name=\"static\"\n    )\n    url = resource.url_for(filename=\"/data.unknown_mime_type\")\n    expect_url = (\n        \"/st/data.unknown_mime_type?\" \"v=aUsn8CHEhhszc81d28QmlcBW0KQpfS2F4trgQKhOYd8%3D\"\n    )\n    assert expect_url == str(url)\n\n\ndef test_add_static_append_version_override_constructor(router: Any) -> None:\n    resource = router.add_static(\n        \"/st\", pathlib.Path(__file__).parent, append_version=True, name=\"static\"\n    )\n    url = resource.url_for(filename=\"/data.unknown_mime_type\", append_version=False)\n    expect_url = \"/st/data.unknown_mime_type\"\n    assert expect_url == str(url)\n\n\ndef test_add_static_append_version_filename_without_slash(router: Any) -> None:\n    resource = router.add_static(\"/st\", pathlib.Path(__file__).parent, name=\"static\")\n    url = resource.url_for(filename=\"data.unknown_mime_type\", append_version=True)\n    expect_url = (\n        \"/st/data.unknown_mime_type?\" \"v=aUsn8CHEhhszc81d28QmlcBW0KQpfS2F4trgQKhOYd8%3D\"\n    )\n    assert expect_url == str(url)\n\n\ndef test_add_static_append_version_non_exists_file(router: Any) -> None:\n    resource = router.add_static(\"/st\", pathlib.Path(__file__).parent, name=\"static\")\n    url = resource.url_for(filename=\"/non_exists_file\", append_version=True)\n    assert \"/st/non_exists_file\" == str(url)\n\n\ndef test_add_static_append_version_non_exists_file_without_slash(router: Any) -> None:\n    resource = router.add_static(\"/st\", pathlib.Path(__file__).parent, name=\"static\")\n    url = resource.url_for(filename=\"non_exists_file\", append_version=True)\n    assert \"/st/non_exists_file\" == str(url)\n\n\ndef test_add_static_append_version_follow_symlink(router: Any, tmp_path: Any) -> None:\n    # Tests the access to a symlink, in static folder with apeend_version\n    symlink_path = tmp_path / \"append_version_symlink\"\n    symlink_target_path = pathlib.Path(__file__).parent\n    pathlib.Path(str(symlink_path)).symlink_to(str(symlink_target_path), True)\n\n    # Register global static route:\n    resource = router.add_static(\n        \"/st\", str(tmp_path), follow_symlinks=True, append_version=True\n    )\n\n    url = resource.url_for(filename=\"/append_version_symlink/data.unknown_mime_type\")\n\n    expect_url = (\n        \"/st/append_version_symlink/data.unknown_mime_type?\"\n        \"v=aUsn8CHEhhszc81d28QmlcBW0KQpfS2F4trgQKhOYd8%3D\"\n    )\n    assert expect_url == str(url)\n\n\ndef test_add_static_append_version_not_follow_symlink(\n    router: Any, tmp_path: Any\n) -> None:\n    # Tests the access to a symlink, in static folder with apeend_version\n\n    symlink_path = tmp_path / \"append_version_symlink\"\n    symlink_target_path = pathlib.Path(__file__).parent\n\n    pathlib.Path(str(symlink_path)).symlink_to(str(symlink_target_path), True)\n\n    # Register global static route:\n    resource = router.add_static(\n        \"/st\", str(tmp_path), follow_symlinks=False, append_version=True\n    )\n\n    filename = \"/append_version_symlink/data.unknown_mime_type\"\n    url = resource.url_for(filename=filename)\n    assert \"/st/append_version_symlink/data.unknown_mime_type\" == str(url)\n\n\ndef test_add_static_quoting(router: Any) -> None:\n    resource = router.add_static(\n        \"/\u043f\u0440\u0435 %2F\u0444\u0438\u043a\u0441\", pathlib.Path(aiohttp.__file__).parent, name=\"static\"\n    )\n    assert router[\"static\"] is resource\n    url = resource.url_for(filename=\"/1 2/\u0444\u0430\u0439\u043b%2F.txt\")\n    assert url.path == \"/\u043f\u0440\u0435 /\u0444\u0438\u043a\u0441/1 2/\u0444\u0430\u0439\u043b%2F.txt\"\n    assert str(url) == (\n        \"/%D0%BF%D1%80%D0%B5%20%2F%D1%84%D0%B8%D0%BA%D1%81\"\n        \"/1%202/%D1%84%D0%B0%D0%B9%D0%BB%252F.txt\"\n    )\n    assert len(resource) == 2\n\n\ndef test_plain_not_match(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/get/path\", handler, name=\"name\")\n    route = router[\"name\"]\n    assert route._match(\"/another/path\") is None\n\n\ndef test_dynamic_not_match(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/get/{name}\", handler, name=\"name\")\n    route = router[\"name\"]\n    assert route._match(\"/another/path\") is None\n\n\nasync def test_static_not_match(router: Any) -> None:\n    router.add_static(\"/pre\", pathlib.Path(aiohttp.__file__).parent, name=\"name\")\n    resource = router[\"name\"]\n    ret = await resource.resolve(make_mocked_request(\"GET\", \"/another/path\"))\n    assert (None, set()) == ret\n\n\ndef test_dynamic_with_trailing_slash(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/get/{name}/\", handler, name=\"name\")\n    route = router[\"name\"]\n    assert {\"name\": \"John\"} == route._match(\"/get/John/\")\n\n\ndef test_len(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/get1\", handler, name=\"name1\")\n    router.add_route(\"GET\", \"/get2\", handler, name=\"name2\")\n    assert 2 == len(router)\n\n\ndef test_iter(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/get1\", handler, name=\"name1\")\n    router.add_route(\"GET\", \"/get2\", handler, name=\"name2\")\n    assert {\"name1\", \"name2\"} == set(iter(router))\n\n\ndef test_contains(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/get1\", handler, name=\"name1\")\n    router.add_route(\"GET\", \"/get2\", handler, name=\"name2\")\n    assert \"name1\" in router\n    assert \"name3\" not in router\n\n\ndef test_static_repr(router: Any) -> None:\n    router.add_static(\"/get\", pathlib.Path(aiohttp.__file__).parent, name=\"name\")\n    assert Matches(r\"<StaticResource 'name' /get\") == repr(router[\"name\"])\n\n\ndef test_static_adds_slash(router: Any) -> None:\n    route = router.add_static(\"/prefix\", pathlib.Path(aiohttp.__file__).parent)\n    assert \"/prefix\" == route._prefix\n\n\ndef test_static_remove_trailing_slash(router: Any) -> None:\n    route = router.add_static(\"/prefix/\", pathlib.Path(aiohttp.__file__).parent)\n    assert \"/prefix\" == route._prefix\n\n\nasync def test_add_route_with_re(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", r\"/handler/{to:\\d+}\", handler)\n\n    req = make_mocked_request(\"GET\", \"/handler/1234\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert {\"to\": \"1234\"} == info\n\n    router.add_route(\"GET\", r\"/handler/{name}.html\", handler)\n    req = make_mocked_request(\"GET\", \"/handler/test.html\")\n    info = await router.resolve(req)\n    assert {\"name\": \"test\"} == info\n\n\nasync def test_add_route_with_re_and_slashes(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", r\"/handler/{to:[^/]+/?}\", handler)\n    req = make_mocked_request(\"GET\", \"/handler/1234/\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert {\"to\": \"1234/\"} == info\n\n    router.add_route(\"GET\", r\"/handler/{to:.+}\", handler)\n    req = make_mocked_request(\"GET\", \"/handler/1234/5/6/7\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert {\"to\": \"1234/5/6/7\"} == info\n\n\nasync def test_add_route_with_re_not_match(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", r\"/handler/{to:\\d+}\", handler)\n\n    req = make_mocked_request(\"GET\", \"/handler/tail\")\n    match_info = await router.resolve(req)\n    assert isinstance(match_info.route, SystemRoute)\n    assert {} == match_info\n    with pytest.raises(HTTPNotFound):\n        await match_info.handler(req)\n\n\nasync def test_add_route_with_re_including_slashes(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", r\"/handler/{to:.+}/tail\", handler)\n    req = make_mocked_request(\"GET\", \"/handler/re/with/slashes/tail\")\n    info = await router.resolve(req)\n    assert info is not None\n    assert {\"to\": \"re/with/slashes\"} == info\n\n\ndef test_add_route_with_invalid_re(router: Any) -> None:\n    handler = make_handler()\n    with pytest.raises(ValueError) as ctx:\n        router.add_route(\"GET\", r\"/handler/{to:+++}\", handler)\n    s = str(ctx.value)\n    assert s.startswith(\n        \"Bad pattern '\"\n        + PATH_SEP\n        + \"handler\"\n        + PATH_SEP\n        + \"(?P<to>+++)': nothing to repeat\"\n    )\n    assert ctx.value.__cause__ is None\n\n\ndef test_route_dynamic_with_regex_spec(router: Any) -> None:\n    handler = make_handler()\n    route = router.add_route(\"GET\", r\"/get/{num:^\\d+}\", handler, name=\"name\")\n\n    url = route.url_for(num=\"123\")\n    assert \"/get/123\" == str(url)\n\n\ndef test_route_dynamic_with_regex_spec_and_trailing_slash(router: Any) -> None:\n    handler = make_handler()\n    route = router.add_route(\"GET\", r\"/get/{num:^\\d+}/\", handler, name=\"name\")\n\n    url = route.url_for(num=\"123\")\n    assert \"/get/123/\" == str(url)\n\n\ndef test_route_dynamic_with_regex(router: Any) -> None:\n    handler = make_handler()\n    route = router.add_route(\"GET\", r\"/{one}/{two:.+}\", handler)\n\n    url = route.url_for(one=\"1\", two=\"2\")\n    assert \"/1/2\" == str(url)\n\n\ndef test_route_dynamic_quoting(router: Any) -> None:\n    handler = make_handler()\n    route = router.add_route(\"GET\", r\"/\u043f\u0440\u0435 %2F\u0444\u0438\u043a\u0441/{arg}\", handler)\n\n    url = route.url_for(arg=\"1 2/\u0442\u0435\u043a\u0441\u0442%2F\")\n    assert url.path == \"/\u043f\u0440\u0435 /\u0444\u0438\u043a\u0441/1 2/\u0442\u0435\u043a\u0441\u0442%2F\"\n    assert str(url) == (\n        \"/%D0%BF%D1%80%D0%B5%20%2F%D1%84%D0%B8%D0%BA%D1%81\"\n        \"/1%202/%D1%82%D0%B5%D0%BA%D1%81%D1%82%252F\"\n    )\n\n\nasync def test_regular_match_info(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/get/{name}\", handler)\n\n    req = make_mocked_request(\"GET\", \"/get/john\")\n    match_info = await router.resolve(req)\n    assert {\"name\": \"john\"} == match_info\n    assert Matches(\"<MatchInfo {'name': 'john'}: .+<Dynamic.+>>\") == repr(match_info)\n\n\nasync def test_match_info_with_plus(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/get/{version}\", handler)\n\n    req = make_mocked_request(\"GET\", \"/get/1.0+test\")\n    match_info = await router.resolve(req)\n    assert {\"version\": \"1.0+test\"} == match_info\n\n\nasync def test_not_found_repr(router: Any) -> None:\n    req = make_mocked_request(\"POST\", \"/path/to\")\n    match_info = await router.resolve(req)\n    assert \"<MatchInfoError 404: Not Found>\" == repr(match_info)\n\n\nasync def test_not_allowed_repr(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/path/to\", handler)\n\n    handler2 = make_handler()\n    router.add_route(\"POST\", \"/path/to\", handler2)\n\n    req = make_mocked_request(\"PUT\", \"/path/to\")\n    match_info = await router.resolve(req)\n    assert \"<MatchInfoError 405: Method Not Allowed>\" == repr(match_info)\n\n\ndef test_default_expect_handler(router: Any) -> None:\n    route = router.add_route(\"GET\", \"/\", make_handler())\n    assert route._expect_handler is _default_expect_handler\n\n\ndef test_custom_expect_handler_plain(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    route = router.add_route(\"GET\", \"/\", make_handler(), expect_handler=handler)\n    assert route._expect_handler is handler\n    assert isinstance(route, ResourceRoute)\n\n\ndef test_custom_expect_handler_dynamic(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    route = router.add_route(\n        \"GET\", \"/get/{name}\", make_handler(), expect_handler=handler\n    )\n    assert route._expect_handler is handler\n    assert isinstance(route, ResourceRoute)\n\n\ndef test_expect_handler_non_coroutine(router: Any) -> None:\n    def handler(request):\n        pass\n\n    with pytest.raises(AssertionError):\n        router.add_route(\"GET\", \"/\", make_handler(), expect_handler=handler)\n\n\nasync def test_dynamic_match_non_ascii(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/{var}\", handler)\n    req = make_mocked_request(\n        \"GET\", \"/%D1%80%D1%83%D1%81%20%D1%82%D0%B5%D0%BA%D1%81%D1%82\"\n    )\n    match_info = await router.resolve(req)\n    assert {\"var\": \"\u0440\u0443\u0441 \u0442\u0435\u043a\u0441\u0442\"} == match_info\n\n\nasync def test_dynamic_match_with_static_part(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/{name}.html\", handler)\n    req = make_mocked_request(\"GET\", \"/file.html\")\n    match_info = await router.resolve(req)\n    assert {\"name\": \"file\"} == match_info\n\n\nasync def test_dynamic_match_two_part2(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/{name}.{ext}\", handler)\n    req = make_mocked_request(\"GET\", \"/file.html\")\n    match_info = await router.resolve(req)\n    assert {\"name\": \"file\", \"ext\": \"html\"} == match_info\n\n\nasync def test_dynamic_match_unquoted_path(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/{path}/{subpath}\", handler)\n    resource_id = \"my%2Fpath%7Cwith%21some%25strange%24characters\"\n    req = make_mocked_request(\"GET\", f\"/path/{resource_id}\")\n    match_info = await router.resolve(req)\n    assert match_info == {\"path\": \"path\", \"subpath\": unquote(resource_id)}\n\n\ndef test_add_route_not_started_with_slash(router: Any) -> None:\n    with pytest.raises(ValueError):\n        handler = make_handler()\n        router.add_route(\"GET\", \"invalid_path\", handler)\n\n\ndef test_add_route_invalid_method(router: Any) -> None:\n    sample_bad_methods = {\n        \"BAD METHOD\",\n        \"B@D_METHOD\",\n        \"[BAD_METHOD]\",\n        \"{BAD_METHOD}\",\n        \"(BAD_METHOD)\",\n        \"B?D_METHOD\",\n    }\n\n    for bad_method in sample_bad_methods:\n        with pytest.raises(ValueError):\n            handler = make_handler()\n            router.add_route(bad_method, \"/path\", handler)\n\n\ndef test_routes_view_len(router: Any, fill_routes: Any) -> None:\n    fill_routes()\n    assert 4 == len(router.routes())\n\n\ndef test_routes_view_iter(router: Any, fill_routes: Any) -> None:\n    routes = fill_routes()\n    assert list(routes) == list(router.routes())\n\n\ndef test_routes_view_contains(router: Any, fill_routes: Any) -> None:\n    routes = fill_routes()\n    for route in routes:\n        assert route in router.routes()\n\n\ndef test_routes_abc(router: Any) -> None:\n    assert isinstance(router.routes(), Sized)\n    assert isinstance(router.routes(), Iterable)\n    assert isinstance(router.routes(), Container)\n\n\ndef test_named_resources_abc(router: Any) -> None:\n    assert isinstance(router.named_resources(), Mapping)\n    assert not isinstance(router.named_resources(), MutableMapping)\n\n\ndef test_named_resources(router: Any) -> None:\n    route1 = router.add_route(\"GET\", \"/plain\", make_handler(), name=\"route1\")\n    route2 = router.add_route(\"GET\", \"/variable/{name}\", make_handler(), name=\"route2\")\n    route3 = router.add_static(\n        \"/static\", pathlib.Path(aiohttp.__file__).parent, name=\"route3\"\n    )\n    names = {route1.name, route2.name, route3.name}\n\n    assert 3 == len(router.named_resources())\n\n    for name in names:\n        assert name in router.named_resources()\n        assert isinstance(router.named_resources()[name], AbstractResource)\n\n\ndef test_resource_iter(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    resource = router.add_resource(\"/path\")\n    r1 = resource.add_route(\"GET\", handler)\n    r2 = resource.add_route(\"POST\", handler)\n    assert 2 == len(resource)\n    assert [r1, r2] == list(resource)\n\n\ndef test_view_route(router: Any) -> None:\n    resource = router.add_resource(\"/path\")\n\n    route = resource.add_route(\"*\", View)\n    assert View is route.handler\n\n\ndef test_resource_route_match(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    resource = router.add_resource(\"/path\")\n    route = resource.add_route(\"GET\", handler)\n    assert {} == route.resource._match(\"/path\")\n\n\ndef test_error_on_double_route_adding(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    resource = router.add_resource(\"/path\")\n\n    resource.add_route(\"GET\", handler)\n    with pytest.raises(RuntimeError):\n        resource.add_route(\"GET\", handler)\n\n\ndef test_error_on_adding_route_after_wildcard(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    resource = router.add_resource(\"/path\")\n\n    resource.add_route(\"*\", handler)\n    with pytest.raises(RuntimeError):\n        resource.add_route(\"GET\", handler)\n\n\nasync def test_http_exception_is_none_when_resolved(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/\", handler)\n    req = make_mocked_request(\"GET\", \"/\")\n    info = await router.resolve(req)\n    assert info.http_exception is None\n\n\nasync def test_http_exception_is_not_none_when_not_resolved(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/\", handler)\n    req = make_mocked_request(\"GET\", \"/abc\")\n    info = await router.resolve(req)\n    assert info.http_exception.status == 404\n\n\nasync def test_match_info_get_info_plain(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/\", handler)\n    req = make_mocked_request(\"GET\", \"/\")\n    info = await router.resolve(req)\n    assert info.get_info() == {\"path\": \"/\"}\n\n\nasync def test_match_info_get_info_dynamic(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/{a}\", handler)\n    req = make_mocked_request(\"GET\", \"/value\")\n    info = await router.resolve(req)\n    assert info.get_info() == {\n        \"pattern\": re.compile(PATH_SEP + \"(?P<a>[^{}/]+)\"),\n        \"formatter\": \"/{a}\",\n    }\n\n\nasync def test_match_info_get_info_dynamic2(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/{a}/{b}\", handler)\n    req = make_mocked_request(\"GET\", \"/path/to\")\n    info = await router.resolve(req)\n    assert info.get_info() == {\n        \"pattern\": re.compile(\n            PATH_SEP + \"(?P<a>[^{}/]+)\" + PATH_SEP + \"(?P<b>[^{}/]+)\"\n        ),\n        \"formatter\": \"/{a}/{b}\",\n    }\n\n\ndef test_static_resource_get_info(router: Any) -> None:\n    directory = pathlib.Path(aiohttp.__file__).parent.resolve()\n    resource = router.add_static(\"/st\", directory)\n    info = resource.get_info()\n    assert len(info) == 3\n    assert info[\"directory\"] == directory\n    assert info[\"prefix\"] == \"/st\"\n    assert all([type(r) is ResourceRoute for r in info[\"routes\"].values()])\n\n\nasync def test_system_route_get_info(router: Any) -> None:\n    handler = make_handler()\n    router.add_route(\"GET\", \"/\", handler)\n    req = make_mocked_request(\"GET\", \"/abc\")\n    info = await router.resolve(req)\n    assert info.get_info()[\"http_exception\"].status == 404\n\n\ndef test_resources_view_len(router: Any) -> None:\n    router.add_resource(\"/plain\")\n    router.add_resource(\"/variable/{name}\")\n    assert 2 == len(router.resources())\n\n\ndef test_resources_view_iter(router: Any) -> None:\n    resource1 = router.add_resource(\"/plain\")\n    resource2 = router.add_resource(\"/variable/{name}\")\n    resources = [resource1, resource2]\n    assert list(resources) == list(router.resources())\n\n\ndef test_resources_view_contains(router: Any) -> None:\n    resource1 = router.add_resource(\"/plain\")\n    resource2 = router.add_resource(\"/variable/{name}\")\n    resources = [resource1, resource2]\n    for resource in resources:\n        assert resource in router.resources()\n\n\ndef test_resources_abc(router: Any) -> None:\n    assert isinstance(router.resources(), Sized)\n    assert isinstance(router.resources(), Iterable)\n    assert isinstance(router.resources(), Container)\n\n\ndef test_static_route_user_home(router: Any) -> None:\n    here = pathlib.Path(aiohttp.__file__).parent\n    try:\n        static_dir = pathlib.Path(\"~\") / here.relative_to(pathlib.Path.home())\n    except ValueError:\n        pytest.skip(\"aiohttp folder is not placed in user's HOME\")\n        return  # TODO: Remove and fix type error\n    route = router.add_static(\"/st\", str(static_dir))\n    assert here == route.get_info()[\"directory\"]\n\n\ndef test_static_route_points_to_file(router: Any) -> None:\n    here = pathlib.Path(aiohttp.__file__).parent / \"__init__.py\"\n    with pytest.raises(ValueError):\n        router.add_static(\"/st\", here)\n\n\nasync def test_404_for_static_resource(router: Any) -> None:\n    resource = router.add_static(\"/st\", pathlib.Path(aiohttp.__file__).parent)\n    ret = await resource.resolve(make_mocked_request(\"GET\", \"/unknown/path\"))\n    assert (None, set()) == ret\n\n\nasync def test_405_for_resource_adapter(router: Any) -> None:\n    resource = router.add_static(\"/st\", pathlib.Path(aiohttp.__file__).parent)\n    ret = await resource.resolve(make_mocked_request(\"POST\", \"/st/abc.py\"))\n    assert (None, {\"HEAD\", \"GET\"}) == ret\n\n\nasync def test_check_allowed_method_for_found_resource(router: Any) -> None:\n    handler = make_handler()\n    resource = router.add_resource(\"/\")\n    resource.add_route(\"GET\", handler)\n    ret = await resource.resolve(make_mocked_request(\"GET\", \"/\"))\n    assert ret[0] is not None\n    assert {\"GET\"} == ret[1]\n\n\ndef test_url_for_in_static_resource(router: Any) -> None:\n    resource = router.add_static(\"/static\", pathlib.Path(aiohttp.__file__).parent)\n    assert URL(\"/static/file.txt\") == resource.url_for(filename=\"file.txt\")\n\n\ndef test_url_for_in_static_resource_pathlib(router: Any) -> None:\n    resource = router.add_static(\"/static\", pathlib.Path(aiohttp.__file__).parent)\n    assert URL(\"/static/file.txt\") == resource.url_for(\n        filename=pathlib.Path(\"file.txt\")\n    )\n\n\ndef test_url_for_in_resource_route(router: Any) -> None:\n    route = router.add_route(\"GET\", \"/get/{name}\", make_handler(), name=\"name\")\n    assert URL(\"/get/John\") == route.url_for(name=\"John\")\n\n\ndef test_subapp_get_info(app: Any) -> None:\n    subapp = web.Application()\n    resource = subapp.add_subapp(\"/pre\", subapp)\n    assert resource.get_info() == {\"prefix\": \"/pre\", \"app\": subapp}\n\n\n@pytest.mark.parametrize(\n    \"domain,error\",\n    [\n        (None, TypeError),\n        (\"\", ValueError),\n        (\"http://dom\", ValueError),\n        (\"*.example.com\", ValueError),\n        (\"example$com\", ValueError),\n    ],\n)\ndef test_domain_validation_error(domain: Any, error: Any) -> None:\n    with pytest.raises(error):\n        Domain(domain)\n\n\ndef test_domain_valid() -> None:\n    assert Domain(\"example.com:81\").canonical == \"example.com:81\"\n    assert MaskDomain(\"*.example.com\").canonical == r\".*\\.example\\.com\"\n    assert Domain(\"\u043f\u0443\u043d\u0438.\u043a\u043e\u0434\").canonical == \"xn--h1ajfq.xn--d1alm\"\n\n\n@pytest.mark.parametrize(\n    \"a,b,result\",\n    [\n        (\"example.com\", \"example.com\", True),\n        (\"example.com:81\", \"example.com:81\", True),\n        (\"example.com:81\", \"example.com\", False),\n        (\"\u043f\u0443\u043d\u0438\u043a\u043e\u0434\", \"xn--d1ahgkhc2a\", True),\n        (\"*.example.com\", \"jpg.example.com\", True),\n        (\"*.example.com\", \"a.example.com\", True),\n        (\"*.example.com\", \"example.com\", False),\n    ],\n)\ndef test_match_domain(a: Any, b: Any, result: Any) -> None:\n    if \"*\" in a:\n        rule = MaskDomain(a)\n    else:\n        rule = Domain(a)\n    assert rule.match_domain(b) is result\n\n\ndef test_add_subapp_errors(app: Any) -> None:\n    with pytest.raises(TypeError):\n        app.add_subapp(1, web.Application())\n\n\ndef test_subapp_rule_resource(app: Any) -> None:\n    subapp = web.Application()\n    subapp.router.add_get(\"/\", make_handler())\n    rule = Domain(\"example.com\")\n    assert rule.get_info() == {\"domain\": \"example.com\"}\n    resource = app.add_domain(\"example.com\", subapp)\n    assert resource.canonical == \"example.com\"\n    assert resource.get_info() == {\"rule\": resource._rule, \"app\": subapp}\n    resource.add_prefix(\"/a\")\n    resource.raw_match(\"/b\")\n    assert len(resource)\n    assert list(resource)\n    assert repr(resource).startswith(\"<MatchedSubAppResource\")\n    with pytest.raises(RuntimeError):\n        resource.url_for()\n\n\nasync def test_add_domain_not_str(app: Any, loop: Any) -> None:\n    app = web.Application()\n    with pytest.raises(TypeError):\n        app.add_domain(1, app)\n\n\nasync def test_add_domain(app: Any, loop: Any) -> None:\n    subapp1 = web.Application()\n    h1 = make_handler()\n    subapp1.router.add_get(\"/\", h1)\n    app.add_domain(\"example.com\", subapp1)\n\n    subapp2 = web.Application()\n    h2 = make_handler()\n    subapp2.router.add_get(\"/\", h2)\n    app.add_domain(\"*.example.com\", subapp2)\n\n    subapp3 = web.Application()\n    h3 = make_handler()\n    subapp3.router.add_get(\"/\", h3)\n    app.add_domain(\"*\", subapp3)\n\n    request = make_mocked_request(\"GET\", \"/\", {\"host\": \"example.com\"})\n    match_info = await app.router.resolve(request)\n    assert match_info.route.handler is h1\n\n    request = make_mocked_request(\"GET\", \"/\", {\"host\": \"a.example.com\"})\n    match_info = await app.router.resolve(request)\n    assert match_info.route.handler is h2\n\n    request = make_mocked_request(\"GET\", \"/\", {\"host\": \"example2.com\"})\n    match_info = await app.router.resolve(request)\n    assert match_info.route.handler is h3\n\n    request = make_mocked_request(\"POST\", \"/\", {\"host\": \"example.com\"})\n    match_info = await app.router.resolve(request)\n    assert isinstance(match_info.http_exception, HTTPMethodNotAllowed)\n\n\ndef test_subapp_url_for(app: Any) -> None:\n    subapp = web.Application()\n    resource = app.add_subapp(\"/pre\", subapp)\n    with pytest.raises(RuntimeError):\n        resource.url_for()\n\n\ndef test_subapp_repr(app: Any) -> None:\n    subapp = web.Application()\n    resource = app.add_subapp(\"/pre\", subapp)\n    assert repr(resource).startswith(\"<PrefixedSubAppResource /pre -> <Application\")\n\n\ndef test_subapp_len(app: Any) -> None:\n    subapp = web.Application()\n    subapp.router.add_get(\"/\", make_handler(), allow_head=False)\n    subapp.router.add_post(\"/\", make_handler())\n    resource = app.add_subapp(\"/pre\", subapp)\n    assert len(resource) == 2\n\n\ndef test_subapp_iter(app: Any) -> None:\n    subapp = web.Application()\n    r1 = subapp.router.add_get(\"/\", make_handler(), allow_head=False)\n    r2 = subapp.router.add_post(\"/\", make_handler())\n    resource = app.add_subapp(\"/pre\", subapp)\n    assert list(resource) == [r1, r2]\n\n\n@pytest.mark.parametrize(\n    \"route_name\",\n    (\n        \"invalid name\",\n        \"class\",\n    ),\n)\ndef test_invalid_route_name(router: Any, route_name: str) -> None:\n    with pytest.raises(ValueError):\n        router.add_get(\"/\", make_handler(), name=route_name)\n\n\ndef test_frozen_router(router: Any) -> None:\n    router.freeze()\n    with pytest.raises(RuntimeError):\n        router.add_get(\"/\", make_handler())\n\n\ndef test_frozen_router_subapp(app: Any) -> None:\n    subapp = web.Application()\n    subapp.freeze()\n    with pytest.raises(RuntimeError):\n        app.add_subapp(\"/pre\", subapp)\n\n\ndef test_frozen_app_on_subapp(app: Any) -> None:\n    app.freeze()\n    subapp = web.Application()\n    with pytest.raises(RuntimeError):\n        app.add_subapp(\"/pre\", subapp)\n\n\ndef test_set_options_route(router: Any) -> None:\n    resource = router.add_static(\"/static\", pathlib.Path(aiohttp.__file__).parent)\n    options = None\n    for route in resource:\n        if route.method == \"OPTIONS\":\n            options = route\n    assert options is None\n    resource.set_options_route(make_handler())\n    for route in resource:\n        if route.method == \"OPTIONS\":\n            options = route\n    assert options is not None\n\n    with pytest.raises(RuntimeError):\n        resource.set_options_route(make_handler())\n\n\ndef test_dynamic_url_with_name_started_from_underscore(router: Any) -> None:\n    route = router.add_route(\"GET\", \"/get/{_name}\", make_handler())\n    assert URL(\"/get/John\") == route.url_for(_name=\"John\")\n\n\ndef test_cannot_add_subapp_with_empty_prefix(app: Any) -> None:\n    subapp = web.Application()\n    with pytest.raises(ValueError):\n        app.add_subapp(\"\", subapp)\n\n\ndef test_cannot_add_subapp_with_slash_prefix(app: Any) -> None:\n    subapp = web.Application()\n    with pytest.raises(ValueError):\n        app.add_subapp(\"/\", subapp)\n\n\nasync def test_convert_empty_path_to_slash_on_freezing(router: Any) -> None:\n    handler = make_handler()\n    route = router.add_get(\"\", handler)\n    resource = route.resource\n    assert resource.get_info() == {\"path\": \"\"}\n    router.freeze()\n    assert resource.get_info() == {\"path\": \"/\"}\n\n\ndef test_plain_resource_canonical() -> None:\n    canonical = \"/plain/path\"\n    res = PlainResource(path=canonical)\n    assert res.canonical == canonical\n\n\ndef test_dynamic_resource_canonical() -> None:\n    canonicals = {\n        \"/get/{name}\": \"/get/{name}\",\n        r\"/get/{num:^\\d+}\": \"/get/{num}\",\n        r\"/handler/{to:\\d+}\": r\"/handler/{to}\",\n        r\"/{one}/{two:.+}\": r\"/{one}/{two}\",\n    }\n    for pattern, canonical in canonicals.items():\n        res = DynamicResource(path=pattern)\n        assert res.canonical == canonical\n\n\ndef test_static_resource_canonical() -> None:\n    prefix = \"/prefix\"\n    directory = str(pathlib.Path(aiohttp.__file__).parent)\n    canonical = prefix\n    res = StaticResource(prefix=prefix, directory=directory)\n    assert res.canonical == canonical\n\n\ndef test_prefixed_subapp_resource_canonical(app: Any) -> None:\n    canonical = \"/prefix\"\n    subapp = web.Application()\n    res = subapp.add_subapp(canonical, subapp)\n    assert res.canonical == canonical\n\n\nasync def test_prefixed_subapp_overlap(app: Any) -> None:\n    # Subapp should not overshadow other subapps with overlapping prefixes\n    subapp1 = web.Application()\n    handler1 = make_handler()\n    subapp1.router.add_get(\"/a\", handler1)\n    app.add_subapp(\"/s\", subapp1)\n\n    subapp2 = web.Application()\n    handler2 = make_handler()\n    subapp2.router.add_get(\"/b\", handler2)\n    app.add_subapp(\"/ss\", subapp2)\n\n    subapp3 = web.Application()\n    handler3 = make_handler()\n    subapp3.router.add_get(\"/c\", handler3)\n    app.add_subapp(\"/s/s\", subapp3)\n\n    match_info = await app.router.resolve(make_mocked_request(\"GET\", \"/s/a\"))\n    assert match_info.route.handler is handler1\n    match_info = await app.router.resolve(make_mocked_request(\"GET\", \"/ss/b\"))\n    assert match_info.route.handler is handler2\n    match_info = await app.router.resolve(make_mocked_request(\"GET\", \"/s/s/c\"))\n    assert match_info.route.handler is handler3\n\n\nasync def test_prefixed_subapp_empty_route(app: Any) -> None:\n    subapp = web.Application()\n    handler = make_handler()\n    subapp.router.add_get(\"\", handler)\n    app.add_subapp(\"/s\", subapp)\n\n    match_info = await app.router.resolve(make_mocked_request(\"GET\", \"/s\"))\n    assert match_info.route.handler is handler\n    match_info = await app.router.resolve(make_mocked_request(\"GET\", \"/s/\"))\n    assert \"<MatchInfoError 404: Not Found>\" == repr(match_info)\n\n\nasync def test_prefixed_subapp_root_route(app: Any) -> None:\n    subapp = web.Application()\n    handler = make_handler()\n    subapp.router.add_get(\"/\", handler)\n    app.add_subapp(\"/s\", subapp)\n\n    match_info = await app.router.resolve(make_mocked_request(\"GET\", \"/s/\"))\n    assert match_info.route.handler is handler\n    match_info = await app.router.resolve(make_mocked_request(\"GET\", \"/s\"))\n    assert \"<MatchInfoError 404: Not Found>\" == repr(match_info)\n", "tests/test_classbasedview.py": "from unittest import mock\n\nimport pytest\n\nfrom aiohttp import web\nfrom aiohttp.web_urldispatcher import View\n\n\ndef test_ctor() -> None:\n    request = mock.Mock()\n    view = View(request)\n    assert view.request is request\n\n\nasync def test_render_ok() -> None:\n    resp = web.Response(text=\"OK\")\n\n    class MyView(View):\n        async def get(self) -> web.StreamResponse:\n            return resp\n\n    request = mock.Mock()\n    request.method = \"GET\"\n    resp2 = await MyView(request)\n    assert resp is resp2\n\n\nasync def test_render_unknown_method() -> None:\n    class MyView(View):\n        async def get(self) -> web.StreamResponse:\n            return web.Response(text=\"OK\")\n\n        options = get\n\n    request = mock.Mock()\n    request.method = \"UNKNOWN\"\n    with pytest.raises(web.HTTPMethodNotAllowed) as ctx:\n        await MyView(request)\n    assert ctx.value.headers[\"allow\"] == \"GET,OPTIONS\"\n    assert ctx.value.status == 405\n\n\nasync def test_render_unsupported_method() -> None:\n    class MyView(View):\n        async def get(self) -> web.StreamResponse:\n            return web.Response(text=\"OK\")\n\n        options = delete = get\n\n    request = mock.Mock()\n    request.method = \"POST\"\n    with pytest.raises(web.HTTPMethodNotAllowed) as ctx:\n        await MyView(request)\n    assert ctx.value.headers[\"allow\"] == \"DELETE,GET,OPTIONS\"\n    assert ctx.value.status == 405\n", "tests/test_web_websocket_functional.py": "# type: ignore\n# HTTP websocket server functional tests\n\nimport asyncio\nimport contextlib\nimport sys\nfrom typing import Any, Optional\n\nimport pytest\n\nimport aiohttp\nfrom aiohttp import WSServerHandshakeError, web\nfrom aiohttp.http import WSCloseCode, WSMsgType\n\n\nasync def test_websocket_can_prepare(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        if not ws.can_prepare(request):\n            raise web.HTTPUpgradeRequired()\n\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 426\n\n\nasync def test_websocket_json(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        if not ws.can_prepare(request):\n            return web.HTTPUpgradeRequired()\n\n        await ws.prepare(request)\n        msg = await ws.receive()\n\n        msg_json = msg.json()\n        answer = msg_json[\"test\"]\n        await ws.send_str(answer)\n\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    expected_value = \"value\"\n    payload = '{\"test\": \"%s\"}' % expected_value\n    await ws.send_str(payload)\n\n    resp = await ws.receive()\n    assert resp.data == expected_value\n\n\nasync def test_websocket_json_invalid_message(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        try:\n            await ws.receive_json()\n        except ValueError:\n            await ws.send_str(\"ValueError was raised\")\n        else:\n            raise Exception(\"No Exception\")\n        finally:\n            await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    payload = \"NOT A VALID JSON STRING\"\n    await ws.send_str(payload)\n\n    data = await ws.receive_str()\n    assert \"ValueError was raised\" in data\n\n\nasync def test_websocket_send_json(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        data = await ws.receive_json()\n        await ws.send_json(data)\n\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    expected_value = \"value\"\n    await ws.send_json({\"test\": expected_value})\n\n    data = await ws.receive_json()\n    assert data[\"test\"] == expected_value\n\n\nasync def test_websocket_receive_json(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        data = await ws.receive_json()\n        answer = data[\"test\"]\n        await ws.send_str(answer)\n\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    expected_value = \"value\"\n    payload = '{\"test\": \"%s\"}' % expected_value\n    await ws.send_str(payload)\n\n    resp = await ws.receive()\n    assert resp.data == expected_value\n\n\nasync def test_send_recv_text(loop: Any, aiohttp_client: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        msg = await ws.receive_str()\n        await ws.send_str(msg + \"/answer\")\n        await ws.close()\n        closed.set_result(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    await ws.send_str(\"ask\")\n    msg = await ws.receive()\n    assert msg.type == aiohttp.WSMsgType.TEXT\n    assert \"ask/answer\" == msg.data\n\n    msg = await ws.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSE\n    assert msg.data == WSCloseCode.OK\n    assert msg.extra == \"\"\n\n    assert ws.closed\n    assert ws.close_code == WSCloseCode.OK\n\n    await closed\n\n\nasync def test_send_recv_bytes(loop: Any, aiohttp_client: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_bytes()\n        await ws.send_bytes(msg + b\"/answer\")\n        await ws.close()\n        closed.set_result(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    await ws.send_bytes(b\"ask\")\n    msg = await ws.receive()\n    assert msg.type == aiohttp.WSMsgType.BINARY\n    assert b\"ask/answer\" == msg.data\n\n    msg = await ws.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSE\n    assert msg.data == WSCloseCode.OK\n    assert msg.extra == \"\"\n\n    assert ws.closed\n    assert ws.close_code == WSCloseCode.OK\n\n    await closed\n\n\nasync def test_send_recv_json(loop: Any, aiohttp_client: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        data = await ws.receive_json()\n        await ws.send_json({\"response\": data[\"request\"]})\n        await ws.close()\n        closed.set_result(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n\n    await ws.send_str('{\"request\": \"test\"}')\n    msg = await ws.receive()\n    data = msg.json()\n    assert msg.type == aiohttp.WSMsgType.TEXT\n    assert data[\"response\"] == \"test\"\n\n    msg = await ws.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSE\n    assert msg.data == WSCloseCode.OK\n    assert msg.extra == \"\"\n\n    await ws.close()\n\n    await closed\n\n\nasync def test_close_timeout(loop: Any, aiohttp_client: Any) -> None:\n    aborted = loop.create_future()\n    elapsed = 1e10  # something big\n\n    async def handler(request):\n        nonlocal elapsed\n        ws = web.WebSocketResponse(timeout=0.1)\n        await ws.prepare(request)\n        assert \"request\" == (await ws.receive_str())\n        await ws.send_str(\"reply\")\n        begin = ws._loop.time()\n        assert await ws.close()\n        elapsed = ws._loop.time() - begin\n        assert ws.close_code == WSCloseCode.ABNORMAL_CLOSURE\n        assert isinstance(ws.exception(), asyncio.TimeoutError)\n        aborted.set_result(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    await ws.send_str(\"request\")\n    assert \"reply\" == (await ws.receive_str())\n\n    # The server closes here.  Then the client sends bogus messages with an\n    # interval shorter than server-side close timeout, to make the server\n    # hanging indefinitely.\n    await asyncio.sleep(0.08)\n    msg = await ws._reader.read()\n    assert msg.type == WSMsgType.CLOSE\n\n    await asyncio.sleep(0.08)\n    assert await aborted\n\n    assert elapsed < 0.25, \"close() should have returned before \" \"at most 2x timeout.\"\n\n    await ws.close()\n\n\nasync def test_concurrent_close(loop: Any, aiohttp_client: Any) -> None:\n    srv_ws = None\n\n    async def handler(request):\n        nonlocal srv_ws\n        ws = srv_ws = web.WebSocketResponse(autoclose=False, protocols=(\"foo\", \"bar\"))\n        await ws.prepare(request)\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.CLOSING\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.CLOSING\n\n        await asyncio.sleep(0)\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.CLOSED\n\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", autoclose=False, protocols=(\"eggs\", \"bar\"))\n\n    await srv_ws.close(code=WSCloseCode.INVALID_TEXT)\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSE\n\n    await asyncio.sleep(0)\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSED\n\n\nasync def test_close_op_code_from_client(loop: Any, aiohttp_client: Any) -> None:\n    srv_ws: Optional[web.WebSocketResponse] = None\n\n    async def handler(request):\n        nonlocal srv_ws\n        ws = srv_ws = web.WebSocketResponse(protocols=(\"foo\", \"bar\"))\n        await ws.prepare(request)\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.CLOSE\n        await asyncio.sleep(0)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws: web.WebSocketResponse = await client.ws_connect(\"/\", protocols=(\"eggs\", \"bar\"))\n\n    await ws._writer._send_frame(b\"\", WSMsgType.CLOSE)\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSE\n\n    await asyncio.sleep(0)\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSED\n\n\nasync def test_auto_pong_with_closing_by_peer(loop: Any, aiohttp_client: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        await ws.receive()\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.CLOSE\n        assert msg.data == WSCloseCode.OK\n        assert msg.extra == \"exit message\"\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", autoclose=False, autoping=False)\n    await ws.ping()\n    await ws.send_str(\"ask\")\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.PONG\n    await ws.close(code=WSCloseCode.OK, message=\"exit message\")\n    await closed\n\n\nasync def test_ping(loop: Any, aiohttp_client: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        await ws.ping(\"data\")\n        await ws.receive()\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", autoping=False)\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.PING\n    assert msg.data == b\"data\"\n    await ws.pong()\n    await ws.close()\n    await closed\n\n\nasync def aiohttp_client_ping(loop: Any, aiohttp_client: Any):\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        await ws.receive()\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", autoping=False)\n\n    await ws.ping(\"data\")\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.PONG\n    assert msg.data == b\"data\"\n    await ws.pong()\n    await ws.close()\n\n\nasync def test_pong(loop: Any, aiohttp_client: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse(autoping=False)\n        await ws.prepare(request)\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.PING\n        await ws.pong(\"data\")\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.CLOSE\n        assert msg.data == WSCloseCode.OK\n        assert msg.extra == \"exit message\"\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", autoping=False)\n\n    await ws.ping(\"data\")\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.PONG\n    assert msg.data == b\"data\"\n\n    await ws.close(code=WSCloseCode.OK, message=\"exit message\")\n\n    await closed\n\n\nasync def test_change_status(loop: Any, aiohttp_client: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        ws.set_status(200)\n        assert 200 == ws.status\n        await ws.prepare(request)\n        assert 101 == ws.status\n        await ws.close()\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", autoping=False)\n\n    await ws.close()\n    await closed\n    await ws.close()\n\n\nasync def test_handle_protocol(loop: Any, aiohttp_client: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse(protocols=(\"foo\", \"bar\"))\n        await ws.prepare(request)\n        await ws.close()\n        assert \"bar\" == ws.ws_protocol\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", protocols=(\"eggs\", \"bar\"))\n\n    await ws.close()\n    await closed\n\n\nasync def test_server_close_handshake(loop: Any, aiohttp_client: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse(protocols=(\"foo\", \"bar\"))\n        await ws.prepare(request)\n        await ws.close()\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", autoclose=False, protocols=(\"eggs\", \"bar\"))\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSE\n    await ws.close()\n    await closed\n\n\nasync def aiohttp_client_close_handshake(loop: Any, aiohttp_client: Any):\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse(autoclose=False, protocols=(\"foo\", \"bar\"))\n        await ws.prepare(request)\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.CLOSE\n        assert not ws.closed\n        await ws.close()\n        assert ws.closed\n        assert ws.close_code == WSCloseCode.INVALID_TEXT\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.CLOSED\n\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", autoclose=False, protocols=(\"eggs\", \"bar\"))\n\n    await ws.close(code=WSCloseCode.INVALID_TEXT)\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSED\n    await closed\n\n\nasync def test_server_close_handshake_server_eats_client_messages(\n    loop: Any, aiohttp_client: Any\n):\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse(protocols=(\"foo\", \"bar\"))\n        await ws.prepare(request)\n        await ws.close()\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\n        \"/\", autoclose=False, autoping=False, protocols=(\"eggs\", \"bar\")\n    )\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.CLOSE\n\n    await ws.send_str(\"text\")\n    await ws.send_bytes(b\"bytes\")\n    await ws.ping()\n\n    await ws.close()\n    await closed\n\n\nasync def test_receive_timeout(loop: Any, aiohttp_client: Any) -> None:\n    raised = False\n\n    async def handler(request):\n        ws = web.WebSocketResponse(receive_timeout=0.1)\n        await ws.prepare(request)\n\n        try:\n            await ws.receive()\n        except asyncio.TimeoutError:\n            nonlocal raised\n            raised = True\n\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    await ws.receive()\n    await ws.close()\n    assert raised\n\n\nasync def test_custom_receive_timeout(loop: Any, aiohttp_client: Any) -> None:\n    raised = False\n\n    async def handler(request):\n        ws = web.WebSocketResponse(receive_timeout=None)\n        await ws.prepare(request)\n\n        try:\n            await ws.receive(0.1)\n        except asyncio.TimeoutError:\n            nonlocal raised\n            raised = True\n\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    await ws.receive()\n    await ws.close()\n    assert raised\n\n\nasync def test_heartbeat(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse(heartbeat=0.05)\n        await ws.prepare(request)\n        await ws.receive()\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app)\n    ws = await client.ws_connect(\"/\", autoping=False)\n    msg = await ws.receive()\n\n    assert msg.type == aiohttp.WSMsgType.PING\n\n    await ws.close()\n\n\nasync def test_heartbeat_no_pong(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse(heartbeat=0.05)\n        await ws.prepare(request)\n\n        await ws.receive()\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app)\n    ws = await client.ws_connect(\"/\", autoping=False)\n    msg = await ws.receive()\n    assert msg.type == aiohttp.WSMsgType.PING\n    await ws.close()\n\n\nasync def test_server_ws_async_for(loop: Any, aiohttp_server: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        async for msg in ws:\n            assert msg.type == aiohttp.WSMsgType.TEXT\n            s = msg.data\n            await ws.send_str(s + \"/answer\")\n        await ws.close()\n        closed.set_result(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app)\n\n    async with aiohttp.ClientSession() as sm:\n        async with sm.ws_connect(server.make_url(\"/\")) as resp:\n            items = [\"q1\", \"q2\", \"q3\"]\n            for item in items:\n                await resp.send_str(item)\n                msg = await resp.receive()\n                assert msg.type == aiohttp.WSMsgType.TEXT\n                assert item + \"/answer\" == msg.data\n\n            await resp.close()\n            await closed\n\n\nasync def test_closed_async_for(loop: Any, aiohttp_client: Any) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        messages = []\n        async for msg in ws:\n            messages.append(msg)\n            if \"stop\" == msg.data:\n                await ws.send_str(\"stopping\")\n                await ws.close()\n\n        assert 1 == len(messages)\n        assert messages[0].type == WSMsgType.TEXT\n        assert messages[0].data == \"stop\"\n\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    await ws.send_str(\"stop\")\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.TEXT\n    assert msg.data == \"stopping\"\n\n    await ws.close()\n    await closed\n\n\nasync def test_websocket_disable_keepalive(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        if not ws.can_prepare(request):\n            return web.Response(text=\"OK\")\n        assert request.protocol._keepalive\n        await ws.prepare(request)\n        assert not request.protocol._keepalive\n        assert not request.protocol._keepalive_handle\n\n        await ws.send_str(\"OK\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    txt = await resp.text()\n    assert txt == \"OK\"\n\n    ws = await client.ws_connect(\"/\")\n    data = await ws.receive_str()\n    assert data == \"OK\"\n\n\nasync def test_receive_str_nonstring(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        if not ws.can_prepare(request):\n            return web.HTTPUpgradeRequired()\n\n        await ws.prepare(request)\n        await ws.send_bytes(b\"answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    with pytest.raises(TypeError):\n        await ws.receive_str()\n\n\nasync def test_receive_bytes_nonbytes(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        if not ws.can_prepare(request):\n            return web.HTTPUpgradeRequired()\n\n        await ws.prepare(request)\n        await ws.send_bytes(\"answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\")\n    with pytest.raises(TypeError):\n        await ws.receive_bytes()\n\n\nasync def test_bug3380(loop: Any, aiohttp_client: Any) -> None:\n    async def handle_null(request):\n        return aiohttp.web.json_response({\"err\": None})\n\n    async def ws_handler(request):\n        return web.Response(status=401)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/ws\", ws_handler)\n    app.router.add_route(\"GET\", \"/api/null\", handle_null)\n\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/api/null\")\n    assert (await resp.json()) == {\"err\": None}\n    resp.close()\n\n    with pytest.raises(WSServerHandshakeError):\n        await client.ws_connect(\"/ws\")\n\n    resp = await client.get(\"/api/null\", timeout=aiohttp.ClientTimeout(total=1))\n    assert (await resp.json()) == {\"err\": None}\n    resp.close()\n\n\nasync def test_receive_being_cancelled_keeps_connection_open(\n    loop: Any, aiohttp_client: Any\n) -> None:\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse(autoping=False)\n        await ws.prepare(request)\n\n        task = asyncio.create_task(ws.receive())\n        await asyncio.sleep(0)\n        task.cancel()\n        with contextlib.suppress(asyncio.CancelledError):\n            await task\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.PING\n        await asyncio.sleep(0)\n        await ws.pong(\"data\")\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.CLOSE\n        assert msg.data == WSCloseCode.OK\n        assert msg.extra == \"exit message\"\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", autoping=False)\n\n    await asyncio.sleep(0)\n    await ws.ping(\"data\")\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.PONG\n    assert msg.data == b\"data\"\n\n    await ws.close(code=WSCloseCode.OK, message=\"exit message\")\n\n    await closed\n\n\nasync def test_receive_timeout_keeps_connection_open(\n    loop: Any, aiohttp_client: Any\n) -> None:\n    closed = loop.create_future()\n    timed_out = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse(autoping=False)\n        await ws.prepare(request)\n\n        task = asyncio.create_task(ws.receive(sys.float_info.min))\n        with contextlib.suppress(asyncio.TimeoutError):\n            await task\n\n        timed_out.set_result(None)\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.PING\n        await asyncio.sleep(0)\n        await ws.pong(\"data\")\n\n        msg = await ws.receive()\n        assert msg.type == WSMsgType.CLOSE\n        assert msg.data == WSCloseCode.OK\n        assert msg.extra == \"exit message\"\n        closed.set_result(None)\n        return ws\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    ws = await client.ws_connect(\"/\", autoping=False)\n\n    await timed_out\n    await ws.ping(\"data\")\n\n    msg = await ws.receive()\n    assert msg.type == WSMsgType.PONG\n    assert msg.data == b\"data\"\n\n    await ws.close(code=WSCloseCode.OK, message=\"exit message\")\n\n    await closed\n", "tests/test_run_app.py": "# type: ignore\nimport asyncio\nimport contextlib\nimport logging\nimport os\nimport platform\nimport signal\nimport socket\nimport ssl\nimport subprocess\nimport sys\nimport time\nfrom typing import Any, Callable, NoReturn, Set\nfrom unittest import mock\nfrom uuid import uuid4\n\nimport pytest\n\nfrom aiohttp import ClientConnectorError, ClientSession, WSCloseCode, web\nfrom aiohttp.test_utils import make_mocked_coro\nfrom aiohttp.web_runner import BaseRunner\n\n_has_unix_domain_socks = hasattr(socket, \"AF_UNIX\")\nif _has_unix_domain_socks:\n    with socket.socket(socket.AF_UNIX, socket.SOCK_STREAM) as _abstract_path_sock:\n        try:\n            _abstract_path_sock.bind(b\"\\x00\" + uuid4().hex.encode(\"ascii\"))\n        except FileNotFoundError:\n            _abstract_path_failed = True\n        else:\n            _abstract_path_failed = False\n        finally:\n            del _abstract_path_sock\nelse:\n    _abstract_path_failed = True\n\nskip_if_no_abstract_paths: Any = pytest.mark.skipif(\n    _abstract_path_failed, reason=\"Linux-style abstract paths are not supported.\"\n)\nskip_if_no_unix_socks: Any = pytest.mark.skipif(\n    not _has_unix_domain_socks, reason=\"Unix domain sockets are not supported\"\n)\ndel _has_unix_domain_socks, _abstract_path_failed\n\nHAS_IPV6: bool = socket.has_ipv6\nif HAS_IPV6:\n    # The socket.has_ipv6 flag may be True if Python was built with IPv6\n    # support, but the target system still may not have it.\n    # So let's ensure that we really have IPv6 support.\n    try:\n        with socket.socket(socket.AF_INET6, socket.SOCK_STREAM):\n            pass\n    except OSError:\n        HAS_IPV6 = False\n\n\ndef skip_if_on_windows() -> None:\n    if platform.system() == \"Windows\":\n        pytest.skip(\"the test is not valid for Windows\")\n\n\n@pytest.fixture\ndef patched_loop(loop: Any):\n    server = mock.Mock()\n    server.wait_closed = make_mocked_coro(None)\n    loop.create_server = make_mocked_coro(server)\n    unix_server = mock.Mock()\n    unix_server.wait_closed = make_mocked_coro(None)\n    loop.create_unix_server = make_mocked_coro(unix_server)\n    asyncio.set_event_loop(loop)\n    return loop\n\n\ndef stopper(loop: Any):\n    def raiser():\n        raise KeyboardInterrupt\n\n    def f(*args):\n        loop.call_soon(raiser)\n\n    return f\n\n\ndef test_run_app_http(patched_loop: Any) -> None:\n    app = web.Application()\n    startup_handler = make_mocked_coro()\n    app.on_startup.append(startup_handler)\n    cleanup_handler = make_mocked_coro()\n    app.on_cleanup.append(cleanup_handler)\n\n    web.run_app(app, print=stopper(patched_loop), loop=patched_loop)\n\n    patched_loop.create_server.assert_called_with(\n        mock.ANY, None, 8080, ssl=None, backlog=128, reuse_address=None, reuse_port=None\n    )\n    startup_handler.assert_called_once_with(app)\n    cleanup_handler.assert_called_once_with(app)\n\n\ndef test_run_app_close_loop(patched_loop: Any) -> None:\n    app = web.Application()\n    web.run_app(app, print=stopper(patched_loop), loop=patched_loop)\n\n    patched_loop.create_server.assert_called_with(\n        mock.ANY, None, 8080, ssl=None, backlog=128, reuse_address=None, reuse_port=None\n    )\n    assert patched_loop.is_closed()\n\n\nmock_unix_server_single: Any = [\n    mock.call(mock.ANY, \"/tmp/testsock1.sock\", ssl=None, backlog=128),\n]\nmock_unix_server_multi: Any = [\n    mock.call(mock.ANY, \"/tmp/testsock1.sock\", ssl=None, backlog=128),\n    mock.call(mock.ANY, \"/tmp/testsock2.sock\", ssl=None, backlog=128),\n]\nmock_server_single: Any = [\n    mock.call(\n        mock.ANY,\n        \"127.0.0.1\",\n        8080,\n        ssl=None,\n        backlog=128,\n        reuse_address=None,\n        reuse_port=None,\n    ),\n]\nmock_server_multi: Any = [\n    mock.call(\n        mock.ANY,\n        \"127.0.0.1\",\n        8080,\n        ssl=None,\n        backlog=128,\n        reuse_address=None,\n        reuse_port=None,\n    ),\n    mock.call(\n        mock.ANY,\n        \"192.168.1.1\",\n        8080,\n        ssl=None,\n        backlog=128,\n        reuse_address=None,\n        reuse_port=None,\n    ),\n]\nmock_server_default_8989: Any = [\n    mock.call(\n        mock.ANY, None, 8989, ssl=None, backlog=128, reuse_address=None, reuse_port=None\n    )\n]\nmock_socket: Any = mock.Mock(getsockname=lambda: (\"mock-socket\", 123))\nmixed_bindings_tests: Any = (\n    (\n        \"Nothing Specified\",\n        {},\n        [\n            mock.call(\n                mock.ANY,\n                None,\n                8080,\n                ssl=None,\n                backlog=128,\n                reuse_address=None,\n                reuse_port=None,\n            )\n        ],\n        [],\n    ),\n    (\"Port Only\", {\"port\": 8989}, mock_server_default_8989, []),\n    (\"Multiple Hosts\", {\"host\": (\"127.0.0.1\", \"192.168.1.1\")}, mock_server_multi, []),\n    (\n        \"Multiple Paths\",\n        {\"path\": (\"/tmp/testsock1.sock\", \"/tmp/testsock2.sock\")},\n        [],\n        mock_unix_server_multi,\n    ),\n    (\n        \"Multiple Paths, Port\",\n        {\"path\": (\"/tmp/testsock1.sock\", \"/tmp/testsock2.sock\"), \"port\": 8989},\n        mock_server_default_8989,\n        mock_unix_server_multi,\n    ),\n    (\n        \"Multiple Paths, Single Host\",\n        {\"path\": (\"/tmp/testsock1.sock\", \"/tmp/testsock2.sock\"), \"host\": \"127.0.0.1\"},\n        mock_server_single,\n        mock_unix_server_multi,\n    ),\n    (\n        \"Single Path, Single Host\",\n        {\"path\": \"/tmp/testsock1.sock\", \"host\": \"127.0.0.1\"},\n        mock_server_single,\n        mock_unix_server_single,\n    ),\n    (\n        \"Single Path, Multiple Hosts\",\n        {\"path\": \"/tmp/testsock1.sock\", \"host\": (\"127.0.0.1\", \"192.168.1.1\")},\n        mock_server_multi,\n        mock_unix_server_single,\n    ),\n    (\n        \"Single Path, Port\",\n        {\"path\": \"/tmp/testsock1.sock\", \"port\": 8989},\n        mock_server_default_8989,\n        mock_unix_server_single,\n    ),\n    (\n        \"Multiple Paths, Multiple Hosts, Port\",\n        {\n            \"path\": (\"/tmp/testsock1.sock\", \"/tmp/testsock2.sock\"),\n            \"host\": (\"127.0.0.1\", \"192.168.1.1\"),\n            \"port\": 8000,\n        },\n        [\n            mock.call(\n                mock.ANY,\n                \"127.0.0.1\",\n                8000,\n                ssl=None,\n                backlog=128,\n                reuse_address=None,\n                reuse_port=None,\n            ),\n            mock.call(\n                mock.ANY,\n                \"192.168.1.1\",\n                8000,\n                ssl=None,\n                backlog=128,\n                reuse_address=None,\n                reuse_port=None,\n            ),\n        ],\n        mock_unix_server_multi,\n    ),\n    (\n        \"Only socket\",\n        {\"sock\": [mock_socket]},\n        [mock.call(mock.ANY, ssl=None, sock=mock_socket, backlog=128)],\n        [],\n    ),\n    (\n        \"Socket, port\",\n        {\"sock\": [mock_socket], \"port\": 8765},\n        [\n            mock.call(\n                mock.ANY,\n                None,\n                8765,\n                ssl=None,\n                backlog=128,\n                reuse_address=None,\n                reuse_port=None,\n            ),\n            mock.call(mock.ANY, sock=mock_socket, ssl=None, backlog=128),\n        ],\n        [],\n    ),\n    (\n        \"Socket, Host, No port\",\n        {\"sock\": [mock_socket], \"host\": \"localhost\"},\n        [\n            mock.call(\n                mock.ANY,\n                \"localhost\",\n                8080,\n                ssl=None,\n                backlog=128,\n                reuse_address=None,\n                reuse_port=None,\n            ),\n            mock.call(mock.ANY, sock=mock_socket, ssl=None, backlog=128),\n        ],\n        [],\n    ),\n    (\n        \"reuse_port\",\n        {\"reuse_port\": True},\n        [\n            mock.call(\n                mock.ANY,\n                None,\n                8080,\n                ssl=None,\n                backlog=128,\n                reuse_address=None,\n                reuse_port=True,\n            )\n        ],\n        [],\n    ),\n    (\n        \"reuse_address\",\n        {\"reuse_address\": False},\n        [\n            mock.call(\n                mock.ANY,\n                None,\n                8080,\n                ssl=None,\n                backlog=128,\n                reuse_address=False,\n                reuse_port=None,\n            )\n        ],\n        [],\n    ),\n    (\n        \"reuse_port, reuse_address\",\n        {\"reuse_address\": True, \"reuse_port\": True},\n        [\n            mock.call(\n                mock.ANY,\n                None,\n                8080,\n                ssl=None,\n                backlog=128,\n                reuse_address=True,\n                reuse_port=True,\n            )\n        ],\n        [],\n    ),\n    (\n        \"Port, reuse_port\",\n        {\"port\": 8989, \"reuse_port\": True},\n        [\n            mock.call(\n                mock.ANY,\n                None,\n                8989,\n                ssl=None,\n                backlog=128,\n                reuse_address=None,\n                reuse_port=True,\n            )\n        ],\n        [],\n    ),\n    (\n        \"Multiple Hosts, reuse_port\",\n        {\"host\": (\"127.0.0.1\", \"192.168.1.1\"), \"reuse_port\": True},\n        [\n            mock.call(\n                mock.ANY,\n                \"127.0.0.1\",\n                8080,\n                ssl=None,\n                backlog=128,\n                reuse_address=None,\n                reuse_port=True,\n            ),\n            mock.call(\n                mock.ANY,\n                \"192.168.1.1\",\n                8080,\n                ssl=None,\n                backlog=128,\n                reuse_address=None,\n                reuse_port=True,\n            ),\n        ],\n        [],\n    ),\n    (\n        \"Multiple Paths, Port, reuse_address\",\n        {\n            \"path\": (\"/tmp/testsock1.sock\", \"/tmp/testsock2.sock\"),\n            \"port\": 8989,\n            \"reuse_address\": False,\n        },\n        [\n            mock.call(\n                mock.ANY,\n                None,\n                8989,\n                ssl=None,\n                backlog=128,\n                reuse_address=False,\n                reuse_port=None,\n            )\n        ],\n        mock_unix_server_multi,\n    ),\n    (\n        \"Multiple Paths, Single Host, reuse_address, reuse_port\",\n        {\n            \"path\": (\"/tmp/testsock1.sock\", \"/tmp/testsock2.sock\"),\n            \"host\": \"127.0.0.1\",\n            \"reuse_address\": True,\n            \"reuse_port\": True,\n        },\n        [\n            mock.call(\n                mock.ANY,\n                \"127.0.0.1\",\n                8080,\n                ssl=None,\n                backlog=128,\n                reuse_address=True,\n                reuse_port=True,\n            ),\n        ],\n        mock_unix_server_multi,\n    ),\n)\nmixed_bindings_test_ids: Any = [test[0] for test in mixed_bindings_tests]\nmixed_bindings_test_params: Any = [test[1:] for test in mixed_bindings_tests]\n\n\n@pytest.mark.parametrize(\n    \"run_app_kwargs, expected_server_calls, expected_unix_server_calls\",\n    mixed_bindings_test_params,\n    ids=mixed_bindings_test_ids,\n)\ndef test_run_app_mixed_bindings(\n    run_app_kwargs: Any,\n    expected_server_calls: Any,\n    expected_unix_server_calls: Any,\n    patched_loop: Any,\n) -> None:\n    app = web.Application()\n    web.run_app(app, print=stopper(patched_loop), **run_app_kwargs, loop=patched_loop)\n\n    assert patched_loop.create_unix_server.mock_calls == expected_unix_server_calls\n    assert patched_loop.create_server.mock_calls == expected_server_calls\n\n\ndef test_run_app_https(patched_loop: Any) -> None:\n    app = web.Application()\n\n    ssl_context = ssl.create_default_context()\n    web.run_app(\n        app, ssl_context=ssl_context, print=stopper(patched_loop), loop=patched_loop\n    )\n\n    patched_loop.create_server.assert_called_with(\n        mock.ANY,\n        None,\n        8443,\n        ssl=ssl_context,\n        backlog=128,\n        reuse_address=None,\n        reuse_port=None,\n    )\n\n\ndef test_run_app_nondefault_host_port(\n    patched_loop: Any, aiohttp_unused_port: Any\n) -> None:\n    port = aiohttp_unused_port()\n    host = \"127.0.0.1\"\n\n    app = web.Application()\n    web.run_app(\n        app, host=host, port=port, print=stopper(patched_loop), loop=patched_loop\n    )\n\n    patched_loop.create_server.assert_called_with(\n        mock.ANY, host, port, ssl=None, backlog=128, reuse_address=None, reuse_port=None\n    )\n\n\ndef test_run_app_multiple_hosts(patched_loop: Any) -> None:\n    hosts = (\"127.0.0.1\", \"127.0.0.2\")\n\n    app = web.Application()\n    web.run_app(app, host=hosts, print=stopper(patched_loop), loop=patched_loop)\n\n    calls = map(\n        lambda h: mock.call(\n            mock.ANY,\n            h,\n            8080,\n            ssl=None,\n            backlog=128,\n            reuse_address=None,\n            reuse_port=None,\n        ),\n        hosts,\n    )\n    patched_loop.create_server.assert_has_calls(calls)\n\n\ndef test_run_app_custom_backlog(patched_loop: Any) -> None:\n    app = web.Application()\n    web.run_app(app, backlog=10, print=stopper(patched_loop), loop=patched_loop)\n\n    patched_loop.create_server.assert_called_with(\n        mock.ANY, None, 8080, ssl=None, backlog=10, reuse_address=None, reuse_port=None\n    )\n\n\ndef test_run_app_custom_backlog_unix(patched_loop: Any) -> None:\n    app = web.Application()\n    web.run_app(\n        app,\n        path=\"/tmp/tmpsock.sock\",\n        backlog=10,\n        print=stopper(patched_loop),\n        loop=patched_loop,\n    )\n\n    patched_loop.create_unix_server.assert_called_with(\n        mock.ANY, \"/tmp/tmpsock.sock\", ssl=None, backlog=10\n    )\n\n\n@skip_if_no_unix_socks\ndef test_run_app_http_unix_socket(patched_loop: Any, unix_sockname: Any) -> None:\n    app = web.Application()\n\n    printer = mock.Mock(wraps=stopper(patched_loop))\n    web.run_app(app, path=unix_sockname, print=printer, loop=patched_loop)\n\n    patched_loop.create_unix_server.assert_called_with(\n        mock.ANY, unix_sockname, ssl=None, backlog=128\n    )\n    assert f\"http://unix:{unix_sockname}:\" in printer.call_args[0][0]\n\n\n@skip_if_no_unix_socks\ndef test_run_app_https_unix_socket(patched_loop: Any, unix_sockname: Any) -> None:\n    app = web.Application()\n\n    ssl_context = ssl.create_default_context()\n    printer = mock.Mock(wraps=stopper(patched_loop))\n    web.run_app(\n        app,\n        path=unix_sockname,\n        ssl_context=ssl_context,\n        print=printer,\n        loop=patched_loop,\n    )\n\n    patched_loop.create_unix_server.assert_called_with(\n        mock.ANY, unix_sockname, ssl=ssl_context, backlog=128\n    )\n    assert f\"https://unix:{unix_sockname}:\" in printer.call_args[0][0]\n\n\n@pytest.mark.skipif(not hasattr(socket, \"AF_UNIX\"), reason=\"requires UNIX sockets\")\n@skip_if_no_abstract_paths\ndef test_run_app_abstract_linux_socket(patched_loop: Any) -> None:\n    sock_path = b\"\\x00\" + uuid4().hex.encode(\"ascii\")\n    app = web.Application()\n    web.run_app(\n        app,\n        path=sock_path.decode(\"ascii\", \"ignore\"),\n        print=stopper(patched_loop),\n        loop=patched_loop,\n    )\n\n    patched_loop.create_unix_server.assert_called_with(\n        mock.ANY, sock_path.decode(\"ascii\"), ssl=None, backlog=128\n    )\n\n\ndef test_run_app_preexisting_inet_socket(patched_loop: Any, mocker: Any) -> None:\n    app = web.Application()\n\n    sock = socket.socket()\n    with contextlib.closing(sock):\n        sock.bind((\"127.0.0.1\", 0))\n        _, port = sock.getsockname()\n\n        printer = mock.Mock(wraps=stopper(patched_loop))\n        web.run_app(app, sock=sock, print=printer, loop=patched_loop)\n\n        patched_loop.create_server.assert_called_with(\n            mock.ANY, sock=sock, backlog=128, ssl=None\n        )\n        assert f\"http://127.0.0.1:{port}\" in printer.call_args[0][0]\n\n\n@pytest.mark.skipif(not HAS_IPV6, reason=\"IPv6 is not available\")\ndef test_run_app_preexisting_inet6_socket(patched_loop: Any) -> None:\n    app = web.Application()\n\n    sock = socket.socket(socket.AF_INET6)\n    with contextlib.closing(sock):\n        sock.bind((\"::1\", 0))\n        port = sock.getsockname()[1]\n\n        printer = mock.Mock(wraps=stopper(patched_loop))\n        web.run_app(app, sock=sock, print=printer, loop=patched_loop)\n\n        patched_loop.create_server.assert_called_with(\n            mock.ANY, sock=sock, backlog=128, ssl=None\n        )\n        assert f\"http://[::1]:{port}\" in printer.call_args[0][0]\n\n\n@skip_if_no_unix_socks\ndef test_run_app_preexisting_unix_socket(patched_loop: Any, mocker: Any) -> None:\n    app = web.Application()\n\n    sock_path = \"/tmp/test_preexisting_sock1\"\n    sock = socket.socket(socket.AF_UNIX)\n    with contextlib.closing(sock):\n        sock.bind(sock_path)\n        os.unlink(sock_path)\n\n        printer = mock.Mock(wraps=stopper(patched_loop))\n        web.run_app(app, sock=sock, print=printer, loop=patched_loop)\n\n        patched_loop.create_server.assert_called_with(\n            mock.ANY, sock=sock, backlog=128, ssl=None\n        )\n        assert f\"http://unix:{sock_path}:\" in printer.call_args[0][0]\n\n\ndef test_run_app_multiple_preexisting_sockets(patched_loop: Any) -> None:\n    app = web.Application()\n\n    sock1 = socket.socket()\n    sock2 = socket.socket()\n    with contextlib.closing(sock1), contextlib.closing(sock2):\n        sock1.bind((\"localhost\", 0))\n        _, port1 = sock1.getsockname()\n        sock2.bind((\"localhost\", 0))\n        _, port2 = sock2.getsockname()\n\n        printer = mock.Mock(wraps=stopper(patched_loop))\n        web.run_app(app, sock=(sock1, sock2), print=printer, loop=patched_loop)\n\n        patched_loop.create_server.assert_has_calls(\n            [\n                mock.call(mock.ANY, sock=sock1, backlog=128, ssl=None),\n                mock.call(mock.ANY, sock=sock2, backlog=128, ssl=None),\n            ]\n        )\n        assert f\"http://127.0.0.1:{port1}\" in printer.call_args[0][0]\n        assert f\"http://127.0.0.1:{port2}\" in printer.call_args[0][0]\n\n\n_script_test_signal = \"\"\"\nfrom aiohttp import web\n\napp = web.Application()\nweb.run_app(app, host=())\n\"\"\"\n\n\ndef test_sigint() -> None:\n    skip_if_on_windows()\n\n    with subprocess.Popen(\n        [sys.executable, \"-u\", \"-c\", _script_test_signal],\n        stdout=subprocess.PIPE,\n    ) as proc:\n        for line in proc.stdout:\n            if line.startswith(b\"======== Running on\"):\n                break\n        proc.send_signal(signal.SIGINT)\n        assert proc.wait() == 0\n\n\ndef test_sigterm() -> None:\n    skip_if_on_windows()\n\n    with subprocess.Popen(\n        [sys.executable, \"-u\", \"-c\", _script_test_signal],\n        stdout=subprocess.PIPE,\n    ) as proc:\n        for line in proc.stdout:\n            if line.startswith(b\"======== Running on\"):\n                break\n        proc.terminate()\n        assert proc.wait() == 0\n\n\ndef test_startup_cleanup_signals_even_on_failure(patched_loop: Any) -> None:\n    patched_loop.create_server = mock.Mock(side_effect=RuntimeError())\n\n    app = web.Application()\n    startup_handler = make_mocked_coro()\n    app.on_startup.append(startup_handler)\n    cleanup_handler = make_mocked_coro()\n    app.on_cleanup.append(cleanup_handler)\n\n    with pytest.raises(RuntimeError):\n        web.run_app(app, print=stopper(patched_loop), loop=patched_loop)\n\n    startup_handler.assert_called_once_with(app)\n    cleanup_handler.assert_called_once_with(app)\n\n\ndef test_run_app_coro(patched_loop: Any) -> None:\n    startup_handler = cleanup_handler = None\n\n    async def make_app():\n        nonlocal startup_handler, cleanup_handler\n        app = web.Application()\n        startup_handler = make_mocked_coro()\n        app.on_startup.append(startup_handler)\n        cleanup_handler = make_mocked_coro()\n        app.on_cleanup.append(cleanup_handler)\n        return app\n\n    web.run_app(make_app(), print=stopper(patched_loop), loop=patched_loop)\n\n    patched_loop.create_server.assert_called_with(\n        mock.ANY, None, 8080, ssl=None, backlog=128, reuse_address=None, reuse_port=None\n    )\n    startup_handler.assert_called_once_with(mock.ANY)\n    cleanup_handler.assert_called_once_with(mock.ANY)\n\n\ndef test_run_app_default_logger(monkeypatch: Any, patched_loop: Any) -> None:\n    logger = web.access_logger\n    attrs = {\n        \"hasHandlers.return_value\": False,\n        \"level\": logging.NOTSET,\n        \"name\": \"aiohttp.access\",\n    }\n    mock_logger = mock.create_autospec(logger, name=\"mock_access_logger\")\n    mock_logger.configure_mock(**attrs)\n\n    app = web.Application()\n    web.run_app(\n        app,\n        debug=True,\n        print=stopper(patched_loop),\n        access_log=mock_logger,\n        loop=patched_loop,\n    )\n    mock_logger.setLevel.assert_any_call(logging.DEBUG)\n    mock_logger.hasHandlers.assert_called_with()\n    assert isinstance(mock_logger.addHandler.call_args[0][0], logging.StreamHandler)\n\n\ndef test_run_app_default_logger_setup_requires_debug(patched_loop: Any) -> None:\n    logger = web.access_logger\n    attrs = {\n        \"hasHandlers.return_value\": False,\n        \"level\": logging.NOTSET,\n        \"name\": \"aiohttp.access\",\n    }\n    mock_logger = mock.create_autospec(logger, name=\"mock_access_logger\")\n    mock_logger.configure_mock(**attrs)\n\n    app = web.Application()\n    web.run_app(\n        app,\n        debug=False,\n        print=stopper(patched_loop),\n        access_log=mock_logger,\n        loop=patched_loop,\n    )\n    mock_logger.setLevel.assert_not_called()\n    mock_logger.hasHandlers.assert_not_called()\n    mock_logger.addHandler.assert_not_called()\n\n\ndef test_run_app_default_logger_setup_requires_default_logger(\n    patched_loop: Any,\n) -> None:\n    logger = web.access_logger\n    attrs = {\n        \"hasHandlers.return_value\": False,\n        \"level\": logging.NOTSET,\n        \"name\": None,\n    }\n    mock_logger = mock.create_autospec(logger, name=\"mock_access_logger\")\n    mock_logger.configure_mock(**attrs)\n\n    app = web.Application()\n    web.run_app(\n        app,\n        debug=True,\n        print=stopper(patched_loop),\n        access_log=mock_logger,\n        loop=patched_loop,\n    )\n    mock_logger.setLevel.assert_not_called()\n    mock_logger.hasHandlers.assert_not_called()\n    mock_logger.addHandler.assert_not_called()\n\n\ndef test_run_app_default_logger_setup_only_if_unconfigured(patched_loop: Any) -> None:\n    logger = web.access_logger\n    attrs = {\n        \"hasHandlers.return_value\": True,\n        \"level\": None,\n        \"name\": \"aiohttp.access\",\n    }\n    mock_logger = mock.create_autospec(logger, name=\"mock_access_logger\")\n    mock_logger.configure_mock(**attrs)\n\n    app = web.Application()\n    web.run_app(\n        app,\n        debug=True,\n        print=stopper(patched_loop),\n        access_log=mock_logger,\n        loop=patched_loop,\n    )\n    mock_logger.setLevel.assert_not_called()\n    mock_logger.hasHandlers.assert_called_with()\n    mock_logger.addHandler.assert_not_called()\n\n\ndef test_run_app_cancels_all_pending_tasks(patched_loop: Any) -> None:\n    app = web.Application()\n    task = None\n\n    async def on_startup(app):\n        nonlocal task\n        loop = asyncio.get_event_loop()\n        task = loop.create_task(asyncio.sleep(1000))\n\n    app.on_startup.append(on_startup)\n\n    web.run_app(app, print=stopper(patched_loop), loop=patched_loop)\n    assert task.cancelled()\n\n\ndef test_run_app_cancels_done_tasks(patched_loop: Any):\n    app = web.Application()\n    task = None\n\n    async def coro():\n        return 123\n\n    async def on_startup(app):\n        nonlocal task\n        loop = asyncio.get_event_loop()\n        task = loop.create_task(coro())\n\n    app.on_startup.append(on_startup)\n\n    web.run_app(app, print=stopper(patched_loop), loop=patched_loop)\n    assert task.done()\n\n\ndef test_run_app_cancels_failed_tasks(patched_loop: Any) -> None:\n    app = web.Application()\n    task = None\n\n    exc = RuntimeError(\"FAIL\")\n\n    async def fail():\n        try:\n            await asyncio.sleep(1000)\n        except asyncio.CancelledError:\n            raise exc\n\n    async def on_startup(app):\n        nonlocal task\n        loop = asyncio.get_event_loop()\n        task = loop.create_task(fail())\n        await asyncio.sleep(0.01)\n\n    app.on_startup.append(on_startup)\n\n    exc_handler = mock.Mock()\n    patched_loop.set_exception_handler(exc_handler)\n    web.run_app(app, print=stopper(patched_loop), loop=patched_loop)\n    assert task.done()\n\n    msg = {\n        \"message\": \"unhandled exception during asyncio.run() shutdown\",\n        \"exception\": exc,\n        \"task\": task,\n    }\n    exc_handler.assert_called_with(patched_loop, msg)\n\n\ndef test_run_app_keepalive_timeout(\n    patched_loop: Any, mocker: Any, monkeypatch: Any\n) -> None:\n    new_timeout = 1234\n    base_runner_init_orig = BaseRunner.__init__\n\n    def base_runner_init_spy(self, *args, **kwargs):\n        assert kwargs[\"keepalive_timeout\"] == new_timeout\n        base_runner_init_orig(self, *args, **kwargs)\n\n    app = web.Application()\n    monkeypatch.setattr(BaseRunner, \"__init__\", base_runner_init_spy)\n    web.run_app(\n        app,\n        keepalive_timeout=new_timeout,\n        print=stopper(patched_loop),\n        loop=patched_loop,\n    )\n\n\ndef test_run_app_context_vars(patched_loop: Any):\n    from contextvars import ContextVar\n\n    count = 0\n    VAR = ContextVar(\"VAR\", default=\"default\")\n\n    async def on_startup(app):\n        nonlocal count\n        assert \"init\" == VAR.get()\n        VAR.set(\"on_startup\")\n        count += 1\n\n    async def on_cleanup(app):\n        nonlocal count\n        assert \"on_startup\" == VAR.get()\n        count += 1\n\n    async def init():\n        nonlocal count\n        assert \"default\" == VAR.get()\n        VAR.set(\"init\")\n        app = web.Application()\n\n        app.on_startup.append(on_startup)\n        app.on_cleanup.append(on_cleanup)\n        count += 1\n        return app\n\n    web.run_app(init(), print=stopper(patched_loop), loop=patched_loop)\n    assert count == 3\n\n\nclass TestShutdown:\n    def raiser(self) -> NoReturn:\n        raise KeyboardInterrupt\n\n    async def stop(self, request: web.Request) -> web.Response:\n        asyncio.get_running_loop().call_soon(self.raiser)\n        return web.Response()\n\n    def run_app(self, port: int, timeout: int, task, extra_test=None) -> asyncio.Task:\n        async def test() -> None:\n            await asyncio.sleep(0.5)\n            async with ClientSession() as sess:\n                for _ in range(5):  # pragma: no cover\n                    try:\n                        async with sess.get(f\"http://localhost:{port}/\"):\n                            pass\n                    except ClientConnectorError:\n                        await asyncio.sleep(0.5)\n                    else:\n                        break\n                async with sess.get(f\"http://localhost:{port}/stop\"):\n                    pass\n\n                if extra_test:\n                    await extra_test(sess)\n\n        async def run_test(app: web.Application) -> None:\n            nonlocal test_task\n            test_task = asyncio.create_task(test())\n            yield\n            await test_task\n\n        async def handler(request: web.Request) -> web.Response:\n            nonlocal t\n            t = asyncio.create_task(task())\n            return web.Response(text=\"FOO\")\n\n        t = test_task = None\n        app = web.Application()\n        app.cleanup_ctx.append(run_test)\n        app.router.add_get(\"/\", handler)\n        app.router.add_get(\"/stop\", self.stop)\n\n        web.run_app(app, port=port, shutdown_timeout=timeout)\n        assert test_task.exception() is None\n        return t\n\n    def test_shutdown_wait_for_task(\n        self, aiohttp_unused_port: Callable[[], int]\n    ) -> None:\n        port = aiohttp_unused_port()\n        finished = False\n\n        async def task():\n            nonlocal finished\n            await asyncio.sleep(2)\n            finished = True\n\n        t = self.run_app(port, 3, task)\n\n        assert finished is True\n        assert t.done()\n        assert not t.cancelled()\n\n    def test_shutdown_timeout_task(\n        self, aiohttp_unused_port: Callable[[], int]\n    ) -> None:\n        port = aiohttp_unused_port()\n        finished = False\n\n        async def task():\n            nonlocal finished\n            await asyncio.sleep(2)\n            finished = True\n\n        t = self.run_app(port, 1, task)\n\n        assert finished is False\n        assert t.done()\n        assert t.cancelled()\n\n    def test_shutdown_wait_for_spawned_task(\n        self, aiohttp_unused_port: Callable[[], int]\n    ) -> None:\n        port = aiohttp_unused_port()\n        finished = False\n        finished_sub = False\n        sub_t = None\n\n        async def sub_task():\n            nonlocal finished_sub\n            await asyncio.sleep(1.5)\n            finished_sub = True\n\n        async def task():\n            nonlocal finished, sub_t\n            await asyncio.sleep(0.5)\n            sub_t = asyncio.create_task(sub_task())\n            finished = True\n\n        t = self.run_app(port, 3, task)\n\n        assert finished is True\n        assert t.done()\n        assert not t.cancelled()\n        assert finished_sub is True\n        assert sub_t.done()\n        assert not sub_t.cancelled()\n\n    def test_shutdown_timeout_not_reached(\n        self, aiohttp_unused_port: Callable[[], int]\n    ) -> None:\n        port = aiohttp_unused_port()\n        finished = False\n\n        async def task():\n            nonlocal finished\n            await asyncio.sleep(1)\n            finished = True\n\n        start_time = time.time()\n        t = self.run_app(port, 15, task)\n\n        assert finished is True\n        assert t.done()\n        # Verify run_app has not waited for timeout.\n        assert time.time() - start_time < 10\n\n    def test_shutdown_new_conn_rejected(\n        self, aiohttp_unused_port: Callable[[], int]\n    ) -> None:\n        port = aiohttp_unused_port()\n        finished = False\n\n        async def task() -> None:\n            nonlocal finished\n            await asyncio.sleep(9)\n            finished = True\n\n        async def test(sess: ClientSession) -> None:\n            # Ensure we are in the middle of shutdown (waiting for task()).\n            await asyncio.sleep(1)\n            with pytest.raises(ClientConnectorError):\n                # Use a new session to try and open a new connection.\n                async with ClientSession() as sess:\n                    async with sess.get(f\"http://localhost:{port}/\"):\n                        pass\n            assert finished is False\n\n        t = self.run_app(port, 10, task, test)\n\n        assert finished is True\n        assert t.done()\n\n    def test_shutdown_pending_handler_responds(\n        self, aiohttp_unused_port: Callable[[], int]\n    ) -> None:\n        port = aiohttp_unused_port()\n        finished = False\n\n        async def test() -> None:\n            async def test_resp(sess):\n                async with sess.get(f\"http://localhost:{port}/\") as resp:\n                    assert await resp.text() == \"FOO\"\n\n            await asyncio.sleep(1)\n            async with ClientSession() as sess:\n                t = asyncio.create_task(test_resp(sess))\n                await asyncio.sleep(1)\n                # Handler is in-progress while we trigger server shutdown.\n                async with sess.get(f\"http://localhost:{port}/stop\"):\n                    pass\n\n                assert finished is False\n                # Handler should still complete and produce a response.\n                await t\n\n        async def run_test(app: web.Application) -> None:\n            nonlocal t\n            t = asyncio.create_task(test())\n            yield\n            await t\n\n        async def handler(request: web.Request) -> web.Response:\n            nonlocal finished\n            await asyncio.sleep(3)\n            finished = True\n            return web.Response(text=\"FOO\")\n\n        t = None\n        app = web.Application()\n        app.cleanup_ctx.append(run_test)\n        app.router.add_get(\"/\", handler)\n        app.router.add_get(\"/stop\", self.stop)\n\n        web.run_app(app, port=port, shutdown_timeout=5)\n        assert t.exception() is None\n        assert finished is True\n\n    def test_shutdown_close_idle_keepalive(\n        self, aiohttp_unused_port: Callable[[], int]\n    ) -> None:\n        port = aiohttp_unused_port()\n\n        async def test() -> None:\n            await asyncio.sleep(1)\n            async with ClientSession() as sess:\n                async with sess.get(f\"http://localhost:{port}/stop\"):\n                    pass\n\n                # Hold on to keep-alive connection.\n                await asyncio.sleep(5)\n\n        async def run_test(app: web.Application) -> None:\n            nonlocal t\n            t = asyncio.create_task(test())\n            yield\n            t.cancel()\n            with contextlib.suppress(asyncio.CancelledError):\n                await t\n\n        t = None\n        app = web.Application()\n        app.cleanup_ctx.append(run_test)\n        app.router.add_get(\"/stop\", self.stop)\n\n        web.run_app(app, port=port, shutdown_timeout=10)\n        # If connection closed, then test() will be cancelled in cleanup_ctx.\n        # If not, then shutdown_timeout will allow it to sleep until complete.\n        assert t.cancelled()\n\n    def test_shutdown_close_websockets(\n        self, aiohttp_unused_port: Callable[[], int]\n    ) -> None:\n        port = aiohttp_unused_port()\n        WS = web.AppKey(\"ws\", Set[web.WebSocketResponse])\n        client_finished = server_finished = False\n\n        async def ws_handler(request: web.Request) -> web.WebSocketResponse:\n            ws = web.WebSocketResponse()\n            await ws.prepare(request)\n            request.app[WS].add(ws)\n            async for msg in ws:\n                pass\n            nonlocal server_finished\n            server_finished = True\n            return ws\n\n        async def close_websockets(app: web.Application) -> None:\n            for ws in app[WS]:\n                await ws.close(code=WSCloseCode.GOING_AWAY)\n\n        async def test() -> None:\n            await asyncio.sleep(1)\n            async with ClientSession() as sess:\n                async with sess.ws_connect(f\"http://localhost:{port}/ws\") as ws:\n                    async with sess.get(f\"http://localhost:{port}/stop\"):\n                        pass\n\n                    async for msg in ws:\n                        pass\n                    nonlocal client_finished\n                    client_finished = True\n\n        async def run_test(app: web.Application) -> None:\n            nonlocal t\n            t = asyncio.create_task(test())\n            yield\n            t.cancel()\n            with contextlib.suppress(asyncio.CancelledError):\n                await t\n\n        t = None\n        app = web.Application()\n        app[WS] = set()\n        app.on_shutdown.append(close_websockets)\n        app.cleanup_ctx.append(run_test)\n        app.router.add_get(\"/ws\", ws_handler)\n        app.router.add_get(\"/stop\", self.stop)\n\n        start = time.time()\n        web.run_app(app, port=port, shutdown_timeout=10)\n        assert time.time() - start < 5\n        assert client_finished\n        assert server_finished\n", "tests/test_client_response.py": "# type: ignore\n# Tests for aiohttp/client.py\n\nimport gc\nimport sys\nfrom json import JSONDecodeError\nfrom typing import Any, Callable\nfrom unittest import mock\n\nimport pytest\nfrom multidict import CIMultiDict\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp import http\nfrom aiohttp.client_reqrep import ClientResponse, RequestInfo\nfrom aiohttp.helpers import TimerNoop\nfrom aiohttp.test_utils import make_mocked_coro\n\n\nclass WriterMock(mock.AsyncMock):\n    def __await__(self) -> None:\n        return self().__await__()\n\n    def add_done_callback(self, cb: Callable[[], None]) -> None:\n        cb()\n\n    def done(self) -> bool:\n        return True\n\n\n@pytest.fixture\ndef session():\n    return mock.Mock()\n\n\nasync def test_http_processing_error(session: Any) -> None:\n    loop = mock.Mock()\n    request_info = mock.Mock()\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://del-cl-resp.org\"),\n        request_info=request_info,\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    loop.get_debug = mock.Mock()\n    loop.get_debug.return_value = True\n\n    connection = mock.Mock()\n    connection.protocol = aiohttp.DataQueue(loop)\n    connection.protocol.set_response_params = mock.Mock()\n    connection.protocol.set_exception(http.HttpProcessingError())\n\n    with pytest.raises(aiohttp.ClientResponseError) as info:\n        await response.start(connection)\n\n    assert info.value.request_info is request_info\n    response.close()\n\n\ndef test_del(session: Any) -> None:\n    loop = mock.Mock()\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://del-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    loop.get_debug = mock.Mock()\n    loop.get_debug.return_value = True\n\n    connection = mock.Mock()\n    response._closed = False\n    response._connection = connection\n    loop.set_exception_handler(lambda loop, ctx: None)\n\n    with pytest.warns(ResourceWarning):\n        del response\n        gc.collect()\n\n    connection.release.assert_called_with()\n\n\ndef test_close(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._closed = False\n    response._connection = mock.Mock()\n    response.close()\n    assert response.connection is None\n    response.close()\n    response.close()\n\n\ndef test_wait_for_100_1(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://python.org\"),\n        continue100=object(),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    assert response._continue is not None\n    response.close()\n\n\ndef test_wait_for_100_2(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://python.org\"),\n        request_info=mock.Mock(),\n        continue100=None,\n        writer=WriterMock(),\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    assert response._continue is None\n    response.close()\n\n\ndef test_repr(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response.status = 200\n    response.reason = \"Ok\"\n    assert \"<ClientResponse(http://def-cl-resp.org) [200 Ok]>\" in repr(response)\n\n\ndef test_repr_non_ascii_url() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://fake-host.org/\\u03bb\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    assert \"<ClientResponse(http://fake-host.org/%CE%BB) [None None]>\" in repr(response)\n\n\ndef test_repr_non_ascii_reason() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://fake-host.org/path\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response.reason = \"\\u03bb\"\n    assert \"<ClientResponse(http://fake-host.org/path) [None \\\\u03bb]>\" in repr(\n        response\n    )\n\n\nasync def test_read_and_release_connection(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result(b\"payload\")\n        return fut\n\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n\n    res = await response.read()\n    assert res == b\"payload\"\n    assert response._connection is None\n\n\nasync def test_read_and_release_connection_with_error(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    content = response.content = mock.Mock()\n    content.read.return_value = loop.create_future()\n    content.read.return_value.set_exception(ValueError)\n\n    with pytest.raises(ValueError):\n        await response.read()\n    assert response._closed\n\n\nasync def test_release(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    fut = loop.create_future()\n    fut.set_result(b\"\")\n    content = response.content = mock.Mock()\n    content.readany.return_value = fut\n\n    response.release()\n    assert response._connection is None\n\n\n@pytest.mark.skipif(\n    sys.implementation.name != \"cpython\",\n    reason=\"Other implementations has different GC strategies\",\n)\nasync def test_release_on_del(loop: Any, session: Any) -> None:\n    connection = mock.Mock()\n    connection.protocol.upgraded = False\n\n    def run(conn):\n        response = ClientResponse(\n            \"get\",\n            URL(\"http://def-cl-resp.org\"),\n            request_info=mock.Mock(),\n            writer=WriterMock(),\n            continue100=None,\n            timer=TimerNoop(),\n            traces=[],\n            loop=loop,\n            session=session,\n        )\n        response._closed = False\n        response._connection = conn\n\n    run(connection)\n\n    assert connection.release.called\n\n\nasync def test_response_eof(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=None,\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._closed = False\n    conn = response._connection = mock.Mock()\n    conn.protocol.upgraded = False\n\n    response._response_eof()\n    assert conn.release.called\n    assert response._connection is None\n\n\nasync def test_response_eof_upgraded(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    conn = response._connection = mock.Mock()\n    conn.protocol.upgraded = True\n\n    response._response_eof()\n    assert not conn.release.called\n    assert response._connection is conn\n\n\nasync def test_response_eof_after_connection_detach(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=None,\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._closed = False\n    conn = response._connection = mock.Mock()\n    conn.protocol = None\n\n    response._response_eof()\n    assert conn.release.called\n    assert response._connection is None\n\n\nasync def test_text(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result('{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'.encode(\"cp1251\"))\n        return fut\n\n    response._headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n\n    res = await response.text()\n    assert res == '{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'\n    assert response._connection is None\n\n\nasync def test_text_bad_encoding(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result('{\"\u0442\u0435\u0441\u0442key\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043dvalue\"}'.encode(\"cp1251\"))\n        return fut\n\n    # lie about the encoding\n    response._headers = {\"Content-Type\": \"application/json;charset=utf-8\"}\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n    with pytest.raises(UnicodeDecodeError):\n        await response.text()\n    # only the valid utf-8 characters will be returned\n    res = await response.text(errors=\"ignore\")\n    assert res == '{\"key\": \"value\"}'\n    assert response._connection is None\n\n\nasync def test_text_custom_encoding(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result('{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'.encode(\"cp1251\"))\n        return fut\n\n    response._headers = {\"Content-Type\": \"application/json\"}\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n    response.get_encoding = mock.Mock()\n\n    res = await response.text(encoding=\"cp1251\")\n    assert res == '{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'\n    assert response._connection is None\n    assert not response.get_encoding.called\n\n\n@pytest.mark.parametrize(\"content_type\", (\"text/plain\", \"text/plain;charset=invalid\"))\nasync def test_text_charset_resolver(\n    content_type: str, loop: Any, session: Any\n) -> None:\n    session._resolve_charset = lambda r, b: \"cp1251\"\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result('{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'.encode(\"cp1251\"))\n        return fut\n\n    response._headers = {\"Content-Type\": content_type}\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n\n    await response.read()\n    res = await response.text()\n    assert res == '{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'\n    assert response._connection is None\n    assert response.get_encoding() == \"cp1251\"\n\n\nasync def test_get_encoding_body_none(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result('{\"encoding\": \"test\"}')\n        return fut\n\n    response._headers = {\"Content-Type\": \"text/html\"}\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n\n    with pytest.raises(\n        RuntimeError,\n        match=\"^Cannot compute fallback encoding of a not yet read body$\",\n    ):\n        response.get_encoding()\n    assert response.closed\n\n\nasync def test_text_after_read(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result('{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'.encode(\"cp1251\"))\n        return fut\n\n    response._headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n\n    res = await response.text()\n    assert res == '{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'\n    assert response._connection is None\n\n\nasync def test_json(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result('{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'.encode(\"cp1251\"))\n        return fut\n\n    response._headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n\n    res = await response.json()\n    assert res == {\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}\n    assert response._connection is None\n\n\nasync def test_json_extended_content_type(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result('{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'.encode(\"cp1251\"))\n        return fut\n\n    response._headers = {\n        \"Content-Type\": \"application/this.is-1_content+subtype+json;charset=cp1251\"\n    }\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n\n    res = await response.json()\n    assert res == {\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}\n    assert response._connection is None\n\n\nasync def test_json_custom_content_type(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result('{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'.encode(\"cp1251\"))\n        return fut\n\n    response._headers = {\"Content-Type\": \"custom/type;charset=cp1251\"}\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n\n    res = await response.json(content_type=\"custom/type\")\n    assert res == {\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}\n    assert response._connection is None\n\n\nasync def test_json_custom_loader(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n    response._body = b\"data\"\n\n    def custom(content):\n        return content + \"-custom\"\n\n    res = await response.json(loads=custom)\n    assert res == \"data-custom\"\n\n\nasync def test_json_invalid_content_type(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._headers = {\"Content-Type\": \"data/octet-stream\"}\n    response._body = b\"\"\n\n    with pytest.raises(aiohttp.ContentTypeError) as info:\n        await response.json()\n\n    assert info.value.request_info == response.request_info\n\n\nasync def test_json_no_content(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._headers = {\"Content-Type\": \"application/json\"}\n    response._body = b\"\"\n\n    with pytest.raises(JSONDecodeError):\n        await response.json(content_type=None)\n\n\nasync def test_json_override_encoding(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result('{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}'.encode(\"cp1251\"))\n        return fut\n\n    response._headers = {\"Content-Type\": \"application/json;charset=utf8\"}\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n    response.get_encoding = mock.Mock()\n\n    res = await response.json(encoding=\"cp1251\")\n    assert res == {\"\u0442\u0435\u0441\u0442\": \"\u043f\u0440\u043e\u0439\u0434\u0435\u043d\"}\n    assert response._connection is None\n    assert not response.get_encoding.called\n\n\ndef test_get_encoding_unknown(loop: Any, session: Any) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n\n    response._headers = {\"Content-Type\": \"application/json\"}\n    assert response.get_encoding() == \"utf-8\"\n\n\ndef test_raise_for_status_2xx() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response.status = 200\n    response.reason = \"OK\"\n    response.raise_for_status()  # should not raise\n\n\ndef test_raise_for_status_4xx() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response.status = 409\n    response.reason = \"CONFLICT\"\n    with pytest.raises(aiohttp.ClientResponseError) as cm:\n        response.raise_for_status()\n    assert str(cm.value.status) == \"409\"\n    assert str(cm.value.message) == \"CONFLICT\"\n    assert response.closed\n\n\ndef test_raise_for_status_4xx_without_reason() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response.status = 404\n    response.reason = \"\"\n    with pytest.raises(aiohttp.ClientResponseError) as cm:\n        response.raise_for_status()\n    assert str(cm.value.status) == \"404\"\n    assert str(cm.value.message) == \"\"\n    assert response.closed\n\n\ndef test_resp_host() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://del-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    assert \"del-cl-resp.org\" == response.host\n\n\ndef test_content_type() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response._headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n\n    assert \"application/json\" == response.content_type\n\n\ndef test_content_type_no_header() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response._headers = {}\n\n    assert \"application/octet-stream\" == response.content_type\n\n\ndef test_charset() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response._headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n\n    assert \"cp1251\" == response.charset\n\n\ndef test_charset_no_header() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response._headers = {}\n\n    assert response.charset is None\n\n\ndef test_charset_no_charset() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response._headers = {\"Content-Type\": \"application/json\"}\n\n    assert response.charset is None\n\n\ndef test_content_disposition_full() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response._headers = {\n        \"Content-Disposition\": 'attachment; filename=\"archive.tar.gz\"; foo=bar'\n    }\n\n    assert \"attachment\" == response.content_disposition.type\n    assert \"bar\" == response.content_disposition.parameters[\"foo\"]\n    assert \"archive.tar.gz\" == response.content_disposition.filename\n    with pytest.raises(TypeError):\n        response.content_disposition.parameters[\"foo\"] = \"baz\"\n\n\ndef test_content_disposition_no_parameters() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response._headers = {\"Content-Disposition\": \"attachment\"}\n\n    assert \"attachment\" == response.content_disposition.type\n    assert response.content_disposition.filename is None\n    assert {} == response.content_disposition.parameters\n\n\ndef test_content_disposition_no_header() -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response._headers = {}\n\n    assert response.content_disposition is None\n\n\ndef test_response_request_info() -> None:\n    url = \"http://def-cl-resp.org\"\n    headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n    response = ClientResponse(\n        \"get\",\n        URL(url),\n        request_info=RequestInfo(url, \"get\", headers, url),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    assert url == response.request_info.url\n    assert \"get\" == response.request_info.method\n    assert headers == response.request_info.headers\n\n\ndef test_request_info_in_exception() -> None:\n    url = \"http://def-cl-resp.org\"\n    headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n    response = ClientResponse(\n        \"get\",\n        URL(url),\n        request_info=RequestInfo(url, \"get\", headers, url),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response.status = 409\n    response.reason = \"CONFLICT\"\n    with pytest.raises(aiohttp.ClientResponseError) as cm:\n        response.raise_for_status()\n    assert cm.value.request_info == response.request_info\n\n\ndef test_no_redirect_history_in_exception() -> None:\n    url = \"http://def-cl-resp.org\"\n    headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n    response = ClientResponse(\n        \"get\",\n        URL(url),\n        request_info=RequestInfo(url, \"get\", headers, url),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response.status = 409\n    response.reason = \"CONFLICT\"\n    with pytest.raises(aiohttp.ClientResponseError) as cm:\n        response.raise_for_status()\n    assert () == cm.value.history\n\n\ndef test_redirect_history_in_exception() -> None:\n    hist_url = \"http://def-cl-resp.org\"\n    url = \"http://def-cl-resp.org/index.htm\"\n    hist_headers = {\"Content-Type\": \"application/json;charset=cp1251\", \"Location\": url}\n    headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n    response = ClientResponse(\n        \"get\",\n        URL(url),\n        request_info=RequestInfo(url, \"get\", headers, url),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response.status = 409\n    response.reason = \"CONFLICT\"\n\n    hist_response = ClientResponse(\n        \"get\",\n        URL(hist_url),\n        request_info=RequestInfo(url, \"get\", headers, url),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n\n    hist_response._headers = hist_headers\n    hist_response.status = 301\n    hist_response.reason = \"REDIRECT\"\n\n    response._history = [hist_response]\n    with pytest.raises(aiohttp.ClientResponseError) as cm:\n        response.raise_for_status()\n    assert [hist_response] == cm.value.history\n\n\nasync def test_response_read_triggers_callback(loop: Any, session: Any) -> None:\n    trace = mock.Mock()\n    trace.send_response_chunk_received = make_mocked_coro()\n    response_method = \"get\"\n    response_url = URL(\"http://def-cl-resp.org\")\n    response_body = b\"This is response\"\n\n    response = ClientResponse(\n        response_method,\n        response_url,\n        request_info=mock.Mock,\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        loop=loop,\n        session=session,\n        traces=[trace],\n    )\n\n    def side_effect(*args, **kwargs):\n        fut = loop.create_future()\n        fut.set_result(response_body)\n        return fut\n\n    response._headers = {\"Content-Type\": \"application/json;charset=cp1251\"}\n    content = response.content = mock.Mock()\n    content.read.side_effect = side_effect\n\n    res = await response.read()\n    assert res == response_body\n    assert response._connection is None\n\n    assert trace.send_response_chunk_received.called\n    assert trace.send_response_chunk_received.call_args == mock.call(\n        response_method, response_url, response_body\n    )\n\n\ndef test_response_real_url(loop: Any, session: Any) -> None:\n    url = URL(\"http://def-cl-resp.org/#urlfragment\")\n    response = ClientResponse(\n        \"get\",\n        url,\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    assert response.url == url.with_fragment(None)\n    assert response.real_url == url\n\n\ndef test_response_links_comma_separated(loop: Any, session: Any) -> None:\n    url = URL(\"http://def-cl-resp.org/\")\n    response = ClientResponse(\n        \"get\",\n        url,\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._headers = CIMultiDict(\n        [\n            (\n                \"Link\",\n                (\n                    \"<http://example.com/page/1.html>; rel=next, \"\n                    \"<http://example.com/>; rel=home\"\n                ),\n            )\n        ]\n    )\n    assert response.links == {\n        \"next\": {\"url\": URL(\"http://example.com/page/1.html\"), \"rel\": \"next\"},\n        \"home\": {\"url\": URL(\"http://example.com/\"), \"rel\": \"home\"},\n    }\n\n\ndef test_response_links_multiple_headers(loop: Any, session: Any) -> None:\n    url = URL(\"http://def-cl-resp.org/\")\n    response = ClientResponse(\n        \"get\",\n        url,\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._headers = CIMultiDict(\n        [\n            (\"Link\", \"<http://example.com/page/1.html>; rel=next\"),\n            (\"Link\", \"<http://example.com/>; rel=home\"),\n        ]\n    )\n    assert response.links == {\n        \"next\": {\"url\": URL(\"http://example.com/page/1.html\"), \"rel\": \"next\"},\n        \"home\": {\"url\": URL(\"http://example.com/\"), \"rel\": \"home\"},\n    }\n\n\ndef test_response_links_no_rel(loop: Any, session: Any) -> None:\n    url = URL(\"http://def-cl-resp.org/\")\n    response = ClientResponse(\n        \"get\",\n        url,\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._headers = CIMultiDict([(\"Link\", \"<http://example.com/>\")])\n    assert response.links == {\n        \"http://example.com/\": {\"url\": URL(\"http://example.com/\")}\n    }\n\n\ndef test_response_links_quoted(loop: Any, session: Any) -> None:\n    url = URL(\"http://def-cl-resp.org/\")\n    response = ClientResponse(\n        \"get\",\n        url,\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._headers = CIMultiDict(\n        [\n            (\"Link\", '<http://example.com/>; rel=\"home-page\"'),\n        ]\n    )\n    assert response.links == {\n        \"home-page\": {\"url\": URL(\"http://example.com/\"), \"rel\": \"home-page\"}\n    }\n\n\ndef test_response_links_relative(loop: Any, session: Any) -> None:\n    url = URL(\"http://def-cl-resp.org/\")\n    response = ClientResponse(\n        \"get\",\n        url,\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._headers = CIMultiDict(\n        [\n            (\"Link\", \"</relative/path>; rel=rel\"),\n        ]\n    )\n    assert response.links == {\n        \"rel\": {\"url\": URL(\"http://def-cl-resp.org/relative/path\"), \"rel\": \"rel\"}\n    }\n\n\ndef test_response_links_empty(loop: Any, session: Any) -> None:\n    url = URL(\"http://def-cl-resp.org/\")\n    response = ClientResponse(\n        \"get\",\n        url,\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=loop,\n        session=session,\n    )\n    response._headers = CIMultiDict()\n    assert response.links == {}\n\n\ndef test_response_not_closed_after_get_ok(mocker) -> None:\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://del-cl-resp.org\"),\n        request_info=mock.Mock(),\n        writer=WriterMock(),\n        continue100=None,\n        timer=TimerNoop(),\n        traces=[],\n        loop=mock.Mock(),\n        session=mock.Mock(),\n    )\n    response.status = 400\n    response.reason = \"Bad Request\"\n    response._closed = False\n    spy = mocker.spy(response, \"raise_for_status\")\n    assert not response.ok\n    assert not response.closed\n    assert spy.call_count == 0\n", "tests/test_imports.py": "import os\nimport platform\nimport sys\nfrom pathlib import Path\n\nimport pytest\n\n\ndef test___all__(pytester: pytest.Pytester) -> None:\n    \"\"\"See https://github.com/aio-libs/aiohttp/issues/6197\"\"\"\n    pytester.makepyfile(\n        test_a=\"\"\"\n            from aiohttp import *\n            assert 'GunicornWebWorker' in globals()\n        \"\"\"\n    )\n    result = pytester.runpytest(\"-vv\")\n    result.assert_outcomes(passed=0, errors=0)\n\n\ndef test_web___all__(pytester: pytest.Pytester) -> None:\n    pytester.makepyfile(\n        test_b=\"\"\"\n            from aiohttp.web import *\n        \"\"\"\n    )\n    result = pytester.runpytest(\"-vv\")\n    result.assert_outcomes(passed=0, errors=0)\n\n\n_TARGET_TIMINGS_BY_PYTHON_VERSION = {\n    \"3.12\": 250,  # 3.12 is expected to be a bit slower due to performance trade-offs\n}\n\n\n@pytest.mark.internal\n@pytest.mark.skipif(\n    not sys.platform.startswith(\"linux\") or platform.python_implementation() == \"PyPy\",\n    reason=\"Timing is more reliable on Linux\",\n)\ndef test_import_time(pytester: pytest.Pytester) -> None:\n    \"\"\"Check that importing aiohttp doesn't take too long.\n\n    Obviously, the time may vary on different machines and may need to be adjusted\n    from time to time, but this should provide an early warning if something is\n    added that significantly increases import time.\n    \"\"\"\n    root = Path(__file__).parent.parent\n    old_path = os.environ.get(\"PYTHONPATH\")\n    os.environ[\"PYTHONPATH\"] = os.pathsep.join([str(root)] + sys.path)\n\n    best_time_ms = 1000\n    cmd = \"import timeit; print(int(timeit.timeit('import aiohttp', number=1) * 1000))\"\n    try:\n        for _ in range(3):\n            r = pytester.run(sys.executable, \"-We\", \"-c\", cmd)\n\n            assert not r.stderr.str()\n            runtime_ms = int(r.stdout.str())\n            if runtime_ms < best_time_ms:\n                best_time_ms = runtime_ms\n    finally:\n        if old_path is None:\n            os.environ.pop(\"PYTHONPATH\")\n        else:\n            os.environ[\"PYTHONPATH\"] = old_path\n\n    expected_time = _TARGET_TIMINGS_BY_PYTHON_VERSION.get(\n        f\"{sys.version_info.major}.{sys.version_info.minor}\", 200\n    )\n    assert best_time_ms < expected_time\n", "tests/test_helpers.py": "# type: ignore\nimport asyncio\nimport base64\nimport datetime\nimport gc\nimport platform\nimport sys\nimport weakref\nfrom math import ceil, modf\nfrom pathlib import Path\nfrom unittest import mock\nfrom urllib.request import getproxies_environment\n\nimport pytest\nfrom multidict import CIMultiDict, MultiDict\nfrom re_assert import Matches\nfrom yarl import URL\n\nfrom aiohttp import helpers\nfrom aiohttp.helpers import (\n    is_expected_content_type,\n    method_must_be_empty_body,\n    must_be_empty_body,\n    parse_http_date,\n    should_remove_content_length,\n)\n\nIS_PYPY = platform.python_implementation() == \"PyPy\"\n\n\n# ------------------- parse_mimetype ----------------------------------\n\n\n@pytest.mark.parametrize(\n    \"mimetype, expected\",\n    [\n        (\"\", helpers.MimeType(\"\", \"\", \"\", MultiDict())),\n        (\"*\", helpers.MimeType(\"*\", \"*\", \"\", MultiDict())),\n        (\"application/json\", helpers.MimeType(\"application\", \"json\", \"\", MultiDict())),\n        (\n            \"application/json;  charset=utf-8\",\n            helpers.MimeType(\n                \"application\", \"json\", \"\", MultiDict({\"charset\": \"utf-8\"})\n            ),\n        ),\n        (\n            \"\"\"application/json; charset=utf-8;\"\"\",\n            helpers.MimeType(\n                \"application\", \"json\", \"\", MultiDict({\"charset\": \"utf-8\"})\n            ),\n        ),\n        (\n            'ApPlIcAtIoN/JSON;ChaRseT=\"UTF-8\"',\n            helpers.MimeType(\n                \"application\", \"json\", \"\", MultiDict({\"charset\": \"UTF-8\"})\n            ),\n        ),\n        (\n            \"application/rss+xml\",\n            helpers.MimeType(\"application\", \"rss\", \"xml\", MultiDict()),\n        ),\n        (\n            \"text/plain;base64\",\n            helpers.MimeType(\"text\", \"plain\", \"\", MultiDict({\"base64\": \"\"})),\n        ),\n    ],\n)\ndef test_parse_mimetype(mimetype, expected) -> None:\n    result = helpers.parse_mimetype(mimetype)\n\n    assert isinstance(result, helpers.MimeType)\n    assert result == expected\n\n\n# ------------------- guess_filename ----------------------------------\n\n\ndef test_guess_filename_with_file_object(tmp_path) -> None:\n    file_path = tmp_path / \"test_guess_filename\"\n    with file_path.open(\"w+b\") as fp:\n        assert helpers.guess_filename(fp, \"no-throw\") is not None\n\n\ndef test_guess_filename_with_path(tmp_path) -> None:\n    file_path = tmp_path / \"test_guess_filename\"\n    assert helpers.guess_filename(file_path, \"no-throw\") is not None\n\n\ndef test_guess_filename_with_default() -> None:\n    assert helpers.guess_filename(None, \"no-throw\") == \"no-throw\"\n\n\n# ------------------- BasicAuth -----------------------------------\n\n\ndef test_basic_auth1() -> None:\n    # missing password here\n    with pytest.raises(ValueError):\n        helpers.BasicAuth(None)\n\n\ndef test_basic_auth2() -> None:\n    with pytest.raises(ValueError):\n        helpers.BasicAuth(\"nkim\", None)\n\n\ndef test_basic_with_auth_colon_in_login() -> None:\n    with pytest.raises(ValueError):\n        helpers.BasicAuth(\"nkim:1\", \"pwd\")\n\n\ndef test_basic_auth3() -> None:\n    auth = helpers.BasicAuth(\"nkim\")\n    assert auth.login == \"nkim\"\n    assert auth.password == \"\"\n\n\ndef test_basic_auth4() -> None:\n    auth = helpers.BasicAuth(\"nkim\", \"pwd\")\n    assert auth.login == \"nkim\"\n    assert auth.password == \"pwd\"\n    assert auth.encode() == \"Basic bmtpbTpwd2Q=\"\n\n\n@pytest.mark.parametrize(\n    \"header\",\n    (\n        \"Basic bmtpbTpwd2Q=\",\n        \"basic bmtpbTpwd2Q=\",\n    ),\n)\ndef test_basic_auth_decode(header) -> None:\n    auth = helpers.BasicAuth.decode(header)\n    assert auth.login == \"nkim\"\n    assert auth.password == \"pwd\"\n\n\ndef test_basic_auth_invalid() -> None:\n    with pytest.raises(ValueError):\n        helpers.BasicAuth.decode(\"bmtpbTpwd2Q=\")\n\n\ndef test_basic_auth_decode_not_basic() -> None:\n    with pytest.raises(ValueError):\n        helpers.BasicAuth.decode(\"Complex bmtpbTpwd2Q=\")\n\n\ndef test_basic_auth_decode_bad_base64() -> None:\n    with pytest.raises(ValueError):\n        helpers.BasicAuth.decode(\"Basic bmtpbTpwd2Q\")\n\n\n@pytest.mark.parametrize(\"header\", (\"Basic ???\", \"Basic   \"))\ndef test_basic_auth_decode_illegal_chars_base64(header) -> None:\n    with pytest.raises(ValueError, match=\"Invalid base64 encoding.\"):\n        helpers.BasicAuth.decode(header)\n\n\ndef test_basic_auth_decode_invalid_credentials() -> None:\n    with pytest.raises(ValueError, match=\"Invalid credentials.\"):\n        header = \"Basic {}\".format(base64.b64encode(b\"username\").decode())\n        helpers.BasicAuth.decode(header)\n\n\n@pytest.mark.parametrize(\n    \"credentials, expected_auth\",\n    (\n        (\":\", helpers.BasicAuth(login=\"\", password=\"\", encoding=\"latin1\")),\n        (\n            \"username:\",\n            helpers.BasicAuth(login=\"username\", password=\"\", encoding=\"latin1\"),\n        ),\n        (\n            \":password\",\n            helpers.BasicAuth(login=\"\", password=\"password\", encoding=\"latin1\"),\n        ),\n        (\n            \"username:password\",\n            helpers.BasicAuth(login=\"username\", password=\"password\", encoding=\"latin1\"),\n        ),\n    ),\n)\ndef test_basic_auth_decode_blank_username(credentials, expected_auth) -> None:\n    header = f\"Basic {base64.b64encode(credentials.encode()).decode()}\"\n    assert helpers.BasicAuth.decode(header) == expected_auth\n\n\ndef test_basic_auth_from_url() -> None:\n    url = URL(\"http://user:pass@example.com\")\n    auth = helpers.BasicAuth.from_url(url)\n    assert auth.login == \"user\"\n    assert auth.password == \"pass\"\n\n\ndef test_basic_auth_from_not_url() -> None:\n    with pytest.raises(TypeError):\n        helpers.BasicAuth.from_url(\"http://user:pass@example.com\")\n\n\nclass ReifyMixin:\n    reify = NotImplemented\n\n    def test_reify(self) -> None:\n        class A:\n            def __init__(self):\n                self._cache = {}\n\n            @self.reify\n            def prop(self):\n                return 1\n\n        a = A()\n        assert 1 == a.prop\n\n    def test_reify_class(self) -> None:\n        class A:\n            def __init__(self):\n                self._cache = {}\n\n            @self.reify\n            def prop(self):\n                \"\"\"Docstring.\"\"\"\n                return 1\n\n        assert isinstance(A.prop, self.reify)\n        assert \"Docstring.\" == A.prop.__doc__\n\n    def test_reify_assignment(self) -> None:\n        class A:\n            def __init__(self):\n                self._cache = {}\n\n            @self.reify\n            def prop(self):\n                return 1\n\n        a = A()\n\n        with pytest.raises(AttributeError):\n            a.prop = 123\n\n\nclass TestPyReify(ReifyMixin):\n    reify = helpers.reify_py\n\n\nif not helpers.NO_EXTENSIONS and not IS_PYPY and hasattr(helpers, \"reify_c\"):\n\n    class TestCReify(ReifyMixin):\n        reify = helpers.reify_c\n\n\n# ----------------------------------- is_ip_address() ----------------------\n\n\ndef test_is_ip_address() -> None:\n    assert helpers.is_ip_address(\"127.0.0.1\")\n    assert helpers.is_ip_address(\"::1\")\n    assert helpers.is_ip_address(\"FE80:0000:0000:0000:0202:B3FF:FE1E:8329\")\n\n    # Hostnames\n    assert not helpers.is_ip_address(\"localhost\")\n    assert not helpers.is_ip_address(\"www.example.com\")\n\n    # Out of range\n    assert not helpers.is_ip_address(\"999.999.999.999\")\n    # Contain a port\n    assert not helpers.is_ip_address(\"127.0.0.1:80\")\n    assert not helpers.is_ip_address(\"[2001:db8:0:1]:80\")\n    # Too many \"::\"\n    assert not helpers.is_ip_address(\"1200::AB00:1234::2552:7777:1313\")\n\n\ndef test_is_ip_address_bytes() -> None:\n    assert helpers.is_ip_address(b\"127.0.0.1\")\n    assert helpers.is_ip_address(b\"::1\")\n    assert helpers.is_ip_address(b\"FE80:0000:0000:0000:0202:B3FF:FE1E:8329\")\n\n    # Hostnames\n    assert not helpers.is_ip_address(b\"localhost\")\n    assert not helpers.is_ip_address(b\"www.example.com\")\n\n    # Out of range\n    assert not helpers.is_ip_address(b\"999.999.999.999\")\n    # Contain a port\n    assert not helpers.is_ip_address(b\"127.0.0.1:80\")\n    assert not helpers.is_ip_address(b\"[2001:db8:0:1]:80\")\n    # Too many \"::\"\n    assert not helpers.is_ip_address(b\"1200::AB00:1234::2552:7777:1313\")\n\n\ndef test_ipv4_addresses() -> None:\n    ip_addresses = [\n        \"0.0.0.0\",\n        \"127.0.0.1\",\n        \"255.255.255.255\",\n    ]\n    for address in ip_addresses:\n        assert helpers.is_ipv4_address(address)\n        assert not helpers.is_ipv6_address(address)\n        assert helpers.is_ip_address(address)\n\n\ndef test_ipv6_addresses() -> None:\n    ip_addresses = [\n        \"0:0:0:0:0:0:0:0\",\n        \"FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF\",\n        \"00AB:0002:3008:8CFD:00AB:0002:3008:8CFD\",\n        \"00ab:0002:3008:8cfd:00ab:0002:3008:8cfd\",\n        \"AB:02:3008:8CFD:AB:02:3008:8CFD\",\n        \"AB:02:3008:8CFD::02:3008:8CFD\",\n        \"::\",\n        \"1::1\",\n    ]\n    for address in ip_addresses:\n        assert not helpers.is_ipv4_address(address)\n        assert helpers.is_ipv6_address(address)\n        assert helpers.is_ip_address(address)\n\n\ndef test_host_addresses() -> None:\n    hosts = [\n        \"www.four.part.host\" \"www.python.org\",\n        \"foo.bar\",\n        \"localhost\",\n    ]\n    for host in hosts:\n        assert not helpers.is_ip_address(host)\n\n\ndef test_is_ip_address_invalid_type() -> None:\n    with pytest.raises(TypeError):\n        helpers.is_ip_address(123)\n\n    with pytest.raises(TypeError):\n        helpers.is_ip_address(object())\n\n\n# ----------------------------------- TimeoutHandle -------------------\n\n\ndef test_timeout_handle(loop) -> None:\n    handle = helpers.TimeoutHandle(loop, 10.2)\n    cb = mock.Mock()\n    handle.register(cb)\n    assert cb == handle._callbacks[0][0]\n    handle.close()\n    assert not handle._callbacks\n\n\ndef test_when_timeout_smaller_second(loop) -> None:\n    timeout = 0.1\n    timer = loop.time() + timeout\n\n    handle = helpers.TimeoutHandle(loop, timeout)\n    when = handle.start()._when\n    handle.close()\n\n    assert isinstance(when, float)\n    assert when - timer == pytest.approx(0, abs=0.001)\n\n\ndef test_when_timeout_smaller_second_with_low_threshold(loop) -> None:\n    timeout = 0.1\n    timer = loop.time() + timeout\n\n    handle = helpers.TimeoutHandle(loop, timeout, 0.01)\n    when = handle.start()._when\n    handle.close()\n\n    assert isinstance(when, int)\n    assert when == ceil(timer)\n\n\ndef test_timeout_handle_cb_exc(loop) -> None:\n    handle = helpers.TimeoutHandle(loop, 10.2)\n    cb = mock.Mock()\n    handle.register(cb)\n    cb.side_effect = ValueError()\n    handle()\n    assert cb.called\n    assert not handle._callbacks\n\n\ndef test_timer_context_not_cancelled() -> None:\n    with mock.patch(\"aiohttp.helpers.asyncio\") as m_asyncio:\n        m_asyncio.TimeoutError = asyncio.TimeoutError\n        loop = mock.Mock()\n        ctx = helpers.TimerContext(loop)\n        ctx.timeout()\n\n        with pytest.raises(asyncio.TimeoutError):\n            with ctx:\n                pass\n\n        assert not m_asyncio.current_task.return_value.cancel.called\n\n\ndef test_timer_context_no_task(loop) -> None:\n    with pytest.raises(RuntimeError):\n        with helpers.TimerContext(loop):\n            pass\n\n\nasync def test_weakref_handle(loop) -> None:\n    cb = mock.Mock()\n    helpers.weakref_handle(cb, \"test\", 0.01, loop)\n    await asyncio.sleep(0.1)\n    assert cb.test.called\n\n\nasync def test_weakref_handle_with_small_threshold(loop) -> None:\n    cb = mock.Mock()\n    loop = mock.Mock()\n    loop.time.return_value = 10\n    helpers.weakref_handle(cb, \"test\", 0.1, loop, 0.01)\n    loop.call_at.assert_called_with(\n        11, helpers._weakref_handle, (weakref.ref(cb), \"test\")\n    )\n\n\nasync def test_weakref_handle_weak(loop) -> None:\n    cb = mock.Mock()\n    helpers.weakref_handle(cb, \"test\", 0.01, loop)\n    del cb\n    gc.collect()\n    await asyncio.sleep(0.1)\n\n\n# -------------------- ceil math -------------------------\n\n\ndef test_ceil_call_later() -> None:\n    cb = mock.Mock()\n    loop = mock.Mock()\n    loop.time.return_value = 10.1\n    helpers.call_later(cb, 10.1, loop)\n    loop.call_at.assert_called_with(21.0, cb)\n\n\nasync def test_ceil_timeout_round(loop) -> None:\n    async with helpers.ceil_timeout(7.5) as cm:\n        if sys.version_info >= (3, 11):\n            frac, integer = modf(cm.when())\n        else:\n            frac, integer = modf(cm.deadline)\n        assert frac == 0\n\n\nasync def test_ceil_timeout_small(loop) -> None:\n    async with helpers.ceil_timeout(1.1) as cm:\n        if sys.version_info >= (3, 11):\n            frac, integer = modf(cm.when())\n        else:\n            frac, integer = modf(cm.deadline)\n        # a chance for exact integer with zero fraction is negligible\n        assert frac != 0\n\n\ndef test_ceil_call_later_with_small_threshold() -> None:\n    cb = mock.Mock()\n    loop = mock.Mock()\n    loop.time.return_value = 10.1\n    helpers.call_later(cb, 4.5, loop, 1)\n    loop.call_at.assert_called_with(15, cb)\n\n\ndef test_ceil_call_later_no_timeout() -> None:\n    cb = mock.Mock()\n    loop = mock.Mock()\n    helpers.call_later(cb, 0, loop)\n    assert not loop.call_at.called\n\n\nasync def test_ceil_timeout_none(loop) -> None:\n    async with helpers.ceil_timeout(None) as cm:\n        if sys.version_info >= (3, 11):\n            assert cm.when() is None\n        else:\n            assert cm.deadline is None\n\n\nasync def test_ceil_timeout_small_with_overriden_threshold(loop) -> None:\n    async with helpers.ceil_timeout(1.5, ceil_threshold=1) as cm:\n        if sys.version_info >= (3, 11):\n            frac, integer = modf(cm.when())\n        else:\n            frac, integer = modf(cm.deadline)\n        assert frac == 0\n\n\n# -------------------------------- ContentDisposition -------------------\n\n\n@pytest.mark.parametrize(\n    \"kwargs, result\",\n    [\n        (dict(foo=\"bar\"), 'attachment; foo=\"bar\"'),\n        (dict(foo=\"bar[]\"), 'attachment; foo=\"bar[]\"'),\n        (dict(foo=' a\"\"b\\\\'), 'attachment; foo=\"\\\\ a\\\\\"\\\\\"b\\\\\\\\\"'),\n        (dict(foo=\"b\u00e4r\"), \"attachment; foo*=utf-8''b%C3%A4r\"),\n        (dict(foo='b\u00e4r \"\\\\', quote_fields=False), 'attachment; foo=\"b\u00e4r \\\\\"\\\\\\\\\"'),\n        (dict(foo=\"b\u00e4r\", _charset=\"latin-1\"), \"attachment; foo*=latin-1''b%E4r\"),\n        (dict(filename=\"b\u00e4r\"), 'attachment; filename=\"b%C3%A4r\"'),\n        (dict(filename=\"b\u00e4r\", _charset=\"latin-1\"), 'attachment; filename=\"b%E4r\"'),\n        (\n            dict(filename='b\u00e4r \"\\\\', quote_fields=False),\n            'attachment; filename=\"b\u00e4r \\\\\"\\\\\\\\\"',\n        ),\n    ],\n)\ndef test_content_disposition(kwargs, result) -> None:\n    assert helpers.content_disposition_header(\"attachment\", **kwargs) == result\n\n\ndef test_content_disposition_bad_type() -> None:\n    with pytest.raises(ValueError):\n        helpers.content_disposition_header(\"foo bar\")\n    with pytest.raises(ValueError):\n        helpers.content_disposition_header(\"\u2014\u00c7\u2013\u00b5\u2014\u00c5\u2014\u00c7\")\n    with pytest.raises(ValueError):\n        helpers.content_disposition_header(\"foo\\x00bar\")\n    with pytest.raises(ValueError):\n        helpers.content_disposition_header(\"\")\n\n\ndef test_set_content_disposition_bad_param() -> None:\n    with pytest.raises(ValueError):\n        helpers.content_disposition_header(\"inline\", **{\"foo bar\": \"baz\"})\n    with pytest.raises(ValueError):\n        helpers.content_disposition_header(\"inline\", **{\"\u2014\u00c7\u2013\u00b5\u2014\u00c5\u2014\u00c7\": \"baz\"})\n    with pytest.raises(ValueError):\n        helpers.content_disposition_header(\"inline\", **{\"\": \"baz\"})\n    with pytest.raises(ValueError):\n        helpers.content_disposition_header(\"inline\", **{\"foo\\x00bar\": \"baz\"})\n\n\n# --------------------- proxies_from_env ------------------------------\n\n\n@pytest.mark.parametrize(\n    (\"proxy_env_vars\", \"url_input\", \"expected_scheme\"),\n    (\n        ({\"http_proxy\": \"http://aiohttp.io/path\"}, \"http://aiohttp.io/path\", \"http\"),\n        ({\"https_proxy\": \"http://aiohttp.io/path\"}, \"http://aiohttp.io/path\", \"https\"),\n        ({\"ws_proxy\": \"http://aiohttp.io/path\"}, \"http://aiohttp.io/path\", \"ws\"),\n        ({\"wss_proxy\": \"http://aiohttp.io/path\"}, \"http://aiohttp.io/path\", \"wss\"),\n    ),\n    indirect=[\"proxy_env_vars\"],\n    ids=(\"http\", \"https\", \"ws\", \"wss\"),\n)\n@pytest.mark.usefixtures(\"proxy_env_vars\")\ndef test_proxies_from_env(url_input, expected_scheme) -> None:\n    url = URL(url_input)\n    ret = helpers.proxies_from_env()\n    assert ret.keys() == {expected_scheme}\n    assert ret[expected_scheme].proxy == url\n    assert ret[expected_scheme].proxy_auth is None\n\n\n@pytest.mark.parametrize(\n    (\"proxy_env_vars\", \"url_input\", \"expected_scheme\"),\n    (\n        (\n            {\"https_proxy\": \"https://aiohttp.io/path\"},\n            \"https://aiohttp.io/path\",\n            \"https\",\n        ),\n        ({\"wss_proxy\": \"wss://aiohttp.io/path\"}, \"wss://aiohttp.io/path\", \"wss\"),\n    ),\n    indirect=[\"proxy_env_vars\"],\n    ids=(\"https\", \"wss\"),\n)\n@pytest.mark.usefixtures(\"proxy_env_vars\")\ndef test_proxies_from_env_skipped(caplog, url_input, expected_scheme) -> None:\n    url = URL(url_input)\n    assert helpers.proxies_from_env() == {}\n    assert len(caplog.records) == 1\n    log_message = \"{proto!s} proxies {url!s} are not supported, ignoring\".format(\n        proto=expected_scheme.upper(), url=url\n    )\n    assert caplog.record_tuples == [(\"aiohttp.client\", 30, log_message)]\n\n\n@pytest.mark.parametrize(\n    (\"proxy_env_vars\", \"url_input\", \"expected_scheme\"),\n    (\n        (\n            {\"http_proxy\": \"http://user:pass@aiohttp.io/path\"},\n            \"http://user:pass@aiohttp.io/path\",\n            \"http\",\n        ),\n    ),\n    indirect=[\"proxy_env_vars\"],\n    ids=(\"http\",),\n)\n@pytest.mark.usefixtures(\"proxy_env_vars\")\ndef test_proxies_from_env_http_with_auth(url_input, expected_scheme) -> None:\n    url = URL(\"http://user:pass@aiohttp.io/path\")\n    ret = helpers.proxies_from_env()\n    assert ret.keys() == {expected_scheme}\n    assert ret[expected_scheme].proxy == url.with_user(None)\n    proxy_auth = ret[expected_scheme].proxy_auth\n    assert proxy_auth.login == \"user\"\n    assert proxy_auth.password == \"pass\"\n    assert proxy_auth.encoding == \"latin1\"\n\n\n# --------------------- get_env_proxy_for_url ------------------------------\n\n\n@pytest.fixture\ndef proxy_env_vars(monkeypatch, request):\n    for schema in getproxies_environment().keys():\n        monkeypatch.delenv(f\"{schema}_proxy\", False)\n\n    for proxy_type, proxy_list in request.param.items():\n        monkeypatch.setenv(proxy_type, proxy_list)\n\n    return request.param\n\n\n@pytest.mark.parametrize(\n    (\"proxy_env_vars\", \"url_input\", \"expected_err_msg\"),\n    (\n        (\n            {\"no_proxy\": \"aiohttp.io\"},\n            \"http://aiohttp.io/path\",\n            r\"Proxying is disallowed for `'aiohttp.io'`\",\n        ),\n        (\n            {\"no_proxy\": \"aiohttp.io,proxy.com\"},\n            \"http://aiohttp.io/path\",\n            r\"Proxying is disallowed for `'aiohttp.io'`\",\n        ),\n        (\n            {\"http_proxy\": \"http://example.com\"},\n            \"https://aiohttp.io/path\",\n            r\"No proxies found for `https://aiohttp.io/path` in the env\",\n        ),\n        (\n            {\"https_proxy\": \"https://example.com\"},\n            \"http://aiohttp.io/path\",\n            r\"No proxies found for `http://aiohttp.io/path` in the env\",\n        ),\n        (\n            {},\n            \"https://aiohttp.io/path\",\n            r\"No proxies found for `https://aiohttp.io/path` in the env\",\n        ),\n        (\n            {\"https_proxy\": \"https://example.com\"},\n            \"\",\n            r\"No proxies found for `` in the env\",\n        ),\n    ),\n    indirect=[\"proxy_env_vars\"],\n    ids=(\n        \"url_matches_the_no_proxy_list\",\n        \"url_matches_the_no_proxy_list_multiple\",\n        \"url_scheme_does_not_match_http_proxy_list\",\n        \"url_scheme_does_not_match_https_proxy_list\",\n        \"no_proxies_are_set\",\n        \"url_is_empty\",\n    ),\n)\n@pytest.mark.usefixtures(\"proxy_env_vars\")\ndef test_get_env_proxy_for_url_negative(url_input, expected_err_msg) -> None:\n    url = URL(url_input)\n    with pytest.raises(LookupError, match=expected_err_msg):\n        helpers.get_env_proxy_for_url(url)\n\n\n@pytest.mark.parametrize(\n    (\"proxy_env_vars\", \"url_input\"),\n    (\n        ({\"http_proxy\": \"http://example.com\"}, \"http://aiohttp.io/path\"),\n        ({\"https_proxy\": \"http://example.com\"}, \"https://aiohttp.io/path\"),\n        (\n            {\"http_proxy\": \"http://example.com,http://proxy.org\"},\n            \"http://aiohttp.io/path\",\n        ),\n    ),\n    indirect=[\"proxy_env_vars\"],\n    ids=(\n        \"url_scheme_match_http_proxy_list\",\n        \"url_scheme_match_https_proxy_list\",\n        \"url_scheme_match_http_proxy_list_multiple\",\n    ),\n)\ndef test_get_env_proxy_for_url(proxy_env_vars, url_input) -> None:\n    url = URL(url_input)\n    proxy, proxy_auth = helpers.get_env_proxy_for_url(url)\n    proxy_list = proxy_env_vars[url.scheme + \"_proxy\"]\n    assert proxy == URL(proxy_list)\n    assert proxy_auth is None\n\n\n# ------------- set_result / set_exception ----------------------\n\n\nasync def test_set_result(loop) -> None:\n    fut = loop.create_future()\n    helpers.set_result(fut, 123)\n    assert 123 == await fut\n\n\nasync def test_set_result_cancelled(loop) -> None:\n    fut = loop.create_future()\n    fut.cancel()\n    helpers.set_result(fut, 123)\n\n    with pytest.raises(asyncio.CancelledError):\n        await fut\n\n\nasync def test_set_exception(loop) -> None:\n    fut = loop.create_future()\n    helpers.set_exception(fut, RuntimeError())\n    with pytest.raises(RuntimeError):\n        await fut\n\n\nasync def test_set_exception_cancelled(loop) -> None:\n    fut = loop.create_future()\n    fut.cancel()\n    helpers.set_exception(fut, RuntimeError())\n\n    with pytest.raises(asyncio.CancelledError):\n        await fut\n\n\n# ----------- ChainMapProxy --------------------------\n\n\nclass TestChainMapProxy:\n    def test_inheritance(self) -> None:\n        with pytest.raises(TypeError):\n\n            class A(helpers.ChainMapProxy):\n                pass\n\n    def test_getitem(self) -> None:\n        d1 = {\"a\": 2, \"b\": 3}\n        d2 = {\"a\": 1}\n        cp = helpers.ChainMapProxy([d1, d2])\n        assert cp[\"a\"] == 2\n        assert cp[\"b\"] == 3\n\n    def test_getitem_not_found(self) -> None:\n        d = {\"a\": 1}\n        cp = helpers.ChainMapProxy([d])\n        with pytest.raises(KeyError):\n            cp[\"b\"]\n\n    def test_get(self) -> None:\n        d1 = {\"a\": 2, \"b\": 3}\n        d2 = {\"a\": 1}\n        cp = helpers.ChainMapProxy([d1, d2])\n        assert cp.get(\"a\") == 2\n\n    def test_get_default(self) -> None:\n        d1 = {\"a\": 2, \"b\": 3}\n        d2 = {\"a\": 1}\n        cp = helpers.ChainMapProxy([d1, d2])\n        assert cp.get(\"c\", 4) == 4\n\n    def test_get_non_default(self) -> None:\n        d1 = {\"a\": 2, \"b\": 3}\n        d2 = {\"a\": 1}\n        cp = helpers.ChainMapProxy([d1, d2])\n        assert cp.get(\"a\", 4) == 2\n\n    def test_len(self) -> None:\n        d1 = {\"a\": 2, \"b\": 3}\n        d2 = {\"a\": 1}\n        cp = helpers.ChainMapProxy([d1, d2])\n        assert len(cp) == 2\n\n    def test_iter(self) -> None:\n        d1 = {\"a\": 2, \"b\": 3}\n        d2 = {\"a\": 1}\n        cp = helpers.ChainMapProxy([d1, d2])\n        assert set(cp) == {\"a\", \"b\"}\n\n    def test_contains(self) -> None:\n        d1 = {\"a\": 2, \"b\": 3}\n        d2 = {\"a\": 1}\n        cp = helpers.ChainMapProxy([d1, d2])\n        assert \"a\" in cp\n        assert \"b\" in cp\n        assert \"c\" not in cp\n\n    def test_bool(self) -> None:\n        assert helpers.ChainMapProxy([{\"a\": 1}])\n        assert not helpers.ChainMapProxy([{}, {}])\n        assert not helpers.ChainMapProxy([])\n\n    def test_repr(self) -> None:\n        d1 = {\"a\": 2, \"b\": 3}\n        d2 = {\"a\": 1}\n        cp = helpers.ChainMapProxy([d1, d2])\n        expected = f\"ChainMapProxy({d1!r}, {d2!r})\"\n        assert expected == repr(cp)\n\n\ndef test_is_expected_content_type_json_match_exact():\n    expected_ct = \"application/json\"\n    response_ct = \"application/json\"\n    assert is_expected_content_type(\n        response_content_type=response_ct, expected_content_type=expected_ct\n    )\n\n\ndef test_is_expected_content_type_json_match_partially():\n    expected_ct = \"application/json\"\n    response_ct = \"application/alto-costmap+json\"  # mime-type from rfc7285\n    assert is_expected_content_type(\n        response_content_type=response_ct, expected_content_type=expected_ct\n    )\n\n\ndef test_is_expected_content_type_non_application_json_suffix():\n    expected_ct = \"application/json\"\n    response_ct = \"model/gltf+json\"  # rfc 6839\n    assert is_expected_content_type(\n        response_content_type=response_ct, expected_content_type=expected_ct\n    )\n\n\ndef test_is_expected_content_type_non_application_json_private_suffix():\n    expected_ct = \"application/json\"\n    response_ct = \"x-foo/bar+json\"  # rfc 6839\n    assert is_expected_content_type(\n        response_content_type=response_ct, expected_content_type=expected_ct\n    )\n\n\ndef test_is_expected_content_type_json_non_lowercase():\n    \"\"\"Per RFC 2045, media type matching is case insensitive.\"\"\"\n    expected_ct = \"application/json\"\n    response_ct = \"Application/JSON\"\n    assert is_expected_content_type(\n        response_content_type=response_ct, expected_content_type=expected_ct\n    )\n\n\ndef test_is_expected_content_type_json_trailing_chars():\n    expected_ct = \"application/json\"\n    response_ct = \"application/json-seq\"\n    assert not is_expected_content_type(\n        response_content_type=response_ct, expected_content_type=expected_ct\n    )\n\n\ndef test_is_expected_content_type_non_json_match_exact():\n    expected_ct = \"text/javascript\"\n    response_ct = \"text/javascript\"\n    assert is_expected_content_type(\n        response_content_type=response_ct, expected_content_type=expected_ct\n    )\n\n\ndef test_is_expected_content_type_non_json_not_match():\n    expected_ct = \"application/json\"\n    response_ct = \"text/plain\"\n    assert not is_expected_content_type(\n        response_content_type=response_ct, expected_content_type=expected_ct\n    )\n\n\n# It's necessary to subclass CookieMixin before using it.\n# See the comments on its __slots__.\nclass CookieImplementation(helpers.CookieMixin):\n    pass\n\n\ndef test_cookies_mixin():\n    sut = CookieImplementation()\n\n    assert sut.cookies == {}\n    assert str(sut.cookies) == \"\"\n\n    sut.set_cookie(\"name\", \"value\")\n    assert str(sut.cookies) == \"Set-Cookie: name=value; Path=/\"\n    sut.set_cookie(\"name\", \"other_value\")\n    assert str(sut.cookies) == \"Set-Cookie: name=other_value; Path=/\"\n\n    sut.cookies[\"name\"] = \"another_other_value\"\n    sut.cookies[\"name\"][\"max-age\"] = 10\n    assert (\n        str(sut.cookies) == \"Set-Cookie: name=another_other_value; Max-Age=10; Path=/\"\n    )\n\n    sut.del_cookie(\"name\")\n    expected = (\n        'Set-Cookie: name=(\"\")?; '\n        \"expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=0; Path=/\"\n    )\n    assert Matches(expected) == str(sut.cookies)\n\n    sut.set_cookie(\"name\", \"value\", domain=\"local.host\")\n    expected = \"Set-Cookie: name=value; Domain=local.host; Path=/\"\n    assert str(sut.cookies) == expected\n\n\ndef test_cookies_mixin_path():\n    sut = CookieImplementation()\n\n    assert sut.cookies == {}\n\n    sut.set_cookie(\"name\", \"value\", path=\"/some/path\")\n    assert str(sut.cookies) == \"Set-Cookie: name=value; Path=/some/path\"\n    sut.set_cookie(\"name\", \"value\", expires=\"123\")\n    assert str(sut.cookies) == \"Set-Cookie: name=value; expires=123; Path=/\"\n    sut.set_cookie(\n        \"name\",\n        \"value\",\n        domain=\"example.com\",\n        path=\"/home\",\n        expires=\"123\",\n        max_age=\"10\",\n        secure=True,\n        httponly=True,\n        version=\"2.0\",\n        samesite=\"lax\",\n    )\n    assert (\n        str(sut.cookies).lower() == \"set-cookie: name=value; \"\n        \"domain=example.com; \"\n        \"expires=123; \"\n        \"httponly; \"\n        \"max-age=10; \"\n        \"path=/home; \"\n        \"samesite=lax; \"\n        \"secure; \"\n        \"version=2.0\"\n    )\n\n\ndef test_sutonse_cookie__issue_del_cookie():\n    sut = CookieImplementation()\n\n    assert sut.cookies == {}\n    assert str(sut.cookies) == \"\"\n\n    sut.del_cookie(\"name\")\n    expected = (\n        'Set-Cookie: name=(\"\")?; '\n        \"expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=0; Path=/\"\n    )\n    assert Matches(expected) == str(sut.cookies)\n\n\ndef test_cookie_set_after_del():\n    sut = CookieImplementation()\n\n    sut.del_cookie(\"name\")\n    sut.set_cookie(\"name\", \"val\")\n    # check for Max-Age dropped\n    expected = \"Set-Cookie: name=val; Path=/\"\n    assert str(sut.cookies) == expected\n\n\ndef test_populate_with_cookies():\n    cookies_mixin = CookieImplementation()\n    cookies_mixin.set_cookie(\"name\", \"value\")\n    headers = CIMultiDict()\n\n    helpers.populate_with_cookies(headers, cookies_mixin.cookies)\n    assert headers == CIMultiDict({\"Set-Cookie\": \"name=value; Path=/\"})\n\n\n@pytest.mark.parametrize(\n    [\"value\", \"expected\"],\n    [\n        # email.utils.parsedate returns None\n        pytest.param(\"xxyyzz\", None),\n        # datetime.datetime fails with ValueError(\"year 4446413 is out of range\")\n        pytest.param(\"Tue, 08 Oct 4446413 00:56:40 GMT\", None),\n        # datetime.datetime fails with ValueError(\"second must be in 0..59\")\n        pytest.param(\"Tue, 08 Oct 2000 00:56:80 GMT\", None),\n        # OK\n        pytest.param(\n            \"Tue, 08 Oct 2000 00:56:40 GMT\",\n            datetime.datetime(2000, 10, 8, 0, 56, 40, tzinfo=datetime.timezone.utc),\n        ),\n        # OK (ignore timezone and overwrite to UTC)\n        pytest.param(\n            \"Tue, 08 Oct 2000 00:56:40 +0900\",\n            datetime.datetime(2000, 10, 8, 0, 56, 40, tzinfo=datetime.timezone.utc),\n        ),\n    ],\n)\ndef test_parse_http_date(value, expected):\n    assert parse_http_date(value) == expected\n\n\n@pytest.mark.parametrize(\n    [\"netrc_contents\", \"expected_username\"],\n    [\n        (\n            \"machine example.com login username password pass\\n\",\n            \"username\",\n        ),\n    ],\n    indirect=(\"netrc_contents\",),\n)\n@pytest.mark.usefixtures(\"netrc_contents\")\ndef test_netrc_from_env(expected_username: str):\n    \"\"\"Test that reading netrc files from env works as expected\"\"\"\n    netrc_obj = helpers.netrc_from_env()\n    assert netrc_obj.authenticators(\"example.com\")[0] == expected_username\n\n\n@pytest.fixture\ndef protected_dir(tmp_path: Path):\n    protected_dir = tmp_path / \"protected\"\n    protected_dir.mkdir()\n    try:\n        protected_dir.chmod(0o600)\n        yield protected_dir\n    finally:\n        protected_dir.rmdir()\n\n\ndef test_netrc_from_home_does_not_raise_if_access_denied(\n    protected_dir: Path, monkeypatch: pytest.MonkeyPatch\n):\n    monkeypatch.setattr(Path, \"home\", lambda: protected_dir)\n    monkeypatch.delenv(\"NETRC\", raising=False)\n\n    helpers.netrc_from_env()\n\n\n@pytest.mark.parametrize(\n    [\"netrc_contents\", \"expected_auth\"],\n    [\n        (\n            \"machine example.com login username password pass\\n\",\n            helpers.BasicAuth(\"username\", \"pass\"),\n        ),\n        (\n            \"machine example.com account username password pass\\n\",\n            helpers.BasicAuth(\"username\", \"pass\"),\n        ),\n        (\n            \"machine example.com password pass\\n\",\n            helpers.BasicAuth(\"\", \"pass\"),\n        ),\n    ],\n    indirect=(\"netrc_contents\",),\n)\n@pytest.mark.usefixtures(\"netrc_contents\")\ndef test_basicauth_present_in_netrc(\n    expected_auth: helpers.BasicAuth,\n):\n    \"\"\"Test that netrc file contents are properly parsed into BasicAuth tuples\"\"\"\n    netrc_obj = helpers.netrc_from_env()\n\n    assert expected_auth == helpers.basicauth_from_netrc(netrc_obj, \"example.com\")\n\n\n@pytest.mark.parametrize(\n    [\"netrc_contents\"],\n    [\n        (\"\",),\n    ],\n    indirect=(\"netrc_contents\",),\n)\n@pytest.mark.usefixtures(\"netrc_contents\")\ndef test_read_basicauth_from_empty_netrc():\n    \"\"\"Test that an error is raised if netrc doesn't have an entry for our host\"\"\"\n    netrc_obj = helpers.netrc_from_env()\n\n    with pytest.raises(\n        LookupError, match=\"No entry for example.com found in the `.netrc` file.\"\n    ):\n        helpers.basicauth_from_netrc(netrc_obj, \"example.com\")\n\n\ndef test_method_must_be_empty_body():\n    \"\"\"Test that HEAD is the only method that unequivocally must have an empty body.\"\"\"\n    assert method_must_be_empty_body(\"HEAD\") is True\n    # CONNECT is only empty on a successful response\n    assert method_must_be_empty_body(\"CONNECT\") is False\n\n\ndef test_should_remove_content_length_is_subset_of_must_be_empty_body():\n    \"\"\"Test should_remove_content_length is always a subset of must_be_empty_body.\"\"\"\n    assert should_remove_content_length(\"GET\", 101) is True\n    assert must_be_empty_body(\"GET\", 101) is True\n\n    assert should_remove_content_length(\"GET\", 102) is True\n    assert must_be_empty_body(\"GET\", 102) is True\n\n    assert should_remove_content_length(\"GET\", 204) is True\n    assert must_be_empty_body(\"GET\", 204) is True\n\n    assert should_remove_content_length(\"GET\", 204) is True\n    assert must_be_empty_body(\"GET\", 204) is True\n\n    assert should_remove_content_length(\"GET\", 200) is False\n    assert must_be_empty_body(\"GET\", 200) is False\n\n    assert should_remove_content_length(\"HEAD\", 200) is False\n    assert must_be_empty_body(\"HEAD\", 200) is True\n\n    # CONNECT is only empty on a successful response\n    assert should_remove_content_length(\"CONNECT\", 200) is True\n    assert must_be_empty_body(\"CONNECT\", 200) is True\n\n    assert should_remove_content_length(\"CONNECT\", 201) is True\n    assert must_be_empty_body(\"CONNECT\", 201) is True\n\n    assert should_remove_content_length(\"CONNECT\", 300) is False\n    assert must_be_empty_body(\"CONNECT\", 300) is False\n", "tests/test_web_cli.py": "from typing import Any\n\nimport pytest\n\nfrom aiohttp import web\n\n\ndef test_entry_func_empty(mocker: Any) -> None:\n    error = mocker.patch(\"aiohttp.web.ArgumentParser.error\", side_effect=SystemExit)\n    argv = [\"\"]\n\n    with pytest.raises(SystemExit):\n        web.main(argv)\n\n    error.assert_called_with(\"'entry-func' not in 'module:function' syntax\")\n\n\ndef test_entry_func_only_module(mocker: Any) -> None:\n    argv = [\"test\"]\n    error = mocker.patch(\"aiohttp.web.ArgumentParser.error\", side_effect=SystemExit)\n\n    with pytest.raises(SystemExit):\n        web.main(argv)\n\n    error.assert_called_with(\"'entry-func' not in 'module:function' syntax\")\n\n\ndef test_entry_func_only_function(mocker: Any) -> None:\n    argv = [\":test\"]\n    error = mocker.patch(\"aiohttp.web.ArgumentParser.error\", side_effect=SystemExit)\n\n    with pytest.raises(SystemExit):\n        web.main(argv)\n\n    error.assert_called_with(\"'entry-func' not in 'module:function' syntax\")\n\n\ndef test_entry_func_only_separator(mocker: Any) -> None:\n    argv = [\":\"]\n    error = mocker.patch(\"aiohttp.web.ArgumentParser.error\", side_effect=SystemExit)\n\n    with pytest.raises(SystemExit):\n        web.main(argv)\n\n    error.assert_called_with(\"'entry-func' not in 'module:function' syntax\")\n\n\ndef test_entry_func_relative_module(mocker: Any) -> None:\n    argv = [\".a.b:c\"]\n\n    error = mocker.patch(\"aiohttp.web.ArgumentParser.error\", side_effect=SystemExit)\n    with pytest.raises(SystemExit):\n        web.main(argv)\n\n    error.assert_called_with(\"relative module names not supported\")\n\n\ndef test_entry_func_non_existent_module(mocker: Any) -> None:\n    argv = [\"alpha.beta:func\"]\n\n    mocker.patch(\"aiohttp.web.import_module\", side_effect=ImportError(\"Test Error\"))\n    error = mocker.patch(\"aiohttp.web.ArgumentParser.error\", side_effect=SystemExit)\n\n    with pytest.raises(SystemExit):\n        web.main(argv)\n\n    error.assert_called_with(\"unable to import alpha.beta: Test Error\")\n\n\ndef test_entry_func_non_existent_attribute(mocker: Any) -> None:\n    argv = [\"alpha.beta:func\"]\n    import_module = mocker.patch(\"aiohttp.web.import_module\")\n    error = mocker.patch(\"aiohttp.web.ArgumentParser.error\", side_effect=SystemExit)\n    module = import_module(\"alpha.beta\")\n    del module.func\n\n    with pytest.raises(SystemExit):\n        web.main(argv)\n\n    error.assert_called_with(\n        \"module {!r} has no attribute {!r}\".format(\"alpha.beta\", \"func\")\n    )\n\n\ndef test_path_when_unsupported(mocker: Any, monkeypatch: Any) -> None:\n    argv = \"--path=test_path.sock alpha.beta:func\".split()\n    mocker.patch(\"aiohttp.web.import_module\")\n    monkeypatch.delattr(\"socket.AF_UNIX\", raising=False)\n\n    error = mocker.patch(\"aiohttp.web.ArgumentParser.error\", side_effect=SystemExit)\n    with pytest.raises(SystemExit):\n        web.main(argv)\n\n    error.assert_called_with(\n        \"file system paths not supported by your\" \" operating environment\"\n    )\n\n\ndef test_entry_func_call(mocker: Any) -> None:\n    mocker.patch(\"aiohttp.web.run_app\")\n    import_module = mocker.patch(\"aiohttp.web.import_module\")\n    argv = (\n        \"-H testhost -P 6666 --extra-optional-eins alpha.beta:func \"\n        \"--extra-optional-zwei extra positional args\"\n    ).split()\n    module = import_module(\"alpha.beta\")\n\n    with pytest.raises(SystemExit):\n        web.main(argv)\n\n    module.func.assert_called_with(\n        (\"--extra-optional-eins --extra-optional-zwei extra positional \" \"args\").split()\n    )\n\n\ndef test_running_application(mocker: Any) -> None:\n    run_app = mocker.patch(\"aiohttp.web.run_app\")\n    import_module = mocker.patch(\"aiohttp.web.import_module\")\n    exit = mocker.patch(\"aiohttp.web.ArgumentParser.exit\", side_effect=SystemExit)\n    argv = (\n        \"-H testhost -P 6666 --extra-optional-eins alpha.beta:func \"\n        \"--extra-optional-zwei extra positional args\"\n    ).split()\n    module = import_module(\"alpha.beta\")\n    app = module.func()\n\n    with pytest.raises(SystemExit):\n        web.main(argv)\n\n    run_app.assert_called_with(app, host=\"testhost\", port=6666, path=None)\n    exit.assert_called_with(message=\"Stopped\\n\")\n", "tests/test_http_parser.py": "# type: ignore\n# Tests for aiohttp/protocol.py\n\nimport asyncio\nimport re\nfrom contextlib import nullcontext\nfrom typing import Any, Dict, List\nfrom unittest import mock\nfrom urllib.parse import quote\n\nimport pytest\nfrom multidict import CIMultiDict\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp import http_exceptions, streams\nfrom aiohttp.http_parser import (\n    NO_EXTENSIONS,\n    DeflateBuffer,\n    HttpPayloadParser,\n    HttpRequestParserPy,\n    HttpResponseParserPy,\n    HttpVersion,\n)\n\ntry:\n    try:\n        import brotlicffi as brotli\n    except ImportError:\n        import brotli\nexcept ImportError:\n    brotli = None\n\nREQUEST_PARSERS: Any = [HttpRequestParserPy]\nRESPONSE_PARSERS: Any = [HttpResponseParserPy]\n\ntry:\n    from aiohttp.http_parser import HttpRequestParserC, HttpResponseParserC\n\n    REQUEST_PARSERS.append(HttpRequestParserC)\n    RESPONSE_PARSERS.append(HttpResponseParserC)\nexcept ImportError:  # pragma: no cover\n    pass\n\n\n@pytest.fixture\ndef protocol():\n    return mock.Mock()\n\n\ndef _gen_ids(parsers: List[Any]) -> List[str]:\n    return [\n        \"py-parser\" if parser.__module__ == \"aiohttp.http_parser\" else \"c-parser\"\n        for parser in parsers\n    ]\n\n\n@pytest.fixture(params=REQUEST_PARSERS, ids=_gen_ids(REQUEST_PARSERS))\ndef parser(loop: Any, protocol: Any, request: Any):\n    # Parser implementations\n    return request.param(\n        protocol,\n        loop,\n        2**16,\n        max_line_size=8190,\n        max_field_size=8190,\n    )\n\n\n@pytest.fixture(params=REQUEST_PARSERS, ids=_gen_ids(REQUEST_PARSERS))\ndef request_cls(request: Any):\n    # Request Parser class\n    return request.param\n\n\n@pytest.fixture(params=RESPONSE_PARSERS, ids=_gen_ids(RESPONSE_PARSERS))\ndef response(loop: Any, protocol: Any, request: Any):\n    # Parser implementations\n    return request.param(\n        protocol,\n        loop,\n        2**16,\n        max_line_size=8190,\n        max_field_size=8190,\n    )\n\n\n@pytest.fixture(params=RESPONSE_PARSERS, ids=_gen_ids(RESPONSE_PARSERS))\ndef response_cls(request: Any):\n    # Parser implementations\n    return request.param\n\n\n@pytest.fixture\ndef stream():\n    return mock.Mock()\n\n\n@pytest.mark.skipif(NO_EXTENSIONS, reason=\"Extensions available but not imported\")\ndef test_c_parser_loaded():\n    assert \"HttpRequestParserC\" in dir(aiohttp.http_parser)\n    assert \"HttpResponseParserC\" in dir(aiohttp.http_parser)\n    assert \"RawRequestMessageC\" in dir(aiohttp.http_parser)\n    assert \"RawResponseMessageC\" in dir(aiohttp.http_parser)\n\n\ndef test_parse_headers(parser: Any) -> None:\n    text = b\"\"\"GET /test HTTP/1.1\\r\ntest: a line\\r\ntest2: data\\r\n\\r\n\"\"\"\n    messages, upgrade, tail = parser.feed_data(text)\n    assert len(messages) == 1\n    msg = messages[0][0]\n\n    assert list(msg.headers.items()) == [(\"test\", \"a line\"), (\"test2\", \"data\")]\n    assert msg.raw_headers == ((b\"test\", b\"a line\"), (b\"test2\", b\"data\"))\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n\n\ndef test_reject_obsolete_line_folding(parser: Any) -> None:\n    text = b\"\"\"GET /test HTTP/1.1\\r\ntest: line\\r\n Content-Length: 48\\r\ntest2: data\\r\n\\r\n\"\"\"\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\n@pytest.mark.skipif(NO_EXTENSIONS, reason=\"Only tests C parser.\")\ndef test_invalid_character(loop: Any, protocol: Any, request: Any) -> None:\n    parser = HttpRequestParserC(\n        protocol,\n        loop,\n        2**16,\n        max_line_size=8190,\n        max_field_size=8190,\n    )\n    text = b\"POST / HTTP/1.1\\r\\nHost: localhost:8080\\r\\nSet-Cookie: abc\\x01def\\r\\n\\r\\n\"\n    error_detail = re.escape(\n        r\"\"\":\n\n    b'Set-Cookie: abc\\x01def'\n                     ^\"\"\"\n    )\n    with pytest.raises(http_exceptions.BadHttpMessage, match=error_detail):\n        parser.feed_data(text)\n\n\n@pytest.mark.skipif(NO_EXTENSIONS, reason=\"Only tests C parser.\")\ndef test_invalid_linebreak(loop: Any, protocol: Any, request: Any) -> None:\n    parser = HttpRequestParserC(\n        protocol,\n        loop,\n        2**16,\n        max_line_size=8190,\n        max_field_size=8190,\n    )\n    text = b\"GET /world HTTP/1.1\\r\\nHost: 127.0.0.1\\n\\r\\n\"\n    error_detail = re.escape(\n        r\"\"\":\n\n    b'Host: 127.0.0.1\\n'\n                     ^\"\"\"\n    )\n    with pytest.raises(http_exceptions.BadHttpMessage, match=error_detail):\n        parser.feed_data(text)\n\n\ndef test_cve_2023_37276(parser: Any) -> None:\n    text = b\"\"\"POST / HTTP/1.1\\r\\nHost: localhost:8080\\r\\nX-Abc: \\rxTransfer-Encoding: chunked\\r\\n\\r\\n\"\"\"\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\n@pytest.mark.parametrize(\n    \"rfc9110_5_6_2_token_delim\",\n    r'\"(),/:;<=>?@[\\]{}',\n)\ndef test_bad_header_name(parser: Any, rfc9110_5_6_2_token_delim: str) -> None:\n    text = f\"POST / HTTP/1.1\\r\\nhead{rfc9110_5_6_2_token_delim}er: val\\r\\n\\r\\n\".encode()\n    expectation = pytest.raises(http_exceptions.BadHttpMessage)\n    if rfc9110_5_6_2_token_delim == \":\":\n        # Inserting colon into header just splits name/value earlier.\n        expectation = nullcontext()\n    with expectation:\n        parser.feed_data(text)\n\n\n@pytest.mark.parametrize(\n    \"hdr\",\n    (\n        \"Content-Length: -5\",  # https://www.rfc-editor.org/rfc/rfc9110.html#name-content-length\n        \"Content-Length: +256\",\n        \"Content-Length: \\N{superscript one}\",\n        \"Content-Length: \\N{mathematical double-struck digit one}\",\n        \"Foo: abc\\rdef\",  # https://www.rfc-editor.org/rfc/rfc9110.html#section-5.5-5\n        \"Bar: abc\\ndef\",\n        \"Baz: abc\\x00def\",\n        \"Foo : bar\",  # https://www.rfc-editor.org/rfc/rfc9112.html#section-5.1-2\n        \"Foo\\t: bar\",\n        \"\\xffoo: bar\",\n    ),\n)\ndef test_bad_headers(parser: Any, hdr: str) -> None:\n    text = f\"POST / HTTP/1.1\\r\\n{hdr}\\r\\n\\r\\n\".encode()\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\ndef test_unpaired_surrogate_in_header_py(loop: Any, protocol: Any) -> None:\n    parser = HttpRequestParserPy(\n        protocol,\n        loop,\n        2**16,\n        max_line_size=8190,\n        max_field_size=8190,\n    )\n    text = b\"POST / HTTP/1.1\\r\\n\\xff\\r\\n\\r\\n\"\n    message = None\n    try:\n        parser.feed_data(text)\n    except http_exceptions.InvalidHeader as e:\n        message = e.message.encode(\"utf-8\")\n    assert message is not None\n\n\ndef test_content_length_transfer_encoding(parser: Any) -> None:\n    text = (\n        b\"GET / HTTP/1.1\\r\\nHost: a\\r\\nContent-Length: 5\\r\\nTransfer-Encoding: a\\r\\n\\r\\n\"\n        + b\"apple\\r\\n\"\n    )\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\ndef test_bad_chunked_py(loop: Any, protocol: Any) -> None:\n    \"\"\"Test that invalid chunked encoding doesn't allow content-length to be used.\"\"\"\n    parser = HttpRequestParserPy(\n        protocol,\n        loop,\n        2**16,\n        max_line_size=8190,\n        max_field_size=8190,\n    )\n    text = (\n        b\"GET / HTTP/1.1\\r\\nHost: a\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n0_2e\\r\\n\\r\\n\"\n        + b\"GET / HTTP/1.1\\r\\nHost: a\\r\\nContent-Length: 5\\r\\n\\r\\n0\\r\\n\\r\\n\"\n    )\n    messages, upgrade, tail = parser.feed_data(text)\n    assert isinstance(messages[0][1].exception(), http_exceptions.TransferEncodingError)\n\n\n@pytest.mark.skipif(\n    \"HttpRequestParserC\" not in dir(aiohttp.http_parser),\n    reason=\"C based HTTP parser not available\",\n)\ndef test_bad_chunked_c(loop: Any, protocol: Any) -> None:\n    \"\"\"C parser behaves differently. Maybe we should align them later.\"\"\"\n    parser = HttpRequestParserC(\n        protocol,\n        loop,\n        2**16,\n        max_line_size=8190,\n        max_field_size=8190,\n    )\n    text = (\n        b\"GET / HTTP/1.1\\r\\nHost: a\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n0_2e\\r\\n\\r\\n\"\n        + b\"GET / HTTP/1.1\\r\\nHost: a\\r\\nContent-Length: 5\\r\\n\\r\\n0\\r\\n\\r\\n\"\n    )\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\ndef test_whitespace_before_header(parser: Any) -> None:\n    text = b\"GET / HTTP/1.1\\r\\n\\tContent-Length: 1\\r\\n\\r\\nX\"\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\ndef test_parse_headers_longline(parser: Any) -> None:\n    invalid_unicode_byte = b\"\\xd9\"\n    header_name = b\"Test\" + invalid_unicode_byte + b\"Header\" + b\"A\" * 8192\n    text = b\"GET /test HTTP/1.1\\r\\n\" + header_name + b\": test\\r\\n\" + b\"\\r\\n\" + b\"\\r\\n\"\n    with pytest.raises((http_exceptions.LineTooLong, http_exceptions.BadHttpMessage)):\n        # FIXME: `LineTooLong` doesn't seem to actually be happening\n        parser.feed_data(text)\n\n\n@pytest.fixture\ndef xfail_c_parser_status(request) -> None:\n    if isinstance(request.getfixturevalue(\"parser\"), HttpRequestParserPy):\n        return\n    request.node.add_marker(\n        pytest.mark.xfail(\n            reason=\"Regression test for Py parser. May match C behaviour later.\",\n            raises=http_exceptions.BadStatusLine,\n        )\n    )\n\n\n@pytest.mark.usefixtures(\"xfail_c_parser_status\")\ndef test_parse_unusual_request_line(parser: Any) -> None:\n    text = b\"#smol //a HTTP/1.3\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    assert len(messages) == 1\n    msg, _ = messages[0]\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert msg.method == \"#smol\"\n    assert msg.path == \"//a\"\n    assert msg.version == (1, 3)\n\n\ndef test_parse(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    assert len(messages) == 1\n    msg, _ = messages[0]\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert msg.method == \"GET\"\n    assert msg.path == \"/test\"\n    assert msg.version == (1, 1)\n\n\nasync def test_parse_body(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\nContent-Length: 4\\r\\n\\r\\nbody\"\n    messages, upgrade, tail = parser.feed_data(text)\n    assert len(messages) == 1\n    _, payload = messages[0]\n    body = await payload.read(4)\n    assert body == b\"body\"\n\n\nasync def test_parse_body_with_CRLF(parser: Any) -> None:\n    text = b\"\\r\\nGET /test HTTP/1.1\\r\\nContent-Length: 4\\r\\n\\r\\nbody\"\n    messages, upgrade, tail = parser.feed_data(text)\n    assert len(messages) == 1\n    _, payload = messages[0]\n    body = await payload.read(4)\n    assert body == b\"body\"\n\n\ndef test_parse_delayed(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    assert len(messages) == 0\n    assert not upgrade\n\n    messages, upgrade, tail = parser.feed_data(b\"\\r\\n\")\n    assert len(messages) == 1\n    msg = messages[0][0]\n    assert msg.method == \"GET\"\n\n\ndef test_headers_multi_feed(parser: Any) -> None:\n    text1 = b\"GET /test HTTP/1.1\\r\\n\"\n    text2 = b\"test: line\"\n    text3 = b\" continue\\r\\n\\r\\n\"\n\n    messages, upgrade, tail = parser.feed_data(text1)\n    assert len(messages) == 0\n\n    messages, upgrade, tail = parser.feed_data(text2)\n    assert len(messages) == 0\n\n    messages, upgrade, tail = parser.feed_data(text3)\n    assert len(messages) == 1\n\n    msg = messages[0][0]\n    assert list(msg.headers.items()) == [(\"test\", \"line continue\")]\n    assert msg.raw_headers == ((b\"test\", b\"line continue\"),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n\n\ndef test_headers_split_field(parser: Any) -> None:\n    text1 = b\"GET /test HTTP/1.1\\r\\n\"\n    text2 = b\"t\"\n    text3 = b\"es\"\n    text4 = b\"t: value\\r\\n\\r\\n\"\n\n    messages, upgrade, tail = parser.feed_data(text1)\n    messages, upgrade, tail = parser.feed_data(text2)\n    messages, upgrade, tail = parser.feed_data(text3)\n    assert len(messages) == 0\n    messages, upgrade, tail = parser.feed_data(text4)\n    assert len(messages) == 1\n\n    msg = messages[0][0]\n    assert list(msg.headers.items()) == [(\"test\", \"value\")]\n    assert msg.raw_headers == ((b\"test\", b\"value\"),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n\n\ndef test_parse_headers_multi(parser: Any) -> None:\n    text = (\n        b\"GET /test HTTP/1.1\\r\\n\"\n        b\"Set-Cookie: c1=cookie1\\r\\n\"\n        b\"Set-Cookie: c2=cookie2\\r\\n\\r\\n\"\n    )\n\n    messages, upgrade, tail = parser.feed_data(text)\n    assert len(messages) == 1\n    msg = messages[0][0]\n\n    assert list(msg.headers.items()) == [\n        (\"Set-Cookie\", \"c1=cookie1\"),\n        (\"Set-Cookie\", \"c2=cookie2\"),\n    ]\n    assert msg.raw_headers == (\n        (b\"Set-Cookie\", b\"c1=cookie1\"),\n        (b\"Set-Cookie\", b\"c2=cookie2\"),\n    )\n    assert not msg.should_close\n    assert msg.compression is None\n\n\ndef test_conn_default_1_0(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.0\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.should_close\n\n\ndef test_conn_default_1_1(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert not msg.should_close\n\n\ndef test_conn_close(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"connection: close\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.should_close\n\n\ndef test_conn_close_1_0(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.0\\r\\n\" b\"connection: close\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.should_close\n\n\ndef test_conn_keep_alive_1_0(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.0\\r\\n\" b\"connection: keep-alive\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert not msg.should_close\n\n\ndef test_conn_keep_alive_1_1(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"connection: keep-alive\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert not msg.should_close\n\n\ndef test_conn_other_1_0(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.0\\r\\n\" b\"connection: test\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.should_close\n\n\ndef test_conn_other_1_1(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"connection: test\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert not msg.should_close\n\n\ndef test_request_chunked(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"transfer-encoding: chunked\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg, payload = messages[0]\n    assert msg.chunked\n    assert not upgrade\n    assert isinstance(payload, streams.StreamReader)\n\n\ndef test_request_te_chunked_with_content_length(parser: Any) -> None:\n    text = (\n        b\"GET /test HTTP/1.1\\r\\n\"\n        b\"content-length: 1234\\r\\n\"\n        b\"transfer-encoding: chunked\\r\\n\\r\\n\"\n    )\n    with pytest.raises(\n        http_exceptions.BadHttpMessage,\n        match=\"Transfer-Encoding can't be present with Content-Length\",\n    ):\n        parser.feed_data(text)\n\n\ndef test_request_te_chunked123(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"transfer-encoding: chunked123\\r\\n\\r\\n\"\n    with pytest.raises(\n        http_exceptions.BadHttpMessage,\n        match=\"Request has invalid `Transfer-Encoding`\",\n    ):\n        parser.feed_data(text)\n\n\ndef test_conn_upgrade(parser: Any) -> None:\n    text = (\n        b\"GET /test HTTP/1.1\\r\\n\"\n        b\"connection: upgrade\\r\\n\"\n        b\"upgrade: websocket\\r\\n\\r\\n\"\n    )\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert not msg.should_close\n    assert msg.upgrade\n    assert upgrade\n\n\ndef test_bad_upgrade(parser: Any) -> None:\n    \"\"\"Test not upgraded if missing Upgrade header.\"\"\"\n    text = b\"GET /test HTTP/1.1\\r\\nconnection: upgrade\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert not msg.upgrade\n    assert not upgrade\n\n\ndef test_compression_empty(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"content-encoding: \\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.compression is None\n\n\ndef test_compression_deflate(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"content-encoding: deflate\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.compression == \"deflate\"\n\n\ndef test_compression_gzip(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"content-encoding: gzip\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.compression == \"gzip\"\n\n\n@pytest.mark.skipif(brotli is None, reason=\"brotli is not installed\")\ndef test_compression_brotli(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"content-encoding: br\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.compression == \"br\"\n\n\ndef test_compression_unknown(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"content-encoding: compress\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.compression is None\n\n\ndef test_url_connect(parser: Any) -> None:\n    text = b\"CONNECT www.google.com HTTP/1.1\\r\\n\" b\"content-length: 0\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg, payload = messages[0]\n    assert upgrade\n    assert msg.url == URL.build(authority=\"www.google.com\")\n\n\ndef test_headers_connect(parser: Any) -> None:\n    text = b\"CONNECT www.google.com HTTP/1.1\\r\\n\" b\"content-length: 0\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg, payload = messages[0]\n    assert upgrade\n    assert isinstance(payload, streams.StreamReader)\n\n\ndef test_url_absolute(parser: Any) -> None:\n    text = (\n        b\"GET https://www.google.com/path/to.html HTTP/1.1\\r\\n\"\n        b\"content-length: 0\\r\\n\\r\\n\"\n    )\n    messages, upgrade, tail = parser.feed_data(text)\n    msg, payload = messages[0]\n    assert not upgrade\n    assert msg.method == \"GET\"\n    assert msg.url == URL(\"https://www.google.com/path/to.html\")\n\n\ndef test_headers_old_websocket_key1(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"SEC-WEBSOCKET-KEY1: line\\r\\n\\r\\n\"\n\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\ndef test_headers_content_length_err_1(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"content-length: line\\r\\n\\r\\n\"\n\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\ndef test_headers_content_length_err_2(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"content-length: -1\\r\\n\\r\\n\"\n\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\n_pad: Dict[bytes, str] = {\n    b\"\": \"empty\",\n    # not a typo. Python likes triple zero\n    b\"\\000\": \"NUL\",\n    b\" \": \"SP\",\n    b\"  \": \"SPSP\",\n    # not a typo: both 0xa0 and 0x0a in case of 8-bit fun\n    b\"\\n\": \"LF\",\n    b\"\\xa0\": \"NBSP\",\n    b\"\\t \": \"TABSP\",\n}\n\n\n@pytest.mark.parametrize(\"hdr\", [b\"\", b\"foo\"], ids=[\"name-empty\", \"with-name\"])\n@pytest.mark.parametrize(\"pad2\", _pad.keys(), ids=[\"post-\" + n for n in _pad.values()])\n@pytest.mark.parametrize(\"pad1\", _pad.keys(), ids=[\"pre-\" + n for n in _pad.values()])\ndef test_invalid_header_spacing(\n    parser: Any, pad1: bytes, pad2: bytes, hdr: bytes\n) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"%s%s%s: value\\r\\n\\r\\n\" % (pad1, hdr, pad2)\n    expectation = pytest.raises(http_exceptions.BadHttpMessage)\n    if pad1 == pad2 == b\"\" and hdr != b\"\":\n        # one entry in param matrix is correct: non-empty name, not padded\n        expectation = nullcontext()\n    with expectation:\n        parser.feed_data(text)\n\n\ndef test_empty_header_name(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\":test\\r\\n\\r\\n\"\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\ndef test_invalid_header(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"test line\\r\\n\\r\\n\"\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\ndef test_invalid_name(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"test[]: line\\r\\n\\r\\n\"\n\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(text)\n\n\n@pytest.mark.parametrize(\"size\", [40960, 8191])\ndef test_max_header_field_size(parser: Any, size: Any) -> None:\n    name = b\"t\" * size\n    text = b\"GET /test HTTP/1.1\\r\\n\" + name + b\":data\\r\\n\\r\\n\"\n\n    match = f\"400, message:\\n  Got more than 8190 bytes \\\\({size}\\\\) when reading\"\n    with pytest.raises(http_exceptions.LineTooLong, match=match):\n        parser.feed_data(text)\n\n\ndef test_max_header_field_size_under_limit(parser: Any) -> None:\n    name = b\"t\" * 8190\n    text = b\"GET /test HTTP/1.1\\r\\n\" + name + b\":data\\r\\n\\r\\n\"\n\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.method == \"GET\"\n    assert msg.path == \"/test\"\n    assert msg.version == (1, 1)\n    assert msg.headers == CIMultiDict({name.decode(): \"data\"})\n    assert msg.raw_headers == ((name, b\"data\"),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    assert msg.url == URL(\"/test\")\n\n\n@pytest.mark.parametrize(\"size\", [40960, 8191])\ndef test_max_header_value_size(parser: Any, size: Any) -> None:\n    name = b\"t\" * size\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"data:\" + name + b\"\\r\\n\\r\\n\"\n\n    match = f\"400, message:\\n  Got more than 8190 bytes \\\\({size}\\\\) when reading\"\n    with pytest.raises(http_exceptions.LineTooLong, match=match):\n        parser.feed_data(text)\n\n\ndef test_max_header_value_size_under_limit(parser: Any) -> None:\n    value = b\"A\" * 8190\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"data:\" + value + b\"\\r\\n\\r\\n\"\n\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert msg.method == \"GET\"\n    assert msg.path == \"/test\"\n    assert msg.version == (1, 1)\n    assert msg.headers == CIMultiDict({\"data\": value.decode()})\n    assert msg.raw_headers == ((b\"data\", value),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    assert msg.url == URL(\"/test\")\n\n\n@pytest.mark.parametrize(\"size\", [40965, 8191])\ndef test_max_header_value_size_continuation(response: Any, size: Any) -> None:\n    name = b\"T\" * (size - 5)\n    text = b\"HTTP/1.1 200 Ok\\r\\ndata: test\\r\\n \" + name + b\"\\r\\n\\r\\n\"\n\n    match = f\"400, message:\\n  Got more than 8190 bytes \\\\({size}\\\\) when reading\"\n    with pytest.raises(http_exceptions.LineTooLong, match=match):\n        response.feed_data(text)\n\n\ndef test_max_header_value_size_continuation_under_limit(response: Any) -> None:\n    value = b\"A\" * 8185\n    text = b\"HTTP/1.1 200 Ok\\r\\ndata: test\\r\\n \" + value + b\"\\r\\n\\r\\n\"\n\n    messages, upgrade, tail = response.feed_data(text)\n    msg = messages[0][0]\n    assert msg.code == 200\n    assert msg.reason == \"Ok\"\n    assert msg.version == (1, 1)\n    assert msg.headers == CIMultiDict({\"data\": \"test \" + value.decode()})\n    assert msg.raw_headers == ((b\"data\", b\"test \" + value),)\n    assert msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n\n\ndef test_http_request_parser(parser: Any) -> None:\n    text = b\"GET /path HTTP/1.1\\r\\n\\r\\n\"\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n\n    assert msg.method == \"GET\"\n    assert msg.path == \"/path\"\n    assert msg.version == (1, 1)\n    assert msg.headers == CIMultiDict()\n    assert msg.raw_headers == ()\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    assert msg.url == URL(\"/path\")\n\n\ndef test_http_request_bad_status_line(parser: Any) -> None:\n    text = b\"getpath \\r\\n\\r\\n\"\n    with pytest.raises(http_exceptions.BadStatusLine) as exc_info:\n        parser.feed_data(text)\n    # Check for accidentally escaped message.\n    assert r\"\\n\" not in exc_info.value.message\n\n\n_num: Dict[bytes, str] = {\n    # dangerous: accepted by Python int()\n    # unicodedata.category(\"\\U0001D7D9\") == 'Nd'\n    \"\\N{mathematical double-struck digit one}\".encode(): \"utf8digit\",\n    # only added for interop tests, refused by Python int()\n    # unicodedata.category(\"\\U000000B9\") == 'No'\n    \"\\N{superscript one}\".encode(): \"utf8number\",\n    \"\\N{superscript one}\".encode(\"latin-1\"): \"latin1number\",\n}\n\n\n@pytest.mark.parametrize(\"nonascii_digit\", _num.keys(), ids=_num.values())\ndef test_http_request_bad_status_line_number(\n    parser: Any, nonascii_digit: bytes\n) -> None:\n    text = b\"GET /digit HTTP/1.\" + nonascii_digit + b\"\\r\\n\\r\\n\"\n    with pytest.raises(http_exceptions.BadStatusLine):\n        parser.feed_data(text)\n\n\ndef test_http_request_bad_status_line_separator(parser: Any) -> None:\n    # single code point, old, multibyte NFKC, multibyte NFKD\n    utf8sep = \"\\N{arabic ligature sallallahou alayhe wasallam}\".encode()\n    text = b\"GET /ligature HTTP/1\" + utf8sep + b\"1\\r\\n\\r\\n\"\n    with pytest.raises(http_exceptions.BadStatusLine):\n        parser.feed_data(text)\n\n\ndef test_http_request_bad_status_line_whitespace(parser: Any) -> None:\n    text = b\"GET\\n/path\\fHTTP/1.1\\r\\n\\r\\n\"\n    with pytest.raises(http_exceptions.BadStatusLine):\n        parser.feed_data(text)\n\n\ndef test_http_request_upgrade(parser: Any) -> None:\n    text = (\n        b\"GET /test HTTP/1.1\\r\\n\"\n        b\"connection: upgrade\\r\\n\"\n        b\"upgrade: websocket\\r\\n\\r\\n\"\n        b\"some raw data\"\n    )\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n    assert not msg.should_close\n    assert msg.upgrade\n    assert upgrade\n    assert tail == b\"some raw data\"\n\n\n@pytest.fixture\ndef xfail_c_parser_url(request) -> None:\n    if isinstance(request.getfixturevalue(\"parser\"), HttpRequestParserPy):\n        return\n    request.node.add_marker(\n        pytest.mark.xfail(\n            reason=\"Regression test for Py parser. May match C behaviour later.\",\n            raises=http_exceptions.InvalidURLError,\n        )\n    )\n\n\n@pytest.mark.usefixtures(\"xfail_c_parser_url\")\ndef test_http_request_parser_utf8_request_line(parser: Any) -> None:\n    messages, upgrade, tail = parser.feed_data(\n        # note the truncated unicode sequence\n        b\"GET /P\\xc3\\xbcnktchen\\xa0\\xef\\xb7 HTTP/1.1\\r\\n\" +\n        # for easier grep: ASCII 0xA0 more commonly known as non-breaking space\n        # note the leading and trailing spaces\n        \"sTeP:  \\N{latin small letter sharp s}nek\\t\\N{no-break space}  \"\n        \"\\r\\n\\r\\n\".encode()\n    )\n    msg = messages[0][0]\n\n    assert msg.method == \"GET\"\n    assert msg.path == \"/P\u00fcnktchen\\udca0\\udcef\\udcb7\"\n    assert msg.version == (1, 1)\n    assert msg.headers == CIMultiDict([(\"STEP\", \"\u00dfnek\\t\\xa0\")])\n    assert msg.raw_headers == ((b\"sTeP\", \"\u00dfnek\\t\\xa0\".encode()),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    # python HTTP parser depends on Cython and CPython URL to match\n    # .. but yarl.URL(\"/abs\") is not equal to URL.build(path=\"/abs\"), see #6409\n    assert msg.url == URL.build(path=\"/P\u00fcnktchen\\udca0\\udcef\\udcb7\", encoded=True)\n\n\ndef test_http_request_parser_utf8(parser: Any) -> None:\n    text = \"GET /path HTTP/1.1\\r\\nx-test:\u0442\u0435\u0441\u0442\\r\\n\\r\\n\".encode()\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n\n    assert msg.method == \"GET\"\n    assert msg.path == \"/path\"\n    assert msg.version == (1, 1)\n    assert msg.headers == CIMultiDict([(\"X-TEST\", \"\u0442\u0435\u0441\u0442\")])\n    assert msg.raw_headers == ((b\"x-test\", \"\u0442\u0435\u0441\u0442\".encode()),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    assert msg.url == URL(\"/path\")\n\n\ndef test_http_request_parser_non_utf8(parser: Any) -> None:\n    text = \"GET /path HTTP/1.1\\r\\nx-test:\u0442\u0435\u0441\u0442\\r\\n\\r\\n\".encode(\"cp1251\")\n    msg = parser.feed_data(text)[0][0][0]\n\n    assert msg.method == \"GET\"\n    assert msg.path == \"/path\"\n    assert msg.version == (1, 1)\n    assert msg.headers == CIMultiDict(\n        [(\"X-TEST\", \"\u0442\u0435\u0441\u0442\".encode(\"cp1251\").decode(\"utf8\", \"surrogateescape\"))]\n    )\n    assert msg.raw_headers == ((b\"x-test\", \"\u0442\u0435\u0441\u0442\".encode(\"cp1251\")),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    assert msg.url == URL(\"/path\")\n\n\ndef test_http_request_parser_two_slashes(parser: Any) -> None:\n    text = b\"GET //path HTTP/1.1\\r\\n\\r\\n\"\n    msg = parser.feed_data(text)[0][0][0]\n\n    assert msg.method == \"GET\"\n    assert msg.path == \"//path\"\n    assert msg.url.path == \"//path\"\n    assert msg.version == (1, 1)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n\n\n@pytest.mark.parametrize(\n    \"rfc9110_5_6_2_token_delim\",\n    [bytes([i]) for i in rb'\"(),/:;<=>?@[\\]{}'],\n)\ndef test_http_request_parser_bad_method(\n    parser: Any, rfc9110_5_6_2_token_delim: bytes\n) -> None:\n    with pytest.raises(http_exceptions.BadStatusLine):\n        parser.feed_data(rfc9110_5_6_2_token_delim + b'ET\" /get HTTP/1.1\\r\\n\\r\\n')\n\n\ndef test_http_request_parser_bad_version(parser: Any) -> None:\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(b\"GET //get HT/11\\r\\n\\r\\n\")\n\n\ndef test_http_request_parser_bad_version_number(parser: Any) -> None:\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        parser.feed_data(b\"GET /test HTTP/1.32\\r\\n\\r\\n\")\n\n\ndef test_http_request_parser_bad_ascii_uri(parser: Any) -> None:\n    with pytest.raises(http_exceptions.InvalidURLError):\n        parser.feed_data(b\"GET ! HTTP/1.1\\r\\n\\r\\n\")\n\n\ndef test_http_request_parser_bad_nonascii_uri(parser: Any) -> None:\n    with pytest.raises(http_exceptions.InvalidURLError):\n        parser.feed_data(b\"GET \\xff HTTP/1.1\\r\\n\\r\\n\")\n\n\n@pytest.mark.parametrize(\"size\", [40965, 8191])\ndef test_http_request_max_status_line(parser: Any, size: Any) -> None:\n    path = b\"t\" * (size - 5)\n    match = f\"400, message:\\n  Got more than 8190 bytes \\\\({size}\\\\) when reading\"\n    with pytest.raises(http_exceptions.LineTooLong, match=match):\n        parser.feed_data(b\"GET /path\" + path + b\" HTTP/1.1\\r\\n\\r\\n\")\n\n\ndef test_http_request_max_status_line_under_limit(parser: Any) -> None:\n    path = b\"t\" * (8190 - 5)\n    messages, upgraded, tail = parser.feed_data(\n        b\"GET /path\" + path + b\" HTTP/1.1\\r\\n\\r\\n\"\n    )\n    msg = messages[0][0]\n\n    assert msg.method == \"GET\"\n    assert msg.path == \"/path\" + path.decode()\n    assert msg.version == (1, 1)\n    assert msg.headers == CIMultiDict()\n    assert msg.raw_headers == ()\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    assert msg.url == URL(\"/path\" + path.decode())\n\n\ndef test_http_response_parser_utf8(response: Any) -> None:\n    text = \"HTTP/1.1 200 Ok\\r\\nx-test:\u0442\u0435\u0441\u0442\\r\\n\\r\\n\".encode()\n\n    messages, upgraded, tail = response.feed_data(text)\n    assert len(messages) == 1\n    msg = messages[0][0]\n\n    assert msg.version == (1, 1)\n    assert msg.code == 200\n    assert msg.reason == \"Ok\"\n    assert msg.headers == CIMultiDict([(\"X-TEST\", \"\u0442\u0435\u0441\u0442\")])\n    assert msg.raw_headers == ((b\"x-test\", \"\u0442\u0435\u0441\u0442\".encode()),)\n    assert not upgraded\n    assert not tail\n\n\ndef test_http_response_parser_utf8_without_reason(response: Any) -> None:\n    text = \"HTTP/1.1 200 \\r\\nx-test:\u0442\u0435\u0441\u0442\\r\\n\\r\\n\".encode()\n\n    messages, upgraded, tail = response.feed_data(text)\n    assert len(messages) == 1\n    msg = messages[0][0]\n\n    assert msg.version == (1, 1)\n    assert msg.code == 200\n    assert msg.reason == \"\"\n    assert msg.headers == CIMultiDict([(\"X-TEST\", \"\u0442\u0435\u0441\u0442\")])\n    assert msg.raw_headers == ((b\"x-test\", \"\u0442\u0435\u0441\u0442\".encode()),)\n    assert not upgraded\n    assert not tail\n\n\ndef test_http_response_parser_obs_line_folding(response: Any) -> None:\n    text = b\"HTTP/1.1 200 Ok\\r\\ntest: line\\r\\n continue\\r\\n\\r\\n\"\n\n    messages, upgraded, tail = response.feed_data(text)\n    assert len(messages) == 1\n    msg = messages[0][0]\n\n    assert msg.version == (1, 1)\n    assert msg.code == 200\n    assert msg.reason == \"Ok\"\n    assert msg.headers == CIMultiDict([(\"TEST\", \"line continue\")])\n    assert msg.raw_headers == ((b\"test\", b\"line continue\"),)\n    assert not upgraded\n    assert not tail\n\n\n@pytest.mark.dev_mode\ndef test_http_response_parser_strict_obs_line_folding(response: Any) -> None:\n    text = b\"HTTP/1.1 200 Ok\\r\\ntest: line\\r\\n continue\\r\\n\\r\\n\"\n\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        response.feed_data(text)\n\n\n@pytest.mark.parametrize(\"size\", [40962, 8191])\ndef test_http_response_parser_bad_status_line_too_long(\n    response: Any, size: Any\n) -> None:\n    reason = b\"t\" * (size - 2)\n    match = f\"400, message:\\n  Got more than 8190 bytes \\\\({size}\\\\) when reading\"\n    with pytest.raises(http_exceptions.LineTooLong, match=match):\n        response.feed_data(b\"HTTP/1.1 200 Ok\" + reason + b\"\\r\\n\\r\\n\")\n\n\ndef test_http_response_parser_status_line_under_limit(response: Any) -> None:\n    reason = b\"O\" * 8190\n    messages, upgraded, tail = response.feed_data(\n        b\"HTTP/1.1 200 \" + reason + b\"\\r\\n\\r\\n\"\n    )\n    msg = messages[0][0]\n    assert msg.version == (1, 1)\n    assert msg.code == 200\n    assert msg.reason == reason.decode()\n\n\ndef test_http_response_parser_bad_version(response: Any) -> None:\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        response.feed_data(b\"HT/11 200 Ok\\r\\n\\r\\n\")\n\n\ndef test_http_response_parser_bad_version_number(response: Any) -> None:\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        response.feed_data(b\"HTTP/12.3 200 Ok\\r\\n\\r\\n\")\n\n\ndef test_http_response_parser_no_reason(response: Any) -> None:\n    msg = response.feed_data(b\"HTTP/1.1 200\\r\\n\\r\\n\")[0][0][0]\n\n    assert msg.version == (1, 1)\n    assert msg.code == 200\n    assert msg.reason == \"\"\n\n\ndef test_http_response_parser_lenient_headers(response: Any) -> None:\n    messages, upgrade, tail = response.feed_data(\n        b\"HTTP/1.1 200 test\\r\\nFoo: abc\\x01def\\r\\n\\r\\n\"\n    )\n    msg = messages[0][0]\n\n    assert msg.headers[\"Foo\"] == \"abc\\x01def\"\n\n\n@pytest.mark.dev_mode\ndef test_http_response_parser_strict_headers(response: Any) -> None:\n    if isinstance(response, HttpResponseParserPy):\n        pytest.xfail(\"Py parser is lenient. May update py-parser later.\")\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        response.feed_data(b\"HTTP/1.1 200 test\\r\\nFoo: abc\\x01def\\r\\n\\r\\n\")\n\n\ndef test_http_response_parser_bad_crlf(response: Any) -> None:\n    \"\"\"Still a lot of dodgy servers sending bad requests like this.\"\"\"\n    messages, upgrade, tail = response.feed_data(\n        b\"HTTP/1.0 200 OK\\nFoo: abc\\nBar: def\\n\\nBODY\\n\"\n    )\n    msg = messages[0][0]\n\n    assert msg.headers[\"Foo\"] == \"abc\"\n    assert msg.headers[\"Bar\"] == \"def\"\n\n\nasync def test_http_response_parser_bad_chunked_lax(response: Any) -> None:\n    text = (\n        b\"HTTP/1.1 200 OK\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n5 \\r\\nabcde\\r\\n0\\r\\n\\r\\n\"\n    )\n    messages, upgrade, tail = response.feed_data(text)\n\n    assert await messages[0][1].read(5) == b\"abcde\"\n\n\n@pytest.mark.dev_mode\nasync def test_http_response_parser_bad_chunked_strict_py(\n    loop: Any, protocol: Any\n) -> None:\n    response = HttpResponseParserPy(\n        protocol,\n        loop,\n        2**16,\n        max_line_size=8190,\n        max_field_size=8190,\n    )\n    text = (\n        b\"HTTP/1.1 200 OK\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n5 \\r\\nabcde\\r\\n0\\r\\n\\r\\n\"\n    )\n    messages, upgrade, tail = response.feed_data(text)\n    assert isinstance(messages[0][1].exception(), http_exceptions.TransferEncodingError)\n\n\n@pytest.mark.dev_mode\n@pytest.mark.skipif(\n    \"HttpRequestParserC\" not in dir(aiohttp.http_parser),\n    reason=\"C based HTTP parser not available\",\n)\nasync def test_http_response_parser_bad_chunked_strict_c(\n    loop: Any, protocol: Any\n) -> None:\n    response = HttpResponseParserC(\n        protocol,\n        loop,\n        2**16,\n        max_line_size=8190,\n        max_field_size=8190,\n    )\n    text = (\n        b\"HTTP/1.1 200 OK\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n5 \\r\\nabcde\\r\\n0\\r\\n\\r\\n\"\n    )\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        response.feed_data(text)\n\n\ndef test_http_response_parser_bad(response: Any) -> None:\n    with pytest.raises(http_exceptions.BadHttpMessage):\n        response.feed_data(b\"HTT/1\\r\\n\\r\\n\")\n\n\ndef test_http_response_parser_code_under_100(response: Any) -> None:\n    with pytest.raises(http_exceptions.BadStatusLine):\n        response.feed_data(b\"HTTP/1.1 99 test\\r\\n\\r\\n\")\n\n\ndef test_http_response_parser_code_above_999(response: Any) -> None:\n    with pytest.raises(http_exceptions.BadStatusLine):\n        response.feed_data(b\"HTTP/1.1 9999 test\\r\\n\\r\\n\")\n\n\ndef test_http_response_parser_code_not_int(response: Any) -> None:\n    with pytest.raises(http_exceptions.BadStatusLine):\n        response.feed_data(b\"HTTP/1.1 ttt test\\r\\n\\r\\n\")\n\n\n@pytest.mark.parametrize(\"nonascii_digit\", _num.keys(), ids=_num.values())\ndef test_http_response_parser_code_not_ascii(\n    response: Any, nonascii_digit: bytes\n) -> None:\n    with pytest.raises(http_exceptions.BadStatusLine):\n        response.feed_data(b\"HTTP/1.1 20\" + nonascii_digit + b\" test\\r\\n\\r\\n\")\n\n\ndef test_http_request_chunked_payload(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"transfer-encoding: chunked\\r\\n\\r\\n\"\n    msg, payload = parser.feed_data(text)[0][0]\n\n    assert msg.chunked\n    assert not payload.is_eof()\n    assert isinstance(payload, streams.StreamReader)\n\n    parser.feed_data(b\"4\\r\\ndata\\r\\n4\\r\\nline\\r\\n0\\r\\n\\r\\n\")\n\n    assert b\"dataline\" == b\"\".join(d for d in payload._buffer)\n    assert [4, 8] == payload._http_chunk_splits\n    assert payload.is_eof()\n\n\ndef test_http_request_chunked_payload_and_next_message(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"transfer-encoding: chunked\\r\\n\\r\\n\"\n    msg, payload = parser.feed_data(text)[0][0]\n\n    messages, upgraded, tail = parser.feed_data(\n        b\"4\\r\\ndata\\r\\n4\\r\\nline\\r\\n0\\r\\n\\r\\n\"\n        b\"POST /test2 HTTP/1.1\\r\\n\"\n        b\"transfer-encoding: chunked\\r\\n\\r\\n\"\n    )\n\n    assert b\"dataline\" == b\"\".join(d for d in payload._buffer)\n    assert [4, 8] == payload._http_chunk_splits\n    assert payload.is_eof()\n\n    assert len(messages) == 1\n    msg2, payload2 = messages[0]\n\n    assert msg2.method == \"POST\"\n    assert msg2.chunked\n    assert not payload2.is_eof()\n\n\ndef test_http_request_chunked_payload_chunks(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"transfer-encoding: chunked\\r\\n\\r\\n\"\n    msg, payload = parser.feed_data(text)[0][0]\n\n    parser.feed_data(b\"4\\r\\ndata\\r\")\n    parser.feed_data(b\"\\n4\")\n    parser.feed_data(b\"\\r\")\n    parser.feed_data(b\"\\n\")\n    parser.feed_data(b\"li\")\n    parser.feed_data(b\"ne\\r\\n0\\r\\n\")\n    parser.feed_data(b\"test: test\\r\\n\")\n\n    assert b\"dataline\" == b\"\".join(d for d in payload._buffer)\n    assert [4, 8] == payload._http_chunk_splits\n    assert not payload.is_eof()\n\n    parser.feed_data(b\"\\r\\n\")\n    assert b\"dataline\" == b\"\".join(d for d in payload._buffer)\n    assert [4, 8] == payload._http_chunk_splits\n    assert payload.is_eof()\n\n\ndef test_parse_chunked_payload_chunk_extension(parser: Any) -> None:\n    text = b\"GET /test HTTP/1.1\\r\\n\" b\"transfer-encoding: chunked\\r\\n\\r\\n\"\n    msg, payload = parser.feed_data(text)[0][0]\n\n    parser.feed_data(b\"4;test\\r\\ndata\\r\\n4\\r\\nline\\r\\n0\\r\\ntest: test\\r\\n\\r\\n\")\n\n    assert b\"dataline\" == b\"\".join(d for d in payload._buffer)\n    assert [4, 8] == payload._http_chunk_splits\n    assert payload.is_eof()\n\n\ndef test_parse_no_length_or_te_on_post(loop: Any, protocol: Any, request_cls: Any):\n    parser = request_cls(protocol, loop, limit=2**16)\n    text = b\"POST /test HTTP/1.1\\r\\n\\r\\n\"\n    msg, payload = parser.feed_data(text)[0][0]\n\n    assert payload.is_eof()\n\n\ndef test_parse_payload_response_without_body(\n    loop: Any, protocol: Any, response_cls: Any\n) -> None:\n    parser = response_cls(protocol, loop, 2**16, response_with_body=False)\n    text = b\"HTTP/1.1 200 Ok\\r\\n\" b\"content-length: 10\\r\\n\\r\\n\"\n    msg, payload = parser.feed_data(text)[0][0]\n\n    assert payload.is_eof()\n\n\ndef test_parse_length_payload(response: Any) -> None:\n    text = b\"HTTP/1.1 200 Ok\\r\\n\" b\"content-length: 4\\r\\n\\r\\n\"\n    msg, payload = response.feed_data(text)[0][0]\n    assert not payload.is_eof()\n\n    response.feed_data(b\"da\")\n    response.feed_data(b\"t\")\n    response.feed_data(b\"aHT\")\n\n    assert payload.is_eof()\n    assert b\"data\" == b\"\".join(d for d in payload._buffer)\n\n\ndef test_parse_no_length_payload(parser: Any) -> None:\n    text = b\"PUT / HTTP/1.1\\r\\n\\r\\n\"\n    msg, payload = parser.feed_data(text)[0][0]\n    assert payload.is_eof()\n\n\ndef test_parse_content_length_payload_multiple(response: Any) -> None:\n    text = b\"HTTP/1.1 200 OK\\r\\ncontent-length: 5\\r\\n\\r\\nfirst\"\n    msg, payload = response.feed_data(text)[0][0]\n    assert msg.version == HttpVersion(major=1, minor=1)\n    assert msg.code == 200\n    assert msg.reason == \"OK\"\n    assert msg.headers == CIMultiDict(\n        [\n            (\"Content-Length\", \"5\"),\n        ]\n    )\n    assert msg.raw_headers == ((b\"content-length\", b\"5\"),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    assert payload.is_eof()\n    assert b\"first\" == b\"\".join(d for d in payload._buffer)\n\n    text = b\"HTTP/1.1 200 OK\\r\\ncontent-length: 6\\r\\n\\r\\nsecond\"\n    msg, payload = response.feed_data(text)[0][0]\n    assert msg.version == HttpVersion(major=1, minor=1)\n    assert msg.code == 200\n    assert msg.reason == \"OK\"\n    assert msg.headers == CIMultiDict(\n        [\n            (\"Content-Length\", \"6\"),\n        ]\n    )\n    assert msg.raw_headers == ((b\"content-length\", b\"6\"),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    assert payload.is_eof()\n    assert b\"second\" == b\"\".join(d for d in payload._buffer)\n\n\ndef test_parse_content_length_than_chunked_payload(response: Any) -> None:\n    text = b\"HTTP/1.1 200 OK\\r\\ncontent-length: 5\\r\\n\\r\\nfirst\"\n    msg, payload = response.feed_data(text)[0][0]\n    assert msg.version == HttpVersion(major=1, minor=1)\n    assert msg.code == 200\n    assert msg.reason == \"OK\"\n    assert msg.headers == CIMultiDict(\n        [\n            (\"Content-Length\", \"5\"),\n        ]\n    )\n    assert msg.raw_headers == ((b\"content-length\", b\"5\"),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    assert payload.is_eof()\n    assert b\"first\" == b\"\".join(d for d in payload._buffer)\n\n    text = (\n        b\"HTTP/1.1 200 OK\\r\\n\"\n        b\"transfer-encoding: chunked\\r\\n\\r\\n\"\n        b\"6\\r\\nsecond\\r\\n0\\r\\n\\r\\n\"\n    )\n    msg, payload = response.feed_data(text)[0][0]\n    assert msg.version == HttpVersion(major=1, minor=1)\n    assert msg.code == 200\n    assert msg.reason == \"OK\"\n    assert msg.headers == CIMultiDict(\n        [\n            (\"Transfer-Encoding\", \"chunked\"),\n        ]\n    )\n    assert msg.raw_headers == ((b\"transfer-encoding\", b\"chunked\"),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert msg.chunked\n    assert payload.is_eof()\n    assert b\"second\" == b\"\".join(d for d in payload._buffer)\n\n\n@pytest.mark.parametrize(\"code\", (204, 304, 101, 102))\ndef test_parse_chunked_payload_empty_body_than_another_chunked(\n    response: Any, code: int\n) -> None:\n    head = f\"HTTP/1.1 {code} OK\\r\\n\".encode()\n    text = head + b\"transfer-encoding: chunked\\r\\n\\r\\n\"\n    msg, payload = response.feed_data(text)[0][0]\n    assert msg.version == HttpVersion(major=1, minor=1)\n    assert msg.code == code\n    assert msg.reason == \"OK\"\n    assert msg.headers == CIMultiDict(\n        [\n            (\"Transfer-Encoding\", \"chunked\"),\n        ]\n    )\n    assert msg.raw_headers == ((b\"transfer-encoding\", b\"chunked\"),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert msg.chunked\n    assert payload.is_eof()\n\n    text = (\n        b\"HTTP/1.1 200 OK\\r\\n\"\n        b\"transfer-encoding: chunked\\r\\n\\r\\n\"\n        b\"6\\r\\nsecond\\r\\n0\\r\\n\\r\\n\"\n    )\n    msg, payload = response.feed_data(text)[0][0]\n    assert msg.version == HttpVersion(major=1, minor=1)\n    assert msg.code == 200\n    assert msg.reason == \"OK\"\n    assert msg.headers == CIMultiDict(\n        [\n            (\"Transfer-Encoding\", \"chunked\"),\n        ]\n    )\n    assert msg.raw_headers == ((b\"transfer-encoding\", b\"chunked\"),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert msg.chunked\n    assert payload.is_eof()\n    assert b\"second\" == b\"\".join(d for d in payload._buffer)\n\n\ndef test_partial_url(parser: Any) -> None:\n    messages, upgrade, tail = parser.feed_data(b\"GET /te\")\n    assert len(messages) == 0\n    messages, upgrade, tail = parser.feed_data(b\"st HTTP/1.1\\r\\n\\r\\n\")\n    assert len(messages) == 1\n\n    msg, payload = messages[0]\n\n    assert msg.method == \"GET\"\n    assert msg.path == \"/test\"\n    assert msg.version == (1, 1)\n    assert payload.is_eof()\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"path\", \"query\", \"fragment\"),\n    [\n        (\"/path%23frag\", \"/path#frag\", {}, \"\"),\n        (\"/path%2523frag\", \"/path%23frag\", {}, \"\"),\n        (\"/path?key=value%23frag\", \"/path\", {\"key\": \"value#frag\"}, \"\"),\n        (\"/path?key=value%2523frag\", \"/path\", {\"key\": \"value%23frag\"}, \"\"),\n        (\"/path#frag%20\", \"/path\", {}, \"frag \"),\n        (\"/path#frag%2520\", \"/path\", {}, \"frag%20\"),\n    ],\n)\ndef test_parse_uri_percent_encoded(\n    parser: Any, uri: Any, path: Any, query: Any, fragment: Any\n) -> None:\n    text = (f\"GET {uri} HTTP/1.1\\r\\n\\r\\n\").encode()\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n\n    assert msg.path == uri\n    assert msg.url == URL(uri)\n    assert msg.url.path == path\n    assert msg.url.query == query\n    assert msg.url.fragment == fragment\n\n\ndef test_parse_uri_utf8(parser: Any) -> None:\n    if not isinstance(parser, HttpRequestParserPy):\n        pytest.xfail(\"Not valid HTTP. Maybe update py-parser to reject later.\")\n    text = (\"GET /\u043f\u0443\u0442\u044c?\u043a\u043b\u044e\u0447=\u0437\u043d\u0430\u0447#\u0444\u0440\u0430\u0433 HTTP/1.1\\r\\n\\r\\n\").encode()\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n\n    assert msg.path == \"/\u043f\u0443\u0442\u044c?\u043a\u043b\u044e\u0447=\u0437\u043d\u0430\u0447#\u0444\u0440\u0430\u0433\"\n    assert msg.url.path == \"/\u043f\u0443\u0442\u044c\"\n    assert msg.url.query == {\"\u043a\u043b\u044e\u0447\": \"\u0437\u043d\u0430\u0447\"}\n    assert msg.url.fragment == \"\u0444\u0440\u0430\u0433\"\n\n\ndef test_parse_uri_utf8_percent_encoded(parser: Any) -> None:\n    text = (\n        \"GET %s HTTP/1.1\\r\\n\\r\\n\" % quote(\"/\u043f\u0443\u0442\u044c?\u043a\u043b\u044e\u0447=\u0437\u043d\u0430\u0447#\u0444\u0440\u0430\u0433\", safe=\"/?=#\")\n    ).encode()\n    messages, upgrade, tail = parser.feed_data(text)\n    msg = messages[0][0]\n\n    assert msg.path == quote(\"/\u043f\u0443\u0442\u044c?\u043a\u043b\u044e\u0447=\u0437\u043d\u0430\u0447#\u0444\u0440\u0430\u0433\", safe=\"/?=#\")\n    assert msg.url == URL(\"/\u043f\u0443\u0442\u044c?\u043a\u043b\u044e\u0447=\u0437\u043d\u0430\u0447#\u0444\u0440\u0430\u0433\")\n    assert msg.url.path == \"/\u043f\u0443\u0442\u044c\"\n    assert msg.url.query == {\"\u043a\u043b\u044e\u0447\": \"\u0437\u043d\u0430\u0447\"}\n    assert msg.url.fragment == \"\u0444\u0440\u0430\u0433\"\n\n\n@pytest.mark.skipif(\n    \"HttpRequestParserC\" not in dir(aiohttp.http_parser),\n    reason=\"C based HTTP parser not available\",\n)\ndef test_parse_bad_method_for_c_parser_raises(loop: Any, protocol: Any) -> None:\n    payload = b\"GET1 /test HTTP/1.1\\r\\n\\r\\n\"\n    parser = HttpRequestParserC(\n        protocol,\n        loop,\n        2**16,\n        max_line_size=8190,\n        max_field_size=8190,\n    )\n\n    with pytest.raises(aiohttp.http_exceptions.BadStatusLine):\n        messages, upgrade, tail = parser.feed_data(payload)\n\n\nclass TestParsePayload:\n    async def test_parse_eof_payload(self, stream: Any) -> None:\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        p = HttpPayloadParser(out)\n        p.feed_data(b\"data\")\n        p.feed_eof()\n\n        assert out.is_eof()\n        assert [(bytearray(b\"data\"))] == list(out._buffer)\n\n    async def test_parse_length_payload_eof(self, stream: Any) -> None:\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n\n        p = HttpPayloadParser(out, length=4)\n        p.feed_data(b\"da\")\n\n        with pytest.raises(http_exceptions.ContentLengthError):\n            p.feed_eof()\n\n    async def test_parse_chunked_payload_size_error(self, stream: Any) -> None:\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        p = HttpPayloadParser(out, chunked=True)\n        with pytest.raises(http_exceptions.TransferEncodingError):\n            p.feed_data(b\"blah\\r\\n\")\n        assert isinstance(out.exception(), http_exceptions.TransferEncodingError)\n\n    async def test_parse_chunked_payload_split_end(self, protocol: Any) -> None:\n        out = aiohttp.StreamReader(protocol, 2**16, loop=None)\n        p = HttpPayloadParser(out, chunked=True)\n        p.feed_data(b\"4\\r\\nasdf\\r\\n0\\r\\n\")\n        p.feed_data(b\"\\r\\n\")\n\n        assert out.is_eof()\n        assert b\"asdf\" == b\"\".join(out._buffer)\n\n    async def test_parse_chunked_payload_split_end2(self, protocol: Any) -> None:\n        out = aiohttp.StreamReader(protocol, 2**16, loop=None)\n        p = HttpPayloadParser(out, chunked=True)\n        p.feed_data(b\"4\\r\\nasdf\\r\\n0\\r\\n\\r\")\n        p.feed_data(b\"\\n\")\n\n        assert out.is_eof()\n        assert b\"asdf\" == b\"\".join(out._buffer)\n\n    async def test_parse_chunked_payload_split_end_trailers(\n        self, protocol: Any\n    ) -> None:\n        out = aiohttp.StreamReader(protocol, 2**16, loop=None)\n        p = HttpPayloadParser(out, chunked=True)\n        p.feed_data(b\"4\\r\\nasdf\\r\\n0\\r\\n\")\n        p.feed_data(b\"Content-MD5: 912ec803b2ce49e4a541068d495ab570\\r\\n\")\n        p.feed_data(b\"\\r\\n\")\n\n        assert out.is_eof()\n        assert b\"asdf\" == b\"\".join(out._buffer)\n\n    async def test_parse_chunked_payload_split_end_trailers2(\n        self, protocol: Any\n    ) -> None:\n        out = aiohttp.StreamReader(protocol, 2**16, loop=None)\n        p = HttpPayloadParser(out, chunked=True)\n        p.feed_data(b\"4\\r\\nasdf\\r\\n0\\r\\n\")\n        p.feed_data(b\"Content-MD5: 912ec803b2ce49e4a541068d495ab570\\r\\n\\r\")\n        p.feed_data(b\"\\n\")\n\n        assert out.is_eof()\n        assert b\"asdf\" == b\"\".join(out._buffer)\n\n    async def test_parse_chunked_payload_split_end_trailers3(\n        self, protocol: Any\n    ) -> None:\n        out = aiohttp.StreamReader(protocol, 2**16, loop=None)\n        p = HttpPayloadParser(out, chunked=True)\n        p.feed_data(b\"4\\r\\nasdf\\r\\n0\\r\\nContent-MD5: \")\n        p.feed_data(b\"912ec803b2ce49e4a541068d495ab570\\r\\n\\r\\n\")\n\n        assert out.is_eof()\n        assert b\"asdf\" == b\"\".join(out._buffer)\n\n    async def test_parse_chunked_payload_split_end_trailers4(\n        self, protocol: Any\n    ) -> None:\n        out = aiohttp.StreamReader(protocol, 2**16, loop=None)\n        p = HttpPayloadParser(out, chunked=True)\n        p.feed_data(b\"4\\r\\nasdf\\r\\n0\\r\\n\" b\"C\")\n        p.feed_data(b\"ontent-MD5: 912ec803b2ce49e4a541068d495ab570\\r\\n\\r\\n\")\n\n        assert out.is_eof()\n        assert b\"asdf\" == b\"\".join(out._buffer)\n\n    async def test_http_payload_parser_length(self, stream: Any) -> None:\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        p = HttpPayloadParser(out, length=2)\n        eof, tail = p.feed_data(b\"1245\")\n        assert eof\n\n        assert b\"12\" == out._buffer[0]\n        assert b\"45\" == tail\n\n    async def test_http_payload_parser_deflate(self, stream: Any) -> None:\n        # c=compressobj(wbits=15); b''.join([c.compress(b'data'), c.flush()])\n        COMPRESSED = b\"x\\x9cKI,I\\x04\\x00\\x04\\x00\\x01\\x9b\"\n\n        length = len(COMPRESSED)\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        p = HttpPayloadParser(out, length=length, compression=\"deflate\")\n        p.feed_data(COMPRESSED)\n        assert b\"data\" == out._buffer[0]\n        assert out.is_eof()\n\n    async def test_http_payload_parser_deflate_no_hdrs(self, stream: Any) -> None:\n        \"\"\"Tests incorrectly formed data (no zlib headers).\"\"\"\n        # c=compressobj(wbits=-15); b''.join([c.compress(b'data'), c.flush()])\n        COMPRESSED = b\"KI,I\\x04\\x00\"\n\n        length = len(COMPRESSED)\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        p = HttpPayloadParser(out, length=length, compression=\"deflate\")\n        p.feed_data(COMPRESSED)\n        assert b\"data\" == out._buffer[0]\n        assert out.is_eof()\n\n    async def test_http_payload_parser_deflate_light(self, stream: Any) -> None:\n        # c=compressobj(wbits=9); b''.join([c.compress(b'data'), c.flush()])\n        COMPRESSED = b\"\\x18\\x95KI,I\\x04\\x00\\x04\\x00\\x01\\x9b\"\n\n        length = len(COMPRESSED)\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        p = HttpPayloadParser(out, length=length, compression=\"deflate\")\n        p.feed_data(COMPRESSED)\n\n        assert b\"data\" == out._buffer[0]\n        assert out.is_eof()\n\n    async def test_http_payload_parser_deflate_split(self, stream: Any) -> None:\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        p = HttpPayloadParser(out, compression=\"deflate\")\n        # Feeding one correct byte should be enough to choose exact\n        # deflate decompressor\n        p.feed_data(b\"x\")\n        p.feed_data(b\"\\x9cKI,I\\x04\\x00\\x04\\x00\\x01\\x9b\")\n        p.feed_eof()\n        assert b\"data\" == out._buffer[0]\n\n    async def test_http_payload_parser_deflate_split_err(self, stream: Any) -> None:\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        p = HttpPayloadParser(out, compression=\"deflate\")\n        # Feeding one wrong byte should be enough to choose exact\n        # deflate decompressor\n        p.feed_data(b\"K\")\n        p.feed_data(b\"I,I\\x04\\x00\")\n        p.feed_eof()\n        assert b\"data\" == out._buffer[0]\n\n    async def test_http_payload_parser_length_zero(self, stream: Any) -> None:\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        p = HttpPayloadParser(out, length=0)\n        assert p.done\n        assert out.is_eof()\n\n    @pytest.mark.skipif(brotli is None, reason=\"brotli is not installed\")\n    async def test_http_payload_brotli(self, stream: Any) -> None:\n        compressed = brotli.compress(b\"brotli data\")\n        out = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        p = HttpPayloadParser(out, length=len(compressed), compression=\"br\")\n        p.feed_data(compressed)\n        assert b\"brotli data\" == out._buffer[0]\n        assert out.is_eof()\n\n\nclass TestDeflateBuffer:\n    async def test_feed_data(self, stream: Any) -> None:\n        buf = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        dbuf = DeflateBuffer(buf, \"deflate\")\n\n        dbuf.decompressor = mock.Mock()\n        dbuf.decompressor.decompress_sync.return_value = b\"line\"\n\n        # First byte should be b'x' in order code not to change the decoder.\n        dbuf.feed_data(b\"xxxx\")\n        assert [b\"line\"] == list(buf._buffer)\n\n    async def test_feed_data_err(self, stream: Any) -> None:\n        buf = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        dbuf = DeflateBuffer(buf, \"deflate\")\n\n        exc = ValueError()\n        dbuf.decompressor = mock.Mock()\n        dbuf.decompressor.decompress_sync.side_effect = exc\n\n        with pytest.raises(http_exceptions.ContentEncodingError):\n            # Should be more than 4 bytes to trigger deflate FSM error.\n            # Should start with b'x', otherwise code switch mocked decoder.\n            dbuf.feed_data(b\"xsomedata\")\n\n    async def test_feed_eof(self, stream: Any) -> None:\n        buf = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        dbuf = DeflateBuffer(buf, \"deflate\")\n\n        dbuf.decompressor = mock.Mock()\n        dbuf.decompressor.flush.return_value = b\"line\"\n\n        dbuf.feed_eof()\n        assert [b\"line\"] == list(buf._buffer)\n        assert buf._eof\n\n    async def test_feed_eof_err_deflate(self, stream: Any) -> None:\n        buf = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        dbuf = DeflateBuffer(buf, \"deflate\")\n\n        dbuf.decompressor = mock.Mock()\n        dbuf.decompressor.flush.return_value = b\"line\"\n        dbuf.decompressor.eof = False\n\n        with pytest.raises(http_exceptions.ContentEncodingError):\n            dbuf.feed_eof()\n\n    async def test_feed_eof_no_err_gzip(self, stream: Any) -> None:\n        buf = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        dbuf = DeflateBuffer(buf, \"gzip\")\n\n        dbuf.decompressor = mock.Mock()\n        dbuf.decompressor.flush.return_value = b\"line\"\n        dbuf.decompressor.eof = False\n\n        dbuf.feed_eof()\n        assert [b\"line\"] == list(buf._buffer)\n\n    async def test_feed_eof_no_err_brotli(self, stream: Any) -> None:\n        buf = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        dbuf = DeflateBuffer(buf, \"br\")\n\n        dbuf.decompressor = mock.Mock()\n        dbuf.decompressor.flush.return_value = b\"line\"\n        dbuf.decompressor.eof = False\n\n        dbuf.feed_eof()\n        assert [b\"line\"] == list(buf._buffer)\n\n    async def test_empty_body(self, stream: Any) -> None:\n        buf = aiohttp.FlowControlDataQueue(stream, 2**16, loop=asyncio.get_event_loop())\n        dbuf = DeflateBuffer(buf, \"deflate\")\n        dbuf.feed_eof()\n\n        assert buf.at_eof()\n", "tests/test_test_utils.py": "# type: ignore\nimport gzip\nfrom socket import socket\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\nfrom multidict import CIMultiDict, CIMultiDictProxy\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp import web\nfrom aiohttp.test_utils import (\n    AioHTTPTestCase,\n    RawTestServer as _RawTestServer,\n    TestClient as _TestClient,\n    TestServer as _TestServer,\n    get_port_socket,\n    loop_context,\n    make_mocked_request,\n)\n\n_hello_world_str = \"Hello, world\"\n_hello_world_bytes = _hello_world_str.encode(\"utf-8\")\n_hello_world_gz = gzip.compress(_hello_world_bytes)\n\n\ndef _create_example_app():\n    async def hello(request):\n        return web.Response(body=_hello_world_bytes)\n\n    async def websocket_handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        msg = await ws.receive()\n        if msg.type == aiohttp.WSMsgType.TEXT:\n            if msg.data == \"close\":\n                await ws.close()\n            else:\n                await ws.send_str(msg.data + \"/answer\")\n\n        return ws\n\n    async def cookie_handler(request):\n        resp = web.Response(body=_hello_world_bytes)\n        resp.set_cookie(\"cookie\", \"val\")\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"*\", \"/\", hello)\n    app.router.add_route(\"*\", \"/websocket\", websocket_handler)\n    app.router.add_route(\"*\", \"/cookie\", cookie_handler)\n    return app\n\n\n# these exist to test the pytest scenario\n@pytest.fixture\ndef loop() -> None:\n    with loop_context() as loop:\n        yield loop\n\n\n@pytest.fixture\ndef app():\n    return _create_example_app()\n\n\n@pytest.fixture\ndef test_client(loop: Any, app: Any) -> None:\n    async def make_client():\n        return _TestClient(_TestServer(app))\n\n    client = loop.run_until_complete(make_client())\n\n    loop.run_until_complete(client.start_server())\n    yield client\n    loop.run_until_complete(client.close())\n\n\nasync def test_aiohttp_client_close_is_idempotent() -> None:\n    # a test client, called multiple times, should\n    # not attempt to close the server again.\n    app = _create_example_app()\n    client = _TestClient(_TestServer(app))\n    await client.close()\n    await client.close()\n\n\nclass TestAioHTTPTestCase(AioHTTPTestCase):\n    async def get_application(self):\n        return _create_example_app()\n\n    async def test_example_with_loop(self) -> None:\n        request = await self.client.request(\"GET\", \"/\")\n        assert request.status == 200\n        text = await request.text()\n        assert _hello_world_str == text\n\n    async def test_example_without_explicit_loop(self) -> None:\n        request = await self.client.request(\"GET\", \"/\")\n        assert request.status == 200\n        text = await request.text()\n        assert _hello_world_str == text\n\n    async def test_inner_example(self) -> None:\n        async def test_get_route() -> None:\n            resp = await self.client.request(\"GET\", \"/\")\n            assert resp.status == 200\n            text = await resp.text()\n            assert _hello_world_str == text\n\n        await test_get_route()\n\n\ndef test_get_route(loop: Any, test_client: Any) -> None:\n    async def test_get_route() -> None:\n        resp = await test_client.request(\"GET\", \"/\")\n        assert resp.status == 200\n        text = await resp.text()\n        assert _hello_world_str == text\n\n    loop.run_until_complete(test_get_route())\n\n\nasync def test_client_websocket(loop: Any, test_client: Any) -> None:\n    resp = await test_client.ws_connect(\"/websocket\")\n    await resp.send_str(\"foo\")\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.TEXT\n    assert \"foo\" in msg.data\n    await resp.send_str(\"close\")\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSE\n\n\nasync def test_client_cookie(loop: Any, test_client: Any) -> None:\n    assert not test_client.session.cookie_jar\n    await test_client.get(\"/cookie\")\n    cookies = list(test_client.session.cookie_jar)\n    assert cookies[0].key == \"cookie\"\n    assert cookies[0].value == \"val\"\n\n\n@pytest.mark.parametrize(\n    \"method\", [\"get\", \"post\", \"options\", \"post\", \"put\", \"patch\", \"delete\"]\n)\nasync def test_test_client_methods(method: Any, loop: Any, test_client: Any) -> None:\n    resp = await getattr(test_client, method)(\"/\")\n    assert resp.status == 200\n    text = await resp.text()\n    assert _hello_world_str == text\n\n\nasync def test_test_client_head(loop: Any, test_client: Any) -> None:\n    resp = await test_client.head(\"/\")\n    assert resp.status == 200\n\n\n@pytest.mark.parametrize(\"headers\", [{\"token\": \"x\"}, CIMultiDict({\"token\": \"x\"}), {}])\ndef test_make_mocked_request(headers: Any) -> None:\n    req = make_mocked_request(\"GET\", \"/\", headers=headers)\n    assert req.method == \"GET\"\n    assert req.path == \"/\"\n    assert isinstance(req, web.Request)\n    assert isinstance(req.headers, CIMultiDictProxy)\n\n\ndef test_make_mocked_request_sslcontext() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    assert req.transport.get_extra_info(\"sslcontext\") is None\n\n\ndef test_make_mocked_request_unknown_extra_info() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    assert req.transport.get_extra_info(\"unknown_extra_info\") is None\n\n\ndef test_make_mocked_request_app() -> None:\n    app = mock.Mock()\n    req = make_mocked_request(\"GET\", \"/\", app=app)\n    assert req.app is app\n\n\ndef test_make_mocked_request_app_can_store_values() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    req.app[\"a_field\"] = \"a_value\"\n    assert req.app[\"a_field\"] == \"a_value\"\n\n\ndef test_make_mocked_request_app_access_non_existing() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    with pytest.raises(AttributeError):\n        req.app.foo\n\n\ndef test_make_mocked_request_match_info() -> None:\n    req = make_mocked_request(\"GET\", \"/\", match_info={\"a\": \"1\", \"b\": \"2\"})\n    assert req.match_info == {\"a\": \"1\", \"b\": \"2\"}\n\n\ndef test_make_mocked_request_content() -> None:\n    payload = mock.Mock()\n    req = make_mocked_request(\"GET\", \"/\", payload=payload)\n    assert req.content is payload\n\n\ndef test_make_mocked_request_transport() -> None:\n    transport = mock.Mock()\n    req = make_mocked_request(\"GET\", \"/\", transport=transport)\n    assert req.transport is transport\n\n\nasync def test_test_client_props() -> None:\n    app = _create_example_app()\n    server = _TestServer(app, scheme=\"http\", host=\"127.0.0.1\")\n    client = _TestClient(server)\n    assert client.scheme == \"http\"\n    assert client.host == \"127.0.0.1\"\n    assert client.port is None\n    async with client:\n        assert isinstance(client.port, int)\n        assert client.server is not None\n        assert client.app is not None\n    assert client.port is None\n\n\nasync def test_test_client_raw_server_props() -> None:\n    async def hello(request):\n        return web.Response()  # pragma: no cover\n\n    server = _RawTestServer(hello, scheme=\"http\", host=\"127.0.0.1\")\n    client = _TestClient(server)\n    assert client.scheme == \"http\"\n    assert client.host == \"127.0.0.1\"\n    assert client.port is None\n    async with client:\n        assert isinstance(client.port, int)\n        assert client.server is not None\n        assert client.app is None\n    assert client.port is None\n\n\nasync def test_test_server_context_manager(loop: Any) -> None:\n    app = _create_example_app()\n    async with _TestServer(app) as server:\n        client = aiohttp.ClientSession()\n        resp = await client.head(server.make_url(\"/\"))\n        assert resp.status == 200\n        resp.close()\n        await client.close()\n\n\ndef test_client_unsupported_arg() -> None:\n    with pytest.raises(TypeError) as e:\n        _TestClient(\"string\")\n\n    assert (\n        str(e.value) == \"server must be TestServer instance, found type: <class 'str'>\"\n    )\n\n\nasync def test_server_make_url_yarl_compatibility(loop: Any) -> None:\n    app = _create_example_app()\n    async with _TestServer(app) as server:\n        make_url = server.make_url\n        assert make_url(URL(\"/foo\")) == make_url(\"/foo\")\n        with pytest.raises(AssertionError):\n            make_url(\"http://foo.com\")\n        with pytest.raises(AssertionError):\n            make_url(URL(\"http://foo.com\"))\n\n\ndef test_testcase_no_app(testdir: Any, loop: Any) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        from aiohttp.test_utils import AioHTTPTestCase\n\n\n        class InvalidTestCase(AioHTTPTestCase):\n            def test_noop(self) -> None:\n                pass\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*TypeError*\"])\n\n\nasync def test_server_context_manager(app: Any, loop: Any) -> None:\n    async with _TestServer(app) as server:\n        async with aiohttp.ClientSession() as client:\n            async with client.head(server.make_url(\"/\")) as resp:\n                assert resp.status == 200\n\n\n@pytest.mark.parametrize(\n    \"method\", [\"head\", \"get\", \"post\", \"options\", \"post\", \"put\", \"patch\", \"delete\"]\n)\nasync def test_client_context_manager_response(\n    method: Any, app: Any, loop: Any\n) -> None:\n    async with _TestClient(_TestServer(app)) as client:\n        async with getattr(client, method)(\"/\") as resp:\n            assert resp.status == 200\n            if method != \"head\":\n                text = await resp.text()\n                assert \"Hello, world\" in text\n\n\nasync def test_custom_port(loop: Any, app: Any, aiohttp_unused_port: Any) -> None:\n    port = aiohttp_unused_port()\n    client = _TestClient(_TestServer(app, port=port))\n    await client.start_server()\n\n    assert client.server.port == port\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    text = await resp.text()\n    assert _hello_world_str == text\n\n    await client.close()\n\n\n@pytest.mark.parametrize(\n    (\"hostname\", \"expected_host\"),\n    [(\"127.0.0.1\", \"127.0.0.1\"), (\"localhost\", \"127.0.0.1\"), (\"::1\", \"::1\")],\n)\nasync def test_test_server_hostnames(\n    hostname: Any, expected_host: Any, loop: Any\n) -> None:\n    app = _create_example_app()\n    server = _TestServer(app, host=hostname, loop=loop)\n    async with server:\n        pass\n    assert server.host == expected_host\n\n\n@pytest.mark.parametrize(\"test_server_cls\", [_TestServer, _RawTestServer])\nasync def test_base_test_server_socket_factory(\n    test_server_cls: type, app: Any, loop: Any\n) -> None:\n    factory_called = False\n\n    def factory(*args, **kwargs) -> socket:\n        nonlocal factory_called\n        factory_called = True\n        return get_port_socket(*args, **kwargs)\n\n    server = test_server_cls(app, loop=loop, socket_factory=factory)\n    async with server:\n        pass\n\n    assert factory_called\n", "tests/test_tracing.py": "# type: ignore\nfrom types import SimpleNamespace\nfrom typing import Any\nfrom unittest.mock import Mock\n\nimport pytest\n\nfrom aiohttp.test_utils import make_mocked_coro\nfrom aiohttp.tracing import (\n    Trace,\n    TraceConfig,\n    TraceConnectionCreateEndParams,\n    TraceConnectionCreateStartParams,\n    TraceConnectionQueuedEndParams,\n    TraceConnectionQueuedStartParams,\n    TraceConnectionReuseconnParams,\n    TraceDnsCacheHitParams,\n    TraceDnsCacheMissParams,\n    TraceDnsResolveHostEndParams,\n    TraceDnsResolveHostStartParams,\n    TraceRequestChunkSentParams,\n    TraceRequestEndParams,\n    TraceRequestExceptionParams,\n    TraceRequestRedirectParams,\n    TraceRequestStartParams,\n    TraceResponseChunkReceivedParams,\n)\n\n\nclass TestTraceConfig:\n    def test_trace_config_ctx_default(self) -> None:\n        trace_config = TraceConfig()\n        assert isinstance(trace_config.trace_config_ctx(), SimpleNamespace)\n\n    def test_trace_config_ctx_factory(self) -> None:\n        trace_config = TraceConfig(trace_config_ctx_factory=dict)\n        assert isinstance(trace_config.trace_config_ctx(), dict)\n\n    def test_trace_config_ctx_request_ctx(self) -> None:\n        trace_request_ctx = Mock()\n        trace_config = TraceConfig()\n        trace_config_ctx = trace_config.trace_config_ctx(\n            trace_request_ctx=trace_request_ctx\n        )\n        assert trace_config_ctx.trace_request_ctx is trace_request_ctx\n\n    def test_freeze(self) -> None:\n        trace_config = TraceConfig()\n        trace_config.freeze()\n\n        assert trace_config.on_request_start.frozen\n        assert trace_config.on_request_chunk_sent.frozen\n        assert trace_config.on_response_chunk_received.frozen\n        assert trace_config.on_request_end.frozen\n        assert trace_config.on_request_exception.frozen\n        assert trace_config.on_request_redirect.frozen\n        assert trace_config.on_connection_queued_start.frozen\n        assert trace_config.on_connection_queued_end.frozen\n        assert trace_config.on_connection_create_start.frozen\n        assert trace_config.on_connection_create_end.frozen\n        assert trace_config.on_connection_reuseconn.frozen\n        assert trace_config.on_dns_resolvehost_start.frozen\n        assert trace_config.on_dns_resolvehost_end.frozen\n        assert trace_config.on_dns_cache_hit.frozen\n        assert trace_config.on_dns_cache_miss.frozen\n        assert trace_config.on_request_headers_sent.frozen\n\n\nclass TestTrace:\n    @pytest.mark.parametrize(\n        \"signal,params,param_obj\",\n        [\n            (\"request_start\", (Mock(), Mock(), Mock()), TraceRequestStartParams),\n            (\n                \"request_chunk_sent\",\n                (Mock(), Mock(), Mock()),\n                TraceRequestChunkSentParams,\n            ),\n            (\n                \"response_chunk_received\",\n                (Mock(), Mock(), Mock()),\n                TraceResponseChunkReceivedParams,\n            ),\n            (\"request_end\", (Mock(), Mock(), Mock(), Mock()), TraceRequestEndParams),\n            (\n                \"request_exception\",\n                (Mock(), Mock(), Mock(), Mock()),\n                TraceRequestExceptionParams,\n            ),\n            (\n                \"request_redirect\",\n                (Mock(), Mock(), Mock(), Mock()),\n                TraceRequestRedirectParams,\n            ),\n            (\"connection_queued_start\", (), TraceConnectionQueuedStartParams),\n            (\"connection_queued_end\", (), TraceConnectionQueuedEndParams),\n            (\"connection_create_start\", (), TraceConnectionCreateStartParams),\n            (\"connection_create_end\", (), TraceConnectionCreateEndParams),\n            (\"connection_reuseconn\", (), TraceConnectionReuseconnParams),\n            (\"dns_resolvehost_start\", (Mock(),), TraceDnsResolveHostStartParams),\n            (\"dns_resolvehost_end\", (Mock(),), TraceDnsResolveHostEndParams),\n            (\"dns_cache_hit\", (Mock(),), TraceDnsCacheHitParams),\n            (\"dns_cache_miss\", (Mock(),), TraceDnsCacheMissParams),\n        ],\n    )\n    async def test_send(self, signal: Any, params: Any, param_obj: Any) -> None:\n        session = Mock()\n        trace_request_ctx = Mock()\n        callback = Mock(side_effect=make_mocked_coro(Mock()))\n\n        trace_config = TraceConfig()\n        getattr(trace_config, \"on_%s\" % signal).append(callback)\n        trace_config.freeze()\n        trace = Trace(\n            session,\n            trace_config,\n            trace_config.trace_config_ctx(trace_request_ctx=trace_request_ctx),\n        )\n        await getattr(trace, \"send_%s\" % signal)(*params)\n\n        callback.assert_called_once_with(\n            session,\n            SimpleNamespace(trace_request_ctx=trace_request_ctx),\n            param_obj(*params),\n        )\n", "tests/test_client_ws_functional.py": "# type: ignore\nimport asyncio\nimport sys\nfrom typing import Any\n\nimport pytest\n\nimport aiohttp\nfrom aiohttp import hdrs, web\nfrom aiohttp.client_ws import ClientWSTimeout\nfrom aiohttp.http import WSCloseCode\nfrom aiohttp.pytest_plugin import AiohttpClient\n\nif sys.version_info >= (3, 11):\n    import asyncio as async_timeout\nelse:\n    import async_timeout\n\n\nasync def test_send_recv_text(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_str()\n        await ws.send_str(msg + \"/answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n    await resp.send_str(\"ask\")\n\n    assert resp.get_extra_info(\"socket\") is not None\n\n    data = await resp.receive_str()\n    assert data == \"ask/answer\"\n    await resp.close()\n\n    assert resp.get_extra_info(\"socket\") is None\n\n\nasync def test_send_recv_bytes_bad_type(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_str()\n        await ws.send_str(msg + \"/answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n    await resp.send_str(\"ask\")\n\n    with pytest.raises(TypeError):\n        await resp.receive_bytes()\n        await resp.close()\n\n\nasync def test_send_recv_bytes(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_bytes()\n        await ws.send_bytes(msg + b\"/answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n\n    await resp.send_bytes(b\"ask\")\n\n    data = await resp.receive_bytes()\n    assert data == b\"ask/answer\"\n\n    await resp.close()\n\n\nasync def test_send_recv_text_bad_type(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_bytes()\n        await ws.send_bytes(msg + b\"/answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n\n    await resp.send_bytes(b\"ask\")\n\n    with pytest.raises(TypeError):\n        await resp.receive_str()\n\n        await resp.close()\n\n\nasync def test_send_recv_json(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        data = await ws.receive_json()\n        await ws.send_json({\"response\": data[\"request\"]})\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n    payload = {\"request\": \"test\"}\n    await resp.send_json(payload)\n\n    data = await resp.receive_json()\n    assert data[\"response\"] == payload[\"request\"]\n    await resp.close()\n\n\nasync def test_ping_pong(aiohttp_client: Any) -> None:\n    loop = asyncio.get_event_loop()\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_bytes()\n        await ws.ping()\n        await ws.send_bytes(msg + b\"/answer\")\n        try:\n            await ws.close()\n        finally:\n            closed.set_result(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n\n    await resp.ping()\n    await resp.send_bytes(b\"ask\")\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.BINARY\n    assert msg.data == b\"ask/answer\"\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSE\n\n    await resp.close()\n    await closed\n\n\nasync def test_ping_pong_manual(aiohttp_client: Any) -> None:\n    loop = asyncio.get_event_loop()\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_bytes()\n        await ws.ping()\n        await ws.send_bytes(msg + b\"/answer\")\n        try:\n            await ws.close()\n        finally:\n            closed.set_result(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\", autoping=False)\n\n    await resp.ping()\n    await resp.send_bytes(b\"ask\")\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.PONG\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.PING\n    await resp.pong()\n\n    msg = await resp.receive()\n    assert msg.data == b\"ask/answer\"\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSE\n\n    await closed\n\n\nasync def test_close(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        await ws.receive_bytes()\n        await ws.send_str(\"test\")\n\n        await ws.receive()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n\n    await resp.send_bytes(b\"ask\")\n\n    closed = await resp.close()\n    assert closed\n    assert resp.closed\n    assert resp.close_code == 1000\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSED\n\n\nasync def test_concurrent_task_close(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        await ws.receive()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    client = await aiohttp_client(app)\n    async with client.ws_connect(\"/\") as resp:\n        # wait for the message in a separate task\n        task = asyncio.create_task(resp.receive())\n\n        # Make sure we start to wait on receiving message before closing the connection\n        await asyncio.sleep(0.1)\n\n        closed = await resp.close()\n\n        await task\n\n        assert closed\n        assert resp.closed\n        assert resp.close_code == 1000\n\n\nasync def test_concurrent_close(aiohttp_client: Any) -> None:\n    client_ws = None\n\n    async def handler(request):\n        nonlocal client_ws\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        await ws.receive_bytes()\n        await ws.send_str(\"test\")\n\n        await client_ws.close()\n\n        msg = await ws.receive()\n        assert msg.type == aiohttp.WSMsgType.CLOSE\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    ws = client_ws = await client.ws_connect(\"/\")\n\n    await ws.send_bytes(b\"ask\")\n\n    msg = await ws.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSING\n\n    await asyncio.sleep(0.01)\n    msg = await ws.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSED\n\n\nasync def test_close_from_server(aiohttp_client: Any) -> None:\n    loop = asyncio.get_event_loop()\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        try:\n            await ws.receive_bytes()\n            await ws.close()\n        finally:\n            closed.set_result(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n\n    await resp.send_bytes(b\"ask\")\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSE\n    assert resp.closed\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSED\n\n    await closed\n\n\nasync def test_close_manual(aiohttp_client: Any) -> None:\n    loop = asyncio.get_event_loop()\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        await ws.receive_bytes()\n        await ws.send_str(\"test\")\n\n        try:\n            await ws.close()\n        finally:\n            closed.set_result(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\", autoclose=False)\n    await resp.send_bytes(b\"ask\")\n\n    msg = await resp.receive()\n    assert msg.data == \"test\"\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSE\n    assert msg.data == 1000\n    assert msg.extra == \"\"\n    assert not resp.closed\n\n    await resp.close()\n    await closed\n    assert resp.closed\n\n\nasync def test_close_timeout_sock_close_read(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        await ws.receive_bytes()\n        await ws.send_str(\"test\")\n        await asyncio.sleep(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    timeout = ClientWSTimeout(ws_close=0.2)\n    resp = await client.ws_connect(\"/\", timeout=timeout, autoclose=False)\n\n    await resp.send_bytes(b\"ask\")\n\n    msg = await resp.receive()\n    assert msg.data == \"test\"\n    assert msg.type == aiohttp.WSMsgType.TEXT\n\n    msg = await resp.close()\n    assert resp.closed\n    assert isinstance(resp.exception(), asyncio.TimeoutError)\n\n\nasync def test_close_timeout_deprecated(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        await ws.receive_bytes()\n        await ws.send_str(\"test\")\n        await asyncio.sleep(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    with pytest.warns(\n        DeprecationWarning,\n        match=\"parameter 'timeout' of type 'float' \"\n        \"is deprecated, please use \"\n        r\"'timeout=ClientWSTimeout\\(ws_close=...\\)'\",\n    ):\n        resp = await client.ws_connect(\"/\", timeout=0.2, autoclose=False)\n\n    await resp.send_bytes(b\"ask\")\n\n    msg = await resp.receive()\n    assert msg.data == \"test\"\n    assert msg.type == aiohttp.WSMsgType.TEXT\n\n    msg = await resp.close()\n    assert resp.closed\n    assert isinstance(resp.exception(), asyncio.TimeoutError)\n\n\nasync def test_close_cancel(aiohttp_client: Any) -> None:\n    loop = asyncio.get_event_loop()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        await ws.receive_bytes()\n        await ws.send_str(\"test\")\n        await asyncio.sleep(10)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\", autoclose=False)\n\n    await resp.send_bytes(b\"ask\")\n\n    text = await resp.receive()\n    assert text.data == \"test\"\n\n    t = loop.create_task(resp.close())\n    await asyncio.sleep(0.1)\n    t.cancel()\n    await asyncio.sleep(0.1)\n    assert resp.closed\n    assert resp.exception() is None\n\n\nasync def test_override_default_headers(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.headers[hdrs.SEC_WEBSOCKET_VERSION] == \"8\"\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        await ws.send_str(\"answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    headers = {hdrs.SEC_WEBSOCKET_VERSION: \"8\"}\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\", headers=headers)\n    msg = await resp.receive()\n    assert msg.data == \"answer\"\n    await resp.close()\n\n\nasync def test_additional_headers(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.headers[\"x-hdr\"] == \"xtra\"\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        await ws.send_str(\"answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\", headers={\"x-hdr\": \"xtra\"})\n    msg = await resp.receive()\n    assert msg.data == \"answer\"\n    await resp.close()\n\n\nasync def test_recv_protocol_error(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        await ws.receive_str()\n        ws._writer.transport.write(b\"01234\" * 100)\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n    await resp.send_str(\"ask\")\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.ERROR\n    assert type(msg.data) is aiohttp.WebSocketError\n    assert msg.data.code == aiohttp.WSCloseCode.PROTOCOL_ERROR\n    assert str(msg.data) == \"Received frame with non-zero reserved bits\"\n    assert msg.extra is None\n    await resp.close()\n\n\nasync def test_recv_timeout(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        await ws.receive_str()\n\n        await asyncio.sleep(0.1)\n\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n    await resp.send_str(\"ask\")\n\n    with pytest.raises(asyncio.TimeoutError):\n        async with async_timeout.timeout(0.01):\n            await resp.receive()\n\n    await resp.close()\n\n\nasync def test_receive_timeout_sock_read(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        await ws.receive()\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    client = await aiohttp_client(app)\n    receive_timeout = ClientWSTimeout(ws_receive=0.1)\n    resp = await client.ws_connect(\"/\", timeout=receive_timeout)\n\n    with pytest.raises(asyncio.TimeoutError):\n        await resp.receive(timeout=0.05)\n\n    await resp.close()\n\n\nasync def test_receive_timeout_deprecation(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        await ws.receive()\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    client = await aiohttp_client(app)\n    with pytest.warns(\n        DeprecationWarning,\n        match=\"float parameter 'receive_timeout' \"\n        \"is deprecated, please use parameter \"\n        r\"'timeout=ClientWSTimeout\\(ws_receive=...\\)'\",\n    ):\n        resp = await client.ws_connect(\"/\", receive_timeout=0.1)\n\n    with pytest.raises(asyncio.TimeoutError):\n        await resp.receive(timeout=0.05)\n\n    await resp.close()\n\n\nasync def test_custom_receive_timeout(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        await ws.receive()\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n\n    with pytest.raises(asyncio.TimeoutError):\n        await resp.receive(0.05)\n\n    await resp.close()\n\n\nasync def test_heartbeat(aiohttp_client: Any) -> None:\n    ping_received = False\n\n    async def handler(request):\n        nonlocal ping_received\n        ws = web.WebSocketResponse(autoping=False)\n        await ws.prepare(request)\n        msg = await ws.receive()\n        if msg.type == aiohttp.WSMsgType.PING:\n            ping_received = True\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\", heartbeat=0.01)\n    await asyncio.sleep(0.1)\n    await resp.receive()\n    await resp.close()\n\n    assert ping_received\n\n\nasync def test_heartbeat_no_pong(aiohttp_client: Any) -> None:\n    ping_received = False\n\n    async def handler(request):\n        nonlocal ping_received\n        ws = web.WebSocketResponse(autoping=False)\n        await ws.prepare(request)\n        msg = await ws.receive()\n        if msg.type == aiohttp.WSMsgType.PING:\n            ping_received = True\n        await ws.receive()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\", heartbeat=0.1)\n\n    # Connection should be closed roughly after 1.5x heartbeat.\n    await asyncio.sleep(0.2)\n    assert ping_received\n    assert resp.close_code is WSCloseCode.ABNORMAL_CLOSURE\n\n\nasync def test_send_recv_compress(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_str()\n        await ws.send_str(msg + \"/answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\", compress=15)\n    await resp.send_str(\"ask\")\n\n    assert resp.compress == 15\n\n    data = await resp.receive_str()\n    assert data == \"ask/answer\"\n\n    await resp.close()\n    assert resp.get_extra_info(\"socket\") is None\n\n\nasync def test_send_recv_compress_wbits(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_str()\n        await ws.send_str(msg + \"/answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\", compress=9)\n    await resp.send_str(\"ask\")\n\n    # Client indicates supports wbits 15\n    # Server supports wbit 15 for decode\n    assert resp.compress == 15\n\n    data = await resp.receive_str()\n    assert data == \"ask/answer\"\n\n    await resp.close()\n    assert resp.get_extra_info(\"socket\") is None\n\n\nasync def test_send_recv_compress_wbit_error(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_bytes()\n        await ws.send_bytes(msg + b\"/answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    with pytest.raises(ValueError):\n        await client.ws_connect(\"/\", compress=1)\n\n\nasync def test_ws_client_async_for(aiohttp_client: Any) -> None:\n    items = [\"q1\", \"q2\", \"q3\"]\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        for i in items:\n            await ws.send_str(i)\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n    it = iter(items)\n    async for msg in resp:\n        assert msg.data == next(it)\n\n    with pytest.raises(StopIteration):\n        next(it)\n\n    assert resp.closed\n\n\nasync def test_ws_async_with(aiohttp_server: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        msg = await ws.receive()\n        await ws.send_str(msg.data + \"/answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    server = await aiohttp_server(app)\n\n    async with aiohttp.ClientSession() as client:\n        async with client.ws_connect(server.make_url(\"/\")) as ws:\n            await ws.send_str(\"request\")\n            msg = await ws.receive()\n            assert msg.data == \"request/answer\"\n\n        assert ws.closed\n\n\nasync def test_ws_async_with_send(aiohttp_server: Any) -> None:\n    # send_xxx methods have to return awaitable objects\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        msg = await ws.receive()\n        await ws.send_str(msg.data + \"/answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    server = await aiohttp_server(app)\n\n    async with aiohttp.ClientSession() as client:\n        async with client.ws_connect(server.make_url(\"/\")) as ws:\n            await ws.send_str(\"request\")\n            msg = await ws.receive()\n            assert msg.data == \"request/answer\"\n\n        assert ws.closed\n\n\nasync def test_ws_async_with_shortcut(aiohttp_server: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n        msg = await ws.receive()\n        await ws.send_str(msg.data + \"/answer\")\n        await ws.close()\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app)\n\n    async with aiohttp.ClientSession() as client:\n        async with client.ws_connect(server.make_url(\"/\")) as ws:\n            await ws.send_str(\"request\")\n            msg = await ws.receive()\n            assert msg.data == \"request/answer\"\n\n        assert ws.closed\n\n\nasync def test_closed_async_for(aiohttp_client: Any) -> None:\n    loop = asyncio.get_event_loop()\n    closed = loop.create_future()\n\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        try:\n            await ws.send_bytes(b\"started\")\n            await ws.receive_bytes()\n        finally:\n            closed.set_result(1)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n\n    messages = []\n    async for msg in resp:\n        messages.append(msg)\n        if b\"started\" == msg.data:\n            await resp.send_bytes(b\"ask\")\n            await resp.close()\n\n    assert 1 == len(messages)\n    assert messages[0].type == aiohttp.WSMsgType.BINARY\n    assert messages[0].data == b\"started\"\n    assert resp.closed\n\n    await closed\n\n\nasync def test_peer_connection_lost(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_str()\n        assert msg == \"ask\"\n        await ws.send_str(\"answer\")\n        request.transport.close()\n        await asyncio.sleep(10)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n    await resp.send_str(\"ask\")\n    assert \"answer\" == await resp.receive_str()\n\n    msg = await resp.receive()\n    assert msg.type == aiohttp.WSMsgType.CLOSED\n    await resp.close()\n\n\nasync def test_peer_connection_lost_iter(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ws = web.WebSocketResponse()\n        await ws.prepare(request)\n\n        msg = await ws.receive_str()\n        assert msg == \"ask\"\n        await ws.send_str(\"answer\")\n        request.transport.close()\n        await asyncio.sleep(100)\n        return ws\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.ws_connect(\"/\")\n    await resp.send_str(\"ask\")\n    async for msg in resp:\n        assert \"answer\" == msg.data\n\n    await resp.close()\n\n\nasync def test_ws_connect_with_wrong_ssl_type(aiohttp_client: AiohttpClient) -> None:\n    app = web.Application()\n    session = await aiohttp_client(app)\n\n    with pytest.raises(TypeError, match=\"ssl should be SSLContext, .*\"):\n        await session.ws_connect(\"/\", ssl=42)\n", "tests/test_tcp_helpers.py": "import socket\nfrom unittest import mock\n\nimport pytest\n\nfrom aiohttp.tcp_helpers import tcp_nodelay\n\nhas_ipv6: bool = socket.has_ipv6\nif has_ipv6:\n    # The socket.has_ipv6 flag may be True if Python was built with IPv6\n    # support, but the target system still may not have it.\n    # So let's ensure that we really have IPv6 support.\n    try:\n        with socket.socket(socket.AF_INET6, socket.SOCK_STREAM):\n            pass\n    except OSError:\n        has_ipv6 = False\n\n\n# nodelay\n\n\ndef test_tcp_nodelay_exception() -> None:\n    transport = mock.Mock()\n    s = mock.Mock()\n    s.setsockopt = mock.Mock()\n    s.family = socket.AF_INET\n    s.setsockopt.side_effect = OSError\n    transport.get_extra_info.return_value = s\n    tcp_nodelay(transport, True)\n    s.setsockopt.assert_called_with(socket.IPPROTO_TCP, socket.TCP_NODELAY, True)\n\n\ndef test_tcp_nodelay_enable() -> None:\n    transport = mock.Mock()\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        transport.get_extra_info.return_value = s\n        tcp_nodelay(transport, True)\n        assert s.getsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY)\n\n\ndef test_tcp_nodelay_enable_and_disable() -> None:\n    transport = mock.Mock()\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        transport.get_extra_info.return_value = s\n        tcp_nodelay(transport, True)\n        assert s.getsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY)\n        tcp_nodelay(transport, False)\n        assert not s.getsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY)\n\n\n@pytest.mark.skipif(not has_ipv6, reason=\"IPv6 is not available\")\ndef test_tcp_nodelay_enable_ipv6() -> None:\n    transport = mock.Mock()\n    with socket.socket(socket.AF_INET6, socket.SOCK_STREAM) as s:\n        transport.get_extra_info.return_value = s\n        tcp_nodelay(transport, True)\n        assert s.getsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY)\n\n\n@pytest.mark.skipif(not hasattr(socket, \"AF_UNIX\"), reason=\"requires unix sockets\")\ndef test_tcp_nodelay_enable_unix() -> None:\n    # do not set nodelay for unix socket\n    transport = mock.Mock()\n    s = mock.Mock(family=socket.AF_UNIX, type=socket.SOCK_STREAM)\n    transport.get_extra_info.return_value = s\n    tcp_nodelay(transport, True)\n    assert not s.setsockopt.called\n\n\ndef test_tcp_nodelay_enable_no_socket() -> None:\n    transport = mock.Mock()\n    transport.get_extra_info.return_value = None\n    tcp_nodelay(transport, True)\n", "tests/test_web_runner.py": "# type: ignore\nimport asyncio\nimport platform\nimport signal\nfrom typing import Any\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom aiohttp import web\nfrom aiohttp.abc import AbstractAccessLogger\nfrom aiohttp.test_utils import get_unused_port_socket\n\n\n@pytest.fixture\ndef app():\n    return web.Application()\n\n\n@pytest.fixture\ndef make_runner(loop: Any, app: Any):\n    asyncio.set_event_loop(loop)\n    runners = []\n\n    def go(**kwargs):\n        runner = web.AppRunner(app, **kwargs)\n        runners.append(runner)\n        return runner\n\n    yield go\n    for runner in runners:\n        loop.run_until_complete(runner.cleanup())\n\n\nasync def test_site_for_nonfrozen_app(make_runner: Any) -> None:\n    runner = make_runner()\n    with pytest.raises(RuntimeError):\n        web.TCPSite(runner)\n    assert len(runner.sites) == 0\n\n\n@pytest.mark.skipif(\n    platform.system() == \"Windows\", reason=\"the test is not valid for Windows\"\n)\nasync def test_runner_setup_handle_signals(make_runner: Any) -> None:\n    runner = make_runner(handle_signals=True)\n    await runner.setup()\n    assert signal.getsignal(signal.SIGTERM) is not signal.SIG_DFL\n    await runner.cleanup()\n    assert signal.getsignal(signal.SIGTERM) is signal.SIG_DFL\n\n\n@pytest.mark.skipif(\n    platform.system() == \"Windows\", reason=\"the test is not valid for Windows\"\n)\nasync def test_runner_setup_without_signal_handling(make_runner: Any) -> None:\n    runner = make_runner(handle_signals=False)\n    await runner.setup()\n    assert signal.getsignal(signal.SIGTERM) is signal.SIG_DFL\n    await runner.cleanup()\n    assert signal.getsignal(signal.SIGTERM) is signal.SIG_DFL\n\n\nasync def test_site_double_added(make_runner: Any) -> None:\n    _sock = get_unused_port_socket(\"127.0.0.1\")\n    runner = make_runner()\n    await runner.setup()\n    site = web.SockSite(runner, _sock)\n    await site.start()\n    with pytest.raises(RuntimeError):\n        await site.start()\n\n    assert len(runner.sites) == 1\n\n\nasync def test_site_stop_not_started(make_runner: Any) -> None:\n    runner = make_runner()\n    await runner.setup()\n    site = web.TCPSite(runner)\n    with pytest.raises(RuntimeError):\n        await site.stop()\n\n    assert len(runner.sites) == 0\n\n\nasync def test_custom_log_format(make_runner: Any) -> None:\n    runner = make_runner(access_log_format=\"abc\")\n    await runner.setup()\n    assert runner.server._kwargs[\"access_log_format\"] == \"abc\"\n\n\nasync def test_unreg_site(make_runner: Any) -> None:\n    runner = make_runner()\n    await runner.setup()\n    site = web.TCPSite(runner)\n    with pytest.raises(RuntimeError):\n        runner._unreg_site(site)\n\n\nasync def test_app_property(make_runner: Any, app: Any) -> None:\n    runner = make_runner()\n    assert runner.app is app\n\n\ndef test_non_app() -> None:\n    with pytest.raises(TypeError):\n        web.AppRunner(object())\n\n\ndef test_app_handler_args() -> None:\n    app = web.Application(handler_args={\"test\": True})\n    runner = web.AppRunner(app)\n    assert runner._kwargs == {\"access_log_class\": web.AccessLogger, \"test\": True}\n\n\nasync def test_app_handler_args_failure() -> None:\n    app = web.Application(handler_args={\"unknown_parameter\": 5})\n    runner = web.AppRunner(app)\n    await runner.setup()\n    assert runner._server\n    rh = runner._server()\n    assert rh._timeout_ceil_threshold == 5\n    await runner.cleanup()\n    assert app\n\n\n@pytest.mark.parametrize(\n    (\"value\", \"expected\"),\n    (\n        (2, 2),\n        (None, 5),\n        (\"2\", 2),\n    ),\n)\nasync def test_app_handler_args_ceil_threshold(value: Any, expected: Any) -> None:\n    app = web.Application(handler_args={\"timeout_ceil_threshold\": value})\n    runner = web.AppRunner(app)\n    await runner.setup()\n    assert runner._server\n    rh = runner._server()\n    assert rh._timeout_ceil_threshold == expected\n    await runner.cleanup()\n    assert app\n\n\nasync def test_app_make_handler_access_log_class_bad_type1() -> None:\n    class Logger:\n        pass\n\n    app = web.Application()\n\n    with pytest.raises(TypeError):\n        web.AppRunner(app, access_log_class=Logger)\n\n\nasync def test_app_make_handler_access_log_class_bad_type2() -> None:\n    class Logger:\n        pass\n\n    app = web.Application(handler_args={\"access_log_class\": Logger})\n\n    with pytest.raises(TypeError):\n        web.AppRunner(app)\n\n\nasync def test_app_make_handler_access_log_class1() -> None:\n    class Logger(AbstractAccessLogger):\n        def log(self, request, response, time):\n            \"\"\"Pass log method.\"\"\"\n\n    app = web.Application()\n    runner = web.AppRunner(app, access_log_class=Logger)\n    assert runner._kwargs[\"access_log_class\"] is Logger\n\n\nasync def test_app_make_handler_access_log_class2() -> None:\n    class Logger(AbstractAccessLogger):\n        def log(self, request, response, time):\n            \"\"\"Pass log method.\"\"\"\n\n    app = web.Application(handler_args={\"access_log_class\": Logger})\n    runner = web.AppRunner(app)\n    assert runner._kwargs[\"access_log_class\"] is Logger\n\n\nasync def test_addresses(make_runner: Any, unix_sockname: Any) -> None:\n    _sock = get_unused_port_socket(\"127.0.0.1\")\n    runner = make_runner()\n    await runner.setup()\n    tcp = web.SockSite(runner, _sock)\n    await tcp.start()\n    unix = web.UnixSite(runner, unix_sockname)\n    await unix.start()\n    actual_addrs = runner.addresses\n    expected_host, expected_post = _sock.getsockname()[:2]\n    assert actual_addrs == [(expected_host, expected_post), unix_sockname]\n\n\n@pytest.mark.skipif(\n    platform.system() != \"Windows\", reason=\"Proactor Event loop present only in Windows\"\n)\nasync def test_named_pipe_runner_wrong_loop(\n    app: Any, selector_loop: Any, pipe_name: Any\n) -> None:\n    runner = web.AppRunner(app)\n    await runner.setup()\n    with pytest.raises(RuntimeError):\n        web.NamedPipeSite(runner, pipe_name)\n\n\n@pytest.mark.skipif(\n    platform.system() != \"Windows\", reason=\"Proactor Event loop present only in Windows\"\n)\nasync def test_named_pipe_runner_proactor_loop(\n    proactor_loop: Any, app: Any, pipe_name: Any\n) -> None:\n    runner = web.AppRunner(app)\n    await runner.setup()\n    pipe = web.NamedPipeSite(runner, pipe_name)\n    await pipe.start()\n    await runner.cleanup()\n\n\nasync def test_tcpsite_default_host(make_runner: Any) -> None:\n    runner = make_runner()\n    await runner.setup()\n    site = web.TCPSite(runner)\n    assert site.name == \"http://0.0.0.0:8080\"\n\n    calls = []\n\n    async def mock_create_server(*args, **kwargs):\n        calls.append((args, kwargs))\n\n    with patch(\"asyncio.get_event_loop\") as mock_get_loop:\n        mock_get_loop.return_value.create_server = mock_create_server\n        await site.start()\n\n    assert len(calls) == 1\n    server, host, port = calls[0][0]\n    assert server is runner.server\n    assert host is None\n    assert port == 8080\n\n\ndef test_run_after_asyncio_run() -> None:\n    async def nothing():\n        pass\n\n    def spy():\n        spy.called = True\n\n    spy.called = False\n\n    async def shutdown():\n        spy()\n        raise web.GracefulExit()\n\n    # asyncio.run() creates a new loop and closes it.\n    asyncio.run(nothing())\n\n    app = web.Application()\n    # create_task() will delay the function until app is run.\n    app.on_startup.append(lambda a: asyncio.create_task(shutdown()))\n\n    web.run_app(app)\n    assert spy.called, \"run_app() should work after asyncio.run().\"\n", "tests/test_locks.py": "# Tests of custom aiohttp locks implementations\nimport asyncio\nfrom typing import Any, Union\n\nimport pytest\n\nfrom aiohttp.locks import EventResultOrError\n\n\nclass TestEventResultOrError:\n    async def test_set_exception(self, loop: Any) -> None:\n        ev = EventResultOrError(loop=loop)\n\n        async def c() -> Union[int, Exception]:\n            try:\n                await ev.wait()\n            except Exception as e:\n                return e\n            return 1\n\n        t = loop.create_task(c())\n        await asyncio.sleep(0)\n        e = Exception()\n        ev.set(exc=e)\n        assert (await t) == e\n\n    async def test_set(self, loop: Any) -> None:\n        ev = EventResultOrError(loop=loop)\n\n        async def c() -> int:\n            await ev.wait()\n            return 1\n\n        t = loop.create_task(c())\n        await asyncio.sleep(0)\n        ev.set()\n        assert (await t) == 1\n\n    async def test_cancel_waiters(self, loop: Any) -> None:\n        ev = EventResultOrError(loop=loop)\n\n        async def c() -> None:\n            await ev.wait()\n\n        t1 = loop.create_task(c())\n        t2 = loop.create_task(c())\n        await asyncio.sleep(0)\n        ev.cancel()\n        ev.set()\n\n        with pytest.raises(asyncio.CancelledError):\n            await t1\n\n        with pytest.raises(asyncio.CancelledError):\n            await t2\n", "tests/test_client_ws.py": "# type: ignore\nimport asyncio\nimport base64\nimport hashlib\nimport os\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\n\nimport aiohttp\nfrom aiohttp import client, hdrs\nfrom aiohttp.http import WS_KEY\nfrom aiohttp.streams import EofStream\nfrom aiohttp.test_utils import make_mocked_coro\n\n\n@pytest.fixture\ndef key_data():\n    return os.urandom(16)\n\n\n@pytest.fixture\ndef key(key_data: Any):\n    return base64.b64encode(key_data)\n\n\n@pytest.fixture\ndef ws_key(key: Any):\n    return base64.b64encode(hashlib.sha1(key + WS_KEY).digest()).decode()\n\n\nasync def test_ws_connect(ws_key: Any, loop: Any, key_data: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n        hdrs.SEC_WEBSOCKET_PROTOCOL: \"chat\",\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            res = await aiohttp.ClientSession().ws_connect(\n                \"http://test.org\", protocols=(\"t1\", \"t2\", \"chat\")\n            )\n\n    assert isinstance(res, client.ClientWebSocketResponse)\n    assert res.protocol == \"chat\"\n    assert hdrs.ORIGIN not in m_req.call_args[1][\"headers\"]\n\n\nasync def test_ws_connect_with_origin(key_data: Any, loop: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 403\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            origin = \"https://example.org/page.html\"\n            with pytest.raises(client.WSServerHandshakeError):\n                await aiohttp.ClientSession().ws_connect(\n                    \"http://test.org\", origin=origin\n                )\n\n    assert hdrs.ORIGIN in m_req.call_args[1][\"headers\"]\n    assert m_req.call_args[1][\"headers\"][hdrs.ORIGIN] == origin\n\n\nasync def test_ws_connect_with_params(ws_key: Any, loop: Any, key_data: Any) -> None:\n    params = {\"key1\": \"value1\", \"key2\": \"value2\"}\n\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n        hdrs.SEC_WEBSOCKET_PROTOCOL: \"chat\",\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            await aiohttp.ClientSession().ws_connect(\n                \"http://test.org\", protocols=(\"t1\", \"t2\", \"chat\"), params=params\n            )\n\n    assert m_req.call_args[1][\"params\"] == params\n\n\nasync def test_ws_connect_custom_response(\n    loop: Any, ws_key: Any, key_data: Any\n) -> None:\n    class CustomResponse(client.ClientWebSocketResponse):\n        def read(self, decode=False):\n            return \"customized!\"\n\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            res = await aiohttp.ClientSession(\n                ws_response_class=CustomResponse\n            ).ws_connect(\"http://test.org\")\n\n    assert res.read() == \"customized!\"\n\n\nasync def test_ws_connect_err_status(loop: Any, ws_key: Any, key_data: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 500\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            with pytest.raises(client.WSServerHandshakeError) as ctx:\n                await aiohttp.ClientSession().ws_connect(\n                    \"http://test.org\", protocols=(\"t1\", \"t2\", \"chat\")\n                )\n\n    assert ctx.value.message == \"Invalid response status\"\n\n\nasync def test_ws_connect_err_upgrade(loop: Any, ws_key: Any, key_data: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"test\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            with pytest.raises(client.WSServerHandshakeError) as ctx:\n                await aiohttp.ClientSession().ws_connect(\n                    \"http://test.org\", protocols=(\"t1\", \"t2\", \"chat\")\n                )\n\n    assert ctx.value.message == \"Invalid upgrade header\"\n\n\nasync def test_ws_connect_err_conn(loop: Any, ws_key: Any, key_data: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"close\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            with pytest.raises(client.WSServerHandshakeError) as ctx:\n                await aiohttp.ClientSession().ws_connect(\n                    \"http://test.org\", protocols=(\"t1\", \"t2\", \"chat\")\n                )\n\n    assert ctx.value.message == \"Invalid connection header\"\n\n\nasync def test_ws_connect_err_challenge(loop: Any, ws_key: Any, key_data: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: \"asdfasdfasdfasdfasdfasdf\",\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            with pytest.raises(client.WSServerHandshakeError) as ctx:\n                await aiohttp.ClientSession().ws_connect(\n                    \"http://test.org\", protocols=(\"t1\", \"t2\", \"chat\")\n                )\n\n    assert ctx.value.message == \"Invalid challenge response\"\n\n\nasync def test_ws_connect_common_headers(ws_key: Any, loop: Any, key_data: Any) -> None:\n    # Emulate a headers dict being reused for a second ws_connect.\n\n    # In this scenario, we need to ensure that the newly generated secret key\n    # is sent to the server, not the stale key.\n    headers = {}\n\n    async def test_connection() -> None:\n        async def mock_get(*args, **kwargs):\n            resp = mock.Mock()\n            resp.status = 101\n            key = kwargs.get(\"headers\").get(hdrs.SEC_WEBSOCKET_KEY)\n            accept = base64.b64encode(\n                hashlib.sha1(base64.b64encode(base64.b64decode(key)) + WS_KEY).digest()\n            ).decode()\n            resp.headers = {\n                hdrs.UPGRADE: \"websocket\",\n                hdrs.CONNECTION: \"upgrade\",\n                hdrs.SEC_WEBSOCKET_ACCEPT: accept,\n                hdrs.SEC_WEBSOCKET_PROTOCOL: \"chat\",\n            }\n            return resp\n\n        with mock.patch(\"aiohttp.client.os\") as m_os:\n            with mock.patch(\n                \"aiohttp.client.ClientSession.request\", side_effect=mock_get\n            ) as m_req:\n                m_os.urandom.return_value = key_data\n\n                res = await aiohttp.ClientSession().ws_connect(\n                    \"http://test.org\", protocols=(\"t1\", \"t2\", \"chat\"), headers=headers\n                )\n\n        assert isinstance(res, client.ClientWebSocketResponse)\n        assert res.protocol == \"chat\"\n        assert hdrs.ORIGIN not in m_req.call_args[1][\"headers\"]\n\n    await test_connection()\n    # Generate a new ws key\n    key_data = os.urandom(16)\n    await test_connection()\n\n\nasync def test_close(loop: Any, ws_key: Any, key_data: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.WebSocketWriter\") as WebSocketWriter:\n        with mock.patch(\"aiohttp.client.os\") as m_os:\n            with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n                m_os.urandom.return_value = key_data\n                m_req.return_value = loop.create_future()\n                m_req.return_value.set_result(resp)\n                writer = mock.Mock()\n                WebSocketWriter.return_value = writer\n                writer.close = make_mocked_coro()\n\n                session = aiohttp.ClientSession()\n                resp = await session.ws_connect(\"http://test.org\")\n                assert not resp.closed\n\n                resp._reader.feed_data(\n                    aiohttp.WSMessage(aiohttp.WSMsgType.CLOSE, b\"\", b\"\")\n                )\n\n                res = await resp.close()\n                writer.close.assert_called_with(1000, b\"\")\n                assert resp.closed\n                assert res\n                assert resp.exception() is None\n\n                # idempotent\n                res = await resp.close()\n                assert not res\n                assert writer.close.call_count == 1\n\n                await session.close()\n\n\nasync def test_close_eofstream(loop: Any, ws_key: Any, key_data: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.WebSocketWriter\") as WebSocketWriter:\n        with mock.patch(\"aiohttp.client.os\") as m_os:\n            with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n                m_os.urandom.return_value = key_data\n                m_req.return_value = loop.create_future()\n                m_req.return_value.set_result(resp)\n                writer = WebSocketWriter.return_value = mock.Mock()\n\n                session = aiohttp.ClientSession()\n                resp = await session.ws_connect(\"http://test.org\")\n                assert not resp.closed\n\n                exc = EofStream()\n                resp._reader.set_exception(exc)\n\n                await resp.receive()\n                writer.close.assert_called_with(1000, b\"\")\n                assert resp.closed\n\n                await session.close()\n\n\nasync def test_close_exc(loop: Any, ws_key: Any, key_data: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.WebSocketWriter\") as WebSocketWriter:\n        with mock.patch(\"aiohttp.client.os\") as m_os:\n            with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n                m_os.urandom.return_value = key_data\n                m_req.return_value = loop.create_future()\n                m_req.return_value.set_result(resp)\n                writer = mock.Mock()\n                WebSocketWriter.return_value = writer\n                writer.close = make_mocked_coro()\n\n                session = aiohttp.ClientSession()\n                resp = await session.ws_connect(\"http://test.org\")\n                assert not resp.closed\n\n                exc = ValueError()\n                resp._reader.set_exception(exc)\n\n                await resp.close()\n                assert resp.closed\n                assert resp.exception() is exc\n\n                await session.close()\n\n\nasync def test_close_exc2(loop: Any, ws_key: Any, key_data: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.WebSocketWriter\") as WebSocketWriter:\n        with mock.patch(\"aiohttp.client.os\") as m_os:\n            with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n                m_os.urandom.return_value = key_data\n                m_req.return_value = loop.create_future()\n                m_req.return_value.set_result(resp)\n                writer = WebSocketWriter.return_value = mock.Mock()\n\n                resp = await aiohttp.ClientSession().ws_connect(\"http://test.org\")\n                assert not resp.closed\n\n                exc = ValueError()\n                writer.close.side_effect = exc\n\n                await resp.close()\n                assert resp.closed\n                assert resp.exception() is exc\n\n                resp._closed = False\n                writer.close.side_effect = asyncio.CancelledError()\n                with pytest.raises(asyncio.CancelledError):\n                    await resp.close()\n\n\nasync def test_send_data_after_close(ws_key: Any, key_data: Any, loop: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            resp = await aiohttp.ClientSession().ws_connect(\"http://test.org\")\n            resp._writer._closing = True\n\n            for meth, args in (\n                (resp.ping, ()),\n                (resp.pong, ()),\n                (resp.send_str, (\"s\",)),\n                (resp.send_bytes, (b\"b\",)),\n                (resp.send_json, ({},)),\n            ):\n                with pytest.raises(ConnectionResetError):\n                    await meth(*args)\n\n\nasync def test_send_data_type_errors(ws_key: Any, key_data: Any, loop: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.WebSocketWriter\") as WebSocketWriter:\n        with mock.patch(\"aiohttp.client.os\") as m_os:\n            with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n                m_os.urandom.return_value = key_data\n                m_req.return_value = loop.create_future()\n                m_req.return_value.set_result(resp)\n                WebSocketWriter.return_value = mock.Mock()\n\n                resp = await aiohttp.ClientSession().ws_connect(\"http://test.org\")\n\n                with pytest.raises(TypeError):\n                    await resp.send_str(b\"s\")\n                with pytest.raises(TypeError):\n                    await resp.send_bytes(\"b\")\n                with pytest.raises(TypeError):\n                    await resp.send_json(set())\n\n\nasync def test_reader_read_exception(ws_key: Any, key_data: Any, loop: Any) -> None:\n    hresp = mock.Mock()\n    hresp.status = 101\n    hresp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.WebSocketWriter\") as WebSocketWriter:\n        with mock.patch(\"aiohttp.client.os\") as m_os:\n            with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n                m_os.urandom.return_value = key_data\n                m_req.return_value = loop.create_future()\n                m_req.return_value.set_result(hresp)\n\n                writer = mock.Mock()\n                WebSocketWriter.return_value = writer\n                writer.close = make_mocked_coro()\n\n                session = aiohttp.ClientSession()\n                resp = await session.ws_connect(\"http://test.org\")\n\n                exc = ValueError()\n                resp._reader.set_exception(exc)\n\n                msg = await resp.receive()\n                assert msg.type == aiohttp.WSMsgType.ERROR\n                assert resp.exception() is exc\n\n                await session.close()\n\n\nasync def test_receive_runtime_err(loop: Any) -> None:\n    resp = client.ClientWebSocketResponse(\n        mock.Mock(), mock.Mock(), mock.Mock(), mock.Mock(), 10.0, True, True, loop\n    )\n    resp._waiting = True\n\n    with pytest.raises(RuntimeError):\n        await resp.receive()\n\n\nasync def test_ws_connect_close_resp_on_err(\n    loop: Any, ws_key: Any, key_data: Any\n) -> None:\n    resp = mock.Mock()\n    resp.status = 500\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            with pytest.raises(client.WSServerHandshakeError):\n                await aiohttp.ClientSession().ws_connect(\n                    \"http://test.org\", protocols=(\"t1\", \"t2\", \"chat\")\n                )\n            resp.close.assert_called_with()\n\n\nasync def test_ws_connect_non_overlapped_protocols(\n    ws_key: Any, loop: Any, key_data: Any\n) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n        hdrs.SEC_WEBSOCKET_PROTOCOL: \"other,another\",\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            res = await aiohttp.ClientSession().ws_connect(\n                \"http://test.org\", protocols=(\"t1\", \"t2\", \"chat\")\n            )\n\n    assert res.protocol is None\n\n\nasync def test_ws_connect_non_overlapped_protocols_2(\n    ws_key: Any, loop: Any, key_data: Any\n) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n        hdrs.SEC_WEBSOCKET_PROTOCOL: \"other,another\",\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            connector = aiohttp.TCPConnector(force_close=True)\n            res = await aiohttp.ClientSession(connector=connector).ws_connect(\n                \"http://test.org\", protocols=(\"t1\", \"t2\", \"chat\")\n            )\n\n    assert res.protocol is None\n    del res\n\n\nasync def test_ws_connect_deflate(loop: Any, ws_key: Any, key_data: Any) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n        hdrs.SEC_WEBSOCKET_EXTENSIONS: \"permessage-deflate\",\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            res = await aiohttp.ClientSession().ws_connect(\n                \"http://test.org\", compress=15\n            )\n\n    assert res.compress == 15\n    assert res.client_notakeover is False\n\n\nasync def test_ws_connect_deflate_per_message(\n    loop: Any, ws_key: Any, key_data: Any\n) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n        hdrs.SEC_WEBSOCKET_EXTENSIONS: \"permessage-deflate\",\n    }\n    with mock.patch(\"aiohttp.client.WebSocketWriter\") as WebSocketWriter:\n        with mock.patch(\"aiohttp.client.os\") as m_os:\n            with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n                m_os.urandom.return_value = key_data\n                m_req.return_value = loop.create_future()\n                m_req.return_value.set_result(resp)\n                writer = WebSocketWriter.return_value = mock.Mock()\n                send = writer.send = make_mocked_coro()\n\n                session = aiohttp.ClientSession()\n                resp = await session.ws_connect(\"http://test.org\")\n\n                await resp.send_str(\"string\", compress=-1)\n                send.assert_called_with(\"string\", binary=False, compress=-1)\n\n                await resp.send_bytes(b\"bytes\", compress=15)\n                send.assert_called_with(b\"bytes\", binary=True, compress=15)\n\n                await resp.send_json([{}], compress=-9)\n                send.assert_called_with(\"[{}]\", binary=False, compress=-9)\n\n                await session.close()\n\n\nasync def test_ws_connect_deflate_server_not_support(\n    loop: Any, ws_key: Any, key_data: Any\n) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            res = await aiohttp.ClientSession().ws_connect(\n                \"http://test.org\", compress=15\n            )\n\n    assert res.compress == 0\n    assert res.client_notakeover is False\n\n\nasync def test_ws_connect_deflate_notakeover(\n    loop: Any, ws_key: Any, key_data: Any\n) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n        hdrs.SEC_WEBSOCKET_EXTENSIONS: \"permessage-deflate; \"\n        \"client_no_context_takeover\",\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            res = await aiohttp.ClientSession().ws_connect(\n                \"http://test.org\", compress=15\n            )\n\n    assert res.compress == 15\n    assert res.client_notakeover is True\n\n\nasync def test_ws_connect_deflate_client_wbits(\n    loop: Any, ws_key: Any, key_data: Any\n) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n        hdrs.SEC_WEBSOCKET_EXTENSIONS: \"permessage-deflate; \"\n        \"client_max_window_bits=10\",\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            res = await aiohttp.ClientSession().ws_connect(\n                \"http://test.org\", compress=15\n            )\n\n    assert res.compress == 10\n    assert res.client_notakeover is False\n\n\nasync def test_ws_connect_deflate_client_wbits_bad(\n    loop: Any, ws_key: Any, key_data: Any\n) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n        hdrs.SEC_WEBSOCKET_EXTENSIONS: \"permessage-deflate; \"\n        \"client_max_window_bits=6\",\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            with pytest.raises(client.WSServerHandshakeError):\n                await aiohttp.ClientSession().ws_connect(\"http://test.org\", compress=15)\n\n\nasync def test_ws_connect_deflate_server_ext_bad(\n    loop: Any, ws_key: Any, key_data: Any\n) -> None:\n    resp = mock.Mock()\n    resp.status = 101\n    resp.headers = {\n        hdrs.UPGRADE: \"websocket\",\n        hdrs.CONNECTION: \"upgrade\",\n        hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,\n        hdrs.SEC_WEBSOCKET_EXTENSIONS: \"permessage-deflate; bad\",\n    }\n    with mock.patch(\"aiohttp.client.os\") as m_os:\n        with mock.patch(\"aiohttp.client.ClientSession.request\") as m_req:\n            m_os.urandom.return_value = key_data\n            m_req.return_value = loop.create_future()\n            m_req.return_value.set_result(resp)\n\n            with pytest.raises(client.WSServerHandshakeError):\n                await aiohttp.ClientSession().ws_connect(\"http://test.org\", compress=15)\n", "tests/test_client_session.py": "# type: ignore\nimport asyncio\nimport contextlib\nimport gc\nimport io\nimport json\nfrom http.cookies import SimpleCookie\nfrom typing import Any, List\nfrom unittest import mock\nfrom uuid import uuid4\n\nimport pytest\nfrom multidict import CIMultiDict, MultiDict\nfrom re_assert import Matches\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp import client, hdrs, web\nfrom aiohttp.client import ClientSession\nfrom aiohttp.client_reqrep import ClientRequest\nfrom aiohttp.connector import BaseConnector, TCPConnector\nfrom aiohttp.test_utils import make_mocked_coro\n\n\n@pytest.fixture\ndef connector(loop: Any, create_mocked_conn: Any):\n    async def make_conn():\n        return BaseConnector()\n\n    conn = loop.run_until_complete(make_conn())\n    proto = create_mocked_conn()\n    conn._conns[\"a\"] = [(proto, 123)]\n    yield conn\n    loop.run_until_complete(conn.close())\n\n\n@pytest.fixture\ndef create_session(loop: Any):\n    session = None\n\n    async def maker(*args, **kwargs):\n        nonlocal session\n        session = ClientSession(*args, **kwargs)\n        return session\n\n    yield maker\n    if session is not None:\n        loop.run_until_complete(session.close())\n\n\n@pytest.fixture\ndef session(create_session: Any, loop: Any):\n    return loop.run_until_complete(create_session())\n\n\n@pytest.fixture\ndef params():\n    return dict(\n        headers={\"Authorization\": \"Basic ...\"},\n        max_redirects=2,\n        encoding=\"latin1\",\n        version=aiohttp.HttpVersion10,\n        compress=\"deflate\",\n        chunked=True,\n        expect100=True,\n        read_until_eof=False,\n    )\n\n\nasync def test_close_coro(create_session: Any) -> None:\n    session = await create_session()\n    await session.close()\n\n\nasync def test_init_headers_simple_dict(create_session: Any) -> None:\n    session = await create_session(headers={\"h1\": \"header1\", \"h2\": \"header2\"})\n    assert sorted(session.headers.items()) == ([(\"h1\", \"header1\"), (\"h2\", \"header2\")])\n\n\nasync def test_init_headers_list_of_tuples(create_session: Any) -> None:\n    session = await create_session(\n        headers=[(\"h1\", \"header1\"), (\"h2\", \"header2\"), (\"h3\", \"header3\")]\n    )\n    assert session.headers == CIMultiDict(\n        [(\"h1\", \"header1\"), (\"h2\", \"header2\"), (\"h3\", \"header3\")]\n    )\n\n\nasync def test_init_headers_MultiDict(create_session: Any) -> None:\n    session = await create_session(\n        headers=MultiDict([(\"h1\", \"header1\"), (\"h2\", \"header2\"), (\"h3\", \"header3\")])\n    )\n    assert session.headers == CIMultiDict(\n        [(\"H1\", \"header1\"), (\"H2\", \"header2\"), (\"H3\", \"header3\")]\n    )\n\n\nasync def test_init_headers_list_of_tuples_with_duplicates(create_session: Any) -> None:\n    session = await create_session(\n        headers=[(\"h1\", \"header11\"), (\"h2\", \"header21\"), (\"h1\", \"header12\")]\n    )\n    assert session.headers == CIMultiDict(\n        [(\"H1\", \"header11\"), (\"H2\", \"header21\"), (\"H1\", \"header12\")]\n    )\n\n\nasync def test_init_cookies_with_simple_dict(create_session: Any) -> None:\n    session = await create_session(cookies={\"c1\": \"cookie1\", \"c2\": \"cookie2\"})\n    cookies = session.cookie_jar.filter_cookies()\n    assert set(cookies) == {\"c1\", \"c2\"}\n    assert cookies[\"c1\"].value == \"cookie1\"\n    assert cookies[\"c2\"].value == \"cookie2\"\n\n\nasync def test_init_cookies_with_list_of_tuples(create_session: Any) -> None:\n    session = await create_session(cookies=[(\"c1\", \"cookie1\"), (\"c2\", \"cookie2\")])\n\n    cookies = session.cookie_jar.filter_cookies()\n    assert set(cookies) == {\"c1\", \"c2\"}\n    assert cookies[\"c1\"].value == \"cookie1\"\n    assert cookies[\"c2\"].value == \"cookie2\"\n\n\nasync def test_merge_headers(create_session: Any) -> None:\n    # Check incoming simple dict\n    session = await create_session(headers={\"h1\": \"header1\", \"h2\": \"header2\"})\n    headers = session._prepare_headers({\"h1\": \"h1\"})\n\n    assert isinstance(headers, CIMultiDict)\n    assert headers == {\"h1\": \"h1\", \"h2\": \"header2\"}\n\n\nasync def test_merge_headers_with_multi_dict(create_session: Any) -> None:\n    session = await create_session(headers={\"h1\": \"header1\", \"h2\": \"header2\"})\n    headers = session._prepare_headers(MultiDict([(\"h1\", \"h1\")]))\n    assert isinstance(headers, CIMultiDict)\n    assert headers == {\"h1\": \"h1\", \"h2\": \"header2\"}\n\n\nasync def test_merge_headers_with_list_of_tuples(create_session: Any) -> None:\n    session = await create_session(headers={\"h1\": \"header1\", \"h2\": \"header2\"})\n    headers = session._prepare_headers([(\"h1\", \"h1\")])\n    assert isinstance(headers, CIMultiDict)\n    assert headers == {\"h1\": \"h1\", \"h2\": \"header2\"}\n\n\nasync def test_merge_headers_with_list_of_tuples_duplicated_names(\n    create_session: Any,\n) -> None:\n    session = await create_session(headers={\"h1\": \"header1\", \"h2\": \"header2\"})\n\n    headers = session._prepare_headers([(\"h1\", \"v1\"), (\"h1\", \"v2\")])\n\n    assert isinstance(headers, CIMultiDict)\n    assert list(sorted(headers.items())) == [\n        (\"h1\", \"v1\"),\n        (\"h1\", \"v2\"),\n        (\"h2\", \"header2\"),\n    ]\n\n\ndef test_http_GET(session: Any, params: Any) -> None:\n    with mock.patch(\n        \"aiohttp.client.ClientSession._request\", new_callable=mock.MagicMock\n    ) as patched:\n        session.get(\"http://test.example.com\", params={\"x\": 1}, **params)\n    assert patched.called, \"`ClientSession._request` not called\"\n    assert list(patched.call_args) == [\n        (\n            \"GET\",\n            \"http://test.example.com\",\n        ),\n        dict(params={\"x\": 1}, allow_redirects=True, **params),\n    ]\n\n\ndef test_http_OPTIONS(session: Any, params: Any) -> None:\n    with mock.patch(\n        \"aiohttp.client.ClientSession._request\", new_callable=mock.MagicMock\n    ) as patched:\n        session.options(\"http://opt.example.com\", params={\"x\": 2}, **params)\n    assert patched.called, \"`ClientSession._request` not called\"\n    assert list(patched.call_args) == [\n        (\n            \"OPTIONS\",\n            \"http://opt.example.com\",\n        ),\n        dict(params={\"x\": 2}, allow_redirects=True, **params),\n    ]\n\n\ndef test_http_HEAD(session: Any, params: Any) -> None:\n    with mock.patch(\n        \"aiohttp.client.ClientSession._request\", new_callable=mock.MagicMock\n    ) as patched:\n        session.head(\"http://head.example.com\", params={\"x\": 2}, **params)\n    assert patched.called, \"`ClientSession._request` not called\"\n    assert list(patched.call_args) == [\n        (\n            \"HEAD\",\n            \"http://head.example.com\",\n        ),\n        dict(params={\"x\": 2}, allow_redirects=False, **params),\n    ]\n\n\ndef test_http_POST(session: Any, params: Any) -> None:\n    with mock.patch(\n        \"aiohttp.client.ClientSession._request\", new_callable=mock.MagicMock\n    ) as patched:\n        session.post(\n            \"http://post.example.com\", params={\"x\": 2}, data=\"Some_data\", **params\n        )\n    assert patched.called, \"`ClientSession._request` not called\"\n    assert list(patched.call_args) == [\n        (\n            \"POST\",\n            \"http://post.example.com\",\n        ),\n        dict(params={\"x\": 2}, data=\"Some_data\", **params),\n    ]\n\n\ndef test_http_PUT(session: Any, params: Any) -> None:\n    with mock.patch(\n        \"aiohttp.client.ClientSession._request\", new_callable=mock.MagicMock\n    ) as patched:\n        session.put(\n            \"http://put.example.com\", params={\"x\": 2}, data=\"Some_data\", **params\n        )\n    assert patched.called, \"`ClientSession._request` not called\"\n    assert list(patched.call_args) == [\n        (\n            \"PUT\",\n            \"http://put.example.com\",\n        ),\n        dict(params={\"x\": 2}, data=\"Some_data\", **params),\n    ]\n\n\ndef test_http_PATCH(session: Any, params: Any) -> None:\n    with mock.patch(\n        \"aiohttp.client.ClientSession._request\", new_callable=mock.MagicMock\n    ) as patched:\n        session.patch(\n            \"http://patch.example.com\", params={\"x\": 2}, data=\"Some_data\", **params\n        )\n    assert patched.called, \"`ClientSession._request` not called\"\n    assert list(patched.call_args) == [\n        (\n            \"PATCH\",\n            \"http://patch.example.com\",\n        ),\n        dict(params={\"x\": 2}, data=\"Some_data\", **params),\n    ]\n\n\ndef test_http_DELETE(session: Any, params: Any) -> None:\n    with mock.patch(\n        \"aiohttp.client.ClientSession._request\", new_callable=mock.MagicMock\n    ) as patched:\n        session.delete(\"http://delete.example.com\", params={\"x\": 2}, **params)\n    assert patched.called, \"`ClientSession._request` not called\"\n    assert list(patched.call_args) == [\n        (\n            \"DELETE\",\n            \"http://delete.example.com\",\n        ),\n        dict(params={\"x\": 2}, **params),\n    ]\n\n\nasync def test_close(create_session: Any, connector: Any) -> None:\n    session = await create_session(connector=connector)\n\n    await session.close()\n    assert session.connector is None\n    assert connector.closed\n\n\nasync def test_closed(session: Any) -> None:\n    assert not session.closed\n    await session.close()\n    assert session.closed\n\n\nasync def test_connector(create_session: Any, loop: Any, mocker: Any) -> None:\n    connector = TCPConnector()\n    mocker.spy(connector, \"close\")\n    session = await create_session(connector=connector)\n    assert session.connector is connector\n\n    await session.close()\n    assert connector.close.called\n    await connector.close()\n\n\nasync def test_create_connector(create_session: Any, loop: Any, mocker: Any) -> None:\n    session = await create_session()\n    connector = session.connector\n    mocker.spy(session.connector, \"close\")\n\n    await session.close()\n    assert connector.close.called\n\n\ndef test_connector_loop(loop: Any) -> None:\n    with contextlib.ExitStack() as stack:\n        another_loop = asyncio.new_event_loop()\n        stack.enter_context(contextlib.closing(another_loop))\n\n        async def make_connector():\n            return TCPConnector()\n\n        connector = another_loop.run_until_complete(make_connector())\n\n        with pytest.raises(RuntimeError) as ctx:\n\n            async def make_sess():\n                return ClientSession(connector=connector)\n\n            loop.run_until_complete(make_sess())\n        assert Matches(\"Session and connector have to use same event loop\") == str(\n            ctx.value\n        )\n        another_loop.run_until_complete(connector.close())\n\n\ndef test_detach(loop: Any, session: Any) -> None:\n    conn = session.connector\n    try:\n        assert not conn.closed\n        session.detach()\n        assert session.connector is None\n        assert session.closed\n        assert not conn.closed\n    finally:\n        loop.run_until_complete(conn.close())\n\n\nasync def test_request_closed_session(session: Any) -> None:\n    await session.close()\n    with pytest.raises(RuntimeError):\n        await session.request(\"get\", \"/\")\n\n\nasync def test_close_flag_for_closed_connector(session: Any) -> None:\n    conn = session.connector\n    assert not session.closed\n    await conn.close()\n    assert session.closed\n\n\nasync def test_double_close(connector: Any, create_session: Any) -> None:\n    session = await create_session(connector=connector)\n\n    await session.close()\n    assert session.connector is None\n    await session.close()\n    assert session.closed\n    assert connector.closed\n\n\nasync def test_del(connector: Any, loop: Any) -> None:\n    loop.set_debug(False)\n    # N.B. don't use session fixture, it stores extra reference internally\n    session = ClientSession(connector=connector)\n    logs = []\n    loop.set_exception_handler(lambda loop, ctx: logs.append(ctx))\n\n    with pytest.warns(ResourceWarning):\n        del session\n        gc.collect()\n\n    assert len(logs) == 1\n    expected = {\"client_session\": mock.ANY, \"message\": \"Unclosed client session\"}\n    assert logs[0] == expected\n\n\nasync def test_del_debug(connector: Any, loop: Any) -> None:\n    loop.set_debug(True)\n    # N.B. don't use session fixture, it stores extra reference internally\n    session = ClientSession(connector=connector)\n    logs = []\n    loop.set_exception_handler(lambda loop, ctx: logs.append(ctx))\n\n    with pytest.warns(ResourceWarning):\n        del session\n        gc.collect()\n\n    assert len(logs) == 1\n    expected = {\n        \"client_session\": mock.ANY,\n        \"message\": \"Unclosed client session\",\n        \"source_traceback\": mock.ANY,\n    }\n    assert logs[0] == expected\n\n\nasync def test_borrow_connector_loop(\n    connector: Any, create_session: Any, loop: Any\n) -> None:\n    session = ClientSession(connector=connector)\n    try:\n        assert session._loop, loop\n    finally:\n        await session.close()\n\n\nasync def test_reraise_os_error(create_session: Any, create_mocked_conn: Any) -> None:\n    err = OSError(1, \"permission error\")\n    req = mock.Mock()\n    req_factory = mock.Mock(return_value=req)\n    req.send = mock.Mock(side_effect=err)\n    session = await create_session(request_class=req_factory)\n\n    async def create_connection(req, traces, timeout):\n        # return self.transport, self.protocol\n        return create_mocked_conn()\n\n    session._connector._create_connection = create_connection\n    session._connector._release = mock.Mock()\n\n    with pytest.raises(aiohttp.ClientOSError) as ctx:\n        await session.request(\"get\", \"http://example.com\")\n    e = ctx.value\n    assert e.errno == err.errno\n    assert e.strerror == err.strerror\n\n\nasync def test_close_conn_on_error(\n    create_session: Any, create_mocked_conn: Any\n) -> None:\n    class UnexpectedException(BaseException):\n        pass\n\n    err = UnexpectedException(\"permission error\")\n    req = mock.Mock()\n    req_factory = mock.Mock(return_value=req)\n    req.send = mock.Mock(side_effect=err)\n    session = await create_session(request_class=req_factory)\n\n    connections = []\n    original_connect = session._connector.connect\n\n    async def connect(req, traces, timeout):\n        conn = await original_connect(req, traces, timeout)\n        connections.append(conn)\n        return conn\n\n    async def create_connection(req, traces, timeout):\n        # return self.transport, self.protocol\n        conn = create_mocked_conn()\n        return conn\n\n    session._connector.connect = connect\n    session._connector._create_connection = create_connection\n    session._connector._release = mock.Mock()\n\n    with pytest.raises(UnexpectedException):\n        async with session.request(\"get\", \"http://example.com\") as resp:\n            await resp.text()\n\n    # normally called during garbage collection.  triggers an exception\n    # if the connection wasn't already closed\n    for c in connections:\n        c.__del__()\n\n\nasync def test_cookie_jar_usage(loop: Any, aiohttp_client: Any) -> None:\n    req_url = None\n\n    jar = mock.Mock()\n    jar.filter_cookies.return_value = None\n\n    async def handler(request):\n        nonlocal req_url\n        req_url = \"http://%s/\" % request.host\n\n        resp = web.Response()\n        resp.set_cookie(\"response\", \"resp_value\")\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    session = await aiohttp_client(\n        app, cookies={\"request\": \"req_value\"}, cookie_jar=jar\n    )\n\n    # Updating the cookie jar with initial user defined cookies\n    jar.update_cookies.assert_called_with({\"request\": \"req_value\"})\n\n    jar.update_cookies.reset_mock()\n    resp = await session.get(\"/\")\n    await resp.release()\n\n    # Filtering the cookie jar before sending the request,\n    # getting the request URL as only parameter\n    jar.filter_cookies.assert_called_with(URL(req_url))\n\n    # Updating the cookie jar with the response cookies\n    assert jar.update_cookies.called\n    resp_cookies = jar.update_cookies.call_args[0][0]\n    assert isinstance(resp_cookies, SimpleCookie)\n    assert \"response\" in resp_cookies\n    assert resp_cookies[\"response\"].value == \"resp_value\"\n\n\nasync def test_session_default_version(loop: Any) -> None:\n    session = aiohttp.ClientSession()\n    assert session.version == aiohttp.HttpVersion11\n    await session.close()\n\n\ndef test_proxy_str(session: Any, params: Any) -> None:\n    with mock.patch(\n        \"aiohttp.client.ClientSession._request\", new_callable=mock.MagicMock\n    ) as patched:\n        session.get(\"http://test.example.com\", proxy=\"http://proxy.com\", **params)\n    assert patched.called, \"`ClientSession._request` not called\"\n    assert list(patched.call_args) == [\n        (\n            \"GET\",\n            \"http://test.example.com\",\n        ),\n        dict(allow_redirects=True, proxy=\"http://proxy.com\", **params),\n    ]\n\n\nasync def test_request_tracing(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.json_response({\"ok\": True})\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n\n    trace_config_ctx = mock.Mock()\n    trace_request_ctx = {}\n    body = \"This is request body\"\n    gathered_req_headers = CIMultiDict()\n    on_request_start = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_request_redirect = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_request_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n\n    with io.BytesIO() as gathered_req_body, io.BytesIO() as gathered_res_body:\n\n        async def on_request_chunk_sent(session, context, params):\n            gathered_req_body.write(params.chunk)\n\n        async def on_response_chunk_received(session, context, params):\n            gathered_res_body.write(params.chunk)\n\n        async def on_request_headers_sent(session, context, params):\n            gathered_req_headers.extend(**params.headers)\n\n        trace_config = aiohttp.TraceConfig(\n            trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)\n        )\n        trace_config.on_request_start.append(on_request_start)\n        trace_config.on_request_end.append(on_request_end)\n        trace_config.on_request_chunk_sent.append(on_request_chunk_sent)\n        trace_config.on_response_chunk_received.append(on_response_chunk_received)\n        trace_config.on_request_redirect.append(on_request_redirect)\n        trace_config.on_request_headers_sent.append(on_request_headers_sent)\n\n        headers = CIMultiDict({\"Custom-Header\": \"Custom value\"})\n        session = await aiohttp_client(\n            app, trace_configs=[trace_config], headers=headers\n        )\n\n        async with session.post(\n            \"/\", data=body, trace_request_ctx=trace_request_ctx\n        ) as resp:\n            await resp.json()\n\n            on_request_start.assert_called_once_with(\n                session.session,\n                trace_config_ctx,\n                aiohttp.TraceRequestStartParams(\n                    hdrs.METH_POST, session.make_url(\"/\"), headers\n                ),\n            )\n\n            on_request_end.assert_called_once_with(\n                session.session,\n                trace_config_ctx,\n                aiohttp.TraceRequestEndParams(\n                    hdrs.METH_POST, session.make_url(\"/\"), headers, resp\n                ),\n            )\n            assert not on_request_redirect.called\n            assert gathered_req_body.getvalue() == body.encode(\"utf8\")\n            assert gathered_res_body.getvalue() == json.dumps({\"ok\": True}).encode(\n                \"utf8\"\n            )\n            assert gathered_req_headers[\"Custom-Header\"] == \"Custom value\"\n\n\nasync def test_request_tracing_url_params(loop: Any, aiohttp_client: Any) -> None:\n    async def root_handler(request):\n        return web.Response()\n\n    async def redirect_handler(request):\n        raise web.HTTPFound(\"/\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", root_handler)\n    app.router.add_get(\"/redirect\", redirect_handler)\n\n    mocks = [mock.Mock(side_effect=make_mocked_coro(mock.Mock())) for _ in range(7)]\n    (\n        on_request_start,\n        on_request_redirect,\n        on_request_end,\n        on_request_exception,\n        on_request_chunk_sent,\n        on_response_chunk_received,\n        on_request_headers_sent,\n    ) = mocks\n\n    trace_config = aiohttp.TraceConfig(\n        trace_config_ctx_factory=mock.Mock(return_value=mock.Mock())\n    )\n    trace_config.on_request_start.append(on_request_start)\n    trace_config.on_request_redirect.append(on_request_redirect)\n    trace_config.on_request_end.append(on_request_end)\n    trace_config.on_request_exception.append(on_request_exception)\n    trace_config.on_request_chunk_sent.append(on_request_chunk_sent)\n    trace_config.on_response_chunk_received.append(on_response_chunk_received)\n    trace_config.on_request_headers_sent.append(on_request_headers_sent)\n\n    session = await aiohttp_client(app, trace_configs=[trace_config])\n\n    def reset_mocks() -> None:\n        for m in mocks:\n            m.reset_mock()\n\n    def to_trace_urls(mock_func: mock.Mock) -> List[URL]:\n        return [call_args[0][-1].url for call_args in mock_func.call_args_list]\n\n    def to_url(path: str) -> URL:\n        return session.make_url(path)\n\n    # Standard\n    for req in [\n        lambda: session.get(\"/?x=0\"),\n        lambda: session.get(\"/\", params=dict(x=0)),\n    ]:\n        reset_mocks()\n        async with req() as resp:\n            await resp.text()\n            assert to_trace_urls(on_request_start) == [to_url(\"/?x=0\")]\n            assert to_trace_urls(on_request_redirect) == []\n            assert to_trace_urls(on_request_end) == [to_url(\"/?x=0\")]\n            assert to_trace_urls(on_request_exception) == []\n            assert to_trace_urls(on_request_chunk_sent) == [to_url(\"/?x=0\")]\n            assert to_trace_urls(on_response_chunk_received) == [to_url(\"/?x=0\")]\n            assert to_trace_urls(on_request_headers_sent) == [to_url(\"/?x=0\")]\n\n    # Redirect\n    for req in [\n        lambda: session.get(\"/redirect?x=0\"),\n        lambda: session.get(\"/redirect\", params=dict(x=0)),\n    ]:\n        reset_mocks()\n        async with req() as resp:\n            await resp.text()\n            assert to_trace_urls(on_request_start) == [to_url(\"/redirect?x=0\")]\n            assert to_trace_urls(on_request_redirect) == [to_url(\"/redirect?x=0\")]\n            assert to_trace_urls(on_request_end) == [to_url(\"/\")]\n            assert to_trace_urls(on_request_exception) == []\n            assert to_trace_urls(on_request_chunk_sent) == [\n                to_url(\"/redirect?x=0\"),\n                to_url(\"/\"),\n            ]\n            assert to_trace_urls(on_response_chunk_received) == [to_url(\"/\")]\n            assert to_trace_urls(on_request_headers_sent) == [\n                to_url(\"/redirect?x=0\"),\n                to_url(\"/\"),\n            ]\n\n    # Exception\n    with mock.patch(\"aiohttp.client.TCPConnector.connect\") as connect_patched:\n        connect_patched.side_effect = Exception()\n\n        for req in [\n            lambda: session.get(\"/?x=0\"),\n            lambda: session.get(\"/\", params=dict(x=0)),\n        ]:\n            reset_mocks()\n            with contextlib.suppress(Exception):\n                await req()\n            assert to_trace_urls(on_request_start) == [to_url(\"/?x=0\")]\n            assert to_trace_urls(on_request_redirect) == []\n            assert to_trace_urls(on_request_end) == []\n            assert to_trace_urls(on_request_exception) == [to_url(\"?x=0\")]\n            assert to_trace_urls(on_request_chunk_sent) == []\n            assert to_trace_urls(on_response_chunk_received) == []\n            assert to_trace_urls(on_request_headers_sent) == []\n\n\nasync def test_request_tracing_exception() -> None:\n    on_request_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_request_exception = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n\n    trace_config = aiohttp.TraceConfig()\n    trace_config.on_request_end.append(on_request_end)\n    trace_config.on_request_exception.append(on_request_exception)\n\n    with mock.patch(\"aiohttp.client.TCPConnector.connect\") as connect_patched:\n        error = Exception()\n        connect_patched.side_effect = error\n\n        session = aiohttp.ClientSession(trace_configs=[trace_config])\n\n        try:\n            await session.get(\"http://example.com\")\n        except Exception:\n            pass\n\n        on_request_exception.assert_called_once_with(\n            session,\n            mock.ANY,\n            aiohttp.TraceRequestExceptionParams(\n                hdrs.METH_GET, URL(\"http://example.com\"), CIMultiDict(), error\n            ),\n        )\n        assert not on_request_end.called\n\n    await session.close()\n\n\nasync def test_request_tracing_interpose_headers(\n    loop: Any, aiohttp_client: Any\n) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    class MyClientRequest(ClientRequest):\n        headers = None\n\n        def __init__(self, *args, **kwargs):\n            super().__init__(*args, **kwargs)\n            MyClientRequest.headers = self.headers\n\n    async def new_headers(session, trace_config_ctx, data):\n        data.headers[\"foo\"] = \"bar\"\n\n    trace_config = aiohttp.TraceConfig()\n    trace_config.on_request_start.append(new_headers)\n\n    session = await aiohttp_client(\n        app, request_class=MyClientRequest, trace_configs=[trace_config]\n    )\n\n    await session.get(\"/\")\n    assert MyClientRequest.headers[\"foo\"] == \"bar\"\n\n\ndef test_client_session_inheritance() -> None:\n    with pytest.raises(TypeError):\n\n        class A(ClientSession):\n            pass\n\n\nasync def test_client_session_custom_attr() -> None:\n    session = ClientSession()\n    with pytest.raises(AttributeError):\n        session.custom = None\n    await session.close()\n\n\nasync def test_client_session_timeout_default_args(loop: Any) -> None:\n    session1 = ClientSession()\n    assert session1.timeout == client.DEFAULT_TIMEOUT\n    await session1.close()\n\n\nasync def test_client_session_timeout_zero() -> None:\n    timeout = client.ClientTimeout(total=10, connect=0, sock_connect=0, sock_read=0)\n    try:\n        async with ClientSession(timeout=timeout) as session:\n            await session.get(\"http://example.com\")\n    except asyncio.TimeoutError:\n        pytest.fail(\"0 should disable timeout.\")\n\n\nasync def test_client_session_timeout_bad_argument() -> None:\n    with pytest.raises(ValueError):\n        ClientSession(timeout=\"test_bad_argumnet\")\n    with pytest.raises(ValueError):\n        ClientSession(timeout=100)\n\n\nasync def test_requote_redirect_url_default() -> None:\n    session = ClientSession()\n    assert session.requote_redirect_url\n    await session.close()\n\n\nasync def test_requote_redirect_url_default_disable() -> None:\n    session = ClientSession(requote_redirect_url=False)\n    assert not session.requote_redirect_url\n    await session.close()\n\n\n@pytest.mark.parametrize(\n    (\"base_url\", \"url\", \"expected_url\"),\n    [\n        pytest.param(\n            None,\n            \"http://example.com/test\",\n            URL(\"http://example.com/test\"),\n            id=\"base_url=None url='http://example.com/test'\",\n        ),\n        pytest.param(\n            None,\n            URL(\"http://example.com/test\"),\n            URL(\"http://example.com/test\"),\n            id=\"base_url=None url=URL('http://example.com/test')\",\n        ),\n        pytest.param(\n            \"http://example.com\",\n            \"/test\",\n            URL(\"http://example.com/test\"),\n            id=\"base_url='http://example.com' url='/test'\",\n        ),\n        pytest.param(\n            URL(\"http://example.com\"),\n            \"/test\",\n            URL(\"http://example.com/test\"),\n            id=\"base_url=URL('http://example.com') url='/test'\",\n        ),\n    ],\n)\nasync def test_build_url_returns_expected_url(\n    create_session, base_url, url, expected_url\n) -> None:\n    session = await create_session(base_url)\n    assert session._build_url(url) == expected_url\n\n\nasync def test_instantiation_with_invalid_timeout_value(loop):\n    loop.set_debug(False)\n    logs = []\n    loop.set_exception_handler(lambda loop, ctx: logs.append(ctx))\n    with pytest.raises(ValueError, match=\"timeout parameter cannot be .*\"):\n        ClientSession(timeout=1)\n    # should not have \"Unclosed client session\" warning\n    assert not logs\n\n\n@pytest.mark.parametrize(\n    (\"outer_name\", \"inner_name\"),\n    [\n        (\"skip_auto_headers\", \"_skip_auto_headers\"),\n        (\"auth\", \"_default_auth\"),\n        (\"json_serialize\", \"_json_serialize\"),\n        (\"connector_owner\", \"_connector_owner\"),\n        (\"raise_for_status\", \"_raise_for_status\"),\n        (\"trust_env\", \"_trust_env\"),\n        (\"trace_configs\", \"_trace_configs\"),\n    ],\n)\nasync def test_properties(\n    session: ClientSession, outer_name: str, inner_name: str\n) -> None:\n    value = uuid4()\n    setattr(session, inner_name, value)\n    assert value == getattr(session, outer_name)\n", "tests/test_cookiejar.py": "# type: ignore\nimport asyncio\nimport datetime\nimport itertools\nimport pathlib\nimport pickle\nimport unittest\nfrom http.cookies import BaseCookie, Morsel, SimpleCookie\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\nfrom freezegun import freeze_time\nfrom yarl import URL\n\nfrom aiohttp import CookieJar, DummyCookieJar\n\n\ndef dump_cookiejar() -> bytes:  # pragma: no cover\n    \"\"\"Create pickled data for test_pickle_format().\"\"\"\n    cj = CookieJar()\n    cj.update_cookies(cookies_to_send.__pytest_wrapped__.obj())\n    return pickle.dumps(cj._cookies, pickle.HIGHEST_PROTOCOL)\n\n\n@pytest.fixture\ndef cookies_to_send():\n    return SimpleCookie(\n        \"shared-cookie=first; \"\n        \"domain-cookie=second; Domain=example.com; \"\n        \"subdomain1-cookie=third; Domain=test1.example.com; \"\n        \"subdomain2-cookie=fourth; Domain=test2.example.com; \"\n        \"dotted-domain-cookie=fifth; Domain=.example.com; \"\n        \"different-domain-cookie=sixth; Domain=different.org; \"\n        \"secure-cookie=seventh; Domain=secure.com; Secure; \"\n        \"no-path-cookie=eighth; Domain=pathtest.com; \"\n        \"path1-cookie=ninth; Domain=pathtest.com; Path=/; \"\n        \"path2-cookie=tenth; Domain=pathtest.com; Path=/one; \"\n        \"path3-cookie=eleventh; Domain=pathtest.com; Path=/one/two; \"\n        \"path4-cookie=twelfth; Domain=pathtest.com; Path=/one/two/; \"\n        \"expires-cookie=thirteenth; Domain=expirestest.com; Path=/;\"\n        \" Expires=Tue, 1 Jan 2999 12:00:00 GMT; \"\n        \"max-age-cookie=fourteenth; Domain=maxagetest.com; Path=/;\"\n        \" Max-Age=60; \"\n        \"invalid-max-age-cookie=fifteenth; Domain=invalid-values.com; \"\n        \" Max-Age=string; \"\n        \"invalid-expires-cookie=sixteenth; Domain=invalid-values.com; \"\n        \" Expires=string;\"\n    )\n\n\n@pytest.fixture\ndef cookies_to_send_with_expired():\n    return SimpleCookie(\n        \"shared-cookie=first; \"\n        \"domain-cookie=second; Domain=example.com; \"\n        \"subdomain1-cookie=third; Domain=test1.example.com; \"\n        \"subdomain2-cookie=fourth; Domain=test2.example.com; \"\n        \"dotted-domain-cookie=fifth; Domain=.example.com; \"\n        \"different-domain-cookie=sixth; Domain=different.org; \"\n        \"secure-cookie=seventh; Domain=secure.com; Secure; \"\n        \"no-path-cookie=eighth; Domain=pathtest.com; \"\n        \"path1-cookie=ninth; Domain=pathtest.com; Path=/; \"\n        \"path2-cookie=tenth; Domain=pathtest.com; Path=/one; \"\n        \"path3-cookie=eleventh; Domain=pathtest.com; Path=/one/two; \"\n        \"path4-cookie=twelfth; Domain=pathtest.com; Path=/one/two/; \"\n        \"expires-cookie=thirteenth; Domain=expirestest.com; Path=/;\"\n        \" Expires=Tue, 1 Jan 1980 12:00:00 GMT; \"\n        \"max-age-cookie=fourteenth; Domain=maxagetest.com; Path=/;\"\n        \" Max-Age=60; \"\n        \"invalid-max-age-cookie=fifteenth; Domain=invalid-values.com; \"\n        \" Max-Age=string; \"\n        \"invalid-expires-cookie=sixteenth; Domain=invalid-values.com; \"\n        \" Expires=string;\"\n    )\n\n\n@pytest.fixture\ndef cookies_to_receive():\n    return SimpleCookie(\n        \"unconstrained-cookie=first; Path=/; \"\n        \"domain-cookie=second; Domain=example.com; Path=/; \"\n        \"subdomain1-cookie=third; Domain=test1.example.com; Path=/; \"\n        \"subdomain2-cookie=fourth; Domain=test2.example.com; Path=/; \"\n        \"dotted-domain-cookie=fifth; Domain=.example.com; Path=/; \"\n        \"different-domain-cookie=sixth; Domain=different.org; Path=/; \"\n        \"no-path-cookie=seventh; Domain=pathtest.com; \"\n        \"path-cookie=eighth; Domain=pathtest.com; Path=/somepath; \"\n        \"wrong-path-cookie=ninth; Domain=pathtest.com; Path=somepath;\"\n    )\n\n\ndef test_date_parsing() -> None:\n    parse_func = CookieJar._parse_date\n    utc = datetime.timezone.utc\n\n    assert parse_func(\"\") is None\n\n    # 70 -> 1970\n    assert (\n        parse_func(\"Tue, 1 Jan 70 00:00:00 GMT\")\n        == datetime.datetime(1970, 1, 1, tzinfo=utc).timestamp()\n    )\n\n    # 10 -> 2010\n    assert (\n        parse_func(\"Tue, 1 Jan 10 00:00:00 GMT\")\n        == datetime.datetime(2010, 1, 1, tzinfo=utc).timestamp()\n    )\n\n    # No day of week string\n    assert (\n        parse_func(\"1 Jan 1970 00:00:00 GMT\")\n        == datetime.datetime(1970, 1, 1, tzinfo=utc).timestamp()\n    )\n\n    # No timezone string\n    assert (\n        parse_func(\"Tue, 1 Jan 1970 00:00:00\")\n        == datetime.datetime(1970, 1, 1, tzinfo=utc).timestamp()\n    )\n\n    # No year\n    assert parse_func(\"Tue, 1 Jan 00:00:00 GMT\") is None\n\n    # No month\n    assert parse_func(\"Tue, 1 1970 00:00:00 GMT\") is None\n\n    # No day of month\n    assert parse_func(\"Tue, Jan 1970 00:00:00 GMT\") is None\n\n    # No time\n    assert parse_func(\"Tue, 1 Jan 1970 GMT\") is None\n\n    # Invalid day of month\n    assert parse_func(\"Tue, 0 Jan 1970 00:00:00 GMT\") is None\n\n    # Invalid year\n    assert parse_func(\"Tue, 1 Jan 1500 00:00:00 GMT\") is None\n\n    # Invalid time\n    assert parse_func(\"Tue, 1 Jan 1970 77:88:99 GMT\") is None\n\n\ndef test_domain_matching() -> None:\n    test_func = CookieJar._is_domain_match\n\n    assert test_func(\"test.com\", \"test.com\")\n    assert test_func(\"test.com\", \"sub.test.com\")\n\n    assert not test_func(\"test.com\", \"\")\n    assert not test_func(\"test.com\", \"test.org\")\n    assert not test_func(\"diff-test.com\", \"test.com\")\n    assert not test_func(\"test.com\", \"diff-test.com\")\n    assert not test_func(\"test.com\", \"127.0.0.1\")\n\n\nasync def test_constructor(cookies_to_send: Any, cookies_to_receive: Any) -> None:\n    jar = CookieJar()\n    jar.update_cookies(cookies_to_send)\n    jar_cookies = SimpleCookie()\n    for cookie in jar:\n        dict.__setitem__(jar_cookies, cookie.key, cookie)\n    expected_cookies = cookies_to_send\n    assert jar_cookies == expected_cookies\n\n\nasync def test_constructor_with_expired(\n    cookies_to_send_with_expired: Any, cookies_to_receive: Any\n) -> None:\n    jar = CookieJar()\n    jar.update_cookies(cookies_to_send_with_expired)\n    jar_cookies = SimpleCookie()\n    for cookie in jar:\n        dict.__setitem__(jar_cookies, cookie.key, cookie)\n    expected_cookies = cookies_to_send_with_expired\n    assert jar_cookies != expected_cookies\n\n\nasync def test_save_load(\n    tmp_path: Any, loop: Any, cookies_to_send: Any, cookies_to_receive: Any\n) -> None:\n    file_path = pathlib.Path(str(tmp_path)) / \"aiohttp.test.cookie\"\n\n    # export cookie jar\n    jar_save = CookieJar()\n    jar_save.update_cookies(cookies_to_receive)\n    jar_save.save(file_path=file_path)\n\n    jar_load = CookieJar()\n    jar_load.load(file_path=file_path)\n\n    jar_test = SimpleCookie()\n    for cookie in jar_load:\n        jar_test[cookie.key] = cookie\n\n    assert jar_test == cookies_to_receive\n\n\nasync def test_update_cookie_with_unicode_domain(loop: Any) -> None:\n    cookies = (\n        \"idna-domain-first=first; Domain=xn--9caa.com; Path=/;\",\n        \"idna-domain-second=second; Domain=xn--9caa.com; Path=/;\",\n    )\n\n    jar = CookieJar()\n    jar.update_cookies(SimpleCookie(cookies[0]), URL(\"http://\u00e9\u00e9.com/\"))\n    jar.update_cookies(SimpleCookie(cookies[1]), URL(\"http://xn--9caa.com/\"))\n\n    jar_test = SimpleCookie()\n    for cookie in jar:\n        jar_test[cookie.key] = cookie\n\n    assert jar_test == SimpleCookie(\" \".join(cookies))\n\n\nasync def test_filter_cookie_with_unicode_domain(loop: Any) -> None:\n    jar = CookieJar()\n    jar.update_cookies(\n        SimpleCookie(\"idna-domain-first=first; Domain=xn--9caa.com; Path=/; \")\n    )\n    assert len(jar.filter_cookies(URL(\"http://\u00e9\u00e9.com\"))) == 1\n    assert len(jar.filter_cookies(URL(\"http://xn--9caa.com\"))) == 1\n\n\nasync def test_filter_cookies_str_deprecated(loop: Any) -> None:\n    jar = CookieJar()\n    with pytest.deprecated_call(\n        match=\"The method accepts yarl.URL instances only, got <class 'str'>\",\n    ):\n        jar.filter_cookies(\"http://\u00e9\u00e9.com\")\n\n\n@pytest.mark.parametrize(\n    (\"url\", \"expected_cookies\"),\n    (\n        (\n            \"http://pathtest.com/one/two/\",\n            (\n                \"no-path-cookie\",\n                \"path1-cookie\",\n                \"path2-cookie\",\n                \"shared-cookie\",\n                \"path3-cookie\",\n                \"path4-cookie\",\n            ),\n        ),\n        (\n            \"http://pathtest.com/one/two\",\n            (\n                \"no-path-cookie\",\n                \"path1-cookie\",\n                \"path2-cookie\",\n                \"shared-cookie\",\n                \"path3-cookie\",\n            ),\n        ),\n        (\n            \"http://pathtest.com/one/two/three/\",\n            (\n                \"no-path-cookie\",\n                \"path1-cookie\",\n                \"path2-cookie\",\n                \"shared-cookie\",\n                \"path3-cookie\",\n                \"path4-cookie\",\n            ),\n        ),\n        (\n            \"http://test1.example.com/\",\n            (\n                \"shared-cookie\",\n                \"domain-cookie\",\n                \"subdomain1-cookie\",\n                \"dotted-domain-cookie\",\n            ),\n        ),\n        (\n            \"http://pathtest.com/\",\n            (\n                \"shared-cookie\",\n                \"no-path-cookie\",\n                \"path1-cookie\",\n            ),\n        ),\n    ),\n)\nasync def test_filter_cookies_with_domain_path_lookup_multilevelpath(\n    loop: Any,\n    url: Any,\n    expected_cookies: Any,\n) -> None:\n    jar = CookieJar()\n    cookies = SimpleCookie(\n        \"shared-cookie=first; \"\n        \"domain-cookie=second; Domain=example.com; \"\n        \"subdomain1-cookie=third; Domain=test1.example.com; \"\n        \"subdomain2-cookie=fourth; Domain=test2.example.com; \"\n        \"dotted-domain-cookie=fifth; Domain=.example.com; \"\n        \"different-domain-cookie=sixth; Domain=different.org; \"\n        \"secure-cookie=seventh; Domain=secure.com; Secure; \"\n        \"no-path-cookie=eighth; Domain=pathtest.com; \"\n        \"path1-cookie=ninth; Domain=pathtest.com; Path=/; \"\n        \"path2-cookie=tenth; Domain=pathtest.com; Path=/one; \"\n        \"path3-cookie=eleventh; Domain=pathtest.com; Path=/one/two; \"\n        \"path4-cookie=twelfth; Domain=pathtest.com; Path=/one/two/; \"\n        \"expires-cookie=thirteenth; Domain=expirestest.com; Path=/;\"\n        \" Expires=Tue, 1 Jan 1980 12:00:00 GMT; \"\n        \"max-age-cookie=fourteenth; Domain=maxagetest.com; Path=/;\"\n        \" Max-Age=60; \"\n        \"invalid-max-age-cookie=fifteenth; Domain=invalid-values.com; \"\n        \" Max-Age=string; \"\n        \"invalid-expires-cookie=sixteenth; Domain=invalid-values.com; \"\n        \" Expires=string;\"\n    )\n    jar.update_cookies(cookies)\n    cookies = jar.filter_cookies(URL(url))\n\n    assert len(cookies) == len(expected_cookies)\n    for c in cookies:\n        assert c in expected_cookies\n\n\nasync def test_domain_filter_ip_cookie_send(loop: Any) -> None:\n    jar = CookieJar()\n    cookies = SimpleCookie(\n        \"shared-cookie=first; \"\n        \"domain-cookie=second; Domain=example.com; \"\n        \"subdomain1-cookie=third; Domain=test1.example.com; \"\n        \"subdomain2-cookie=fourth; Domain=test2.example.com; \"\n        \"dotted-domain-cookie=fifth; Domain=.example.com; \"\n        \"different-domain-cookie=sixth; Domain=different.org; \"\n        \"secure-cookie=seventh; Domain=secure.com; Secure; \"\n        \"no-path-cookie=eighth; Domain=pathtest.com; \"\n        \"path1-cookie=ninth; Domain=pathtest.com; Path=/; \"\n        \"path2-cookie=tenth; Domain=pathtest.com; Path=/one; \"\n        \"path3-cookie=eleventh; Domain=pathtest.com; Path=/one/two; \"\n        \"path4-cookie=twelfth; Domain=pathtest.com; Path=/one/two/; \"\n        \"expires-cookie=thirteenth; Domain=expirestest.com; Path=/;\"\n        \" Expires=Tue, 1 Jan 1980 12:00:00 GMT; \"\n        \"max-age-cookie=fourteenth; Domain=maxagetest.com; Path=/;\"\n        \" Max-Age=60; \"\n        \"invalid-max-age-cookie=fifteenth; Domain=invalid-values.com; \"\n        \" Max-Age=string; \"\n        \"invalid-expires-cookie=sixteenth; Domain=invalid-values.com; \"\n        \" Expires=string;\"\n    )\n\n    jar.update_cookies(cookies)\n    cookies_sent = jar.filter_cookies(URL(\"http://1.2.3.4/\")).output(header=\"Cookie:\")\n    assert cookies_sent == \"Cookie: shared-cookie=first\"\n\n\nasync def test_domain_filter_ip_cookie_receive(cookies_to_receive: Any) -> None:\n    jar = CookieJar()\n\n    jar.update_cookies(cookies_to_receive, URL(\"http://1.2.3.4/\"))\n    assert len(jar) == 0\n\n\n@pytest.mark.parametrize(\n    (\"cookies\", \"expected\", \"quote_bool\"),\n    [\n        (\n            \"shared-cookie=first; ip-cookie=second; Domain=127.0.0.1;\",\n            \"Cookie: ip-cookie=second\\r\\nCookie: shared-cookie=first\",\n            True,\n        ),\n        ('ip-cookie=\"second\"; Domain=127.0.0.1;', 'Cookie: ip-cookie=\"second\"', True),\n        (\"custom-cookie=value/one;\", 'Cookie: custom-cookie=\"value/one\"', True),\n        (\"custom-cookie=value1;\", \"Cookie: custom-cookie=value1\", True),\n        (\"custom-cookie=value/one;\", \"Cookie: custom-cookie=value/one\", False),\n    ],\n    ids=(\n        \"IP domain preserved\",\n        \"no shared cookie\",\n        \"quoted cookie with special char\",\n        \"quoted cookie w/o special char\",\n        \"unquoted cookie with special char\",\n    ),\n)\nasync def test_quotes_correctly_based_on_input(\n    loop: Any, cookies: Any, expected: Any, quote_bool: Any\n) -> None:\n    jar = CookieJar(unsafe=True, quote_cookie=quote_bool)\n    jar.update_cookies(SimpleCookie(cookies))\n    cookies_sent = jar.filter_cookies(URL(\"http://127.0.0.1/\")).output(header=\"Cookie:\")\n    assert cookies_sent == expected\n\n\nasync def test_ignore_domain_ending_with_dot(loop: Any) -> None:\n    jar = CookieJar(unsafe=True)\n    jar.update_cookies(\n        SimpleCookie(\"cookie=val; Domain=example.com.;\"), URL(\"http://www.example.com\")\n    )\n    cookies_sent = jar.filter_cookies(URL(\"http://www.example.com/\"))\n    assert cookies_sent.output(header=\"Cookie:\") == \"Cookie: cookie=val\"\n    cookies_sent = jar.filter_cookies(URL(\"http://example.com/\"))\n    assert cookies_sent.output(header=\"Cookie:\") == \"\"\n\n\nclass TestCookieJarBase(unittest.TestCase):\n    loop: Any\n    jar: Any\n\n    def setUp(self):\n        self.loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(None)\n\n        # N.B. those need to be overridden in child test cases\n        async def make_jar():\n            return CookieJar()\n\n        self.jar = self.loop.run_until_complete(make_jar())\n\n    def tearDown(self) -> None:\n        self.loop.close()\n\n    def request_reply_with_same_url(self, url: Any):\n        self.jar.update_cookies(self.cookies_to_send)\n        cookies_sent = self.jar.filter_cookies(URL(url))\n\n        self.jar.clear()\n\n        self.jar.update_cookies(self.cookies_to_receive, URL(url))\n        cookies_received = SimpleCookie()\n        for cookie in self.jar:\n            dict.__setitem__(cookies_received, cookie.key, cookie)\n\n        self.jar.clear()\n\n        return cookies_sent, cookies_received\n\n\nclass TestCookieJarSafe(TestCookieJarBase):\n    cookies_to_send: Any\n    cookies_to_receive: Any\n    jar: Any\n\n    def setUp(self):\n        super().setUp()\n\n        self.cookies_to_send = SimpleCookie(\n            \"shared-cookie=first; \"\n            \"domain-cookie=second; Domain=example.com; \"\n            \"subdomain1-cookie=third; Domain=test1.example.com; \"\n            \"subdomain2-cookie=fourth; Domain=test2.example.com; \"\n            \"dotted-domain-cookie=fifth; Domain=.example.com; \"\n            \"different-domain-cookie=sixth; Domain=different.org; \"\n            \"secure-cookie=seventh; Domain=secure.com; Secure; \"\n            \"no-path-cookie=eighth; Domain=pathtest.com; \"\n            \"path1-cookie=ninth; Domain=pathtest.com; Path=/; \"\n            \"path2-cookie=tenth; Domain=pathtest.com; Path=/one; \"\n            \"path3-cookie=eleventh; Domain=pathtest.com; Path=/one/two; \"\n            \"path4-cookie=twelfth; Domain=pathtest.com; Path=/one/two/; \"\n            \"expires-cookie=thirteenth; Domain=expirestest.com; Path=/;\"\n            \" Expires=Tue, 1 Jan 1980 12:00:00 GMT; \"\n            \"max-age-cookie=fourteenth; Domain=maxagetest.com; Path=/;\"\n            \" Max-Age=60; \"\n            \"invalid-max-age-cookie=fifteenth; Domain=invalid-values.com; \"\n            \" Max-Age=string; \"\n            \"invalid-expires-cookie=sixteenth; Domain=invalid-values.com; \"\n            \" Expires=string;\"\n        )\n\n        self.cookies_to_receive = SimpleCookie(\n            \"unconstrained-cookie=first; Path=/; \"\n            \"domain-cookie=second; Domain=example.com; Path=/; \"\n            \"subdomain1-cookie=third; Domain=test1.example.com; Path=/; \"\n            \"subdomain2-cookie=fourth; Domain=test2.example.com; Path=/; \"\n            \"dotted-domain-cookie=fifth; Domain=.example.com; Path=/; \"\n            \"different-domain-cookie=sixth; Domain=different.org; Path=/; \"\n            \"no-path-cookie=seventh; Domain=pathtest.com; \"\n            \"path-cookie=eighth; Domain=pathtest.com; Path=/somepath; \"\n            \"wrong-path-cookie=ninth; Domain=pathtest.com; Path=somepath;\"\n        )\n\n        async def make_jar():\n            return CookieJar()\n\n        self.jar = self.loop.run_until_complete(make_jar())\n\n    def timed_request(self, url: Any, update_time: Any, send_time: Any):\n        if isinstance(update_time, int):\n            update_time = datetime.timedelta(seconds=update_time)\n        elif isinstance(update_time, float):\n            update_time = datetime.datetime.fromtimestamp(update_time)\n        if isinstance(send_time, int):\n            send_time = datetime.timedelta(seconds=send_time)\n        elif isinstance(send_time, float):\n            send_time = datetime.datetime.fromtimestamp(send_time)\n\n        with freeze_time(update_time):\n            self.jar.update_cookies(self.cookies_to_send)\n\n        with freeze_time(send_time):\n            cookies_sent = self.jar.filter_cookies(URL(url))\n\n        self.jar.clear()\n\n        return cookies_sent\n\n    def test_domain_filter_same_host(self) -> None:\n        cookies_sent, cookies_received = self.request_reply_with_same_url(\n            \"http://example.com/\"\n        )\n\n        self.assertEqual(\n            set(cookies_sent.keys()),\n            {\"shared-cookie\", \"domain-cookie\", \"dotted-domain-cookie\"},\n        )\n\n        self.assertEqual(\n            set(cookies_received.keys()),\n            {\"unconstrained-cookie\", \"domain-cookie\", \"dotted-domain-cookie\"},\n        )\n\n    def test_domain_filter_same_host_and_subdomain(self) -> None:\n        cookies_sent, cookies_received = self.request_reply_with_same_url(\n            \"http://test1.example.com/\"\n        )\n\n        self.assertEqual(\n            set(cookies_sent.keys()),\n            {\n                \"shared-cookie\",\n                \"domain-cookie\",\n                \"subdomain1-cookie\",\n                \"dotted-domain-cookie\",\n            },\n        )\n\n        self.assertEqual(\n            set(cookies_received.keys()),\n            {\n                \"unconstrained-cookie\",\n                \"domain-cookie\",\n                \"subdomain1-cookie\",\n                \"dotted-domain-cookie\",\n            },\n        )\n\n    def test_domain_filter_same_host_diff_subdomain(self) -> None:\n        cookies_sent, cookies_received = self.request_reply_with_same_url(\n            \"http://different.example.com/\"\n        )\n\n        self.assertEqual(\n            set(cookies_sent.keys()),\n            {\"shared-cookie\", \"domain-cookie\", \"dotted-domain-cookie\"},\n        )\n\n        self.assertEqual(\n            set(cookies_received.keys()),\n            {\"unconstrained-cookie\", \"domain-cookie\", \"dotted-domain-cookie\"},\n        )\n\n    def test_domain_filter_diff_host(self) -> None:\n        cookies_sent, cookies_received = self.request_reply_with_same_url(\n            \"http://different.org/\"\n        )\n\n        self.assertEqual(\n            set(cookies_sent.keys()), {\"shared-cookie\", \"different-domain-cookie\"}\n        )\n\n        self.assertEqual(\n            set(cookies_received.keys()),\n            {\"unconstrained-cookie\", \"different-domain-cookie\"},\n        )\n\n    def test_domain_filter_host_only(self) -> None:\n        self.jar.update_cookies(self.cookies_to_receive, URL(\"http://example.com/\"))\n        sub_cookie = SimpleCookie(\"subdomain=spam; Path=/;\")\n        self.jar.update_cookies(sub_cookie, URL(\"http://foo.example.com/\"))\n\n        cookies_sent = self.jar.filter_cookies(URL(\"http://foo.example.com/\"))\n        self.assertIn(\"subdomain\", set(cookies_sent.keys()))\n        self.assertNotIn(\"unconstrained-cookie\", set(cookies_sent.keys()))\n\n    def test_secure_filter(self) -> None:\n        cookies_sent, _ = self.request_reply_with_same_url(\"http://secure.com/\")\n\n        self.assertEqual(set(cookies_sent.keys()), {\"shared-cookie\"})\n\n        cookies_sent, _ = self.request_reply_with_same_url(\"https://secure.com/\")\n\n        self.assertEqual(set(cookies_sent.keys()), {\"shared-cookie\", \"secure-cookie\"})\n\n    def test_path_filter_root(self) -> None:\n        cookies_sent, _ = self.request_reply_with_same_url(\"http://pathtest.com/\")\n\n        self.assertEqual(\n            set(cookies_sent.keys()),\n            {\"shared-cookie\", \"no-path-cookie\", \"path1-cookie\"},\n        )\n\n    def test_path_filter_folder(self) -> None:\n        cookies_sent, _ = self.request_reply_with_same_url(\"http://pathtest.com/one/\")\n\n        self.assertEqual(\n            set(cookies_sent.keys()),\n            {\"shared-cookie\", \"no-path-cookie\", \"path1-cookie\", \"path2-cookie\"},\n        )\n\n    def test_path_filter_file(self) -> None:\n        cookies_sent, _ = self.request_reply_with_same_url(\n            \"http://pathtest.com/one/two\"\n        )\n\n        self.assertEqual(\n            set(cookies_sent.keys()),\n            {\n                \"shared-cookie\",\n                \"no-path-cookie\",\n                \"path1-cookie\",\n                \"path2-cookie\",\n                \"path3-cookie\",\n            },\n        )\n\n    def test_path_filter_subfolder(self) -> None:\n        cookies_sent, _ = self.request_reply_with_same_url(\n            \"http://pathtest.com/one/two/\"\n        )\n\n        self.assertEqual(\n            set(cookies_sent.keys()),\n            {\n                \"shared-cookie\",\n                \"no-path-cookie\",\n                \"path1-cookie\",\n                \"path2-cookie\",\n                \"path3-cookie\",\n                \"path4-cookie\",\n            },\n        )\n\n    def test_path_filter_subsubfolder(self) -> None:\n        cookies_sent, _ = self.request_reply_with_same_url(\n            \"http://pathtest.com/one/two/three/\"\n        )\n\n        self.assertEqual(\n            set(cookies_sent.keys()),\n            {\n                \"shared-cookie\",\n                \"no-path-cookie\",\n                \"path1-cookie\",\n                \"path2-cookie\",\n                \"path3-cookie\",\n                \"path4-cookie\",\n            },\n        )\n\n    def test_path_filter_different_folder(self) -> None:\n        cookies_sent, _ = self.request_reply_with_same_url(\n            \"http://pathtest.com/hundred/\"\n        )\n\n        self.assertEqual(\n            set(cookies_sent.keys()),\n            {\"shared-cookie\", \"no-path-cookie\", \"path1-cookie\"},\n        )\n\n    def test_path_value(self) -> None:\n        _, cookies_received = self.request_reply_with_same_url(\"http://pathtest.com/\")\n\n        self.assertEqual(\n            set(cookies_received.keys()),\n            {\n                \"unconstrained-cookie\",\n                \"no-path-cookie\",\n                \"path-cookie\",\n                \"wrong-path-cookie\",\n            },\n        )\n\n        self.assertEqual(cookies_received[\"no-path-cookie\"][\"path\"], \"/\")\n        self.assertEqual(cookies_received[\"path-cookie\"][\"path\"], \"/somepath\")\n        self.assertEqual(cookies_received[\"wrong-path-cookie\"][\"path\"], \"/\")\n\n    def test_expires(self) -> None:\n        ts_before = datetime.datetime(\n            1975, 1, 1, tzinfo=datetime.timezone.utc\n        ).timestamp()\n\n        ts_after = datetime.datetime(\n            2030, 1, 1, tzinfo=datetime.timezone.utc\n        ).timestamp()\n\n        cookies_sent = self.timed_request(\n            \"http://expirestest.com/\", ts_before, ts_before\n        )\n\n        self.assertEqual(set(cookies_sent.keys()), {\"shared-cookie\", \"expires-cookie\"})\n\n        cookies_sent = self.timed_request(\n            \"http://expirestest.com/\", ts_before, ts_after\n        )\n\n        self.assertEqual(set(cookies_sent.keys()), {\"shared-cookie\"})\n\n    def test_max_age(self) -> None:\n        cookies_sent = self.timed_request(\"http://maxagetest.com/\", 1000, 1000)\n\n        self.assertEqual(set(cookies_sent.keys()), {\"shared-cookie\", \"max-age-cookie\"})\n\n        cookies_sent = self.timed_request(\"http://maxagetest.com/\", 1000, 2000)\n\n        self.assertEqual(set(cookies_sent.keys()), {\"shared-cookie\"})\n\n    def test_invalid_values(self) -> None:\n        cookies_sent, cookies_received = self.request_reply_with_same_url(\n            \"http://invalid-values.com/\"\n        )\n\n        self.assertEqual(\n            set(cookies_sent.keys()),\n            {\"shared-cookie\", \"invalid-max-age-cookie\", \"invalid-expires-cookie\"},\n        )\n\n        cookie = cookies_sent[\"invalid-max-age-cookie\"]\n        self.assertEqual(cookie[\"max-age\"], \"\")\n\n        cookie = cookies_sent[\"invalid-expires-cookie\"]\n        self.assertEqual(cookie[\"expires\"], \"\")\n\n    def test_cookie_not_expired_when_added_after_removal(self) -> None:\n        # Test case for https://github.com/aio-libs/aiohttp/issues/2084\n        timestamps = [\n            533588.993,\n            533588.993,\n            533588.993,\n            533588.993,\n            533589.093,\n            533589.093,\n        ]\n\n        loop = mock.Mock()\n        loop.time.side_effect = itertools.chain(\n            timestamps, itertools.cycle([timestamps[-1]])\n        )\n\n        async def make_jar():\n            return CookieJar(unsafe=True)\n\n        jar = self.loop.run_until_complete(make_jar())\n        # Remove `foo` cookie.\n        jar.update_cookies(SimpleCookie('foo=\"\"; Max-Age=0'))\n        # Set `foo` cookie to `bar`.\n        jar.update_cookies(SimpleCookie('foo=\"bar\"'))\n\n        # Assert that there is a cookie.\n        assert len(jar) == 1\n\n    def test_path_filter_diff_folder_same_name(self) -> None:\n        async def make_jar():\n            return CookieJar(unsafe=True)\n\n        jar = self.loop.run_until_complete(make_jar())\n\n        jar.update_cookies(\n            SimpleCookie(\"path-cookie=zero; Domain=pathtest.com; Path=/; \")\n        )\n        jar.update_cookies(\n            SimpleCookie(\"path-cookie=one; Domain=pathtest.com; Path=/one; \")\n        )\n        self.assertEqual(len(jar), 2)\n\n        jar_filtered = jar.filter_cookies(URL(\"http://pathtest.com/\"))\n        self.assertEqual(len(jar_filtered), 1)\n        self.assertEqual(jar_filtered[\"path-cookie\"].value, \"zero\")\n\n        jar_filtered = jar.filter_cookies(URL(\"http://pathtest.com/one\"))\n        self.assertEqual(len(jar_filtered), 1)\n        self.assertEqual(jar_filtered[\"path-cookie\"].value, \"one\")\n\n    def test_path_filter_diff_folder_same_name_return_best_match_independent_from_put_order(\n        self,\n    ) -> None:\n        async def make_jar():\n            return CookieJar(unsafe=True)\n\n        jar = self.loop.run_until_complete(make_jar())\n        jar.update_cookies(\n            SimpleCookie(\"path-cookie=one; Domain=pathtest.com; Path=/one; \")\n        )\n        jar.update_cookies(\n            SimpleCookie(\"path-cookie=zero; Domain=pathtest.com; Path=/; \")\n        )\n        jar.update_cookies(\n            SimpleCookie(\"path-cookie=two; Domain=pathtest.com; Path=/second; \")\n        )\n        self.assertEqual(len(jar), 3)\n\n        jar_filtered = jar.filter_cookies(URL(\"http://pathtest.com/\"))\n        self.assertEqual(len(jar_filtered), 1)\n        self.assertEqual(jar_filtered[\"path-cookie\"].value, \"zero\")\n\n        jar_filtered = jar.filter_cookies(URL(\"http://pathtest.com/second\"))\n        self.assertEqual(len(jar_filtered), 1)\n        self.assertEqual(jar_filtered[\"path-cookie\"].value, \"two\")\n\n        jar_filtered = jar.filter_cookies(URL(\"http://pathtest.com/one\"))\n        self.assertEqual(len(jar_filtered), 1)\n        self.assertEqual(jar_filtered[\"path-cookie\"].value, \"one\")\n\n\nasync def test_dummy_cookie_jar() -> None:\n    cookie = SimpleCookie(\"foo=bar; Domain=example.com;\")\n    dummy_jar = DummyCookieJar()\n    assert len(dummy_jar) == 0\n    dummy_jar.update_cookies(cookie)\n    assert len(dummy_jar) == 0\n    with pytest.raises(StopIteration):\n        next(iter(dummy_jar))\n    assert not dummy_jar.filter_cookies(URL(\"http://example.com/\"))\n    dummy_jar.clear()\n\n\nasync def test_loose_cookies_types() -> None:\n    jar = CookieJar()\n\n    accepted_types = [\n        [(\"str\", BaseCookie())],\n        [(\"str\", Morsel())],\n        [\n            (\"str\", \"str\"),\n        ],\n        {\"str\": BaseCookie()},\n        {\"str\": Morsel()},\n        {\"str\": \"str\"},\n        SimpleCookie(),\n    ]\n\n    for loose_cookies_type in accepted_types:\n        jar.update_cookies(cookies=loose_cookies_type)\n\n\nasync def test_cookie_jar_clear_all() -> None:\n    sut = CookieJar()\n    cookie = SimpleCookie()\n    cookie[\"foo\"] = \"bar\"\n    sut.update_cookies(cookie)\n\n    sut.clear()\n    assert len(sut) == 0\n\n\nasync def test_cookie_jar_clear_expired():\n    sut = CookieJar()\n\n    cookie = SimpleCookie()\n\n    cookie[\"foo\"] = \"bar\"\n    cookie[\"foo\"][\"expires\"] = \"Tue, 1 Jan 1990 12:00:00 GMT\"\n\n    with freeze_time(\"1980-01-01\"):\n        sut.update_cookies(cookie)\n\n    sut.clear(lambda x: False)\n    with freeze_time(\"1980-01-01\"):\n        assert len(sut) == 0\n\n\nasync def test_cookie_jar_filter_cookies_expires():\n    \"\"\"Test that calling filter_cookies will expire stale cookies.\"\"\"\n    jar = CookieJar()\n    assert len(jar) == 0\n\n    cookie = SimpleCookie()\n\n    cookie[\"foo\"] = \"bar\"\n    cookie[\"foo\"][\"expires\"] = \"Tue, 1 Jan 1990 12:00:00 GMT\"\n\n    with freeze_time(\"1980-01-01\"):\n        jar.update_cookies(cookie)\n\n    assert len(jar) == 1\n\n    # filter_cookies should expire stale cookies\n    jar.filter_cookies(URL(\"http://any.com/\"))\n\n    assert len(jar) == 0\n\n\nasync def test_cookie_jar_clear_domain() -> None:\n    sut = CookieJar()\n    cookie = SimpleCookie()\n    cookie[\"foo\"] = \"bar\"\n    cookie[\"domain_cookie\"] = \"value\"\n    cookie[\"domain_cookie\"][\"domain\"] = \"example.com\"\n    cookie[\"subdomain_cookie\"] = \"value\"\n    cookie[\"subdomain_cookie\"][\"domain\"] = \"test.example.com\"\n    sut.update_cookies(cookie)\n\n    sut.clear_domain(\"example.com\")\n    iterator = iter(sut)\n    morsel = next(iterator)\n    assert morsel.key == \"foo\"\n    assert morsel.value == \"bar\"\n    with pytest.raises(StopIteration):\n        next(iterator)\n\n\ndef test_pickle_format(cookies_to_send) -> None:\n    \"\"\"Test if cookiejar pickle format breaks.\n\n    If this test fails, it may indicate that saved cookiejars will stop working.\n    If that happens then:\n        1. Avoid releasing the change in a bugfix release.\n        2. Try to include a migration script in the release notes (example below).\n        3. Use dump_cookiejar() at the top of this file to update `pickled`.\n\n    Depending on the changes made, a migration script might look like:\n        import pickle\n        with file_path.open(\"rb\") as f:\n            cookies = pickle.load(f)\n\n        morsels = [(name, m) for c in cookies.values() for name, m in c.items()]\n        cookies.clear()\n        for name, m in morsels:\n            cookies[(m[\"domain\"], m[\"path\"])][name] = m\n\n        with file_path.open(\"wb\") as f:\n            pickle.dump(cookies, f, pickle.HIGHEST_PROTOCOL)\n    \"\"\"\n    pickled = b\"\\x80\\x04\\x95\\xc8\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x0bcollections\\x94\\x8c\\x0bdefaultdict\\x94\\x93\\x94\\x8c\\x0chttp.cookies\\x94\\x8c\\x0cSimpleCookie\\x94\\x93\\x94\\x85\\x94R\\x94(\\x8c\\x00\\x94h\\x08\\x86\\x94h\\x05)\\x81\\x94\\x8c\\rshared-cookie\\x94h\\x03\\x8c\\x06Morsel\\x94\\x93\\x94)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94\\x8c\\x01/\\x94\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94h\\x08\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(\\x8c\\x03key\\x94h\\x0b\\x8c\\x05value\\x94\\x8c\\x05first\\x94\\x8c\\x0bcoded_value\\x94h\\x1cubs\\x8c\\x0bexample.com\\x94h\\x08\\x86\\x94h\\x05)\\x81\\x94(\\x8c\\rdomain-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94h\\x1e\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah!h\\x1b\\x8c\\x06second\\x94h\\x1dh-ub\\x8c\\x14dotted-domain-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94\\x8c\\x0bexample.com\\x94\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah.h\\x1b\\x8c\\x05fifth\\x94h\\x1dh;ubu\\x8c\\x11test1.example.com\\x94h\\x08\\x86\\x94h\\x05)\\x81\\x94\\x8c\\x11subdomain1-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94h<\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah?h\\x1b\\x8c\\x05third\\x94h\\x1dhKubs\\x8c\\x11test2.example.com\\x94h\\x08\\x86\\x94h\\x05)\\x81\\x94\\x8c\\x11subdomain2-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94hL\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ahOh\\x1b\\x8c\\x06fourth\\x94h\\x1dh[ubs\\x8c\\rdifferent.org\\x94h\\x08\\x86\\x94h\\x05)\\x81\\x94\\x8c\\x17different-domain-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94h\\\\\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah_h\\x1b\\x8c\\x05sixth\\x94h\\x1dhkubs\\x8c\\nsecure.com\\x94h\\x08\\x86\\x94h\\x05)\\x81\\x94\\x8c\\rsecure-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94hl\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94\\x88\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ahoh\\x1b\\x8c\\x07seventh\\x94h\\x1dh{ubs\\x8c\\x0cpathtest.com\\x94h\\x08\\x86\\x94h\\x05)\\x81\\x94(\\x8c\\x0eno-path-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94h|\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah\\x7fh\\x1b\\x8c\\x06eighth\\x94h\\x1dh\\x8bub\\x8c\\x0cpath1-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94\\x8c\\x0cpathtest.com\\x94\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah\\x8ch\\x1b\\x8c\\x05ninth\\x94h\\x1dh\\x99ubu\\x8c\\x0cpathtest.com\\x94\\x8c\\x04/one\\x94\\x86\\x94h\\x05)\\x81\\x94\\x8c\\x0cpath2-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x9b\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94h\\x9a\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah\\x9eh\\x1b\\x8c\\x05tenth\\x94h\\x1dh\\xaaubs\\x8c\\x0cpathtest.com\\x94\\x8c\\x08/one/two\\x94\\x86\\x94h\\x05)\\x81\\x94(\\x8c\\x0cpath3-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\xac\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94h\\xab\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah\\xafh\\x1b\\x8c\\x08eleventh\\x94h\\x1dh\\xbbub\\x8c\\x0cpath4-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94\\x8c\\t/one/two/\\x94\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94\\x8c\\x0cpathtest.com\\x94\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah\\xbch\\x1b\\x8c\\x07twelfth\\x94h\\x1dh\\xcaubu\\x8c\\x0fexpirestest.com\\x94h\\x08\\x86\\x94h\\x05)\\x81\\x94\\x8c\\x0eexpires-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94\\x8c\\x1cTue, 1 Jan 2999 12:00:00 GMT\\x94\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94h\\xcb\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah\\xceh\\x1b\\x8c\\nthirteenth\\x94h\\x1dh\\xdbubs\\x8c\\x0emaxagetest.com\\x94h\\x08\\x86\\x94h\\x05)\\x81\\x94\\x8c\\x0emax-age-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94h\\xdc\\x8c\\x07max-age\\x94\\x8c\\x0260\\x94\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah\\xdfh\\x1b\\x8c\\nfourteenth\\x94h\\x1dh\\xecubs\\x8c\\x12invalid-values.com\\x94h\\x08\\x86\\x94h\\x05)\\x81\\x94(\\x8c\\x16invalid-max-age-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94h\\xed\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah\\xf0h\\x1b\\x8c\\tfifteenth\\x94h\\x1dh\\xfcub\\x8c\\x16invalid-expires-cookie\\x94h\\r)\\x81\\x94(\\x8c\\x07expires\\x94h\\x08\\x8c\\x04path\\x94h\\x11\\x8c\\x07comment\\x94h\\x08\\x8c\\x06domain\\x94\\x8c\\x12invalid-values.com\\x94\\x8c\\x07max-age\\x94h\\x08\\x8c\\x06secure\\x94h\\x08\\x8c\\x08httponly\\x94h\\x08\\x8c\\x07version\\x94h\\x08\\x8c\\x08samesite\\x94h\\x08u}\\x94(h\\x1ah\\xfdh\\x1b\\x8c\\tsixteenth\\x94h\\x1dj\\n\\x01\\x00\\x00ubuu.\"\n    cookies = pickle.loads(pickled)\n\n    cj = CookieJar()\n    cj.update_cookies(cookies_to_send)\n\n    assert cookies == cj._cookies\n\n\n@pytest.mark.parametrize(\n    \"url\",\n    [\n        \"http://127.0.0.1/index.html\",\n        URL(\"http://127.0.0.1/index.html\"),\n        [\"http://127.0.0.1/index.html\"],\n        [URL(\"http://127.0.0.1/index.html\")],\n    ],\n)\nasync def test_treat_as_secure_origin_init(url) -> None:\n    jar = CookieJar(unsafe=True, treat_as_secure_origin=url)\n    assert jar._treat_as_secure_origin == [URL(\"http://127.0.0.1\")]\n\n\nasync def test_treat_as_secure_origin() -> None:\n    endpoint = URL(\"http://127.0.0.1/\")\n\n    jar = CookieJar(unsafe=True, treat_as_secure_origin=[endpoint])\n    secure_cookie = SimpleCookie(\n        \"cookie-key=cookie-value; HttpOnly; Path=/; Secure\",\n    )\n\n    jar.update_cookies(\n        secure_cookie,\n        endpoint,\n    )\n\n    assert len(jar) == 1\n    filtered_cookies = jar.filter_cookies(request_url=endpoint)\n    assert len(filtered_cookies) == 1\n", "tests/test_http_writer.py": "# type: ignore\n# Tests for aiohttp/http_writer.py\nimport array\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\nfrom multidict import CIMultiDict\n\nfrom aiohttp import http\nfrom aiohttp.test_utils import make_mocked_coro\n\n\n@pytest.fixture\ndef buf():\n    return bytearray()\n\n\n@pytest.fixture\ndef transport(buf: Any):\n    transport = mock.Mock()\n\n    def write(chunk):\n        buf.extend(chunk)\n\n    transport.write.side_effect = write\n    transport.is_closing.return_value = False\n    return transport\n\n\n@pytest.fixture\ndef protocol(loop: Any, transport: Any):\n    protocol = mock.Mock(transport=transport)\n    protocol._drain_helper = make_mocked_coro()\n    return protocol\n\n\ndef test_payloadwriter_properties(transport: Any, protocol: Any, loop: Any) -> None:\n    writer = http.StreamWriter(protocol, loop)\n    assert writer.protocol == protocol\n    assert writer.transport == transport\n\n\nasync def test_write_payload_eof(transport: Any, protocol: Any, loop: Any) -> None:\n    write = transport.write = mock.Mock()\n    msg = http.StreamWriter(protocol, loop)\n\n    await msg.write(b\"data1\")\n    await msg.write(b\"data2\")\n    await msg.write_eof()\n\n    content = b\"\".join([c[1][0] for c in list(write.mock_calls)])\n    assert b\"data1data2\" == content.split(b\"\\r\\n\\r\\n\", 1)[-1]\n\n\nasync def test_write_payload_chunked(\n    buf: Any, protocol: Any, transport: Any, loop: Any\n) -> None:\n    msg = http.StreamWriter(protocol, loop)\n    msg.enable_chunking()\n    await msg.write(b\"data\")\n    await msg.write_eof()\n\n    assert b\"4\\r\\ndata\\r\\n0\\r\\n\\r\\n\" == buf\n\n\nasync def test_write_payload_chunked_multiple(\n    buf: Any, protocol: Any, transport: Any, loop: Any\n) -> None:\n    msg = http.StreamWriter(protocol, loop)\n    msg.enable_chunking()\n    await msg.write(b\"data1\")\n    await msg.write(b\"data2\")\n    await msg.write_eof()\n\n    assert b\"5\\r\\ndata1\\r\\n5\\r\\ndata2\\r\\n0\\r\\n\\r\\n\" == buf\n\n\nasync def test_write_payload_length(protocol: Any, transport: Any, loop: Any) -> None:\n    write = transport.write = mock.Mock()\n\n    msg = http.StreamWriter(protocol, loop)\n    msg.length = 2\n    await msg.write(b\"d\")\n    await msg.write(b\"ata\")\n    await msg.write_eof()\n\n    content = b\"\".join([c[1][0] for c in list(write.mock_calls)])\n    assert b\"da\" == content.split(b\"\\r\\n\\r\\n\", 1)[-1]\n\n\nasync def test_write_payload_chunked_filter(\n    protocol: Any, transport: Any, loop: Any\n) -> None:\n    write = transport.write = mock.Mock()\n\n    msg = http.StreamWriter(protocol, loop)\n    msg.enable_chunking()\n    await msg.write(b\"da\")\n    await msg.write(b\"ta\")\n    await msg.write_eof()\n\n    content = b\"\".join([c[1][0] for c in list(write.mock_calls)])\n    assert content.endswith(b\"2\\r\\nda\\r\\n2\\r\\nta\\r\\n0\\r\\n\\r\\n\")\n\n\nasync def test_write_payload_chunked_filter_mutiple_chunks(\n    protocol: Any, transport: Any, loop: Any\n) -> None:\n    write = transport.write = mock.Mock()\n    msg = http.StreamWriter(protocol, loop)\n    msg.enable_chunking()\n    await msg.write(b\"da\")\n    await msg.write(b\"ta\")\n    await msg.write(b\"1d\")\n    await msg.write(b\"at\")\n    await msg.write(b\"a2\")\n    await msg.write_eof()\n    content = b\"\".join([c[1][0] for c in list(write.mock_calls)])\n    assert content.endswith(\n        b\"2\\r\\nda\\r\\n2\\r\\nta\\r\\n2\\r\\n1d\\r\\n2\\r\\nat\\r\\n\" b\"2\\r\\na2\\r\\n0\\r\\n\\r\\n\"\n    )\n\n\nasync def test_write_payload_deflate_compression(\n    protocol: Any, transport: Any, loop: Any\n) -> None:\n    COMPRESSED = b\"x\\x9cKI,I\\x04\\x00\\x04\\x00\\x01\\x9b\"\n    write = transport.write = mock.Mock()\n    msg = http.StreamWriter(protocol, loop)\n    msg.enable_compression(\"deflate\")\n    await msg.write(b\"data\")\n    await msg.write_eof()\n\n    chunks = [c[1][0] for c in list(write.mock_calls)]\n    assert all(chunks)\n    content = b\"\".join(chunks)\n    assert COMPRESSED == content.split(b\"\\r\\n\\r\\n\", 1)[-1]\n\n\nasync def test_write_payload_deflate_and_chunked(\n    buf: Any, protocol: Any, transport: Any, loop: Any\n) -> None:\n    msg = http.StreamWriter(protocol, loop)\n    msg.enable_compression(\"deflate\")\n    msg.enable_chunking()\n\n    await msg.write(b\"da\")\n    await msg.write(b\"ta\")\n    await msg.write_eof()\n\n    thing = b\"2\\r\\nx\\x9c\\r\\n\" b\"a\\r\\nKI,I\\x04\\x00\\x04\\x00\\x01\\x9b\\r\\n\" b\"0\\r\\n\\r\\n\"\n    assert thing == buf\n\n\nasync def test_write_payload_bytes_memoryview(\n    buf: Any, protocol: Any, transport: Any, loop: Any\n) -> None:\n    msg = http.StreamWriter(protocol, loop)\n\n    mv = memoryview(b\"abcd\")\n\n    await msg.write(mv)\n    await msg.write_eof()\n\n    thing = b\"abcd\"\n    assert thing == buf\n\n\nasync def test_write_payload_short_ints_memoryview(\n    buf: Any, protocol: Any, transport: Any, loop: Any\n) -> None:\n    msg = http.StreamWriter(protocol, loop)\n    msg.enable_chunking()\n\n    payload = memoryview(array.array(\"H\", [65, 66, 67]))\n\n    await msg.write(payload)\n    await msg.write_eof()\n\n    endians = (\n        (b\"6\\r\\n\" b\"\\x00A\\x00B\\x00C\\r\\n\" b\"0\\r\\n\\r\\n\"),\n        (b\"6\\r\\n\" b\"A\\x00B\\x00C\\x00\\r\\n\" b\"0\\r\\n\\r\\n\"),\n    )\n    assert buf in endians\n\n\nasync def test_write_payload_2d_shape_memoryview(\n    buf: Any, protocol: Any, transport: Any, loop: Any\n) -> None:\n    msg = http.StreamWriter(protocol, loop)\n    msg.enable_chunking()\n\n    mv = memoryview(b\"ABCDEF\")\n    payload = mv.cast(\"c\", [3, 2])\n\n    await msg.write(payload)\n    await msg.write_eof()\n\n    thing = b\"6\\r\\n\" b\"ABCDEF\\r\\n\" b\"0\\r\\n\\r\\n\"\n    assert thing == buf\n\n\nasync def test_write_payload_slicing_long_memoryview(\n    buf: Any, protocol: Any, transport: Any, loop: Any\n) -> None:\n    msg = http.StreamWriter(protocol, loop)\n    msg.length = 4\n\n    mv = memoryview(b\"ABCDEF\")\n    payload = mv.cast(\"c\", [3, 2])\n\n    await msg.write(payload)\n    await msg.write_eof()\n\n    thing = b\"ABCD\"\n    assert thing == buf\n\n\nasync def test_write_drain(protocol: Any, transport: Any, loop: Any) -> None:\n    msg = http.StreamWriter(protocol, loop)\n    msg.drain = make_mocked_coro()\n    await msg.write(b\"1\" * (64 * 1024 * 2), drain=False)\n    assert not msg.drain.called\n\n    await msg.write(b\"1\", drain=True)\n    assert msg.drain.called\n    assert msg.buffer_size == 0\n\n\nasync def test_write_calls_callback(protocol: Any, transport: Any, loop: Any) -> None:\n    on_chunk_sent = make_mocked_coro()\n    msg = http.StreamWriter(protocol, loop, on_chunk_sent=on_chunk_sent)\n    chunk = b\"1\"\n    await msg.write(chunk)\n    assert on_chunk_sent.called\n    assert on_chunk_sent.call_args == mock.call(chunk)\n\n\nasync def test_write_eof_calls_callback(\n    protocol: Any, transport: Any, loop: Any\n) -> None:\n    on_chunk_sent = make_mocked_coro()\n    msg = http.StreamWriter(protocol, loop, on_chunk_sent=on_chunk_sent)\n    chunk = b\"1\"\n    await msg.write_eof(chunk=chunk)\n    assert on_chunk_sent.called\n    assert on_chunk_sent.call_args == mock.call(chunk)\n\n\nasync def test_write_to_closing_transport(\n    protocol: Any, transport: Any, loop: Any\n) -> None:\n    msg = http.StreamWriter(protocol, loop)\n\n    await msg.write(b\"Before closing\")\n    transport.is_closing.return_value = True\n\n    with pytest.raises(ConnectionResetError):\n        await msg.write(b\"After closing\")\n\n\nasync def test_write_to_closed_transport(\n    protocol: Any, transport: Any, loop: Any\n) -> None:\n    \"\"\"Test that writing to a closed transport raises ConnectionResetError.\n\n    The StreamWriter checks to see if protocol.transport is None before\n    writing to the transport. If it is None, it raises ConnectionResetError.\n    \"\"\"\n    msg = http.StreamWriter(protocol, loop)\n\n    await msg.write(b\"Before transport close\")\n    protocol.transport = None\n\n    with pytest.raises(ConnectionResetError, match=\"Cannot write to closing transport\"):\n        await msg.write(b\"After transport closed\")\n\n\nasync def test_drain(protocol: Any, transport: Any, loop: Any) -> None:\n    msg = http.StreamWriter(protocol, loop)\n    await msg.drain()\n    assert protocol._drain_helper.called\n\n\nasync def test_drain_no_transport(protocol: Any, transport: Any, loop: Any) -> None:\n    msg = http.StreamWriter(protocol, loop)\n    msg._protocol.transport = None\n    await msg.drain()\n    assert not protocol._drain_helper.called\n\n\nasync def test_write_headers_prevents_injection(\n    protocol: Any, transport: Any, loop: Any\n) -> None:\n    msg = http.StreamWriter(protocol, loop)\n    status_line = \"HTTP/1.1 200 OK\"\n    wrong_headers = CIMultiDict({\"Set-Cookie: abc=123\\r\\nContent-Length\": \"256\"})\n    with pytest.raises(ValueError):\n        await msg.write_headers(status_line, wrong_headers)\n    wrong_headers = CIMultiDict({\"Content-Length\": \"256\\r\\nSet-Cookie: abc=123\"})\n    with pytest.raises(ValueError):\n        await msg.write_headers(status_line, wrong_headers)\n", "tests/test_web_request.py": "# type: ignore\nimport asyncio\nimport datetime\nimport socket\nimport weakref\nfrom collections.abc import MutableMapping\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\nfrom multidict import CIMultiDict, CIMultiDictProxy, MultiDict\nfrom yarl import URL\n\nfrom aiohttp import HttpVersion, web\nfrom aiohttp.client_exceptions import ServerDisconnectedError\nfrom aiohttp.http_parser import RawRequestMessage\nfrom aiohttp.streams import StreamReader\nfrom aiohttp.test_utils import make_mocked_request\nfrom aiohttp.web import HTTPRequestEntityTooLarge, HTTPUnsupportedMediaType\nfrom aiohttp.web_request import ETag\n\n\n@pytest.fixture\ndef protocol():\n    return mock.Mock(_reading_paused=False)\n\n\ndef test_base_ctor() -> None:\n    message = RawRequestMessage(\n        \"GET\",\n        \"/path/to?a=1&b=2\",\n        HttpVersion(1, 1),\n        CIMultiDictProxy(CIMultiDict()),\n        (),\n        False,\n        False,\n        False,\n        False,\n        URL(\"/path/to?a=1&b=2\"),\n    )\n\n    req = web.BaseRequest(\n        message, mock.Mock(), mock.Mock(), mock.Mock(), mock.Mock(), mock.Mock()\n    )\n\n    assert \"GET\" == req.method\n    assert HttpVersion(1, 1) == req.version\n    # MacOS may return CamelCased host name, need .lower()\n    # FQDN can be wider than host, e.g.\n    # 'fv-az397-495' in 'fv-az397-495.internal.cloudapp.net'\n    assert req.host.lower() in socket.getfqdn().lower()\n    assert \"/path/to?a=1&b=2\" == req.path_qs\n    assert \"/path/to\" == req.path\n    assert \"a=1&b=2\" == req.query_string\n    assert CIMultiDict() == req.headers\n    assert () == req.raw_headers\n\n    get = req.query\n    assert MultiDict([(\"a\", \"1\"), (\"b\", \"2\")]) == get\n    # second call should return the same object\n    assert get is req.query\n\n    assert req.keep_alive\n\n    assert \"__dict__\" not in dir(req)\n\n    assert req\n\n\ndef test_ctor() -> None:\n    req = make_mocked_request(\"GET\", \"/path/to?a=1&b=2\")\n\n    assert \"GET\" == req.method\n    assert HttpVersion(1, 1) == req.version\n    # MacOS may return CamelCased host name, need .lower()\n    # FQDN can be wider than host, e.g.\n    # 'fv-az397-495' in 'fv-az397-495.internal.cloudapp.net'\n    assert req.host.lower() in socket.getfqdn().lower()\n    assert \"/path/to?a=1&b=2\" == req.path_qs\n    assert \"/path/to\" == req.path\n    assert \"a=1&b=2\" == req.query_string\n    assert CIMultiDict() == req.headers\n    assert () == req.raw_headers\n\n    get = req.query\n    assert MultiDict([(\"a\", \"1\"), (\"b\", \"2\")]) == get\n    # second call should return the same object\n    assert get is req.query\n\n    assert req.keep_alive\n\n    # just make sure that all lines of make_mocked_request covered\n    headers = CIMultiDict(FOO=\"bar\")\n    payload = mock.Mock()\n    protocol = mock.Mock()\n    app = mock.Mock()\n    req = make_mocked_request(\n        \"GET\",\n        \"/path/to?a=1&b=2\",\n        headers=headers,\n        protocol=protocol,\n        payload=payload,\n        app=app,\n    )\n    assert req.app is app\n    assert req.content is payload\n    assert req.protocol is protocol\n    assert req.transport is protocol.transport\n    assert req.headers == headers\n    assert req.raw_headers == ((b\"FOO\", b\"bar\"),)\n    assert req.task is req._task\n\n    assert \"__dict__\" not in dir(req)\n\n\ndef test_doubleslashes() -> None:\n    # NB: //foo/bar is an absolute URL with foo netloc and /bar path\n    req = make_mocked_request(\"GET\", \"/bar//foo/\")\n    assert \"/bar//foo/\" == req.path\n\n\ndef test_content_type_not_specified() -> None:\n    req = make_mocked_request(\"Get\", \"/\")\n    assert \"application/octet-stream\" == req.content_type\n\n\ndef test_content_type_from_spec() -> None:\n    req = make_mocked_request(\n        \"Get\", \"/\", CIMultiDict([(\"CONTENT-TYPE\", \"application/json\")])\n    )\n    assert \"application/json\" == req.content_type\n\n\ndef test_content_type_from_spec_with_charset() -> None:\n    req = make_mocked_request(\n        \"Get\", \"/\", CIMultiDict([(\"CONTENT-TYPE\", \"text/html; charset=UTF-8\")])\n    )\n    assert \"text/html\" == req.content_type\n    assert \"UTF-8\" == req.charset\n\n\ndef test_calc_content_type_on_getting_charset() -> None:\n    req = make_mocked_request(\n        \"Get\", \"/\", CIMultiDict([(\"CONTENT-TYPE\", \"text/html; charset=UTF-8\")])\n    )\n    assert \"UTF-8\" == req.charset\n    assert \"text/html\" == req.content_type\n\n\ndef test_urlencoded_querystring() -> None:\n    req = make_mocked_request(\"GET\", \"/yandsearch?text=%D1%82%D0%B5%D0%BA%D1%81%D1%82\")\n    assert {\"text\": \"\u0442\u0435\u043a\u0441\u0442\"} == req.query\n\n\ndef test_non_ascii_path() -> None:\n    req = make_mocked_request(\"GET\", \"/\u043f\u0443\u0442\u044c\")\n    assert \"/\u043f\u0443\u0442\u044c\" == req.path\n\n\ndef test_non_ascii_raw_path() -> None:\n    req = make_mocked_request(\"GET\", \"/\u043f\u0443\u0442\u044c\")\n    assert \"/\u043f\u0443\u0442\u044c\" == req.raw_path\n\n\ndef test_absolute_url() -> None:\n    req = make_mocked_request(\"GET\", \"https://example.com/path/to?a=1\")\n    assert req.url == URL(\"https://example.com/path/to?a=1\")\n    assert req.scheme == \"https\"\n    assert req.host == \"example.com\"\n    assert req.rel_url == URL.build(path=\"/path/to\", query={\"a\": \"1\"})\n\n\ndef test_content_length() -> None:\n    req = make_mocked_request(\"Get\", \"/\", CIMultiDict([(\"CONTENT-LENGTH\", \"123\")]))\n\n    assert 123 == req.content_length\n\n\ndef test_range_to_slice_head() -> None:\n    def bytes_gen(size):\n        for i in range(size):\n            yield i % 256\n\n    payload = bytearray(bytes_gen(10000))\n    req = make_mocked_request(\n        \"GET\", \"/\", headers=CIMultiDict([(\"RANGE\", \"bytes=0-499\")]), payload=payload\n    )\n    assert isinstance(req.http_range, slice)\n    assert req.content[req.http_range] == payload[:500]\n\n\ndef test_range_to_slice_mid() -> None:\n    def bytes_gen(size):\n        for i in range(size):\n            yield i % 256\n\n    payload = bytearray(bytes_gen(10000))\n    req = make_mocked_request(\n        \"GET\", \"/\", headers=CIMultiDict([(\"RANGE\", \"bytes=500-999\")]), payload=payload\n    )\n    assert isinstance(req.http_range, slice)\n    assert req.content[req.http_range] == payload[500:1000]\n\n\ndef test_range_to_slice_tail_start() -> None:\n    def bytes_gen(size):\n        for i in range(size):\n            yield i % 256\n\n    payload = bytearray(bytes_gen(10000))\n    req = make_mocked_request(\n        \"GET\", \"/\", headers=CIMultiDict([(\"RANGE\", \"bytes=9500-\")]), payload=payload\n    )\n    assert isinstance(req.http_range, slice)\n    assert req.content[req.http_range] == payload[-500:]\n\n\ndef test_range_to_slice_tail_stop() -> None:\n    def bytes_gen(size):\n        for i in range(size):\n            yield i % 256\n\n    payload = bytearray(bytes_gen(10000))\n    req = make_mocked_request(\n        \"GET\", \"/\", headers=CIMultiDict([(\"RANGE\", \"bytes=-500\")]), payload=payload\n    )\n    assert isinstance(req.http_range, slice)\n    assert req.content[req.http_range] == payload[-500:]\n\n\ndef test_non_keepalive_on_http10() -> None:\n    req = make_mocked_request(\"GET\", \"/\", version=HttpVersion(1, 0))\n    assert not req.keep_alive\n\n\ndef test_non_keepalive_on_closing() -> None:\n    req = make_mocked_request(\"GET\", \"/\", closing=True)\n    assert not req.keep_alive\n\n\nasync def test_call_POST_on_GET_request() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n\n    ret = await req.post()\n    assert CIMultiDict() == ret\n\n\nasync def test_call_POST_on_weird_content_type() -> None:\n    req = make_mocked_request(\n        \"POST\", \"/\", headers=CIMultiDict({\"CONTENT-TYPE\": \"something/weird\"})\n    )\n\n    ret = await req.post()\n    assert CIMultiDict() == ret\n\n\nasync def test_call_POST_twice() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n\n    ret1 = await req.post()\n    ret2 = await req.post()\n    assert ret1 is ret2\n\n\ndef test_no_request_cookies() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n\n    assert req.cookies == {}\n\n    cookies = req.cookies\n    assert cookies is req.cookies\n\n\ndef test_request_cookie() -> None:\n    headers = CIMultiDict(COOKIE=\"cookie1=value1; cookie2=value2\")\n    req = make_mocked_request(\"GET\", \"/\", headers=headers)\n\n    assert req.cookies == {\"cookie1\": \"value1\", \"cookie2\": \"value2\"}\n\n\ndef test_request_cookie__set_item() -> None:\n    headers = CIMultiDict(COOKIE=\"name=value\")\n    req = make_mocked_request(\"GET\", \"/\", headers=headers)\n\n    assert req.cookies == {\"name\": \"value\"}\n\n    with pytest.raises(TypeError):\n        req.cookies[\"my\"] = \"value\"\n\n\ndef test_match_info() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    assert req._match_info is req.match_info\n\n\ndef test_request_is_mutable_mapping() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    assert isinstance(req, MutableMapping)\n    req[\"key\"] = \"value\"\n    assert \"value\" == req[\"key\"]\n\n\ndef test_request_delitem() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    req[\"key\"] = \"value\"\n    assert \"value\" == req[\"key\"]\n    del req[\"key\"]\n    assert \"key\" not in req\n\n\ndef test_request_len() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    assert len(req) == 0\n    req[\"key\"] = \"value\"\n    assert len(req) == 1\n\n\ndef test_request_iter() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    req[\"key\"] = \"value\"\n    req[\"key2\"] = \"value2\"\n    assert set(req) == {\"key\", \"key2\"}\n\n\ndef test___repr__() -> None:\n    req = make_mocked_request(\"GET\", \"/path/to\")\n    assert \"<Request GET /path/to >\" == repr(req)\n\n\ndef test___repr___non_ascii_path() -> None:\n    req = make_mocked_request(\"GET\", \"/path/\\U0001f415\\U0001f308\")\n    assert \"<Request GET /path/\\\\U0001f415\\\\U0001f308 >\" == repr(req)\n\n\ndef test_http_scheme() -> None:\n    req = make_mocked_request(\"GET\", \"/\", headers={\"Host\": \"example.com\"})\n    assert \"http\" == req.scheme\n    assert req.secure is False\n\n\ndef test_https_scheme_by_ssl_transport() -> None:\n    req = make_mocked_request(\n        \"GET\", \"/\", headers={\"Host\": \"example.com\"}, sslcontext=True\n    )\n    assert \"https\" == req.scheme\n    assert req.secure is True\n\n\ndef test_single_forwarded_header() -> None:\n    header = \"by=identifier;for=identifier;host=identifier;proto=identifier\"\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert req.forwarded[0][\"by\"] == \"identifier\"\n    assert req.forwarded[0][\"for\"] == \"identifier\"\n    assert req.forwarded[0][\"host\"] == \"identifier\"\n    assert req.forwarded[0][\"proto\"] == \"identifier\"\n\n\n@pytest.mark.parametrize(\n    \"forward_for_in, forward_for_out\",\n    [\n        (\"1.2.3.4:1234\", \"1.2.3.4:1234\"),\n        (\"1.2.3.4\", \"1.2.3.4\"),\n        ('\"[2001:db8:cafe::17]:1234\"', \"[2001:db8:cafe::17]:1234\"),\n        ('\"[2001:db8:cafe::17]\"', \"[2001:db8:cafe::17]\"),\n    ],\n)\ndef test_forwarded_node_identifier(forward_for_in: Any, forward_for_out: Any) -> None:\n    header = f\"for={forward_for_in}\"\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert req.forwarded == ({\"for\": forward_for_out},)\n\n\ndef test_single_forwarded_header_camelcase() -> None:\n    header = \"bY=identifier;fOr=identifier;HOst=identifier;pRoTO=identifier\"\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert req.forwarded[0][\"by\"] == \"identifier\"\n    assert req.forwarded[0][\"for\"] == \"identifier\"\n    assert req.forwarded[0][\"host\"] == \"identifier\"\n    assert req.forwarded[0][\"proto\"] == \"identifier\"\n\n\ndef test_single_forwarded_header_single_param() -> None:\n    header = \"BY=identifier\"\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert req.forwarded[0][\"by\"] == \"identifier\"\n\n\ndef test_single_forwarded_header_multiple_param() -> None:\n    header = \"By=identifier1,BY=identifier2,  By=identifier3 ,  BY=identifier4\"\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert len(req.forwarded) == 4\n    assert req.forwarded[0][\"by\"] == \"identifier1\"\n    assert req.forwarded[1][\"by\"] == \"identifier2\"\n    assert req.forwarded[2][\"by\"] == \"identifier3\"\n    assert req.forwarded[3][\"by\"] == \"identifier4\"\n\n\ndef test_single_forwarded_header_quoted_escaped() -> None:\n    header = r'BY=identifier;pROTO=\"\\lala lan\\d\\~ 123\\!&\"'\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert req.forwarded[0][\"by\"] == \"identifier\"\n    assert req.forwarded[0][\"proto\"] == \"lala land~ 123!&\"\n\n\ndef test_single_forwarded_header_custom_param() -> None:\n    header = r'BY=identifier;PROTO=https;SOME=\"other, \\\"value\\\"\"'\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert len(req.forwarded) == 1\n    assert req.forwarded[0][\"by\"] == \"identifier\"\n    assert req.forwarded[0][\"proto\"] == \"https\"\n    assert req.forwarded[0][\"some\"] == 'other, \"value\"'\n\n\ndef test_single_forwarded_header_empty_params() -> None:\n    # This is allowed by the grammar given in RFC 7239\n    header = \";For=identifier;;PROTO=https;;;\"\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert req.forwarded[0][\"for\"] == \"identifier\"\n    assert req.forwarded[0][\"proto\"] == \"https\"\n\n\ndef test_single_forwarded_header_bad_separator() -> None:\n    header = \"BY=identifier PROTO=https\"\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert \"proto\" not in req.forwarded[0]\n\n\ndef test_single_forwarded_header_injection1() -> None:\n    # We might receive a header like this if we're sitting behind a reverse\n    # proxy that blindly appends a forwarded-element without checking\n    # the syntax of existing field-values. We should be able to recover\n    # the appended element anyway.\n    header = 'for=_injected;by=\", for=_real'\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert len(req.forwarded) == 2\n    assert \"by\" not in req.forwarded[0]\n    assert req.forwarded[1][\"for\"] == \"_real\"\n\n\ndef test_single_forwarded_header_injection2() -> None:\n    header = \"very bad syntax, for=_real\"\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert len(req.forwarded) == 2\n    assert \"for\" not in req.forwarded[0]\n    assert req.forwarded[1][\"for\"] == \"_real\"\n\n\ndef test_single_forwarded_header_long_quoted_string() -> None:\n    header = 'for=\"' + \"\\\\\\\\\" * 5000 + '\"'\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Forwarded\": header}))\n    assert req.forwarded[0][\"for\"] == \"\\\\\" * 5000\n\n\ndef test_multiple_forwarded_headers() -> None:\n    headers = CIMultiDict()\n    headers.add(\"Forwarded\", \"By=identifier1;for=identifier2, BY=identifier3\")\n    headers.add(\"Forwarded\", \"By=identifier4;fOr=identifier5\")\n    req = make_mocked_request(\"GET\", \"/\", headers=headers)\n    assert len(req.forwarded) == 3\n    assert req.forwarded[0][\"by\"] == \"identifier1\"\n    assert req.forwarded[0][\"for\"] == \"identifier2\"\n    assert req.forwarded[1][\"by\"] == \"identifier3\"\n    assert req.forwarded[2][\"by\"] == \"identifier4\"\n    assert req.forwarded[2][\"for\"] == \"identifier5\"\n\n\ndef test_multiple_forwarded_headers_bad_syntax() -> None:\n    headers = CIMultiDict()\n    headers.add(\"Forwarded\", \"for=_1;by=_2\")\n    headers.add(\"Forwarded\", \"invalid value\")\n    headers.add(\"Forwarded\", \"\")\n    headers.add(\"Forwarded\", \"for=_3;by=_4\")\n    req = make_mocked_request(\"GET\", \"/\", headers=headers)\n    assert len(req.forwarded) == 4\n    assert req.forwarded[0][\"for\"] == \"_1\"\n    assert \"for\" not in req.forwarded[1]\n    assert \"for\" not in req.forwarded[2]\n    assert req.forwarded[3][\"by\"] == \"_4\"\n\n\ndef test_multiple_forwarded_headers_injection() -> None:\n    headers = CIMultiDict()\n    # This could be sent by an attacker, hoping to \"shadow\" the second header.\n    headers.add(\"Forwarded\", 'for=_injected;by=\"')\n    # This is added by our trusted reverse proxy.\n    headers.add(\"Forwarded\", \"for=_real;by=_actual_proxy\")\n    req = make_mocked_request(\"GET\", \"/\", headers=headers)\n    assert len(req.forwarded) == 2\n    assert \"by\" not in req.forwarded[0]\n    assert req.forwarded[1][\"for\"] == \"_real\"\n    assert req.forwarded[1][\"by\"] == \"_actual_proxy\"\n\n\ndef test_host_by_host_header() -> None:\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"Host\": \"example.com\"}))\n    assert req.host == \"example.com\"\n\n\ndef test_raw_headers() -> None:\n    req = make_mocked_request(\"GET\", \"/\", headers=CIMultiDict({\"X-HEADER\": \"aaa\"}))\n    assert req.raw_headers == ((b\"X-HEADER\", b\"aaa\"),)\n\n\ndef test_rel_url() -> None:\n    req = make_mocked_request(\"GET\", \"/path\")\n    assert URL(\"/path\") == req.rel_url\n\n\ndef test_url_url() -> None:\n    req = make_mocked_request(\"GET\", \"/path\", headers={\"HOST\": \"example.com\"})\n    assert URL(\"http://example.com/path\") == req.url\n\n\ndef test_clone() -> None:\n    req = make_mocked_request(\"GET\", \"/path\")\n    req2 = req.clone()\n    assert req2.method == \"GET\"\n    assert req2.rel_url == URL(\"/path\")\n\n\ndef test_clone_client_max_size() -> None:\n    req = make_mocked_request(\"GET\", \"/path\", client_max_size=1024)\n    req2 = req.clone()\n    assert req._client_max_size == req2._client_max_size\n    assert req2._client_max_size == 1024\n\n\ndef test_clone_override_client_max_size() -> None:\n    req = make_mocked_request(\"GET\", \"/path\", client_max_size=1024)\n    req2 = req.clone(client_max_size=2048)\n    assert req2.client_max_size == 2048\n\n\ndef test_clone_method() -> None:\n    req = make_mocked_request(\"GET\", \"/path\")\n    req2 = req.clone(method=\"POST\")\n    assert req2.method == \"POST\"\n    assert req2.rel_url == URL(\"/path\")\n\n\ndef test_clone_rel_url() -> None:\n    req = make_mocked_request(\"GET\", \"/path\")\n    req2 = req.clone(rel_url=URL(\"/path2\"))\n    assert req2.rel_url == URL(\"/path2\")\n\n\ndef test_clone_rel_url_str() -> None:\n    req = make_mocked_request(\"GET\", \"/path\")\n    req2 = req.clone(rel_url=\"/path2\")\n    assert req2.rel_url == URL(\"/path2\")\n\n\ndef test_clone_headers() -> None:\n    req = make_mocked_request(\"GET\", \"/path\", headers={\"A\": \"B\"})\n    req2 = req.clone(headers=CIMultiDict({\"B\": \"C\"}))\n    assert req2.headers == CIMultiDict({\"B\": \"C\"})\n    assert req2.raw_headers == ((b\"B\", b\"C\"),)\n\n\ndef test_clone_headers_dict() -> None:\n    req = make_mocked_request(\"GET\", \"/path\", headers={\"A\": \"B\"})\n    req2 = req.clone(headers={\"B\": \"C\"})\n    assert req2.headers == CIMultiDict({\"B\": \"C\"})\n    assert req2.raw_headers == ((b\"B\", b\"C\"),)\n\n\nasync def test_cannot_clone_after_read(protocol: Any) -> None:\n    payload = StreamReader(protocol, 2**16, loop=asyncio.get_event_loop())\n    payload.feed_data(b\"data\")\n    payload.feed_eof()\n    req = make_mocked_request(\"GET\", \"/path\", payload=payload)\n    await req.read()\n    with pytest.raises(RuntimeError):\n        req.clone()\n\n\nasync def test_make_too_big_request(protocol: Any) -> None:\n    payload = StreamReader(protocol, 2**16, loop=asyncio.get_event_loop())\n    large_file = 1024**2 * b\"x\"\n    too_large_file = large_file + b\"x\"\n    payload.feed_data(too_large_file)\n    payload.feed_eof()\n    req = make_mocked_request(\"POST\", \"/\", payload=payload)\n    with pytest.raises(HTTPRequestEntityTooLarge) as err:\n        await req.read()\n\n    assert err.value.status_code == 413\n\n\nasync def test_request_with_wrong_content_type_encoding(protocol: Any) -> None:\n    payload = StreamReader(protocol, 2**16, loop=asyncio.get_event_loop())\n    payload.feed_data(b\"{}\")\n    payload.feed_eof()\n    headers = {\"Content-Type\": \"text/html; charset=test\"}\n    req = make_mocked_request(\"POST\", \"/\", payload=payload, headers=headers)\n\n    with pytest.raises(HTTPUnsupportedMediaType) as err:\n        await req.text()\n    assert err.value.status_code == 415\n\n\nasync def test_make_too_big_request_same_size_to_max(protocol: Any) -> None:\n    payload = StreamReader(protocol, 2**16, loop=asyncio.get_event_loop())\n    large_file = 1024**2 * b\"x\"\n    payload.feed_data(large_file)\n    payload.feed_eof()\n    req = make_mocked_request(\"POST\", \"/\", payload=payload)\n    resp_text = await req.read()\n\n    assert resp_text == large_file\n\n\nasync def test_make_too_big_request_adjust_limit(protocol: Any) -> None:\n    payload = StreamReader(protocol, 2**16, loop=asyncio.get_event_loop())\n    large_file = 1024**2 * b\"x\"\n    too_large_file = large_file + b\"x\"\n    payload.feed_data(too_large_file)\n    payload.feed_eof()\n    max_size = 1024**2 + 2\n    req = make_mocked_request(\"POST\", \"/\", payload=payload, client_max_size=max_size)\n    txt = await req.read()\n    assert len(txt) == 1024**2 + 1\n\n\nasync def test_multipart_formdata(protocol: Any) -> None:\n    payload = StreamReader(protocol, 2**16, loop=asyncio.get_event_loop())\n    payload.feed_data(\n        b\"-----------------------------326931944431359\\r\\n\"\n        b'Content-Disposition: form-data; name=\"a\"\\r\\n'\n        b\"\\r\\n\"\n        b\"b\\r\\n\"\n        b\"-----------------------------326931944431359\\r\\n\"\n        b'Content-Disposition: form-data; name=\"c\"\\r\\n'\n        b\"\\r\\n\"\n        b\"d\\r\\n\"\n        b\"-----------------------------326931944431359--\\r\\n\"\n    )\n    content_type = (\n        \"multipart/form-data; boundary=\" \"---------------------------326931944431359\"\n    )\n    payload.feed_eof()\n    req = make_mocked_request(\n        \"POST\", \"/\", headers={\"CONTENT-TYPE\": content_type}, payload=payload\n    )\n    result = await req.post()\n    assert dict(result) == {\"a\": \"b\", \"c\": \"d\"}\n\n\nasync def test_multipart_formdata_file(protocol: Any) -> None:\n    # Make sure file uploads work, even without a content type\n    payload = StreamReader(protocol, 2**16, loop=asyncio.get_event_loop())\n    payload.feed_data(\n        b\"-----------------------------326931944431359\\r\\n\"\n        b'Content-Disposition: form-data; name=\"a_file\"; filename=\"binary\"\\r\\n'\n        b\"\\r\\n\"\n        b\"\\ff\\r\\n\"\n        b\"-----------------------------326931944431359--\\r\\n\"\n    )\n    content_type = (\n        \"multipart/form-data; boundary=\" \"---------------------------326931944431359\"\n    )\n    payload.feed_eof()\n    req = make_mocked_request(\n        \"POST\", \"/\", headers={\"CONTENT-TYPE\": content_type}, payload=payload\n    )\n    result = await req.post()\n    assert hasattr(result[\"a_file\"], \"file\")\n    content = result[\"a_file\"].file.read()\n    assert content == b\"\\ff\"\n\n    req._finish()\n\n\nasync def test_make_too_big_request_limit_None(protocol: Any) -> None:\n    payload = StreamReader(protocol, 2**16, loop=asyncio.get_event_loop())\n    large_file = 1024**2 * b\"x\"\n    too_large_file = large_file + b\"x\"\n    payload.feed_data(too_large_file)\n    payload.feed_eof()\n    max_size = None\n    req = make_mocked_request(\"POST\", \"/\", payload=payload, client_max_size=max_size)\n    txt = await req.read()\n    assert len(txt) == 1024**2 + 1\n\n\ndef test_remote_peername_tcp() -> None:\n    transp = mock.Mock()\n    transp.get_extra_info.return_value = (\"10.10.10.10\", 1234)\n    req = make_mocked_request(\"GET\", \"/\", transport=transp)\n    assert req.remote == \"10.10.10.10\"\n\n\ndef test_remote_peername_unix() -> None:\n    transp = mock.Mock()\n    transp.get_extra_info.return_value = \"/path/to/sock\"\n    req = make_mocked_request(\"GET\", \"/\", transport=transp)\n    assert req.remote == \"/path/to/sock\"\n\n\ndef test_save_state_on_clone() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    req[\"key\"] = \"val\"\n    req2 = req.clone()\n    req2[\"key\"] = \"val2\"\n    assert req[\"key\"] == \"val\"\n    assert req2[\"key\"] == \"val2\"\n\n\ndef test_clone_scheme() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    req2 = req.clone(scheme=\"https\")\n    assert req2.scheme == \"https\"\n\n\ndef test_clone_host() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    req2 = req.clone(host=\"example.com\")\n    assert req2.host == \"example.com\"\n\n\ndef test_clone_remote() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    req2 = req.clone(remote=\"11.11.11.11\")\n    assert req2.remote == \"11.11.11.11\"\n\n\ndef test_remote_with_closed_transport() -> None:\n    transp = mock.Mock()\n    transp.get_extra_info.return_value = (\"10.10.10.10\", 1234)\n    req = make_mocked_request(\"GET\", \"/\", transport=transp)\n    req._protocol = None\n    assert req.remote == \"10.10.10.10\"\n\n\ndef test_url_http_with_closed_transport() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    req._protocol = None\n    assert str(req.url).startswith(\"http://\")\n\n\ndef test_url_https_with_closed_transport() -> None:\n    req = make_mocked_request(\"GET\", \"/\", sslcontext=True)\n    req._protocol = None\n    assert str(req.url).startswith(\"https://\")\n\n\nasync def test_get_extra_info() -> None:\n    valid_key = \"test\"\n    valid_value = \"existent\"\n    default_value = \"default\"\n\n    def get_extra_info(name: str, default: Any = None):\n        return {valid_key: valid_value}.get(name, default)\n\n    transp = mock.Mock()\n    transp.get_extra_info.side_effect = get_extra_info\n    req = make_mocked_request(\"GET\", \"/\", transport=transp)\n\n    req_extra_info = req.get_extra_info(valid_key, default_value)\n    transp_extra_info = req._protocol.transport.get_extra_info(valid_key, default_value)\n    assert req_extra_info == transp_extra_info\n\n    req._protocol.transport = None\n    extra_info = req.get_extra_info(valid_key, default_value)\n    assert extra_info == default_value\n\n    req._protocol = None\n    extra_info = req.get_extra_info(valid_key, default_value)\n    assert extra_info == default_value\n\n\ndef test_eq() -> None:\n    req1 = make_mocked_request(\"GET\", \"/path/to?a=1&b=2\")\n    req2 = make_mocked_request(\"GET\", \"/path/to?a=1&b=2\")\n    assert req1 != req2\n    assert req1 == req1\n\n\nasync def test_json(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body_text = await request.text()\n        assert body_text == '{\"some\": \"data\"}'\n        assert request.headers[\"Content-Type\"] == \"application/json\"\n        body_json = await request.json()\n        assert body_json == {\"some\": \"data\"}\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    json_data = {\"some\": \"data\"}\n    async with client.post(\"/\", json=json_data) as resp:\n        assert 200 == resp.status\n\n\nasync def test_json_invalid_content_type(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body_text = await request.text()\n        assert body_text == '{\"some\": \"data\"}'\n        assert request.headers[\"Content-Type\"] == \"text/plain\"\n        await request.json()  # raises HTTP 400\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    json_data = {\"some\": \"data\"}\n    headers = {\"Content-Type\": \"text/plain\"}\n    async with client.post(\"/\", json=json_data, headers=headers) as resp:\n        assert 400 == resp.status\n        resp_text = await resp.text()\n        assert resp_text == (\n            \"Attempt to decode JSON with \" \"unexpected mimetype: text/plain\"\n        )\n\n\ndef test_weakref_creation() -> None:\n    req = make_mocked_request(\"GET\", \"/\")\n    weakref.ref(req)\n\n\n@pytest.mark.xfail(\n    raises=ServerDisconnectedError,\n    reason=\"see https://github.com/aio-libs/aiohttp/issues/4572\",\n)\nasync def test_handler_return_type(aiohttp_client: Any) -> None:\n    async def invalid_handler_1(request):\n        return 1\n\n    app = web.Application()\n    app.router.add_get(\"/1\", invalid_handler_1)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/1\") as resp:\n        assert 500 == resp.status\n\n\n@pytest.mark.parametrize(\n    [\"header\", \"header_attr\"],\n    [\n        pytest.param(\"If-Match\", \"if_match\"),\n        pytest.param(\"If-None-Match\", \"if_none_match\"),\n    ],\n)\n@pytest.mark.parametrize(\n    [\"header_val\", \"expected\"],\n    [\n        pytest.param(\n            '\"67ab43\", W/\"54ed21\", \"7892,dd\"',\n            (\n                ETag(is_weak=False, value=\"67ab43\"),\n                ETag(is_weak=True, value=\"54ed21\"),\n                ETag(is_weak=False, value=\"7892,dd\"),\n            ),\n        ),\n        pytest.param(\n            '\"bfc1ef-5b2c2730249c88ca92d82d\"',\n            (ETag(is_weak=False, value=\"bfc1ef-5b2c2730249c88ca92d82d\"),),\n        ),\n        pytest.param(\n            '\"valid-tag\", \"also-valid-tag\",somegarbage\"last-tag\"',\n            (\n                ETag(is_weak=False, value=\"valid-tag\"),\n                ETag(is_weak=False, value=\"also-valid-tag\"),\n            ),\n        ),\n        pytest.param(\n            '\"ascii\", \"\u044d\u0442\u043e \u0442\u043e\u0447\u043d\u043e \u043d\u0435 ascii\", \"ascii again\"',\n            (ETag(is_weak=False, value=\"ascii\"),),\n        ),\n        pytest.param(\n            \"*\",\n            (ETag(is_weak=False, value=\"*\"),),\n        ),\n    ],\n)\ndef test_etag_headers(header, header_attr, header_val, expected) -> None:\n    req = make_mocked_request(\"GET\", \"/\", headers={header: header_val})\n    assert getattr(req, header_attr) == expected\n\n\n@pytest.mark.parametrize(\n    [\"header\", \"header_attr\"],\n    [\n        pytest.param(\"If-Modified-Since\", \"if_modified_since\"),\n        pytest.param(\"If-Unmodified-Since\", \"if_unmodified_since\"),\n        pytest.param(\"If-Range\", \"if_range\"),\n    ],\n)\n@pytest.mark.parametrize(\n    [\"header_val\", \"expected\"],\n    [\n        pytest.param(\"xxyyzz\", None),\n        pytest.param(\"Tue, 08 Oct 4446413 00:56:40 GMT\", None),\n        pytest.param(\"Tue, 08 Oct 2000 00:56:80 GMT\", None),\n        pytest.param(\n            \"Tue, 08 Oct 2000 00:56:40 GMT\",\n            datetime.datetime(2000, 10, 8, 0, 56, 40, tzinfo=datetime.timezone.utc),\n        ),\n    ],\n)\ndef test_datetime_headers(header, header_attr, header_val, expected) -> None:\n    req = make_mocked_request(\"GET\", \"/\", headers={header: header_val})\n    assert getattr(req, header_attr) == expected\n", "tests/test_worker.py": "# Tests for aiohttp/worker.py\nimport asyncio\nimport os\nimport socket\nimport ssl\nfrom typing import TYPE_CHECKING, Callable, Dict, Optional\nfrom unittest import mock\n\nimport pytest\nfrom _pytest.fixtures import SubRequest\n\nfrom aiohttp import web\n\nif TYPE_CHECKING:\n    from aiohttp import worker as base_worker\nelse:\n    base_worker = pytest.importorskip(\"aiohttp.worker\")\n\n\ntry:\n    import uvloop\nexcept ImportError:\n    uvloop = None  # type: ignore[assignment]\n\n\nWRONG_LOG_FORMAT = '%a \"%{Referrer}i\" %(h)s %(l)s %s'\nACCEPTABLE_LOG_FORMAT = '%a \"%{Referrer}i\" %s'\n\n\nclass BaseTestWorker:\n    def __init__(self) -> None:\n        self.servers: Dict[object, object] = {}\n        self.exit_code = 0\n        self._notify_waiter: Optional[asyncio.Future[bool]] = None\n        self.cfg = mock.Mock()\n        self.cfg.graceful_timeout = 100\n        self.pid = \"pid\"\n        self.wsgi = web.Application()\n\n\nclass AsyncioWorker(BaseTestWorker, base_worker.GunicornWebWorker):\n    pass\n\n\nPARAMS = [AsyncioWorker]\nif uvloop is not None:\n\n    class UvloopWorker(BaseTestWorker, base_worker.GunicornUVLoopWebWorker):\n        pass\n\n    PARAMS.append(UvloopWorker)\n\n\n@pytest.fixture(params=PARAMS)\ndef worker(\n    request: SubRequest, loop: asyncio.AbstractEventLoop\n) -> base_worker.GunicornWebWorker:\n    asyncio.set_event_loop(loop)\n    ret = request.param()\n    ret.notify = mock.Mock()\n    return ret  # type: ignore[no-any-return]\n\n\ndef test_init_process(worker: base_worker.GunicornWebWorker) -> None:\n    with mock.patch(\"aiohttp.worker.asyncio\") as m_asyncio:\n        try:\n            worker.init_process()\n        except TypeError:\n            pass\n\n        assert m_asyncio.new_event_loop.called\n        assert m_asyncio.set_event_loop.called\n\n\ndef test_run(\n    worker: base_worker.GunicornWebWorker, loop: asyncio.AbstractEventLoop\n) -> None:\n    worker.log = mock.Mock()\n    worker.cfg = mock.Mock()\n    worker.cfg.access_log_format = ACCEPTABLE_LOG_FORMAT\n    worker.cfg.is_ssl = False\n    worker.cfg.graceful_timeout = 100\n    worker.sockets = []\n\n    worker.loop = loop\n    with pytest.raises(SystemExit):\n        worker.run()\n    worker.log.exception.assert_not_called()\n    assert loop.is_closed()\n\n\ndef test_run_async_factory(\n    worker: base_worker.GunicornWebWorker, loop: asyncio.AbstractEventLoop\n) -> None:\n    worker.log = mock.Mock()\n    worker.cfg = mock.Mock()\n    worker.cfg.access_log_format = ACCEPTABLE_LOG_FORMAT\n    worker.cfg.is_ssl = False\n    worker.cfg.graceful_timeout = 100\n    worker.sockets = []\n    app = worker.wsgi\n\n    async def make_app() -> web.Application:\n        return app  # type: ignore[no-any-return]\n\n    worker.wsgi = make_app\n\n    worker.loop = loop\n    worker.alive = False\n    with pytest.raises(SystemExit):\n        worker.run()\n    worker.log.exception.assert_not_called()\n    assert loop.is_closed()\n\n\ndef test_run_not_app(\n    worker: base_worker.GunicornWebWorker, loop: asyncio.AbstractEventLoop\n) -> None:\n    worker.log = mock.Mock()\n    worker.cfg = mock.Mock()\n    worker.cfg.access_log_format = ACCEPTABLE_LOG_FORMAT\n\n    worker.loop = loop\n    worker.wsgi = \"not-app\"\n    worker.alive = False\n    with pytest.raises(SystemExit):\n        worker.run()\n    worker.log.exception.assert_called_with(\"Exception in gunicorn worker\")\n    assert loop.is_closed()\n\n\ndef test_handle_abort(worker: base_worker.GunicornWebWorker) -> None:\n    with mock.patch(\"aiohttp.worker.sys\") as m_sys:\n        worker.handle_abort(0, None)\n        assert not worker.alive\n        assert worker.exit_code == 1\n        m_sys.exit.assert_called_with(1)\n\n\ndef test__wait_next_notify(worker: base_worker.GunicornWebWorker) -> None:\n    worker.loop = mloop = mock.create_autospec(asyncio.AbstractEventLoop)\n    with mock.patch.object(worker, \"_notify_waiter_done\", autospec=True):\n        fut = worker._wait_next_notify()\n\n        assert worker._notify_waiter == fut\n        mloop.call_later.assert_called_with(1.0, worker._notify_waiter_done, fut)\n\n\ndef test__notify_waiter_done(worker: base_worker.GunicornWebWorker) -> None:\n    worker._notify_waiter = None\n    worker._notify_waiter_done()\n    assert worker._notify_waiter is None\n\n    waiter = worker._notify_waiter = mock.Mock()\n    worker._notify_waiter.done.return_value = False\n    worker._notify_waiter_done()\n\n    assert worker._notify_waiter is None\n    waiter.set_result.assert_called_with(True)\n\n\ndef test__notify_waiter_done_explicit_waiter(\n    worker: base_worker.GunicornWebWorker,\n) -> None:\n    worker._notify_waiter = None\n    assert worker._notify_waiter is None\n\n    waiter = worker._notify_waiter = mock.Mock()\n    waiter.done.return_value = False\n    waiter2 = worker._notify_waiter = mock.Mock()\n    worker._notify_waiter_done(waiter)\n\n    assert worker._notify_waiter is waiter2\n    waiter.set_result.assert_called_with(True)\n    assert not waiter2.set_result.called\n\n\ndef test_init_signals(worker: base_worker.GunicornWebWorker) -> None:\n    worker.loop = mock.Mock()\n    worker.init_signals()\n    assert worker.loop.add_signal_handler.called\n\n\n@pytest.mark.parametrize(\n    \"source,result\",\n    [\n        (ACCEPTABLE_LOG_FORMAT, ACCEPTABLE_LOG_FORMAT),\n        (\n            AsyncioWorker.DEFAULT_GUNICORN_LOG_FORMAT,\n            AsyncioWorker.DEFAULT_AIOHTTP_LOG_FORMAT,\n        ),\n    ],\n)\ndef test__get_valid_log_format_ok(\n    worker: base_worker.GunicornWebWorker, source: str, result: str\n) -> None:\n    assert result == worker._get_valid_log_format(source)\n\n\ndef test__get_valid_log_format_exc(worker: base_worker.GunicornWebWorker) -> None:\n    with pytest.raises(ValueError) as exc:\n        worker._get_valid_log_format(WRONG_LOG_FORMAT)\n    assert \"%(name)s\" in str(exc.value)\n\n\nasync def test__run_ok_parent_changed(\n    worker: base_worker.GunicornWebWorker,\n    loop: asyncio.AbstractEventLoop,\n    aiohttp_unused_port: Callable[[], int],\n) -> None:\n    worker.ppid = 0\n    worker.alive = True\n    sock = socket.socket()\n    addr = (\"localhost\", aiohttp_unused_port())\n    sock.bind(addr)\n    worker.sockets = [sock]\n    worker.log = mock.Mock()\n    worker.loop = loop\n    worker.max_requests = 0\n    worker.cfg.access_log_format = ACCEPTABLE_LOG_FORMAT\n    worker.cfg.is_ssl = False\n\n    await worker._run()\n\n    worker.notify.assert_called_with()\n    worker.log.info.assert_called_with(\"Parent changed, shutting down: %s\", worker)\n\n\nasync def test__run_exc(\n    worker: base_worker.GunicornWebWorker,\n    loop: asyncio.AbstractEventLoop,\n    aiohttp_unused_port: Callable[[], int],\n) -> None:\n    worker.ppid = os.getppid()\n    worker.alive = True\n    sock = socket.socket()\n    addr = (\"localhost\", aiohttp_unused_port())\n    sock.bind(addr)\n    worker.sockets = [sock]\n    worker.log = mock.Mock()\n    worker.loop = loop\n    worker.max_requests = 0\n    worker.cfg.access_log_format = ACCEPTABLE_LOG_FORMAT\n    worker.cfg.is_ssl = False\n\n    def raiser() -> None:\n        waiter = worker._notify_waiter\n        worker.alive = False\n        assert waiter is not None\n        waiter.set_exception(RuntimeError())\n\n    loop.call_later(0.1, raiser)\n    await worker._run()\n\n    worker.notify.assert_called_with()\n\n\ndef test__create_ssl_context_without_certs_and_ciphers(\n    worker: base_worker.GunicornWebWorker,\n    tls_certificate_pem_path: str,\n) -> None:\n    worker.cfg.ssl_version = ssl.PROTOCOL_TLS_CLIENT\n    worker.cfg.cert_reqs = ssl.CERT_OPTIONAL\n    worker.cfg.certfile = tls_certificate_pem_path\n    worker.cfg.keyfile = tls_certificate_pem_path\n    worker.cfg.ca_certs = None\n    worker.cfg.ciphers = None\n    ctx = worker._create_ssl_context(worker.cfg)\n    assert isinstance(ctx, ssl.SSLContext)\n\n\ndef test__create_ssl_context_with_ciphers(\n    worker: base_worker.GunicornWebWorker,\n    tls_certificate_pem_path: str,\n) -> None:\n    worker.cfg.ssl_version = ssl.PROTOCOL_TLS_CLIENT\n    worker.cfg.cert_reqs = ssl.CERT_OPTIONAL\n    worker.cfg.certfile = tls_certificate_pem_path\n    worker.cfg.keyfile = tls_certificate_pem_path\n    worker.cfg.ca_certs = None\n    worker.cfg.ciphers = \"3DES PSK\"\n    ctx = worker._create_ssl_context(worker.cfg)\n    assert isinstance(ctx, ssl.SSLContext)\n\n\ndef test__create_ssl_context_with_ca_certs(\n    worker: base_worker.GunicornWebWorker,\n    tls_ca_certificate_pem_path: str,\n    tls_certificate_pem_path: str,\n) -> None:\n    worker.cfg.ssl_version = ssl.PROTOCOL_TLS_CLIENT\n    worker.cfg.cert_reqs = ssl.CERT_OPTIONAL\n    worker.cfg.certfile = tls_certificate_pem_path\n    worker.cfg.keyfile = tls_certificate_pem_path\n    worker.cfg.ca_certs = tls_ca_certificate_pem_path\n    worker.cfg.ciphers = None\n    ctx = worker._create_ssl_context(worker.cfg)\n    assert isinstance(ctx, ssl.SSLContext)\n", "tests/test_web_urldispatcher.py": "import asyncio\nimport functools\nimport pathlib\nimport sys\nfrom typing import Optional\nfrom unittest import mock\nfrom unittest.mock import MagicMock\n\nimport pytest\nimport yarl\n\nfrom aiohttp import web\nfrom aiohttp.pytest_plugin import AiohttpClient\nfrom aiohttp.web_urldispatcher import Resource, SystemRoute\n\n\n@pytest.mark.parametrize(\n    \"show_index,status,prefix,request_path,data\",\n    [\n        pytest.param(False, 403, \"/\", \"/\", None, id=\"index_forbidden\"),\n        pytest.param(\n            True,\n            200,\n            \"/\",\n            \"/\",\n            b\"<html>\\n<head>\\n<title>Index of /.</title>\\n</head>\\n<body>\\n<h1>Index of\"\n            b' /.</h1>\\n<ul>\\n<li><a href=\"/my_dir\">my_dir/</a></li>\\n<li><a href=\"/my_file\">'\n            b\"my_file</a></li>\\n</ul>\\n</body>\\n</html>\",\n        ),\n        pytest.param(\n            True,\n            200,\n            \"/static\",\n            \"/static\",\n            b\"<html>\\n<head>\\n<title>Index of /.</title>\\n</head>\\n<body>\\n<h1>Index of\"\n            b' /.</h1>\\n<ul>\\n<li><a href=\"/static/my_dir\">my_dir/</a></li>\\n<li><a href=\"'\n            b'/static/my_file\">my_file</a></li>\\n</ul>\\n</body>\\n</html>',\n            id=\"index_static\",\n        ),\n        pytest.param(\n            True,\n            200,\n            \"/static\",\n            \"/static/my_dir\",\n            b\"<html>\\n<head>\\n<title>Index of /my_dir</title>\\n</head>\\n<body>\\n<h1>\"\n            b'Index of /my_dir</h1>\\n<ul>\\n<li><a href=\"/static/my_dir/my_file_in_dir\">'\n            b\"my_file_in_dir</a></li>\\n</ul>\\n</body>\\n</html>\",\n            id=\"index_subdir\",\n        ),\n    ],\n)\nasync def test_access_root_of_static_handler(\n    tmp_path: pathlib.Path,\n    aiohttp_client: AiohttpClient,\n    show_index: bool,\n    status: int,\n    prefix: str,\n    request_path: str,\n    data: Optional[bytes],\n) -> None:\n    # Tests the operation of static file server.\n    # Try to access the root of static file server, and make\n    # sure that correct HTTP statuses are returned depending if we directory\n    # index should be shown or not.\n    my_file = tmp_path / \"my_file\"\n    my_dir = tmp_path / \"my_dir\"\n    my_dir.mkdir()\n    my_file_in_dir = my_dir / \"my_file_in_dir\"\n\n    with my_file.open(\"w\") as fw:\n        fw.write(\"hello\")\n\n    with my_file_in_dir.open(\"w\") as fw:\n        fw.write(\"world\")\n\n    app = web.Application()\n\n    # Register global static route:\n    app.router.add_static(prefix, str(tmp_path), show_index=show_index)\n    client = await aiohttp_client(app)\n\n    # Request the root of the static directory.\n    async with await client.get(request_path) as r:\n        assert r.status == status\n\n        if data:\n            assert r.headers[\"Content-Type\"] == \"text/html; charset=utf-8\"\n            read_ = await r.read()\n            assert read_ == data\n\n\n@pytest.mark.internal  # Dependent on filesystem\n@pytest.mark.skipif(\n    not sys.platform.startswith(\"linux\"),\n    reason=\"Invalid filenames on some filesystems (like Windows)\",\n)\n@pytest.mark.parametrize(\n    \"show_index,status,prefix,request_path,data\",\n    [\n        pytest.param(False, 403, \"/\", \"/\", None, id=\"index_forbidden\"),\n        pytest.param(\n            True,\n            200,\n            \"/\",\n            \"/\",\n            b\"<html>\\n<head>\\n<title>Index of /.</title>\\n</head>\\n<body>\\n<h1>Index of\"\n            b' /.</h1>\\n<ul>\\n<li><a href=\"/%3Cimg%20src=0%20onerror=alert(1)%3E.dir\">&l'\n            b't;img src=0 onerror=alert(1)&gt;.dir/</a></li>\\n<li><a href=\"/%3Cimg%20sr'\n            b'c=0%20onerror=alert(1)%3E.txt\">&lt;img src=0 onerror=alert(1)&gt;.txt</a></l'\n            b\"i>\\n</ul>\\n</body>\\n</html>\",\n        ),\n        pytest.param(\n            True,\n            200,\n            \"/static\",\n            \"/static\",\n            b\"<html>\\n<head>\\n<title>Index of /.</title>\\n</head>\\n<body>\\n<h1>Index of\"\n            b' /.</h1>\\n<ul>\\n<li><a href=\"/static/%3Cimg%20src=0%20onerror=alert(1)%3E.'\n            b'dir\">&lt;img src=0 onerror=alert(1)&gt;.dir/</a></li>\\n<li><a href=\"/stat'\n            b'ic/%3Cimg%20src=0%20onerror=alert(1)%3E.txt\">&lt;img src=0 onerror=alert(1)&'\n            b\"gt;.txt</a></li>\\n</ul>\\n</body>\\n</html>\",\n            id=\"index_static\",\n        ),\n        pytest.param(\n            True,\n            200,\n            \"/static\",\n            \"/static/<img src=0 onerror=alert(1)>.dir\",\n            b\"<html>\\n<head>\\n<title>Index of /&lt;img src=0 onerror=alert(1)&gt;.dir</t\"\n            b\"itle>\\n</head>\\n<body>\\n<h1>Index of /&lt;img src=0 onerror=alert(1)&gt;.di\"\n            b'r</h1>\\n<ul>\\n<li><a href=\"/static/%3Cimg%20src=0%20onerror=alert(1)%3E.di'\n            b'r/my_file_in_dir\">my_file_in_dir</a></li>\\n</ul>\\n</body>\\n</html>',\n            id=\"index_subdir\",\n        ),\n    ],\n)\nasync def test_access_root_of_static_handler_xss(\n    tmp_path: pathlib.Path,\n    aiohttp_client: AiohttpClient,\n    show_index: bool,\n    status: int,\n    prefix: str,\n    request_path: str,\n    data: Optional[bytes],\n) -> None:\n    # Tests the operation of static file server.\n    # Try to access the root of static file server, and make\n    # sure that correct HTTP statuses are returned depending if we directory\n    # index should be shown or not.\n    # Ensure that html in file names is escaped.\n    # Ensure that links are url quoted.\n    my_file = tmp_path / \"<img src=0 onerror=alert(1)>.txt\"\n    my_dir = tmp_path / \"<img src=0 onerror=alert(1)>.dir\"\n    my_dir.mkdir()\n    my_file_in_dir = my_dir / \"my_file_in_dir\"\n\n    with my_file.open(\"w\") as fw:\n        fw.write(\"hello\")\n\n    with my_file_in_dir.open(\"w\") as fw:\n        fw.write(\"world\")\n\n    app = web.Application()\n\n    # Register global static route:\n    app.router.add_static(prefix, str(tmp_path), show_index=show_index)\n    client = await aiohttp_client(app)\n\n    # Request the root of the static directory.\n    async with await client.get(request_path) as r:\n        assert r.status == status\n\n        if data:\n            assert r.headers[\"Content-Type\"] == \"text/html; charset=utf-8\"\n            read_ = await r.read()\n            assert read_ == data\n\n\nasync def test_follow_symlink(\n    tmp_path: pathlib.Path, aiohttp_client: AiohttpClient\n) -> None:\n    # Tests the access to a symlink, in static folder\n    data = \"hello world\"\n\n    my_dir_path = tmp_path / \"my_dir\"\n    my_dir_path.mkdir()\n\n    my_file_path = my_dir_path / \"my_file_in_dir\"\n    with my_file_path.open(\"w\") as fw:\n        fw.write(data)\n\n    my_symlink_path = tmp_path / \"my_symlink\"\n    pathlib.Path(str(my_symlink_path)).symlink_to(str(my_dir_path), True)\n\n    app = web.Application()\n\n    # Register global static route:\n    app.router.add_static(\"/\", str(tmp_path), follow_symlinks=True)\n    client = await aiohttp_client(app)\n\n    # Request the root of the static directory.\n    r = await client.get(\"/my_symlink/my_file_in_dir\")\n    assert r.status == 200\n    assert (await r.text()) == data\n\n\nasync def test_follow_symlink_directory_traversal(\n    tmp_path: pathlib.Path, aiohttp_client: AiohttpClient\n) -> None:\n    # Tests that follow_symlinks does not allow directory transversal\n    data = \"private\"\n\n    private_file = tmp_path / \"private_file\"\n    private_file.write_text(data)\n\n    safe_path = tmp_path / \"safe_dir\"\n    safe_path.mkdir()\n\n    app = web.Application()\n\n    # Register global static route:\n    app.router.add_static(\"/\", str(safe_path), follow_symlinks=True)\n    client = await aiohttp_client(app)\n\n    await client.start_server()\n    # We need to use a raw socket to test this, as the client will normalize\n    # the path before sending it to the server.\n    reader, writer = await asyncio.open_connection(client.host, client.port)\n    writer.write(b\"GET /../private_file HTTP/1.1\\r\\n\\r\\n\")\n    response = await reader.readuntil(b\"\\r\\n\\r\\n\")\n    assert b\"404 Not Found\" in response\n    writer.close()\n    await writer.wait_closed()\n    await client.close()\n\n\nasync def test_follow_symlink_directory_traversal_after_normalization(\n    tmp_path: pathlib.Path, aiohttp_client: AiohttpClient\n) -> None:\n    # Tests that follow_symlinks does not allow directory transversal\n    # after normalization\n    #\n    # Directory structure\n    # |-- secret_dir\n    # |   |-- private_file (should never be accessible)\n    # |   |-- symlink_target_dir\n    # |       |-- symlink_target_file (should be accessible via the my_symlink symlink)\n    # |       |-- sandbox_dir\n    # |           |-- my_symlink -> symlink_target_dir\n    #\n    secret_path = tmp_path / \"secret_dir\"\n    secret_path.mkdir()\n\n    # This file is below the symlink target and should not be reachable\n    private_file = secret_path / \"private_file\"\n    private_file.write_text(\"private\")\n\n    symlink_target_path = secret_path / \"symlink_target_dir\"\n    symlink_target_path.mkdir()\n\n    sandbox_path = symlink_target_path / \"sandbox_dir\"\n    sandbox_path.mkdir()\n\n    # This file should be reachable via the symlink\n    symlink_target_file = symlink_target_path / \"symlink_target_file\"\n    symlink_target_file.write_text(\"readable\")\n\n    my_symlink_path = sandbox_path / \"my_symlink\"\n    pathlib.Path(str(my_symlink_path)).symlink_to(str(symlink_target_path), True)\n\n    app = web.Application()\n\n    # Register global static route:\n    app.router.add_static(\"/\", str(sandbox_path), follow_symlinks=True)\n    client = await aiohttp_client(app)\n\n    await client.start_server()\n    # We need to use a raw socket to test this, as the client will normalize\n    # the path before sending it to the server.\n    reader, writer = await asyncio.open_connection(client.host, client.port)\n    writer.write(b\"GET /my_symlink/../private_file HTTP/1.1\\r\\n\\r\\n\")\n    response = await reader.readuntil(b\"\\r\\n\\r\\n\")\n    assert b\"404 Not Found\" in response\n    writer.close()\n    await writer.wait_closed()\n\n    reader, writer = await asyncio.open_connection(client.host, client.port)\n    writer.write(b\"GET /my_symlink/symlink_target_file HTTP/1.1\\r\\n\\r\\n\")\n    response = await reader.readuntil(b\"\\r\\n\\r\\n\")\n    assert b\"200 OK\" in response\n    response = await reader.readuntil(b\"readable\")\n    assert response == b\"readable\"\n    writer.close()\n    await writer.wait_closed()\n    await client.close()\n\n\n@pytest.mark.parametrize(\n    \"dir_name,filename,data\",\n    [\n        (\"\", \"test file.txt\", \"test text\"),\n        (\"test dir name\", \"test dir file .txt\", \"test text file folder\"),\n    ],\n)\nasync def test_access_to_the_file_with_spaces(\n    tmp_path: pathlib.Path,\n    aiohttp_client: AiohttpClient,\n    dir_name: str,\n    filename: str,\n    data: str,\n) -> None:\n    # Checks operation of static files with spaces\n\n    my_dir_path = tmp_path / dir_name\n    if my_dir_path != tmp_path:\n        my_dir_path.mkdir()\n\n    my_file_path = my_dir_path / filename\n    with my_file_path.open(\"w\") as fw:\n        fw.write(data)\n\n    app = web.Application()\n\n    url = \"/\" + str(pathlib.Path(dir_name, filename))\n\n    app.router.add_static(\"/\", str(tmp_path))\n    client = await aiohttp_client(app)\n\n    r = await client.get(url)\n    assert r.status == 200\n    assert (await r.text()) == data\n\n\nasync def test_access_non_existing_resource(\n    tmp_path: pathlib.Path, aiohttp_client: AiohttpClient\n) -> None:\n    # Tests accessing non-existing resource\n    # Try to access a non-exiting resource and make sure that 404 HTTP status\n    # returned.\n    app = web.Application()\n\n    # Register global static route:\n    app.router.add_static(\"/\", str(tmp_path), show_index=True)\n    client = await aiohttp_client(app)\n\n    # Request the root of the static directory.\n    r = await client.get(\"/non_existing_resource\")\n    assert r.status == 404\n\n\n@pytest.mark.parametrize(\n    \"registered_path,request_url\",\n    [\n        (\"/a:b\", \"/a:b\"),\n        (\"/a@b\", \"/a@b\"),\n        (\"/a:b\", \"/a%3Ab\"),\n    ],\n)\nasync def test_url_escaping(\n    aiohttp_client: AiohttpClient, registered_path: str, request_url: str\n) -> None:\n    # Tests accessing a resource with\n    app = web.Application()\n\n    async def handler(request: web.Request) -> web.Response:\n        return web.Response()\n\n    app.router.add_get(registered_path, handler)\n    client = await aiohttp_client(app)\n\n    r = await client.get(request_url)\n    assert r.status == 200\n\n\nasync def test_handler_metadata_persistence() -> None:\n    # Tests accessing metadata of a handler after registering it on the app\n    # router.\n    app = web.Application()\n\n    async def async_handler(request: web.Request) -> web.Response:\n        \"\"\"Doc\"\"\"\n        return web.Response()  # pragma: no cover\n\n    app.router.add_get(\"/async\", async_handler)\n\n    for resource in app.router.resources():\n        for route in resource:\n            assert route.handler.__doc__ == \"Doc\"\n\n\nasync def test_unauthorized_folder_access(\n    tmp_path: pathlib.Path, aiohttp_client: AiohttpClient\n) -> None:\n    # Tests the unauthorized access to a folder of static file server.\n    # Try to list a folder content of static file server when server does not\n    # have permissions to do so for the folder.\n    my_dir = tmp_path / \"my_dir\"\n    my_dir.mkdir()\n\n    app = web.Application()\n\n    with mock.patch(\"pathlib.Path.__new__\") as path_constructor:\n        path = MagicMock()\n        path.joinpath.return_value = path\n        path.resolve.return_value = path\n        path.iterdir.return_value.__iter__.side_effect = PermissionError()\n        path_constructor.return_value = path\n\n        # Register global static route:\n        app.router.add_static(\"/\", str(tmp_path), show_index=True)\n        client = await aiohttp_client(app)\n\n        # Request the root of the static directory.\n        r = await client.get(\"/\" + my_dir.name)\n        assert r.status == 403\n\n\nasync def test_access_symlink_loop(\n    tmp_path: pathlib.Path, aiohttp_client: AiohttpClient\n) -> None:\n    # Tests the access to a looped symlink, which could not be resolved.\n    my_dir_path = tmp_path / \"my_symlink\"\n    pathlib.Path(str(my_dir_path)).symlink_to(str(my_dir_path), True)\n\n    app = web.Application()\n\n    # Register global static route:\n    app.router.add_static(\"/\", str(tmp_path), show_index=True)\n    client = await aiohttp_client(app)\n\n    # Request the root of the static directory.\n    r = await client.get(\"/\" + my_dir_path.name)\n    assert r.status == 404\n\n\nasync def test_access_special_resource(\n    tmp_path: pathlib.Path, aiohttp_client: AiohttpClient\n) -> None:\n    # Tests the access to a resource that is neither a file nor a directory.\n    # Checks that if a special resource is accessed (f.e. named pipe or UNIX\n    # domain socket) then 404 HTTP status returned.\n    app = web.Application()\n\n    with mock.patch(\"pathlib.Path.__new__\") as path_constructor:\n        special = MagicMock()\n        special.is_dir.return_value = False\n        special.is_file.return_value = False\n\n        path = MagicMock()\n        path.joinpath.side_effect = lambda p: (special if p == \"special\" else path)\n        path.resolve.return_value = path\n        special.resolve.return_value = special\n\n        path_constructor.return_value = path\n\n        # Register global static route:\n        app.router.add_static(\"/\", str(tmp_path), show_index=True)\n        client = await aiohttp_client(app)\n\n        # Request the root of the static directory.\n        r = await client.get(\"/special\")\n        assert r.status == 403\n\n\nasync def test_partially_applied_handler(aiohttp_client: AiohttpClient) -> None:\n    app = web.Application()\n\n    async def handler(data: bytes, request: web.Request) -> web.Response:\n        return web.Response(body=data)\n\n    app.router.add_route(\"GET\", \"/\", functools.partial(handler, b\"hello\"))\n\n    client = await aiohttp_client(app)\n\n    r = await client.get(\"/\")\n    data = await r.read()\n    assert data == b\"hello\"\n\n\nasync def test_static_head(\n    tmp_path: pathlib.Path, aiohttp_client: AiohttpClient\n) -> None:\n    # Test HEAD on static route\n    my_file_path = tmp_path / \"test.txt\"\n    with my_file_path.open(\"wb\") as fw:\n        fw.write(b\"should_not_see_this\\n\")\n\n    app = web.Application()\n    app.router.add_static(\"/\", str(tmp_path))\n    client = await aiohttp_client(app)\n\n    r = await client.head(\"/test.txt\")\n    assert r.status == 200\n\n    # Check that there is no content sent (see #4809). This can't easily be\n    # done with aiohttp_client because the buffering can consume the content.\n    reader, writer = await asyncio.open_connection(client.host, client.port)\n    writer.write(b\"HEAD /test.txt HTTP/1.1\\r\\n\")\n    writer.write(b\"Host: localhost\\r\\n\")\n    writer.write(b\"Connection: close\\r\\n\")\n    writer.write(b\"\\r\\n\")\n    while await reader.readline() != b\"\\r\\n\":\n        pass\n    content = await reader.read()\n    writer.close()\n    assert content == b\"\"\n\n\ndef test_system_route() -> None:\n    route = SystemRoute(web.HTTPCreated(reason=\"test\"))\n    with pytest.raises(RuntimeError):\n        route.url_for()\n    assert route.name is None\n    assert route.resource is None\n    assert \"<SystemRoute 201: test>\" == repr(route)\n    assert 201 == route.status\n    assert \"test\" == route.reason\n\n\nasync def test_allow_head(aiohttp_client: AiohttpClient) -> None:\n    # Test allow_head on routes.\n    app = web.Application()\n\n    async def handler(request: web.Request) -> web.Response:\n        return web.Response()\n\n    app.router.add_get(\"/a\", handler, name=\"a\")\n    app.router.add_get(\"/b\", handler, allow_head=False, name=\"b\")\n    client = await aiohttp_client(app)\n\n    r = await client.get(\"/a\")\n    assert r.status == 200\n    await r.release()\n\n    r = await client.head(\"/a\")\n    assert r.status == 200\n    await r.release()\n\n    r = await client.get(\"/b\")\n    assert r.status == 200\n    await r.release()\n\n    r = await client.head(\"/b\")\n    assert r.status == 405\n    await r.release()\n\n\n@pytest.mark.parametrize(\n    \"path\",\n    [\n        \"/a\",\n        \"/{a}\",\n    ],\n)\ndef test_reuse_last_added_resource(path: str) -> None:\n    # Test that adding a route with the same name and path of the last added\n    # resource doesn't create a new resource.\n    app = web.Application()\n\n    async def handler(request: web.Request) -> web.Response:\n        return web.Response()  # pragma: no cover\n\n    app.router.add_get(path, handler, name=\"a\")\n    app.router.add_post(path, handler, name=\"a\")\n\n    assert len(app.router.resources()) == 1\n\n\ndef test_resource_raw_match() -> None:\n    app = web.Application()\n\n    async def handler(request: web.Request) -> web.Response:\n        return web.Response()  # pragma: no cover\n\n    route = app.router.add_get(\"/a\", handler, name=\"a\")\n    assert route.resource is not None\n    assert route.resource.raw_match(\"/a\")\n\n    route = app.router.add_get(\"/{b}\", handler, name=\"b\")\n    assert route.resource is not None\n    assert route.resource.raw_match(\"/{b}\")\n\n    resource = app.router.add_static(\"/static\", \".\")\n    assert not resource.raw_match(\"/static\")\n\n\nasync def test_add_view(aiohttp_client: AiohttpClient) -> None:\n    app = web.Application()\n\n    class MyView(web.View):\n        async def get(self) -> web.Response:\n            return web.Response()\n\n        async def post(self) -> web.Response:\n            return web.Response()\n\n    app.router.add_view(\"/a\", MyView)\n\n    client = await aiohttp_client(app)\n\n    r = await client.get(\"/a\")\n    assert r.status == 200\n    await r.release()\n\n    r = await client.post(\"/a\")\n    assert r.status == 200\n    await r.release()\n\n    r = await client.put(\"/a\")\n    assert r.status == 405\n    await r.release()\n\n\nasync def test_decorate_view(aiohttp_client: AiohttpClient) -> None:\n    routes = web.RouteTableDef()\n\n    @routes.view(\"/a\")\n    class MyView(web.View):\n        async def get(self) -> web.Response:\n            return web.Response()\n\n        async def post(self) -> web.Response:\n            return web.Response()\n\n    app = web.Application()\n    app.router.add_routes(routes)\n\n    client = await aiohttp_client(app)\n\n    r = await client.get(\"/a\")\n    assert r.status == 200\n    await r.release()\n\n    r = await client.post(\"/a\")\n    assert r.status == 200\n    await r.release()\n\n    r = await client.put(\"/a\")\n    assert r.status == 405\n    await r.release()\n\n\nasync def test_web_view(aiohttp_client: AiohttpClient) -> None:\n    app = web.Application()\n\n    class MyView(web.View):\n        async def get(self) -> web.Response:\n            return web.Response()\n\n        async def post(self) -> web.Response:\n            return web.Response()\n\n    app.router.add_routes([web.view(\"/a\", MyView)])\n\n    client = await aiohttp_client(app)\n\n    r = await client.get(\"/a\")\n    assert r.status == 200\n    await r.release()\n\n    r = await client.post(\"/a\")\n    assert r.status == 200\n    await r.release()\n\n    r = await client.put(\"/a\")\n    assert r.status == 405\n    await r.release()\n\n\nasync def test_static_absolute_url(\n    aiohttp_client: AiohttpClient, tmp_path: pathlib.Path\n) -> None:\n    # requested url is an absolute name like\n    # /static/\\\\machine_name\\c$ or /static/D:\\path\n    # where the static dir is totally different\n    app = web.Application()\n    file_path = tmp_path / \"file.txt\"\n    file_path.write_text(\"sample text\", \"ascii\")\n    here = pathlib.Path(__file__).parent\n    app.router.add_static(\"/static\", here)\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/static/\" + str(file_path.resolve()))\n    assert resp.status == 403\n\n\nasync def test_for_issue_5250(\n    aiohttp_client: AiohttpClient, tmp_path: pathlib.Path\n) -> None:\n    app = web.Application()\n    app.router.add_static(\"/foo\", tmp_path)\n\n    async def get_foobar(request: web.Request) -> web.Response:\n        return web.Response(body=\"success!\")\n\n    app.router.add_get(\"/foobar\", get_foobar)\n\n    client = await aiohttp_client(app)\n    async with await client.get(\"/foobar\") as resp:\n        assert resp.status == 200\n        assert (await resp.text()) == \"success!\"\n\n\n@pytest.mark.xfail(\n    raises=AssertionError,\n    reason=\"Regression in v3.7: https://github.com/aio-libs/aiohttp/issues/5621\",\n)\n@pytest.mark.parametrize(\n    (\"route_definition\", \"urlencoded_path\", \"expected_http_resp_status\"),\n    (\n        (\"/467,802,24834/hello\", \"/467%2C802%2C24834/hello\", 200),\n        (\"/{user_ids:([0-9]+)(,([0-9]+))*}/hello\", \"/467%2C802%2C24834/hello\", 200),\n        (\"/1%2C3/hello\", \"/1%2C3/hello\", 404),\n    ),\n    ids=(\"urldecoded_route\", \"urldecoded_route_with_regex\", \"urlencoded_route\"),\n)\nasync def test_decoded_url_match(\n    aiohttp_client: AiohttpClient,\n    route_definition: str,\n    urlencoded_path: str,\n    expected_http_resp_status: int,\n) -> None:\n    app = web.Application()\n\n    async def handler(request: web.Request) -> web.Response:\n        return web.Response()\n\n    app.router.add_get(route_definition, handler)\n    client = await aiohttp_client(app)\n\n    r = await client.get(yarl.URL(urlencoded_path, encoded=True))\n    assert r.status == expected_http_resp_status\n    await r.release()\n\n\nasync def test_order_is_preserved(aiohttp_client: AiohttpClient) -> None:\n    \"\"\"Test route order is preserved.\n\n    Note that fixed/static paths are always preferred over a regex path.\n    \"\"\"\n    app = web.Application()\n\n    async def handler(request: web.Request) -> web.Response:\n        assert isinstance(request.match_info._route.resource, Resource)\n        return web.Response(text=request.match_info._route.resource.canonical)\n\n    app.router.add_get(\"/first/x/{b}/\", handler)\n    app.router.add_get(r\"/first/{x:.*/b}\", handler)\n\n    app.router.add_get(r\"/second/{user}/info\", handler)\n    app.router.add_get(\"/second/bob/info\", handler)\n\n    app.router.add_get(\"/third/bob/info\", handler)\n    app.router.add_get(r\"/third/{user}/info\", handler)\n\n    app.router.add_get(r\"/forth/{name:\\d+}\", handler)\n    app.router.add_get(\"/forth/42\", handler)\n\n    app.router.add_get(\"/fifth/42\", handler)\n    app.router.add_get(r\"/fifth/{name:\\d+}\", handler)\n\n    client = await aiohttp_client(app)\n\n    r = await client.get(\"/first/x/b/\")\n    assert r.status == 200\n    assert await r.text() == \"/first/x/{b}/\"\n\n    r = await client.get(\"/second/frank/info\")\n    assert r.status == 200\n    assert await r.text() == \"/second/{user}/info\"\n\n    # Fixed/static paths are always preferred over regex paths\n    r = await client.get(\"/second/bob/info\")\n    assert r.status == 200\n    assert await r.text() == \"/second/bob/info\"\n\n    r = await client.get(\"/third/bob/info\")\n    assert r.status == 200\n    assert await r.text() == \"/third/bob/info\"\n\n    r = await client.get(\"/third/frank/info\")\n    assert r.status == 200\n    assert await r.text() == \"/third/{user}/info\"\n\n    r = await client.get(\"/forth/21\")\n    assert r.status == 200\n    assert await r.text() == \"/forth/{name}\"\n\n    # Fixed/static paths are always preferred over regex paths\n    r = await client.get(\"/forth/42\")\n    assert r.status == 200\n    assert await r.text() == \"/forth/42\"\n\n    r = await client.get(\"/fifth/21\")\n    assert r.status == 200\n    assert await r.text() == \"/fifth/{name}\"\n\n    r = await client.get(\"/fifth/42\")\n    assert r.status == 200\n    assert await r.text() == \"/fifth/42\"\n\n\nasync def test_url_with_many_slashes(aiohttp_client: AiohttpClient) -> None:\n    app = web.Application()\n\n    class MyView(web.View):\n        async def get(self) -> web.Response:\n            return web.Response()\n\n    app.router.add_routes([web.view(\"/a\", MyView)])\n\n    client = await aiohttp_client(app)\n\n    r = await client.get(\"///a\")\n    assert r.status == 200\n    await r.release()\n", "tests/test_formdata.py": "# type: ignore\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\n\nfrom aiohttp import FormData, web\n\n\n@pytest.fixture\ndef buf():\n    return bytearray()\n\n\n@pytest.fixture\ndef writer(buf: Any):\n    writer = mock.Mock()\n\n    async def write(chunk):\n        buf.extend(chunk)\n\n    writer.write.side_effect = write\n    return writer\n\n\ndef test_formdata_multipart(buf: Any, writer: Any) -> None:\n    form = FormData()\n    assert not form.is_multipart\n\n    form.add_field(\"test\", b\"test\", filename=\"test.txt\")\n    assert form.is_multipart\n\n\ndef test_invalid_formdata_payload() -> None:\n    form = FormData()\n    form.add_field(\"test\", object(), filename=\"test.txt\")\n    with pytest.raises(TypeError):\n        form()\n\n\ndef test_invalid_formdata_params() -> None:\n    with pytest.raises(TypeError):\n        FormData(\"asdasf\")\n\n\ndef test_invalid_formdata_params2() -> None:\n    with pytest.raises(TypeError):\n        FormData(\"as\")  # 2-char str is not allowed\n\n\ndef test_invalid_formdata_content_type() -> None:\n    form = FormData()\n    invalid_vals = [0, 0.1, {}, [], b\"foo\"]\n    for invalid_val in invalid_vals:\n        with pytest.raises(TypeError):\n            form.add_field(\"foo\", \"bar\", content_type=invalid_val)\n\n\ndef test_invalid_formdata_filename() -> None:\n    form = FormData()\n    invalid_vals = [0, 0.1, {}, [], b\"foo\"]\n    for invalid_val in invalid_vals:\n        with pytest.raises(TypeError):\n            form.add_field(\"foo\", \"bar\", filename=invalid_val)\n\n\ndef test_invalid_formdata_content_transfer_encoding() -> None:\n    form = FormData()\n    invalid_vals = [0, 0.1, {}, [], b\"foo\"]\n    for invalid_val in invalid_vals:\n        with pytest.raises(TypeError):\n            form.add_field(\"foo\", \"bar\", content_transfer_encoding=invalid_val)\n\n\nasync def test_formdata_field_name_is_quoted(buf: Any, writer: Any) -> None:\n    form = FormData(charset=\"ascii\")\n    form.add_field(\"email 1\", \"xxx@x.co\", content_type=\"multipart/form-data\")\n    payload = form()\n    await payload.write(writer)\n    assert b'name=\"email\\\\ 1\"' in buf\n\n\nasync def test_formdata_field_name_is_not_quoted(buf: Any, writer: Any) -> None:\n    form = FormData(quote_fields=False, charset=\"ascii\")\n    form.add_field(\"email 1\", \"xxx@x.co\", content_type=\"multipart/form-data\")\n    payload = form()\n    await payload.write(writer)\n    assert b'name=\"email 1\"' in buf\n\n\nasync def test_mark_formdata_as_processed(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.add_routes([web.post(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    data = FormData()\n    data.add_field(\"test\", \"test_value\", content_type=\"application/json\")\n\n    resp = await client.post(\"/\", data=data)\n    assert len(data._writer._parts) == 1\n\n    with pytest.raises(RuntimeError):\n        await client.post(\"/\", data=data)\n\n    resp.release()\n\n\nasync def test_formdata_boundary_param() -> None:\n    boundary = \"some_boundary\"\n    form = FormData(boundary=boundary)\n    assert form._writer.boundary == boundary\n", "tests/test_pytest_plugin.py": "import os\nimport platform\nimport warnings\nfrom typing import Any\n\nfrom aiohttp import pytest_plugin\n\npytest_plugins: str = \"pytester\"\n\nCONFTEST: str = \"\"\"\npytest_plugins = 'aiohttp.pytest_plugin'\n\"\"\"\n\n\nIS_PYPY: Any = platform.python_implementation() == \"PyPy\"\n\n\ndef test_aiohttp_plugin(testdir: Any) -> None:\n    testdir.makepyfile(\n        \"\"\"\\\nimport pytest\nfrom unittest import mock\n\nfrom aiohttp import web\n\n\nasync def hello(request):\n    return web.Response(body=b'Hello, world')\n\n\nasync def create_app():\n    app = web.Application()\n    app.router.add_route('GET', '/', hello)\n    return app\n\n\nasync def test_hello(aiohttp_client) -> None:\n    client = await aiohttp_client(await create_app())\n    resp = await client.get('/')\n    assert resp.status == 200\n    text = await resp.text()\n    assert 'Hello, world' in text\n\n\nasync def test_hello_from_app(aiohttp_client) -> None:\n    app = web.Application()\n    app.router.add_get('/', hello)\n    client = await aiohttp_client(app)\n    resp = await client.get('/')\n    assert resp.status == 200\n    text = await resp.text()\n    assert 'Hello, world' in text\n\n\nasync def test_hello_with_loop(aiohttp_client) -> None:\n    client = await aiohttp_client(await create_app())\n    resp = await client.get('/')\n    assert resp.status == 200\n    text = await resp.text()\n    assert 'Hello, world' in text\n\n\nasync def test_noop() -> None:\n    pass\n\n\nasync def previous(request):\n    if request.method == 'POST':\n        with pytest.deprecated_call():  # FIXME: this isn't actually called\n            request.app['value'] = (await request.post())['value']\n        return web.Response(body=b'thanks for the data')\n    else:\n        v = request.app.get('value', 'unknown')\n        return web.Response(body='value: {}'.format(v).encode())\n\n\ndef create_stateful_app():\n    app = web.Application()\n    app.router.add_route('*', '/', previous)\n    return app\n\n\n@pytest.fixture\ndef cli(loop, aiohttp_client):\n    return loop.run_until_complete(aiohttp_client(create_stateful_app()))\n\n\ndef test_noncoro() -> None:\n    assert True\n\n\nasync def test_failed_to_create_client(aiohttp_client) -> None:\n\n    def make_app():\n        raise RuntimeError()\n\n    with pytest.raises(RuntimeError):\n        await aiohttp_client(make_app())\n\n\nasync def test_custom_port_aiohttp_client(aiohttp_client, aiohttp_unused_port):\n    port = aiohttp_unused_port()\n    client = await aiohttp_client(await create_app(),\n                                  server_kwargs={'port': port})\n    assert client.port == port\n    resp = await client.get('/')\n    assert resp.status == 200\n    text = await resp.text()\n    assert 'Hello, world' in text\n\n\nasync def test_custom_port_test_server(aiohttp_server, aiohttp_unused_port):\n    app = await create_app()\n    port = aiohttp_unused_port()\n    server = await aiohttp_server(app, port=port)\n    assert server.port == port\n\n\"\"\"\n    )\n    testdir.makeconftest(CONFTEST)\n    result = testdir.runpytest(\"-p\", \"no:sugar\", \"--aiohttp-loop=pyloop\")\n    result.assert_outcomes(passed=8)\n\n\ndef test_warning_checks(testdir: Any) -> None:\n    testdir.makepyfile(\n        \"\"\"\\\n\nasync def foobar():\n    return 123\n\nasync def test_good() -> None:\n    v = await foobar()\n    assert v == 123\n\nasync def test_bad() -> None:\n    foobar()\n\"\"\"\n    )\n    testdir.makeconftest(CONFTEST)\n    result = testdir.runpytest(\n        \"-p\", \"no:sugar\", \"-s\", \"-W\", \"default\", \"--aiohttp-loop=pyloop\"\n    )\n    expected_outcomes = (\n        {\"failed\": 0, \"passed\": 2}\n        if IS_PYPY and bool(os.environ.get(\"PYTHONASYNCIODEBUG\"))\n        else {\"failed\": 1, \"passed\": 1}\n    )\n    # Under PyPy \"coroutine 'foobar' was never awaited\" does not happen.\n    result.assert_outcomes(**expected_outcomes)\n\n\ndef test_aiohttp_plugin_async_fixture(testdir: Any, capsys: Any) -> None:\n    testdir.makepyfile(\n        \"\"\"\\\nimport pytest\n\nfrom aiohttp import web\n\n\nasync def hello(request):\n    return web.Response(body=b'Hello, world')\n\n\ndef create_app():\n    app = web.Application()\n    app.router.add_route('GET', '/', hello)\n    return app\n\n\n@pytest.fixture\nasync def cli(aiohttp_client, loop):\n    client = await aiohttp_client(create_app())\n    return client\n\n\n@pytest.fixture\nasync def foo():\n    return 42\n\n\n@pytest.fixture\nasync def bar(request):\n    # request should be accessible in async fixtures if needed\n    return request.function\n\n\nasync def test_hello(cli, loop) -> None:\n    resp = await cli.get('/')\n    assert resp.status == 200\n\n\ndef test_foo(loop, foo) -> None:\n    assert foo == 42\n\n\ndef test_foo_without_loop(foo) -> None:\n    # will raise an error because there is no loop\n    pass\n\n\ndef test_bar(loop, bar) -> None:\n    assert bar is test_bar\n\"\"\"\n    )\n    testdir.makeconftest(CONFTEST)\n    result = testdir.runpytest(\"-p\", \"no:sugar\", \"--aiohttp-loop=pyloop\")\n    result.assert_outcomes(passed=3, errors=1)\n    result.stdout.fnmatch_lines(\n        \"*Asynchronous fixtures must depend on the 'loop' fixture \"\n        \"or be used in tests depending from it.\"\n    )\n\n\ndef test_aiohttp_plugin_async_gen_fixture(testdir: Any) -> None:\n    testdir.makepyfile(\n        \"\"\"\\\nimport pytest\nfrom unittest import mock\n\nfrom aiohttp import web\n\n\ncanary = mock.Mock()\n\n\nasync def hello(request):\n    return web.Response(body=b'Hello, world')\n\n\ndef create_app():\n    app = web.Application()\n    app.router.add_route('GET', '/', hello)\n    return app\n\n\n@pytest.fixture\nasync def cli(aiohttp_client, loop):\n    yield await aiohttp_client(create_app())\n    canary()\n\n\nasync def test_hello(cli) -> None:\n    resp = await cli.get('/')\n    assert resp.status == 200\n\n\ndef test_finalized() -> None:\n    assert canary.called is True\n\"\"\"\n    )\n    testdir.makeconftest(CONFTEST)\n    result = testdir.runpytest(\"-p\", \"no:sugar\", \"--aiohttp-loop=pyloop\")\n    result.assert_outcomes(passed=2)\n\n\ndef test_warnings_propagated(recwarn: Any) -> None:\n    with pytest_plugin._runtime_warning_context():\n        warnings.warn(\"test warning is propagated\")\n    assert len(recwarn) == 1\n    message = recwarn[0].message\n    assert isinstance(message, UserWarning)\n    assert message.args == (\"test warning is propagated\",)\n\n\ndef test_aiohttp_client_cls_fixture_custom_client_used(testdir: Any) -> None:\n    testdir.makepyfile(\n        \"\"\"\nimport pytest\nfrom aiohttp.web import Application\nfrom aiohttp.test_utils import TestClient\n\n\nclass CustomClient(TestClient):\n    pass\n\n\n@pytest.fixture\ndef aiohttp_client_cls():\n    return CustomClient\n\n\nasync def test_hello(aiohttp_client) -> None:\n    client = await aiohttp_client(Application())\n    assert isinstance(client, CustomClient)\n\n\"\"\"\n    )\n    testdir.makeconftest(CONFTEST)\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=1)\n\n\ndef test_aiohttp_client_cls_fixture_factory(testdir: Any) -> None:\n    testdir.makeconftest(\n        CONFTEST\n        + \"\"\"\n\ndef pytest_configure(config):\n    config.addinivalue_line(\"markers\", \"rest: RESTful API tests\")\n    config.addinivalue_line(\"markers\", \"graphql: GraphQL API tests\")\n\n\"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\nimport pytest\nfrom aiohttp.web import Application\nfrom aiohttp.test_utils import TestClient\n\n\nclass RESTfulClient(TestClient):\n    pass\n\n\nclass GraphQLClient(TestClient):\n    pass\n\n\n@pytest.fixture\ndef aiohttp_client_cls(request):\n    if request.node.get_closest_marker('rest') is not None:\n        return RESTfulClient\n    elif request.node.get_closest_marker('graphql') is not None:\n        return GraphQLClient\n    return TestClient\n\n\n@pytest.mark.rest\nasync def test_rest(aiohttp_client) -> None:\n    client = await aiohttp_client(Application())\n    assert isinstance(client, RESTfulClient)\n\n\n@pytest.mark.graphql\nasync def test_graphql(aiohttp_client) -> None:\n    client = await aiohttp_client(Application())\n    assert isinstance(client, GraphQLClient)\n\n\"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=2)\n", "tests/test_web_middleware.py": "# type: ignore\nfrom typing import Any\n\nimport pytest\nfrom yarl import URL\n\nfrom aiohttp import web\nfrom aiohttp.typedefs import Handler\n\n\nasync def test_middleware_modifies_response(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"OK\")\n\n    async def middleware(request, handler: Handler):\n        resp = await handler(request)\n        assert 200 == resp.status\n        resp.set_status(201)\n        resp.text = resp.text + \"[MIDDLEWARE]\"\n        return resp\n\n    app = web.Application()\n    app.middlewares.append(middleware)\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/\")\n    assert 201 == resp.status\n    txt = await resp.text()\n    assert \"OK[MIDDLEWARE]\" == txt\n\n\nasync def test_middleware_handles_exception(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        raise RuntimeError(\"Error text\")\n\n    async def middleware(request, handler: Handler):\n        with pytest.raises(RuntimeError) as ctx:\n            await handler(request)\n        return web.Response(status=501, text=str(ctx.value) + \"[MIDDLEWARE]\")\n\n    app = web.Application()\n    app.middlewares.append(middleware)\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/\")\n    assert 501 == resp.status\n    txt = await resp.text()\n    assert \"Error text[MIDDLEWARE]\" == txt\n\n\nasync def test_middleware_chain(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=\"OK\")\n\n    handler.annotation = \"annotation_value\"\n\n    async def handler2(request):\n        return web.Response(text=\"OK\")\n\n    middleware_annotation_seen_values = []\n\n    def make_middleware(num):\n        async def middleware(request, handler: Handler):\n            middleware_annotation_seen_values.append(\n                getattr(handler, \"annotation\", None)\n            )\n            resp = await handler(request)\n            resp.text = resp.text + f\"[{num}]\"\n            return resp\n\n        return middleware\n\n    app = web.Application()\n    app.middlewares.append(make_middleware(1))\n    app.middlewares.append(make_middleware(2))\n    app.router.add_route(\"GET\", \"/\", handler)\n    app.router.add_route(\"GET\", \"/r2\", handler2)\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert \"OK[2][1]\" == txt\n    assert middleware_annotation_seen_values == [\"annotation_value\", \"annotation_value\"]\n\n    # check that attributes from handler are not applied to handler2\n    resp = await client.get(\"/r2\")\n    assert 200 == resp.status\n    assert middleware_annotation_seen_values == [\n        \"annotation_value\",\n        \"annotation_value\",\n        None,\n        None,\n    ]\n\n\nasync def test_middleware_subapp(loop: Any, aiohttp_client: Any) -> None:\n    async def sub_handler(request):\n        return web.Response(text=\"OK\")\n\n    sub_handler.annotation = \"annotation_value\"\n\n    async def handler(request):\n        return web.Response(text=\"OK\")\n\n    middleware_annotation_seen_values = []\n\n    def make_middleware(num):\n        async def middleware(request, handler: Handler):\n            annotation = getattr(handler, \"annotation\", None)\n            if annotation is not None:\n                middleware_annotation_seen_values.append(f\"{annotation}/{num}\")\n            return await handler(request)\n\n        return middleware\n\n    app = web.Application()\n    app.middlewares.append(make_middleware(1))\n    app.router.add_route(\"GET\", \"/r2\", handler)\n\n    subapp = web.Application()\n    subapp.middlewares.append(make_middleware(2))\n    subapp.router.add_route(\"GET\", \"/\", sub_handler)\n    app.add_subapp(\"/sub\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/sub/\")\n    assert 200 == resp.status\n    await resp.text()\n    assert middleware_annotation_seen_values == [\n        \"annotation_value/1\",\n        \"annotation_value/2\",\n    ]\n\n    # check that attributes from sub_handler are not applied to handler\n    del middleware_annotation_seen_values[:]\n    resp = await client.get(\"/r2\")\n    assert 200 == resp.status\n    assert middleware_annotation_seen_values == []\n\n\n@pytest.fixture\ndef cli(loop: Any, aiohttp_client: Any):\n    async def handler(request):\n        return web.Response(text=\"OK\")\n\n    def wrapper(extra_middlewares):\n        app = web.Application()\n        app.router.add_route(\"GET\", \"/resource1\", handler)\n        app.router.add_route(\"GET\", \"/resource2/\", handler)\n        app.router.add_route(\"GET\", \"/resource1/a/b\", handler)\n        app.router.add_route(\"GET\", \"/resource2/a/b/\", handler)\n        app.router.add_route(\"GET\", \"/resource2/a/b%2Fc/\", handler)\n        app.middlewares.extend(extra_middlewares)\n        return aiohttp_client(app, server_kwargs={\"skip_url_asserts\": True})\n\n    return wrapper\n\n\nclass TestNormalizePathMiddleware:\n    @pytest.mark.parametrize(\n        \"path, status\",\n        [\n            (\"/resource1\", 200),\n            (\"/resource1/\", 404),\n            (\"/resource2\", 200),\n            (\"/resource2/\", 200),\n            (\"/resource1?p1=1&p2=2\", 200),\n            (\"/resource1/?p1=1&p2=2\", 404),\n            (\"/resource2?p1=1&p2=2\", 200),\n            (\"/resource2/?p1=1&p2=2\", 200),\n            (\"/resource2/a/b%2Fc\", 200),\n            (\"/resource2/a/b%2Fc/\", 200),\n        ],\n    )\n    async def test_add_trailing_when_necessary(\n        self, path: Any, status: Any, cli: Any\n    ) -> None:\n        extra_middlewares = [web.normalize_path_middleware(merge_slashes=False)]\n        client = await cli(extra_middlewares)\n\n        resp = await client.get(path)\n        assert resp.status == status\n        assert resp.url.query == URL(path).query\n\n    @pytest.mark.parametrize(\n        \"path, status\",\n        [\n            (\"/resource1\", 200),\n            (\"/resource1/\", 200),\n            (\"/resource2\", 404),\n            (\"/resource2/\", 200),\n            (\"/resource1?p1=1&p2=2\", 200),\n            (\"/resource1/?p1=1&p2=2\", 200),\n            (\"/resource2?p1=1&p2=2\", 404),\n            (\"/resource2/?p1=1&p2=2\", 200),\n            (\"/resource2/a/b%2Fc\", 404),\n            (\"/resource2/a/b%2Fc/\", 200),\n            (\"/resource12\", 404),\n            (\"/resource12345\", 404),\n        ],\n    )\n    async def test_remove_trailing_when_necessary(\n        self, path: Any, status: Any, cli: Any\n    ) -> None:\n        extra_middlewares = [\n            web.normalize_path_middleware(\n                append_slash=False, remove_slash=True, merge_slashes=False\n            )\n        ]\n        client = await cli(extra_middlewares)\n\n        resp = await client.get(path)\n        assert resp.status == status\n        assert resp.url.query == URL(path).query\n\n    @pytest.mark.parametrize(\n        \"path, status\",\n        [\n            (\"/resource1\", 200),\n            (\"/resource1/\", 404),\n            (\"/resource2\", 404),\n            (\"/resource2/\", 200),\n            (\"/resource1?p1=1&p2=2\", 200),\n            (\"/resource1/?p1=1&p2=2\", 404),\n            (\"/resource2?p1=1&p2=2\", 404),\n            (\"/resource2/?p1=1&p2=2\", 200),\n            (\"/resource2/a/b%2Fc\", 404),\n            (\"/resource2/a/b%2Fc/\", 200),\n        ],\n    )\n    async def test_no_trailing_slash_when_disabled(\n        self, path: Any, status: Any, cli: Any\n    ) -> None:\n        extra_middlewares = [\n            web.normalize_path_middleware(append_slash=False, merge_slashes=False)\n        ]\n        client = await cli(extra_middlewares)\n\n        resp = await client.get(path)\n        assert resp.status == status\n        assert resp.url.query == URL(path).query\n\n    @pytest.mark.parametrize(\n        \"path, status\",\n        [\n            (\"/resource1/a/b\", 200),\n            (\"//resource1//a//b\", 200),\n            (\"//resource1//a//b/\", 404),\n            (\"///resource1//a//b\", 200),\n            (\"/////resource1/a///b\", 200),\n            (\"/////resource1/a//b/\", 404),\n            (\"/resource1/a/b?p=1\", 200),\n            (\"//resource1//a//b?p=1\", 200),\n            (\"//resource1//a//b/?p=1\", 404),\n            (\"///resource1//a//b?p=1\", 200),\n            (\"/////resource1/a///b?p=1\", 200),\n            (\"/////resource1/a//b/?p=1\", 404),\n        ],\n    )\n    async def test_merge_slash(self, path: Any, status: Any, cli: Any) -> None:\n        extra_middlewares = [web.normalize_path_middleware(append_slash=False)]\n        client = await cli(extra_middlewares)\n\n        resp = await client.get(path)\n        assert resp.status == status\n        assert resp.url.query == URL(path).query\n\n    @pytest.mark.parametrize(\n        \"path, status\",\n        [\n            (\"/resource1/a/b\", 200),\n            (\"/resource1/a/b/\", 404),\n            (\"//resource2//a//b\", 200),\n            (\"//resource2//a//b/\", 200),\n            (\"///resource1//a//b\", 200),\n            (\"///resource1//a//b/\", 404),\n            (\"/////resource1/a///b\", 200),\n            (\"/////resource1/a///b/\", 404),\n            (\"/resource2/a/b\", 200),\n            (\"//resource2//a//b\", 200),\n            (\"//resource2//a//b/\", 200),\n            (\"///resource2//a//b\", 200),\n            (\"///resource2//a//b/\", 200),\n            (\"/////resource2/a///b\", 200),\n            (\"/////resource2/a///b/\", 200),\n            (\"/resource1/a/b?p=1\", 200),\n            (\"/resource1/a/b/?p=1\", 404),\n            (\"//resource2//a//b?p=1\", 200),\n            (\"//resource2//a//b/?p=1\", 200),\n            (\"///resource1//a//b?p=1\", 200),\n            (\"///resource1//a//b/?p=1\", 404),\n            (\"/////resource1/a///b?p=1\", 200),\n            (\"/////resource1/a///b/?p=1\", 404),\n            (\"/resource2/a/b?p=1\", 200),\n            (\"//resource2//a//b?p=1\", 200),\n            (\"//resource2//a//b/?p=1\", 200),\n            (\"///resource2//a//b?p=1\", 200),\n            (\"///resource2//a//b/?p=1\", 200),\n            (\"/////resource2/a///b?p=1\", 200),\n            (\"/////resource2/a///b/?p=1\", 200),\n        ],\n    )\n    async def test_append_and_merge_slash(\n        self, path: Any, status: Any, cli: Any\n    ) -> None:\n        extra_middlewares = [web.normalize_path_middleware()]\n\n        client = await cli(extra_middlewares)\n        resp = await client.get(path)\n        assert resp.status == status\n        assert resp.url.query == URL(path).query\n\n    @pytest.mark.parametrize(\n        \"path, status\",\n        [\n            (\"/resource1/a/b\", 200),\n            (\"/resource1/a/b/\", 200),\n            (\"//resource2//a//b\", 404),\n            (\"//resource2//a//b/\", 200),\n            (\"///resource1//a//b\", 200),\n            (\"///resource1//a//b/\", 200),\n            (\"/////resource1/a///b\", 200),\n            (\"/////resource1/a///b/\", 200),\n            (\"/////resource1/a///b///\", 200),\n            (\"/resource2/a/b\", 404),\n            (\"//resource2//a//b\", 404),\n            (\"//resource2//a//b/\", 200),\n            (\"///resource2//a//b\", 404),\n            (\"///resource2//a//b/\", 200),\n            (\"/////resource2/a///b\", 404),\n            (\"/////resource2/a///b/\", 200),\n            (\"/resource1/a/b?p=1\", 200),\n            (\"/resource1/a/b/?p=1\", 200),\n            (\"//resource2//a//b?p=1\", 404),\n            (\"//resource2//a//b/?p=1\", 200),\n            (\"///resource1//a//b?p=1\", 200),\n            (\"///resource1//a//b/?p=1\", 200),\n            (\"/////resource1/a///b?p=1\", 200),\n            (\"/////resource1/a///b/?p=1\", 200),\n            (\"/resource2/a/b?p=1\", 404),\n            (\"//resource2//a//b?p=1\", 404),\n            (\"//resource2//a//b/?p=1\", 200),\n            (\"///resource2//a//b?p=1\", 404),\n            (\"///resource2//a//b/?p=1\", 200),\n            (\"/////resource2/a///b?p=1\", 404),\n            (\"/////resource2/a///b/?p=1\", 200),\n        ],\n    )\n    async def test_remove_and_merge_slash(\n        self, path: Any, status: Any, cli: Any\n    ) -> None:\n        extra_middlewares = [\n            web.normalize_path_middleware(append_slash=False, remove_slash=True)\n        ]\n\n        client = await cli(extra_middlewares)\n        resp = await client.get(path)\n        assert resp.status == status\n        assert resp.url.query == URL(path).query\n\n    async def test_cannot_remove_and_add_slash(self) -> None:\n        with pytest.raises(AssertionError):\n            web.normalize_path_middleware(append_slash=True, remove_slash=True)\n\n    @pytest.mark.parametrize(\n        [\"append_slash\", \"remove_slash\"],\n        [\n            (True, False),\n            (False, True),\n            (False, False),\n        ],\n    )\n    async def test_open_redirects(\n        self, append_slash: bool, remove_slash: bool, aiohttp_client: Any\n    ) -> None:\n        async def handle(request: web.Request) -> web.StreamResponse:\n            pytest.fail(\n                msg=\"Security advisory 'GHSA-v6wp-4m6f-gcjg' test handler \"\n                \"matched unexpectedly\",\n                pytrace=False,\n            )\n\n        app = web.Application(\n            middlewares=[\n                web.normalize_path_middleware(\n                    append_slash=append_slash, remove_slash=remove_slash\n                )\n            ]\n        )\n        app.add_routes([web.get(\"/\", handle), web.get(\"/google.com\", handle)])\n        client = await aiohttp_client(app, server_kwargs={\"skip_url_asserts\": True})\n        resp = await client.get(\"//google.com\", allow_redirects=False)\n        assert resp.status == 308\n        assert resp.headers[\"Location\"] == \"/google.com\"\n        assert resp.url.query == URL(\"//google.com\").query\n\n\nasync def test_bug_3669(aiohttp_client: Any):\n    async def paymethod(request):\n        return web.Response(text=\"OK\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/paymethod\", paymethod)\n    app.middlewares.append(\n        web.normalize_path_middleware(append_slash=False, remove_slash=True)\n    )\n\n    client = await aiohttp_client(app, server_kwargs={\"skip_url_asserts\": True})\n\n    resp = await client.get(\"/paymethods\")\n    assert resp.status == 404\n    assert resp.url.path != \"/paymethod\"\n\n\nasync def test_old_style_middleware(loop: Any, aiohttp_client: Any) -> None:\n    async def view_handler(request):\n        return web.Response(body=b\"OK\")\n\n    with pytest.deprecated_call(\n        match=r\"^Middleware decorator is deprecated since 4\\.0 and its \"\n        r\"behaviour is default, you can simply remove this decorator\\.$\",\n    ):\n\n        @web.middleware\n        async def middleware(request, handler: Handler):\n            resp = await handler(request)\n            assert 200 == resp.status\n            resp.set_status(201)\n            resp.text = resp.text + \"[old style middleware]\"\n            return resp\n\n    app = web.Application(middlewares=[middleware])\n    app.router.add_route(\"GET\", \"/\", view_handler)\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/\")\n    assert 201 == resp.status\n    txt = await resp.text()\n    assert \"OK[old style middleware]\" == txt\n\n\nasync def test_new_style_middleware_class(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"OK\")\n\n    class Middleware:\n        async def __call__(self, request, handler: Handler):\n            resp = await handler(request)\n            assert 200 == resp.status\n            resp.set_status(201)\n            resp.text = resp.text + \"[new style middleware]\"\n            return resp\n\n    app = web.Application()\n    app.middlewares.append(Middleware())\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/\")\n    assert 201 == resp.status\n    txt = await resp.text()\n    assert \"OK[new style middleware]\" == txt\n\n\nasync def test_new_style_middleware_method(loop: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"OK\")\n\n    class Middleware:\n        async def call(self, request, handler: Handler):\n            resp = await handler(request)\n            assert 200 == resp.status\n            resp.set_status(201)\n            resp.text = resp.text + \"[new style middleware]\"\n            return resp\n\n    app = web.Application()\n    app.middlewares.append(Middleware().call)\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/\")\n    assert 201 == resp.status\n    txt = await resp.text()\n    assert \"OK[new style middleware]\" == txt\n", "tests/test_route_def.py": "# type: ignore\nimport pathlib\nfrom typing import Any\n\nimport pytest\nfrom yarl import URL\n\nfrom aiohttp import web\nfrom aiohttp.web_urldispatcher import UrlDispatcher\n\n\n@pytest.fixture\ndef router():\n    return UrlDispatcher()\n\n\ndef test_get(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    router.add_routes([web.get(\"/\", handler)])\n    assert len(router.routes()) == 2  # GET and HEAD\n\n    route = list(router.routes())[1]\n    assert route.handler is handler\n    assert route.method == \"GET\"\n    assert str(route.url_for()) == \"/\"\n\n    route2 = list(router.routes())[0]\n    assert route2.handler is handler\n    assert route2.method == \"HEAD\"\n\n\ndef test_head(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    router.add_routes([web.head(\"/\", handler)])\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.handler is handler\n    assert route.method == \"HEAD\"\n    assert str(route.url_for()) == \"/\"\n\n\ndef test_options(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    router.add_routes([web.options(\"/\", handler)])\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.handler is handler\n    assert route.method == \"OPTIONS\"\n    assert str(route.url_for()) == \"/\"\n\n\ndef test_post(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    router.add_routes([web.post(\"/\", handler)])\n\n    route = list(router.routes())[0]\n    assert route.handler is handler\n    assert route.method == \"POST\"\n    assert str(route.url_for()) == \"/\"\n\n\ndef test_put(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    router.add_routes([web.put(\"/\", handler)])\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.handler is handler\n    assert route.method == \"PUT\"\n    assert str(route.url_for()) == \"/\"\n\n\ndef test_patch(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    router.add_routes([web.patch(\"/\", handler)])\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.handler is handler\n    assert route.method == \"PATCH\"\n    assert str(route.url_for()) == \"/\"\n\n\ndef test_delete(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    router.add_routes([web.delete(\"/\", handler)])\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.handler is handler\n    assert route.method == \"DELETE\"\n    assert str(route.url_for()) == \"/\"\n\n\ndef test_route(router: Any) -> None:\n    async def handler(request):\n        pass\n\n    router.add_routes([web.route(\"OTHER\", \"/\", handler)])\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.handler is handler\n    assert route.method == \"OTHER\"\n    assert str(route.url_for()) == \"/\"\n\n\ndef test_static(router: Any) -> None:\n    folder = pathlib.Path(__file__).parent\n    router.add_routes([web.static(\"/prefix\", folder)])\n    assert len(router.resources()) == 1  # 2 routes: for HEAD and GET\n\n    resource = list(router.resources())[0]\n    info = resource.get_info()\n    assert info[\"prefix\"] == \"/prefix\"\n    assert info[\"directory\"] == folder\n    url = resource.url_for(filename=\"aiohttp.png\")\n    assert url == URL(\"/prefix/aiohttp.png\")\n\n\ndef test_head_deco(router: Any) -> None:\n    routes = web.RouteTableDef()\n\n    @routes.head(\"/path\")\n    async def handler(request):\n        pass\n\n    router.add_routes(routes)\n\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.method == \"HEAD\"\n    assert str(route.url_for()) == \"/path\"\n\n\ndef test_get_deco(router: Any) -> None:\n    routes = web.RouteTableDef()\n\n    @routes.get(\"/path\")\n    async def handler(request):\n        pass\n\n    router.add_routes(routes)\n\n    assert len(router.routes()) == 2\n\n    route1 = list(router.routes())[0]\n    assert route1.method == \"HEAD\"\n    assert str(route1.url_for()) == \"/path\"\n\n    route2 = list(router.routes())[1]\n    assert route2.method == \"GET\"\n    assert str(route2.url_for()) == \"/path\"\n\n\ndef test_post_deco(router: Any) -> None:\n    routes = web.RouteTableDef()\n\n    @routes.post(\"/path\")\n    async def handler(request):\n        pass\n\n    router.add_routes(routes)\n\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.method == \"POST\"\n    assert str(route.url_for()) == \"/path\"\n\n\ndef test_put_deco(router: Any) -> None:\n    routes = web.RouteTableDef()\n\n    @routes.put(\"/path\")\n    async def handler(request):\n        pass\n\n    router.add_routes(routes)\n\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.method == \"PUT\"\n    assert str(route.url_for()) == \"/path\"\n\n\ndef test_patch_deco(router: Any) -> None:\n    routes = web.RouteTableDef()\n\n    @routes.patch(\"/path\")\n    async def handler(request):\n        pass\n\n    router.add_routes(routes)\n\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.method == \"PATCH\"\n    assert str(route.url_for()) == \"/path\"\n\n\ndef test_delete_deco(router: Any) -> None:\n    routes = web.RouteTableDef()\n\n    @routes.delete(\"/path\")\n    async def handler(request):\n        pass\n\n    router.add_routes(routes)\n\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.method == \"DELETE\"\n    assert str(route.url_for()) == \"/path\"\n\n\ndef test_options_deco(router: Any) -> None:\n    routes = web.RouteTableDef()\n\n    @routes.options(\"/path\")\n    async def handler(request):\n        pass\n\n    router.add_routes(routes)\n\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.method == \"OPTIONS\"\n    assert str(route.url_for()) == \"/path\"\n\n\ndef test_route_deco(router: Any) -> None:\n    routes = web.RouteTableDef()\n\n    @routes.route(\"OTHER\", \"/path\")\n    async def handler(request):\n        pass\n\n    router.add_routes(routes)\n\n    assert len(router.routes()) == 1\n\n    route = list(router.routes())[0]\n    assert route.method == \"OTHER\"\n    assert str(route.url_for()) == \"/path\"\n\n\ndef test_routedef_sequence_protocol() -> None:\n    routes = web.RouteTableDef()\n\n    @routes.delete(\"/path\")\n    async def handler(request):\n        pass\n\n    assert len(routes) == 1\n\n    info = routes[0]\n    assert isinstance(info, web.RouteDef)\n    assert info in routes\n    assert list(routes)[0] is info\n\n\ndef test_repr_route_def() -> None:\n    routes = web.RouteTableDef()\n\n    @routes.get(\"/path\")\n    async def handler(request):\n        pass\n\n    rd = routes[0]\n    assert repr(rd) == \"<RouteDef GET /path -> 'handler'>\"\n\n\ndef test_repr_route_def_with_extra_info() -> None:\n    routes = web.RouteTableDef()\n\n    @routes.get(\"/path\", extra=\"info\")\n    async def handler(request):\n        pass\n\n    rd = routes[0]\n    assert repr(rd) == \"<RouteDef GET /path -> 'handler', extra='info'>\"\n\n\ndef test_repr_static_def() -> None:\n    routes = web.RouteTableDef()\n\n    routes.static(\"/prefix\", \"/path\", name=\"name\")\n\n    rd = routes[0]\n    assert repr(rd) == \"<StaticDef /prefix -> /path, name='name'>\"\n\n\ndef test_repr_route_table_def() -> None:\n    routes = web.RouteTableDef()\n\n    @routes.get(\"/path\")\n    async def handler(request):\n        pass\n\n    assert repr(routes) == \"<RouteTableDef count=1>\"\n", "tests/test_loop.py": "import asyncio\nimport platform\nimport threading\nfrom typing import Any\n\nimport pytest\n\nfrom aiohttp import web\nfrom aiohttp.test_utils import AioHTTPTestCase, loop_context\n\n\n@pytest.mark.skipif(\n    platform.system() == \"Windows\", reason=\"the test is not valid for Windows\"\n)\nasync def test_subprocess_co(loop: Any) -> None:\n    proc = await asyncio.create_subprocess_shell(\n        \"exit 0\",\n        stdin=asyncio.subprocess.DEVNULL,\n        stdout=asyncio.subprocess.DEVNULL,\n        stderr=asyncio.subprocess.DEVNULL,\n    )\n    await proc.wait()\n\n\nclass TestCase(AioHTTPTestCase):\n    on_startup_called: bool\n\n    async def get_application(self) -> web.Application:\n        app = web.Application()\n        app.on_startup.append(self.on_startup_hook)\n        return app\n\n    async def on_startup_hook(self, app: Any) -> None:\n        self.on_startup_called = True\n\n    async def test_on_startup_hook(self) -> None:\n        self.assertTrue(self.on_startup_called)\n\n\ndef test_default_loop(loop: Any) -> None:\n    assert asyncio.get_event_loop_policy().get_event_loop() is loop\n\n\ndef test_setup_loop_non_main_thread() -> None:\n    child_exc = None\n\n    def target() -> None:\n        try:\n            with loop_context() as loop:\n                assert asyncio.get_event_loop_policy().get_event_loop() is loop\n                loop.run_until_complete(test_subprocess_co(loop))\n        except Exception as exc:\n            nonlocal child_exc\n            child_exc = exc\n\n    # Ensures setup_test_loop can be called by pytest-xdist in non-main thread.\n    t = threading.Thread(target=target)\n    t.start()\n    t.join()\n\n    assert child_exc is None\n", "tests/test_http_exceptions.py": "# type: ignore\n# Tests for http_exceptions.py\n\nimport pickle\n\nfrom aiohttp import http_exceptions\n\n\nclass TestHttpProcessingError:\n    def test_ctor(self) -> None:\n        err = http_exceptions.HttpProcessingError(\n            code=500, message=\"Internal error\", headers={}\n        )\n        assert err.code == 500\n        assert err.message == \"Internal error\"\n        assert err.headers == {}\n\n    def test_pickle(self) -> None:\n        err = http_exceptions.HttpProcessingError(\n            code=500, message=\"Internal error\", headers={}\n        )\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.code == 500\n            assert err2.message == \"Internal error\"\n            assert err2.headers == {}\n            assert err2.foo == \"bar\"\n\n    def test_str(self) -> None:\n        err = http_exceptions.HttpProcessingError(\n            code=500, message=\"Internal error\", headers={}\n        )\n        assert str(err) == \"500, message:\\n  Internal error\"\n\n    def test_repr(self) -> None:\n        err = http_exceptions.HttpProcessingError(\n            code=500, message=\"Internal error\", headers={}\n        )\n        assert repr(err) == (\"<HttpProcessingError: 500, message='Internal error'>\")\n\n\nclass TestBadHttpMessage:\n    def test_ctor(self) -> None:\n        err = http_exceptions.BadHttpMessage(\"Bad HTTP message\", headers={})\n        assert err.code == 400\n        assert err.message == \"Bad HTTP message\"\n        assert err.headers == {}\n\n    def test_pickle(self) -> None:\n        err = http_exceptions.BadHttpMessage(message=\"Bad HTTP message\", headers={})\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.code == 400\n            assert err2.message == \"Bad HTTP message\"\n            assert err2.headers == {}\n            assert err2.foo == \"bar\"\n\n    def test_str(self) -> None:\n        err = http_exceptions.BadHttpMessage(message=\"Bad HTTP message\", headers={})\n        assert str(err) == \"400, message:\\n  Bad HTTP message\"\n\n    def test_repr(self) -> None:\n        err = http_exceptions.BadHttpMessage(message=\"Bad HTTP message\", headers={})\n        assert repr(err) == \"<BadHttpMessage: 400, message='Bad HTTP message'>\"\n\n\nclass TestLineTooLong:\n    def test_ctor(self) -> None:\n        err = http_exceptions.LineTooLong(\"spam\", \"10\", \"12\")\n        assert err.code == 400\n        assert err.message == \"Got more than 10 bytes (12) when reading spam.\"\n        assert err.headers is None\n\n    def test_pickle(self) -> None:\n        err = http_exceptions.LineTooLong(line=\"spam\", limit=\"10\", actual_size=\"12\")\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.code == 400\n            assert err2.message == (\"Got more than 10 bytes (12) \" \"when reading spam.\")\n            assert err2.headers is None\n            assert err2.foo == \"bar\"\n\n    def test_str(self) -> None:\n        err = http_exceptions.LineTooLong(line=\"spam\", limit=\"10\", actual_size=\"12\")\n        expected = \"400, message:\\n  Got more than 10 bytes (12) when reading spam.\"\n        assert str(err) == expected\n\n    def test_repr(self) -> None:\n        err = http_exceptions.LineTooLong(line=\"spam\", limit=\"10\", actual_size=\"12\")\n        assert repr(err) == (\n            \"<LineTooLong: 400, message='Got more than \"\n            \"10 bytes (12) when reading spam.'>\"\n        )\n\n\nclass TestInvalidHeader:\n    def test_ctor(self) -> None:\n        err = http_exceptions.InvalidHeader(\"X-Spam\")\n        assert err.code == 400\n        assert err.message == \"Invalid HTTP header: 'X-Spam'\"\n        assert err.headers is None\n\n    def test_pickle(self) -> None:\n        err = http_exceptions.InvalidHeader(hdr=\"X-Spam\")\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.code == 400\n            assert err2.message == \"Invalid HTTP header: 'X-Spam'\"\n            assert err2.headers is None\n            assert err2.foo == \"bar\"\n\n    def test_str(self) -> None:\n        err = http_exceptions.InvalidHeader(hdr=\"X-Spam\")\n        assert str(err) == \"400, message:\\n  Invalid HTTP header: 'X-Spam'\"\n\n    def test_repr(self) -> None:\n        err = http_exceptions.InvalidHeader(hdr=\"X-Spam\")\n        expected = \"<InvalidHeader: 400, message=\\\"Invalid HTTP header: 'X-Spam'\\\">\"\n        assert repr(err) == expected\n\n\nclass TestBadStatusLine:\n    def test_ctor(self) -> None:\n        err = http_exceptions.BadStatusLine(\"Test\")\n        assert err.line == \"Test\"\n        assert str(err) == \"400, message:\\n  Bad status line 'Test'\"\n\n    def test_ctor2(self) -> None:\n        err = http_exceptions.BadStatusLine(b\"\")\n        assert err.line == \"b''\"\n        assert str(err) == \"400, message:\\n  Bad status line \\\"b''\\\"\"\n\n    def test_pickle(self) -> None:\n        err = http_exceptions.BadStatusLine(\"Test\")\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.line == \"Test\"\n            assert err2.foo == \"bar\"\n", "tests/test_client_fingerprint.py": "import hashlib\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\n\nimport aiohttp\n\nssl: Any = pytest.importorskip(\"ssl\")\n\n\ndef test_fingerprint_sha256() -> None:\n    sha256 = hashlib.sha256(b\"12345678\" * 64).digest()\n    fp = aiohttp.Fingerprint(sha256)\n    assert fp.fingerprint == sha256\n\n\ndef test_fingerprint_sha1() -> None:\n    sha1 = hashlib.sha1(b\"12345678\" * 64).digest()\n    with pytest.raises(ValueError):\n        aiohttp.Fingerprint(sha1)\n\n\ndef test_fingerprint_md5() -> None:\n    md5 = hashlib.md5(b\"12345678\" * 64).digest()\n    with pytest.raises(ValueError):\n        aiohttp.Fingerprint(md5)\n\n\ndef test_fingerprint_check_no_ssl() -> None:\n    sha256 = hashlib.sha256(b\"12345678\" * 64).digest()\n    fp = aiohttp.Fingerprint(sha256)\n    transport = mock.Mock()\n    transport.get_extra_info.return_value = None\n    fp.check(transport)\n", "tests/test_web_response.py": "# type: ignore\nimport collections.abc\nimport datetime\nimport gzip\nimport json\nimport re\nimport weakref\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import Any, Optional\nfrom unittest import mock\n\nimport aiosignal\nimport pytest\nfrom multidict import CIMultiDict, CIMultiDictProxy\nfrom re_assert import Matches\n\nfrom aiohttp import HttpVersion, HttpVersion10, HttpVersion11, hdrs\nfrom aiohttp.helpers import ETag\nfrom aiohttp.http_writer import StreamWriter, _serialize_headers\nfrom aiohttp.payload import BytesPayload\nfrom aiohttp.test_utils import make_mocked_coro, make_mocked_request\nfrom aiohttp.web import ContentCoding, Response, StreamResponse, json_response\n\n\ndef make_request(\n    method: Any,\n    path: Any,\n    headers: Any = CIMultiDict(),\n    version: Any = HttpVersion11,\n    on_response_prepare: Optional[Any] = None,\n    **kwargs: Any,\n):\n    app = kwargs.pop(\"app\", None) or mock.Mock()\n    app._debug = False\n    if on_response_prepare is None:\n        on_response_prepare = aiosignal.Signal(app)\n    app.on_response_prepare = on_response_prepare\n    app.on_response_prepare.freeze()\n    protocol = kwargs.pop(\"protocol\", None) or mock.Mock()\n    return make_mocked_request(\n        method, path, headers, version=version, protocol=protocol, app=app, **kwargs\n    )\n\n\n@pytest.fixture\ndef buf():\n    return bytearray()\n\n\n@pytest.fixture\ndef writer(buf: Any):\n    writer = mock.Mock()\n\n    def acquire(cb):\n        cb(writer.transport)\n\n    def buffer_data(chunk):\n        buf.extend(chunk)\n\n    def write(chunk):\n        buf.extend(chunk)\n\n    async def write_headers(status_line, headers):\n        headers = _serialize_headers(status_line, headers)\n        buf.extend(headers)\n\n    async def write_eof(chunk=b\"\"):\n        buf.extend(chunk)\n\n    writer.acquire.side_effect = acquire\n    writer.transport.write.side_effect = write\n    writer.write.side_effect = write\n    writer.write_eof.side_effect = write_eof\n    writer.write_headers.side_effect = write_headers\n    writer.buffer_data.side_effect = buffer_data\n    writer.drain.return_value = ()\n\n    return writer\n\n\ndef test_stream_response_ctor() -> None:\n    resp = StreamResponse()\n    assert 200 == resp.status\n    assert resp.keep_alive is None\n\n    assert resp.task is None\n\n    req = mock.Mock()\n    resp._req = req\n    assert resp.task is req.task\n\n\ndef test_stream_response_hashable() -> None:\n    # should not raise exception\n    hash(StreamResponse())\n\n\ndef test_stream_response_eq() -> None:\n    resp1 = StreamResponse()\n    resp2 = StreamResponse()\n\n    assert resp1 == resp1\n    assert not resp1 == resp2\n\n\ndef test_stream_response_is_mutable_mapping() -> None:\n    resp = StreamResponse()\n    assert isinstance(resp, collections.abc.MutableMapping)\n    resp[\"key\"] = \"value\"\n    assert \"value\" == resp[\"key\"]\n\n\ndef test_stream_response_delitem() -> None:\n    resp = StreamResponse()\n    resp[\"key\"] = \"value\"\n    del resp[\"key\"]\n    assert \"key\" not in resp\n\n\ndef test_stream_response_len() -> None:\n    resp = StreamResponse()\n    assert len(resp) == 0\n    resp[\"key\"] = \"value\"\n    assert len(resp) == 1\n\n\ndef test_request_iter() -> None:\n    resp = StreamResponse()\n    resp[\"key\"] = \"value\"\n    resp[\"key2\"] = \"value2\"\n    assert set(resp) == {\"key\", \"key2\"}\n\n\ndef test_content_length() -> None:\n    resp = StreamResponse()\n    assert resp.content_length is None\n\n\ndef test_content_length_setter() -> None:\n    resp = StreamResponse()\n\n    resp.content_length = 234\n    assert 234 == resp.content_length\n\n\ndef test_content_length_setter_with_enable_chunked_encoding() -> None:\n    resp = StreamResponse()\n\n    resp.enable_chunked_encoding()\n    with pytest.raises(RuntimeError):\n        resp.content_length = 234\n\n\ndef test_drop_content_length_header_on_setting_len_to_None() -> None:\n    resp = StreamResponse()\n\n    resp.content_length = 1\n    assert \"1\" == resp.headers[\"Content-Length\"]\n    resp.content_length = None\n    assert \"Content-Length\" not in resp.headers\n\n\ndef test_set_content_length_to_None_on_non_set() -> None:\n    resp = StreamResponse()\n\n    resp.content_length = None\n    assert \"Content-Length\" not in resp.headers\n    resp.content_length = None\n    assert \"Content-Length\" not in resp.headers\n\n\ndef test_setting_content_type() -> None:\n    resp = StreamResponse()\n\n    resp.content_type = \"text/html\"\n    assert \"text/html\" == resp.headers[\"content-type\"]\n\n\ndef test_setting_charset() -> None:\n    resp = StreamResponse()\n\n    resp.content_type = \"text/html\"\n    resp.charset = \"koi8-r\"\n    assert \"text/html; charset=koi8-r\" == resp.headers[\"content-type\"]\n\n\ndef test_default_charset() -> None:\n    resp = StreamResponse()\n\n    assert resp.charset is None\n\n\ndef test_reset_charset() -> None:\n    resp = StreamResponse()\n\n    resp.content_type = \"text/html\"\n    resp.charset = None\n    assert resp.charset is None\n\n\ndef test_reset_charset_after_setting() -> None:\n    resp = StreamResponse()\n\n    resp.content_type = \"text/html\"\n    resp.charset = \"koi8-r\"\n    resp.charset = None\n    assert resp.charset is None\n\n\ndef test_charset_without_content_type() -> None:\n    resp = StreamResponse()\n\n    with pytest.raises(RuntimeError):\n        resp.charset = \"koi8-r\"\n\n\ndef test_last_modified_initial() -> None:\n    resp = StreamResponse()\n    assert resp.last_modified is None\n\n\ndef test_last_modified_string() -> None:\n    resp = StreamResponse()\n\n    dt = datetime.datetime(1990, 1, 2, 3, 4, 5, 0, datetime.timezone.utc)\n    resp.last_modified = \"Mon, 2 Jan 1990 03:04:05 GMT\"\n    assert resp.last_modified == dt\n\n\ndef test_last_modified_timestamp() -> None:\n    resp = StreamResponse()\n\n    dt = datetime.datetime(1970, 1, 1, 0, 0, 0, 0, datetime.timezone.utc)\n\n    resp.last_modified = 0\n    assert resp.last_modified == dt\n\n    resp.last_modified = 0.0\n    assert resp.last_modified == dt\n\n\ndef test_last_modified_datetime() -> None:\n    resp = StreamResponse()\n\n    dt = datetime.datetime(2001, 2, 3, 4, 5, 6, 0, datetime.timezone.utc)\n    resp.last_modified = dt\n    assert resp.last_modified == dt\n\n\ndef test_last_modified_reset() -> None:\n    resp = StreamResponse()\n\n    resp.last_modified = 0\n    resp.last_modified = None\n    assert resp.last_modified is None\n\n\n@pytest.mark.parametrize(\n    [\"header_val\", \"expected\"],\n    [\n        pytest.param(\"xxyyzz\", None),\n        pytest.param(\"Tue, 08 Oct 4446413 00:56:40 GMT\", None),\n        pytest.param(\"Tue, 08 Oct 2000 00:56:80 GMT\", None),\n    ],\n)\ndef test_last_modified_string_invalid(header_val, expected) -> None:\n    resp = StreamResponse(headers={\"Last-Modified\": header_val})\n    assert resp.last_modified == expected\n\n\ndef test_etag_initial() -> None:\n    resp = StreamResponse()\n    assert resp.etag is None\n\n\ndef test_etag_string() -> None:\n    resp = StreamResponse()\n    value = \"0123-kotik\"\n    resp.etag = value\n    assert resp.etag == ETag(value=value)\n    assert resp.headers[hdrs.ETAG] == f'\"{value}\"'\n\n\n@pytest.mark.parametrize(\n    [\"etag\", \"expected_header\"],\n    (\n        (ETag(value=\"0123-weak-kotik\", is_weak=True), 'W/\"0123-weak-kotik\"'),\n        (ETag(value=\"0123-strong-kotik\", is_weak=False), '\"0123-strong-kotik\"'),\n    ),\n)\ndef test_etag_class(etag, expected_header) -> None:\n    resp = StreamResponse()\n    resp.etag = etag\n    assert resp.etag == etag\n    assert resp.headers[hdrs.ETAG] == expected_header\n\n\ndef test_etag_any() -> None:\n    resp = StreamResponse()\n    resp.etag = \"*\"\n    assert resp.etag == ETag(value=\"*\")\n    assert resp.headers[hdrs.ETAG] == \"*\"\n\n\n@pytest.mark.parametrize(\n    \"invalid_value\",\n    (\n        '\"invalid\"',\n        \"\u043f\u043e\u0432\u0438\u043d\u0435\u043d \u0431\u0443\u0442\u0438 ascii\",\n        ETag(value='\"invalid\"', is_weak=True),\n        ETag(value=\"bad \u00a9\u00ae\"),\n    ),\n)\ndef test_etag_invalid_value_set(invalid_value) -> None:\n    resp = StreamResponse()\n    with pytest.raises(ValueError, match=\"is not a valid etag\"):\n        resp.etag = invalid_value\n\n\n@pytest.mark.parametrize(\n    \"header\",\n    (\n        \"forgotten quotes\",\n        '\"\u2200 x \u2209 ascii\"',\n    ),\n)\ndef test_etag_invalid_value_get(header) -> None:\n    resp = StreamResponse()\n    resp.headers[\"ETag\"] = header\n    assert resp.etag is None\n\n\n@pytest.mark.parametrize(\"invalid\", (123, ETag(value=123, is_weak=True)))\ndef test_etag_invalid_value_class(invalid) -> None:\n    resp = StreamResponse()\n    with pytest.raises(ValueError, match=\"Unsupported etag type\"):\n        resp.etag = invalid\n\n\ndef test_etag_reset() -> None:\n    resp = StreamResponse()\n    resp.etag = \"*\"\n    resp.etag = None\n    assert resp.etag is None\n\n\nasync def test_start() -> None:\n    req = make_request(\"GET\", \"/\")\n    resp = StreamResponse()\n    assert resp.keep_alive is None\n\n    msg = await resp.prepare(req)\n\n    assert msg.write_headers.called\n    msg2 = await resp.prepare(req)\n    assert msg is msg2\n\n    assert resp.keep_alive\n\n    req2 = make_request(\"GET\", \"/\")\n    # with pytest.raises(RuntimeError):\n    msg3 = await resp.prepare(req2)\n    assert msg is msg3\n\n\nasync def test_chunked_encoding() -> None:\n    req = make_request(\"GET\", \"/\")\n    resp = StreamResponse()\n    assert not resp.chunked\n\n    resp.enable_chunked_encoding()\n    assert resp.chunked\n\n    msg = await resp.prepare(req)\n    assert msg.chunked\n\n\ndef test_enable_chunked_encoding_with_content_length() -> None:\n    resp = StreamResponse()\n\n    resp.content_length = 234\n    with pytest.raises(RuntimeError):\n        resp.enable_chunked_encoding()\n\n\nasync def test_chunked_encoding_forbidden_for_http_10() -> None:\n    req = make_request(\"GET\", \"/\", version=HttpVersion10)\n    resp = StreamResponse()\n    resp.enable_chunked_encoding()\n\n    with pytest.raises(RuntimeError) as ctx:\n        await resp.prepare(req)\n    assert Matches(\"Using chunked encoding is forbidden for HTTP/1.0\") == str(ctx.value)\n\n\nasync def test_compression_no_accept() -> None:\n    req = make_request(\"GET\", \"/\")\n    resp = StreamResponse()\n    assert not resp.chunked\n\n    assert not resp.compression\n    resp.enable_compression()\n    assert resp.compression\n\n    msg = await resp.prepare(req)\n    assert not msg.enable_compression.called\n\n\nasync def test_compression_default_coding() -> None:\n    req = make_request(\n        \"GET\", \"/\", headers=CIMultiDict({hdrs.ACCEPT_ENCODING: \"gzip, deflate\"})\n    )\n    resp = StreamResponse()\n    assert not resp.chunked\n\n    assert not resp.compression\n    resp.enable_compression()\n    assert resp.compression\n\n    msg = await resp.prepare(req)\n\n    msg.enable_compression.assert_called_with(\"deflate\")\n    assert \"deflate\" == resp.headers.get(hdrs.CONTENT_ENCODING)\n    assert msg.filter is not None\n\n\nasync def test_force_compression_deflate() -> None:\n    req = make_request(\n        \"GET\", \"/\", headers=CIMultiDict({hdrs.ACCEPT_ENCODING: \"gzip, deflate\"})\n    )\n    resp = StreamResponse()\n\n    resp.enable_compression(ContentCoding.deflate)\n    assert resp.compression\n\n    msg = await resp.prepare(req)\n    msg.enable_compression.assert_called_with(\"deflate\")\n    assert \"deflate\" == resp.headers.get(hdrs.CONTENT_ENCODING)\n\n\nasync def test_force_compression_no_accept_deflate() -> None:\n    req = make_request(\"GET\", \"/\")\n    resp = StreamResponse()\n\n    resp.enable_compression(ContentCoding.deflate)\n    assert resp.compression\n\n    msg = await resp.prepare(req)\n    msg.enable_compression.assert_called_with(\"deflate\")\n    assert \"deflate\" == resp.headers.get(hdrs.CONTENT_ENCODING)\n\n\nasync def test_force_compression_gzip() -> None:\n    req = make_request(\n        \"GET\", \"/\", headers=CIMultiDict({hdrs.ACCEPT_ENCODING: \"gzip, deflate\"})\n    )\n    resp = StreamResponse()\n\n    resp.enable_compression(ContentCoding.gzip)\n    assert resp.compression\n\n    msg = await resp.prepare(req)\n    msg.enable_compression.assert_called_with(\"gzip\")\n    assert \"gzip\" == resp.headers.get(hdrs.CONTENT_ENCODING)\n\n\nasync def test_force_compression_no_accept_gzip() -> None:\n    req = make_request(\"GET\", \"/\")\n    resp = StreamResponse()\n\n    resp.enable_compression(ContentCoding.gzip)\n    assert resp.compression\n\n    msg = await resp.prepare(req)\n    msg.enable_compression.assert_called_with(\"gzip\")\n    assert \"gzip\" == resp.headers.get(hdrs.CONTENT_ENCODING)\n\n\nasync def test_change_content_threaded_compression_enabled() -> None:\n    req = make_request(\"GET\", \"/\")\n    body_thread_size = 1024\n    body = b\"answer\" * body_thread_size\n    resp = Response(body=body, zlib_executor_size=body_thread_size)\n    resp.enable_compression(ContentCoding.gzip)\n\n    await resp.prepare(req)\n    assert gzip.decompress(resp._compressed_body) == body\n\n\nasync def test_change_content_threaded_compression_enabled_explicit() -> None:\n    req = make_request(\"GET\", \"/\")\n    body_thread_size = 1024\n    body = b\"answer\" * body_thread_size\n    with ThreadPoolExecutor(1) as executor:\n        resp = Response(\n            body=body, zlib_executor_size=body_thread_size, zlib_executor=executor\n        )\n        resp.enable_compression(ContentCoding.gzip)\n\n        await resp.prepare(req)\n        assert gzip.decompress(resp._compressed_body) == body\n\n\nasync def test_change_content_length_if_compression_enabled() -> None:\n    req = make_request(\"GET\", \"/\")\n    resp = Response(body=b\"answer\")\n    resp.enable_compression(ContentCoding.gzip)\n\n    await resp.prepare(req)\n    assert resp.content_length is not None and resp.content_length != len(b\"answer\")\n\n\nasync def test_set_content_length_if_compression_enabled() -> None:\n    writer = mock.Mock()\n\n    async def write_headers(status_line, headers):\n        assert hdrs.CONTENT_LENGTH in headers\n        assert headers[hdrs.CONTENT_LENGTH] == \"26\"\n        assert hdrs.TRANSFER_ENCODING not in headers\n\n    writer.write_headers.side_effect = write_headers\n    req = make_request(\"GET\", \"/\", writer=writer)\n    resp = Response(body=b\"answer\")\n    resp.enable_compression(ContentCoding.gzip)\n\n    await resp.prepare(req)\n    assert resp.content_length == 26\n    del resp.headers[hdrs.CONTENT_LENGTH]\n    assert resp.content_length == 26\n\n\nasync def test_remove_content_length_if_compression_enabled_http11() -> None:\n    writer = mock.Mock()\n\n    async def write_headers(status_line, headers):\n        assert hdrs.CONTENT_LENGTH not in headers\n        assert headers.get(hdrs.TRANSFER_ENCODING, \"\") == \"chunked\"\n\n    writer.write_headers.side_effect = write_headers\n    req = make_request(\"GET\", \"/\", writer=writer)\n    resp = StreamResponse()\n    resp.content_length = 123\n    resp.enable_compression(ContentCoding.gzip)\n    await resp.prepare(req)\n    assert resp.content_length is None\n\n\nasync def test_remove_content_length_if_compression_enabled_http10() -> None:\n    writer = mock.Mock()\n\n    async def write_headers(status_line, headers):\n        assert hdrs.CONTENT_LENGTH not in headers\n        assert hdrs.TRANSFER_ENCODING not in headers\n\n    writer.write_headers.side_effect = write_headers\n    req = make_request(\"GET\", \"/\", version=HttpVersion10, writer=writer)\n    resp = StreamResponse()\n    resp.content_length = 123\n    resp.enable_compression(ContentCoding.gzip)\n    await resp.prepare(req)\n    assert resp.content_length is None\n\n\nasync def test_force_compression_identity() -> None:\n    writer = mock.Mock()\n\n    async def write_headers(status_line, headers):\n        assert hdrs.CONTENT_LENGTH in headers\n        assert hdrs.TRANSFER_ENCODING not in headers\n\n    writer.write_headers.side_effect = write_headers\n    req = make_request(\"GET\", \"/\", writer=writer)\n    resp = StreamResponse()\n    resp.content_length = 123\n    resp.enable_compression(ContentCoding.identity)\n    await resp.prepare(req)\n    assert resp.content_length == 123\n\n\nasync def test_force_compression_identity_response() -> None:\n    writer = mock.Mock()\n\n    async def write_headers(status_line, headers):\n        assert headers[hdrs.CONTENT_LENGTH] == \"6\"\n        assert hdrs.TRANSFER_ENCODING not in headers\n\n    writer.write_headers.side_effect = write_headers\n    req = make_request(\"GET\", \"/\", writer=writer)\n    resp = Response(body=b\"answer\")\n    resp.enable_compression(ContentCoding.identity)\n    await resp.prepare(req)\n    assert resp.content_length == 6\n\n\nasync def test_rm_content_length_if_compression_http11() -> None:\n    writer = mock.Mock()\n\n    async def write_headers(status_line, headers):\n        assert hdrs.CONTENT_LENGTH not in headers\n        assert headers.get(hdrs.TRANSFER_ENCODING, \"\") == \"chunked\"\n\n    writer.write_headers.side_effect = write_headers\n    req = make_request(\"GET\", \"/\", writer=writer)\n    payload = BytesPayload(b\"answer\", headers={\"X-Test-Header\": \"test\"})\n    resp = Response(body=payload)\n    resp.body = payload\n    resp.enable_compression(ContentCoding.gzip)\n    await resp.prepare(req)\n    assert resp.content_length is None\n\n\nasync def test_rm_content_length_if_compression_http10() -> None:\n    writer = mock.Mock()\n\n    async def write_headers(status_line, headers):\n        assert hdrs.CONTENT_LENGTH not in headers\n        assert hdrs.TRANSFER_ENCODING not in headers\n\n    writer.write_headers.side_effect = write_headers\n    req = make_request(\"GET\", \"/\", version=HttpVersion10, writer=writer)\n    resp = Response(body=BytesPayload(b\"answer\"))\n    resp.enable_compression(ContentCoding.gzip)\n    await resp.prepare(req)\n    assert resp.content_length is None\n\n\n@pytest.mark.parametrize(\"status\", (100, 101, 204, 304))\nasync def test_rm_transfer_encoding_rfc_9112_6_3_http_11(status: int) -> None:\n    \"\"\"Remove transfer encoding for RFC 9112 sec 6.3 with HTTP/1.1.\"\"\"\n    writer = mock.create_autospec(StreamWriter, spec_set=True, instance=True)\n    req = make_request(\"GET\", \"/\", version=HttpVersion11, writer=writer)\n    resp = Response(status=status, headers={hdrs.TRANSFER_ENCODING: \"chunked\"})\n    await resp.prepare(req)\n    assert resp.content_length == 0\n    assert not resp.chunked\n    assert hdrs.CONTENT_LENGTH not in resp.headers\n    assert hdrs.TRANSFER_ENCODING not in resp.headers\n\n\n@pytest.mark.parametrize(\"status\", (100, 101, 102, 204, 304))\nasync def test_rm_content_length_1xx_204_304_responses(status: int) -> None:\n    \"\"\"Remove content length for 1xx, 204, and 304 responses.\n\n    Content-Length is forbidden for 1xx and 204\n    https://datatracker.ietf.org/doc/html/rfc7230#section-3.3.2\n\n    Content-Length is discouraged for 304.\n    https://datatracker.ietf.org/doc/html/rfc7232#section-4.1\n    \"\"\"\n    writer = mock.create_autospec(StreamWriter, spec_set=True, instance=True)\n    req = make_request(\"GET\", \"/\", version=HttpVersion11, writer=writer)\n    resp = Response(status=status, body=\"answer\")\n    await resp.prepare(req)\n    assert not resp.chunked\n    assert hdrs.CONTENT_LENGTH not in resp.headers\n    assert hdrs.TRANSFER_ENCODING not in resp.headers\n\n\nasync def test_head_response_keeps_content_length_of_original_body() -> None:\n    \"\"\"Verify HEAD response keeps the content length of the original body HTTP/1.1.\"\"\"\n    writer = mock.create_autospec(StreamWriter, spec_set=True, instance=True)\n    req = make_request(\"HEAD\", \"/\", version=HttpVersion11, writer=writer)\n    resp = Response(status=200, body=b\"answer\")\n    await resp.prepare(req)\n    assert resp.content_length == 6\n    assert not resp.chunked\n    assert resp.headers[hdrs.CONTENT_LENGTH] == \"6\"\n    assert hdrs.TRANSFER_ENCODING not in resp.headers\n\n\nasync def test_head_response_omits_content_length_when_body_unset() -> None:\n    \"\"\"Verify HEAD response omits content-length body when its unset.\"\"\"\n    writer = mock.create_autospec(StreamWriter, spec_set=True, instance=True)\n    req = make_request(\"HEAD\", \"/\", version=HttpVersion11, writer=writer)\n    resp = Response(status=200)\n    await resp.prepare(req)\n    assert resp.content_length == 0\n    assert not resp.chunked\n    assert hdrs.CONTENT_LENGTH not in resp.headers\n    assert hdrs.TRANSFER_ENCODING not in resp.headers\n\n\nasync def test_304_response_omits_content_length_when_body_unset() -> None:\n    \"\"\"Verify 304 response omits content-length body when its unset.\"\"\"\n    writer = mock.create_autospec(StreamWriter, spec_set=True, instance=True)\n    req = make_request(\"GET\", \"/\", version=HttpVersion11, writer=writer)\n    resp = Response(status=304)\n    await resp.prepare(req)\n    assert resp.content_length == 0\n    assert not resp.chunked\n    assert hdrs.CONTENT_LENGTH not in resp.headers\n    assert hdrs.TRANSFER_ENCODING not in resp.headers\n\n\nasync def test_content_length_on_chunked() -> None:\n    req = make_request(\"GET\", \"/\")\n    resp = Response(body=b\"answer\")\n    assert resp.content_length == 6\n    resp.enable_chunked_encoding()\n    assert resp.content_length is None\n    await resp.prepare(req)\n\n\nasync def test_write_non_byteish() -> None:\n    resp = StreamResponse()\n    await resp.prepare(make_request(\"GET\", \"/\"))\n\n    with pytest.raises(AssertionError):\n        await resp.write(123)\n\n\nasync def test_write_before_start() -> None:\n    resp = StreamResponse()\n\n    with pytest.raises(RuntimeError):\n        await resp.write(b\"data\")\n\n\nasync def test_cannot_write_after_eof() -> None:\n    resp = StreamResponse()\n    req = make_request(\"GET\", \"/\")\n    await resp.prepare(req)\n\n    await resp.write(b\"data\")\n    await resp.write_eof()\n    req.writer.write.reset_mock()\n\n    with pytest.raises(RuntimeError):\n        await resp.write(b\"next data\")\n    assert not req.writer.write.called\n\n\nasync def test___repr___after_eof() -> None:\n    resp = StreamResponse()\n    await resp.prepare(make_request(\"GET\", \"/\"))\n\n    assert resp.prepared\n\n    await resp.write(b\"data\")\n    await resp.write_eof()\n    assert not resp.prepared\n    resp_repr = repr(resp)\n    assert resp_repr == \"<StreamResponse OK eof>\"\n\n\nasync def test_cannot_write_eof_before_headers() -> None:\n    resp = StreamResponse()\n\n    with pytest.raises(AssertionError):\n        await resp.write_eof()\n\n\nasync def test_cannot_write_eof_twice() -> None:\n    resp = StreamResponse()\n    writer = mock.Mock()\n    resp_impl = await resp.prepare(make_request(\"GET\", \"/\"))\n    resp_impl.write = make_mocked_coro(None)\n    resp_impl.write_eof = make_mocked_coro(None)\n\n    await resp.write(b\"data\")\n    assert resp_impl.write.called\n\n    await resp.write_eof()\n\n    resp_impl.write.reset_mock()\n    await resp.write_eof()\n    assert not writer.write.called\n\n\ndef test_force_close() -> None:\n    resp = StreamResponse()\n\n    assert resp.keep_alive is None\n    resp.force_close()\n    assert resp.keep_alive is False\n\n\ndef test_set_status_with_reason() -> None:\n    resp = StreamResponse()\n\n    resp.set_status(200, \"Everything is fine!\")\n    assert 200 == resp.status\n    assert \"Everything is fine!\" == resp.reason\n\n\nasync def test_start_force_close() -> None:\n    req = make_request(\"GET\", \"/\")\n    resp = StreamResponse()\n    resp.force_close()\n    assert not resp.keep_alive\n\n    await resp.prepare(req)\n    assert not resp.keep_alive\n\n\nasync def test___repr__() -> None:\n    req = make_request(\"GET\", \"/path/to\")\n    resp = StreamResponse(reason=301)\n    await resp.prepare(req)\n    assert \"<StreamResponse 301 GET /path/to >\" == repr(resp)\n\n\ndef test___repr___not_prepared() -> None:\n    resp = StreamResponse(reason=301)\n    assert \"<StreamResponse 301 not prepared>\" == repr(resp)\n\n\nasync def test_keep_alive_http10_default() -> None:\n    req = make_request(\"GET\", \"/\", version=HttpVersion10)\n    resp = StreamResponse()\n    await resp.prepare(req)\n    assert not resp.keep_alive\n\n\nasync def test_keep_alive_http10_switched_on() -> None:\n    headers = CIMultiDict(Connection=\"keep-alive\")\n    req = make_request(\"GET\", \"/\", version=HttpVersion10, headers=headers)\n    req._message = req._message._replace(should_close=False)\n    resp = StreamResponse()\n    await resp.prepare(req)\n    assert resp.keep_alive\n\n\nasync def test_keep_alive_http09() -> None:\n    headers = CIMultiDict(Connection=\"keep-alive\")\n    req = make_request(\"GET\", \"/\", version=HttpVersion(0, 9), headers=headers)\n    resp = StreamResponse()\n    await resp.prepare(req)\n    assert not resp.keep_alive\n\n\nasync def test_prepare_twice() -> None:\n    req = make_request(\"GET\", \"/\")\n    resp = StreamResponse()\n\n    impl1 = await resp.prepare(req)\n    impl2 = await resp.prepare(req)\n    assert impl1 is impl2\n\n\nasync def test_prepare_calls_signal() -> None:\n    app = mock.Mock()\n    sig = make_mocked_coro()\n    on_response_prepare = aiosignal.Signal(app)\n    on_response_prepare.append(sig)\n    req = make_request(\"GET\", \"/\", app=app, on_response_prepare=on_response_prepare)\n    resp = StreamResponse()\n\n    await resp.prepare(req)\n\n    sig.assert_called_with(req, resp)\n\n\n# Response class\n\n\ndef test_response_ctor() -> None:\n    resp = Response()\n\n    assert 200 == resp.status\n    assert \"OK\" == resp.reason\n    assert resp.body is None\n    assert resp.content_length == 0\n    assert \"CONTENT-LENGTH\" not in resp.headers\n\n\nasync def test_ctor_with_headers_and_status() -> None:\n    resp = Response(body=b\"body\", status=201, headers={\"Age\": \"12\", \"DATE\": \"date\"})\n\n    assert 201 == resp.status\n    assert b\"body\" == resp.body\n    assert resp.headers[\"AGE\"] == \"12\"\n\n    req = make_mocked_request(\"GET\", \"/\")\n    await resp._start(req)\n    assert 4 == resp.content_length\n    assert resp.headers[\"CONTENT-LENGTH\"] == \"4\"\n\n\ndef test_ctor_content_type() -> None:\n    resp = Response(content_type=\"application/json\")\n\n    assert 200 == resp.status\n    assert \"OK\" == resp.reason\n    assert 0 == resp.content_length\n    assert CIMultiDict([(\"CONTENT-TYPE\", \"application/json\")]) == resp.headers\n\n\ndef test_ctor_text_body_combined() -> None:\n    with pytest.raises(ValueError):\n        Response(body=b\"123\", text=\"test text\")\n\n\nasync def test_ctor_text() -> None:\n    resp = Response(text=\"test text\")\n\n    assert 200 == resp.status\n    assert \"OK\" == resp.reason\n    assert 9 == resp.content_length\n    assert CIMultiDict([(\"CONTENT-TYPE\", \"text/plain; charset=utf-8\")]) == resp.headers\n\n    assert resp.body == b\"test text\"\n    assert resp.text == \"test text\"\n\n    resp.headers[\"DATE\"] = \"date\"\n    req = make_mocked_request(\"GET\", \"/\", version=HttpVersion11)\n    await resp._start(req)\n    assert resp.headers[\"CONTENT-LENGTH\"] == \"9\"\n\n\ndef test_ctor_charset() -> None:\n    resp = Response(text=\"\u0442\u0435\u043a\u0441\u0442\", charset=\"koi8-r\")\n\n    assert \"\u0442\u0435\u043a\u0441\u0442\".encode(\"koi8-r\") == resp.body\n    assert \"koi8-r\" == resp.charset\n\n\ndef test_ctor_charset_default_utf8() -> None:\n    resp = Response(text=\"test test\", charset=None)\n\n    assert \"utf-8\" == resp.charset\n\n\ndef test_ctor_charset_in_content_type() -> None:\n    with pytest.raises(ValueError):\n        Response(text=\"test test\", content_type=\"text/plain; charset=utf-8\")\n\n\ndef test_ctor_charset_without_text() -> None:\n    resp = Response(content_type=\"text/plain\", charset=\"koi8-r\")\n\n    assert \"koi8-r\" == resp.charset\n\n\ndef test_ctor_content_type_with_extra() -> None:\n    resp = Response(text=\"test test\", content_type=\"text/plain; version=0.0.4\")\n\n    assert resp.content_type == \"text/plain\"\n    assert resp.headers[\"content-type\"] == \"text/plain; version=0.0.4; charset=utf-8\"\n\n\ndef test_ctor_both_content_type_param_and_header_with_text() -> None:\n    with pytest.raises(ValueError):\n        Response(\n            headers={\"Content-Type\": \"application/json\"},\n            content_type=\"text/html\",\n            text=\"text\",\n        )\n\n\ndef test_ctor_both_charset_param_and_header_with_text() -> None:\n    with pytest.raises(ValueError):\n        Response(\n            headers={\"Content-Type\": \"application/json\"}, charset=\"koi8-r\", text=\"text\"\n        )\n\n\ndef test_ctor_both_content_type_param_and_header() -> None:\n    with pytest.raises(ValueError):\n        Response(headers={\"Content-Type\": \"application/json\"}, content_type=\"text/html\")\n\n\ndef test_ctor_both_charset_param_and_header() -> None:\n    with pytest.raises(ValueError):\n        Response(headers={\"Content-Type\": \"application/json\"}, charset=\"koi8-r\")\n\n\nasync def test_assign_nonbyteish_body() -> None:\n    resp = Response(body=b\"data\")\n\n    with pytest.raises(ValueError):\n        resp.body = 123\n    assert b\"data\" == resp.body\n    assert 4 == resp.content_length\n\n    resp.headers[\"DATE\"] = \"date\"\n    req = make_mocked_request(\"GET\", \"/\", version=HttpVersion11)\n    await resp._start(req)\n    assert resp.headers[\"CONTENT-LENGTH\"] == \"4\"\n    assert 4 == resp.content_length\n\n\ndef test_assign_nonstr_text() -> None:\n    resp = Response(text=\"test\")\n\n    with pytest.raises(AssertionError):\n        resp.text = b\"123\"\n    assert b\"test\" == resp.body\n    assert 4 == resp.content_length\n\n\ndef test_response_set_content_length() -> None:\n    resp = Response()\n    with pytest.raises(RuntimeError):\n        resp.content_length = 1\n\n\nasync def test_send_headers_for_empty_body(buf: Any, writer: Any) -> None:\n    req = make_request(\"GET\", \"/\", writer=writer)\n    resp = Response()\n\n    await resp.prepare(req)\n    await resp.write_eof()\n    txt = buf.decode(\"utf8\")\n    assert (\n        Matches(\n            \"HTTP/1.1 200 OK\\r\\n\"\n            \"Content-Length: 0\\r\\n\"\n            \"Content-Type: application/octet-stream\\r\\n\"\n            \"Date: .+\\r\\n\"\n            \"Server: .+\\r\\n\\r\\n\"\n        )\n        == txt\n    )\n\n\nasync def test_render_with_body(buf: Any, writer: Any) -> None:\n    req = make_request(\"GET\", \"/\", writer=writer)\n    resp = Response(body=b\"data\")\n\n    await resp.prepare(req)\n    await resp.write_eof()\n\n    txt = buf.decode(\"utf8\")\n    assert (\n        Matches(\n            \"HTTP/1.1 200 OK\\r\\n\"\n            \"Content-Length: 4\\r\\n\"\n            \"Content-Type: application/octet-stream\\r\\n\"\n            \"Date: .+\\r\\n\"\n            \"Server: .+\\r\\n\\r\\n\"\n            \"data\"\n        )\n        == txt\n    )\n\n\nasync def test_send_set_cookie_header(buf: Any, writer: Any) -> None:\n    resp = Response()\n    resp.cookies[\"name\"] = \"value\"\n    req = make_request(\"GET\", \"/\", writer=writer)\n\n    await resp.prepare(req)\n    await resp.write_eof()\n\n    txt = buf.decode(\"utf8\")\n    assert (\n        Matches(\n            \"HTTP/1.1 200 OK\\r\\n\"\n            \"Content-Length: 0\\r\\n\"\n            \"Set-Cookie: name=value\\r\\n\"\n            \"Content-Type: application/octet-stream\\r\\n\"\n            \"Date: .+\\r\\n\"\n            \"Server: .+\\r\\n\\r\\n\"\n        )\n        == txt\n    )\n\n\nasync def test_consecutive_write_eof() -> None:\n    writer = mock.Mock()\n    writer.write_eof = make_mocked_coro()\n    writer.write_headers = make_mocked_coro()\n    req = make_request(\"GET\", \"/\", writer=writer)\n    data = b\"data\"\n    resp = Response(body=data)\n\n    await resp.prepare(req)\n    await resp.write_eof()\n    await resp.write_eof()\n    writer.write_eof.assert_called_once_with(data)\n\n\ndef test_set_text_with_content_type() -> None:\n    resp = Response()\n    resp.content_type = \"text/html\"\n    resp.text = \"text\"\n\n    assert \"text\" == resp.text\n    assert b\"text\" == resp.body\n    assert \"text/html\" == resp.content_type\n\n\ndef test_set_text_with_charset() -> None:\n    resp = Response()\n    resp.content_type = \"text/plain\"\n    resp.charset = \"KOI8-R\"\n    resp.text = \"\u0442\u0435\u043a\u0441\u0442\"\n\n    assert \"\u0442\u0435\u043a\u0441\u0442\" == resp.text\n    assert \"\u0442\u0435\u043a\u0441\u0442\".encode(\"koi8-r\") == resp.body\n    assert \"koi8-r\" == resp.charset\n\n\ndef test_default_content_type_in_stream_response() -> None:\n    resp = StreamResponse()\n    assert resp.content_type == \"application/octet-stream\"\n\n\ndef test_default_content_type_in_response() -> None:\n    resp = Response()\n    assert resp.content_type == \"application/octet-stream\"\n\n\ndef test_content_type_with_set_text() -> None:\n    resp = Response(text=\"text\")\n    assert resp.content_type == \"text/plain\"\n\n\ndef test_content_type_with_set_body() -> None:\n    resp = Response(body=b\"body\")\n    assert resp.content_type == \"application/octet-stream\"\n\n\ndef test_started_when_not_started() -> None:\n    resp = StreamResponse()\n    assert not resp.prepared\n\n\nasync def test_started_when_started() -> None:\n    resp = StreamResponse()\n    await resp.prepare(make_request(\"GET\", \"/\"))\n    assert resp.prepared\n\n\nasync def test_drain_before_start() -> None:\n    resp = StreamResponse()\n    with pytest.raises(AssertionError):\n        await resp.drain()\n\n\nasync def test_changing_status_after_prepare_raises() -> None:\n    resp = StreamResponse()\n    await resp.prepare(make_request(\"GET\", \"/\"))\n    with pytest.raises(AssertionError):\n        resp.set_status(400)\n\n\ndef test_nonstr_text_in_ctor() -> None:\n    with pytest.raises(TypeError):\n        Response(text=b\"data\")\n\n\ndef test_text_in_ctor_with_content_type() -> None:\n    resp = Response(text=\"data\", content_type=\"text/html\")\n    assert \"data\" == resp.text\n    assert \"text/html\" == resp.content_type\n\n\ndef test_text_in_ctor_with_content_type_header() -> None:\n    resp = Response(text=\"\u0442\u0435\u043a\u0441\u0442\", headers={\"Content-Type\": \"text/html; charset=koi8-r\"})\n    assert \"\u0442\u0435\u043a\u0441\u0442\".encode(\"koi8-r\") == resp.body\n    assert \"text/html\" == resp.content_type\n    assert \"koi8-r\" == resp.charset\n\n\ndef test_text_in_ctor_with_content_type_header_multidict() -> None:\n    headers = CIMultiDict({\"Content-Type\": \"text/html; charset=koi8-r\"})\n    resp = Response(text=\"\u0442\u0435\u043a\u0441\u0442\", headers=headers)\n    assert \"\u0442\u0435\u043a\u0441\u0442\".encode(\"koi8-r\") == resp.body\n    assert \"text/html\" == resp.content_type\n    assert \"koi8-r\" == resp.charset\n\n\ndef test_body_in_ctor_with_content_type_header_multidict() -> None:\n    headers = CIMultiDict({\"Content-Type\": \"text/html; charset=koi8-r\"})\n    resp = Response(body=\"\u0442\u0435\u043a\u0441\u0442\".encode(\"koi8-r\"), headers=headers)\n    assert \"\u0442\u0435\u043a\u0441\u0442\".encode(\"koi8-r\") == resp.body\n    assert \"text/html\" == resp.content_type\n    assert \"koi8-r\" == resp.charset\n\n\ndef test_text_with_empty_payload() -> None:\n    resp = Response(status=200)\n    assert resp.body is None\n    assert resp.text is None\n\n\ndef test_response_with_content_length_header_without_body() -> None:\n    resp = Response(headers={\"Content-Length\": 123})\n    assert resp.content_length == 123\n\n\ndef test_response_with_immutable_headers() -> None:\n    resp = Response(\n        text=\"text\", headers=CIMultiDictProxy(CIMultiDict({\"Header\": \"Value\"}))\n    )\n    assert resp.headers == {\n        \"Header\": \"Value\",\n        \"Content-Type\": \"text/plain; charset=utf-8\",\n    }\n\n\nasync def test_response_prepared_after_header_preparation() -> None:\n    req = make_request(\"GET\", \"/\")\n    resp = StreamResponse()\n    await resp.prepare(req)\n\n    assert type(resp.headers[\"Server\"]) is str\n\n    async def _strip_server(req, res):\n        assert \"Server\" in res.headers\n\n        if \"Server\" in res.headers:\n            del res.headers[\"Server\"]\n\n    app = mock.Mock()\n    sig = aiosignal.Signal(app)\n    sig.append(_strip_server)\n\n    req = make_request(\"GET\", \"/\", on_response_prepare=sig, app=app)\n    resp = StreamResponse()\n    await resp.prepare(req)\n\n    assert \"Server\" not in resp.headers\n\n\ndef test_weakref_creation() -> None:\n    resp = Response()\n    weakref.ref(resp)\n\n\nclass TestJSONResponse:\n    def test_content_type_is_application_json_by_default(self) -> None:\n        resp = json_response(\"\")\n        assert \"application/json\" == resp.content_type\n\n    def test_passing_text_only(self) -> None:\n        resp = json_response(text=json.dumps(\"jaysawn\"))\n        assert resp.text == json.dumps(\"jaysawn\")\n\n    def test_data_and_text_raises_value_error(self) -> None:\n        with pytest.raises(ValueError) as excinfo:\n            json_response(data=\"foo\", text=\"bar\")\n        expected_message = \"only one of data, text, or body should be specified\"\n        assert expected_message == excinfo.value.args[0]\n\n    def test_data_and_body_raises_value_error(self) -> None:\n        with pytest.raises(ValueError) as excinfo:\n            json_response(data=\"foo\", body=b\"bar\")\n        expected_message = \"only one of data, text, or body should be specified\"\n        assert expected_message == excinfo.value.args[0]\n\n    def test_text_is_json_encoded(self) -> None:\n        resp = json_response({\"foo\": 42})\n        assert json.dumps({\"foo\": 42}) == resp.text\n\n    def test_content_type_is_overrideable(self) -> None:\n        resp = json_response({\"foo\": 42}, content_type=\"application/vnd.json+api\")\n        assert \"application/vnd.json+api\" == resp.content_type\n\n\n@pytest.mark.dev_mode\nasync def test_no_warn_small_cookie(buf: Any, writer: Any) -> None:\n    resp = Response()\n    resp.set_cookie(\"foo\", \"\u00ff\" + \"8\" * 4064, max_age=2600)  # No warning\n    req = make_request(\"GET\", \"/\", writer=writer)\n\n    await resp.prepare(req)\n    await resp.write_eof()\n\n    cookie = re.search(b\"Set-Cookie: (.*?)\\r\\n\", buf).group(1)\n    assert len(cookie) == 4096\n\n\n@pytest.mark.dev_mode\nasync def test_warn_large_cookie(buf: Any, writer: Any) -> None:\n    resp = Response()\n\n    with pytest.warns(\n        UserWarning,\n        match=\"The size of is too large, it might get ignored by the client.\",\n    ):\n        resp.set_cookie(\"foo\", \"\u00ff\" + \"8\" * 4065, max_age=2600)\n    req = make_request(\"GET\", \"/\", writer=writer)\n\n    await resp.prepare(req)\n    await resp.write_eof()\n\n    cookie = re.search(b\"Set-Cookie: (.*?)\\r\\n\", buf).group(1)\n    assert len(cookie) == 4097\n", "tests/test_websocket_handshake.py": "# Tests for http/websocket.py\n\nimport base64\nimport os\nfrom typing import Any, List, Tuple\n\nimport pytest\n\nfrom aiohttp import web\nfrom aiohttp.test_utils import make_mocked_request\n\n\ndef gen_ws_headers(\n    protocols: str = \"\",\n    compress: int = 0,\n    extension_text: str = \"\",\n    server_notakeover: bool = False,\n    client_notakeover: bool = False,\n) -> Tuple[List[Tuple[str, str]], str]:\n    key = base64.b64encode(os.urandom(16)).decode()\n    hdrs = [\n        (\"Upgrade\", \"websocket\"),\n        (\"Connection\", \"upgrade\"),\n        (\"Sec-Websocket-Version\", \"13\"),\n        (\"Sec-Websocket-Key\", key),\n    ]\n    if protocols:\n        hdrs += [(\"Sec-Websocket-Protocol\", protocols)]\n    if compress:\n        params = \"permessage-deflate\"\n        if compress < 15:\n            params += \"; server_max_window_bits=\" + str(compress)\n        if server_notakeover:\n            params += \"; server_no_context_takeover\"\n        if client_notakeover:\n            params += \"; client_no_context_takeover\"\n        if extension_text:\n            params += \"; \" + extension_text\n        hdrs += [(\"Sec-Websocket-Extensions\", params)]\n    return hdrs, key\n\n\nasync def test_no_upgrade() -> None:\n    ws = web.WebSocketResponse()\n    req = make_mocked_request(\"GET\", \"/\")\n    with pytest.raises(web.HTTPBadRequest):\n        await ws.prepare(req)\n\n\nasync def test_no_connection() -> None:\n    ws = web.WebSocketResponse()\n    req = make_mocked_request(\n        \"GET\", \"/\", headers={\"Upgrade\": \"websocket\", \"Connection\": \"keep-alive\"}\n    )\n    with pytest.raises(web.HTTPBadRequest):\n        await ws.prepare(req)\n\n\nasync def test_protocol_version_unset() -> None:\n    ws = web.WebSocketResponse()\n    req = make_mocked_request(\n        \"GET\", \"/\", headers={\"Upgrade\": \"websocket\", \"Connection\": \"upgrade\"}\n    )\n    with pytest.raises(web.HTTPBadRequest):\n        await ws.prepare(req)\n\n\nasync def test_protocol_version_not_supported() -> None:\n    ws = web.WebSocketResponse()\n    req = make_mocked_request(\n        \"GET\",\n        \"/\",\n        headers={\n            \"Upgrade\": \"websocket\",\n            \"Connection\": \"upgrade\",\n            \"Sec-Websocket-Version\": \"1\",\n        },\n    )\n    with pytest.raises(web.HTTPBadRequest):\n        await ws.prepare(req)\n\n\nasync def test_protocol_key_not_present() -> None:\n    ws = web.WebSocketResponse()\n    req = make_mocked_request(\n        \"GET\",\n        \"/\",\n        headers={\n            \"Upgrade\": \"websocket\",\n            \"Connection\": \"upgrade\",\n            \"Sec-Websocket-Version\": \"13\",\n        },\n    )\n    with pytest.raises(web.HTTPBadRequest):\n        await ws.prepare(req)\n\n\nasync def test_protocol_key_invalid() -> None:\n    ws = web.WebSocketResponse()\n    req = make_mocked_request(\n        \"GET\",\n        \"/\",\n        headers={\n            \"Upgrade\": \"websocket\",\n            \"Connection\": \"upgrade\",\n            \"Sec-Websocket-Version\": \"13\",\n            \"Sec-Websocket-Key\": \"123\",\n        },\n    )\n    with pytest.raises(web.HTTPBadRequest):\n        await ws.prepare(req)\n\n\nasync def test_protocol_key_bad_size() -> None:\n    ws = web.WebSocketResponse()\n    sec_key = base64.b64encode(os.urandom(2))\n    val = sec_key.decode()\n    req = make_mocked_request(\n        \"GET\",\n        \"/\",\n        headers={\n            \"Upgrade\": \"websocket\",\n            \"Connection\": \"upgrade\",\n            \"Sec-Websocket-Version\": \"13\",\n            \"Sec-Websocket-Key\": val,\n        },\n    )\n    with pytest.raises(web.HTTPBadRequest):\n        await ws.prepare(req)\n\n\nasync def test_handshake_ok() -> None:\n    hdrs, sec_key = gen_ws_headers()\n    ws = web.WebSocketResponse()\n    req = make_mocked_request(\"GET\", \"/\", headers=hdrs)\n\n    await ws.prepare(req)\n\n    assert ws.ws_protocol is None\n\n\nasync def test_handshake_protocol() -> None:\n    # Tests if one protocol is returned by handshake\n    proto = \"chat\"\n\n    ws = web.WebSocketResponse(protocols={\"chat\"})\n    req = make_mocked_request(\"GET\", \"/\", headers=gen_ws_headers(proto)[0])\n\n    await ws.prepare(req)\n\n    assert ws.ws_protocol == proto\n\n\nasync def test_handshake_protocol_agreement() -> None:\n    # Tests if the right protocol is selected given multiple\n    best_proto = \"worse_proto\"\n    wanted_protos = [\"best\", \"chat\", \"worse_proto\"]\n    server_protos = \"worse_proto,chat\"\n\n    ws = web.WebSocketResponse(protocols=wanted_protos)\n    req = make_mocked_request(\"GET\", \"/\", headers=gen_ws_headers(server_protos)[0])\n\n    await ws.prepare(req)\n\n    assert ws.ws_protocol == best_proto\n\n\nasync def test_handshake_protocol_unsupported(caplog: Any) -> None:\n    # Tests if a protocol mismatch handshake warns and returns None\n    proto = \"chat\"\n    req = make_mocked_request(\"GET\", \"/\", headers=gen_ws_headers(\"test\")[0])\n\n    ws = web.WebSocketResponse(protocols=[proto])\n    await ws.prepare(req)\n\n    assert (\n        caplog.records[-1].msg\n        == \"Client protocols %r don\u2019t overlap server-known ones %r\"\n    )\n    assert ws.ws_protocol is None\n\n\nasync def test_handshake_compress() -> None:\n    hdrs, sec_key = gen_ws_headers(compress=15)\n\n    req = make_mocked_request(\"GET\", \"/\", headers=hdrs)\n\n    ws = web.WebSocketResponse()\n    await ws.prepare(req)\n\n    assert ws.compress == 15\n\n\ndef test_handshake_compress_server_notakeover() -> None:\n    hdrs, sec_key = gen_ws_headers(compress=15, server_notakeover=True)\n\n    req = make_mocked_request(\"GET\", \"/\", headers=hdrs)\n\n    ws = web.WebSocketResponse()\n    headers, _, compress, notakeover = ws._handshake(req)\n\n    assert compress == 15\n    assert notakeover is True\n    assert \"Sec-Websocket-Extensions\" in headers\n    assert headers[\"Sec-Websocket-Extensions\"] == (\n        \"permessage-deflate; server_no_context_takeover\"\n    )\n\n\ndef test_handshake_compress_client_notakeover() -> None:\n    hdrs, sec_key = gen_ws_headers(compress=15, client_notakeover=True)\n\n    req = make_mocked_request(\"GET\", \"/\", headers=hdrs)\n\n    ws = web.WebSocketResponse()\n    headers, _, compress, notakeover = ws._handshake(req)\n\n    assert \"Sec-Websocket-Extensions\" in headers\n    assert headers[\"Sec-Websocket-Extensions\"] == (\"permessage-deflate\"), hdrs\n\n    assert compress == 15\n\n\ndef test_handshake_compress_wbits() -> None:\n    hdrs, sec_key = gen_ws_headers(compress=9)\n\n    req = make_mocked_request(\"GET\", \"/\", headers=hdrs)\n\n    ws = web.WebSocketResponse()\n    headers, _, compress, notakeover = ws._handshake(req)\n\n    assert \"Sec-Websocket-Extensions\" in headers\n    assert headers[\"Sec-Websocket-Extensions\"] == (\n        \"permessage-deflate; server_max_window_bits=9\"\n    )\n    assert compress == 9\n\n\ndef test_handshake_compress_wbits_error() -> None:\n    hdrs, sec_key = gen_ws_headers(compress=6)\n\n    req = make_mocked_request(\"GET\", \"/\", headers=hdrs)\n\n    ws = web.WebSocketResponse()\n    headers, _, compress, notakeover = ws._handshake(req)\n\n    assert \"Sec-Websocket-Extensions\" not in headers\n    assert compress == 0\n\n\ndef test_handshake_compress_bad_ext() -> None:\n    hdrs, sec_key = gen_ws_headers(compress=15, extension_text=\"bad\")\n\n    req = make_mocked_request(\"GET\", \"/\", headers=hdrs)\n\n    ws = web.WebSocketResponse()\n    headers, _, compress, notakeover = ws._handshake(req)\n\n    assert \"Sec-Websocket-Extensions\" not in headers\n    assert compress == 0\n\n\ndef test_handshake_compress_multi_ext_bad() -> None:\n    hdrs, sec_key = gen_ws_headers(\n        compress=15, extension_text=\"bad, permessage-deflate\"\n    )\n\n    req = make_mocked_request(\"GET\", \"/\", headers=hdrs)\n\n    ws = web.WebSocketResponse()\n    headers, _, compress, notakeover = ws._handshake(req)\n\n    assert \"Sec-Websocket-Extensions\" in headers\n    assert headers[\"Sec-Websocket-Extensions\"] == \"permessage-deflate\"\n\n\ndef test_handshake_compress_multi_ext_wbits() -> None:\n    hdrs, sec_key = gen_ws_headers(compress=6, extension_text=\", permessage-deflate\")\n\n    req = make_mocked_request(\"GET\", \"/\", headers=hdrs)\n\n    ws = web.WebSocketResponse()\n    headers, _, compress, notakeover = ws._handshake(req)\n\n    assert \"Sec-Websocket-Extensions\" in headers\n    assert headers[\"Sec-Websocket-Extensions\"] == \"permessage-deflate\"\n    assert compress == 15\n\n\ndef test_handshake_no_transfer_encoding() -> None:\n    hdrs, sec_key = gen_ws_headers()\n    req = make_mocked_request(\"GET\", \"/\", headers=hdrs)\n\n    ws = web.WebSocketResponse()\n    headers, _, compress, notakeover = ws._handshake(req)\n\n    assert \"Transfer-Encoding\" not in headers\n", "tests/test_web_server.py": "# type: ignore\nimport asyncio\nfrom contextlib import suppress\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\n\nfrom aiohttp import client, helpers, web\n\n\nasync def test_simple_server(aiohttp_raw_server: Any, aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=str(request.rel_url))\n\n    server = await aiohttp_raw_server(handler)\n    cli = await aiohttp_client(server)\n    resp = await cli.get(\"/path/to\")\n    assert resp.status == 200\n    txt = await resp.text()\n    assert txt == \"/path/to\"\n\n\n@pytest.mark.xfail(\n    not helpers.NO_EXTENSIONS,\n    raises=client.ServerDisconnectedError,\n    reason=\"The behavior of C-extensions differs from pure-Python: \"\n    \"https://github.com/aio-libs/aiohttp/issues/6446\",\n)\nasync def test_unsupported_upgrade(aiohttp_raw_server, aiohttp_client) -> None:\n    # don't fail if a client probes for an unsupported protocol upgrade\n    # https://github.com/aio-libs/aiohttp/issues/6446#issuecomment-999032039\n    async def handler(request: web.Request):\n        return web.Response(body=await request.read())\n\n    upgrade_headers = {\"Connection\": \"Upgrade\", \"Upgrade\": \"unsupported_proto\"}\n    server = await aiohttp_raw_server(handler)\n    cli = await aiohttp_client(server)\n    test_data = b\"Test\"\n    resp = await cli.post(\"/path/to\", data=test_data, headers=upgrade_headers)\n    assert resp.status == 200\n    data = await resp.read()\n    assert data == test_data\n\n\nasync def test_raw_server_not_http_exception(\n    aiohttp_raw_server: Any, aiohttp_client: Any, loop: Any\n) -> None:\n    # disable debug mode not to print traceback\n    loop.set_debug(False)\n\n    exc = RuntimeError(\"custom runtime error\")\n\n    async def handler(request):\n        raise exc\n\n    logger = mock.Mock()\n    server = await aiohttp_raw_server(handler, logger=logger)\n    cli = await aiohttp_client(server)\n    resp = await cli.get(\"/path/to\")\n    assert resp.status == 500\n    assert resp.headers[\"Content-Type\"].startswith(\"text/plain\")\n\n    txt = await resp.text()\n    assert txt.startswith(\"500 Internal Server Error\")\n    assert \"Traceback\" not in txt\n\n    logger.exception.assert_called_with(\"Error handling request\", exc_info=exc)\n\n\nasync def test_raw_server_handler_timeout(\n    aiohttp_raw_server: Any, aiohttp_client: Any\n) -> None:\n    loop = asyncio.get_event_loop()\n    loop.set_debug(True)\n    exc = asyncio.TimeoutError(\"error\")\n\n    async def handler(request):\n        raise exc\n\n    logger = mock.Mock()\n    server = await aiohttp_raw_server(handler, logger=logger)\n    cli = await aiohttp_client(server)\n    resp = await cli.get(\"/path/to\")\n    assert resp.status == 504\n\n    await resp.text()\n    logger.debug.assert_called_with(\"Request handler timed out.\", exc_info=exc)\n\n\nasync def test_raw_server_do_not_swallow_exceptions(\n    aiohttp_raw_server: Any, aiohttp_client: Any\n) -> None:\n    async def handler(request):\n        raise asyncio.CancelledError()\n\n    loop = asyncio.get_event_loop()\n    loop.set_debug(True)\n    logger = mock.Mock()\n    server = await aiohttp_raw_server(handler, logger=logger)\n    cli = await aiohttp_client(server)\n\n    with pytest.raises(client.ServerDisconnectedError):\n        await cli.get(\"/path/to\")\n\n    logger.debug.assert_called_with(\"Ignored premature client disconnection\")\n\n\nasync def test_raw_server_cancelled_in_write_eof(\n    aiohttp_raw_server: Any, aiohttp_client: Any\n):\n    class MyResponse(web.Response):\n        async def write_eof(self, data=b\"\"):\n            raise asyncio.CancelledError(\"error\")\n\n    async def handler(request):\n        resp = MyResponse(text=str(request.rel_url))\n        return resp\n\n    loop = asyncio.get_event_loop()\n    loop.set_debug(True)\n    logger = mock.Mock()\n    server = await aiohttp_raw_server(handler, logger=logger)\n    cli = await aiohttp_client(server)\n\n    resp = await cli.get(\"/path/to\")\n    with pytest.raises(client.ClientPayloadError):\n        await resp.read()\n\n    logger.debug.assert_called_with(\"Ignored premature client disconnection\")\n\n\nasync def test_raw_server_not_http_exception_debug(\n    aiohttp_raw_server: Any, aiohttp_client: Any\n) -> None:\n    exc = RuntimeError(\"custom runtime error\")\n\n    async def handler(request):\n        raise exc\n\n    loop = asyncio.get_event_loop()\n    loop.set_debug(True)\n    logger = mock.Mock()\n    server = await aiohttp_raw_server(handler, logger=logger)\n    cli = await aiohttp_client(server)\n    resp = await cli.get(\"/path/to\")\n    assert resp.status == 500\n    assert resp.headers[\"Content-Type\"].startswith(\"text/plain\")\n\n    txt = await resp.text()\n    assert \"Traceback (most recent call last):\\n\" in txt\n\n    logger.exception.assert_called_with(\"Error handling request\", exc_info=exc)\n\n\nasync def test_raw_server_html_exception(\n    aiohttp_raw_server: Any, aiohttp_client: Any, loop: Any\n) -> None:\n    # disable debug mode not to print traceback\n    loop.set_debug(False)\n\n    exc = RuntimeError(\"custom runtime error\")\n\n    async def handler(request):\n        raise exc\n\n    logger = mock.Mock()\n    server = await aiohttp_raw_server(handler, logger=logger)\n    cli = await aiohttp_client(server)\n    resp = await cli.get(\"/path/to\", headers={\"Accept\": \"text/html\"})\n    assert resp.status == 500\n    assert resp.headers[\"Content-Type\"].startswith(\"text/html\")\n\n    txt = await resp.text()\n    assert txt == (\n        \"<html><head><title>500 Internal Server Error</title></head><body>\\n\"\n        \"<h1>500 Internal Server Error</h1>\\n\"\n        \"Server got itself in trouble\\n\"\n        \"</body></html>\\n\"\n    )\n\n    logger.exception.assert_called_with(\"Error handling request\", exc_info=exc)\n\n\nasync def test_raw_server_html_exception_debug(\n    aiohttp_raw_server: Any, aiohttp_client: Any\n) -> None:\n    exc = RuntimeError(\"custom runtime error\")\n\n    async def handler(request):\n        raise exc\n\n    loop = asyncio.get_event_loop()\n    loop.set_debug(True)\n    logger = mock.Mock()\n    server = await aiohttp_raw_server(handler, logger=logger)\n    cli = await aiohttp_client(server)\n    resp = await cli.get(\"/path/to\", headers={\"Accept\": \"text/html\"})\n    assert resp.status == 500\n    assert resp.headers[\"Content-Type\"].startswith(\"text/html\")\n\n    txt = await resp.text()\n    assert txt.startswith(\n        \"<html><head><title>500 Internal Server Error</title></head><body>\\n\"\n        \"<h1>500 Internal Server Error</h1>\\n\"\n        \"<h2>Traceback:</h2>\\n\"\n        \"<pre>Traceback (most recent call last):\\n\"\n    )\n\n    logger.exception.assert_called_with(\"Error handling request\", exc_info=exc)\n\n\nasync def test_handler_cancellation(aiohttp_unused_port) -> None:\n    event = asyncio.Event()\n    port = aiohttp_unused_port()\n\n    async def on_request(_: web.Request) -> web.Response:\n        nonlocal event\n        try:\n            await asyncio.sleep(10)\n        except asyncio.CancelledError:\n            event.set()\n            raise\n        else:\n            raise web.HTTPInternalServerError()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", on_request)\n\n    runner = web.AppRunner(app, handler_cancellation=True)\n    await runner.setup()\n\n    site = web.TCPSite(runner, host=\"localhost\", port=port)\n\n    await site.start()\n\n    try:\n        assert runner.server.handler_cancellation, \"Flag was not propagated\"\n\n        async with client.ClientSession(\n            timeout=client.ClientTimeout(total=0.15)\n        ) as sess:\n            with pytest.raises(asyncio.TimeoutError):\n                await sess.get(f\"http://localhost:{port}/\")\n\n        with suppress(asyncio.TimeoutError):\n            await asyncio.wait_for(event.wait(), timeout=1)\n        assert event.is_set(), \"Request handler hasn't been cancelled\"\n    finally:\n        await asyncio.gather(runner.shutdown(), site.stop())\n\n\nasync def test_no_handler_cancellation(aiohttp_unused_port) -> None:\n    timeout_event = asyncio.Event()\n    done_event = asyncio.Event()\n    port = aiohttp_unused_port()\n    started = False\n\n    async def on_request(_: web.Request) -> web.Response:\n        nonlocal done_event, started, timeout_event\n        started = True\n        await asyncio.wait_for(timeout_event.wait(), timeout=5)\n        done_event.set()\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", on_request)\n\n    runner = web.AppRunner(app)\n    await runner.setup()\n\n    site = web.TCPSite(runner, host=\"localhost\", port=port)\n\n    await site.start()\n\n    try:\n        async with client.ClientSession(\n            timeout=client.ClientTimeout(total=0.2)\n        ) as sess:\n            with pytest.raises(asyncio.TimeoutError):\n                await sess.get(f\"http://localhost:{port}/\")\n        await asyncio.sleep(0.1)\n        timeout_event.set()\n\n        with suppress(asyncio.TimeoutError):\n            await asyncio.wait_for(done_event.wait(), timeout=1)\n        assert started\n        assert done_event.is_set()\n    finally:\n        await asyncio.gather(runner.shutdown(), site.stop())\n", "tests/test_web_sendfile_functional.py": "# type: ignore\nimport asyncio\nimport gzip\nimport pathlib\nimport socket\nimport zlib\nfrom typing import Any, Iterable, Optional\n\nimport pytest\n\nimport aiohttp\nfrom aiohttp import web\n\ntry:\n    import brotlicffi as brotli\nexcept ImportError:\n    import brotli\n\ntry:\n    import ssl\nexcept ImportError:\n    ssl = None\n\n\nHELLO_AIOHTTP = b\"Hello aiohttp! :-)\\n\"\n\n\n@pytest.fixture(scope=\"module\")\ndef hello_txt(request, tmp_path_factory) -> pathlib.Path:\n    \"\"\"Create a temp path with hello.txt and compressed versions.\n\n    The uncompressed text file path is returned by default. Alternatively, an\n    indirect parameter can be passed with an encoding to get a compressed path.\n    \"\"\"\n    txt = tmp_path_factory.mktemp(\"hello-\") / \"hello.txt\"\n    hello = {\n        None: txt,\n        \"gzip\": txt.with_suffix(f\"{txt.suffix}.gz\"),\n        \"br\": txt.with_suffix(f\"{txt.suffix}.br\"),\n    }\n    hello[None].write_bytes(HELLO_AIOHTTP)\n    hello[\"gzip\"].write_bytes(gzip.compress(HELLO_AIOHTTP))\n    hello[\"br\"].write_bytes(brotli.compress(HELLO_AIOHTTP))\n    encoding = getattr(request, \"param\", None)\n    return hello[encoding]\n\n\n@pytest.fixture\ndef loop_without_sendfile(loop: Any):\n    def sendfile(*args, **kwargs):\n        raise NotImplementedError\n\n    loop.sendfile = sendfile\n    return loop\n\n\n@pytest.fixture\ndef loop_with_mocked_native_sendfile(loop: Any):\n    def sendfile(transport, fobj, offset, count):\n        if count == 0:\n            raise ValueError(\"count must be a positive integer (got 0)\")\n        raise NotImplementedError\n\n    loop.sendfile = sendfile\n    return loop\n\n\n@pytest.fixture(params=[\"sendfile\", \"no_sendfile\"], ids=[\"sendfile\", \"no_sendfile\"])\ndef sender(request: Any, loop_without_sendfile: Any):\n    def maker(*args, **kwargs):\n        ret = web.FileResponse(*args, **kwargs)\n        if request.param == \"no_sendfile\":\n            asyncio.set_event_loop(loop_without_sendfile)\n        return ret\n\n    return maker\n\n\n@pytest.fixture\ndef app_with_static_route(sender: Any) -> web.Application:\n    filename = \"data.unknown_mime_type\"\n    filepath = pathlib.Path(__file__).parent / filename\n\n    async def handler(request):\n        return sender(filepath)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    return app\n\n\nasync def test_static_file_ok(\n    aiohttp_client: Any, app_with_static_route: web.Application\n) -> None:\n    client = await aiohttp_client(app_with_static_route)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    txt = await resp.text()\n    assert \"file content\" == txt.rstrip()\n    assert \"application/octet-stream\" == resp.headers[\"Content-Type\"]\n    assert resp.headers.get(\"Content-Encoding\") is None\n    await resp.release()\n    await client.close()\n\n\nasync def test_zero_bytes_file_ok(aiohttp_client: Any, sender: Any) -> None:\n    filepath = pathlib.Path(__file__).parent / \"data.zero_bytes\"\n\n    async def handler(request):\n        return sender(filepath)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    # Run the request multiple times to ensure\n    # that an untrapped exception is not hidden\n    # because there is no read of the zero bytes\n    for i in range(2):\n        resp = await client.get(\"/\")\n        assert resp.status == 200\n        txt = await resp.text()\n        assert \"\" == txt.rstrip()\n        assert \"application/octet-stream\" == resp.headers[\"Content-Type\"]\n        assert resp.headers.get(\"Content-Encoding\") is None\n        await resp.release()\n\n    await client.close()\n\n\nasync def test_zero_bytes_file_mocked_native_sendfile(\n    aiohttp_client: Any, loop_with_mocked_native_sendfile: Any\n) -> None:\n    filepath = pathlib.Path(__file__).parent / \"data.zero_bytes\"\n\n    async def handler(request):\n        asyncio.set_event_loop(loop_with_mocked_native_sendfile)\n        return web.FileResponse(filepath)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    # Run the request multiple times to ensure\n    # that an untrapped exception is not hidden\n    # because there is no read of the zero bytes\n    for i in range(2):\n        resp = await client.get(\"/\")\n        assert resp.status == 200\n        txt = await resp.text()\n        assert \"\" == txt.rstrip()\n        assert \"application/octet-stream\" == resp.headers[\"Content-Type\"]\n        assert resp.headers.get(\"Content-Encoding\") is None\n        assert resp.headers.get(\"Content-Length\") == \"0\"\n        await resp.release()\n\n    await client.close()\n\n\nasync def test_static_file_ok_string_path(\n    aiohttp_client: Any, app_with_static_route: web.Application\n) -> None:\n    client = await aiohttp_client(app_with_static_route)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    txt = await resp.text()\n    assert \"file content\" == txt.rstrip()\n    assert \"application/octet-stream\" == resp.headers[\"Content-Type\"]\n    assert resp.headers.get(\"Content-Encoding\") is None\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_not_exists(aiohttp_client: Any) -> None:\n    app = web.Application()\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/fake\")\n    assert resp.status == 404\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_name_too_long(aiohttp_client: Any) -> None:\n    app = web.Application()\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/x*500\")\n    assert resp.status == 404\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_upper_directory(aiohttp_client: Any) -> None:\n    app = web.Application()\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/../../\")\n    assert resp.status == 404\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_with_content_type(aiohttp_client: Any, sender: Any) -> None:\n    filepath = pathlib.Path(__file__).parent / \"aiohttp.jpg\"\n\n    async def handler(request):\n        return sender(filepath, chunk_size=16)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    body = await resp.read()\n    with filepath.open(\"rb\") as f:\n        content = f.read()\n        assert content == body\n    assert resp.headers[\"Content-Type\"] == \"image/jpeg\"\n    assert resp.headers.get(\"Content-Encoding\") is None\n    resp.close()\n    await resp.release()\n    await client.close()\n\n\n@pytest.mark.parametrize(\"hello_txt\", [\"gzip\", \"br\"], indirect=True)\nasync def test_static_file_custom_content_type(\n    hello_txt: pathlib.Path, aiohttp_client: Any, sender: Any\n) -> None:\n    \"\"\"Test that custom type without encoding is returned for encoded request.\"\"\"\n\n    async def handler(request):\n        resp = sender(hello_txt, chunk_size=16)\n        resp.content_type = \"application/pdf\"\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    assert resp.headers.get(\"Content-Encoding\") is None\n    assert resp.headers[\"Content-Type\"] == \"application/pdf\"\n    assert await resp.read() == hello_txt.read_bytes()\n    resp.close()\n    await resp.release()\n    await client.close()\n\n\n@pytest.mark.parametrize(\n    (\"accept_encoding\", \"expect_encoding\"),\n    [(\"gzip, deflate\", \"gzip\"), (\"gzip, deflate, br\", \"br\")],\n)\nasync def test_static_file_custom_content_type_compress(\n    hello_txt: pathlib.Path,\n    aiohttp_client: Any,\n    sender: Any,\n    accept_encoding: str,\n    expect_encoding: str,\n):\n    \"\"\"Test that custom type with encoding is returned for unencoded requests.\"\"\"\n\n    async def handler(request):\n        resp = sender(hello_txt, chunk_size=16)\n        resp.content_type = \"application/pdf\"\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\", headers={\"Accept-Encoding\": accept_encoding})\n    assert resp.status == 200\n    assert resp.headers.get(\"Content-Encoding\") == expect_encoding\n    assert resp.headers[\"Content-Type\"] == \"application/pdf\"\n    assert await resp.read() == HELLO_AIOHTTP\n    resp.close()\n    await resp.release()\n    await client.close()\n\n\n@pytest.mark.parametrize(\n    (\"accept_encoding\", \"expect_encoding\"),\n    [(\"gzip, deflate\", \"gzip\"), (\"gzip, deflate, br\", \"br\")],\n)\n@pytest.mark.parametrize(\"forced_compression\", [None, web.ContentCoding.gzip])\nasync def test_static_file_with_encoding_and_enable_compression(\n    hello_txt: pathlib.Path,\n    aiohttp_client: Any,\n    sender: Any,\n    accept_encoding: str,\n    expect_encoding: str,\n    forced_compression: Optional[web.ContentCoding],\n):\n    \"\"\"Test that enable_compression does not double compress when an encoded file is also present.\"\"\"\n\n    async def handler(request):\n        resp = sender(hello_txt)\n        resp.enable_compression(forced_compression)\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\", headers={\"Accept-Encoding\": accept_encoding})\n    assert resp.status == 200\n    assert resp.headers.get(\"Content-Encoding\") == expect_encoding\n    assert resp.headers[\"Content-Type\"] == \"text/plain\"\n    assert await resp.read() == HELLO_AIOHTTP\n    resp.close()\n    await resp.release()\n    await client.close()\n\n\n@pytest.mark.parametrize(\n    (\"hello_txt\", \"expect_encoding\"), [[\"gzip\"] * 2, [\"br\"] * 2], indirect=[\"hello_txt\"]\n)\nasync def test_static_file_with_content_encoding(\n    hello_txt: pathlib.Path, aiohttp_client: Any, sender: Any, expect_encoding: str\n) -> None:\n    \"\"\"Test requesting static compressed files returns the correct content type and encoding.\"\"\"\n\n    async def handler(request):\n        return sender(hello_txt)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    assert resp.headers.get(\"Content-Encoding\") == expect_encoding\n    assert resp.headers[\"Content-Type\"] == \"text/plain\"\n    assert await resp.read() == HELLO_AIOHTTP\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_modified_since(\n    aiohttp_client: Any, app_with_static_route: web.Application\n) -> None:\n    client = await aiohttp_client(app_with_static_route)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    lastmod = resp.headers.get(\"Last-Modified\")\n    assert lastmod is not None\n    resp.close()\n    await resp.release()\n\n    resp = await client.get(\"/\", headers={\"If-Modified-Since\": lastmod})\n    body = await resp.read()\n    assert 304 == resp.status\n    assert resp.headers.get(\"Content-Length\") is None\n    assert resp.headers.get(\"Last-Modified\") == lastmod\n    assert b\"\" == body\n    resp.close()\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_modified_since_past_date(\n    aiohttp_client: Any, app_with_static_route: web.Application\n) -> None:\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"Mon, 1 Jan 1990 01:01:01 GMT\"\n\n    resp = await client.get(\"/\", headers={\"If-Modified-Since\": lastmod})\n    assert 200 == resp.status\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_modified_since_invalid_date(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"not a valid HTTP-date\"\n\n    resp = await client.get(\"/\", headers={\"If-Modified-Since\": lastmod})\n    assert 200 == resp.status\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_modified_since_future_date(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"Fri, 31 Dec 9999 23:59:59 GMT\"\n\n    resp = await client.get(\"/\", headers={\"If-Modified-Since\": lastmod})\n    body = await resp.read()\n    assert 304 == resp.status\n    assert resp.headers.get(\"Content-Length\") is None\n    assert resp.headers.get(\"Last-Modified\")\n    assert b\"\" == body\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\n@pytest.mark.parametrize(\"if_unmodified_since\", (\"\", \"Fri, 31 Dec 0000 23:59:59 GMT\"))\nasync def test_static_file_if_match(\n    aiohttp_client: Any,\n    app_with_static_route: web.Application,\n    if_unmodified_since: str,\n) -> None:\n    client = await aiohttp_client(app_with_static_route)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    original_etag = resp.headers.get(\"ETag\")\n\n    assert original_etag is not None\n    resp.close()\n    await resp.release()\n\n    headers = {\"If-Match\": original_etag, \"If-Unmodified-Since\": if_unmodified_since}\n    resp = await client.head(\"/\", headers=headers)\n    body = await resp.read()\n    assert 200 == resp.status\n    assert resp.headers.get(\"ETag\")\n    assert resp.headers.get(\"Last-Modified\")\n    assert b\"\" == body\n    resp.close()\n    await resp.release()\n\n    await client.close()\n\n\n@pytest.mark.parametrize(\"if_unmodified_since\", (\"\", \"Fri, 31 Dec 0000 23:59:59 GMT\"))\n@pytest.mark.parametrize(\n    \"etags,expected_status\",\n    [\n        ((\"*\",), 200),\n        (('\"example-tag\"', 'W/\"weak-tag\"'), 412),\n    ],\n)\nasync def test_static_file_if_match_custom_tags(\n    aiohttp_client: Any,\n    app_with_static_route: web.Application,\n    if_unmodified_since: str,\n    etags: Iterable[str],\n    expected_status: Iterable[int],\n) -> None:\n    client = await aiohttp_client(app_with_static_route)\n\n    if_match = \", \".join(etags)\n    headers = {\"If-Match\": if_match, \"If-Unmodified-Since\": if_unmodified_since}\n    resp = await client.head(\"/\", headers=headers)\n    body = await resp.read()\n    assert expected_status == resp.status\n    assert b\"\" == body\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\n@pytest.mark.parametrize(\"if_modified_since\", (\"\", \"Fri, 31 Dec 9999 23:59:59 GMT\"))\n@pytest.mark.parametrize(\n    \"additional_etags\",\n    (\n        (),\n        ('\"some-other-strong-etag\"', 'W/\"weak-tag\"', \"invalid-tag\"),\n    ),\n)\nasync def test_static_file_if_none_match(\n    aiohttp_client: Any,\n    app_with_static_route: web.Application,\n    if_modified_since: str,\n    additional_etags: Iterable[str],\n) -> None:\n    client = await aiohttp_client(app_with_static_route)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    original_etag = resp.headers.get(\"ETag\")\n\n    assert resp.headers.get(\"Last-Modified\") is not None\n    assert original_etag is not None\n    resp.close()\n    await resp.release()\n\n    etag = \",\".join((original_etag, *additional_etags))\n\n    resp = await client.get(\n        \"/\", headers={\"If-None-Match\": etag, \"If-Modified-Since\": if_modified_since}\n    )\n    body = await resp.read()\n    assert 304 == resp.status\n    assert resp.headers.get(\"Content-Length\") is None\n    assert resp.headers.get(\"ETag\") == original_etag\n    assert b\"\" == body\n    resp.close()\n    await resp.release()\n\n    await client.close()\n\n\nasync def test_static_file_if_none_match_star(\n    aiohttp_client: Any,\n    app_with_static_route: web.Application,\n) -> None:\n    client = await aiohttp_client(app_with_static_route)\n\n    resp = await client.head(\"/\", headers={\"If-None-Match\": \"*\"})\n    body = await resp.read()\n    assert 304 == resp.status\n    assert resp.headers.get(\"Content-Length\") is None\n    assert resp.headers.get(\"ETag\")\n    assert resp.headers.get(\"Last-Modified\")\n    assert b\"\" == body\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\n@pytest.mark.skipif(not ssl, reason=\"ssl not supported\")\nasync def test_static_file_ssl(\n    aiohttp_server: Any,\n    ssl_ctx: Any,\n    aiohttp_client: Any,\n    client_ssl_ctx: Any,\n) -> None:\n    dirname = pathlib.Path(__file__).parent\n    filename = \"data.unknown_mime_type\"\n    app = web.Application()\n    app.router.add_static(\"/static\", dirname)\n    server = await aiohttp_server(app, ssl=ssl_ctx)\n    conn = aiohttp.TCPConnector(ssl=client_ssl_ctx)\n    client = await aiohttp_client(server, connector=conn)\n\n    resp = await client.get(\"/static/\" + filename)\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert \"file content\" == txt.rstrip()\n    ct = resp.headers[\"CONTENT-TYPE\"]\n    assert \"application/octet-stream\" == ct\n    assert resp.headers.get(\"CONTENT-ENCODING\") is None\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_directory_traversal_attack(aiohttp_client: Any) -> None:\n    dirname = pathlib.Path(__file__).parent\n    relpath = \"../README.rst\"\n    full_path = dirname / relpath\n    assert full_path.is_file()\n\n    app = web.Application()\n    app.router.add_static(\"/static\", dirname)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/static/\" + relpath)\n    assert 404 == resp.status\n    await resp.release()\n\n    url_relpath2 = \"/static/dir/../\" + relpath\n    resp = await client.get(url_relpath2)\n    assert 404 == resp.status\n    await resp.release()\n\n    url_abspath = \"/static/\" + str(full_path.resolve())\n    resp = await client.get(url_abspath)\n    assert 403 == resp.status\n    await resp.release()\n\n    await client.close()\n\n\ndef test_static_route_path_existence_check() -> None:\n    directory = pathlib.Path(__file__).parent\n    web.StaticResource(\"/\", directory)\n\n    nodirectory = directory / \"nonexistent-uPNiOEAg5d\"\n    with pytest.raises(ValueError):\n        web.StaticResource(\"/\", nodirectory)\n\n\nasync def test_static_file_huge(aiohttp_client: Any, tmp_path: Any) -> None:\n    file_path = tmp_path / \"huge_data.unknown_mime_type\"\n\n    # fill 20MB file\n    with file_path.open(\"wb\") as f:\n        for i in range(1024 * 20):\n            f.write((chr(i % 64 + 0x20) * 1024).encode())\n\n    file_st = file_path.stat()\n\n    app = web.Application()\n    app.router.add_static(\"/static\", str(tmp_path))\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/static/\" + file_path.name)\n    assert 200 == resp.status\n    ct = resp.headers[\"CONTENT-TYPE\"]\n    assert \"application/octet-stream\" == ct\n    assert resp.headers.get(\"CONTENT-ENCODING\") is None\n    assert int(resp.headers.get(\"CONTENT-LENGTH\")) == file_st.st_size\n\n    f = file_path.open(\"rb\")\n    off = 0\n    cnt = 0\n    while off < file_st.st_size:\n        chunk = await resp.content.readany()\n        expected = f.read(len(chunk))\n        assert chunk == expected\n        off += len(chunk)\n        cnt += 1\n    f.close()\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_range(aiohttp_client: Any, sender: Any) -> None:\n    filepath = pathlib.Path(__file__).parent / \"sample.txt\"\n\n    filesize = filepath.stat().st_size\n\n    async def handler(request):\n        return sender(filepath, chunk_size=16)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with filepath.open(\"rb\") as f:\n        content = f.read()\n\n    # Ensure the whole file requested in parts is correct\n    responses = await asyncio.gather(\n        client.get(\"/\", headers={\"Range\": \"bytes=0-999\"}),\n        client.get(\"/\", headers={\"Range\": \"bytes=1000-1999\"}),\n        client.get(\"/\", headers={\"Range\": \"bytes=2000-\"}),\n    )\n    assert len(responses) == 3\n    assert responses[0].status == 206, \"failed 'bytes=0-999': %s\" % responses[0].reason\n    assert responses[0].headers[\"Content-Range\"] == \"bytes 0-999/{}\".format(\n        filesize\n    ), \"failed: Content-Range Error\"\n    assert responses[1].status == 206, (\n        \"failed 'bytes=1000-1999': %s\" % responses[1].reason\n    )\n    assert responses[1].headers[\"Content-Range\"] == \"bytes 1000-1999/{}\".format(\n        filesize\n    ), \"failed: Content-Range Error\"\n    assert responses[2].status == 206, \"failed 'bytes=2000-': %s\" % responses[2].reason\n    assert responses[2].headers[\"Content-Range\"] == \"bytes 2000-{}/{}\".format(\n        filesize - 1, filesize\n    ), \"failed: Content-Range Error\"\n\n    body = await asyncio.gather(\n        *(resp.read() for resp in responses),\n    )\n\n    assert len(body[0]) == 1000, \"failed 'bytes=0-999', received %d bytes\" % len(\n        body[0]\n    )\n    assert len(body[1]) == 1000, \"failed 'bytes=1000-1999', received %d bytes\" % len(\n        body[1]\n    )\n    responses[0].close()\n    responses[1].close()\n    responses[2].close()\n\n    await asyncio.gather(\n        *(resp.release() for resp in responses),\n    )\n\n    assert content == b\"\".join(body)\n\n    await client.close()\n\n\nasync def test_static_file_range_end_bigger_than_size(aiohttp_client: Any, sender: Any):\n    filepath = pathlib.Path(__file__).parent / \"aiohttp.png\"\n\n    async def handler(request):\n        return sender(filepath, chunk_size=16)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with filepath.open(\"rb\") as f:\n        content = f.read()\n\n        # Ensure the whole file requested in parts is correct\n        response = await client.get(\"/\", headers={\"Range\": \"bytes=54000-55000\"})\n\n        assert response.status == 206, (\n            \"failed 'bytes=54000-55000': %s\" % response.reason\n        )\n        assert (\n            response.headers[\"Content-Range\"] == \"bytes 54000-54996/54997\"\n        ), \"failed: Content-Range Error\"\n\n        body = await response.read()\n        assert len(body) == 997, \"failed 'bytes=54000-55000', received %d bytes\" % len(\n            body\n        )\n\n        assert content[54000:] == body\n\n    await response.release()\n    await client.close()\n\n\nasync def test_static_file_range_beyond_eof(aiohttp_client: Any, sender: Any) -> None:\n    filepath = pathlib.Path(__file__).parent / \"aiohttp.png\"\n\n    async def handler(request):\n        return sender(filepath, chunk_size=16)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    # Ensure the whole file requested in parts is correct\n    response = await client.get(\"/\", headers={\"Range\": \"bytes=1000000-1200000\"})\n\n    assert response.status == 416, (\n        \"failed 'bytes=1000000-1200000': %s\" % response.reason\n    )\n\n    await response.release()\n    await client.close()\n\n\nasync def test_static_file_range_tail(aiohttp_client: Any, sender: Any) -> None:\n    filepath = pathlib.Path(__file__).parent / \"aiohttp.png\"\n\n    async def handler(request):\n        return sender(filepath, chunk_size=16)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with filepath.open(\"rb\") as f:\n        content = f.read()\n\n    # Ensure the tail of the file is correct\n    resp = await client.get(\"/\", headers={\"Range\": \"bytes=-500\"})\n    assert resp.status == 206, resp.reason\n    assert (\n        resp.headers[\"Content-Range\"] == \"bytes 54497-54996/54997\"\n    ), \"failed: Content-Range Error\"\n    body4 = await resp.read()\n    resp.close()\n    await resp.release()\n    assert content[-500:] == body4\n\n    # Ensure out-of-range tails could be handled\n    resp2 = await client.get(\"/\", headers={\"Range\": \"bytes=-99999999999999\"})\n    assert resp2.status == 206, resp.reason\n    assert (\n        resp2.headers[\"Content-Range\"] == \"bytes 0-54996/54997\"\n    ), \"failed: Content-Range Error\"\n    await resp2.release()\n\n    await client.close()\n\n\nasync def test_static_file_invalid_range(aiohttp_client: Any, sender: Any) -> None:\n    filepath = pathlib.Path(__file__).parent / \"aiohttp.png\"\n\n    async def handler(request):\n        return sender(filepath, chunk_size=16)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    # range must be in bytes\n    resp = await client.get(\"/\", headers={\"Range\": \"blocks=0-10\"})\n    assert resp.status == 416, \"Range must be in bytes\"\n    resp.close()\n    await resp.release()\n\n    # start > end\n    resp = await client.get(\"/\", headers={\"Range\": \"bytes=100-0\"})\n    assert resp.status == 416, \"Range start can't be greater than end\"\n    resp.close()\n    await resp.release()\n\n    # start > end\n    resp = await client.get(\"/\", headers={\"Range\": \"bytes=10-9\"})\n    assert resp.status == 416, \"Range start can't be greater than end\"\n    resp.close()\n    await resp.release()\n\n    # non-number range\n    resp = await client.get(\"/\", headers={\"Range\": \"bytes=a-f\"})\n    assert resp.status == 416, \"Range must be integers\"\n    resp.close()\n    await resp.release()\n\n    # double dash range\n    resp = await client.get(\"/\", headers={\"Range\": \"bytes=0--10\"})\n    assert resp.status == 416, \"double dash in range\"\n    resp.close()\n    await resp.release()\n\n    # no range\n    resp = await client.get(\"/\", headers={\"Range\": \"bytes=-\"})\n    assert resp.status == 416, \"no range given\"\n    resp.close()\n    await resp.release()\n\n    await client.close()\n\n\nasync def test_static_file_if_unmodified_since_past_with_range(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"Mon, 1 Jan 1990 01:01:01 GMT\"\n\n    resp = await client.get(\n        \"/\", headers={\"If-Unmodified-Since\": lastmod, \"Range\": \"bytes=2-\"}\n    )\n    assert 412 == resp.status\n    resp.close()\n    await resp.release()\n\n    await client.close()\n\n\nasync def test_static_file_if_unmodified_since_future_with_range(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"Fri, 31 Dec 9999 23:59:59 GMT\"\n\n    resp = await client.get(\n        \"/\", headers={\"If-Unmodified-Since\": lastmod, \"Range\": \"bytes=2-\"}\n    )\n    assert 206 == resp.status\n    assert resp.headers[\"Content-Range\"] == \"bytes 2-12/13\"\n    assert resp.headers[\"Content-Length\"] == \"11\"\n    resp.close()\n    await resp.release()\n\n    await client.close()\n\n\nasync def test_static_file_if_range_past_with_range(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"Mon, 1 Jan 1990 01:01:01 GMT\"\n\n    resp = await client.get(\"/\", headers={\"If-Range\": lastmod, \"Range\": \"bytes=2-\"})\n    assert 200 == resp.status\n    assert resp.headers[\"Content-Length\"] == \"13\"\n    resp.close()\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_range_future_with_range(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"Fri, 31 Dec 9999 23:59:59 GMT\"\n\n    resp = await client.get(\"/\", headers={\"If-Range\": lastmod, \"Range\": \"bytes=2-\"})\n    assert 206 == resp.status\n    assert resp.headers[\"Content-Range\"] == \"bytes 2-12/13\"\n    assert resp.headers[\"Content-Length\"] == \"11\"\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_unmodified_since_past_without_range(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"Mon, 1 Jan 1990 01:01:01 GMT\"\n\n    resp = await client.get(\"/\", headers={\"If-Unmodified-Since\": lastmod})\n    assert 412 == resp.status\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_unmodified_since_future_without_range(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"Fri, 31 Dec 9999 23:59:59 GMT\"\n\n    resp = await client.get(\"/\", headers={\"If-Unmodified-Since\": lastmod})\n    assert 200 == resp.status\n    assert resp.headers[\"Content-Length\"] == \"13\"\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_range_past_without_range(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"Mon, 1 Jan 1990 01:01:01 GMT\"\n\n    resp = await client.get(\"/\", headers={\"If-Range\": lastmod})\n    assert 200 == resp.status\n    assert resp.headers[\"Content-Length\"] == \"13\"\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_range_future_without_range(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"Fri, 31 Dec 9999 23:59:59 GMT\"\n\n    resp = await client.get(\"/\", headers={\"If-Range\": lastmod})\n    assert 200 == resp.status\n    assert resp.headers[\"Content-Length\"] == \"13\"\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_unmodified_since_invalid_date(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"not a valid HTTP-date\"\n\n    resp = await client.get(\"/\", headers={\"If-Unmodified-Since\": lastmod})\n    assert 200 == resp.status\n    resp.close()\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_if_range_invalid_date(\n    aiohttp_client: Any, app_with_static_route: web.Application\n):\n    client = await aiohttp_client(app_with_static_route)\n\n    lastmod = \"not a valid HTTP-date\"\n\n    resp = await client.get(\"/\", headers={\"If-Range\": lastmod})\n    assert 200 == resp.status\n    resp.close()\n    await resp.release()\n\n    await client.close()\n\n\nasync def test_static_file_compression(aiohttp_client: Any, sender: Any) -> None:\n    filepath = pathlib.Path(__file__).parent / \"data.unknown_mime_type\"\n\n    async def handler(request):\n        ret = sender(filepath)\n        ret.enable_compression()\n        return ret\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, auto_decompress=False)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    zcomp = zlib.compressobj(wbits=zlib.MAX_WBITS)\n    expected_body = zcomp.compress(b\"file content\\n\") + zcomp.flush()\n    assert expected_body == await resp.read()\n    assert \"application/octet-stream\" == resp.headers[\"Content-Type\"]\n    assert resp.headers.get(\"Content-Encoding\") == \"deflate\"\n    await resp.release()\n\n    await client.close()\n\n\nasync def test_static_file_huge_cancel(aiohttp_client: Any, tmp_path: Any) -> None:\n    file_path = tmp_path / \"huge_data.unknown_mime_type\"\n\n    # fill 100MB file\n    with file_path.open(\"wb\") as f:\n        for i in range(1024 * 20):\n            f.write((chr(i % 64 + 0x20) * 1024).encode())\n\n    task = None\n\n    async def handler(request):\n        nonlocal task\n        task = request.task\n        # reduce send buffer size\n        tr = request.transport\n        sock = tr.get_extra_info(\"socket\")\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, 1024)\n        ret = web.FileResponse(file_path)\n        return ret\n\n    app = web.Application()\n\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    task.cancel()\n    await asyncio.sleep(0)\n    data = b\"\"\n    while True:\n        try:\n            data += await resp.content.read(1024)\n        except aiohttp.ClientPayloadError:\n            break\n    assert len(data) < 1024 * 1024 * 20\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_static_file_huge_error(aiohttp_client: Any, tmp_path: Any) -> None:\n    file_path = tmp_path / \"huge_data.unknown_mime_type\"\n\n    # fill 20MB file\n    with file_path.open(\"wb\") as f:\n        f.seek(20 * 1024 * 1024)\n        f.write(b\"1\")\n\n    async def handler(request):\n        # reduce send buffer size\n        tr = request.transport\n        sock = tr.get_extra_info(\"socket\")\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, 1024)\n        ret = web.FileResponse(file_path)\n        return ret\n\n    app = web.Application()\n\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    # raise an exception on server side\n    resp.close()\n\n    await resp.release()\n    await client.close()\n", "tests/test_client_request.py": "# type: ignore\nimport asyncio\nimport hashlib\nimport io\nimport pathlib\nimport zlib\nfrom http.cookies import BaseCookie, Morsel, SimpleCookie\nfrom typing import Any, Callable, Dict, Optional\nfrom unittest import mock\n\nimport pytest\nfrom multidict import CIMultiDict, CIMultiDictProxy, istr\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp import BaseConnector, hdrs, helpers, payload\nfrom aiohttp.client_exceptions import ClientConnectionError\nfrom aiohttp.client_reqrep import (\n    ClientRequest,\n    ClientResponse,\n    Fingerprint,\n    _gen_default_accept_encoding,\n)\nfrom aiohttp.http import HttpVersion\nfrom aiohttp.test_utils import make_mocked_coro\n\n\nclass WriterMock(mock.AsyncMock):\n    def __await__(self) -> None:\n        return self().__await__()\n\n    def add_done_callback(self, cb: Callable[[], None]) -> None:\n        \"\"\"Dummy method.\"\"\"\n\n    def remove_done_callback(self, cb: Callable[[], None]) -> None:\n        \"\"\"Dummy method.\"\"\"\n\n\n@pytest.fixture\ndef make_request(loop: Any):\n    request = None\n\n    def maker(method, url, *args, **kwargs):\n        nonlocal request\n        request = ClientRequest(method, URL(url), *args, loop=loop, **kwargs)\n        return request\n\n    yield maker\n    if request is not None:\n        loop.run_until_complete(request.close())\n\n\n@pytest.fixture\ndef buf():\n    return bytearray()\n\n\n@pytest.fixture\ndef protocol(loop: Any, transport: Any):\n    protocol = mock.Mock()\n    protocol.transport = transport\n    protocol._drain_helper.return_value = loop.create_future()\n    protocol._drain_helper.return_value.set_result(None)\n    return protocol\n\n\n@pytest.fixture\ndef transport(buf: Any):\n    transport = mock.Mock()\n\n    def write(chunk):\n        buf.extend(chunk)\n\n    async def write_eof():\n        pass\n\n    transport.write.side_effect = write\n    transport.write_eof.side_effect = write_eof\n    transport.is_closing.return_value = False\n\n    return transport\n\n\n@pytest.fixture\ndef conn(transport: Any, protocol: Any):\n    return mock.Mock(transport=transport, protocol=protocol)\n\n\ndef test_method1(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\")\n    assert req.method == \"GET\"\n\n\ndef test_method2(make_request: Any) -> None:\n    req = make_request(\"head\", \"http://python.org/\")\n    assert req.method == \"HEAD\"\n\n\ndef test_method3(make_request: Any) -> None:\n    req = make_request(\"HEAD\", \"http://python.org/\")\n    assert req.method == \"HEAD\"\n\n\ndef test_method_invalid(make_request: Any) -> None:\n    with pytest.raises(ValueError, match=\"Method cannot contain non-token characters\"):\n        make_request(\"METHOD WITH\\nWHITESPACES\", \"http://python.org/\")\n\n\ndef test_version_1_0(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\", version=\"1.0\")\n    assert req.version == (1, 0)\n\n\ndef test_version_default(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\")\n    assert req.version == (1, 1)\n\n\ndef test_request_info(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\")\n    url = URL(\"http://python.org/\")\n    assert req.request_info == aiohttp.RequestInfo(url, \"GET\", req.headers, url)\n\n\ndef test_request_info_with_fragment(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/#urlfragment\")\n    assert req.request_info == aiohttp.RequestInfo(\n        URL(\"http://python.org/\"),\n        \"GET\",\n        req.headers,\n        URL(\"http://python.org/#urlfragment\"),\n    )\n\n\ndef test_version_err(make_request: Any) -> None:\n    with pytest.raises(ValueError):\n        make_request(\"get\", \"http://python.org/\", version=\"1.c\")\n\n\ndef test_keep_alive(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\", version=(0, 9))\n    assert not req.keep_alive()\n\n    req = make_request(\"get\", \"http://python.org/\", version=(1, 0))\n    assert not req.keep_alive()\n\n    req = make_request(\n        \"get\",\n        \"http://python.org/\",\n        version=(1, 0),\n        headers={\"connection\": \"keep-alive\"},\n    )\n    assert req.keep_alive()\n\n    req = make_request(\"get\", \"http://python.org/\", version=(1, 1))\n    assert req.keep_alive()\n\n    req = make_request(\n        \"get\", \"http://python.org/\", version=(1, 1), headers={\"connection\": \"close\"}\n    )\n    assert not req.keep_alive()\n\n\ndef test_host_port_default_http(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\")\n    assert req.host == \"python.org\"\n    assert req.port == 80\n    assert not req.is_ssl()\n\n\ndef test_host_port_default_https(make_request: Any) -> None:\n    req = make_request(\"get\", \"https://python.org/\")\n    assert req.host == \"python.org\"\n    assert req.port == 443\n    assert req.is_ssl()\n\n\ndef test_host_port_nondefault_http(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org:960/\")\n    assert req.host == \"python.org\"\n    assert req.port == 960\n    assert not req.is_ssl()\n\n\ndef test_host_port_nondefault_https(make_request: Any) -> None:\n    req = make_request(\"get\", \"https://python.org:960/\")\n    assert req.host == \"python.org\"\n    assert req.port == 960\n    assert req.is_ssl()\n\n\ndef test_host_port_default_ws(make_request: Any) -> None:\n    req = make_request(\"get\", \"ws://python.org/\")\n    assert req.host == \"python.org\"\n    assert req.port == 80\n    assert not req.is_ssl()\n\n\ndef test_host_port_default_wss(make_request: Any) -> None:\n    req = make_request(\"get\", \"wss://python.org/\")\n    assert req.host == \"python.org\"\n    assert req.port == 443\n    assert req.is_ssl()\n\n\ndef test_host_port_nondefault_ws(make_request: Any) -> None:\n    req = make_request(\"get\", \"ws://python.org:960/\")\n    assert req.host == \"python.org\"\n    assert req.port == 960\n    assert not req.is_ssl()\n\n\ndef test_host_port_nondefault_wss(make_request: Any) -> None:\n    req = make_request(\"get\", \"wss://python.org:960/\")\n    assert req.host == \"python.org\"\n    assert req.port == 960\n    assert req.is_ssl()\n\n\ndef test_host_port_none_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"unix://localhost/path\")\n    assert req.headers[\"Host\"] == \"localhost\"\n\n\ndef test_host_port_err(make_request: Any) -> None:\n    with pytest.raises(ValueError):\n        make_request(\"get\", \"http://python.org:123e/\")\n\n\ndef test_hostname_err(make_request: Any) -> None:\n    with pytest.raises(ValueError):\n        make_request(\"get\", \"http://:8080/\")\n\n\ndef test_host_header_host_first(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\")\n    assert list(req.headers)[0] == \"Host\"\n\n\ndef test_host_header_host_without_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\")\n    assert req.headers[\"HOST\"] == \"python.org\"\n\n\ndef test_host_header_host_with_default_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org:80/\")\n    assert req.headers[\"HOST\"] == \"python.org\"\n\n\ndef test_host_header_host_with_nondefault_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org:99/\")\n    assert req.headers[\"HOST\"] == \"python.org:99\"\n\n\ndef test_host_header_host_idna_encode(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://xn--9caa.com\")\n    assert req.headers[\"HOST\"] == \"xn--9caa.com\"\n\n\ndef test_host_header_host_unicode(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://\u00e9\u00e9.com\")\n    assert req.headers[\"HOST\"] == \"xn--9caa.com\"\n\n\ndef test_host_header_explicit_host(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\", headers={\"host\": \"example.com\"})\n    assert req.headers[\"HOST\"] == \"example.com\"\n\n\ndef test_host_header_explicit_host_with_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\", headers={\"host\": \"example.com:99\"})\n    assert req.headers[\"HOST\"] == \"example.com:99\"\n\n\ndef test_host_header_ipv4(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://127.0.0.2\")\n    assert req.headers[\"HOST\"] == \"127.0.0.2\"\n\n\ndef test_host_header_ipv6(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://[::2]\")\n    assert req.headers[\"HOST\"] == \"[::2]\"\n\n\ndef test_host_header_ipv4_with_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://127.0.0.2:99\")\n    assert req.headers[\"HOST\"] == \"127.0.0.2:99\"\n\n\ndef test_host_header_ipv6_with_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://[::2]:99\")\n    assert req.headers[\"HOST\"] == \"[::2]:99\"\n\n\n@pytest.mark.parametrize(\n    (\"url\", \"headers\", \"expected\"),\n    (\n        pytest.param(\"http://localhost.\", None, \"localhost\", id=\"dot only at the end\"),\n        pytest.param(\"http://python.org.\", None, \"python.org\", id=\"single dot\"),\n        pytest.param(\n            \"http://python.org.:99\", None, \"python.org:99\", id=\"single dot with port\"\n        ),\n        pytest.param(\n            \"http://python.org...:99\",\n            None,\n            \"python.org:99\",\n            id=\"multiple dots with port\",\n        ),\n        pytest.param(\n            \"http://python.org.:99\",\n            {\"host\": \"example.com.:99\"},\n            \"example.com.:99\",\n            id=\"explicit host header\",\n        ),\n        pytest.param(\"https://python.org.\", None, \"python.org\", id=\"https\"),\n        pytest.param(\"https://...\", None, \"\", id=\"only dots\"),\n        pytest.param(\n            \"http://pr\u00edklad.example.org.:99\",\n            None,\n            \"xn--prklad-4va.example.org:99\",\n            id=\"single dot with port idna\",\n        ),\n    ),\n)\ndef test_host_header_fqdn(\n    make_request: Any, url: str, headers: Dict[str, str], expected: str\n) -> None:\n    req = make_request(\"get\", url, headers=headers)\n    assert req.headers[\"HOST\"] == expected\n\n\ndef test_default_headers_useragent(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org/\")\n\n    assert \"SERVER\" not in req.headers\n    assert \"USER-AGENT\" in req.headers\n\n\ndef test_default_headers_useragent_custom(make_request: Any) -> None:\n    req = make_request(\n        \"get\", \"http://python.org/\", headers={\"user-agent\": \"my custom agent\"}\n    )\n\n    assert \"USER-Agent\" in req.headers\n    assert \"my custom agent\" == req.headers[\"User-Agent\"]\n\n\ndef test_skip_default_useragent_header(make_request: Any) -> None:\n    req = make_request(\n        \"get\", \"http://python.org/\", skip_auto_headers={istr(\"user-agent\")}\n    )\n\n    assert \"User-Agent\" not in req.headers\n\n\ndef test_headers(make_request: Any) -> None:\n    req = make_request(\n        \"post\", \"http://python.org/\", headers={\"Content-Type\": \"text/plain\"}\n    )\n\n    assert \"CONTENT-TYPE\" in req.headers\n    assert req.headers[\"CONTENT-TYPE\"] == \"text/plain\"\n    assert req.headers[\"ACCEPT-ENCODING\"] == \"gzip, deflate, br\"\n\n\ndef test_headers_list(make_request: Any) -> None:\n    req = make_request(\n        \"post\", \"http://python.org/\", headers=[(\"Content-Type\", \"text/plain\")]\n    )\n    assert \"CONTENT-TYPE\" in req.headers\n    assert req.headers[\"CONTENT-TYPE\"] == \"text/plain\"\n\n\ndef test_headers_default(make_request: Any) -> None:\n    req = make_request(\n        \"get\", \"http://python.org/\", headers={\"ACCEPT-ENCODING\": \"deflate\"}\n    )\n    assert req.headers[\"ACCEPT-ENCODING\"] == \"deflate\"\n\n\ndef test_invalid_url(make_request: Any) -> None:\n    with pytest.raises(aiohttp.InvalidURL):\n        make_request(\"get\", \"hiwpefhipowhefopw\")\n\n\ndef test_no_path(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://python.org\")\n    assert \"/\" == req.url.path\n\n\ndef test_ipv6_default_http_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://[2001:db8::1]/\")\n    assert req.host == \"2001:db8::1\"\n    assert req.port == 80\n    assert not req.is_ssl()\n\n\ndef test_ipv6_default_https_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"https://[2001:db8::1]/\")\n    assert req.host == \"2001:db8::1\"\n    assert req.port == 443\n    assert req.is_ssl()\n\n\ndef test_ipv6_nondefault_http_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://[2001:db8::1]:960/\")\n    assert req.host == \"2001:db8::1\"\n    assert req.port == 960\n    assert not req.is_ssl()\n\n\ndef test_ipv6_nondefault_https_port(make_request: Any) -> None:\n    req = make_request(\"get\", \"https://[2001:db8::1]:960/\")\n    assert req.host == \"2001:db8::1\"\n    assert req.port == 960\n    assert req.is_ssl()\n\n\ndef test_basic_auth(make_request: Any) -> None:\n    req = make_request(\n        \"get\", \"http://python.org\", auth=aiohttp.BasicAuth(\"nkim\", \"1234\")\n    )\n    assert \"AUTHORIZATION\" in req.headers\n    assert \"Basic bmtpbToxMjM0\" == req.headers[\"AUTHORIZATION\"]\n\n\ndef test_basic_auth_utf8(make_request: Any) -> None:\n    req = make_request(\n        \"get\", \"http://python.org\", auth=aiohttp.BasicAuth(\"nkim\", \"\u0441\u0435\u043a\u0440\u0435\u0442\", \"utf-8\")\n    )\n    assert \"AUTHORIZATION\" in req.headers\n    assert \"Basic bmtpbTrRgdC10LrRgNC10YI=\" == req.headers[\"AUTHORIZATION\"]\n\n\ndef test_basic_auth_tuple_forbidden(make_request: Any) -> None:\n    with pytest.raises(TypeError):\n        make_request(\"get\", \"http://python.org\", auth=(\"nkim\", \"1234\"))\n\n\ndef test_basic_auth_from_url(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://nkim:1234@python.org\")\n    assert \"AUTHORIZATION\" in req.headers\n    assert \"Basic bmtpbToxMjM0\" == req.headers[\"AUTHORIZATION\"]\n    assert \"python.org\" == req.host\n\n\ndef test_basic_auth_from_url_overridden(make_request: Any) -> None:\n    req = make_request(\n        \"get\", \"http://garbage@python.org\", auth=aiohttp.BasicAuth(\"nkim\", \"1234\")\n    )\n    assert \"AUTHORIZATION\" in req.headers\n    assert \"Basic bmtpbToxMjM0\" == req.headers[\"AUTHORIZATION\"]\n    assert \"python.org\" == req.host\n\n\ndef test_path_is_not_double_encoded1(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://0.0.0.0/get/test case\")\n    assert req.url.raw_path == \"/get/test%20case\"\n\n\ndef test_path_is_not_double_encoded2(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://0.0.0.0/get/test%2fcase\")\n    assert req.url.raw_path == \"/get/test%2Fcase\"\n\n\ndef test_path_is_not_double_encoded3(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://0.0.0.0/get/test%20case\")\n    assert req.url.raw_path == \"/get/test%20case\"\n\n\ndef test_path_safe_chars_preserved(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://0.0.0.0/get/:=+/%2B/\")\n    assert req.url.path == \"/get/:=+/+/\"\n\n\ndef test_params_are_added_before_fragment1(make_request: Any) -> None:\n    req = make_request(\"GET\", \"http://example.com/path#fragment\", params={\"a\": \"b\"})\n    assert str(req.url) == \"http://example.com/path?a=b\"\n\n\ndef test_params_are_added_before_fragment2(make_request: Any) -> None:\n    req = make_request(\n        \"GET\", \"http://example.com/path?key=value#fragment\", params={\"a\": \"b\"}\n    )\n    assert str(req.url) == \"http://example.com/path?key=value&a=b\"\n\n\ndef test_path_not_contain_fragment1(make_request: Any) -> None:\n    req = make_request(\"GET\", \"http://example.com/path#fragment\")\n    assert req.url.path == \"/path\"\n\n\ndef test_path_not_contain_fragment2(make_request: Any) -> None:\n    req = make_request(\"GET\", \"http://example.com/path?key=value#fragment\")\n    assert str(req.url) == \"http://example.com/path?key=value\"\n\n\ndef test_cookies(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://test.com/path\", cookies={\"cookie1\": \"val1\"})\n\n    assert \"COOKIE\" in req.headers\n    assert \"cookie1=val1\" == req.headers[\"COOKIE\"]\n\n\ndef test_cookies_is_quoted_with_special_characters(make_request: Any) -> None:\n    req = make_request(\"get\", \"http://test.com/path\", cookies={\"cookie1\": \"val/one\"})\n\n    assert \"COOKIE\" in req.headers\n    assert 'cookie1=\"val/one\"' == req.headers[\"COOKIE\"]\n\n\ndef test_cookies_merge_with_headers(make_request: Any) -> None:\n    req = make_request(\n        \"get\",\n        \"http://test.com/path\",\n        headers={\"cookie\": \"cookie1=val1\"},\n        cookies={\"cookie2\": \"val2\"},\n    )\n\n    assert \"cookie1=val1; cookie2=val2\" == req.headers[\"COOKIE\"]\n\n\ndef test_query_multivalued_param(make_request: Any) -> None:\n    for meth in ClientRequest.ALL_METHODS:\n        req = make_request(\n            meth, \"http://python.org\", params=((\"test\", \"foo\"), (\"test\", \"baz\"))\n        )\n\n        assert str(req.url) == \"http://python.org/?test=foo&test=baz\"\n\n\ndef test_query_str_param(make_request: Any) -> None:\n    for meth in ClientRequest.ALL_METHODS:\n        req = make_request(meth, \"http://python.org\", params=\"test=foo\")\n        assert str(req.url) == \"http://python.org/?test=foo\"\n\n\ndef test_query_bytes_param_raises(make_request: Any) -> None:\n    for meth in ClientRequest.ALL_METHODS:\n        with pytest.raises(TypeError):\n            make_request(meth, \"http://python.org\", params=b\"test=foo\")\n\n\ndef test_query_str_param_is_not_encoded(make_request: Any) -> None:\n    for meth in ClientRequest.ALL_METHODS:\n        req = make_request(meth, \"http://python.org\", params=\"test=f+oo\")\n        assert str(req.url) == \"http://python.org/?test=f+oo\"\n\n\ndef test_params_update_path_and_url(make_request: Any) -> None:\n    req = make_request(\n        \"get\", \"http://python.org\", params=((\"test\", \"foo\"), (\"test\", \"baz\"))\n    )\n    assert str(req.url) == \"http://python.org/?test=foo&test=baz\"\n\n\ndef test_params_empty_path_and_url(make_request: Any) -> None:\n    req_empty = make_request(\"get\", \"http://python.org\", params={})\n    assert str(req_empty.url) == \"http://python.org\"\n    req_none = make_request(\"get\", \"http://python.org\")\n    assert str(req_none.url) == \"http://python.org\"\n\n\ndef test_gen_netloc_all(make_request: Any) -> None:\n    req = make_request(\n        \"get\",\n        \"https://aiohttp:pwpwpw@\"\n        + \"12345678901234567890123456789\"\n        + \"012345678901234567890:8080\",\n    )\n    assert (\n        req.headers[\"HOST\"]\n        == \"12345678901234567890123456789\" + \"012345678901234567890:8080\"\n    )\n\n\ndef test_gen_netloc_no_port(make_request: Any) -> None:\n    req = make_request(\n        \"get\",\n        \"https://aiohttp:pwpwpw@\"\n        + \"12345678901234567890123456789\"\n        + \"012345678901234567890/\",\n    )\n    assert (\n        req.headers[\"HOST\"] == \"12345678901234567890123456789\" + \"012345678901234567890\"\n    )\n\n\nasync def test_connection_header(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\"get\", URL(\"http://python.org\"), loop=loop)\n    req.keep_alive = mock.Mock()\n    req.headers.clear()\n\n    req.keep_alive.return_value = True\n    req.version = HttpVersion(1, 1)\n    req.headers.clear()\n    await req.send(conn)\n    assert req.headers.get(\"CONNECTION\") is None\n\n    req.version = HttpVersion(1, 0)\n    req.headers.clear()\n    await req.send(conn)\n    assert req.headers.get(\"CONNECTION\") == \"keep-alive\"\n\n    req.keep_alive.return_value = False\n    req.version = HttpVersion(1, 1)\n    req.headers.clear()\n    await req.send(conn)\n    assert req.headers.get(\"CONNECTION\") == \"close\"\n\n\nasync def test_no_content_length(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\"get\", URL(\"http://python.org\"), loop=loop)\n    resp = await req.send(conn)\n    assert req.headers.get(\"CONTENT-LENGTH\") is None\n    await req.close()\n    resp.close()\n\n\nasync def test_no_content_length_head(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\"head\", URL(\"http://python.org\"), loop=loop)\n    resp = await req.send(conn)\n    assert req.headers.get(\"CONTENT-LENGTH\") is None\n    await req.close()\n    resp.close()\n\n\nasync def test_content_type_auto_header_get(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\"get\", URL(\"http://python.org\"), loop=loop)\n    resp = await req.send(conn)\n    assert \"CONTENT-TYPE\" not in req.headers\n    resp.close()\n    await req.close()\n\n\nasync def test_content_type_auto_header_form(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"post\", URL(\"http://python.org\"), data={\"hey\": \"you\"}, loop=loop\n    )\n    resp = await req.send(conn)\n    assert \"application/x-www-form-urlencoded\" == req.headers.get(\"CONTENT-TYPE\")\n    resp.close()\n\n\nasync def test_content_type_auto_header_bytes(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\"post\", URL(\"http://python.org\"), data=b\"hey you\", loop=loop)\n    resp = await req.send(conn)\n    assert \"application/octet-stream\" == req.headers.get(\"CONTENT-TYPE\")\n    resp.close()\n\n\nasync def test_content_type_skip_auto_header_bytes(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"post\",\n        URL(\"http://python.org\"),\n        data=b\"hey you\",\n        skip_auto_headers={\"Content-Type\"},\n        loop=loop,\n    )\n    resp = await req.send(conn)\n    assert \"CONTENT-TYPE\" not in req.headers\n    resp.close()\n\n\nasync def test_content_type_skip_auto_header_form(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"post\",\n        URL(\"http://python.org\"),\n        data={\"hey\": \"you\"},\n        loop=loop,\n        skip_auto_headers={\"Content-Type\"},\n    )\n    resp = await req.send(conn)\n    assert \"CONTENT-TYPE\" not in req.headers\n    resp.close()\n\n\nasync def test_content_type_auto_header_content_length_no_skip(\n    loop: Any, conn: Any\n) -> None:\n    with io.BytesIO(b\"hey\") as file_handle:\n        req = ClientRequest(\n            \"post\",\n            URL(\"http://python.org\"),\n            data=file_handle,\n            skip_auto_headers={\"Content-Length\"},\n            loop=loop,\n        )\n        resp = await req.send(conn)\n        assert req.headers.get(\"CONTENT-LENGTH\") == \"3\"\n        resp.close()\n\n\nasync def test_urlencoded_formdata_charset(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"post\",\n        URL(\"http://python.org\"),\n        data=aiohttp.FormData({\"hey\": \"you\"}, charset=\"koi8-r\"),\n        loop=loop,\n    )\n    await req.send(conn)\n    assert \"application/x-www-form-urlencoded; charset=koi8-r\" == req.headers.get(\n        \"CONTENT-TYPE\"\n    )\n\n\nasync def test_formdata_boundary_from_headers(loop: Any, conn: Any) -> None:\n    boundary = \"some_boundary\"\n    file_path = pathlib.Path(__file__).parent / \"aiohttp.png\"\n    with file_path.open(\"rb\") as f:\n        req = ClientRequest(\n            \"post\",\n            URL(\"http://python.org\"),\n            data={\"aiohttp.png\": f},\n            headers={\"Content-Type\": f\"multipart/form-data; boundary={boundary}\"},\n            loop=loop,\n        )\n        await req.send(conn)\n        assert req.body._boundary == boundary.encode()\n\n\nasync def test_post_data(loop: Any, conn: Any) -> None:\n    for meth in ClientRequest.POST_METHODS:\n        req = ClientRequest(\n            meth, URL(\"http://python.org/\"), data={\"life\": \"42\"}, loop=loop\n        )\n        resp = await req.send(conn)\n        assert \"/\" == req.url.path\n        assert b\"life=42\" == req.body._value\n        assert \"application/x-www-form-urlencoded\" == req.headers[\"CONTENT-TYPE\"]\n        await req.close()\n        resp.close()\n\n\nasync def test_pass_falsy_data(loop: Any) -> None:\n    with mock.patch(\"aiohttp.client_reqrep.ClientRequest.update_body_from_data\"):\n        req = ClientRequest(\"post\", URL(\"http://python.org/\"), data={}, loop=loop)\n        req.update_body_from_data.assert_called_once_with({})\n    await req.close()\n\n\nasync def test_pass_falsy_data_file(loop: Any, tmp_path: Any) -> None:\n    testfile = (tmp_path / \"tmpfile\").open(\"w+b\")\n    testfile.write(b\"data\")\n    testfile.seek(0)\n    skip = frozenset([hdrs.CONTENT_TYPE])\n    req = ClientRequest(\n        \"post\",\n        URL(\"http://python.org/\"),\n        data=testfile,\n        skip_auto_headers=skip,\n        loop=loop,\n    )\n    assert req.headers.get(\"CONTENT-LENGTH\", None) is not None\n    await req.close()\n    testfile.close()\n\n\n# Elasticsearch API requires to send request body with GET-requests\nasync def test_get_with_data(loop: Any) -> None:\n    for meth in ClientRequest.GET_METHODS:\n        req = ClientRequest(\n            meth, URL(\"http://python.org/\"), data={\"life\": \"42\"}, loop=loop\n        )\n        assert \"/\" == req.url.path\n        assert b\"life=42\" == req.body._value\n        await req.close()\n\n\nasync def test_bytes_data(loop: Any, conn: Any) -> None:\n    for meth in ClientRequest.POST_METHODS:\n        req = ClientRequest(\n            meth, URL(\"http://python.org/\"), data=b\"binary data\", loop=loop\n        )\n        resp = await req.send(conn)\n        assert \"/\" == req.url.path\n        assert isinstance(req.body, payload.BytesPayload)\n        assert b\"binary data\" == req.body._value\n        assert \"application/octet-stream\" == req.headers[\"CONTENT-TYPE\"]\n        await req.close()\n        resp.close()\n\n\nasync def test_content_encoding(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"post\", URL(\"http://python.org/\"), data=\"foo\", compress=\"deflate\", loop=loop\n    )\n    with mock.patch(\"aiohttp.client_reqrep.StreamWriter\") as m_writer:\n        m_writer.return_value.write_headers = make_mocked_coro()\n        resp = await req.send(conn)\n    assert req.headers[\"TRANSFER-ENCODING\"] == \"chunked\"\n    assert req.headers[\"CONTENT-ENCODING\"] == \"deflate\"\n    m_writer.return_value.enable_compression.assert_called_with(\"deflate\")\n    await req.close()\n    resp.close()\n\n\nasync def test_content_encoding_dont_set_headers_if_no_body(\n    loop: Any, conn: Any\n) -> None:\n    req = ClientRequest(\n        \"post\", URL(\"http://python.org/\"), compress=\"deflate\", loop=loop\n    )\n    with mock.patch(\"aiohttp.client_reqrep.http\"):\n        resp = await req.send(conn)\n    assert \"TRANSFER-ENCODING\" not in req.headers\n    assert \"CONTENT-ENCODING\" not in req.headers\n    await req.close()\n    resp.close()\n\n\nasync def test_content_encoding_header(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"post\",\n        URL(\"http://python.org/\"),\n        data=\"foo\",\n        headers={\"Content-Encoding\": \"deflate\"},\n        loop=loop,\n    )\n    with mock.patch(\"aiohttp.client_reqrep.StreamWriter\") as m_writer:\n        m_writer.return_value.write_headers = make_mocked_coro()\n        resp = await req.send(conn)\n\n    assert not m_writer.return_value.enable_compression.called\n    assert not m_writer.return_value.enable_chunking.called\n    await req.close()\n    resp.close()\n\n\nasync def test_compress_and_content_encoding(loop: Any, conn: Any) -> None:\n    with pytest.raises(ValueError):\n        ClientRequest(\n            \"post\",\n            URL(\"http://python.org/\"),\n            data=\"foo\",\n            headers={\"content-encoding\": \"deflate\"},\n            compress=\"deflate\",\n            loop=loop,\n        )\n\n\nasync def test_chunked(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"post\",\n        URL(\"http://python.org/\"),\n        headers={\"TRANSFER-ENCODING\": \"gzip\"},\n        loop=loop,\n    )\n    resp = await req.send(conn)\n    assert \"gzip\" == req.headers[\"TRANSFER-ENCODING\"]\n    await req.close()\n    resp.close()\n\n\nasync def test_chunked2(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"post\",\n        URL(\"http://python.org/\"),\n        headers={\"Transfer-encoding\": \"chunked\"},\n        loop=loop,\n    )\n    resp = await req.send(conn)\n    assert \"chunked\" == req.headers[\"TRANSFER-ENCODING\"]\n    await req.close()\n    resp.close()\n\n\nasync def test_chunked_explicit(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\"post\", URL(\"http://python.org/\"), chunked=True, loop=loop)\n    with mock.patch(\"aiohttp.client_reqrep.StreamWriter\") as m_writer:\n        m_writer.return_value.write_headers = make_mocked_coro()\n        resp = await req.send(conn)\n\n    assert \"chunked\" == req.headers[\"TRANSFER-ENCODING\"]\n    m_writer.return_value.enable_chunking.assert_called_with()\n    await req.close()\n    resp.close()\n\n\nasync def test_chunked_length(loop: Any, conn: Any) -> None:\n    with pytest.raises(ValueError):\n        ClientRequest(\n            \"post\",\n            URL(\"http://python.org/\"),\n            headers={\"CONTENT-LENGTH\": \"1000\"},\n            chunked=True,\n            loop=loop,\n        )\n\n\nasync def test_chunked_transfer_encoding(loop: Any, conn: Any) -> None:\n    with pytest.raises(ValueError):\n        ClientRequest(\n            \"post\",\n            URL(\"http://python.org/\"),\n            headers={\"TRANSFER-ENCODING\": \"chunked\"},\n            chunked=True,\n            loop=loop,\n        )\n\n\nasync def test_file_upload_not_chunked(loop: Any) -> None:\n    file_path = pathlib.Path(__file__).parent / \"aiohttp.png\"\n    with file_path.open(\"rb\") as f:\n        req = ClientRequest(\"post\", URL(\"http://python.org/\"), data=f, loop=loop)\n        assert not req.chunked\n        assert req.headers[\"CONTENT-LENGTH\"] == str(file_path.stat().st_size)\n        await req.close()\n\n\nasync def test_precompressed_data_stays_intact(loop: Any) -> None:\n    data = zlib.compress(b\"foobar\")\n    req = ClientRequest(\n        \"post\",\n        URL(\"http://python.org/\"),\n        data=data,\n        headers={\"CONTENT-ENCODING\": \"deflate\"},\n        compress=False,\n        loop=loop,\n    )\n    assert not req.compress\n    assert not req.chunked\n    assert req.headers[\"CONTENT-ENCODING\"] == \"deflate\"\n    await req.close()\n\n\nasync def test_file_upload_not_chunked_seek(loop: Any) -> None:\n    file_path = pathlib.Path(__file__).parent / \"aiohttp.png\"\n    with file_path.open(\"rb\") as f:\n        f.seek(100)\n        req = ClientRequest(\"post\", URL(\"http://python.org/\"), data=f, loop=loop)\n        assert req.headers[\"CONTENT-LENGTH\"] == str(file_path.stat().st_size - 100)\n        await req.close()\n\n\nasync def test_file_upload_force_chunked(loop: Any) -> None:\n    file_path = pathlib.Path(__file__).parent / \"aiohttp.png\"\n    with file_path.open(\"rb\") as f:\n        req = ClientRequest(\n            \"post\", URL(\"http://python.org/\"), data=f, chunked=True, loop=loop\n        )\n        assert req.chunked\n        assert \"CONTENT-LENGTH\" not in req.headers\n        await req.close()\n\n\nasync def test_expect100(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\"get\", URL(\"http://python.org/\"), expect100=True, loop=loop)\n    resp = await req.send(conn)\n    assert \"100-continue\" == req.headers[\"EXPECT\"]\n    assert req._continue is not None\n    req.terminate()\n    resp.close()\n\n\nasync def test_expect_100_continue_header(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"get\", URL(\"http://python.org/\"), headers={\"expect\": \"100-continue\"}, loop=loop\n    )\n    resp = await req.send(conn)\n    assert \"100-continue\" == req.headers[\"EXPECT\"]\n    assert req._continue is not None\n    req.terminate()\n    resp.close()\n\n\nasync def test_data_stream(loop: Any, buf: Any, conn: Any) -> None:\n    async def gen():\n        yield b\"binary data\"\n        yield b\" result\"\n\n    req = ClientRequest(\"POST\", URL(\"http://python.org/\"), data=gen(), loop=loop)\n    assert req.chunked\n    assert req.headers[\"TRANSFER-ENCODING\"] == \"chunked\"\n\n    resp = await req.send(conn)\n    assert asyncio.isfuture(req._writer)\n    await resp.wait_for_close()\n    assert req._writer is None\n    assert (\n        buf.split(b\"\\r\\n\\r\\n\", 1)[1] == b\"b\\r\\nbinary data\\r\\n7\\r\\n result\\r\\n0\\r\\n\\r\\n\"\n    )\n    await req.close()\n\n\nasync def test_data_file(loop: Any, buf: Any, conn: Any) -> None:\n    with io.BufferedReader(io.BytesIO(b\"*\" * 2)) as file_handle:\n        req = ClientRequest(\n            \"POST\",\n            URL(\"http://python.org/\"),\n            data=file_handle,\n            loop=loop,\n        )\n        assert req.chunked\n        assert isinstance(req.body, payload.BufferedReaderPayload)\n        assert req.headers[\"TRANSFER-ENCODING\"] == \"chunked\"\n\n        resp = await req.send(conn)\n        assert asyncio.isfuture(req._writer)\n        await resp.wait_for_close()\n\n        assert req._writer is None\n        assert buf.split(b\"\\r\\n\\r\\n\", 1)[1] == b\"2\\r\\n\" + b\"*\" * 2 + b\"\\r\\n0\\r\\n\\r\\n\"\n        await req.close()\n\n\nasync def test_data_stream_exc(loop: Any, conn: Any) -> None:\n    fut = loop.create_future()\n\n    async def gen():\n        yield b\"binary data\"\n        await fut\n\n    req = ClientRequest(\"POST\", URL(\"http://python.org/\"), data=gen(), loop=loop)\n    assert req.chunked\n    assert req.headers[\"TRANSFER-ENCODING\"] == \"chunked\"\n\n    async def throw_exc():\n        await asyncio.sleep(0.01)\n        fut.set_exception(ValueError)\n\n    loop.create_task(throw_exc())\n\n    await req.send(conn)\n    await req._writer\n    # assert conn.close.called\n    assert conn.protocol.set_exception.called\n    await req.close()\n\n\nasync def test_data_stream_exc_chain(loop: Any, conn: Any) -> None:\n    fut = loop.create_future()\n\n    async def gen():\n        await fut\n        return\n        yield\n\n    req = ClientRequest(\"POST\", URL(\"http://python.org/\"), data=gen(), loop=loop)\n\n    inner_exc = ValueError()\n\n    async def throw_exc():\n        await asyncio.sleep(0.01)\n        fut.set_exception(inner_exc)\n\n    loop.create_task(throw_exc())\n\n    await req.send(conn)\n    await req._writer\n    # assert connection.close.called\n    assert conn.protocol.set_exception.called\n    outer_exc = conn.protocol.set_exception.call_args[0][0]\n    assert isinstance(outer_exc, ClientConnectionError)\n    assert outer_exc.__cause__ is inner_exc\n    await req.close()\n\n\nasync def test_data_stream_continue(loop: Any, buf: Any, conn: Any) -> None:\n    async def gen():\n        yield b\"binary data\"\n        yield b\" result\"\n\n    req = ClientRequest(\n        \"POST\", URL(\"http://python.org/\"), data=gen(), expect100=True, loop=loop\n    )\n    assert req.chunked\n\n    async def coro():\n        await asyncio.sleep(0.0001)\n        req._continue.set_result(1)\n\n    loop.create_task(coro())\n\n    resp = await req.send(conn)\n    await req._writer\n    assert (\n        buf.split(b\"\\r\\n\\r\\n\", 1)[1] == b\"b\\r\\nbinary data\\r\\n7\\r\\n result\\r\\n0\\r\\n\\r\\n\"\n    )\n    await req.close()\n    resp.close()\n\n\nasync def test_data_continue(loop: Any, buf: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"POST\", URL(\"http://python.org/\"), data=b\"data\", expect100=True, loop=loop\n    )\n\n    async def coro():\n        await asyncio.sleep(0.0001)\n        req._continue.set_result(1)\n\n    loop.create_task(coro())\n\n    resp = await req.send(conn)\n\n    await req._writer\n    assert buf.split(b\"\\r\\n\\r\\n\", 1)[1] == b\"data\"\n    await req.close()\n    resp.close()\n\n\nasync def test_close(loop: Any, buf: Any, conn: Any) -> None:\n    async def gen():\n        await asyncio.sleep(0.00001)\n        yield b\"result\"\n\n    req = ClientRequest(\"POST\", URL(\"http://python.org/\"), data=gen(), loop=loop)\n    resp = await req.send(conn)\n    await req.close()\n    assert buf.split(b\"\\r\\n\\r\\n\", 1)[1] == b\"6\\r\\nresult\\r\\n0\\r\\n\\r\\n\"\n    await req.close()\n    resp.close()\n\n\nasync def test_bad_version(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\n        \"GET\",\n        URL(\"http://python.org\"),\n        loop=loop,\n        headers={\"Connection\": \"Close\"},\n        version=(\"1\", \"1\\r\\nInjected-Header: not allowed\"),\n    )\n\n    with pytest.raises(AttributeError):\n        await req.send(conn)\n\n\nasync def test_custom_response_class(loop: Any, conn: Any) -> None:\n    class CustomResponse(ClientResponse):\n        def read(self, decode=False):\n            return \"customized!\"\n\n    req = ClientRequest(\n        \"GET\", URL(\"http://python.org/\"), response_class=CustomResponse, loop=loop\n    )\n    resp = await req.send(conn)\n    assert \"customized!\" == resp.read()\n    await req.close()\n    resp.close()\n\n\nasync def test_oserror_on_write_bytes(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\"POST\", URL(\"http://python.org/\"), loop=loop)\n\n    writer = WriterMock()\n    writer.write.side_effect = OSError\n\n    await req.write_bytes(writer, conn)\n\n    assert conn.protocol.set_exception.called\n    exc = conn.protocol.set_exception.call_args[0][0]\n    assert isinstance(exc, aiohttp.ClientOSError)\n\n\nasync def test_terminate(loop: Any, conn: Any) -> None:\n    req = ClientRequest(\"get\", URL(\"http://python.org\"), loop=loop)\n    resp = await req.send(conn)\n    assert req._writer is not None\n    writer = req._writer = WriterMock()\n    writer.cancel = mock.Mock()\n\n    req.terminate()\n    assert req._writer is None\n    writer.cancel.assert_called_with()\n    resp.close()\n\n\ndef test_terminate_with_closed_loop(loop: Any, conn: Any) -> None:\n    req = resp = writer = None\n\n    async def go():\n        nonlocal req, resp, writer\n        req = ClientRequest(\"get\", URL(\"http://python.org\"), loop=loop)\n        resp = await req.send(conn)\n        assert req._writer is not None\n        writer = req._writer = WriterMock()\n\n        await asyncio.sleep(0.05)\n\n    loop.run_until_complete(go())\n\n    loop.close()\n    req.terminate()\n    assert req._writer is None\n    assert not writer.cancel.called\n    resp.close()\n\n\ndef test_terminate_without_writer(loop: Any) -> None:\n    req = ClientRequest(\"get\", URL(\"http://python.org\"), loop=loop)\n    assert req._writer is None\n\n    req.terminate()\n    assert req._writer is None\n\n\nasync def test_custom_req_rep(loop: Any, create_mocked_conn: Any) -> None:\n    conn = None\n\n    class CustomResponse(ClientResponse):\n        async def start(self, connection, read_until_eof=False):\n            nonlocal conn\n            conn = connection\n            self.status = 123\n            self.reason = \"Test OK\"\n            self._headers = CIMultiDictProxy(CIMultiDict())\n            self.cookies = SimpleCookie()\n            return\n\n    called = False\n\n    class CustomRequest(ClientRequest):\n        async def send(self, conn):\n            resp = self.response_class(\n                self.method,\n                self.url,\n                writer=self._writer,\n                continue100=self._continue,\n                timer=self._timer,\n                request_info=self.request_info,\n                traces=self._traces,\n                loop=self.loop,\n                session=self._session,\n            )\n            self.response = resp\n            nonlocal called\n            called = True\n            return resp\n\n    async def create_connection(req, traces, timeout):\n        assert isinstance(req, CustomRequest)\n        return create_mocked_conn()\n\n    connector = BaseConnector()\n    connector._create_connection = create_connection\n\n    session = aiohttp.ClientSession(\n        request_class=CustomRequest, response_class=CustomResponse, connector=connector\n    )\n\n    resp = await session.request(\"get\", URL(\"http://example.com/path/to\"))\n    assert isinstance(resp, CustomResponse)\n    assert called\n    resp.close()\n    await session.close()\n    conn.close()\n\n\ndef test_bad_fingerprint(loop: Any) -> None:\n    with pytest.raises(ValueError):\n        Fingerprint(b\"invalid\")\n\n\ndef test_insecure_fingerprint_md5(loop: Any) -> None:\n    with pytest.raises(ValueError):\n        Fingerprint(hashlib.md5(b\"foo\").digest())\n\n\ndef test_insecure_fingerprint_sha1(loop: Any) -> None:\n    with pytest.raises(ValueError):\n        Fingerprint(hashlib.sha1(b\"foo\").digest())\n\n\ndef test_loose_cookies_types(loop: Any) -> None:\n    req = ClientRequest(\"get\", URL(\"http://python.org\"), loop=loop)\n    morsel = Morsel()\n    morsel.set(key=\"string\", val=\"Another string\", coded_val=\"really\")\n\n    accepted_types = [\n        [(\"str\", BaseCookie())],\n        [(\"str\", morsel)],\n        [\n            (\"str\", \"str\"),\n        ],\n        {\"str\": BaseCookie()},\n        {\"str\": morsel},\n        {\"str\": \"str\"},\n        SimpleCookie(),\n    ]\n\n    for loose_cookies_type in accepted_types:\n        req.update_cookies(cookies=loose_cookies_type)\n\n\n@pytest.mark.parametrize(\n    \"has_brotli,expected\",\n    [\n        (False, \"gzip, deflate\"),\n        (True, \"gzip, deflate, br\"),\n    ],\n)\ndef test_gen_default_accept_encoding(has_brotli: Any, expected: Any) -> None:\n    with mock.patch(\"aiohttp.client_reqrep.HAS_BROTLI\", has_brotli):\n        assert _gen_default_accept_encoding() == expected\n\n\n@pytest.mark.parametrize(\n    (\"netrc_contents\", \"expected_auth\"),\n    [\n        (\n            \"machine example.com login username password pass\\n\",\n            helpers.BasicAuth(\"username\", \"pass\"),\n        )\n    ],\n    indirect=(\"netrc_contents\",),\n)\n@pytest.mark.usefixtures(\"netrc_contents\")\ndef test_basicauth_from_netrc_present(\n    make_request: Any,\n    expected_auth: Optional[helpers.BasicAuth],\n):\n    \"\"\"Test appropriate Authorization header is sent when netrc is not empty.\"\"\"\n    req = make_request(\"get\", \"http://example.com\", trust_env=True)\n    assert req.headers[hdrs.AUTHORIZATION] == expected_auth.encode()\n\n\n@pytest.mark.parametrize(\n    \"netrc_contents\",\n    (\"machine example.com login username password pass\\n\",),\n    indirect=(\"netrc_contents\",),\n)\n@pytest.mark.usefixtures(\"netrc_contents\")\ndef test_basicauth_from_netrc_present_untrusted_env(\n    make_request: Any,\n):\n    \"\"\"Test no authorization header is sent via netrc if trust_env is False\"\"\"\n    req = make_request(\"get\", \"http://example.com\", trust_env=False)\n    assert hdrs.AUTHORIZATION not in req.headers\n\n\n@pytest.mark.parametrize(\n    \"netrc_contents\",\n    (\"\",),\n    indirect=(\"netrc_contents\",),\n)\n@pytest.mark.usefixtures(\"netrc_contents\")\ndef test_basicauth_from_empty_netrc(\n    make_request: Any,\n):\n    \"\"\"Test that no Authorization header is sent when netrc is empty\"\"\"\n    req = make_request(\"get\", \"http://example.com\", trust_env=True)\n    assert hdrs.AUTHORIZATION not in req.headers\n", "tests/test_client_exceptions.py": "# type: ignore\n# Tests for client_exceptions.py\n\nimport errno\nimport pickle\nfrom typing import Any\n\nfrom yarl import URL\n\nfrom aiohttp import client, client_reqrep\n\n\nclass TestClientResponseError:\n    request_info: Any = client.RequestInfo(\n        url=\"http://example.com\",\n        method=\"GET\",\n        headers={},\n        real_url=\"http://example.com\",\n    )\n\n    def test_default_status(self) -> None:\n        err = client.ClientResponseError(history=(), request_info=self.request_info)\n        assert err.status == 0\n\n    def test_status(self) -> None:\n        err = client.ClientResponseError(\n            status=400, history=(), request_info=self.request_info\n        )\n        assert err.status == 400\n\n    def test_pickle(self) -> None:\n        err = client.ClientResponseError(request_info=self.request_info, history=())\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.request_info == self.request_info\n            assert err2.history == ()\n            assert err2.status == 0\n            assert err2.message == \"\"\n            assert err2.headers is None\n\n        err = client.ClientResponseError(\n            request_info=self.request_info,\n            history=(),\n            status=400,\n            message=\"Something wrong\",\n            headers={},\n        )\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.request_info == self.request_info\n            assert err2.history == ()\n            assert err2.status == 400\n            assert err2.message == \"Something wrong\"\n            assert err2.headers == {}\n            assert err2.foo == \"bar\"\n\n    def test_repr(self) -> None:\n        err = client.ClientResponseError(request_info=self.request_info, history=())\n        assert repr(err) == (f\"ClientResponseError({self.request_info!r}, ())\")\n\n        err = client.ClientResponseError(\n            request_info=self.request_info,\n            history=(),\n            status=400,\n            message=\"Something wrong\",\n            headers={},\n        )\n        assert repr(err) == (\n            \"ClientResponseError(%r, (), status=400, \"\n            \"message='Something wrong', headers={})\" % (self.request_info,)\n        )\n\n    def test_str(self) -> None:\n        err = client.ClientResponseError(\n            request_info=self.request_info,\n            history=(),\n            status=400,\n            message=\"Something wrong\",\n            headers={},\n        )\n        assert str(err) == (\n            \"400, message='Something wrong', \" \"url='http://example.com'\"\n        )\n\n\nclass TestClientConnectorError:\n    connection_key: Any = client_reqrep.ConnectionKey(\n        host=\"example.com\",\n        port=8080,\n        is_ssl=False,\n        ssl=True,\n        proxy=None,\n        proxy_auth=None,\n        proxy_headers_hash=None,\n    )\n\n    def test_ctor(self) -> None:\n        err = client.ClientConnectorError(\n            connection_key=self.connection_key,\n            os_error=OSError(errno.ENOENT, \"No such file\"),\n        )\n        assert err.errno == errno.ENOENT\n        assert err.strerror == \"No such file\"\n        assert err.os_error.errno == errno.ENOENT\n        assert err.os_error.strerror == \"No such file\"\n        assert err.host == \"example.com\"\n        assert err.port == 8080\n        assert err.ssl is True\n\n    def test_pickle(self) -> None:\n        err = client.ClientConnectorError(\n            connection_key=self.connection_key,\n            os_error=OSError(errno.ENOENT, \"No such file\"),\n        )\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.errno == errno.ENOENT\n            assert err2.strerror == \"No such file\"\n            assert err2.os_error.errno == errno.ENOENT\n            assert err2.os_error.strerror == \"No such file\"\n            assert err2.host == \"example.com\"\n            assert err2.port == 8080\n            assert err2.ssl is True\n            assert err2.foo == \"bar\"\n\n    def test_repr(self) -> None:\n        os_error = OSError(errno.ENOENT, \"No such file\")\n        err = client.ClientConnectorError(\n            connection_key=self.connection_key, os_error=os_error\n        )\n        assert repr(err) == (\n            f\"ClientConnectorError({self.connection_key!r}, {os_error!r})\"\n        )\n\n    def test_str(self) -> None:\n        err = client.ClientConnectorError(\n            connection_key=self.connection_key,\n            os_error=OSError(errno.ENOENT, \"No such file\"),\n        )\n        assert str(err) == (\n            \"Cannot connect to host example.com:8080 ssl:default [No such file]\"\n        )\n\n\nclass TestClientConnectorCertificateError:\n    connection_key: Any = client_reqrep.ConnectionKey(\n        host=\"example.com\",\n        port=8080,\n        is_ssl=False,\n        ssl=True,\n        proxy=None,\n        proxy_auth=None,\n        proxy_headers_hash=None,\n    )\n\n    def test_ctor(self) -> None:\n        certificate_error = Exception(\"Bad certificate\")\n        err = client.ClientConnectorCertificateError(\n            connection_key=self.connection_key, certificate_error=certificate_error\n        )\n        assert err.certificate_error == certificate_error\n        assert err.host == \"example.com\"\n        assert err.port == 8080\n        assert err.ssl is False\n\n    def test_pickle(self) -> None:\n        certificate_error = Exception(\"Bad certificate\")\n        err = client.ClientConnectorCertificateError(\n            connection_key=self.connection_key, certificate_error=certificate_error\n        )\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.certificate_error.args == (\"Bad certificate\",)\n            assert err2.host == \"example.com\"\n            assert err2.port == 8080\n            assert err2.ssl is False\n            assert err2.foo == \"bar\"\n\n    def test_repr(self) -> None:\n        certificate_error = Exception(\"Bad certificate\")\n        err = client.ClientConnectorCertificateError(\n            connection_key=self.connection_key, certificate_error=certificate_error\n        )\n        assert repr(err) == (\n            \"ClientConnectorCertificateError(%r, %r)\"\n            % (self.connection_key, certificate_error)\n        )\n\n    def test_str(self) -> None:\n        certificate_error = Exception(\"Bad certificate\")\n        err = client.ClientConnectorCertificateError(\n            connection_key=self.connection_key, certificate_error=certificate_error\n        )\n        assert str(err) == (\n            \"Cannot connect to host example.com:8080 ssl:False\"\n            \" [Exception: ('Bad certificate',)]\"\n        )\n\n\nclass TestServerDisconnectedError:\n    def test_ctor(self) -> None:\n        err = client.ServerDisconnectedError()\n        assert err.message == \"Server disconnected\"\n\n        err = client.ServerDisconnectedError(message=\"No connection\")\n        assert err.message == \"No connection\"\n\n    def test_pickle(self) -> None:\n        err = client.ServerDisconnectedError(message=\"No connection\")\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.message == \"No connection\"\n            assert err2.foo == \"bar\"\n\n    def test_repr(self) -> None:\n        err = client.ServerDisconnectedError()\n        assert repr(err) == (\"ServerDisconnectedError\" \"('Server disconnected')\")\n\n        err = client.ServerDisconnectedError(message=\"No connection\")\n        assert repr(err) == \"ServerDisconnectedError('No connection')\"\n\n    def test_str(self) -> None:\n        err = client.ServerDisconnectedError()\n        assert str(err) == \"Server disconnected\"\n\n        err = client.ServerDisconnectedError(message=\"No connection\")\n        assert str(err) == \"No connection\"\n\n\nclass TestServerFingerprintMismatch:\n    def test_ctor(self) -> None:\n        err = client.ServerFingerprintMismatch(\n            expected=b\"exp\", got=b\"got\", host=\"example.com\", port=8080\n        )\n        assert err.expected == b\"exp\"\n        assert err.got == b\"got\"\n        assert err.host == \"example.com\"\n        assert err.port == 8080\n\n    def test_pickle(self) -> None:\n        err = client.ServerFingerprintMismatch(\n            expected=b\"exp\", got=b\"got\", host=\"example.com\", port=8080\n        )\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.expected == b\"exp\"\n            assert err2.got == b\"got\"\n            assert err2.host == \"example.com\"\n            assert err2.port == 8080\n            assert err2.foo == \"bar\"\n\n    def test_repr(self) -> None:\n        err = client.ServerFingerprintMismatch(b\"exp\", b\"got\", \"example.com\", 8080)\n        assert repr(err) == (\n            \"<ServerFingerprintMismatch expected=b'exp' \"\n            \"got=b'got' host='example.com' port=8080>\"\n        )\n\n\nclass TestInvalidURL:\n    def test_ctor(self) -> None:\n        err = client.InvalidURL(url=\":wrong:url:\", description=\":description:\")\n        assert err.url == \":wrong:url:\"\n        assert err.description == \":description:\"\n\n    def test_pickle(self) -> None:\n        err = client.InvalidURL(url=\":wrong:url:\")\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.url == \":wrong:url:\"\n            assert err2.foo == \"bar\"\n\n    def test_repr_no_description(self) -> None:\n        err = client.InvalidURL(url=\":wrong:url:\")\n        assert err.args == (\":wrong:url:\",)\n        assert repr(err) == \"<InvalidURL :wrong:url:>\"\n\n    def test_repr_yarl_URL(self) -> None:\n        err = client.InvalidURL(url=URL(\":wrong:url:\"))\n        assert repr(err) == \"<InvalidURL :wrong:url:>\"\n\n    def test_repr_with_description(self) -> None:\n        err = client.InvalidURL(url=\":wrong:url:\", description=\":description:\")\n        assert repr(err) == \"<InvalidURL :wrong:url: - :description:>\"\n\n    def test_str_no_description(self) -> None:\n        err = client.InvalidURL(url=\":wrong:url:\")\n        assert str(err) == \":wrong:url:\"\n\n    def test_none_description(self) -> None:\n        err = client.InvalidURL(\":wrong:url:\")\n        assert err.description is None\n\n    def test_str_with_description(self) -> None:\n        err = client.InvalidURL(url=\":wrong:url:\", description=\":description:\")\n        assert str(err) == \":wrong:url: - :description:\"\n", "tests/test_multipart_helpers.py": "import pytest\n\nimport aiohttp\nfrom aiohttp import content_disposition_filename, parse_content_disposition\n\n\nclass TestParseContentDisposition:\n    # http://greenbytes.de/tech/tc2231/\n\n    def test_parse_empty(self) -> None:\n        disptype, params = parse_content_disposition(None)\n        assert disptype is None\n        assert {} == params\n\n    def test_inlonly(self) -> None:\n        disptype, params = parse_content_disposition(\"inline\")\n        assert \"inline\" == disptype\n        assert {} == params\n\n    def test_inlonlyquoted(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition('\"inline\"')\n        assert disptype is None\n        assert {} == params\n\n    def test_semicolon(self) -> None:\n        disptype, params = parse_content_disposition(\n            'form-data; name=\"data\"; filename=\"file ; name.mp4\"'\n        )\n        assert disptype == \"form-data\"\n        assert params == {\"name\": \"data\", \"filename\": \"file ; name.mp4\"}\n\n    def test_inlwithasciifilename(self) -> None:\n        disptype, params = parse_content_disposition('inline; filename=\"foo.html\"')\n        assert \"inline\" == disptype\n        assert {\"filename\": \"foo.html\"} == params\n\n    def test_inlwithfnattach(self) -> None:\n        disptype, params = parse_content_disposition(\n            'inline; filename=\"Not an attachment!\"'\n        )\n        assert \"inline\" == disptype\n        assert {\"filename\": \"Not an attachment!\"} == params\n\n    def test_attonly(self) -> None:\n        disptype, params = parse_content_disposition(\"attachment\")\n        assert \"attachment\" == disptype\n        assert {} == params\n\n    def test_attonlyquoted(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition('\"attachment\"')\n        assert disptype is None\n        assert {} == params\n\n    def test_attonlyucase(self) -> None:\n        disptype, params = parse_content_disposition(\"ATTACHMENT\")\n        assert \"attachment\" == disptype\n        assert {} == params\n\n    def test_attwithasciifilename(self) -> None:\n        disptype, params = parse_content_disposition('attachment; filename=\"foo.html\"')\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo.html\"} == params\n\n    def test_inlwithasciifilenamepdf(self) -> None:\n        disptype, params = parse_content_disposition('attachment; filename=\"foo.pdf\"')\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo.pdf\"} == params\n\n    def test_attwithasciifilename25(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"0000000000111111111122222\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"0000000000111111111122222\"} == params\n\n    def test_attwithasciifilename35(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"00000000001111111111222222222233333\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"00000000001111111111222222222233333\"} == params\n\n    def test_attwithasciifnescapedchar(self) -> None:\n        disptype, params = parse_content_disposition(\n            r'attachment; filename=\"f\\oo.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo.html\"} == params\n\n    def test_attwithasciifnescapedquote(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"\"quoting\" tested.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": '\"quoting\" tested.html'} == params\n\n    @pytest.mark.skip(\"need more smart parser which respects quoted text\")\n    def test_attwithquotedsemicolon(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"Here\\'s a semicolon;.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"Here's a semicolon;.html\"} == params\n\n    def test_attwithfilenameandextparam(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; foo=\"bar\"; filename=\"foo.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo.html\", \"foo\": \"bar\"} == params\n\n    def test_attwithfilenameandextparamescaped(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; foo=\"\"\\\\\";filename=\"foo.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo.html\", \"foo\": '\"\\\\'} == params\n\n    def test_attwithasciifilenameucase(self) -> None:\n        disptype, params = parse_content_disposition('attachment; FILENAME=\"foo.html\"')\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo.html\"} == params\n\n    def test_attwithasciifilenamenq(self) -> None:\n        disptype, params = parse_content_disposition(\"attachment; filename=foo.html\")\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo.html\"} == params\n\n    def test_attwithtokfncommanq(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename=foo,bar.html\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attwithasciifilenamenqs(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename=foo.html ;\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attemptyparam(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\"attachment; ;filename=foo\")\n        assert disptype is None\n        assert {} == params\n\n    def test_attwithasciifilenamenqws(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename=foo bar.html\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attwithfntokensq(self) -> None:\n        disptype, params = parse_content_disposition(\"attachment; filename='foo.html'\")\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"'foo.html'\"} == params\n\n    def test_attwithisofnplain(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"foo-\u00e4.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo-\u00e4.html\"} == params\n\n    def test_attwithutf8fnplain(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"foo-\u00c3\u00a4.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo-\u00c3\u00a4.html\"} == params\n\n    def test_attwithfnrawpctenca(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"foo-%41.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo-%41.html\"} == params\n\n    def test_attwithfnusingpct(self) -> None:\n        disptype, params = parse_content_disposition('attachment; filename=\"50%.html\"')\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"50%.html\"} == params\n\n    def test_attwithfnrawpctencaq(self) -> None:\n        disptype, params = parse_content_disposition(\n            r'attachment; filename=\"foo-%\\41.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": r\"foo-%41.html\"} == params\n\n    def test_attwithnamepct(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"foo-%41.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo-%41.html\"} == params\n\n    def test_attwithfilenamepctandiso(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"\u00e4-%41.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"\u00e4-%41.html\"} == params\n\n    def test_attwithfnrawpctenclong(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"foo-%c3%a4-%e2%82%ac.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo-%c3%a4-%e2%82%ac.html\"} == params\n\n    def test_attwithasciifilenamews1(self) -> None:\n        disptype, params = parse_content_disposition('attachment; filename =\"foo.html\"')\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo.html\"} == params\n\n    def test_attwith2filenames(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                'attachment; filename=\"foo.html\"; filename=\"bar.html\"'\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attfnbrokentoken(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename=foo[1](2).html\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attfnbrokentokeniso(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename=foo-\u00e4.html\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attfnbrokentokenutf(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename=foo-\u00c3\u00a4.html\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attmissingdisposition(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\"filename=foo.html\")\n        assert disptype is None\n        assert {} == params\n\n    def test_attmissingdisposition2(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\"x=y; filename=foo.html\")\n        assert disptype is None\n        assert {} == params\n\n    def test_attmissingdisposition3(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                '\"foo; filename=bar;baz\"; filename=qux'\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attmissingdisposition4(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"filename=foo.html, filename=bar.html\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_emptydisposition(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\"; filename=foo.html\")\n        assert disptype is None\n        assert {} == params\n\n    def test_doublecolon(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \": inline; attachment; filename=foo.html\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attandinline(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"inline; attachment; filename=foo.html\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attandinline2(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; inline; filename=foo.html\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attbrokenquotedfn(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                'attachment; filename=\"foo.html\".txt'\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attbrokenquotedfn2(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition('attachment; filename=\"bar')\n        assert disptype is None\n        assert {} == params\n\n    def test_attbrokenquotedfn3(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                'attachment; filename=foo\"bar;baz\"qux'\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attmultinstances(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename=foo.html, attachment; filename=bar.html\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attmissingdelim(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; foo=foo filename=bar\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attmissingdelim2(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename=bar foo=foo\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attmissingdelim3(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\"attachment filename=bar\")\n        assert disptype is None\n        assert {} == params\n\n    def test_attreversed(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"filename=foo.html; attachment\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attconfusedparam(self) -> None:\n        disptype, params = parse_content_disposition(\"attachment; xfilename=foo.html\")\n        assert \"attachment\" == disptype\n        assert {\"xfilename\": \"foo.html\"} == params\n\n    def test_attabspath(self) -> None:\n        disptype, params = parse_content_disposition('attachment; filename=\"/foo.html\"')\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo.html\"} == params\n\n    def test_attabspathwin(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"\\\\foo.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo.html\"} == params\n\n    def test_attcdate(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; creation-date=\"Wed, 12 Feb 1997 16:29:51 -0500\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"creation-date\": \"Wed, 12 Feb 1997 16:29:51 -0500\"} == params\n\n    def test_attmdate(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; modification-date=\"Wed, 12 Feb 1997 16:29:51 -0500\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"modification-date\": \"Wed, 12 Feb 1997 16:29:51 -0500\"} == params\n\n    def test_dispext(self) -> None:\n        disptype, params = parse_content_disposition(\"foobar\")\n        assert \"foobar\" == disptype\n        assert {} == params\n\n    def test_dispextbadfn(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; example=\"filename=example.txt\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"example\": \"filename=example.txt\"} == params\n\n    def test_attwithisofn2231iso(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename*=iso-8859-1''foo-%E4.html\"\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*\": \"foo-\u00e4.html\"} == params\n\n    def test_attwithfn2231utf8(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename*=UTF-8''foo-%c3%a4-%e2%82%ac.html\"\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*\": \"foo-\u00e4-\u20ac.html\"} == params\n\n    def test_attwithfn2231noc(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename*=''foo-%c3%a4-%e2%82%ac.html\"\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*\": \"foo-\u00e4-\u20ac.html\"} == params\n\n    def test_attwithfn2231utf8comp(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename*=UTF-8''foo-a%cc%88.html\"\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*\": \"foo-a\u0308.html\"} == params\n\n    @pytest.mark.skip(\"should raise decoding error: %82 is invalid for latin1\")\n    def test_attwithfn2231utf8_bad(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionParam):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename*=iso-8859-1''foo-%c3%a4-%e2%82%ac.html\"\n            )\n        assert \"attachment\" == disptype\n        assert {} == params\n\n    @pytest.mark.skip(\"should raise decoding error: %E4 is invalid for utf-8\")\n    def test_attwithfn2231iso_bad(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionParam):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename*=utf-8''foo-%E4.html\"\n            )\n        assert \"attachment\" == disptype\n        assert {} == params\n\n    def test_attwithfn2231ws1(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionParam):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename *=UTF-8''foo-%c3%a4.html\"\n            )\n        assert \"attachment\" == disptype\n        assert {} == params\n\n    def test_attwithfn2231ws2(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename*= UTF-8''foo-%c3%a4.html\"\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*\": \"foo-\u00e4.html\"} == params\n\n    def test_attwithfn2231ws3(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename* =UTF-8''foo-%c3%a4.html\"\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*\": \"foo-\u00e4.html\"} == params\n\n    def test_attwithfn2231quot(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionParam):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename*=\\\"UTF-8''foo-%c3%a4.html\\\"\"\n            )\n        assert \"attachment\" == disptype\n        assert {} == params\n\n    def test_attwithfn2231quot2(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionParam):\n            disptype, params = parse_content_disposition(\n                'attachment; filename*=\"foo%20bar.html\"'\n            )\n        assert \"attachment\" == disptype\n        assert {} == params\n\n    def test_attwithfn2231singleqmissing(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionParam):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename*=UTF-8'foo-%c3%a4.html\"\n            )\n        assert \"attachment\" == disptype\n        assert {} == params\n\n    @pytest.mark.skip(\"urllib.parse.unquote is tolerate to standalone % chars\")\n    def test_attwithfn2231nbadpct1(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionParam):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename*=UTF-8''foo%\"\n            )\n        assert \"attachment\" == disptype\n        assert {} == params\n\n    @pytest.mark.skip(\"urllib.parse.unquote is tolerate to standalone % chars\")\n    def test_attwithfn2231nbadpct2(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionParam):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename*=UTF-8''f%oo.html\"\n            )\n        assert \"attachment\" == disptype\n        assert {} == params\n\n    def test_attwithfn2231dpct(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename*=UTF-8''A-%2541.html\"\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*\": \"A-%41.html\"} == params\n\n    def test_attwithfn2231abspathdisguised(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename*=UTF-8''%5cfoo.html\"\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*\": \"\\\\foo.html\"} == params\n\n    def test_attfncont(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename*0=\"foo.\"; filename*1=\"html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*0\": \"foo.\", \"filename*1\": \"html\"} == params\n\n    def test_attfncontqs(self) -> None:\n        disptype, params = parse_content_disposition(\n            r'attachment; filename*0=\"foo\"; filename*1=\"\\b\\a\\r.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*0\": \"foo\", \"filename*1\": \"bar.html\"} == params\n\n    def test_attfncontenc(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename*0*=UTF-8\" 'foo-%c3%a4; filename*1=\".html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*0*\": \"UTF-8\" \"foo-%c3%a4\", \"filename*1\": \".html\"} == params\n\n    def test_attfncontlz(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename*0=\"foo\"; filename*01=\"bar\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*0\": \"foo\", \"filename*01\": \"bar\"} == params\n\n    def test_attfncontnc(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename*0=\"foo\"; filename*2=\"bar\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*0\": \"foo\", \"filename*2\": \"bar\"} == params\n\n    def test_attfnconts1(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename*0=\"foo.\"; filename*2=\"html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*0\": \"foo.\", \"filename*2\": \"html\"} == params\n\n    def test_attfncontord(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename*1=\"bar\"; filename*0=\"foo\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename*0\": \"foo\", \"filename*1\": \"bar\"} == params\n\n    def test_attfnboth(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"foo-ae.html\";' \" filename*=UTF-8''foo-%c3%a4.html\"\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo-ae.html\", \"filename*\": \"foo-\u00e4.html\"} == params\n\n    def test_attfnboth2(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename*=UTF-8''foo-%c3%a4.html;\" ' filename=\"foo-ae.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"foo-ae.html\", \"filename*\": \"foo-\u00e4.html\"} == params\n\n    def test_attfnboth3(self) -> None:\n        disptype, params = parse_content_disposition(\n            \"attachment; filename*0*=ISO-8859-15''euro-sign%3d%a4;\"\n            \" filename*=ISO-8859-1''currency-sign%3d%a4\"\n        )\n        assert \"attachment\" == disptype\n        assert {\n            \"filename*\": \"currency-sign=\u00a4\",\n            \"filename*0*\": \"ISO-8859-15''euro-sign%3d%a4\",\n        } == params\n\n    def test_attnewandfn(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; foobar=x; filename=\"foo.html\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"foobar\": \"x\", \"filename\": \"foo.html\"} == params\n\n    def test_attrfc2047token(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionHeader):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename==?ISO-8859-1?Q?foo-=E4.html?=\"\n            )\n        assert disptype is None\n        assert {} == params\n\n    def test_attrfc2047quoted(self) -> None:\n        disptype, params = parse_content_disposition(\n            'attachment; filename=\"=?ISO-8859-1?Q?foo-=E4.html?=\"'\n        )\n        assert \"attachment\" == disptype\n        assert {\"filename\": \"=?ISO-8859-1?Q?foo-=E4.html?=\"} == params\n\n    def test_bad_continuous_param(self) -> None:\n        with pytest.warns(aiohttp.BadContentDispositionParam):\n            disptype, params = parse_content_disposition(\n                \"attachment; filename*0=foo bar\"\n            )\n        assert \"attachment\" == disptype\n        assert {} == params\n\n\nclass TestContentDispositionFilename:\n    # http://greenbytes.de/tech/tc2231/\n\n    def test_no_filename(self) -> None:\n        assert content_disposition_filename({}) is None\n        assert content_disposition_filename({\"foo\": \"bar\"}) is None\n\n    def test_filename(self) -> None:\n        params = {\"filename\": \"foo.html\"}\n        assert \"foo.html\" == content_disposition_filename(params)\n\n    def test_filename_ext(self) -> None:\n        params = {\"filename*\": \"\u0444\u0430\u0439\u043b.html\"}\n        assert \"\u0444\u0430\u0439\u043b.html\" == content_disposition_filename(params)\n\n    def test_attfncont(self) -> None:\n        params = {\"filename*0\": \"foo.\", \"filename*1\": \"html\"}\n        assert \"foo.html\" == content_disposition_filename(params)\n\n    def test_attfncontqs(self) -> None:\n        params = {\"filename*0\": \"foo\", \"filename*1\": \"bar.html\"}\n        assert \"foobar.html\" == content_disposition_filename(params)\n\n    def test_attfncontenc(self) -> None:\n        params = {\"filename*0*\": \"UTF-8''foo-%c3%a4\", \"filename*1\": \".html\"}\n        assert \"foo-\u00e4.html\" == content_disposition_filename(params)\n\n    def test_attfncontlz(self) -> None:\n        params = {\"filename*0\": \"foo\", \"filename*01\": \"bar\"}\n        assert \"foo\" == content_disposition_filename(params)\n\n    def test_attfncontnc(self) -> None:\n        params = {\"filename*0\": \"foo\", \"filename*2\": \"bar\"}\n        assert \"foo\" == content_disposition_filename(params)\n\n    def test_attfnconts1(self) -> None:\n        params = {\"filename*1\": \"foo\", \"filename*2\": \"bar\"}\n        assert content_disposition_filename(params) is None\n\n    def test_attfnboth(self) -> None:\n        params = {\"filename\": \"foo-ae.html\", \"filename*\": \"foo-\u00e4.html\"}\n        assert \"foo-\u00e4.html\" == content_disposition_filename(params)\n\n    def test_attfnboth3(self) -> None:\n        params = {\n            \"filename*0*\": \"ISO-8859-15''euro-sign%3d%a4\",\n            \"filename*\": \"currency-sign=\u00a4\",\n        }\n        assert \"currency-sign=\u00a4\" == content_disposition_filename(params)\n\n    def test_attrfc2047quoted(self) -> None:\n        params = {\"filename\": \"=?ISO-8859-1?Q?foo-=E4.html?=\"}\n        assert \"=?ISO-8859-1?Q?foo-=E4.html?=\" == content_disposition_filename(params)\n", "tests/conftest.py": "# type: ignore\nimport asyncio\nimport os\nimport socket\nimport ssl\nimport sys\nfrom hashlib import md5, sha256\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom typing import Any, List\nfrom unittest import mock\nfrom uuid import uuid4\n\nimport pytest\n\nfrom aiohttp.test_utils import loop_context\n\ntry:\n    import trustme\n\n    # Check if the CA is available in runtime, MacOS on Py3.10 fails somehow\n    trustme.CA()\n\n    TRUSTME: bool = True\nexcept ImportError:\n    TRUSTME = False\n\npytest_plugins: List[str] = [\"aiohttp.pytest_plugin\", \"pytester\"]\n\nIS_HPUX = sys.platform.startswith(\"hp-ux\")\nIS_LINUX = sys.platform.startswith(\"linux\")\n\n\n@pytest.fixture\ndef tls_certificate_authority() -> Any:\n    if not TRUSTME:\n        pytest.xfail(\"trustme is not supported\")\n    return trustme.CA()\n\n\n@pytest.fixture\ndef tls_certificate(tls_certificate_authority: Any) -> Any:\n    return tls_certificate_authority.issue_cert(\n        \"localhost\",\n        \"xn--prklad-4va.localhost\",\n        \"127.0.0.1\",\n        \"::1\",\n    )\n\n\n@pytest.fixture\ndef ssl_ctx(tls_certificate: Any) -> ssl.SSLContext:\n    ssl_ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n    tls_certificate.configure_cert(ssl_ctx)\n    return ssl_ctx\n\n\n@pytest.fixture\ndef client_ssl_ctx(tls_certificate_authority: Any) -> ssl.SSLContext:\n    ssl_ctx = ssl.create_default_context(purpose=ssl.Purpose.SERVER_AUTH)\n    tls_certificate_authority.configure_trust(ssl_ctx)\n    return ssl_ctx\n\n\n@pytest.fixture\ndef tls_ca_certificate_pem_path(tls_certificate_authority: Any) -> None:\n    with tls_certificate_authority.cert_pem.tempfile() as ca_cert_pem:\n        yield ca_cert_pem\n\n\n@pytest.fixture\ndef tls_certificate_pem_path(tls_certificate: Any) -> None:\n    with tls_certificate.private_key_and_cert_chain_pem.tempfile() as cert_pem:\n        yield cert_pem\n\n\n@pytest.fixture\ndef tls_certificate_pem_bytes(tls_certificate: Any) -> bytes:\n    return tls_certificate.cert_chain_pems[0].bytes()\n\n\n@pytest.fixture\ndef tls_certificate_fingerprint_sha256(tls_certificate_pem_bytes: Any) -> str:\n    tls_cert_der = ssl.PEM_cert_to_DER_cert(tls_certificate_pem_bytes.decode())\n    return sha256(tls_cert_der).digest()\n\n\n@pytest.fixture\ndef pipe_name() -> str:\n    name = rf\"\\\\.\\pipe\\{uuid4().hex}\"\n    return name\n\n\n@pytest.fixture\ndef create_mocked_conn(loop: Any):\n    def _proto_factory(conn_closing_result=None, **kwargs):\n        proto = mock.Mock(**kwargs)\n        proto.closed = loop.create_future()\n        proto.closed.set_result(conn_closing_result)\n        return proto\n\n    yield _proto_factory\n\n\n@pytest.fixture\ndef unix_sockname(tmp_path: Any, tmp_path_factory: Any):\n    # Generate an fs path to the UNIX domain socket for testing.\n\n    # N.B. Different OS kernels have different fs path length limitations\n    # for it. For Linux, it's 108, for HP-UX it's 92 (or higher) depending\n    # on its version. For most of the BSDs (Open, Free, macOS) it's\n    # mostly 104 but sometimes it can be down to 100.\n\n    # Ref: https://github.com/aio-libs/aiohttp/issues/3572\n    if not hasattr(socket, \"AF_UNIX\"):\n        pytest.skip(\"requires UNIX sockets\")\n\n    max_sock_len = 92 if IS_HPUX else 108 if IS_LINUX else 100\n    # Amount of bytes allocated for the UNIX socket path by OS kernel.\n    # Ref: https://unix.stackexchange.com/a/367012/27133\n\n    sock_file_name = \"unix.sock\"\n    unique_prefix = f\"{uuid4()!s}-\"\n    unique_prefix_len = len(unique_prefix.encode())\n\n    root_tmp_dir = Path(\"/tmp\").resolve()\n    os_tmp_dir = Path(os.getenv(\"TMPDIR\", \"/tmp\")).resolve()\n    original_base_tmp_path = Path(\n        str(tmp_path_factory.getbasetemp()),\n    ).resolve()\n\n    original_base_tmp_path_hash = md5(\n        str(original_base_tmp_path).encode(),\n    ).hexdigest()\n\n    def make_tmp_dir(base_tmp_dir):\n        return TemporaryDirectory(\n            dir=str(base_tmp_dir),\n            prefix=\"pt-\",\n            suffix=f\"-{original_base_tmp_path_hash!s}\",\n        )\n\n    def assert_sock_fits(sock_path):\n        sock_path_len = len(sock_path.encode())\n        # exit-check to verify that it's correct and simplify debugging\n        # in the future\n        assert sock_path_len <= max_sock_len, (\n            \"Suggested UNIX socket ({sock_path}) is {sock_path_len} bytes \"\n            \"long but the current kernel only has {max_sock_len} bytes \"\n            \"allocated to hold it so it must be shorter. \"\n            \"See https://github.com/aio-libs/aiohttp/issues/3572 \"\n            \"for more info.\"\n        ).format_map(locals())\n\n    paths = original_base_tmp_path, os_tmp_dir, root_tmp_dir\n    unique_paths = [p for n, p in enumerate(paths) if p not in paths[:n]]\n    paths_num = len(unique_paths)\n\n    for num, tmp_dir_path in enumerate(paths, 1):\n        with make_tmp_dir(tmp_dir_path) as tmpd:\n            tmpd = Path(tmpd).resolve()\n            sock_path = str(tmpd / sock_file_name)\n            sock_path_len = len(sock_path.encode())\n\n            if num >= paths_num:\n                # exit-check to verify that it's correct and simplify\n                # debugging in the future\n                assert_sock_fits(sock_path)\n\n            if sock_path_len <= max_sock_len:\n                if max_sock_len - sock_path_len >= unique_prefix_len:\n                    # If we're lucky to have extra space in the path,\n                    # let's also make it more unique\n                    sock_path = str(tmpd / \"\".join((unique_prefix, sock_file_name)))\n                    # Double-checking it:\n                    assert_sock_fits(sock_path)\n                yield sock_path\n                return\n\n\n@pytest.fixture\ndef selector_loop() -> None:\n    policy = asyncio.WindowsSelectorEventLoopPolicy()\n    asyncio.set_event_loop_policy(policy)\n\n    with loop_context(policy.new_event_loop) as _loop:\n        asyncio.set_event_loop(_loop)\n        yield _loop\n\n\n@pytest.fixture\ndef netrc_contents(\n    tmp_path: Path,\n    monkeypatch: pytest.MonkeyPatch,\n    request: pytest.FixtureRequest,\n):\n    \"\"\"\n    Prepare :file:`.netrc` with given contents.\n\n    Monkey-patches :envvar:`NETRC` to point to created file.\n    \"\"\"\n    netrc_contents = getattr(request, \"param\", None)\n\n    netrc_file_path = tmp_path / \".netrc\"\n    if netrc_contents is not None:\n        netrc_file_path.write_text(netrc_contents)\n\n    monkeypatch.setenv(\"NETRC\", str(netrc_file_path))\n\n    return netrc_file_path\n\n\n@pytest.fixture\ndef start_connection():\n    with mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    ) as start_connection_mock:\n        yield start_connection_mock\n", "tests/test_resolver.py": "import asyncio\nimport ipaddress\nimport socket\nfrom ipaddress import ip_address\nfrom typing import Any, Awaitable, Callable, Collection, List, NamedTuple, Tuple, Union\nfrom unittest.mock import Mock, patch\n\nimport pytest\n\nfrom aiohttp.resolver import (\n    _NUMERIC_SOCKET_FLAGS,\n    _SUPPORTS_SCOPE_ID,\n    AsyncResolver,\n    DefaultResolver,\n    ThreadedResolver,\n)\n\ntry:\n    import aiodns\n\n    getaddrinfo: Any = hasattr(aiodns.DNSResolver, \"getaddrinfo\")\nexcept ImportError:\n    aiodns = None  # type: ignore[assignment]\n    getaddrinfo = False\n\n\nclass FakeAIODNSAddrInfoNode(NamedTuple):\n\n    family: int\n    addr: Union[Tuple[bytes, int], Tuple[bytes, int, int, int]]\n\n\nclass FakeAIODNSAddrInfoIPv4Result:\n    def __init__(self, hosts: Collection[str]) -> None:\n        self.nodes = [\n            FakeAIODNSAddrInfoNode(socket.AF_INET, (h.encode(), 0)) for h in hosts\n        ]\n\n\nclass FakeAIODNSAddrInfoIPv6Result:\n    def __init__(self, hosts: Collection[str]) -> None:\n        self.nodes = [\n            FakeAIODNSAddrInfoNode(\n                socket.AF_INET6,\n                (h.encode(), 0, 0, 3 if ip_address(h).is_link_local else 0),\n            )\n            for h in hosts\n        ]\n\n\nclass FakeAIODNSNameInfoIPv6Result:\n    def __init__(self, host: str) -> None:\n        self.node = host\n        self.service = None\n\n\nclass FakeQueryResult:\n    host: Any\n\n    def __init__(self, host: Any) -> None:\n        self.host = host\n\n\nasync def fake_aiodns_getaddrinfo_ipv4_result(\n    hosts: Collection[str],\n) -> FakeAIODNSAddrInfoIPv4Result:\n    return FakeAIODNSAddrInfoIPv4Result(hosts=hosts)\n\n\nasync def fake_aiodns_getaddrinfo_ipv6_result(\n    hosts: Collection[str],\n) -> FakeAIODNSAddrInfoIPv6Result:\n    return FakeAIODNSAddrInfoIPv6Result(hosts=hosts)\n\n\nasync def fake_aiodns_getnameinfo_ipv6_result(\n    host: str,\n) -> FakeAIODNSNameInfoIPv6Result:\n    return FakeAIODNSNameInfoIPv6Result(host)\n\n\nasync def fake_query_result(result: Any) -> List[FakeQueryResult]:\n    return [FakeQueryResult(host=h) for h in result]\n\n\ndef fake_addrinfo(hosts: Collection[str]) -> Callable[..., Awaitable[Any]]:\n    async def fake(*args: Any, **kwargs: Any) -> List[Any]:\n        if not hosts:\n            raise socket.gaierror\n\n        return [(socket.AF_INET, None, socket.SOCK_STREAM, None, [h, 0]) for h in hosts]\n\n    return fake\n\n\ndef fake_ipv6_addrinfo(hosts: Collection[str]) -> Callable[..., Awaitable[Any]]:\n    async def fake(*args: Any, **kwargs: Any) -> List[Any]:\n        if not hosts:\n            raise socket.gaierror\n\n        return [\n            (\n                socket.AF_INET6,\n                None,\n                socket.SOCK_STREAM,\n                None,\n                (h, 0, 0, 3 if ip_address(h).is_link_local else 0),\n            )\n            for h in hosts\n        ]\n\n    return fake\n\n\ndef fake_ipv6_nameinfo(host: str) -> Callable[..., Awaitable[Any]]:\n    async def fake(*args: Any, **kwargs: Any) -> Tuple[str, int]:\n        return host, 0\n\n    return fake\n\n\n@pytest.mark.skipif(not getaddrinfo, reason=\"aiodns >=3.2.0 required\")\nasync def test_async_resolver_positive_ipv4_lookup(loop: Any) -> None:\n    with patch(\"aiodns.DNSResolver\") as mock:\n        mock().getaddrinfo.return_value = fake_aiodns_getaddrinfo_ipv4_result(\n            [\"127.0.0.1\"]\n        )\n        resolver = AsyncResolver()\n        real = await resolver.resolve(\"www.python.org\")\n        ipaddress.ip_address(real[0][\"host\"])\n        mock().getaddrinfo.assert_called_with(\n            \"www.python.org\",\n            family=socket.AF_INET,\n            flags=socket.AI_ADDRCONFIG,\n            port=0,\n            type=socket.SOCK_STREAM,\n        )\n\n\n@pytest.mark.skipif(not getaddrinfo, reason=\"aiodns >=3.2.0 required\")\n@pytest.mark.skipif(\n    not _SUPPORTS_SCOPE_ID, reason=\"python version does not support scope id\"\n)\nasync def test_async_resolver_positive_link_local_ipv6_lookup(loop: Any) -> None:\n    with patch(\"aiodns.DNSResolver\") as mock:\n        mock().getaddrinfo.return_value = fake_aiodns_getaddrinfo_ipv6_result(\n            [\"fe80::1\"]\n        )\n        mock().getnameinfo.return_value = fake_aiodns_getnameinfo_ipv6_result(\n            \"fe80::1%eth0\"\n        )\n        resolver = AsyncResolver()\n        real = await resolver.resolve(\"www.python.org\")\n        ipaddress.ip_address(real[0][\"host\"])\n        mock().getaddrinfo.assert_called_with(\n            \"www.python.org\",\n            family=socket.AF_INET,\n            flags=socket.AI_ADDRCONFIG,\n            port=0,\n            type=socket.SOCK_STREAM,\n        )\n        mock().getnameinfo.assert_called_with(\n            (\"fe80::1\", 0, 0, 3), _NUMERIC_SOCKET_FLAGS\n        )\n\n\n@pytest.mark.skipif(not getaddrinfo, reason=\"aiodns >=3.2.0 required\")\nasync def test_async_resolver_multiple_replies(loop: Any) -> None:\n    with patch(\"aiodns.DNSResolver\") as mock:\n        ips = [\"127.0.0.1\", \"127.0.0.2\", \"127.0.0.3\", \"127.0.0.4\"]\n        mock().getaddrinfo.return_value = fake_aiodns_getaddrinfo_ipv4_result(ips)\n        resolver = AsyncResolver()\n        real = await resolver.resolve(\"www.google.com\")\n        ipaddrs = [ipaddress.ip_address(x[\"host\"]) for x in real]\n        assert len(ipaddrs) > 3, \"Expecting multiple addresses\"\n\n\n@pytest.mark.skipif(not getaddrinfo, reason=\"aiodns >=3.2.0 required\")\nasync def test_async_resolver_negative_lookup(loop: Any) -> None:\n    with patch(\"aiodns.DNSResolver\") as mock:\n        mock().getaddrinfo.side_effect = aiodns.error.DNSError()\n        resolver = AsyncResolver()\n        with pytest.raises(OSError):\n            await resolver.resolve(\"doesnotexist.bla\")\n\n\n@pytest.mark.skipif(not getaddrinfo, reason=\"aiodns >=3.2.0 required\")\nasync def test_async_resolver_no_hosts_in_getaddrinfo(loop: Any) -> None:\n    with patch(\"aiodns.DNSResolver\") as mock:\n        mock().getaddrinfo.return_value = fake_aiodns_getaddrinfo_ipv4_result([])\n        resolver = AsyncResolver()\n        with pytest.raises(OSError):\n            await resolver.resolve(\"doesnotexist.bla\")\n\n\nasync def test_threaded_resolver_positive_lookup() -> None:\n    loop = Mock()\n    loop.getaddrinfo = fake_addrinfo([\"127.0.0.1\"])\n    resolver = ThreadedResolver()\n    resolver._loop = loop\n    real = await resolver.resolve(\"www.python.org\")\n    assert real[0][\"hostname\"] == \"www.python.org\"\n    ipaddress.ip_address(real[0][\"host\"])\n\n\n@pytest.mark.skipif(\n    not _SUPPORTS_SCOPE_ID, reason=\"python version does not support scope id\"\n)\nasync def test_threaded_resolver_positive_ipv6_link_local_lookup() -> None:\n    loop = Mock()\n    loop.getaddrinfo = fake_ipv6_addrinfo([\"fe80::1\"])\n    loop.getnameinfo = fake_ipv6_nameinfo(\"fe80::1%eth0\")\n    resolver = ThreadedResolver()\n    resolver._loop = loop\n    real = await resolver.resolve(\"www.python.org\")\n    assert real[0][\"hostname\"] == \"www.python.org\"\n    ipaddress.ip_address(real[0][\"host\"])\n\n\nasync def test_threaded_resolver_multiple_replies() -> None:\n    loop = Mock()\n    ips = [\"127.0.0.1\", \"127.0.0.2\", \"127.0.0.3\", \"127.0.0.4\"]\n    loop.getaddrinfo = fake_addrinfo(ips)\n    resolver = ThreadedResolver()\n    resolver._loop = loop\n    real = await resolver.resolve(\"www.google.com\")\n    ipaddrs = [ipaddress.ip_address(x[\"host\"]) for x in real]\n    assert len(ipaddrs) > 3, \"Expecting multiple addresses\"\n\n\nasync def test_threaded_negative_lookup() -> None:\n    loop = Mock()\n    ips: List[Any] = []\n    loop.getaddrinfo = fake_addrinfo(ips)\n    resolver = ThreadedResolver()\n    resolver._loop = loop\n    with pytest.raises(socket.gaierror):\n        await resolver.resolve(\"doesnotexist.bla\")\n\n\nasync def test_threaded_negative_ipv6_lookup() -> None:\n    loop = Mock()\n    ips: List[Any] = []\n    loop.getaddrinfo = fake_ipv6_addrinfo(ips)\n    resolver = ThreadedResolver()\n    resolver._loop = loop\n    with pytest.raises(socket.gaierror):\n        await resolver.resolve(\"doesnotexist.bla\")\n\n\nasync def test_threaded_negative_lookup_with_unknown_result() -> None:\n    loop = Mock()\n\n    # If compile CPython with `--disable-ipv6` option,\n    # we will get an (int, bytes) tuple, instead of a Exception.\n    async def unknown_addrinfo(*args: Any, **kwargs: Any) -> List[Any]:\n        return [\n            (\n                socket.AF_INET6,\n                socket.SOCK_STREAM,\n                6,\n                \"\",\n                (10, b\"\\x01\\xbb\\x00\\x00\\x00\\x00*\\x04NB\\x00\\x1a\\x00\\x00\"),\n            )\n        ]\n\n    loop.getaddrinfo = unknown_addrinfo\n    resolver = ThreadedResolver()\n    resolver._loop = loop\n    with patch(\"socket.has_ipv6\", False):\n        res = await resolver.resolve(\"www.python.org\")\n    assert len(res) == 0\n\n\nasync def test_close_for_threaded_resolver(loop: Any) -> None:\n    resolver = ThreadedResolver()\n    await resolver.close()\n\n\n@pytest.mark.skipif(aiodns is None, reason=\"aiodns required\")\nasync def test_close_for_async_resolver(loop: Any) -> None:\n    resolver = AsyncResolver()\n    await resolver.close()\n\n\nasync def test_default_loop_for_threaded_resolver(loop: Any) -> None:\n    asyncio.set_event_loop(loop)\n    resolver = ThreadedResolver()\n    assert resolver._loop is loop\n\n\n@pytest.mark.skipif(not getaddrinfo, reason=\"aiodns >=3.2.0 required\")\nasync def test_async_resolver_ipv6_positive_lookup(loop: Any) -> None:\n    with patch(\"aiodns.DNSResolver\") as mock:\n        mock().getaddrinfo.return_value = fake_aiodns_getaddrinfo_ipv6_result([\"::1\"])\n        resolver = AsyncResolver()\n        real = await resolver.resolve(\"www.python.org\")\n        ipaddress.ip_address(real[0][\"host\"])\n        mock().getaddrinfo.assert_called_with(\n            \"www.python.org\",\n            family=socket.AF_INET,\n            flags=socket.AI_ADDRCONFIG,\n            port=0,\n            type=socket.SOCK_STREAM,\n        )\n\n\nasync def test_async_resolver_aiodns_not_present(loop: Any, monkeypatch: Any) -> None:\n    monkeypatch.setattr(\"aiohttp.resolver.aiodns\", None)\n    with pytest.raises(RuntimeError):\n        AsyncResolver()\n\n\ndef test_default_resolver() -> None:\n    # if getaddrinfo:\n    #     assert DefaultResolver is AsyncResolver\n    # else:\n    #     assert DefaultResolver is ThreadedResolver\n    assert DefaultResolver is ThreadedResolver\n", "tests/test_websocket_writer.py": "# type: ignore\nimport asyncio\nimport random\nfrom typing import Any, Callable\nfrom unittest import mock\n\nimport pytest\n\nfrom aiohttp import DataQueue, WSMessage\nfrom aiohttp.http import WebSocketReader, WebSocketWriter\nfrom aiohttp.test_utils import make_mocked_coro\n\n\n@pytest.fixture\ndef protocol():\n    ret = mock.Mock()\n    ret._drain_helper = make_mocked_coro()\n    return ret\n\n\n@pytest.fixture\ndef transport():\n    ret = mock.Mock()\n    ret.is_closing.return_value = False\n    return ret\n\n\n@pytest.fixture\ndef writer(protocol: Any, transport: Any):\n    return WebSocketWriter(protocol, transport, use_mask=False)\n\n\nasync def test_pong(writer: Any) -> None:\n    await writer.pong()\n    writer.transport.write.assert_called_with(b\"\\x8a\\x00\")\n\n\nasync def test_ping(writer: Any) -> None:\n    await writer.ping()\n    writer.transport.write.assert_called_with(b\"\\x89\\x00\")\n\n\nasync def test_send_text(writer: Any) -> None:\n    await writer.send(b\"text\")\n    writer.transport.write.assert_called_with(b\"\\x81\\x04text\")\n\n\nasync def test_send_binary(writer: Any) -> None:\n    await writer.send(\"binary\", True)\n    writer.transport.write.assert_called_with(b\"\\x82\\x06binary\")\n\n\nasync def test_send_binary_long(writer: Any) -> None:\n    await writer.send(b\"b\" * 127, True)\n    assert writer.transport.write.call_args[0][0].startswith(b\"\\x82~\\x00\\x7fb\")\n\n\nasync def test_send_binary_very_long(writer: Any) -> None:\n    await writer.send(b\"b\" * 65537, True)\n    assert (\n        writer.transport.write.call_args_list[0][0][0]\n        == b\"\\x82\\x7f\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x01\"\n    )\n    assert writer.transport.write.call_args_list[1][0][0] == b\"b\" * 65537\n\n\nasync def test_close(writer: Any) -> None:\n    await writer.close(1001, \"msg\")\n    writer.transport.write.assert_called_with(b\"\\x88\\x05\\x03\\xe9msg\")\n\n    await writer.close(1001, b\"msg\")\n    writer.transport.write.assert_called_with(b\"\\x88\\x05\\x03\\xe9msg\")\n\n    # Test that Service Restart close code is also supported\n    await writer.close(1012, b\"msg\")\n    writer.transport.write.assert_called_with(b\"\\x88\\x05\\x03\\xf4msg\")\n\n\nasync def test_send_text_masked(protocol: Any, transport: Any) -> None:\n    writer = WebSocketWriter(\n        protocol, transport, use_mask=True, random=random.Random(123)\n    )\n    await writer.send(b\"text\")\n    writer.transport.write.assert_called_with(b\"\\x81\\x84\\rg\\xb3fy\\x02\\xcb\\x12\")\n\n\nasync def test_send_compress_text(protocol: Any, transport: Any) -> None:\n    writer = WebSocketWriter(protocol, transport, compress=15)\n    await writer.send(b\"text\")\n    writer.transport.write.assert_called_with(b\"\\xc1\\x06*I\\xad(\\x01\\x00\")\n    await writer.send(b\"text\")\n    writer.transport.write.assert_called_with(b\"\\xc1\\x05*\\x01b\\x00\\x00\")\n\n\nasync def test_send_compress_text_notakeover(protocol: Any, transport: Any) -> None:\n    writer = WebSocketWriter(protocol, transport, compress=15, notakeover=True)\n    await writer.send(b\"text\")\n    writer.transport.write.assert_called_with(b\"\\xc1\\x06*I\\xad(\\x01\\x00\")\n    await writer.send(b\"text\")\n    writer.transport.write.assert_called_with(b\"\\xc1\\x06*I\\xad(\\x01\\x00\")\n\n\nasync def test_send_compress_text_per_message(protocol: Any, transport: Any) -> None:\n    writer = WebSocketWriter(protocol, transport)\n    await writer.send(b\"text\", compress=15)\n    writer.transport.write.assert_called_with(b\"\\xc1\\x06*I\\xad(\\x01\\x00\")\n    await writer.send(b\"text\")\n    writer.transport.write.assert_called_with(b\"\\x81\\x04text\")\n    await writer.send(b\"text\", compress=15)\n    writer.transport.write.assert_called_with(b\"\\xc1\\x06*I\\xad(\\x01\\x00\")\n\n\n@pytest.mark.parametrize(\n    (\"max_sync_chunk_size\", \"payload_point_generator\"),\n    (\n        (16, lambda count: count),\n        (4096, lambda count: count),\n        (32, lambda count: 64 + count if count % 2 else count),\n    ),\n)\nasync def test_concurrent_messages(\n    protocol: Any,\n    transport: Any,\n    max_sync_chunk_size: int,\n    payload_point_generator: Callable[[int], int],\n) -> None:\n    \"\"\"Ensure messages are compressed correctly when there are multiple concurrent writers.\n\n    This test generates is parametrized to\n\n    - Generate messages that are larger than patch\n      WEBSOCKET_MAX_SYNC_CHUNK_SIZE of 16\n      where compression will run in the executor\n\n    - Generate messages that are smaller than patch\n      WEBSOCKET_MAX_SYNC_CHUNK_SIZE of 4096\n      where compression will run in the event loop\n\n    - Interleave generated messages with a\n      WEBSOCKET_MAX_SYNC_CHUNK_SIZE of 32\n      where compression will run in the event loop\n      and in the executor\n    \"\"\"\n    with mock.patch(\n        \"aiohttp.http_websocket.WEBSOCKET_MAX_SYNC_CHUNK_SIZE\", max_sync_chunk_size\n    ):\n        writer = WebSocketWriter(protocol, transport, compress=15)\n        queue: DataQueue[WSMessage] = DataQueue(asyncio.get_running_loop())\n        reader = WebSocketReader(queue, 50000)\n        writers = []\n        payloads = []\n        for count in range(1, 64 + 1):\n            point = payload_point_generator(count)\n            payload = bytes((point,)) * point\n            payloads.append(payload)\n            writers.append(writer.send(payload, binary=True))\n        await asyncio.gather(*writers)\n\n    for call in writer.transport.write.call_args_list:\n        call_bytes = call[0][0]\n        result, _ = reader.feed_data(call_bytes)\n        assert result is False\n        msg = await queue.read()\n        bytes_data: bytes = msg.data\n        first_char = bytes_data[0:1]\n        char_val = ord(first_char)\n        assert len(bytes_data) == char_val\n        # If we have a concurrency problem, the data\n        # tends to get mixed up between messages so\n        # we want to validate that all the bytes are\n        # the same value\n        assert bytes_data == bytes_data[0:1] * char_val\n", "tests/test_web_functional.py": "# type: ignore\nimport asyncio\nimport io\nimport json\nimport pathlib\nimport socket\nimport zlib\nfrom typing import Any, Optional\nfrom unittest import mock\n\nimport pytest\nfrom multidict import CIMultiDictProxy, MultiDict\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp import (\n    FormData,\n    HttpVersion,\n    HttpVersion10,\n    HttpVersion11,\n    TraceConfig,\n    multipart,\n    web,\n)\nfrom aiohttp.hdrs import CONTENT_LENGTH, CONTENT_TYPE, TRANSFER_ENCODING\nfrom aiohttp.test_utils import make_mocked_coro\nfrom aiohttp.typedefs import Handler\n\ntry:\n    import brotlicffi as brotli\nexcept ImportError:\n    import brotli\n\ntry:\n    import ssl\nexcept ImportError:\n    ssl = None\n\n\n@pytest.fixture\ndef here():\n    return pathlib.Path(__file__).parent\n\n\n@pytest.fixture\ndef fname(here: Any):\n    return here / \"conftest.py\"\n\n\ndef new_dummy_form():\n    form = FormData()\n    form.add_field(\"name\", b\"123\")\n    return form\n\n\nasync def test_simple_get(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert \"OK\" == txt\n\n    await resp.release()\n\n\nasync def test_simple_get_with_text(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(text=\"OK\", headers={\"content-type\": \"text/plain\"})\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert \"OK\" == txt\n\n    await resp.release()\n\n\nasync def test_handler_returns_not_response(\n    aiohttp_server: Any, aiohttp_client: Any\n) -> None:\n    asyncio.get_event_loop().set_debug(True)\n    logger = mock.Mock()\n\n    async def handler(request):\n        return \"abc\"\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app, logger=logger)\n    client = await aiohttp_client(server)\n\n    with pytest.raises(aiohttp.ServerDisconnectedError):\n        await client.get(\"/\")\n\n    logger.exception.assert_called_with(\n        \"Unhandled runtime exception\", exc_info=mock.ANY\n    )\n\n\nasync def test_handler_returns_none(aiohttp_server: Any, aiohttp_client: Any) -> None:\n    asyncio.get_event_loop().set_debug(True)\n    logger = mock.Mock()\n\n    async def handler(request):\n        return None\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app, logger=logger)\n    client = await aiohttp_client(server)\n\n    with pytest.raises(aiohttp.ServerDisconnectedError):\n        await client.get(\"/\")\n\n    # Actual error text is placed in exc_info\n    logger.exception.assert_called_with(\n        \"Unhandled runtime exception\", exc_info=mock.ANY\n    )\n\n\nasync def test_head_returns_empty_body(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"test\")\n\n    app = web.Application()\n    app.router.add_head(\"/\", handler)\n    client = await aiohttp_client(app, version=HttpVersion11)\n\n    resp = await client.head(\"/\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert \"\" == txt\n    # The Content-Length header should be set to 4 which is\n    # the length of the response body if it would have been\n    # returned by a GET request.\n    assert resp.headers[\"Content-Length\"] == \"4\"\n\n\nasync def test_response_before_complete(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    data = b\"0\" * 1024 * 1024\n\n    resp = await client.post(\"/\", data=data)\n    assert 200 == resp.status\n    text = await resp.text()\n    assert \"OK\" == text\n\n    await resp.release()\n\n\nasync def test_post_form(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert {\"a\": \"1\", \"b\": \"2\", \"c\": \"\"} == data\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data={\"a\": 1, \"b\": 2, \"c\": \"\"})\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert \"OK\" == txt\n\n    await resp.release()\n\n\nasync def test_post_text(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.text()\n        assert \"\u0440\u0443\u0441\u0441\u043a\u0438\u0439\" == data\n        data2 = await request.text()\n        assert data == data2\n        return web.Response(text=data)\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data=\"\u0440\u0443\u0441\u0441\u043a\u0438\u0439\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert \"\u0440\u0443\u0441\u0441\u043a\u0438\u0439\" == txt\n\n    await resp.release()\n\n\nasync def test_post_json(aiohttp_client: Any) -> None:\n    dct = {\"key\": \"\u0442\u0435\u043a\u0441\u0442\"}\n\n    async def handler(request):\n        data = await request.json()\n        assert dct == data\n        data2 = await request.json(loads=json.loads)\n        assert data == data2\n        resp = web.Response()\n        resp.content_type = \"application/json\"\n        resp.body = json.dumps(data).encode(\"utf8\")\n        return resp\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    headers = {\"Content-Type\": \"application/json\"}\n    resp = await client.post(\"/\", data=json.dumps(dct), headers=headers)\n    assert 200 == resp.status\n    data = await resp.json()\n    assert dct == data\n\n    await resp.release()\n\n\nasync def test_multipart(aiohttp_client: Any) -> None:\n    with multipart.MultipartWriter() as writer:\n        writer.append(\"test\")\n        writer.append_json({\"passed\": True})\n\n    async def handler(request):\n        reader = await request.multipart()\n        assert isinstance(reader, multipart.MultipartReader)\n\n        part = await reader.next()\n        assert isinstance(part, multipart.BodyPartReader)\n        thing = await part.text()\n        assert thing == \"test\"\n\n        part = await reader.next()\n        assert isinstance(part, multipart.BodyPartReader)\n        assert part.headers[\"Content-Type\"] == \"application/json\"\n        thing = await part.json()\n        assert thing == {\"passed\": True}\n\n        resp = web.Response()\n        resp.content_type = \"application/json\"\n        resp.body = b\"\"\n        return resp\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data=writer)\n    assert 200 == resp.status\n    await resp.release()\n\n\nasync def test_multipart_empty(aiohttp_client: Any) -> None:\n    with multipart.MultipartWriter() as writer:\n        pass\n\n    async def handler(request):\n        reader = await request.multipart()\n        assert isinstance(reader, multipart.MultipartReader)\n        async for part in reader:\n            assert False, f\"Unexpected part found in reader: {part!r}\"\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data=writer)\n    assert 200 == resp.status\n    await resp.release()\n\n\nasync def test_multipart_content_transfer_encoding(aiohttp_client: Any) -> None:\n    # For issue #1168\n    with multipart.MultipartWriter() as writer:\n        writer.append(b\"\\x00\" * 10, headers={\"Content-Transfer-Encoding\": \"binary\"})\n\n    async def handler(request):\n        reader = await request.multipart()\n        assert isinstance(reader, multipart.MultipartReader)\n\n        part = await reader.next()\n        assert isinstance(part, multipart.BodyPartReader)\n        assert part.headers[\"Content-Transfer-Encoding\"] == \"binary\"\n        thing = await part.read()\n        assert thing == b\"\\x00\" * 10\n\n        resp = web.Response()\n        resp.content_type = \"application/json\"\n        resp.body = b\"\"\n        return resp\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data=writer)\n    assert 200 == resp.status\n    await resp.release()\n\n\nasync def test_render_redirect(aiohttp_client: Any) -> None:\n    async def handler(request):\n        raise web.HTTPMovedPermanently(location=\"/path\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\", allow_redirects=False)\n    assert 301 == resp.status\n    txt = await resp.text()\n    assert \"301: Moved Permanently\" == txt\n    assert \"/path\" == resp.headers[\"location\"]\n\n    await resp.release()\n\n\nasync def test_post_single_file(aiohttp_client: Any) -> None:\n    here = pathlib.Path(__file__).parent\n\n    def check_file(fs):\n        fullname = here / fs.filename\n        with fullname.open(\"rb\") as f:\n            test_data = f.read()\n            data = fs.file.read()\n            assert test_data == data\n\n    async def handler(request):\n        data = await request.post()\n        assert [\"data.unknown_mime_type\"] == list(data.keys())\n        for fs in data.values():\n            check_file(fs)\n            fs.file.close()\n        resp = web.Response(body=b\"OK\")\n        return resp\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    fname = here / \"data.unknown_mime_type\"\n\n    with fname.open(\"rb\") as fd:\n        resp = await client.post(\"/\", data=[fd])\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_files_upload_with_same_key(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        files = data.getall(\"file\")\n        file_names = set()\n        for _file in files:\n            assert not _file.file.closed\n            if _file.filename == \"test1.jpeg\":\n                assert _file.file.read() == b\"binary data 1\"\n            if _file.filename == \"test2.jpeg\":\n                assert _file.file.read() == b\"binary data 2\"\n            file_names.add(_file.filename)\n            _file.file.close()\n        assert len(files) == 2\n        assert file_names == {\"test1.jpeg\", \"test2.jpeg\"}\n        resp = web.Response(body=b\"OK\")\n        return resp\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    data = FormData()\n    data.add_field(\n        \"file\", b\"binary data 1\", content_type=\"image/jpeg\", filename=\"test1.jpeg\"\n    )\n    data.add_field(\n        \"file\", b\"binary data 2\", content_type=\"image/jpeg\", filename=\"test2.jpeg\"\n    )\n    resp = await client.post(\"/\", data=data)\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_post_files(aiohttp_client: Any) -> None:\n    here = pathlib.Path(__file__).parent\n\n    def check_file(fs):\n        fullname = here / fs.filename\n        with fullname.open(\"rb\") as f:\n            test_data = f.read()\n            data = fs.file.read()\n            assert test_data == data\n\n    async def handler(request):\n        data = await request.post()\n        assert [\"data.unknown_mime_type\", \"conftest.py\"] == list(data.keys())\n        for fs in data.values():\n            check_file(fs)\n            fs.file.close()\n        resp = web.Response(body=b\"OK\")\n        return resp\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with (here / \"data.unknown_mime_type\").open(\"rb\") as f1:\n        with (here / \"conftest.py\").open(\"rb\") as f2:\n            resp = await client.post(\"/\", data=[f1, f2])\n            assert 200 == resp.status\n\n            await resp.release()\n\n\nasync def test_release_post_data(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await request.release()\n        chunk = await request.content.readany()\n        assert chunk == b\"\"\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data=\"post text\")\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_post_form_with_duplicate_keys(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        lst = list(data.items())\n        assert [(\"a\", \"1\"), (\"a\", \"2\")] == lst\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data=MultiDict([(\"a\", 1), (\"a\", 2)]))\n    assert 200 == resp.status\n\n    await resp.release()\n\n\ndef test_repr_for_application() -> None:\n    app = web.Application()\n    assert f\"<Application 0x{id(app):x}>\" == repr(app)\n\n\nasync def test_expect_default_handler_unknown(aiohttp_client: Any) -> None:\n    # Test default Expect handler for unknown Expect value.\n\n    # A server that does not understand or is unable to comply with any of\n    # the expectation values in the Expect field of a request MUST respond\n    # with appropriate error status. The server MUST respond with a 417\n    # (Expectation Failed) status if any of the expectations cannot be met\n    # or, if there are other problems with the request, some other 4xx\n    # status.\n\n    # http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.20\n    async def handler(request):\n        await request.post()\n        pytest.xfail(\n            \"Handler should not proceed to this point in case of \"\n            \"unknown Expect header\"\n        )\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", headers={\"Expect\": \"SPAM\"})\n    assert 417 == resp.status\n\n    await resp.release()\n\n\nasync def test_100_continue(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert b\"123\" == data[\"name\"]\n        return web.Response()\n\n    form = FormData()\n    form.add_field(\"name\", b\"123\")\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data=form, expect100=True)\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_100_continue_custom(aiohttp_client: Any) -> None:\n    expect_received = False\n\n    async def handler(request):\n        data = await request.post()\n        assert b\"123\" == data[\"name\"]\n        return web.Response()\n\n    async def expect_handler(request):\n        nonlocal expect_received\n        expect_received = True\n        if request.version == HttpVersion11:\n            await request.writer.write(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler, expect_handler=expect_handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data=new_dummy_form(), expect100=True)\n    assert 200 == resp.status\n    assert expect_received\n\n    await resp.release()\n\n\nasync def test_100_continue_custom_response(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert b\"123\", data[\"name\"]\n        return web.Response()\n\n    async def expect_handler(request):\n        if request.version == HttpVersion11:\n            if auth_err:\n                raise web.HTTPForbidden()\n\n            await request.writer.write(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler, expect_handler=expect_handler)\n    client = await aiohttp_client(app)\n\n    auth_err = False\n    resp = await client.post(\"/\", data=new_dummy_form(), expect100=True)\n    assert 200 == resp.status\n    await resp.release()\n\n    auth_err = True\n    resp = await client.post(\"/\", data=new_dummy_form(), expect100=True)\n    assert 403 == resp.status\n    await resp.release()\n\n\nasync def test_expect_handler_custom_response(aiohttp_client: Any) -> None:\n    cache = {\"foo\": \"bar\"}\n\n    async def handler(request: web.Request) -> web.Response:\n        return web.Response(text=\"handler\")\n\n    async def expect_handler(request: web.Request) -> Optional[web.Response]:\n        k = request.headers.get(\"X-Key\")\n        cached_value = cache.get(k)\n        if cached_value:\n            return web.Response(text=cached_value)\n\n    app = web.Application()\n    # expect_handler is only typed on add_route().\n    app.router.add_route(\"POST\", \"/\", handler, expect_handler=expect_handler)\n    client = await aiohttp_client(app)\n\n    async with client.post(\"/\", expect100=True, headers={\"X-Key\": \"foo\"}) as resp:\n        assert resp.status == 200\n        assert await resp.text() == \"bar\"\n\n    async with client.post(\"/\", expect100=True, headers={\"X-Key\": \"spam\"}) as resp:\n        assert resp.status == 200\n        assert await resp.text() == \"handler\"\n\n\nasync def test_100_continue_for_not_found(aiohttp_client: Any) -> None:\n    app = web.Application()\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/not_found\", data=\"data\", expect100=True)\n    assert 404 == resp.status\n\n    await resp.release()\n\n\nasync def test_100_continue_for_not_allowed(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\", expect100=True)\n    assert 405 == resp.status\n\n    await resp.release()\n\n\nasync def test_http11_keep_alive_default(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, version=HttpVersion11)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    assert resp.version == HttpVersion11\n    assert \"Connection\" not in resp.headers\n\n    await resp.release()\n\n\n@pytest.mark.xfail\nasync def test_http10_keep_alive_default(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, version=HttpVersion10)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    assert resp.version == HttpVersion10\n    assert resp.headers[\"Connection\"] == \"keep-alive\"\n\n    await resp.release()\n\n\nasync def test_http10_keep_alive_with_headers_close(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await request.read()\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, version=HttpVersion10)\n\n    headers = {\"Connection\": \"close\"}\n    resp = await client.get(\"/\", headers=headers)\n    assert 200 == resp.status\n    assert resp.version == HttpVersion10\n    assert \"Connection\" not in resp.headers\n\n    await resp.release()\n\n\nasync def test_http10_keep_alive_with_headers(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await request.read()\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, version=HttpVersion10)\n\n    headers = {\"Connection\": \"keep-alive\"}\n    resp = await client.get(\"/\", headers=headers)\n    assert 200 == resp.status\n    assert resp.version == HttpVersion10\n    assert resp.headers[\"Connection\"] == \"keep-alive\"\n\n    await resp.release()\n\n\nasync def test_upload_file(aiohttp_client: Any) -> None:\n    here = pathlib.Path(__file__).parent\n    fname = here / \"aiohttp.png\"\n    with fname.open(\"rb\") as f:\n        data = f.read()\n\n    async def handler(request):\n        form = await request.post()\n        raw_data = form[\"file\"].file.read()\n        form[\"file\"].file.close()\n        assert data == raw_data\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data={\"file\": io.BytesIO(data)})\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_upload_file_object(aiohttp_client: Any) -> None:\n    here = pathlib.Path(__file__).parent\n    fname = here / \"aiohttp.png\"\n    with fname.open(\"rb\") as f:\n        data = f.read()\n\n    async def handler(request):\n        form = await request.post()\n        raw_data = form[\"file\"].file.read()\n        form[\"file\"].file.close()\n        assert data == raw_data\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        resp = await client.post(\"/\", data={\"file\": f})\n        assert 200 == resp.status\n\n        await resp.release()\n\n\n@pytest.mark.parametrize(\n    \"method\", [\"get\", \"post\", \"options\", \"post\", \"put\", \"patch\", \"delete\"]\n)\nasync def test_empty_content_for_query_without_body(\n    method: Any, aiohttp_client: Any\n) -> None:\n    async def handler(request):\n        assert not request.body_exists\n        assert not request.can_read_body\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(method, \"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.request(method, \"/\")\n    assert 200 == resp.status\n\n\nasync def test_empty_content_for_query_with_body(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.body_exists\n        assert request.can_read_body\n        body = await request.read()\n        return web.Response(body=body)\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data=b\"data\")\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_get_with_empty_arg(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert \"arg\" in request.query\n        assert \"\" == request.query[\"arg\"]\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/?arg\")\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_large_header(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    headers = {\"Long-Header\": \"ab\" * 8129}\n    resp = await client.get(\"/\", headers=headers)\n    assert 400 == resp.status\n\n    await resp.release()\n\n\nasync def test_large_header_allowed(aiohttp_client: Any, aiohttp_server: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    server = await aiohttp_server(app, max_field_size=81920)\n    client = await aiohttp_client(server)\n\n    headers = {\"Long-Header\": \"ab\" * 8129}\n    resp = await client.post(\"/\", headers=headers)\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_get_with_empty_arg_with_equal(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert \"arg\" in request.query\n        assert \"\" == request.query[\"arg\"]\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/?arg=\")\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_response_with_async_gen(aiohttp_client: Any, fname: Any) -> None:\n    with fname.open(\"rb\") as f:\n        data = f.read()\n\n    data_size = len(data)\n\n    async def stream(f_name):\n        with f_name.open(\"rb\") as f:\n            data = f.read(100)\n            while data:\n                yield data\n                data = f.read(100)\n\n    async def handler(request):\n        headers = {\"Content-Length\": str(data_size)}\n        return web.Response(body=stream(fname), headers=headers)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    resp_data = await resp.read()\n    assert resp_data == data\n    assert resp.headers.get(\"Content-Length\") == str(len(resp_data))\n\n    await resp.release()\n\n\nasync def test_response_with_async_gen_no_params(\n    aiohttp_client: Any, fname: Any\n) -> None:\n    with fname.open(\"rb\") as f:\n        data = f.read()\n\n    data_size = len(data)\n\n    async def stream():\n        with fname.open(\"rb\") as f:\n            data = f.read(100)\n            while data:\n                yield data\n                data = f.read(100)\n\n    async def handler(request):\n        headers = {\"Content-Length\": str(data_size)}\n        return web.Response(body=stream(), headers=headers)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    resp_data = await resp.read()\n    assert resp_data == data\n    assert resp.headers.get(\"Content-Length\") == str(len(resp_data))\n\n    await resp.release()\n\n\nasync def test_response_with_file(aiohttp_client: Any, fname: Any) -> None:\n    outer_file_descriptor = None\n\n    with fname.open(\"rb\") as f:\n        data = f.read()\n\n    async def handler(request):\n        nonlocal outer_file_descriptor\n        outer_file_descriptor = fname.open(\"rb\")\n        return web.Response(body=outer_file_descriptor)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    resp_data = await resp.read()\n    expected_content_disposition = 'attachment; filename=\"conftest.py\"'\n    assert resp_data == data\n    assert resp.headers.get(\"Content-Type\") in (\n        \"application/octet-stream\",\n        \"text/x-python\",\n        \"text/plain\",\n    )\n    assert resp.headers.get(\"Content-Length\") == str(len(resp_data))\n    assert resp.headers.get(\"Content-Disposition\") == expected_content_disposition\n\n    await resp.release()\n\n    outer_file_descriptor.close()\n\n\nasync def test_response_with_file_ctype(aiohttp_client: Any, fname: Any) -> None:\n    outer_file_descriptor = None\n\n    with fname.open(\"rb\") as f:\n        data = f.read()\n\n    async def handler(request):\n        nonlocal outer_file_descriptor\n        outer_file_descriptor = fname.open(\"rb\")\n\n        return web.Response(\n            body=outer_file_descriptor, headers={\"content-type\": \"text/binary\"}\n        )\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    resp_data = await resp.read()\n    expected_content_disposition = 'attachment; filename=\"conftest.py\"'\n    assert resp_data == data\n    assert resp.headers.get(\"Content-Type\") == \"text/binary\"\n    assert resp.headers.get(\"Content-Length\") == str(len(resp_data))\n    assert resp.headers.get(\"Content-Disposition\") == expected_content_disposition\n\n    await resp.release()\n\n    outer_file_descriptor.close()\n\n\nasync def test_response_with_payload_disp(aiohttp_client: Any, fname: Any) -> None:\n    outer_file_descriptor = None\n\n    with fname.open(\"rb\") as f:\n        data = f.read()\n\n    async def handler(request):\n        nonlocal outer_file_descriptor\n        outer_file_descriptor = fname.open(\"rb\")\n        pl = aiohttp.get_payload(outer_file_descriptor)\n        pl.set_content_disposition(\"inline\", filename=\"test.txt\")\n        return web.Response(body=pl, headers={\"content-type\": \"text/binary\"})\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    resp_data = await resp.read()\n    assert resp_data == data\n    assert resp.headers.get(\"Content-Type\") == \"text/binary\"\n    assert resp.headers.get(\"Content-Length\") == str(len(resp_data))\n    assert resp.headers.get(\"Content-Disposition\") == 'inline; filename=\"test.txt\"'\n\n    await resp.release()\n\n    outer_file_descriptor.close()\n\n\nasync def test_response_with_payload_stringio(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        return web.Response(body=io.StringIO(\"test\"))\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    resp_data = await resp.read()\n    assert resp_data == b\"test\"\n\n    await resp.release()\n\n\n@pytest.mark.parametrize(\n    \"compressor,encoding\",\n    [\n        (zlib.compressobj(wbits=16 + zlib.MAX_WBITS), \"gzip\"),\n        (zlib.compressobj(wbits=zlib.MAX_WBITS), \"deflate\"),\n        # Actually, wrong compression format, but\n        # should be supported for some legacy cases.\n        (zlib.compressobj(wbits=-zlib.MAX_WBITS), \"deflate\"),\n    ],\n)\nasync def test_response_with_precompressed_body(\n    aiohttp_client: Any, compressor: Any, encoding: Any\n) -> None:\n    async def handler(request):\n        headers = {\"Content-Encoding\": encoding}\n        data = compressor.compress(b\"mydata\") + compressor.flush()\n        return web.Response(body=data, headers=headers)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    data = await resp.read()\n    assert b\"mydata\" == data\n    assert resp.headers.get(\"Content-Encoding\") == encoding\n\n    await resp.release()\n\n\nasync def test_response_with_precompressed_body_brotli(aiohttp_client: Any) -> None:\n    async def handler(request):\n        headers = {\"Content-Encoding\": \"br\"}\n        return web.Response(body=brotli.compress(b\"mydata\"), headers=headers)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    data = await resp.read()\n    assert b\"mydata\" == data\n    assert resp.headers.get(\"Content-Encoding\") == \"br\"\n\n    await resp.release()\n\n\nasync def test_bad_request_payload(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.method == \"POST\"\n\n        with pytest.raises(aiohttp.web.RequestPayloadError):\n            await request.content.read()\n\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data=b\"test\", headers={\"content-encoding\": \"gzip\"})\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_stream_response_multiple_chunks(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse()\n        resp.enable_chunked_encoding()\n        await resp.prepare(request)\n        await resp.write(b\"x\")\n        await resp.write(b\"y\")\n        await resp.write(b\"z\")\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    data = await resp.read()\n    assert b\"xyz\" == data\n\n    await resp.release()\n\n\nasync def test_start_without_routes(aiohttp_client: Any) -> None:\n    app = web.Application()\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 404 == resp.status\n\n    await resp.release()\n\n\nasync def test_requests_count(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n    assert client.server.handler.requests_count == 0\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    assert client.server.handler.requests_count == 1\n    await resp.release()\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    assert client.server.handler.requests_count == 2\n    await resp.release()\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    assert client.server.handler.requests_count == 3\n    await resp.release()\n\n\nasync def test_redirect_url(aiohttp_client: Any) -> None:\n    async def redirector(request):\n        raise web.HTTPFound(location=URL(\"/redirected\"))\n\n    async def redirected(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/redirector\", redirector)\n    app.router.add_get(\"/redirected\", redirected)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/redirector\")\n    assert resp.status == 200\n\n    await resp.release()\n\n\nasync def test_simple_subapp(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=\"OK\")\n\n    app = web.Application()\n    subapp = web.Application()\n    subapp.router.add_get(\"/to\", handler)\n    app.add_subapp(\"/path\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/path/to\")\n    assert resp.status == 200\n    txt = await resp.text()\n    assert \"OK\" == txt\n\n    await resp.release()\n\n\nasync def test_subapp_reverse_url(aiohttp_client: Any) -> None:\n    async def handler(request):\n        raise web.HTTPMovedPermanently(location=subapp.router[\"name\"].url_for())\n\n    async def handler2(request):\n        return web.Response(text=\"OK\")\n\n    app = web.Application()\n    subapp = web.Application()\n    subapp.router.add_get(\"/to\", handler)\n    subapp.router.add_get(\"/final\", handler2, name=\"name\")\n    app.add_subapp(\"/path\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/path/to\")\n    assert resp.status == 200\n    txt = await resp.text()\n    assert \"OK\" == txt\n    assert resp.url.path == \"/path/final\"\n\n    await resp.release()\n\n\nasync def test_subapp_reverse_variable_url(aiohttp_client: Any) -> None:\n    async def handler(request):\n        raise web.HTTPMovedPermanently(\n            location=subapp.router[\"name\"].url_for(part=\"final\")\n        )\n\n    async def handler2(request):\n        return web.Response(text=\"OK\")\n\n    app = web.Application()\n    subapp = web.Application()\n    subapp.router.add_get(\"/to\", handler)\n    subapp.router.add_get(\"/{part}\", handler2, name=\"name\")\n    app.add_subapp(\"/path\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/path/to\")\n    assert resp.status == 200\n    txt = await resp.text()\n    assert \"OK\" == txt\n    assert resp.url.path == \"/path/final\"\n\n    await resp.release()\n\n\nasync def test_subapp_reverse_static_url(aiohttp_client: Any) -> None:\n    fname = \"aiohttp.png\"\n\n    async def handler(request):\n        raise web.HTTPMovedPermanently(\n            location=subapp.router[\"name\"].url_for(filename=fname)\n        )\n\n    app = web.Application()\n    subapp = web.Application()\n    subapp.router.add_get(\"/to\", handler)\n    here = pathlib.Path(__file__).parent\n    subapp.router.add_static(\"/static\", here, name=\"name\")\n    app.add_subapp(\"/path\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/path/to\")\n    assert resp.url.path == \"/path/static/\" + fname\n    assert resp.status == 200\n    body = await resp.read()\n\n    await resp.release()\n\n    with (here / fname).open(\"rb\") as f:\n        assert body == f.read()\n\n\nasync def test_subapp_app(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.app is subapp\n        return web.Response(text=\"OK\")\n\n    app = web.Application()\n    subapp = web.Application()\n    subapp.router.add_get(\"/to\", handler)\n    app.add_subapp(\"/path/\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/path/to\")\n    assert resp.status == 200\n    txt = await resp.text()\n    assert \"OK\" == txt\n\n    await resp.release()\n\n\nasync def test_subapp_not_found(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=\"OK\")\n\n    app = web.Application()\n    subapp = web.Application()\n    subapp.router.add_get(\"/to\", handler)\n    app.add_subapp(\"/path/\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/path/other\")\n    assert resp.status == 404\n\n    await resp.release()\n\n\nasync def test_subapp_not_found2(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=\"OK\")\n\n    app = web.Application()\n    subapp = web.Application()\n    subapp.router.add_get(\"/to\", handler)\n    app.add_subapp(\"/path/\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/invalid/other\")\n    assert resp.status == 404\n\n    await resp.release()\n\n\nasync def test_subapp_not_allowed(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=\"OK\")\n\n    app = web.Application()\n    subapp = web.Application()\n    subapp.router.add_get(\"/to\", handler)\n    app.add_subapp(\"/path/\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.post(\"/path/to\")\n    assert resp.status == 405\n    assert resp.headers[\"Allow\"] == \"GET,HEAD\"\n\n    await resp.release()\n\n\nasync def test_subapp_cannot_add_app_in_handler(aiohttp_client: Any) -> None:\n    async def handler(request):\n        request.match_info.add_app(app)\n        return web.Response(text=\"OK\")\n\n    app = web.Application()\n    subapp = web.Application()\n    subapp.router.add_get(\"/to\", handler)\n    app.add_subapp(\"/path/\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/path/to\")\n    assert resp.status == 500\n\n    await resp.release()\n\n\nasync def test_old_style_subapp_middlewares(aiohttp_client: Any) -> None:\n    order = []\n\n    async def handler(request):\n        return web.Response(text=\"OK\")\n\n    with pytest.deprecated_call(\n        match=r\"^Middleware decorator is deprecated since 4\\.0 and \"\n        r\"its behaviour is default, you can simply remove \"\n        r\"this decorator\\.$\",\n    ):\n\n        @web.middleware\n        async def middleware(request, handler: Handler):\n            order.append((1, request.app[name]))\n            resp = await handler(request)\n            assert 200 == resp.status\n            order.append((2, request.app[name]))\n            return resp\n\n    app = web.Application(middlewares=[middleware])\n    name = web.AppKey(\"app\", str)\n    subapp1 = web.Application(middlewares=[middleware])\n    subapp2 = web.Application(middlewares=[middleware])\n    app[name] = \"app\"\n    subapp1[name] = \"subapp1\"\n    subapp2[name] = \"subapp2\"\n\n    subapp2.router.add_get(\"/to\", handler)\n    subapp1.add_subapp(\"/b/\", subapp2)\n    app.add_subapp(\"/a/\", subapp1)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/a/b/to\")\n    assert resp.status == 200\n    assert [\n        (1, \"app\"),\n        (1, \"subapp1\"),\n        (1, \"subapp2\"),\n        (2, \"subapp2\"),\n        (2, \"subapp1\"),\n        (2, \"app\"),\n    ] == order\n\n    await resp.release()\n\n\nasync def test_subapp_on_response_prepare(aiohttp_client: Any) -> None:\n    order = []\n\n    async def handler(request):\n        return web.Response(text=\"OK\")\n\n    def make_signal(app):\n        async def on_response(request, response):\n            order.append(app)\n\n        return on_response\n\n    app = web.Application()\n    app.on_response_prepare.append(make_signal(app))\n    subapp1 = web.Application()\n    subapp1.on_response_prepare.append(make_signal(subapp1))\n    subapp2 = web.Application()\n    subapp2.on_response_prepare.append(make_signal(subapp2))\n    subapp2.router.add_get(\"/to\", handler)\n    subapp1.add_subapp(\"/b/\", subapp2)\n    app.add_subapp(\"/a/\", subapp1)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/a/b/to\")\n    assert resp.status == 200\n    assert [app, subapp1, subapp2] == order\n\n    await resp.release()\n\n\nasync def test_subapp_on_startup(aiohttp_server: Any) -> None:\n    order = []\n\n    async def on_signal(app):\n        order.append(app)\n\n    app = web.Application()\n    app.on_startup.append(on_signal)\n    subapp1 = web.Application()\n    subapp1.on_startup.append(on_signal)\n    subapp2 = web.Application()\n    subapp2.on_startup.append(on_signal)\n    subapp1.add_subapp(\"/b/\", subapp2)\n    app.add_subapp(\"/a/\", subapp1)\n\n    await aiohttp_server(app)\n\n    assert [app, subapp1, subapp2] == order\n\n\nasync def test_subapp_on_shutdown(aiohttp_server: Any) -> None:\n    order = []\n\n    async def on_signal(app):\n        order.append(app)\n\n    app = web.Application()\n    app.on_shutdown.append(on_signal)\n    subapp1 = web.Application()\n    subapp1.on_shutdown.append(on_signal)\n    subapp2 = web.Application()\n    subapp2.on_shutdown.append(on_signal)\n    subapp1.add_subapp(\"/b/\", subapp2)\n    app.add_subapp(\"/a/\", subapp1)\n\n    server = await aiohttp_server(app)\n    await server.close()\n\n    assert [app, subapp1, subapp2] == order\n\n\nasync def test_subapp_on_cleanup(aiohttp_server: Any) -> None:\n    order = []\n\n    async def on_signal(app):\n        order.append(app)\n\n    app = web.Application()\n    app.on_cleanup.append(on_signal)\n    subapp1 = web.Application()\n    subapp1.on_cleanup.append(on_signal)\n    subapp2 = web.Application()\n    subapp2.on_cleanup.append(on_signal)\n    subapp1.add_subapp(\"/b/\", subapp2)\n    app.add_subapp(\"/a/\", subapp1)\n\n    server = await aiohttp_server(app)\n    await server.close()\n\n    assert [app, subapp1, subapp2] == order\n\n\n@pytest.mark.parametrize(\n    \"route,expected,middlewares\",\n    [\n        (\"/sub/\", [\"A: root\", \"C: sub\", \"D: sub\"], \"AC\"),\n        (\"/\", [\"A: root\", \"B: root\"], \"AC\"),\n        (\"/sub/\", [\"A: root\", \"D: sub\"], \"A\"),\n        (\"/\", [\"A: root\", \"B: root\"], \"A\"),\n        (\"/sub/\", [\"C: sub\", \"D: sub\"], \"C\"),\n        (\"/\", [\"B: root\"], \"C\"),\n        (\"/sub/\", [\"D: sub\"], \"\"),\n        (\"/\", [\"B: root\"], \"\"),\n    ],\n)\nasync def test_subapp_middleware_context(\n    aiohttp_client: Any, route: Any, expected: Any, middlewares: Any\n):\n    values = []\n\n    def show_app_context(appname):\n        async def middleware(request, handler: Handler):\n            values.append(f\"{appname}: {request.app[my_value]}\")\n            return await handler(request)\n\n        return middleware\n\n    def make_handler(appname):\n        async def handler(request):\n            values.append(f\"{appname}: {request.app[my_value]}\")\n            return web.Response(text=\"Ok\")\n\n        return handler\n\n    app = web.Application()\n    my_value = web.AppKey(\"my_value\", str)\n    app[my_value] = \"root\"\n    if \"A\" in middlewares:\n        app.middlewares.append(show_app_context(\"A\"))\n    app.router.add_get(\"/\", make_handler(\"B\"))\n\n    subapp = web.Application()\n    subapp[my_value] = \"sub\"\n    if \"C\" in middlewares:\n        subapp.middlewares.append(show_app_context(\"C\"))\n    subapp.router.add_get(\"/\", make_handler(\"D\"))\n    app.add_subapp(\"/sub/\", subapp)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(route)\n    assert 200 == resp.status\n    assert \"Ok\" == await resp.text()\n    assert expected == values\n\n    await resp.release()\n\n\nasync def test_custom_date_header(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(headers={\"Date\": \"Sun, 30 Oct 2016 03:13:52 GMT\"})\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    assert resp.headers[\"Date\"] == \"Sun, 30 Oct 2016 03:13:52 GMT\"\n\n    await resp.release()\n\n\nasync def test_response_prepared_with_clone(aiohttp_client: Any) -> None:\n    async def handler(request):\n        cloned = request.clone()\n        resp = web.StreamResponse()\n        await resp.prepare(cloned)\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n\n    await resp.release()\n\n\nasync def test_app_max_client_size(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await request.post()\n        return web.Response(body=b\"ok\")\n\n    max_size = 1024**2\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n    data = {\"long_string\": max_size * \"x\" + \"xxx\"}\n    with pytest.warns(ResourceWarning):\n        resp = await client.post(\"/\", data=data)\n    assert 413 == resp.status\n    resp_text = await resp.text()\n    assert (\n        \"Maximum request body size 1048576 exceeded, \" \"actual body size\" in resp_text\n    )\n    # Maximum request body size X exceeded, actual body size X\n    body_size = int(resp_text.split()[-1])\n    assert body_size >= max_size\n\n    await resp.release()\n\n\nasync def test_app_max_client_size_adjusted(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await request.post()\n        return web.Response(body=b\"ok\")\n\n    default_max_size = 1024**2\n    custom_max_size = default_max_size * 2\n    app = web.Application(client_max_size=custom_max_size)\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n    data = {\"long_string\": default_max_size * \"x\" + \"xxx\"}\n\n    with pytest.warns(ResourceWarning):\n        resp = await client.post(\"/\", data=data)\n    assert 200 == resp.status\n    resp_text = await resp.text()\n    assert \"ok\" == resp_text\n    await resp.release()\n\n    too_large_data = {\"log_string\": custom_max_size * \"x\" + \"xxx\"}\n    with pytest.warns(ResourceWarning):\n        resp = await client.post(\"/\", data=too_large_data)\n    assert 413 == resp.status\n    resp_text = await resp.text()\n    assert (\n        \"Maximum request body size 2097152 exceeded, \" \"actual body size\" in resp_text\n    )\n    # Maximum request body size X exceeded, actual body size X\n    body_size = int(resp_text.split()[-1])\n    assert body_size >= custom_max_size\n\n    await resp.release()\n\n\nasync def test_app_max_client_size_none(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await request.post()\n        return web.Response(body=b\"ok\")\n\n    default_max_size = 1024**2\n    custom_max_size = None\n    app = web.Application(client_max_size=custom_max_size)\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    data = {\"long_string\": default_max_size * \"x\" + \"xxx\"}\n    with pytest.warns(ResourceWarning):\n        resp = await client.post(\"/\", data=data)\n    assert 200 == resp.status\n    resp_text = await resp.text()\n    assert \"ok\" == resp_text\n    await resp.release()\n\n    too_large_data = {\"log_string\": default_max_size * 2 * \"x\"}\n    with pytest.warns(ResourceWarning):\n        resp = await client.post(\"/\", data=too_large_data)\n    assert 200 == resp.status\n    resp_text = await resp.text()\n    assert resp_text == \"ok\"\n    await resp.release()\n\n\nasync def test_post_max_client_size(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await request.post()\n        return web.Response()\n\n    app = web.Application(client_max_size=10)\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with io.BytesIO(b\"test\") as file_handle:\n        data = {\"long_string\": 1024 * \"x\", \"file\": file_handle}\n        resp = await client.post(\"/\", data=data)\n\n        assert 413 == resp.status\n        resp_text = await resp.text()\n        assert (\n            \"Maximum request body size 10 exceeded, \"\n            \"actual body size 1024\" in resp_text\n        )\n        data[\"file\"].close()\n\n        await resp.release()\n\n\nasync def test_post_max_client_size_for_file(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await request.post()\n        return web.Response()\n\n    app = web.Application(client_max_size=2)\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with io.BytesIO(b\"test\") as file_handle:\n        data = {\"file\": file_handle}\n        resp = await client.post(\"/\", data=data)\n\n    assert 413 == resp.status\n\n    await resp.release()\n\n\nasync def test_response_with_bodypart(aiohttp_client: Any) -> None:\n    async def handler(request):\n        reader = await request.multipart()\n        part = await reader.next()\n        return web.Response(body=part)\n\n    app = web.Application(client_max_size=2)\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with io.BytesIO(b\"test\") as file_handle:\n        data = {\"file\": file_handle}\n        resp = await client.post(\"/\", data=data)\n\n        assert 200 == resp.status\n        body = await resp.read()\n        assert body == b\"test\"\n\n        disp = multipart.parse_content_disposition(resp.headers[\"content-disposition\"])\n        assert disp == (\"attachment\", {\"name\": \"file\", \"filename\": \"file\"})\n\n        await resp.release()\n\n\nasync def test_response_with_bodypart_named(aiohttp_client: Any, tmp_path: Any) -> None:\n    async def handler(request):\n        reader = await request.multipart()\n        part = await reader.next()\n        return web.Response(body=part)\n\n    app = web.Application(client_max_size=2)\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    f = tmp_path / \"foobar.txt\"\n    f.write_text(\"test\", encoding=\"utf8\")\n    with f.open(\"rb\") as fd:\n        data = {\"file\": fd}\n        resp = await client.post(\"/\", data=data)\n\n        assert 200 == resp.status\n        body = await resp.read()\n    assert body == b\"test\"\n\n    disp = multipart.parse_content_disposition(resp.headers[\"content-disposition\"])\n    assert disp == (\"attachment\", {\"name\": \"file\", \"filename\": \"foobar.txt\"})\n\n    await resp.release()\n\n\nasync def test_response_with_bodypart_invalid_name(aiohttp_client: Any) -> None:\n    async def handler(request):\n        reader = await request.multipart()\n        part = await reader.next()\n        return web.Response(body=part)\n\n    app = web.Application(client_max_size=2)\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with aiohttp.MultipartWriter() as mpwriter:\n        mpwriter.append(b\"test\")\n        resp = await client.post(\"/\", data=mpwriter)\n\n    assert 200 == resp.status\n    body = await resp.read()\n    assert body == b\"test\"\n\n    assert \"content-disposition\" not in resp.headers\n\n    await resp.release()\n\n\nasync def test_request_clone(aiohttp_client: Any) -> None:\n    async def handler(request):\n        r2 = request.clone(method=\"POST\")\n        assert r2.method == \"POST\"\n        assert r2.match_info is request.match_info\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    await resp.release()\n\n\nasync def test_await(aiohttp_server: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse(headers={\"content-length\": str(4)})\n        await resp.prepare(request)\n        with pytest.deprecated_call(\n            match=r\"^drain method is deprecated, use await resp\\.write\\(\\)$\",\n        ):\n            await resp.drain()\n        await asyncio.sleep(0.01)\n        await resp.write(b\"test\")\n        await asyncio.sleep(0.01)\n        await resp.write_eof()\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app)\n\n    async with aiohttp.ClientSession() as session:\n        resp = await session.get(server.make_url(\"/\"))\n        assert resp.status == 200\n        assert resp.connection is not None\n        await resp.read()\n        await resp.release()\n        assert resp.connection is None\n\n\nasync def test_response_context_manager(aiohttp_server: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app)\n    session = aiohttp.ClientSession()\n    resp = await session.get(server.make_url(\"/\"))\n    async with resp:\n        assert resp.status == 200\n    assert resp.connection is None\n\n    await session.close()\n\n\nasync def test_response_context_manager_error(aiohttp_server: Any) -> None:\n    async def handler(request):\n        return web.Response(text=\"some text\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app)\n    session = aiohttp.ClientSession()\n    cm = session.get(server.make_url(\"/\"))\n    resp = await cm\n    with pytest.raises(RuntimeError):\n        async with resp:\n            assert resp.status == 200\n            resp.content.set_exception(RuntimeError())\n            await resp.read()\n    assert resp.closed\n\n    assert len(session._connector._conns) == 1\n\n    await session.close()\n\n\nasync def aiohttp_client_api_context_manager(aiohttp_server: Any):\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app)\n\n    async with aiohttp.ClientSession() as session:\n        async with session.get(server.make_url(\"/\")) as resp:\n            assert resp.status == 200\n            assert resp.connection is None\n    assert resp.connection is None\n\n\nasync def test_context_manager_close_on_release(\n    aiohttp_server: Any, mocker: Any\n) -> None:\n    async def handler(request):\n        resp = web.StreamResponse()\n        await resp.prepare(request)\n        with pytest.deprecated_call(\n            match=r\"^drain method is deprecated, use await resp\\.write\\(\\)$\",\n        ):\n            await resp.drain()\n        await asyncio.sleep(10)\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app)\n\n    async with aiohttp.ClientSession() as session:\n        resp = await session.get(server.make_url(\"/\"))\n        proto = resp.connection._protocol\n        mocker.spy(proto, \"close\")\n        async with resp:\n            assert resp.status == 200\n            assert resp.connection is not None\n        assert resp.connection is None\n        assert proto.close.called\n\n        await resp.release()  # Trigger handler completion\n\n\nasync def test_iter_any(aiohttp_server: Any) -> None:\n    data = b\"0123456789\" * 1024\n\n    async def handler(request):\n        buf = []\n        async for raw in request.content.iter_any():\n            buf.append(raw)\n        assert b\"\".join(buf) == data\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"POST\", \"/\", handler)\n    server = await aiohttp_server(app)\n\n    async with aiohttp.ClientSession() as session:\n        async with session.post(server.make_url(\"/\"), data=data) as resp:\n            assert resp.status == 200\n\n\nasync def test_request_tracing(aiohttp_server: Any) -> None:\n    on_request_start = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_request_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_dns_resolvehost_start = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_dns_resolvehost_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_request_redirect = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_connection_create_start = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_connection_create_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n\n    async def redirector(request):\n        raise web.HTTPFound(location=URL(\"/redirected\"))\n\n    async def redirected(request):\n        return web.Response()\n\n    trace_config = TraceConfig()\n\n    trace_config.on_request_start.append(on_request_start)\n    trace_config.on_request_end.append(on_request_end)\n    trace_config.on_request_redirect.append(on_request_redirect)\n    trace_config.on_connection_create_start.append(on_connection_create_start)\n    trace_config.on_connection_create_end.append(on_connection_create_end)\n    trace_config.on_dns_resolvehost_start.append(on_dns_resolvehost_start)\n    trace_config.on_dns_resolvehost_end.append(on_dns_resolvehost_end)\n\n    app = web.Application()\n    app.router.add_get(\"/redirector\", redirector)\n    app.router.add_get(\"/redirected\", redirected)\n    server = await aiohttp_server(app)\n\n    class FakeResolver:\n        _LOCAL_HOST = {0: \"127.0.0.1\", socket.AF_INET: \"127.0.0.1\"}\n\n        def __init__(self, fakes):\n            # fakes -- dns -> port dict\n            self._fakes = fakes\n            self._resolver = aiohttp.DefaultResolver()\n\n        async def resolve(self, host, port=0, family=socket.AF_INET):\n            fake_port = self._fakes.get(host)\n            if fake_port is not None:\n                return [\n                    {\n                        \"hostname\": host,\n                        \"host\": self._LOCAL_HOST[family],\n                        \"port\": fake_port,\n                        \"family\": socket.AF_INET,\n                        \"proto\": 0,\n                        \"flags\": socket.AI_NUMERICHOST,\n                    }\n                ]\n            else:\n                return await self._resolver.resolve(host, port, family)\n\n    resolver = FakeResolver({\"example.com\": server.port})\n    connector = aiohttp.TCPConnector(resolver=resolver)\n    client = aiohttp.ClientSession(connector=connector, trace_configs=[trace_config])\n\n    resp = await client.get(\"http://example.com/redirector\", data=\"foo\")\n\n    assert on_request_start.called\n    assert on_request_end.called\n    assert on_dns_resolvehost_start.called\n    assert on_dns_resolvehost_end.called\n    assert on_request_redirect.called\n    assert on_connection_create_start.called\n    assert on_connection_create_end.called\n\n    await resp.release()\n    await client.close()\n\n\nasync def test_raise_http_exception(aiohttp_client: Any) -> None:\n    async def handler(request):\n        raise web.HTTPForbidden()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 403\n    await resp.release()\n\n\nasync def test_request_path(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.path_qs == \"/path%20to?a=1\"\n        assert request.path == \"/path to\"\n        assert request.raw_path == \"/path%20to?a=1\"\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_get(\"/path to\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/path to\", params={\"a\": \"1\"})\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert \"OK\" == txt\n    await resp.release()\n\n\nasync def test_app_add_routes(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.add_routes([web.get(\"/get\", handler)])\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/get\")\n    assert resp.status == 200\n    await resp.release()\n\n\nasync def test_request_headers_type(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert isinstance(request.headers, CIMultiDictProxy)\n        return web.Response()\n\n    app = web.Application()\n    app.add_routes([web.get(\"/get\", handler)])\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/get\")\n    assert resp.status == 200\n    await resp.release()\n\n\nasync def test_signal_on_error_handler(aiohttp_client: Any) -> None:\n    async def on_prepare(request, response):\n        response.headers[\"X-Custom\"] = \"val\"\n\n    app = web.Application()\n    app.on_response_prepare.append(on_prepare)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/\")\n    assert resp.status == 404\n    assert resp.headers[\"X-Custom\"] == \"val\"\n    await resp.release()\n\n\n@pytest.mark.skipif(\n    \"HttpRequestParserC\" not in dir(aiohttp.http_parser),\n    reason=\"C based HTTP parser not available\",\n)\nasync def test_bad_method_for_c_http_parser_not_hangs(aiohttp_client: Any) -> None:\n    app = web.Application()\n    timeout = aiohttp.ClientTimeout(sock_read=0.2)\n    client = await aiohttp_client(app, timeout=timeout)\n    resp = await client.request(\"GET1\", \"/\")\n    assert 400 == resp.status\n\n\nasync def test_read_bufsize(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ret = request.content.get_read_buffer_limits()\n        data = await request.text()  # read posted data\n        return web.Response(text=f\"{data} {ret!r}\")\n\n    app = web.Application(handler_args={\"read_bufsize\": 2})\n    app.router.add_post(\"/\", handler)\n\n    client = await aiohttp_client(app)\n    resp = await client.post(\"/\", data=b\"data\")\n    assert resp.status == 200\n    assert await resp.text() == \"data (2, 4)\"\n    await resp.release()\n\n\n@pytest.mark.parametrize(\n    \"auto_decompress,len_of\", [(True, \"uncompressed\"), (False, \"compressed\")]\n)\nasync def test_auto_decompress(\n    aiohttp_client: Any,\n    auto_decompress: bool,\n    len_of: str,\n) -> None:\n    async def handler(request):\n        data = await request.read()\n        return web.Response(text=str(len(data)))\n\n    app = web.Application(handler_args={\"auto_decompress\": auto_decompress})\n    app.router.add_post(\"/\", handler)\n\n    client = await aiohttp_client(app)\n    uncompressed = b\"dataaaaaaaaaaaaaaaaaaaaaaaaa\"\n    compressor = zlib.compressobj(wbits=16 + zlib.MAX_WBITS)\n    compressed = compressor.compress(uncompressed) + compressor.flush()\n    assert len(compressed) != len(uncompressed)\n    headers = {\"content-encoding\": \"gzip\"}\n    resp = await client.post(\"/\", data=compressed, headers=headers)\n    assert resp.status == 200\n    assert await resp.text() == str(len(locals()[len_of]))\n    await resp.release()\n\n\n@pytest.mark.parametrize(\n    \"status\",\n    [101, 204],\n)\nasync def test_response_101_204_no_content_length_http11(\n    status: Any, aiohttp_client: Any\n) -> None:\n    async def handler(_):\n        return web.Response(status=status)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, version=\"1.1\")\n    resp = await client.get(\"/\")\n    assert CONTENT_LENGTH not in resp.headers\n    assert TRANSFER_ENCODING not in resp.headers\n    await resp.release()\n\n\nasync def test_stream_response_headers_204(aiohttp_client: Any):\n    async def handler(_):\n        return web.StreamResponse(status=204)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/\")\n    assert CONTENT_TYPE not in resp.headers\n    assert TRANSFER_ENCODING not in resp.headers\n    await resp.release()\n\n\nasync def test_httpfound_cookies_302(aiohttp_client: Any) -> None:\n    async def handler(_):\n        resp = web.HTTPFound(\"/\")\n        resp.set_cookie(\"my-cookie\", \"cookie-value\")\n        raise resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\", allow_redirects=False)\n    assert \"my-cookie\" in resp.cookies\n    await resp.release()\n\n\n@pytest.mark.parametrize(\"status\", (101, 204, 304))\n@pytest.mark.parametrize(\"version\", (HttpVersion10, HttpVersion11))\nasync def test_no_body_for_1xx_204_304_responses(\n    aiohttp_client: Any, status: int, version: HttpVersion\n) -> None:\n    \"\"\"Test no body is present for for 1xx, 204, and 304 responses.\"\"\"\n\n    async def handler(_):\n        return web.Response(status=status, body=b\"should not get to client\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, version=version)\n    resp = await client.get(\"/\")\n    assert CONTENT_TYPE not in resp.headers\n    assert TRANSFER_ENCODING not in resp.headers\n    await resp.read() == b\"\"\n    await resp.release()\n", "tests/test_web_log.py": "# type: ignore\nimport datetime\nimport logging\nimport platform\nimport sys\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\n\nimport aiohttp\nfrom aiohttp import web\nfrom aiohttp.abc import AbstractAccessLogger, AbstractAsyncAccessLogger\nfrom aiohttp.typedefs import Handler\nfrom aiohttp.web_log import AccessLogger\nfrom aiohttp.web_response import Response\n\ntry:\n    from contextvars import ContextVar\nexcept ImportError:\n    ContextVar = None\n\nIS_PYPY: Any = platform.python_implementation() == \"PyPy\"\n\n\ndef test_access_logger_format() -> None:\n    log_format = '%T \"%{ETag}o\" %X {X} %%P'\n    mock_logger = mock.Mock()\n    access_logger = AccessLogger(mock_logger, log_format)\n    expected = '%s \"%s\" %%X {X} %%%s'\n    assert expected == access_logger._log_format\n\n\n@pytest.mark.skipif(\n    IS_PYPY,\n    reason=\"\"\"\n    Because of patching :py:class:`datetime.datetime`, under PyPy it\n    fails in :py:func:`isinstance` call in\n    :py:meth:`datetime.datetime.__sub__` (called from\n    :py:meth:`aiohttp.AccessLogger._format_t`):\n\n    *** TypeError: isinstance() arg 2 must be a class, type, or tuple of classes and types\n\n    (Pdb) from datetime import datetime\n    (Pdb) isinstance(now, datetime)\n    *** TypeError: isinstance() arg 2 must be a class, type, or tuple of classes and types\n    (Pdb) datetime.__class__\n    <class 'unittest.mock.MagicMock'>\n    (Pdb) isinstance(now, datetime.__class__)\n    False\n\n    Ref: https://bitbucket.org/pypy/pypy/issues/1187/call-to-isinstance-in-__sub__-self-other\n    Ref: https://github.com/celery/celery/issues/811\n    Ref: https://stackoverflow.com/a/46102240/595220\n    \"\"\",\n)\n@pytest.mark.parametrize(\n    \"log_format,expected,extra\",\n    [\n        (\n            \"%t\",\n            \"[01/Jan/1843:00:29:56 +0800]\",\n            {\"request_start_time\": \"[01/Jan/1843:00:29:56 +0800]\"},\n        ),\n        (\n            '%a %t %P %r %s %b %T %Tf %D \"%{H1}i\" \"%{H2}i\"',\n            (\n                \"127.0.0.2 [01/Jan/1843:00:29:56 +0800] <42> \"\n                'GET /path HTTP/1.1 200 42 3 3.141593 3141593 \"a\" \"b\"'\n            ),\n            {\n                \"first_request_line\": \"GET /path HTTP/1.1\",\n                \"process_id\": \"<42>\",\n                \"remote_address\": \"127.0.0.2\",\n                \"request_start_time\": \"[01/Jan/1843:00:29:56 +0800]\",\n                \"request_time\": \"3\",\n                \"request_time_frac\": \"3.141593\",\n                \"request_time_micro\": \"3141593\",\n                \"response_size\": 42,\n                \"response_status\": 200,\n                \"request_header\": {\"H1\": \"a\", \"H2\": \"b\"},\n            },\n        ),\n    ],\n)\ndef test_access_logger_atoms(\n    monkeypatch: Any, log_format: Any, expected: Any, extra: Any\n) -> None:\n    class PatchedDatetime(datetime.datetime):\n        @staticmethod\n        def now(tz):\n            return datetime.datetime(1843, 1, 1, 0, 30, tzinfo=tz)\n\n    monkeypatch.setattr(\"datetime.datetime\", PatchedDatetime)\n    monkeypatch.setattr(\"time.timezone\", -28800)\n    monkeypatch.setattr(\"os.getpid\", lambda: 42)\n    mock_logger = mock.Mock()\n    access_logger = AccessLogger(mock_logger, log_format)\n    request = mock.Mock(\n        headers={\"H1\": \"a\", \"H2\": \"b\"},\n        method=\"GET\",\n        path_qs=\"/path\",\n        version=aiohttp.HttpVersion(1, 1),\n        remote=\"127.0.0.2\",\n    )\n    response = mock.Mock(headers={}, body_length=42, status=200)\n    access_logger.log(request, response, 3.1415926)\n    assert not mock_logger.exception.called, mock_logger.exception.call_args\n\n    mock_logger.info.assert_called_with(expected, extra=extra)\n\n\ndef test_access_logger_dicts() -> None:\n    log_format = \"%{User-Agent}i %{Content-Length}o %{None}i\"\n    mock_logger = mock.Mock()\n    access_logger = AccessLogger(mock_logger, log_format)\n    request = mock.Mock(\n        headers={\"User-Agent\": \"Mock/1.0\"}, version=(1, 1), remote=\"127.0.0.2\"\n    )\n    response = mock.Mock(headers={\"Content-Length\": 123})\n    access_logger.log(request, response, 0.0)\n    assert not mock_logger.error.called\n    expected = \"Mock/1.0 123 -\"\n    extra = {\n        \"request_header\": {\"User-Agent\": \"Mock/1.0\", \"None\": \"-\"},\n        \"response_header\": {\"Content-Length\": 123},\n    }\n\n    mock_logger.info.assert_called_with(expected, extra=extra)\n\n\ndef test_access_logger_unix_socket() -> None:\n    log_format = \"|%a|\"\n    mock_logger = mock.Mock()\n    access_logger = AccessLogger(mock_logger, log_format)\n    request = mock.Mock(headers={\"User-Agent\": \"Mock/1.0\"}, version=(1, 1), remote=\"\")\n    response = mock.Mock()\n    access_logger.log(request, response, 0.0)\n    assert not mock_logger.error.called\n    expected = \"||\"\n    mock_logger.info.assert_called_with(expected, extra={\"remote_address\": \"\"})\n\n\ndef test_logger_no_message() -> None:\n    mock_logger = mock.Mock()\n    access_logger = AccessLogger(mock_logger, \"%r %{content-type}i\")\n    extra_dict = {\n        \"first_request_line\": \"-\",\n        \"request_header\": {\"content-type\": \"(no headers)\"},\n    }\n\n    access_logger.log(None, None, 0.0)\n    mock_logger.info.assert_called_with(\"- (no headers)\", extra=extra_dict)\n\n\ndef test_logger_internal_error() -> None:\n    mock_logger = mock.Mock()\n    access_logger = AccessLogger(mock_logger, \"%D\")\n    access_logger.log(None, None, \"invalid\")\n    mock_logger.exception.assert_called_with(\"Error in logging\")\n\n\ndef test_logger_no_transport() -> None:\n    mock_logger = mock.Mock()\n    access_logger = AccessLogger(mock_logger, \"%a\")\n    access_logger.log(None, None, 0)\n    mock_logger.info.assert_called_with(\"-\", extra={\"remote_address\": \"-\"})\n\n\ndef test_logger_abc() -> None:\n    class Logger(AbstractAccessLogger):\n        def log(self, request, response, time):\n            1 / 0\n\n    mock_logger = mock.Mock()\n    access_logger = Logger(mock_logger, None)\n\n    with pytest.raises(ZeroDivisionError):\n        access_logger.log(None, None, None)\n\n    class Logger(AbstractAccessLogger):\n        def log(self, request, response, time):\n            self.logger.info(\n                self.log_format.format(request=request, response=response, time=time)\n            )\n\n    mock_logger = mock.Mock()\n    access_logger = Logger(mock_logger, \"{request} {response} {time}\")\n    access_logger.log(\"request\", \"response\", 1)\n    mock_logger.info.assert_called_with(\"request response 1\")\n\n\nasync def test_exc_info_context(aiohttp_raw_server: Any, aiohttp_client: Any) -> None:\n    exc_msg = None\n\n    class Logger(AbstractAccessLogger):\n        def log(self, request, response, time):\n            nonlocal exc_msg\n            exc_msg = \"{0.__name__}: {1}\".format(*sys.exc_info())\n\n    async def handler(request):\n        raise RuntimeError(\"intentional runtime error\")\n\n    logger = mock.Mock()\n    server = await aiohttp_raw_server(handler, access_log_class=Logger, logger=logger)\n    cli = await aiohttp_client(server)\n    resp = await cli.get(\"/path/to\", headers={\"Accept\": \"text/html\"})\n    assert resp.status == 500\n    assert exc_msg == \"RuntimeError: intentional runtime error\"\n\n\nasync def test_async_logger(aiohttp_raw_server: Any, aiohttp_client: Any):\n    msg = None\n\n    class Logger(AbstractAsyncAccessLogger):\n        async def log(self, request, response, time):\n            nonlocal msg\n            msg = f\"{request.path}: {response.status}\"\n\n    async def handler(request):\n        return Response(text=\"ok\")\n\n    logger = mock.Mock()\n    server = await aiohttp_raw_server(handler, access_log_class=Logger, logger=logger)\n    cli = await aiohttp_client(server)\n    resp = await cli.get(\"/path/to\", headers={\"Accept\": \"text/html\"})\n    assert resp.status == 200\n    assert msg == \"/path/to: 200\"\n\n\nasync def test_contextvars_logger(aiohttp_server: Any, aiohttp_client: Any):\n    VAR = ContextVar(\"VAR\")\n\n    async def handler(request):\n        return web.Response()\n\n    async def middleware(request, handler: Handler):\n        VAR.set(\"uuid\")\n        return await handler(request)\n\n    msg = None\n\n    class Logger(AbstractAccessLogger):\n        def log(self, request, response, time):\n            nonlocal msg\n            msg = f\"contextvars: {VAR.get()}\"\n\n    app = web.Application(middlewares=[middleware])\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app, access_log_class=Logger)\n    client = await aiohttp_client(server)\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    assert msg == \"contextvars: uuid\"\n\n\ndef test_logger_does_nothing_when_disabled(caplog: pytest.LogCaptureFixture) -> None:\n    \"\"\"Test that the logger does nothing when the log level is disabled.\"\"\"\n    mock_logger = logging.getLogger(\"test.aiohttp.log\")\n    mock_logger.setLevel(logging.INFO)\n    access_logger = AccessLogger(mock_logger, \"%b\")\n    access_logger.log(\n        mock.Mock(name=\"mock_request\"), mock.Mock(name=\"mock_response\"), 42\n    )\n    assert \"mock_response\" in caplog.text\n", "tests/test_streams.py": "# type: ignore\n# Tests for streams.py\n\nimport abc\nimport asyncio\nimport gc\nimport types\nfrom collections import defaultdict\nfrom itertools import groupby\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\nfrom re_assert import Matches\n\nfrom aiohttp import streams\n\nDATA: bytes = b\"line1\\nline2\\nline3\\n\"\n\n\ndef chunkify(seq: Any, n: Any) -> None:\n    for i in range(0, len(seq), n):\n        yield seq[i : i + n]\n\n\nasync def create_stream():\n    loop = asyncio.get_event_loop()\n    protocol = mock.Mock(_reading_paused=False)\n    stream = streams.StreamReader(protocol, 2**16, loop=loop)\n    stream.feed_data(DATA)\n    stream.feed_eof()\n    return stream\n\n\n@pytest.fixture\ndef protocol():\n    return mock.Mock(_reading_paused=False)\n\n\nMEMLEAK_SKIP_TYPES: Any = (\n    *(getattr(types, name) for name in dir(types) if name.endswith(\"Type\")),\n    mock.Mock,\n    abc.ABCMeta,\n)\n\n\ndef get_memory_usage(obj: Any):\n    objs = [obj]\n    # Memory leak may be caused by leaked links to same objects.\n    # Without link counting, [1,2,3] is indistinguishable from [1,2,3,3,3,3,3,3]\n    known = defaultdict(int)\n    known[id(obj)] += 1\n\n    while objs:\n        refs = gc.get_referents(*objs)\n        objs = []\n        for obj in refs:\n            if isinstance(obj, MEMLEAK_SKIP_TYPES):\n                continue\n            i = id(obj)\n            known[i] += 1\n            if known[i] == 1:\n                objs.append(obj)\n\n        # Make list of unhashable objects uniq\n        objs.sort(key=id)\n        objs = [next(g) for (i, g) in groupby(objs, id)]\n\n    return sum(known.values())\n\n\nclass TestStreamReader:\n    DATA: bytes = b\"line1\\nline2\\nline3\\n\"\n\n    def _make_one(self, *args, **kwargs) -> streams.StreamReader:\n        loop = asyncio.get_event_loop()\n        kwargs.setdefault(\"limit\", 2**16)\n        kwargs.setdefault(\"loop\", loop)\n        return streams.StreamReader(mock.Mock(_reading_paused=False), *args, **kwargs)\n\n    async def test_create_waiter(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n        stream._waiter = loop.create_future\n        with pytest.raises(RuntimeError):\n            await stream._wait(\"test\")\n\n    async def test_at_eof(self) -> None:\n        stream = self._make_one()\n        assert not stream.at_eof()\n\n        stream.feed_data(b\"some data\\n\")\n        assert not stream.at_eof()\n\n        await stream.readline()\n        assert not stream.at_eof()\n\n        stream.feed_data(b\"some data\\n\")\n        stream.feed_eof()\n        await stream.readline()\n        assert stream.at_eof()\n\n    async def test_wait_eof(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n        wait_task = loop.create_task(stream.wait_eof())\n\n        async def cb() -> None:\n            await asyncio.sleep(0.1)\n            stream.feed_eof()\n\n        loop.create_task(cb())\n        await wait_task\n        assert stream.is_eof()\n        assert stream._eof_waiter is None\n\n    async def test_wait_eof_eof(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n        stream.feed_eof()\n\n        wait_task = loop.create_task(stream.wait_eof())\n        await wait_task\n        assert stream.is_eof()\n\n    async def test_feed_empty_data(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"\")\n        stream.feed_eof()\n\n        data = await stream.read()\n        assert b\"\" == data\n\n    async def test_feed_nonempty_data(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(self.DATA)\n        stream.feed_eof()\n\n        data = await stream.read()\n        assert self.DATA == data\n\n    async def test_read_zero(self) -> None:\n        # Read zero bytes.\n        stream = self._make_one()\n        stream.feed_data(self.DATA)\n\n        data = await stream.read(0)\n        assert b\"\" == data\n\n        stream.feed_eof()\n        data = await stream.read()\n        assert self.DATA == data\n\n    async def test_read(self) -> None:\n        loop = asyncio.get_event_loop()\n        # Read bytes.\n        stream = self._make_one()\n        read_task = loop.create_task(stream.read(30))\n\n        def cb():\n            stream.feed_data(self.DATA)\n\n        loop.call_soon(cb)\n\n        data = await read_task\n        assert self.DATA == data\n\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\"\" == data\n\n    async def test_read_line_breaks(self) -> None:\n        # Read bytes without line breaks.\n        stream = self._make_one()\n        stream.feed_data(b\"line1\")\n        stream.feed_data(b\"line2\")\n\n        data = await stream.read(5)\n        assert b\"line1\" == data\n\n        data = await stream.read(5)\n        assert b\"line2\" == data\n\n    async def test_read_all(self) -> None:\n        # Read all available buffered bytes\n        stream = self._make_one()\n        stream.feed_data(b\"line1\")\n        stream.feed_data(b\"line2\")\n        stream.feed_eof()\n\n        data = await stream.read()\n        assert b\"line1line2\" == data\n\n    async def test_read_up_to(self) -> None:\n        # Read available buffered bytes up to requested amount\n        stream = self._make_one()\n        stream.feed_data(b\"line1\")\n        stream.feed_data(b\"line2\")\n\n        data = await stream.read(8)\n        assert b\"line1lin\" == data\n\n        data = await stream.read(8)\n        assert b\"e2\" == data\n\n    async def test_read_eof(self) -> None:\n        loop = asyncio.get_event_loop()\n        # Read bytes, stop at eof.\n        stream = self._make_one()\n        read_task = loop.create_task(stream.read(1024))\n\n        def cb():\n            stream.feed_eof()\n\n        loop.call_soon(cb)\n\n        data = await read_task\n        assert b\"\" == data\n\n        data = await stream.read()\n        assert data == b\"\"\n\n    async def test_read_eof_unread_data_no_warning(self) -> None:\n        # Read bytes.\n        stream = self._make_one()\n        stream.feed_eof()\n\n        with mock.patch(\"aiohttp.streams.internal_logger\") as internal_logger:\n            await stream.read()\n            await stream.read()\n            await stream.read()\n            await stream.read()\n            await stream.read()\n        with pytest.deprecated_call(\n            match=r\"^unread_data\\(\\) is deprecated and will be \"\n            r\"removed in future releases \\(#3260\\)$\",\n        ):\n            stream.unread_data(b\"data\")\n        await stream.read()\n        await stream.read()\n        assert not internal_logger.warning.called\n\n    async def test_read_until_eof(self) -> None:\n        loop = asyncio.get_event_loop()\n        # Read all bytes until eof.\n        stream = self._make_one()\n        read_task = loop.create_task(stream.read(-1))\n\n        def cb():\n            stream.feed_data(b\"chunk1\\n\")\n            stream.feed_data(b\"chunk2\")\n            stream.feed_eof()\n\n        loop.call_soon(cb)\n\n        data = await read_task\n        assert b\"chunk1\\nchunk2\" == data\n\n        data = await stream.read()\n        assert b\"\" == data\n\n    async def test_read_exception(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"line\\n\")\n\n        data = await stream.read(2)\n        assert b\"li\" == data\n\n        stream.set_exception(ValueError())\n        with pytest.raises(ValueError):\n            await stream.read(2)\n\n    async def test_readline(self) -> None:\n        loop = asyncio.get_event_loop()\n        # Read one line. 'readline' will need to wait for the data\n        # to come from 'cb'\n        stream = self._make_one()\n        stream.feed_data(b\"chunk1 \")\n        read_task = loop.create_task(stream.readline())\n\n        def cb():\n            stream.feed_data(b\"chunk2 \")\n            stream.feed_data(b\"chunk3 \")\n            stream.feed_data(b\"\\n chunk4\")\n\n        loop.call_soon(cb)\n\n        line = await read_task\n        assert b\"chunk1 chunk2 chunk3 \\n\" == line\n\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\" chunk4\" == data\n\n    async def test_readline_limit_with_existing_data(self) -> None:\n        # Read one line. The data is in StreamReader's buffer\n        # before the event loop is run.\n\n        stream = self._make_one(limit=2)\n        stream.feed_data(b\"li\")\n        stream.feed_data(b\"ne1\\nline2\\n\")\n\n        with pytest.raises(ValueError):\n            await stream.readline()\n        # The buffer should contain the remaining data after exception\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\"line2\\n\" == data\n\n    async def test_readline_limit(self) -> None:\n        loop = asyncio.get_event_loop()\n        # Read one line. StreamReaders are fed with data after\n        # their 'readline' methods are called.\n        stream = self._make_one(limit=4)\n\n        def cb():\n            stream.feed_data(b\"chunk1\")\n            stream.feed_data(b\"chunk2\\n\")\n            stream.feed_data(b\"chunk3\\n\")\n            stream.feed_eof()\n\n        loop.call_soon(cb)\n\n        with pytest.raises(ValueError):\n            await stream.readline()\n        data = await stream.read()\n        assert b\"chunk3\\n\" == data\n\n    async def test_readline_nolimit_nowait(self) -> None:\n        # All needed data for the first 'readline' call will be\n        # in the buffer.\n        stream = self._make_one()\n        stream.feed_data(self.DATA[:6])\n        stream.feed_data(self.DATA[6:])\n\n        line = await stream.readline()\n        assert b\"line1\\n\" == line\n\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\"line2\\nline3\\n\" == data\n\n    async def test_readline_eof(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"some data\")\n        stream.feed_eof()\n\n        line = await stream.readline()\n        assert b\"some data\" == line\n\n    async def test_readline_empty_eof(self) -> None:\n        stream = self._make_one()\n        stream.feed_eof()\n\n        line = await stream.readline()\n        assert b\"\" == line\n\n    async def test_readline_read_byte_count(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(self.DATA)\n\n        await stream.readline()\n\n        data = await stream.read(7)\n        assert b\"line2\\nl\" == data\n\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\"ine3\\n\" == data\n\n    async def test_readline_exception(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"line\\n\")\n\n        data = await stream.readline()\n        assert b\"line\\n\" == data\n\n        stream.set_exception(ValueError())\n        with pytest.raises(ValueError):\n            await stream.readline()\n\n    @pytest.mark.parametrize(\"separator\", [b\"*\", b\"**\"])\n    async def test_readuntil(self, separator: bytes) -> None:\n        loop = asyncio.get_event_loop()\n        # Read one chunk. 'readuntil' will need to wait for the data\n        # to come from 'cb'\n        stream = self._make_one()\n        stream.feed_data(b\"chunk1 \")\n        read_task = loop.create_task(stream.readuntil(separator))\n\n        def cb():\n            stream.feed_data(b\"chunk2 \")\n            stream.feed_data(b\"chunk3 \")\n            stream.feed_data(separator + b\" chunk4\")\n\n        loop.call_soon(cb)\n\n        line = await read_task\n        assert b\"chunk1 chunk2 chunk3 \" + separator == line\n\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\" chunk4\" == data\n\n    @pytest.mark.parametrize(\"separator\", [b\"&\", b\"&&\"])\n    async def test_readuntil_limit_with_existing_data(self, separator: bytes) -> None:\n        # Read one chunk. The data is in StreamReader's buffer\n        # before the event loop is run.\n\n        stream = self._make_one(limit=2)\n        stream.feed_data(b\"li\")\n        stream.feed_data(b\"ne1\" + separator + b\"line2\" + separator)\n\n        with pytest.raises(ValueError):\n            await stream.readuntil(separator)\n        # The buffer should contain the remaining data after exception\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\"line2\" + separator == data\n\n    @pytest.mark.parametrize(\"separator\", [b\"$\", b\"$$\"])\n    async def test_readuntil_limit(self, separator: bytes) -> None:\n        loop = asyncio.get_event_loop()\n        # Read one chunk. StreamReaders are fed with data after\n        # their 'readuntil' methods are called.\n        stream = self._make_one(limit=4)\n\n        def cb():\n            stream.feed_data(b\"chunk1\")\n            stream.feed_data(b\"chunk2\" + separator)\n            stream.feed_data(b\"chunk3#\")\n            stream.feed_eof()\n\n        loop.call_soon(cb)\n\n        with pytest.raises(ValueError, match=\"Chunk too big\"):\n            await stream.readuntil(separator)\n        data = await stream.read()\n        assert b\"chunk3#\" == data\n\n    @pytest.mark.parametrize(\"separator\", [b\"!\", b\"!!\"])\n    async def test_readuntil_nolimit_nowait(self, separator: bytes) -> None:\n        # All needed data for the first 'readuntil' call will be\n        # in the buffer.\n        seplen = len(separator)\n        stream = self._make_one()\n        data = b\"line1\" + separator + b\"line2\" + separator + b\"line3\" + separator\n        stream.feed_data(data[: 5 + seplen])\n        stream.feed_data(data[5 + seplen :])\n\n        line = await stream.readuntil(separator)\n        assert b\"line1\" + separator == line\n\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\"line2\" + separator + b\"line3\" + separator == data\n\n    @pytest.mark.parametrize(\"separator\", [b\"@\", b\"@@\"])\n    async def test_readuntil_eof(self, separator: bytes) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"some data\")\n        stream.feed_eof()\n\n        line = await stream.readuntil(separator)\n        assert b\"some data\" == line\n\n    @pytest.mark.parametrize(\"separator\", [b\"@\", b\"@@\"])\n    async def test_readuntil_empty_eof(self, separator: bytes) -> None:\n        stream = self._make_one()\n        stream.feed_eof()\n\n        line = await stream.readuntil(separator)\n        assert b\"\" == line\n\n    @pytest.mark.parametrize(\"separator\", [b\"!\", b\"!!\"])\n    async def test_readuntil_read_byte_count(self, separator: bytes) -> None:\n        seplen = len(separator)\n        stream = self._make_one()\n        stream.feed_data(\n            b\"line1\" + separator + b\"line2\" + separator + b\"line3\" + separator\n        )\n\n        await stream.readuntil(separator)\n\n        data = await stream.read(6 + seplen)\n        assert b\"line2\" + separator + b\"l\" == data\n\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\"ine3\" + separator == data\n\n    @pytest.mark.parametrize(\"separator\", [b\"#\", b\"##\"])\n    async def test_readuntil_exception(self, separator: bytes) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"line\" + separator)\n\n        data = await stream.readuntil(separator)\n        assert b\"line\" + separator == data\n\n        stream.set_exception(ValueError(\"Another exception\"))\n        with pytest.raises(ValueError, match=\"Another exception\"):\n            await stream.readuntil(separator)\n\n    async def test_readexactly_zero_or_less(self) -> None:\n        # Read exact number of bytes (zero or less).\n        stream = self._make_one()\n        stream.feed_data(self.DATA)\n\n        data = await stream.readexactly(0)\n        assert b\"\" == data\n        stream.feed_eof()\n        data = await stream.read()\n        assert self.DATA == data\n\n        stream = self._make_one()\n        stream.feed_data(self.DATA)\n\n        data = await stream.readexactly(-1)\n        assert b\"\" == data\n        stream.feed_eof()\n        data = await stream.read()\n        assert self.DATA == data\n\n    async def test_readexactly(self) -> None:\n        loop = asyncio.get_event_loop()\n        # Read exact number of bytes.\n        stream = self._make_one()\n\n        n = 2 * len(self.DATA)\n        read_task = loop.create_task(stream.readexactly(n))\n\n        def cb():\n            stream.feed_data(self.DATA)\n            stream.feed_data(self.DATA)\n            stream.feed_data(self.DATA)\n\n        loop.call_soon(cb)\n\n        data = await read_task\n        assert self.DATA + self.DATA == data\n\n        stream.feed_eof()\n        data = await stream.read()\n        assert self.DATA == data\n\n    async def test_readexactly_eof(self) -> None:\n        loop = asyncio.get_event_loop()\n        # Read exact number of bytes (eof).\n        stream = self._make_one()\n        n = 2 * len(self.DATA)\n        read_task = loop.create_task(stream.readexactly(n))\n\n        def cb():\n            stream.feed_data(self.DATA)\n            stream.feed_eof()\n\n        loop.call_soon(cb)\n\n        with pytest.raises(asyncio.IncompleteReadError) as cm:\n            await read_task\n        assert cm.value.partial == self.DATA\n        assert cm.value.expected == n\n        assert str(cm.value) == \"18 bytes read on a total of 36 expected bytes\"\n        data = await stream.read()\n        assert b\"\" == data\n\n    async def test_readexactly_exception(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"line\\n\")\n\n        data = await stream.readexactly(2)\n        assert b\"li\" == data\n\n        stream.set_exception(ValueError())\n        with pytest.raises(ValueError):\n            await stream.readexactly(2)\n\n    async def test_unread_data(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"line1\")\n        stream.feed_data(b\"line2\")\n        stream.feed_data(b\"onemoreline\")\n\n        data = await stream.read(5)\n        assert b\"line1\" == data\n\n        with pytest.deprecated_call(\n            match=r\"^unread_data\\(\\) is deprecated and will be \"\n            r\"removed in future releases \\(#3260\\)$\",\n        ):\n            stream.unread_data(data)\n\n        data = await stream.read(5)\n        assert b\"line1\" == data\n\n        data = await stream.read(4)\n        assert b\"line\" == data\n\n        with pytest.deprecated_call(\n            match=r\"^unread_data\\(\\) is deprecated and will be \"\n            r\"removed in future releases \\(#3260\\)$\",\n        ):\n            stream.unread_data(b\"line1line\")\n\n        data = b\"\"\n        while len(data) < 10:\n            data += await stream.read(10)\n        assert b\"line1line2\" == data\n\n        data = await stream.read(7)\n        assert b\"onemore\" == data\n\n        with pytest.deprecated_call(\n            match=r\"^unread_data\\(\\) is deprecated and will be \"\n            r\"removed in future releases \\(#3260\\)$\",\n        ):\n            stream.unread_data(data)\n\n        data = b\"\"\n        while len(data) < 11:\n            data += await stream.read(11)\n        assert b\"onemoreline\" == data\n\n        with pytest.deprecated_call(\n            match=r\"^unread_data\\(\\) is deprecated and will be \"\n            r\"removed in future releases \\(#3260\\)$\",\n        ):\n            stream.unread_data(b\"line\")\n        data = await stream.read(4)\n        assert b\"line\" == data\n\n        stream.feed_eof()\n        with pytest.deprecated_call(\n            match=r\"^unread_data\\(\\) is deprecated and will be \"\n            r\"removed in future releases \\(#3260\\)$\",\n        ):\n            stream.unread_data(b\"at_eof\")\n        data = await stream.read(6)\n        assert b\"at_eof\" == data\n\n    async def test_exception(self) -> None:\n        stream = self._make_one()\n        assert stream.exception() is None\n\n        exc = ValueError()\n        stream.set_exception(exc)\n        assert stream.exception() is exc\n\n    async def test_exception_waiter(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n\n        async def set_err():\n            stream.set_exception(ValueError())\n\n        t1 = loop.create_task(stream.readline())\n        t2 = loop.create_task(set_err())\n\n        await asyncio.wait([t1, t2])\n        with pytest.raises(ValueError):\n            t1.result()\n\n    async def test_exception_cancel(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n\n        async def read_a_line():\n            await stream.readline()\n\n        t = loop.create_task(read_a_line())\n        await asyncio.sleep(0)\n        t.cancel()\n        await asyncio.sleep(0)\n        # The following line fails if set_exception() isn't careful.\n        stream.set_exception(RuntimeError(\"message\"))\n        await asyncio.sleep(0)\n        assert stream._waiter is None\n\n    async def test_readany_eof(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n        read_task = loop.create_task(stream.readany())\n        loop.call_soon(stream.feed_data, b\"chunk1\\n\")\n\n        data = await read_task\n        assert b\"chunk1\\n\" == data\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\"\" == data\n\n    async def test_readany_empty_eof(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n        stream.feed_eof()\n        read_task = loop.create_task(stream.readany())\n\n        data = await read_task\n\n        assert b\"\" == data\n\n    async def test_readany_exception(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"line\\n\")\n\n        data = await stream.readany()\n        assert b\"line\\n\" == data\n\n        stream.set_exception(ValueError())\n        with pytest.raises(ValueError):\n            await stream.readany()\n\n    async def test_read_nowait(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"line1\\nline2\\n\")\n\n        assert stream.read_nowait() == b\"line1\\nline2\\n\"\n        assert stream.read_nowait() == b\"\"\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\"\" == data\n\n    async def test_read_nowait_n(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"line1\\nline2\\n\")\n\n        assert stream.read_nowait(4) == b\"line\"\n        assert stream.read_nowait() == b\"1\\nline2\\n\"\n        assert stream.read_nowait() == b\"\"\n        stream.feed_eof()\n        data = await stream.read()\n        assert b\"\" == data\n\n    async def test_read_nowait_exception(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"line\\n\")\n        stream.set_exception(ValueError())\n\n        with pytest.raises(ValueError):\n            stream.read_nowait()\n\n    async def test_read_nowait_waiter(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n        stream.feed_data(b\"line\\n\")\n        stream._waiter = loop.create_future()\n\n        with pytest.raises(RuntimeError):\n            stream.read_nowait()\n\n    async def test_readchunk(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n\n        def cb():\n            stream.feed_data(b\"chunk1\")\n            stream.feed_data(b\"chunk2\")\n            stream.feed_eof()\n\n        loop.call_soon(cb)\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"chunk1\" == data\n        assert not end_of_chunk\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"chunk2\" == data\n        assert not end_of_chunk\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert not end_of_chunk\n\n    async def test_readchunk_wait_eof(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n\n        async def cb():\n            await asyncio.sleep(0.1)\n            stream.feed_eof()\n\n        loop.create_task(cb())\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert not end_of_chunk\n        assert stream.is_eof()\n\n    async def test_begin_and_end_chunk_receiving(self) -> None:\n        stream = self._make_one()\n\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part1\")\n        stream.feed_data(b\"part2\")\n        stream.end_http_chunk_receiving()\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"part1part2\" == data\n        assert end_of_chunk\n\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part3\")\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"part3\" == data\n        assert not end_of_chunk\n\n        stream.end_http_chunk_receiving()\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert end_of_chunk\n\n        stream.feed_eof()\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert not end_of_chunk\n\n    async def test_readany_chunk_end_race(self) -> None:\n        stream = self._make_one()\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part1\")\n\n        data = await stream.readany()\n        assert data == b\"part1\"\n\n        loop = asyncio.get_event_loop()\n        task = loop.create_task(stream.readany())\n\n        # Give a chance for task to create waiter and start waiting for it.\n        await asyncio.sleep(0.1)\n        assert stream._waiter is not None\n        assert not task.done()  # Just for sure.\n\n        # This will trigger waiter, but without feeding any data.\n        # The stream should re-create waiter again.\n        stream.end_http_chunk_receiving()\n\n        # Give a chance for task to resolve.\n        # If everything is OK, previous action SHOULD NOT resolve the task.\n        await asyncio.sleep(0.1)\n        assert not task.done()  # The actual test.\n\n        stream.begin_http_chunk_receiving()\n        # This SHOULD unblock the task actually.\n        stream.feed_data(b\"part2\")\n        stream.end_http_chunk_receiving()\n\n        data = await task\n        assert data == b\"part2\"\n\n    async def test_end_chunk_receiving_without_begin(self) -> None:\n        stream = self._make_one()\n        with pytest.raises(RuntimeError):\n            stream.end_http_chunk_receiving()\n\n    async def test_readchunk_with_unread(self) -> None:\n        # Test that stream.unread does not break controlled chunk receiving.\n        stream = self._make_one()\n\n        # Send 2 chunks\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part1\")\n        stream.end_http_chunk_receiving()\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part2\")\n        stream.end_http_chunk_receiving()\n\n        # Read only one chunk\n        data, end_of_chunk = await stream.readchunk()\n\n        # Try to unread a part of the first chunk\n        with pytest.deprecated_call(\n            match=r\"^unread_data\\(\\) is deprecated and will be \"\n            r\"removed in future releases \\(#3260\\)$\",\n        ):\n            stream.unread_data(b\"rt1\")\n\n        # The end_of_chunk signal was already received for the first chunk,\n        # so we receive up to the second one\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"rt1part2\" == data\n        assert end_of_chunk\n\n        # Unread a part of the second chunk\n        with pytest.deprecated_call(\n            match=r\"^unread_data\\(\\) is deprecated and will be \"\n            r\"removed in future releases \\(#3260\\)$\",\n        ):\n            stream.unread_data(b\"rt2\")\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"rt2\" == data\n        # end_of_chunk was already received for this chunk\n        assert not end_of_chunk\n\n        stream.feed_eof()\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert not end_of_chunk\n\n    async def test_readchunk_with_other_read_calls(self) -> None:\n        # Test that stream.readchunk works when other read calls are made on\n        # the stream.\n        stream = self._make_one()\n\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part1\")\n        stream.end_http_chunk_receiving()\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part2\")\n        stream.end_http_chunk_receiving()\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part3\")\n        stream.end_http_chunk_receiving()\n\n        data = await stream.read(7)\n        assert b\"part1pa\" == data\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"rt2\" == data\n        assert end_of_chunk\n\n        # Corner case between read/readchunk\n        data = await stream.read(5)\n        assert b\"part3\" == data\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert end_of_chunk\n\n        stream.feed_eof()\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert not end_of_chunk\n\n    async def test_chunksplits_memory_leak(self) -> None:\n        # Test for memory leak on chunksplits\n        stream = self._make_one()\n\n        N = 500\n\n        # Warm-up variables\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"Y\" * N)\n        stream.end_http_chunk_receiving()\n        await stream.read(N)\n\n        N = 300\n\n        before = get_memory_usage(stream)\n        for _ in range(N):\n            stream.begin_http_chunk_receiving()\n            stream.feed_data(b\"X\")\n            stream.end_http_chunk_receiving()\n        await stream.read(N)\n        after = get_memory_usage(stream)\n\n        assert abs(after - before) == 0\n\n    async def test_read_empty_chunks(self) -> None:\n        # Test that feeding empty chunks does not break stream\n        stream = self._make_one()\n\n        # Simulate empty first chunk. This is significant special case\n        stream.begin_http_chunk_receiving()\n        stream.end_http_chunk_receiving()\n\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"ungzipped\")\n        stream.end_http_chunk_receiving()\n\n        # Possible when compression is enabled.\n        stream.begin_http_chunk_receiving()\n        stream.end_http_chunk_receiving()\n\n        # is also possible\n        stream.begin_http_chunk_receiving()\n        stream.end_http_chunk_receiving()\n\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\" data\")\n        stream.end_http_chunk_receiving()\n\n        stream.feed_eof()\n\n        data = await stream.read()\n        assert data == b\"ungzipped data\"\n\n    async def test_readchunk_separate_http_chunk_tail(self) -> None:\n        # Test that stream.readchunk returns (b'', True) when end of\n        # http chunk received after body\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part1\")\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"part1\" == data\n        assert not end_of_chunk\n\n        async def cb():\n            await asyncio.sleep(0.1)\n            stream.end_http_chunk_receiving()\n\n        loop.create_task(cb())\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert end_of_chunk\n\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part2\")\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"part2\" == data\n        assert not end_of_chunk\n\n        stream.end_http_chunk_receiving()\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part3\")\n        stream.end_http_chunk_receiving()\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert end_of_chunk\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"part3\" == data\n        assert end_of_chunk\n\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(b\"part4\")\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"part4\" == data\n        assert not end_of_chunk\n\n        async def cb():\n            await asyncio.sleep(0.1)\n            stream.end_http_chunk_receiving()\n            stream.feed_eof()\n\n        loop.create_task(cb())\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert end_of_chunk\n\n        data, end_of_chunk = await stream.readchunk()\n        assert b\"\" == data\n        assert not end_of_chunk\n\n    async def test___repr__(self) -> None:\n        stream = self._make_one()\n        assert \"<StreamReader>\" == repr(stream)\n\n    async def test___repr__nondefault_limit(self) -> None:\n        stream = self._make_one(limit=123)\n        assert \"<StreamReader low=123 high=246>\" == repr(stream)\n\n    async def test___repr__eof(self) -> None:\n        stream = self._make_one()\n        stream.feed_eof()\n        assert \"<StreamReader eof>\" == repr(stream)\n\n    async def test___repr__data(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"data\")\n        assert \"<StreamReader 4 bytes>\" == repr(stream)\n\n    async def test___repr__exception(self) -> None:\n        stream = self._make_one()\n        exc = RuntimeError()\n        stream.set_exception(exc)\n        assert \"<StreamReader e=RuntimeError()>\" == repr(stream)\n\n    async def test___repr__waiter(self) -> None:\n        loop = asyncio.get_event_loop()\n        stream = self._make_one()\n        stream._waiter = loop.create_future()\n        assert Matches(r\"<StreamReader w=<Future pending[\\S ]*>>\") == repr(stream)\n        stream._waiter.set_result(None)\n        await stream._waiter\n        stream._waiter = None\n        assert \"<StreamReader>\" == repr(stream)\n\n    async def test_unread_empty(self) -> None:\n        stream = self._make_one()\n        stream.feed_data(b\"line1\")\n        stream.feed_eof()\n        with pytest.deprecated_call(\n            match=r\"^unread_data\\(\\) is deprecated and will be \"\n            r\"removed in future releases \\(#3260\\)$\",\n        ):\n            stream.unread_data(b\"\")\n\n        data = await stream.read(5)\n        assert b\"line1\" == data\n        assert stream.at_eof()\n\n\nasync def test_empty_stream_reader() -> None:\n    s = streams.EmptyStreamReader()\n    assert str(s) is not None\n    assert s.set_exception(ValueError()) is None\n    assert s.exception() is None\n    assert s.feed_eof() is None\n    assert s.feed_data(b\"data\") is None\n    assert s.at_eof()\n    assert (await s.wait_eof()) is None\n    assert await s.read() == b\"\"\n    assert await s.readline() == b\"\"\n    assert await s.readany() == b\"\"\n    assert await s.readchunk() == (b\"\", False)\n    assert await s.readchunk() == (b\"\", True)\n    with pytest.raises(asyncio.IncompleteReadError):\n        await s.readexactly(10)\n    assert s.read_nowait() == b\"\"\n\n\nasync def test_empty_stream_reader_iter_chunks() -> None:\n    s = streams.EmptyStreamReader()\n\n    # check that iter_chunks() does not cause infinite loop\n    iter_chunks = s.iter_chunks()\n    with pytest.raises(StopAsyncIteration):\n        await iter_chunks.__anext__()\n\n\n@pytest.fixture\nasync def buffer(loop: Any):\n    return streams.DataQueue(loop)\n\n\nclass TestDataQueue:\n    def test_is_eof(self, buffer: Any) -> None:\n        assert not buffer.is_eof()\n        buffer.feed_eof()\n        assert buffer.is_eof()\n\n    def test_at_eof(self, buffer: Any) -> None:\n        assert not buffer.at_eof()\n        buffer.feed_eof()\n        assert buffer.at_eof()\n        buffer._buffer.append(object())\n        assert not buffer.at_eof()\n\n    def test_feed_data(self, buffer: Any) -> None:\n        item = b\" \"\n        buffer.feed_data(item)\n        assert [item] == list(buffer._buffer)\n\n    def test_feed_eof(self, buffer: Any) -> None:\n        buffer.feed_eof()\n        assert buffer._eof\n\n    async def test_read(self, buffer: Any) -> None:\n        loop = asyncio.get_event_loop()\n        item = b\"\"\n\n        def cb():\n            buffer.feed_data(item)\n\n        loop.call_soon(cb)\n\n        data = await buffer.read()\n        assert item is data\n\n    async def test_read_eof(self, buffer: Any) -> None:\n        loop = asyncio.get_event_loop()\n\n        def cb():\n            buffer.feed_eof()\n\n        loop.call_soon(cb)\n\n        with pytest.raises(streams.EofStream):\n            await buffer.read()\n\n    async def test_read_cancelled(self, buffer: Any) -> None:\n        loop = asyncio.get_event_loop()\n        read_task = loop.create_task(buffer.read())\n        await asyncio.sleep(0)\n        waiter = buffer._waiter\n        assert asyncio.isfuture(waiter)\n\n        read_task.cancel()\n        with pytest.raises(asyncio.CancelledError):\n            await read_task\n        assert waiter.cancelled()\n        assert buffer._waiter is None\n\n        buffer.feed_data(b\"test\")\n        assert buffer._waiter is None\n\n    async def test_read_until_eof(self, buffer: Any) -> None:\n        item = \"\"\n        buffer.feed_data(item)\n        buffer.feed_eof()\n\n        data = await buffer.read()\n        assert data is item\n\n        with pytest.raises(streams.EofStream):\n            await buffer.read()\n\n    async def test_read_exc(self, buffer: Any) -> None:\n        item = \"\"\n        buffer.feed_data(item)\n        buffer.set_exception(ValueError)\n\n        data = await buffer.read()\n        assert item is data\n\n        with pytest.raises(ValueError):\n            await buffer.read()\n\n    async def test_read_exception(self, buffer: Any) -> None:\n        buffer.set_exception(ValueError())\n\n        with pytest.raises(ValueError):\n            await buffer.read()\n\n    async def test_read_exception_with_data(self, buffer: Any) -> None:\n        val = \"\"\n        buffer.feed_data(val)\n        buffer.set_exception(ValueError())\n\n        assert val is (await buffer.read())\n        with pytest.raises(ValueError):\n            await buffer.read()\n\n    async def test_read_exception_on_wait(self, buffer: Any) -> None:\n        loop = asyncio.get_event_loop()\n        read_task = loop.create_task(buffer.read())\n        await asyncio.sleep(0)\n        assert asyncio.isfuture(buffer._waiter)\n\n        buffer.feed_eof()\n        buffer.set_exception(ValueError())\n\n        with pytest.raises(ValueError):\n            await read_task\n\n    def test_exception(self, buffer: Any) -> None:\n        assert buffer.exception() is None\n\n        exc = ValueError()\n        buffer.set_exception(exc)\n        assert buffer.exception() is exc\n\n    async def test_exception_waiter(self, buffer: Any) -> None:\n        loop = asyncio.get_event_loop()\n\n        async def set_err():\n            buffer.set_exception(ValueError())\n\n        t1 = loop.create_task(buffer.read())\n        t2 = loop.create_task(set_err())\n\n        await asyncio.wait([t1, t2])\n\n        with pytest.raises(ValueError):\n            t1.result()\n\n\nasync def test_feed_data_waiters(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n    waiter = reader._waiter = loop.create_future()\n    eof_waiter = reader._eof_waiter = loop.create_future()\n\n    reader.feed_data(b\"1\")\n    assert list(reader._buffer) == [b\"1\"]\n    assert reader._size == 1\n    assert reader.total_bytes == 1\n\n    assert waiter.done()\n    assert not eof_waiter.done()\n    assert reader._waiter is None\n    assert reader._eof_waiter is eof_waiter\n\n\nasync def test_feed_data_completed_waiters(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n    waiter = reader._waiter = loop.create_future()\n\n    waiter.set_result(1)\n    reader.feed_data(b\"1\")\n\n    assert reader._waiter is None\n\n\nasync def test_feed_eof_waiters(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n    waiter = reader._waiter = loop.create_future()\n    eof_waiter = reader._eof_waiter = loop.create_future()\n\n    reader.feed_eof()\n    assert reader._eof\n\n    assert waiter.done()\n    assert eof_waiter.done()\n    assert reader._waiter is None\n    assert reader._eof_waiter is None\n\n\nasync def test_feed_eof_cancelled(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n    waiter = reader._waiter = loop.create_future()\n    eof_waiter = reader._eof_waiter = loop.create_future()\n\n    waiter.set_result(1)\n    eof_waiter.set_result(1)\n\n    reader.feed_eof()\n\n    assert waiter.done()\n    assert eof_waiter.done()\n    assert reader._waiter is None\n    assert reader._eof_waiter is None\n\n\nasync def test_on_eof(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n\n    on_eof = mock.Mock()\n    reader.on_eof(on_eof)\n\n    assert not on_eof.called\n    reader.feed_eof()\n    assert on_eof.called\n\n\nasync def test_on_eof_empty_reader() -> None:\n    reader = streams.EmptyStreamReader()\n\n    on_eof = mock.Mock()\n    reader.on_eof(on_eof)\n\n    assert on_eof.called\n\n\nasync def test_on_eof_exc_in_callback(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n\n    on_eof = mock.Mock()\n    on_eof.side_effect = ValueError\n\n    reader.on_eof(on_eof)\n    assert not on_eof.called\n    reader.feed_eof()\n    assert on_eof.called\n    assert not reader._eof_callbacks\n\n\nasync def test_on_eof_exc_in_callback_empty_stream_reader() -> None:\n    reader = streams.EmptyStreamReader()\n\n    on_eof = mock.Mock()\n    on_eof.side_effect = ValueError\n\n    reader.on_eof(on_eof)\n    assert on_eof.called\n\n\nasync def test_on_eof_eof_is_set(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n    reader.feed_eof()\n\n    on_eof = mock.Mock()\n    reader.on_eof(on_eof)\n    assert on_eof.called\n    assert not reader._eof_callbacks\n\n\nasync def test_on_eof_eof_is_set_exception(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n    reader.feed_eof()\n\n    on_eof = mock.Mock()\n    on_eof.side_effect = ValueError\n\n    reader.on_eof(on_eof)\n    assert on_eof.called\n    assert not reader._eof_callbacks\n\n\nasync def test_set_exception(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n    waiter = reader._waiter = loop.create_future()\n    eof_waiter = reader._eof_waiter = loop.create_future()\n\n    exc = ValueError()\n    reader.set_exception(exc)\n\n    assert waiter.exception() is exc\n    assert eof_waiter.exception() is exc\n    assert reader._waiter is None\n    assert reader._eof_waiter is None\n\n\nasync def test_set_exception_cancelled(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n    waiter = reader._waiter = loop.create_future()\n    eof_waiter = reader._eof_waiter = loop.create_future()\n\n    waiter.set_result(1)\n    eof_waiter.set_result(1)\n\n    exc = ValueError()\n    reader.set_exception(exc)\n\n    assert waiter.exception() is None\n    assert eof_waiter.exception() is None\n    assert reader._waiter is None\n    assert reader._eof_waiter is None\n\n\nasync def test_set_exception_eof_callbacks(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    reader = streams.StreamReader(protocol, 2**16, loop=loop)\n\n    on_eof = mock.Mock()\n    reader.on_eof(on_eof)\n\n    reader.set_exception(ValueError())\n    assert not on_eof.called\n    assert not reader._eof_callbacks\n\n\nasync def test_stream_reader_lines() -> None:\n    line_iter = iter(DATA.splitlines(keepends=True))\n    async for line in await create_stream():\n        assert line == next(line_iter, None)\n    pytest.raises(StopIteration, next, line_iter)\n\n\nasync def test_stream_reader_chunks_complete() -> None:\n    # Tests if chunked iteration works if the chunking works out\n    # (i.e. the data is divisible by the chunk size)\n    chunk_iter = chunkify(DATA, 9)\n    async for data in (await create_stream()).iter_chunked(9):\n        assert data == next(chunk_iter, None)\n    pytest.raises(StopIteration, next, chunk_iter)\n\n\nasync def test_stream_reader_chunks_incomplete() -> None:\n    # Tests if chunked iteration works if the last chunk is incomplete\n    chunk_iter = chunkify(DATA, 8)\n    async for data in (await create_stream()).iter_chunked(8):\n        assert data == next(chunk_iter, None)\n    pytest.raises(StopIteration, next, chunk_iter)\n\n\nasync def test_data_queue_empty() -> None:\n    # Tests that async looping yields nothing if nothing is there\n    loop = asyncio.get_event_loop()\n    buffer = streams.DataQueue(loop)\n    buffer.feed_eof()\n\n    async for _ in buffer:\n        assert False\n\n\nasync def test_data_queue_items() -> None:\n    # Tests that async looping yields objects identically\n    loop = asyncio.get_event_loop()\n    buffer = streams.DataQueue(loop)\n\n    items = [\"a\", \"b\"]\n    buffer.feed_data(items[0])\n    buffer.feed_data(items[1])\n    buffer.feed_eof()\n\n    item_iter = iter(items)\n    async for item in buffer:\n        assert item is next(item_iter, None)\n    pytest.raises(StopIteration, next, item_iter)\n\n\nasync def test_stream_reader_iter_any() -> None:\n    it = iter([b\"line1\\nline2\\nline3\\n\"])\n    async for raw in (await create_stream()).iter_any():\n        assert raw == next(it)\n    pytest.raises(StopIteration, next, it)\n\n\nasync def test_stream_reader_iter() -> None:\n    it = iter([b\"line1\\n\", b\"line2\\n\", b\"line3\\n\"])\n    async for raw in await create_stream():\n        assert raw == next(it)\n    pytest.raises(StopIteration, next, it)\n\n\nasync def test_stream_reader_iter_chunks_no_chunked_encoding() -> None:\n    it = iter([b\"line1\\nline2\\nline3\\n\"])\n    async for data, end_of_chunk in (await create_stream()).iter_chunks():\n        assert (data, end_of_chunk) == (next(it), False)\n    pytest.raises(StopIteration, next, it)\n\n\nasync def test_stream_reader_iter_chunks_chunked_encoding(protocol: Any) -> None:\n    loop = asyncio.get_event_loop()\n    stream = streams.StreamReader(protocol, 2**16, loop=loop)\n    for line in DATA.splitlines(keepends=True):\n        stream.begin_http_chunk_receiving()\n        stream.feed_data(line)\n        stream.end_http_chunk_receiving()\n    stream.feed_eof()\n\n    it = iter([b\"line1\\n\", b\"line2\\n\", b\"line3\\n\"])\n    async for data, end_of_chunk in stream.iter_chunks():\n        assert (data, end_of_chunk) == (next(it), True)\n    pytest.raises(StopIteration, next, it)\n\n\ndef test_isinstance_check() -> None:\n    assert isinstance(streams.EMPTY_PAYLOAD, streams.StreamReader)\n", "tests/test_base_protocol.py": "import asyncio\nfrom contextlib import suppress\nfrom unittest import mock\n\nimport pytest\n\nfrom aiohttp.base_protocol import BaseProtocol\n\n\nasync def test_loop() -> None:\n    loop = asyncio.get_event_loop()\n    asyncio.set_event_loop(None)\n    pr = BaseProtocol(loop)\n    assert pr._loop is loop\n\n\nasync def test_pause_writing() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop)\n    assert not pr._paused\n    pr.pause_writing()\n    assert pr._paused\n\n\nasync def test_pause_reading_no_transport() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop)\n    assert not pr._reading_paused\n    pr.pause_reading()\n    assert not pr._reading_paused\n\n\nasync def test_pause_reading_stub_transport() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop)\n    tr = asyncio.Transport()\n    pr.transport = tr\n    assert not pr._reading_paused\n    pr.pause_reading()\n    assert pr._reading_paused\n\n\nasync def test_resume_reading_no_transport() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop)\n    pr._reading_paused = True\n    pr.resume_reading()\n    assert pr._reading_paused\n\n\nasync def test_resume_reading_stub_transport() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop)\n    tr = asyncio.Transport()\n    pr.transport = tr\n    pr._reading_paused = True\n    pr.resume_reading()\n    assert not pr._reading_paused\n\n\nasync def test_resume_writing_no_waiters() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    pr.pause_writing()\n    assert pr._paused\n    pr.resume_writing()\n    assert not pr._paused\n\n\nasync def test_resume_writing_waiter_done() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    waiter = mock.Mock(done=mock.Mock(return_value=True))\n    pr._drain_waiter = waiter\n    pr._paused = True\n    pr.resume_writing()\n    assert not pr._paused\n    assert waiter.mock_calls == [mock.call.done()]\n\n\nasync def test_connection_made() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    assert pr.transport is None\n    pr.connection_made(tr)\n    assert pr.transport is not None\n\n\nasync def test_connection_lost_not_paused() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    pr.connection_made(tr)\n    assert pr.connected\n    pr.connection_lost(None)\n    assert pr.transport is None\n    assert not pr.connected\n\n\nasync def test_connection_lost_paused_without_waiter() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    pr.connection_made(tr)\n    assert pr.connected\n    pr.pause_writing()\n    pr.connection_lost(None)\n    assert pr.transport is None\n    assert not pr.connected\n\n\nasync def test_connection_lost_waiter_done() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    pr._paused = True\n    waiter = mock.Mock(done=mock.Mock(return_value=True))\n    pr._drain_waiter = waiter\n    pr.connection_lost(None)\n    assert pr._drain_waiter is None\n    assert waiter.mock_calls == [mock.call.done()]\n\n\nasync def test_drain_lost() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    pr.connection_made(tr)\n    pr.connection_lost(None)\n    with pytest.raises(ConnectionResetError):\n        await pr._drain_helper()\n\n\nasync def test_drain_not_paused() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    pr.connection_made(tr)\n    assert pr._drain_waiter is None\n    await pr._drain_helper()\n    assert pr._drain_waiter is None\n\n\nasync def test_resume_drain_waited() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    pr.connection_made(tr)\n    pr.pause_writing()\n\n    t = loop.create_task(pr._drain_helper())\n    await asyncio.sleep(0)\n\n    assert pr._drain_waiter is not None\n    pr.resume_writing()\n    await t\n    assert pr._drain_waiter is None\n\n\nasync def test_lost_drain_waited_ok() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    pr.connection_made(tr)\n    pr.pause_writing()\n\n    t = loop.create_task(pr._drain_helper())\n    await asyncio.sleep(0)\n\n    assert pr._drain_waiter is not None\n    pr.connection_lost(None)\n    await t\n    assert pr._drain_waiter is None\n\n\nasync def test_lost_drain_waited_exception() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    pr.connection_made(tr)\n    pr.pause_writing()\n\n    t = loop.create_task(pr._drain_helper())\n    await asyncio.sleep(0)\n\n    assert pr._drain_waiter is not None\n    exc = RuntimeError()\n    pr.connection_lost(exc)\n    with pytest.raises(ConnectionError, match=r\"^Connection lost$\") as cm:\n        await t\n    assert cm.value.__cause__ is exc\n    assert pr._drain_waiter is None\n\n\nasync def test_lost_drain_cancelled() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    pr.connection_made(tr)\n    pr.pause_writing()\n\n    fut = loop.create_future()\n\n    async def wait() -> None:\n        fut.set_result(None)\n        await pr._drain_helper()\n\n    t = loop.create_task(wait())\n    await fut\n    t.cancel()\n\n    assert pr._drain_waiter is not None\n    pr.connection_lost(None)\n    with suppress(asyncio.CancelledError):\n        await t\n    assert pr._drain_waiter is None\n\n\nasync def test_resume_drain_cancelled() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    pr.connection_made(tr)\n    pr.pause_writing()\n\n    fut = loop.create_future()\n\n    async def wait() -> None:\n        fut.set_result(None)\n        await pr._drain_helper()\n\n    t = loop.create_task(wait())\n    await fut\n    t.cancel()\n\n    assert pr._drain_waiter is not None\n    pr.resume_writing()\n    with suppress(asyncio.CancelledError):\n        await t\n    assert pr._drain_waiter is None\n\n\nasync def test_parallel_drain_race_condition() -> None:\n    loop = asyncio.get_event_loop()\n    pr = BaseProtocol(loop=loop)\n    tr = mock.Mock()\n    pr.connection_made(tr)\n    pr.pause_writing()\n\n    ts = [loop.create_task(pr._drain_helper()) for _ in range(5)]\n    assert not (await asyncio.wait(ts, timeout=0.5))[\n        0\n    ], \"All draining tasks must be pending\"\n\n    assert pr._drain_waiter is not None\n    pr.resume_writing()\n    await asyncio.gather(*ts)\n    assert pr._drain_waiter is None\n", "tests/test_proxy.py": "# type: ignore\nimport asyncio\nimport gc\nimport socket\nimport ssl\nimport unittest\nfrom typing import Any\nfrom unittest import mock\n\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp.client_reqrep import ClientRequest, ClientResponse\nfrom aiohttp.helpers import TimerNoop\nfrom aiohttp.test_utils import make_mocked_coro\n\n\nclass TestProxy(unittest.TestCase):\n    loop: Any\n    response_mock_attrs: Any = {\n        \"status\": 200,\n    }\n    mocked_response: Any = mock.Mock(**response_mock_attrs)\n    clientrequest_mock_attrs: Any = {\n        \"return_value.send.return_value.start\": make_mocked_coro(mocked_response),\n    }\n\n    def setUp(self) -> None:\n        self.loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(None)\n\n    def tearDown(self) -> None:\n        # just in case if we have transport close callbacks\n        self.loop.stop()\n        self.loop.run_forever()\n        self.loop.close()\n        gc.collect()\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_connect(self, start_connection: Any, ClientRequestMock: Any) -> None:\n        req = ClientRequest(\n            \"GET\",\n            URL(\"http://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        self.assertEqual(str(req.proxy), \"http://proxy.example.com\")\n\n        # mock all the things!\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        proto = mock.Mock(\n            **{\n                \"transport.get_extra_info.return_value\": False,\n            }\n        )\n        self.loop.create_connection = make_mocked_coro((proto.transport, proto))\n        conn = self.loop.run_until_complete(\n            connector.connect(req, None, aiohttp.ClientTimeout())\n        )\n        self.assertEqual(req.url, URL(\"http://www.python.org\"))\n        self.assertIs(conn._protocol, proto)\n        self.assertIs(conn.transport, proto.transport)\n\n        ClientRequestMock.assert_called_with(\n            \"GET\",\n            URL(\"http://proxy.example.com\"),\n            auth=None,\n            headers={\"Host\": \"www.python.org\"},\n            loop=self.loop,\n            ssl=True,\n        )\n\n        conn.close()\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_proxy_headers(self, start_connection: Any, ClientRequestMock: Any) -> None:\n        req = ClientRequest(\n            \"GET\",\n            URL(\"http://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            proxy_headers={\"Foo\": \"Bar\"},\n            loop=self.loop,\n        )\n        self.assertEqual(str(req.proxy), \"http://proxy.example.com\")\n\n        # mock all the things!\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        proto = mock.Mock(\n            **{\n                \"transport.get_extra_info.return_value\": False,\n            }\n        )\n        self.loop.create_connection = make_mocked_coro((proto.transport, proto))\n        conn = self.loop.run_until_complete(\n            connector.connect(req, None, aiohttp.ClientTimeout())\n        )\n        self.assertEqual(req.url, URL(\"http://www.python.org\"))\n        self.assertIs(conn._protocol, proto)\n        self.assertIs(conn.transport, proto.transport)\n\n        ClientRequestMock.assert_called_with(\n            \"GET\",\n            URL(\"http://proxy.example.com\"),\n            auth=None,\n            headers={\"Host\": \"www.python.org\", \"Foo\": \"Bar\"},\n            loop=self.loop,\n            ssl=True,\n        )\n\n        conn.close()\n\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_proxy_auth(self, start_connection: Any) -> None:\n        with self.assertRaises(ValueError) as ctx:\n            ClientRequest(\n                \"GET\",\n                URL(\"http://python.org\"),\n                proxy=URL(\"http://proxy.example.com\"),\n                proxy_auth=(\"user\", \"pass\"),\n                loop=mock.Mock(),\n            )\n        self.assertEqual(\n            ctx.exception.args[0],\n            \"proxy_auth must be None or BasicAuth() tuple\",\n        )\n\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_proxy_dns_error(self, start_connection: Any) -> None:\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector: aiohttp.TCPConnector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            raise_exception=OSError(\"dont take it serious\")\n        )\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"http://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        expected_headers = dict(req.headers)\n        with self.assertRaises(aiohttp.ClientConnectorError):\n            self.loop.run_until_complete(\n                connector.connect(req, None, aiohttp.ClientTimeout())\n            )\n        self.assertEqual(req.url.path, \"/\")\n        self.assertEqual(dict(req.headers), expected_headers)\n\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_proxy_connection_error(self, start_connection: Any) -> None:\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"www.python.org\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": socket.AI_NUMERICHOST,\n                }\n            ]\n        )\n        connector._loop.create_connection = make_mocked_coro(\n            raise_exception=OSError(\"dont take it serious\")\n        )\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"http://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        with self.assertRaises(aiohttp.ClientProxyConnectionError):\n            self.loop.run_until_complete(\n                connector.connect(req, None, aiohttp.ClientTimeout())\n            )\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_proxy_server_hostname_default(\n        self, start_connection: Any, ClientRequestMock: Any\n    ) -> None:\n        proxy_req = ClientRequest(\n            \"GET\", URL(\"http://proxy.example.com\"), loop=self.loop\n        )\n        ClientRequestMock.return_value = proxy_req\n\n        proxy_resp = ClientResponse(\n            \"get\",\n            URL(\"http://proxy.example.com\"),\n            request_info=mock.Mock(),\n            writer=None,\n            continue100=None,\n            timer=TimerNoop(),\n            traces=[],\n            loop=self.loop,\n            session=mock.Mock(),\n        )\n        proxy_req.send = make_mocked_coro(proxy_resp)\n        proxy_resp.start = make_mocked_coro(mock.Mock(status=200))\n\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        tr, proto = mock.Mock(), mock.Mock()\n        self.loop.create_connection = make_mocked_coro((tr, proto))\n        self.loop.start_tls = make_mocked_coro(mock.Mock())\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"https://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        self.loop.run_until_complete(\n            connector._create_connection(req, None, aiohttp.ClientTimeout())\n        )\n\n        self.assertEqual(\n            self.loop.start_tls.call_args.kwargs[\"server_hostname\"], \"www.python.org\"\n        )\n\n        self.loop.run_until_complete(proxy_req.close())\n        proxy_resp.close()\n        self.loop.run_until_complete(req.close())\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_proxy_server_hostname_override(\n        self, start_connection: Any, ClientRequestMock: Any\n    ) -> None:\n        proxy_req = ClientRequest(\n            \"GET\",\n            URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        ClientRequestMock.return_value = proxy_req\n\n        proxy_resp = ClientResponse(\n            \"get\",\n            URL(\"http://proxy.example.com\"),\n            request_info=mock.Mock(),\n            writer=None,\n            continue100=None,\n            timer=TimerNoop(),\n            traces=[],\n            loop=self.loop,\n            session=mock.Mock(),\n        )\n        proxy_req.send = make_mocked_coro(proxy_resp)\n        proxy_resp.start = make_mocked_coro(mock.Mock(status=200))\n\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        tr, proto = mock.Mock(), mock.Mock()\n        self.loop.create_connection = make_mocked_coro((tr, proto))\n        self.loop.start_tls = make_mocked_coro(mock.Mock())\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"https://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            server_hostname=\"server-hostname.example.com\",\n            loop=self.loop,\n        )\n        self.loop.run_until_complete(\n            connector._create_connection(req, None, aiohttp.ClientTimeout())\n        )\n\n        self.assertEqual(\n            self.loop.start_tls.call_args.kwargs[\"server_hostname\"],\n            \"server-hostname.example.com\",\n        )\n\n        self.loop.run_until_complete(proxy_req.close())\n        proxy_resp.close()\n        self.loop.run_until_complete(req.close())\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_https_connect(self, start_connection: Any, ClientRequestMock: Any) -> None:\n        proxy_req = ClientRequest(\n            \"GET\", URL(\"http://proxy.example.com\"), loop=self.loop\n        )\n        ClientRequestMock.return_value = proxy_req\n\n        proxy_resp = ClientResponse(\n            \"get\",\n            URL(\"http://proxy.example.com\"),\n            request_info=mock.Mock(),\n            writer=None,\n            continue100=None,\n            timer=TimerNoop(),\n            traces=[],\n            loop=self.loop,\n            session=mock.Mock(),\n        )\n        proxy_req.send = make_mocked_coro(proxy_resp)\n        proxy_resp.start = make_mocked_coro(mock.Mock(status=200))\n\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        tr, proto = mock.Mock(), mock.Mock()\n        self.loop.create_connection = make_mocked_coro((tr, proto))\n        self.loop.start_tls = make_mocked_coro(mock.Mock())\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"https://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        self.loop.run_until_complete(\n            connector._create_connection(req, None, aiohttp.ClientTimeout())\n        )\n\n        self.assertEqual(req.url.path, \"/\")\n        self.assertEqual(proxy_req.method, \"CONNECT\")\n        self.assertEqual(proxy_req.url, URL(\"https://www.python.org\"))\n\n        self.loop.run_until_complete(proxy_req.close())\n        proxy_resp.close()\n        self.loop.run_until_complete(req.close())\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_https_connect_certificate_error(\n        self, start_connection: Any, ClientRequestMock: Any\n    ) -> None:\n        proxy_req = ClientRequest(\n            \"GET\", URL(\"http://proxy.example.com\"), loop=self.loop\n        )\n        ClientRequestMock.return_value = proxy_req\n\n        proxy_resp = ClientResponse(\n            \"get\",\n            URL(\"http://proxy.example.com\"),\n            request_info=mock.Mock(),\n            writer=None,\n            continue100=None,\n            timer=TimerNoop(),\n            traces=[],\n            loop=self.loop,\n            session=mock.Mock(),\n        )\n        proxy_req.send = make_mocked_coro(proxy_resp)\n        proxy_resp.start = make_mocked_coro(mock.Mock(status=200))\n\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        # Called on connection to http://proxy.example.com\n        self.loop.create_connection = make_mocked_coro((mock.Mock(), mock.Mock()))\n        # Called on connection to https://www.python.org\n        self.loop.start_tls = make_mocked_coro(raise_exception=ssl.CertificateError)\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"https://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        with self.assertRaises(aiohttp.ClientConnectorCertificateError):\n            self.loop.run_until_complete(\n                connector._create_connection(req, None, aiohttp.ClientTimeout())\n            )\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_https_connect_ssl_error(\n        self, start_connection: Any, ClientRequestMock: Any\n    ) -> None:\n        proxy_req = ClientRequest(\n            \"GET\", URL(\"http://proxy.example.com\"), loop=self.loop\n        )\n        ClientRequestMock.return_value = proxy_req\n\n        proxy_resp = ClientResponse(\n            \"get\",\n            URL(\"http://proxy.example.com\"),\n            request_info=mock.Mock(),\n            writer=None,\n            continue100=None,\n            timer=TimerNoop(),\n            traces=[],\n            loop=self.loop,\n            session=mock.Mock(),\n        )\n        proxy_req.send = make_mocked_coro(proxy_resp)\n        proxy_resp.start = make_mocked_coro(mock.Mock(status=200))\n\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        # Called on connection to http://proxy.example.com\n        self.loop.create_connection = make_mocked_coro(\n            (mock.Mock(), mock.Mock()),\n        )\n        # Called on connection to https://www.python.org\n        self.loop.start_tls = make_mocked_coro(raise_exception=ssl.SSLError)\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"https://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        with self.assertRaises(aiohttp.ClientConnectorSSLError):\n            self.loop.run_until_complete(\n                connector._create_connection(req, None, aiohttp.ClientTimeout())\n            )\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_https_connect_http_proxy_error(\n        self, start_connection: Any, ClientRequestMock: Any\n    ) -> None:\n        proxy_req = ClientRequest(\n            \"GET\", URL(\"http://proxy.example.com\"), loop=self.loop\n        )\n        ClientRequestMock.return_value = proxy_req\n\n        proxy_resp = ClientResponse(\n            \"get\",\n            URL(\"http://proxy.example.com\"),\n            request_info=mock.Mock(),\n            writer=None,\n            continue100=None,\n            timer=TimerNoop(),\n            traces=[],\n            loop=self.loop,\n            session=mock.Mock(),\n        )\n        proxy_req.send = make_mocked_coro(proxy_resp)\n        proxy_resp.start = make_mocked_coro(mock.Mock(status=400, reason=\"bad request\"))\n\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        tr, proto = mock.Mock(), mock.Mock()\n        tr.get_extra_info.return_value = None\n        self.loop.create_connection = make_mocked_coro((tr, proto))\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"https://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        with self.assertRaisesRegex(\n            aiohttp.ClientHttpProxyError, \"400, message='bad request'\"\n        ):\n            self.loop.run_until_complete(\n                connector._create_connection(req, None, aiohttp.ClientTimeout())\n            )\n\n        self.loop.run_until_complete(proxy_req.close())\n        proxy_resp.close()\n        self.loop.run_until_complete(req.close())\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_https_connect_resp_start_error(\n        self, start_connection: Any, ClientRequestMock: Any\n    ) -> None:\n        proxy_req = ClientRequest(\n            \"GET\", URL(\"http://proxy.example.com\"), loop=self.loop\n        )\n        ClientRequestMock.return_value = proxy_req\n\n        proxy_resp = ClientResponse(\n            \"get\",\n            URL(\"http://proxy.example.com\"),\n            request_info=mock.Mock(),\n            writer=None,\n            continue100=None,\n            timer=TimerNoop(),\n            traces=[],\n            loop=self.loop,\n            session=mock.Mock(),\n        )\n        proxy_req.send = make_mocked_coro(proxy_resp)\n        proxy_resp.start = make_mocked_coro(raise_exception=OSError(\"error message\"))\n\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        tr, proto = mock.Mock(), mock.Mock()\n        tr.get_extra_info.return_value = None\n        self.loop.create_connection = make_mocked_coro((tr, proto))\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"https://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        with self.assertRaisesRegex(OSError, \"error message\"):\n            self.loop.run_until_complete(\n                connector._create_connection(req, None, aiohttp.ClientTimeout())\n            )\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_request_port(self, start_connection: Any, ClientRequestMock: Any) -> None:\n        proxy_req = ClientRequest(\n            \"GET\", URL(\"http://proxy.example.com\"), loop=self.loop\n        )\n        ClientRequestMock.return_value = proxy_req\n\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        tr, proto = mock.Mock(), mock.Mock()\n        tr.get_extra_info.return_value = None\n        self.loop.create_connection = make_mocked_coro((tr, proto))\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"http://localhost:1234/path\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        self.loop.run_until_complete(\n            connector._create_connection(req, None, aiohttp.ClientTimeout())\n        )\n        self.assertEqual(req.url, URL(\"http://localhost:1234/path\"))\n\n    def test_proxy_auth_property(self) -> None:\n        req = aiohttp.ClientRequest(\n            \"GET\",\n            URL(\"http://localhost:1234/path\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            proxy_auth=aiohttp.helpers.BasicAuth(\"user\", \"pass\"),\n            loop=self.loop,\n        )\n        self.assertEqual((\"user\", \"pass\", \"latin1\"), req.proxy_auth)\n\n    def test_proxy_auth_property_default(self) -> None:\n        req = aiohttp.ClientRequest(\n            \"GET\",\n            URL(\"http://localhost:1234/path\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        self.assertIsNone(req.proxy_auth)\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_https_connect_pass_ssl_context(\n        self, start_connection: Any, ClientRequestMock: Any\n    ) -> None:\n        proxy_req = ClientRequest(\n            \"GET\", URL(\"http://proxy.example.com\"), loop=self.loop\n        )\n        ClientRequestMock.return_value = proxy_req\n\n        proxy_resp = ClientResponse(\n            \"get\",\n            URL(\"http://proxy.example.com\"),\n            request_info=mock.Mock(),\n            writer=None,\n            continue100=None,\n            timer=TimerNoop(),\n            traces=[],\n            loop=self.loop,\n            session=mock.Mock(),\n        )\n        proxy_req.send = make_mocked_coro(proxy_resp)\n        proxy_resp.start = make_mocked_coro(mock.Mock(status=200))\n\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        tr, proto = mock.Mock(), mock.Mock()\n        self.loop.create_connection = make_mocked_coro((tr, proto))\n        self.loop.start_tls = make_mocked_coro(mock.Mock())\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"https://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        self.loop.run_until_complete(\n            connector._create_connection(req, None, aiohttp.ClientTimeout())\n        )\n\n        self.loop.start_tls.assert_called_with(\n            mock.ANY,\n            mock.ANY,\n            connector._make_ssl_context(True),\n            server_hostname=\"www.python.org\",\n            ssl_handshake_timeout=mock.ANY,\n        )\n\n        self.assertEqual(req.url.path, \"/\")\n        self.assertEqual(proxy_req.method, \"CONNECT\")\n        self.assertEqual(proxy_req.url, URL(\"https://www.python.org\"))\n\n        self.loop.run_until_complete(proxy_req.close())\n        proxy_resp.close()\n        self.loop.run_until_complete(req.close())\n\n    @mock.patch(\"aiohttp.connector.ClientRequest\")\n    @mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\",\n        autospec=True,\n        spec_set=True,\n    )\n    def test_https_auth(self, start_connection: Any, ClientRequestMock: Any) -> None:\n        proxy_req = ClientRequest(\n            \"GET\",\n            URL(\"http://proxy.example.com\"),\n            auth=aiohttp.helpers.BasicAuth(\"user\", \"pass\"),\n            loop=self.loop,\n        )\n        ClientRequestMock.return_value = proxy_req\n\n        proxy_resp = ClientResponse(\n            \"get\",\n            URL(\"http://proxy.example.com\"),\n            request_info=mock.Mock(),\n            writer=None,\n            continue100=None,\n            timer=TimerNoop(),\n            traces=[],\n            loop=self.loop,\n            session=mock.Mock(),\n        )\n        proxy_req.send = make_mocked_coro(proxy_resp)\n        proxy_resp.start = make_mocked_coro(mock.Mock(status=200))\n\n        async def make_conn():\n            return aiohttp.TCPConnector()\n\n        connector = self.loop.run_until_complete(make_conn())\n        connector._resolve_host = make_mocked_coro(\n            [\n                {\n                    \"hostname\": \"hostname\",\n                    \"host\": \"127.0.0.1\",\n                    \"port\": 80,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n        )\n\n        tr, proto = mock.Mock(), mock.Mock()\n        self.loop.create_connection = make_mocked_coro((tr, proto))\n        self.loop.start_tls = make_mocked_coro(mock.Mock())\n\n        self.assertIn(\"AUTHORIZATION\", proxy_req.headers)\n        self.assertNotIn(\"PROXY-AUTHORIZATION\", proxy_req.headers)\n\n        req = ClientRequest(\n            \"GET\",\n            URL(\"https://www.python.org\"),\n            proxy=URL(\"http://proxy.example.com\"),\n            loop=self.loop,\n        )\n        self.assertNotIn(\"AUTHORIZATION\", req.headers)\n        self.assertNotIn(\"PROXY-AUTHORIZATION\", req.headers)\n        self.loop.run_until_complete(\n            connector._create_connection(req, None, aiohttp.ClientTimeout())\n        )\n\n        self.assertEqual(req.url.path, \"/\")\n        self.assertNotIn(\"AUTHORIZATION\", req.headers)\n        self.assertNotIn(\"PROXY-AUTHORIZATION\", req.headers)\n        self.assertNotIn(\"AUTHORIZATION\", proxy_req.headers)\n        self.assertIn(\"PROXY-AUTHORIZATION\", proxy_req.headers)\n\n        connector._resolve_host.assert_called_with(\n            \"proxy.example.com\", 80, traces=mock.ANY\n        )\n\n        self.loop.run_until_complete(proxy_req.close())\n        proxy_resp.close()\n        self.loop.run_until_complete(req.close())\n", "tests/test_connector.py": "# type: ignore\n# Tests of http client with custom Connector\n\nimport asyncio\nimport gc\nimport hashlib\nimport platform\nimport socket\nimport ssl\nimport sys\nimport uuid\nfrom collections import deque\nfrom contextlib import closing\nfrom typing import Any, List, Optional\nfrom unittest import mock\n\nimport pytest\nfrom aiohappyeyeballs import AddrInfoType\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp import client, web\nfrom aiohttp.client import ClientRequest, ClientTimeout\nfrom aiohttp.client_reqrep import ConnectionKey\nfrom aiohttp.connector import Connection, TCPConnector, _DNSCacheTable\nfrom aiohttp.locks import EventResultOrError\nfrom aiohttp.test_utils import make_mocked_coro, unused_port\nfrom aiohttp.tracing import Trace\n\n\n@pytest.fixture()\ndef key():\n    # Connection key\n    return ConnectionKey(\"localhost\", 80, False, True, None, None, None)\n\n\n@pytest.fixture\ndef key2():\n    # Connection key\n    return ConnectionKey(\"localhost\", 80, False, True, None, None, None)\n\n\n@pytest.fixture\ndef ssl_key():\n    # Connection key\n    return ConnectionKey(\"localhost\", 80, True, True, None, None, None)\n\n\n@pytest.fixture\ndef unix_server(loop: Any, unix_sockname: Any) -> None:\n    runners = []\n\n    async def go(app):\n        runner = web.AppRunner(app)\n        runners.append(runner)\n        await runner.setup()\n        site = web.UnixSite(runner, unix_sockname)\n        await site.start()\n\n    yield go\n\n    for runner in runners:\n        loop.run_until_complete(runner.cleanup())\n\n\n@pytest.fixture\ndef named_pipe_server(proactor_loop: Any, pipe_name: Any) -> None:\n    runners = []\n\n    async def go(app):\n        runner = web.AppRunner(app)\n        runners.append(runner)\n        await runner.setup()\n        site = web.NamedPipeSite(runner, pipe_name)\n        await site.start()\n\n    yield go\n\n    for runner in runners:\n        proactor_loop.run_until_complete(runner.cleanup())\n\n\ndef create_mocked_conn(conn_closing_result: Optional[Any] = None, **kwargs: Any):\n    assert \"loop\" not in kwargs\n    try:\n        loop = asyncio.get_running_loop()\n    except RuntimeError:\n        loop = asyncio.get_event_loop_policy().get_event_loop()\n\n    proto = mock.Mock(**kwargs)\n    proto.closed = loop.create_future()\n    proto.closed.set_result(conn_closing_result)\n    return proto\n\n\ndef test_connection_del(loop: Any) -> None:\n    connector = mock.Mock()\n    key = mock.Mock()\n    protocol = mock.Mock()\n    loop.set_debug(0)\n    conn = Connection(connector, key, protocol, loop=loop)\n    exc_handler = mock.Mock()\n    loop.set_exception_handler(exc_handler)\n\n    with pytest.warns(ResourceWarning):\n        del conn\n        gc.collect()\n\n    connector._release.assert_called_with(key, protocol, should_close=True)\n    msg = {\n        \"message\": mock.ANY,\n        \"client_connection\": mock.ANY,\n    }\n    exc_handler.assert_called_with(loop, msg)\n\n\ndef test_connection_del_loop_debug(loop: Any) -> None:\n    connector = mock.Mock()\n    key = mock.Mock()\n    protocol = mock.Mock()\n    loop.set_debug(1)\n    conn = Connection(connector, key, protocol, loop=loop)\n    exc_handler = mock.Mock()\n    loop.set_exception_handler(exc_handler)\n\n    with pytest.warns(ResourceWarning):\n        del conn\n        gc.collect()\n\n    msg = {\n        \"message\": mock.ANY,\n        \"client_connection\": mock.ANY,\n        \"source_traceback\": mock.ANY,\n    }\n    exc_handler.assert_called_with(loop, msg)\n\n\ndef test_connection_del_loop_closed(loop: Any) -> None:\n    connector = mock.Mock()\n    key = mock.Mock()\n    protocol = mock.Mock()\n    loop.set_debug(1)\n    conn = Connection(connector, key, protocol, loop=loop)\n    exc_handler = mock.Mock()\n    loop.set_exception_handler(exc_handler)\n    loop.close()\n\n    with pytest.warns(ResourceWarning):\n        del conn\n        gc.collect()\n\n    assert not connector._release.called\n    assert not exc_handler.called\n\n\nasync def test_del(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    proto = create_mocked_conn(loop, should_close=False)\n    conn._release(\"a\", proto)\n    conns_impl = conn._conns\n\n    exc_handler = mock.Mock()\n    loop.set_exception_handler(exc_handler)\n\n    with pytest.warns(ResourceWarning):\n        del conn\n        gc.collect()\n\n    assert not conns_impl\n    proto.close.assert_called_with()\n    msg = {\n        \"connector\": mock.ANY,  # conn was deleted\n        \"connections\": mock.ANY,\n        \"message\": \"Unclosed connector\",\n    }\n    if loop.get_debug():\n        msg[\"source_traceback\"] = mock.ANY\n    exc_handler.assert_called_with(loop, msg)\n\n\n@pytest.mark.xfail\nasync def test_del_with_scheduled_cleanup(loop: Any) -> None:\n    loop.set_debug(True)\n    conn = aiohttp.BaseConnector(keepalive_timeout=0.01)\n    transp = create_mocked_conn(loop)\n    conn._conns[\"a\"] = [(transp, 123)]\n\n    conns_impl = conn._conns\n    exc_handler = mock.Mock()\n    loop.set_exception_handler(exc_handler)\n\n    with pytest.warns(ResourceWarning):\n        # obviously doesn't deletion because loop has a strong\n        # reference to connector's instance method, isn't it?\n        del conn\n        await asyncio.sleep(0.01)\n        gc.collect()\n\n    assert not conns_impl\n    transp.close.assert_called_with()\n    msg = {\"connector\": mock.ANY, \"message\": \"Unclosed connector\"}  # conn was deleted\n    if loop.get_debug():\n        msg[\"source_traceback\"] = mock.ANY\n    exc_handler.assert_called_with(loop, msg)\n\n\n@pytest.mark.skipif(\n    sys.implementation.name != \"cpython\", reason=\"CPython GC is required for the test\"\n)\ndef test_del_with_closed_loop(loop: Any) -> None:\n    async def make_conn():\n        return aiohttp.BaseConnector()\n\n    conn = loop.run_until_complete(make_conn())\n    transp = create_mocked_conn(loop)\n    conn._conns[\"a\"] = [(transp, 123)]\n\n    conns_impl = conn._conns\n    exc_handler = mock.Mock()\n    loop.set_exception_handler(exc_handler)\n    loop.close()\n\n    with pytest.warns(ResourceWarning):\n        del conn\n        gc.collect()\n\n    assert not conns_impl\n    assert not transp.close.called\n    assert exc_handler.called\n\n\nasync def test_del_empty_connector(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n\n    exc_handler = mock.Mock()\n    loop.set_exception_handler(exc_handler)\n\n    del conn\n\n    assert not exc_handler.called\n\n\nasync def test_create_conn() -> None:\n    conn = aiohttp.BaseConnector()\n    with pytest.raises(NotImplementedError):\n        await conn._create_connection(object(), [], object())\n\n\nasync def test_async_context_manager(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n\n    async with conn as c:\n        assert conn is c\n\n    assert conn.closed\n\n\nasync def test_close() -> None:\n    proto = create_mocked_conn()\n\n    conn = aiohttp.BaseConnector()\n    assert not conn.closed\n    conn._conns[(\"host\", 8080, False)] = [(proto, object())]\n    await conn.close()\n\n    assert not conn._conns\n    assert proto.close.called\n    assert conn.closed\n\n\nasync def test_get(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    assert conn._get(1) is None\n\n    proto = create_mocked_conn(loop)\n    conn._conns[1] = [(proto, loop.time())]\n    assert conn._get(1) == proto\n    await conn.close()\n\n\nasync def test_get_unconnected_proto(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    key = ConnectionKey(\"localhost\", 80, False, None, None, None, None)\n    assert conn._get(key) is None\n\n    proto = create_mocked_conn(loop)\n    conn._conns[key] = [(proto, loop.time())]\n    assert conn._get(key) == proto\n\n    assert conn._get(key) is None\n    conn._conns[key] = [(proto, loop.time())]\n    proto.is_connected = lambda *args: False\n    assert conn._get(key) is None\n    await conn.close()\n\n\nasync def test_get_unconnected_proto_ssl(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    key = ConnectionKey(\"localhost\", 80, True, None, None, None, None)\n    assert conn._get(key) is None\n\n    proto = create_mocked_conn(loop)\n    conn._conns[key] = [(proto, loop.time())]\n    assert conn._get(key) == proto\n\n    assert conn._get(key) is None\n    conn._conns[key] = [(proto, loop.time())]\n    proto.is_connected = lambda *args: False\n    assert conn._get(key) is None\n    await conn.close()\n\n\nasync def test_get_expired(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    key = ConnectionKey(\"localhost\", 80, False, None, None, None, None)\n    assert conn._get(key) is None\n\n    proto = create_mocked_conn(loop)\n    conn._conns[key] = [(proto, loop.time() - 1000)]\n    assert conn._get(key) is None\n    assert not conn._conns\n    await conn.close()\n\n\nasync def test_get_expired_ssl(loop: Any) -> None:\n    conn = aiohttp.BaseConnector(enable_cleanup_closed=True)\n    key = ConnectionKey(\"localhost\", 80, True, None, None, None, None)\n    assert conn._get(key) is None\n\n    proto = create_mocked_conn(loop)\n    transport = proto.transport\n    conn._conns[key] = [(proto, loop.time() - 1000)]\n    assert conn._get(key) is None\n    assert not conn._conns\n    assert conn._cleanup_closed_transports == [transport]\n    await conn.close()\n\n\nasync def test_release_acquired(key: Any) -> None:\n    proto = create_mocked_conn()\n    conn = aiohttp.BaseConnector(limit=5)\n    conn._release_waiter = mock.Mock()\n\n    conn._acquired.add(proto)\n    conn._acquired_per_host[key].add(proto)\n    conn._release_acquired(key, proto)\n    assert 0 == len(conn._acquired)\n    assert 0 == len(conn._acquired_per_host)\n    assert conn._release_waiter.called\n\n    conn._release_acquired(key, proto)\n    assert 0 == len(conn._acquired)\n    assert 0 == len(conn._acquired_per_host)\n\n    await conn.close()\n\n\nasync def test_release_acquired_closed(key: Any) -> None:\n    proto = create_mocked_conn()\n    conn = aiohttp.BaseConnector(limit=5)\n    conn._release_waiter = mock.Mock()\n\n    conn._acquired.add(proto)\n    conn._acquired_per_host[key].add(proto)\n    conn._closed = True\n    conn._release_acquired(key, proto)\n    assert 1 == len(conn._acquired)\n    assert 1 == len(conn._acquired_per_host[key])\n    assert not conn._release_waiter.called\n    await conn.close()\n\n\nasync def test_release(loop: Any, key: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    conn._release_waiter = mock.Mock()\n\n    proto = create_mocked_conn(loop, should_close=False)\n\n    conn._acquired.add(proto)\n    conn._acquired_per_host[key].add(proto)\n\n    conn._release(key, proto)\n    assert conn._release_waiter.called\n    assert conn._cleanup_handle is not None\n    assert conn._conns[key][0][0] == proto\n    assert conn._conns[key][0][1] == pytest.approx(loop.time(), abs=0.1)\n    assert not conn._cleanup_closed_transports\n    await conn.close()\n\n\nasync def test_release_ssl_transport(loop: Any, ssl_key: Any) -> None:\n    conn = aiohttp.BaseConnector(enable_cleanup_closed=True)\n    conn._release_waiter = mock.Mock()\n\n    proto = create_mocked_conn(loop)\n    transport = proto.transport\n    conn._acquired.add(proto)\n    conn._acquired_per_host[ssl_key].add(proto)\n\n    conn._release(ssl_key, proto, should_close=True)\n    assert conn._cleanup_closed_transports == [transport]\n    await conn.close()\n\n\nasync def test_release_already_closed() -> None:\n    conn = aiohttp.BaseConnector()\n\n    proto = create_mocked_conn()\n    key = 1\n    conn._acquired.add(proto)\n    await conn.close()\n\n    conn._release_waiters = mock.Mock()\n    conn._release_acquired = mock.Mock()\n\n    conn._release(key, proto)\n    assert not conn._release_waiters.called\n    assert not conn._release_acquired.called\n\n\nasync def test_release_waiter_no_limit(loop: Any, key: Any, key2: Any) -> None:\n    # limit is 0\n    conn = aiohttp.BaseConnector(limit=0)\n    w = mock.Mock()\n    w.done.return_value = False\n    conn._waiters[key].append(w)\n    conn._release_waiter()\n    assert len(conn._waiters[key]) == 0\n    assert w.done.called\n    await conn.close()\n\n\nasync def test_release_waiter_first_available(loop: Any, key: Any, key2: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    w1, w2 = mock.Mock(), mock.Mock()\n    w1.done.return_value = False\n    w2.done.return_value = False\n    conn._waiters[key].append(w2)\n    conn._waiters[key2].append(w1)\n    conn._release_waiter()\n    assert (\n        w1.set_result.called\n        and not w2.set_result.called\n        or not w1.set_result.called\n        and w2.set_result.called\n    )\n    await conn.close()\n\n\nasync def test_release_waiter_release_first(loop: Any, key: Any, key2: Any) -> None:\n    conn = aiohttp.BaseConnector(limit=1)\n    w1, w2 = mock.Mock(), mock.Mock()\n    w1.done.return_value = False\n    w2.done.return_value = False\n    conn._waiters[key] = deque([w1, w2])\n    conn._release_waiter()\n    assert w1.set_result.called\n    assert not w2.set_result.called\n    await conn.close()\n\n\nasync def test_release_waiter_skip_done_waiter(loop: Any, key: Any, key2: Any) -> None:\n    conn = aiohttp.BaseConnector(limit=1)\n    w1, w2 = mock.Mock(), mock.Mock()\n    w1.done.return_value = True\n    w2.done.return_value = False\n    conn._waiters[key] = deque([w1, w2])\n    conn._release_waiter()\n    assert not w1.set_result.called\n    assert w2.set_result.called\n    await conn.close()\n\n\nasync def test_release_waiter_per_host(loop: Any, key: Any, key2: Any) -> None:\n    # no limit\n    conn = aiohttp.BaseConnector(limit=0, limit_per_host=2)\n    w1, w2 = mock.Mock(), mock.Mock()\n    w1.done.return_value = False\n    w2.done.return_value = False\n    conn._waiters[key] = deque([w1])\n    conn._waiters[key2] = deque([w2])\n    conn._release_waiter()\n    assert (w1.set_result.called and not w2.set_result.called) or (\n        not w1.set_result.called and w2.set_result.called\n    )\n    await conn.close()\n\n\nasync def test_release_waiter_no_available(loop: Any, key: Any, key2: Any) -> None:\n    # limit is 0\n    conn = aiohttp.BaseConnector(limit=0)\n    w = mock.Mock()\n    w.done.return_value = False\n    conn._waiters[key].append(w)\n    conn._available_connections = mock.Mock(return_value=0)\n    conn._release_waiter()\n    assert len(conn._waiters) == 1\n    assert not w.done.called\n    await conn.close()\n\n\nasync def test_release_close(key: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    proto = create_mocked_conn(should_close=True)\n\n    conn._acquired.add(proto)\n    conn._release(key, proto)\n    assert not conn._conns\n    assert proto.close.called\n\n\nasync def test_release_proto_closed_future(loop: Any, key: Any):\n    conn = aiohttp.BaseConnector()\n    protocol = mock.Mock(should_close=True, closed=loop.create_future())\n    conn._release(key, protocol)\n    # See PR #6321\n    assert protocol.closed.result() is None\n\n\nasync def test__drop_acquire_per_host1(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    conn._drop_acquired_per_host(123, 456)\n    assert len(conn._acquired_per_host) == 0\n\n\nasync def test__drop_acquire_per_host2(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    conn._acquired_per_host[123].add(456)\n    conn._drop_acquired_per_host(123, 456)\n    assert len(conn._acquired_per_host) == 0\n\n\nasync def test__drop_acquire_per_host3(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    conn._acquired_per_host[123].add(456)\n    conn._acquired_per_host[123].add(789)\n    conn._drop_acquired_per_host(123, 456)\n    assert len(conn._acquired_per_host) == 1\n    assert conn._acquired_per_host[123] == {789}\n\n\nasync def test_tcp_connector_certificate_error(\n    loop: Any, start_connection: mock.AsyncMock\n) -> None:\n    req = ClientRequest(\"GET\", URL(\"https://127.0.0.1:443\"), loop=loop)\n\n    async def certificate_error(*args, **kwargs):\n        raise ssl.CertificateError\n\n    conn = aiohttp.TCPConnector()\n    conn._loop.create_connection = certificate_error\n\n    with pytest.raises(aiohttp.ClientConnectorCertificateError) as ctx:\n        await conn.connect(req, [], ClientTimeout())\n\n    assert isinstance(ctx.value, ssl.CertificateError)\n    assert isinstance(ctx.value.certificate_error, ssl.CertificateError)\n    assert isinstance(ctx.value, aiohttp.ClientSSLError)\n\n\nasync def test_tcp_connector_server_hostname_default(\n    loop: Any, start_connection: mock.AsyncMock\n) -> None:\n    conn = aiohttp.TCPConnector()\n\n    with mock.patch.object(\n        conn._loop, \"create_connection\", autospec=True, spec_set=True\n    ) as create_connection:\n        create_connection.return_value = mock.Mock(), mock.Mock()\n\n        req = ClientRequest(\"GET\", URL(\"https://127.0.0.1:443\"), loop=loop)\n\n        with closing(await conn.connect(req, [], ClientTimeout())):\n            assert create_connection.call_args.kwargs[\"server_hostname\"] == \"127.0.0.1\"\n\n\nasync def test_tcp_connector_server_hostname_override(\n    loop: Any, start_connection: mock.AsyncMock\n) -> None:\n    conn = aiohttp.TCPConnector()\n\n    with mock.patch.object(\n        conn._loop, \"create_connection\", autospec=True, spec_set=True\n    ) as create_connection:\n        create_connection.return_value = mock.Mock(), mock.Mock()\n\n        req = ClientRequest(\n            \"GET\", URL(\"https://127.0.0.1:443\"), loop=loop, server_hostname=\"localhost\"\n        )\n\n        with closing(await conn.connect(req, [], ClientTimeout())):\n            assert create_connection.call_args.kwargs[\"server_hostname\"] == \"localhost\"\n\n\nasync def test_tcp_connector_multiple_hosts_errors(loop: Any) -> None:\n    conn = aiohttp.TCPConnector()\n\n    ip1 = \"192.168.1.1\"\n    ip2 = \"192.168.1.2\"\n    ip3 = \"192.168.1.3\"\n    ip4 = \"192.168.1.4\"\n    ip5 = \"192.168.1.5\"\n    ips = [ip1, ip2, ip3, ip4, ip5]\n    addrs_tried = []\n    ips_tried = []\n\n    fingerprint = hashlib.sha256(b\"foo\").digest()\n\n    req = ClientRequest(\n        \"GET\",\n        URL(\"https://mocked.host\"),\n        ssl=aiohttp.Fingerprint(fingerprint),\n        loop=loop,\n    )\n\n    async def _resolve_host(host, port, traces=None):\n        return [\n            {\n                \"hostname\": host,\n                \"host\": ip,\n                \"port\": port,\n                \"family\": socket.AF_INET,\n                \"proto\": 0,\n                \"flags\": socket.AI_NUMERICHOST,\n            }\n            for ip in ips\n        ]\n\n    conn._resolve_host = _resolve_host\n\n    os_error = certificate_error = ssl_error = fingerprint_error = False\n    connected = False\n\n    async def start_connection(*args, **kwargs):\n        addr_infos: List[AddrInfoType] = kwargs[\"addr_infos\"]\n\n        first_addr_info = addr_infos[0]\n        first_addr_info_addr = first_addr_info[-1]\n        addrs_tried.append(first_addr_info_addr)\n\n        mock_socket = mock.create_autospec(socket.socket, spec_set=True, instance=True)\n        mock_socket.getpeername.return_value = first_addr_info_addr\n        return mock_socket\n\n    async def create_connection(*args, **kwargs):\n        nonlocal os_error, certificate_error, ssl_error, fingerprint_error\n        nonlocal connected\n\n        sock = kwargs[\"sock\"]\n        addr_info = sock.getpeername()\n        ip = addr_info[0]\n\n        ips_tried.append(ip)\n\n        if ip == ip1:\n            os_error = True\n            raise OSError\n\n        if ip == ip2:\n            certificate_error = True\n            raise ssl.CertificateError\n\n        if ip == ip3:\n            ssl_error = True\n            raise ssl.SSLError\n\n        if ip == ip4:\n            sock: socket.socket = kwargs[\"sock\"]\n\n            # Close the socket since we are not actually connecting\n            # and we don't want to leak it.\n            sock.close()\n\n            fingerprint_error = True\n            tr = create_mocked_conn(loop)\n            pr = create_mocked_conn(loop)\n\n            def get_extra_info(param):\n                if param == \"sslcontext\":\n                    return True\n\n                if param == \"ssl_object\":\n                    s = create_mocked_conn(loop)\n                    s.getpeercert.return_value = b\"not foo\"\n                    return s\n\n                if param == \"peername\":\n                    return (\"192.168.1.5\", 12345)\n\n                if param == \"socket\":\n                    return sock\n\n                assert False, param\n\n            tr.get_extra_info = get_extra_info\n            return tr, pr\n\n        if ip == ip5:\n            sock: socket.socket = kwargs[\"sock\"]\n\n            # Close the socket since we are not actually connecting\n            # and we don't want to leak it.\n            sock.close()\n\n            connected = True\n            tr = create_mocked_conn(loop)\n            pr = create_mocked_conn(loop)\n\n            def get_extra_info(param):\n                if param == \"sslcontext\":\n                    return True\n\n                if param == \"ssl_object\":\n                    s = create_mocked_conn(loop)\n                    s.getpeercert.return_value = b\"foo\"\n                    return s\n\n                assert False\n\n            tr.get_extra_info = get_extra_info\n            return tr, pr\n\n        assert False\n\n    conn._loop.create_connection = create_connection\n\n    with mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\", start_connection\n    ):\n        established_connection = await conn.connect(req, [], ClientTimeout())\n\n    assert ips_tried == ips\n    assert addrs_tried == [(ip, 443) for ip in ips]\n\n    assert os_error\n    assert certificate_error\n    assert ssl_error\n    assert fingerprint_error\n    assert connected\n\n    established_connection.close()\n\n\n@pytest.mark.parametrize(\n    (\"happy_eyeballs_delay\"),\n    [0.1, 0.25, None],\n)\nasync def test_tcp_connector_happy_eyeballs(\n    loop: Any, happy_eyeballs_delay: Optional[float]\n) -> None:\n    conn = aiohttp.TCPConnector(happy_eyeballs_delay=happy_eyeballs_delay)\n\n    ip1 = \"dead::beef::\"\n    ip2 = \"192.168.1.1\"\n    ips = [ip1, ip2]\n    addrs_tried = []\n\n    req = ClientRequest(\n        \"GET\",\n        URL(\"https://mocked.host\"),\n        loop=loop,\n    )\n\n    async def _resolve_host(host, port, traces=None):\n        return [\n            {\n                \"hostname\": host,\n                \"host\": ip,\n                \"port\": port,\n                \"family\": socket.AF_INET6 if \":\" in ip else socket.AF_INET,\n                \"proto\": 0,\n                \"flags\": socket.AI_NUMERICHOST,\n            }\n            for ip in ips\n        ]\n\n    conn._resolve_host = _resolve_host\n\n    os_error = False\n    connected = False\n\n    async def sock_connect(*args, **kwargs):\n        addr = args[1]\n        nonlocal os_error\n\n        addrs_tried.append(addr)\n\n        if addr[0] == ip1:\n            os_error = True\n            raise OSError\n\n    async def create_connection(*args, **kwargs):\n        sock: socket.socket = kwargs[\"sock\"]\n\n        # Close the socket since we are not actually connecting\n        # and we don't want to leak it.\n        sock.close()\n\n        nonlocal connected\n        connected = True\n        tr = create_mocked_conn(loop)\n        pr = create_mocked_conn(loop)\n        return tr, pr\n\n    conn._loop.sock_connect = sock_connect\n    conn._loop.create_connection = create_connection\n\n    established_connection = await conn.connect(req, [], ClientTimeout())\n\n    assert addrs_tried == [(ip1, 443, 0, 0), (ip2, 443)]\n\n    assert os_error\n    assert connected\n\n    established_connection.close()\n\n\nasync def test_tcp_connector_interleave(loop: Any) -> None:\n    conn = aiohttp.TCPConnector(interleave=2)\n\n    ip1 = \"192.168.1.1\"\n    ip2 = \"192.168.1.2\"\n    ip3 = \"dead::beef::\"\n    ip4 = \"aaaa::beef::\"\n    ip5 = \"192.168.1.5\"\n    ips = [ip1, ip2, ip3, ip4, ip5]\n    success_ips = []\n    interleave = None\n\n    req = ClientRequest(\n        \"GET\",\n        URL(\"https://mocked.host\"),\n        loop=loop,\n    )\n\n    async def _resolve_host(host, port, traces=None):\n        return [\n            {\n                \"hostname\": host,\n                \"host\": ip,\n                \"port\": port,\n                \"family\": socket.AF_INET6 if \":\" in ip else socket.AF_INET,\n                \"proto\": 0,\n                \"flags\": socket.AI_NUMERICHOST,\n            }\n            for ip in ips\n        ]\n\n    conn._resolve_host = _resolve_host\n\n    async def start_connection(*args, **kwargs):\n        nonlocal interleave\n        addr_infos: List[AddrInfoType] = kwargs[\"addr_infos\"]\n        interleave = kwargs[\"interleave\"]\n        # Mock the 4th host connecting successfully\n        fourth_addr_info = addr_infos[3]\n        fourth_addr_info_addr = fourth_addr_info[-1]\n        mock_socket = mock.create_autospec(socket.socket, spec_set=True, instance=True)\n        mock_socket.getpeername.return_value = fourth_addr_info_addr\n        return mock_socket\n\n    async def create_connection(*args, **kwargs):\n        sock = kwargs[\"sock\"]\n        addr_info = sock.getpeername()\n        ip = addr_info[0]\n\n        success_ips.append(ip)\n\n        sock: socket.socket = kwargs[\"sock\"]\n        # Close the socket since we are not actually connecting\n        # and we don't want to leak it.\n        sock.close()\n        tr = create_mocked_conn(loop)\n        pr = create_mocked_conn(loop)\n        return tr, pr\n\n    conn._loop.create_connection = create_connection\n\n    with mock.patch(\n        \"aiohttp.connector.aiohappyeyeballs.start_connection\", start_connection\n    ):\n        established_connection = await conn.connect(req, [], ClientTimeout())\n\n    assert success_ips == [ip4]\n    assert interleave == 2\n    established_connection.close()\n\n\nasync def test_tcp_connector_family_is_respected(loop: Any) -> None:\n    conn = aiohttp.TCPConnector(family=socket.AF_INET)\n\n    ip1 = \"dead::beef::\"\n    ip2 = \"192.168.1.1\"\n    ips = [ip1, ip2]\n    addrs_tried = []\n\n    req = ClientRequest(\n        \"GET\",\n        URL(\"https://mocked.host\"),\n        loop=loop,\n    )\n\n    async def _resolve_host(host, port, traces=None):\n        return [\n            {\n                \"hostname\": host,\n                \"host\": ip,\n                \"port\": port,\n                \"family\": socket.AF_INET6 if \":\" in ip else socket.AF_INET,\n                \"proto\": 0,\n                \"flags\": socket.AI_NUMERICHOST,\n            }\n            for ip in ips\n        ]\n\n    conn._resolve_host = _resolve_host\n    connected = False\n\n    async def sock_connect(*args, **kwargs):\n        addr = args[1]\n        addrs_tried.append(addr)\n\n    async def create_connection(*args, **kwargs):\n        sock: socket.socket = kwargs[\"sock\"]\n\n        # Close the socket since we are not actually connecting\n        # and we don't want to leak it.\n        sock.close()\n\n        nonlocal connected\n        connected = True\n        tr = create_mocked_conn(loop)\n        pr = create_mocked_conn(loop)\n        return tr, pr\n\n    conn._loop.sock_connect = sock_connect\n    conn._loop.create_connection = create_connection\n\n    established_connection = await conn.connect(req, [], ClientTimeout())\n\n    # We should only try the IPv4 address since we specified\n    # the family to be AF_INET\n    assert addrs_tried == [(ip2, 443)]\n\n    assert connected\n\n    established_connection.close()\n\n\nasync def test_tcp_connector_resolve_host(loop: Any) -> None:\n    conn = aiohttp.TCPConnector(use_dns_cache=True)\n\n    res = await conn._resolve_host(\"localhost\", 8080)\n    assert res\n    for rec in res:\n        if rec[\"family\"] == socket.AF_INET:\n            assert rec[\"host\"] == \"127.0.0.1\"\n            assert rec[\"hostname\"] == \"localhost\"\n            assert rec[\"port\"] == 8080\n        elif rec[\"family\"] == socket.AF_INET6:\n            assert rec[\"hostname\"] == \"localhost\"\n            assert rec[\"port\"] == 8080\n            if platform.system() == \"Darwin\":\n                assert rec[\"host\"] in (\"::1\", \"fe80::1\", \"fe80::1%lo0\")\n            else:\n                assert rec[\"host\"] == \"::1\"\n\n\n@pytest.fixture\ndef dns_response(loop: Any):\n    async def coro():\n        # simulates a network operation\n        await asyncio.sleep(0)\n        return [\"127.0.0.1\"]\n\n    return coro\n\n\nasync def test_tcp_connector_dns_cache_not_expired(\n    loop: Any, dns_response: Any\n) -> None:\n    with mock.patch(\"aiohttp.connector.DefaultResolver\") as m_resolver:\n        conn = aiohttp.TCPConnector(use_dns_cache=True, ttl_dns_cache=10)\n        m_resolver().resolve.return_value = dns_response()\n        await conn._resolve_host(\"localhost\", 8080)\n        await conn._resolve_host(\"localhost\", 8080)\n        m_resolver().resolve.assert_called_once_with(\"localhost\", 8080, family=0)\n\n\nasync def test_tcp_connector_dns_cache_forever(loop: Any, dns_response: Any) -> None:\n    with mock.patch(\"aiohttp.connector.DefaultResolver\") as m_resolver:\n        conn = aiohttp.TCPConnector(use_dns_cache=True, ttl_dns_cache=10)\n        m_resolver().resolve.return_value = dns_response()\n        await conn._resolve_host(\"localhost\", 8080)\n        await conn._resolve_host(\"localhost\", 8080)\n        m_resolver().resolve.assert_called_once_with(\"localhost\", 8080, family=0)\n\n\nasync def test_tcp_connector_use_dns_cache_disabled(\n    loop: Any, dns_response: Any\n) -> None:\n    with mock.patch(\"aiohttp.connector.DefaultResolver\") as m_resolver:\n        conn = aiohttp.TCPConnector(use_dns_cache=False)\n        m_resolver().resolve.side_effect = [dns_response(), dns_response()]\n        await conn._resolve_host(\"localhost\", 8080)\n        await conn._resolve_host(\"localhost\", 8080)\n        m_resolver().resolve.assert_has_calls(\n            [\n                mock.call(\"localhost\", 8080, family=0),\n                mock.call(\"localhost\", 8080, family=0),\n            ]\n        )\n\n\nasync def test_tcp_connector_dns_throttle_requests(\n    loop: Any, dns_response: Any\n) -> None:\n    with mock.patch(\"aiohttp.connector.DefaultResolver\") as m_resolver:\n        conn = aiohttp.TCPConnector(use_dns_cache=True, ttl_dns_cache=10)\n        m_resolver().resolve.return_value = dns_response()\n        loop.create_task(conn._resolve_host(\"localhost\", 8080))\n        loop.create_task(conn._resolve_host(\"localhost\", 8080))\n        await asyncio.sleep(0)\n        await asyncio.sleep(0)\n        m_resolver().resolve.assert_called_once_with(\"localhost\", 8080, family=0)\n\n\nasync def test_tcp_connector_dns_throttle_requests_exception_spread(loop: Any) -> None:\n    with mock.patch(\"aiohttp.connector.DefaultResolver\") as m_resolver:\n        conn = aiohttp.TCPConnector(use_dns_cache=True, ttl_dns_cache=10)\n        e = Exception()\n        m_resolver().resolve.side_effect = e\n        r1 = loop.create_task(conn._resolve_host(\"localhost\", 8080))\n        r2 = loop.create_task(conn._resolve_host(\"localhost\", 8080))\n        await asyncio.sleep(0)\n        await asyncio.sleep(0)\n        await asyncio.sleep(0)\n        await asyncio.sleep(0)\n        assert r1.exception() == e\n        assert r2.exception() == e\n\n\nasync def test_tcp_connector_dns_throttle_requests_cancelled_when_close(\n    loop: Any, dns_response: Any\n) -> None:\n    with mock.patch(\"aiohttp.connector.DefaultResolver\") as m_resolver:\n        conn = aiohttp.TCPConnector(use_dns_cache=True, ttl_dns_cache=10)\n        m_resolver().resolve.return_value = dns_response()\n        loop.create_task(conn._resolve_host(\"localhost\", 8080))\n        f = loop.create_task(conn._resolve_host(\"localhost\", 8080))\n\n        await asyncio.sleep(0)\n        await asyncio.sleep(0)\n        await conn.close()\n\n        with pytest.raises(asyncio.CancelledError):\n            await f\n\n\n@pytest.fixture\ndef dns_response_error(loop: Any):\n    async def coro():\n        # simulates a network operation\n        await asyncio.sleep(0)\n        raise socket.gaierror(-3, \"Temporary failure in name resolution\")\n\n    return coro\n\n\nasync def test_tcp_connector_cancel_dns_error_captured(\n    loop: Any, dns_response_error: Any\n) -> None:\n    exception_handler_called = False\n\n    def exception_handler(loop, context):\n        nonlocal exception_handler_called\n        exception_handler_called = True\n\n    loop.set_exception_handler(mock.Mock(side_effect=exception_handler))\n\n    with mock.patch(\"aiohttp.connector.DefaultResolver\") as m_resolver:\n        req = ClientRequest(\n            method=\"GET\", url=URL(\"http://temporary-failure:80\"), loop=loop\n        )\n        conn = aiohttp.TCPConnector(\n            use_dns_cache=False,\n        )\n        m_resolver().resolve.return_value = dns_response_error()\n        f = loop.create_task(conn._create_direct_connection(req, [], ClientTimeout(0)))\n\n        await asyncio.sleep(0)\n        f.cancel()\n        with pytest.raises(asyncio.CancelledError):\n            await f\n\n        gc.collect()\n        assert exception_handler_called is False\n\n\nasync def test_tcp_connector_dns_tracing(loop: Any, dns_response: Any) -> None:\n    session = mock.Mock()\n    trace_config_ctx = mock.Mock()\n    on_dns_resolvehost_start = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_dns_resolvehost_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_dns_cache_hit = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_dns_cache_miss = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n\n    trace_config = aiohttp.TraceConfig(\n        trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)\n    )\n    trace_config.on_dns_resolvehost_start.append(on_dns_resolvehost_start)\n    trace_config.on_dns_resolvehost_end.append(on_dns_resolvehost_end)\n    trace_config.on_dns_cache_hit.append(on_dns_cache_hit)\n    trace_config.on_dns_cache_miss.append(on_dns_cache_miss)\n    trace_config.freeze()\n    traces = [Trace(session, trace_config, trace_config.trace_config_ctx())]\n\n    with mock.patch(\"aiohttp.connector.DefaultResolver\") as m_resolver:\n        conn = aiohttp.TCPConnector(use_dns_cache=True, ttl_dns_cache=10)\n\n        m_resolver().resolve.return_value = dns_response()\n\n        await conn._resolve_host(\"localhost\", 8080, traces=traces)\n        on_dns_resolvehost_start.assert_called_once_with(\n            session,\n            trace_config_ctx,\n            aiohttp.TraceDnsResolveHostStartParams(\"localhost\"),\n        )\n        on_dns_resolvehost_end.assert_called_once_with(\n            session, trace_config_ctx, aiohttp.TraceDnsResolveHostEndParams(\"localhost\")\n        )\n        on_dns_cache_miss.assert_called_once_with(\n            session, trace_config_ctx, aiohttp.TraceDnsCacheMissParams(\"localhost\")\n        )\n        assert not on_dns_cache_hit.called\n\n        await conn._resolve_host(\"localhost\", 8080, traces=traces)\n        on_dns_cache_hit.assert_called_once_with(\n            session, trace_config_ctx, aiohttp.TraceDnsCacheHitParams(\"localhost\")\n        )\n\n\nasync def test_tcp_connector_dns_tracing_cache_disabled(\n    loop: Any, dns_response: Any\n) -> None:\n    session = mock.Mock()\n    trace_config_ctx = mock.Mock()\n    on_dns_resolvehost_start = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_dns_resolvehost_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n\n    trace_config = aiohttp.TraceConfig(\n        trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)\n    )\n    trace_config.on_dns_resolvehost_start.append(on_dns_resolvehost_start)\n    trace_config.on_dns_resolvehost_end.append(on_dns_resolvehost_end)\n    trace_config.freeze()\n    traces = [Trace(session, trace_config, trace_config.trace_config_ctx())]\n\n    with mock.patch(\"aiohttp.connector.DefaultResolver\") as m_resolver:\n        conn = aiohttp.TCPConnector(use_dns_cache=False)\n\n        m_resolver().resolve.side_effect = [dns_response(), dns_response()]\n\n        await conn._resolve_host(\"localhost\", 8080, traces=traces)\n\n        await conn._resolve_host(\"localhost\", 8080, traces=traces)\n\n        on_dns_resolvehost_start.assert_has_calls(\n            [\n                mock.call(\n                    session,\n                    trace_config_ctx,\n                    aiohttp.TraceDnsResolveHostStartParams(\"localhost\"),\n                ),\n                mock.call(\n                    session,\n                    trace_config_ctx,\n                    aiohttp.TraceDnsResolveHostStartParams(\"localhost\"),\n                ),\n            ]\n        )\n        on_dns_resolvehost_end.assert_has_calls(\n            [\n                mock.call(\n                    session,\n                    trace_config_ctx,\n                    aiohttp.TraceDnsResolveHostEndParams(\"localhost\"),\n                ),\n                mock.call(\n                    session,\n                    trace_config_ctx,\n                    aiohttp.TraceDnsResolveHostEndParams(\"localhost\"),\n                ),\n            ]\n        )\n\n\nasync def test_tcp_connector_dns_tracing_throttle_requests(\n    loop: Any, dns_response: Any\n) -> None:\n    session = mock.Mock()\n    trace_config_ctx = mock.Mock()\n    on_dns_cache_hit = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_dns_cache_miss = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n\n    trace_config = aiohttp.TraceConfig(\n        trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)\n    )\n    trace_config.on_dns_cache_hit.append(on_dns_cache_hit)\n    trace_config.on_dns_cache_miss.append(on_dns_cache_miss)\n    trace_config.freeze()\n    traces = [Trace(session, trace_config, trace_config.trace_config_ctx())]\n\n    with mock.patch(\"aiohttp.connector.DefaultResolver\") as m_resolver:\n        conn = aiohttp.TCPConnector(use_dns_cache=True, ttl_dns_cache=10)\n        m_resolver().resolve.return_value = dns_response()\n        loop.create_task(conn._resolve_host(\"localhost\", 8080, traces=traces))\n        loop.create_task(conn._resolve_host(\"localhost\", 8080, traces=traces))\n        await asyncio.sleep(0)\n        await asyncio.sleep(0)\n        on_dns_cache_hit.assert_called_once_with(\n            session, trace_config_ctx, aiohttp.TraceDnsCacheHitParams(\"localhost\")\n        )\n        on_dns_cache_miss.assert_called_once_with(\n            session, trace_config_ctx, aiohttp.TraceDnsCacheMissParams(\"localhost\")\n        )\n\n\nasync def test_dns_error(loop: Any) -> None:\n    connector = aiohttp.TCPConnector()\n    connector._resolve_host = make_mocked_coro(\n        raise_exception=OSError(\"dont take it serious\")\n    )\n\n    req = ClientRequest(\"GET\", URL(\"http://www.python.org\"), loop=loop)\n\n    with pytest.raises(aiohttp.ClientConnectorError):\n        await connector.connect(req, [], ClientTimeout())\n\n\nasync def test_get_pop_empty_conns(loop: Any) -> None:\n    # see issue #473\n    conn = aiohttp.BaseConnector()\n    key = (\"127.0.0.1\", 80, False)\n    conn._conns[key] = []\n    proto = conn._get(key)\n    assert proto is None\n    assert not conn._conns\n\n\nasync def test_release_close_do_not_add_to_pool(loop: Any, key: Any) -> None:\n    # see issue #473\n    conn = aiohttp.BaseConnector()\n\n    proto = create_mocked_conn(loop, should_close=True)\n\n    conn._acquired.add(proto)\n    conn._release(key, proto)\n    assert not conn._conns\n\n\nasync def test_release_close_do_not_delete_existing_connections(\n    loop: Any, key: Any\n) -> None:\n    proto1 = create_mocked_conn(loop)\n\n    conn = aiohttp.BaseConnector()\n    conn._conns[key] = [(proto1, 1)]\n\n    proto = create_mocked_conn(loop, should_close=True)\n    conn._acquired.add(proto)\n    conn._release(key, proto)\n    assert conn._conns[key] == [(proto1, 1)]\n    assert proto.close.called\n    await conn.close()\n\n\nasync def test_release_not_started(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    proto = create_mocked_conn(should_close=False)\n    key = 1\n    conn._acquired.add(proto)\n    conn._release(key, proto)\n    # assert conn._conns == {1: [(proto, 10)]}\n    rec = conn._conns[1]\n    assert rec[0][0] == proto\n    assert rec[0][1] == pytest.approx(loop.time(), abs=0.05)\n    assert not proto.close.called\n    await conn.close()\n\n\nasync def test_release_not_opened(loop: Any, key: Any) -> None:\n    conn = aiohttp.BaseConnector()\n\n    proto = create_mocked_conn(loop)\n    conn._acquired.add(proto)\n    conn._release(key, proto)\n    assert proto.close.called\n\n\nasync def test_connect(loop: Any, key: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"http://localhost:80\"), loop=loop)\n\n    conn = aiohttp.BaseConnector()\n    conn._conns[key] = [(proto, loop.time())]\n    conn._create_connection = create_mocked_conn(loop)\n    conn._create_connection.return_value = loop.create_future()\n    conn._create_connection.return_value.set_result(proto)\n\n    connection = await conn.connect(req, [], ClientTimeout())\n    assert not conn._create_connection.called\n    assert connection._protocol is proto\n    assert connection.transport is proto.transport\n    assert isinstance(connection, Connection)\n    connection.close()\n\n\nasync def test_connect_tracing(loop: Any) -> None:\n    session = mock.Mock()\n    trace_config_ctx = mock.Mock()\n    on_connection_create_start = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_connection_create_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n\n    trace_config = aiohttp.TraceConfig(\n        trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)\n    )\n    trace_config.on_connection_create_start.append(on_connection_create_start)\n    trace_config.on_connection_create_end.append(on_connection_create_end)\n    trace_config.freeze()\n    traces = [Trace(session, trace_config, trace_config.trace_config_ctx())]\n\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"http://host:80\"), loop=loop)\n\n    conn = aiohttp.BaseConnector()\n    conn._create_connection = mock.Mock()\n    conn._create_connection.return_value = loop.create_future()\n    conn._create_connection.return_value.set_result(proto)\n\n    conn2 = await conn.connect(req, traces, ClientTimeout())\n    conn2.release()\n\n    on_connection_create_start.assert_called_with(\n        session, trace_config_ctx, aiohttp.TraceConnectionCreateStartParams()\n    )\n    on_connection_create_end.assert_called_with(\n        session, trace_config_ctx, aiohttp.TraceConnectionCreateEndParams()\n    )\n\n\nasync def test_close_during_connect(loop: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    fut = loop.create_future()\n    req = ClientRequest(\"GET\", URL(\"http://host:80\"), loop=loop)\n\n    conn = aiohttp.BaseConnector()\n    conn._create_connection = mock.Mock()\n    conn._create_connection.return_value = fut\n\n    task = loop.create_task(conn.connect(req, None, ClientTimeout()))\n    await asyncio.sleep(0)\n    await conn.close()\n\n    fut.set_result(proto)\n    with pytest.raises(aiohttp.ClientConnectionError):\n        await task\n\n    assert proto.close.called\n\n\nasync def test_ctor_cleanup() -> None:\n    loop = mock.Mock()\n    loop.time.return_value = 1.5\n    conn = aiohttp.BaseConnector(keepalive_timeout=10, enable_cleanup_closed=True)\n    assert conn._cleanup_handle is None\n    assert conn._cleanup_closed_handle is not None\n\n\nasync def test_cleanup(key: Any) -> None:\n    testset = {\n        key: [(mock.Mock(), 10), (mock.Mock(), 300)],\n    }\n    testset[key][0][0].is_connected.return_value = True\n    testset[key][1][0].is_connected.return_value = False\n\n    loop = mock.Mock()\n    loop.time.return_value = 300\n    conn = aiohttp.BaseConnector()\n    conn._conns = testset\n    existing_handle = conn._cleanup_handle = mock.Mock()\n\n    conn._cleanup()\n    assert existing_handle.cancel.called\n    assert conn._conns == {}\n    assert conn._cleanup_handle is None\n\n\nasync def test_cleanup_close_ssl_transport(loop: Any, ssl_key: Any) -> None:\n    proto = create_mocked_conn(loop)\n    transport = proto.transport\n    testset = {ssl_key: [(proto, 10)]}\n\n    loop = mock.Mock()\n    loop.time.return_value = asyncio.get_event_loop().time() + 300\n    conn = aiohttp.BaseConnector(enable_cleanup_closed=True)\n    conn._loop = loop\n    conn._conns = testset\n    existing_handle = conn._cleanup_handle = mock.Mock()\n\n    conn._cleanup()\n    assert existing_handle.cancel.called\n    assert conn._conns == {}\n    assert conn._cleanup_closed_transports == [transport]\n\n\nasync def test_cleanup2(loop: Any) -> None:\n    testset = {1: [(create_mocked_conn(), 300)]}\n    testset[1][0][0].is_connected.return_value = True\n\n    conn = aiohttp.BaseConnector(keepalive_timeout=10)\n    conn._loop = mock.Mock()\n    conn._loop.time.return_value = 300\n    conn._conns = testset\n    conn._cleanup()\n    assert conn._conns == testset\n\n    assert conn._cleanup_handle is not None\n    conn._loop.call_at.assert_called_with(310, mock.ANY, mock.ANY)\n    await conn.close()\n\n\nasync def test_cleanup3(loop: Any, key: Any) -> None:\n    testset = {\n        key: [(create_mocked_conn(loop), 290.1), (create_mocked_conn(loop), 305.1)]\n    }\n    testset[key][0][0].is_connected.return_value = True\n\n    conn = aiohttp.BaseConnector(keepalive_timeout=10)\n    conn._loop = mock.Mock()\n    conn._loop.time.return_value = 308.5\n    conn._conns = testset\n\n    conn._cleanup()\n    assert conn._conns == {key: [testset[key][1]]}\n\n    assert conn._cleanup_handle is not None\n    conn._loop.call_at.assert_called_with(319, mock.ANY, mock.ANY)\n    await conn.close()\n\n\nasync def test_cleanup_closed(loop: Any, mocker: Any) -> None:\n    if not hasattr(loop, \"__dict__\"):\n        pytest.skip(\"can not override loop attributes\")\n\n    mocker.spy(loop, \"call_at\")\n    conn = aiohttp.BaseConnector(enable_cleanup_closed=True)\n\n    tr = mock.Mock()\n    conn._cleanup_closed_handle = cleanup_closed_handle = mock.Mock()\n    conn._cleanup_closed_transports = [tr]\n    conn._cleanup_closed()\n    assert tr.abort.called\n    assert not conn._cleanup_closed_transports\n    assert loop.call_at.called\n    assert cleanup_closed_handle.cancel.called\n\n\nasync def test_cleanup_closed_disabled(loop: Any, mocker: Any) -> None:\n    conn = aiohttp.BaseConnector(enable_cleanup_closed=False)\n\n    tr = mock.Mock()\n    conn._cleanup_closed_transports = [tr]\n    conn._cleanup_closed()\n    assert tr.abort.called\n    assert not conn._cleanup_closed_transports\n\n\nasync def test_tcp_connector_ctor(loop: Any) -> None:\n    conn = aiohttp.TCPConnector()\n    assert conn._ssl is True\n\n    assert conn.use_dns_cache\n    assert conn.family == 0\n\n\nasync def test_invalid_ssl_param() -> None:\n    with pytest.raises(TypeError):\n        aiohttp.TCPConnector(ssl=object())\n\n\nasync def test_tcp_connector_ctor_fingerprint_valid(loop: Any) -> None:\n    valid = aiohttp.Fingerprint(hashlib.sha256(b\"foo\").digest())\n    conn = aiohttp.TCPConnector(ssl=valid)\n    assert conn._ssl is valid\n\n\nasync def test_insecure_fingerprint_md5(loop: Any) -> None:\n    with pytest.raises(ValueError):\n        aiohttp.TCPConnector(ssl=aiohttp.Fingerprint(hashlib.md5(b\"foo\").digest()))\n\n\nasync def test_insecure_fingerprint_sha1(loop: Any) -> None:\n    with pytest.raises(ValueError):\n        aiohttp.TCPConnector(ssl=aiohttp.Fingerprint(hashlib.sha1(b\"foo\").digest()))\n\n\nasync def test_tcp_connector_clear_dns_cache(loop: Any) -> None:\n    conn = aiohttp.TCPConnector()\n    hosts = [\"a\", \"b\"]\n    conn._cached_hosts.add((\"localhost\", 123), hosts)\n    conn._cached_hosts.add((\"localhost\", 124), hosts)\n    conn.clear_dns_cache(\"localhost\", 123)\n    with pytest.raises(KeyError):\n        conn._cached_hosts.next_addrs((\"localhost\", 123))\n\n    assert conn._cached_hosts.next_addrs((\"localhost\", 124)) == hosts\n\n    # Remove removed element is OK\n    conn.clear_dns_cache(\"localhost\", 123)\n    with pytest.raises(KeyError):\n        conn._cached_hosts.next_addrs((\"localhost\", 123))\n\n    conn.clear_dns_cache()\n    with pytest.raises(KeyError):\n        conn._cached_hosts.next_addrs((\"localhost\", 124))\n\n\nasync def test_tcp_connector_clear_dns_cache_bad_args(loop: Any) -> None:\n    conn = aiohttp.TCPConnector()\n    with pytest.raises(ValueError):\n        conn.clear_dns_cache(\"localhost\")\n\n\nasync def test_dont_recreate_ssl_context(loop: Any) -> None:\n    conn = aiohttp.TCPConnector()\n    ctx = conn._make_ssl_context(True)\n    assert ctx is conn._make_ssl_context(True)\n\n\nasync def test_dont_recreate_ssl_context2(loop: Any) -> None:\n    conn = aiohttp.TCPConnector()\n    ctx = conn._make_ssl_context(False)\n    assert ctx is conn._make_ssl_context(False)\n\n\nasync def test___get_ssl_context1(loop: Any) -> None:\n    conn = aiohttp.TCPConnector()\n    req = mock.Mock()\n    req.is_ssl.return_value = False\n    assert conn._get_ssl_context(req) is None\n\n\nasync def test___get_ssl_context2(loop: Any) -> None:\n    ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n    conn = aiohttp.TCPConnector()\n    req = mock.Mock()\n    req.is_ssl.return_value = True\n    req.ssl = ctx\n    assert conn._get_ssl_context(req) is ctx\n\n\nasync def test___get_ssl_context3(loop: Any) -> None:\n    ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n    conn = aiohttp.TCPConnector(ssl=ctx)\n    req = mock.Mock()\n    req.is_ssl.return_value = True\n    req.ssl = True\n    assert conn._get_ssl_context(req) is ctx\n\n\nasync def test___get_ssl_context4(loop: Any) -> None:\n    ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n    conn = aiohttp.TCPConnector(ssl=ctx)\n    req = mock.Mock()\n    req.is_ssl.return_value = True\n    req.ssl = False\n    assert conn._get_ssl_context(req) is conn._make_ssl_context(False)\n\n\nasync def test___get_ssl_context5(loop: Any) -> None:\n    ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n    conn = aiohttp.TCPConnector(ssl=ctx)\n    req = mock.Mock()\n    req.is_ssl.return_value = True\n    req.ssl = aiohttp.Fingerprint(hashlib.sha256(b\"1\").digest())\n    assert conn._get_ssl_context(req) is conn._make_ssl_context(False)\n\n\nasync def test___get_ssl_context6(loop: Any) -> None:\n    conn = aiohttp.TCPConnector()\n    req = mock.Mock()\n    req.is_ssl.return_value = True\n    req.ssl = True\n    assert conn._get_ssl_context(req) is conn._make_ssl_context(True)\n\n\nasync def test_close_twice(loop: Any) -> None:\n    proto = create_mocked_conn(loop)\n\n    conn = aiohttp.BaseConnector()\n    conn._conns[1] = [(proto, object())]\n    await conn.close()\n\n    assert not conn._conns\n    assert proto.close.called\n    assert conn.closed\n\n    conn._conns = \"Invalid\"  # fill with garbage\n    await conn.close()\n    assert conn.closed\n\n\nasync def test_close_cancels_cleanup_handle(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    conn._release(1, create_mocked_conn(should_close=False))\n    assert conn._cleanup_handle is not None\n    await conn.close()\n    assert conn._cleanup_handle is None\n\n\nasync def test_close_abort_closed_transports(loop: Any) -> None:\n    tr = mock.Mock()\n\n    conn = aiohttp.BaseConnector()\n    conn._cleanup_closed_transports.append(tr)\n    await conn.close()\n\n    assert not conn._cleanup_closed_transports\n    assert tr.abort.called\n    assert conn.closed\n\n\nasync def test_close_cancels_cleanup_closed_handle(loop: Any) -> None:\n    conn = aiohttp.BaseConnector(enable_cleanup_closed=True)\n    assert conn._cleanup_closed_handle is not None\n    await conn.close()\n    assert conn._cleanup_closed_handle is None\n\n\nasync def test_ctor_with_default_loop(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    assert loop is conn._loop\n\n\nasync def test_connect_with_limit(loop: Any, key: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\n        \"GET\", URL(\"http://localhost:80\"), loop=loop, response_class=mock.Mock()\n    )\n\n    conn = aiohttp.BaseConnector(limit=1)\n    conn._conns[key] = [(proto, loop.time())]\n    conn._create_connection = mock.Mock()\n    conn._create_connection.return_value = loop.create_future()\n    conn._create_connection.return_value.set_result(proto)\n\n    connection1 = await conn.connect(req, None, ClientTimeout())\n    assert connection1._protocol == proto\n\n    assert 1 == len(conn._acquired)\n    assert proto in conn._acquired\n    assert key in conn._acquired_per_host\n    assert proto in conn._acquired_per_host[key]\n\n    acquired = False\n\n    async def f():\n        nonlocal acquired\n        connection2 = await conn.connect(req, None, ClientTimeout())\n        acquired = True\n        assert 1 == len(conn._acquired)\n        assert 1 == len(conn._acquired_per_host[key])\n        connection2.release()\n\n    task = loop.create_task(f())\n\n    await asyncio.sleep(0.01)\n    assert not acquired\n    connection1.release()\n    await asyncio.sleep(0)\n    assert acquired\n    await task\n    await conn.close()\n\n\nasync def test_connect_queued_operation_tracing(loop: Any, key: Any) -> None:\n    session = mock.Mock()\n    trace_config_ctx = mock.Mock()\n    on_connection_queued_start = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n    on_connection_queued_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n\n    trace_config = aiohttp.TraceConfig(\n        trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)\n    )\n    trace_config.on_connection_queued_start.append(on_connection_queued_start)\n    trace_config.on_connection_queued_end.append(on_connection_queued_end)\n    trace_config.freeze()\n    traces = [Trace(session, trace_config, trace_config.trace_config_ctx())]\n\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\n        \"GET\", URL(\"http://localhost1:80\"), loop=loop, response_class=mock.Mock()\n    )\n\n    conn = aiohttp.BaseConnector(limit=1)\n    conn._conns[key] = [(proto, loop.time())]\n    conn._create_connection = mock.Mock()\n    conn._create_connection.return_value = loop.create_future()\n    conn._create_connection.return_value.set_result(proto)\n\n    connection1 = await conn.connect(req, traces, ClientTimeout())\n\n    async def f():\n        connection2 = await conn.connect(req, traces, ClientTimeout())\n        on_connection_queued_start.assert_called_with(\n            session, trace_config_ctx, aiohttp.TraceConnectionQueuedStartParams()\n        )\n        on_connection_queued_end.assert_called_with(\n            session, trace_config_ctx, aiohttp.TraceConnectionQueuedEndParams()\n        )\n        connection2.release()\n\n    task = asyncio.ensure_future(f())\n    await asyncio.sleep(0.01)\n    connection1.release()\n    await task\n    await conn.close()\n\n\nasync def test_connect_reuseconn_tracing(loop: Any, key: Any) -> None:\n    session = mock.Mock()\n    trace_config_ctx = mock.Mock()\n    on_connection_reuseconn = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))\n\n    trace_config = aiohttp.TraceConfig(\n        trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)\n    )\n    trace_config.on_connection_reuseconn.append(on_connection_reuseconn)\n    trace_config.freeze()\n    traces = [Trace(session, trace_config, trace_config.trace_config_ctx())]\n\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\n        \"GET\", URL(\"http://localhost:80\"), loop=loop, response_class=mock.Mock()\n    )\n\n    conn = aiohttp.BaseConnector(limit=1)\n    conn._conns[key] = [(proto, loop.time())]\n    conn2 = await conn.connect(req, traces, ClientTimeout())\n    conn2.release()\n\n    on_connection_reuseconn.assert_called_with(\n        session, trace_config_ctx, aiohttp.TraceConnectionReuseconnParams()\n    )\n    await conn.close()\n\n\nasync def test_connect_with_limit_and_limit_per_host(loop: Any, key: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"http://localhost:80\"), loop=loop)\n\n    conn = aiohttp.BaseConnector(limit=1000, limit_per_host=1)\n    conn._conns[key] = [(proto, loop.time())]\n    conn._create_connection = mock.Mock()\n    conn._create_connection.return_value = loop.create_future()\n    conn._create_connection.return_value.set_result(proto)\n\n    acquired = False\n    connection1 = await conn.connect(req, None, ClientTimeout())\n\n    async def f():\n        nonlocal acquired\n        connection2 = await conn.connect(req, None, ClientTimeout())\n        acquired = True\n        assert 1 == len(conn._acquired)\n        assert 1 == len(conn._acquired_per_host[key])\n        connection2.release()\n\n    task = loop.create_task(f())\n\n    await asyncio.sleep(0.01)\n    assert not acquired\n    connection1.release()\n    await asyncio.sleep(0)\n    assert acquired\n    await task\n    await conn.close()\n\n\nasync def test_connect_with_no_limit_and_limit_per_host(loop: Any, key: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"http://localhost1:80\"), loop=loop)\n\n    conn = aiohttp.BaseConnector(limit=0, limit_per_host=1)\n    conn._conns[key] = [(proto, loop.time())]\n    conn._create_connection = mock.Mock()\n    conn._create_connection.return_value = loop.create_future()\n    conn._create_connection.return_value.set_result(proto)\n\n    acquired = False\n    connection1 = await conn.connect(req, None, ClientTimeout())\n\n    async def f():\n        nonlocal acquired\n        connection2 = await conn.connect(req, None, ClientTimeout())\n        acquired = True\n        connection2.release()\n\n    task = loop.create_task(f())\n\n    await asyncio.sleep(0.01)\n    assert not acquired\n    connection1.release()\n    await asyncio.sleep(0)\n    assert acquired\n    await task\n    await conn.close()\n\n\nasync def test_connect_with_no_limits(loop: Any, key: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"http://localhost:80\"), loop=loop)\n\n    conn = aiohttp.BaseConnector(limit=0, limit_per_host=0)\n    conn._conns[key] = [(proto, loop.time())]\n    conn._create_connection = mock.Mock()\n    conn._create_connection.return_value = loop.create_future()\n    conn._create_connection.return_value.set_result(proto)\n\n    acquired = False\n    connection1 = await conn.connect(req, None, ClientTimeout())\n\n    async def f():\n        nonlocal acquired\n        connection2 = await conn.connect(req, None, ClientTimeout())\n        acquired = True\n        assert 1 == len(conn._acquired)\n        assert 1 == len(conn._acquired_per_host[key])\n        connection2.release()\n\n    task = loop.create_task(f())\n\n    await asyncio.sleep(0.01)\n    assert acquired\n    connection1.release()\n    await task\n    await conn.close()\n\n\nasync def test_connect_with_limit_cancelled(loop: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"http://host:80\"), loop=loop)\n\n    conn = aiohttp.BaseConnector(limit=1)\n    key = (\"host\", 80, False)\n    conn._conns[key] = [(proto, loop.time())]\n    conn._create_connection = mock.Mock()\n    conn._create_connection.return_value = loop.create_future()\n    conn._create_connection.return_value.set_result(proto)\n\n    connection = await conn.connect(req, None, ClientTimeout())\n    assert connection._protocol == proto\n    assert connection.transport == proto.transport\n\n    assert 1 == len(conn._acquired)\n\n    with pytest.raises(asyncio.TimeoutError):\n        # limit exhausted\n        await asyncio.wait_for(conn.connect(req, None, ClientTimeout()), 0.01)\n    connection.close()\n\n    await conn.close()\n\n\nasync def test_connect_with_capacity_release_waiters(loop: Any) -> None:\n    def check_with_exc(err):\n        conn = aiohttp.BaseConnector(limit=1)\n        conn._create_connection = mock.Mock()\n        conn._create_connection.return_value = loop.create_future()\n        conn._create_connection.return_value.set_exception(err)\n\n        with pytest.raises(Exception):\n            req = mock.Mock()\n            yield from conn.connect(req, None, ClientTimeout())\n\n        assert not conn._waiters\n\n    check_with_exc(OSError(1, \"permission error\"))\n    check_with_exc(RuntimeError())\n    check_with_exc(asyncio.TimeoutError())\n\n\nasync def test_connect_with_limit_concurrent(loop: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.should_close = False\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"http://host:80\"), loop=loop)\n\n    max_connections = 2\n    num_connections = 0\n\n    conn = aiohttp.BaseConnector(limit=max_connections)\n\n    # Use a real coroutine for _create_connection; a mock would mask\n    # problems that only happen when the method yields.\n\n    async def create_connection(req, traces, timeout):\n        nonlocal num_connections\n        num_connections += 1\n        await asyncio.sleep(0)\n\n        # Make a new transport mock each time because acquired\n        # transports are stored in a set. Reusing the same object\n        # messes with the count.\n        proto = create_mocked_conn(loop, should_close=False)\n        proto.is_connected.return_value = True\n\n        return proto\n\n    conn._create_connection = create_connection\n\n    # Simulate something like a crawler. It opens a connection, does\n    # something with it, closes it, then creates tasks that make more\n    # connections and waits for them to finish. The crawler is started\n    # with multiple concurrent requests and stops when it hits a\n    # predefined maximum number of requests.\n\n    max_requests = 50\n    num_requests = 0\n    start_requests = max_connections + 1\n\n    async def f(start=True):\n        nonlocal num_requests\n        if num_requests == max_requests:\n            return\n        num_requests += 1\n        if not start:\n            connection = await conn.connect(req, None, ClientTimeout())\n            await asyncio.sleep(0)\n            connection.release()\n            await asyncio.sleep(0)\n        tasks = [loop.create_task(f(start=False)) for i in range(start_requests)]\n        await asyncio.wait(tasks)\n\n    await f()\n    await conn.close()\n\n    assert max_connections == num_connections\n\n\nasync def test_connect_waiters_cleanup(loop: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"http://host:80\"), loop=loop)\n\n    conn = aiohttp.BaseConnector(limit=1)\n    conn._available_connections = mock.Mock(return_value=0)\n\n    t = loop.create_task(conn.connect(req, None, ClientTimeout()))\n\n    await asyncio.sleep(0)\n    assert conn._waiters.keys()\n\n    t.cancel()\n    await asyncio.sleep(0)\n    assert not conn._waiters.keys()\n\n\nasync def test_connect_waiters_cleanup_key_error(loop: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"http://host:80\"), loop=loop)\n\n    conn = aiohttp.BaseConnector(limit=1)\n    conn._available_connections = mock.Mock(return_value=0)\n\n    t = loop.create_task(conn.connect(req, None, ClientTimeout()))\n\n    await asyncio.sleep(0)\n    assert conn._waiters.keys()\n\n    # we delete the entry explicitly before the\n    # canceled connection grabs the loop again, we\n    # must expect a none failure termination\n    conn._waiters.clear()\n    t.cancel()\n    await asyncio.sleep(0)\n    assert not conn._waiters.keys() == []\n\n\nasync def test_close_with_acquired_connection(loop: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"http://host:80\"), loop=loop)\n\n    conn = aiohttp.BaseConnector(limit=1)\n    key = (\"host\", 80, False)\n    conn._conns[key] = [(proto, loop.time())]\n    conn._create_connection = mock.Mock()\n    conn._create_connection.return_value = loop.create_future()\n    conn._create_connection.return_value.set_result(proto)\n\n    connection = await conn.connect(req, None, ClientTimeout())\n\n    assert 1 == len(conn._acquired)\n    await conn.close()\n    assert 0 == len(conn._acquired)\n    assert conn.closed\n    proto.close.assert_called_with()\n\n    assert not connection.closed\n    connection.close()\n    assert connection.closed\n\n\nasync def test_default_force_close(loop: Any) -> None:\n    connector = aiohttp.BaseConnector()\n    assert not connector.force_close\n\n\nasync def test_limit_property(loop: Any) -> None:\n    conn = aiohttp.BaseConnector(limit=15)\n    assert 15 == conn.limit\n\n    await conn.close()\n\n\nasync def test_limit_per_host_property(loop: Any) -> None:\n    conn = aiohttp.BaseConnector(limit_per_host=15)\n    assert 15 == conn.limit_per_host\n\n    await conn.close()\n\n\nasync def test_limit_property_default(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    assert conn.limit == 100\n    await conn.close()\n\n\nasync def test_limit_per_host_property_default(loop: Any) -> None:\n    conn = aiohttp.BaseConnector()\n    assert conn.limit_per_host == 0\n    await conn.close()\n\n\nasync def test_force_close_and_explicit_keep_alive(loop: Any) -> None:\n    with pytest.raises(ValueError):\n        aiohttp.BaseConnector(keepalive_timeout=30, force_close=True)\n\n    conn = aiohttp.BaseConnector(force_close=True, keepalive_timeout=None)\n    assert conn\n\n    conn = aiohttp.BaseConnector(force_close=True)\n\n    assert conn\n\n\nasync def test_error_on_connection(loop: Any, key: Any) -> None:\n    conn = aiohttp.BaseConnector(limit=1)\n\n    req = mock.Mock()\n    req.connection_key = key\n    proto = create_mocked_conn(loop)\n    i = 0\n\n    fut = loop.create_future()\n    exc = OSError()\n\n    async def create_connection(req, traces, timeout):\n        nonlocal i\n        i += 1\n        if i == 1:\n            await fut\n            raise exc\n        elif i == 2:\n            return proto\n\n    conn._create_connection = create_connection\n\n    t1 = loop.create_task(conn.connect(req, None, ClientTimeout()))\n    t2 = loop.create_task(conn.connect(req, None, ClientTimeout()))\n    await asyncio.sleep(0)\n    assert not t1.done()\n    assert not t2.done()\n    assert len(conn._acquired_per_host[key]) == 1\n\n    fut.set_result(None)\n    with pytest.raises(OSError):\n        await t1\n\n    ret = await t2\n    assert len(conn._acquired_per_host[key]) == 1\n\n    assert ret._key == key\n    assert ret.protocol == proto\n    assert proto in conn._acquired\n    ret.release()\n\n\nasync def test_cancelled_waiter(loop: Any) -> None:\n    conn = aiohttp.BaseConnector(limit=1)\n    req = mock.Mock()\n    req.connection_key = \"key\"\n    proto = create_mocked_conn(loop)\n\n    async def create_connection(req, traces=None):\n        await asyncio.sleep(1)\n        return proto\n\n    conn._create_connection = create_connection\n\n    conn._acquired.add(proto)\n\n    conn2 = loop.create_task(conn.connect(req, None, ClientTimeout()))\n    await asyncio.sleep(0)\n    conn2.cancel()\n\n    with pytest.raises(asyncio.CancelledError):\n        await conn2\n\n\nasync def test_error_on_connection_with_cancelled_waiter(loop: Any, key: Any) -> None:\n    conn = aiohttp.BaseConnector(limit=1)\n\n    req = mock.Mock()\n    req.connection_key = key\n    proto = create_mocked_conn()\n    i = 0\n\n    fut1 = loop.create_future()\n    fut2 = loop.create_future()\n    exc = OSError()\n\n    async def create_connection(req, traces, timeout):\n        nonlocal i\n        i += 1\n        if i == 1:\n            await fut1\n            raise exc\n        if i == 2:\n            await fut2\n        elif i == 3:\n            return proto\n\n    conn._create_connection = create_connection\n\n    t1 = loop.create_task(conn.connect(req, None, ClientTimeout()))\n    t2 = loop.create_task(conn.connect(req, None, ClientTimeout()))\n    t3 = loop.create_task(conn.connect(req, None, ClientTimeout()))\n    await asyncio.sleep(0)\n    assert not t1.done()\n    assert not t2.done()\n    assert len(conn._acquired_per_host[key]) == 1\n\n    fut1.set_result(None)\n    fut2.cancel()\n    with pytest.raises(OSError):\n        await t1\n\n    with pytest.raises(asyncio.CancelledError):\n        await t2\n\n    ret = await t3\n    assert len(conn._acquired_per_host[key]) == 1\n\n    assert ret._key == key\n    assert ret.protocol == proto\n    assert proto in conn._acquired\n    ret.release()\n\n\nasync def test_tcp_connector(aiohttp_client: Any, loop: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    r = await client.get(\"/\")\n    assert r.status == 200\n\n\n@pytest.mark.skipif(not hasattr(socket, \"AF_UNIX\"), reason=\"requires UNIX sockets\")\nasync def test_unix_connector_not_found(loop: Any) -> None:\n    connector = aiohttp.UnixConnector(\"/\" + uuid.uuid4().hex)\n\n    req = ClientRequest(\"GET\", URL(\"http://www.python.org\"), loop=loop)\n    with pytest.raises(aiohttp.ClientConnectorError):\n        await connector.connect(req, None, ClientTimeout())\n\n\n@pytest.mark.skipif(not hasattr(socket, \"AF_UNIX\"), reason=\"requires UNIX sockets\")\nasync def test_unix_connector_permission(loop: Any) -> None:\n    loop.create_unix_connection = make_mocked_coro(raise_exception=PermissionError())\n    connector = aiohttp.UnixConnector(\"/\" + uuid.uuid4().hex)\n\n    req = ClientRequest(\"GET\", URL(\"http://www.python.org\"), loop=loop)\n    with pytest.raises(aiohttp.ClientConnectorError):\n        await connector.connect(req, None, ClientTimeout())\n\n\n@pytest.mark.skipif(\n    platform.system() != \"Windows\", reason=\"Proactor Event loop present only in Windows\"\n)\nasync def test_named_pipe_connector_wrong_loop(\n    selector_loop: Any, pipe_name: Any\n) -> None:\n    with pytest.raises(RuntimeError):\n        aiohttp.NamedPipeConnector(pipe_name)\n\n\n@pytest.mark.skipif(\n    platform.system() != \"Windows\", reason=\"Proactor Event loop present only in Windows\"\n)\nasync def test_named_pipe_connector_not_found(\n    proactor_loop: Any, pipe_name: Any\n) -> None:\n    asyncio.set_event_loop(proactor_loop)\n    connector = aiohttp.NamedPipeConnector(pipe_name)\n\n    req = ClientRequest(\"GET\", URL(\"http://www.python.org\"), loop=proactor_loop)\n    with pytest.raises(aiohttp.ClientConnectorError):\n        await connector.connect(req, None, ClientTimeout())\n\n\n@pytest.mark.skipif(\n    platform.system() != \"Windows\", reason=\"Proactor Event loop present only in Windows\"\n)\nasync def test_named_pipe_connector_permission(\n    proactor_loop: Any, pipe_name: Any\n) -> None:\n    proactor_loop.create_pipe_connection = make_mocked_coro(\n        raise_exception=PermissionError()\n    )\n    asyncio.set_event_loop(proactor_loop)\n    connector = aiohttp.NamedPipeConnector(pipe_name)\n\n    req = ClientRequest(\"GET\", URL(\"http://www.python.org\"), loop=proactor_loop)\n    with pytest.raises(aiohttp.ClientConnectorError):\n        await connector.connect(req, None, ClientTimeout())\n\n\nasync def test_default_use_dns_cache() -> None:\n    conn = aiohttp.TCPConnector()\n    assert conn.use_dns_cache\n\n\nasync def test_resolver_not_called_with_address_is_ip(loop: Any) -> None:\n    resolver = mock.MagicMock()\n    connector = aiohttp.TCPConnector(resolver=resolver)\n\n    req = ClientRequest(\n        \"GET\",\n        URL(f\"http://127.0.0.1:{unused_port()}\"),\n        loop=loop,\n        response_class=mock.Mock(),\n    )\n\n    with pytest.raises(OSError):\n        await connector.connect(req, None, ClientTimeout())\n\n    resolver.resolve.assert_not_called()\n\n\nasync def test_tcp_connector_raise_connector_ssl_error(\n    aiohttp_server: Any, ssl_ctx: Any\n) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    srv = await aiohttp_server(app, ssl=ssl_ctx)\n\n    port = unused_port()\n    conn = aiohttp.TCPConnector(local_addr=(\"127.0.0.1\", port))\n\n    session = aiohttp.ClientSession(connector=conn)\n    url = srv.make_url(\"/\")\n\n    with pytest.raises(aiohttp.ClientConnectorCertificateError) as ctx:\n        await session.get(url)\n\n    assert isinstance(ctx.value, aiohttp.ClientConnectorCertificateError)\n    assert isinstance(ctx.value.certificate_error, ssl.SSLError)\n\n    await session.close()\n\n\n@pytest.mark.parametrize(\n    \"host\",\n    (\n        pytest.param(\"127.0.0.1\", id=\"ip address\"),\n        pytest.param(\"localhost\", id=\"domain name\"),\n        pytest.param(\"localhost.\", id=\"fully-qualified domain name\"),\n        pytest.param(\n            \"localhost...\", id=\"fully-qualified domain name with multiple trailing dots\"\n        ),\n        pytest.param(\"pr\u00edklad.localhost.\", id=\"idna fully-qualified domain name\"),\n    ),\n)\nasync def test_tcp_connector_do_not_raise_connector_ssl_error(\n    aiohttp_server: Any, ssl_ctx: Any, client_ssl_ctx: Any, host: str\n) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    srv = await aiohttp_server(app, ssl=ssl_ctx)\n    port = unused_port()\n    conn = aiohttp.TCPConnector(local_addr=(\"127.0.0.1\", port))\n\n    # resolving something.localhost with the real DNS resolver does not work on macOS, so we have a stub.\n    async def _resolve_host(host, port, traces=None):\n        return [\n            {\n                \"hostname\": host,\n                \"host\": \"127.0.0.1\",\n                \"port\": port,\n                \"family\": socket.AF_INET,\n                \"proto\": 0,\n                \"flags\": socket.AI_NUMERICHOST,\n            },\n            {\n                \"hostname\": host,\n                \"host\": \"::1\",\n                \"port\": port,\n                \"family\": socket.AF_INET,\n                \"proto\": 0,\n                \"flags\": socket.AI_NUMERICHOST,\n            },\n        ]\n\n    conn._resolve_host = _resolve_host\n\n    session = aiohttp.ClientSession(connector=conn)\n    url = srv.make_url(\"/\")\n\n    r = await session.get(url.with_host(host), ssl=client_ssl_ctx)\n\n    r.release()\n    first_conn = next(iter(conn._conns.values()))[0][0]\n\n    try:\n        _sslcontext = first_conn.transport._ssl_protocol._sslcontext\n    except AttributeError:\n        _sslcontext = first_conn.transport._sslcontext\n\n    assert _sslcontext is client_ssl_ctx\n    r.close()\n\n    await session.close()\n    await conn.close()\n\n\nasync def test_tcp_connector_uses_provided_local_addr(aiohttp_server: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    srv = await aiohttp_server(app)\n\n    port = unused_port()\n    conn = aiohttp.TCPConnector(local_addr=(\"127.0.0.1\", port))\n\n    session = aiohttp.ClientSession(connector=conn)\n    url = srv.make_url(\"/\")\n\n    r = await session.get(url)\n    r.release()\n\n    first_conn = next(iter(conn._conns.values()))[0][0]\n    assert first_conn.transport.get_extra_info(\"sockname\") == (\"127.0.0.1\", port)\n    r.close()\n    await session.close()\n    await conn.close()\n\n\nasync def test_unix_connector(unix_server: Any, unix_sockname: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    await unix_server(app)\n\n    url = \"http://127.0.0.1/\"\n\n    connector = aiohttp.UnixConnector(unix_sockname)\n    assert unix_sockname == connector.path\n\n    session = client.ClientSession(connector=connector)\n    r = await session.get(url)\n    assert r.status == 200\n    r.close()\n    await session.close()\n\n\n@pytest.mark.skipif(\n    platform.system() != \"Windows\", reason=\"Proactor Event loop present only in Windows\"\n)\nasync def test_named_pipe_connector(\n    proactor_loop: Any, named_pipe_server: Any, pipe_name: Any\n) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    await named_pipe_server(app)\n\n    url = \"http://this-does-not-matter.com\"\n\n    connector = aiohttp.NamedPipeConnector(pipe_name)\n    assert pipe_name == connector.path\n\n    session = client.ClientSession(connector=connector)\n    r = await session.get(url)\n    assert r.status == 200\n    r.close()\n    await session.close()\n\n\nclass TestDNSCacheTable:\n    @pytest.fixture\n    def dns_cache_table(self):\n        return _DNSCacheTable()\n\n    def test_next_addrs_basic(self, dns_cache_table: Any) -> None:\n        dns_cache_table.add(\"localhost\", [\"127.0.0.1\"])\n        dns_cache_table.add(\"foo\", [\"127.0.0.2\"])\n\n        addrs = dns_cache_table.next_addrs(\"localhost\")\n        assert addrs == [\"127.0.0.1\"]\n        addrs = dns_cache_table.next_addrs(\"foo\")\n        assert addrs == [\"127.0.0.2\"]\n        with pytest.raises(KeyError):\n            dns_cache_table.next_addrs(\"no-such-host\")\n\n    def test_remove(self, dns_cache_table: Any) -> None:\n        dns_cache_table.add(\"localhost\", [\"127.0.0.1\"])\n        dns_cache_table.remove(\"localhost\")\n        with pytest.raises(KeyError):\n            dns_cache_table.next_addrs(\"localhost\")\n\n    def test_clear(self, dns_cache_table: Any) -> None:\n        dns_cache_table.add(\"localhost\", [\"127.0.0.1\"])\n        dns_cache_table.clear()\n        with pytest.raises(KeyError):\n            dns_cache_table.next_addrs(\"localhost\")\n\n    def test_not_expired_ttl_None(self, dns_cache_table: Any) -> None:\n        dns_cache_table.add(\"localhost\", [\"127.0.0.1\"])\n        assert not dns_cache_table.expired(\"localhost\")\n\n    def test_not_expired_ttl(self) -> None:\n        dns_cache_table = _DNSCacheTable(ttl=0.1)\n        dns_cache_table.add(\"localhost\", [\"127.0.0.1\"])\n        assert not dns_cache_table.expired(\"localhost\")\n\n    def test_expired_ttl(self, monkeypatch: pytest.MonkeyPatch) -> None:\n        dns_cache_table = _DNSCacheTable(ttl=1)\n        monkeypatch.setattr(\"aiohttp.connector.monotonic\", lambda: 1)\n        dns_cache_table.add(\"localhost\", [\"127.0.0.1\"])\n        monkeypatch.setattr(\"aiohttp.connector.monotonic\", lambda: 2)\n        assert not dns_cache_table.expired(\"localhost\")\n        monkeypatch.setattr(\"aiohttp.connector.monotonic\", lambda: 3)\n        assert dns_cache_table.expired(\"localhost\")\n\n    def test_never_expire(self, monkeypatch: pytest.MonkeyPatch) -> None:\n        dns_cache_table = _DNSCacheTable(ttl=None)\n        monkeypatch.setattr(\"aiohttp.connector.monotonic\", lambda: 1)\n        dns_cache_table.add(\"localhost\", [\"127.0.0.1\"])\n        monkeypatch.setattr(\"aiohttp.connector.monotonic\", lambda: 10000000)\n        assert not dns_cache_table.expired(\"localhost\")\n\n    def test_always_expire(self, monkeypatch: pytest.MonkeyPatch) -> None:\n        dns_cache_table = _DNSCacheTable(ttl=0)\n        monkeypatch.setattr(\"aiohttp.connector.monotonic\", lambda: 1)\n        dns_cache_table.add(\"localhost\", [\"127.0.0.1\"])\n        monkeypatch.setattr(\"aiohttp.connector.monotonic\", lambda: 1.00001)\n        assert dns_cache_table.expired(\"localhost\")\n\n    def test_next_addrs(self, dns_cache_table: Any) -> None:\n        dns_cache_table.add(\"foo\", [\"127.0.0.1\", \"127.0.0.2\", \"127.0.0.3\"])\n\n        # Each calls to next_addrs return the hosts using\n        # a round robin strategy.\n        addrs = dns_cache_table.next_addrs(\"foo\")\n        assert addrs == [\"127.0.0.1\", \"127.0.0.2\", \"127.0.0.3\"]\n\n        addrs = dns_cache_table.next_addrs(\"foo\")\n        assert addrs == [\"127.0.0.2\", \"127.0.0.3\", \"127.0.0.1\"]\n\n        addrs = dns_cache_table.next_addrs(\"foo\")\n        assert addrs == [\"127.0.0.3\", \"127.0.0.1\", \"127.0.0.2\"]\n\n        addrs = dns_cache_table.next_addrs(\"foo\")\n        assert addrs == [\"127.0.0.1\", \"127.0.0.2\", \"127.0.0.3\"]\n\n    def test_next_addrs_single(self, dns_cache_table: Any) -> None:\n        dns_cache_table.add(\"foo\", [\"127.0.0.1\"])\n\n        addrs = dns_cache_table.next_addrs(\"foo\")\n        assert addrs == [\"127.0.0.1\"]\n\n        addrs = dns_cache_table.next_addrs(\"foo\")\n        assert addrs == [\"127.0.0.1\"]\n\n\nasync def test_connector_cache_trace_race() -> None:\n    class DummyTracer:\n        async def send_dns_cache_hit(self, *args, **kwargs):\n            connector._cached_hosts.remove((\"\", 0))\n\n    token = object()\n    connector = TCPConnector()\n    connector._cached_hosts.add((\"\", 0), [token])\n\n    traces = [DummyTracer()]\n    assert await connector._resolve_host(\"\", 0, traces) == [token]\n\n\nasync def test_connector_throttle_trace_race(loop: Any) -> None:\n    key = (\"\", 0)\n    token = object()\n\n    class DummyTracer:\n        async def send_dns_cache_hit(self, *args, **kwargs):\n            event = connector._throttle_dns_events.pop(key)\n            event.set()\n            connector._cached_hosts.add(key, [token])\n\n    connector = TCPConnector()\n    connector._throttle_dns_events[key] = EventResultOrError(loop)\n    traces = [DummyTracer()]\n    assert await connector._resolve_host(\"\", 0, traces) == [token]\n\n\nasync def test_connector_does_not_remove_needed_waiters(loop: Any, key: Any) -> None:\n    proto = create_mocked_conn(loop)\n    proto.is_connected.return_value = True\n\n    req = ClientRequest(\"GET\", URL(\"https://localhost:80\"), loop=loop)\n    connection_key = req.connection_key\n\n    connector = aiohttp.BaseConnector()\n    connector._available_connections = mock.Mock(return_value=0)\n    connector._conns[key] = [(proto, loop.time())]\n    connector._create_connection = create_mocked_conn(loop)\n    connector._create_connection.return_value = loop.create_future()\n    connector._create_connection.return_value.set_result(proto)\n\n    dummy_waiter = loop.create_future()\n\n    async def await_connection_and_check_waiters() -> None:\n        connection = await connector.connect(req, [], ClientTimeout())\n        try:\n            assert connection_key in connector._waiters\n            assert dummy_waiter in connector._waiters[connection_key]\n        finally:\n            connection.close()\n\n    async def allow_connection_and_add_dummy_waiter() -> None:\n        # `asyncio.gather` may execute coroutines not in order.\n        # Skip one event loop run cycle in such a case.\n        if connection_key not in connector._waiters:\n            await asyncio.sleep(0)\n        connector._waiters[connection_key].popleft().set_result(None)\n        del connector._waiters[connection_key]\n        connector._waiters[connection_key].append(dummy_waiter)\n\n    await asyncio.gather(\n        await_connection_and_check_waiters(),\n        allow_connection_and_add_dummy_waiter(),\n    )\n\n    await connector.close()\n", "tests/test_multipart.py": "# type: ignore\nimport asyncio\nimport io\nimport json\nimport pathlib\nimport zlib\nfrom typing import Any, Optional\nfrom unittest import mock\n\nimport pytest\n\nimport aiohttp\nfrom aiohttp import payload\nfrom aiohttp.hdrs import (\n    CONTENT_DISPOSITION,\n    CONTENT_ENCODING,\n    CONTENT_TRANSFER_ENCODING,\n    CONTENT_TYPE,\n)\nfrom aiohttp.helpers import parse_mimetype\nfrom aiohttp.multipart import MultipartResponseWrapper\nfrom aiohttp.streams import StreamReader\nfrom aiohttp.test_utils import make_mocked_coro\n\nBOUNDARY: bytes = b\"--:\"\n\n\n@pytest.fixture\ndef buf():\n    return bytearray()\n\n\n@pytest.fixture\ndef stream(buf: Any):\n    writer = mock.Mock()\n\n    async def write(chunk):\n        buf.extend(chunk)\n\n    writer.write.side_effect = write\n    return writer\n\n\n@pytest.fixture\ndef writer():\n    return aiohttp.MultipartWriter(boundary=\":\")\n\n\nclass Response:\n    headers: Any\n    content: Any\n\n    def __init__(self, headers: Any, content: Any) -> None:\n        self.headers = headers\n        self.content = content\n\n\nclass Stream:\n    content: Any\n\n    def __init__(self, content: Any) -> None:\n        self.content = io.BytesIO(content)\n\n    async def read(self, size: Optional[Any] = None):\n        return self.content.read(size)\n\n    def at_eof(self):\n        return self.content.tell() == len(self.content.getbuffer())\n\n    async def readline(self):\n        return self.content.readline()\n\n    def unread_data(self, data: Any) -> None:\n        self.content = io.BytesIO(data + self.content.read())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.content.close()\n\n\nclass StreamWithShortenRead(Stream):\n    def __init__(self, content: Any) -> None:\n        self._first = True\n        super().__init__(content)\n\n    async def read(self, size: Optional[Any] = None):\n        if size is not None and self._first:\n            self._first = False\n            size = size // 2\n        return await super().read(size)\n\n\nclass TestMultipartResponseWrapper:\n    def test_at_eof(self) -> None:\n        wrapper = MultipartResponseWrapper(mock.Mock(), mock.Mock())\n        wrapper.at_eof()\n        assert wrapper.resp.content.at_eof.called\n\n    async def test_next(self) -> None:\n        wrapper = MultipartResponseWrapper(mock.Mock(), mock.Mock())\n        wrapper.stream.next = make_mocked_coro(b\"\")\n        wrapper.stream.at_eof.return_value = False\n        await wrapper.next()\n        assert wrapper.stream.next.called\n\n    async def test_release(self) -> None:\n        wrapper = MultipartResponseWrapper(mock.Mock(), mock.Mock())\n        wrapper.resp.release = make_mocked_coro(None)\n        await wrapper.release()\n        assert wrapper.resp.release.called\n\n    async def test_release_when_stream_at_eof(self) -> None:\n        wrapper = MultipartResponseWrapper(mock.Mock(), mock.Mock())\n        wrapper.resp.release = make_mocked_coro(None)\n        wrapper.stream.next = make_mocked_coro(b\"\")\n        wrapper.stream.at_eof.return_value = True\n        await wrapper.next()\n        assert wrapper.stream.next.called\n        assert wrapper.resp.release.called\n\n\nclass TestPartReader:\n    async def test_next(self) -> None:\n        with Stream(b\"Hello, world!\\r\\n--:\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.next()\n            assert b\"Hello, world!\" == result\n            assert obj.at_eof()\n\n    async def test_next_next(self) -> None:\n        with Stream(b\"Hello, world!\\r\\n--:\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.next()\n            assert b\"Hello, world!\" == result\n            assert obj.at_eof()\n            result = await obj.next()\n            assert result is None\n\n    async def test_read(self) -> None:\n        with Stream(b\"Hello, world!\\r\\n--:\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.read()\n            assert b\"Hello, world!\" == result\n            assert obj.at_eof()\n\n    async def test_read_chunk_at_eof(self) -> None:\n        with Stream(b\"--:\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            obj._at_eof = True\n            result = await obj.read_chunk()\n        assert b\"\" == result\n\n    async def test_read_chunk_without_content_length(self) -> None:\n        with Stream(b\"Hello, world!\\r\\n--:\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            c1 = await obj.read_chunk(8)\n            c2 = await obj.read_chunk(8)\n            c3 = await obj.read_chunk(8)\n        assert c1 + c2 == b\"Hello, world!\"\n        assert c3 == b\"\"\n\n    async def test_read_incomplete_chunk(self) -> None:\n        with Stream(b\"\") as stream:\n\n            def prepare(data):\n                return data\n\n            with mock.patch.object(\n                stream,\n                \"read\",\n                side_effect=[\n                    prepare(b\"Hello, \"),\n                    prepare(b\"World\"),\n                    prepare(b\"!\\r\\n--:\"),\n                    prepare(b\"\"),\n                ],\n            ):\n                obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n                c1 = await obj.read_chunk(8)\n                assert c1 == b\"Hello, \"\n                c2 = await obj.read_chunk(8)\n                assert c2 == b\"World\"\n                c3 = await obj.read_chunk(8)\n                assert c3 == b\"!\"\n\n    async def test_read_all_at_once(self) -> None:\n        with Stream(b\"Hello, World!\\r\\n--:--\\r\\n\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.read_chunk()\n            assert b\"Hello, World!\" == result\n            result = await obj.read_chunk()\n            assert b\"\" == result\n            assert obj.at_eof()\n\n    async def test_read_incomplete_body_chunked(self) -> None:\n        with Stream(b\"Hello, World!\\r\\n-\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = b\"\"\n            with pytest.raises(AssertionError):\n                for _ in range(4):\n                    result += await obj.read_chunk(7)\n        assert b\"Hello, World!\\r\\n-\" == result\n\n    async def test_read_boundary_with_incomplete_chunk(self) -> None:\n        with Stream(b\"\") as stream:\n\n            def prepare(data):\n                return data\n\n            with mock.patch.object(\n                stream,\n                \"read\",\n                side_effect=[\n                    prepare(b\"Hello, World\"),\n                    prepare(b\"!\\r\\n\"),\n                    prepare(b\"--:\"),\n                    prepare(b\"\"),\n                ],\n            ):\n                obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n                c1 = await obj.read_chunk(12)\n                assert c1 == b\"Hello, World\"\n                c2 = await obj.read_chunk(8)\n                assert c2 == b\"!\"\n                c3 = await obj.read_chunk(8)\n                assert c3 == b\"\"\n\n    async def test_multi_read_chunk(self) -> None:\n        with Stream(b\"Hello,\\r\\n--:\\r\\n\\r\\nworld!\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.read_chunk(8)\n            assert b\"Hello,\" == result\n            result = await obj.read_chunk(8)\n            assert b\"\" == result\n            assert obj.at_eof()\n\n    async def test_read_chunk_properly_counts_read_bytes(self) -> None:\n        expected = b\".\" * 10\n        size = len(expected)\n        with StreamWithShortenRead(expected + b\"\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {\"CONTENT-LENGTH\": size}, stream)\n            result = bytearray()\n            while True:\n                chunk = await obj.read_chunk()\n                if not chunk:\n                    break\n                result.extend(chunk)\n        assert size == len(result)\n        assert b\".\" * size == result\n        assert obj.at_eof()\n\n    async def test_read_does_not_read_boundary(self) -> None:\n        with Stream(b\"Hello, world!\\r\\n--:\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.read()\n            assert b\"Hello, world!\" == result\n            assert b\"--:\" == (await stream.read())\n\n    async def test_multiread(self) -> None:\n        with Stream(b\"Hello,\\r\\n--:\\r\\n\\r\\nworld!\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.read()\n            assert b\"Hello,\" == result\n            result = await obj.read()\n            assert b\"\" == result\n            assert obj.at_eof()\n\n    async def test_read_multiline(self) -> None:\n        with Stream(b\"Hello\\n,\\r\\nworld!\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.read()\n            assert b\"Hello\\n,\\r\\nworld!\" == result\n            result = await obj.read()\n            assert b\"\" == result\n            assert obj.at_eof()\n\n    async def test_read_respects_content_length(self) -> None:\n        with Stream(b\".\" * 100500 + b\"\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {\"CONTENT-LENGTH\": 100500}, stream)\n            result = await obj.read()\n            assert b\".\" * 100500 == result\n            assert obj.at_eof()\n\n    async def test_read_with_content_encoding_gzip(self) -> None:\n        with Stream(\n            b\"\\x1f\\x8b\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x0b\\xc9\\xccMU\"\n            b\"(\\xc9W\\x08J\\xcdI\\xacP\\x04\\x00$\\xfb\\x9eV\\x0e\\x00\\x00\\x00\"\n            b\"\\r\\n--:--\"\n        ) as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {CONTENT_ENCODING: \"gzip\"}, stream)\n            result = await obj.read(decode=True)\n        assert b\"Time to Relax!\" == result\n\n    async def test_read_with_content_encoding_deflate(self) -> None:\n        with Stream(b\"\\x0b\\xc9\\xccMU(\\xc9W\\x08J\\xcdI\\xacP\\x04\\x00\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_ENCODING: \"deflate\"}, stream\n            )\n            result = await obj.read(decode=True)\n        assert b\"Time to Relax!\" == result\n\n    async def test_read_with_content_encoding_identity(self) -> None:\n        thing = (\n            b\"\\x1f\\x8b\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x0b\\xc9\\xccMU\"\n            b\"(\\xc9W\\x08J\\xcdI\\xacP\\x04\\x00$\\xfb\\x9eV\\x0e\\x00\\x00\\x00\"\n            b\"\\r\\n\"\n        )\n        with Stream(thing + b\"--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_ENCODING: \"identity\"}, stream\n            )\n            result = await obj.read(decode=True)\n        assert thing[:-2] == result\n\n    async def test_read_with_content_encoding_unknown(self) -> None:\n        with Stream(b\"\\x0e4Time to Relax!\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {CONTENT_ENCODING: \"snappy\"}, stream)\n            with pytest.raises(RuntimeError):\n                await obj.read(decode=True)\n\n    async def test_read_with_content_transfer_encoding_base64(self) -> None:\n        with Stream(b\"VGltZSB0byBSZWxheCE=\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TRANSFER_ENCODING: \"base64\"}, stream\n            )\n            result = await obj.read(decode=True)\n        assert b\"Time to Relax!\" == result\n\n    async def test_decode_with_content_transfer_encoding_base64(self) -> None:\n        with Stream(b\"VG\\r\\r\\nltZSB0byBSZ\\r\\nWxheCE=\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TRANSFER_ENCODING: \"base64\"}, stream\n            )\n            result = b\"\"\n            while not obj.at_eof():\n                chunk = await obj.read_chunk(size=6)\n                result += obj.decode(chunk)\n        assert b\"Time to Relax!\" == result\n\n    async def test_read_with_content_transfer_encoding_quoted_printable(self) -> None:\n        with Stream(\n            b\"=D0=9F=D1=80=D0=B8=D0=B2=D0=B5=D1=82,\" b\" =D0=BC=D0=B8=D1=80!\\r\\n--:--\"\n        ) as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TRANSFER_ENCODING: \"quoted-printable\"}, stream\n            )\n            result = await obj.read(decode=True)\n        expected = (\n            b\"\\xd0\\x9f\\xd1\\x80\\xd0\\xb8\\xd0\\xb2\\xd0\\xb5\\xd1\\x82,\"\n            b\" \\xd0\\xbc\\xd0\\xb8\\xd1\\x80!\"\n        )\n        assert result == expected\n\n    @pytest.mark.parametrize(\"encoding\", (\"binary\", \"8bit\", \"7bit\"))\n    async def test_read_with_content_transfer_encoding_binary(\n        self, encoding: Any\n    ) -> None:\n        data = (\n            b\"\\xd0\\x9f\\xd1\\x80\\xd0\\xb8\\xd0\\xb2\\xd0\\xb5\\xd1\\x82,\"\n            b\" \\xd0\\xbc\\xd0\\xb8\\xd1\\x80!\"\n        )\n        with Stream(data + b\"\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TRANSFER_ENCODING: encoding}, stream\n            )\n            result = await obj.read(decode=True)\n        assert data == result\n\n    async def test_read_with_content_transfer_encoding_unknown(self) -> None:\n        with Stream(b\"\\x0e4Time to Relax!\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TRANSFER_ENCODING: \"unknown\"}, stream\n            )\n            with pytest.raises(RuntimeError):\n                await obj.read(decode=True)\n\n    async def test_read_text(self) -> None:\n        with Stream(b\"Hello, world!\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.text()\n        assert \"Hello, world!\" == result\n\n    async def test_read_text_default_encoding(self) -> None:\n        with Stream(\"\u041f\u0440\u0438\u0432\u0435\u0442, \u041c\u0438\u0440!\\r\\n--:--\".encode()) as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.text()\n        assert \"\u041f\u0440\u0438\u0432\u0435\u0442, \u041c\u0438\u0440!\" == result\n\n    async def test_read_text_encoding(self) -> None:\n        with Stream(\"\u041f\u0440\u0438\u0432\u0435\u0442, \u041c\u0438\u0440!\\r\\n--:--\".encode(\"cp1251\")) as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.text(encoding=\"cp1251\")\n        assert \"\u041f\u0440\u0438\u0432\u0435\u0442, \u041c\u0438\u0440!\" == result\n\n    async def test_read_text_guess_encoding(self) -> None:\n        with Stream(\"\u041f\u0440\u0438\u0432\u0435\u0442, \u041c\u0438\u0440!\\r\\n--:--\".encode(\"cp1251\")) as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TYPE: \"text/plain;charset=cp1251\"}, stream\n            )\n            result = await obj.text()\n        assert \"\u041f\u0440\u0438\u0432\u0435\u0442, \u041c\u0438\u0440!\" == result\n\n    async def test_read_text_compressed(self) -> None:\n        with Stream(b\"\\x0b\\xc9\\xccMU(\\xc9W\\x08J\\xcdI\\xacP\\x04\\x00\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY,\n                {CONTENT_ENCODING: \"deflate\", CONTENT_TYPE: \"text/plain\"},\n                stream,\n            )\n            result = await obj.text()\n        assert \"Time to Relax!\" == result\n\n    async def test_read_text_while_closed(self) -> None:\n        with Stream(b\"\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {CONTENT_TYPE: \"text/plain\"}, stream)\n            obj._at_eof = True\n            result = await obj.text()\n        assert \"\" == result\n\n    async def test_read_json(self) -> None:\n        with Stream(b'{\"test\": \"passed\"}\\r\\n--:--') as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TYPE: \"application/json\"}, stream\n            )\n            result = await obj.json()\n        assert {\"test\": \"passed\"} == result\n\n    async def test_read_json_encoding(self) -> None:\n        with Stream('{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0430\u0441\u0441\u0435\u0434\"}\\r\\n--:--'.encode(\"cp1251\")) as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TYPE: \"application/json\"}, stream\n            )\n            result = await obj.json(encoding=\"cp1251\")\n        assert {\"\u0442\u0435\u0441\u0442\": \"\u043f\u0430\u0441\u0441\u0435\u0434\"} == result\n\n    async def test_read_json_guess_encoding(self) -> None:\n        with Stream('{\"\u0442\u0435\u0441\u0442\": \"\u043f\u0430\u0441\u0441\u0435\u0434\"}\\r\\n--:--'.encode(\"cp1251\")) as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TYPE: \"application/json; charset=cp1251\"}, stream\n            )\n            result = await obj.json()\n        assert {\"\u0442\u0435\u0441\u0442\": \"\u043f\u0430\u0441\u0441\u0435\u0434\"} == result\n\n    async def test_read_json_compressed(self) -> None:\n        with Stream(b\"\\xabV*I-.Q\\xb2RP*H,.NMQ\\xaa\\x05\\x00\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY,\n                {CONTENT_ENCODING: \"deflate\", CONTENT_TYPE: \"application/json\"},\n                stream,\n            )\n            result = await obj.json()\n        assert {\"test\": \"passed\"} == result\n\n    async def test_read_json_while_closed(self) -> None:\n        with Stream(b\"\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TYPE: \"application/json\"}, stream\n            )\n            obj._at_eof = True\n            result = await obj.json()\n        assert result is None\n\n    async def test_read_form(self) -> None:\n        with Stream(b\"foo=bar&foo=baz&boo=\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TYPE: \"application/x-www-form-urlencoded\"}, stream\n            )\n            result = await obj.form()\n        assert [(\"foo\", \"bar\"), (\"foo\", \"baz\"), (\"boo\", \"\")] == result\n\n    async def test_read_form_invalid_utf8(self) -> None:\n        with Stream(b\"\\xff\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TYPE: \"application/x-www-form-urlencoded\"}, stream\n            )\n            with pytest.raises(\n                ValueError, match=\"data cannot be decoded with utf-8 encoding\"\n            ):\n                await obj.form()\n\n    async def test_read_form_encoding(self) -> None:\n        with Stream(\"foo=bar&foo=baz&boo=\\r\\n--:--\".encode(\"cp1251\")) as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY, {CONTENT_TYPE: \"application/x-www-form-urlencoded\"}, stream\n            )\n            result = await obj.form(encoding=\"cp1251\")\n        assert [(\"foo\", \"bar\"), (\"foo\", \"baz\"), (\"boo\", \"\")] == result\n\n    async def test_read_form_guess_encoding(self) -> None:\n        with Stream(b\"foo=bar&foo=baz&boo=\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY,\n                {CONTENT_TYPE: \"application/x-www-form-urlencoded; charset=utf-8\"},\n                stream,\n            )\n            result = await obj.form()\n        assert [(\"foo\", \"bar\"), (\"foo\", \"baz\"), (\"boo\", \"\")] == result\n\n    async def test_read_form_while_closed(self) -> None:\n        with Stream(b\"\") as stream:\n            obj = aiohttp.BodyPartReader(\n                BOUNDARY,\n                {CONTENT_TYPE: \"application/x-www-form-urlencoded\"},\n                stream,\n            )\n            obj._at_eof = True\n            result = await obj.form()\n        assert not result\n\n    async def test_readline(self) -> None:\n        with Stream(b\"Hello\\n,\\r\\nworld!\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            result = await obj.readline()\n            assert b\"Hello\\n\" == result\n            result = await obj.readline()\n            assert b\",\\r\\n\" == result\n            result = await obj.readline()\n            assert b\"world!\" == result\n            result = await obj.readline()\n            assert b\"\" == result\n            assert obj.at_eof()\n\n    async def test_release(self) -> None:\n        with Stream(b\"Hello,\\r\\n--:\\r\\n\\r\\nworld!\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            await obj.release()\n            assert obj.at_eof()\n            assert b\"--:\\r\\n\\r\\nworld!\\r\\n--:--\" == stream.content.read()\n\n    async def test_release_respects_content_length(self) -> None:\n        with Stream(b\".\" * 100500 + b\"\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {\"CONTENT-LENGTH\": 100500}, stream)\n            result = await obj.release()\n            assert result is None\n            assert obj.at_eof()\n\n    async def test_release_release(self) -> None:\n        with Stream(b\"Hello,\\r\\n--:\\r\\n\\r\\nworld!\\r\\n--:--\") as stream:\n            obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n            await obj.release()\n            await obj.release()\n            assert b\"--:\\r\\n\\r\\nworld!\\r\\n--:--\" == stream.content.read()\n\n    async def test_filename(self) -> None:\n        part = aiohttp.BodyPartReader(\n            BOUNDARY, {CONTENT_DISPOSITION: \"attachment; filename=foo.html\"}, None\n        )\n        assert \"foo.html\" == part.filename\n\n    async def test_reading_long_part(self) -> None:\n        size = 2 * 2**16\n        protocol = mock.Mock(_reading_paused=False)\n        stream = StreamReader(protocol, 2**16, loop=asyncio.get_event_loop())\n        stream.feed_data(b\"0\" * size + b\"\\r\\n--:--\")\n        stream.feed_eof()\n        obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)\n        data = await obj.read()\n        assert len(data) == size\n\n\nclass TestMultipartReader:\n    def test_from_response(self) -> None:\n        with Stream(b\"--:\\r\\n\\r\\nhello\\r\\n--:--\") as stream:\n            resp = Response(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            res = aiohttp.MultipartReader.from_response(resp)\n        assert isinstance(res, MultipartResponseWrapper)\n        assert isinstance(res.stream, aiohttp.MultipartReader)\n\n    def test_bad_boundary(self) -> None:\n        with Stream(b\"\") as stream:\n            resp = Response(\n                {CONTENT_TYPE: \"multipart/related;boundary=\" + \"a\" * 80}, stream\n            )\n            with pytest.raises(ValueError):\n                aiohttp.MultipartReader.from_response(resp)\n\n    def test_dispatch(self) -> None:\n        with Stream(b\"--:\\r\\n\\r\\necho\\r\\n--:--\") as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            res = reader._get_part_reader({CONTENT_TYPE: \"text/plain\"})\n        assert isinstance(res, reader.part_reader_cls)\n\n    def test_dispatch_bodypart(self) -> None:\n        with Stream(b\"--:\\r\\n\\r\\necho\\r\\n--:--\") as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            res = reader._get_part_reader({CONTENT_TYPE: \"text/plain\"})\n        assert isinstance(res, reader.part_reader_cls)\n\n    def test_dispatch_multipart(self) -> None:\n        with Stream(\n            b\"----:--\\r\\n\"\n            b\"\\r\\n\"\n            b\"test\\r\\n\"\n            b\"----:--\\r\\n\"\n            b\"\\r\\n\"\n            b\"passed\\r\\n\"\n            b\"----:----\\r\\n\"\n            b\"--:--\"\n        ) as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            res = reader._get_part_reader(\n                {CONTENT_TYPE: \"multipart/related;boundary=--:--\"}\n            )\n        assert isinstance(res, reader.__class__)\n\n    def test_dispatch_custom_multipart_reader(self) -> None:\n        class CustomReader(aiohttp.MultipartReader):\n            pass\n\n        with Stream(\n            b\"----:--\\r\\n\"\n            b\"\\r\\n\"\n            b\"test\\r\\n\"\n            b\"----:--\\r\\n\"\n            b\"\\r\\n\"\n            b\"passed\\r\\n\"\n            b\"----:----\\r\\n\"\n            b\"--:--\"\n        ) as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            reader.multipart_reader_cls = CustomReader\n            res = reader._get_part_reader(\n                {CONTENT_TYPE: \"multipart/related;boundary=--:--\"}\n            )\n        assert isinstance(res, CustomReader)\n\n    async def test_emit_next(self) -> None:\n        with Stream(b\"--:\\r\\n\\r\\necho\\r\\n--:--\") as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            res = await reader.next()\n        assert isinstance(res, reader.part_reader_cls)\n\n    async def test_invalid_boundary(self) -> None:\n        with Stream(b\"---:\\r\\n\\r\\necho\\r\\n---:--\") as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            with pytest.raises(ValueError):\n                await reader.next()\n\n    async def test_release(self) -> None:\n        with Stream(\n            b\"--:\\r\\n\"\n            b\"Content-Type: multipart/related;boundary=--:--\\r\\n\"\n            b\"\\r\\n\"\n            b\"----:--\\r\\n\"\n            b\"\\r\\n\"\n            b\"test\\r\\n\"\n            b\"----:--\\r\\n\"\n            b\"\\r\\n\"\n            b\"passed\\r\\n\"\n            b\"----:----\\r\\n\"\n            b\"\\r\\n\"\n            b\"--:--\"\n        ) as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/mixed;boundary=\":\"'},\n                stream,\n            )\n            await reader.release()\n            assert reader.at_eof()\n\n    async def test_release_release(self) -> None:\n        with Stream(b\"--:\\r\\n\\r\\necho\\r\\n--:--\") as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            await reader.release()\n            assert reader.at_eof()\n            await reader.release()\n            assert reader.at_eof()\n\n    async def test_release_next(self) -> None:\n        with Stream(b\"--:\\r\\n\\r\\necho\\r\\n--:--\") as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            await reader.release()\n            assert reader.at_eof()\n            res = await reader.next()\n            assert res is None\n\n    async def test_second_next_releases_previous_object(self) -> None:\n        with Stream(\n            b\"--:\\r\\n\" b\"\\r\\n\" b\"test\\r\\n\" b\"--:\\r\\n\" b\"\\r\\n\" b\"passed\\r\\n\" b\"--:--\"\n        ) as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            first = await reader.next()\n            assert isinstance(first, aiohttp.BodyPartReader)\n            second = await reader.next()\n            assert first.at_eof()\n            assert not second.at_eof()\n\n    async def test_release_without_read_the_last_object(self) -> None:\n        with Stream(\n            b\"--:\\r\\n\" b\"\\r\\n\" b\"test\\r\\n\" b\"--:\\r\\n\" b\"\\r\\n\" b\"passed\\r\\n\" b\"--:--\"\n        ) as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            first = await reader.next()\n            second = await reader.next()\n            third = await reader.next()\n\n            assert first.at_eof()\n            assert second.at_eof()\n            assert second.at_eof()\n            assert third is None\n\n    async def test_read_chunk_by_length_doesnt_break_reader(self) -> None:\n        with Stream(\n            b\"--:\\r\\n\"\n            b\"Content-Length: 4\\r\\n\\r\\n\"\n            b\"test\"\n            b\"\\r\\n--:\\r\\n\"\n            b\"Content-Length: 6\\r\\n\\r\\n\"\n            b\"passed\"\n            b\"\\r\\n--:--\"\n        ) as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            body_parts = []\n            while True:\n                read_part = b\"\"\n                part = await reader.next()\n                if part is None:\n                    break\n                while not part.at_eof():\n                    read_part += await part.read_chunk(3)\n                body_parts.append(read_part)\n\n        assert body_parts == [b\"test\", b\"passed\"]\n\n    async def test_read_chunk_from_stream_doesnt_break_reader(self) -> None:\n        with Stream(\n            b\"--:\\r\\n\"\n            b\"\\r\\n\"\n            b\"chunk\"\n            b\"\\r\\n--:\\r\\n\"\n            b\"\\r\\n\"\n            b\"two_chunks\"\n            b\"\\r\\n--:--\"\n        ) as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            body_parts = []\n            while True:\n                read_part = b\"\"\n                part = await reader.next()\n                if part is None:\n                    break\n                while not part.at_eof():\n                    chunk = await part.read_chunk(5)\n                    assert chunk\n                    read_part += chunk\n                body_parts.append(read_part)\n\n        assert body_parts == [b\"chunk\", b\"two_chunks\"]\n\n    async def test_reading_skips_prelude(self) -> None:\n        with Stream(\n            b\"Multi-part data is not supported.\\r\\n\"\n            b\"\\r\\n\"\n            b\"--:\\r\\n\"\n            b\"\\r\\n\"\n            b\"test\\r\\n\"\n            b\"--:\\r\\n\"\n            b\"\\r\\n\"\n            b\"passed\\r\\n\"\n            b\"--:--\"\n        ) as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/related;boundary=\":\"'},\n                stream,\n            )\n            first = await reader.next()\n            assert isinstance(first, aiohttp.BodyPartReader)\n            second = await reader.next()\n\n            assert first.at_eof()\n            assert not second.at_eof()\n\n    async def test_read_form_default_encoding(self) -> None:\n        with Stream(\n            b\"--:\\r\\n\"\n            b'Content-Disposition: form-data; name=\"_charset_\"\\r\\n\\r\\n'\n            b\"ascii\"\n            b\"\\r\\n\"\n            b\"--:\\r\\n\"\n            b'Content-Disposition: form-data; name=\"field1\"\\r\\n\\r\\n'\n            b\"foo\"\n            b\"\\r\\n\"\n            b\"--:\\r\\n\"\n            b\"Content-Type: text/plain;charset=UTF-8\\r\\n\"\n            b'Content-Disposition: form-data; name=\"field2\"\\r\\n\\r\\n'\n            b\"foo\"\n            b\"\\r\\n\"\n            b\"--:\\r\\n\"\n            b'Content-Disposition: form-data; name=\"field3\"\\r\\n\\r\\n'\n            b\"foo\"\n            b\"\\r\\n\"\n        ) as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/form-data;boundary=\":\"'},\n                stream,\n            )\n            field1 = await reader.next()\n            assert field1.name == \"field1\"\n            assert field1.get_charset(\"default\") == \"ascii\"\n            field2 = await reader.next()\n            assert field2.name == \"field2\"\n            assert field2.get_charset(\"default\") == \"UTF-8\"\n            field3 = await reader.next()\n            assert field3.name == \"field3\"\n            assert field3.get_charset(\"default\") == \"ascii\"\n\n    async def test_read_form_invalid_default_encoding(self) -> None:\n        with Stream(\n            b\"--:\\r\\n\"\n            b'Content-Disposition: form-data; name=\"_charset_\"\\r\\n\\r\\n'\n            b\"this-value-is-too-long-to-be-a-charset\"\n            b\"\\r\\n\"\n            b\"--:\\r\\n\"\n            b'Content-Disposition: form-data; name=\"field1\"\\r\\n\\r\\n'\n            b\"foo\"\n            b\"\\r\\n\"\n        ) as stream:\n            reader = aiohttp.MultipartReader(\n                {CONTENT_TYPE: 'multipart/form-data;boundary=\":\"'},\n                stream,\n            )\n            with pytest.raises(RuntimeError, match=\"Invalid default charset\"):\n                await reader.next()\n\n\nasync def test_writer(writer: Any) -> None:\n    assert writer.size == 7\n    assert writer.boundary == \":\"\n\n\nasync def test_writer_serialize_io_chunk(buf: Any, stream: Any, writer: Any) -> None:\n    with io.BytesIO(b\"foobarbaz\") as file_handle:\n        writer.append(file_handle)\n        await writer.write(stream)\n    assert (\n        buf == b\"--:\\r\\nContent-Type: application/octet-stream\"\n        b\"\\r\\nContent-Length: 9\\r\\n\\r\\nfoobarbaz\\r\\n--:--\\r\\n\"\n    )\n\n\nasync def test_writer_serialize_json(buf: Any, stream: Any, writer: Any) -> None:\n    writer.append_json({\"\u043f\u0440\u0438\u0432\u0435\u0442\": \"\u043c\u0438\u0440\"})\n    await writer.write(stream)\n    assert (\n        b'{\"\\\\u043f\\\\u0440\\\\u0438\\\\u0432\\\\u0435\\\\u0442\":'\n        b' \"\\\\u043c\\\\u0438\\\\u0440\"}' in buf\n    )\n\n\nasync def test_writer_serialize_form(buf: Any, stream: Any, writer: Any) -> None:\n    data = [(\"foo\", \"bar\"), (\"foo\", \"baz\"), (\"boo\", \"zoo\")]\n    writer.append_form(data)\n    await writer.write(stream)\n\n    assert b\"foo=bar&foo=baz&boo=zoo\" in buf\n\n\nasync def test_writer_serialize_form_dict(buf: Any, stream: Any, writer: Any) -> None:\n    data = {\"hello\": \"\u043c\u0438\u0440\"}\n    writer.append_form(data)\n    await writer.write(stream)\n\n    assert b\"hello=%D0%BC%D0%B8%D1%80\" in buf\n\n\nasync def test_writer_write(buf: Any, stream: Any, writer: Any) -> None:\n    writer.append(\"foo-bar-baz\")\n    writer.append_json({\"test\": \"passed\"})\n    writer.append_form({\"test\": \"passed\"})\n    writer.append_form([(\"one\", 1), (\"two\", 2)])\n\n    sub_multipart = aiohttp.MultipartWriter(boundary=\"::\")\n    sub_multipart.append(\"nested content\")\n    sub_multipart.headers[\"X-CUSTOM\"] = \"test\"\n    writer.append(sub_multipart)\n    await writer.write(stream)\n\n    assert (\n        b\"--:\\r\\n\"\n        b\"Content-Type: text/plain; charset=utf-8\\r\\n\"\n        b\"Content-Length: 11\\r\\n\\r\\n\"\n        b\"foo-bar-baz\"\n        b\"\\r\\n\"\n        b\"--:\\r\\n\"\n        b\"Content-Type: application/json\\r\\n\"\n        b\"Content-Length: 18\\r\\n\\r\\n\"\n        b'{\"test\": \"passed\"}'\n        b\"\\r\\n\"\n        b\"--:\\r\\n\"\n        b\"Content-Type: application/x-www-form-urlencoded\\r\\n\"\n        b\"Content-Length: 11\\r\\n\\r\\n\"\n        b\"test=passed\"\n        b\"\\r\\n\"\n        b\"--:\\r\\n\"\n        b\"Content-Type: application/x-www-form-urlencoded\\r\\n\"\n        b\"Content-Length: 11\\r\\n\\r\\n\"\n        b\"one=1&two=2\"\n        b\"\\r\\n\"\n        b\"--:\\r\\n\"\n        b'Content-Type: multipart/mixed; boundary=\"::\"\\r\\n'\n        b\"X-CUSTOM: test\\r\\nContent-Length: 93\\r\\n\\r\\n\"\n        b\"--::\\r\\n\"\n        b\"Content-Type: text/plain; charset=utf-8\\r\\n\"\n        b\"Content-Length: 14\\r\\n\\r\\n\"\n        b\"nested content\\r\\n\"\n        b\"--::--\\r\\n\"\n        b\"\\r\\n\"\n        b\"--:--\\r\\n\"\n    ) == bytes(buf)\n\n\nasync def test_writer_write_no_close_boundary(buf: Any, stream: Any) -> None:\n    writer = aiohttp.MultipartWriter(boundary=\":\")\n    writer.append(\"foo-bar-baz\")\n    writer.append_json({\"test\": \"passed\"})\n    writer.append_form({\"test\": \"passed\"})\n    writer.append_form([(\"one\", 1), (\"two\", 2)])\n    await writer.write(stream, close_boundary=False)\n\n    assert (\n        b\"--:\\r\\n\"\n        b\"Content-Type: text/plain; charset=utf-8\\r\\n\"\n        b\"Content-Length: 11\\r\\n\\r\\n\"\n        b\"foo-bar-baz\"\n        b\"\\r\\n\"\n        b\"--:\\r\\n\"\n        b\"Content-Type: application/json\\r\\n\"\n        b\"Content-Length: 18\\r\\n\\r\\n\"\n        b'{\"test\": \"passed\"}'\n        b\"\\r\\n\"\n        b\"--:\\r\\n\"\n        b\"Content-Type: application/x-www-form-urlencoded\\r\\n\"\n        b\"Content-Length: 11\\r\\n\\r\\n\"\n        b\"test=passed\"\n        b\"\\r\\n\"\n        b\"--:\\r\\n\"\n        b\"Content-Type: application/x-www-form-urlencoded\\r\\n\"\n        b\"Content-Length: 11\\r\\n\\r\\n\"\n        b\"one=1&two=2\"\n        b\"\\r\\n\"\n    ) == bytes(buf)\n\n\nasync def test_writer_write_no_parts(buf: Any, stream: Any, writer: Any) -> None:\n    await writer.write(stream)\n    assert b\"--:--\\r\\n\" == bytes(buf)\n\n\nasync def test_writer_serialize_with_content_encoding_gzip(\n    buf: Any, stream: Any, writer: Any\n) -> None:\n    writer.append(\"Time to Relax!\", {CONTENT_ENCODING: \"gzip\"})\n    await writer.write(stream)\n    headers, message = bytes(buf).split(b\"\\r\\n\\r\\n\", 1)\n\n    assert (\n        b\"--:\\r\\nContent-Type: text/plain; charset=utf-8\\r\\n\"\n        b\"Content-Encoding: gzip\" == headers\n    )\n\n    decompressor = zlib.decompressobj(wbits=16 + zlib.MAX_WBITS)\n    data = decompressor.decompress(message.split(b\"\\r\\n\")[0])\n    data += decompressor.flush()\n    assert b\"Time to Relax!\" == data\n\n\nasync def test_writer_serialize_with_content_encoding_deflate(\n    buf: Any, stream: Any, writer: Any\n) -> None:\n    writer.append(\"Time to Relax!\", {CONTENT_ENCODING: \"deflate\"})\n    await writer.write(stream)\n    headers, message = bytes(buf).split(b\"\\r\\n\\r\\n\", 1)\n\n    assert (\n        b\"--:\\r\\nContent-Type: text/plain; charset=utf-8\\r\\n\"\n        b\"Content-Encoding: deflate\" == headers\n    )\n\n    thing = b\"\\x0b\\xc9\\xccMU(\\xc9W\\x08J\\xcdI\\xacP\\x04\\x00\\r\\n--:--\\r\\n\"\n    assert thing == message\n\n\nasync def test_writer_serialize_with_content_encoding_identity(\n    buf: Any, stream: Any, writer: Any\n) -> None:\n    thing = b\"\\x0b\\xc9\\xccMU(\\xc9W\\x08J\\xcdI\\xacP\\x04\\x00\"\n    writer.append(thing, {CONTENT_ENCODING: \"identity\"})\n    await writer.write(stream)\n    headers, message = bytes(buf).split(b\"\\r\\n\\r\\n\", 1)\n\n    assert (\n        b\"--:\\r\\nContent-Type: application/octet-stream\\r\\n\"\n        b\"Content-Encoding: identity\\r\\n\"\n        b\"Content-Length: 16\" == headers\n    )\n\n    assert thing == message.split(b\"\\r\\n\")[0]\n\n\ndef test_writer_serialize_with_content_encoding_unknown(\n    buf: Any, stream: Any, writer: Any\n) -> None:\n    with pytest.raises(RuntimeError):\n        writer.append(\"Time to Relax!\", {CONTENT_ENCODING: \"snappy\"})\n\n\nasync def test_writer_with_content_transfer_encoding_base64(\n    buf: Any, stream: Any, writer: Any\n) -> None:\n    writer.append(\"Time to Relax!\", {CONTENT_TRANSFER_ENCODING: \"base64\"})\n    await writer.write(stream)\n    headers, message = bytes(buf).split(b\"\\r\\n\\r\\n\", 1)\n\n    assert (\n        b\"--:\\r\\nContent-Type: text/plain; charset=utf-8\\r\\n\"\n        b\"Content-Transfer-Encoding: base64\" == headers\n    )\n\n    assert b\"VGltZSB0byBSZWxheCE=\" == message.split(b\"\\r\\n\")[0]\n\n\nasync def test_writer_content_transfer_encoding_quote_printable(\n    buf: Any, stream: Any, writer: Any\n) -> None:\n    writer.append(\"\u041f\u0440\u0438\u0432\u0435\u0442, \u043c\u0438\u0440!\", {CONTENT_TRANSFER_ENCODING: \"quoted-printable\"})\n    await writer.write(stream)\n    headers, message = bytes(buf).split(b\"\\r\\n\\r\\n\", 1)\n\n    assert (\n        b\"--:\\r\\nContent-Type: text/plain; charset=utf-8\\r\\n\"\n        b\"Content-Transfer-Encoding: quoted-printable\" == headers\n    )\n\n    assert (\n        b\"=D0=9F=D1=80=D0=B8=D0=B2=D0=B5=D1=82,\"\n        b\" =D0=BC=D0=B8=D1=80!\" == message.split(b\"\\r\\n\")[0]\n    )\n\n\ndef test_writer_content_transfer_encoding_unknown(\n    buf: Any, stream: Any, writer: Any\n) -> None:\n    with pytest.raises(RuntimeError):\n        writer.append(\"Time to Relax!\", {CONTENT_TRANSFER_ENCODING: \"unknown\"})\n\n\nclass TestMultipartWriter:\n    def test_default_subtype(self, writer: Any) -> None:\n        mimetype = parse_mimetype(writer.headers.get(CONTENT_TYPE))\n\n        assert \"multipart\" == mimetype.type\n        assert \"mixed\" == mimetype.subtype\n\n    def test_unquoted_boundary(self) -> None:\n        writer = aiohttp.MultipartWriter(boundary=\"abc123\")\n        expected = {CONTENT_TYPE: \"multipart/mixed; boundary=abc123\"}\n        assert expected == writer.headers\n\n    def test_quoted_boundary(self) -> None:\n        writer = aiohttp.MultipartWriter(boundary=R\"\\\"\")\n        expected = {CONTENT_TYPE: R'multipart/mixed; boundary=\"\\\\\\\"\"'}\n        assert expected == writer.headers\n\n    def test_bad_boundary(self) -> None:\n        with pytest.raises(ValueError):\n            aiohttp.MultipartWriter(boundary=\"\u0442\u0435\u0441\u0442\")\n        with pytest.raises(ValueError):\n            aiohttp.MultipartWriter(boundary=\"test\\n\")\n        with pytest.raises(ValueError):\n            aiohttp.MultipartWriter(boundary=\"X\" * 71)\n\n    def test_default_headers(self, writer: Any) -> None:\n        expected = {CONTENT_TYPE: 'multipart/mixed; boundary=\":\"'}\n        assert expected == writer.headers\n\n    def test_iter_parts(self, writer: Any) -> None:\n        writer.append(\"foo\")\n        writer.append(\"bar\")\n        writer.append(\"baz\")\n        assert 3 == len(list(writer))\n\n    def test_append(self, writer: Any) -> None:\n        assert 0 == len(writer)\n        writer.append(\"hello, world!\")\n        assert 1 == len(writer)\n        assert isinstance(writer._parts[0][0], payload.Payload)\n\n    def test_append_with_headers(self, writer: Any) -> None:\n        writer.append(\"hello, world!\", {\"x-foo\": \"bar\"})\n        assert 1 == len(writer)\n        assert \"x-foo\" in writer._parts[0][0].headers\n        assert writer._parts[0][0].headers[\"x-foo\"] == \"bar\"\n\n    def test_append_json(self, writer: Any) -> None:\n        writer.append_json({\"foo\": \"bar\"})\n        assert 1 == len(writer)\n        part = writer._parts[0][0]\n        assert part.headers[CONTENT_TYPE] == \"application/json\"\n\n    def test_append_part(self, writer: Any) -> None:\n        part = payload.get_payload(\"test\", headers={CONTENT_TYPE: \"text/plain\"})\n        writer.append(part, {CONTENT_TYPE: \"test/passed\"})\n        assert 1 == len(writer)\n        part = writer._parts[0][0]\n        assert part.headers[CONTENT_TYPE] == \"test/passed\"\n\n    def test_append_json_overrides_content_type(self, writer: Any) -> None:\n        writer.append_json({\"foo\": \"bar\"}, {CONTENT_TYPE: \"test/passed\"})\n        assert 1 == len(writer)\n        part = writer._parts[0][0]\n        assert part.headers[CONTENT_TYPE] == \"test/passed\"\n\n    def test_append_form(self, writer: Any) -> None:\n        writer.append_form({\"foo\": \"bar\"}, {CONTENT_TYPE: \"test/passed\"})\n        assert 1 == len(writer)\n        part = writer._parts[0][0]\n        assert part.headers[CONTENT_TYPE] == \"test/passed\"\n\n    def test_append_multipart(self, writer: Any) -> None:\n        subwriter = aiohttp.MultipartWriter(boundary=\":\")\n        subwriter.append_json({\"foo\": \"bar\"})\n        writer.append(subwriter, {CONTENT_TYPE: \"test/passed\"})\n        assert 1 == len(writer)\n        part = writer._parts[0][0]\n        assert part.headers[CONTENT_TYPE] == \"test/passed\"\n\n    def test_set_content_disposition_after_append(self):\n        writer = aiohttp.MultipartWriter(\"form-data\")\n        part = writer.append(\"some-data\")\n        part.set_content_disposition(\"form-data\", name=\"method\")\n        assert 'name=\"method\"' in part.headers[CONTENT_DISPOSITION]\n\n    def test_automatic_content_disposition(self):\n        writer = aiohttp.MultipartWriter(\"form-data\")\n        writer.append_json(())\n        part = payload.StringPayload(\"foo\")\n        part.set_content_disposition(\"form-data\", name=\"second\")\n        writer.append_payload(part)\n        writer.append(\"foo\")\n\n        disps = tuple(p[0].headers[CONTENT_DISPOSITION] for p in writer._parts)\n        assert 'name=\"section-0\"' in disps[0]\n        assert 'name=\"second\"' in disps[1]\n        assert 'name=\"section-2\"' in disps[2]\n\n    def test_with(self) -> None:\n        with aiohttp.MultipartWriter(boundary=\":\") as writer:\n            writer.append(\"foo\")\n            writer.append(b\"bar\")\n            writer.append_json({\"baz\": True})\n        assert 3 == len(writer)\n\n    def test_append_int_not_allowed(self) -> None:\n        with pytest.raises(TypeError):\n            with aiohttp.MultipartWriter(boundary=\":\") as writer:\n                writer.append(1)\n\n    def test_append_float_not_allowed(self) -> None:\n        with pytest.raises(TypeError):\n            with aiohttp.MultipartWriter(boundary=\":\") as writer:\n                writer.append(1.1)\n\n    def test_append_none_not_allowed(self) -> None:\n        with pytest.raises(TypeError):\n            with aiohttp.MultipartWriter(boundary=\":\") as writer:\n                writer.append(None)\n\n    async def test_write_preserves_content_disposition(\n        self, buf: Any, stream: Any\n    ) -> None:\n        with aiohttp.MultipartWriter(boundary=\":\") as writer:\n            part = writer.append(b\"foo\", headers={CONTENT_TYPE: \"test/passed\"})\n            part.set_content_disposition(\"form-data\", filename=\"bug\")\n        await writer.write(stream)\n\n        headers, message = bytes(buf).split(b\"\\r\\n\\r\\n\", 1)\n\n        assert headers == (\n            b\"--:\\r\\n\"\n            b\"Content-Type: test/passed\\r\\n\"\n            b\"Content-Length: 3\\r\\n\"\n            b\"Content-Disposition:\"\n            b' form-data; filename=\"bug\"'\n        )\n        assert message == b\"foo\\r\\n--:--\\r\\n\"\n\n    async def test_preserve_content_disposition_header(\n        self, buf: Any, stream: Any\n    ) -> None:\n        # https://github.com/aio-libs/aiohttp/pull/3475#issuecomment-451072381\n        with pathlib.Path(__file__).open(\"rb\") as fobj:\n            with aiohttp.MultipartWriter(\"form-data\", boundary=\":\") as writer:\n                part = writer.append(\n                    fobj,\n                    headers={\n                        CONTENT_DISPOSITION: 'attachments; filename=\"bug.py\"',\n                        CONTENT_TYPE: \"text/python\",\n                    },\n                )\n            await writer.write(stream)\n\n        assert part.headers[CONTENT_TYPE] == \"text/python\"\n        assert part.headers[CONTENT_DISPOSITION] == ('attachments; filename=\"bug.py\"')\n\n        headers, _ = bytes(buf).split(b\"\\r\\n\\r\\n\", 1)\n\n        assert headers == (\n            b\"--:\\r\\n\"\n            b\"Content-Type: text/python\\r\\n\"\n            b'Content-Disposition: attachments; filename=\"bug.py\"'\n        )\n\n    async def test_set_content_disposition_override(\n        self, buf: Any, stream: Any\n    ) -> None:\n        # https://github.com/aio-libs/aiohttp/pull/3475#issuecomment-451072381\n        with pathlib.Path(__file__).open(\"rb\") as fobj:\n            with aiohttp.MultipartWriter(\"form-data\", boundary=\":\") as writer:\n                part = writer.append(\n                    fobj,\n                    headers={\n                        CONTENT_DISPOSITION: 'attachments; filename=\"bug.py\"',\n                        CONTENT_TYPE: \"text/python\",\n                    },\n                )\n            await writer.write(stream)\n\n        assert part.headers[CONTENT_TYPE] == \"text/python\"\n        assert part.headers[CONTENT_DISPOSITION] == ('attachments; filename=\"bug.py\"')\n\n        headers, _ = bytes(buf).split(b\"\\r\\n\\r\\n\", 1)\n\n        assert headers == (\n            b\"--:\\r\\n\"\n            b\"Content-Type: text/python\\r\\n\"\n            b'Content-Disposition: attachments; filename=\"bug.py\"'\n        )\n\n    async def test_reset_content_disposition_header(\n        self, buf: Any, stream: Any\n    ) -> None:\n        # https://github.com/aio-libs/aiohttp/pull/3475#issuecomment-451072381\n        with pathlib.Path(__file__).open(\"rb\") as fobj:\n            with aiohttp.MultipartWriter(\"form-data\", boundary=\":\") as writer:\n                part = writer.append(\n                    fobj,\n                    headers={CONTENT_TYPE: \"text/plain\"},\n                )\n\n            assert CONTENT_DISPOSITION in part.headers\n\n            part.set_content_disposition(\"attachments\", filename=\"bug.py\")\n\n            await writer.write(stream)\n\n        headers, _ = bytes(buf).split(b\"\\r\\n\\r\\n\", 1)\n\n        assert headers == (\n            b\"--:\\r\\n\"\n            b\"Content-Type: text/plain\\r\\n\"\n            b\"Content-Disposition:\"\n            b' attachments; filename=\"bug.py\"'\n        )\n\n\nasync def test_async_for_reader() -> None:\n    data = [{\"test\": \"passed\"}, 42, b\"plain text\", b\"aiohttp\\n\", b\"no epilogue\"]\n    with Stream(\n        b\"\\r\\n\".join(\n            [\n                b\"--:\",\n                b\"Content-Type: application/json\",\n                b\"\",\n                json.dumps(data[0]).encode(),\n                b\"--:\",\n                b\"Content-Type: application/json\",\n                b\"\",\n                json.dumps(data[1]).encode(),\n                b\"--:\",\n                b'Content-Type: multipart/related; boundary=\"::\"',\n                b\"\",\n                b\"--::\",\n                b\"Content-Type: text/plain\",\n                b\"\",\n                data[2],\n                b\"--::\",\n                b'Content-Disposition: attachment; filename=\"aiohttp\"',\n                b\"Content-Type: text/plain\",\n                b\"Content-Length: 28\",\n                b\"Content-Encoding: gzip\",\n                b\"\",\n                b\"\\x1f\\x8b\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x03K\\xcc\\xcc\\xcf())\"\n                b\"\\xe0\\x02\\x00\\xd6\\x90\\xe2O\\x08\\x00\\x00\\x00\",\n                b\"--::\",\n                b'Content-Type: multipart/related; boundary=\":::\"',\n                b\"\",\n                b\"--:::\",\n                b\"Content-Type: text/plain\",\n                b\"\",\n                data[4],\n                b\"--:::--\",\n                b\"--::--\",\n                b\"\",\n                b\"--:--\",\n                b\"\",\n            ]\n        )\n    ) as stream:\n        reader = aiohttp.MultipartReader(\n            headers={CONTENT_TYPE: 'multipart/mixed; boundary=\":\"'},\n            content=stream,\n        )\n        idata = iter(data)\n\n        async def check(reader):\n            async for part in reader:\n                if isinstance(part, aiohttp.BodyPartReader):\n                    if part.headers[CONTENT_TYPE] == \"application/json\":\n                        assert next(idata) == (await part.json())\n                    else:\n                        assert next(idata) == await part.read(decode=True)\n                else:\n                    await check(part)\n\n        await check(reader)\n\n\nasync def test_async_for_bodypart() -> None:\n    with Stream(b\"foobarbaz\\r\\n--:--\") as stream:\n        part = aiohttp.BodyPartReader(boundary=b\"--:\", headers={}, content=stream)\n        async for data in part:\n            assert data == b\"foobarbaz\"\n", "tests/test_flowcontrol_streams.py": "# type: ignore\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\n\nfrom aiohttp import streams\n\n\n@pytest.fixture\ndef protocol():\n    return mock.Mock(_reading_paused=False)\n\n\n@pytest.fixture\ndef stream(loop: Any, protocol: Any):\n    out = streams.StreamReader(protocol, limit=1, loop=loop)\n    out._allow_pause = True\n    return out\n\n\n@pytest.fixture\ndef buffer(loop: Any, protocol: Any):\n    out = streams.FlowControlDataQueue(protocol, limit=1, loop=loop)\n    out._allow_pause = True\n    return out\n\n\nclass TestFlowControlStreamReader:\n    async def test_read(self, stream: Any) -> None:\n        stream.feed_data(b\"da\")\n        res = await stream.read(1)\n        assert res == b\"d\"\n        assert not stream._protocol.resume_reading.called\n\n    async def test_read_resume_paused(self, stream: Any) -> None:\n        stream.feed_data(b\"test\")\n        stream._protocol._reading_paused = True\n\n        res = await stream.read(1)\n        assert res == b\"t\"\n        assert stream._protocol.pause_reading.called\n\n    async def test_readline(self, stream: Any) -> None:\n        stream.feed_data(b\"d\\n\")\n        res = await stream.readline()\n        assert res == b\"d\\n\"\n        assert not stream._protocol.resume_reading.called\n\n    async def test_readline_resume_paused(self, stream: Any) -> None:\n        stream._protocol._reading_paused = True\n        stream.feed_data(b\"d\\n\")\n        res = await stream.readline()\n        assert res == b\"d\\n\"\n        assert stream._protocol.resume_reading.called\n\n    async def test_readany(self, stream: Any) -> None:\n        stream.feed_data(b\"data\")\n        res = await stream.readany()\n        assert res == b\"data\"\n        assert not stream._protocol.resume_reading.called\n\n    async def test_readany_resume_paused(self, stream: Any) -> None:\n        stream._protocol._reading_paused = True\n        stream.feed_data(b\"data\")\n        res = await stream.readany()\n        assert res == b\"data\"\n        assert stream._protocol.resume_reading.called\n\n    async def test_readchunk(self, stream: Any) -> None:\n        stream.feed_data(b\"data\")\n        res, end_of_http_chunk = await stream.readchunk()\n        assert res == b\"data\"\n        assert not end_of_http_chunk\n        assert not stream._protocol.resume_reading.called\n\n    async def test_readchunk_resume_paused(self, stream: Any) -> None:\n        stream._protocol._reading_paused = True\n        stream.feed_data(b\"data\")\n        res, end_of_http_chunk = await stream.readchunk()\n        assert res == b\"data\"\n        assert not end_of_http_chunk\n        assert stream._protocol.resume_reading.called\n\n    async def test_readexactly(self, stream: Any) -> None:\n        stream.feed_data(b\"data\")\n        res = await stream.readexactly(3)\n        assert res == b\"dat\"\n        assert not stream._protocol.resume_reading.called\n\n    async def test_feed_data(self, stream: Any) -> None:\n        stream._protocol._reading_paused = False\n        stream.feed_data(b\"datadata\")\n        assert stream._protocol.pause_reading.called\n\n    async def test_read_nowait(self, stream: Any) -> None:\n        stream._protocol._reading_paused = True\n        stream.feed_data(b\"data1\")\n        stream.feed_data(b\"data2\")\n        stream.feed_data(b\"data3\")\n        res = await stream.read(5)\n        assert res == b\"data1\"\n        assert stream._protocol.resume_reading.call_count == 0\n\n        res = stream.read_nowait(5)\n        assert res == b\"data2\"\n        assert stream._protocol.resume_reading.call_count == 0\n\n        res = stream.read_nowait(5)\n        assert res == b\"data3\"\n        assert stream._protocol.resume_reading.call_count == 1\n\n        stream._protocol._reading_paused = False\n        res = stream.read_nowait(5)\n        assert res == b\"\"\n        assert stream._protocol.resume_reading.call_count == 1\n\n\nclass TestFlowControlDataQueue:\n    def test_feed_pause(self, buffer: Any) -> None:\n        buffer._protocol._reading_paused = False\n        buffer.feed_data(\"x\" * 100)\n\n        assert buffer._protocol.pause_reading.called\n\n    async def test_resume_on_read(self, buffer: Any) -> None:\n        buffer.feed_data(\"x\" * 100)\n\n        buffer._protocol._reading_paused = True\n        await buffer.read()\n        assert buffer._protocol.resume_reading.called\n", "tests/test_client_connection.py": "import gc\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\n\nfrom aiohttp.connector import Connection\n\n\n@pytest.fixture\ndef key() -> object:\n    return object()\n\n\n@pytest.fixture\ndef loop() -> Any:\n    return mock.Mock()\n\n\n@pytest.fixture\ndef connector() -> Any:\n    return mock.Mock()\n\n\n@pytest.fixture\ndef protocol() -> Any:\n    return mock.Mock(should_close=False)\n\n\ndef test_ctor(connector: Any, key: Any, protocol: Any, loop: Any) -> None:\n    conn = Connection(connector, key, protocol, loop)\n    assert conn.protocol is protocol\n    conn.close()\n\n\ndef test_callbacks_on_close(connector: Any, key: Any, protocol: Any, loop: Any) -> None:\n    conn = Connection(connector, key, protocol, loop)\n    notified = False\n\n    def cb() -> None:\n        nonlocal notified\n        notified = True\n\n    conn.add_callback(cb)\n    conn.close()\n    assert notified\n\n\ndef test_callbacks_on_release(\n    connector: Any, key: Any, protocol: Any, loop: Any\n) -> None:\n    conn = Connection(connector, key, protocol, loop)\n    notified = False\n\n    def cb() -> None:\n        nonlocal notified\n        notified = True\n\n    conn.add_callback(cb)\n    conn.release()\n    assert notified\n\n\ndef test_callbacks_exception(\n    connector: Any, key: Any, protocol: Any, loop: Any\n) -> None:\n    conn = Connection(connector, key, protocol, loop)\n    notified = False\n\n    def cb1() -> None:\n        raise Exception\n\n    def cb2() -> None:\n        nonlocal notified\n        notified = True\n\n    conn.add_callback(cb1)\n    conn.add_callback(cb2)\n    conn.close()\n    assert notified\n\n\ndef test_del(connector: Any, key: Any, protocol: Any, loop: Any) -> None:\n    loop.is_closed.return_value = False\n    conn = Connection(connector, key, protocol, loop)\n    exc_handler = mock.Mock()\n    loop.set_exception_handler(exc_handler)\n\n    with pytest.warns(ResourceWarning):\n        del conn\n        gc.collect()\n\n    connector._release.assert_called_with(key, protocol, should_close=True)\n    msg = {\n        \"client_connection\": mock.ANY,  # conn was deleted\n        \"message\": \"Unclosed connection\",\n    }\n    if loop.get_debug():\n        msg[\"source_traceback\"] = mock.ANY\n    loop.call_exception_handler.assert_called_with(msg)\n\n\ndef test_close(connector: Any, key: Any, protocol: Any, loop: Any) -> None:\n    conn = Connection(connector, key, protocol, loop)\n    assert not conn.closed\n    conn.close()\n    assert conn._protocol is None\n    connector._release.assert_called_with(key, protocol, should_close=True)\n    assert conn.closed\n\n\ndef test_release(connector: Any, key: Any, protocol: Any, loop: Any) -> None:\n    conn = Connection(connector, key, protocol, loop)\n    assert not conn.closed\n    conn.release()\n    assert not protocol.transport.close.called\n    assert conn._protocol is None\n    connector._release.assert_called_with(key, protocol, should_close=False)\n    assert conn.closed\n\n\ndef test_release_proto_should_close(\n    connector: Any, key: Any, protocol: Any, loop: Any\n) -> None:\n    protocol.should_close = True\n    conn = Connection(connector, key, protocol, loop)\n    assert not conn.closed\n    conn.release()\n    assert not protocol.transport.close.called\n    assert conn._protocol is None\n    connector._release.assert_called_with(key, protocol, should_close=True)\n    assert conn.closed\n\n\ndef test_release_released(connector: Any, key: Any, protocol: Any, loop: Any) -> None:\n    conn = Connection(connector, key, protocol, loop)\n    conn.release()\n    connector._release.reset_mock()\n    conn.release()\n    assert not protocol.transport.close.called\n    assert conn._protocol is None\n    assert not connector._release.called\n", "tests/test_client_functional.py": "# type: ignore\n# HTTP client functional tests against aiohttp.web server\n\nimport asyncio\nimport datetime\nimport http.cookies\nimport io\nimport json\nimport pathlib\nimport socket\nimport ssl\nimport sys\nimport time\nfrom typing import Any, AsyncIterator, Type\nfrom unittest import mock\n\nimport pytest\nfrom multidict import MultiDict\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp import Fingerprint, ServerFingerprintMismatch, hdrs, web\nfrom aiohttp.abc import AbstractResolver\nfrom aiohttp.client_exceptions import (\n    InvalidURL,\n    InvalidUrlClientError,\n    InvalidUrlRedirectClientError,\n    NonHttpUrlClientError,\n    NonHttpUrlRedirectClientError,\n    SocketTimeoutError,\n    TooManyRedirects,\n)\nfrom aiohttp.pytest_plugin import AiohttpClient, TestClient\nfrom aiohttp.test_utils import unused_port\n\n\n@pytest.fixture\ndef here():\n    return pathlib.Path(__file__).parent\n\n\n@pytest.fixture\ndef fname(here: Any):\n    return here / \"conftest.py\"\n\n\nasync def test_keepalive_two_requests_success(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    connector = aiohttp.TCPConnector(limit=1)\n    client = await aiohttp_client(app, connector=connector)\n\n    resp1 = await client.get(\"/\")\n    await resp1.read()\n    resp2 = await client.get(\"/\")\n    await resp2.read()\n\n    assert 1 == len(client._session.connector._conns)\n\n\nasync def test_keepalive_after_head_requests_success(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(body=b\"OK\")\n\n    cnt_conn_reuse = 0\n\n    async def on_reuseconn(session, ctx, params):\n        nonlocal cnt_conn_reuse\n        cnt_conn_reuse += 1\n\n    trace_config = aiohttp.TraceConfig()\n    trace_config._on_connection_reuseconn.append(on_reuseconn)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    app.router.add_route(\"HEAD\", \"/\", handler)\n\n    connector = aiohttp.TCPConnector(limit=1)\n    client = await aiohttp_client(\n        app, connector=connector, trace_configs=[trace_config]\n    )\n\n    resp1 = await client.head(\"/\")\n    await resp1.read()\n    resp2 = await client.get(\"/\")\n    await resp2.read()\n\n    assert 1 == cnt_conn_reuse\n\n\n@pytest.mark.parametrize(\"status\", (101, 204, 304))\nasync def test_keepalive_after_empty_body_status(\n    aiohttp_client: Any, status: int\n) -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(status=status)\n\n    cnt_conn_reuse = 0\n\n    async def on_reuseconn(session, ctx, params):\n        nonlocal cnt_conn_reuse\n        cnt_conn_reuse += 1\n\n    trace_config = aiohttp.TraceConfig()\n    trace_config._on_connection_reuseconn.append(on_reuseconn)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    connector = aiohttp.TCPConnector(limit=1)\n    client = await aiohttp_client(\n        app, connector=connector, trace_configs=[trace_config]\n    )\n\n    resp1 = await client.get(\"/\")\n    await resp1.read()\n    resp2 = await client.get(\"/\")\n    await resp2.read()\n\n    assert cnt_conn_reuse == 1\n\n\n@pytest.mark.parametrize(\"status\", (101, 204, 304))\nasync def test_keepalive_after_empty_body_status_stream_response(\n    aiohttp_client: Any, status: int\n) -> None:\n    async def handler(request):\n        stream_response = web.StreamResponse(status=status)\n        await stream_response.prepare(request)\n        return stream_response\n\n    cnt_conn_reuse = 0\n\n    async def on_reuseconn(session, ctx, params):\n        nonlocal cnt_conn_reuse\n        cnt_conn_reuse += 1\n\n    trace_config = aiohttp.TraceConfig()\n    trace_config._on_connection_reuseconn.append(on_reuseconn)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    connector = aiohttp.TCPConnector(limit=1)\n    client = await aiohttp_client(\n        app, connector=connector, trace_configs=[trace_config]\n    )\n\n    resp1 = await client.get(\"/\")\n    await resp1.read()\n    resp2 = await client.get(\"/\")\n    await resp2.read()\n\n    assert cnt_conn_reuse == 1\n\n\nasync def test_keepalive_response_released(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    connector = aiohttp.TCPConnector(limit=1)\n    client = await aiohttp_client(app, connector=connector)\n\n    resp1 = await client.get(\"/\")\n    resp1.release()\n    resp2 = await client.get(\"/\")\n    resp2.release()\n\n    assert 1 == len(client._session.connector._conns)\n\n\nasync def test_upgrade_connection_not_released_after_read(aiohttp_client: Any) -> None:\n    async def handler(request: web.Request) -> web.Response:\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(\n            status=101, headers={\"Connection\": \"Upgrade\", \"Upgrade\": \"tcp\"}\n        )\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    await resp.read()\n    assert resp.connection is not None\n    assert not resp.closed\n\n\nasync def test_keepalive_server_force_close_connection(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        response = web.Response(body=b\"OK\")\n        response.force_close()\n        return response\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    connector = aiohttp.TCPConnector(limit=1)\n    client = await aiohttp_client(app, connector=connector)\n\n    resp1 = await client.get(\"/\")\n    resp1.close()\n    resp2 = await client.get(\"/\")\n    resp2.close()\n\n    assert 0 == len(client._session.connector._conns)\n\n\nasync def test_keepalive_timeout_async_sleep() -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    runner = web.AppRunner(app, tcp_keepalive=True, keepalive_timeout=0.001)\n    await runner.setup()\n\n    port = unused_port()\n    site = web.TCPSite(runner, host=\"localhost\", port=port)\n    await site.start()\n\n    try:\n        async with aiohttp.client.ClientSession() as sess:\n            resp1 = await sess.get(f\"http://localhost:{port}/\")\n            await resp1.read()\n            # wait for server keepalive_timeout\n            await asyncio.sleep(0.01)\n            resp2 = await sess.get(f\"http://localhost:{port}/\")\n            await resp2.read()\n    finally:\n        await asyncio.gather(runner.shutdown(), site.stop())\n\n\n@pytest.mark.skipif(\n    sys.version_info[:2] == (3, 11),\n    reason=\"https://github.com/pytest-dev/pytest/issues/10763\",\n)\nasync def test_keepalive_timeout_sync_sleep() -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    runner = web.AppRunner(app, tcp_keepalive=True, keepalive_timeout=0.001)\n    await runner.setup()\n\n    port = unused_port()\n    site = web.TCPSite(runner, host=\"localhost\", port=port)\n    await site.start()\n\n    try:\n        async with aiohttp.client.ClientSession() as sess:\n            resp1 = await sess.get(f\"http://localhost:{port}/\")\n            await resp1.read()\n            # wait for server keepalive_timeout\n            # time.sleep is a more challenging scenario than asyncio.sleep\n            time.sleep(0.01)\n            resp2 = await sess.get(f\"http://localhost:{port}/\")\n            await resp2.read()\n    finally:\n        await asyncio.gather(runner.shutdown(), site.stop())\n\n\nasync def test_release_early(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await request.read()\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/\")\n    assert resp.closed\n    await resp.wait_for_close()\n    assert 1 == len(client._session.connector._conns)\n\n\nasync def test_HTTP_304(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(status=304)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 304\n    content = await resp.read()\n    assert content == b\"\"\n\n\nasync def test_stream_request_on_server_eof(aiohttp_client) -> None:\n    async def handler(request):\n        return web.Response(text=\"OK\", status=200)\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n    app.add_routes([web.put(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async def data_gen():\n        for _ in range(2):\n            yield b\"just data\"\n            await asyncio.sleep(0.1)\n\n    async with client.put(\"/\", data=data_gen()) as resp:\n        assert 200 == resp.status\n        assert len(client.session.connector._acquired) == 1\n        conn = next(iter(client.session.connector._acquired))\n\n    async with client.get(\"/\") as resp:\n        assert 200 == resp.status\n\n    # Connection should have been reused\n    conns = next(iter(client.session.connector._conns.values()))\n    assert len(conns) == 1\n    assert conns[0][0] is conn\n\n\nasync def test_stream_request_on_server_eof_nested(aiohttp_client) -> None:\n    async def handler(request):\n        return web.Response(text=\"OK\", status=200)\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n    app.add_routes([web.put(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async def data_gen():\n        for _ in range(2):\n            yield b\"just data\"\n            await asyncio.sleep(0.1)\n\n    async with client.put(\"/\", data=data_gen()) as resp:\n        assert 200 == resp.status\n        async with client.get(\"/\") as resp:\n            assert 200 == resp.status\n\n    # Should be 2 separate connections\n    conns = next(iter(client.session.connector._conns.values()))\n    assert len(conns) == 2\n\n\nasync def test_HTTP_304_WITH_BODY(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        return web.Response(body=b\"test\", status=304)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 304\n    content = await resp.read()\n    assert content == b\"\"\n\n\nasync def test_auto_header_user_agent(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert \"aiohttp\" in request.headers[\"user-agent\"]\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\") as resp:\n        assert 200 == resp.status\n\n\nasync def test_skip_auto_headers_user_agent(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert hdrs.USER_AGENT not in request.headers\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\", skip_auto_headers=[\"user-agent\"]) as resp:\n        assert 200 == resp.status\n\n\nasync def test_skip_default_auto_headers_user_agent(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert hdrs.USER_AGENT not in request.headers\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app, skip_auto_headers=[\"user-agent\"])\n\n    async with client.get(\"/\") as resp:\n        assert 200 == resp.status\n\n\nasync def test_skip_auto_headers_content_type(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert hdrs.CONTENT_TYPE not in request.headers\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\", skip_auto_headers=[\"content-type\"]) as resp:\n        assert 200 == resp.status\n\n\nasync def test_post_data_bytesio(aiohttp_client: Any) -> None:\n    data = b\"some buffer\"\n\n    async def handler(request):\n        assert len(data) == request.content_length\n        val = await request.read()\n        assert data == val\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"POST\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    with io.BytesIO(data) as file_handle:\n        async with client.post(\"/\", data=file_handle) as resp:\n            assert 200 == resp.status\n\n\nasync def test_post_data_with_bytesio_file(aiohttp_client: Any) -> None:\n    data = b\"some buffer\"\n\n    async def handler(request):\n        post_data = await request.post()\n        assert [\"file\"] == list(post_data.keys())\n        assert data == post_data[\"file\"].file.read()\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"POST\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    with io.BytesIO(data) as file_handle:\n        async with client.post(\"/\", data={\"file\": file_handle}) as resp:\n            assert 200 == resp.status\n\n\nasync def test_post_data_stringio(aiohttp_client: Any) -> None:\n    data = \"some buffer\"\n\n    async def handler(request):\n        assert len(data) == request.content_length\n        assert request.headers[\"CONTENT-TYPE\"] == \"text/plain; charset=utf-8\"\n        val = await request.text()\n        assert data == val\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"POST\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.post(\"/\", data=io.StringIO(data)) as resp:\n        assert 200 == resp.status\n\n\nasync def test_post_data_textio_encoding(aiohttp_client: Any) -> None:\n    data = \"\u0442\u0435\u043a\u0441\u0442\"\n\n    async def handler(request):\n        assert request.headers[\"CONTENT-TYPE\"] == \"text/plain; charset=koi8-r\"\n        val = await request.text()\n        assert data == val\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"POST\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    pl = aiohttp.TextIOPayload(io.StringIO(data), encoding=\"koi8-r\")\n    async with client.post(\"/\", data=pl) as resp:\n        assert 200 == resp.status\n\n\nasync def test_ssl_client(\n    aiohttp_server: Any, ssl_ctx: Any, aiohttp_client: Any, client_ssl_ctx: Any\n) -> None:\n    connector = aiohttp.TCPConnector(ssl=client_ssl_ctx)\n\n    async def handler(request):\n        return web.Response(text=\"Test message\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app, ssl=ssl_ctx)\n    client = await aiohttp_client(server, connector=connector)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert txt == \"Test message\"\n\n\nasync def test_tcp_connector_fingerprint_ok(\n    aiohttp_server: Any,\n    aiohttp_client: Any,\n    ssl_ctx: Any,\n    tls_certificate_fingerprint_sha256: Any,\n):\n    tls_fingerprint = Fingerprint(tls_certificate_fingerprint_sha256)\n\n    async def handler(request):\n        return web.Response(text=\"Test message\")\n\n    connector = aiohttp.TCPConnector(ssl=tls_fingerprint)\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app, ssl=ssl_ctx)\n    client = await aiohttp_client(server, connector=connector)\n\n    async with client.get(\"/\") as resp:\n        assert resp.status == 200\n\n\nasync def test_tcp_connector_fingerprint_fail(\n    aiohttp_server: Any,\n    aiohttp_client: Any,\n    ssl_ctx: Any,\n    tls_certificate_fingerprint_sha256: Any,\n):\n    async def handler(request):\n        return web.Response(text=\"Test message\")\n\n    bad_fingerprint = b\"\\x00\" * len(tls_certificate_fingerprint_sha256)\n\n    connector = aiohttp.TCPConnector(ssl=Fingerprint(bad_fingerprint))\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app, ssl=ssl_ctx)\n    client = await aiohttp_client(server, connector=connector)\n\n    with pytest.raises(ServerFingerprintMismatch) as cm:\n        await client.get(\"/\")\n    exc = cm.value\n    assert exc.expected == bad_fingerprint\n    assert exc.got == tls_certificate_fingerprint_sha256\n\n\nasync def test_format_task_get(aiohttp_server: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_server(app)\n    client = aiohttp.ClientSession()\n    task = asyncio.create_task(client.get(server.make_url(\"/\")))\n    assert f\"{task}\".startswith(\"<Task pending\")\n    resp = await task\n    resp.close()\n    await client.close()\n\n\nasync def test_str_params(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert \"q=t est\" in request.rel_url.query_string\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\", params=\"q=t+est\") as resp:\n        assert 200 == resp.status\n\n\nasync def test_drop_params_on_redirect(aiohttp_client: Any) -> None:\n    async def handler_redirect(request):\n        return web.Response(status=301, headers={\"Location\": \"/ok?a=redirect\"})\n\n    async def handler_ok(request):\n        assert request.rel_url.query_string == \"a=redirect\"\n        return web.Response(status=200)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/ok\", handler_ok)\n    app.router.add_route(\"GET\", \"/redirect\", handler_redirect)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/redirect\", params={\"a\": \"initial\"}) as resp:\n        assert resp.status == 200\n\n\nasync def test_drop_fragment_on_redirect(aiohttp_client: Any) -> None:\n    async def handler_redirect(request):\n        return web.Response(status=301, headers={\"Location\": \"/ok#fragment\"})\n\n    async def handler_ok(request):\n        return web.Response(status=200)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/ok\", handler_ok)\n    app.router.add_route(\"GET\", \"/redirect\", handler_redirect)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/redirect\") as resp:\n        assert resp.status == 200\n        assert resp.url.path == \"/ok\"\n\n\nasync def test_drop_fragment(aiohttp_client: Any) -> None:\n    async def handler_ok(request):\n        return web.Response(status=200)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/ok\", handler_ok)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/ok#fragment\") as resp:\n        assert resp.status == 200\n        assert resp.url.path == \"/ok\"\n\n\nasync def test_history(aiohttp_client: Any) -> None:\n    async def handler_redirect(request):\n        return web.Response(status=301, headers={\"Location\": \"/ok\"})\n\n    async def handler_ok(request):\n        return web.Response(status=200)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/ok\", handler_ok)\n    app.router.add_route(\"GET\", \"/redirect\", handler_redirect)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/ok\") as resp:\n        assert len(resp.history) == 0\n        assert resp.status == 200\n\n    async with client.get(\"/redirect\") as resp_redirect:\n        assert len(resp_redirect.history) == 1\n        assert resp_redirect.history[0].status == 301\n        assert resp_redirect.status == 200\n\n\nasync def test_keepalive_closed_by_server(aiohttp_client: Any) -> None:\n    async def handler(request):\n        body = await request.read()\n        assert b\"\" == body\n        resp = web.Response(body=b\"OK\")\n        resp.force_close()\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    connector = aiohttp.TCPConnector(limit=1)\n    client = await aiohttp_client(app, connector=connector)\n\n    resp1 = await client.get(\"/\")\n    val1 = await resp1.read()\n    assert val1 == b\"OK\"\n    resp2 = await client.get(\"/\")\n    val2 = await resp2.read()\n    assert val2 == b\"OK\"\n\n    assert 0 == len(client._session.connector._conns)\n\n\nasync def test_wait_for(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"OK\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await asyncio.wait_for(client.get(\"/\"), 10)\n    assert resp.status == 200\n    txt = await resp.text()\n    assert txt == \"OK\"\n\n\nasync def test_raw_headers(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    async with client.get(\"/\") as resp:\n        assert resp.status == 200\n\n        raw_headers = tuple((bytes(h), bytes(v)) for h, v in resp.raw_headers)\n        assert raw_headers == (\n            (b\"Content-Length\", b\"0\"),\n            (b\"Content-Type\", b\"application/octet-stream\"),\n            (b\"Date\", mock.ANY),\n            (b\"Server\", mock.ANY),\n        )\n\n\nasync def test_host_header_first(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert list(request.headers)[0] == hdrs.HOST\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    async with client.get(\"/\") as resp:\n        assert resp.status == 200\n\n\nasync def test_empty_header_values(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.Response()\n        resp.headers[\"X-Empty\"] = \"\"\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n    async with client.get(\"/\") as resp:\n        assert resp.status == 200\n        raw_headers = tuple((bytes(h), bytes(v)) for h, v in resp.raw_headers)\n        assert raw_headers == (\n            (b\"X-Empty\", b\"\"),\n            (b\"Content-Length\", b\"0\"),\n            (b\"Content-Type\", b\"application/octet-stream\"),\n            (b\"Date\", mock.ANY),\n            (b\"Server\", mock.ANY),\n        )\n\n\nasync def test_204_with_gzipped_content_encoding(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse(status=204)\n        resp.content_length = 0\n        resp.content_type = \"application/json\"\n        # resp.enable_compression(web.ContentCoding.gzip)\n        resp.headers[\"Content-Encoding\"] = \"gzip\"\n        await resp.prepare(request)\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"DELETE\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.delete(\"/\") as resp:\n        assert resp.status == 204\n        assert resp.closed\n\n\nasync def test_timeout_on_reading_headers(aiohttp_client: Any, mocker: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse()\n        await asyncio.sleep(0.1)\n        await resp.prepare(request)\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    with pytest.raises(asyncio.TimeoutError):\n        await client.get(\"/\", timeout=aiohttp.ClientTimeout(total=0.01))\n\n\nasync def test_timeout_on_conn_reading_headers(\n    aiohttp_client: Any, mocker: Any\n) -> None:\n    # tests case where user did not set a connection timeout\n\n    async def handler(request):\n        resp = web.StreamResponse()\n        await asyncio.sleep(0.1)\n        await resp.prepare(request)\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    conn = aiohttp.TCPConnector()\n    client = await aiohttp_client(app, connector=conn)\n\n    with pytest.raises(asyncio.TimeoutError):\n        await client.get(\"/\", timeout=aiohttp.ClientTimeout(total=0.01))\n\n\nasync def test_timeout_on_session_read_timeout(\n    aiohttp_client: Any, mocker: Any\n) -> None:\n    async def handler(request):\n        resp = web.StreamResponse()\n        await asyncio.sleep(0.1)\n        await resp.prepare(request)\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    conn = aiohttp.TCPConnector()\n    client = await aiohttp_client(\n        app, connector=conn, timeout=aiohttp.ClientTimeout(sock_read=0.01)\n    )\n\n    with pytest.raises(asyncio.TimeoutError):\n        await client.get(\"/\")\n\n\nasync def test_read_timeout_between_chunks(aiohttp_client: Any, mocker: Any) -> None:\n    async def handler(request):\n        resp = aiohttp.web.StreamResponse()\n        await resp.prepare(request)\n        # write data 4 times, with pauses. Total time 2 seconds.\n        for _ in range(4):\n            await asyncio.sleep(0.5)\n            await resp.write(b\"data\\n\")\n        return resp\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    # A timeout of 0.2 seconds should apply per read.\n    timeout = aiohttp.ClientTimeout(sock_read=1)\n    client = await aiohttp_client(app, timeout=timeout)\n\n    res = b\"\"\n    async with await client.get(\"/\") as resp:\n        res += await resp.read()\n\n    assert res == b\"data\\n\" * 4\n\n\nasync def test_read_timeout_on_reading_chunks(aiohttp_client: Any, mocker: Any) -> None:\n    async def handler(request):\n        resp = aiohttp.web.StreamResponse()\n        await resp.prepare(request)\n        await resp.write(b\"data\\n\")\n        await asyncio.sleep(1)\n        await resp.write(b\"data\\n\")\n        return resp\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    # A timeout of 0.2 seconds should apply per read.\n    timeout = aiohttp.ClientTimeout(sock_read=0.2)\n    client = await aiohttp_client(app, timeout=timeout)\n\n    async with await client.get(\"/\") as resp:\n        assert (await resp.content.read(5)) == b\"data\\n\"\n        with pytest.raises(asyncio.TimeoutError):\n            await resp.content.read()\n\n\nasync def test_read_timeout_on_write(aiohttp_client: Any) -> None:\n    async def gen_payload() -> AsyncIterator[str]:\n        # Delay writing to ensure read timeout isn't triggered before writing completes.\n        await asyncio.sleep(0.5)\n        yield b\"foo\"\n\n    async def handler(request: web.Request) -> web.Response:\n        return web.Response(body=await request.read())\n\n    app = web.Application()\n    app.router.add_put(\"/\", handler)\n\n    timeout = aiohttp.ClientTimeout(total=None, sock_read=0.1)\n    client = await aiohttp_client(app)\n    async with client.put(\"/\", data=gen_payload(), timeout=timeout) as resp:\n        result = await resp.read()  # Should not trigger a read timeout.\n    assert result == b\"foo\"\n\n\nasync def test_timeout_on_reading_data(aiohttp_client: Any, mocker: Any) -> None:\n    loop = asyncio.get_event_loop()\n\n    fut = loop.create_future()\n\n    async def handler(request):\n        resp = web.StreamResponse(headers={\"content-length\": \"100\"})\n        await resp.prepare(request)\n        fut.set_result(None)\n        await asyncio.sleep(0.2)\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\", timeout=aiohttp.ClientTimeout(1))\n    await fut\n\n    with pytest.raises(asyncio.TimeoutError):\n        await resp.read()\n\n\nasync def test_timeout_none(aiohttp_client: Any, mocker: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse()\n        await resp.prepare(request)\n        return resp\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\", timeout=None) as resp:\n        assert resp.status == 200\n\n\nasync def test_readline_error_on_conn_close(aiohttp_client: Any) -> None:\n    loop = asyncio.get_event_loop()\n\n    async def handler(request):\n        resp_ = web.StreamResponse()\n        await resp_.prepare(request)\n\n        # make sure connection is closed by client.\n        with pytest.raises(aiohttp.ServerDisconnectedError):\n            for _ in range(10):\n                await resp_.write(b\"data\\n\")\n                await asyncio.sleep(0.5)\n            return resp_\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_client(app)\n\n    session = aiohttp.ClientSession()\n    try:\n        timer_started = False\n        url, headers = server.make_url(\"/\"), {\"Connection\": \"Keep-alive\"}\n        resp = await session.get(url, headers=headers)\n        with pytest.raises(aiohttp.ClientConnectionError):\n            while True:\n                data = await resp.content.readline()\n                data = data.strip()\n                if not data:\n                    break\n                assert data == b\"data\"\n                if not timer_started:\n\n                    def do_release():\n                        loop.create_task(resp.release())\n\n                    loop.call_later(1.0, do_release)\n                    timer_started = True\n    finally:\n        await session.close()\n\n\nasync def test_no_error_on_conn_close_if_eof(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp_ = web.StreamResponse()\n        await resp_.prepare(request)\n        await resp_.write(b\"data\\n\")\n        await asyncio.sleep(0.5)\n        return resp_\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_client(app)\n\n    session = aiohttp.ClientSession()\n    try:\n        url, headers = server.make_url(\"/\"), {\"Connection\": \"Keep-alive\"}\n        resp = await session.get(url, headers=headers)\n        while True:\n            data = await resp.content.readline()\n            data = data.strip()\n            if not data:\n                break\n            assert data == b\"data\"\n\n        assert resp.content.exception() is None\n    finally:\n        await session.close()\n\n\nasync def test_error_not_overwrote_on_conn_close(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp_ = web.StreamResponse()\n        await resp_.prepare(request)\n        return resp_\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    server = await aiohttp_client(app)\n\n    session = aiohttp.ClientSession()\n    try:\n        url, headers = server.make_url(\"/\"), {\"Connection\": \"Keep-alive\"}\n        resp = await session.get(url, headers=headers)\n        resp.content.set_exception(ValueError())\n    finally:\n        await session.close()\n\n    assert isinstance(resp.content.exception(), ValueError)\n\n\nasync def test_HTTP_200_OK_METHOD(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    app = web.Application()\n    for meth in (\"get\", \"post\", \"put\", \"delete\", \"head\", \"patch\", \"options\"):\n        app.router.add_route(meth.upper(), \"/\", handler)\n\n    client = await aiohttp_client(app)\n    for meth in (\"get\", \"post\", \"put\", \"delete\", \"head\", \"patch\", \"options\"):\n        resp = await client.request(meth, \"/\")\n        assert resp.status == 200\n        assert len(resp.history) == 0\n\n        content1 = await resp.read()\n        content2 = await resp.read()\n        assert content1 == content2\n        content = await resp.text()\n\n        if meth == \"head\":\n            assert b\"\" == content1\n        else:\n            assert meth.upper() == content\n\n\nasync def test_HTTP_200_OK_METHOD_connector(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    conn = aiohttp.TCPConnector()\n    conn.clear_dns_cache()\n\n    app = web.Application()\n    for meth in (\"get\", \"post\", \"put\", \"delete\", \"head\"):\n        app.router.add_route(meth.upper(), \"/\", handler)\n    client = await aiohttp_client(app, connector=conn)\n\n    for meth in (\"get\", \"post\", \"put\", \"delete\", \"head\"):\n        resp = await client.request(meth, \"/\")\n\n        content1 = await resp.read()\n        content2 = await resp.read()\n        assert content1 == content2\n        content = await resp.text()\n\n        assert resp.status == 200\n        if meth == \"head\":\n            assert b\"\" == content1\n        else:\n            assert meth.upper() == content\n\n\nasync def test_HTTP_302_REDIRECT_GET(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    async def redirect(request):\n        raise web.HTTPFound(location=\"/\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    app.router.add_get(\"/redirect\", redirect)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/redirect\") as resp:\n        assert 200 == resp.status\n        assert 1 == len(resp.history)\n\n\nasync def test_HTTP_302_REDIRECT_HEAD(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    async def redirect(request):\n        raise web.HTTPFound(location=\"/\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    app.router.add_get(\"/redirect\", redirect)\n    app.router.add_head(\"/\", handler)\n    app.router.add_head(\"/redirect\", redirect)\n    client = await aiohttp_client(app)\n\n    async with client.request(\"head\", \"/redirect\") as resp:\n        assert 200 == resp.status\n        assert 1 == len(resp.history)\n        assert resp.method == \"HEAD\"\n\n\nasync def test_HTTP_302_REDIRECT_NON_HTTP(aiohttp_client: Any) -> None:\n    async def redirect(request):\n        raise web.HTTPFound(location=\"ftp://127.0.0.1/test/\")\n\n    app = web.Application()\n    app.router.add_get(\"/redirect\", redirect)\n    client = await aiohttp_client(app)\n\n    with pytest.raises(NonHttpUrlRedirectClientError):\n        await client.get(\"/redirect\")\n\n\nasync def test_HTTP_302_REDIRECT_POST(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    async def redirect(request):\n        raise web.HTTPFound(location=\"/\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    app.router.add_post(\"/redirect\", redirect)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/redirect\")\n    assert 200 == resp.status\n    assert 1 == len(resp.history)\n    txt = await resp.text()\n    assert txt == \"GET\"\n    resp.close()\n\n\nasync def test_HTTP_302_REDIRECT_POST_with_content_length_hdr(\n    aiohttp_client: Any,\n) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    async def redirect(request):\n        await request.read()\n        raise web.HTTPFound(location=\"/\")\n\n    data = json.dumps({\"some\": \"data\"})\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    app.router.add_post(\"/redirect\", redirect)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\n        \"/redirect\", data=data, headers={\"Content-Length\": str(len(data))}\n    )\n    assert 200 == resp.status\n    assert 1 == len(resp.history)\n    txt = await resp.text()\n    assert txt == \"GET\"\n    resp.close()\n\n\nasync def test_HTTP_307_REDIRECT_POST(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    async def redirect(request):\n        await request.read()\n        raise web.HTTPTemporaryRedirect(location=\"/\")\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    app.router.add_post(\"/redirect\", redirect)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/redirect\", data={\"some\": \"data\"})\n    assert 200 == resp.status\n    assert 1 == len(resp.history)\n    txt = await resp.text()\n    assert txt == \"POST\"\n    resp.close()\n\n\nasync def test_HTTP_308_PERMANENT_REDIRECT_POST(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    async def redirect(request):\n        await request.read()\n        raise web.HTTPPermanentRedirect(location=\"/\")\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    app.router.add_post(\"/redirect\", redirect)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/redirect\", data={\"some\": \"data\"})\n    assert 200 == resp.status\n    assert 1 == len(resp.history)\n    txt = await resp.text()\n    assert txt == \"POST\"\n    resp.close()\n\n\nasync def test_HTTP_302_max_redirects(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    async def redirect(request):\n        count = int(request.match_info[\"count\"])\n        if count:\n            raise web.HTTPFound(location=f\"/redirect/{count - 1}\")\n        else:\n            raise web.HTTPFound(location=\"/\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    app.router.add_get(r\"/redirect/{count:\\d+}\", redirect)\n    client = await aiohttp_client(app)\n\n    with pytest.raises(TooManyRedirects) as ctx:\n        await client.get(\"/redirect/5\", max_redirects=2)\n    assert 2 == len(ctx.value.history)\n    assert ctx.value.request_info.url.path == \"/redirect/5\"\n    assert ctx.value.request_info.method == \"GET\"\n\n\nasync def test_HTTP_200_GET_WITH_PARAMS(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(\n            text=\"&\".join(k + \"=\" + v for k, v in request.query.items())\n        )\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\", params={\"q\": \"test\"})\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert txt == \"q=test\"\n    resp.close()\n\n\nasync def test_HTTP_200_GET_WITH_MultiDict_PARAMS(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(\n            text=\"&\".join(k + \"=\" + v for k, v in request.query.items())\n        )\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\", params=MultiDict([(\"q\", \"test\"), (\"q\", \"test2\")]))\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert txt == \"q=test&q=test2\"\n    resp.close()\n\n\nasync def test_HTTP_200_GET_WITH_MIXED_PARAMS(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(\n            text=\"&\".join(k + \"=\" + v for k, v in request.query.items())\n        )\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/?test=true\", params={\"q\": \"test\"})\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert txt == \"test=true&q=test\"\n    resp.close()\n\n\nasync def test_POST_DATA(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        return web.json_response(dict(data))\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data={\"some\": \"data\"})\n    assert 200 == resp.status\n    content = await resp.json()\n    assert content == {\"some\": \"data\"}\n    resp.close()\n\n\nasync def test_POST_DATA_with_explicit_formdata(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        return web.json_response(dict(data))\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    form = aiohttp.FormData()\n    form.add_field(\"name\", \"text\")\n\n    resp = await client.post(\"/\", data=form)\n    assert 200 == resp.status\n    content = await resp.json()\n    assert content == {\"name\": \"text\"}\n    resp.close()\n\n\nasync def test_POST_DATA_with_charset(aiohttp_client: Any) -> None:\n    async def handler(request):\n        mp = await request.multipart()\n        part = await mp.next()\n        text = await part.text()\n        return web.Response(text=text)\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    form = aiohttp.FormData()\n    form.add_field(\"name\", \"\u0442\u0435\u043a\u0441\u0442\", content_type=\"text/plain; charset=koi8-r\")\n\n    resp = await client.post(\"/\", data=form)\n    assert 200 == resp.status\n    content = await resp.text()\n    assert content == \"\u0442\u0435\u043a\u0441\u0442\"\n    resp.close()\n\n\nasync def test_POST_DATA_formdats_with_charset(aiohttp_client: Any) -> None:\n    async def handler(request):\n        mp = await request.post()\n        assert \"name\" in mp\n        return web.Response(text=mp[\"name\"])\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    form = aiohttp.FormData(charset=\"koi8-r\")\n    form.add_field(\"name\", \"\u0442\u0435\u043a\u0441\u0442\")\n\n    resp = await client.post(\"/\", data=form)\n    assert 200 == resp.status\n    content = await resp.text()\n    assert content == \"\u0442\u0435\u043a\u0441\u0442\"\n    resp.close()\n\n\nasync def test_POST_DATA_with_charset_post(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        return web.Response(text=data[\"name\"])\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    form = aiohttp.FormData()\n    form.add_field(\"name\", \"\u0442\u0435\u043a\u0441\u0442\", content_type=\"text/plain; charset=koi8-r\")\n\n    resp = await client.post(\"/\", data=form)\n    assert 200 == resp.status\n    content = await resp.text()\n    assert content == \"\u0442\u0435\u043a\u0441\u0442\"\n    resp.close()\n\n\nasync def test_POST_MultiDict(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert data == MultiDict([(\"q\", \"test1\"), (\"q\", \"test2\")])\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.post(\n        \"/\", data=MultiDict([(\"q\", \"test1\"), (\"q\", \"test2\")])\n    ) as resp:\n        assert 200 == resp.status\n\n\nasync def test_POST_DATA_DEFLATE(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        return web.json_response(dict(data))\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", data={\"some\": \"data\"}, compress=True)\n    assert 200 == resp.status\n    content = await resp.json()\n    assert content == {\"some\": \"data\"}\n    resp.close()\n\n\nasync def test_POST_FILES(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert data[\"some\"].filename == fname.name\n        with fname.open(\"rb\") as f:\n            content1 = f.read()\n        content2 = data[\"some\"].file.read()\n        assert content1 == content2\n        assert data[\"test\"].file.read() == b\"data\"\n        data[\"some\"].file.close()\n        data[\"test\"].file.close()\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        async with client.post(\n            \"/\", data={\"some\": f, \"test\": io.BytesIO(b\"data\")}, chunked=True\n        ) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_FILES_DEFLATE(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert data[\"some\"].filename == fname.name\n        with fname.open(\"rb\") as f:\n            content1 = f.read()\n        content2 = data[\"some\"].file.read()\n        data[\"some\"].file.close()\n        assert content1 == content2\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        async with client.post(\n            \"/\", data={\"some\": f}, chunked=True, compress=\"deflate\"\n        ) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_bytes(aiohttp_client: Any) -> None:\n    body = b\"0\" * 12345\n\n    async def handler(request):\n        data = await request.read()\n        assert body == data\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.post(\"/\", data=body) as resp:\n        assert 200 == resp.status\n\n\nasync def test_POST_bytes_too_large(aiohttp_client: Any) -> None:\n    body = b\"0\" * (2**20 + 1)\n\n    async def handler(request):\n        data = await request.content.read()\n        assert body == data\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with pytest.warns(ResourceWarning):\n        resp = await client.post(\"/\", data=body)\n\n    assert 200 == resp.status\n    resp.close()\n\n\nasync def test_POST_FILES_STR(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        with fname.open(\"rb\") as f:\n            content1 = f.read().decode()\n        content2 = data[\"some\"]\n        assert content1 == content2\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        async with client.post(\"/\", data={\"some\": f.read().decode()}) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_FILES_STR_SIMPLE(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        data = await request.read()\n        with fname.open(\"rb\") as f:\n            content = f.read()\n        assert content == data\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        async with client.post(\"/\", data=f.read()) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_FILES_LIST(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert fname.name == data[\"some\"].filename\n        with fname.open(\"rb\") as f:\n            content = f.read()\n        assert content == data[\"some\"].file.read()\n        data[\"some\"].file.close()\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        async with client.post(\"/\", data=[(\"some\", f)]) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_FILES_CT(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert fname.name == data[\"some\"].filename\n        assert \"text/plain\" == data[\"some\"].content_type\n        with fname.open(\"rb\") as f:\n            content = f.read()\n        assert content == data[\"some\"].file.read()\n        data[\"some\"].file.close()\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        form = aiohttp.FormData()\n        form.add_field(\"some\", f, content_type=\"text/plain\")\n        async with client.post(\"/\", data=form) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_FILES_SINGLE(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        data = await request.text()\n        with fname.open(\"rb\") as f:\n            content = f.read().decode()\n            assert content == data\n        # if system cannot determine 'text/x-python' MIME type\n        # then use 'application/octet-stream' default\n        assert request.content_type in [\n            \"text/plain\",\n            \"application/octet-stream\",\n            \"text/x-python\",\n        ]\n        assert \"content-disposition\" not in request.headers\n\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        async with client.post(\"/\", data=f) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_FILES_SINGLE_content_disposition(\n    aiohttp_client: Any, fname: Any\n) -> None:\n    async def handler(request):\n        data = await request.text()\n        with fname.open(\"rb\") as f:\n            content = f.read().decode()\n            assert content == data\n        # if system cannot determine 'application/pgp-keys' MIME type\n        # then use 'application/octet-stream' default\n        assert request.content_type in [\n            \"text/plain\",\n            \"application/octet-stream\",\n            \"text/x-python\",\n        ]\n        assert request.headers[\"content-disposition\"] == (\n            'inline; filename=\"conftest.py\"'\n        )\n\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        async with client.post(\n            \"/\", data=aiohttp.get_payload(f, disposition=\"inline\")\n        ) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_FILES_SINGLE_BINARY(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        data = await request.read()\n        with fname.open(\"rb\") as f:\n            content = f.read()\n        assert content == data\n        # if system cannot determine 'application/pgp-keys' MIME type\n        # then use 'application/octet-stream' default\n        assert request.content_type in [\n            \"application/pgp-keys\",\n            \"text/plain\",\n            \"text/x-python\",\n            \"application/octet-stream\",\n        ]\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        async with client.post(\"/\", data=f) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_FILES_IO(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert b\"data\" == data[\"unknown\"].file.read()\n        assert data[\"unknown\"].content_type == \"application/octet-stream\"\n        assert data[\"unknown\"].filename == \"unknown\"\n        data[\"unknown\"].file.close()\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with io.BytesIO(b\"data\") as file_handle:\n        async with client.post(\"/\", data=[file_handle]) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_FILES_IO_WITH_PARAMS(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert data[\"test\"] == \"true\"\n        assert data[\"unknown\"].content_type == \"application/octet-stream\"\n        assert data[\"unknown\"].filename == \"unknown\"\n        assert data[\"unknown\"].file.read() == b\"data\"\n        data[\"unknown\"].file.close()\n        assert data.getall(\"q\") == [\"t1\", \"t2\"]\n\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with io.BytesIO(b\"data\") as file_handle:\n        async with client.post(\n            \"/\",\n            data=((\"test\", \"true\"), MultiDict([(\"q\", \"t1\"), (\"q\", \"t2\")]), file_handle),\n        ) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_FILES_WITH_DATA(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        data = await request.post()\n        assert data[\"test\"] == \"true\"\n        assert data[\"some\"].content_type in [\n            \"text/x-python\",\n            \"text/plain\",\n            \"application/octet-stream\",\n        ]\n        assert data[\"some\"].filename == fname.name\n        with fname.open(\"rb\") as f:\n            assert data[\"some\"].file.read() == f.read()\n            data[\"some\"].file.close()\n\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        async with client.post(\"/\", data={\"test\": \"true\", \"some\": f}) as resp:\n            assert 200 == resp.status\n\n\nasync def test_POST_STREAM_DATA(aiohttp_client: Any, fname: Any) -> None:\n    async def handler(request):\n        assert request.content_type == \"application/octet-stream\"\n        content = await request.read()\n        with fname.open(\"rb\") as f:\n            expected = f.read()\n            assert request.content_length == len(expected)\n            assert content == expected\n\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with fname.open(\"rb\") as f:\n        data_size = len(f.read())\n\n    async def gen(fname):\n        with fname.open(\"rb\") as f:\n            data = f.read(100)\n            while data:\n                yield data\n                data = f.read(100)\n\n    async with client.post(\n        \"/\", data=gen(fname), headers={\"Content-Length\": str(data_size)}\n    ) as resp:\n        assert 200 == resp.status\n\n\nasync def test_json(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.content_type == \"application/json\"\n        data = await request.json()\n        return web.Response(body=aiohttp.JsonPayload(data))\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.post(\"/\", json={\"some\": \"data\"})\n    assert 200 == resp.status\n    content = await resp.json()\n    assert content == {\"some\": \"data\"}\n    resp.close()\n\n    with pytest.raises(ValueError):\n        await client.post(\"/\", data=\"some data\", json={\"some\": \"data\"})\n\n\nasync def test_json_custom(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.content_type == \"application/json\"\n        data = await request.json()\n        return web.Response(body=aiohttp.JsonPayload(data))\n\n    used = False\n\n    def dumps(obj):\n        nonlocal used\n        used = True\n        return json.dumps(obj)\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app, json_serialize=dumps)\n\n    resp = await client.post(\"/\", json={\"some\": \"data\"})\n    assert 200 == resp.status\n    assert used\n    content = await resp.json()\n    assert content == {\"some\": \"data\"}\n    resp.close()\n\n    with pytest.raises(ValueError):\n        await client.post(\"/\", data=\"some data\", json={\"some\": \"data\"})\n\n\nasync def test_expect_continue(aiohttp_client: Any) -> None:\n    expect_called = False\n\n    async def handler(request):\n        data = await request.post()\n        assert data == {\"some\": \"data\"}\n        return web.Response()\n\n    async def expect_handler(request):\n        nonlocal expect_called\n        expect = request.headers.get(hdrs.EXPECT)\n        if expect.lower() == \"100-continue\":\n            request.transport.write(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n            expect_called = True\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler, expect_handler=expect_handler)\n    client = await aiohttp_client(app)\n\n    async with client.post(\"/\", data={\"some\": \"data\"}, expect100=True) as resp:\n        assert 200 == resp.status\n    assert expect_called\n\n\nasync def test_encoding_deflate(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.Response(text=\"text\")\n        resp.enable_chunked_encoding()\n        resp.enable_compression(web.ContentCoding.deflate)\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert txt == \"text\"\n    resp.close()\n\n\nasync def test_encoding_deflate_nochunk(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.Response(text=\"text\")\n        resp.enable_compression(web.ContentCoding.deflate)\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert txt == \"text\"\n    resp.close()\n\n\nasync def test_encoding_gzip(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.Response(text=\"text\")\n        resp.enable_chunked_encoding()\n        resp.enable_compression(web.ContentCoding.gzip)\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert txt == \"text\"\n    resp.close()\n\n\nasync def test_encoding_gzip_write_by_chunks(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse()\n        resp.enable_compression(web.ContentCoding.gzip)\n        await resp.prepare(request)\n        await resp.write(b\"0\")\n        await resp.write(b\"0\")\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert txt == \"00\"\n    resp.close()\n\n\nasync def test_encoding_gzip_nochunk(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.Response(text=\"text\")\n        resp.enable_compression(web.ContentCoding.gzip)\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    txt = await resp.text()\n    assert txt == \"text\"\n    resp.close()\n\n\nasync def test_bad_payload_compression(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.Response(text=\"text\")\n        resp.headers[\"Content-Encoding\"] = \"gzip\"\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n\n    with pytest.raises(aiohttp.ClientPayloadError):\n        await resp.read()\n\n    resp.close()\n\n\nasync def test_bad_payload_chunked_encoding(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse()\n        resp.force_close()\n        resp._length_check = False\n        resp.headers[\"Transfer-Encoding\"] = \"chunked\"\n        writer = await resp.prepare(request)\n        await writer.write(b\"9\\r\\n\\r\\n\")\n        await writer.write_eof()\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n\n    with pytest.raises(aiohttp.ClientPayloadError):\n        await resp.read()\n\n    resp.close()\n\n\nasync def test_no_payload_304_with_chunked_encoding(aiohttp_client: Any) -> None:\n    \"\"\"Test a 304 response with no payload with chunked set should have it removed.\"\"\"\n\n    async def handler(request):\n        resp = web.StreamResponse(status=304)\n        resp.enable_chunked_encoding()\n        resp._length_check = False\n        resp.headers[\"Transfer-Encoding\"] = \"chunked\"\n        writer = await resp.prepare(request)\n        await writer.write_eof()\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 304\n    assert hdrs.CONTENT_LENGTH not in resp.headers\n    assert hdrs.TRANSFER_ENCODING not in resp.headers\n    await resp.read()\n\n    resp.close()\n\n\nasync def test_head_request_with_chunked_encoding(aiohttp_client: Any) -> None:\n    \"\"\"Test a head response with chunked set should have it removed.\"\"\"\n\n    async def handler(request):\n        resp = web.StreamResponse(status=200)\n        resp.enable_chunked_encoding()\n        resp._length_check = False\n        resp.headers[\"Transfer-Encoding\"] = \"chunked\"\n        writer = await resp.prepare(request)\n        await writer.write_eof()\n        return resp\n\n    app = web.Application()\n    app.router.add_head(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.head(\"/\")\n    assert resp.status == 200\n    assert hdrs.CONTENT_LENGTH not in resp.headers\n    assert hdrs.TRANSFER_ENCODING not in resp.headers\n    await resp.read()\n\n    resp.close()\n\n\nasync def test_no_payload_200_with_chunked_encoding(aiohttp_client: Any) -> None:\n    \"\"\"Test chunked is preserved on a 200 response with no payload.\"\"\"\n\n    async def handler(request):\n        resp = web.StreamResponse(status=200)\n        resp.enable_chunked_encoding()\n        resp._length_check = False\n        resp.headers[\"Transfer-Encoding\"] = \"chunked\"\n        writer = await resp.prepare(request)\n        await writer.write_eof()\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert resp.status == 200\n    assert hdrs.CONTENT_LENGTH not in resp.headers\n    assert hdrs.TRANSFER_ENCODING in resp.headers\n    await resp.read()\n\n    resp.close()\n\n\nasync def test_bad_payload_content_length(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.Response(text=\"text\")\n        resp.headers[\"Content-Length\"] = \"10000\"\n        resp.force_close()\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n\n    with pytest.raises(aiohttp.ClientPayloadError):\n        await resp.read()\n\n    resp.close()\n\n\nasync def test_payload_content_length_by_chunks(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse(headers={\"content-length\": \"2\"})\n        await resp.prepare(request)\n        await resp.write(b\"answer\")\n        await resp.write(b\"two\")\n        request.transport.close()\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    data = await resp.read()\n    assert data == b\"an\"\n    resp.close()\n\n\nasync def test_chunked(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.Response(text=\"text\")\n        resp.enable_chunked_encoding()\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    assert 200 == resp.status\n    assert resp.headers[\"Transfer-Encoding\"] == \"chunked\"\n    txt = await resp.text()\n    assert txt == \"text\"\n    resp.close()\n\n\nasync def test_shortcuts(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    app = web.Application()\n    for meth in (\"get\", \"post\", \"put\", \"delete\", \"head\", \"patch\", \"options\"):\n        app.router.add_route(meth.upper(), \"/\", handler)\n    client = await aiohttp_client(app)\n\n    for meth in (\"get\", \"post\", \"put\", \"delete\", \"head\", \"patch\", \"options\"):\n        coro = getattr(client.session, meth)\n        resp = await coro(client.make_url(\"/\"))\n\n        assert resp.status == 200\n        assert len(resp.history) == 0\n\n        content1 = await resp.read()\n        content2 = await resp.read()\n        assert content1 == content2\n        content = await resp.text()\n\n        if meth == \"head\":\n            assert b\"\" == content1\n        else:\n            assert meth.upper() == content\n\n\nasync def test_cookies(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.cookies.keys() == {\"test1\", \"test3\"}\n        assert request.cookies[\"test1\"] == \"123\"\n        assert request.cookies[\"test3\"] == \"456\"\n        return web.Response()\n\n    c = http.cookies.Morsel()\n    c.set(\"test3\", \"456\", \"456\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, cookies={\"test1\": \"123\", \"test2\": c})\n\n    async with client.get(\"/\") as resp:\n        assert 200 == resp.status\n\n\nasync def test_cookies_per_request(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.cookies.keys() == {\"test1\", \"test3\", \"test4\", \"test6\"}\n        assert request.cookies[\"test1\"] == \"123\"\n        assert request.cookies[\"test3\"] == \"456\"\n        assert request.cookies[\"test4\"] == \"789\"\n        assert request.cookies[\"test6\"] == \"abc\"\n        return web.Response()\n\n    c = http.cookies.Morsel()\n    c.set(\"test3\", \"456\", \"456\")\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, cookies={\"test1\": \"123\", \"test2\": c})\n\n    rc = http.cookies.Morsel()\n    rc.set(\"test6\", \"abc\", \"abc\")\n\n    async with client.get(\"/\", cookies={\"test4\": \"789\", \"test5\": rc}) as resp:\n        assert 200 == resp.status\n\n\nasync def test_cookies_redirect(aiohttp_client: Any) -> None:\n    async def redirect1(request):\n        ret = web.Response(status=301, headers={\"Location\": \"/redirect2\"})\n        ret.set_cookie(\"c\", \"1\")\n        return ret\n\n    async def redirect2(request):\n        ret = web.Response(status=301, headers={\"Location\": \"/\"})\n        ret.set_cookie(\"c\", \"2\")\n        return ret\n\n    async def handler(request):\n        assert request.cookies.keys() == {\"c\"}\n        assert request.cookies[\"c\"] == \"2\"\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/redirect1\", redirect1)\n    app.router.add_get(\"/redirect2\", redirect2)\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app)\n    async with client.get(\"/redirect1\") as resp:\n        assert 200 == resp.status\n\n\nasync def test_cookies_on_empty_session_jar(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert \"custom-cookie\" in request.cookies\n        assert request.cookies[\"custom-cookie\"] == \"abc\"\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, cookies=None)\n\n    async with client.get(\"/\", cookies={\"custom-cookie\": \"abc\"}) as resp:\n        assert 200 == resp.status\n\n\nasync def test_morsel_with_attributes(aiohttp_client: Any) -> None:\n    # A comment from original test:\n    #\n    # No cookie attribute should pass here\n    # they are only used as filters\n    # whether to send particular cookie or not.\n    # E.g. if cookie expires it just becomes thrown away.\n    # Server who sent the cookie with some attributes\n    # already knows them, no need to send this back again and again\n\n    async def handler(request):\n        assert request.cookies.keys() == {\"test3\"}\n        assert request.cookies[\"test3\"] == \"456\"\n        return web.Response()\n\n    c = http.cookies.Morsel()\n    c.set(\"test3\", \"456\", \"456\")\n    c[\"httponly\"] = True\n    c[\"secure\"] = True\n    c[\"max-age\"] = 1000\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app, cookies={\"test2\": c})\n\n    async with client.get(\"/\") as resp:\n        assert 200 == resp.status\n\n\nasync def test_set_cookies(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ret = web.Response()\n        ret.set_cookie(\"c1\", \"cookie1\")\n        ret.set_cookie(\"c2\", \"cookie2\")\n        ret.headers.add(\n            \"Set-Cookie\",\n            \"ISAWPLB{A7F52349-3531-4DA9-8776-F74BC6F4F1BB}=\"\n            \"{925EC0B8-CB17-4BEB-8A35-1033813B0523}; \"\n            \"HttpOnly; Path=/\",\n        )\n        return ret\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with mock.patch(\"aiohttp.client_reqrep.client_logger\") as m_log:\n        async with client.get(\"/\") as resp:\n            assert 200 == resp.status\n            cookie_names = {c.key for c in client.session.cookie_jar}\n        assert cookie_names == {\"c1\", \"c2\"}\n\n        m_log.warning.assert_called_with(\"Can not load response cookies: %s\", mock.ANY)\n\n\nasync def test_set_cookies_expired(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ret = web.Response()\n        ret.set_cookie(\"c1\", \"cookie1\")\n        ret.set_cookie(\"c2\", \"cookie2\")\n        ret.headers.add(\n            \"Set-Cookie\",\n            \"c3=cookie3; \" \"HttpOnly; Path=/\" \" Expires=Tue, 1 Jan 1980 12:00:00 GMT; \",\n        )\n        return ret\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\") as resp:\n        assert 200 == resp.status\n        cookie_names = {c.key for c in client.session.cookie_jar}\n    assert cookie_names == {\"c1\", \"c2\"}\n\n\nasync def test_set_cookies_max_age(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ret = web.Response()\n        ret.set_cookie(\"c1\", \"cookie1\")\n        ret.set_cookie(\"c2\", \"cookie2\")\n        ret.headers.add(\"Set-Cookie\", \"c3=cookie3; \" \"HttpOnly; Path=/\" \" Max-Age=1; \")\n        return ret\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\") as resp:\n        assert 200 == resp.status\n        cookie_names = {c.key for c in client.session.cookie_jar}\n        assert cookie_names == {\"c1\", \"c2\", \"c3\"}\n        await asyncio.sleep(2)\n        cookie_names = {c.key for c in client.session.cookie_jar}\n        assert cookie_names == {\"c1\", \"c2\"}\n\n\nasync def test_set_cookies_max_age_overflow(aiohttp_client: Any) -> None:\n    async def handler(request):\n        ret = web.Response()\n        ret.headers.add(\n            \"Set-Cookie\",\n            \"overflow=overflow; \" \"HttpOnly; Path=/\" \" Max-Age=\" + str(overflow) + \"; \",\n        )\n        return ret\n\n    overflow = int(\n        datetime.datetime.max.replace(tzinfo=datetime.timezone.utc).timestamp()\n    )\n    empty = None\n    try:\n        empty = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(\n            seconds=overflow\n        )\n    except OverflowError as ex:\n        assert isinstance(ex, OverflowError)\n    assert not isinstance(empty, datetime.datetime)\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\") as resp:\n        assert 200 == resp.status\n        for cookie in client.session.cookie_jar:\n            if cookie.key == \"overflow\":\n                assert int(cookie[\"max-age\"]) == int(overflow)\n\n\nasync def test_request_conn_error() -> None:\n    client = aiohttp.ClientSession()\n    with pytest.raises(aiohttp.ClientConnectionError):\n        await client.get(\"http://0.0.0.0:1\")\n    await client.close()\n\n\n@pytest.mark.xfail\nasync def test_broken_connection(aiohttp_client: Any) -> None:\n    async def handler(request):\n        request.transport.close()\n        return web.Response(text=\"answer\" * 1000)\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    with pytest.raises(aiohttp.ClientResponseError):\n        await client.get(\"/\")\n\n\nasync def test_broken_connection_2(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse(headers={\"content-length\": \"1000\"})\n        await resp.prepare(request)\n        await resp.write(b\"answer\")\n        request.transport.close()\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/\")\n    with pytest.raises(aiohttp.ClientPayloadError):\n        await resp.read()\n    resp.close()\n\n\nasync def test_custom_headers(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert request.headers[\"x-api-key\"] == \"foo\"\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n    client = await aiohttp_client(app)\n\n    async with client.post(\n        \"/\", headers={\"Content-Type\": \"application/json\", \"x-api-key\": \"foo\"}\n    ) as resp:\n        assert resp.status == 200\n\n\nasync def test_redirect_to_absolute_url(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(text=request.method)\n\n    async def redirect(request):\n        raise web.HTTPFound(location=client.make_url(\"/\"))\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    app.router.add_get(\"/redirect\", redirect)\n\n    client = await aiohttp_client(app)\n    async with client.get(\"/redirect\") as resp:\n        assert 200 == resp.status\n\n\nasync def test_redirect_without_location_header(aiohttp_client: Any) -> None:\n    body = b\"redirect\"\n\n    async def handler_redirect(request):\n        return web.Response(status=301, body=body)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/redirect\", handler_redirect)\n    client = await aiohttp_client(app)\n\n    resp = await client.get(\"/redirect\")\n    data = await resp.read()\n    assert data == body\n\n\nINVALID_URL_WITH_ERROR_MESSAGE_YARL_NEW = (\n    # yarl.URL.__new__ raises ValueError\n    (\"http://:/\", \"http://:/\"),\n    (\"http://example.org:non_int_port/\", \"http://example.org:non_int_port/\"),\n)\n\nINVALID_URL_WITH_ERROR_MESSAGE_YARL_ORIGIN = (\n    # # yarl.URL.origin raises ValueError\n    (\"http:/\", \"http:///\"),\n    (\"http:/example.com\", \"http:///example.com\"),\n    (\"http:///example.com\", \"http:///example.com\"),\n)\n\nNON_HTTP_URL_WITH_ERROR_MESSAGE = (\n    (\"call:+380123456789\", r\"call:\\+380123456789\"),\n    (\"skype:handle\", \"skype:handle\"),\n    (\"slack://instance/room\", \"slack://instance/room\"),\n    (\"steam:code\", \"steam:code\"),\n    (\"twitter://handle\", \"twitter://handle\"),\n    (\"bluesky://profile/d:i:d\", \"bluesky://profile/d:i:d\"),\n)\n\n\n@pytest.mark.parametrize(\n    (\"url\", \"error_message_url\", \"expected_exception_class\"),\n    (\n        *(\n            (url, message, InvalidUrlClientError)\n            for (url, message) in INVALID_URL_WITH_ERROR_MESSAGE_YARL_NEW\n        ),\n        *(\n            (url, message, InvalidUrlClientError)\n            for (url, message) in INVALID_URL_WITH_ERROR_MESSAGE_YARL_ORIGIN\n        ),\n        *(\n            (url, message, NonHttpUrlClientError)\n            for (url, message) in NON_HTTP_URL_WITH_ERROR_MESSAGE\n        ),\n    ),\n)\nasync def test_invalid_and_non_http_url(\n    url: Any, error_message_url: Any, expected_exception_class: Any\n) -> None:\n    async with aiohttp.ClientSession() as http_session:\n        with pytest.raises(\n            expected_exception_class, match=rf\"^{error_message_url}( - [A-Za-z ]+)?\"\n        ):\n            await http_session.get(url)\n\n\n@pytest.mark.parametrize(\n    (\"invalid_redirect_url\", \"error_message_url\", \"expected_exception_class\"),\n    (\n        *(\n            (url, message, InvalidUrlRedirectClientError)\n            for (url, message) in INVALID_URL_WITH_ERROR_MESSAGE_YARL_ORIGIN\n            + INVALID_URL_WITH_ERROR_MESSAGE_YARL_NEW\n        ),\n        *(\n            (url, message, NonHttpUrlRedirectClientError)\n            for (url, message) in NON_HTTP_URL_WITH_ERROR_MESSAGE\n        ),\n    ),\n)\nasync def test_invalid_redirect_url(\n    aiohttp_client: Any,\n    invalid_redirect_url: Any,\n    error_message_url: str,\n    expected_exception_class: Any,\n) -> None:\n    headers = {hdrs.LOCATION: invalid_redirect_url}\n\n    async def generate_redirecting_response(request):\n        return web.Response(status=301, headers=headers)\n\n    app = web.Application()\n    app.router.add_get(\"/redirect\", generate_redirecting_response)\n    client = await aiohttp_client(app)\n\n    with pytest.raises(\n        expected_exception_class, match=rf\"^{error_message_url}( - [A-Za-z ]+)?\"\n    ):\n        await client.get(\"/redirect\")\n\n\n@pytest.mark.parametrize(\n    (\"invalid_redirect_url\", \"error_message_url\", \"expected_exception_class\"),\n    (\n        *(\n            (url, message, InvalidUrlRedirectClientError)\n            for (url, message) in INVALID_URL_WITH_ERROR_MESSAGE_YARL_ORIGIN\n            + INVALID_URL_WITH_ERROR_MESSAGE_YARL_NEW\n        ),\n        *(\n            (url, message, NonHttpUrlRedirectClientError)\n            for (url, message) in NON_HTTP_URL_WITH_ERROR_MESSAGE\n        ),\n    ),\n)\nasync def test_invalid_redirect_url_multiple_redirects(\n    aiohttp_client: Any,\n    invalid_redirect_url: Any,\n    error_message_url: str,\n    expected_exception_class: Any,\n) -> None:\n    app = web.Application()\n\n    for path, location in [\n        (\"/redirect\", \"/redirect1\"),\n        (\"/redirect1\", \"/redirect2\"),\n        (\"/redirect2\", invalid_redirect_url),\n    ]:\n\n        async def generate_redirecting_response(request):\n            return web.Response(status=301, headers={hdrs.LOCATION: location})\n\n        app.router.add_get(path, generate_redirecting_response)\n\n    client = await aiohttp_client(app)\n\n    with pytest.raises(\n        expected_exception_class, match=rf\"^{error_message_url}( - [A-Za-z ]+)?\"\n    ):\n        await client.get(\"/redirect\")\n\n\n@pytest.mark.parametrize(\n    (\"status\", \"expected_ok\"),\n    (\n        (200, True),\n        (201, True),\n        (301, True),\n        (400, False),\n        (403, False),\n        (500, False),\n    ),\n)\nasync def test_ok_from_status(\n    aiohttp_client: Any, status: Any, expected_ok: Any\n) -> None:\n    async def handler(request):\n        return web.Response(status=status, body=b\"\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/endpoint\", handler)\n    client = await aiohttp_client(app, raise_for_status=False)\n    async with client.get(\"/endpoint\") as resp:\n        assert resp.ok is expected_ok\n\n\nasync def test_raise_for_status(aiohttp_client: Any) -> None:\n    async def handler(request):\n        raise web.HTTPBadRequest()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app, raise_for_status=True)\n\n    with pytest.raises(aiohttp.ClientResponseError):\n        await client.get(\"/\")\n\n\nasync def test_raise_for_status_per_request(aiohttp_client: Any) -> None:\n    async def handler(request):\n        raise web.HTTPBadRequest()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app)\n\n    with pytest.raises(aiohttp.ClientResponseError):\n        await client.get(\"/\", raise_for_status=True)\n\n\nasync def test_raise_for_status_disable_per_request(aiohttp_client: Any) -> None:\n    async def handler(request):\n        raise web.HTTPBadRequest()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n    client = await aiohttp_client(app, raise_for_status=True)\n\n    async with client.get(\"/\", raise_for_status=False) as resp:\n        assert 400 == resp.status\n\n\nasync def test_request_raise_for_status_default(aiohttp_server: Any) -> None:\n    async def handler(request):\n        raise web.HTTPBadRequest()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app)\n\n    async with aiohttp.request(\"GET\", server.make_url(\"/\")) as resp:\n        assert resp.status == 400\n\n\nasync def test_request_raise_for_status_disabled(aiohttp_server: Any) -> None:\n    async def handler(request):\n        raise web.HTTPBadRequest()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app)\n    url = server.make_url(\"/\")\n\n    async with aiohttp.request(\"GET\", url, raise_for_status=False) as resp:\n        assert resp.status == 400\n\n\nasync def test_request_raise_for_status_enabled(aiohttp_server: Any) -> None:\n    async def handler(request):\n        raise web.HTTPBadRequest()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app)\n    url = server.make_url(\"/\")\n\n    with pytest.raises(aiohttp.ClientResponseError):\n        async with aiohttp.request(\"GET\", url, raise_for_status=True):\n            assert False, \"never executed\"  # pragma: no cover\n\n\nasync def test_session_raise_for_status_coro(aiohttp_client: Any) -> None:\n    async def handle(request):\n        return web.Response(text=\"ok\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handle)\n\n    raise_for_status_called = 0\n\n    async def custom_r4s(response):\n        nonlocal raise_for_status_called\n        raise_for_status_called += 1\n        assert response.status == 200\n        assert response.request_info.method == \"GET\"\n\n    client = await aiohttp_client(app, raise_for_status=custom_r4s)\n    await client.get(\"/\")\n    assert raise_for_status_called == 1\n    await client.get(\"/\", raise_for_status=True)\n    assert raise_for_status_called == 1  # custom_r4s not called again\n    await client.get(\"/\", raise_for_status=False)\n    assert raise_for_status_called == 1  # custom_r4s not called again\n\n\nasync def test_request_raise_for_status_coro(aiohttp_client: Any) -> None:\n    async def handle(request):\n        return web.Response(text=\"ok\")\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handle)\n\n    raise_for_status_called = 0\n\n    async def custom_r4s(response):\n        nonlocal raise_for_status_called\n        raise_for_status_called += 1\n        assert response.status == 200\n        assert response.request_info.method == \"GET\"\n\n    client = await aiohttp_client(app)\n    await client.get(\"/\", raise_for_status=custom_r4s)\n    assert raise_for_status_called == 1\n    await client.get(\"/\", raise_for_status=True)\n    assert raise_for_status_called == 1  # custom_r4s not called again\n    await client.get(\"/\", raise_for_status=False)\n    assert raise_for_status_called == 1  # custom_r4s not called again\n\n\nasync def test_invalid_idna() -> None:\n    session = aiohttp.ClientSession()\n    try:\n        with pytest.raises(aiohttp.InvalidURL):\n            await session.get(\"http://\\u2061owhefopw.com\")\n    finally:\n        await session.close()\n\n\nasync def test_creds_in_auth_and_url() -> None:\n    session = aiohttp.ClientSession()\n    try:\n        with pytest.raises(ValueError):\n            await session.get(\n                \"http://user:pass@example.com\", auth=aiohttp.BasicAuth(\"user2\", \"pass2\")\n            )\n    finally:\n        await session.close()\n\n\n@pytest.fixture\ndef create_server_for_url_and_handler(\n    aiohttp_server: Any, tls_certificate_authority: Any\n):\n    def create(url: URL, srv: Any):\n        app = web.Application()\n        app.router.add_route(\"GET\", url.path, srv)\n\n        kwargs = {}\n        if url.scheme == \"https\":\n            cert = tls_certificate_authority.issue_cert(\n                url.host, \"localhost\", \"127.0.0.1\"\n            )\n            ssl_ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n            cert.configure_cert(ssl_ctx)\n            kwargs[\"ssl\"] = ssl_ctx\n        return aiohttp_server(app, **kwargs)\n\n    return create\n\n\n@pytest.mark.parametrize(\n    [\"url_from\", \"url_to\", \"is_drop_header_expected\"],\n    [\n        [\n            \"http://host1.com/path1\",\n            \"http://host2.com/path2\",\n            True,\n        ],\n        [\"http://host1.com/path1\", \"https://host1.com/path1\", False],\n        [\"https://host1.com/path1\", \"http://host1.com/path2\", True],\n    ],\n    ids=(\n        \"entirely different hosts\",\n        \"http -> https\",\n        \"https -> http\",\n    ),\n)\nasync def test_drop_auth_on_redirect_to_other_host(\n    create_server_for_url_and_handler: Any,\n    url_from: str,\n    url_to: str,\n    is_drop_header_expected: bool,\n) -> None:\n    url_from, url_to = URL(url_from), URL(url_to)\n\n    async def srv_from(request):\n        assert request.host == url_from.host\n        assert request.headers[\"Authorization\"] == \"Basic dXNlcjpwYXNz\"\n        raise web.HTTPFound(url_to)\n\n    async def srv_to(request):\n        assert request.host == url_to.host\n        if is_drop_header_expected:\n            assert \"Authorization\" not in request.headers, \"Header wasn't dropped\"\n        else:\n            assert \"Authorization\" in request.headers, \"Header was dropped\"\n        return web.Response()\n\n    server_from = await create_server_for_url_and_handler(url_from, srv_from)\n    server_to = await create_server_for_url_and_handler(url_to, srv_to)\n\n    assert (\n        url_from.host != url_to.host or server_from.scheme != server_to.scheme\n    ), \"Invalid test case, host or scheme must differ\"\n\n    protocol_port_map = {\n        \"http\": 80,\n        \"https\": 443,\n    }\n    etc_hosts = {\n        (url_from.host, protocol_port_map[server_from.scheme]): server_from,\n        (url_to.host, protocol_port_map[server_to.scheme]): server_to,\n    }\n\n    class FakeResolver(AbstractResolver):\n        async def resolve(self, host, port=0, family=socket.AF_INET):\n            server = etc_hosts[(host, port)]\n\n            return [\n                {\n                    \"hostname\": host,\n                    \"host\": server.host,\n                    \"port\": server.port,\n                    \"family\": socket.AF_INET,\n                    \"proto\": 0,\n                    \"flags\": socket.AI_NUMERICHOST,\n                }\n            ]\n\n        async def close(self):\n            pass\n\n    connector = aiohttp.TCPConnector(resolver=FakeResolver(), ssl=False)\n\n    async with aiohttp.ClientSession(connector=connector) as client:\n        resp = await client.get(\n            url_from,\n            auth=aiohttp.BasicAuth(\"user\", \"pass\"),\n        )\n        assert resp.status == 200\n        resp = await client.get(\n            url_from,\n            headers={\"Authorization\": \"Basic dXNlcjpwYXNz\"},\n        )\n        assert resp.status == 200\n\n\nasync def test_async_with_session() -> None:\n    async with aiohttp.ClientSession() as session:\n        pass\n\n    assert session.closed\n\n\nasync def test_session_close_awaitable() -> None:\n    session = aiohttp.ClientSession()\n    await session.close()\n\n    assert session.closed\n\n\nasync def test_close_resp_on_error_async_with_session(aiohttp_server: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse(headers={\"content-length\": \"100\"})\n        await resp.prepare(request)\n        await asyncio.sleep(0.1)\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app)\n\n    async with aiohttp.ClientSession() as session:\n        with pytest.raises(RuntimeError):\n            async with session.get(server.make_url(\"/\")) as resp:\n                resp.content.set_exception(RuntimeError())\n                await resp.read()\n\n        assert len(session._connector._conns) == 0\n\n\nasync def test_release_resp_on_normal_exit_from_cm(aiohttp_server: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app)\n\n    async with aiohttp.ClientSession() as session:\n        async with session.get(server.make_url(\"/\")) as resp:\n            await resp.read()\n\n        assert len(session._connector._conns) == 1\n\n\nasync def test_non_close_detached_session_on_error_cm(aiohttp_server: Any) -> None:\n    async def handler(request):\n        resp = web.StreamResponse(headers={\"content-length\": \"100\"})\n        await resp.prepare(request)\n        await asyncio.sleep(0.1)\n        return resp\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app)\n\n    session = aiohttp.ClientSession()\n    cm = session.get(server.make_url(\"/\"))\n    assert not session.closed\n    with pytest.raises(RuntimeError):\n        async with cm as resp:\n            resp.content.set_exception(RuntimeError())\n            await resp.read()\n    assert not session.closed\n\n\nasync def test_close_detached_session_on_non_existing_addr() -> None:\n    class FakeResolver(AbstractResolver):\n        async def resolve(host, port=0, family=socket.AF_INET):\n            return {}\n\n        async def close(self):\n            pass\n\n    connector = aiohttp.TCPConnector(resolver=FakeResolver())\n\n    session = aiohttp.ClientSession(connector=connector)\n\n    async with session:\n        cm = session.get(\"http://non-existing.example.com\")\n        assert not session.closed\n        with pytest.raises(Exception):\n            await cm\n\n    assert session.closed\n\n\nasync def test_aiohttp_request_context_manager(aiohttp_server: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app)\n\n    async with aiohttp.request(\"GET\", server.make_url(\"/\")) as resp:\n        await resp.read()\n        assert resp.status == 200\n\n\nasync def test_aiohttp_request_ctx_manager_close_sess_on_error(\n    ssl_ctx: Any, aiohttp_server: Any\n) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app, ssl=ssl_ctx)\n\n    cm = aiohttp.request(\"GET\", server.make_url(\"/\"))\n\n    with pytest.raises(aiohttp.ClientConnectionError):\n        async with cm:\n            pass\n\n    assert cm._session.closed\n\n\nasync def test_aiohttp_request_ctx_manager_not_found() -> None:\n    with pytest.raises(aiohttp.ClientConnectionError):\n        async with aiohttp.request(\"GET\", \"http://wrong-dns-name.com\"):\n            assert False, \"never executed\"  # pragma: no cover\n\n\nasync def test_aiohttp_request_coroutine(aiohttp_server: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    server = await aiohttp_server(app)\n\n    not_an_awaitable = aiohttp.request(\"GET\", server.make_url(\"/\"))\n    with pytest.raises(\n        TypeError,\n        match=\"^object _SessionRequestContextManager \"\n        \"can't be used in 'await' expression$\",\n    ):\n        await not_an_awaitable\n\n    await not_an_awaitable._coro  # coroutine 'ClientSession._request' was never awaited\n    await server.close()\n\n\nasync def test_yield_from_in_session_request(aiohttp_client: Any) -> None:\n    # a test for backward compatibility with yield from syntax\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app)\n    async with client.get(\"/\") as resp:\n        assert resp.status == 200\n\n\nasync def test_close_context_manager(aiohttp_client: Any) -> None:\n    # a test for backward compatibility with yield from syntax\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app)\n    ctx = client.get(\"/\")\n    ctx.close()\n    assert not ctx._coro.cr_running\n\n\nasync def test_session_auth(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.json_response({\"headers\": dict(request.headers)})\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app, auth=aiohttp.BasicAuth(\"login\", \"pass\"))\n\n    r = await client.get(\"/\")\n    assert r.status == 200\n    content = await r.json()\n    assert content[\"headers\"][\"Authorization\"] == \"Basic bG9naW46cGFzcw==\"\n\n\nasync def test_session_auth_override(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.json_response({\"headers\": dict(request.headers)})\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app, auth=aiohttp.BasicAuth(\"login\", \"pass\"))\n\n    r = await client.get(\"/\", auth=aiohttp.BasicAuth(\"other_login\", \"pass\"))\n    assert r.status == 200\n    content = await r.json()\n    val = content[\"headers\"][\"Authorization\"]\n    assert val == \"Basic b3RoZXJfbG9naW46cGFzcw==\"\n\n\nasync def test_session_auth_header_conflict(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app, auth=aiohttp.BasicAuth(\"login\", \"pass\"))\n    headers = {\"Authorization\": \"Basic b3RoZXJfbG9naW46cGFzcw==\"}\n    with pytest.raises(ValueError):\n        await client.get(\"/\", headers=headers)\n\n\nasync def test_session_headers(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.json_response({\"headers\": dict(request.headers)})\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app, headers={\"X-Real-IP\": \"192.168.0.1\"})\n\n    r = await client.get(\"/\")\n    assert r.status == 200\n    content = await r.json()\n    assert content[\"headers\"][\"X-Real-IP\"] == \"192.168.0.1\"\n\n\nasync def test_session_headers_merge(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.json_response({\"headers\": dict(request.headers)})\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(\n        app, headers=[(\"X-Real-IP\", \"192.168.0.1\"), (\"X-Sent-By\", \"requests\")]\n    )\n\n    r = await client.get(\"/\", headers={\"X-Sent-By\": \"aiohttp\"})\n    assert r.status == 200\n    content = await r.json()\n    assert content[\"headers\"][\"X-Real-IP\"] == \"192.168.0.1\"\n    assert content[\"headers\"][\"X-Sent-By\"] == \"aiohttp\"\n\n\nasync def test_multidict_headers(aiohttp_client: Any) -> None:\n    async def handler(request):\n        assert await request.read() == data\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_post(\"/\", handler)\n\n    client = await aiohttp_client(app)\n\n    data = b\"sample data\"\n\n    async with client.post(\n        \"/\", data=data, headers=MultiDict({\"Content-Length\": str(len(data))})\n    ) as r:\n        assert r.status == 200\n\n\nasync def test_request_conn_closed(aiohttp_client: Any) -> None:\n    async def handler(request):\n        request.transport.close()\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app)\n    with pytest.raises(aiohttp.ServerDisconnectedError) as excinfo:\n        resp = await client.get(\"/\")\n        await resp.read()\n\n    assert str(excinfo.value) != \"\"\n\n\nasync def test_dont_close_explicit_connector(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n\n    client = await aiohttp_client(app)\n    r = await client.get(\"/\")\n    await r.read()\n\n    assert 1 == len(client.session.connector._conns)\n\n\nasync def test_server_close_keepalive_connection() -> None:\n    loop = asyncio.get_event_loop()\n\n    class Proto(asyncio.Protocol):\n        def connection_made(self, transport):\n            self.transp = transport\n            self.data = b\"\"\n\n        def data_received(self, data):\n            self.data += data\n            if data.endswith(b\"\\r\\n\\r\\n\"):\n                self.transp.write(\n                    b\"HTTP/1.1 200 OK\\r\\n\"\n                    b\"CONTENT-LENGTH: 2\\r\\n\"\n                    b\"CONNECTION: close\\r\\n\"\n                    b\"\\r\\n\"\n                    b\"ok\"\n                )\n                self.transp.close()\n\n        def connection_lost(self, exc):\n            self.transp = None\n\n    server = await loop.create_server(Proto, \"127.0.0.1\", unused_port())\n\n    addr = server.sockets[0].getsockname()\n\n    connector = aiohttp.TCPConnector(limit=1)\n    session = aiohttp.ClientSession(connector=connector)\n\n    url = \"http://{}:{}/\".format(*addr)\n    for i in range(2):\n        r = await session.request(\"GET\", url)\n        await r.read()\n        assert 0 == len(connector._conns)\n    await session.close()\n    await connector.close()\n    server.close()\n    await server.wait_closed()\n\n\nasync def test_handle_keepalive_on_closed_connection() -> None:\n    loop = asyncio.get_event_loop()\n\n    class Proto(asyncio.Protocol):\n        def connection_made(self, transport):\n            self.transp = transport\n            self.data = b\"\"\n\n        def data_received(self, data):\n            self.data += data\n            if data.endswith(b\"\\r\\n\\r\\n\"):\n                self.transp.write(\n                    b\"HTTP/1.1 200 OK\\r\\n\" b\"CONTENT-LENGTH: 2\\r\\n\" b\"\\r\\n\" b\"ok\"\n                )\n                self.transp.close()\n\n        def connection_lost(self, exc):\n            self.transp = None\n\n    server = await loop.create_server(Proto, \"127.0.0.1\", unused_port())\n\n    addr = server.sockets[0].getsockname()\n\n    async with aiohttp.TCPConnector(limit=1) as connector:\n        async with aiohttp.ClientSession(connector=connector) as session:\n            url = \"http://{}:{}/\".format(*addr)\n\n            r = await session.request(\"GET\", url)\n            await r.read()\n            assert 1 == len(connector._conns)\n            closed_conn = next(iter(connector._conns.values()))\n\n            await session.request(\"GET\", url)\n            assert 1 == len(connector._conns)\n            new_conn = next(iter(connector._conns.values()))\n            assert closed_conn is not new_conn\n\n    server.close()\n    await server.wait_closed()\n\n\nasync def test_error_in_performing_request(\n    ssl_ctx: Any, aiohttp_client: Any, aiohttp_server: Any\n):\n    async def handler(request):\n        return web.Response()\n\n    def exception_handler(loop, context):\n        # skip log messages about destroyed but pending tasks\n        pass\n\n    loop = asyncio.get_event_loop()\n    loop.set_exception_handler(exception_handler)\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    server = await aiohttp_server(app, ssl=ssl_ctx)\n\n    conn = aiohttp.TCPConnector(limit=1)\n    client = await aiohttp_client(server, connector=conn)\n\n    with pytest.raises(aiohttp.ClientConnectionError):\n        await client.get(\"/\")\n\n    # second try should not hang\n    with pytest.raises(aiohttp.ClientConnectionError):\n        await client.get(\"/\")\n\n\nasync def test_await_after_cancelling(aiohttp_client: Any) -> None:\n    loop = asyncio.get_event_loop()\n\n    async def handler(request):\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_route(\"GET\", \"/\", handler)\n\n    client = await aiohttp_client(app)\n\n    fut1 = loop.create_future()\n    fut2 = loop.create_future()\n\n    async def fetch1():\n        resp = await client.get(\"/\")\n        assert resp.status == 200\n        fut1.set_result(None)\n        with pytest.raises(asyncio.CancelledError):\n            await fut2\n        resp.release()\n\n    async def fetch2():\n        await fut1\n        resp = await client.get(\"/\")\n        assert resp.status == 200\n\n    async def canceller():\n        await fut1\n        fut2.cancel()\n\n    await asyncio.gather(fetch1(), fetch2(), canceller())\n\n\nasync def test_async_payload_generator(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.read()\n        assert data == b\"1234567890\" * 100\n        return web.Response()\n\n    app = web.Application()\n    app.add_routes([web.post(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async def gen():\n        for i in range(100):\n            yield b\"1234567890\"\n\n    async with client.post(\"/\", data=gen()) as resp:\n        assert resp.status == 200\n\n\nasync def test_read_from_closed_response(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"data\")\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\") as resp:\n        assert resp.status == 200\n\n    with pytest.raises(aiohttp.ClientConnectionError):\n        await resp.read()\n\n\nasync def test_read_from_closed_response2(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"data\")\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\") as resp:\n        assert resp.status == 200\n        await resp.read()\n\n    with pytest.raises(aiohttp.ClientConnectionError):\n        await resp.read()\n\n\nasync def test_read_from_closed_content(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"data\")\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async with client.get(\"/\") as resp:\n        assert resp.status == 200\n\n    with pytest.raises(aiohttp.ClientConnectionError):\n        await resp.content.readline()\n\n\nasync def test_read_timeout(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await asyncio.sleep(5)\n        return web.Response()\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    timeout = aiohttp.ClientTimeout(sock_read=0.1)\n    client = await aiohttp_client(app, timeout=timeout)\n\n    with pytest.raises(aiohttp.ServerTimeoutError):\n        await client.get(\"/\")\n\n\nasync def test_socket_timeout(aiohttp_client: Any) -> None:\n    async def handler(request):\n        await asyncio.sleep(5)\n        return web.Response()\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    timeout = aiohttp.ClientTimeout(sock_read=0.1)\n    client = await aiohttp_client(app, timeout=timeout)\n\n    with pytest.raises(SocketTimeoutError):\n        await client.get(\"/\")\n\n\nasync def test_read_timeout_closes_connection(aiohttp_client: AiohttpClient) -> None:\n    request_count = 0\n\n    async def handler(request):\n        nonlocal request_count\n        request_count += 1\n        if request_count < 3:\n            await asyncio.sleep(0.5)\n        return web.Response(body=f\"request:{request_count}\")\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    timeout = aiohttp.ClientTimeout(total=0.1)\n    client: TestClient = await aiohttp_client(app, timeout=timeout)\n    with pytest.raises(asyncio.TimeoutError):\n        await client.get(\"/\")\n\n    # Make sure its really closed\n    assert not client.session.connector._conns\n\n    with pytest.raises(asyncio.TimeoutError):\n        await client.get(\"/\")\n\n    # Make sure its really closed\n    assert not client.session.connector._conns\n    result = await client.get(\"/\")\n    assert await result.read() == b\"request:3\"\n\n    # Make sure its not closed\n    assert client.session.connector._conns\n\n\nasync def test_read_timeout_on_prepared_response(aiohttp_client: Any) -> None:\n    async def handler(request):\n        resp = aiohttp.web.StreamResponse()\n        await resp.prepare(request)\n        await asyncio.sleep(5)\n        await resp.drain()\n        return resp\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    timeout = aiohttp.ClientTimeout(sock_read=0.1)\n    client = await aiohttp_client(app, timeout=timeout)\n\n    with pytest.raises(aiohttp.ServerTimeoutError):\n        async with await client.get(\"/\") as resp:\n            await resp.read()\n\n\nasync def test_timeout_with_full_buffer(aiohttp_client: Any) -> None:\n    async def handler(request):\n        \"\"\"Server response that never ends and always has more data available.\"\"\"\n        resp = web.StreamResponse()\n        await resp.prepare(request)\n        while True:\n            await resp.write(b\"1\" * 1000)\n            await asyncio.sleep(0.01)\n\n    async def request(client):\n        timeout = aiohttp.ClientTimeout(total=0.5)\n        async with await client.get(\"/\", timeout=timeout) as resp:\n            with pytest.raises(asyncio.TimeoutError):\n                async for data in resp.content.iter_chunked(1):\n                    await asyncio.sleep(0.01)\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n    # wait_for() used just to ensure that a failing test doesn't hang.\n    await asyncio.wait_for(request(client), 1)\n\n\nasync def test_read_bufsize_session_default(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"1234567\")\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app, read_bufsize=2)\n\n    async with await client.get(\"/\") as resp:\n        assert resp.content.get_read_buffer_limits() == (2, 4)\n\n\nasync def test_read_bufsize_explicit(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(body=b\"1234567\")\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async with await client.get(\"/\", read_bufsize=4) as resp:\n        assert resp.content.get_read_buffer_limits() == (4, 8)\n\n\nasync def test_http_empty_data_text(aiohttp_client: Any) -> None:\n    async def handler(request):\n        data = await request.read()\n        ret = \"ok\" if data == b\"\" else \"fail\"\n        resp = web.Response(text=ret)\n        resp.headers[\"Content-Type\"] = request.headers[\"Content-Type\"]\n        return resp\n\n    app = web.Application()\n    app.add_routes([web.post(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async with await client.post(\"/\", data=\"\") as resp:\n        assert resp.status == 200\n        assert await resp.text() == \"ok\"\n        assert resp.headers[\"Content-Type\"] == \"text/plain; charset=utf-8\"\n\n\nasync def test_max_field_size_session_default(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(headers={\"Custom\": \"x\" * 8190})\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async with await client.get(\"/\") as resp:\n        assert resp.headers[\"Custom\"] == \"x\" * 8190\n\n\nasync def test_max_field_size_session_default_fail(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(headers={\"Custom\": \"x\" * 8191})\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n    with pytest.raises(aiohttp.ClientResponseError):\n        await client.get(\"/\")\n\n\nasync def test_max_field_size_session_explicit(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(headers={\"Custom\": \"x\" * 8191})\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app, max_field_size=8191)\n\n    async with await client.get(\"/\") as resp:\n        assert resp.headers[\"Custom\"] == \"x\" * 8191\n\n\nasync def test_max_field_size_request_explicit(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(headers={\"Custom\": \"x\" * 8191})\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async with await client.get(\"/\", max_field_size=8191) as resp:\n        assert resp.headers[\"Custom\"] == \"x\" * 8191\n\n\nasync def test_max_line_size_session_default(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(status=200, reason=\"x\" * 8190)\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async with await client.get(\"/\") as resp:\n        assert resp.reason == \"x\" * 8190\n\n\nasync def test_max_line_size_session_default_fail(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(status=200, reason=\"x\" * 8192)\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n    with pytest.raises(aiohttp.ClientResponseError):\n        await client.get(\"/\")\n\n\nasync def test_max_line_size_session_explicit(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(status=200, reason=\"x\" * 8191)\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app, max_line_size=8191)\n\n    async with await client.get(\"/\") as resp:\n        assert resp.reason == \"x\" * 8191\n\n\nasync def test_max_line_size_request_explicit(aiohttp_client: Any) -> None:\n    async def handler(request):\n        return web.Response(status=200, reason=\"x\" * 8191)\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n\n    client = await aiohttp_client(app)\n\n    async with await client.get(\"/\", max_line_size=8191) as resp:\n        assert resp.reason == \"x\" * 8191\n\n\n@pytest.mark.xfail(raises=asyncio.TimeoutError, reason=\"#7599\")\nasync def test_rejected_upload(aiohttp_client: Any, tmp_path: Any) -> None:\n    async def ok_handler(request):\n        return web.Response()\n\n    async def not_ok_handler(request):\n        raise web.HTTPBadRequest()\n\n    app = web.Application()\n    app.router.add_get(\"/ok\", ok_handler)\n    app.router.add_post(\"/not_ok\", not_ok_handler)\n    client = await aiohttp_client(app)\n\n    file_size_bytes = 1024 * 1024\n    file_path = tmp_path / \"uploaded.txt\"\n    file_path.write_text(\"0\" * file_size_bytes, encoding=\"utf8\")\n\n    with open(file_path, \"rb\") as file:\n        data = {\"file\": file}\n        async with await client.post(\"/not_ok\", data=data) as resp_not_ok:\n            assert 400 == resp_not_ok.status\n\n    async with await client.get(\n        \"/ok\", timeout=aiohttp.ClientTimeout(total=0.01)\n    ) as resp_ok:\n        assert 200 == resp_ok.status\n\n\nasync def test_request_with_wrong_ssl_type(aiohttp_client: AiohttpClient) -> None:\n    app = web.Application()\n    session = await aiohttp_client(app)\n\n    with pytest.raises(TypeError, match=\"ssl should be SSLContext, Fingerprint, .*\"):\n        await session.get(\"/\", ssl=42)  # type: ignore[arg-type]\n\n\n@pytest.mark.parametrize(\n    (\"value\", \"exc_type\"),\n    [(42, TypeError), (\"InvalidUrl\", InvalidURL)],\n)\nasync def test_request_with_wrong_proxy(\n    aiohttp_client: AiohttpClient, value: Any, exc_type: Type[Exception]\n) -> None:\n    app = web.Application()\n    session = await aiohttp_client(app)\n\n    with pytest.raises(exc_type):\n        await session.get(\"/\", proxy=value)  # type: ignore[arg-type]\n\n\nasync def test_raise_for_status_is_none(aiohttp_client: AiohttpClient) -> None:\n    async def handler(_: web.Request) -> web.Response:\n        return web.Response()\n\n    app = web.Application()\n    app.router.add_get(\"/\", handler)\n    session = await aiohttp_client(app, raise_for_status=None)  # type: ignore[arg-type]\n\n    await session.get(\"/\")\n\n\n@pytest.mark.xfail(\n    reason=\"#8395 Error message regression for large headers in 3.9.4\",\n    raises=AssertionError,\n)\nasync def test_header_too_large_error(aiohttp_client: Any) -> None:\n    \"\"\"By default when not specifying `max_field_size` requests should fail with a 400 status code.\"\"\"\n\n    async def handler(_: web.Request) -> web.Response:\n        return web.Response(headers={\"VeryLargeHeader\": \"x\" * 10000})\n\n    app = web.Application()\n    app.add_routes([web.get(\"/\", handler)])\n    client = await aiohttp_client(app)\n\n    with pytest.raises(\n        aiohttp.ClientResponseError, match=\"Got more than 8190 bytes*\"\n    ) as exc_info:\n        await client.get(\"/\")\n    assert exc_info.value.status == 400\n", "tests/test_web_exceptions.py": "import collections\nimport pickle\nfrom traceback import format_exception\nfrom typing import Mapping, NoReturn\n\nimport pytest\nfrom yarl import URL\n\nfrom aiohttp import web\nfrom aiohttp.pytest_plugin import AiohttpClient\n\n\ndef test_all_http_exceptions_exported() -> None:\n    assert \"HTTPException\" in web.__all__\n    for name in dir(web):\n        if name.startswith(\"_\"):\n            continue\n        obj = getattr(web, name)\n        if isinstance(obj, type) and issubclass(obj, web.HTTPException):\n            assert name in web.__all__\n\n\nasync def test_ctor() -> None:\n    resp = web.HTTPOk()\n    assert resp.text == \"200: OK\"\n    compare: Mapping[str, str] = {\"Content-Type\": \"text/plain\"}\n    assert resp.headers == compare\n    assert resp.reason == \"OK\"\n    assert resp.status == 200\n    assert bool(resp)\n\n\nasync def test_ctor_with_headers() -> None:\n    resp = web.HTTPOk(headers={\"X-Custom\": \"value\"})\n    assert resp.text == \"200: OK\"\n    compare: Mapping[str, str] = {\"Content-Type\": \"text/plain\", \"X-Custom\": \"value\"}\n    assert resp.headers == compare\n    assert resp.reason == \"OK\"\n    assert resp.status == 200\n\n\nasync def test_ctor_content_type() -> None:\n    resp = web.HTTPOk(text=\"text\", content_type=\"custom\")\n    assert resp.text == \"text\"\n    compare: Mapping[str, str] = {\"Content-Type\": \"custom\"}\n    assert resp.headers == compare\n    assert resp.reason == \"OK\"\n    assert resp.status == 200\n    assert bool(resp)\n\n\nasync def test_ctor_content_type_without_text() -> None:\n    with pytest.deprecated_call(\n        match=r\"^content_type without text is deprecated since \"\n        r\"4\\.0 and scheduled for removal in 5\\.0 \\(#3462\\)$\",\n    ):\n        resp = web.HTTPResetContent(content_type=\"custom\")\n    assert resp.text is None\n    compare: Mapping[str, str] = {\"Content-Type\": \"custom\"}\n    assert resp.headers == compare\n    assert resp.reason == \"Reset Content\"\n    assert resp.status == 205\n    assert bool(resp)\n\n\nasync def test_ctor_text_for_empty_body() -> None:\n    with pytest.deprecated_call(\n        match=r\"^text argument is deprecated for HTTP status 205 since \"\n        r\"4\\.0 and scheduled for removal in 5\\.0 \\(#3462\\),the \"\n        r\"response should be provided without a body$\",\n    ):\n        resp = web.HTTPResetContent(text=\"text\")\n    assert resp.text == \"text\"\n    compare: Mapping[str, str] = {\"Content-Type\": \"text/plain\"}\n    assert resp.headers == compare\n    assert resp.reason == \"Reset Content\"\n    assert resp.status == 205\n\n\ndef test_terminal_classes_has_status_code() -> None:\n    terminals = set()\n    for name in dir(web):\n        obj = getattr(web, name)\n        if isinstance(obj, type) and issubclass(obj, web.HTTPException):\n            terminals.add(obj)\n\n    dup = frozenset(terminals)\n    for cls1 in dup:\n        for cls2 in dup:\n            if cls1 in cls2.__bases__:\n                terminals.discard(cls1)\n\n    for cls in terminals:\n        assert cls.status_code is not None\n    codes = collections.Counter(cls.status_code for cls in terminals)\n    assert None not in codes\n    assert 1 == codes.most_common(1)[0][1]\n\n\ndef test_with_text() -> None:\n    resp = web.HTTPNotFound(text=\"Page not found\")\n    assert 404 == resp.status\n    assert \"Page not found\" == resp.text\n    assert \"text/plain\" == resp.headers[\"Content-Type\"]\n\n\ndef test_default_text() -> None:\n    resp = web.HTTPOk()\n    assert \"200: OK\" == resp.text\n\n\ndef test_empty_text_204() -> None:\n    resp = web.HTTPNoContent()\n    assert resp.text is None\n\n\ndef test_empty_text_205() -> None:\n    resp = web.HTTPResetContent()\n    assert resp.text is None\n\n\ndef test_empty_text_304() -> None:\n    resp = web.HTTPNoContent()\n    resp.text is None\n\n\ndef test_no_link_451() -> None:\n    with pytest.raises(TypeError):\n        web.HTTPUnavailableForLegalReasons()  # type: ignore[call-arg]\n\n\ndef test_link_none_451() -> None:\n    resp = web.HTTPUnavailableForLegalReasons(link=None)\n    assert resp.link is None\n    assert \"Link\" not in resp.headers\n\n\ndef test_link_empty_451() -> None:\n    resp = web.HTTPUnavailableForLegalReasons(link=\"\")\n    assert resp.link is None\n    assert \"Link\" not in resp.headers\n\n\ndef test_link_str_451() -> None:\n    resp = web.HTTPUnavailableForLegalReasons(link=\"http://warning.or.kr/\")\n    assert resp.link == URL(\"http://warning.or.kr/\")\n    assert resp.headers[\"Link\"] == '<http://warning.or.kr/>; rel=\"blocked-by\"'\n\n\ndef test_link_url_451() -> None:\n    resp = web.HTTPUnavailableForLegalReasons(link=URL(\"http://warning.or.kr/\"))\n    assert resp.link == URL(\"http://warning.or.kr/\")\n    assert resp.headers[\"Link\"] == '<http://warning.or.kr/>; rel=\"blocked-by\"'\n\n\ndef test_link_CRLF_451() -> None:\n    resp = web.HTTPUnavailableForLegalReasons(link=\"http://warning.or.kr/\\r\\n\")\n    assert \"\\r\\n\" not in resp.headers[\"Link\"]\n\n\ndef test_HTTPException_retains_cause() -> None:\n    with pytest.raises(web.HTTPException) as ei:\n        try:\n            raise Exception(\"CustomException\")\n        except Exception as exc:\n            raise web.HTTPException() from exc\n    tb = \"\".join(format_exception(ei.type, ei.value, ei.tb))\n    assert \"CustomException\" in tb\n    assert \"direct cause\" in tb\n\n\nclass TestHTTPOk:\n    def test_ctor_all(self) -> None:\n        resp = web.HTTPOk(\n            headers={\"X-Custom\": \"value\"},\n            reason=\"Done\",\n            text=\"text\",\n            content_type=\"custom\",\n        )\n        assert resp.text == \"text\"\n        compare: Mapping[str, str] = {\"X-Custom\": \"value\", \"Content-Type\": \"custom\"}\n        assert resp.headers == compare\n        assert resp.reason == \"Done\"\n        assert resp.status == 200\n\n    def test_pickle(self) -> None:\n        resp = web.HTTPOk(\n            headers={\"X-Custom\": \"value\"},\n            reason=\"Done\",\n            text=\"text\",\n            content_type=\"custom\",\n        )\n        resp.foo = \"bar\"  # type: ignore[attr-defined]\n        for proto in range(2, pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(resp, proto)\n            resp2 = pickle.loads(pickled)\n            assert resp2.text == \"text\"\n            assert resp2.headers == resp.headers\n            assert resp2.reason == \"Done\"\n            assert resp2.status == 200\n            assert resp2.foo == \"bar\"\n\n    async def test_app(self, aiohttp_client: AiohttpClient) -> None:\n        async def handler(request: web.Request) -> NoReturn:\n            raise web.HTTPOk()\n\n        app = web.Application()\n        app.router.add_get(\"/\", handler)\n        cli = await aiohttp_client(app)\n\n        resp = await cli.get(\"/\")\n        assert 200 == resp.status\n        txt = await resp.text()\n        assert \"200: OK\" == txt\n\n\nclass TestHTTPFound:\n    def test_location_str(self) -> None:\n        exc = web.HTTPFound(location=\"/redirect\")\n        assert exc.location == URL(\"/redirect\")\n        assert exc.headers[\"Location\"] == \"/redirect\"\n\n    def test_location_url(self) -> None:\n        exc = web.HTTPFound(location=URL(\"/redirect\"))\n        assert exc.location == URL(\"/redirect\")\n        assert exc.headers[\"Location\"] == \"/redirect\"\n\n    def test_empty_location(self) -> None:\n        with pytest.raises(ValueError):\n            web.HTTPFound(location=\"\")\n        with pytest.raises(ValueError):\n            web.HTTPFound(location=None)  # type: ignore[arg-type]\n\n    def test_location_CRLF(self) -> None:\n        exc = web.HTTPFound(location=\"/redirect\\r\\n\")\n        assert \"\\r\\n\" not in exc.headers[\"Location\"]\n\n    def test_pickle(self) -> None:\n        resp = web.HTTPFound(\n            location=\"http://example.com\",\n            headers={\"X-Custom\": \"value\"},\n            reason=\"Wow\",\n            text=\"text\",\n            content_type=\"custom\",\n        )\n        resp.foo = \"bar\"  # type: ignore[attr-defined]\n        for proto in range(2, pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(resp, proto)\n            resp2 = pickle.loads(pickled)\n            assert resp2.location == URL(\"http://example.com\")\n            assert resp2.text == \"text\"\n            assert resp2.headers == resp.headers\n            assert resp2.reason == \"Wow\"\n            assert resp2.status == 302\n            assert resp2.foo == \"bar\"\n\n    async def test_app(self, aiohttp_client: AiohttpClient) -> None:\n        async def handler(request: web.Request) -> NoReturn:\n            raise web.HTTPFound(location=\"/redirect\")\n\n        app = web.Application()\n        app.router.add_get(\"/\", handler)\n        cli = await aiohttp_client(app)\n\n        resp = await cli.get(\"/\", allow_redirects=False)\n        assert 302 == resp.status\n        txt = await resp.text()\n        assert \"302: Found\" == txt\n        assert \"/redirect\" == resp.headers[\"location\"]\n\n\nclass TestHTTPMethodNotAllowed:\n    async def test_ctor(self) -> None:\n        resp = web.HTTPMethodNotAllowed(\n            \"GET\",\n            [\"POST\", \"PUT\"],\n            headers={\"X-Custom\": \"value\"},\n            reason=\"Unsupported\",\n            text=\"text\",\n            content_type=\"custom\",\n        )\n        assert resp.method == \"GET\"\n        assert resp.allowed_methods == {\"POST\", \"PUT\"}\n        assert resp.text == \"text\"\n        compare: Mapping[str, str] = {\n            \"X-Custom\": \"value\",\n            \"Content-Type\": \"custom\",\n            \"Allow\": \"POST,PUT\",\n        }\n        assert resp.headers == compare\n        assert resp.reason == \"Unsupported\"\n        assert resp.status == 405\n\n    def test_pickle(self) -> None:\n        resp = web.HTTPMethodNotAllowed(\n            method=\"GET\",\n            allowed_methods=(\"POST\", \"PUT\"),\n            headers={\"X-Custom\": \"value\"},\n            reason=\"Unsupported\",\n            text=\"text\",\n            content_type=\"custom\",\n        )\n        resp.foo = \"bar\"  # type: ignore[attr-defined]\n        for proto in range(2, pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(resp, proto)\n            resp2 = pickle.loads(pickled)\n            assert resp2.method == \"GET\"\n            assert resp2.allowed_methods == {\"POST\", \"PUT\"}\n            assert resp2.text == \"text\"\n            assert resp2.headers == resp.headers\n            assert resp2.reason == \"Unsupported\"\n            assert resp2.status == 405\n            assert resp2.foo == \"bar\"\n\n\nclass TestHTTPRequestEntityTooLarge:\n    def test_ctor(self) -> None:\n        resp = web.HTTPRequestEntityTooLarge(\n            max_size=100,\n            actual_size=123,\n            headers={\"X-Custom\": \"value\"},\n            reason=\"Too large\",\n        )\n        assert resp.text == (\n            \"Maximum request body size 100 exceeded, \" \"actual body size 123\"\n        )\n        compare: Mapping[str, str] = {\"X-Custom\": \"value\", \"Content-Type\": \"text/plain\"}\n        assert resp.headers == compare\n        assert resp.reason == \"Too large\"\n        assert resp.status == 413\n\n    def test_pickle(self) -> None:\n        resp = web.HTTPRequestEntityTooLarge(\n            100, actual_size=123, headers={\"X-Custom\": \"value\"}, reason=\"Too large\"\n        )\n        resp.foo = \"bar\"  # type: ignore[attr-defined]\n        for proto in range(2, pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(resp, proto)\n            resp2 = pickle.loads(pickled)\n            assert resp2.text == resp.text\n            assert resp2.headers == resp.headers\n            assert resp2.reason == \"Too large\"\n            assert resp2.status == 413\n            assert resp2.foo == \"bar\"\n\n\nclass TestHTTPUnavailableForLegalReasons:\n    def test_ctor(self) -> None:\n        exc = web.HTTPUnavailableForLegalReasons(\n            link=\"http://warning.or.kr/\",\n            headers={\"X-Custom\": \"value\"},\n            reason=\"Zaprescheno\",\n            text=\"text\",\n            content_type=\"custom\",\n        )\n        assert exc.link == URL(\"http://warning.or.kr/\")\n        assert exc.text == \"text\"\n        compare: Mapping[str, str] = {\n            \"X-Custom\": \"value\",\n            \"Content-Type\": \"custom\",\n            \"Link\": '<http://warning.or.kr/>; rel=\"blocked-by\"',\n        }\n        assert exc.headers == compare\n        assert exc.reason == \"Zaprescheno\"\n        assert exc.status == 451\n\n    def test_no_link(self) -> None:\n        with pytest.raises(TypeError):\n            web.HTTPUnavailableForLegalReasons()  # type: ignore[call-arg]\n\n    def test_none_link(self) -> None:\n        exc = web.HTTPUnavailableForLegalReasons(link=None)\n        assert exc.link is None\n        assert \"Link\" not in exc.headers\n\n    def test_empty_link(self) -> None:\n        exc = web.HTTPUnavailableForLegalReasons(link=\"\")\n        assert exc.link is None\n        assert \"Link\" not in exc.headers\n\n    def test_link_str(self) -> None:\n        exc = web.HTTPUnavailableForLegalReasons(link=\"http://warning.or.kr/\")\n        assert exc.link == URL(\"http://warning.or.kr/\")\n        assert exc.headers[\"Link\"] == '<http://warning.or.kr/>; rel=\"blocked-by\"'\n\n    def test_link_url(self) -> None:\n        exc = web.HTTPUnavailableForLegalReasons(link=URL(\"http://warning.or.kr/\"))\n        assert exc.link == URL(\"http://warning.or.kr/\")\n        assert exc.headers[\"Link\"] == '<http://warning.or.kr/>; rel=\"blocked-by\"'\n\n    def test_link_CRLF(self) -> None:\n        exc = web.HTTPUnavailableForLegalReasons(link=\"http://warning.or.kr/\\r\\n\")\n        assert \"\\r\\n\" not in exc.headers[\"Link\"]\n\n    def test_pickle(self) -> None:\n        resp = web.HTTPUnavailableForLegalReasons(\n            link=\"http://warning.or.kr/\",\n            headers={\"X-Custom\": \"value\"},\n            reason=\"Zaprescheno\",\n            text=\"text\",\n            content_type=\"custom\",\n        )\n        resp.foo = \"bar\"  # type: ignore[attr-defined]\n        for proto in range(2, pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(resp, proto)\n            resp2 = pickle.loads(pickled)\n            assert resp2.link == URL(\"http://warning.or.kr/\")\n            assert resp2.text == \"text\"\n            assert resp2.headers == resp.headers\n            assert resp2.reason == \"Zaprescheno\"\n            assert resp2.status == 451\n            assert resp2.foo == \"bar\"\n", "tests/test_websocket_parser.py": "# type: ignore\nimport pickle\nimport random\nimport struct\nimport zlib\nfrom typing import Any\nfrom unittest import mock\n\nimport pytest\n\nimport aiohttp\nfrom aiohttp import http_websocket\nfrom aiohttp.http import WebSocketError, WSCloseCode, WSMessage, WSMsgType\nfrom aiohttp.http_websocket import (\n    _WS_DEFLATE_TRAILING,\n    PACK_CLOSE_CODE,\n    PACK_LEN1,\n    PACK_LEN2,\n    PACK_LEN3,\n    WebSocketReader,\n    _websocket_mask,\n)\n\n\ndef build_frame(\n    message: Any,\n    opcode: Any,\n    use_mask: bool = False,\n    noheader: bool = False,\n    is_fin: bool = True,\n    compress: bool = False,\n):\n    # Send a frame over the websocket with message as its payload.\n    if compress:\n        compressobj = zlib.compressobj(wbits=-9)\n        message = compressobj.compress(message)\n        message = message + compressobj.flush(zlib.Z_SYNC_FLUSH)\n        if message.endswith(_WS_DEFLATE_TRAILING):\n            message = message[:-4]\n    msg_length = len(message)\n    if use_mask:  # pragma: no cover\n        mask_bit = 0x80\n    else:\n        mask_bit = 0\n\n    if is_fin:\n        header_first_byte = 0x80 | opcode\n    else:\n        header_first_byte = opcode\n\n    if compress:\n        header_first_byte |= 0x40\n\n    if msg_length < 126:\n        header = PACK_LEN1(header_first_byte, msg_length | mask_bit)\n    elif msg_length < (1 << 16):  # pragma: no cover\n        header = PACK_LEN2(header_first_byte, 126 | mask_bit, msg_length)\n    else:\n        header = PACK_LEN3(header_first_byte, 127 | mask_bit, msg_length)\n\n    if use_mask:  # pragma: no cover\n        mask = random.randrange(0, 0xFFFFFFFF)\n        mask = mask.to_bytes(4, \"big\")\n        message = bytearray(message)\n        _websocket_mask(mask, message)\n        if noheader:\n            return message\n        else:\n            return header + mask + message\n    else:\n        if noheader:\n            return message\n        else:\n            return header + message\n\n\ndef build_close_frame(code: int = 1000, message: bytes = b\"\", noheader: bool = False):\n    # Close the websocket, sending the specified code and message.\n    if isinstance(message, str):  # pragma: no cover\n        message = message.encode(\"utf-8\")\n    return build_frame(\n        PACK_CLOSE_CODE(code) + message, opcode=WSMsgType.CLOSE, noheader=noheader\n    )\n\n\n@pytest.fixture()\ndef out(loop: Any):\n    return aiohttp.DataQueue(loop)\n\n\n@pytest.fixture()\ndef parser(out: Any):\n    return WebSocketReader(out, 4 * 1024 * 1024)\n\n\ndef test_parse_frame(parser: Any) -> None:\n    parser.parse_frame(struct.pack(\"!BB\", 0b00000001, 0b00000001))\n    res = parser.parse_frame(b\"1\")\n    fin, opcode, payload, compress = res[0]\n\n    assert (0, 1, b\"1\", False) == (fin, opcode, payload, not not compress)\n\n\ndef test_parse_frame_length0(parser: Any) -> None:\n    fin, opcode, payload, compress = parser.parse_frame(\n        struct.pack(\"!BB\", 0b00000001, 0b00000000)\n    )[0]\n\n    assert (0, 1, b\"\", False) == (fin, opcode, payload, not not compress)\n\n\ndef test_parse_frame_length2(parser: Any) -> None:\n    parser.parse_frame(struct.pack(\"!BB\", 0b00000001, 126))\n    parser.parse_frame(struct.pack(\"!H\", 4))\n    res = parser.parse_frame(b\"1234\")\n    fin, opcode, payload, compress = res[0]\n\n    assert (0, 1, b\"1234\", False) == (fin, opcode, payload, not not compress)\n\n\ndef test_parse_frame_length4(parser: Any) -> None:\n    parser.parse_frame(struct.pack(\"!BB\", 0b00000001, 127))\n    parser.parse_frame(struct.pack(\"!Q\", 4))\n    fin, opcode, payload, compress = parser.parse_frame(b\"1234\")[0]\n\n    assert (0, 1, b\"1234\", False) == (fin, opcode, payload, not not compress)\n\n\ndef test_parse_frame_mask(parser: Any) -> None:\n    parser.parse_frame(struct.pack(\"!BB\", 0b00000001, 0b10000001))\n    parser.parse_frame(b\"0001\")\n    fin, opcode, payload, compress = parser.parse_frame(b\"1\")[0]\n\n    assert (0, 1, b\"\\x01\", False) == (fin, opcode, payload, not not compress)\n\n\ndef test_parse_frame_header_reversed_bits(out: Any, parser: Any) -> None:\n    with pytest.raises(WebSocketError):\n        parser.parse_frame(struct.pack(\"!BB\", 0b01100000, 0b00000000))\n        raise out.exception()\n\n\ndef test_parse_frame_header_control_frame(out: Any, parser: Any) -> None:\n    with pytest.raises(WebSocketError):\n        parser.parse_frame(struct.pack(\"!BB\", 0b00001000, 0b00000000))\n        raise out.exception()\n\n\ndef _test_parse_frame_header_new_data_err(out, parser):\n    with pytest.raises(WebSocketError):\n        parser.parse_frame(struct.pack(\"!BB\", 0b000000000, 0b00000000))\n        raise out.exception()\n\n\ndef test_parse_frame_header_payload_size(out: Any, parser: Any) -> None:\n    with pytest.raises(WebSocketError):\n        parser.parse_frame(struct.pack(\"!BB\", 0b10001000, 0b01111110))\n        raise out.exception()\n\n\ndef test_ping_frame(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [(1, WSMsgType.PING, b\"data\", False)]\n\n    parser.feed_data(b\"\")\n    res = out._buffer[0]\n    assert res == (WSMsgType.PING, b\"data\", \"\")\n\n\ndef test_pong_frame(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [(1, WSMsgType.PONG, b\"data\", False)]\n\n    parser.feed_data(b\"\")\n    res = out._buffer[0]\n    assert res == (WSMsgType.PONG, b\"data\", \"\")\n\n\ndef test_close_frame(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [(1, WSMsgType.CLOSE, b\"\", False)]\n\n    parser.feed_data(b\"\")\n    res = out._buffer[0]\n    assert res == (WSMsgType.CLOSE, 0, \"\")\n\n\ndef test_close_frame_info(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [(1, WSMsgType.CLOSE, b\"0112345\", False)]\n\n    parser.feed_data(b\"\")\n    res = out._buffer[0]\n    assert res == (WSMessage(WSMsgType.CLOSE, 12337, \"12345\"))\n\n\ndef test_close_frame_invalid(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [(1, WSMsgType.CLOSE, b\"1\", False)]\n    parser.feed_data(b\"\")\n\n    assert isinstance(out.exception(), WebSocketError)\n    assert out.exception().code == WSCloseCode.PROTOCOL_ERROR\n\n\ndef test_close_frame_invalid_2(out: Any, parser: Any) -> None:\n    data = build_close_frame(code=1)\n\n    with pytest.raises(WebSocketError) as ctx:\n        parser._feed_data(data)\n\n    assert ctx.value.code == WSCloseCode.PROTOCOL_ERROR\n\n\ndef test_close_frame_unicode_err(parser: Any) -> None:\n    data = build_close_frame(code=1000, message=b\"\\xf4\\x90\\x80\\x80\")\n\n    with pytest.raises(WebSocketError) as ctx:\n        parser._feed_data(data)\n\n    assert ctx.value.code == WSCloseCode.INVALID_TEXT\n\n\ndef test_unknown_frame(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [(1, WSMsgType.CONTINUATION, b\"\", False)]\n\n    with pytest.raises(WebSocketError):\n        parser.feed_data(b\"\")\n        raise out.exception()\n\n\ndef test_simple_text(out: Any, parser: Any) -> None:\n    data = build_frame(b\"text\", WSMsgType.TEXT)\n    parser._feed_data(data)\n    res = out._buffer[0]\n    assert res == (WSMsgType.TEXT, \"text\", \"\")\n\n\ndef test_simple_text_unicode_err(parser: Any) -> None:\n    data = build_frame(b\"\\xf4\\x90\\x80\\x80\", WSMsgType.TEXT)\n\n    with pytest.raises(WebSocketError) as ctx:\n        parser._feed_data(data)\n\n    assert ctx.value.code == WSCloseCode.INVALID_TEXT\n\n\ndef test_simple_binary(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [(1, WSMsgType.BINARY, b\"binary\", False)]\n\n    parser.feed_data(b\"\")\n    res = out._buffer[0]\n    assert res == (WSMsgType.BINARY, b\"binary\", \"\")\n\n\ndef test_fragmentation_header(out: Any, parser: Any) -> None:\n    data = build_frame(b\"a\", WSMsgType.TEXT)\n    parser._feed_data(data[:1])\n    parser._feed_data(data[1:])\n\n    res = out._buffer[0]\n    assert res == (WSMessage(WSMsgType.TEXT, \"a\", \"\"))\n\n\ndef test_continuation(out: Any, parser: Any) -> None:\n    data1 = build_frame(b\"line1\", WSMsgType.TEXT, is_fin=False)\n    parser._feed_data(data1)\n\n    data2 = build_frame(b\"line2\", WSMsgType.CONTINUATION)\n    parser._feed_data(data2)\n\n    res = out._buffer[0]\n    assert res == (WSMessage(WSMsgType.TEXT, \"line1line2\", \"\"))\n\n\ndef test_continuation_with_ping(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [\n        (0, WSMsgType.TEXT, b\"line1\", False),\n        (0, WSMsgType.PING, b\"\", False),\n        (1, WSMsgType.CONTINUATION, b\"line2\", False),\n    ]\n\n    data1 = build_frame(b\"line1\", WSMsgType.TEXT, is_fin=False)\n    parser._feed_data(data1)\n\n    data2 = build_frame(b\"\", WSMsgType.PING)\n    parser._feed_data(data2)\n\n    data3 = build_frame(b\"line2\", WSMsgType.CONTINUATION)\n    parser._feed_data(data3)\n\n    res = out._buffer[0]\n    assert res == (WSMessage(WSMsgType.PING, b\"\", \"\"))\n    res = out._buffer[1]\n    assert res == (WSMessage(WSMsgType.TEXT, \"line1line2\", \"\"))\n\n\ndef test_continuation_err(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [\n        (0, WSMsgType.TEXT, b\"line1\", False),\n        (1, WSMsgType.TEXT, b\"line2\", False),\n    ]\n\n    with pytest.raises(WebSocketError):\n        parser._feed_data(b\"\")\n\n\ndef test_continuation_with_close(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [\n        (0, WSMsgType.TEXT, b\"line1\", False),\n        (0, WSMsgType.CLOSE, build_close_frame(1002, b\"test\", noheader=True), False),\n        (1, WSMsgType.CONTINUATION, b\"line2\", False),\n    ]\n\n    parser.feed_data(b\"\")\n    res = out._buffer[0]\n    assert res, WSMessage(WSMsgType.CLOSE, 1002, \"test\")\n    res = out._buffer[1]\n    assert res == (WSMessage(WSMsgType.TEXT, \"line1line2\", \"\"))\n\n\ndef test_continuation_with_close_unicode_err(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [\n        (0, WSMsgType.TEXT, b\"line1\", False),\n        (\n            0,\n            WSMsgType.CLOSE,\n            build_close_frame(1000, b\"\\xf4\\x90\\x80\\x80\", noheader=True),\n            False,\n        ),\n        (1, WSMsgType.CONTINUATION, b\"line2\", False),\n    ]\n\n    with pytest.raises(WebSocketError) as ctx:\n        parser._feed_data(b\"\")\n\n    assert ctx.value.code == WSCloseCode.INVALID_TEXT\n\n\ndef test_continuation_with_close_bad_code(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [\n        (0, WSMsgType.TEXT, b\"line1\", False),\n        (0, WSMsgType.CLOSE, build_close_frame(1, b\"test\", noheader=True), False),\n        (1, WSMsgType.CONTINUATION, b\"line2\", False),\n    ]\n\n    with pytest.raises(WebSocketError) as ctx:\n        parser._feed_data(b\"\")\n\n    assert ctx.value.code == WSCloseCode.PROTOCOL_ERROR\n\n\ndef test_continuation_with_close_bad_payload(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [\n        (0, WSMsgType.TEXT, b\"line1\", False),\n        (0, WSMsgType.CLOSE, b\"1\", False),\n        (1, WSMsgType.CONTINUATION, b\"line2\", False),\n    ]\n\n    with pytest.raises(WebSocketError) as ctx:\n        parser._feed_data(b\"\")\n\n    assert ctx.value.code, WSCloseCode.PROTOCOL_ERROR\n\n\ndef test_continuation_with_close_empty(out: Any, parser: Any) -> None:\n    parser.parse_frame = mock.Mock()\n    parser.parse_frame.return_value = [\n        (0, WSMsgType.TEXT, b\"line1\", False),\n        (0, WSMsgType.CLOSE, b\"\", False),\n        (1, WSMsgType.CONTINUATION, b\"line2\", False),\n    ]\n\n    parser.feed_data(b\"\")\n    res = out._buffer[0]\n    assert res, WSMessage(WSMsgType.CLOSE, 0, \"\")\n    res = out._buffer[1]\n    assert res == (WSMessage(WSMsgType.TEXT, \"line1line2\", \"\"))\n\n\nwebsocket_mask_data: bytes = b\"some very long data for masking by websocket\"\nwebsocket_mask_mask: bytes = b\"1234\"\nwebsocket_mask_masked: bytes = (\n    b\"B]^Q\\x11DVFH\\x12_[_U\\x13PPFR\\x14W]A\\x14\\\\S@_X\" b\"\\\\T\\x14SK\\x13CTP@[RYV@\"\n)\n\n\ndef test_websocket_mask_python() -> None:\n    message = bytearray(websocket_mask_data)\n    http_websocket._websocket_mask_python(websocket_mask_mask, message)\n    assert message == websocket_mask_masked\n\n\n@pytest.mark.skipif(\n    not hasattr(http_websocket, \"_websocket_mask_cython\"), reason=\"Requires Cython\"\n)\ndef test_websocket_mask_cython() -> None:\n    message = bytearray(websocket_mask_data)\n    http_websocket._websocket_mask_cython(websocket_mask_mask, message)\n    assert message == websocket_mask_masked\n\n\ndef test_websocket_mask_python_empty() -> None:\n    message = bytearray()\n    http_websocket._websocket_mask_python(websocket_mask_mask, message)\n    assert message == bytearray()\n\n\n@pytest.mark.skipif(\n    not hasattr(http_websocket, \"_websocket_mask_cython\"), reason=\"Requires Cython\"\n)\ndef test_websocket_mask_cython_empty() -> None:\n    message = bytearray()\n    http_websocket._websocket_mask_cython(websocket_mask_mask, message)\n    assert message == bytearray()\n\n\ndef test_parse_compress_frame_single(parser: Any) -> None:\n    parser.parse_frame(struct.pack(\"!BB\", 0b11000001, 0b00000001))\n    res = parser.parse_frame(b\"1\")\n    fin, opcode, payload, compress = res[0]\n\n    assert (1, 1, b\"1\", True) == (fin, opcode, payload, not not compress)\n\n\ndef test_parse_compress_frame_multi(parser: Any) -> None:\n    parser.parse_frame(struct.pack(\"!BB\", 0b01000001, 126))\n    parser.parse_frame(struct.pack(\"!H\", 4))\n    res = parser.parse_frame(b\"1234\")\n    fin, opcode, payload, compress = res[0]\n    assert (0, 1, b\"1234\", True) == (fin, opcode, payload, not not compress)\n\n    parser.parse_frame(struct.pack(\"!BB\", 0b10000001, 126))\n    parser.parse_frame(struct.pack(\"!H\", 4))\n    res = parser.parse_frame(b\"1234\")\n    fin, opcode, payload, compress = res[0]\n    assert (1, 1, b\"1234\", True) == (fin, opcode, payload, not not compress)\n\n    parser.parse_frame(struct.pack(\"!BB\", 0b10000001, 126))\n    parser.parse_frame(struct.pack(\"!H\", 4))\n    res = parser.parse_frame(b\"1234\")\n    fin, opcode, payload, compress = res[0]\n    assert (1, 1, b\"1234\", False) == (fin, opcode, payload, not not compress)\n\n\ndef test_parse_compress_error_frame(parser: Any) -> None:\n    parser.parse_frame(struct.pack(\"!BB\", 0b01000001, 0b00000001))\n    parser.parse_frame(b\"1\")\n\n    with pytest.raises(WebSocketError) as ctx:\n        parser.parse_frame(struct.pack(\"!BB\", 0b11000001, 0b00000001))\n        parser.parse_frame(b\"1\")\n\n    assert ctx.value.code == WSCloseCode.PROTOCOL_ERROR\n\n\ndef test_parse_no_compress_frame_single() -> None:\n    parser_no_compress = WebSocketReader(out, 0, compress=False)\n    with pytest.raises(WebSocketError) as ctx:\n        parser_no_compress.parse_frame(struct.pack(\"!BB\", 0b11000001, 0b00000001))\n        parser_no_compress.parse_frame(b\"1\")\n\n    assert ctx.value.code == WSCloseCode.PROTOCOL_ERROR\n\n\ndef test_msg_too_large(out: Any) -> None:\n    parser = WebSocketReader(out, 256, compress=False)\n    data = build_frame(b\"text\" * 256, WSMsgType.TEXT)\n    with pytest.raises(WebSocketError) as ctx:\n        parser._feed_data(data)\n    assert ctx.value.code == WSCloseCode.MESSAGE_TOO_BIG\n\n\ndef test_msg_too_large_not_fin(out: Any) -> None:\n    parser = WebSocketReader(out, 256, compress=False)\n    data = build_frame(b\"text\" * 256, WSMsgType.TEXT, is_fin=False)\n    with pytest.raises(WebSocketError) as ctx:\n        parser._feed_data(data)\n    assert ctx.value.code == WSCloseCode.MESSAGE_TOO_BIG\n\n\ndef test_compressed_msg_too_large(out: Any) -> None:\n    parser = WebSocketReader(out, 256, compress=True)\n    data = build_frame(b\"aaa\" * 256, WSMsgType.TEXT, compress=True)\n    with pytest.raises(WebSocketError) as ctx:\n        parser._feed_data(data)\n    assert ctx.value.code == WSCloseCode.MESSAGE_TOO_BIG\n\n\nclass TestWebSocketError:\n    def test_ctor(self) -> None:\n        err = WebSocketError(WSCloseCode.PROTOCOL_ERROR, \"Something invalid\")\n        assert err.code == WSCloseCode.PROTOCOL_ERROR\n        assert str(err) == \"Something invalid\"\n\n    def test_pickle(self) -> None:\n        err = WebSocketError(WSCloseCode.PROTOCOL_ERROR, \"Something invalid\")\n        err.foo = \"bar\"\n        for proto in range(pickle.HIGHEST_PROTOCOL + 1):\n            pickled = pickle.dumps(err, proto)\n            err2 = pickle.loads(pickled)\n            assert err2.code == WSCloseCode.PROTOCOL_ERROR\n            assert str(err2) == \"Something invalid\"\n            assert err2.foo == \"bar\"\n", "tests/test_payload.py": "import array\nfrom io import StringIO\nfrom typing import Any, AsyncIterator, Iterator\n\nimport pytest\n\nfrom aiohttp import payload\n\n\n@pytest.fixture\ndef registry() -> Iterator[payload.PayloadRegistry]:\n    old = payload.PAYLOAD_REGISTRY\n    reg = payload.PAYLOAD_REGISTRY = payload.PayloadRegistry()\n    yield reg\n    payload.PAYLOAD_REGISTRY = old\n\n\nclass Payload(payload.Payload):\n    async def write(self, writer: Any) -> None:\n        pass\n\n\ndef test_register_type(registry: Any) -> None:\n    class TestProvider:\n        pass\n\n    payload.register_payload(Payload, TestProvider)\n    p = payload.get_payload(TestProvider())\n    assert isinstance(p, Payload)\n\n\ndef test_register_unsupported_order(registry: Any) -> None:\n    class TestProvider:\n        pass\n\n    with pytest.raises(ValueError):\n        payload.register_payload(\n            Payload, TestProvider, order=object()  # type: ignore[arg-type]\n        )\n\n\ndef test_payload_ctor() -> None:\n    p = Payload(\"test\", encoding=\"utf-8\", filename=\"test.txt\")\n    assert p._value == \"test\"\n    assert p._encoding == \"utf-8\"\n    assert p.size is None\n    assert p.filename == \"test.txt\"\n    assert p.content_type == \"text/plain\"\n\n\ndef test_payload_content_type() -> None:\n    p = Payload(\"test\", headers={\"content-type\": \"application/json\"})\n    assert p.content_type == \"application/json\"\n\n\ndef test_bytes_payload_default_content_type() -> None:\n    p = payload.BytesPayload(b\"data\")\n    assert p.content_type == \"application/octet-stream\"\n\n\ndef test_bytes_payload_explicit_content_type() -> None:\n    p = payload.BytesPayload(b\"data\", content_type=\"application/custom\")\n    assert p.content_type == \"application/custom\"\n\n\ndef test_bytes_payload_bad_type() -> None:\n    with pytest.raises(TypeError):\n        payload.BytesPayload(object())  # type: ignore[arg-type]\n\n\ndef test_bytes_payload_memoryview_correct_size() -> None:\n    mv = memoryview(array.array(\"H\", [1, 2, 3]))\n    p = payload.BytesPayload(mv)\n    assert p.size == 6\n\n\ndef test_string_payload() -> None:\n    p = payload.StringPayload(\"test\")\n    assert p.encoding == \"utf-8\"\n    assert p.content_type == \"text/plain; charset=utf-8\"\n\n    p = payload.StringPayload(\"test\", encoding=\"koi8-r\")\n    assert p.encoding == \"koi8-r\"\n    assert p.content_type == \"text/plain; charset=koi8-r\"\n\n    p = payload.StringPayload(\"test\", content_type=\"text/plain; charset=koi8-r\")\n    assert p.encoding == \"koi8-r\"\n    assert p.content_type == \"text/plain; charset=koi8-r\"\n\n\ndef test_string_io_payload() -> None:\n    s = StringIO(\"\u0171\" * 5000)\n    p = payload.StringIOPayload(s)\n    assert p.encoding == \"utf-8\"\n    assert p.content_type == \"text/plain; charset=utf-8\"\n    assert p.size == 10000\n\n\ndef test_async_iterable_payload_default_content_type() -> None:\n    async def gen() -> AsyncIterator[bytes]:\n        return\n        yield b\"abc\"\n\n    p = payload.AsyncIterablePayload(gen())\n    assert p.content_type == \"application/octet-stream\"\n\n\ndef test_async_iterable_payload_explicit_content_type() -> None:\n    async def gen() -> AsyncIterator[bytes]:\n        return\n        yield b\"abc\"\n\n    p = payload.AsyncIterablePayload(gen(), content_type=\"application/custom\")\n    assert p.content_type == \"application/custom\"\n\n\ndef test_async_iterable_payload_not_async_iterable() -> None:\n    with pytest.raises(TypeError):\n        payload.AsyncIterablePayload(object())  # type: ignore[arg-type]\n", "tests/test_client_proto.py": "# type: ignore\nfrom typing import Any\nfrom unittest import mock\n\nfrom yarl import URL\n\nfrom aiohttp import http\nfrom aiohttp.client_exceptions import ClientOSError, ServerDisconnectedError\nfrom aiohttp.client_proto import ResponseHandler\nfrom aiohttp.client_reqrep import ClientResponse\nfrom aiohttp.helpers import TimerNoop\n\n\nasync def test_oserror(loop: Any) -> None:\n    proto = ResponseHandler(loop=loop)\n    transport = mock.Mock()\n    proto.connection_made(transport)\n    proto.connection_lost(OSError())\n\n    assert proto.should_close\n    assert isinstance(proto.exception(), ClientOSError)\n\n\nasync def test_pause_resume_on_error(loop: Any) -> None:\n    proto = ResponseHandler(loop=loop)\n    transport = mock.Mock()\n    proto.connection_made(transport)\n\n    proto.pause_reading()\n    assert proto._reading_paused\n\n    proto.resume_reading()\n    assert not proto._reading_paused\n\n\nasync def test_client_proto_bad_message(loop: Any) -> None:\n    proto = ResponseHandler(loop=loop)\n    transport = mock.Mock()\n    proto.connection_made(transport)\n    proto.set_response_params()\n\n    proto.data_received(b\"HTTP\\r\\n\\r\\n\")\n    assert proto.should_close\n    assert transport.close.called\n    assert isinstance(proto.exception(), http.HttpProcessingError)\n\n\nasync def test_uncompleted_message(loop: Any) -> None:\n    proto = ResponseHandler(loop=loop)\n    transport = mock.Mock()\n    proto.connection_made(transport)\n    proto.set_response_params(read_until_eof=True)\n\n    proto.data_received(\n        b\"HTTP/1.1 301 Moved Permanently\\r\\n\" b\"Location: http://python.org/\"\n    )\n    proto.connection_lost(None)\n\n    exc = proto.exception()\n    assert isinstance(exc, ServerDisconnectedError)\n    assert exc.message.code == 301\n    assert dict(exc.message.headers) == {\"Location\": \"http://python.org/\"}\n\n\nasync def test_client_protocol_readuntil_eof(loop: Any) -> None:\n    proto = ResponseHandler(loop=loop)\n    transport = mock.Mock()\n    proto.connection_made(transport)\n    conn = mock.Mock()\n    conn.protocol = proto\n\n    proto.data_received(b\"HTTP/1.1 200 Ok\\r\\n\\r\\n\")\n\n    response = ClientResponse(\n        \"get\",\n        URL(\"http://def-cl-resp.org\"),\n        writer=mock.Mock(),\n        continue100=None,\n        timer=TimerNoop(),\n        request_info=mock.Mock(),\n        traces=[],\n        loop=loop,\n        session=mock.Mock(),\n    )\n    proto.set_response_params(read_until_eof=True)\n    await response.start(conn)\n\n    assert not response.content.is_eof()\n\n    proto.data_received(b\"0000\")\n    data = await response.content.readany()\n    assert data == b\"0000\"\n\n    proto.data_received(b\"1111\")\n    data = await response.content.readany()\n    assert data == b\"1111\"\n\n    proto.connection_lost(None)\n    assert response.content.is_eof()\n\n\nasync def test_empty_data(loop: Any) -> None:\n    proto = ResponseHandler(loop=loop)\n    proto.data_received(b\"\")\n\n    # do nothing\n\n\nasync def test_schedule_timeout(loop: Any) -> None:\n    proto = ResponseHandler(loop=loop)\n    proto.set_response_params(read_timeout=1)\n    assert proto._read_timeout_handle is None\n    proto.start_timeout()\n    assert proto._read_timeout_handle is not None\n\n\nasync def test_drop_timeout(loop: Any) -> None:\n    proto = ResponseHandler(loop=loop)\n    proto.set_response_params(read_timeout=1)\n    proto.start_timeout()\n    assert proto._read_timeout_handle is not None\n    proto._drop_timeout()\n    assert proto._read_timeout_handle is None\n\n\nasync def test_reschedule_timeout(loop: Any) -> None:\n    proto = ResponseHandler(loop=loop)\n    proto.set_response_params(read_timeout=1)\n    proto.start_timeout()\n    assert proto._read_timeout_handle is not None\n    h = proto._read_timeout_handle\n    proto._reschedule_timeout()\n    assert proto._read_timeout_handle is not None\n    assert proto._read_timeout_handle is not h\n\n\nasync def test_eof_received(loop: Any) -> None:\n    proto = ResponseHandler(loop=loop)\n    proto.set_response_params(read_timeout=1)\n    proto.start_timeout()\n    assert proto._read_timeout_handle is not None\n    proto.eof_received()\n    assert proto._read_timeout_handle is None\n\n\nasync def test_connection_lost_sets_transport_to_none(loop: Any, mocker: Any) -> None:\n    \"\"\"Ensure that the transport is set to None when the connection is lost.\n\n    This ensures the writer knows that the connection is closed.\n    \"\"\"\n    proto = ResponseHandler(loop=loop)\n    proto.connection_made(mocker.Mock())\n    assert proto.transport is not None\n\n    proto.connection_lost(OSError())\n\n    assert proto.transport is None\n", "tests/test_web_request_handler.py": "from unittest import mock\n\nfrom aiohttp import web\nfrom aiohttp.test_utils import make_mocked_coro\n\n\nasync def serve(request: web.BaseRequest) -> web.Response:\n    return web.Response()\n\n\nasync def test_repr() -> None:\n    manager = web.Server(serve)\n    handler = manager()\n\n    assert \"<RequestHandler disconnected>\" == repr(handler)\n\n    with mock.patch.object(handler, \"transport\", autospec=True):\n        assert \"<RequestHandler connected>\" == repr(handler)\n\n\nasync def test_connections() -> None:\n    manager = web.Server(serve)\n    assert manager.connections == []\n\n    handler = object()\n    transport = object()\n    manager.connection_made(handler, transport)  # type: ignore[arg-type]\n    assert manager.connections == [handler]\n\n    manager.connection_lost(handler, None)  # type: ignore[arg-type]\n    assert manager.connections == []\n\n\nasync def test_shutdown_no_timeout() -> None:\n    manager = web.Server(serve)\n\n    handler = mock.Mock()\n    handler.shutdown = make_mocked_coro(mock.Mock())\n    transport = mock.Mock()\n    manager.connection_made(handler, transport)\n\n    await manager.shutdown()\n\n    manager.connection_lost(handler, None)\n    assert manager.connections == []\n    handler.shutdown.assert_called_with(None)\n\n\nasync def test_shutdown_timeout() -> None:\n    manager = web.Server(serve)\n\n    handler = mock.Mock()\n    handler.shutdown = make_mocked_coro(mock.Mock())\n    transport = mock.Mock()\n    manager.connection_made(handler, transport)\n\n    await manager.shutdown(timeout=0.1)\n\n    manager.connection_lost(handler, None)\n    assert manager.connections == []\n    handler.shutdown.assert_called_with(0.1)\n", "tests/autobahn/test_autobahn.py": "import json\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom typing import Any, Dict, Generator, List\n\nimport pytest\nfrom pytest import TempPathFactory\nfrom python_on_whales import DockerException, docker\n\n\n@pytest.fixture(scope=\"session\")\ndef report_dir(tmp_path_factory: TempPathFactory) -> Path:\n    return tmp_path_factory.mktemp(\"reports\")\n\n\n@pytest.fixture(scope=\"session\", autouse=True)\ndef build_autobahn_testsuite() -> Generator[None, None, None]:\n    try:\n        docker.build(\n            file=\"tests/autobahn/Dockerfile.autobahn\",\n            tags=[\"autobahn-testsuite\"],\n            context_path=\".\",\n        )\n    except DockerException:\n        pytest.skip(\"The docker daemon is not running.\")\n\n    try:\n        yield\n    finally:\n        docker.image.remove(x=\"autobahn-testsuite\")\n\n\ndef get_failed_tests(report_path: str, name: str) -> List[Dict[str, Any]]:\n    path = Path(report_path)\n    result_summary = json.loads((path / \"index.json\").read_text())[name]\n    failed_messages = []\n    PASS = {\"OK\", \"INFORMATIONAL\"}\n    entry_fields = {\"case\", \"description\", \"expectation\", \"expected\", \"received\"}\n    for results in result_summary.values():\n        if results[\"behavior\"] in PASS and results[\"behaviorClose\"] in PASS:\n            continue\n        report = json.loads((path / results[\"reportfile\"]).read_text())\n        failed_messages.append({field: report[field] for field in entry_fields})\n    return failed_messages\n\n\n@pytest.mark.skipif(sys.platform == \"darwin\", reason=\"Don't run on macOS\")\n@pytest.mark.xfail\ndef test_client(report_dir: Path, request: Any) -> None:\n    try:\n        print(\"Starting autobahn-testsuite server\")\n        autobahn_container = docker.run(\n            detach=True,\n            image=\"autobahn-testsuite\",\n            name=\"autobahn\",\n            publish=[(9001, 9001)],\n            remove=True,\n            volumes=[\n                (f\"{request.fspath.dirname}/client\", \"/config\"),\n                (f\"{report_dir}\", \"/reports\"),\n            ],\n        )\n        print(\"Running aiohttp test client\")\n        client = subprocess.Popen(\n            [\"wait-for-it\", \"-s\", \"localhost:9001\", \"--\"]\n            + [sys.executable]\n            + [\"tests/autobahn/client/client.py\"]\n        )\n        client.wait()\n    finally:\n        print(\"Stopping client and server\")\n        client.terminate()\n        client.wait()\n        # https://github.com/gabrieldemarmiesse/python-on-whales/pull/580\n        autobahn_container.stop()  # type: ignore[union-attr]\n\n    failed_messages = get_failed_tests(f\"{report_dir}/clients\", \"aiohttp\")\n\n    assert not failed_messages, \"\\n\".join(\n        \"\\n\\t\".join(\n            f\"{field}: {msg[field]}\"\n            for field in (\"case\", \"description\", \"expectation\", \"expected\", \"received\")\n        )\n        for msg in failed_messages\n    )\n\n\n@pytest.mark.skipif(sys.platform == \"darwin\", reason=\"Don't run on macOS\")\n@pytest.mark.xfail\ndef test_server(report_dir: Path, request: Any) -> None:\n    try:\n        print(\"Starting aiohttp test server\")\n        server = subprocess.Popen(\n            [sys.executable] + [\"tests/autobahn/server/server.py\"]\n        )\n        print(\"Starting autobahn-testsuite client\")\n        docker.run(\n            image=\"autobahn-testsuite\",\n            name=\"autobahn\",\n            remove=True,\n            volumes=[\n                (f\"{request.fspath.dirname}/server\", \"/config\"),\n                (f\"{report_dir}\", \"/reports\"),\n            ],\n            networks=[\"host\"],\n            command=[\n                \"wait-for-it\",\n                \"-s\",\n                \"localhost:9001\",\n                \"--\",\n                \"wstest\",\n                \"--mode\",\n                \"fuzzingclient\",\n                \"--spec\",\n                \"/config/fuzzingclient.json\",\n            ],\n        )\n    finally:\n        print(\"Stopping client and server\")\n        server.terminate()\n        server.wait()\n\n    failed_messages = get_failed_tests(f\"{report_dir}/servers\", \"AutobahnServer\")\n\n    assert not failed_messages, \"\\n\".join(\n        \"\\n\\t\".join(\n            f\"{field}: {msg[field]}\"\n            for field in (\"case\", \"description\", \"expectation\", \"expected\", \"received\")\n        )\n        for msg in failed_messages\n    )\n", "tests/autobahn/client/client.py": "#!/usr/bin/env python3\n\nimport asyncio\n\nimport aiohttp\n\n\nasync def client(url: str, name: str) -> None:\n    async with aiohttp.ClientSession() as session:\n        async with session.ws_connect(url + \"/getCaseCount\") as ws:\n            num_tests = int((await ws.receive()).data)\n            print(\"running %d cases\" % num_tests)\n\n        for i in range(1, num_tests + 1):\n            print(\"running test case:\", i)\n            text_url = url + \"/runCase?case=%d&agent=%s\" % (i, name)\n            async with session.ws_connect(text_url) as ws:\n                async for msg in ws:\n                    if msg.type == aiohttp.WSMsgType.TEXT:\n                        await ws.send_str(msg.data)\n                    elif msg.type == aiohttp.WSMsgType.BINARY:\n                        await ws.send_bytes(msg.data)\n                    else:\n                        break\n\n        url = url + \"/updateReports?agent=%s\" % name\n        async with session.ws_connect(url) as ws:\n            print(\"finally requesting %s\" % url)\n\n\nasync def run(url: str, name: str) -> None:\n    try:\n        await client(url, name)\n    except Exception:\n        import traceback\n\n        traceback.print_exc()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(run(\"http://localhost:9001\", \"aiohttp\"))\n", "tests/autobahn/server/server.py": "#!/usr/bin/env python3\n\nimport logging\nfrom typing import List\n\nfrom aiohttp import WSCloseCode, web\n\nwebsockets = web.AppKey(\"websockets\", List[web.WebSocketResponse])\n\n\nasync def wshandler(request: web.Request) -> web.WebSocketResponse:\n    ws = web.WebSocketResponse(autoclose=False)\n    is_ws = ws.can_prepare(request)\n    if not is_ws:\n        raise web.HTTPBadRequest()\n\n    await ws.prepare(request)\n\n    request.app[websockets].append(ws)\n\n    while True:\n        msg = await ws.receive()\n\n        if msg.type == web.WSMsgType.TEXT:\n            await ws.send_str(msg.data)\n        elif msg.type == web.WSMsgType.BINARY:\n            await ws.send_bytes(msg.data)\n        elif msg.type == web.WSMsgType.CLOSE:\n            await ws.close()\n            break\n        else:\n            break\n\n    return ws\n\n\nasync def on_shutdown(app: web.Application) -> None:\n    ws_list = app[websockets]\n    for ws in set(ws_list):\n        await ws.close(code=WSCloseCode.GOING_AWAY, message=b\"Server shutdown\")\n\n\nif __name__ == \"__main__\":\n    logging.basicConfig(\n        level=logging.DEBUG, format=\"%(asctime)s %(levelname)s %(message)s\"\n    )\n\n    app = web.Application()\n    l: List[web.WebSocketResponse] = []\n    app[websockets] = l\n    app.router.add_route(\"GET\", \"/\", wshandler)\n    app.on_shutdown.append(on_shutdown)\n    try:\n        web.run_app(app, port=9001)\n    except KeyboardInterrupt:\n        print(\"Server stopped at http://127.0.0.1:9001\")\n", "requirements/sync-direct-runtime-deps.py": "#!/usr/bin/env python\n\"\"\"Sync direct runtime dependencies from setup.cfg to runtime-deps.in.\"\"\"\n\nfrom configparser import ConfigParser\nfrom pathlib import Path\n\ncfg = ConfigParser()\ncfg.read(Path(\"setup.cfg\"))\nreqs = cfg[\"options\"][\"install_requires\"] + cfg.items(\"options.extras_require\")[0][1]\nreqs = sorted(reqs.split(\"\\n\"), key=str.casefold)\nreqs.remove(\"\")\n\nwith open(Path(\"requirements\", \"runtime-deps.in\"), \"w\") as outfile:\n    header = \"# Extracted from `setup.cfg` via `make sync-direct-runtime-deps`\\n\\n\"\n    outfile.write(header)\n    outfile.write(\"\\n\".join(reqs) + \"\\n\")\n", "aiohttp/web_fileresponse.py": "import asyncio\nimport mimetypes\nimport os\nimport pathlib\nimport sys\nfrom contextlib import suppress\nfrom types import MappingProxyType\nfrom typing import (\n    IO,\n    TYPE_CHECKING,\n    Any,\n    Awaitable,\n    Callable,\n    Final,\n    Optional,\n    Tuple,\n    cast,\n)\n\nfrom . import hdrs\nfrom .abc import AbstractStreamWriter\nfrom .helpers import ETAG_ANY, ETag, must_be_empty_body\nfrom .typedefs import LooseHeaders, PathLike\nfrom .web_exceptions import (\n    HTTPNotModified,\n    HTTPPartialContent,\n    HTTPPreconditionFailed,\n    HTTPRequestRangeNotSatisfiable,\n)\nfrom .web_response import StreamResponse\n\n__all__ = (\"FileResponse\",)\n\nif TYPE_CHECKING:\n    from .web_request import BaseRequest\n\n\n_T_OnChunkSent = Optional[Callable[[bytes], Awaitable[None]]]\n\n\nNOSENDFILE: Final[bool] = bool(os.environ.get(\"AIOHTTP_NOSENDFILE\"))\n\nif sys.version_info < (3, 9):\n    mimetypes.encodings_map[\".br\"] = \"br\"\n\n# File extension to IANA encodings map that will be checked in the order defined.\nENCODING_EXTENSIONS = MappingProxyType(\n    {ext: mimetypes.encodings_map[ext] for ext in (\".br\", \".gz\")}\n)\n\n\nclass FileResponse(StreamResponse):\n    \"\"\"A response object can be used to send files.\"\"\"\n\n    def __init__(\n        self,\n        path: PathLike,\n        chunk_size: int = 256 * 1024,\n        status: int = 200,\n        reason: Optional[str] = None,\n        headers: Optional[LooseHeaders] = None,\n    ) -> None:\n        super().__init__(status=status, reason=reason, headers=headers)\n\n        self._path = pathlib.Path(path)\n        self._chunk_size = chunk_size\n\n    async def _sendfile_fallback(\n        self, writer: AbstractStreamWriter, fobj: IO[Any], offset: int, count: int\n    ) -> AbstractStreamWriter:\n        # To keep memory usage low,fobj is transferred in chunks\n        # controlled by the constructor's chunk_size argument.\n\n        chunk_size = self._chunk_size\n        loop = asyncio.get_event_loop()\n\n        await loop.run_in_executor(None, fobj.seek, offset)\n\n        chunk = await loop.run_in_executor(None, fobj.read, chunk_size)\n        while chunk:\n            await writer.write(chunk)\n            count = count - chunk_size\n            if count <= 0:\n                break\n            chunk = await loop.run_in_executor(None, fobj.read, min(chunk_size, count))\n\n        await writer.drain()\n        return writer\n\n    async def _sendfile(\n        self, request: \"BaseRequest\", fobj: IO[Any], offset: int, count: int\n    ) -> AbstractStreamWriter:\n        writer = await super().prepare(request)\n        assert writer is not None\n\n        if NOSENDFILE or self.compression:\n            return await self._sendfile_fallback(writer, fobj, offset, count)\n\n        loop = request._loop\n        transport = request.transport\n        assert transport is not None\n\n        try:\n            await loop.sendfile(transport, fobj, offset, count)\n        except NotImplementedError:\n            return await self._sendfile_fallback(writer, fobj, offset, count)\n\n        await super().write_eof()\n        return writer\n\n    @staticmethod\n    def _strong_etag_match(etag_value: str, etags: Tuple[ETag, ...]) -> bool:\n        if len(etags) == 1 and etags[0].value == ETAG_ANY:\n            return True\n        return any(etag.value == etag_value for etag in etags if not etag.is_weak)\n\n    async def _not_modified(\n        self, request: \"BaseRequest\", etag_value: str, last_modified: float\n    ) -> Optional[AbstractStreamWriter]:\n        self.set_status(HTTPNotModified.status_code)\n        self._length_check = False\n        self.etag = etag_value  # type: ignore[assignment]\n        self.last_modified = last_modified  # type: ignore[assignment]\n        # Delete any Content-Length headers provided by user. HTTP 304\n        # should always have empty response body\n        return await super().prepare(request)\n\n    async def _precondition_failed(\n        self, request: \"BaseRequest\"\n    ) -> Optional[AbstractStreamWriter]:\n        self.set_status(HTTPPreconditionFailed.status_code)\n        self.content_length = 0\n        return await super().prepare(request)\n\n    def _get_file_path_stat_encoding(\n        self, accept_encoding: str\n    ) -> Tuple[pathlib.Path, os.stat_result, Optional[str]]:\n        \"\"\"Return the file path, stat result, and encoding.\n\n        If an uncompressed file is returned, the encoding is set to\n        :py:data:`None`.\n\n        This method should be called from a thread executor\n        since it calls os.stat which may block.\n        \"\"\"\n        file_path = self._path\n        for file_extension, file_encoding in ENCODING_EXTENSIONS.items():\n            if file_encoding not in accept_encoding:\n                continue\n\n            compressed_path = file_path.with_suffix(file_path.suffix + file_extension)\n            with suppress(OSError):\n                return compressed_path, compressed_path.stat(), file_encoding\n\n        # Fallback to the uncompressed file\n        return file_path, file_path.stat(), None\n\n    async def prepare(self, request: \"BaseRequest\") -> Optional[AbstractStreamWriter]:\n        loop = asyncio.get_event_loop()\n        # Encoding comparisons should be case-insensitive\n        # https://www.rfc-editor.org/rfc/rfc9110#section-8.4.1\n        accept_encoding = request.headers.get(hdrs.ACCEPT_ENCODING, \"\").lower()\n        file_path, st, file_encoding = await loop.run_in_executor(\n            None, self._get_file_path_stat_encoding, accept_encoding\n        )\n\n        etag_value = f\"{st.st_mtime_ns:x}-{st.st_size:x}\"\n        last_modified = st.st_mtime\n\n        # https://tools.ietf.org/html/rfc7232#section-6\n        ifmatch = request.if_match\n        if ifmatch is not None and not self._strong_etag_match(etag_value, ifmatch):\n            return await self._precondition_failed(request)\n\n        unmodsince = request.if_unmodified_since\n        if (\n            unmodsince is not None\n            and ifmatch is None\n            and st.st_mtime > unmodsince.timestamp()\n        ):\n            return await self._precondition_failed(request)\n\n        ifnonematch = request.if_none_match\n        if ifnonematch is not None and self._strong_etag_match(etag_value, ifnonematch):\n            return await self._not_modified(request, etag_value, last_modified)\n\n        modsince = request.if_modified_since\n        if (\n            modsince is not None\n            and ifnonematch is None\n            and st.st_mtime <= modsince.timestamp()\n        ):\n            return await self._not_modified(request, etag_value, last_modified)\n\n        ct = None\n        if hdrs.CONTENT_TYPE not in self.headers:\n            ct, encoding = mimetypes.guess_type(str(file_path))\n            if not ct:\n                ct = \"application/octet-stream\"\n        else:\n            encoding = file_encoding\n\n        status = self._status\n        file_size = st.st_size\n        count = file_size\n\n        start = None\n\n        ifrange = request.if_range\n        if ifrange is None or st.st_mtime <= ifrange.timestamp():\n            # If-Range header check:\n            # condition = cached date >= last modification date\n            # return 206 if True else 200.\n            # if False:\n            #   Range header would not be processed, return 200\n            # if True but Range header missing\n            #   return 200\n            try:\n                rng = request.http_range\n                start = rng.start\n                end = rng.stop\n            except ValueError:\n                # https://tools.ietf.org/html/rfc7233:\n                # A server generating a 416 (Range Not Satisfiable) response to\n                # a byte-range request SHOULD send a Content-Range header field\n                # with an unsatisfied-range value.\n                # The complete-length in a 416 response indicates the current\n                # length of the selected representation.\n                #\n                # Will do the same below. Many servers ignore this and do not\n                # send a Content-Range header with HTTP 416\n                self.headers[hdrs.CONTENT_RANGE] = f\"bytes */{file_size}\"\n                self.set_status(HTTPRequestRangeNotSatisfiable.status_code)\n                return await super().prepare(request)\n\n            # If a range request has been made, convert start, end slice\n            # notation into file pointer offset and count\n            if start is not None or end is not None:\n                if start < 0 and end is None:  # return tail of file\n                    start += file_size\n                    if start < 0:\n                        # if Range:bytes=-1000 in request header but file size\n                        # is only 200, there would be trouble without this\n                        start = 0\n                    count = file_size - start\n                else:\n                    # rfc7233:If the last-byte-pos value is\n                    # absent, or if the value is greater than or equal to\n                    # the current length of the representation data,\n                    # the byte range is interpreted as the remainder\n                    # of the representation (i.e., the server replaces the\n                    # value of last-byte-pos with a value that is one less than\n                    # the current length of the selected representation).\n                    count = (\n                        min(end if end is not None else file_size, file_size) - start\n                    )\n\n                if start >= file_size:\n                    # HTTP 416 should be returned in this case.\n                    #\n                    # According to https://tools.ietf.org/html/rfc7233:\n                    # If a valid byte-range-set includes at least one\n                    # byte-range-spec with a first-byte-pos that is less than\n                    # the current length of the representation, or at least one\n                    # suffix-byte-range-spec with a non-zero suffix-length,\n                    # then the byte-range-set is satisfiable. Otherwise, the\n                    # byte-range-set is unsatisfiable.\n                    self.headers[hdrs.CONTENT_RANGE] = f\"bytes */{file_size}\"\n                    self.set_status(HTTPRequestRangeNotSatisfiable.status_code)\n                    return await super().prepare(request)\n\n                status = HTTPPartialContent.status_code\n                # Even though you are sending the whole file, you should still\n                # return a HTTP 206 for a Range request.\n                self.set_status(status)\n\n        if ct:\n            self.content_type = ct\n        if encoding:\n            self.headers[hdrs.CONTENT_ENCODING] = encoding\n        if file_encoding:\n            self.headers[hdrs.VARY] = hdrs.ACCEPT_ENCODING\n            # Disable compression if we are already sending\n            # a compressed file since we don't want to double\n            # compress.\n            self._compression = False\n\n        self.etag = etag_value  # type: ignore[assignment]\n        self.last_modified = st.st_mtime  # type: ignore[assignment]\n        self.content_length = count\n\n        self.headers[hdrs.ACCEPT_RANGES] = \"bytes\"\n\n        real_start = cast(int, start)\n\n        if status == HTTPPartialContent.status_code:\n            self.headers[hdrs.CONTENT_RANGE] = \"bytes {}-{}/{}\".format(\n                real_start, real_start + count - 1, file_size\n            )\n\n        # If we are sending 0 bytes calling sendfile() will throw a ValueError\n        if count == 0 or must_be_empty_body(request.method, self.status):\n            return await super().prepare(request)\n\n        fobj = await loop.run_in_executor(None, file_path.open, \"rb\")\n        if start:  # be aware that start could be None or int=0 here.\n            offset = start\n        else:\n            offset = 0\n\n        try:\n            return await self._sendfile(request, fobj, offset, count)\n        finally:\n            await asyncio.shield(loop.run_in_executor(None, fobj.close))\n", "aiohttp/tracing.py": "import dataclasses\nfrom types import SimpleNamespace\nfrom typing import TYPE_CHECKING, Awaitable, Optional, Protocol, Type, TypeVar\n\nfrom aiosignal import Signal\nfrom multidict import CIMultiDict\nfrom yarl import URL\n\nfrom .client_reqrep import ClientResponse\n\nif TYPE_CHECKING:\n    from .client import ClientSession\n\n    _ParamT_contra = TypeVar(\"_ParamT_contra\", contravariant=True)\n\n    class _SignalCallback(Protocol[_ParamT_contra]):\n        def __call__(\n            self,\n            __client_session: ClientSession,\n            __trace_config_ctx: SimpleNamespace,\n            __params: _ParamT_contra,\n        ) -> Awaitable[None]: ...\n\n\n__all__ = (\n    \"TraceConfig\",\n    \"TraceRequestStartParams\",\n    \"TraceRequestEndParams\",\n    \"TraceRequestExceptionParams\",\n    \"TraceConnectionQueuedStartParams\",\n    \"TraceConnectionQueuedEndParams\",\n    \"TraceConnectionCreateStartParams\",\n    \"TraceConnectionCreateEndParams\",\n    \"TraceConnectionReuseconnParams\",\n    \"TraceDnsResolveHostStartParams\",\n    \"TraceDnsResolveHostEndParams\",\n    \"TraceDnsCacheHitParams\",\n    \"TraceDnsCacheMissParams\",\n    \"TraceRequestRedirectParams\",\n    \"TraceRequestChunkSentParams\",\n    \"TraceResponseChunkReceivedParams\",\n    \"TraceRequestHeadersSentParams\",\n)\n\n\nclass TraceConfig:\n    \"\"\"First-class used to trace requests launched via ClientSession objects.\"\"\"\n\n    def __init__(\n        self, trace_config_ctx_factory: Type[SimpleNamespace] = SimpleNamespace\n    ) -> None:\n        self._on_request_start: Signal[_SignalCallback[TraceRequestStartParams]] = (\n            Signal(self)\n        )\n        self._on_request_chunk_sent: Signal[\n            _SignalCallback[TraceRequestChunkSentParams]\n        ] = Signal(self)\n        self._on_response_chunk_received: Signal[\n            _SignalCallback[TraceResponseChunkReceivedParams]\n        ] = Signal(self)\n        self._on_request_end: Signal[_SignalCallback[TraceRequestEndParams]] = Signal(\n            self\n        )\n        self._on_request_exception: Signal[\n            _SignalCallback[TraceRequestExceptionParams]\n        ] = Signal(self)\n        self._on_request_redirect: Signal[\n            _SignalCallback[TraceRequestRedirectParams]\n        ] = Signal(self)\n        self._on_connection_queued_start: Signal[\n            _SignalCallback[TraceConnectionQueuedStartParams]\n        ] = Signal(self)\n        self._on_connection_queued_end: Signal[\n            _SignalCallback[TraceConnectionQueuedEndParams]\n        ] = Signal(self)\n        self._on_connection_create_start: Signal[\n            _SignalCallback[TraceConnectionCreateStartParams]\n        ] = Signal(self)\n        self._on_connection_create_end: Signal[\n            _SignalCallback[TraceConnectionCreateEndParams]\n        ] = Signal(self)\n        self._on_connection_reuseconn: Signal[\n            _SignalCallback[TraceConnectionReuseconnParams]\n        ] = Signal(self)\n        self._on_dns_resolvehost_start: Signal[\n            _SignalCallback[TraceDnsResolveHostStartParams]\n        ] = Signal(self)\n        self._on_dns_resolvehost_end: Signal[\n            _SignalCallback[TraceDnsResolveHostEndParams]\n        ] = Signal(self)\n        self._on_dns_cache_hit: Signal[_SignalCallback[TraceDnsCacheHitParams]] = (\n            Signal(self)\n        )\n        self._on_dns_cache_miss: Signal[_SignalCallback[TraceDnsCacheMissParams]] = (\n            Signal(self)\n        )\n        self._on_request_headers_sent: Signal[\n            _SignalCallback[TraceRequestHeadersSentParams]\n        ] = Signal(self)\n\n        self._trace_config_ctx_factory = trace_config_ctx_factory\n\n    def trace_config_ctx(\n        self, trace_request_ctx: Optional[SimpleNamespace] = None\n    ) -> SimpleNamespace:\n        \"\"\"Return a new trace_config_ctx instance\"\"\"\n        return self._trace_config_ctx_factory(trace_request_ctx=trace_request_ctx)\n\n    def freeze(self) -> None:\n        self._on_request_start.freeze()\n        self._on_request_chunk_sent.freeze()\n        self._on_response_chunk_received.freeze()\n        self._on_request_end.freeze()\n        self._on_request_exception.freeze()\n        self._on_request_redirect.freeze()\n        self._on_connection_queued_start.freeze()\n        self._on_connection_queued_end.freeze()\n        self._on_connection_create_start.freeze()\n        self._on_connection_create_end.freeze()\n        self._on_connection_reuseconn.freeze()\n        self._on_dns_resolvehost_start.freeze()\n        self._on_dns_resolvehost_end.freeze()\n        self._on_dns_cache_hit.freeze()\n        self._on_dns_cache_miss.freeze()\n        self._on_request_headers_sent.freeze()\n\n    @property\n    def on_request_start(self) -> \"Signal[_SignalCallback[TraceRequestStartParams]]\":\n        return self._on_request_start\n\n    @property\n    def on_request_chunk_sent(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceRequestChunkSentParams]]\":\n        return self._on_request_chunk_sent\n\n    @property\n    def on_response_chunk_received(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceResponseChunkReceivedParams]]\":\n        return self._on_response_chunk_received\n\n    @property\n    def on_request_end(self) -> \"Signal[_SignalCallback[TraceRequestEndParams]]\":\n        return self._on_request_end\n\n    @property\n    def on_request_exception(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceRequestExceptionParams]]\":\n        return self._on_request_exception\n\n    @property\n    def on_request_redirect(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceRequestRedirectParams]]\":\n        return self._on_request_redirect\n\n    @property\n    def on_connection_queued_start(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceConnectionQueuedStartParams]]\":\n        return self._on_connection_queued_start\n\n    @property\n    def on_connection_queued_end(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceConnectionQueuedEndParams]]\":\n        return self._on_connection_queued_end\n\n    @property\n    def on_connection_create_start(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceConnectionCreateStartParams]]\":\n        return self._on_connection_create_start\n\n    @property\n    def on_connection_create_end(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceConnectionCreateEndParams]]\":\n        return self._on_connection_create_end\n\n    @property\n    def on_connection_reuseconn(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceConnectionReuseconnParams]]\":\n        return self._on_connection_reuseconn\n\n    @property\n    def on_dns_resolvehost_start(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceDnsResolveHostStartParams]]\":\n        return self._on_dns_resolvehost_start\n\n    @property\n    def on_dns_resolvehost_end(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceDnsResolveHostEndParams]]\":\n        return self._on_dns_resolvehost_end\n\n    @property\n    def on_dns_cache_hit(self) -> \"Signal[_SignalCallback[TraceDnsCacheHitParams]]\":\n        return self._on_dns_cache_hit\n\n    @property\n    def on_dns_cache_miss(self) -> \"Signal[_SignalCallback[TraceDnsCacheMissParams]]\":\n        return self._on_dns_cache_miss\n\n    @property\n    def on_request_headers_sent(\n        self,\n    ) -> \"Signal[_SignalCallback[TraceRequestHeadersSentParams]]\":\n        return self._on_request_headers_sent\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceRequestStartParams:\n    \"\"\"Parameters sent by the `on_request_start` signal\"\"\"\n\n    method: str\n    url: URL\n    headers: \"CIMultiDict[str]\"\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceRequestChunkSentParams:\n    \"\"\"Parameters sent by the `on_request_chunk_sent` signal\"\"\"\n\n    method: str\n    url: URL\n    chunk: bytes\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceResponseChunkReceivedParams:\n    \"\"\"Parameters sent by the `on_response_chunk_received` signal\"\"\"\n\n    method: str\n    url: URL\n    chunk: bytes\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceRequestEndParams:\n    \"\"\"Parameters sent by the `on_request_end` signal\"\"\"\n\n    method: str\n    url: URL\n    headers: \"CIMultiDict[str]\"\n    response: ClientResponse\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceRequestExceptionParams:\n    \"\"\"Parameters sent by the `on_request_exception` signal\"\"\"\n\n    method: str\n    url: URL\n    headers: \"CIMultiDict[str]\"\n    exception: BaseException\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceRequestRedirectParams:\n    \"\"\"Parameters sent by the `on_request_redirect` signal\"\"\"\n\n    method: str\n    url: URL\n    headers: \"CIMultiDict[str]\"\n    response: ClientResponse\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceConnectionQueuedStartParams:\n    \"\"\"Parameters sent by the `on_connection_queued_start` signal\"\"\"\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceConnectionQueuedEndParams:\n    \"\"\"Parameters sent by the `on_connection_queued_end` signal\"\"\"\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceConnectionCreateStartParams:\n    \"\"\"Parameters sent by the `on_connection_create_start` signal\"\"\"\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceConnectionCreateEndParams:\n    \"\"\"Parameters sent by the `on_connection_create_end` signal\"\"\"\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceConnectionReuseconnParams:\n    \"\"\"Parameters sent by the `on_connection_reuseconn` signal\"\"\"\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceDnsResolveHostStartParams:\n    \"\"\"Parameters sent by the `on_dns_resolvehost_start` signal\"\"\"\n\n    host: str\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceDnsResolveHostEndParams:\n    \"\"\"Parameters sent by the `on_dns_resolvehost_end` signal\"\"\"\n\n    host: str\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceDnsCacheHitParams:\n    \"\"\"Parameters sent by the `on_dns_cache_hit` signal\"\"\"\n\n    host: str\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceDnsCacheMissParams:\n    \"\"\"Parameters sent by the `on_dns_cache_miss` signal\"\"\"\n\n    host: str\n\n\n@dataclasses.dataclass(frozen=True)\nclass TraceRequestHeadersSentParams:\n    \"\"\"Parameters sent by the `on_request_headers_sent` signal\"\"\"\n\n    method: str\n    url: URL\n    headers: \"CIMultiDict[str]\"\n\n\nclass Trace:\n    \"\"\"Internal dependency holder class.\n\n    Used to keep together the main dependencies used\n    at the moment of send a signal.\n    \"\"\"\n\n    def __init__(\n        self,\n        session: \"ClientSession\",\n        trace_config: TraceConfig,\n        trace_config_ctx: SimpleNamespace,\n    ) -> None:\n        self._trace_config = trace_config\n        self._trace_config_ctx = trace_config_ctx\n        self._session = session\n\n    async def send_request_start(\n        self, method: str, url: URL, headers: \"CIMultiDict[str]\"\n    ) -> None:\n        return await self._trace_config.on_request_start.send(\n            self._session,\n            self._trace_config_ctx,\n            TraceRequestStartParams(method, url, headers),\n        )\n\n    async def send_request_chunk_sent(\n        self, method: str, url: URL, chunk: bytes\n    ) -> None:\n        return await self._trace_config.on_request_chunk_sent.send(\n            self._session,\n            self._trace_config_ctx,\n            TraceRequestChunkSentParams(method, url, chunk),\n        )\n\n    async def send_response_chunk_received(\n        self, method: str, url: URL, chunk: bytes\n    ) -> None:\n        return await self._trace_config.on_response_chunk_received.send(\n            self._session,\n            self._trace_config_ctx,\n            TraceResponseChunkReceivedParams(method, url, chunk),\n        )\n\n    async def send_request_end(\n        self,\n        method: str,\n        url: URL,\n        headers: \"CIMultiDict[str]\",\n        response: ClientResponse,\n    ) -> None:\n        return await self._trace_config.on_request_end.send(\n            self._session,\n            self._trace_config_ctx,\n            TraceRequestEndParams(method, url, headers, response),\n        )\n\n    async def send_request_exception(\n        self,\n        method: str,\n        url: URL,\n        headers: \"CIMultiDict[str]\",\n        exception: BaseException,\n    ) -> None:\n        return await self._trace_config.on_request_exception.send(\n            self._session,\n            self._trace_config_ctx,\n            TraceRequestExceptionParams(method, url, headers, exception),\n        )\n\n    async def send_request_redirect(\n        self,\n        method: str,\n        url: URL,\n        headers: \"CIMultiDict[str]\",\n        response: ClientResponse,\n    ) -> None:\n        return await self._trace_config._on_request_redirect.send(\n            self._session,\n            self._trace_config_ctx,\n            TraceRequestRedirectParams(method, url, headers, response),\n        )\n\n    async def send_connection_queued_start(self) -> None:\n        return await self._trace_config.on_connection_queued_start.send(\n            self._session, self._trace_config_ctx, TraceConnectionQueuedStartParams()\n        )\n\n    async def send_connection_queued_end(self) -> None:\n        return await self._trace_config.on_connection_queued_end.send(\n            self._session, self._trace_config_ctx, TraceConnectionQueuedEndParams()\n        )\n\n    async def send_connection_create_start(self) -> None:\n        return await self._trace_config.on_connection_create_start.send(\n            self._session, self._trace_config_ctx, TraceConnectionCreateStartParams()\n        )\n\n    async def send_connection_create_end(self) -> None:\n        return await self._trace_config.on_connection_create_end.send(\n            self._session, self._trace_config_ctx, TraceConnectionCreateEndParams()\n        )\n\n    async def send_connection_reuseconn(self) -> None:\n        return await self._trace_config.on_connection_reuseconn.send(\n            self._session, self._trace_config_ctx, TraceConnectionReuseconnParams()\n        )\n\n    async def send_dns_resolvehost_start(self, host: str) -> None:\n        return await self._trace_config.on_dns_resolvehost_start.send(\n            self._session, self._trace_config_ctx, TraceDnsResolveHostStartParams(host)\n        )\n\n    async def send_dns_resolvehost_end(self, host: str) -> None:\n        return await self._trace_config.on_dns_resolvehost_end.send(\n            self._session, self._trace_config_ctx, TraceDnsResolveHostEndParams(host)\n        )\n\n    async def send_dns_cache_hit(self, host: str) -> None:\n        return await self._trace_config.on_dns_cache_hit.send(\n            self._session, self._trace_config_ctx, TraceDnsCacheHitParams(host)\n        )\n\n    async def send_dns_cache_miss(self, host: str) -> None:\n        return await self._trace_config.on_dns_cache_miss.send(\n            self._session, self._trace_config_ctx, TraceDnsCacheMissParams(host)\n        )\n\n    async def send_request_headers(\n        self, method: str, url: URL, headers: \"CIMultiDict[str]\"\n    ) -> None:\n        return await self._trace_config._on_request_headers_sent.send(\n            self._session,\n            self._trace_config_ctx,\n            TraceRequestHeadersSentParams(method, url, headers),\n        )\n", "aiohttp/log.py": "import logging\n\naccess_logger = logging.getLogger(\"aiohttp.access\")\nclient_logger = logging.getLogger(\"aiohttp.client\")\ninternal_logger = logging.getLogger(\"aiohttp.internal\")\nserver_logger = logging.getLogger(\"aiohttp.server\")\nweb_logger = logging.getLogger(\"aiohttp.web\")\nws_logger = logging.getLogger(\"aiohttp.websocket\")\n", "aiohttp/web_protocol.py": "import asyncio\nimport asyncio.streams\nimport dataclasses\nimport traceback\nfrom collections import deque\nfrom contextlib import suppress\nfrom html import escape as html_escape\nfrom http import HTTPStatus\nfrom logging import Logger\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Awaitable,\n    Callable,\n    Deque,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n    cast,\n)\n\nimport yarl\n\nfrom .abc import AbstractAccessLogger, AbstractAsyncAccessLogger, AbstractStreamWriter\nfrom .base_protocol import BaseProtocol\nfrom .helpers import ceil_timeout, set_exception\nfrom .http import (\n    HttpProcessingError,\n    HttpRequestParser,\n    HttpVersion10,\n    RawRequestMessage,\n    StreamWriter,\n)\nfrom .log import access_logger, server_logger\nfrom .streams import EMPTY_PAYLOAD, StreamReader\nfrom .tcp_helpers import tcp_keepalive\nfrom .web_exceptions import HTTPException\nfrom .web_log import AccessLogger\nfrom .web_request import BaseRequest\nfrom .web_response import Response, StreamResponse\n\n__all__ = (\"RequestHandler\", \"RequestPayloadError\", \"PayloadAccessError\")\n\nif TYPE_CHECKING:\n    from .web_server import Server\n\n\n_RequestFactory = Callable[\n    [\n        RawRequestMessage,\n        StreamReader,\n        \"RequestHandler\",\n        AbstractStreamWriter,\n        \"asyncio.Task[None]\",\n    ],\n    BaseRequest,\n]\n\n_RequestHandler = Callable[[BaseRequest], Awaitable[StreamResponse]]\n_AnyAbstractAccessLogger = Union[\n    Type[AbstractAsyncAccessLogger],\n    Type[AbstractAccessLogger],\n]\n\nERROR = RawRequestMessage(\n    \"UNKNOWN\",\n    \"/\",\n    HttpVersion10,\n    {},  # type: ignore[arg-type]\n    {},  # type: ignore[arg-type]\n    True,\n    None,\n    False,\n    False,\n    yarl.URL(\"/\"),\n)\n\n\nclass RequestPayloadError(Exception):\n    \"\"\"Payload parsing error.\"\"\"\n\n\nclass PayloadAccessError(Exception):\n    \"\"\"Payload was accessed after response was sent.\"\"\"\n\n\nclass AccessLoggerWrapper(AbstractAsyncAccessLogger):\n    \"\"\"Wrap an AbstractAccessLogger so it behaves like an AbstractAsyncAccessLogger.\"\"\"\n\n    def __init__(\n        self, access_logger: AbstractAccessLogger, loop: asyncio.AbstractEventLoop\n    ) -> None:\n        self.access_logger = access_logger\n        self._loop = loop\n        super().__init__()\n\n    async def log(\n        self, request: BaseRequest, response: StreamResponse, request_start: float\n    ) -> None:\n        self.access_logger.log(request, response, self._loop.time() - request_start)\n\n\n@dataclasses.dataclass(frozen=True)\nclass _ErrInfo:\n    status: int\n    exc: BaseException\n    message: str\n\n\n_MsgType = Tuple[Union[RawRequestMessage, _ErrInfo], StreamReader]\n\n\nclass RequestHandler(BaseProtocol):\n    \"\"\"HTTP protocol implementation.\n\n    RequestHandler handles incoming HTTP request. It reads request line,\n    request headers and request payload and calls handle_request() method.\n    By default it always returns with 404 response.\n\n    RequestHandler handles errors in incoming request, like bad\n    status line, bad headers or incomplete payload. If any error occurs,\n    connection gets closed.\n\n    keepalive_timeout -- number of seconds before closing\n                         keep-alive connection\n\n    tcp_keepalive -- TCP keep-alive is on, default is on\n\n    logger -- custom logger object\n\n    access_log_class -- custom class for access_logger\n\n    access_log -- custom logging object\n\n    access_log_format -- access log format string\n\n    loop -- Optional event loop\n\n    max_line_size -- Optional maximum header line size\n\n    max_field_size -- Optional maximum header field size\n\n    timeout_ceil_threshold -- Optional value to specify\n                              threshold to ceil() timeout\n                              values\n\n    \"\"\"\n\n    KEEPALIVE_RESCHEDULE_DELAY = 1\n\n    __slots__ = (\n        \"_request_count\",\n        \"_keepalive\",\n        \"_manager\",\n        \"_request_handler\",\n        \"_request_factory\",\n        \"_tcp_keepalive\",\n        \"_keepalive_time\",\n        \"_keepalive_handle\",\n        \"_keepalive_timeout\",\n        \"_lingering_time\",\n        \"_messages\",\n        \"_message_tail\",\n        \"_waiter\",\n        \"_task_handler\",\n        \"_upgrade\",\n        \"_payload_parser\",\n        \"_request_parser\",\n        \"logger\",\n        \"access_log\",\n        \"access_logger\",\n        \"_close\",\n        \"_force_close\",\n        \"_current_request\",\n        \"_timeout_ceil_threshold\",\n    )\n\n    def __init__(\n        self,\n        manager: \"Server\",\n        *,\n        loop: asyncio.AbstractEventLoop,\n        keepalive_timeout: float = 75.0,  # NGINX default is 75 secs\n        tcp_keepalive: bool = True,\n        logger: Logger = server_logger,\n        access_log_class: _AnyAbstractAccessLogger = AccessLogger,\n        access_log: Optional[Logger] = access_logger,\n        access_log_format: str = AccessLogger.LOG_FORMAT,\n        max_line_size: int = 8190,\n        max_field_size: int = 8190,\n        lingering_time: float = 10.0,\n        read_bufsize: int = 2**16,\n        auto_decompress: bool = True,\n        timeout_ceil_threshold: float = 5,\n    ):\n        super().__init__(loop)\n\n        self._request_count = 0\n        self._keepalive = False\n        self._current_request: Optional[BaseRequest] = None\n        self._manager: Optional[Server] = manager\n        self._request_handler: Optional[_RequestHandler] = manager.request_handler\n        self._request_factory: Optional[_RequestFactory] = manager.request_factory\n\n        self._tcp_keepalive = tcp_keepalive\n        # placeholder to be replaced on keepalive timeout setup\n        self._keepalive_time = 0.0\n        self._keepalive_handle: Optional[asyncio.Handle] = None\n        self._keepalive_timeout = keepalive_timeout\n        self._lingering_time = float(lingering_time)\n\n        self._messages: Deque[_MsgType] = deque()\n        self._message_tail = b\"\"\n\n        self._waiter: Optional[asyncio.Future[None]] = None\n        self._task_handler: Optional[asyncio.Task[None]] = None\n\n        self._upgrade = False\n        self._payload_parser: Any = None\n        self._request_parser: Optional[HttpRequestParser] = HttpRequestParser(\n            self,\n            loop,\n            read_bufsize,\n            max_line_size=max_line_size,\n            max_field_size=max_field_size,\n            payload_exception=RequestPayloadError,\n            auto_decompress=auto_decompress,\n        )\n\n        self._timeout_ceil_threshold: float = 5\n        try:\n            self._timeout_ceil_threshold = float(timeout_ceil_threshold)\n        except (TypeError, ValueError):\n            pass\n\n        self.logger = logger\n        self.access_log = access_log\n        if access_log:\n            if issubclass(access_log_class, AbstractAsyncAccessLogger):\n                self.access_logger: Optional[AbstractAsyncAccessLogger] = (\n                    access_log_class()\n                )\n            else:\n                access_logger = access_log_class(access_log, access_log_format)\n                self.access_logger = AccessLoggerWrapper(\n                    access_logger,\n                    self._loop,\n                )\n        else:\n            self.access_logger = None\n\n        self._close = False\n        self._force_close = False\n\n    def __repr__(self) -> str:\n        return \"<{} {}>\".format(\n            self.__class__.__name__,\n            \"connected\" if self.transport is not None else \"disconnected\",\n        )\n\n    @property\n    def keepalive_timeout(self) -> float:\n        return self._keepalive_timeout\n\n    async def shutdown(self, timeout: Optional[float] = 15.0) -> None:\n        \"\"\"Do worker process exit preparations.\n\n        We need to clean up everything and stop accepting requests.\n        It is especially important for keep-alive connections.\n        \"\"\"\n        self._force_close = True\n\n        if self._keepalive_handle is not None:\n            self._keepalive_handle.cancel()\n\n        if self._waiter:\n            self._waiter.cancel()\n\n        # wait for handlers\n        with suppress(asyncio.CancelledError, asyncio.TimeoutError):\n            async with ceil_timeout(timeout):\n                if self._current_request is not None:\n                    self._current_request._cancel(asyncio.CancelledError())\n\n                if self._task_handler is not None and not self._task_handler.done():\n                    await self._task_handler\n\n        # force-close non-idle handler\n        if self._task_handler is not None:\n            self._task_handler.cancel()\n\n        if self.transport is not None:\n            self.transport.close()\n            self.transport = None\n\n    def connection_made(self, transport: asyncio.BaseTransport) -> None:\n        super().connection_made(transport)\n\n        real_transport = cast(asyncio.Transport, transport)\n        if self._tcp_keepalive:\n            tcp_keepalive(real_transport)\n\n        self._task_handler = self._loop.create_task(self.start())\n        assert self._manager is not None\n        self._manager.connection_made(self, real_transport)\n\n    def connection_lost(self, exc: Optional[BaseException]) -> None:\n        if self._manager is None:\n            return\n        self._manager.connection_lost(self, exc)\n\n        super().connection_lost(exc)\n\n        # Grab value before setting _manager to None.\n        handler_cancellation = self._manager.handler_cancellation\n\n        self._manager = None\n        self._force_close = True\n        self._request_factory = None\n        self._request_handler = None\n        self._request_parser = None\n\n        if self._keepalive_handle is not None:\n            self._keepalive_handle.cancel()\n\n        if self._current_request is not None:\n            if exc is None:\n                exc = ConnectionResetError(\"Connection lost\")\n            self._current_request._cancel(exc)\n\n        if self._waiter is not None:\n            self._waiter.cancel()\n\n        if handler_cancellation and self._task_handler is not None:\n            self._task_handler.cancel()\n\n        self._task_handler = None\n\n        if self._payload_parser is not None:\n            self._payload_parser.feed_eof()\n            self._payload_parser = None\n\n    def set_parser(self, parser: Any) -> None:\n        # Actual type is WebReader\n        assert self._payload_parser is None\n\n        self._payload_parser = parser\n\n        if self._message_tail:\n            self._payload_parser.feed_data(self._message_tail)\n            self._message_tail = b\"\"\n\n    def eof_received(self) -> None:\n        pass\n\n    def data_received(self, data: bytes) -> None:\n        if self._force_close or self._close:\n            return\n        # parse http messages\n        messages: Sequence[_MsgType]\n        if self._payload_parser is None and not self._upgrade:\n            assert self._request_parser is not None\n            try:\n                messages, upgraded, tail = self._request_parser.feed_data(data)\n            except HttpProcessingError as exc:\n                messages = [\n                    (_ErrInfo(status=400, exc=exc, message=exc.message), EMPTY_PAYLOAD)\n                ]\n                upgraded = False\n                tail = b\"\"\n\n            for msg, payload in messages or ():\n                self._request_count += 1\n                self._messages.append((msg, payload))\n\n            waiter = self._waiter\n            if messages and waiter is not None and not waiter.done():\n                # don't set result twice\n                waiter.set_result(None)\n\n            self._upgrade = upgraded\n            if upgraded and tail:\n                self._message_tail = tail\n\n        # no parser, just store\n        elif self._payload_parser is None and self._upgrade and data:\n            self._message_tail += data\n\n        # feed payload\n        elif data:\n            eof, tail = self._payload_parser.feed_data(data)\n            if eof:\n                self.close()\n\n    def keep_alive(self, val: bool) -> None:\n        \"\"\"Set keep-alive connection mode.\n\n        :param bool val: new state.\n        \"\"\"\n        self._keepalive = val\n        if self._keepalive_handle:\n            self._keepalive_handle.cancel()\n            self._keepalive_handle = None\n\n    def close(self) -> None:\n        \"\"\"Close connection.\n\n        Stop accepting new pipelining messages and close\n        connection when handlers done processing messages.\n        \"\"\"\n        self._close = True\n        if self._waiter:\n            self._waiter.cancel()\n\n    def force_close(self) -> None:\n        \"\"\"Forcefully close connection.\"\"\"\n        self._force_close = True\n        if self._waiter:\n            self._waiter.cancel()\n        if self.transport is not None:\n            self.transport.close()\n            self.transport = None\n\n    async def log_access(\n        self, request: BaseRequest, response: StreamResponse, request_start: float\n    ) -> None:\n        if self.access_logger is not None:\n            await self.access_logger.log(request, response, request_start)\n\n    def log_debug(self, *args: Any, **kw: Any) -> None:\n        if self._loop.get_debug():\n            self.logger.debug(*args, **kw)\n\n    def log_exception(self, *args: Any, **kw: Any) -> None:\n        self.logger.exception(*args, **kw)\n\n    def _process_keepalive(self) -> None:\n        if self._force_close or not self._keepalive:\n            return\n\n        next = self._keepalive_time + self._keepalive_timeout\n\n        # handler in idle state\n        if self._waiter:\n            if self._loop.time() > next:\n                self.force_close()\n                return\n\n        # not all request handlers are done,\n        # reschedule itself to next second\n        self._keepalive_handle = self._loop.call_later(\n            self.KEEPALIVE_RESCHEDULE_DELAY,\n            self._process_keepalive,\n        )\n\n    async def _handle_request(\n        self,\n        request: BaseRequest,\n        start_time: float,\n        request_handler: Callable[[BaseRequest], Awaitable[StreamResponse]],\n    ) -> Tuple[StreamResponse, bool]:\n        assert self._request_handler is not None\n        try:\n            try:\n                self._current_request = request\n                resp = await request_handler(request)\n            finally:\n                self._current_request = None\n        except HTTPException as exc:\n            resp = Response(\n                status=exc.status, reason=exc.reason, text=exc.text, headers=exc.headers\n            )\n            resp._cookies = exc._cookies\n            reset = await self.finish_response(request, resp, start_time)\n        except asyncio.CancelledError:\n            raise\n        except asyncio.TimeoutError as exc:\n            self.log_debug(\"Request handler timed out.\", exc_info=exc)\n            resp = self.handle_error(request, 504)\n            reset = await self.finish_response(request, resp, start_time)\n        except Exception as exc:\n            resp = self.handle_error(request, 500, exc)\n            reset = await self.finish_response(request, resp, start_time)\n        else:\n            reset = await self.finish_response(request, resp, start_time)\n\n        return resp, reset\n\n    async def start(self) -> None:\n        \"\"\"Process incoming request.\n\n        It reads request line, request headers and request payload, then\n        calls handle_request() method. Subclass has to override\n        handle_request(). start() handles various exceptions in request\n        or response handling. Connection is being closed always unless\n        keep_alive(True) specified.\n        \"\"\"\n        loop = self._loop\n        handler = self._task_handler\n        assert handler is not None\n        manager = self._manager\n        assert manager is not None\n        keepalive_timeout = self._keepalive_timeout\n        resp = None\n        assert self._request_factory is not None\n        assert self._request_handler is not None\n\n        while not self._force_close:\n            if not self._messages:\n                try:\n                    # wait for next request\n                    self._waiter = loop.create_future()\n                    await self._waiter\n                except asyncio.CancelledError:\n                    break\n                finally:\n                    self._waiter = None\n\n            message, payload = self._messages.popleft()\n\n            start = loop.time()\n\n            manager.requests_count += 1\n            writer = StreamWriter(self, loop)\n            if isinstance(message, _ErrInfo):\n                # make request_factory work\n                request_handler = self._make_error_handler(message)\n                message = ERROR\n            else:\n                request_handler = self._request_handler\n\n            request = self._request_factory(message, payload, self, writer, handler)\n            try:\n                # a new task is used for copy context vars (#3406)\n                task = self._loop.create_task(\n                    self._handle_request(request, start, request_handler)\n                )\n                try:\n                    resp, reset = await task\n                except (asyncio.CancelledError, ConnectionError):\n                    self.log_debug(\"Ignored premature client disconnection\")\n                    break\n\n                # Drop the processed task from asyncio.Task.all_tasks() early\n                del task\n                # https://github.com/python/mypy/issues/14309\n                if reset:  # type: ignore[possibly-undefined]\n                    self.log_debug(\"Ignored premature client disconnection 2\")\n                    break\n\n                # notify server about keep-alive\n                self._keepalive = bool(resp.keep_alive)\n\n                # check payload\n                if not payload.is_eof():\n                    lingering_time = self._lingering_time\n                    # Could be force closed while awaiting above tasks.\n                    if not self._force_close and lingering_time:  # type: ignore[redundant-expr]\n                        self.log_debug(\n                            \"Start lingering close timer for %s sec.\", lingering_time\n                        )\n\n                        now = loop.time()\n                        end_t = now + lingering_time\n\n                        with suppress(asyncio.TimeoutError, asyncio.CancelledError):\n                            while not payload.is_eof() and now < end_t:\n                                async with ceil_timeout(end_t - now):\n                                    # read and ignore\n                                    await payload.readany()\n                                now = loop.time()\n\n                    # if payload still uncompleted\n                    if not payload.is_eof() and not self._force_close:\n                        self.log_debug(\"Uncompleted request.\")\n                        self.close()\n\n                set_exception(payload, PayloadAccessError())\n\n            except asyncio.CancelledError:\n                self.log_debug(\"Ignored premature client disconnection \")\n                break\n            except RuntimeError as exc:\n                if self._loop.get_debug():\n                    self.log_exception(\"Unhandled runtime exception\", exc_info=exc)\n                self.force_close()\n            except Exception as exc:\n                self.log_exception(\"Unhandled exception\", exc_info=exc)\n                self.force_close()\n            finally:\n                if self.transport is None and resp is not None:\n                    self.log_debug(\"Ignored premature client disconnection.\")\n                elif not self._force_close:\n                    if self._keepalive and not self._close:\n                        # start keep-alive timer\n                        if keepalive_timeout is not None:\n                            now = self._loop.time()\n                            self._keepalive_time = now\n                            if self._keepalive_handle is None:\n                                self._keepalive_handle = loop.call_at(\n                                    now + keepalive_timeout, self._process_keepalive\n                                )\n                    else:\n                        break\n\n        # remove handler, close transport if no handlers left\n        if not self._force_close:\n            self._task_handler = None\n            if self.transport is not None:\n                self.transport.close()\n\n    async def finish_response(\n        self, request: BaseRequest, resp: StreamResponse, start_time: float\n    ) -> bool:\n        \"\"\"Prepare the response and write_eof, then log access.\n\n        This has to\n        be called within the context of any exception so the access logger\n        can get exception information. Returns True if the client disconnects\n        prematurely.\n        \"\"\"\n        request._finish()\n        if self._request_parser is not None:\n            self._request_parser.set_upgraded(False)\n            self._upgrade = False\n            if self._message_tail:\n                self._request_parser.feed_data(self._message_tail)\n                self._message_tail = b\"\"\n        try:\n            prepare_meth = resp.prepare\n        except AttributeError:\n            if resp is None:\n                raise RuntimeError(\"Missing return \" \"statement on request handler\")\n            else:\n                raise RuntimeError(\n                    \"Web-handler should return \"\n                    \"a response instance, \"\n                    \"got {!r}\".format(resp)\n                )\n        try:\n            await prepare_meth(request)\n            await resp.write_eof()\n        except ConnectionError:\n            await self.log_access(request, resp, start_time)\n            return True\n        else:\n            await self.log_access(request, resp, start_time)\n            return False\n\n    def handle_error(\n        self,\n        request: BaseRequest,\n        status: int = 500,\n        exc: Optional[BaseException] = None,\n        message: Optional[str] = None,\n    ) -> StreamResponse:\n        \"\"\"Handle errors.\n\n        Returns HTTP response with specific status code. Logs additional\n        information. It always closes current connection.\n        \"\"\"\n        self.log_exception(\"Error handling request\", exc_info=exc)\n\n        # some data already got sent, connection is broken\n        if request.writer.output_size > 0:\n            raise ConnectionError(\n                \"Response is sent already, cannot send another response \"\n                \"with the error message\"\n            )\n\n        ct = \"text/plain\"\n        if status == HTTPStatus.INTERNAL_SERVER_ERROR:\n            title = \"{0.value} {0.phrase}\".format(HTTPStatus.INTERNAL_SERVER_ERROR)\n            msg = HTTPStatus.INTERNAL_SERVER_ERROR.description\n            tb = None\n            if self._loop.get_debug():\n                with suppress(Exception):\n                    tb = traceback.format_exc()\n\n            if \"text/html\" in request.headers.get(\"Accept\", \"\"):\n                if tb:\n                    tb = html_escape(tb)\n                    msg = f\"<h2>Traceback:</h2>\\n<pre>{tb}</pre>\"\n                message = (\n                    \"<html><head>\"\n                    \"<title>{title}</title>\"\n                    \"</head><body>\\n<h1>{title}</h1>\"\n                    \"\\n{msg}\\n</body></html>\\n\"\n                ).format(title=title, msg=msg)\n                ct = \"text/html\"\n            else:\n                if tb:\n                    msg = tb\n                message = title + \"\\n\\n\" + msg\n\n        resp = Response(status=status, text=message, content_type=ct)\n        resp.force_close()\n\n        return resp\n\n    def _make_error_handler(\n        self, err_info: _ErrInfo\n    ) -> Callable[[BaseRequest], Awaitable[StreamResponse]]:\n        async def handler(request: BaseRequest) -> StreamResponse:\n            return self.handle_error(\n                request, err_info.status, err_info.exc, err_info.message\n            )\n\n        return handler\n", "aiohttp/web_urldispatcher.py": "import abc\nimport asyncio\nimport base64\nimport functools\nimport hashlib\nimport html\nimport keyword\nimport os\nimport re\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom types import MappingProxyType\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Awaitable,\n    Callable,\n    Container,\n    Dict,\n    Final,\n    Generator,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    NoReturn,\n    Optional,\n    Pattern,\n    Set,\n    Sized,\n    Tuple,\n    Type,\n    TypedDict,\n    Union,\n    cast,\n)\n\nfrom yarl import URL, __version__ as yarl_version  # type: ignore[attr-defined]\n\nfrom . import hdrs\nfrom .abc import AbstractMatchInfo, AbstractRouter, AbstractView\nfrom .helpers import DEBUG\nfrom .http import HttpVersion11\nfrom .typedefs import Handler, PathLike\nfrom .web_exceptions import (\n    HTTPException,\n    HTTPExpectationFailed,\n    HTTPForbidden,\n    HTTPMethodNotAllowed,\n    HTTPNotFound,\n)\nfrom .web_fileresponse import FileResponse\nfrom .web_request import Request\nfrom .web_response import Response, StreamResponse\nfrom .web_routedef import AbstractRouteDef\n\n__all__ = (\n    \"UrlDispatcher\",\n    \"UrlMappingMatchInfo\",\n    \"AbstractResource\",\n    \"Resource\",\n    \"PlainResource\",\n    \"DynamicResource\",\n    \"AbstractRoute\",\n    \"ResourceRoute\",\n    \"StaticResource\",\n    \"View\",\n)\n\n\nif TYPE_CHECKING:\n    from .web_app import Application\n\n    BaseDict = Dict[str, str]\nelse:\n    BaseDict = dict\n\nYARL_VERSION: Final[Tuple[int, ...]] = tuple(map(int, yarl_version.split(\".\")[:2]))\n\nHTTP_METHOD_RE: Final[Pattern[str]] = re.compile(\n    r\"^[0-9A-Za-z!#\\$%&'\\*\\+\\-\\.\\^_`\\|~]+$\"\n)\nROUTE_RE: Final[Pattern[str]] = re.compile(\n    r\"(\\{[_a-zA-Z][^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\})\"\n)\nPATH_SEP: Final[str] = re.escape(\"/\")\n\n\n_ExpectHandler = Callable[[Request], Awaitable[Optional[StreamResponse]]]\n_Resolve = Tuple[Optional[\"UrlMappingMatchInfo\"], Set[str]]\n\nhtml_escape = functools.partial(html.escape, quote=True)\n\n\nclass _InfoDict(TypedDict, total=False):\n    path: str\n\n    formatter: str\n    pattern: Pattern[str]\n\n    directory: Path\n    prefix: str\n    routes: Mapping[str, \"AbstractRoute\"]\n\n    app: \"Application\"\n\n    domain: str\n\n    rule: \"AbstractRuleMatching\"\n\n    http_exception: HTTPException\n\n\nclass AbstractResource(Sized, Iterable[\"AbstractRoute\"]):\n    def __init__(self, *, name: Optional[str] = None) -> None:\n        self._name = name\n\n    @property\n    def name(self) -> Optional[str]:\n        return self._name\n\n    @property\n    @abc.abstractmethod\n    def canonical(self) -> str:\n        \"\"\"Exposes the resource's canonical path.\n\n        For example '/foo/bar/{name}'\n\n        \"\"\"\n\n    @abc.abstractmethod  # pragma: no branch\n    def url_for(self, **kwargs: str) -> URL:\n        \"\"\"Construct url for resource with additional params.\"\"\"\n\n    @abc.abstractmethod  # pragma: no branch\n    async def resolve(self, request: Request) -> _Resolve:\n        \"\"\"Resolve resource.\n\n        Return (UrlMappingMatchInfo, allowed_methods) pair.\n        \"\"\"\n\n    @abc.abstractmethod\n    def add_prefix(self, prefix: str) -> None:\n        \"\"\"Add a prefix to processed URLs.\n\n        Required for subapplications support.\n        \"\"\"\n\n    @abc.abstractmethod\n    def get_info(self) -> _InfoDict:\n        \"\"\"Return a dict with additional info useful for introspection\"\"\"\n\n    def freeze(self) -> None:\n        pass\n\n    @abc.abstractmethod\n    def raw_match(self, path: str) -> bool:\n        \"\"\"Perform a raw match against path\"\"\"\n\n\nclass AbstractRoute(abc.ABC):\n    def __init__(\n        self,\n        method: str,\n        handler: Union[Handler, Type[AbstractView]],\n        *,\n        expect_handler: Optional[_ExpectHandler] = None,\n        resource: Optional[AbstractResource] = None,\n    ) -> None:\n        if expect_handler is None:\n            expect_handler = _default_expect_handler\n\n        assert asyncio.iscoroutinefunction(\n            expect_handler\n        ), f\"Coroutine is expected, got {expect_handler!r}\"\n\n        method = method.upper()\n        if not HTTP_METHOD_RE.match(method):\n            raise ValueError(f\"{method} is not allowed HTTP method\")\n\n        if asyncio.iscoroutinefunction(handler):\n            pass\n        elif isinstance(handler, type) and issubclass(handler, AbstractView):\n            pass\n        else:\n            raise TypeError(\n                \"Only async functions are allowed as web-handlers \"\n                \", got {!r}\".format(handler)\n            )\n\n        self._method = method\n        self._handler = handler\n        self._expect_handler = expect_handler\n        self._resource = resource\n\n    @property\n    def method(self) -> str:\n        return self._method\n\n    @property\n    def handler(self) -> Handler:\n        return self._handler\n\n    @property\n    @abc.abstractmethod\n    def name(self) -> Optional[str]:\n        \"\"\"Optional route's name, always equals to resource's name.\"\"\"\n\n    @property\n    def resource(self) -> Optional[AbstractResource]:\n        return self._resource\n\n    @abc.abstractmethod\n    def get_info(self) -> _InfoDict:\n        \"\"\"Return a dict with additional info useful for introspection\"\"\"\n\n    @abc.abstractmethod  # pragma: no branch\n    def url_for(self, *args: str, **kwargs: str) -> URL:\n        \"\"\"Construct url for route with additional params.\"\"\"\n\n    async def handle_expect_header(self, request: Request) -> Optional[StreamResponse]:\n        return await self._expect_handler(request)\n\n\nclass UrlMappingMatchInfo(BaseDict, AbstractMatchInfo):\n    def __init__(self, match_dict: Dict[str, str], route: AbstractRoute):\n        super().__init__(match_dict)\n        self._route = route\n        self._apps: List[Application] = []\n        self._current_app: Optional[Application] = None\n        self._frozen = False\n\n    @property\n    def handler(self) -> Handler:\n        return self._route.handler\n\n    @property\n    def route(self) -> AbstractRoute:\n        return self._route\n\n    @property\n    def expect_handler(self) -> _ExpectHandler:\n        return self._route.handle_expect_header\n\n    @property\n    def http_exception(self) -> Optional[HTTPException]:\n        return None\n\n    def get_info(self) -> _InfoDict:  # type: ignore[override]\n        return self._route.get_info()\n\n    @property\n    def apps(self) -> Tuple[\"Application\", ...]:\n        return tuple(self._apps)\n\n    def add_app(self, app: \"Application\") -> None:\n        if self._frozen:\n            raise RuntimeError(\"Cannot change apps stack after .freeze() call\")\n        if self._current_app is None:\n            self._current_app = app\n        self._apps.insert(0, app)\n\n    @property\n    def current_app(self) -> \"Application\":\n        app = self._current_app\n        assert app is not None\n        return app\n\n    @contextmanager\n    def set_current_app(self, app: \"Application\") -> Generator[None, None, None]:\n        if DEBUG:  # pragma: no cover\n            if app not in self._apps:\n                raise RuntimeError(\n                    \"Expected one of the following apps {!r}, got {!r}\".format(\n                        self._apps, app\n                    )\n                )\n        prev = self._current_app\n        self._current_app = app\n        try:\n            yield\n        finally:\n            self._current_app = prev\n\n    def freeze(self) -> None:\n        self._frozen = True\n\n    def __repr__(self) -> str:\n        return f\"<MatchInfo {super().__repr__()}: {self._route}>\"\n\n\nclass MatchInfoError(UrlMappingMatchInfo):\n    def __init__(self, http_exception: HTTPException) -> None:\n        self._exception = http_exception\n        super().__init__({}, SystemRoute(self._exception))\n\n    @property\n    def http_exception(self) -> HTTPException:\n        return self._exception\n\n    def __repr__(self) -> str:\n        return \"<MatchInfoError {}: {}>\".format(\n            self._exception.status, self._exception.reason\n        )\n\n\nasync def _default_expect_handler(request: Request) -> None:\n    \"\"\"Default handler for Expect header.\n\n    Just send \"100 Continue\" to client.\n    raise HTTPExpectationFailed if value of header is not \"100-continue\"\n    \"\"\"\n    expect = request.headers.get(hdrs.EXPECT, \"\")\n    if request.version == HttpVersion11:\n        if expect.lower() == \"100-continue\":\n            await request.writer.write(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n        else:\n            raise HTTPExpectationFailed(text=\"Unknown Expect: %s\" % expect)\n\n\nclass Resource(AbstractResource):\n    def __init__(self, *, name: Optional[str] = None) -> None:\n        super().__init__(name=name)\n        self._routes: List[ResourceRoute] = []\n\n    def add_route(\n        self,\n        method: str,\n        handler: Union[Type[AbstractView], Handler],\n        *,\n        expect_handler: Optional[_ExpectHandler] = None,\n    ) -> \"ResourceRoute\":\n        for route_obj in self._routes:\n            if route_obj.method == method or route_obj.method == hdrs.METH_ANY:\n                raise RuntimeError(\n                    \"Added route will never be executed, \"\n                    \"method {route.method} is already \"\n                    \"registered\".format(route=route_obj)\n                )\n\n        route_obj = ResourceRoute(method, handler, self, expect_handler=expect_handler)\n        self.register_route(route_obj)\n        return route_obj\n\n    def register_route(self, route: \"ResourceRoute\") -> None:\n        assert isinstance(\n            route, ResourceRoute\n        ), f\"Instance of Route class is required, got {route!r}\"\n        self._routes.append(route)\n\n    async def resolve(self, request: Request) -> _Resolve:\n        allowed_methods: Set[str] = set()\n\n        match_dict = self._match(request.rel_url.raw_path)\n        if match_dict is None:\n            return None, allowed_methods\n\n        for route_obj in self._routes:\n            route_method = route_obj.method\n            allowed_methods.add(route_method)\n\n            if route_method == request.method or route_method == hdrs.METH_ANY:\n                return (UrlMappingMatchInfo(match_dict, route_obj), allowed_methods)\n        else:\n            return None, allowed_methods\n\n    @abc.abstractmethod\n    def _match(self, path: str) -> Optional[Dict[str, str]]:\n        pass  # pragma: no cover\n\n    def __len__(self) -> int:\n        return len(self._routes)\n\n    def __iter__(self) -> Iterator[\"ResourceRoute\"]:\n        return iter(self._routes)\n\n    # TODO: implement all abstract methods\n\n\nclass PlainResource(Resource):\n    def __init__(self, path: str, *, name: Optional[str] = None) -> None:\n        super().__init__(name=name)\n        assert not path or path.startswith(\"/\")\n        self._path = path\n\n    @property\n    def canonical(self) -> str:\n        return self._path\n\n    def freeze(self) -> None:\n        if not self._path:\n            self._path = \"/\"\n\n    def add_prefix(self, prefix: str) -> None:\n        assert prefix.startswith(\"/\")\n        assert not prefix.endswith(\"/\")\n        assert len(prefix) > 1\n        self._path = prefix + self._path\n\n    def _match(self, path: str) -> Optional[Dict[str, str]]:\n        # string comparison is about 10 times faster than regexp matching\n        if self._path == path:\n            return {}\n        else:\n            return None\n\n    def raw_match(self, path: str) -> bool:\n        return self._path == path\n\n    def get_info(self) -> _InfoDict:\n        return {\"path\": self._path}\n\n    def url_for(self) -> URL:  # type: ignore[override]\n        return URL.build(path=self._path, encoded=True)\n\n    def __repr__(self) -> str:\n        name = \"'\" + self.name + \"' \" if self.name is not None else \"\"\n        return f\"<PlainResource {name} {self._path}>\"\n\n\nclass DynamicResource(Resource):\n    DYN = re.compile(r\"\\{(?P<var>[_a-zA-Z][_a-zA-Z0-9]*)\\}\")\n    DYN_WITH_RE = re.compile(r\"\\{(?P<var>[_a-zA-Z][_a-zA-Z0-9]*):(?P<re>.+)\\}\")\n    GOOD = r\"[^{}/]+\"\n\n    def __init__(self, path: str, *, name: Optional[str] = None) -> None:\n        super().__init__(name=name)\n        pattern = \"\"\n        formatter = \"\"\n        for part in ROUTE_RE.split(path):\n            match = self.DYN.fullmatch(part)\n            if match:\n                pattern += \"(?P<{}>{})\".format(match.group(\"var\"), self.GOOD)\n                formatter += \"{\" + match.group(\"var\") + \"}\"\n                continue\n\n            match = self.DYN_WITH_RE.fullmatch(part)\n            if match:\n                pattern += \"(?P<{var}>{re})\".format(**match.groupdict())\n                formatter += \"{\" + match.group(\"var\") + \"}\"\n                continue\n\n            if \"{\" in part or \"}\" in part:\n                raise ValueError(f\"Invalid path '{path}'['{part}']\")\n\n            part = _requote_path(part)\n            formatter += part\n            pattern += re.escape(part)\n\n        try:\n            compiled = re.compile(pattern)\n        except re.error as exc:\n            raise ValueError(f\"Bad pattern '{pattern}': {exc}\") from None\n        assert compiled.pattern.startswith(PATH_SEP)\n        assert formatter.startswith(\"/\")\n        self._pattern = compiled\n        self._formatter = formatter\n\n    @property\n    def canonical(self) -> str:\n        return self._formatter\n\n    def add_prefix(self, prefix: str) -> None:\n        assert prefix.startswith(\"/\")\n        assert not prefix.endswith(\"/\")\n        assert len(prefix) > 1\n        self._pattern = re.compile(re.escape(prefix) + self._pattern.pattern)\n        self._formatter = prefix + self._formatter\n\n    def _match(self, path: str) -> Optional[Dict[str, str]]:\n        match = self._pattern.fullmatch(path)\n        if match is None:\n            return None\n        else:\n            return {\n                key: _unquote_path(value) for key, value in match.groupdict().items()\n            }\n\n    def raw_match(self, path: str) -> bool:\n        return self._formatter == path\n\n    def get_info(self) -> _InfoDict:\n        return {\"formatter\": self._formatter, \"pattern\": self._pattern}\n\n    def url_for(self, **parts: str) -> URL:\n        url = self._formatter.format_map({k: _quote_path(v) for k, v in parts.items()})\n        return URL.build(path=url, encoded=True)\n\n    def __repr__(self) -> str:\n        name = \"'\" + self.name + \"' \" if self.name is not None else \"\"\n        return \"<DynamicResource {name} {formatter}>\".format(\n            name=name, formatter=self._formatter\n        )\n\n\nclass PrefixResource(AbstractResource):\n    def __init__(self, prefix: str, *, name: Optional[str] = None) -> None:\n        assert not prefix or prefix.startswith(\"/\"), prefix\n        assert prefix in (\"\", \"/\") or not prefix.endswith(\"/\"), prefix\n        super().__init__(name=name)\n        self._prefix = _requote_path(prefix)\n        self._prefix2 = self._prefix + \"/\"\n\n    @property\n    def canonical(self) -> str:\n        return self._prefix\n\n    def add_prefix(self, prefix: str) -> None:\n        assert prefix.startswith(\"/\")\n        assert not prefix.endswith(\"/\")\n        assert len(prefix) > 1\n        self._prefix = prefix + self._prefix\n        self._prefix2 = self._prefix + \"/\"\n\n    def raw_match(self, prefix: str) -> bool:\n        return False\n\n    # TODO: impl missing abstract methods\n\n\nclass StaticResource(PrefixResource):\n    VERSION_KEY = \"v\"\n\n    def __init__(\n        self,\n        prefix: str,\n        directory: PathLike,\n        *,\n        name: Optional[str] = None,\n        expect_handler: Optional[_ExpectHandler] = None,\n        chunk_size: int = 256 * 1024,\n        show_index: bool = False,\n        follow_symlinks: bool = False,\n        append_version: bool = False,\n    ) -> None:\n        super().__init__(prefix, name=name)\n        try:\n            directory = Path(directory)\n            if str(directory).startswith(\"~\"):\n                directory = Path(os.path.expanduser(str(directory)))\n            directory = directory.resolve()\n            if not directory.is_dir():\n                raise ValueError(\"Not a directory\")\n        except (FileNotFoundError, ValueError) as error:\n            raise ValueError(f\"No directory exists at '{directory}'\") from error\n        self._directory = directory\n        self._show_index = show_index\n        self._chunk_size = chunk_size\n        self._follow_symlinks = follow_symlinks\n        self._expect_handler = expect_handler\n        self._append_version = append_version\n\n        self._routes = {\n            \"GET\": ResourceRoute(\n                \"GET\", self._handle, self, expect_handler=expect_handler\n            ),\n            \"HEAD\": ResourceRoute(\n                \"HEAD\", self._handle, self, expect_handler=expect_handler\n            ),\n        }\n\n    def url_for(  # type: ignore[override]\n        self,\n        *,\n        filename: PathLike,\n        append_version: Optional[bool] = None,\n    ) -> URL:\n        if append_version is None:\n            append_version = self._append_version\n        filename = str(filename).lstrip(\"/\")\n\n        url = URL.build(path=self._prefix, encoded=True)\n        # filename is not encoded\n        if YARL_VERSION < (1, 6):\n            url = url / filename.replace(\"%\", \"%25\")\n        else:\n            url = url / filename\n\n        if append_version:\n            unresolved_path = self._directory.joinpath(filename)\n            try:\n                if self._follow_symlinks:\n                    normalized_path = Path(os.path.normpath(unresolved_path))\n                    normalized_path.relative_to(self._directory)\n                    filepath = normalized_path.resolve()\n                else:\n                    filepath = unresolved_path.resolve()\n                    filepath.relative_to(self._directory)\n            except (ValueError, FileNotFoundError):\n                # ValueError for case when path point to symlink\n                # with follow_symlinks is False\n                return url  # relatively safe\n            if filepath.is_file():\n                # TODO cache file content\n                # with file watcher for cache invalidation\n                with filepath.open(\"rb\") as f:\n                    file_bytes = f.read()\n                h = self._get_file_hash(file_bytes)\n                url = url.with_query({self.VERSION_KEY: h})\n                return url\n        return url\n\n    @staticmethod\n    def _get_file_hash(byte_array: bytes) -> str:\n        m = hashlib.sha256()  # todo sha256 can be configurable param\n        m.update(byte_array)\n        b64 = base64.urlsafe_b64encode(m.digest())\n        return b64.decode(\"ascii\")\n\n    def get_info(self) -> _InfoDict:\n        return {\n            \"directory\": self._directory,\n            \"prefix\": self._prefix,\n            \"routes\": self._routes,\n        }\n\n    def set_options_route(self, handler: Handler) -> None:\n        if \"OPTIONS\" in self._routes:\n            raise RuntimeError(\"OPTIONS route was set already\")\n        self._routes[\"OPTIONS\"] = ResourceRoute(\n            \"OPTIONS\", handler, self, expect_handler=self._expect_handler\n        )\n\n    async def resolve(self, request: Request) -> _Resolve:\n        path = request.rel_url.raw_path\n        method = request.method\n        allowed_methods = set(self._routes)\n        if not path.startswith(self._prefix2) and path != self._prefix:\n            return None, set()\n\n        if method not in allowed_methods:\n            return None, allowed_methods\n\n        match_dict = {\"filename\": _unquote_path(path[len(self._prefix) + 1 :])}\n        return (UrlMappingMatchInfo(match_dict, self._routes[method]), allowed_methods)\n\n    def __len__(self) -> int:\n        return len(self._routes)\n\n    def __iter__(self) -> Iterator[AbstractRoute]:\n        return iter(self._routes.values())\n\n    async def _handle(self, request: Request) -> StreamResponse:\n        rel_url = request.match_info[\"filename\"]\n        try:\n            filename = Path(rel_url)\n            if filename.anchor:\n                # rel_url is an absolute name like\n                # /static/\\\\machine_name\\c$ or /static/D:\\path\n                # where the static dir is totally different\n                raise HTTPForbidden()\n            unresolved_path = self._directory.joinpath(filename)\n            if self._follow_symlinks:\n                normalized_path = Path(os.path.normpath(unresolved_path))\n                normalized_path.relative_to(self._directory)\n                filepath = normalized_path.resolve()\n            else:\n                filepath = unresolved_path.resolve()\n                filepath.relative_to(self._directory)\n        except (ValueError, FileNotFoundError) as error:\n            # relatively safe\n            raise HTTPNotFound() from error\n        except HTTPForbidden:\n            raise\n        except Exception as error:\n            # perm error or other kind!\n            request.app.logger.exception(error)\n            raise HTTPNotFound() from error\n\n        # on opening a dir, load its contents if allowed\n        if filepath.is_dir():\n            if self._show_index:\n                try:\n                    return Response(\n                        text=self._directory_as_html(filepath), content_type=\"text/html\"\n                    )\n                except PermissionError:\n                    raise HTTPForbidden()\n            else:\n                raise HTTPForbidden()\n        elif filepath.is_file():\n            return FileResponse(filepath, chunk_size=self._chunk_size)\n        else:\n            raise HTTPNotFound\n\n    def _directory_as_html(self, filepath: Path) -> str:\n        # returns directory's index as html\n\n        # sanity check\n        assert filepath.is_dir()\n\n        relative_path_to_dir = filepath.relative_to(self._directory).as_posix()\n        index_of = f\"Index of /{html_escape(relative_path_to_dir)}\"\n        h1 = f\"<h1>{index_of}</h1>\"\n\n        index_list = []\n        dir_index = filepath.iterdir()\n        for _file in sorted(dir_index):\n            # show file url as relative to static path\n            rel_path = _file.relative_to(self._directory).as_posix()\n            quoted_file_url = _quote_path(f\"{self._prefix}/{rel_path}\")\n\n            # if file is a directory, add '/' to the end of the name\n            if _file.is_dir():\n                file_name = f\"{_file.name}/\"\n            else:\n                file_name = _file.name\n\n            index_list.append(\n                f'<li><a href=\"{quoted_file_url}\">{html_escape(file_name)}</a></li>'\n            )\n        ul = \"<ul>\\n{}\\n</ul>\".format(\"\\n\".join(index_list))\n        body = f\"<body>\\n{h1}\\n{ul}\\n</body>\"\n\n        head_str = f\"<head>\\n<title>{index_of}</title>\\n</head>\"\n        html = f\"<html>\\n{head_str}\\n{body}\\n</html>\"\n\n        return html\n\n    def __repr__(self) -> str:\n        name = \"'\" + self.name + \"'\" if self.name is not None else \"\"\n        return \"<StaticResource {name} {path} -> {directory!r}>\".format(\n            name=name, path=self._prefix, directory=self._directory\n        )\n\n\nclass PrefixedSubAppResource(PrefixResource):\n    def __init__(self, prefix: str, app: \"Application\") -> None:\n        super().__init__(prefix)\n        self._app = app\n        self._add_prefix_to_resources(prefix)\n\n    def add_prefix(self, prefix: str) -> None:\n        super().add_prefix(prefix)\n        self._add_prefix_to_resources(prefix)\n\n    def _add_prefix_to_resources(self, prefix: str) -> None:\n        router = self._app.router\n        for resource in router.resources():\n            # Since the canonical path of a resource is about\n            # to change, we need to unindex it and then reindex\n            router.unindex_resource(resource)\n            resource.add_prefix(prefix)\n            router.index_resource(resource)\n\n    def url_for(self, *args: str, **kwargs: str) -> URL:\n        raise RuntimeError(\".url_for() is not supported \" \"by sub-application root\")\n\n    def get_info(self) -> _InfoDict:\n        return {\"app\": self._app, \"prefix\": self._prefix}\n\n    async def resolve(self, request: Request) -> _Resolve:\n        match_info = await self._app.router.resolve(request)\n        match_info.add_app(self._app)\n        if isinstance(match_info.http_exception, HTTPMethodNotAllowed):\n            methods = match_info.http_exception.allowed_methods\n        else:\n            methods = set()\n        return match_info, methods\n\n    def __len__(self) -> int:\n        return len(self._app.router.routes())\n\n    def __iter__(self) -> Iterator[AbstractRoute]:\n        return iter(self._app.router.routes())\n\n    def __repr__(self) -> str:\n        return \"<PrefixedSubAppResource {prefix} -> {app!r}>\".format(\n            prefix=self._prefix, app=self._app\n        )\n\n\nclass AbstractRuleMatching(abc.ABC):\n    @abc.abstractmethod  # pragma: no branch\n    async def match(self, request: Request) -> bool:\n        \"\"\"Return bool if the request satisfies the criteria\"\"\"\n\n    @abc.abstractmethod  # pragma: no branch\n    def get_info(self) -> _InfoDict:\n        \"\"\"Return a dict with additional info useful for introspection\"\"\"\n\n    @property\n    @abc.abstractmethod  # pragma: no branch\n    def canonical(self) -> str:\n        \"\"\"Return a str\"\"\"\n\n\nclass Domain(AbstractRuleMatching):\n    re_part = re.compile(r\"(?!-)[a-z\\d-]{1,63}(?<!-)\")\n\n    def __init__(self, domain: str) -> None:\n        super().__init__()\n        self._domain = self.validation(domain)\n\n    @property\n    def canonical(self) -> str:\n        return self._domain\n\n    def validation(self, domain: str) -> str:\n        if not isinstance(domain, str):\n            raise TypeError(\"Domain must be str\")\n        domain = domain.rstrip(\".\").lower()\n        if not domain:\n            raise ValueError(\"Domain cannot be empty\")\n        elif \"://\" in domain:\n            raise ValueError(\"Scheme not supported\")\n        url = URL(\"http://\" + domain)\n        assert url.raw_host is not None\n        if not all(self.re_part.fullmatch(x) for x in url.raw_host.split(\".\")):\n            raise ValueError(\"Domain not valid\")\n        if url.port == 80:\n            return url.raw_host\n        return f\"{url.raw_host}:{url.port}\"\n\n    async def match(self, request: Request) -> bool:\n        host = request.headers.get(hdrs.HOST)\n        if not host:\n            return False\n        return self.match_domain(host)\n\n    def match_domain(self, host: str) -> bool:\n        return host.lower() == self._domain\n\n    def get_info(self) -> _InfoDict:\n        return {\"domain\": self._domain}\n\n\nclass MaskDomain(Domain):\n    re_part = re.compile(r\"(?!-)[a-z\\d\\*-]{1,63}(?<!-)\")\n\n    def __init__(self, domain: str) -> None:\n        super().__init__(domain)\n        mask = self._domain.replace(\".\", r\"\\.\").replace(\"*\", \".*\")\n        self._mask = re.compile(mask)\n\n    @property\n    def canonical(self) -> str:\n        return self._mask.pattern\n\n    def match_domain(self, host: str) -> bool:\n        return self._mask.fullmatch(host) is not None\n\n\nclass MatchedSubAppResource(PrefixedSubAppResource):\n    def __init__(self, rule: AbstractRuleMatching, app: \"Application\") -> None:\n        AbstractResource.__init__(self)\n        self._prefix = \"\"\n        self._app = app\n        self._rule = rule\n\n    @property\n    def canonical(self) -> str:\n        return self._rule.canonical\n\n    def get_info(self) -> _InfoDict:\n        return {\"app\": self._app, \"rule\": self._rule}\n\n    async def resolve(self, request: Request) -> _Resolve:\n        if not await self._rule.match(request):\n            return None, set()\n        match_info = await self._app.router.resolve(request)\n        match_info.add_app(self._app)\n        if isinstance(match_info.http_exception, HTTPMethodNotAllowed):\n            methods = match_info.http_exception.allowed_methods\n        else:\n            methods = set()\n        return match_info, methods\n\n    def __repr__(self) -> str:\n        return \"<MatchedSubAppResource -> {app!r}>\" \"\".format(app=self._app)\n\n\nclass ResourceRoute(AbstractRoute):\n    \"\"\"A route with resource\"\"\"\n\n    def __init__(\n        self,\n        method: str,\n        handler: Union[Handler, Type[AbstractView]],\n        resource: AbstractResource,\n        *,\n        expect_handler: Optional[_ExpectHandler] = None,\n    ) -> None:\n        super().__init__(\n            method, handler, expect_handler=expect_handler, resource=resource\n        )\n\n    def __repr__(self) -> str:\n        return \"<ResourceRoute [{method}] {resource} -> {handler!r}\".format(\n            method=self.method, resource=self._resource, handler=self.handler\n        )\n\n    @property\n    def name(self) -> Optional[str]:\n        if self._resource is None:\n            return None\n        return self._resource.name\n\n    def url_for(self, *args: str, **kwargs: str) -> URL:\n        \"\"\"Construct url for route with additional params.\"\"\"\n        assert self._resource is not None\n        return self._resource.url_for(*args, **kwargs)\n\n    def get_info(self) -> _InfoDict:\n        assert self._resource is not None\n        return self._resource.get_info()\n\n\nclass SystemRoute(AbstractRoute):\n    def __init__(self, http_exception: HTTPException) -> None:\n        super().__init__(hdrs.METH_ANY, self._handle)\n        self._http_exception = http_exception\n\n    def url_for(self, *args: str, **kwargs: str) -> URL:\n        raise RuntimeError(\".url_for() is not allowed for SystemRoute\")\n\n    @property\n    def name(self) -> Optional[str]:\n        return None\n\n    def get_info(self) -> _InfoDict:\n        return {\"http_exception\": self._http_exception}\n\n    async def _handle(self, request: Request) -> StreamResponse:\n        raise self._http_exception\n\n    @property\n    def status(self) -> int:\n        return self._http_exception.status\n\n    @property\n    def reason(self) -> str:\n        return self._http_exception.reason\n\n    def __repr__(self) -> str:\n        return \"<SystemRoute {self.status}: {self.reason}>\".format(self=self)\n\n\nclass View(AbstractView):\n    async def _iter(self) -> StreamResponse:\n        if self.request.method not in hdrs.METH_ALL:\n            self._raise_allowed_methods()\n        method: Optional[Callable[[], Awaitable[StreamResponse]]] = getattr(\n            self, self.request.method.lower(), None\n        )\n        if method is None:\n            self._raise_allowed_methods()\n        return await method()\n\n    def __await__(self) -> Generator[Any, None, StreamResponse]:\n        return self._iter().__await__()\n\n    def _raise_allowed_methods(self) -> NoReturn:\n        allowed_methods = {m for m in hdrs.METH_ALL if hasattr(self, m.lower())}\n        raise HTTPMethodNotAllowed(self.request.method, allowed_methods)\n\n\nclass ResourcesView(Sized, Iterable[AbstractResource], Container[AbstractResource]):\n    def __init__(self, resources: List[AbstractResource]) -> None:\n        self._resources = resources\n\n    def __len__(self) -> int:\n        return len(self._resources)\n\n    def __iter__(self) -> Iterator[AbstractResource]:\n        yield from self._resources\n\n    def __contains__(self, resource: object) -> bool:\n        return resource in self._resources\n\n\nclass RoutesView(Sized, Iterable[AbstractRoute], Container[AbstractRoute]):\n    def __init__(self, resources: List[AbstractResource]):\n        self._routes: List[AbstractRoute] = []\n        for resource in resources:\n            for route in resource:\n                self._routes.append(route)\n\n    def __len__(self) -> int:\n        return len(self._routes)\n\n    def __iter__(self) -> Iterator[AbstractRoute]:\n        yield from self._routes\n\n    def __contains__(self, route: object) -> bool:\n        return route in self._routes\n\n\nclass UrlDispatcher(AbstractRouter, Mapping[str, AbstractResource]):\n    NAME_SPLIT_RE = re.compile(r\"[.:-]\")\n    HTTP_NOT_FOUND = HTTPNotFound()\n\n    def __init__(self) -> None:\n        super().__init__()\n        self._resources: List[AbstractResource] = []\n        self._named_resources: Dict[str, AbstractResource] = {}\n        self._resource_index: dict[str, list[AbstractResource]] = {}\n        self._matched_sub_app_resources: List[MatchedSubAppResource] = []\n\n    async def resolve(self, request: Request) -> UrlMappingMatchInfo:\n        resource_index = self._resource_index\n        allowed_methods: Set[str] = set()\n\n        # Walk the url parts looking for candidates. We walk the url backwards\n        # to ensure the most explicit match is found first. If there are multiple\n        # candidates for a given url part because there are multiple resources\n        # registered for the same canonical path, we resolve them in a linear\n        # fashion to ensure registration order is respected.\n        url_part = request.rel_url.raw_path\n        while url_part:\n            for candidate in resource_index.get(url_part, ()):\n                match_dict, allowed = await candidate.resolve(request)\n                if match_dict is not None:\n                    return match_dict\n                else:\n                    allowed_methods |= allowed\n            if url_part == \"/\":\n                break\n            url_part = url_part.rpartition(\"/\")[0] or \"/\"\n\n        #\n        # We didn't find any candidates, so we'll try the matched sub-app\n        # resources which we have to walk in a linear fashion because they\n        # have regex/wildcard match rules and we cannot index them.\n        #\n        # For most cases we do not expect there to be many of these since\n        # currently they are only added by `add_domain`\n        #\n        for resource in self._matched_sub_app_resources:\n            match_dict, allowed = await resource.resolve(request)\n            if match_dict is not None:\n                return match_dict\n            else:\n                allowed_methods |= allowed\n\n        if allowed_methods:\n            return MatchInfoError(HTTPMethodNotAllowed(request.method, allowed_methods))\n\n        return MatchInfoError(self.HTTP_NOT_FOUND)\n\n    def __iter__(self) -> Iterator[str]:\n        return iter(self._named_resources)\n\n    def __len__(self) -> int:\n        return len(self._named_resources)\n\n    def __contains__(self, resource: object) -> bool:\n        return resource in self._named_resources\n\n    def __getitem__(self, name: str) -> AbstractResource:\n        return self._named_resources[name]\n\n    def resources(self) -> ResourcesView:\n        return ResourcesView(self._resources)\n\n    def routes(self) -> RoutesView:\n        return RoutesView(self._resources)\n\n    def named_resources(self) -> Mapping[str, AbstractResource]:\n        return MappingProxyType(self._named_resources)\n\n    def register_resource(self, resource: AbstractResource) -> None:\n        assert isinstance(\n            resource, AbstractResource\n        ), f\"Instance of AbstractResource class is required, got {resource!r}\"\n        if self.frozen:\n            raise RuntimeError(\"Cannot register a resource into frozen router.\")\n\n        name = resource.name\n\n        if name is not None:\n            parts = self.NAME_SPLIT_RE.split(name)\n            for part in parts:\n                if keyword.iskeyword(part):\n                    raise ValueError(\n                        f\"Incorrect route name {name!r}, \"\n                        \"python keywords cannot be used \"\n                        \"for route name\"\n                    )\n                if not part.isidentifier():\n                    raise ValueError(\n                        \"Incorrect route name {!r}, \"\n                        \"the name should be a sequence of \"\n                        \"python identifiers separated \"\n                        \"by dash, dot or column\".format(name)\n                    )\n            if name in self._named_resources:\n                raise ValueError(\n                    \"Duplicate {!r}, \"\n                    \"already handled by {!r}\".format(name, self._named_resources[name])\n                )\n            self._named_resources[name] = resource\n        self._resources.append(resource)\n\n        if isinstance(resource, MatchedSubAppResource):\n            # We cannot index match sub-app resources because they have match rules\n            self._matched_sub_app_resources.append(resource)\n        else:\n            self.index_resource(resource)\n\n    def _get_resource_index_key(self, resource: AbstractResource) -> str:\n        \"\"\"Return a key to index the resource in the resource index.\"\"\"\n        # strip at the first { to allow for variables\n        return resource.canonical.partition(\"{\")[0].rstrip(\"/\") or \"/\"\n\n    def index_resource(self, resource: AbstractResource) -> None:\n        \"\"\"Add a resource to the resource index.\"\"\"\n        resource_key = self._get_resource_index_key(resource)\n        # There may be multiple resources for a canonical path\n        # so we keep them in a list to ensure that registration\n        # order is respected.\n        self._resource_index.setdefault(resource_key, []).append(resource)\n\n    def unindex_resource(self, resource: AbstractResource) -> None:\n        \"\"\"Remove a resource from the resource index.\"\"\"\n        resource_key = self._get_resource_index_key(resource)\n        self._resource_index[resource_key].remove(resource)\n\n    def add_resource(self, path: str, *, name: Optional[str] = None) -> Resource:\n        if path and not path.startswith(\"/\"):\n            raise ValueError(\"path should be started with / or be empty\")\n        # Reuse last added resource if path and name are the same\n        if self._resources:\n            resource = self._resources[-1]\n            if resource.name == name and resource.raw_match(path):\n                return cast(Resource, resource)\n        if not (\"{\" in path or \"}\" in path or ROUTE_RE.search(path)):\n            resource = PlainResource(_requote_path(path), name=name)\n            self.register_resource(resource)\n            return resource\n        resource = DynamicResource(path, name=name)\n        self.register_resource(resource)\n        return resource\n\n    def add_route(\n        self,\n        method: str,\n        path: str,\n        handler: Union[Handler, Type[AbstractView]],\n        *,\n        name: Optional[str] = None,\n        expect_handler: Optional[_ExpectHandler] = None,\n    ) -> AbstractRoute:\n        resource = self.add_resource(path, name=name)\n        return resource.add_route(method, handler, expect_handler=expect_handler)\n\n    def add_static(\n        self,\n        prefix: str,\n        path: PathLike,\n        *,\n        name: Optional[str] = None,\n        expect_handler: Optional[_ExpectHandler] = None,\n        chunk_size: int = 256 * 1024,\n        show_index: bool = False,\n        follow_symlinks: bool = False,\n        append_version: bool = False,\n    ) -> AbstractResource:\n        \"\"\"Add static files view.\n\n        prefix - url prefix\n        path - folder with files\n\n        \"\"\"\n        assert prefix.startswith(\"/\")\n        if prefix.endswith(\"/\"):\n            prefix = prefix[:-1]\n        resource = StaticResource(\n            prefix,\n            path,\n            name=name,\n            expect_handler=expect_handler,\n            chunk_size=chunk_size,\n            show_index=show_index,\n            follow_symlinks=follow_symlinks,\n            append_version=append_version,\n        )\n        self.register_resource(resource)\n        return resource\n\n    def add_head(self, path: str, handler: Handler, **kwargs: Any) -> AbstractRoute:\n        \"\"\"Shortcut for add_route with method HEAD.\"\"\"\n        return self.add_route(hdrs.METH_HEAD, path, handler, **kwargs)\n\n    def add_options(self, path: str, handler: Handler, **kwargs: Any) -> AbstractRoute:\n        \"\"\"Shortcut for add_route with method OPTIONS.\"\"\"\n        return self.add_route(hdrs.METH_OPTIONS, path, handler, **kwargs)\n\n    def add_get(\n        self,\n        path: str,\n        handler: Handler,\n        *,\n        name: Optional[str] = None,\n        allow_head: bool = True,\n        **kwargs: Any,\n    ) -> AbstractRoute:\n        \"\"\"Shortcut for add_route with method GET.\n\n        If allow_head is true, another\n        route is added allowing head requests to the same endpoint.\n        \"\"\"\n        resource = self.add_resource(path, name=name)\n        if allow_head:\n            resource.add_route(hdrs.METH_HEAD, handler, **kwargs)\n        return resource.add_route(hdrs.METH_GET, handler, **kwargs)\n\n    def add_post(self, path: str, handler: Handler, **kwargs: Any) -> AbstractRoute:\n        \"\"\"Shortcut for add_route with method POST.\"\"\"\n        return self.add_route(hdrs.METH_POST, path, handler, **kwargs)\n\n    def add_put(self, path: str, handler: Handler, **kwargs: Any) -> AbstractRoute:\n        \"\"\"Shortcut for add_route with method PUT.\"\"\"\n        return self.add_route(hdrs.METH_PUT, path, handler, **kwargs)\n\n    def add_patch(self, path: str, handler: Handler, **kwargs: Any) -> AbstractRoute:\n        \"\"\"Shortcut for add_route with method PATCH.\"\"\"\n        return self.add_route(hdrs.METH_PATCH, path, handler, **kwargs)\n\n    def add_delete(self, path: str, handler: Handler, **kwargs: Any) -> AbstractRoute:\n        \"\"\"Shortcut for add_route with method DELETE.\"\"\"\n        return self.add_route(hdrs.METH_DELETE, path, handler, **kwargs)\n\n    def add_view(\n        self, path: str, handler: Type[AbstractView], **kwargs: Any\n    ) -> AbstractRoute:\n        \"\"\"Shortcut for add_route with ANY methods for a class-based view.\"\"\"\n        return self.add_route(hdrs.METH_ANY, path, handler, **kwargs)\n\n    def freeze(self) -> None:\n        super().freeze()\n        for resource in self._resources:\n            resource.freeze()\n\n    def add_routes(self, routes: Iterable[AbstractRouteDef]) -> List[AbstractRoute]:\n        \"\"\"Append routes to route table.\n\n        Parameter should be a sequence of RouteDef objects.\n\n        Returns a list of registered AbstractRoute instances.\n        \"\"\"\n        registered_routes = []\n        for route_def in routes:\n            registered_routes.extend(route_def.register(self))\n        return registered_routes\n\n\ndef _quote_path(value: str) -> str:\n    if YARL_VERSION < (1, 6):\n        value = value.replace(\"%\", \"%25\")\n    return URL.build(path=value, encoded=False).raw_path\n\n\ndef _unquote_path(value: str) -> str:\n    return URL.build(path=value, encoded=True).path\n\n\ndef _requote_path(value: str) -> str:\n    # Quote non-ascii characters and other characters which must be quoted,\n    # but preserve existing %-sequences.\n    result = _quote_path(value)\n    if \"%\" in value:\n        result = result.replace(\"%25\", \"%\")\n    return result\n", "aiohttp/multipart.py": "import base64\nimport binascii\nimport json\nimport re\nimport uuid\nimport warnings\nimport zlib\nfrom collections import deque\nfrom types import TracebackType\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    AsyncIterator,\n    Deque,\n    Dict,\n    Iterator,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n    cast,\n)\nfrom urllib.parse import parse_qsl, unquote, urlencode\n\nfrom multidict import CIMultiDict, CIMultiDictProxy\n\nfrom .compression_utils import ZLibCompressor, ZLibDecompressor\nfrom .hdrs import (\n    CONTENT_DISPOSITION,\n    CONTENT_ENCODING,\n    CONTENT_LENGTH,\n    CONTENT_TRANSFER_ENCODING,\n    CONTENT_TYPE,\n)\nfrom .helpers import CHAR, TOKEN, parse_mimetype, reify\nfrom .http import HeadersParser\nfrom .payload import (\n    JsonPayload,\n    LookupError,\n    Order,\n    Payload,\n    StringPayload,\n    get_payload,\n    payload_type,\n)\nfrom .streams import StreamReader\n\n__all__ = (\n    \"MultipartReader\",\n    \"MultipartWriter\",\n    \"BodyPartReader\",\n    \"BadContentDispositionHeader\",\n    \"BadContentDispositionParam\",\n    \"parse_content_disposition\",\n    \"content_disposition_filename\",\n)\n\n\nif TYPE_CHECKING:\n    from .client_reqrep import ClientResponse\n\n\nclass BadContentDispositionHeader(RuntimeWarning):\n    pass\n\n\nclass BadContentDispositionParam(RuntimeWarning):\n    pass\n\n\ndef parse_content_disposition(\n    header: Optional[str],\n) -> Tuple[Optional[str], Dict[str, str]]:\n    def is_token(string: str) -> bool:\n        return bool(string) and TOKEN >= set(string)\n\n    def is_quoted(string: str) -> bool:\n        return string[0] == string[-1] == '\"'\n\n    def is_rfc5987(string: str) -> bool:\n        return is_token(string) and string.count(\"'\") == 2\n\n    def is_extended_param(string: str) -> bool:\n        return string.endswith(\"*\")\n\n    def is_continuous_param(string: str) -> bool:\n        pos = string.find(\"*\") + 1\n        if not pos:\n            return False\n        substring = string[pos:-1] if string.endswith(\"*\") else string[pos:]\n        return substring.isdigit()\n\n    def unescape(text: str, *, chars: str = \"\".join(map(re.escape, CHAR))) -> str:\n        return re.sub(f\"\\\\\\\\([{chars}])\", \"\\\\1\", text)\n\n    if not header:\n        return None, {}\n\n    disptype, *parts = header.split(\";\")\n    if not is_token(disptype):\n        warnings.warn(BadContentDispositionHeader(header))\n        return None, {}\n\n    params: Dict[str, str] = {}\n    while parts:\n        item = parts.pop(0)\n\n        if \"=\" not in item:\n            warnings.warn(BadContentDispositionHeader(header))\n            return None, {}\n\n        key, value = item.split(\"=\", 1)\n        key = key.lower().strip()\n        value = value.lstrip()\n\n        if key in params:\n            warnings.warn(BadContentDispositionHeader(header))\n            return None, {}\n\n        if not is_token(key):\n            warnings.warn(BadContentDispositionParam(item))\n            continue\n\n        elif is_continuous_param(key):\n            if is_quoted(value):\n                value = unescape(value[1:-1])\n            elif not is_token(value):\n                warnings.warn(BadContentDispositionParam(item))\n                continue\n\n        elif is_extended_param(key):\n            if is_rfc5987(value):\n                encoding, _, value = value.split(\"'\", 2)\n                encoding = encoding or \"utf-8\"\n            else:\n                warnings.warn(BadContentDispositionParam(item))\n                continue\n\n            try:\n                value = unquote(value, encoding, \"strict\")\n            except UnicodeDecodeError:  # pragma: nocover\n                warnings.warn(BadContentDispositionParam(item))\n                continue\n\n        else:\n            failed = True\n            if is_quoted(value):\n                failed = False\n                value = unescape(value[1:-1].lstrip(\"\\\\/\"))\n            elif is_token(value):\n                failed = False\n            elif parts:\n                # maybe just ; in filename, in any case this is just\n                # one case fix, for proper fix we need to redesign parser\n                _value = f\"{value};{parts[0]}\"\n                if is_quoted(_value):\n                    parts.pop(0)\n                    value = unescape(_value[1:-1].lstrip(\"\\\\/\"))\n                    failed = False\n\n            if failed:\n                warnings.warn(BadContentDispositionHeader(header))\n                return None, {}\n\n        params[key] = value\n\n    return disptype.lower(), params\n\n\ndef content_disposition_filename(\n    params: Mapping[str, str], name: str = \"filename\"\n) -> Optional[str]:\n    name_suf = \"%s*\" % name\n    if not params:\n        return None\n    elif name_suf in params:\n        return params[name_suf]\n    elif name in params:\n        return params[name]\n    else:\n        parts = []\n        fnparams = sorted(\n            (key, value) for key, value in params.items() if key.startswith(name_suf)\n        )\n        for num, (key, value) in enumerate(fnparams):\n            _, tail = key.split(\"*\", 1)\n            if tail.endswith(\"*\"):\n                tail = tail[:-1]\n            if tail == str(num):\n                parts.append(value)\n            else:\n                break\n        if not parts:\n            return None\n        value = \"\".join(parts)\n        if \"'\" in value:\n            encoding, _, value = value.split(\"'\", 2)\n            encoding = encoding or \"utf-8\"\n            return unquote(value, encoding, \"strict\")\n        return value\n\n\nclass MultipartResponseWrapper:\n    \"\"\"Wrapper around the MultipartReader.\n\n    It takes care about\n    underlying connection and close it when it needs in.\n    \"\"\"\n\n    def __init__(\n        self,\n        resp: \"ClientResponse\",\n        stream: \"MultipartReader\",\n    ) -> None:\n        self.resp = resp\n        self.stream = stream\n\n    def __aiter__(self) -> \"MultipartResponseWrapper\":\n        return self\n\n    async def __anext__(\n        self,\n    ) -> Union[\"MultipartReader\", \"BodyPartReader\"]:\n        part = await self.next()\n        if part is None:\n            raise StopAsyncIteration\n        return part\n\n    def at_eof(self) -> bool:\n        \"\"\"Returns True when all response data had been read.\"\"\"\n        return self.resp.content.at_eof()\n\n    async def next(\n        self,\n    ) -> Optional[Union[\"MultipartReader\", \"BodyPartReader\"]]:\n        \"\"\"Emits next multipart reader object.\"\"\"\n        item = await self.stream.next()\n        if self.stream.at_eof():\n            await self.release()\n        return item\n\n    async def release(self) -> None:\n        \"\"\"Release the connection gracefully.\n\n        All remaining content is read to the void.\n        \"\"\"\n        await self.resp.release()\n\n\nclass BodyPartReader:\n    \"\"\"Multipart reader for single body part.\"\"\"\n\n    chunk_size = 8192\n\n    def __init__(\n        self,\n        boundary: bytes,\n        headers: \"CIMultiDictProxy[str]\",\n        content: StreamReader,\n        *,\n        subtype: str = \"mixed\",\n        default_charset: Optional[str] = None,\n    ) -> None:\n        self.headers = headers\n        self._boundary = boundary\n        self._content = content\n        self._default_charset = default_charset\n        self._at_eof = False\n        self._is_form_data = subtype == \"form-data\"\n        # https://datatracker.ietf.org/doc/html/rfc7578#section-4.8\n        length = None if self._is_form_data else self.headers.get(CONTENT_LENGTH, None)\n        self._length = int(length) if length is not None else None\n        self._read_bytes = 0\n        self._unread: Deque[bytes] = deque()\n        self._prev_chunk: Optional[bytes] = None\n        self._content_eof = 0\n        self._cache: Dict[str, Any] = {}\n\n    def __aiter__(self) -> AsyncIterator[\"BodyPartReader\"]:\n        return self  # type: ignore[return-value]\n\n    async def __anext__(self) -> bytes:\n        part = await self.next()\n        if part is None:\n            raise StopAsyncIteration\n        return part\n\n    async def next(self) -> Optional[bytes]:\n        item = await self.read()\n        if not item:\n            return None\n        return item\n\n    async def read(self, *, decode: bool = False) -> bytes:\n        \"\"\"Reads body part data.\n\n        decode: Decodes data following by encoding\n                method from Content-Encoding header. If it missed\n                data remains untouched\n        \"\"\"\n        if self._at_eof:\n            return b\"\"\n        data = bytearray()\n        while not self._at_eof:\n            data.extend(await self.read_chunk(self.chunk_size))\n        if decode:\n            return self.decode(data)\n        return data\n\n    async def read_chunk(self, size: int = chunk_size) -> bytes:\n        \"\"\"Reads body part content chunk of the specified size.\n\n        size: chunk size\n        \"\"\"\n        if self._at_eof:\n            return b\"\"\n        if self._length:\n            chunk = await self._read_chunk_from_length(size)\n        else:\n            chunk = await self._read_chunk_from_stream(size)\n\n        # For the case of base64 data, we must read a fragment of size with a\n        # remainder of 0 by dividing by 4 for string without symbols \\n or \\r\n        encoding = self.headers.get(CONTENT_TRANSFER_ENCODING)\n        if encoding and encoding.lower() == \"base64\":\n            stripped_chunk = b\"\".join(chunk.split())\n            remainder = len(stripped_chunk) % 4\n\n            while remainder != 0 and not self.at_eof():\n                over_chunk_size = 4 - remainder\n                over_chunk = b\"\"\n\n                if self._prev_chunk:\n                    over_chunk = self._prev_chunk[:over_chunk_size]\n                    self._prev_chunk = self._prev_chunk[len(over_chunk) :]\n\n                if len(over_chunk) != over_chunk_size:\n                    over_chunk += await self._content.read(4 - len(over_chunk))\n\n                if not over_chunk:\n                    self._at_eof = True\n\n                stripped_chunk += b\"\".join(over_chunk.split())\n                chunk += over_chunk\n                remainder = len(stripped_chunk) % 4\n\n        self._read_bytes += len(chunk)\n        if self._read_bytes == self._length:\n            self._at_eof = True\n        if self._at_eof:\n            clrf = await self._content.readline()\n            assert (\n                b\"\\r\\n\" == clrf\n            ), \"reader did not read all the data or it is malformed\"\n        return chunk\n\n    async def _read_chunk_from_length(self, size: int) -> bytes:\n        # Reads body part content chunk of the specified size.\n        # The body part must has Content-Length header with proper value.\n        assert self._length is not None, \"Content-Length required for chunked read\"\n        chunk_size = min(size, self._length - self._read_bytes)\n        chunk = await self._content.read(chunk_size)\n        if self._content.at_eof():\n            self._at_eof = True\n        return chunk\n\n    async def _read_chunk_from_stream(self, size: int) -> bytes:\n        # Reads content chunk of body part with unknown length.\n        # The Content-Length header for body part is not necessary.\n        assert (\n            size >= len(self._boundary) + 2\n        ), \"Chunk size must be greater or equal than boundary length + 2\"\n        first_chunk = self._prev_chunk is None\n        if first_chunk:\n            self._prev_chunk = await self._content.read(size)\n\n        chunk = await self._content.read(size)\n        self._content_eof += int(self._content.at_eof())\n        assert self._content_eof < 3, \"Reading after EOF\"\n        assert self._prev_chunk is not None\n        window = self._prev_chunk + chunk\n        sub = b\"\\r\\n\" + self._boundary\n        if first_chunk:\n            idx = window.find(sub)\n        else:\n            idx = window.find(sub, max(0, len(self._prev_chunk) - len(sub)))\n        if idx >= 0:\n            # pushing boundary back to content\n            with warnings.catch_warnings():\n                warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n                self._content.unread_data(window[idx:])\n            if size > idx:\n                self._prev_chunk = self._prev_chunk[:idx]\n            chunk = window[len(self._prev_chunk) : idx]\n            if not chunk:\n                self._at_eof = True\n        result = self._prev_chunk\n        self._prev_chunk = chunk\n        return result\n\n    async def readline(self) -> bytes:\n        \"\"\"Reads body part by line by line.\"\"\"\n        if self._at_eof:\n            return b\"\"\n\n        if self._unread:\n            line = self._unread.popleft()\n        else:\n            line = await self._content.readline()\n\n        if line.startswith(self._boundary):\n            # the very last boundary may not come with \\r\\n,\n            # so set single rules for everyone\n            sline = line.rstrip(b\"\\r\\n\")\n            boundary = self._boundary\n            last_boundary = self._boundary + b\"--\"\n            # ensure that we read exactly the boundary, not something alike\n            if sline == boundary or sline == last_boundary:\n                self._at_eof = True\n                self._unread.append(line)\n                return b\"\"\n        else:\n            next_line = await self._content.readline()\n            if next_line.startswith(self._boundary):\n                line = line[:-2]  # strip CRLF but only once\n            self._unread.append(next_line)\n\n        return line\n\n    async def release(self) -> None:\n        \"\"\"Like read(), but reads all the data to the void.\"\"\"\n        if self._at_eof:\n            return\n        while not self._at_eof:\n            await self.read_chunk(self.chunk_size)\n\n    async def text(self, *, encoding: Optional[str] = None) -> str:\n        \"\"\"Like read(), but assumes that body part contains text data.\"\"\"\n        data = await self.read(decode=True)\n        # see https://www.w3.org/TR/html5/forms.html#multipart/form-data-encoding-algorithm\n        # and https://dvcs.w3.org/hg/xhr/raw-file/tip/Overview.html#dom-xmlhttprequest-send\n        encoding = encoding or self.get_charset(default=\"utf-8\")\n        return data.decode(encoding)\n\n    async def json(self, *, encoding: Optional[str] = None) -> Optional[Dict[str, Any]]:\n        \"\"\"Like read(), but assumes that body parts contains JSON data.\"\"\"\n        data = await self.read(decode=True)\n        if not data:\n            return None\n        encoding = encoding or self.get_charset(default=\"utf-8\")\n        return cast(Dict[str, Any], json.loads(data.decode(encoding)))\n\n    async def form(self, *, encoding: Optional[str] = None) -> List[Tuple[str, str]]:\n        \"\"\"Like read(), but assumes that body parts contain form urlencoded data.\"\"\"\n        data = await self.read(decode=True)\n        if not data:\n            return []\n        if encoding is not None:\n            real_encoding = encoding\n        else:\n            real_encoding = self.get_charset(default=\"utf-8\")\n        try:\n            decoded_data = data.rstrip().decode(real_encoding)\n        except UnicodeDecodeError:\n            raise ValueError(\"data cannot be decoded with %s encoding\" % real_encoding)\n\n        return parse_qsl(\n            decoded_data,\n            keep_blank_values=True,\n            encoding=real_encoding,\n        )\n\n    def at_eof(self) -> bool:\n        \"\"\"Returns True if the boundary was reached or False otherwise.\"\"\"\n        return self._at_eof\n\n    def decode(self, data: bytes) -> bytes:\n        \"\"\"Decodes data.\n\n        Decoding is done according the specified Content-Encoding\n        or Content-Transfer-Encoding headers value.\n        \"\"\"\n        if CONTENT_TRANSFER_ENCODING in self.headers:\n            data = self._decode_content_transfer(data)\n        # https://datatracker.ietf.org/doc/html/rfc7578#section-4.8\n        if not self._is_form_data and CONTENT_ENCODING in self.headers:\n            return self._decode_content(data)\n        return data\n\n    def _decode_content(self, data: bytes) -> bytes:\n        encoding = self.headers.get(CONTENT_ENCODING, \"\").lower()\n        if encoding == \"identity\":\n            return data\n        if encoding in {\"deflate\", \"gzip\"}:\n            return ZLibDecompressor(\n                encoding=encoding,\n                suppress_deflate_header=True,\n            ).decompress_sync(data)\n\n        raise RuntimeError(f\"unknown content encoding: {encoding}\")\n\n    def _decode_content_transfer(self, data: bytes) -> bytes:\n        encoding = self.headers.get(CONTENT_TRANSFER_ENCODING, \"\").lower()\n\n        if encoding == \"base64\":\n            return base64.b64decode(data)\n        elif encoding == \"quoted-printable\":\n            return binascii.a2b_qp(data)\n        elif encoding in (\"binary\", \"8bit\", \"7bit\"):\n            return data\n        else:\n            raise RuntimeError(\n                \"unknown content transfer encoding: {}\" \"\".format(encoding)\n            )\n\n    def get_charset(self, default: str) -> str:\n        \"\"\"Returns charset parameter from Content-Type header or default.\"\"\"\n        ctype = self.headers.get(CONTENT_TYPE, \"\")\n        mimetype = parse_mimetype(ctype)\n        return mimetype.parameters.get(\"charset\", self._default_charset or default)\n\n    @reify\n    def name(self) -> Optional[str]:\n        \"\"\"Returns name specified in Content-Disposition header.\n\n        If the header is missing or malformed, returns None.\n        \"\"\"\n        _, params = parse_content_disposition(self.headers.get(CONTENT_DISPOSITION))\n        return content_disposition_filename(params, \"name\")\n\n    @reify\n    def filename(self) -> Optional[str]:\n        \"\"\"Returns filename specified in Content-Disposition header.\n\n        Returns None if the header is missing or malformed.\n        \"\"\"\n        _, params = parse_content_disposition(self.headers.get(CONTENT_DISPOSITION))\n        return content_disposition_filename(params, \"filename\")\n\n\n@payload_type(BodyPartReader, order=Order.try_first)\nclass BodyPartReaderPayload(Payload):\n    def __init__(self, value: BodyPartReader, *args: Any, **kwargs: Any) -> None:\n        super().__init__(value, *args, **kwargs)\n\n        params: Dict[str, str] = {}\n        if value.name is not None:\n            params[\"name\"] = value.name\n        if value.filename is not None:\n            params[\"filename\"] = value.filename\n\n        if params:\n            self.set_content_disposition(\"attachment\", True, **params)\n\n    async def write(self, writer: Any) -> None:\n        field = self._value\n        chunk = await field.read_chunk(size=2**16)\n        while chunk:\n            await writer.write(field.decode(chunk))\n            chunk = await field.read_chunk(size=2**16)\n\n\nclass MultipartReader:\n    \"\"\"Multipart body reader.\"\"\"\n\n    #: Response wrapper, used when multipart readers constructs from response.\n    response_wrapper_cls = MultipartResponseWrapper\n    #: Multipart reader class, used to handle multipart/* body parts.\n    #: None points to type(self)\n    multipart_reader_cls = None\n    #: Body part reader class for non multipart/* content types.\n    part_reader_cls = BodyPartReader\n\n    def __init__(self, headers: Mapping[str, str], content: StreamReader) -> None:\n        self._mimetype = parse_mimetype(headers[CONTENT_TYPE])\n        assert self._mimetype.type == \"multipart\", \"multipart/* content type expected\"\n        if \"boundary\" not in self._mimetype.parameters:\n            raise ValueError(\n                \"boundary missed for Content-Type: %s\" % headers[CONTENT_TYPE]\n            )\n\n        self.headers = headers\n        self._boundary = (\"--\" + self._get_boundary()).encode()\n        self._content = content\n        self._default_charset: Optional[str] = None\n        self._last_part: Optional[Union[\"MultipartReader\", BodyPartReader]] = None\n        self._at_eof = False\n        self._at_bof = True\n        self._unread: List[bytes] = []\n\n    def __aiter__(\n        self,\n    ) -> AsyncIterator[\"BodyPartReader\"]:\n        return self  # type: ignore[return-value]\n\n    async def __anext__(\n        self,\n    ) -> Optional[Union[\"MultipartReader\", BodyPartReader]]:\n        part = await self.next()\n        if part is None:\n            raise StopAsyncIteration\n        return part\n\n    @classmethod\n    def from_response(\n        cls,\n        response: \"ClientResponse\",\n    ) -> MultipartResponseWrapper:\n        \"\"\"Constructs reader instance from HTTP response.\n\n        :param response: :class:`~aiohttp.client.ClientResponse` instance\n        \"\"\"\n        obj = cls.response_wrapper_cls(\n            response, cls(response.headers, response.content)\n        )\n        return obj\n\n    def at_eof(self) -> bool:\n        \"\"\"Returns True if the final boundary was reached, false otherwise.\"\"\"\n        return self._at_eof\n\n    async def next(\n        self,\n    ) -> Optional[Union[\"MultipartReader\", BodyPartReader]]:\n        \"\"\"Emits the next multipart body part.\"\"\"\n        # So, if we're at BOF, we need to skip till the boundary.\n        if self._at_eof:\n            return None\n        await self._maybe_release_last_part()\n        if self._at_bof:\n            await self._read_until_first_boundary()\n            self._at_bof = False\n        else:\n            await self._read_boundary()\n        if self._at_eof:  # we just read the last boundary, nothing to do there\n            return None\n\n        part = await self.fetch_next_part()\n        # https://datatracker.ietf.org/doc/html/rfc7578#section-4.6\n        if (\n            self._last_part is None\n            and self._mimetype.subtype == \"form-data\"\n            and isinstance(part, BodyPartReader)\n        ):\n            _, params = parse_content_disposition(part.headers.get(CONTENT_DISPOSITION))\n            if params.get(\"name\") == \"_charset_\":\n                # Longest encoding in https://encoding.spec.whatwg.org/encodings.json\n                # is 19 characters, so 32 should be more than enough for any valid encoding.\n                charset = await part.read_chunk(32)\n                if len(charset) > 31:\n                    raise RuntimeError(\"Invalid default charset\")\n                self._default_charset = charset.strip().decode()\n                part = await self.fetch_next_part()\n        self._last_part = part\n        return self._last_part\n\n    async def release(self) -> None:\n        \"\"\"Reads all the body parts to the void till the final boundary.\"\"\"\n        while not self._at_eof:\n            item = await self.next()\n            if item is None:\n                break\n            await item.release()\n\n    async def fetch_next_part(\n        self,\n    ) -> Union[\"MultipartReader\", BodyPartReader]:\n        \"\"\"Returns the next body part reader.\"\"\"\n        headers = await self._read_headers()\n        return self._get_part_reader(headers)\n\n    def _get_part_reader(\n        self,\n        headers: \"CIMultiDictProxy[str]\",\n    ) -> Union[\"MultipartReader\", BodyPartReader]:\n        \"\"\"Dispatches the response by the `Content-Type` header.\n\n        Returns a suitable reader instance.\n\n        :param dict headers: Response headers\n        \"\"\"\n        ctype = headers.get(CONTENT_TYPE, \"\")\n        mimetype = parse_mimetype(ctype)\n\n        if mimetype.type == \"multipart\":\n            if self.multipart_reader_cls is None:\n                return type(self)(headers, self._content)\n            return self.multipart_reader_cls(headers, self._content)\n        else:\n            return self.part_reader_cls(\n                self._boundary,\n                headers,\n                self._content,\n                subtype=self._mimetype.subtype,\n                default_charset=self._default_charset,\n            )\n\n    def _get_boundary(self) -> str:\n        boundary = self._mimetype.parameters[\"boundary\"]\n        if len(boundary) > 70:\n            raise ValueError(\"boundary %r is too long (70 chars max)\" % boundary)\n\n        return boundary\n\n    async def _readline(self) -> bytes:\n        if self._unread:\n            return self._unread.pop()\n        return await self._content.readline()\n\n    async def _read_until_first_boundary(self) -> None:\n        while True:\n            chunk = await self._readline()\n            if chunk == b\"\":\n                raise ValueError(f\"Could not find starting boundary {self._boundary!r}\")\n            chunk = chunk.rstrip()\n            if chunk == self._boundary:\n                return\n            elif chunk == self._boundary + b\"--\":\n                self._at_eof = True\n                return\n\n    async def _read_boundary(self) -> None:\n        chunk = (await self._readline()).rstrip()\n        if chunk == self._boundary:\n            pass\n        elif chunk == self._boundary + b\"--\":\n            self._at_eof = True\n            epilogue = await self._readline()\n            next_line = await self._readline()\n\n            # the epilogue is expected and then either the end of input or the\n            # parent multipart boundary, if the parent boundary is found then\n            # it should be marked as unread and handed to the parent for\n            # processing\n            if next_line[:2] == b\"--\":\n                self._unread.append(next_line)\n            # otherwise the request is likely missing an epilogue and both\n            # lines should be passed to the parent for processing\n            # (this handles the old behavior gracefully)\n            else:\n                self._unread.extend([next_line, epilogue])\n        else:\n            raise ValueError(f\"Invalid boundary {chunk!r}, expected {self._boundary!r}\")\n\n    async def _read_headers(self) -> \"CIMultiDictProxy[str]\":\n        lines = [b\"\"]\n        while True:\n            chunk = await self._content.readline()\n            chunk = chunk.strip()\n            lines.append(chunk)\n            if not chunk:\n                break\n        parser = HeadersParser()\n        headers, raw_headers = parser.parse_headers(lines)\n        return headers\n\n    async def _maybe_release_last_part(self) -> None:\n        \"\"\"Ensures that the last read body part is read completely.\"\"\"\n        if self._last_part is not None:\n            if not self._last_part.at_eof():\n                await self._last_part.release()\n            self._unread.extend(self._last_part._unread)\n            self._last_part = None\n\n\n_Part = Tuple[Payload, str, str]\n\n\nclass MultipartWriter(Payload):\n    \"\"\"Multipart body writer.\"\"\"\n\n    def __init__(self, subtype: str = \"mixed\", boundary: Optional[str] = None) -> None:\n        boundary = boundary if boundary is not None else uuid.uuid4().hex\n        # The underlying Payload API demands a str (utf-8), not bytes,\n        # so we need to ensure we don't lose anything during conversion.\n        # As a result, require the boundary to be ASCII only.\n        # In both situations.\n\n        try:\n            self._boundary = boundary.encode(\"ascii\")\n        except UnicodeEncodeError:\n            raise ValueError(\"boundary should contain ASCII only chars\") from None\n\n        if len(boundary) > 70:\n            raise ValueError(\"boundary %r is too long (70 chars max)\" % boundary)\n\n        ctype = f\"multipart/{subtype}; boundary={self._boundary_value}\"\n\n        super().__init__(None, content_type=ctype)\n\n        self._parts: List[_Part] = []\n        self._is_form_data = subtype == \"form-data\"\n\n    def __enter__(self) -> \"MultipartWriter\":\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        pass\n\n    def __iter__(self) -> Iterator[_Part]:\n        return iter(self._parts)\n\n    def __len__(self) -> int:\n        return len(self._parts)\n\n    def __bool__(self) -> bool:\n        return True\n\n    _valid_tchar_regex = re.compile(rb\"\\A[!#$%&'*+\\-.^_`|~\\w]+\\Z\")\n    _invalid_qdtext_char_regex = re.compile(rb\"[\\x00-\\x08\\x0A-\\x1F\\x7F]\")\n\n    @property\n    def _boundary_value(self) -> str:\n        \"\"\"Wrap boundary parameter value in quotes, if necessary.\n\n        Reads self.boundary and returns a unicode string.\n        \"\"\"\n        # Refer to RFCs 7231, 7230, 5234.\n        #\n        # parameter      = token \"=\" ( token / quoted-string )\n        # token          = 1*tchar\n        # quoted-string  = DQUOTE *( qdtext / quoted-pair ) DQUOTE\n        # qdtext         = HTAB / SP / %x21 / %x23-5B / %x5D-7E / obs-text\n        # obs-text       = %x80-FF\n        # quoted-pair    = \"\\\" ( HTAB / SP / VCHAR / obs-text )\n        # tchar          = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\"\n        #                  / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\"\n        #                  / DIGIT / ALPHA\n        #                  ; any VCHAR, except delimiters\n        # VCHAR           = %x21-7E\n        value = self._boundary\n        if re.match(self._valid_tchar_regex, value):\n            return value.decode(\"ascii\")  # cannot fail\n\n        if re.search(self._invalid_qdtext_char_regex, value):\n            raise ValueError(\"boundary value contains invalid characters\")\n\n        # escape %x5C and %x22\n        quoted_value_content = value.replace(b\"\\\\\", b\"\\\\\\\\\")\n        quoted_value_content = quoted_value_content.replace(b'\"', b'\\\\\"')\n\n        return '\"' + quoted_value_content.decode(\"ascii\") + '\"'\n\n    @property\n    def boundary(self) -> str:\n        return self._boundary.decode(\"ascii\")\n\n    def append(self, obj: Any, headers: Optional[Mapping[str, str]] = None) -> Payload:\n        if headers is None:\n            headers = CIMultiDict()\n\n        if isinstance(obj, Payload):\n            obj.headers.update(headers)\n            return self.append_payload(obj)\n        else:\n            try:\n                payload = get_payload(obj, headers=headers)\n            except LookupError:\n                raise TypeError(\"Cannot create payload from %r\" % obj)\n            else:\n                return self.append_payload(payload)\n\n    def append_payload(self, payload: Payload) -> Payload:\n        \"\"\"Adds a new body part to multipart writer.\"\"\"\n        encoding: Optional[str] = None\n        te_encoding: Optional[str] = None\n        if self._is_form_data:\n            # https://datatracker.ietf.org/doc/html/rfc7578#section-4.7\n            # https://datatracker.ietf.org/doc/html/rfc7578#section-4.8\n            assert (\n                not {CONTENT_ENCODING, CONTENT_LENGTH, CONTENT_TRANSFER_ENCODING}\n                & payload.headers.keys()\n            )\n            # Set default Content-Disposition in case user doesn't create one\n            if CONTENT_DISPOSITION not in payload.headers:\n                name = f\"section-{len(self._parts)}\"\n                payload.set_content_disposition(\"form-data\", name=name)\n        else:\n            # compression\n            encoding = payload.headers.get(CONTENT_ENCODING, \"\").lower()\n            if encoding and encoding not in (\"deflate\", \"gzip\", \"identity\"):\n                raise RuntimeError(f\"unknown content encoding: {encoding}\")\n            if encoding == \"identity\":\n                encoding = None\n\n            # te encoding\n            te_encoding = payload.headers.get(CONTENT_TRANSFER_ENCODING, \"\").lower()\n            if te_encoding not in (\"\", \"base64\", \"quoted-printable\", \"binary\"):\n                raise RuntimeError(f\"unknown content transfer encoding: {te_encoding}\")\n            if te_encoding == \"binary\":\n                te_encoding = None\n\n            # size\n            size = payload.size\n            if size is not None and not (encoding or te_encoding):\n                payload.headers[CONTENT_LENGTH] = str(size)\n\n        self._parts.append((payload, encoding, te_encoding))  # type: ignore[arg-type]\n        return payload\n\n    def append_json(\n        self, obj: Any, headers: Optional[Mapping[str, str]] = None\n    ) -> Payload:\n        \"\"\"Helper to append JSON part.\"\"\"\n        if headers is None:\n            headers = CIMultiDict()\n\n        return self.append_payload(JsonPayload(obj, headers=headers))\n\n    def append_form(\n        self,\n        obj: Union[Sequence[Tuple[str, str]], Mapping[str, str]],\n        headers: Optional[Mapping[str, str]] = None,\n    ) -> Payload:\n        \"\"\"Helper to append form urlencoded part.\"\"\"\n        assert isinstance(obj, (Sequence, Mapping))\n\n        if headers is None:\n            headers = CIMultiDict()\n\n        if isinstance(obj, Mapping):\n            obj = list(obj.items())\n        data = urlencode(obj, doseq=True)\n\n        return self.append_payload(\n            StringPayload(\n                data, headers=headers, content_type=\"application/x-www-form-urlencoded\"\n            )\n        )\n\n    @property\n    def size(self) -> Optional[int]:\n        \"\"\"Size of the payload.\"\"\"\n        total = 0\n        for part, encoding, te_encoding in self._parts:\n            if encoding or te_encoding or part.size is None:\n                return None\n\n            total += int(\n                2\n                + len(self._boundary)\n                + 2\n                + part.size  # b'--'+self._boundary+b'\\r\\n'\n                + len(part._binary_headers)\n                + 2  # b'\\r\\n'\n            )\n\n        total += 2 + len(self._boundary) + 4  # b'--'+self._boundary+b'--\\r\\n'\n        return total\n\n    async def write(self, writer: Any, close_boundary: bool = True) -> None:\n        \"\"\"Write body.\"\"\"\n        for part, encoding, te_encoding in self._parts:\n            if self._is_form_data:\n                # https://datatracker.ietf.org/doc/html/rfc7578#section-4.2\n                assert CONTENT_DISPOSITION in part.headers\n                assert \"name=\" in part.headers[CONTENT_DISPOSITION]\n\n            await writer.write(b\"--\" + self._boundary + b\"\\r\\n\")\n            await writer.write(part._binary_headers)\n\n            if encoding or te_encoding:\n                w = MultipartPayloadWriter(writer)\n                if encoding:\n                    w.enable_compression(encoding)\n                if te_encoding:\n                    w.enable_encoding(te_encoding)\n                await part.write(w)  # type: ignore[arg-type]\n                await w.write_eof()\n            else:\n                await part.write(writer)\n\n            await writer.write(b\"\\r\\n\")\n\n        if close_boundary:\n            await writer.write(b\"--\" + self._boundary + b\"--\\r\\n\")\n\n\nclass MultipartPayloadWriter:\n    def __init__(self, writer: Any) -> None:\n        self._writer = writer\n        self._encoding: Optional[str] = None\n        self._compress: Optional[ZLibCompressor] = None\n        self._encoding_buffer: Optional[bytearray] = None\n\n    def enable_encoding(self, encoding: str) -> None:\n        if encoding == \"base64\":\n            self._encoding = encoding\n            self._encoding_buffer = bytearray()\n        elif encoding == \"quoted-printable\":\n            self._encoding = \"quoted-printable\"\n\n    def enable_compression(\n        self, encoding: str = \"deflate\", strategy: int = zlib.Z_DEFAULT_STRATEGY\n    ) -> None:\n        self._compress = ZLibCompressor(\n            encoding=encoding,\n            suppress_deflate_header=True,\n            strategy=strategy,\n        )\n\n    async def write_eof(self) -> None:\n        if self._compress is not None:\n            chunk = self._compress.flush()\n            if chunk:\n                self._compress = None\n                await self.write(chunk)\n\n        if self._encoding == \"base64\":\n            if self._encoding_buffer:\n                await self._writer.write(base64.b64encode(self._encoding_buffer))\n\n    async def write(self, chunk: bytes) -> None:\n        if self._compress is not None:\n            if chunk:\n                chunk = await self._compress.compress(chunk)\n                if not chunk:\n                    return\n\n        if self._encoding == \"base64\":\n            buf = self._encoding_buffer\n            assert buf is not None\n            buf.extend(chunk)\n\n            if buf:\n                div, mod = divmod(len(buf), 3)\n                enc_chunk, self._encoding_buffer = (buf[: div * 3], buf[div * 3 :])\n                if enc_chunk:\n                    b64chunk = base64.b64encode(enc_chunk)\n                    await self._writer.write(b64chunk)\n        elif self._encoding == \"quoted-printable\":\n            await self._writer.write(binascii.b2a_qp(chunk))\n        else:\n            await self._writer.write(chunk)\n", "aiohttp/http.py": "import sys\n\nfrom . import __version__\nfrom .http_exceptions import HttpProcessingError\nfrom .http_parser import (\n    HeadersParser,\n    HttpParser,\n    HttpRequestParser,\n    HttpResponseParser,\n    RawRequestMessage,\n    RawResponseMessage,\n)\nfrom .http_websocket import (\n    WS_CLOSED_MESSAGE,\n    WS_CLOSING_MESSAGE,\n    WS_KEY,\n    WebSocketError,\n    WebSocketReader,\n    WebSocketWriter,\n    WSCloseCode,\n    WSMessage,\n    WSMsgType,\n    ws_ext_gen,\n    ws_ext_parse,\n)\nfrom .http_writer import HttpVersion, HttpVersion10, HttpVersion11, StreamWriter\n\n__all__ = (\n    \"HttpProcessingError\",\n    \"SERVER_SOFTWARE\",\n    # .http_writer\n    \"StreamWriter\",\n    \"HttpVersion\",\n    \"HttpVersion10\",\n    \"HttpVersion11\",\n    # .http_parser\n    \"HeadersParser\",\n    \"HttpParser\",\n    \"HttpRequestParser\",\n    \"HttpResponseParser\",\n    \"RawRequestMessage\",\n    \"RawResponseMessage\",\n    # .http_websocket\n    \"WS_CLOSED_MESSAGE\",\n    \"WS_CLOSING_MESSAGE\",\n    \"WS_KEY\",\n    \"WebSocketReader\",\n    \"WebSocketWriter\",\n    \"ws_ext_gen\",\n    \"ws_ext_parse\",\n    \"WSMessage\",\n    \"WebSocketError\",\n    \"WSMsgType\",\n    \"WSCloseCode\",\n)\n\n\nSERVER_SOFTWARE: str = \"Python/{0[0]}.{0[1]} aiohttp/{1}\".format(\n    sys.version_info, __version__\n)\n", "aiohttp/client_reqrep.py": "import asyncio\nimport codecs\nimport contextlib\nimport dataclasses\nimport functools\nimport io\nimport re\nimport sys\nimport traceback\nimport warnings\nfrom hashlib import md5, sha1, sha256\nfrom http.cookies import CookieError, Morsel, SimpleCookie\nfrom types import MappingProxyType, TracebackType\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Mapping,\n    Optional,\n    Tuple,\n    Type,\n    Union,\n    cast,\n)\n\nfrom multidict import CIMultiDict, CIMultiDictProxy, MultiDict, MultiDictProxy\nfrom yarl import URL\n\nfrom . import hdrs, helpers, http, multipart, payload\nfrom .abc import AbstractStreamWriter\nfrom .client_exceptions import (\n    ClientConnectionError,\n    ClientOSError,\n    ClientResponseError,\n    ContentTypeError,\n    InvalidURL,\n    ServerFingerprintMismatch,\n)\nfrom .compression_utils import HAS_BROTLI\nfrom .formdata import FormData\nfrom .hdrs import CONTENT_TYPE\nfrom .helpers import (\n    BaseTimerContext,\n    BasicAuth,\n    HeadersMixin,\n    TimerNoop,\n    basicauth_from_netrc,\n    is_expected_content_type,\n    netrc_from_env,\n    noop,\n    parse_mimetype,\n    reify,\n    set_exception,\n    set_result,\n)\nfrom .http import (\n    SERVER_SOFTWARE,\n    HttpVersion,\n    HttpVersion10,\n    HttpVersion11,\n    StreamWriter,\n)\nfrom .log import client_logger\nfrom .streams import StreamReader\nfrom .typedefs import (\n    DEFAULT_JSON_DECODER,\n    JSONDecoder,\n    LooseCookies,\n    LooseHeaders,\n    RawHeaders,\n)\n\ntry:\n    import ssl\n    from ssl import SSLContext\nexcept ImportError:  # pragma: no cover\n    ssl = None  # type: ignore[assignment]\n    SSLContext = object  # type: ignore[misc,assignment]\n\n\n__all__ = (\"ClientRequest\", \"ClientResponse\", \"RequestInfo\", \"Fingerprint\")\n\n\nif TYPE_CHECKING:\n    from .client import ClientSession\n    from .connector import Connection\n    from .tracing import Trace\n\n\n_CONTAINS_CONTROL_CHAR_RE = re.compile(r\"[^-!#$%&'*+.^_`|~0-9a-zA-Z]\")\n\n\ndef _gen_default_accept_encoding() -> str:\n    return \"gzip, deflate, br\" if HAS_BROTLI else \"gzip, deflate\"\n\n\n@dataclasses.dataclass(frozen=True)\nclass ContentDisposition:\n    type: Optional[str]\n    parameters: \"MappingProxyType[str, str]\"\n    filename: Optional[str]\n\n\n@dataclasses.dataclass(frozen=True)\nclass RequestInfo:\n    url: URL\n    method: str\n    headers: \"CIMultiDictProxy[str]\"\n    real_url: URL\n\n\nclass Fingerprint:\n    HASHFUNC_BY_DIGESTLEN = {\n        16: md5,\n        20: sha1,\n        32: sha256,\n    }\n\n    def __init__(self, fingerprint: bytes) -> None:\n        digestlen = len(fingerprint)\n        hashfunc = self.HASHFUNC_BY_DIGESTLEN.get(digestlen)\n        if not hashfunc:\n            raise ValueError(\"fingerprint has invalid length\")\n        elif hashfunc is md5 or hashfunc is sha1:\n            raise ValueError(\n                \"md5 and sha1 are insecure and \" \"not supported. Use sha256.\"\n            )\n        self._hashfunc = hashfunc\n        self._fingerprint = fingerprint\n\n    @property\n    def fingerprint(self) -> bytes:\n        return self._fingerprint\n\n    def check(self, transport: asyncio.Transport) -> None:\n        if not transport.get_extra_info(\"sslcontext\"):\n            return\n        sslobj = transport.get_extra_info(\"ssl_object\")\n        cert = sslobj.getpeercert(binary_form=True)\n        got = self._hashfunc(cert).digest()\n        if got != self._fingerprint:\n            host, port, *_ = transport.get_extra_info(\"peername\")\n            raise ServerFingerprintMismatch(self._fingerprint, got, host, port)\n\n\nif ssl is not None:\n    SSL_ALLOWED_TYPES = (ssl.SSLContext, bool, Fingerprint)\nelse:  # pragma: no cover\n    SSL_ALLOWED_TYPES = (bool,)\n\n\n@dataclasses.dataclass(frozen=True)\nclass ConnectionKey:\n    # the key should contain an information about used proxy / TLS\n    # to prevent reusing wrong connections from a pool\n    host: str\n    port: Optional[int]\n    is_ssl: bool\n    ssl: Union[SSLContext, bool, Fingerprint]\n    proxy: Optional[URL]\n    proxy_auth: Optional[BasicAuth]\n    proxy_headers_hash: Optional[int]  # hash(CIMultiDict)\n\n\nclass ClientRequest:\n    GET_METHODS = {\n        hdrs.METH_GET,\n        hdrs.METH_HEAD,\n        hdrs.METH_OPTIONS,\n        hdrs.METH_TRACE,\n    }\n    POST_METHODS = {hdrs.METH_PATCH, hdrs.METH_POST, hdrs.METH_PUT}\n    ALL_METHODS = GET_METHODS.union(POST_METHODS).union({hdrs.METH_DELETE})\n\n    DEFAULT_HEADERS = {\n        hdrs.ACCEPT: \"*/*\",\n        hdrs.ACCEPT_ENCODING: _gen_default_accept_encoding(),\n    }\n\n    body = b\"\"\n    auth = None\n    response = None\n\n    __writer = None  # async task for streaming data\n    _continue = None  # waiter future for '100 Continue' response\n\n    # N.B.\n    # Adding __del__ method with self._writer closing doesn't make sense\n    # because _writer is instance method, thus it keeps a reference to self.\n    # Until writer has finished finalizer will not be called.\n\n    def __init__(\n        self,\n        method: str,\n        url: URL,\n        *,\n        params: Optional[Mapping[str, str]] = None,\n        headers: Optional[LooseHeaders] = None,\n        skip_auto_headers: Iterable[str] = frozenset(),\n        data: Any = None,\n        cookies: Optional[LooseCookies] = None,\n        auth: Optional[BasicAuth] = None,\n        version: http.HttpVersion = http.HttpVersion11,\n        compress: Optional[str] = None,\n        chunked: Optional[bool] = None,\n        expect100: bool = False,\n        loop: asyncio.AbstractEventLoop,\n        response_class: Optional[Type[\"ClientResponse\"]] = None,\n        proxy: Optional[URL] = None,\n        proxy_auth: Optional[BasicAuth] = None,\n        timer: Optional[BaseTimerContext] = None,\n        session: Optional[\"ClientSession\"] = None,\n        ssl: Union[SSLContext, bool, Fingerprint] = True,\n        proxy_headers: Optional[LooseHeaders] = None,\n        traces: Optional[List[\"Trace\"]] = None,\n        trust_env: bool = False,\n        server_hostname: Optional[str] = None,\n    ):\n        match = _CONTAINS_CONTROL_CHAR_RE.search(method)\n        if match:\n            raise ValueError(\n                f\"Method cannot contain non-token characters {method!r} \"\n                f\"(found at least {match.group()!r})\"\n            )\n        assert isinstance(url, URL), url\n        assert isinstance(proxy, (URL, type(None))), proxy\n        # FIXME: session is None in tests only, need to fix tests\n        # assert session is not None\n        self._session = cast(\"ClientSession\", session)\n        if params:\n            q = MultiDict(url.query)\n            url2 = url.with_query(params)\n            q.extend(url2.query)\n            url = url.with_query(q)\n        self.original_url = url\n        self.url = url.with_fragment(None)\n        self.method = method.upper()\n        self.chunked = chunked\n        self.compress = compress\n        self.loop = loop\n        self.length = None\n        if response_class is None:\n            real_response_class = ClientResponse\n        else:\n            real_response_class = response_class\n        self.response_class: Type[ClientResponse] = real_response_class\n        self._timer = timer if timer is not None else TimerNoop()\n        self._ssl = ssl\n        self.server_hostname = server_hostname\n\n        if loop.get_debug():\n            self._source_traceback = traceback.extract_stack(sys._getframe(1))\n\n        self.update_version(version)\n        self.update_host(url)\n        self.update_headers(headers)\n        self.update_auto_headers(skip_auto_headers)\n        self.update_cookies(cookies)\n        self.update_content_encoding(data)\n        self.update_auth(auth, trust_env)\n        self.update_proxy(proxy, proxy_auth, proxy_headers)\n\n        self.update_body_from_data(data)\n        if data is not None or self.method not in self.GET_METHODS:\n            self.update_transfer_encoding()\n        self.update_expect_continue(expect100)\n        if traces is None:\n            traces = []\n        self._traces = traces\n\n    def __reset_writer(self, _: object = None) -> None:\n        self.__writer = None\n\n    @property\n    def _writer(self) -> Optional[\"asyncio.Task[None]\"]:\n        return self.__writer\n\n    @_writer.setter\n    def _writer(self, writer: Optional[\"asyncio.Task[None]\"]) -> None:\n        if self.__writer is not None:\n            self.__writer.remove_done_callback(self.__reset_writer)\n        self.__writer = writer\n        if writer is not None:\n            writer.add_done_callback(self.__reset_writer)\n\n    def is_ssl(self) -> bool:\n        return self.url.scheme in (\"https\", \"wss\")\n\n    @property\n    def ssl(self) -> Union[\"SSLContext\", bool, Fingerprint]:\n        return self._ssl\n\n    @property\n    def connection_key(self) -> ConnectionKey:\n        proxy_headers = self.proxy_headers\n        if proxy_headers:\n            h: Optional[int] = hash(tuple((k, v) for k, v in proxy_headers.items()))\n        else:\n            h = None\n        return ConnectionKey(\n            self.host,\n            self.port,\n            self.is_ssl(),\n            self.ssl,\n            self.proxy,\n            self.proxy_auth,\n            h,\n        )\n\n    @property\n    def host(self) -> str:\n        ret = self.url.raw_host\n        assert ret is not None\n        return ret\n\n    @property\n    def port(self) -> Optional[int]:\n        return self.url.port\n\n    @property\n    def request_info(self) -> RequestInfo:\n        headers: CIMultiDictProxy[str] = CIMultiDictProxy(self.headers)\n        return RequestInfo(self.url, self.method, headers, self.original_url)\n\n    def update_host(self, url: URL) -> None:\n        \"\"\"Update destination host, port and connection type (ssl).\"\"\"\n        # get host/port\n        if not url.raw_host:\n            raise InvalidURL(url)\n\n        # basic auth info\n        username, password = url.user, url.password\n        if username:\n            self.auth = helpers.BasicAuth(username, password or \"\")\n\n    def update_version(self, version: Union[http.HttpVersion, str]) -> None:\n        \"\"\"Convert request version to two elements tuple.\n\n        parser HTTP version '1.1' => (1, 1)\n        \"\"\"\n        if isinstance(version, str):\n            v = [part.strip() for part in version.split(\".\", 1)]\n            try:\n                version = http.HttpVersion(int(v[0]), int(v[1]))\n            except ValueError:\n                raise ValueError(\n                    f\"Can not parse http version number: {version}\"\n                ) from None\n        self.version = version\n\n    def update_headers(self, headers: Optional[LooseHeaders]) -> None:\n        \"\"\"Update request headers.\"\"\"\n        self.headers: CIMultiDict[str] = CIMultiDict()\n\n        # add host\n        netloc = cast(str, self.url.raw_host)\n        if helpers.is_ipv6_address(netloc):\n            netloc = f\"[{netloc}]\"\n        # See https://github.com/aio-libs/aiohttp/issues/3636.\n        netloc = netloc.rstrip(\".\")\n        if self.url.port is not None and not self.url.is_default_port():\n            netloc += \":\" + str(self.url.port)\n        self.headers[hdrs.HOST] = netloc\n\n        if headers:\n            if isinstance(headers, (dict, MultiDictProxy, MultiDict)):\n                headers = headers.items()  # type: ignore[assignment]\n\n            for key, value in headers:  # type: ignore[misc]\n                # A special case for Host header\n                if key.lower() == \"host\":\n                    self.headers[key] = value\n                else:\n                    self.headers.add(key, value)\n\n    def update_auto_headers(self, skip_auto_headers: Iterable[str]) -> None:\n        self.skip_auto_headers = CIMultiDict(\n            (hdr, None) for hdr in sorted(skip_auto_headers)\n        )\n        used_headers = self.headers.copy()\n        used_headers.extend(self.skip_auto_headers)  # type: ignore[arg-type]\n\n        for hdr, val in self.DEFAULT_HEADERS.items():\n            if hdr not in used_headers:\n                self.headers.add(hdr, val)\n\n        if hdrs.USER_AGENT not in used_headers:\n            self.headers[hdrs.USER_AGENT] = SERVER_SOFTWARE\n\n    def update_cookies(self, cookies: Optional[LooseCookies]) -> None:\n        \"\"\"Update request cookies header.\"\"\"\n        if not cookies:\n            return\n\n        c = SimpleCookie()\n        if hdrs.COOKIE in self.headers:\n            c.load(self.headers.get(hdrs.COOKIE, \"\"))\n            del self.headers[hdrs.COOKIE]\n\n        if isinstance(cookies, Mapping):\n            iter_cookies = cookies.items()\n        else:\n            iter_cookies = cookies  # type: ignore[assignment]\n        for name, value in iter_cookies:\n            if isinstance(value, Morsel):\n                # Preserve coded_value\n                mrsl_val = value.get(value.key, Morsel())\n                mrsl_val.set(value.key, value.value, value.coded_value)\n                c[name] = mrsl_val\n            else:\n                c[name] = value  # type: ignore[assignment]\n\n        self.headers[hdrs.COOKIE] = c.output(header=\"\", sep=\";\").strip()\n\n    def update_content_encoding(self, data: Any) -> None:\n        \"\"\"Set request content encoding.\"\"\"\n        if data is None:\n            return\n\n        enc = self.headers.get(hdrs.CONTENT_ENCODING, \"\").lower()\n        if enc:\n            if self.compress:\n                raise ValueError(\n                    \"compress can not be set \" \"if Content-Encoding header is set\"\n                )\n        elif self.compress:\n            if not isinstance(self.compress, str):\n                self.compress = \"deflate\"\n            self.headers[hdrs.CONTENT_ENCODING] = self.compress\n            self.chunked = True  # enable chunked, no need to deal with length\n\n    def update_transfer_encoding(self) -> None:\n        \"\"\"Analyze transfer-encoding header.\"\"\"\n        te = self.headers.get(hdrs.TRANSFER_ENCODING, \"\").lower()\n\n        if \"chunked\" in te:\n            if self.chunked:\n                raise ValueError(\n                    \"chunked can not be set \"\n                    'if \"Transfer-Encoding: chunked\" header is set'\n                )\n\n        elif self.chunked:\n            if hdrs.CONTENT_LENGTH in self.headers:\n                raise ValueError(\n                    \"chunked can not be set \" \"if Content-Length header is set\"\n                )\n\n            self.headers[hdrs.TRANSFER_ENCODING] = \"chunked\"\n        else:\n            if hdrs.CONTENT_LENGTH not in self.headers:\n                self.headers[hdrs.CONTENT_LENGTH] = str(len(self.body))\n\n    def update_auth(self, auth: Optional[BasicAuth], trust_env: bool = False) -> None:\n        \"\"\"Set basic auth.\"\"\"\n        if auth is None:\n            auth = self.auth\n        if auth is None and trust_env and self.url.host is not None:\n            netrc_obj = netrc_from_env()\n            with contextlib.suppress(LookupError):\n                auth = basicauth_from_netrc(netrc_obj, self.url.host)\n        if auth is None:\n            return\n\n        if not isinstance(auth, helpers.BasicAuth):\n            raise TypeError(\"BasicAuth() tuple is required instead\")\n\n        self.headers[hdrs.AUTHORIZATION] = auth.encode()\n\n    def update_body_from_data(self, body: Any) -> None:\n        if body is None:\n            return\n\n        # FormData\n        if isinstance(body, FormData):\n            body = body()\n\n        try:\n            body = payload.PAYLOAD_REGISTRY.get(body, disposition=None)\n        except payload.LookupError:\n            boundary = None\n            if CONTENT_TYPE in self.headers:\n                boundary = parse_mimetype(self.headers[CONTENT_TYPE]).parameters.get(\n                    \"boundary\"\n                )\n            body = FormData(body, boundary=boundary)()\n\n        self.body = body\n\n        # enable chunked encoding if needed\n        if not self.chunked:\n            if hdrs.CONTENT_LENGTH not in self.headers:\n                size = body.size\n                if size is None:\n                    self.chunked = True\n                else:\n                    if hdrs.CONTENT_LENGTH not in self.headers:\n                        self.headers[hdrs.CONTENT_LENGTH] = str(size)\n\n        # copy payload headers\n        assert body.headers\n        for key, value in body.headers.items():\n            if key in self.headers:\n                continue\n            if key in self.skip_auto_headers:\n                continue\n            self.headers[key] = value\n\n    def update_expect_continue(self, expect: bool = False) -> None:\n        if expect:\n            self.headers[hdrs.EXPECT] = \"100-continue\"\n        elif self.headers.get(hdrs.EXPECT, \"\").lower() == \"100-continue\":\n            expect = True\n\n        if expect:\n            self._continue = self.loop.create_future()\n\n    def update_proxy(\n        self,\n        proxy: Optional[URL],\n        proxy_auth: Optional[BasicAuth],\n        proxy_headers: Optional[LooseHeaders],\n    ) -> None:\n        if proxy_auth and not isinstance(proxy_auth, helpers.BasicAuth):\n            raise ValueError(\"proxy_auth must be None or BasicAuth() tuple\")\n        self.proxy = proxy\n        self.proxy_auth = proxy_auth\n        self.proxy_headers = proxy_headers\n\n    def keep_alive(self) -> bool:\n        if self.version < HttpVersion10:\n            # keep alive not supported at all\n            return False\n        if self.version == HttpVersion10:\n            if self.headers.get(hdrs.CONNECTION) == \"keep-alive\":\n                return True\n            else:  # no headers means we close for Http 1.0\n                return False\n        elif self.headers.get(hdrs.CONNECTION) == \"close\":\n            return False\n\n        return True\n\n    async def write_bytes(\n        self, writer: AbstractStreamWriter, conn: \"Connection\"\n    ) -> None:\n        \"\"\"Support coroutines that yields bytes objects.\"\"\"\n        # 100 response\n        if self._continue is not None:\n            try:\n                await writer.drain()\n                await self._continue\n            except asyncio.CancelledError:\n                return\n\n        protocol = conn.protocol\n        assert protocol is not None\n        try:\n            if isinstance(self.body, payload.Payload):\n                await self.body.write(writer)\n            else:\n                if isinstance(self.body, (bytes, bytearray)):\n                    self.body = (self.body,)  # type: ignore[assignment]\n\n                for chunk in self.body:\n                    await writer.write(chunk)  # type: ignore[arg-type]\n        except OSError as underlying_exc:\n            reraised_exc = underlying_exc\n\n            exc_is_not_timeout = underlying_exc.errno is not None or not isinstance(\n                underlying_exc, asyncio.TimeoutError\n            )\n            if exc_is_not_timeout:\n                reraised_exc = ClientOSError(\n                    underlying_exc.errno,\n                    f\"Can not write request body for {self.url !s}\",\n                )\n\n            set_exception(protocol, reraised_exc, underlying_exc)\n        except asyncio.CancelledError:\n            await writer.write_eof()\n        except Exception as underlying_exc:\n            set_exception(\n                protocol,\n                ClientConnectionError(\n                    f\"Failed to send bytes into the underlying connection {conn !s}\",\n                ),\n                underlying_exc,\n            )\n        else:\n            await writer.write_eof()\n            protocol.start_timeout()\n\n    async def send(self, conn: \"Connection\") -> \"ClientResponse\":\n        # Specify request target:\n        # - CONNECT request must send authority form URI\n        # - not CONNECT proxy must send absolute form URI\n        # - most common is origin form URI\n        if self.method == hdrs.METH_CONNECT:\n            connect_host = self.url.raw_host\n            assert connect_host is not None\n            if helpers.is_ipv6_address(connect_host):\n                connect_host = f\"[{connect_host}]\"\n            path = f\"{connect_host}:{self.url.port}\"\n        elif self.proxy and not self.is_ssl():\n            path = str(self.url)\n        else:\n            path = self.url.raw_path\n            if self.url.raw_query_string:\n                path += \"?\" + self.url.raw_query_string\n\n        protocol = conn.protocol\n        assert protocol is not None\n        writer = StreamWriter(\n            protocol,\n            self.loop,\n            on_chunk_sent=functools.partial(\n                self._on_chunk_request_sent, self.method, self.url\n            ),\n            on_headers_sent=functools.partial(\n                self._on_headers_request_sent, self.method, self.url\n            ),\n        )\n\n        if self.compress:\n            writer.enable_compression(self.compress)\n\n        if self.chunked is not None:\n            writer.enable_chunking()\n\n        # set default content-type\n        if (\n            self.method in self.POST_METHODS\n            and hdrs.CONTENT_TYPE not in self.skip_auto_headers\n            and hdrs.CONTENT_TYPE not in self.headers\n        ):\n            self.headers[hdrs.CONTENT_TYPE] = \"application/octet-stream\"\n\n        # set the connection header\n        connection = self.headers.get(hdrs.CONNECTION)\n        if not connection:\n            if self.keep_alive():\n                if self.version == HttpVersion10:\n                    connection = \"keep-alive\"\n            else:\n                if self.version == HttpVersion11:\n                    connection = \"close\"\n\n        if connection is not None:\n            self.headers[hdrs.CONNECTION] = connection\n\n        # status + headers\n        status_line = \"{0} {1} HTTP/{v.major}.{v.minor}\".format(\n            self.method, path, v=self.version\n        )\n        await writer.write_headers(status_line, self.headers)\n\n        self._writer = self.loop.create_task(self.write_bytes(writer, conn))\n\n        response_class = self.response_class\n        assert response_class is not None\n        self.response = response_class(\n            self.method,\n            self.original_url,\n            writer=self._writer,\n            continue100=self._continue,\n            timer=self._timer,\n            request_info=self.request_info,\n            traces=self._traces,\n            loop=self.loop,\n            session=self._session,\n        )\n        return self.response\n\n    async def close(self) -> None:\n        if self._writer is not None:\n            with contextlib.suppress(asyncio.CancelledError):\n                await self._writer\n\n    def terminate(self) -> None:\n        if self._writer is not None:\n            if not self.loop.is_closed():\n                self._writer.cancel()\n            self._writer.remove_done_callback(self.__reset_writer)\n            self._writer = None\n\n    async def _on_chunk_request_sent(self, method: str, url: URL, chunk: bytes) -> None:\n        for trace in self._traces:\n            await trace.send_request_chunk_sent(method, url, chunk)\n\n    async def _on_headers_request_sent(\n        self, method: str, url: URL, headers: \"CIMultiDict[str]\"\n    ) -> None:\n        for trace in self._traces:\n            await trace.send_request_headers(method, url, headers)\n\n\nclass ClientResponse(HeadersMixin):\n    # Some of these attributes are None when created,\n    # but will be set by the start() method.\n    # As the end user will likely never see the None values, we cheat the types below.\n    # from the Status-Line of the response\n    version: Optional[HttpVersion] = None  # HTTP-Version\n    status: int = None  # type: ignore[assignment] # Status-Code\n    reason: Optional[str] = None  # Reason-Phrase\n\n    content: StreamReader = None  # type: ignore[assignment] # Payload stream\n    _headers: CIMultiDictProxy[str] = None  # type: ignore[assignment]\n    _raw_headers: RawHeaders = None  # type: ignore[assignment]\n\n    _connection = None  # current connection\n    _source_traceback: Optional[traceback.StackSummary] = None\n    # set up by ClientRequest after ClientResponse object creation\n    # post-init stage allows to not change ctor signature\n    _closed = True  # to allow __del__ for non-initialized properly response\n    _released = False\n    __writer = None\n\n    def __init__(\n        self,\n        method: str,\n        url: URL,\n        *,\n        writer: \"asyncio.Task[None]\",\n        continue100: Optional[\"asyncio.Future[bool]\"],\n        timer: Optional[BaseTimerContext],\n        request_info: RequestInfo,\n        traces: List[\"Trace\"],\n        loop: asyncio.AbstractEventLoop,\n        session: \"ClientSession\",\n    ) -> None:\n        assert isinstance(url, URL)\n        super().__init__()\n\n        self.method = method\n        self.cookies = SimpleCookie()\n\n        self._real_url = url\n        self._url = url.with_fragment(None)\n        self._body: Optional[bytes] = None\n        self._writer: Optional[asyncio.Task[None]] = writer\n        self._continue = continue100  # None by default\n        self._closed = True\n        self._history: Tuple[ClientResponse, ...] = ()\n        self._request_info = request_info\n        self._timer = timer if timer is not None else TimerNoop()\n        self._cache: Dict[str, Any] = {}\n        self._traces = traces\n        self._loop = loop\n        # store a reference to session #1985\n        self._session: Optional[ClientSession] = session\n        # Save reference to _resolve_charset, so that get_encoding() will still\n        # work after the response has finished reading the body.\n        if session is None:\n            # TODO: Fix session=None in tests (see ClientRequest.__init__).\n            self._resolve_charset: Callable[[\"ClientResponse\", bytes], str] = (\n                lambda *_: \"utf-8\"\n            )\n        else:\n            self._resolve_charset = session._resolve_charset\n        if loop.get_debug():\n            self._source_traceback = traceback.extract_stack(sys._getframe(1))\n\n    def __reset_writer(self, _: object = None) -> None:\n        self.__writer = None\n\n    @property\n    def _writer(self) -> Optional[\"asyncio.Task[None]\"]:\n        return self.__writer\n\n    @_writer.setter\n    def _writer(self, writer: Optional[\"asyncio.Task[None]\"]) -> None:\n        if self.__writer is not None:\n            self.__writer.remove_done_callback(self.__reset_writer)\n        self.__writer = writer\n        if writer is not None:\n            writer.add_done_callback(self.__reset_writer)\n\n    @reify\n    def url(self) -> URL:\n        return self._url\n\n    @reify\n    def real_url(self) -> URL:\n        return self._real_url\n\n    @reify\n    def host(self) -> str:\n        assert self._url.host is not None\n        return self._url.host\n\n    @reify\n    def headers(self) -> \"CIMultiDictProxy[str]\":\n        return self._headers\n\n    @reify\n    def raw_headers(self) -> RawHeaders:\n        return self._raw_headers\n\n    @reify\n    def request_info(self) -> RequestInfo:\n        return self._request_info\n\n    @reify\n    def content_disposition(self) -> Optional[ContentDisposition]:\n        raw = self._headers.get(hdrs.CONTENT_DISPOSITION)\n        if raw is None:\n            return None\n        disposition_type, params_dct = multipart.parse_content_disposition(raw)\n        params = MappingProxyType(params_dct)\n        filename = multipart.content_disposition_filename(params)\n        return ContentDisposition(disposition_type, params, filename)\n\n    def __del__(self, _warnings: Any = warnings) -> None:\n        if self._closed:\n            return\n\n        if self._connection is not None:\n            self._connection.release()\n            self._cleanup_writer()\n\n            if self._loop.get_debug():\n                _warnings.warn(\n                    f\"Unclosed response {self!r}\", ResourceWarning, source=self\n                )\n                context = {\"client_response\": self, \"message\": \"Unclosed response\"}\n                if self._source_traceback:\n                    context[\"source_traceback\"] = self._source_traceback\n                self._loop.call_exception_handler(context)\n\n    def __repr__(self) -> str:\n        out = io.StringIO()\n        ascii_encodable_url = str(self.url)\n        if self.reason:\n            ascii_encodable_reason = self.reason.encode(\n                \"ascii\", \"backslashreplace\"\n            ).decode(\"ascii\")\n        else:\n            ascii_encodable_reason = \"None\"\n        print(\n            \"<ClientResponse({}) [{} {}]>\".format(\n                ascii_encodable_url, self.status, ascii_encodable_reason\n            ),\n            file=out,\n        )\n        print(self.headers, file=out)\n        return out.getvalue()\n\n    @property\n    def connection(self) -> Optional[\"Connection\"]:\n        return self._connection\n\n    @reify\n    def history(self) -> Tuple[\"ClientResponse\", ...]:\n        \"\"\"A sequence of responses, if redirects occurred.\"\"\"\n        return self._history\n\n    @reify\n    def links(self) -> \"MultiDictProxy[MultiDictProxy[Union[str, URL]]]\":\n        links_str = \", \".join(self.headers.getall(\"link\", []))\n\n        if not links_str:\n            return MultiDictProxy(MultiDict())\n\n        links: MultiDict[MultiDictProxy[Union[str, URL]]] = MultiDict()\n\n        for val in re.split(r\",(?=\\s*<)\", links_str):\n            match = re.match(r\"\\s*<(.*)>(.*)\", val)\n            if match is None:  # pragma: no cover\n                # the check exists to suppress mypy error\n                continue\n            url, params_str = match.groups()\n            params = params_str.split(\";\")[1:]\n\n            link: MultiDict[Union[str, URL]] = MultiDict()\n\n            for param in params:\n                match = re.match(r\"^\\s*(\\S*)\\s*=\\s*(['\\\"]?)(.*?)(\\2)\\s*$\", param, re.M)\n                if match is None:  # pragma: no cover\n                    # the check exists to suppress mypy error\n                    continue\n                key, _, value, _ = match.groups()\n\n                link.add(key, value)\n\n            key = link.get(\"rel\", url)\n\n            link.add(\"url\", self.url.join(URL(url)))\n\n            links.add(str(key), MultiDictProxy(link))\n\n        return MultiDictProxy(links)\n\n    async def start(self, connection: \"Connection\") -> \"ClientResponse\":\n        \"\"\"Start response processing.\"\"\"\n        self._closed = False\n        self._protocol = connection.protocol\n        self._connection = connection\n\n        with self._timer:\n            while True:\n                # read response\n                try:\n                    protocol = self._protocol\n                    message, payload = await protocol.read()  # type: ignore[union-attr]\n                except http.HttpProcessingError as exc:\n                    raise ClientResponseError(\n                        self.request_info,\n                        self.history,\n                        status=exc.code,\n                        message=exc.message,\n                        headers=exc.headers,\n                    ) from exc\n\n                if message.code < 100 or message.code > 199 or message.code == 101:\n                    break\n\n                if self._continue is not None:\n                    set_result(self._continue, True)\n                    self._continue = None\n\n        # payload eof handler\n        payload.on_eof(self._response_eof)\n\n        # response status\n        self.version = message.version\n        self.status = message.code\n        self.reason = message.reason\n\n        # headers\n        self._headers = message.headers  # type is CIMultiDictProxy\n        self._raw_headers = message.raw_headers  # type is Tuple[bytes, bytes]\n\n        # payload\n        self.content = payload\n\n        # cookies\n        for hdr in self.headers.getall(hdrs.SET_COOKIE, ()):\n            try:\n                self.cookies.load(hdr)\n            except CookieError as exc:\n                client_logger.warning(\"Can not load response cookies: %s\", exc)\n        return self\n\n    def _response_eof(self) -> None:\n        if self._closed:\n            return\n\n        # protocol could be None because connection could be detached\n        protocol = self._connection and self._connection.protocol\n        if protocol is not None and protocol.upgraded:\n            return\n\n        self._closed = True\n        self._cleanup_writer()\n        self._release_connection()\n\n    @property\n    def closed(self) -> bool:\n        return self._closed\n\n    def close(self) -> None:\n        if not self._released:\n            self._notify_content()\n\n        self._closed = True\n        if self._loop.is_closed():\n            return\n\n        self._cleanup_writer()\n        if self._connection is not None:\n            self._connection.close()\n            self._connection = None\n\n    def release(self) -> Any:\n        if not self._released:\n            self._notify_content()\n\n        self._closed = True\n\n        self._cleanup_writer()\n        self._release_connection()\n        return noop()\n\n    @property\n    def ok(self) -> bool:\n        \"\"\"Returns ``True`` if ``status`` is less than ``400``, ``False`` if not.\n\n        This is **not** a check for ``200 OK`` but a check that the response\n        status is under 400.\n        \"\"\"\n        return 400 > self.status\n\n    def raise_for_status(self) -> None:\n        if not self.ok:\n            # reason should always be not None for a started response\n            assert self.reason is not None\n            self.release()\n            raise ClientResponseError(\n                self.request_info,\n                self.history,\n                status=self.status,\n                message=self.reason,\n                headers=self.headers,\n            )\n\n    def _release_connection(self) -> None:\n        if self._connection is not None:\n            if self._writer is None:\n                self._connection.release()\n                self._connection = None\n            else:\n                self._writer.add_done_callback(lambda f: self._release_connection())\n\n    async def _wait_released(self) -> None:\n        if self._writer is not None:\n            await self._writer\n        self._release_connection()\n\n    def _cleanup_writer(self) -> None:\n        if self._writer is not None:\n            self._writer.cancel()\n        self._session = None\n\n    def _notify_content(self) -> None:\n        content = self.content\n        # content can be None here, but the types are cheated elsewhere.\n        if content and content.exception() is None:  # type: ignore[truthy-bool]\n            set_exception(content, ClientConnectionError(\"Connection closed\"))\n        self._released = True\n\n    async def wait_for_close(self) -> None:\n        if self._writer is not None:\n            await self._writer\n        self.release()\n\n    async def read(self) -> bytes:\n        \"\"\"Read response payload.\"\"\"\n        if self._body is None:\n            try:\n                self._body = await self.content.read()\n                for trace in self._traces:\n                    await trace.send_response_chunk_received(\n                        self.method, self.url, self._body\n                    )\n            except BaseException:\n                self.close()\n                raise\n        elif self._released:  # Response explicitly released\n            raise ClientConnectionError(\"Connection closed\")\n\n        protocol = self._connection and self._connection.protocol\n        if protocol is None or not protocol.upgraded:\n            await self._wait_released()  # Underlying connection released\n        return self._body\n\n    def get_encoding(self) -> str:\n        ctype = self.headers.get(hdrs.CONTENT_TYPE, \"\").lower()\n        mimetype = helpers.parse_mimetype(ctype)\n\n        encoding = mimetype.parameters.get(\"charset\")\n        if encoding:\n            with contextlib.suppress(LookupError):\n                return codecs.lookup(encoding).name\n\n        if mimetype.type == \"application\" and (\n            mimetype.subtype == \"json\" or mimetype.subtype == \"rdap\"\n        ):\n            # RFC 7159 states that the default encoding is UTF-8.\n            # RFC 7483 defines application/rdap+json\n            return \"utf-8\"\n\n        if self._body is None:\n            raise RuntimeError(\n                \"Cannot compute fallback encoding of a not yet read body\"\n            )\n\n        return self._resolve_charset(self, self._body)\n\n    async def text(self, encoding: Optional[str] = None, errors: str = \"strict\") -> str:\n        \"\"\"Read response payload and decode.\"\"\"\n        if self._body is None:\n            await self.read()\n\n        if encoding is None:\n            encoding = self.get_encoding()\n\n        return self._body.decode(encoding, errors=errors)  # type: ignore[union-attr]\n\n    async def json(\n        self,\n        *,\n        encoding: Optional[str] = None,\n        loads: JSONDecoder = DEFAULT_JSON_DECODER,\n        content_type: Optional[str] = \"application/json\",\n    ) -> Any:\n        \"\"\"Read and decodes JSON response.\"\"\"\n        if self._body is None:\n            await self.read()\n\n        if content_type:\n            if not is_expected_content_type(self.content_type, content_type):\n                raise ContentTypeError(\n                    self.request_info,\n                    self.history,\n                    message=(\n                        \"Attempt to decode JSON with \"\n                        \"unexpected mimetype: %s\" % self.content_type\n                    ),\n                    headers=self.headers,\n                )\n\n        if encoding is None:\n            encoding = self.get_encoding()\n\n        return loads(self._body.decode(encoding))  # type: ignore[union-attr]\n\n    async def __aenter__(self) -> \"ClientResponse\":\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        # similar to _RequestContextManager, we do not need to check\n        # for exceptions, response object can close connection\n        # if state is broken\n        self.release()\n        await self.wait_for_close()\n", "aiohttp/connector.py": "import asyncio\nimport dataclasses\nimport functools\nimport logging\nimport random\nimport socket\nimport sys\nimport traceback\nimport warnings\nfrom collections import defaultdict, deque\nfrom contextlib import suppress\nfrom http import HTTPStatus\nfrom http.cookies import SimpleCookie\nfrom itertools import cycle, islice\nfrom time import monotonic\nfrom types import TracebackType\nfrom typing import (  # noqa\n    TYPE_CHECKING,\n    Any,\n    Awaitable,\n    Callable,\n    DefaultDict,\n    Dict,\n    Iterator,\n    List,\n    Literal,\n    Optional,\n    Set,\n    Tuple,\n    Type,\n    Union,\n    cast,\n)\n\nimport aiohappyeyeballs\n\nfrom . import hdrs, helpers\nfrom .abc import AbstractResolver, ResolveResult\nfrom .client_exceptions import (\n    ClientConnectionError,\n    ClientConnectorCertificateError,\n    ClientConnectorError,\n    ClientConnectorSSLError,\n    ClientHttpProxyError,\n    ClientProxyConnectionError,\n    ServerFingerprintMismatch,\n    UnixClientConnectorError,\n    cert_errors,\n    ssl_errors,\n)\nfrom .client_proto import ResponseHandler\nfrom .client_reqrep import SSL_ALLOWED_TYPES, ClientRequest, Fingerprint\nfrom .helpers import _SENTINEL, ceil_timeout, is_ip_address, sentinel, set_result\nfrom .locks import EventResultOrError\nfrom .resolver import DefaultResolver\n\ntry:\n    import ssl\n\n    SSLContext = ssl.SSLContext\nexcept ImportError:  # pragma: no cover\n    ssl = None  # type: ignore[assignment]\n    SSLContext = object  # type: ignore[misc,assignment]\n\n\n__all__ = (\"BaseConnector\", \"TCPConnector\", \"UnixConnector\", \"NamedPipeConnector\")\n\n\nif TYPE_CHECKING:\n    from .client import ClientTimeout\n    from .client_reqrep import ConnectionKey\n    from .tracing import Trace\n\n\nclass Connection:\n    _source_traceback = None\n    _transport = None\n\n    def __init__(\n        self,\n        connector: \"BaseConnector\",\n        key: \"ConnectionKey\",\n        protocol: ResponseHandler,\n        loop: asyncio.AbstractEventLoop,\n    ) -> None:\n        self._key = key\n        self._connector = connector\n        self._loop = loop\n        self._protocol: Optional[ResponseHandler] = protocol\n        self._callbacks: List[Callable[[], None]] = []\n\n        if loop.get_debug():\n            self._source_traceback = traceback.extract_stack(sys._getframe(1))\n\n    def __repr__(self) -> str:\n        return f\"Connection<{self._key}>\"\n\n    def __del__(self, _warnings: Any = warnings) -> None:\n        if self._protocol is not None:\n            _warnings.warn(\n                f\"Unclosed connection {self!r}\", ResourceWarning, source=self\n            )\n            if self._loop.is_closed():\n                return\n\n            self._connector._release(self._key, self._protocol, should_close=True)\n\n            context = {\"client_connection\": self, \"message\": \"Unclosed connection\"}\n            if self._source_traceback is not None:\n                context[\"source_traceback\"] = self._source_traceback\n            self._loop.call_exception_handler(context)\n\n    def __bool__(self) -> Literal[True]:\n        \"\"\"Force subclasses to not be falsy, to make checks simpler.\"\"\"\n        return True\n\n    @property\n    def transport(self) -> Optional[asyncio.Transport]:\n        if self._protocol is None:\n            return None\n        return self._protocol.transport\n\n    @property\n    def protocol(self) -> Optional[ResponseHandler]:\n        return self._protocol\n\n    def add_callback(self, callback: Callable[[], None]) -> None:\n        if callback is not None:\n            self._callbacks.append(callback)\n\n    def _notify_release(self) -> None:\n        callbacks, self._callbacks = self._callbacks[:], []\n\n        for cb in callbacks:\n            with suppress(Exception):\n                cb()\n\n    def close(self) -> None:\n        self._notify_release()\n\n        if self._protocol is not None:\n            self._connector._release(self._key, self._protocol, should_close=True)\n            self._protocol = None\n\n    def release(self) -> None:\n        self._notify_release()\n\n        if self._protocol is not None:\n            self._connector._release(\n                self._key, self._protocol, should_close=self._protocol.should_close\n            )\n            self._protocol = None\n\n    @property\n    def closed(self) -> bool:\n        return self._protocol is None or not self._protocol.is_connected()\n\n\nclass _TransportPlaceholder:\n    \"\"\"placeholder for BaseConnector.connect function\"\"\"\n\n    def __init__(self, loop: asyncio.AbstractEventLoop) -> None:\n        fut = loop.create_future()\n        fut.set_result(None)\n        self.closed: asyncio.Future[Optional[Exception]] = fut\n\n    def close(self) -> None:\n        pass\n\n\nclass BaseConnector:\n    \"\"\"Base connector class.\n\n    keepalive_timeout - (optional) Keep-alive timeout.\n    force_close - Set to True to force close and do reconnect\n        after each request (and between redirects).\n    limit - The total number of simultaneous connections.\n    limit_per_host - Number of simultaneous connections to one host.\n    enable_cleanup_closed - Enables clean-up closed ssl transports.\n                            Disabled by default.\n    timeout_ceil_threshold - Trigger ceiling of timeout values when\n                             it's above timeout_ceil_threshold.\n    loop - Optional event loop.\n    \"\"\"\n\n    _closed = True  # prevent AttributeError in __del__ if ctor was failed\n    _source_traceback = None\n\n    # abort transport after 2 seconds (cleanup broken connections)\n    _cleanup_closed_period = 2.0\n\n    def __init__(\n        self,\n        *,\n        keepalive_timeout: Union[_SENTINEL, None, float] = sentinel,\n        force_close: bool = False,\n        limit: int = 100,\n        limit_per_host: int = 0,\n        enable_cleanup_closed: bool = False,\n        timeout_ceil_threshold: float = 5,\n    ) -> None:\n        if force_close:\n            if keepalive_timeout is not None and keepalive_timeout is not sentinel:\n                raise ValueError(\n                    \"keepalive_timeout cannot \" \"be set if force_close is True\"\n                )\n        else:\n            if keepalive_timeout is sentinel:\n                keepalive_timeout = 15.0\n\n        self._timeout_ceil_threshold = timeout_ceil_threshold\n\n        loop = asyncio.get_running_loop()\n\n        self._closed = False\n        if loop.get_debug():\n            self._source_traceback = traceback.extract_stack(sys._getframe(1))\n\n        self._conns: Dict[ConnectionKey, List[Tuple[ResponseHandler, float]]] = {}\n        self._limit = limit\n        self._limit_per_host = limit_per_host\n        self._acquired: Set[ResponseHandler] = set()\n        self._acquired_per_host: DefaultDict[ConnectionKey, Set[ResponseHandler]] = (\n            defaultdict(set)\n        )\n        self._keepalive_timeout = cast(float, keepalive_timeout)\n        self._force_close = force_close\n\n        # {host_key: FIFO list of waiters}\n        self._waiters = defaultdict(deque)  # type: ignore[var-annotated]\n\n        self._loop = loop\n        self._factory = functools.partial(ResponseHandler, loop=loop)\n\n        self.cookies = SimpleCookie()\n\n        # start keep-alive connection cleanup task\n        self._cleanup_handle: Optional[asyncio.TimerHandle] = None\n\n        # start cleanup closed transports task\n        self._cleanup_closed_handle: Optional[asyncio.TimerHandle] = None\n        self._cleanup_closed_disabled = not enable_cleanup_closed\n        self._cleanup_closed_transports: List[Optional[asyncio.Transport]] = []\n        self._cleanup_closed()\n\n    def __del__(self, _warnings: Any = warnings) -> None:\n        if self._closed:\n            return\n        if not self._conns:\n            return\n\n        conns = [repr(c) for c in self._conns.values()]\n\n        self._close_immediately()\n\n        _warnings.warn(f\"Unclosed connector {self!r}\", ResourceWarning, source=self)\n        context = {\n            \"connector\": self,\n            \"connections\": conns,\n            \"message\": \"Unclosed connector\",\n        }\n        if self._source_traceback is not None:\n            context[\"source_traceback\"] = self._source_traceback\n        self._loop.call_exception_handler(context)\n\n    async def __aenter__(self) -> \"BaseConnector\":\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]] = None,\n        exc_value: Optional[BaseException] = None,\n        exc_traceback: Optional[TracebackType] = None,\n    ) -> None:\n        await self.close()\n\n    @property\n    def force_close(self) -> bool:\n        \"\"\"Ultimately close connection on releasing if True.\"\"\"\n        return self._force_close\n\n    @property\n    def limit(self) -> int:\n        \"\"\"The total number for simultaneous connections.\n\n        If limit is 0 the connector has no limit.\n        The default limit size is 100.\n        \"\"\"\n        return self._limit\n\n    @property\n    def limit_per_host(self) -> int:\n        \"\"\"The limit for simultaneous connections to the same endpoint.\n\n        Endpoints are the same if they are have equal\n        (host, port, is_ssl) triple.\n        \"\"\"\n        return self._limit_per_host\n\n    def _cleanup(self) -> None:\n        \"\"\"Cleanup unused transports.\"\"\"\n        if self._cleanup_handle:\n            self._cleanup_handle.cancel()\n            # _cleanup_handle should be unset, otherwise _release() will not\n            # recreate it ever!\n            self._cleanup_handle = None\n\n        now = self._loop.time()\n        timeout = self._keepalive_timeout\n\n        if self._conns:\n            connections = {}\n            deadline = now - timeout\n            for key, conns in self._conns.items():\n                alive = []\n                for proto, use_time in conns:\n                    if proto.is_connected():\n                        if use_time - deadline < 0:\n                            transport = proto.transport\n                            proto.close()\n                            if key.is_ssl and not self._cleanup_closed_disabled:\n                                self._cleanup_closed_transports.append(transport)\n                        else:\n                            alive.append((proto, use_time))\n                    else:\n                        transport = proto.transport\n                        proto.close()\n                        if key.is_ssl and not self._cleanup_closed_disabled:\n                            self._cleanup_closed_transports.append(transport)\n\n                if alive:\n                    connections[key] = alive\n\n            self._conns = connections\n\n        if self._conns:\n            self._cleanup_handle = helpers.weakref_handle(\n                self,\n                \"_cleanup\",\n                timeout,\n                self._loop,\n                timeout_ceil_threshold=self._timeout_ceil_threshold,\n            )\n\n    def _drop_acquired_per_host(\n        self, key: \"ConnectionKey\", val: ResponseHandler\n    ) -> None:\n        acquired_per_host = self._acquired_per_host\n        if key not in acquired_per_host:\n            return\n        conns = acquired_per_host[key]\n        conns.remove(val)\n        if not conns:\n            del self._acquired_per_host[key]\n\n    def _cleanup_closed(self) -> None:\n        \"\"\"Double confirmation for transport close.\n\n        Some broken ssl servers may leave socket open without proper close.\n        \"\"\"\n        if self._cleanup_closed_handle:\n            self._cleanup_closed_handle.cancel()\n\n        for transport in self._cleanup_closed_transports:\n            if transport is not None:\n                transport.abort()\n\n        self._cleanup_closed_transports = []\n\n        if not self._cleanup_closed_disabled:\n            self._cleanup_closed_handle = helpers.weakref_handle(\n                self,\n                \"_cleanup_closed\",\n                self._cleanup_closed_period,\n                self._loop,\n                timeout_ceil_threshold=self._timeout_ceil_threshold,\n            )\n\n    async def close(self) -> None:\n        \"\"\"Close all opened transports.\"\"\"\n        waiters = self._close_immediately()\n        if waiters:\n            results = await asyncio.gather(*waiters, return_exceptions=True)\n            for res in results:\n                if isinstance(res, Exception):\n                    err_msg = \"Error while closing connector: \" + repr(res)\n                    logging.error(err_msg)\n\n    def _close_immediately(self) -> List[\"asyncio.Future[None]\"]:\n        waiters: List[\"asyncio.Future[None]\"] = []\n\n        if self._closed:\n            return waiters\n\n        self._closed = True\n\n        try:\n            if self._loop.is_closed():\n                return waiters\n\n            # cancel cleanup task\n            if self._cleanup_handle:\n                self._cleanup_handle.cancel()\n\n            # cancel cleanup close task\n            if self._cleanup_closed_handle:\n                self._cleanup_closed_handle.cancel()\n\n            for data in self._conns.values():\n                for proto, t0 in data:\n                    proto.close()\n                    waiters.append(proto.closed)\n\n            for proto in self._acquired:\n                proto.close()\n                waiters.append(proto.closed)\n\n            # TODO (A.Yushovskiy, 24-May-2019) collect transp. closing futures\n            for transport in self._cleanup_closed_transports:\n                if transport is not None:\n                    transport.abort()\n\n            return waiters\n\n        finally:\n            self._conns.clear()\n            self._acquired.clear()\n            self._waiters.clear()\n            self._cleanup_handle = None\n            self._cleanup_closed_transports.clear()\n            self._cleanup_closed_handle = None\n\n    @property\n    def closed(self) -> bool:\n        \"\"\"Is connector closed.\n\n        A readonly property.\n        \"\"\"\n        return self._closed\n\n    def _available_connections(self, key: \"ConnectionKey\") -> int:\n        \"\"\"\n        Return number of available connections.\n\n        The limit, limit_per_host and the connection key are taken into account.\n\n        If it returns less than 1 means that there are no connections\n        available.\n        \"\"\"\n        if self._limit:\n            # total calc available connections\n            available = self._limit - len(self._acquired)\n\n            # check limit per host\n            if (\n                self._limit_per_host\n                and available > 0\n                and key in self._acquired_per_host\n            ):\n                acquired = self._acquired_per_host.get(key)\n                assert acquired is not None\n                available = self._limit_per_host - len(acquired)\n\n        elif self._limit_per_host and key in self._acquired_per_host:\n            # check limit per host\n            acquired = self._acquired_per_host.get(key)\n            assert acquired is not None\n            available = self._limit_per_host - len(acquired)\n        else:\n            available = 1\n\n        return available\n\n    async def connect(\n        self, req: ClientRequest, traces: List[\"Trace\"], timeout: \"ClientTimeout\"\n    ) -> Connection:\n        \"\"\"Get from pool or create new connection.\"\"\"\n        key = req.connection_key\n        available = self._available_connections(key)\n\n        # Wait if there are no available connections or if there are/were\n        # waiters (i.e. don't steal connection from a waiter about to wake up)\n        if available <= 0 or key in self._waiters:\n            fut = self._loop.create_future()\n\n            # This connection will now count towards the limit.\n            self._waiters[key].append(fut)\n\n            if traces:\n                for trace in traces:\n                    await trace.send_connection_queued_start()\n\n            try:\n                await fut\n            except BaseException as e:\n                if key in self._waiters:\n                    # remove a waiter even if it was cancelled, normally it's\n                    #  removed when it's notified\n                    try:\n                        self._waiters[key].remove(fut)\n                    except ValueError:  # fut may no longer be in list\n                        pass\n\n                raise e\n            finally:\n                if key in self._waiters and not self._waiters[key]:\n                    del self._waiters[key]\n\n            if traces:\n                for trace in traces:\n                    await trace.send_connection_queued_end()\n\n        proto = self._get(key)\n        if proto is None:\n            placeholder = cast(ResponseHandler, _TransportPlaceholder(self._loop))\n            self._acquired.add(placeholder)\n            self._acquired_per_host[key].add(placeholder)\n\n            if traces:\n                for trace in traces:\n                    await trace.send_connection_create_start()\n\n            try:\n                proto = await self._create_connection(req, traces, timeout)\n                if self._closed:\n                    proto.close()\n                    raise ClientConnectionError(\"Connector is closed.\")\n            except BaseException:\n                if not self._closed:\n                    self._acquired.remove(placeholder)\n                    self._drop_acquired_per_host(key, placeholder)\n                    self._release_waiter()\n                raise\n            else:\n                if not self._closed:\n                    self._acquired.remove(placeholder)\n                    self._drop_acquired_per_host(key, placeholder)\n\n            if traces:\n                for trace in traces:\n                    await trace.send_connection_create_end()\n        else:\n            if traces:\n                # Acquire the connection to prevent race conditions with limits\n                placeholder = cast(ResponseHandler, _TransportPlaceholder(self._loop))\n                self._acquired.add(placeholder)\n                self._acquired_per_host[key].add(placeholder)\n                for trace in traces:\n                    await trace.send_connection_reuseconn()\n                self._acquired.remove(placeholder)\n                self._drop_acquired_per_host(key, placeholder)\n\n        self._acquired.add(proto)\n        self._acquired_per_host[key].add(proto)\n        return Connection(self, key, proto, self._loop)\n\n    def _get(self, key: \"ConnectionKey\") -> Optional[ResponseHandler]:\n        try:\n            conns = self._conns[key]\n        except KeyError:\n            return None\n\n        t1 = self._loop.time()\n        while conns:\n            proto, t0 = conns.pop()\n            if proto.is_connected():\n                if t1 - t0 > self._keepalive_timeout:\n                    transport = proto.transport\n                    proto.close()\n                    # only for SSL transports\n                    if key.is_ssl and not self._cleanup_closed_disabled:\n                        self._cleanup_closed_transports.append(transport)\n                else:\n                    if not conns:\n                        # The very last connection was reclaimed: drop the key\n                        del self._conns[key]\n                    return proto\n            else:\n                transport = proto.transport\n                proto.close()\n                if key.is_ssl and not self._cleanup_closed_disabled:\n                    self._cleanup_closed_transports.append(transport)\n\n        # No more connections: drop the key\n        del self._conns[key]\n        return None\n\n    def _release_waiter(self) -> None:\n        \"\"\"\n        Iterates over all waiters until one to be released is found.\n\n        The one to be released is not finished and\n        belongs to a host that has available connections.\n        \"\"\"\n        if not self._waiters:\n            return\n\n        # Having the dict keys ordered this avoids to iterate\n        # at the same order at each call.\n        queues = list(self._waiters.keys())\n        random.shuffle(queues)\n\n        for key in queues:\n            if self._available_connections(key) < 1:\n                continue\n\n            waiters = self._waiters[key]\n            while waiters:\n                waiter = waiters.popleft()\n                if not waiter.done():\n                    waiter.set_result(None)\n                    return\n\n    def _release_acquired(self, key: \"ConnectionKey\", proto: ResponseHandler) -> None:\n        if self._closed:\n            # acquired connection is already released on connector closing\n            return\n\n        try:\n            self._acquired.remove(proto)\n            self._drop_acquired_per_host(key, proto)\n        except KeyError:  # pragma: no cover\n            # this may be result of undetermenistic order of objects\n            # finalization due garbage collection.\n            pass\n        else:\n            self._release_waiter()\n\n    def _release(\n        self,\n        key: \"ConnectionKey\",\n        protocol: ResponseHandler,\n        *,\n        should_close: bool = False,\n    ) -> None:\n        if self._closed:\n            # acquired connection is already released on connector closing\n            return\n\n        self._release_acquired(key, protocol)\n\n        if self._force_close:\n            should_close = True\n\n        if should_close or protocol.should_close:\n            transport = protocol.transport\n            protocol.close()\n            # TODO: Remove once fixed: https://bugs.python.org/issue39951\n            # See PR #6321\n            set_result(protocol.closed, None)\n\n            if key.is_ssl and not self._cleanup_closed_disabled:\n                self._cleanup_closed_transports.append(transport)\n        else:\n            conns = self._conns.get(key)\n            if conns is None:\n                conns = self._conns[key] = []\n            conns.append((protocol, self._loop.time()))\n\n            if self._cleanup_handle is None:\n                self._cleanup_handle = helpers.weakref_handle(\n                    self,\n                    \"_cleanup\",\n                    self._keepalive_timeout,\n                    self._loop,\n                    timeout_ceil_threshold=self._timeout_ceil_threshold,\n                )\n\n    async def _create_connection(\n        self, req: ClientRequest, traces: List[\"Trace\"], timeout: \"ClientTimeout\"\n    ) -> ResponseHandler:\n        raise NotImplementedError()\n\n\nclass _DNSCacheTable:\n    def __init__(self, ttl: Optional[float] = None) -> None:\n        self._addrs_rr: Dict[Tuple[str, int], Tuple[Iterator[ResolveResult], int]] = {}\n        self._timestamps: Dict[Tuple[str, int], float] = {}\n        self._ttl = ttl\n\n    def __contains__(self, host: object) -> bool:\n        return host in self._addrs_rr\n\n    def add(self, key: Tuple[str, int], addrs: List[ResolveResult]) -> None:\n        self._addrs_rr[key] = (cycle(addrs), len(addrs))\n\n        if self._ttl is not None:\n            self._timestamps[key] = monotonic()\n\n    def remove(self, key: Tuple[str, int]) -> None:\n        self._addrs_rr.pop(key, None)\n\n        if self._ttl is not None:\n            self._timestamps.pop(key, None)\n\n    def clear(self) -> None:\n        self._addrs_rr.clear()\n        self._timestamps.clear()\n\n    def next_addrs(self, key: Tuple[str, int]) -> List[ResolveResult]:\n        loop, length = self._addrs_rr[key]\n        addrs = list(islice(loop, length))\n        # Consume one more element to shift internal state of `cycle`\n        next(loop)\n        return addrs\n\n    def expired(self, key: Tuple[str, int]) -> bool:\n        if self._ttl is None:\n            return False\n\n        return self._timestamps[key] + self._ttl < monotonic()\n\n\nclass TCPConnector(BaseConnector):\n    \"\"\"TCP connector.\n\n    verify_ssl - Set to True to check ssl certifications.\n    fingerprint - Pass the binary sha256\n        digest of the expected certificate in DER format to verify\n        that the certificate the server presents matches. See also\n        https://en.wikipedia.org/wiki/Transport_Layer_Security#Certificate_pinning\n    resolver - Enable DNS lookups and use this\n        resolver\n    use_dns_cache - Use memory cache for DNS lookups.\n    ttl_dns_cache - Max seconds having cached a DNS entry, None forever.\n    family - socket address family\n    local_addr - local tuple of (host, port) to bind socket to\n\n    keepalive_timeout - (optional) Keep-alive timeout.\n    force_close - Set to True to force close and do reconnect\n        after each request (and between redirects).\n    limit - The total number of simultaneous connections.\n    limit_per_host - Number of simultaneous connections to one host.\n    enable_cleanup_closed - Enables clean-up closed ssl transports.\n                            Disabled by default.\n    happy_eyeballs_delay - This is the \u201cConnection Attempt Delay\u201d\n                           as defined in RFC 8305. To disable\n                           the happy eyeballs algorithm, set to None.\n    interleave - \u201cFirst Address Family Count\u201d as defined in RFC 8305\n    loop - Optional event loop.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        use_dns_cache: bool = True,\n        ttl_dns_cache: Optional[int] = 10,\n        family: socket.AddressFamily = socket.AddressFamily.AF_UNSPEC,\n        ssl: Union[bool, Fingerprint, SSLContext] = True,\n        local_addr: Optional[Tuple[str, int]] = None,\n        resolver: Optional[AbstractResolver] = None,\n        keepalive_timeout: Union[None, float, _SENTINEL] = sentinel,\n        force_close: bool = False,\n        limit: int = 100,\n        limit_per_host: int = 0,\n        enable_cleanup_closed: bool = False,\n        timeout_ceil_threshold: float = 5,\n        happy_eyeballs_delay: Optional[float] = 0.25,\n        interleave: Optional[int] = None,\n    ):\n        super().__init__(\n            keepalive_timeout=keepalive_timeout,\n            force_close=force_close,\n            limit=limit,\n            limit_per_host=limit_per_host,\n            enable_cleanup_closed=enable_cleanup_closed,\n            timeout_ceil_threshold=timeout_ceil_threshold,\n        )\n\n        if not isinstance(ssl, SSL_ALLOWED_TYPES):\n            raise TypeError(\n                \"ssl should be SSLContext, Fingerprint, or bool, \"\n                \"got {!r} instead.\".format(ssl)\n            )\n        self._ssl = ssl\n        if resolver is None:\n            resolver = DefaultResolver()\n        self._resolver: AbstractResolver = resolver\n\n        self._use_dns_cache = use_dns_cache\n        self._cached_hosts = _DNSCacheTable(ttl=ttl_dns_cache)\n        self._throttle_dns_events: Dict[Tuple[str, int], EventResultOrError] = {}\n        self._family = family\n        self._local_addr_infos = aiohappyeyeballs.addr_to_addr_infos(local_addr)\n        self._happy_eyeballs_delay = happy_eyeballs_delay\n        self._interleave = interleave\n\n    def _close_immediately(self) -> List[\"asyncio.Future[None]\"]:\n        for ev in self._throttle_dns_events.values():\n            ev.cancel()\n        return super()._close_immediately()\n\n    @property\n    def family(self) -> int:\n        \"\"\"Socket family like AF_INET.\"\"\"\n        return self._family\n\n    @property\n    def use_dns_cache(self) -> bool:\n        \"\"\"True if local DNS caching is enabled.\"\"\"\n        return self._use_dns_cache\n\n    def clear_dns_cache(\n        self, host: Optional[str] = None, port: Optional[int] = None\n    ) -> None:\n        \"\"\"Remove specified host/port or clear all dns local cache.\"\"\"\n        if host is not None and port is not None:\n            self._cached_hosts.remove((host, port))\n        elif host is not None or port is not None:\n            raise ValueError(\"either both host and port \" \"or none of them are allowed\")\n        else:\n            self._cached_hosts.clear()\n\n    async def _resolve_host(\n        self, host: str, port: int, traces: Optional[List[\"Trace\"]] = None\n    ) -> List[ResolveResult]:\n        \"\"\"Resolve host and return list of addresses.\"\"\"\n        if is_ip_address(host):\n            return [\n                {\n                    \"hostname\": host,\n                    \"host\": host,\n                    \"port\": port,\n                    \"family\": self._family,\n                    \"proto\": 0,\n                    \"flags\": 0,\n                }\n            ]\n\n        if not self._use_dns_cache:\n            if traces:\n                for trace in traces:\n                    await trace.send_dns_resolvehost_start(host)\n\n            res = await self._resolver.resolve(host, port, family=self._family)\n\n            if traces:\n                for trace in traces:\n                    await trace.send_dns_resolvehost_end(host)\n\n            return res\n\n        key = (host, port)\n        if key in self._cached_hosts and not self._cached_hosts.expired(key):\n            # get result early, before any await (#4014)\n            result = self._cached_hosts.next_addrs(key)\n\n            if traces:\n                for trace in traces:\n                    await trace.send_dns_cache_hit(host)\n            return result\n\n        #\n        # If multiple connectors are resolving the same host, we wait\n        # for the first one to resolve and then use the result for all of them.\n        # We use a throttle event to ensure that we only resolve the host once\n        # and then use the result for all the waiters.\n        #\n        # In this case we need to create a task to ensure that we can shield\n        # the task from cancellation as cancelling this lookup should not cancel\n        # the underlying lookup or else the cancel event will get broadcast to\n        # all the waiters across all connections.\n        #\n        resolved_host_task = asyncio.create_task(\n            self._resolve_host_with_throttle(key, host, port, traces)\n        )\n        try:\n            return await asyncio.shield(resolved_host_task)\n        except asyncio.CancelledError:\n\n            def drop_exception(fut: \"asyncio.Future[List[ResolveResult]]\") -> None:\n                with suppress(Exception, asyncio.CancelledError):\n                    fut.result()\n\n            resolved_host_task.add_done_callback(drop_exception)\n            raise\n\n    async def _resolve_host_with_throttle(\n        self,\n        key: Tuple[str, int],\n        host: str,\n        port: int,\n        traces: Optional[List[\"Trace\"]],\n    ) -> List[ResolveResult]:\n        \"\"\"Resolve host with a dns events throttle.\"\"\"\n        if key in self._throttle_dns_events:\n            # get event early, before any await (#4014)\n            event = self._throttle_dns_events[key]\n            if traces:\n                for trace in traces:\n                    await trace.send_dns_cache_hit(host)\n            await event.wait()\n        else:\n            # update dict early, before any await (#4014)\n            self._throttle_dns_events[key] = EventResultOrError(self._loop)\n            if traces:\n                for trace in traces:\n                    await trace.send_dns_cache_miss(host)\n            try:\n                if traces:\n                    for trace in traces:\n                        await trace.send_dns_resolvehost_start(host)\n\n                addrs = await self._resolver.resolve(host, port, family=self._family)\n                if traces:\n                    for trace in traces:\n                        await trace.send_dns_resolvehost_end(host)\n\n                self._cached_hosts.add(key, addrs)\n                self._throttle_dns_events[key].set()\n            except BaseException as e:\n                # any DNS exception, independently of the implementation\n                # is set for the waiters to raise the same exception.\n                self._throttle_dns_events[key].set(exc=e)\n                raise\n            finally:\n                self._throttle_dns_events.pop(key)\n\n        return self._cached_hosts.next_addrs(key)\n\n    async def _create_connection(\n        self, req: ClientRequest, traces: List[\"Trace\"], timeout: \"ClientTimeout\"\n    ) -> ResponseHandler:\n        \"\"\"Create connection.\n\n        Has same keyword arguments as BaseEventLoop.create_connection.\n        \"\"\"\n        if req.proxy:\n            _, proto = await self._create_proxy_connection(req, traces, timeout)\n        else:\n            _, proto = await self._create_direct_connection(req, traces, timeout)\n\n        return proto\n\n    @staticmethod\n    @functools.lru_cache(None)\n    def _make_ssl_context(verified: bool) -> SSLContext:\n        if verified:\n            return ssl.create_default_context()\n        else:\n            sslcontext = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n            sslcontext.options |= ssl.OP_NO_SSLv2\n            sslcontext.options |= ssl.OP_NO_SSLv3\n            sslcontext.check_hostname = False\n            sslcontext.verify_mode = ssl.CERT_NONE\n            try:\n                sslcontext.options |= ssl.OP_NO_COMPRESSION\n            except AttributeError as attr_err:\n                warnings.warn(\n                    \"{!s}: The Python interpreter is compiled \"\n                    \"against OpenSSL < 1.0.0. Ref: \"\n                    \"https://docs.python.org/3/library/ssl.html\"\n                    \"#ssl.OP_NO_COMPRESSION\".format(attr_err),\n                )\n            sslcontext.set_default_verify_paths()\n            return sslcontext\n\n    def _get_ssl_context(self, req: ClientRequest) -> Optional[SSLContext]:\n        \"\"\"Logic to get the correct SSL context\n\n        0. if req.ssl is false, return None\n\n        1. if ssl_context is specified in req, use it\n        2. if _ssl_context is specified in self, use it\n        3. otherwise:\n            1. if verify_ssl is not specified in req, use self.ssl_context\n               (will generate a default context according to self.verify_ssl)\n            2. if verify_ssl is True in req, generate a default SSL context\n            3. if verify_ssl is False in req, generate a SSL context that\n               won't verify\n        \"\"\"\n        if req.is_ssl():\n            if ssl is None:  # pragma: no cover\n                raise RuntimeError(\"SSL is not supported.\")\n            sslcontext = req.ssl\n            if isinstance(sslcontext, ssl.SSLContext):\n                return sslcontext\n            if sslcontext is not True:\n                # not verified or fingerprinted\n                return self._make_ssl_context(False)\n            sslcontext = self._ssl\n            if isinstance(sslcontext, ssl.SSLContext):\n                return sslcontext\n            if sslcontext is not True:\n                # not verified or fingerprinted\n                return self._make_ssl_context(False)\n            return self._make_ssl_context(True)\n        else:\n            return None\n\n    def _get_fingerprint(self, req: ClientRequest) -> Optional[\"Fingerprint\"]:\n        ret = req.ssl\n        if isinstance(ret, Fingerprint):\n            return ret\n        ret = self._ssl\n        if isinstance(ret, Fingerprint):\n            return ret\n        return None\n\n    async def _wrap_create_connection(\n        self,\n        *args: Any,\n        addr_infos: List[aiohappyeyeballs.AddrInfoType],\n        req: ClientRequest,\n        timeout: \"ClientTimeout\",\n        client_error: Type[Exception] = ClientConnectorError,\n        **kwargs: Any,\n    ) -> Tuple[asyncio.Transport, ResponseHandler]:\n        try:\n            async with ceil_timeout(\n                timeout.sock_connect, ceil_threshold=timeout.ceil_threshold\n            ):\n                sock = await aiohappyeyeballs.start_connection(\n                    addr_infos=addr_infos,\n                    local_addr_infos=self._local_addr_infos,\n                    happy_eyeballs_delay=self._happy_eyeballs_delay,\n                    interleave=self._interleave,\n                    loop=self._loop,\n                )\n                return await self._loop.create_connection(*args, **kwargs, sock=sock)\n        except cert_errors as exc:\n            raise ClientConnectorCertificateError(req.connection_key, exc) from exc\n        except ssl_errors as exc:\n            raise ClientConnectorSSLError(req.connection_key, exc) from exc\n        except OSError as exc:\n            if exc.errno is None and isinstance(exc, asyncio.TimeoutError):\n                raise\n            raise client_error(req.connection_key, exc) from exc\n\n    def _warn_about_tls_in_tls(\n        self,\n        underlying_transport: asyncio.Transport,\n        req: ClientRequest,\n    ) -> None:\n        \"\"\"Issue a warning if the requested URL has HTTPS scheme.\"\"\"\n        if req.request_info.url.scheme != \"https\":\n            return\n\n        asyncio_supports_tls_in_tls = getattr(\n            underlying_transport,\n            \"_start_tls_compatible\",\n            False,\n        )\n\n        if asyncio_supports_tls_in_tls:\n            return\n\n        warnings.warn(\n            \"An HTTPS request is being sent through an HTTPS proxy. \"\n            \"This support for TLS in TLS is known to be disabled \"\n            \"in the stdlib asyncio. This is why you'll probably see \"\n            \"an error in the log below.\\n\\n\"\n            \"It is possible to enable it via monkeypatching. \"\n            \"For more details, see:\\n\"\n            \"* https://bugs.python.org/issue37179\\n\"\n            \"* https://github.com/python/cpython/pull/28073\\n\\n\"\n            \"You can temporarily patch this as follows:\\n\"\n            \"* https://docs.aiohttp.org/en/stable/client_advanced.html#proxy-support\\n\"\n            \"* https://github.com/aio-libs/aiohttp/discussions/6044\\n\",\n            RuntimeWarning,\n            source=self,\n            # Why `4`? At least 3 of the calls in the stack originate\n            # from the methods in this class.\n            stacklevel=3,\n        )\n\n    async def _start_tls_connection(\n        self,\n        underlying_transport: asyncio.Transport,\n        req: ClientRequest,\n        timeout: \"ClientTimeout\",\n        client_error: Type[Exception] = ClientConnectorError,\n    ) -> Tuple[asyncio.BaseTransport, ResponseHandler]:\n        \"\"\"Wrap the raw TCP transport with TLS.\"\"\"\n        tls_proto = self._factory()  # Create a brand new proto for TLS\n\n        # Safety of the `cast()` call here is based on the fact that\n        # internally `_get_ssl_context()` only returns `None` when\n        # `req.is_ssl()` evaluates to `False` which is never gonna happen\n        # in this code path. Of course, it's rather fragile\n        # maintainability-wise but this is to be solved separately.\n        sslcontext = cast(ssl.SSLContext, self._get_ssl_context(req))\n\n        try:\n            async with ceil_timeout(\n                timeout.sock_connect, ceil_threshold=timeout.ceil_threshold\n            ):\n                try:\n                    tls_transport = await self._loop.start_tls(\n                        underlying_transport,\n                        tls_proto,\n                        sslcontext,\n                        server_hostname=req.server_hostname or req.host,\n                        ssl_handshake_timeout=timeout.total,\n                    )\n                except BaseException:\n                    # We need to close the underlying transport since\n                    # `start_tls()` probably failed before it had a\n                    # chance to do this:\n                    underlying_transport.close()\n                    raise\n        except cert_errors as exc:\n            raise ClientConnectorCertificateError(req.connection_key, exc) from exc\n        except ssl_errors as exc:\n            raise ClientConnectorSSLError(req.connection_key, exc) from exc\n        except OSError as exc:\n            if exc.errno is None and isinstance(exc, asyncio.TimeoutError):\n                raise\n            raise client_error(req.connection_key, exc) from exc\n        except TypeError as type_err:\n            # Example cause looks like this:\n            # TypeError: transport <asyncio.sslproto._SSLProtocolTransport\n            # object at 0x7f760615e460> is not supported by start_tls()\n\n            raise ClientConnectionError(\n                \"Cannot initialize a TLS-in-TLS connection to host \"\n                f\"{req.host!s}:{req.port:d} through an underlying connection \"\n                f\"to an HTTPS proxy {req.proxy!s} ssl:{req.ssl or 'default'} \"\n                f\"[{type_err!s}]\"\n            ) from type_err\n        else:\n            if tls_transport is None:\n                msg = \"Failed to start TLS (possibly caused by closing transport)\"\n                raise client_error(req.connection_key, OSError(msg))\n            tls_proto.connection_made(\n                tls_transport\n            )  # Kick the state machine of the new TLS protocol\n\n        return tls_transport, tls_proto\n\n    def _convert_hosts_to_addr_infos(\n        self, hosts: List[ResolveResult]\n    ) -> List[aiohappyeyeballs.AddrInfoType]:\n        \"\"\"Converts the list of hosts to a list of addr_infos.\n\n        The list of hosts is the result of a DNS lookup. The list of\n        addr_infos is the result of a call to `socket.getaddrinfo()`.\n        \"\"\"\n        addr_infos: List[aiohappyeyeballs.AddrInfoType] = []\n        for hinfo in hosts:\n            host = hinfo[\"host\"]\n            is_ipv6 = \":\" in host\n            family = socket.AF_INET6 if is_ipv6 else socket.AF_INET\n            if self._family and self._family != family:\n                continue\n            addr = (host, hinfo[\"port\"], 0, 0) if is_ipv6 else (host, hinfo[\"port\"])\n            addr_infos.append(\n                (family, socket.SOCK_STREAM, socket.IPPROTO_TCP, \"\", addr)\n            )\n        return addr_infos\n\n    async def _create_direct_connection(\n        self,\n        req: ClientRequest,\n        traces: List[\"Trace\"],\n        timeout: \"ClientTimeout\",\n        *,\n        client_error: Type[Exception] = ClientConnectorError,\n    ) -> Tuple[asyncio.Transport, ResponseHandler]:\n        sslcontext = self._get_ssl_context(req)\n        fingerprint = self._get_fingerprint(req)\n\n        host = req.url.raw_host\n        assert host is not None\n        # Replace multiple trailing dots with a single one.\n        # A trailing dot is only present for fully-qualified domain names.\n        # See https://github.com/aio-libs/aiohttp/pull/7364.\n        if host.endswith(\"..\"):\n            host = host.rstrip(\".\") + \".\"\n        port = req.port\n        assert port is not None\n        try:\n            # Cancelling this lookup should not cancel the underlying lookup\n            #  or else the cancel event will get broadcast to all the waiters\n            #  across all connections.\n            hosts = await self._resolve_host(host, port, traces=traces)\n        except OSError as exc:\n            if exc.errno is None and isinstance(exc, asyncio.TimeoutError):\n                raise\n            # in case of proxy it is not ClientProxyConnectionError\n            # it is problem of resolving proxy ip itself\n            raise ClientConnectorError(req.connection_key, exc) from exc\n\n        last_exc: Optional[Exception] = None\n        addr_infos = self._convert_hosts_to_addr_infos(hosts)\n        while addr_infos:\n            # Strip trailing dots, certificates contain FQDN without dots.\n            # See https://github.com/aio-libs/aiohttp/issues/3636\n            server_hostname = (\n                (req.server_hostname or host).rstrip(\".\") if sslcontext else None\n            )\n\n            try:\n                transp, proto = await self._wrap_create_connection(\n                    self._factory,\n                    timeout=timeout,\n                    ssl=sslcontext,\n                    addr_infos=addr_infos,\n                    server_hostname=server_hostname,\n                    req=req,\n                    client_error=client_error,\n                )\n            except ClientConnectorError as exc:\n                last_exc = exc\n                aiohappyeyeballs.pop_addr_infos_interleave(addr_infos, self._interleave)\n                continue\n\n            if req.is_ssl() and fingerprint:\n                try:\n                    fingerprint.check(transp)\n                except ServerFingerprintMismatch as exc:\n                    transp.close()\n                    if not self._cleanup_closed_disabled:\n                        self._cleanup_closed_transports.append(transp)\n                    last_exc = exc\n                    # Remove the bad peer from the list of addr_infos\n                    sock: socket.socket = transp.get_extra_info(\"socket\")\n                    bad_peer = sock.getpeername()\n                    aiohappyeyeballs.remove_addr_infos(addr_infos, bad_peer)\n                    continue\n\n            return transp, proto\n        assert last_exc is not None\n        raise last_exc\n\n    async def _create_proxy_connection(\n        self, req: ClientRequest, traces: List[\"Trace\"], timeout: \"ClientTimeout\"\n    ) -> Tuple[asyncio.BaseTransport, ResponseHandler]:\n        headers: Dict[str, str] = {}\n        if req.proxy_headers is not None:\n            headers = req.proxy_headers  # type: ignore[assignment]\n        headers[hdrs.HOST] = req.headers[hdrs.HOST]\n\n        url = req.proxy\n        assert url is not None\n        proxy_req = ClientRequest(\n            hdrs.METH_GET,\n            url,\n            headers=headers,\n            auth=req.proxy_auth,\n            loop=self._loop,\n            ssl=req.ssl,\n        )\n\n        # create connection to proxy server\n        transport, proto = await self._create_direct_connection(\n            proxy_req, [], timeout, client_error=ClientProxyConnectionError\n        )\n\n        # Many HTTP proxies has buggy keepalive support.  Let's not\n        # reuse connection but close it after processing every\n        # response.\n        proto.force_close()\n\n        auth = proxy_req.headers.pop(hdrs.AUTHORIZATION, None)\n        if auth is not None:\n            if not req.is_ssl():\n                req.headers[hdrs.PROXY_AUTHORIZATION] = auth\n            else:\n                proxy_req.headers[hdrs.PROXY_AUTHORIZATION] = auth\n\n        if req.is_ssl():\n            self._warn_about_tls_in_tls(transport, req)\n\n            # For HTTPS requests over HTTP proxy\n            # we must notify proxy to tunnel connection\n            # so we send CONNECT command:\n            #   CONNECT www.python.org:443 HTTP/1.1\n            #   Host: www.python.org\n            #\n            # next we must do TLS handshake and so on\n            # to do this we must wrap raw socket into secure one\n            # asyncio handles this perfectly\n            proxy_req.method = hdrs.METH_CONNECT\n            proxy_req.url = req.url\n            key = dataclasses.replace(\n                req.connection_key, proxy=None, proxy_auth=None, proxy_headers_hash=None\n            )\n            conn = Connection(self, key, proto, self._loop)\n            proxy_resp = await proxy_req.send(conn)\n            try:\n                protocol = conn._protocol\n                assert protocol is not None\n\n                # read_until_eof=True will ensure the connection isn't closed\n                # once the response is received and processed allowing\n                # START_TLS to work on the connection below.\n                protocol.set_response_params(\n                    read_until_eof=True,\n                    timeout_ceil_threshold=self._timeout_ceil_threshold,\n                )\n                resp = await proxy_resp.start(conn)\n            except BaseException:\n                proxy_resp.close()\n                conn.close()\n                raise\n            else:\n                conn._protocol = None\n                conn._transport = None\n                try:\n                    if resp.status != 200:\n                        message = resp.reason\n                        if message is None:\n                            message = HTTPStatus(resp.status).phrase\n                        raise ClientHttpProxyError(\n                            proxy_resp.request_info,\n                            resp.history,\n                            status=resp.status,\n                            message=message,\n                            headers=resp.headers,\n                        )\n                except BaseException:\n                    # It shouldn't be closed in `finally` because it's fed to\n                    # `loop.start_tls()` and the docs say not to touch it after\n                    # passing there.\n                    transport.close()\n                    raise\n\n                return await self._start_tls_connection(\n                    # Access the old transport for the last time before it's\n                    # closed and forgotten forever:\n                    transport,\n                    req=req,\n                    timeout=timeout,\n                )\n            finally:\n                proxy_resp.close()\n\n        return transport, proto\n\n\nclass UnixConnector(BaseConnector):\n    \"\"\"Unix socket connector.\n\n    path - Unix socket path.\n    keepalive_timeout - (optional) Keep-alive timeout.\n    force_close - Set to True to force close and do reconnect\n        after each request (and between redirects).\n    limit - The total number of simultaneous connections.\n    limit_per_host - Number of simultaneous connections to one host.\n    loop - Optional event loop.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: str,\n        force_close: bool = False,\n        keepalive_timeout: Union[_SENTINEL, float, None] = sentinel,\n        limit: int = 100,\n        limit_per_host: int = 0,\n    ) -> None:\n        super().__init__(\n            force_close=force_close,\n            keepalive_timeout=keepalive_timeout,\n            limit=limit,\n            limit_per_host=limit_per_host,\n        )\n        self._path = path\n\n    @property\n    def path(self) -> str:\n        \"\"\"Path to unix socket.\"\"\"\n        return self._path\n\n    async def _create_connection(\n        self, req: ClientRequest, traces: List[\"Trace\"], timeout: \"ClientTimeout\"\n    ) -> ResponseHandler:\n        try:\n            async with ceil_timeout(\n                timeout.sock_connect, ceil_threshold=timeout.ceil_threshold\n            ):\n                _, proto = await self._loop.create_unix_connection(\n                    self._factory, self._path\n                )\n        except OSError as exc:\n            if exc.errno is None and isinstance(exc, asyncio.TimeoutError):\n                raise\n            raise UnixClientConnectorError(self.path, req.connection_key, exc) from exc\n\n        return proto\n\n\nclass NamedPipeConnector(BaseConnector):\n    \"\"\"Named pipe connector.\n\n    Only supported by the proactor event loop.\n    See also: https://docs.python.org/3/library/asyncio-eventloop.html\n\n    path - Windows named pipe path.\n    keepalive_timeout - (optional) Keep-alive timeout.\n    force_close - Set to True to force close and do reconnect\n        after each request (and between redirects).\n    limit - The total number of simultaneous connections.\n    limit_per_host - Number of simultaneous connections to one host.\n    loop - Optional event loop.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: str,\n        force_close: bool = False,\n        keepalive_timeout: Union[_SENTINEL, float, None] = sentinel,\n        limit: int = 100,\n        limit_per_host: int = 0,\n    ) -> None:\n        super().__init__(\n            force_close=force_close,\n            keepalive_timeout=keepalive_timeout,\n            limit=limit,\n            limit_per_host=limit_per_host,\n        )\n        if not isinstance(\n            self._loop, asyncio.ProactorEventLoop  # type: ignore[attr-defined]\n        ):\n            raise RuntimeError(\n                \"Named Pipes only available in proactor \" \"loop under windows\"\n            )\n        self._path = path\n\n    @property\n    def path(self) -> str:\n        \"\"\"Path to the named pipe.\"\"\"\n        return self._path\n\n    async def _create_connection(\n        self, req: ClientRequest, traces: List[\"Trace\"], timeout: \"ClientTimeout\"\n    ) -> ResponseHandler:\n        try:\n            async with ceil_timeout(\n                timeout.sock_connect, ceil_threshold=timeout.ceil_threshold\n            ):\n                _, proto = await self._loop.create_pipe_connection(  # type: ignore[attr-defined]\n                    self._factory, self._path\n                )\n                # the drain is required so that the connection_made is called\n                # and transport is set otherwise it is not set before the\n                # `assert conn.transport is not None`\n                # in client.py's _request method\n                await asyncio.sleep(0)\n                # other option is to manually set transport like\n                # `proto.transport = trans`\n        except OSError as exc:\n            if exc.errno is None and isinstance(exc, asyncio.TimeoutError):\n                raise\n            raise ClientConnectorError(req.connection_key, exc) from exc\n\n        return cast(ResponseHandler, proto)\n", "aiohttp/http_writer.py": "\"\"\"Http related parsers and protocol.\"\"\"\n\nimport asyncio\nimport zlib\nfrom typing import Any, Awaitable, Callable, NamedTuple, Optional, Union  # noqa\n\nfrom multidict import CIMultiDict\n\nfrom .abc import AbstractStreamWriter\nfrom .base_protocol import BaseProtocol\nfrom .compression_utils import ZLibCompressor\nfrom .helpers import NO_EXTENSIONS\n\n__all__ = (\"StreamWriter\", \"HttpVersion\", \"HttpVersion10\", \"HttpVersion11\")\n\n\nclass HttpVersion(NamedTuple):\n    major: int\n    minor: int\n\n\nHttpVersion10 = HttpVersion(1, 0)\nHttpVersion11 = HttpVersion(1, 1)\n\n\n_T_OnChunkSent = Optional[Callable[[bytes], Awaitable[None]]]\n_T_OnHeadersSent = Optional[Callable[[\"CIMultiDict[str]\"], Awaitable[None]]]\n\n\nclass StreamWriter(AbstractStreamWriter):\n    def __init__(\n        self,\n        protocol: BaseProtocol,\n        loop: asyncio.AbstractEventLoop,\n        on_chunk_sent: _T_OnChunkSent = None,\n        on_headers_sent: _T_OnHeadersSent = None,\n    ) -> None:\n        self._protocol = protocol\n\n        self.loop = loop\n        self.length = None\n        self.chunked = False\n        self.buffer_size = 0\n        self.output_size = 0\n\n        self._eof = False\n        self._compress: Optional[ZLibCompressor] = None\n        self._drain_waiter = None\n\n        self._on_chunk_sent: _T_OnChunkSent = on_chunk_sent\n        self._on_headers_sent: _T_OnHeadersSent = on_headers_sent\n\n    @property\n    def transport(self) -> Optional[asyncio.Transport]:\n        return self._protocol.transport\n\n    @property\n    def protocol(self) -> BaseProtocol:\n        return self._protocol\n\n    def enable_chunking(self) -> None:\n        self.chunked = True\n\n    def enable_compression(\n        self, encoding: str = \"deflate\", strategy: int = zlib.Z_DEFAULT_STRATEGY\n    ) -> None:\n        self._compress = ZLibCompressor(encoding=encoding, strategy=strategy)\n\n    def _write(self, chunk: bytes) -> None:\n        size = len(chunk)\n        self.buffer_size += size\n        self.output_size += size\n        transport = self.transport\n        if not self._protocol.connected or transport is None or transport.is_closing():\n            raise ConnectionResetError(\"Cannot write to closing transport\")\n        transport.write(chunk)\n\n    async def write(\n        self, chunk: bytes, *, drain: bool = True, LIMIT: int = 0x10000\n    ) -> None:\n        \"\"\"Writes chunk of data to a stream.\n\n        write_eof() indicates end of stream.\n        writer can't be used after write_eof() method being called.\n        write() return drain future.\n        \"\"\"\n        if self._on_chunk_sent is not None:\n            await self._on_chunk_sent(chunk)\n\n        if isinstance(chunk, memoryview):\n            if chunk.nbytes != len(chunk):\n                # just reshape it\n                chunk = chunk.cast(\"c\")\n\n        if self._compress is not None:\n            chunk = await self._compress.compress(chunk)\n            if not chunk:\n                return\n\n        if self.length is not None:\n            chunk_len = len(chunk)\n            if self.length >= chunk_len:\n                self.length = self.length - chunk_len\n            else:\n                chunk = chunk[: self.length]\n                self.length = 0\n                if not chunk:\n                    return\n\n        if chunk:\n            if self.chunked:\n                chunk_len_pre = (\"%x\\r\\n\" % len(chunk)).encode(\"ascii\")\n                chunk = chunk_len_pre + chunk + b\"\\r\\n\"\n\n            self._write(chunk)\n\n            if self.buffer_size > LIMIT and drain:\n                self.buffer_size = 0\n                await self.drain()\n\n    async def write_headers(\n        self, status_line: str, headers: \"CIMultiDict[str]\"\n    ) -> None:\n        \"\"\"Write request/response status and headers.\"\"\"\n        if self._on_headers_sent is not None:\n            await self._on_headers_sent(headers)\n\n        # status + headers\n        buf = _serialize_headers(status_line, headers)\n        self._write(buf)\n\n    async def write_eof(self, chunk: bytes = b\"\") -> None:\n        if self._eof:\n            return\n\n        if chunk and self._on_chunk_sent is not None:\n            await self._on_chunk_sent(chunk)\n\n        if self._compress:\n            if chunk:\n                chunk = await self._compress.compress(chunk)\n\n            chunk += self._compress.flush()\n            if chunk and self.chunked:\n                chunk_len = (\"%x\\r\\n\" % len(chunk)).encode(\"ascii\")\n                chunk = chunk_len + chunk + b\"\\r\\n0\\r\\n\\r\\n\"\n        else:\n            if self.chunked:\n                if chunk:\n                    chunk_len = (\"%x\\r\\n\" % len(chunk)).encode(\"ascii\")\n                    chunk = chunk_len + chunk + b\"\\r\\n0\\r\\n\\r\\n\"\n                else:\n                    chunk = b\"0\\r\\n\\r\\n\"\n\n        if chunk:\n            self._write(chunk)\n\n        await self.drain()\n\n        self._eof = True\n\n    async def drain(self) -> None:\n        \"\"\"Flush the write buffer.\n\n        The intended use is to write\n\n          await w.write(data)\n          await w.drain()\n        \"\"\"\n        if self._protocol.transport is not None:\n            await self._protocol._drain_helper()\n\n\ndef _safe_header(string: str) -> str:\n    if \"\\r\" in string or \"\\n\" in string:\n        raise ValueError(\n            \"Newline or carriage return detected in headers. \"\n            \"Potential header injection attack.\"\n        )\n    return string\n\n\ndef _py_serialize_headers(status_line: str, headers: \"CIMultiDict[str]\") -> bytes:\n    headers_gen = (_safe_header(k) + \": \" + _safe_header(v) for k, v in headers.items())\n    line = status_line + \"\\r\\n\" + \"\\r\\n\".join(headers_gen) + \"\\r\\n\\r\\n\"\n    return line.encode(\"utf-8\")\n\n\n_serialize_headers = _py_serialize_headers\n\ntry:\n    import aiohttp._http_writer as _http_writer  # type: ignore[import-not-found]\n\n    _c_serialize_headers = _http_writer._serialize_headers\n    if not NO_EXTENSIONS:\n        _serialize_headers = _c_serialize_headers\nexcept ImportError:\n    pass\n", "aiohttp/pytest_plugin.py": "import asyncio\nimport contextlib\nimport inspect\nimport warnings\nfrom typing import Any, Awaitable, Callable, Dict, Iterator, Optional, Type, Union\n\nimport pytest\n\nfrom aiohttp.web import Application\n\nfrom .test_utils import (\n    BaseTestServer,\n    RawTestServer,\n    TestClient,\n    TestServer,\n    loop_context,\n    setup_test_loop,\n    teardown_test_loop,\n    unused_port as _unused_port,\n)\n\ntry:\n    import uvloop\nexcept ImportError:  # pragma: no cover\n    uvloop = None  # type: ignore[assignment]\n\nAiohttpClient = Callable[[Union[Application, BaseTestServer]], Awaitable[TestClient]]\nAiohttpRawServer = Callable[[Application], Awaitable[RawTestServer]]\nAiohttpServer = Callable[[Application], Awaitable[TestServer]]\n\n\ndef pytest_addoption(parser):  # type: ignore[no-untyped-def]\n    parser.addoption(\n        \"--aiohttp-fast\",\n        action=\"store_true\",\n        default=False,\n        help=\"run tests faster by disabling extra checks\",\n    )\n    parser.addoption(\n        \"--aiohttp-loop\",\n        action=\"store\",\n        default=\"pyloop\",\n        help=\"run tests with specific loop: pyloop, uvloop or all\",\n    )\n    parser.addoption(\n        \"--aiohttp-enable-loop-debug\",\n        action=\"store_true\",\n        default=False,\n        help=\"enable event loop debug mode\",\n    )\n\n\ndef pytest_fixture_setup(fixturedef):  # type: ignore[no-untyped-def]\n    \"\"\"Set up pytest fixture.\n\n    Allow fixtures to be coroutines. Run coroutine fixtures in an event loop.\n    \"\"\"\n    func = fixturedef.func\n\n    if inspect.isasyncgenfunction(func):\n        # async generator fixture\n        is_async_gen = True\n    elif asyncio.iscoroutinefunction(func):\n        # regular async fixture\n        is_async_gen = False\n    else:\n        # not an async fixture, nothing to do\n        return\n\n    strip_request = False\n    if \"request\" not in fixturedef.argnames:\n        fixturedef.argnames += (\"request\",)\n        strip_request = True\n\n    def wrapper(*args, **kwargs):  # type: ignore[no-untyped-def]\n        request = kwargs[\"request\"]\n        if strip_request:\n            del kwargs[\"request\"]\n\n        # if neither the fixture nor the test use the 'loop' fixture,\n        # 'getfixturevalue' will fail because the test is not parameterized\n        # (this can be removed someday if 'loop' is no longer parameterized)\n        if \"loop\" not in request.fixturenames:\n            raise Exception(\n                \"Asynchronous fixtures must depend on the 'loop' fixture or \"\n                \"be used in tests depending from it.\"\n            )\n\n        _loop = request.getfixturevalue(\"loop\")\n\n        if is_async_gen:\n            # for async generators, we need to advance the generator once,\n            # then advance it again in a finalizer\n            gen = func(*args, **kwargs)\n\n            def finalizer():  # type: ignore[no-untyped-def]\n                try:\n                    return _loop.run_until_complete(gen.__anext__())\n                except StopAsyncIteration:\n                    pass\n\n            request.addfinalizer(finalizer)\n            return _loop.run_until_complete(gen.__anext__())\n        else:\n            return _loop.run_until_complete(func(*args, **kwargs))\n\n    fixturedef.func = wrapper\n\n\n@pytest.fixture\ndef fast(request):  # type: ignore[no-untyped-def]\n    \"\"\"--fast config option\"\"\"\n    return request.config.getoption(\"--aiohttp-fast\")\n\n\n@pytest.fixture\ndef loop_debug(request):  # type: ignore[no-untyped-def]\n    \"\"\"--enable-loop-debug config option\"\"\"\n    return request.config.getoption(\"--aiohttp-enable-loop-debug\")\n\n\n@contextlib.contextmanager\ndef _runtime_warning_context():  # type: ignore[no-untyped-def]\n    \"\"\"Context manager which checks for RuntimeWarnings.\n\n    This exists specifically to\n    avoid \"coroutine 'X' was never awaited\" warnings being missed.\n\n    If RuntimeWarnings occur in the context a RuntimeError is raised.\n    \"\"\"\n    with warnings.catch_warnings(record=True) as _warnings:\n        yield\n        rw = [\n            \"{w.filename}:{w.lineno}:{w.message}\".format(w=w)\n            for w in _warnings\n            if w.category == RuntimeWarning\n        ]\n        if rw:\n            raise RuntimeError(\n                \"{} Runtime Warning{},\\n{}\".format(\n                    len(rw), \"\" if len(rw) == 1 else \"s\", \"\\n\".join(rw)\n                )\n            )\n\n    # Propagate warnings to pytest\n    for msg in _warnings:\n        warnings.showwarning(\n            msg.message, msg.category, msg.filename, msg.lineno, msg.file, msg.line\n        )\n\n\n@contextlib.contextmanager\ndef _passthrough_loop_context(loop, fast=False):  # type: ignore[no-untyped-def]\n    \"\"\"Passthrough loop context.\n\n    Sets up and tears down a loop unless one is passed in via the loop\n    argument when it's passed straight through.\n    \"\"\"\n    if loop:\n        # loop already exists, pass it straight through\n        yield loop\n    else:\n        # this shadows loop_context's standard behavior\n        loop = setup_test_loop()\n        yield loop\n        teardown_test_loop(loop, fast=fast)\n\n\ndef pytest_pycollect_makeitem(collector, name, obj):  # type: ignore[no-untyped-def]\n    \"\"\"Fix pytest collecting for coroutines.\"\"\"\n    if collector.funcnamefilter(name) and asyncio.iscoroutinefunction(obj):\n        return list(collector._genfunctions(name, obj))\n\n\ndef pytest_pyfunc_call(pyfuncitem):  # type: ignore[no-untyped-def]\n    \"\"\"Run coroutines in an event loop instead of a normal function call.\"\"\"\n    fast = pyfuncitem.config.getoption(\"--aiohttp-fast\")\n    if asyncio.iscoroutinefunction(pyfuncitem.function):\n        existing_loop = pyfuncitem.funcargs.get(\n            \"proactor_loop\"\n        ) or pyfuncitem.funcargs.get(\"loop\", None)\n        with _runtime_warning_context():\n            with _passthrough_loop_context(existing_loop, fast=fast) as _loop:\n                testargs = {\n                    arg: pyfuncitem.funcargs[arg]\n                    for arg in pyfuncitem._fixtureinfo.argnames\n                }\n                _loop.run_until_complete(pyfuncitem.obj(**testargs))\n\n        return True\n\n\ndef pytest_generate_tests(metafunc):  # type: ignore[no-untyped-def]\n    if \"loop_factory\" not in metafunc.fixturenames:\n        return\n\n    loops = metafunc.config.option.aiohttp_loop\n    avail_factories: Dict[str, Type[asyncio.AbstractEventLoopPolicy]]\n    avail_factories = {\"pyloop\": asyncio.DefaultEventLoopPolicy}\n\n    if uvloop is not None:  # pragma: no cover\n        avail_factories[\"uvloop\"] = uvloop.EventLoopPolicy\n\n    if loops == \"all\":\n        loops = \"pyloop,uvloop?\"\n\n    factories = {}  # type: ignore[var-annotated]\n    for name in loops.split(\",\"):\n        required = not name.endswith(\"?\")\n        name = name.strip(\" ?\")\n        if name not in avail_factories:  # pragma: no cover\n            if required:\n                raise ValueError(\n                    \"Unknown loop '%s', available loops: %s\"\n                    % (name, list(factories.keys()))\n                )\n            else:\n                continue\n        factories[name] = avail_factories[name]\n    metafunc.parametrize(\n        \"loop_factory\", list(factories.values()), ids=list(factories.keys())\n    )\n\n\n@pytest.fixture\ndef loop(loop_factory, fast, loop_debug):  # type: ignore[no-untyped-def]\n    \"\"\"Return an instance of the event loop.\"\"\"\n    policy = loop_factory()\n    asyncio.set_event_loop_policy(policy)\n    with loop_context(fast=fast) as _loop:\n        if loop_debug:\n            _loop.set_debug(True)  # pragma: no cover\n        asyncio.set_event_loop(_loop)\n        yield _loop\n\n\n@pytest.fixture\ndef proactor_loop():  # type: ignore[no-untyped-def]\n    policy = asyncio.WindowsProactorEventLoopPolicy()  # type: ignore[attr-defined]\n    asyncio.set_event_loop_policy(policy)\n\n    with loop_context(policy.new_event_loop) as _loop:\n        asyncio.set_event_loop(_loop)\n        yield _loop\n\n\n@pytest.fixture\ndef aiohttp_unused_port() -> Callable[[], int]:\n    \"\"\"Return a port that is unused on the current host.\"\"\"\n    return _unused_port\n\n\n@pytest.fixture\ndef aiohttp_server(loop: asyncio.AbstractEventLoop) -> Iterator[AiohttpServer]:\n    \"\"\"Factory to create a TestServer instance, given an app.\n\n    aiohttp_server(app, **kwargs)\n    \"\"\"\n    servers = []\n\n    async def go(app, *, port=None, **kwargs):  # type: ignore[no-untyped-def]\n        server = TestServer(app, port=port)\n        await server.start_server(**kwargs)\n        servers.append(server)\n        return server\n\n    yield go\n\n    async def finalize() -> None:\n        while servers:\n            await servers.pop().close()\n\n    loop.run_until_complete(finalize())\n\n\n@pytest.fixture\ndef aiohttp_raw_server(loop: asyncio.AbstractEventLoop) -> Iterator[AiohttpRawServer]:\n    \"\"\"Factory to create a RawTestServer instance, given a web handler.\n\n    aiohttp_raw_server(handler, **kwargs)\n    \"\"\"\n    servers = []\n\n    async def go(handler, *, port=None, **kwargs):  # type: ignore[no-untyped-def]\n        server = RawTestServer(handler, port=port)\n        await server.start_server(**kwargs)\n        servers.append(server)\n        return server\n\n    yield go\n\n    async def finalize() -> None:\n        while servers:\n            await servers.pop().close()\n\n    loop.run_until_complete(finalize())\n\n\n@pytest.fixture\ndef aiohttp_client_cls() -> Type[TestClient]:\n    \"\"\"\n    Client class to use in ``aiohttp_client`` factory.\n\n    Use it for passing custom ``TestClient`` implementations.\n\n    Example::\n\n       class MyClient(TestClient):\n           async def login(self, *, user, pw):\n               payload = {\"username\": user, \"password\": pw}\n               return await self.post(\"/login\", json=payload)\n\n       @pytest.fixture\n       def aiohttp_client_cls():\n           return MyClient\n\n       def test_login(aiohttp_client):\n           app = web.Application()\n           client = await aiohttp_client(app)\n           await client.login(user=\"admin\", pw=\"s3cr3t\")\n\n    \"\"\"\n    return TestClient\n\n\n@pytest.fixture\ndef aiohttp_client(\n    loop: asyncio.AbstractEventLoop, aiohttp_client_cls: Type[TestClient]\n) -> Iterator[AiohttpClient]:\n    \"\"\"Factory to create a TestClient instance.\n\n    aiohttp_client(app, **kwargs)\n    aiohttp_client(server, **kwargs)\n    aiohttp_client(raw_server, **kwargs)\n    \"\"\"\n    clients = []\n\n    async def go(\n        __param: Union[Application, BaseTestServer],\n        *,\n        server_kwargs: Optional[Dict[str, Any]] = None,\n        **kwargs: Any\n    ) -> TestClient:\n        if isinstance(__param, Application):\n            server_kwargs = server_kwargs or {}\n            server = TestServer(__param, **server_kwargs)\n            client = aiohttp_client_cls(server, **kwargs)\n        elif isinstance(__param, BaseTestServer):\n            client = aiohttp_client_cls(__param, **kwargs)\n        else:\n            raise ValueError(\"Unknown argument type: %r\" % type(__param))\n\n        await client.start_server()\n        clients.append(client)\n        return client\n\n    yield go\n\n    async def finalize() -> None:\n        while clients:\n            await clients.pop().close()\n\n    loop.run_until_complete(finalize())\n", "aiohttp/web_ws.py": "import asyncio\nimport base64\nimport binascii\nimport dataclasses\nimport hashlib\nimport json\nimport sys\nfrom typing import Any, Final, Iterable, Optional, Tuple, cast\n\nfrom multidict import CIMultiDict\n\nfrom . import hdrs\nfrom .abc import AbstractStreamWriter\nfrom .helpers import call_later, set_exception, set_result\nfrom .http import (\n    WS_CLOSED_MESSAGE,\n    WS_CLOSING_MESSAGE,\n    WS_KEY,\n    WebSocketError,\n    WebSocketReader,\n    WebSocketWriter,\n    WSCloseCode,\n    WSMessage,\n    WSMsgType as WSMsgType,\n    ws_ext_gen,\n    ws_ext_parse,\n)\nfrom .log import ws_logger\nfrom .streams import EofStream, FlowControlDataQueue\nfrom .typedefs import JSONDecoder, JSONEncoder\nfrom .web_exceptions import HTTPBadRequest, HTTPException\nfrom .web_request import BaseRequest\nfrom .web_response import StreamResponse\n\nif sys.version_info >= (3, 11):\n    import asyncio as async_timeout\nelse:\n    import async_timeout\n\n__all__ = (\n    \"WebSocketResponse\",\n    \"WebSocketReady\",\n    \"WSMsgType\",\n)\n\nTHRESHOLD_CONNLOST_ACCESS: Final[int] = 5\n\n\n@dataclasses.dataclass(frozen=True)\nclass WebSocketReady:\n    ok: bool\n    protocol: Optional[str]\n\n    def __bool__(self) -> bool:\n        return self.ok\n\n\nclass WebSocketResponse(StreamResponse):\n    __slots__ = (\n        \"_protocols\",\n        \"_ws_protocol\",\n        \"_writer\",\n        \"_reader\",\n        \"_closed\",\n        \"_closing\",\n        \"_conn_lost\",\n        \"_close_code\",\n        \"_loop\",\n        \"_waiting\",\n        \"_exception\",\n        \"_timeout\",\n        \"_receive_timeout\",\n        \"_autoclose\",\n        \"_autoping\",\n        \"_heartbeat\",\n        \"_heartbeat_cb\",\n        \"_pong_heartbeat\",\n        \"_pong_response_cb\",\n        \"_compress\",\n        \"_max_msg_size\",\n    )\n\n    def __init__(\n        self,\n        *,\n        timeout: float = 10.0,\n        receive_timeout: Optional[float] = None,\n        autoclose: bool = True,\n        autoping: bool = True,\n        heartbeat: Optional[float] = None,\n        protocols: Iterable[str] = (),\n        compress: bool = True,\n        max_msg_size: int = 4 * 1024 * 1024,\n    ) -> None:\n        super().__init__(status=101)\n        self._length_check = False\n        self._protocols = protocols\n        self._ws_protocol: Optional[str] = None\n        self._writer: Optional[WebSocketWriter] = None\n        self._reader: Optional[FlowControlDataQueue[WSMessage]] = None\n        self._closed = False\n        self._closing = False\n        self._conn_lost = 0\n        self._close_code: Optional[int] = None\n        self._loop: Optional[asyncio.AbstractEventLoop] = None\n        self._waiting: Optional[asyncio.Future[bool]] = None\n        self._exception: Optional[BaseException] = None\n        self._timeout = timeout\n        self._receive_timeout = receive_timeout\n        self._autoclose = autoclose\n        self._autoping = autoping\n        self._heartbeat = heartbeat\n        self._heartbeat_cb: Optional[asyncio.TimerHandle] = None\n        if heartbeat is not None:\n            self._pong_heartbeat = heartbeat / 2.0\n        self._pong_response_cb: Optional[asyncio.TimerHandle] = None\n        self._compress = compress\n        self._max_msg_size = max_msg_size\n\n    def _cancel_heartbeat(self) -> None:\n        if self._pong_response_cb is not None:\n            self._pong_response_cb.cancel()\n            self._pong_response_cb = None\n\n        if self._heartbeat_cb is not None:\n            self._heartbeat_cb.cancel()\n            self._heartbeat_cb = None\n\n    def _reset_heartbeat(self) -> None:\n        self._cancel_heartbeat()\n\n        if self._heartbeat is not None:\n            assert self._loop is not None\n            self._heartbeat_cb = call_later(\n                self._send_heartbeat,\n                self._heartbeat,\n                self._loop,\n                timeout_ceil_threshold=(\n                    self._req._protocol._timeout_ceil_threshold\n                    if self._req is not None\n                    else 5\n                ),\n            )\n\n    def _send_heartbeat(self) -> None:\n        if self._heartbeat is not None and not self._closed:\n            assert self._loop is not None and self._writer is not None\n            # fire-and-forget a task is not perfect but maybe ok for\n            # sending ping. Otherwise we need a long-living heartbeat\n            # task in the class.\n            self._loop.create_task(self._writer.ping())  # type: ignore[unused-awaitable]\n\n            if self._pong_response_cb is not None:\n                self._pong_response_cb.cancel()\n            self._pong_response_cb = call_later(\n                self._pong_not_received,\n                self._pong_heartbeat,\n                self._loop,\n                timeout_ceil_threshold=(\n                    self._req._protocol._timeout_ceil_threshold\n                    if self._req is not None\n                    else 5\n                ),\n            )\n\n    def _pong_not_received(self) -> None:\n        if self._req is not None and self._req.transport is not None:\n            self._closed = True\n            self._set_code_close_transport(WSCloseCode.ABNORMAL_CLOSURE)\n            self._exception = asyncio.TimeoutError()\n\n    async def prepare(self, request: BaseRequest) -> AbstractStreamWriter:\n        # make pre-check to don't hide it by do_handshake() exceptions\n        if self._payload_writer is not None:\n            return self._payload_writer\n\n        protocol, writer = self._pre_start(request)\n        payload_writer = await super().prepare(request)\n        assert payload_writer is not None\n        self._post_start(request, protocol, writer)\n        await payload_writer.drain()\n        return payload_writer\n\n    def _handshake(\n        self, request: BaseRequest\n    ) -> Tuple[\"CIMultiDict[str]\", str, bool, bool]:\n        headers = request.headers\n        if \"websocket\" != headers.get(hdrs.UPGRADE, \"\").lower().strip():\n            raise HTTPBadRequest(\n                text=(\n                    \"No WebSocket UPGRADE hdr: {}\\n Can \"\n                    '\"Upgrade\" only to \"WebSocket\".'\n                ).format(headers.get(hdrs.UPGRADE))\n            )\n\n        if \"upgrade\" not in headers.get(hdrs.CONNECTION, \"\").lower():\n            raise HTTPBadRequest(\n                text=\"No CONNECTION upgrade hdr: {}\".format(\n                    headers.get(hdrs.CONNECTION)\n                )\n            )\n\n        # find common sub-protocol between client and server\n        protocol = None\n        if hdrs.SEC_WEBSOCKET_PROTOCOL in headers:\n            req_protocols = [\n                str(proto.strip())\n                for proto in headers[hdrs.SEC_WEBSOCKET_PROTOCOL].split(\",\")\n            ]\n\n            for proto in req_protocols:\n                if proto in self._protocols:\n                    protocol = proto\n                    break\n            else:\n                # No overlap found: Return no protocol as per spec\n                ws_logger.warning(\n                    \"Client protocols %r don\u2019t overlap server-known ones %r\",\n                    req_protocols,\n                    self._protocols,\n                )\n\n        # check supported version\n        version = headers.get(hdrs.SEC_WEBSOCKET_VERSION, \"\")\n        if version not in (\"13\", \"8\", \"7\"):\n            raise HTTPBadRequest(text=f\"Unsupported version: {version}\")\n\n        # check client handshake for validity\n        key = headers.get(hdrs.SEC_WEBSOCKET_KEY)\n        try:\n            if not key or len(base64.b64decode(key)) != 16:\n                raise HTTPBadRequest(text=f\"Handshake error: {key!r}\")\n        except binascii.Error:\n            raise HTTPBadRequest(text=f\"Handshake error: {key!r}\") from None\n\n        accept_val = base64.b64encode(\n            hashlib.sha1(key.encode() + WS_KEY).digest()\n        ).decode()\n        response_headers = CIMultiDict(\n            {\n                hdrs.UPGRADE: \"websocket\",\n                hdrs.CONNECTION: \"upgrade\",\n                hdrs.SEC_WEBSOCKET_ACCEPT: accept_val,\n            }\n        )\n\n        notakeover = False\n        compress = 0\n        if self._compress:\n            extensions = headers.get(hdrs.SEC_WEBSOCKET_EXTENSIONS)\n            # Server side always get return with no exception.\n            # If something happened, just drop compress extension\n            compress, notakeover = ws_ext_parse(extensions, isserver=True)\n            if compress:\n                enabledext = ws_ext_gen(\n                    compress=compress, isserver=True, server_notakeover=notakeover\n                )\n                response_headers[hdrs.SEC_WEBSOCKET_EXTENSIONS] = enabledext\n\n        if protocol:\n            response_headers[hdrs.SEC_WEBSOCKET_PROTOCOL] = protocol\n        return (\n            response_headers,\n            protocol,\n            compress,\n            notakeover,\n        )  # type: ignore[return-value]\n\n    def _pre_start(self, request: BaseRequest) -> Tuple[str, WebSocketWriter]:\n        self._loop = request._loop\n\n        headers, protocol, compress, notakeover = self._handshake(request)\n\n        self.set_status(101)\n        self.headers.update(headers)\n        self.force_close()\n        self._compress = compress\n        transport = request._protocol.transport\n        assert transport is not None\n        writer = WebSocketWriter(\n            request._protocol, transport, compress=compress, notakeover=notakeover\n        )\n\n        return protocol, writer\n\n    def _post_start(\n        self, request: BaseRequest, protocol: str, writer: WebSocketWriter\n    ) -> None:\n        self._ws_protocol = protocol\n        self._writer = writer\n\n        self._reset_heartbeat()\n\n        loop = self._loop\n        assert loop is not None\n        self._reader = FlowControlDataQueue(request._protocol, 2**16, loop=loop)\n        request.protocol.set_parser(\n            WebSocketReader(self._reader, self._max_msg_size, compress=self._compress)\n        )\n        # disable HTTP keepalive for WebSocket\n        request.protocol.keep_alive(False)\n\n    def can_prepare(self, request: BaseRequest) -> WebSocketReady:\n        if self._writer is not None:\n            raise RuntimeError(\"Already started\")\n        try:\n            _, protocol, _, _ = self._handshake(request)\n        except HTTPException:\n            return WebSocketReady(False, None)\n        else:\n            return WebSocketReady(True, protocol)\n\n    @property\n    def closed(self) -> bool:\n        return self._closed\n\n    @property\n    def close_code(self) -> Optional[int]:\n        return self._close_code\n\n    @property\n    def ws_protocol(self) -> Optional[str]:\n        return self._ws_protocol\n\n    @property\n    def compress(self) -> bool:\n        return self._compress\n\n    def get_extra_info(self, name: str, default: Any = None) -> Any:\n        \"\"\"Get optional transport information.\n\n        If no value associated with ``name`` is found, ``default`` is returned.\n        \"\"\"\n        writer = self._writer\n        if writer is None:\n            return default\n        transport = writer.transport\n        if transport is None:\n            return default\n        return transport.get_extra_info(name, default)\n\n    def exception(self) -> Optional[BaseException]:\n        return self._exception\n\n    async def ping(self, message: bytes = b\"\") -> None:\n        if self._writer is None:\n            raise RuntimeError(\"Call .prepare() first\")\n        await self._writer.ping(message)\n\n    async def pong(self, message: bytes = b\"\") -> None:\n        # unsolicited pong\n        if self._writer is None:\n            raise RuntimeError(\"Call .prepare() first\")\n        await self._writer.pong(message)\n\n    async def send_str(self, data: str, compress: Optional[bool] = None) -> None:\n        if self._writer is None:\n            raise RuntimeError(\"Call .prepare() first\")\n        if not isinstance(data, str):\n            raise TypeError(\"data argument must be str (%r)\" % type(data))\n        await self._writer.send(data, binary=False, compress=compress)\n\n    async def send_bytes(self, data: bytes, compress: Optional[bool] = None) -> None:\n        if self._writer is None:\n            raise RuntimeError(\"Call .prepare() first\")\n        if not isinstance(data, (bytes, bytearray, memoryview)):\n            raise TypeError(\"data argument must be byte-ish (%r)\" % type(data))\n        await self._writer.send(data, binary=True, compress=compress)\n\n    async def send_json(\n        self,\n        data: Any,\n        compress: Optional[bool] = None,\n        *,\n        dumps: JSONEncoder = json.dumps,\n    ) -> None:\n        await self.send_str(dumps(data), compress=compress)\n\n    async def write_eof(self) -> None:  # type: ignore[override]\n        if self._eof_sent:\n            return\n        if self._payload_writer is None:\n            raise RuntimeError(\"Response has not been started\")\n\n        await self.close()\n        self._eof_sent = True\n\n    async def close(\n        self, *, code: int = WSCloseCode.OK, message: bytes = b\"\", drain: bool = True\n    ) -> bool:\n        \"\"\"Close websocket connection.\"\"\"\n        if self._writer is None:\n            raise RuntimeError(\"Call .prepare() first\")\n\n        self._cancel_heartbeat()\n        reader = self._reader\n        assert reader is not None\n\n        # we need to break `receive()` cycle first,\n        # `close()` may be called from different task\n        if self._waiting is not None and not self._closed:\n            reader.feed_data(WS_CLOSING_MESSAGE)\n            await self._waiting\n\n        if self._closed:\n            return False\n\n        self._closed = True\n        try:\n            await self._writer.close(code, message)\n            writer = self._payload_writer\n            assert writer is not None\n            if drain:\n                await writer.drain()\n        except (asyncio.CancelledError, asyncio.TimeoutError):\n            self._set_code_close_transport(WSCloseCode.ABNORMAL_CLOSURE)\n            raise\n        except Exception as exc:\n            self._exception = exc\n            self._set_code_close_transport(WSCloseCode.ABNORMAL_CLOSURE)\n            return True\n\n        if self._closing:\n            self._close_transport()\n            return True\n\n        reader = self._reader\n        assert reader is not None\n        try:\n            async with async_timeout.timeout(self._timeout):\n                msg = await reader.read()\n        except asyncio.CancelledError:\n            self._set_code_close_transport(WSCloseCode.ABNORMAL_CLOSURE)\n            raise\n        except Exception as exc:\n            self._exception = exc\n            self._set_code_close_transport(WSCloseCode.ABNORMAL_CLOSURE)\n            return True\n\n        if msg.type == WSMsgType.CLOSE:\n            self._set_code_close_transport(msg.data)\n            return True\n\n        self._set_code_close_transport(WSCloseCode.ABNORMAL_CLOSURE)\n        self._exception = asyncio.TimeoutError()\n        return True\n\n    def _set_closing(self, code: WSCloseCode) -> None:\n        \"\"\"Set the close code and mark the connection as closing.\"\"\"\n        self._closing = True\n        self._close_code = code\n\n    def _set_code_close_transport(self, code: WSCloseCode) -> None:\n        \"\"\"Set the close code and close the transport.\"\"\"\n        self._close_code = code\n        self._close_transport()\n\n    def _close_transport(self) -> None:\n        \"\"\"Close the transport.\"\"\"\n        if self._req is not None and self._req.transport is not None:\n            self._req.transport.close()\n\n    async def receive(self, timeout: Optional[float] = None) -> WSMessage:\n        if self._reader is None:\n            raise RuntimeError(\"Call .prepare() first\")\n\n        loop = self._loop\n        assert loop is not None\n        while True:\n            if self._waiting is not None:\n                raise RuntimeError(\"Concurrent call to receive() is not allowed\")\n\n            if self._closed:\n                self._conn_lost += 1\n                if self._conn_lost >= THRESHOLD_CONNLOST_ACCESS:\n                    raise RuntimeError(\"WebSocket connection is closed.\")\n                return WS_CLOSED_MESSAGE\n            elif self._closing:\n                return WS_CLOSING_MESSAGE\n\n            try:\n                self._waiting = loop.create_future()\n                try:\n                    async with async_timeout.timeout(timeout or self._receive_timeout):\n                        msg = await self._reader.read()\n                    self._reset_heartbeat()\n                finally:\n                    waiter = self._waiting\n                    set_result(waiter, True)\n                    self._waiting = None\n            except asyncio.TimeoutError:\n                raise\n            except EofStream:\n                self._close_code = WSCloseCode.OK\n                await self.close()\n                return WSMessage(WSMsgType.CLOSED, None, None)\n            except WebSocketError as exc:\n                self._close_code = exc.code\n                await self.close(code=exc.code)\n                return WSMessage(WSMsgType.ERROR, exc, None)\n            except Exception as exc:\n                self._exception = exc\n                self._set_closing(WSCloseCode.ABNORMAL_CLOSURE)\n                await self.close()\n                return WSMessage(WSMsgType.ERROR, exc, None)\n\n            if msg.type == WSMsgType.CLOSE:\n                self._set_closing(msg.data)\n                # Could be closed while awaiting reader.\n                if not self._closed and self._autoclose:  # type: ignore[redundant-expr]\n                    # The client is likely going to close the\n                    # connection out from under us so we do not\n                    # want to drain any pending writes as it will\n                    # likely result writing to a broken pipe.\n                    await self.close(drain=False)\n            elif msg.type == WSMsgType.CLOSING:\n                self._set_closing(WSCloseCode.OK)\n            elif msg.type == WSMsgType.PING and self._autoping:\n                await self.pong(msg.data)\n                continue\n            elif msg.type == WSMsgType.PONG and self._autoping:\n                continue\n\n            return msg\n\n    async def receive_str(self, *, timeout: Optional[float] = None) -> str:\n        msg = await self.receive(timeout)\n        if msg.type != WSMsgType.TEXT:\n            raise TypeError(\n                \"Received message {}:{!r} is not WSMsgType.TEXT\".format(\n                    msg.type, msg.data\n                )\n            )\n        return cast(str, msg.data)\n\n    async def receive_bytes(self, *, timeout: Optional[float] = None) -> bytes:\n        msg = await self.receive(timeout)\n        if msg.type != WSMsgType.BINARY:\n            raise TypeError(f\"Received message {msg.type}:{msg.data!r} is not bytes\")\n        return cast(bytes, msg.data)\n\n    async def receive_json(\n        self, *, loads: JSONDecoder = json.loads, timeout: Optional[float] = None\n    ) -> Any:\n        data = await self.receive_str(timeout=timeout)\n        return loads(data)\n\n    async def write(self, data: bytes) -> None:\n        raise RuntimeError(\"Cannot call .write() for websocket\")\n\n    def __aiter__(self) -> \"WebSocketResponse\":\n        return self\n\n    async def __anext__(self) -> WSMessage:\n        msg = await self.receive()\n        if msg.type in (WSMsgType.CLOSE, WSMsgType.CLOSING, WSMsgType.CLOSED):\n            raise StopAsyncIteration\n        return msg\n\n    def _cancel(self, exc: BaseException) -> None:\n        # web_protocol calls this from connection_lost\n        # or when the server is shutting down.\n        self._closing = True\n        if self._reader is not None:\n            set_exception(self._reader, exc)\n", "aiohttp/web.py": "import asyncio\nimport logging\nimport os\nimport socket\nimport sys\nimport warnings\nfrom argparse import ArgumentParser\nfrom collections.abc import Iterable\nfrom contextlib import suppress\nfrom functools import partial\nfrom importlib import import_module\nfrom typing import (\n    Any,\n    Awaitable,\n    Callable,\n    Iterable as TypingIterable,\n    List,\n    Optional,\n    Set,\n    Type,\n    Union,\n    cast,\n)\nfrom weakref import WeakSet\n\nfrom .abc import AbstractAccessLogger\nfrom .helpers import AppKey\nfrom .log import access_logger\nfrom .typedefs import PathLike\nfrom .web_app import Application, CleanupError\nfrom .web_exceptions import (\n    HTTPAccepted,\n    HTTPBadGateway,\n    HTTPBadRequest,\n    HTTPClientError,\n    HTTPConflict,\n    HTTPCreated,\n    HTTPError,\n    HTTPException,\n    HTTPExpectationFailed,\n    HTTPFailedDependency,\n    HTTPForbidden,\n    HTTPFound,\n    HTTPGatewayTimeout,\n    HTTPGone,\n    HTTPInsufficientStorage,\n    HTTPInternalServerError,\n    HTTPLengthRequired,\n    HTTPMethodNotAllowed,\n    HTTPMisdirectedRequest,\n    HTTPMove,\n    HTTPMovedPermanently,\n    HTTPMultipleChoices,\n    HTTPNetworkAuthenticationRequired,\n    HTTPNoContent,\n    HTTPNonAuthoritativeInformation,\n    HTTPNotAcceptable,\n    HTTPNotExtended,\n    HTTPNotFound,\n    HTTPNotImplemented,\n    HTTPNotModified,\n    HTTPOk,\n    HTTPPartialContent,\n    HTTPPaymentRequired,\n    HTTPPermanentRedirect,\n    HTTPPreconditionFailed,\n    HTTPPreconditionRequired,\n    HTTPProxyAuthenticationRequired,\n    HTTPRedirection,\n    HTTPRequestEntityTooLarge,\n    HTTPRequestHeaderFieldsTooLarge,\n    HTTPRequestRangeNotSatisfiable,\n    HTTPRequestTimeout,\n    HTTPRequestURITooLong,\n    HTTPResetContent,\n    HTTPSeeOther,\n    HTTPServerError,\n    HTTPServiceUnavailable,\n    HTTPSuccessful,\n    HTTPTemporaryRedirect,\n    HTTPTooManyRequests,\n    HTTPUnauthorized,\n    HTTPUnavailableForLegalReasons,\n    HTTPUnprocessableEntity,\n    HTTPUnsupportedMediaType,\n    HTTPUpgradeRequired,\n    HTTPUseProxy,\n    HTTPVariantAlsoNegotiates,\n    HTTPVersionNotSupported,\n    NotAppKeyWarning,\n)\nfrom .web_fileresponse import FileResponse\nfrom .web_log import AccessLogger\nfrom .web_middlewares import middleware, normalize_path_middleware\nfrom .web_protocol import PayloadAccessError, RequestHandler, RequestPayloadError\nfrom .web_request import BaseRequest, FileField, Request\nfrom .web_response import ContentCoding, Response, StreamResponse, json_response\nfrom .web_routedef import (\n    AbstractRouteDef,\n    RouteDef,\n    RouteTableDef,\n    StaticDef,\n    delete,\n    get,\n    head,\n    options,\n    patch,\n    post,\n    put,\n    route,\n    static,\n    view,\n)\nfrom .web_runner import (\n    AppRunner,\n    BaseRunner,\n    BaseSite,\n    GracefulExit,\n    NamedPipeSite,\n    ServerRunner,\n    SockSite,\n    TCPSite,\n    UnixSite,\n)\nfrom .web_server import Server\nfrom .web_urldispatcher import (\n    AbstractResource,\n    AbstractRoute,\n    DynamicResource,\n    PlainResource,\n    PrefixedSubAppResource,\n    Resource,\n    ResourceRoute,\n    StaticResource,\n    UrlDispatcher,\n    UrlMappingMatchInfo,\n    View,\n)\nfrom .web_ws import WebSocketReady, WebSocketResponse, WSMsgType\n\n__all__ = (\n    # web_app\n    \"AppKey\",\n    \"Application\",\n    \"CleanupError\",\n    # web_exceptions\n    \"NotAppKeyWarning\",\n    \"HTTPAccepted\",\n    \"HTTPBadGateway\",\n    \"HTTPBadRequest\",\n    \"HTTPClientError\",\n    \"HTTPConflict\",\n    \"HTTPCreated\",\n    \"HTTPError\",\n    \"HTTPException\",\n    \"HTTPExpectationFailed\",\n    \"HTTPFailedDependency\",\n    \"HTTPForbidden\",\n    \"HTTPFound\",\n    \"HTTPGatewayTimeout\",\n    \"HTTPGone\",\n    \"HTTPInsufficientStorage\",\n    \"HTTPInternalServerError\",\n    \"HTTPLengthRequired\",\n    \"HTTPMethodNotAllowed\",\n    \"HTTPMisdirectedRequest\",\n    \"HTTPMove\",\n    \"HTTPMovedPermanently\",\n    \"HTTPMultipleChoices\",\n    \"HTTPNetworkAuthenticationRequired\",\n    \"HTTPNoContent\",\n    \"HTTPNonAuthoritativeInformation\",\n    \"HTTPNotAcceptable\",\n    \"HTTPNotExtended\",\n    \"HTTPNotFound\",\n    \"HTTPNotImplemented\",\n    \"HTTPNotModified\",\n    \"HTTPOk\",\n    \"HTTPPartialContent\",\n    \"HTTPPaymentRequired\",\n    \"HTTPPermanentRedirect\",\n    \"HTTPPreconditionFailed\",\n    \"HTTPPreconditionRequired\",\n    \"HTTPProxyAuthenticationRequired\",\n    \"HTTPRedirection\",\n    \"HTTPRequestEntityTooLarge\",\n    \"HTTPRequestHeaderFieldsTooLarge\",\n    \"HTTPRequestRangeNotSatisfiable\",\n    \"HTTPRequestTimeout\",\n    \"HTTPRequestURITooLong\",\n    \"HTTPResetContent\",\n    \"HTTPSeeOther\",\n    \"HTTPServerError\",\n    \"HTTPServiceUnavailable\",\n    \"HTTPSuccessful\",\n    \"HTTPTemporaryRedirect\",\n    \"HTTPTooManyRequests\",\n    \"HTTPUnauthorized\",\n    \"HTTPUnavailableForLegalReasons\",\n    \"HTTPUnprocessableEntity\",\n    \"HTTPUnsupportedMediaType\",\n    \"HTTPUpgradeRequired\",\n    \"HTTPUseProxy\",\n    \"HTTPVariantAlsoNegotiates\",\n    \"HTTPVersionNotSupported\",\n    # web_fileresponse\n    \"FileResponse\",\n    # web_middlewares\n    \"middleware\",\n    \"normalize_path_middleware\",\n    # web_protocol\n    \"PayloadAccessError\",\n    \"RequestHandler\",\n    \"RequestPayloadError\",\n    # web_request\n    \"BaseRequest\",\n    \"FileField\",\n    \"Request\",\n    # web_response\n    \"ContentCoding\",\n    \"Response\",\n    \"StreamResponse\",\n    \"json_response\",\n    # web_routedef\n    \"AbstractRouteDef\",\n    \"RouteDef\",\n    \"RouteTableDef\",\n    \"StaticDef\",\n    \"delete\",\n    \"get\",\n    \"head\",\n    \"options\",\n    \"patch\",\n    \"post\",\n    \"put\",\n    \"route\",\n    \"static\",\n    \"view\",\n    # web_runner\n    \"AppRunner\",\n    \"BaseRunner\",\n    \"BaseSite\",\n    \"GracefulExit\",\n    \"ServerRunner\",\n    \"SockSite\",\n    \"TCPSite\",\n    \"UnixSite\",\n    \"NamedPipeSite\",\n    # web_server\n    \"Server\",\n    # web_urldispatcher\n    \"AbstractResource\",\n    \"AbstractRoute\",\n    \"DynamicResource\",\n    \"PlainResource\",\n    \"PrefixedSubAppResource\",\n    \"Resource\",\n    \"ResourceRoute\",\n    \"StaticResource\",\n    \"UrlDispatcher\",\n    \"UrlMappingMatchInfo\",\n    \"View\",\n    # web_ws\n    \"WebSocketReady\",\n    \"WebSocketResponse\",\n    \"WSMsgType\",\n    # web\n    \"run_app\",\n)\n\n\ntry:\n    from ssl import SSLContext\nexcept ImportError:  # pragma: no cover\n    SSLContext = Any  # type: ignore[misc,assignment]\n\n# Only display warning when using -Wdefault, -We, -X dev or similar.\nwarnings.filterwarnings(\"ignore\", category=NotAppKeyWarning, append=True)\n\nHostSequence = TypingIterable[str]\n\n\nasync def _run_app(\n    app: Union[Application, Awaitable[Application]],\n    *,\n    host: Optional[Union[str, HostSequence]] = None,\n    port: Optional[int] = None,\n    path: Union[PathLike, TypingIterable[PathLike], None] = None,\n    sock: Optional[Union[socket.socket, TypingIterable[socket.socket]]] = None,\n    shutdown_timeout: float = 60.0,\n    keepalive_timeout: float = 75.0,\n    ssl_context: Optional[SSLContext] = None,\n    print: Optional[Callable[..., None]] = print,\n    backlog: int = 128,\n    access_log_class: Type[AbstractAccessLogger] = AccessLogger,\n    access_log_format: str = AccessLogger.LOG_FORMAT,\n    access_log: Optional[logging.Logger] = access_logger,\n    handle_signals: bool = True,\n    reuse_address: Optional[bool] = None,\n    reuse_port: Optional[bool] = None,\n    handler_cancellation: bool = False,\n) -> None:\n    async def wait(\n        starting_tasks: \"WeakSet[asyncio.Task[object]]\", shutdown_timeout: float\n    ) -> None:\n        # Wait for pending tasks for a given time limit.\n        t = asyncio.current_task()\n        assert t is not None\n        starting_tasks.add(t)\n        with suppress(asyncio.TimeoutError):\n            await asyncio.wait_for(_wait(starting_tasks), timeout=shutdown_timeout)\n\n    async def _wait(exclude: \"WeakSet[asyncio.Task[object]]\") -> None:\n        t = asyncio.current_task()\n        assert t is not None\n        exclude.add(t)\n        while tasks := asyncio.all_tasks().difference(exclude):\n            await asyncio.wait(tasks)\n\n    # An internal function to actually do all dirty job for application running\n    if asyncio.iscoroutine(app):\n        app = await app\n\n    app = cast(Application, app)\n\n    runner = AppRunner(\n        app,\n        handle_signals=handle_signals,\n        access_log_class=access_log_class,\n        access_log_format=access_log_format,\n        access_log=access_log,\n        keepalive_timeout=keepalive_timeout,\n        shutdown_timeout=shutdown_timeout,\n        handler_cancellation=handler_cancellation,\n    )\n\n    await runner.setup()\n    # On shutdown we want to avoid waiting on tasks which run forever.\n    # It's very likely that all tasks which run forever will have been created by\n    # the time we have completed the application startup (in runner.setup()),\n    # so we just record all running tasks here and exclude them later.\n    starting_tasks: \"WeakSet[asyncio.Task[object]]\" = WeakSet(asyncio.all_tasks())\n    runner.shutdown_callback = partial(wait, starting_tasks, shutdown_timeout)\n\n    sites: List[BaseSite] = []\n\n    try:\n        if host is not None:\n            if isinstance(host, (str, bytes, bytearray, memoryview)):\n                sites.append(\n                    TCPSite(\n                        runner,\n                        host,\n                        port,\n                        ssl_context=ssl_context,\n                        backlog=backlog,\n                        reuse_address=reuse_address,\n                        reuse_port=reuse_port,\n                    )\n                )\n            else:\n                for h in host:\n                    sites.append(\n                        TCPSite(\n                            runner,\n                            h,\n                            port,\n                            ssl_context=ssl_context,\n                            backlog=backlog,\n                            reuse_address=reuse_address,\n                            reuse_port=reuse_port,\n                        )\n                    )\n        elif path is None and sock is None or port is not None:\n            sites.append(\n                TCPSite(\n                    runner,\n                    port=port,\n                    ssl_context=ssl_context,\n                    backlog=backlog,\n                    reuse_address=reuse_address,\n                    reuse_port=reuse_port,\n                )\n            )\n\n        if path is not None:\n            if isinstance(path, (str, os.PathLike)):\n                sites.append(\n                    UnixSite(\n                        runner,\n                        path,\n                        ssl_context=ssl_context,\n                        backlog=backlog,\n                    )\n                )\n            else:\n                for p in path:\n                    sites.append(\n                        UnixSite(\n                            runner,\n                            p,\n                            ssl_context=ssl_context,\n                            backlog=backlog,\n                        )\n                    )\n\n        if sock is not None:\n            if not isinstance(sock, Iterable):\n                sites.append(\n                    SockSite(\n                        runner,\n                        sock,\n                        ssl_context=ssl_context,\n                        backlog=backlog,\n                    )\n                )\n            else:\n                for s in sock:\n                    sites.append(\n                        SockSite(\n                            runner,\n                            s,\n                            ssl_context=ssl_context,\n                            backlog=backlog,\n                        )\n                    )\n        for site in sites:\n            await site.start()\n\n        if print:  # pragma: no branch\n            names = sorted(str(s.name) for s in runner.sites)\n            print(\n                \"======== Running on {} ========\\n\"\n                \"(Press CTRL+C to quit)\".format(\", \".join(names))\n            )\n\n        # sleep forever by 1 hour intervals,\n        while True:\n            await asyncio.sleep(3600)\n    finally:\n        await runner.cleanup()\n\n\ndef _cancel_tasks(\n    to_cancel: Set[\"asyncio.Task[Any]\"], loop: asyncio.AbstractEventLoop\n) -> None:\n    if not to_cancel:\n        return\n\n    for task in to_cancel:\n        task.cancel()\n\n    loop.run_until_complete(asyncio.gather(*to_cancel, return_exceptions=True))\n\n    for task in to_cancel:\n        if task.cancelled():\n            continue\n        if task.exception() is not None:\n            loop.call_exception_handler(\n                {\n                    \"message\": \"unhandled exception during asyncio.run() shutdown\",\n                    \"exception\": task.exception(),\n                    \"task\": task,\n                }\n            )\n\n\ndef run_app(\n    app: Union[Application, Awaitable[Application]],\n    *,\n    debug: bool = False,\n    host: Optional[Union[str, HostSequence]] = None,\n    port: Optional[int] = None,\n    path: Union[PathLike, TypingIterable[PathLike], None] = None,\n    sock: Optional[Union[socket.socket, TypingIterable[socket.socket]]] = None,\n    shutdown_timeout: float = 60.0,\n    keepalive_timeout: float = 75.0,\n    ssl_context: Optional[SSLContext] = None,\n    print: Optional[Callable[..., None]] = print,\n    backlog: int = 128,\n    access_log_class: Type[AbstractAccessLogger] = AccessLogger,\n    access_log_format: str = AccessLogger.LOG_FORMAT,\n    access_log: Optional[logging.Logger] = access_logger,\n    handle_signals: bool = True,\n    reuse_address: Optional[bool] = None,\n    reuse_port: Optional[bool] = None,\n    handler_cancellation: bool = False,\n    loop: Optional[asyncio.AbstractEventLoop] = None,\n) -> None:\n    \"\"\"Run an app locally\"\"\"\n    if loop is None:\n        loop = asyncio.new_event_loop()\n    loop.set_debug(debug)\n\n    # Configure if and only if in debugging mode and using the default logger\n    if loop.get_debug() and access_log and access_log.name == \"aiohttp.access\":\n        if access_log.level == logging.NOTSET:\n            access_log.setLevel(logging.DEBUG)\n        if not access_log.hasHandlers():\n            access_log.addHandler(logging.StreamHandler())\n\n    main_task = loop.create_task(\n        _run_app(\n            app,\n            host=host,\n            port=port,\n            path=path,\n            sock=sock,\n            shutdown_timeout=shutdown_timeout,\n            keepalive_timeout=keepalive_timeout,\n            ssl_context=ssl_context,\n            print=print,\n            backlog=backlog,\n            access_log_class=access_log_class,\n            access_log_format=access_log_format,\n            access_log=access_log,\n            handle_signals=handle_signals,\n            reuse_address=reuse_address,\n            reuse_port=reuse_port,\n            handler_cancellation=handler_cancellation,\n        )\n    )\n\n    try:\n        asyncio.set_event_loop(loop)\n        loop.run_until_complete(main_task)\n    except (GracefulExit, KeyboardInterrupt):  # pragma: no cover\n        pass\n    finally:\n        _cancel_tasks({main_task}, loop)\n        _cancel_tasks(asyncio.all_tasks(loop), loop)\n        loop.run_until_complete(loop.shutdown_asyncgens())\n        loop.close()\n        asyncio.set_event_loop(None)\n\n\ndef main(argv: List[str]) -> None:\n    arg_parser = ArgumentParser(\n        description=\"aiohttp.web Application server\", prog=\"aiohttp.web\"\n    )\n    arg_parser.add_argument(\n        \"entry_func\",\n        help=(\n            \"Callable returning the `aiohttp.web.Application` instance to \"\n            \"run. Should be specified in the 'module:function' syntax.\"\n        ),\n        metavar=\"entry-func\",\n    )\n    arg_parser.add_argument(\n        \"-H\",\n        \"--hostname\",\n        help=\"TCP/IP hostname to serve on (default: %(default)r)\",\n        default=\"localhost\",\n    )\n    arg_parser.add_argument(\n        \"-P\",\n        \"--port\",\n        help=\"TCP/IP port to serve on (default: %(default)r)\",\n        type=int,\n        default=\"8080\",\n    )\n    arg_parser.add_argument(\n        \"-U\",\n        \"--path\",\n        help=\"Unix file system path to serve on. Specifying a path will cause \"\n        \"hostname and port arguments to be ignored.\",\n    )\n    args, extra_argv = arg_parser.parse_known_args(argv)\n\n    # Import logic\n    mod_str, _, func_str = args.entry_func.partition(\":\")\n    if not func_str or not mod_str:\n        arg_parser.error(\"'entry-func' not in 'module:function' syntax\")\n    if mod_str.startswith(\".\"):\n        arg_parser.error(\"relative module names not supported\")\n    try:\n        module = import_module(mod_str)\n    except ImportError as ex:\n        arg_parser.error(f\"unable to import {mod_str}: {ex}\")\n    try:\n        func = getattr(module, func_str)\n    except AttributeError:\n        arg_parser.error(f\"module {mod_str!r} has no attribute {func_str!r}\")\n\n    # Compatibility logic\n    if args.path is not None and not hasattr(socket, \"AF_UNIX\"):\n        arg_parser.error(\n            \"file system paths not supported by your operating\" \" environment\"\n        )\n\n    logging.basicConfig(level=logging.DEBUG)\n\n    app = func(extra_argv)\n    run_app(app, host=args.hostname, port=args.port, path=args.path)\n    arg_parser.exit(message=\"Stopped\\n\")\n\n\nif __name__ == \"__main__\":  # pragma: no branch\n    main(sys.argv[1:])  # pragma: no cover\n", "aiohttp/formdata.py": "import io\nfrom typing import Any, Iterable, List, Optional\nfrom urllib.parse import urlencode\n\nfrom multidict import MultiDict, MultiDictProxy\n\nfrom . import hdrs, multipart, payload\nfrom .helpers import guess_filename\nfrom .payload import Payload\n\n__all__ = (\"FormData\",)\n\n\nclass FormData:\n    \"\"\"Helper class for form body generation.\n\n    Supports multipart/form-data and application/x-www-form-urlencoded.\n    \"\"\"\n\n    def __init__(\n        self,\n        fields: Iterable[Any] = (),\n        quote_fields: bool = True,\n        charset: Optional[str] = None,\n        boundary: Optional[str] = None,\n    ) -> None:\n        self._boundary = boundary\n        self._writer = multipart.MultipartWriter(\"form-data\", boundary=self._boundary)\n        self._fields: List[Any] = []\n        self._is_multipart = False\n        self._is_processed = False\n        self._quote_fields = quote_fields\n        self._charset = charset\n\n        if isinstance(fields, dict):\n            fields = list(fields.items())\n        elif not isinstance(fields, (list, tuple)):\n            fields = (fields,)\n        self.add_fields(*fields)\n\n    @property\n    def is_multipart(self) -> bool:\n        return self._is_multipart\n\n    def add_field(\n        self,\n        name: str,\n        value: Any,\n        *,\n        content_type: Optional[str] = None,\n        filename: Optional[str] = None,\n    ) -> None:\n        if isinstance(value, (io.IOBase, bytes, bytearray, memoryview)):\n            self._is_multipart = True\n\n        type_options: MultiDict[str] = MultiDict({\"name\": name})\n        if filename is not None and not isinstance(filename, str):\n            raise TypeError(\n                \"filename must be an instance of str. \" \"Got: %s\" % filename\n            )\n        if filename is None and isinstance(value, io.IOBase):\n            filename = guess_filename(value, name)\n        if filename is not None:\n            type_options[\"filename\"] = filename\n            self._is_multipart = True\n\n        headers = {}\n        if content_type is not None:\n            if not isinstance(content_type, str):\n                raise TypeError(\n                    \"content_type must be an instance of str. \" \"Got: %s\" % content_type\n                )\n            headers[hdrs.CONTENT_TYPE] = content_type\n            self._is_multipart = True\n\n        self._fields.append((type_options, headers, value))\n\n    def add_fields(self, *fields: Any) -> None:\n        to_add = list(fields)\n\n        while to_add:\n            rec = to_add.pop(0)\n\n            if isinstance(rec, io.IOBase):\n                k = guess_filename(rec, \"unknown\")\n                self.add_field(k, rec)  # type: ignore[arg-type]\n\n            elif isinstance(rec, (MultiDictProxy, MultiDict)):\n                to_add.extend(rec.items())\n\n            elif isinstance(rec, (list, tuple)) and len(rec) == 2:\n                k, fp = rec\n                self.add_field(k, fp)  # type: ignore[arg-type]\n\n            else:\n                raise TypeError(\n                    \"Only io.IOBase, multidict and (name, file) \"\n                    \"pairs allowed, use .add_field() for passing \"\n                    \"more complex parameters, got {!r}\".format(rec)\n                )\n\n    def _gen_form_urlencoded(self) -> payload.BytesPayload:\n        # form data (x-www-form-urlencoded)\n        data = []\n        for type_options, _, value in self._fields:\n            data.append((type_options[\"name\"], value))\n\n        charset = self._charset if self._charset is not None else \"utf-8\"\n\n        if charset == \"utf-8\":\n            content_type = \"application/x-www-form-urlencoded\"\n        else:\n            content_type = \"application/x-www-form-urlencoded; \" \"charset=%s\" % charset\n\n        return payload.BytesPayload(\n            urlencode(data, doseq=True, encoding=charset).encode(),\n            content_type=content_type,\n        )\n\n    def _gen_form_data(self) -> multipart.MultipartWriter:\n        \"\"\"Encode a list of fields using the multipart/form-data MIME format\"\"\"\n        if self._is_processed:\n            raise RuntimeError(\"Form data has been processed already\")\n        for dispparams, headers, value in self._fields:\n            try:\n                if hdrs.CONTENT_TYPE in headers:\n                    part = payload.get_payload(\n                        value,\n                        content_type=headers[hdrs.CONTENT_TYPE],\n                        headers=headers,\n                        encoding=self._charset,\n                    )\n                else:\n                    part = payload.get_payload(\n                        value, headers=headers, encoding=self._charset\n                    )\n            except Exception as exc:\n                raise TypeError(\n                    \"Can not serialize value type: %r\\n \"\n                    \"headers: %r\\n value: %r\" % (type(value), headers, value)\n                ) from exc\n\n            if dispparams:\n                part.set_content_disposition(\n                    \"form-data\", quote_fields=self._quote_fields, **dispparams\n                )\n                # FIXME cgi.FieldStorage doesn't likes body parts with\n                # Content-Length which were sent via chunked transfer encoding\n                assert part.headers is not None\n                part.headers.popall(hdrs.CONTENT_LENGTH, None)\n\n            self._writer.append_payload(part)\n\n        self._is_processed = True\n        return self._writer\n\n    def __call__(self) -> Payload:\n        if self._is_multipart:\n            return self._gen_form_data()\n        else:\n            return self._gen_form_urlencoded()\n", "aiohttp/web_server.py": "\"\"\"Low level HTTP server.\"\"\"\n\nimport asyncio\nimport warnings\nfrom typing import Any, Awaitable, Callable, Dict, List, Optional  # noqa\n\nfrom .abc import AbstractStreamWriter\nfrom .http_parser import RawRequestMessage\nfrom .streams import StreamReader\nfrom .web_protocol import RequestHandler, _RequestFactory, _RequestHandler\nfrom .web_request import BaseRequest\n\n__all__ = (\"Server\",)\n\n\nclass Server:\n    def __init__(\n        self,\n        handler: _RequestHandler,\n        *,\n        request_factory: Optional[_RequestFactory] = None,\n        debug: Optional[bool] = None,\n        handler_cancellation: bool = False,\n        **kwargs: Any,\n    ) -> None:\n        if debug is not None:\n            warnings.warn(\n                \"debug argument is no-op since 4.0 \" \"and scheduled for removal in 5.0\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n        self._loop = asyncio.get_running_loop()\n        self._connections: Dict[RequestHandler, asyncio.Transport] = {}\n        self._kwargs = kwargs\n        self.requests_count = 0\n        self.request_handler = handler\n        self.request_factory = request_factory or self._make_request\n        self.handler_cancellation = handler_cancellation\n\n    @property\n    def connections(self) -> List[RequestHandler]:\n        return list(self._connections.keys())\n\n    def connection_made(\n        self, handler: RequestHandler, transport: asyncio.Transport\n    ) -> None:\n        self._connections[handler] = transport\n\n    def connection_lost(\n        self, handler: RequestHandler, exc: Optional[BaseException] = None\n    ) -> None:\n        if handler in self._connections:\n            del self._connections[handler]\n\n    def _make_request(\n        self,\n        message: RawRequestMessage,\n        payload: StreamReader,\n        protocol: RequestHandler,\n        writer: AbstractStreamWriter,\n        task: \"asyncio.Task[None]\",\n    ) -> BaseRequest:\n        return BaseRequest(message, payload, protocol, writer, task, self._loop)\n\n    def pre_shutdown(self) -> None:\n        for conn in self._connections:\n            conn.close()\n\n    async def shutdown(self, timeout: Optional[float] = None) -> None:\n        coros = (conn.shutdown(timeout) for conn in self._connections)\n        await asyncio.gather(*coros)\n        self._connections.clear()\n\n    def __call__(self) -> RequestHandler:\n        try:\n            return RequestHandler(self, loop=self._loop, **self._kwargs)\n        except TypeError:\n            # Failsafe creation: remove all custom handler_args\n            kwargs = {\n                k: v\n                for k, v in self._kwargs.items()\n                if k in [\"debug\", \"access_log_class\"]\n            }\n            return RequestHandler(self, loop=self._loop, **kwargs)\n", "aiohttp/resolver.py": "import asyncio\nimport socket\nimport sys\nfrom typing import Any, List, Tuple, Type, Union\n\nfrom .abc import AbstractResolver, ResolveResult\n\n__all__ = (\"ThreadedResolver\", \"AsyncResolver\", \"DefaultResolver\")\n\ntry:\n    import aiodns\n\n    # aiodns_default = hasattr(aiodns.DNSResolver, 'getaddrinfo')\nexcept ImportError:  # pragma: no cover\n    aiodns = None  # type: ignore[assignment]\n\n\naiodns_default = False\n\n_NUMERIC_SOCKET_FLAGS = socket.AI_NUMERICHOST | socket.AI_NUMERICSERV\n_SUPPORTS_SCOPE_ID = sys.version_info >= (3, 9, 0)\n\n\nclass ThreadedResolver(AbstractResolver):\n    \"\"\"Threaded resolver.\n\n    Uses an Executor for synchronous getaddrinfo() calls.\n    concurrent.futures.ThreadPoolExecutor is used by default.\n    \"\"\"\n\n    def __init__(self) -> None:\n        self._loop = asyncio.get_running_loop()\n\n    async def resolve(\n        self, host: str, port: int = 0, family: socket.AddressFamily = socket.AF_INET\n    ) -> List[ResolveResult]:\n        infos = await self._loop.getaddrinfo(\n            host,\n            port,\n            type=socket.SOCK_STREAM,\n            family=family,\n            flags=socket.AI_ADDRCONFIG,\n        )\n\n        hosts: List[ResolveResult] = []\n        for family, _, proto, _, address in infos:\n            if family == socket.AF_INET6:\n                if len(address) < 3:\n                    # IPv6 is not supported by Python build,\n                    # or IPv6 is not enabled in the host\n                    continue\n                if address[3] and _SUPPORTS_SCOPE_ID:\n                    # This is essential for link-local IPv6 addresses.\n                    # LL IPv6 is a VERY rare case. Strictly speaking, we should use\n                    # getnameinfo() unconditionally, but performance makes sense.\n                    resolved_host, _port = await self._loop.getnameinfo(\n                        address, _NUMERIC_SOCKET_FLAGS\n                    )\n                    port = int(_port)\n                else:\n                    resolved_host, port = address[:2]\n            else:  # IPv4\n                assert family == socket.AF_INET\n                resolved_host, port = address  # type: ignore[misc]\n            hosts.append(\n                ResolveResult(\n                    hostname=host,\n                    host=resolved_host,\n                    port=port,\n                    family=family,\n                    proto=proto,\n                    flags=_NUMERIC_SOCKET_FLAGS,\n                )\n            )\n\n        return hosts\n\n    async def close(self) -> None:\n        pass\n\n\nclass AsyncResolver(AbstractResolver):\n    \"\"\"Use the `aiodns` package to make asynchronous DNS lookups\"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        if aiodns is None:\n            raise RuntimeError(\"Resolver requires aiodns library\")\n\n        self._resolver = aiodns.DNSResolver(*args, **kwargs)\n\n    async def resolve(\n        self, host: str, port: int = 0, family: socket.AddressFamily = socket.AF_INET\n    ) -> List[ResolveResult]:\n        try:\n            resp = await self._resolver.getaddrinfo(\n                host,\n                port=port,\n                type=socket.SOCK_STREAM,\n                family=family,\n                flags=socket.AI_ADDRCONFIG,\n            )\n        except aiodns.error.DNSError as exc:\n            msg = exc.args[1] if len(exc.args) >= 1 else \"DNS lookup failed\"\n            raise OSError(msg) from exc\n        hosts: List[ResolveResult] = []\n        for node in resp.nodes:\n            address: Union[Tuple[bytes, int], Tuple[bytes, int, int, int]] = node.addr\n            family = node.family\n            if family == socket.AF_INET6:\n                if len(address) > 3 and address[3] and _SUPPORTS_SCOPE_ID:\n                    # This is essential for link-local IPv6 addresses.\n                    # LL IPv6 is a VERY rare case. Strictly speaking, we should use\n                    # getnameinfo() unconditionally, but performance makes sense.\n                    result = await self._resolver.getnameinfo(\n                        (address[0].decode(\"ascii\"), *address[1:]),\n                        _NUMERIC_SOCKET_FLAGS,\n                    )\n                    resolved_host = result.node\n                else:\n                    resolved_host = address[0].decode(\"ascii\")\n                    port = address[1]\n            else:  # IPv4\n                assert family == socket.AF_INET\n                resolved_host = address[0].decode(\"ascii\")\n                port = address[1]\n            hosts.append(\n                ResolveResult(\n                    hostname=host,\n                    host=resolved_host,\n                    port=port,\n                    family=family,\n                    proto=0,\n                    flags=_NUMERIC_SOCKET_FLAGS,\n                )\n            )\n\n        if not hosts:\n            raise OSError(\"DNS lookup failed\")\n\n        return hosts\n\n    async def close(self) -> None:\n        self._resolver.cancel()\n\n\n_DefaultType = Type[Union[AsyncResolver, ThreadedResolver]]\nDefaultResolver: _DefaultType = AsyncResolver if aiodns_default else ThreadedResolver\n", "aiohttp/locks.py": "import asyncio\nimport collections\nfrom typing import Any, Deque, Optional\n\n\nclass EventResultOrError:\n    \"\"\"Event asyncio lock helper class.\n\n    Wraps the Event asyncio lock allowing either to awake the\n    locked Tasks without any error or raising an exception.\n\n    thanks to @vorpalsmith for the simple design.\n    \"\"\"\n\n    def __init__(self, loop: asyncio.AbstractEventLoop) -> None:\n        self._loop = loop\n        self._exc: Optional[BaseException] = None\n        self._event = asyncio.Event()\n        self._waiters: Deque[asyncio.Future[Any]] = collections.deque()\n\n    def set(self, exc: Optional[BaseException] = None) -> None:\n        self._exc = exc\n        self._event.set()\n\n    async def wait(self) -> Any:\n        waiter = self._loop.create_task(self._event.wait())\n        self._waiters.append(waiter)\n        try:\n            val = await waiter\n        finally:\n            self._waiters.remove(waiter)\n\n        if self._exc is not None:\n            raise self._exc\n\n        return val\n\n    def cancel(self) -> None:\n        \"\"\"Cancel all waiters\"\"\"\n        for waiter in self._waiters:\n            waiter.cancel()\n", "aiohttp/client_ws.py": "\"\"\"WebSocket client for asyncio.\"\"\"\n\nimport asyncio\nimport dataclasses\nimport sys\nfrom typing import Any, Final, Optional, cast\n\nfrom .client_exceptions import ClientError\nfrom .client_reqrep import ClientResponse\nfrom .helpers import call_later, set_result\nfrom .http import (\n    WS_CLOSED_MESSAGE,\n    WS_CLOSING_MESSAGE,\n    WebSocketError,\n    WSCloseCode,\n    WSMessage,\n    WSMsgType,\n)\nfrom .http_websocket import WebSocketWriter  # WSMessage\nfrom .streams import EofStream, FlowControlDataQueue\nfrom .typedefs import (\n    DEFAULT_JSON_DECODER,\n    DEFAULT_JSON_ENCODER,\n    JSONDecoder,\n    JSONEncoder,\n)\n\nif sys.version_info >= (3, 11):\n    import asyncio as async_timeout\nelse:\n    import async_timeout\n\n\n@dataclasses.dataclass(frozen=True)\nclass ClientWSTimeout:\n    ws_receive: Optional[float] = None\n    ws_close: Optional[float] = None\n\n\nDEFAULT_WS_CLIENT_TIMEOUT: Final[ClientWSTimeout] = ClientWSTimeout(\n    ws_receive=None, ws_close=10.0\n)\n\n\nclass ClientWebSocketResponse:\n    def __init__(\n        self,\n        reader: \"FlowControlDataQueue[WSMessage]\",\n        writer: WebSocketWriter,\n        protocol: Optional[str],\n        response: ClientResponse,\n        timeout: ClientWSTimeout,\n        autoclose: bool,\n        autoping: bool,\n        loop: asyncio.AbstractEventLoop,\n        *,\n        heartbeat: Optional[float] = None,\n        compress: int = 0,\n        client_notakeover: bool = False,\n    ) -> None:\n        self._response = response\n        self._conn = response.connection\n\n        self._writer = writer\n        self._reader = reader\n        self._protocol = protocol\n        self._closed = False\n        self._closing = False\n        self._close_code: Optional[int] = None\n        self._timeout: ClientWSTimeout = timeout\n        self._autoclose = autoclose\n        self._autoping = autoping\n        self._heartbeat = heartbeat\n        self._heartbeat_cb: Optional[asyncio.TimerHandle] = None\n        if heartbeat is not None:\n            self._pong_heartbeat = heartbeat / 2.0\n        self._pong_response_cb: Optional[asyncio.TimerHandle] = None\n        self._loop = loop\n        self._waiting: Optional[asyncio.Future[bool]] = None\n        self._exception: Optional[BaseException] = None\n        self._compress = compress\n        self._client_notakeover = client_notakeover\n\n        self._reset_heartbeat()\n\n    def _cancel_heartbeat(self) -> None:\n        if self._pong_response_cb is not None:\n            self._pong_response_cb.cancel()\n            self._pong_response_cb = None\n\n        if self._heartbeat_cb is not None:\n            self._heartbeat_cb.cancel()\n            self._heartbeat_cb = None\n\n    def _reset_heartbeat(self) -> None:\n        self._cancel_heartbeat()\n\n        if self._heartbeat is not None:\n            self._heartbeat_cb = call_later(\n                self._send_heartbeat,\n                self._heartbeat,\n                self._loop,\n                timeout_ceil_threshold=(\n                    self._conn._connector._timeout_ceil_threshold\n                    if self._conn is not None\n                    else 5\n                ),\n            )\n\n    def _send_heartbeat(self) -> None:\n        if self._heartbeat is not None and not self._closed:\n            # fire-and-forget a task is not perfect but maybe ok for\n            # sending ping. Otherwise we need a long-living heartbeat\n            # task in the class.\n            self._loop.create_task(self._writer.ping())  # type: ignore[unused-awaitable]\n\n            if self._pong_response_cb is not None:\n                self._pong_response_cb.cancel()\n            self._pong_response_cb = call_later(\n                self._pong_not_received,\n                self._pong_heartbeat,\n                self._loop,\n                timeout_ceil_threshold=(\n                    self._conn._connector._timeout_ceil_threshold\n                    if self._conn is not None\n                    else 5\n                ),\n            )\n\n    def _pong_not_received(self) -> None:\n        if not self._closed:\n            self._closed = True\n            self._close_code = WSCloseCode.ABNORMAL_CLOSURE\n            self._exception = asyncio.TimeoutError()\n            self._response.close()\n\n    @property\n    def closed(self) -> bool:\n        return self._closed\n\n    @property\n    def close_code(self) -> Optional[int]:\n        return self._close_code\n\n    @property\n    def protocol(self) -> Optional[str]:\n        return self._protocol\n\n    @property\n    def compress(self) -> int:\n        return self._compress\n\n    @property\n    def client_notakeover(self) -> bool:\n        return self._client_notakeover\n\n    def get_extra_info(self, name: str, default: Any = None) -> Any:\n        \"\"\"extra info from connection transport\"\"\"\n        conn = self._response.connection\n        if conn is None:\n            return default\n        transport = conn.transport\n        if transport is None:\n            return default\n        return transport.get_extra_info(name, default)\n\n    def exception(self) -> Optional[BaseException]:\n        return self._exception\n\n    async def ping(self, message: bytes = b\"\") -> None:\n        await self._writer.ping(message)\n\n    async def pong(self, message: bytes = b\"\") -> None:\n        await self._writer.pong(message)\n\n    async def send_str(self, data: str, compress: Optional[int] = None) -> None:\n        if not isinstance(data, str):\n            raise TypeError(\"data argument must be str (%r)\" % type(data))\n        await self._writer.send(data, binary=False, compress=compress)\n\n    async def send_bytes(self, data: bytes, compress: Optional[int] = None) -> None:\n        if not isinstance(data, (bytes, bytearray, memoryview)):\n            raise TypeError(\"data argument must be byte-ish (%r)\" % type(data))\n        await self._writer.send(data, binary=True, compress=compress)\n\n    async def send_json(\n        self,\n        data: Any,\n        compress: Optional[int] = None,\n        *,\n        dumps: JSONEncoder = DEFAULT_JSON_ENCODER,\n    ) -> None:\n        await self.send_str(dumps(data), compress=compress)\n\n    async def close(self, *, code: int = WSCloseCode.OK, message: bytes = b\"\") -> bool:\n        # we need to break `receive()` cycle first,\n        # `close()` may be called from different task\n        if self._waiting is not None and not self._closing:\n            self._closing = True\n            self._reader.feed_data(WS_CLOSING_MESSAGE)\n            await self._waiting\n\n        if not self._closed:\n            self._cancel_heartbeat()\n            self._closed = True\n            try:\n                await self._writer.close(code, message)\n            except asyncio.CancelledError:\n                self._close_code = WSCloseCode.ABNORMAL_CLOSURE\n                self._response.close()\n                raise\n            except Exception as exc:\n                self._close_code = WSCloseCode.ABNORMAL_CLOSURE\n                self._exception = exc\n                self._response.close()\n                return True\n\n            if self._close_code:\n                self._response.close()\n                return True\n\n            while True:\n                try:\n                    async with async_timeout.timeout(self._timeout.ws_close):\n                        msg = await self._reader.read()\n                except asyncio.CancelledError:\n                    self._close_code = WSCloseCode.ABNORMAL_CLOSURE\n                    self._response.close()\n                    raise\n                except Exception as exc:\n                    self._close_code = WSCloseCode.ABNORMAL_CLOSURE\n                    self._exception = exc\n                    self._response.close()\n                    return True\n\n                if msg.type == WSMsgType.CLOSE:\n                    self._close_code = msg.data\n                    self._response.close()\n                    return True\n        else:\n            return False\n\n    async def receive(self, timeout: Optional[float] = None) -> WSMessage:\n        while True:\n            if self._waiting is not None:\n                raise RuntimeError(\"Concurrent call to receive() is not allowed\")\n\n            if self._closed:\n                return WS_CLOSED_MESSAGE\n            elif self._closing:\n                await self.close()\n                return WS_CLOSED_MESSAGE\n\n            try:\n                self._waiting = self._loop.create_future()\n                try:\n                    async with async_timeout.timeout(\n                        timeout or self._timeout.ws_receive\n                    ):\n                        msg = await self._reader.read()\n                    self._reset_heartbeat()\n                finally:\n                    waiter = self._waiting\n                    self._waiting = None\n                    set_result(waiter, True)\n            except (asyncio.CancelledError, asyncio.TimeoutError):\n                self._close_code = WSCloseCode.ABNORMAL_CLOSURE\n                raise\n            except EofStream:\n                self._close_code = WSCloseCode.OK\n                await self.close()\n                return WSMessage(WSMsgType.CLOSED, None, None)\n            except ClientError:\n                self._closed = True\n                self._close_code = WSCloseCode.ABNORMAL_CLOSURE\n                return WS_CLOSED_MESSAGE\n            except WebSocketError as exc:\n                self._close_code = exc.code\n                await self.close(code=exc.code)\n                return WSMessage(WSMsgType.ERROR, exc, None)\n            except Exception as exc:\n                self._exception = exc\n                self._closing = True\n                self._close_code = WSCloseCode.ABNORMAL_CLOSURE\n                await self.close()\n                return WSMessage(WSMsgType.ERROR, exc, None)\n\n            if msg.type == WSMsgType.CLOSE:\n                self._closing = True\n                self._close_code = msg.data\n                # Could be closed elsewhere while awaiting reader\n                if not self._closed and self._autoclose:  # type: ignore[redundant-expr]\n                    await self.close()\n            elif msg.type == WSMsgType.CLOSING:\n                self._closing = True\n            elif msg.type == WSMsgType.PING and self._autoping:\n                await self.pong(msg.data)\n                continue\n            elif msg.type == WSMsgType.PONG and self._autoping:\n                continue\n\n            return msg\n\n    async def receive_str(self, *, timeout: Optional[float] = None) -> str:\n        msg = await self.receive(timeout)\n        if msg.type != WSMsgType.TEXT:\n            raise TypeError(f\"Received message {msg.type}:{msg.data!r} is not str\")\n        return cast(str, msg.data)\n\n    async def receive_bytes(self, *, timeout: Optional[float] = None) -> bytes:\n        msg = await self.receive(timeout)\n        if msg.type != WSMsgType.BINARY:\n            raise TypeError(f\"Received message {msg.type}:{msg.data!r} is not bytes\")\n        return cast(bytes, msg.data)\n\n    async def receive_json(\n        self,\n        *,\n        loads: JSONDecoder = DEFAULT_JSON_DECODER,\n        timeout: Optional[float] = None,\n    ) -> Any:\n        data = await self.receive_str(timeout=timeout)\n        return loads(data)\n\n    def __aiter__(self) -> \"ClientWebSocketResponse\":\n        return self\n\n    async def __anext__(self) -> WSMessage:\n        msg = await self.receive()\n        if msg.type in (WSMsgType.CLOSE, WSMsgType.CLOSING, WSMsgType.CLOSED):\n            raise StopAsyncIteration\n        return msg\n", "aiohttp/web_response.py": "import asyncio\nimport collections.abc\nimport datetime\nimport enum\nimport json\nimport math\nimport time\nimport warnings\nfrom concurrent.futures import Executor\nfrom http import HTTPStatus\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Dict,\n    Iterator,\n    MutableMapping,\n    Optional,\n    Union,\n    cast,\n)\n\nfrom multidict import CIMultiDict, istr\n\nfrom . import hdrs, payload\nfrom .abc import AbstractStreamWriter\nfrom .compression_utils import ZLibCompressor\nfrom .helpers import (\n    ETAG_ANY,\n    QUOTED_ETAG_RE,\n    CookieMixin,\n    ETag,\n    HeadersMixin,\n    must_be_empty_body,\n    parse_http_date,\n    populate_with_cookies,\n    rfc822_formatted_time,\n    sentinel,\n    should_remove_content_length,\n    validate_etag_value,\n)\nfrom .http import SERVER_SOFTWARE, HttpVersion10, HttpVersion11\nfrom .payload import Payload\nfrom .typedefs import JSONEncoder, LooseHeaders\n\n__all__ = (\"ContentCoding\", \"StreamResponse\", \"Response\", \"json_response\")\n\n\nif TYPE_CHECKING:\n    from .web_request import BaseRequest\n\n    BaseClass = MutableMapping[str, Any]\nelse:\n    BaseClass = collections.abc.MutableMapping\n\n\n# TODO(py311): Convert to StrEnum for wider use\nclass ContentCoding(enum.Enum):\n    # The content codings that we have support for.\n    #\n    # Additional registered codings are listed at:\n    # https://www.iana.org/assignments/http-parameters/http-parameters.xhtml#content-coding\n    deflate = \"deflate\"\n    gzip = \"gzip\"\n    identity = \"identity\"\n\n\n############################################################\n# HTTP Response classes\n############################################################\n\n\nclass StreamResponse(BaseClass, HeadersMixin, CookieMixin):\n    __slots__ = (\n        \"_length_check\",\n        \"_body\",\n        \"_keep_alive\",\n        \"_chunked\",\n        \"_compression\",\n        \"_compression_force\",\n        \"_req\",\n        \"_payload_writer\",\n        \"_eof_sent\",\n        \"_must_be_empty_body\",\n        \"_body_length\",\n        \"_state\",\n        \"_headers\",\n        \"_status\",\n        \"_reason\",\n        \"_cookies\",\n        \"__weakref__\",\n    )\n\n    def __init__(\n        self,\n        *,\n        status: int = 200,\n        reason: Optional[str] = None,\n        headers: Optional[LooseHeaders] = None,\n    ) -> None:\n        super().__init__()\n        self._length_check = True\n        self._body = None\n        self._keep_alive: Optional[bool] = None\n        self._chunked = False\n        self._compression = False\n        self._compression_force: Optional[ContentCoding] = None\n\n        self._req: Optional[BaseRequest] = None\n        self._payload_writer: Optional[AbstractStreamWriter] = None\n        self._eof_sent = False\n        self._must_be_empty_body: Optional[bool] = None\n        self._body_length = 0\n        self._state: Dict[str, Any] = {}\n\n        if headers is not None:\n            self._headers: CIMultiDict[str] = CIMultiDict(headers)\n        else:\n            self._headers = CIMultiDict()\n\n        self.set_status(status, reason)\n\n    @property\n    def prepared(self) -> bool:\n        return self._payload_writer is not None\n\n    @property\n    def task(self) -> \"Optional[asyncio.Task[None]]\":\n        if self._req:\n            return self._req.task\n        else:\n            return None\n\n    @property\n    def status(self) -> int:\n        return self._status\n\n    @property\n    def chunked(self) -> bool:\n        return self._chunked\n\n    @property\n    def compression(self) -> bool:\n        return self._compression\n\n    @property\n    def reason(self) -> str:\n        return self._reason\n\n    def set_status(\n        self,\n        status: int,\n        reason: Optional[str] = None,\n    ) -> None:\n        assert not self.prepared, (\n            \"Cannot change the response status code after \" \"the headers have been sent\"\n        )\n        self._status = int(status)\n        if reason is None:\n            try:\n                reason = HTTPStatus(self._status).phrase\n            except ValueError:\n                reason = \"\"\n        self._reason = reason\n\n    @property\n    def keep_alive(self) -> Optional[bool]:\n        return self._keep_alive\n\n    def force_close(self) -> None:\n        self._keep_alive = False\n\n    @property\n    def body_length(self) -> int:\n        return self._body_length\n\n    def enable_chunked_encoding(self) -> None:\n        \"\"\"Enables automatic chunked transfer encoding.\"\"\"\n        self._chunked = True\n\n        if hdrs.CONTENT_LENGTH in self._headers:\n            raise RuntimeError(\n                \"You can't enable chunked encoding when \" \"a content length is set\"\n            )\n\n    def enable_compression(self, force: Optional[ContentCoding] = None) -> None:\n        \"\"\"Enables response compression encoding.\"\"\"\n        self._compression = True\n        self._compression_force = force\n\n    @property\n    def headers(self) -> \"CIMultiDict[str]\":\n        return self._headers\n\n    @property\n    def content_length(self) -> Optional[int]:\n        # Just a placeholder for adding setter\n        return super().content_length\n\n    @content_length.setter\n    def content_length(self, value: Optional[int]) -> None:\n        if value is not None:\n            value = int(value)\n            if self._chunked:\n                raise RuntimeError(\n                    \"You can't set content length when \" \"chunked encoding is enable\"\n                )\n            self._headers[hdrs.CONTENT_LENGTH] = str(value)\n        else:\n            self._headers.pop(hdrs.CONTENT_LENGTH, None)\n\n    @property\n    def content_type(self) -> str:\n        # Just a placeholder for adding setter\n        return super().content_type\n\n    @content_type.setter\n    def content_type(self, value: str) -> None:\n        self.content_type  # read header values if needed\n        self._content_type = str(value)\n        self._generate_content_type_header()\n\n    @property\n    def charset(self) -> Optional[str]:\n        # Just a placeholder for adding setter\n        return super().charset\n\n    @charset.setter\n    def charset(self, value: Optional[str]) -> None:\n        ctype = self.content_type  # read header values if needed\n        if ctype == \"application/octet-stream\":\n            raise RuntimeError(\n                \"Setting charset for application/octet-stream \"\n                \"doesn't make sense, setup content_type first\"\n            )\n        assert self._content_dict is not None\n        if value is None:\n            self._content_dict.pop(\"charset\", None)\n        else:\n            self._content_dict[\"charset\"] = str(value).lower()\n        self._generate_content_type_header()\n\n    @property\n    def last_modified(self) -> Optional[datetime.datetime]:\n        \"\"\"The value of Last-Modified HTTP header, or None.\n\n        This header is represented as a `datetime` object.\n        \"\"\"\n        return parse_http_date(self._headers.get(hdrs.LAST_MODIFIED))\n\n    @last_modified.setter\n    def last_modified(\n        self, value: Optional[Union[int, float, datetime.datetime, str]]\n    ) -> None:\n        if value is None:\n            self._headers.pop(hdrs.LAST_MODIFIED, None)\n        elif isinstance(value, (int, float)):\n            self._headers[hdrs.LAST_MODIFIED] = time.strftime(\n                \"%a, %d %b %Y %H:%M:%S GMT\", time.gmtime(math.ceil(value))\n            )\n        elif isinstance(value, datetime.datetime):\n            self._headers[hdrs.LAST_MODIFIED] = time.strftime(\n                \"%a, %d %b %Y %H:%M:%S GMT\", value.utctimetuple()\n            )\n        elif isinstance(value, str):\n            self._headers[hdrs.LAST_MODIFIED] = value\n\n    @property\n    def etag(self) -> Optional[ETag]:\n        quoted_value = self._headers.get(hdrs.ETAG)\n        if not quoted_value:\n            return None\n        elif quoted_value == ETAG_ANY:\n            return ETag(value=ETAG_ANY)\n        match = QUOTED_ETAG_RE.fullmatch(quoted_value)\n        if not match:\n            return None\n        is_weak, value = match.group(1, 2)\n        return ETag(\n            is_weak=bool(is_weak),\n            value=value,\n        )\n\n    @etag.setter\n    def etag(self, value: Optional[Union[ETag, str]]) -> None:\n        if value is None:\n            self._headers.pop(hdrs.ETAG, None)\n        elif (isinstance(value, str) and value == ETAG_ANY) or (\n            isinstance(value, ETag) and value.value == ETAG_ANY\n        ):\n            self._headers[hdrs.ETAG] = ETAG_ANY\n        elif isinstance(value, str):\n            validate_etag_value(value)\n            self._headers[hdrs.ETAG] = f'\"{value}\"'\n        elif isinstance(value, ETag) and isinstance(value.value, str):  # type: ignore[redundant-expr]\n            validate_etag_value(value.value)\n            hdr_value = f'W/\"{value.value}\"' if value.is_weak else f'\"{value.value}\"'\n            self._headers[hdrs.ETAG] = hdr_value\n        else:\n            raise ValueError(\n                f\"Unsupported etag type: {type(value)}. \"\n                f\"etag must be str, ETag or None\"\n            )\n\n    def _generate_content_type_header(\n        self, CONTENT_TYPE: istr = hdrs.CONTENT_TYPE\n    ) -> None:\n        assert self._content_dict is not None\n        assert self._content_type is not None\n        params = \"; \".join(f\"{k}={v}\" for k, v in self._content_dict.items())\n        if params:\n            ctype = self._content_type + \"; \" + params\n        else:\n            ctype = self._content_type\n        self._headers[CONTENT_TYPE] = ctype\n\n    async def _do_start_compression(self, coding: ContentCoding) -> None:\n        if coding != ContentCoding.identity:\n            assert self._payload_writer is not None\n            self._headers[hdrs.CONTENT_ENCODING] = coding.value\n            self._payload_writer.enable_compression(coding.value)\n            # Compressed payload may have different content length,\n            # remove the header\n            self._headers.popall(hdrs.CONTENT_LENGTH, None)\n\n    async def _start_compression(self, request: \"BaseRequest\") -> None:\n        if self._compression_force:\n            await self._do_start_compression(self._compression_force)\n        else:\n            # Encoding comparisons should be case-insensitive\n            # https://www.rfc-editor.org/rfc/rfc9110#section-8.4.1\n            accept_encoding = request.headers.get(hdrs.ACCEPT_ENCODING, \"\").lower()\n            for coding in ContentCoding:\n                if coding.value in accept_encoding:\n                    await self._do_start_compression(coding)\n                    return\n\n    async def prepare(self, request: \"BaseRequest\") -> Optional[AbstractStreamWriter]:\n        if self._eof_sent:\n            return None\n        if self._payload_writer is not None:\n            return self._payload_writer\n        self._must_be_empty_body = must_be_empty_body(request.method, self.status)\n        return await self._start(request)\n\n    async def _start(self, request: \"BaseRequest\") -> AbstractStreamWriter:\n        self._req = request\n        writer = self._payload_writer = request._payload_writer\n\n        await self._prepare_headers()\n        await request._prepare_hook(self)\n        await self._write_headers()\n\n        return writer\n\n    async def _prepare_headers(self) -> None:\n        request = self._req\n        assert request is not None\n        writer = self._payload_writer\n        assert writer is not None\n        keep_alive = self._keep_alive\n        if keep_alive is None:\n            keep_alive = request.keep_alive\n        self._keep_alive = keep_alive\n\n        version = request.version\n\n        headers = self._headers\n        populate_with_cookies(headers, self.cookies)\n\n        if self._compression:\n            await self._start_compression(request)\n\n        if self._chunked:\n            if version != HttpVersion11:\n                raise RuntimeError(\n                    \"Using chunked encoding is forbidden \"\n                    \"for HTTP/{0.major}.{0.minor}\".format(request.version)\n                )\n            if not self._must_be_empty_body:\n                writer.enable_chunking()\n                headers[hdrs.TRANSFER_ENCODING] = \"chunked\"\n            if hdrs.CONTENT_LENGTH in headers:\n                del headers[hdrs.CONTENT_LENGTH]\n        elif self._length_check:\n            writer.length = self.content_length\n            if writer.length is None:\n                if version >= HttpVersion11:\n                    if not self._must_be_empty_body:\n                        writer.enable_chunking()\n                        headers[hdrs.TRANSFER_ENCODING] = \"chunked\"\n                elif not self._must_be_empty_body:\n                    keep_alive = False\n\n        # HTTP 1.1: https://tools.ietf.org/html/rfc7230#section-3.3.2\n        # HTTP 1.0: https://tools.ietf.org/html/rfc1945#section-10.4\n        if self._must_be_empty_body:\n            if hdrs.CONTENT_LENGTH in headers and should_remove_content_length(\n                request.method, self.status\n            ):\n                del headers[hdrs.CONTENT_LENGTH]\n            # https://datatracker.ietf.org/doc/html/rfc9112#section-6.1-10\n            # https://datatracker.ietf.org/doc/html/rfc9112#section-6.1-13\n            if hdrs.TRANSFER_ENCODING in headers:\n                del headers[hdrs.TRANSFER_ENCODING]\n        else:\n            headers.setdefault(hdrs.CONTENT_TYPE, \"application/octet-stream\")\n        headers.setdefault(hdrs.DATE, rfc822_formatted_time())\n        headers.setdefault(hdrs.SERVER, SERVER_SOFTWARE)\n\n        # connection header\n        if hdrs.CONNECTION not in headers:\n            if keep_alive:\n                if version == HttpVersion10:\n                    headers[hdrs.CONNECTION] = \"keep-alive\"\n            else:\n                if version == HttpVersion11:\n                    headers[hdrs.CONNECTION] = \"close\"\n\n    async def _write_headers(self) -> None:\n        request = self._req\n        assert request is not None\n        writer = self._payload_writer\n        assert writer is not None\n        # status line\n        version = request.version\n        status_line = \"HTTP/{}.{} {} {}\".format(\n            version[0], version[1], self._status, self._reason\n        )\n        await writer.write_headers(status_line, self._headers)\n\n    async def write(self, data: bytes) -> None:\n        assert isinstance(\n            data, (bytes, bytearray, memoryview)\n        ), \"data argument must be byte-ish (%r)\" % type(data)\n\n        if self._eof_sent:\n            raise RuntimeError(\"Cannot call write() after write_eof()\")\n        if self._payload_writer is None:\n            raise RuntimeError(\"Cannot call write() before prepare()\")\n\n        await self._payload_writer.write(data)\n\n    async def drain(self) -> None:\n        assert not self._eof_sent, \"EOF has already been sent\"\n        assert self._payload_writer is not None, \"Response has not been started\"\n        warnings.warn(\n            \"drain method is deprecated, use await resp.write()\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        await self._payload_writer.drain()\n\n    async def write_eof(self, data: bytes = b\"\") -> None:\n        assert isinstance(\n            data, (bytes, bytearray, memoryview)\n        ), \"data argument must be byte-ish (%r)\" % type(data)\n\n        if self._eof_sent:\n            return\n\n        assert self._payload_writer is not None, \"Response has not been started\"\n\n        await self._payload_writer.write_eof(data)\n        self._eof_sent = True\n        self._req = None\n        self._body_length = self._payload_writer.output_size\n        self._payload_writer = None\n\n    def __repr__(self) -> str:\n        if self._eof_sent:\n            info = \"eof\"\n        elif self.prepared:\n            assert self._req is not None\n            info = f\"{self._req.method} {self._req.path} \"\n        else:\n            info = \"not prepared\"\n        return f\"<{self.__class__.__name__} {self.reason} {info}>\"\n\n    def __getitem__(self, key: str) -> Any:\n        return self._state[key]\n\n    def __setitem__(self, key: str, value: Any) -> None:\n        self._state[key] = value\n\n    def __delitem__(self, key: str) -> None:\n        del self._state[key]\n\n    def __len__(self) -> int:\n        return len(self._state)\n\n    def __iter__(self) -> Iterator[str]:\n        return iter(self._state)\n\n    def __hash__(self) -> int:\n        return hash(id(self))\n\n    def __eq__(self, other: object) -> bool:\n        return self is other\n\n\nclass Response(StreamResponse):\n    __slots__ = (\n        \"_body_payload\",\n        \"_compressed_body\",\n        \"_zlib_executor_size\",\n        \"_zlib_executor\",\n    )\n\n    def __init__(\n        self,\n        *,\n        body: Any = None,\n        status: int = 200,\n        reason: Optional[str] = None,\n        text: Optional[str] = None,\n        headers: Optional[LooseHeaders] = None,\n        content_type: Optional[str] = None,\n        charset: Optional[str] = None,\n        zlib_executor_size: Optional[int] = None,\n        zlib_executor: Optional[Executor] = None,\n    ) -> None:\n        if body is not None and text is not None:\n            raise ValueError(\"body and text are not allowed together\")\n\n        if headers is None:\n            real_headers: CIMultiDict[str] = CIMultiDict()\n        elif not isinstance(headers, CIMultiDict):\n            real_headers = CIMultiDict(headers)\n        else:\n            real_headers = headers  # = cast('CIMultiDict[str]', headers)\n\n        if content_type is not None and \"charset\" in content_type:\n            raise ValueError(\"charset must not be in content_type \" \"argument\")\n\n        if text is not None:\n            if hdrs.CONTENT_TYPE in real_headers:\n                if content_type or charset:\n                    raise ValueError(\n                        \"passing both Content-Type header and \"\n                        \"content_type or charset params \"\n                        \"is forbidden\"\n                    )\n            else:\n                # fast path for filling headers\n                if not isinstance(text, str):\n                    raise TypeError(\"text argument must be str (%r)\" % type(text))\n                if content_type is None:\n                    content_type = \"text/plain\"\n                if charset is None:\n                    charset = \"utf-8\"\n                real_headers[hdrs.CONTENT_TYPE] = content_type + \"; charset=\" + charset\n                body = text.encode(charset)\n                text = None\n        else:\n            if hdrs.CONTENT_TYPE in real_headers:\n                if content_type is not None or charset is not None:\n                    raise ValueError(\n                        \"passing both Content-Type header and \"\n                        \"content_type or charset params \"\n                        \"is forbidden\"\n                    )\n            else:\n                if content_type is not None:\n                    if charset is not None:\n                        content_type += \"; charset=\" + charset\n                    real_headers[hdrs.CONTENT_TYPE] = content_type\n\n        super().__init__(status=status, reason=reason, headers=real_headers)\n\n        if text is not None:\n            self.text = text\n        else:\n            self.body = body\n\n        self._compressed_body: Optional[bytes] = None\n        self._zlib_executor_size = zlib_executor_size\n        self._zlib_executor = zlib_executor\n\n    @property\n    def body(self) -> Optional[Union[bytes, Payload]]:\n        return self._body\n\n    @body.setter\n    def body(self, body: bytes) -> None:\n        if body is None:\n            self._body: Optional[bytes] = None\n            self._body_payload: bool = False\n        elif isinstance(body, (bytes, bytearray)):\n            self._body = body\n            self._body_payload = False\n        else:\n            try:\n                self._body = body = payload.PAYLOAD_REGISTRY.get(body)\n            except payload.LookupError:\n                raise ValueError(\"Unsupported body type %r\" % type(body))\n\n            self._body_payload = True\n\n            headers = self._headers\n\n            # set content-type\n            if hdrs.CONTENT_TYPE not in headers:\n                headers[hdrs.CONTENT_TYPE] = body.content_type\n\n            # copy payload headers\n            if body.headers:\n                for key, value in body.headers.items():\n                    if key not in headers:\n                        headers[key] = value\n\n        self._compressed_body = None\n\n    @property\n    def text(self) -> Optional[str]:\n        if self._body is None:\n            return None\n        return self._body.decode(self.charset or \"utf-8\")\n\n    @text.setter\n    def text(self, text: str) -> None:\n        assert isinstance(text, str), \"text argument must be str (%r)\" % type(text)\n\n        if self.content_type == \"application/octet-stream\":\n            self.content_type = \"text/plain\"\n        if self.charset is None:\n            self.charset = \"utf-8\"\n\n        self._body = text.encode(self.charset)\n        self._body_payload = False\n        self._compressed_body = None\n\n    @property\n    def content_length(self) -> Optional[int]:\n        if self._chunked:\n            return None\n\n        if hdrs.CONTENT_LENGTH in self._headers:\n            return super().content_length\n\n        if self._compressed_body is not None:\n            # Return length of the compressed body\n            return len(self._compressed_body)\n        elif self._body_payload:\n            # A payload without content length, or a compressed payload\n            return None\n        elif self._body is not None:\n            return len(self._body)\n        else:\n            return 0\n\n    @content_length.setter\n    def content_length(self, value: Optional[int]) -> None:\n        raise RuntimeError(\"Content length is set automatically\")\n\n    async def write_eof(self, data: bytes = b\"\") -> None:\n        if self._eof_sent:\n            return\n        if self._compressed_body is None:\n            body: Optional[Union[bytes, Payload]] = self._body\n        else:\n            body = self._compressed_body\n        assert not data, f\"data arg is not supported, got {data!r}\"\n        assert self._req is not None\n        assert self._payload_writer is not None\n        if body is not None:\n            if self._must_be_empty_body:\n                await super().write_eof()\n            elif self._body_payload:\n                payload = cast(Payload, body)\n                await payload.write(self._payload_writer)\n                await super().write_eof()\n            else:\n                await super().write_eof(cast(bytes, body))\n        else:\n            await super().write_eof()\n\n    async def _start(self, request: \"BaseRequest\") -> AbstractStreamWriter:\n        if should_remove_content_length(request.method, self.status):\n            if hdrs.CONTENT_LENGTH in self._headers:\n                del self._headers[hdrs.CONTENT_LENGTH]\n        elif not self._chunked and hdrs.CONTENT_LENGTH not in self._headers:\n            if self._body_payload:\n                size = cast(Payload, self._body).size\n                if size is not None:\n                    self._headers[hdrs.CONTENT_LENGTH] = str(size)\n            else:\n                body_len = len(self._body) if self._body else \"0\"\n                # https://www.rfc-editor.org/rfc/rfc9110.html#section-8.6-7\n                if body_len != \"0\" or (\n                    self.status != 304 and request.method.upper() != hdrs.METH_HEAD\n                ):\n                    self._headers[hdrs.CONTENT_LENGTH] = str(body_len)\n\n        return await super()._start(request)\n\n    async def _do_start_compression(self, coding: ContentCoding) -> None:\n        if self._body_payload or self._chunked:\n            return await super()._do_start_compression(coding)\n\n        if coding != ContentCoding.identity:\n            # Instead of using _payload_writer.enable_compression,\n            # compress the whole body\n            compressor = ZLibCompressor(\n                encoding=str(coding.value),\n                max_sync_chunk_size=self._zlib_executor_size,\n                executor=self._zlib_executor,\n            )\n            assert self._body is not None\n            if self._zlib_executor_size is None and len(self._body) > 1024 * 1024:\n                warnings.warn(\n                    \"Synchronous compression of large response bodies \"\n                    f\"({len(self._body)} bytes) might block the async event loop. \"\n                    \"Consider providing a custom value to zlib_executor_size/\"\n                    \"zlib_executor response properties or disabling compression on it.\"\n                )\n            self._compressed_body = (\n                await compressor.compress(self._body) + compressor.flush()\n            )\n            assert self._compressed_body is not None\n\n            self._headers[hdrs.CONTENT_ENCODING] = coding.value\n            self._headers[hdrs.CONTENT_LENGTH] = str(len(self._compressed_body))\n\n\ndef json_response(\n    data: Any = sentinel,\n    *,\n    text: Optional[str] = None,\n    body: Optional[bytes] = None,\n    status: int = 200,\n    reason: Optional[str] = None,\n    headers: Optional[LooseHeaders] = None,\n    content_type: str = \"application/json\",\n    dumps: JSONEncoder = json.dumps,\n) -> Response:\n    if data is not sentinel:\n        if text or body:\n            raise ValueError(\"only one of data, text, or body should be specified\")\n        else:\n            text = dumps(data)\n    return Response(\n        text=text,\n        body=body,\n        status=status,\n        reason=reason,\n        headers=headers,\n        content_type=content_type,\n    )\n", "aiohttp/http_exceptions.py": "\"\"\"Low-level http related exceptions.\"\"\"\n\nfrom textwrap import indent\nfrom typing import Optional, Union\n\nfrom .typedefs import _CIMultiDict\n\n__all__ = (\"HttpProcessingError\",)\n\n\nclass HttpProcessingError(Exception):\n    \"\"\"HTTP error.\n\n    Shortcut for raising HTTP errors with custom code, message and headers.\n\n    code: HTTP Error code.\n    message: (optional) Error message.\n    headers: (optional) Headers to be sent in response, a list of pairs\n    \"\"\"\n\n    code = 0\n    message = \"\"\n    headers = None\n\n    def __init__(\n        self,\n        *,\n        code: Optional[int] = None,\n        message: str = \"\",\n        headers: Optional[_CIMultiDict] = None,\n    ) -> None:\n        if code is not None:\n            self.code = code\n        self.headers = headers\n        self.message = message\n\n    def __str__(self) -> str:\n        msg = indent(self.message, \"  \")\n        return f\"{self.code}, message:\\n{msg}\"\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__.__name__}: {self.code}, message={self.message!r}>\"\n\n\nclass BadHttpMessage(HttpProcessingError):\n    code = 400\n    message = \"Bad Request\"\n\n    def __init__(self, message: str, *, headers: Optional[_CIMultiDict] = None) -> None:\n        super().__init__(message=message, headers=headers)\n        self.args = (message,)\n\n\nclass HttpBadRequest(BadHttpMessage):\n    code = 400\n    message = \"Bad Request\"\n\n\nclass PayloadEncodingError(BadHttpMessage):\n    \"\"\"Base class for payload errors\"\"\"\n\n\nclass ContentEncodingError(PayloadEncodingError):\n    \"\"\"Content encoding error.\"\"\"\n\n\nclass TransferEncodingError(PayloadEncodingError):\n    \"\"\"transfer encoding error.\"\"\"\n\n\nclass ContentLengthError(PayloadEncodingError):\n    \"\"\"Not enough data for satisfy content length header.\"\"\"\n\n\nclass LineTooLong(BadHttpMessage):\n    def __init__(\n        self, line: str, limit: str = \"Unknown\", actual_size: str = \"Unknown\"\n    ) -> None:\n        super().__init__(\n            f\"Got more than {limit} bytes ({actual_size}) when reading {line}.\"\n        )\n        self.args = (line, limit, actual_size)\n\n\nclass InvalidHeader(BadHttpMessage):\n    def __init__(self, hdr: Union[bytes, str]) -> None:\n        hdr_s = hdr.decode(errors=\"backslashreplace\") if isinstance(hdr, bytes) else hdr\n        super().__init__(f\"Invalid HTTP header: {hdr!r}\")\n        self.hdr = hdr_s\n        self.args = (hdr,)\n\n\nclass BadStatusLine(BadHttpMessage):\n    def __init__(self, line: str = \"\", error: Optional[str] = None) -> None:\n        if not isinstance(line, str):\n            line = repr(line)\n        super().__init__(error or f\"Bad status line {line!r}\")\n        self.args = (line,)\n        self.line = line\n\n\nclass InvalidURLError(BadHttpMessage):\n    pass\n", "aiohttp/worker.py": "\"\"\"Async gunicorn worker for aiohttp.web\"\"\"\n\nimport asyncio\nimport os\nimport re\nimport signal\nimport sys\nfrom types import FrameType\nfrom typing import Any, Awaitable, Callable, Optional, Union  # noqa\n\nfrom gunicorn.config import AccessLogFormat as GunicornAccessLogFormat\nfrom gunicorn.workers import base\n\nfrom aiohttp import web\n\nfrom .helpers import set_result\nfrom .web_app import Application\nfrom .web_log import AccessLogger\n\ntry:\n    import ssl\n\n    SSLContext = ssl.SSLContext\nexcept ImportError:  # pragma: no cover\n    ssl = None  # type: ignore[assignment]\n    SSLContext = object  # type: ignore[misc,assignment]\n\n\n__all__ = (\"GunicornWebWorker\", \"GunicornUVLoopWebWorker\")\n\n\nclass GunicornWebWorker(base.Worker):  # type: ignore[misc,no-any-unimported]\n    DEFAULT_AIOHTTP_LOG_FORMAT = AccessLogger.LOG_FORMAT\n    DEFAULT_GUNICORN_LOG_FORMAT = GunicornAccessLogFormat.default\n\n    def __init__(self, *args: Any, **kw: Any) -> None:  # pragma: no cover\n        super().__init__(*args, **kw)\n\n        self._task: Optional[asyncio.Task[None]] = None\n        self.exit_code = 0\n        self._notify_waiter: Optional[asyncio.Future[bool]] = None\n\n    def init_process(self) -> None:\n        # create new event_loop after fork\n        self.loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(self.loop)\n\n        super().init_process()\n\n    def run(self) -> None:\n        self._task = self.loop.create_task(self._run())\n\n        try:  # ignore all finalization problems\n            self.loop.run_until_complete(self._task)\n        except Exception:\n            self.log.exception(\"Exception in gunicorn worker\")\n        self.loop.run_until_complete(self.loop.shutdown_asyncgens())\n        self.loop.close()\n\n        sys.exit(self.exit_code)\n\n    async def _run(self) -> None:\n        runner = None\n        if isinstance(self.wsgi, Application):\n            app = self.wsgi\n        elif asyncio.iscoroutinefunction(self.wsgi):\n            wsgi = await self.wsgi()\n            if isinstance(wsgi, web.AppRunner):\n                runner = wsgi\n                app = runner.app\n            else:\n                app = wsgi\n        else:\n            raise RuntimeError(\n                \"wsgi app should be either Application or \"\n                \"async function returning Application, got {}\".format(self.wsgi)\n            )\n\n        if runner is None:\n            access_log = self.log.access_log if self.cfg.accesslog else None\n            runner = web.AppRunner(\n                app,\n                logger=self.log,\n                keepalive_timeout=self.cfg.keepalive,\n                access_log=access_log,\n                access_log_format=self._get_valid_log_format(\n                    self.cfg.access_log_format\n                ),\n                shutdown_timeout=self.cfg.graceful_timeout / 100 * 95,\n            )\n        await runner.setup()\n\n        ctx = self._create_ssl_context(self.cfg) if self.cfg.is_ssl else None\n\n        assert runner is not None\n        server = runner.server\n        assert server is not None\n        for sock in self.sockets:\n            site = web.SockSite(\n                runner,\n                sock,\n                ssl_context=ctx,\n            )\n            await site.start()\n\n        # If our parent changed then we shut down.\n        pid = os.getpid()\n        try:\n            while self.alive:  # type: ignore[has-type]\n                self.notify()\n\n                cnt = server.requests_count\n                if self.max_requests and cnt > self.max_requests:\n                    self.alive = False\n                    self.log.info(\"Max requests, shutting down: %s\", self)\n\n                elif pid == os.getpid() and self.ppid != os.getppid():\n                    self.alive = False\n                    self.log.info(\"Parent changed, shutting down: %s\", self)\n                else:\n                    await self._wait_next_notify()\n        except BaseException:\n            pass\n\n        await runner.cleanup()\n\n    def _wait_next_notify(self) -> \"asyncio.Future[bool]\":\n        self._notify_waiter_done()\n\n        loop = self.loop\n        assert loop is not None\n        self._notify_waiter = waiter = loop.create_future()\n        self.loop.call_later(1.0, self._notify_waiter_done, waiter)\n\n        return waiter\n\n    def _notify_waiter_done(\n        self, waiter: Optional[\"asyncio.Future[bool]\"] = None\n    ) -> None:\n        if waiter is None:\n            waiter = self._notify_waiter\n        if waiter is not None:\n            set_result(waiter, True)\n\n        if waiter is self._notify_waiter:\n            self._notify_waiter = None\n\n    def init_signals(self) -> None:\n        # Set up signals through the event loop API.\n\n        self.loop.add_signal_handler(\n            signal.SIGQUIT, self.handle_quit, signal.SIGQUIT, None\n        )\n\n        self.loop.add_signal_handler(\n            signal.SIGTERM, self.handle_exit, signal.SIGTERM, None\n        )\n\n        self.loop.add_signal_handler(\n            signal.SIGINT, self.handle_quit, signal.SIGINT, None\n        )\n\n        self.loop.add_signal_handler(\n            signal.SIGWINCH, self.handle_winch, signal.SIGWINCH, None\n        )\n\n        self.loop.add_signal_handler(\n            signal.SIGUSR1, self.handle_usr1, signal.SIGUSR1, None\n        )\n\n        self.loop.add_signal_handler(\n            signal.SIGABRT, self.handle_abort, signal.SIGABRT, None\n        )\n\n        # Don't let SIGTERM and SIGUSR1 disturb active requests\n        # by interrupting system calls\n        signal.siginterrupt(signal.SIGTERM, False)\n        signal.siginterrupt(signal.SIGUSR1, False)\n        # Reset signals so Gunicorn doesn't swallow subprocess return codes\n        # See: https://github.com/aio-libs/aiohttp/issues/6130\n\n    def handle_quit(self, sig: int, frame: Optional[FrameType]) -> None:\n        self.alive = False\n\n        # worker_int callback\n        self.cfg.worker_int(self)\n\n        # wakeup closing process\n        self._notify_waiter_done()\n\n    def handle_abort(self, sig: int, frame: Optional[FrameType]) -> None:\n        self.alive = False\n        self.exit_code = 1\n        self.cfg.worker_abort(self)\n        sys.exit(1)\n\n    @staticmethod\n    def _create_ssl_context(cfg: Any) -> \"SSLContext\":\n        \"\"\"Creates SSLContext instance for usage in asyncio.create_server.\n\n        See ssl.SSLSocket.__init__ for more details.\n        \"\"\"\n        if ssl is None:  # pragma: no cover\n            raise RuntimeError(\"SSL is not supported.\")\n\n        ctx = ssl.SSLContext(cfg.ssl_version)\n        ctx.load_cert_chain(cfg.certfile, cfg.keyfile)\n        ctx.verify_mode = cfg.cert_reqs\n        if cfg.ca_certs:\n            ctx.load_verify_locations(cfg.ca_certs)\n        if cfg.ciphers:\n            ctx.set_ciphers(cfg.ciphers)\n        return ctx\n\n    def _get_valid_log_format(self, source_format: str) -> str:\n        if source_format == self.DEFAULT_GUNICORN_LOG_FORMAT:\n            return self.DEFAULT_AIOHTTP_LOG_FORMAT\n        elif re.search(r\"%\\([^\\)]+\\)\", source_format):\n            raise ValueError(\n                \"Gunicorn's style options in form of `%(name)s` are not \"\n                \"supported for the log formatting. Please use aiohttp's \"\n                \"format specification to configure access log formatting: \"\n                \"http://docs.aiohttp.org/en/stable/logging.html\"\n                \"#format-specification\"\n            )\n        else:\n            return source_format\n\n\nclass GunicornUVLoopWebWorker(GunicornWebWorker):\n    def init_process(self) -> None:\n        import uvloop\n\n        # Setup uvloop policy, so that every\n        # asyncio.get_event_loop() will create an instance\n        # of uvloop event loop.\n        asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n\n        super().init_process()\n", "aiohttp/web_app.py": "import asyncio\nimport logging\nimport warnings\nfrom functools import partial, update_wrapper\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    AsyncIterator,\n    Awaitable,\n    Callable,\n    Dict,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    MutableMapping,\n    Optional,\n    Sequence,\n    Type,\n    TypeVar,\n    Union,\n    cast,\n    final,\n    overload,\n)\n\nfrom aiosignal import Signal\nfrom frozenlist import FrozenList\n\nfrom . import hdrs\nfrom .helpers import AppKey\nfrom .log import web_logger\nfrom .typedefs import Middleware\nfrom .web_exceptions import NotAppKeyWarning\nfrom .web_middlewares import _fix_request_current_app\nfrom .web_request import Request\nfrom .web_response import StreamResponse\nfrom .web_routedef import AbstractRouteDef\nfrom .web_urldispatcher import (\n    AbstractResource,\n    AbstractRoute,\n    Domain,\n    MaskDomain,\n    MatchedSubAppResource,\n    PrefixedSubAppResource,\n    UrlDispatcher,\n)\n\n__all__ = (\"Application\", \"CleanupError\")\n\n\nif TYPE_CHECKING:\n    _AppSignal = Signal[Callable[[\"Application\"], Awaitable[None]]]\n    _RespPrepareSignal = Signal[Callable[[Request, StreamResponse], Awaitable[None]]]\n    _Middlewares = FrozenList[Middleware]\n    _MiddlewaresHandlers = Sequence[Middleware]\n    _Subapps = List[\"Application\"]\nelse:\n    # No type checker mode, skip types\n    _AppSignal = Signal\n    _RespPrepareSignal = Signal\n    _Handler = Callable\n    _Middlewares = FrozenList\n    _MiddlewaresHandlers = Sequence\n    _Subapps = List\n\n_T = TypeVar(\"_T\")\n_U = TypeVar(\"_U\")\n_Resource = TypeVar(\"_Resource\", bound=AbstractResource)\n\n\n@final\nclass Application(MutableMapping[Union[str, AppKey[Any]], Any]):\n    __slots__ = (\n        \"logger\",\n        \"_debug\",\n        \"_router\",\n        \"_loop\",\n        \"_handler_args\",\n        \"_middlewares\",\n        \"_middlewares_handlers\",\n        \"_run_middlewares\",\n        \"_state\",\n        \"_frozen\",\n        \"_pre_frozen\",\n        \"_subapps\",\n        \"_on_response_prepare\",\n        \"_on_startup\",\n        \"_on_shutdown\",\n        \"_on_cleanup\",\n        \"_client_max_size\",\n        \"_cleanup_ctx\",\n    )\n\n    def __init__(\n        self,\n        *,\n        logger: logging.Logger = web_logger,\n        middlewares: Iterable[Middleware] = (),\n        handler_args: Optional[Mapping[str, Any]] = None,\n        client_max_size: int = 1024**2,\n        debug: Any = ...,  # mypy doesn't support ellipsis\n    ) -> None:\n        if debug is not ...:\n            warnings.warn(\n                \"debug argument is no-op since 4.0 \" \"and scheduled for removal in 5.0\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n        self._router = UrlDispatcher()\n        self._handler_args = handler_args\n        self.logger = logger\n\n        self._middlewares: _Middlewares = FrozenList(middlewares)\n\n        # initialized on freezing\n        self._middlewares_handlers: _MiddlewaresHandlers = tuple()\n        # initialized on freezing\n        self._run_middlewares: Optional[bool] = None\n\n        self._state: Dict[Union[AppKey[Any], str], object] = {}\n        self._frozen = False\n        self._pre_frozen = False\n        self._subapps: _Subapps = []\n\n        self._on_response_prepare: _RespPrepareSignal = Signal(self)\n        self._on_startup: _AppSignal = Signal(self)\n        self._on_shutdown: _AppSignal = Signal(self)\n        self._on_cleanup: _AppSignal = Signal(self)\n        self._cleanup_ctx = CleanupContext()\n        self._on_startup.append(self._cleanup_ctx._on_startup)\n        self._on_cleanup.append(self._cleanup_ctx._on_cleanup)\n        self._client_max_size = client_max_size\n\n    def __init_subclass__(cls: Type[\"Application\"]) -> None:\n        raise TypeError(\n            \"Inheritance class {} from web.Application \"\n            \"is forbidden\".format(cls.__name__)\n        )\n\n    # MutableMapping API\n\n    def __eq__(self, other: object) -> bool:\n        return self is other\n\n    @overload  # type: ignore[override]\n    def __getitem__(self, key: AppKey[_T]) -> _T: ...\n\n    @overload\n    def __getitem__(self, key: str) -> Any: ...\n\n    def __getitem__(self, key: Union[str, AppKey[_T]]) -> Any:\n        return self._state[key]\n\n    def _check_frozen(self) -> None:\n        if self._frozen:\n            raise RuntimeError(\n                \"Changing state of started or joined \" \"application is forbidden\"\n            )\n\n    @overload  # type: ignore[override]\n    def __setitem__(self, key: AppKey[_T], value: _T) -> None: ...\n\n    @overload\n    def __setitem__(self, key: str, value: Any) -> None: ...\n\n    def __setitem__(self, key: Union[str, AppKey[_T]], value: Any) -> None:\n        self._check_frozen()\n        if not isinstance(key, AppKey):\n            warnings.warn(\n                \"It is recommended to use web.AppKey instances for keys.\\n\"\n                + \"https://docs.aiohttp.org/en/stable/web_advanced.html\"\n                + \"#application-s-config\",\n                category=NotAppKeyWarning,\n                stacklevel=2,\n            )\n        self._state[key] = value\n\n    def __delitem__(self, key: Union[str, AppKey[_T]]) -> None:\n        self._check_frozen()\n        del self._state[key]\n\n    def __len__(self) -> int:\n        return len(self._state)\n\n    def __iter__(self) -> Iterator[Union[str, AppKey[Any]]]:\n        return iter(self._state)\n\n    @overload  # type: ignore[override]\n    def get(self, key: AppKey[_T], default: None = ...) -> Optional[_T]: ...\n\n    @overload\n    def get(self, key: AppKey[_T], default: _U) -> Union[_T, _U]: ...\n\n    @overload\n    def get(self, key: str, default: Any = ...) -> Any: ...\n\n    def get(self, key: Union[str, AppKey[_T]], default: Any = None) -> Any:\n        return self._state.get(key, default)\n\n    ########\n    def _set_loop(self, loop: Optional[asyncio.AbstractEventLoop]) -> None:\n        warnings.warn(\n            \"_set_loop() is no-op since 4.0 \" \"and scheduled for removal in 5.0\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n\n    @property\n    def pre_frozen(self) -> bool:\n        return self._pre_frozen\n\n    def pre_freeze(self) -> None:\n        if self._pre_frozen:\n            return\n\n        self._pre_frozen = True\n        self._middlewares.freeze()\n        self._router.freeze()\n        self._on_response_prepare.freeze()\n        self._cleanup_ctx.freeze()\n        self._on_startup.freeze()\n        self._on_shutdown.freeze()\n        self._on_cleanup.freeze()\n        self._middlewares_handlers = tuple(self._prepare_middleware())\n\n        # If current app and any subapp do not have middlewares avoid run all\n        # of the code footprint that it implies, which have a middleware\n        # hardcoded per app that sets up the current_app attribute. If no\n        # middlewares are configured the handler will receive the proper\n        # current_app without needing all of this code.\n        self._run_middlewares = True if self.middlewares else False\n\n        for subapp in self._subapps:\n            subapp.pre_freeze()\n            self._run_middlewares = self._run_middlewares or subapp._run_middlewares\n\n    @property\n    def frozen(self) -> bool:\n        return self._frozen\n\n    def freeze(self) -> None:\n        if self._frozen:\n            return\n\n        self.pre_freeze()\n        self._frozen = True\n        for subapp in self._subapps:\n            subapp.freeze()\n\n    @property\n    def debug(self) -> bool:\n        warnings.warn(\n            \"debug property is deprecated since 4.0\" \"and scheduled for removal in 5.0\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return asyncio.get_event_loop().get_debug()\n\n    def _reg_subapp_signals(self, subapp: \"Application\") -> None:\n        def reg_handler(signame: str) -> None:\n            subsig = getattr(subapp, signame)\n\n            async def handler(app: \"Application\") -> None:\n                await subsig.send(subapp)\n\n            appsig = getattr(self, signame)\n            appsig.append(handler)\n\n        reg_handler(\"on_startup\")\n        reg_handler(\"on_shutdown\")\n        reg_handler(\"on_cleanup\")\n\n    def add_subapp(self, prefix: str, subapp: \"Application\") -> PrefixedSubAppResource:\n        if not isinstance(prefix, str):\n            raise TypeError(\"Prefix must be str\")\n        prefix = prefix.rstrip(\"/\")\n        if not prefix:\n            raise ValueError(\"Prefix cannot be empty\")\n        factory = partial(PrefixedSubAppResource, prefix, subapp)\n        return self._add_subapp(factory, subapp)\n\n    def _add_subapp(\n        self, resource_factory: Callable[[], _Resource], subapp: \"Application\"\n    ) -> _Resource:\n        if self.frozen:\n            raise RuntimeError(\"Cannot add sub application to frozen application\")\n        if subapp.frozen:\n            raise RuntimeError(\"Cannot add frozen application\")\n        resource = resource_factory()\n        self.router.register_resource(resource)\n        self._reg_subapp_signals(subapp)\n        self._subapps.append(subapp)\n        subapp.pre_freeze()\n        return resource\n\n    def add_domain(self, domain: str, subapp: \"Application\") -> MatchedSubAppResource:\n        if not isinstance(domain, str):\n            raise TypeError(\"Domain must be str\")\n        elif \"*\" in domain:\n            rule: Domain = MaskDomain(domain)\n        else:\n            rule = Domain(domain)\n        factory = partial(MatchedSubAppResource, rule, subapp)\n        return self._add_subapp(factory, subapp)\n\n    def add_routes(self, routes: Iterable[AbstractRouteDef]) -> List[AbstractRoute]:\n        return self.router.add_routes(routes)\n\n    @property\n    def on_response_prepare(self) -> _RespPrepareSignal:\n        return self._on_response_prepare\n\n    @property\n    def on_startup(self) -> _AppSignal:\n        return self._on_startup\n\n    @property\n    def on_shutdown(self) -> _AppSignal:\n        return self._on_shutdown\n\n    @property\n    def on_cleanup(self) -> _AppSignal:\n        return self._on_cleanup\n\n    @property\n    def cleanup_ctx(self) -> \"CleanupContext\":\n        return self._cleanup_ctx\n\n    @property\n    def router(self) -> UrlDispatcher:\n        return self._router\n\n    @property\n    def middlewares(self) -> _Middlewares:\n        return self._middlewares\n\n    async def startup(self) -> None:\n        \"\"\"Causes on_startup signal\n\n        Should be called in the event loop along with the request handler.\n        \"\"\"\n        await self.on_startup.send(self)\n\n    async def shutdown(self) -> None:\n        \"\"\"Causes on_shutdown signal\n\n        Should be called before cleanup()\n        \"\"\"\n        await self.on_shutdown.send(self)\n\n    async def cleanup(self) -> None:\n        \"\"\"Causes on_cleanup signal\n\n        Should be called after shutdown()\n        \"\"\"\n        if self.on_cleanup.frozen:\n            await self.on_cleanup.send(self)\n        else:\n            # If an exception occurs in startup, ensure cleanup contexts are completed.\n            await self._cleanup_ctx._on_cleanup(self)\n\n    def _prepare_middleware(self) -> Iterator[Middleware]:\n        yield from reversed(self._middlewares)\n        yield _fix_request_current_app(self)\n\n    async def _handle(self, request: Request) -> StreamResponse:\n        match_info = await self._router.resolve(request)\n        match_info.add_app(self)\n        match_info.freeze()\n\n        resp = None\n        request._match_info = match_info\n        expect = request.headers.get(hdrs.EXPECT)\n        if expect:\n            resp = await match_info.expect_handler(request)\n            await request.writer.drain()\n\n        if resp is None:\n            handler = match_info.handler\n\n            if self._run_middlewares:\n                for app in match_info.apps[::-1]:\n                    assert app.pre_frozen, \"middleware handlers are not ready\"\n                    for m in app._middlewares_handlers:\n                        handler = update_wrapper(partial(m, handler=handler), handler)\n\n            resp = await handler(request)\n\n        return resp\n\n    def __call__(self) -> \"Application\":\n        \"\"\"gunicorn compatibility\"\"\"\n        return self\n\n    def __repr__(self) -> str:\n        return f\"<Application 0x{id(self):x}>\"\n\n    def __bool__(self) -> bool:\n        return True\n\n\nclass CleanupError(RuntimeError):\n    @property\n    def exceptions(self) -> List[BaseException]:\n        return cast(List[BaseException], self.args[1])\n\n\nif TYPE_CHECKING:\n    _CleanupContextBase = FrozenList[Callable[[Application], AsyncIterator[None]]]\nelse:\n    _CleanupContextBase = FrozenList\n\n\nclass CleanupContext(_CleanupContextBase):\n    def __init__(self) -> None:\n        super().__init__()\n        self._exits: List[AsyncIterator[None]] = []\n\n    async def _on_startup(self, app: Application) -> None:\n        for cb in self:\n            it = cb(app).__aiter__()\n            await it.__anext__()\n            self._exits.append(it)\n\n    async def _on_cleanup(self, app: Application) -> None:\n        errors = []\n        for it in reversed(self._exits):\n            try:\n                await it.__anext__()\n            except StopAsyncIteration:\n                pass\n            except Exception as exc:\n                errors.append(exc)\n            else:\n                errors.append(RuntimeError(f\"{it!r} has more than one 'yield'\"))\n        if errors:\n            if len(errors) == 1:\n                raise errors[0]\n            else:\n                raise CleanupError(\"Multiple errors on cleanup stage\", errors)\n", "aiohttp/streams.py": "import asyncio\nimport collections\nimport warnings\nfrom typing import (\n    Awaitable,\n    Callable,\n    Deque,\n    Final,\n    Generic,\n    List,\n    Optional,\n    Tuple,\n    TypeVar,\n)\n\nfrom .base_protocol import BaseProtocol\nfrom .helpers import (\n    _EXC_SENTINEL,\n    BaseTimerContext,\n    TimerNoop,\n    set_exception,\n    set_result,\n)\nfrom .log import internal_logger\n\n__all__ = (\n    \"EMPTY_PAYLOAD\",\n    \"EofStream\",\n    \"StreamReader\",\n    \"DataQueue\",\n    \"FlowControlDataQueue\",\n)\n\n_T = TypeVar(\"_T\")\n_SizedT = TypeVar(\"_SizedT\", bound=collections.abc.Sized)\n\n\nclass EofStream(Exception):\n    \"\"\"eof stream indication.\"\"\"\n\n\nclass AsyncStreamIterator(Generic[_T]):\n    def __init__(self, read_func: Callable[[], Awaitable[_T]]) -> None:\n        self.read_func = read_func\n\n    def __aiter__(self) -> \"AsyncStreamIterator[_T]\":\n        return self\n\n    async def __anext__(self) -> _T:\n        try:\n            rv = await self.read_func()\n        except EofStream:\n            raise StopAsyncIteration\n        if rv == b\"\":\n            raise StopAsyncIteration\n        return rv\n\n\nclass ChunkTupleAsyncStreamIterator:\n    def __init__(self, stream: \"StreamReader\") -> None:\n        self._stream = stream\n\n    def __aiter__(self) -> \"ChunkTupleAsyncStreamIterator\":\n        return self\n\n    async def __anext__(self) -> Tuple[bytes, bool]:\n        rv = await self._stream.readchunk()\n        if rv == (b\"\", False):\n            raise StopAsyncIteration\n        return rv\n\n\nclass AsyncStreamReaderMixin:\n    def __aiter__(self) -> AsyncStreamIterator[bytes]:\n        return AsyncStreamIterator(self.readline)  # type: ignore[attr-defined]\n\n    def iter_chunked(self, n: int) -> AsyncStreamIterator[bytes]:\n        \"\"\"Returns an asynchronous iterator that yields chunks of size n.\"\"\"\n        return AsyncStreamIterator(lambda: self.read(n))  # type: ignore[attr-defined]\n\n    def iter_any(self) -> AsyncStreamIterator[bytes]:\n        \"\"\"Yield all available data as soon as it is received.\"\"\"\n        return AsyncStreamIterator(self.readany)  # type: ignore[attr-defined]\n\n    def iter_chunks(self) -> ChunkTupleAsyncStreamIterator:\n        \"\"\"Yield chunks of data as they are received by the server.\n\n        The yielded objects are tuples\n        of (bytes, bool) as returned by the StreamReader.readchunk method.\n        \"\"\"\n        return ChunkTupleAsyncStreamIterator(self)  # type: ignore[arg-type]\n\n\nclass StreamReader(AsyncStreamReaderMixin):\n    \"\"\"An enhancement of asyncio.StreamReader.\n\n    Supports asynchronous iteration by line, chunk or as available::\n\n        async for line in reader:\n            ...\n        async for chunk in reader.iter_chunked(1024):\n            ...\n        async for slice in reader.iter_any():\n            ...\n\n    \"\"\"\n\n    total_bytes = 0\n\n    def __init__(\n        self,\n        protocol: BaseProtocol,\n        limit: int,\n        *,\n        timer: Optional[BaseTimerContext] = None,\n        loop: asyncio.AbstractEventLoop,\n    ) -> None:\n        self._protocol = protocol\n        self._low_water = limit\n        self._high_water = limit * 2\n        if loop is None:\n            loop = asyncio.get_event_loop()\n        self._loop = loop\n        self._size = 0\n        self._cursor = 0\n        self._http_chunk_splits: Optional[List[int]] = None\n        self._buffer: Deque[bytes] = collections.deque()\n        self._buffer_offset = 0\n        self._eof = False\n        self._waiter: Optional[asyncio.Future[None]] = None\n        self._eof_waiter: Optional[asyncio.Future[None]] = None\n        self._exception: Optional[BaseException] = None\n        self._timer = TimerNoop() if timer is None else timer\n        self._eof_callbacks: List[Callable[[], None]] = []\n\n    def __repr__(self) -> str:\n        info = [self.__class__.__name__]\n        if self._size:\n            info.append(\"%d bytes\" % self._size)\n        if self._eof:\n            info.append(\"eof\")\n        if self._low_water != 2**16:  # default limit\n            info.append(\"low=%d high=%d\" % (self._low_water, self._high_water))\n        if self._waiter:\n            info.append(\"w=%r\" % self._waiter)\n        if self._exception:\n            info.append(\"e=%r\" % self._exception)\n        return \"<%s>\" % \" \".join(info)\n\n    def get_read_buffer_limits(self) -> Tuple[int, int]:\n        return (self._low_water, self._high_water)\n\n    def exception(self) -> Optional[BaseException]:\n        return self._exception\n\n    def set_exception(\n        self,\n        exc: BaseException,\n        exc_cause: BaseException = _EXC_SENTINEL,\n    ) -> None:\n        self._exception = exc\n        self._eof_callbacks.clear()\n\n        waiter = self._waiter\n        if waiter is not None:\n            self._waiter = None\n            set_exception(waiter, exc, exc_cause)\n\n        waiter = self._eof_waiter\n        if waiter is not None:\n            self._eof_waiter = None\n            set_exception(waiter, exc, exc_cause)\n\n    def on_eof(self, callback: Callable[[], None]) -> None:\n        if self._eof:\n            try:\n                callback()\n            except Exception:\n                internal_logger.exception(\"Exception in eof callback\")\n        else:\n            self._eof_callbacks.append(callback)\n\n    def feed_eof(self) -> None:\n        self._eof = True\n\n        waiter = self._waiter\n        if waiter is not None:\n            self._waiter = None\n            set_result(waiter, None)\n\n        waiter = self._eof_waiter\n        if waiter is not None:\n            self._eof_waiter = None\n            set_result(waiter, None)\n\n        for cb in self._eof_callbacks:\n            try:\n                cb()\n            except Exception:\n                internal_logger.exception(\"Exception in eof callback\")\n\n        self._eof_callbacks.clear()\n\n    def is_eof(self) -> bool:\n        \"\"\"Return True if  'feed_eof' was called.\"\"\"\n        return self._eof\n\n    def at_eof(self) -> bool:\n        \"\"\"Return True if the buffer is empty and 'feed_eof' was called.\"\"\"\n        return self._eof and not self._buffer\n\n    async def wait_eof(self) -> None:\n        if self._eof:\n            return\n\n        assert self._eof_waiter is None\n        self._eof_waiter = self._loop.create_future()\n        try:\n            await self._eof_waiter\n        finally:\n            self._eof_waiter = None\n\n    def unread_data(self, data: bytes) -> None:\n        \"\"\"rollback reading some data from stream, inserting it to buffer head.\"\"\"\n        warnings.warn(\n            \"unread_data() is deprecated \"\n            \"and will be removed in future releases (#3260)\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        if not data:\n            return\n\n        if self._buffer_offset:\n            self._buffer[0] = self._buffer[0][self._buffer_offset :]\n            self._buffer_offset = 0\n        self._size += len(data)\n        self._cursor -= len(data)\n        self._buffer.appendleft(data)\n        self._eof_counter = 0\n\n    def feed_data(self, data: bytes) -> None:\n        assert not self._eof, \"feed_data after feed_eof\"\n\n        if not data:\n            return\n\n        self._size += len(data)\n        self._buffer.append(data)\n        self.total_bytes += len(data)\n\n        waiter = self._waiter\n        if waiter is not None:\n            self._waiter = None\n            set_result(waiter, None)\n\n        if self._size > self._high_water and not self._protocol._reading_paused:\n            self._protocol.pause_reading()\n\n    def begin_http_chunk_receiving(self) -> None:\n        if self._http_chunk_splits is None:\n            if self.total_bytes:\n                raise RuntimeError(\n                    \"Called begin_http_chunk_receiving when\" \"some data was already fed\"\n                )\n            self._http_chunk_splits = []\n\n    def end_http_chunk_receiving(self) -> None:\n        if self._http_chunk_splits is None:\n            raise RuntimeError(\n                \"Called end_chunk_receiving without calling \"\n                \"begin_chunk_receiving first\"\n            )\n\n        # self._http_chunk_splits contains logical byte offsets from start of\n        # the body transfer. Each offset is the offset of the end of a chunk.\n        # \"Logical\" means bytes, accessible for a user.\n        # If no chunks containing logical data were received, current position\n        # is difinitely zero.\n        pos = self._http_chunk_splits[-1] if self._http_chunk_splits else 0\n\n        if self.total_bytes == pos:\n            # We should not add empty chunks here. So we check for that.\n            # Note, when chunked + gzip is used, we can receive a chunk\n            # of compressed data, but that data may not be enough for gzip FSM\n            # to yield any uncompressed data. That's why current position may\n            # not change after receiving a chunk.\n            return\n\n        self._http_chunk_splits.append(self.total_bytes)\n\n        # wake up readchunk when end of http chunk received\n        waiter = self._waiter\n        if waiter is not None:\n            self._waiter = None\n            set_result(waiter, None)\n\n    async def _wait(self, func_name: str) -> None:\n        # StreamReader uses a future to link the protocol feed_data() method\n        # to a read coroutine. Running two read coroutines at the same time\n        # would have an unexpected behaviour. It would not possible to know\n        # which coroutine would get the next data.\n        if self._waiter is not None:\n            raise RuntimeError(\n                \"%s() called while another coroutine is \"\n                \"already waiting for incoming data\" % func_name\n            )\n\n        waiter = self._waiter = self._loop.create_future()\n        try:\n            with self._timer:\n                await waiter\n        finally:\n            self._waiter = None\n\n    async def readline(self) -> bytes:\n        return await self.readuntil()\n\n    async def readuntil(self, separator: bytes = b\"\\n\") -> bytes:\n        seplen = len(separator)\n        if seplen == 0:\n            raise ValueError(\"Separator should be at least one-byte string\")\n\n        if self._exception is not None:\n            raise self._exception\n\n        chunk = b\"\"\n        chunk_size = 0\n        not_enough = True\n\n        while not_enough:\n            while self._buffer and not_enough:\n                offset = self._buffer_offset\n                ichar = self._buffer[0].find(separator, offset) + 1\n                # Read from current offset to found separator or to the end.\n                data = self._read_nowait_chunk(\n                    ichar - offset + seplen - 1 if ichar else -1\n                )\n                chunk += data\n                chunk_size += len(data)\n                if ichar:\n                    not_enough = False\n\n                if chunk_size > self._high_water:\n                    raise ValueError(\"Chunk too big\")\n\n            if self._eof:\n                break\n\n            if not_enough:\n                await self._wait(\"readuntil\")\n\n        return chunk\n\n    async def read(self, n: int = -1) -> bytes:\n        if self._exception is not None:\n            raise self._exception\n\n        if not n:\n            return b\"\"\n\n        if n < 0:\n            # This used to just loop creating a new waiter hoping to\n            # collect everything in self._buffer, but that would\n            # deadlock if the subprocess sends more than self.limit\n            # bytes.  So just call self.readany() until EOF.\n            blocks = []\n            while True:\n                block = await self.readany()\n                if not block:\n                    break\n                blocks.append(block)\n            return b\"\".join(blocks)\n\n        # TODO: should be `if` instead of `while`\n        # because waiter maybe triggered on chunk end,\n        # without feeding any data\n        while not self._buffer and not self._eof:\n            await self._wait(\"read\")\n\n        return self._read_nowait(n)\n\n    async def readany(self) -> bytes:\n        if self._exception is not None:\n            raise self._exception\n\n        # TODO: should be `if` instead of `while`\n        # because waiter maybe triggered on chunk end,\n        # without feeding any data\n        while not self._buffer and not self._eof:\n            await self._wait(\"readany\")\n\n        return self._read_nowait(-1)\n\n    async def readchunk(self) -> Tuple[bytes, bool]:\n        \"\"\"Returns a tuple of (data, end_of_http_chunk).\n\n        When chunked transfer\n        encoding is used, end_of_http_chunk is a boolean indicating if the end\n        of the data corresponds to the end of a HTTP chunk , otherwise it is\n        always False.\n        \"\"\"\n        while True:\n            if self._exception is not None:\n                raise self._exception\n\n            while self._http_chunk_splits:\n                pos = self._http_chunk_splits.pop(0)\n                if pos == self._cursor:\n                    return (b\"\", True)\n                if pos > self._cursor:\n                    return (self._read_nowait(pos - self._cursor), True)\n                internal_logger.warning(\n                    \"Skipping HTTP chunk end due to data \"\n                    \"consumption beyond chunk boundary\"\n                )\n\n            if self._buffer:\n                return (self._read_nowait_chunk(-1), False)\n                # return (self._read_nowait(-1), False)\n\n            if self._eof:\n                # Special case for signifying EOF.\n                # (b'', True) is not a final return value actually.\n                return (b\"\", False)\n\n            await self._wait(\"readchunk\")\n\n    async def readexactly(self, n: int) -> bytes:\n        if self._exception is not None:\n            raise self._exception\n\n        blocks: List[bytes] = []\n        while n > 0:\n            block = await self.read(n)\n            if not block:\n                partial = b\"\".join(blocks)\n                raise asyncio.IncompleteReadError(partial, len(partial) + n)\n            blocks.append(block)\n            n -= len(block)\n\n        return b\"\".join(blocks)\n\n    def read_nowait(self, n: int = -1) -> bytes:\n        # default was changed to be consistent with .read(-1)\n        #\n        # I believe the most users don't know about the method and\n        # they are not affected.\n        if self._exception is not None:\n            raise self._exception\n\n        if self._waiter and not self._waiter.done():\n            raise RuntimeError(\n                \"Called while some coroutine is waiting for incoming data.\"\n            )\n\n        return self._read_nowait(n)\n\n    def _read_nowait_chunk(self, n: int) -> bytes:\n        first_buffer = self._buffer[0]\n        offset = self._buffer_offset\n        if n != -1 and len(first_buffer) - offset > n:\n            data = first_buffer[offset : offset + n]\n            self._buffer_offset += n\n\n        elif offset:\n            self._buffer.popleft()\n            data = first_buffer[offset:]\n            self._buffer_offset = 0\n\n        else:\n            data = self._buffer.popleft()\n\n        self._size -= len(data)\n        self._cursor += len(data)\n\n        chunk_splits = self._http_chunk_splits\n        # Prevent memory leak: drop useless chunk splits\n        while chunk_splits and chunk_splits[0] < self._cursor:\n            chunk_splits.pop(0)\n\n        if self._size < self._low_water and self._protocol._reading_paused:\n            self._protocol.resume_reading()\n        return data\n\n    def _read_nowait(self, n: int) -> bytes:\n        \"\"\"Read not more than n bytes, or whole buffer if n == -1\"\"\"\n        self._timer.assert_timeout()\n\n        chunks = []\n        while self._buffer:\n            chunk = self._read_nowait_chunk(n)\n            chunks.append(chunk)\n            if n != -1:\n                n -= len(chunk)\n                if n == 0:\n                    break\n\n        return b\"\".join(chunks) if chunks else b\"\"\n\n\nclass EmptyStreamReader(StreamReader):  # lgtm [py/missing-call-to-init]\n    def __init__(self) -> None:\n        self._read_eof_chunk = False\n\n    def __repr__(self) -> str:\n        return \"<%s>\" % self.__class__.__name__\n\n    def exception(self) -> Optional[BaseException]:\n        return None\n\n    def set_exception(\n        self,\n        exc: BaseException,\n        exc_cause: BaseException = _EXC_SENTINEL,\n    ) -> None:\n        pass\n\n    def on_eof(self, callback: Callable[[], None]) -> None:\n        try:\n            callback()\n        except Exception:\n            internal_logger.exception(\"Exception in eof callback\")\n\n    def feed_eof(self) -> None:\n        pass\n\n    def is_eof(self) -> bool:\n        return True\n\n    def at_eof(self) -> bool:\n        return True\n\n    async def wait_eof(self) -> None:\n        return\n\n    def feed_data(self, data: bytes) -> None:\n        pass\n\n    async def readline(self) -> bytes:\n        return b\"\"\n\n    async def read(self, n: int = -1) -> bytes:\n        return b\"\"\n\n    # TODO add async def readuntil\n\n    async def readany(self) -> bytes:\n        return b\"\"\n\n    async def readchunk(self) -> Tuple[bytes, bool]:\n        if not self._read_eof_chunk:\n            self._read_eof_chunk = True\n            return (b\"\", False)\n\n        return (b\"\", True)\n\n    async def readexactly(self, n: int) -> bytes:\n        raise asyncio.IncompleteReadError(b\"\", n)\n\n    def read_nowait(self, n: int = -1) -> bytes:\n        return b\"\"\n\n\nEMPTY_PAYLOAD: Final[StreamReader] = EmptyStreamReader()\n\n\nclass DataQueue(Generic[_SizedT]):\n    \"\"\"DataQueue is a general-purpose blocking queue with one reader.\"\"\"\n\n    def __init__(self, loop: asyncio.AbstractEventLoop) -> None:\n        self._loop = loop\n        self._eof = False\n        self._waiter: Optional[asyncio.Future[None]] = None\n        self._exception: Optional[BaseException] = None\n        self._size = 0\n        self._buffer: Deque[_SizedT] = collections.deque()\n\n    def __len__(self) -> int:\n        return len(self._buffer)\n\n    def is_eof(self) -> bool:\n        return self._eof\n\n    def at_eof(self) -> bool:\n        return self._eof and not self._buffer\n\n    def exception(self) -> Optional[BaseException]:\n        return self._exception\n\n    def set_exception(\n        self,\n        exc: BaseException,\n        exc_cause: BaseException = _EXC_SENTINEL,\n    ) -> None:\n        self._eof = True\n        self._exception = exc\n\n        waiter = self._waiter\n        if waiter is not None:\n            self._waiter = None\n            set_exception(waiter, exc, exc_cause)\n\n    def feed_data(self, data: _SizedT) -> None:\n        self._size += len(data)\n        self._buffer.append(data)\n\n        waiter = self._waiter\n        if waiter is not None:\n            self._waiter = None\n            set_result(waiter, None)\n\n    def feed_eof(self) -> None:\n        self._eof = True\n\n        waiter = self._waiter\n        if waiter is not None:\n            self._waiter = None\n            set_result(waiter, None)\n\n    async def read(self) -> _SizedT:\n        if not self._buffer and not self._eof:\n            assert not self._waiter\n            self._waiter = self._loop.create_future()\n            try:\n                await self._waiter\n            except (asyncio.CancelledError, asyncio.TimeoutError):\n                self._waiter = None\n                raise\n\n        if self._buffer:\n            data = self._buffer.popleft()\n            self._size -= len(data)\n            return data\n        else:\n            if self._exception is not None:\n                raise self._exception\n            else:\n                raise EofStream\n\n    def __aiter__(self) -> AsyncStreamIterator[_SizedT]:\n        return AsyncStreamIterator(self.read)\n\n\nclass FlowControlDataQueue(DataQueue[_SizedT]):\n    \"\"\"FlowControlDataQueue resumes and pauses an underlying stream.\n\n    It is a destination for parsed data.\n    \"\"\"\n\n    def __init__(\n        self, protocol: BaseProtocol, limit: int, *, loop: asyncio.AbstractEventLoop\n    ) -> None:\n        super().__init__(loop=loop)\n\n        self._protocol = protocol\n        self._limit = limit * 2\n\n    def feed_data(self, data: _SizedT) -> None:\n        super().feed_data(data)\n\n        if self._size > self._limit and not self._protocol._reading_paused:\n            self._protocol.pause_reading()\n\n    async def read(self) -> _SizedT:\n        try:\n            return await super().read()\n        finally:\n            if self._size < self._limit and self._protocol._reading_paused:\n                self._protocol.resume_reading()\n", "aiohttp/payload.py": "import asyncio\nimport enum\nimport io\nimport json\nimport mimetypes\nimport os\nimport warnings\nfrom abc import ABC, abstractmethod\nfrom itertools import chain\nfrom typing import (\n    IO,\n    TYPE_CHECKING,\n    Any,\n    Dict,\n    Final,\n    Iterable,\n    Optional,\n    TextIO,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom multidict import CIMultiDict\n\nfrom . import hdrs\nfrom .abc import AbstractStreamWriter\nfrom .helpers import (\n    _SENTINEL,\n    content_disposition_header,\n    guess_filename,\n    parse_mimetype,\n    sentinel,\n)\nfrom .streams import StreamReader\nfrom .typedefs import JSONEncoder, _CIMultiDict\n\n__all__ = (\n    \"PAYLOAD_REGISTRY\",\n    \"get_payload\",\n    \"payload_type\",\n    \"Payload\",\n    \"BytesPayload\",\n    \"StringPayload\",\n    \"IOBasePayload\",\n    \"BytesIOPayload\",\n    \"BufferedReaderPayload\",\n    \"TextIOPayload\",\n    \"StringIOPayload\",\n    \"JsonPayload\",\n    \"AsyncIterablePayload\",\n)\n\nTOO_LARGE_BYTES_BODY: Final[int] = 2**20  # 1 MB\n\nif TYPE_CHECKING:\n    from typing import List\n\n\nclass LookupError(Exception):\n    pass\n\n\nclass Order(str, enum.Enum):\n    normal = \"normal\"\n    try_first = \"try_first\"\n    try_last = \"try_last\"\n\n\ndef get_payload(data: Any, *args: Any, **kwargs: Any) -> \"Payload\":\n    return PAYLOAD_REGISTRY.get(data, *args, **kwargs)\n\n\ndef register_payload(\n    factory: Type[\"Payload\"], type: Any, *, order: Order = Order.normal\n) -> None:\n    PAYLOAD_REGISTRY.register(factory, type, order=order)\n\n\nclass payload_type:\n    def __init__(self, type: Any, *, order: Order = Order.normal) -> None:\n        self.type = type\n        self.order = order\n\n    def __call__(self, factory: Type[\"Payload\"]) -> Type[\"Payload\"]:\n        register_payload(factory, self.type, order=self.order)\n        return factory\n\n\nPayloadType = Type[\"Payload\"]\n_PayloadRegistryItem = Tuple[PayloadType, Any]\n\n\nclass PayloadRegistry:\n    \"\"\"Payload registry.\n\n    note: we need zope.interface for more efficient adapter search\n    \"\"\"\n\n    def __init__(self) -> None:\n        self._first: List[_PayloadRegistryItem] = []\n        self._normal: List[_PayloadRegistryItem] = []\n        self._last: List[_PayloadRegistryItem] = []\n\n    def get(\n        self,\n        data: Any,\n        *args: Any,\n        _CHAIN: \"Type[chain[_PayloadRegistryItem]]\" = chain,\n        **kwargs: Any,\n    ) -> \"Payload\":\n        if isinstance(data, Payload):\n            return data\n        for factory, type in _CHAIN(self._first, self._normal, self._last):\n            if isinstance(data, type):\n                return factory(data, *args, **kwargs)\n\n        raise LookupError()\n\n    def register(\n        self, factory: PayloadType, type: Any, *, order: Order = Order.normal\n    ) -> None:\n        if order is Order.try_first:\n            self._first.append((factory, type))\n        elif order is Order.normal:\n            self._normal.append((factory, type))\n        elif order is Order.try_last:\n            self._last.append((factory, type))\n        else:\n            raise ValueError(f\"Unsupported order {order!r}\")\n\n\nclass Payload(ABC):\n    _default_content_type: str = \"application/octet-stream\"\n    _size: Optional[int] = None\n\n    def __init__(\n        self,\n        value: Any,\n        headers: Optional[\n            Union[_CIMultiDict, Dict[str, str], Iterable[Tuple[str, str]]]\n        ] = None,\n        content_type: Union[None, str, _SENTINEL] = sentinel,\n        filename: Optional[str] = None,\n        encoding: Optional[str] = None,\n        **kwargs: Any,\n    ) -> None:\n        self._encoding = encoding\n        self._filename = filename\n        self._headers: _CIMultiDict = CIMultiDict()\n        self._value = value\n        if content_type is not sentinel and content_type is not None:\n            assert isinstance(content_type, str)\n            self._headers[hdrs.CONTENT_TYPE] = content_type\n        elif self._filename is not None:\n            content_type = mimetypes.guess_type(self._filename)[0]\n            if content_type is None:\n                content_type = self._default_content_type\n            self._headers[hdrs.CONTENT_TYPE] = content_type\n        else:\n            self._headers[hdrs.CONTENT_TYPE] = self._default_content_type\n        self._headers.update(headers or {})\n\n    @property\n    def size(self) -> Optional[int]:\n        \"\"\"Size of the payload.\"\"\"\n        return self._size\n\n    @property\n    def filename(self) -> Optional[str]:\n        \"\"\"Filename of the payload.\"\"\"\n        return self._filename\n\n    @property\n    def headers(self) -> _CIMultiDict:\n        \"\"\"Custom item headers\"\"\"\n        return self._headers\n\n    @property\n    def _binary_headers(self) -> bytes:\n        return (\n            \"\".join([k + \": \" + v + \"\\r\\n\" for k, v in self.headers.items()]).encode(\n                \"utf-8\"\n            )\n            + b\"\\r\\n\"\n        )\n\n    @property\n    def encoding(self) -> Optional[str]:\n        \"\"\"Payload encoding\"\"\"\n        return self._encoding\n\n    @property\n    def content_type(self) -> str:\n        \"\"\"Content type\"\"\"\n        return self._headers[hdrs.CONTENT_TYPE]\n\n    def set_content_disposition(\n        self,\n        disptype: str,\n        quote_fields: bool = True,\n        _charset: str = \"utf-8\",\n        **params: Any,\n    ) -> None:\n        \"\"\"Sets ``Content-Disposition`` header.\"\"\"\n        self._headers[hdrs.CONTENT_DISPOSITION] = content_disposition_header(\n            disptype, quote_fields=quote_fields, _charset=_charset, **params\n        )\n\n    @abstractmethod\n    async def write(self, writer: AbstractStreamWriter) -> None:\n        \"\"\"Write payload.\n\n        writer is an AbstractStreamWriter instance:\n        \"\"\"\n\n\nclass BytesPayload(Payload):\n    def __init__(\n        self, value: Union[bytes, bytearray, memoryview], *args: Any, **kwargs: Any\n    ) -> None:\n        if not isinstance(value, (bytes, bytearray, memoryview)):\n            raise TypeError(f\"value argument must be byte-ish, not {type(value)!r}\")\n\n        if \"content_type\" not in kwargs:\n            kwargs[\"content_type\"] = \"application/octet-stream\"\n\n        super().__init__(value, *args, **kwargs)\n\n        if isinstance(value, memoryview):\n            self._size = value.nbytes\n        else:\n            self._size = len(value)\n\n        if self._size > TOO_LARGE_BYTES_BODY:\n            warnings.warn(\n                \"Sending a large body directly with raw bytes might\"\n                \" lock the event loop. You should probably pass an \"\n                \"io.BytesIO object instead\",\n                ResourceWarning,\n                source=self,\n            )\n\n    async def write(self, writer: AbstractStreamWriter) -> None:\n        await writer.write(self._value)\n\n\nclass StringPayload(BytesPayload):\n    def __init__(\n        self,\n        value: str,\n        *args: Any,\n        encoding: Optional[str] = None,\n        content_type: Optional[str] = None,\n        **kwargs: Any,\n    ) -> None:\n        if encoding is None:\n            if content_type is None:\n                real_encoding = \"utf-8\"\n                content_type = \"text/plain; charset=utf-8\"\n            else:\n                mimetype = parse_mimetype(content_type)\n                real_encoding = mimetype.parameters.get(\"charset\", \"utf-8\")\n        else:\n            if content_type is None:\n                content_type = \"text/plain; charset=%s\" % encoding\n            real_encoding = encoding\n\n        super().__init__(\n            value.encode(real_encoding),\n            encoding=real_encoding,\n            content_type=content_type,\n            *args,\n            **kwargs,\n        )\n\n\nclass StringIOPayload(StringPayload):\n    def __init__(self, value: IO[str], *args: Any, **kwargs: Any) -> None:\n        super().__init__(value.read(), *args, **kwargs)\n\n\nclass IOBasePayload(Payload):\n    _value: IO[Any]\n\n    def __init__(\n        self, value: IO[Any], disposition: str = \"attachment\", *args: Any, **kwargs: Any\n    ) -> None:\n        if \"filename\" not in kwargs:\n            kwargs[\"filename\"] = guess_filename(value)\n\n        super().__init__(value, *args, **kwargs)\n\n        if self._filename is not None and disposition is not None:\n            if hdrs.CONTENT_DISPOSITION not in self.headers:\n                self.set_content_disposition(disposition, filename=self._filename)\n\n    async def write(self, writer: AbstractStreamWriter) -> None:\n        loop = asyncio.get_event_loop()\n        try:\n            chunk = await loop.run_in_executor(None, self._value.read, 2**16)\n            while chunk:\n                await writer.write(chunk)\n                chunk = await loop.run_in_executor(None, self._value.read, 2**16)\n        finally:\n            await loop.run_in_executor(None, self._value.close)\n\n\nclass TextIOPayload(IOBasePayload):\n    _value: TextIO\n\n    def __init__(\n        self,\n        value: TextIO,\n        *args: Any,\n        encoding: Optional[str] = None,\n        content_type: Optional[str] = None,\n        **kwargs: Any,\n    ) -> None:\n        if encoding is None:\n            if content_type is None:\n                encoding = \"utf-8\"\n                content_type = \"text/plain; charset=utf-8\"\n            else:\n                mimetype = parse_mimetype(content_type)\n                encoding = mimetype.parameters.get(\"charset\", \"utf-8\")\n        else:\n            if content_type is None:\n                content_type = \"text/plain; charset=%s\" % encoding\n\n        super().__init__(\n            value,\n            content_type=content_type,\n            encoding=encoding,\n            *args,\n            **kwargs,\n        )\n\n    @property\n    def size(self) -> Optional[int]:\n        try:\n            return os.fstat(self._value.fileno()).st_size - self._value.tell()\n        except OSError:\n            return None\n\n    async def write(self, writer: AbstractStreamWriter) -> None:\n        loop = asyncio.get_event_loop()\n        try:\n            chunk = await loop.run_in_executor(None, self._value.read, 2**16)\n            while chunk:\n                data = (\n                    chunk.encode(encoding=self._encoding)\n                    if self._encoding\n                    else chunk.encode()\n                )\n                await writer.write(data)\n                chunk = await loop.run_in_executor(None, self._value.read, 2**16)\n        finally:\n            await loop.run_in_executor(None, self._value.close)\n\n\nclass BytesIOPayload(IOBasePayload):\n    @property\n    def size(self) -> int:\n        position = self._value.tell()\n        end = self._value.seek(0, os.SEEK_END)\n        self._value.seek(position)\n        return end - position\n\n\nclass BufferedReaderPayload(IOBasePayload):\n    @property\n    def size(self) -> Optional[int]:\n        try:\n            return os.fstat(self._value.fileno()).st_size - self._value.tell()\n        except OSError:\n            # data.fileno() is not supported, e.g.\n            # io.BufferedReader(io.BytesIO(b'data'))\n            return None\n\n\nclass JsonPayload(BytesPayload):\n    def __init__(\n        self,\n        value: Any,\n        encoding: str = \"utf-8\",\n        content_type: str = \"application/json\",\n        dumps: JSONEncoder = json.dumps,\n        *args: Any,\n        **kwargs: Any,\n    ) -> None:\n        super().__init__(\n            dumps(value).encode(encoding),\n            content_type=content_type,\n            encoding=encoding,\n            *args,\n            **kwargs,\n        )\n\n\nif TYPE_CHECKING:\n    from typing import AsyncIterable, AsyncIterator\n\n    _AsyncIterator = AsyncIterator[bytes]\n    _AsyncIterable = AsyncIterable[bytes]\nelse:\n    from collections.abc import AsyncIterable, AsyncIterator\n\n    _AsyncIterator = AsyncIterator\n    _AsyncIterable = AsyncIterable\n\n\nclass AsyncIterablePayload(Payload):\n    _iter: Optional[_AsyncIterator] = None\n\n    def __init__(self, value: _AsyncIterable, *args: Any, **kwargs: Any) -> None:\n        if not isinstance(value, AsyncIterable):\n            raise TypeError(\n                \"value argument must support \"\n                \"collections.abc.AsyncIterable interface, \"\n                \"got {!r}\".format(type(value))\n            )\n\n        if \"content_type\" not in kwargs:\n            kwargs[\"content_type\"] = \"application/octet-stream\"\n\n        super().__init__(value, *args, **kwargs)\n\n        self._iter = value.__aiter__()\n\n    async def write(self, writer: AbstractStreamWriter) -> None:\n        if self._iter:\n            try:\n                # iter is not None check prevents rare cases\n                # when the case iterable is used twice\n                while True:\n                    chunk = await self._iter.__anext__()\n                    await writer.write(chunk)\n            except StopAsyncIteration:\n                self._iter = None\n\n\nclass StreamReaderPayload(AsyncIterablePayload):\n    def __init__(self, value: StreamReader, *args: Any, **kwargs: Any) -> None:\n        super().__init__(value.iter_any(), *args, **kwargs)\n\n\nPAYLOAD_REGISTRY = PayloadRegistry()\nPAYLOAD_REGISTRY.register(BytesPayload, (bytes, bytearray, memoryview))\nPAYLOAD_REGISTRY.register(StringPayload, str)\nPAYLOAD_REGISTRY.register(StringIOPayload, io.StringIO)\nPAYLOAD_REGISTRY.register(TextIOPayload, io.TextIOBase)\nPAYLOAD_REGISTRY.register(BytesIOPayload, io.BytesIO)\nPAYLOAD_REGISTRY.register(BufferedReaderPayload, (io.BufferedReader, io.BufferedRandom))\nPAYLOAD_REGISTRY.register(IOBasePayload, io.IOBase)\nPAYLOAD_REGISTRY.register(StreamReaderPayload, StreamReader)\n# try_last for giving a chance to more specialized async interables like\n# multidict.BodyPartReaderPayload override the default\nPAYLOAD_REGISTRY.register(AsyncIterablePayload, AsyncIterable, order=Order.try_last)\n", "aiohttp/abc.py": "import logging\nimport socket\nfrom abc import ABC, abstractmethod\nfrom collections.abc import Sized\nfrom http.cookies import BaseCookie, Morsel\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Awaitable,\n    Callable,\n    Dict,\n    Generator,\n    Iterable,\n    List,\n    Optional,\n    Tuple,\n    TypedDict,\n)\n\nfrom multidict import CIMultiDict\nfrom yarl import URL\n\nfrom .typedefs import LooseCookies\n\nif TYPE_CHECKING:\n    from .web_app import Application\n    from .web_exceptions import HTTPException\n    from .web_request import BaseRequest, Request\n    from .web_response import StreamResponse\nelse:\n    BaseRequest = Request = Application = StreamResponse = None\n    HTTPException = None\n\n\nclass AbstractRouter(ABC):\n    def __init__(self) -> None:\n        self._frozen = False\n\n    def post_init(self, app: Application) -> None:\n        \"\"\"Post init stage.\n\n        Not an abstract method for sake of backward compatibility,\n        but if the router wants to be aware of the application\n        it can override this.\n        \"\"\"\n\n    @property\n    def frozen(self) -> bool:\n        return self._frozen\n\n    def freeze(self) -> None:\n        \"\"\"Freeze router.\"\"\"\n        self._frozen = True\n\n    @abstractmethod\n    async def resolve(self, request: Request) -> \"AbstractMatchInfo\":\n        \"\"\"Return MATCH_INFO for given request\"\"\"\n\n\nclass AbstractMatchInfo(ABC):\n    @property  # pragma: no branch\n    @abstractmethod\n    def handler(self) -> Callable[[Request], Awaitable[StreamResponse]]:\n        \"\"\"Execute matched request handler\"\"\"\n\n    @property\n    @abstractmethod\n    def expect_handler(\n        self,\n    ) -> Callable[[Request], Awaitable[Optional[StreamResponse]]]:\n        \"\"\"Expect handler for 100-continue processing\"\"\"\n\n    @property  # pragma: no branch\n    @abstractmethod\n    def http_exception(self) -> Optional[HTTPException]:\n        \"\"\"HTTPException instance raised on router's resolving, or None\"\"\"\n\n    @abstractmethod  # pragma: no branch\n    def get_info(self) -> Dict[str, Any]:\n        \"\"\"Return a dict with additional info useful for introspection\"\"\"\n\n    @property  # pragma: no branch\n    @abstractmethod\n    def apps(self) -> Tuple[Application, ...]:\n        \"\"\"Stack of nested applications.\n\n        Top level application is left-most element.\n\n        \"\"\"\n\n    @abstractmethod\n    def add_app(self, app: Application) -> None:\n        \"\"\"Add application to the nested apps stack.\"\"\"\n\n    @abstractmethod\n    def freeze(self) -> None:\n        \"\"\"Freeze the match info.\n\n        The method is called after route resolution.\n\n        After the call .add_app() is forbidden.\n\n        \"\"\"\n\n\nclass AbstractView(ABC):\n    \"\"\"Abstract class based view.\"\"\"\n\n    def __init__(self, request: Request) -> None:\n        self._request = request\n\n    @property\n    def request(self) -> Request:\n        \"\"\"Request instance.\"\"\"\n        return self._request\n\n    @abstractmethod\n    def __await__(self) -> Generator[Any, None, StreamResponse]:\n        \"\"\"Execute the view handler.\"\"\"\n\n\nclass ResolveResult(TypedDict):\n    \"\"\"Resolve result.\n\n    This is the result returned from an AbstractResolver's\n    resolve method.\n\n    :param hostname: The hostname that was provided.\n    :param host: The IP address that was resolved.\n    :param port: The port that was resolved.\n    :param family: The address family that was resolved.\n    :param proto: The protocol that was resolved.\n    :param flags: The flags that were resolved.\n    \"\"\"\n\n    hostname: str\n    host: str\n    port: int\n    family: int\n    proto: int\n    flags: int\n\n\nclass AbstractResolver(ABC):\n    \"\"\"Abstract DNS resolver.\"\"\"\n\n    @abstractmethod\n    async def resolve(\n        self, host: str, port: int = 0, family: socket.AddressFamily = socket.AF_INET\n    ) -> List[ResolveResult]:\n        \"\"\"Return IP address for given hostname\"\"\"\n\n    @abstractmethod\n    async def close(self) -> None:\n        \"\"\"Release resolver\"\"\"\n\n\nif TYPE_CHECKING:\n    IterableBase = Iterable[Morsel[str]]\nelse:\n    IterableBase = Iterable\n\n\nClearCookiePredicate = Callable[[\"Morsel[str]\"], bool]\n\n\nclass AbstractCookieJar(Sized, IterableBase):\n    \"\"\"Abstract Cookie Jar.\"\"\"\n\n    @abstractmethod\n    def clear(self, predicate: Optional[ClearCookiePredicate] = None) -> None:\n        \"\"\"Clear all cookies if no predicate is passed.\"\"\"\n\n    @abstractmethod\n    def clear_domain(self, domain: str) -> None:\n        \"\"\"Clear all cookies for domain and all subdomains.\"\"\"\n\n    @abstractmethod\n    def update_cookies(self, cookies: LooseCookies, response_url: URL = URL()) -> None:\n        \"\"\"Update cookies.\"\"\"\n\n    @abstractmethod\n    def filter_cookies(self, request_url: URL) -> \"BaseCookie[str]\":\n        \"\"\"Return the jar's cookies filtered by their attributes.\"\"\"\n\n\nclass AbstractStreamWriter(ABC):\n    \"\"\"Abstract stream writer.\"\"\"\n\n    buffer_size = 0\n    output_size = 0\n    length: Optional[int] = 0\n\n    @abstractmethod\n    async def write(self, chunk: bytes) -> None:\n        \"\"\"Write chunk into stream.\"\"\"\n\n    @abstractmethod\n    async def write_eof(self, chunk: bytes = b\"\") -> None:\n        \"\"\"Write last chunk.\"\"\"\n\n    @abstractmethod\n    async def drain(self) -> None:\n        \"\"\"Flush the write buffer.\"\"\"\n\n    @abstractmethod\n    def enable_compression(self, encoding: str = \"deflate\") -> None:\n        \"\"\"Enable HTTP body compression\"\"\"\n\n    @abstractmethod\n    def enable_chunking(self) -> None:\n        \"\"\"Enable HTTP chunked mode\"\"\"\n\n    @abstractmethod\n    async def write_headers(\n        self, status_line: str, headers: \"CIMultiDict[str]\"\n    ) -> None:\n        \"\"\"Write HTTP headers\"\"\"\n\n\nclass AbstractAccessLogger(ABC):\n    \"\"\"Abstract writer to access log.\"\"\"\n\n    def __init__(self, logger: logging.Logger, log_format: str) -> None:\n        self.logger = logger\n        self.log_format = log_format\n\n    @abstractmethod\n    def log(self, request: BaseRequest, response: StreamResponse, time: float) -> None:\n        \"\"\"Emit log to logger.\"\"\"\n\n\nclass AbstractAsyncAccessLogger(ABC):\n    \"\"\"Abstract asynchronous writer to access log.\"\"\"\n\n    @abstractmethod\n    async def log(\n        self, request: BaseRequest, response: StreamResponse, request_start: float\n    ) -> None:\n        \"\"\"Emit log to logger.\"\"\"\n", "aiohttp/helpers.py": "\"\"\"Various helper functions\"\"\"\n\nimport asyncio\nimport base64\nimport binascii\nimport contextlib\nimport dataclasses\nimport datetime\nimport enum\nimport functools\nimport inspect\nimport netrc\nimport os\nimport platform\nimport re\nimport sys\nimport time\nimport warnings\nimport weakref\nfrom collections import namedtuple\nfrom contextlib import suppress\nfrom email.parser import HeaderParser\nfrom email.utils import parsedate\nfrom http.cookies import SimpleCookie\nfrom math import ceil\nfrom pathlib import Path\nfrom types import TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    ContextManager,\n    Dict,\n    Generator,\n    Generic,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    Optional,\n    Pattern,\n    Protocol,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    final,\n    get_args,\n    overload,\n)\nfrom urllib.parse import quote\nfrom urllib.request import getproxies, proxy_bypass\n\nfrom multidict import CIMultiDict, MultiDict, MultiDictProxy\nfrom yarl import URL\n\nfrom . import hdrs\nfrom .log import client_logger\nfrom .typedefs import PathLike  # noqa\n\nif sys.version_info >= (3, 11):\n    import asyncio as async_timeout\nelse:\n    import async_timeout\n\n__all__ = (\"BasicAuth\", \"ChainMapProxy\", \"ETag\")\n\nPY_310 = sys.version_info >= (3, 10)\n\nCOOKIE_MAX_LENGTH = 4096\n\n_T = TypeVar(\"_T\")\n_S = TypeVar(\"_S\")\n\n_SENTINEL = enum.Enum(\"_SENTINEL\", \"sentinel\")\nsentinel = _SENTINEL.sentinel\n\nNO_EXTENSIONS = bool(os.environ.get(\"AIOHTTP_NO_EXTENSIONS\"))\n\nDEBUG = sys.flags.dev_mode or (\n    not sys.flags.ignore_environment and bool(os.environ.get(\"PYTHONASYNCIODEBUG\"))\n)\n\n\nCHAR = {chr(i) for i in range(0, 128)}\nCTL = {chr(i) for i in range(0, 32)} | {\n    chr(127),\n}\nSEPARATORS = {\n    \"(\",\n    \")\",\n    \"<\",\n    \">\",\n    \"@\",\n    \",\",\n    \";\",\n    \":\",\n    \"\\\\\",\n    '\"',\n    \"/\",\n    \"[\",\n    \"]\",\n    \"?\",\n    \"=\",\n    \"{\",\n    \"}\",\n    \" \",\n    chr(9),\n}\nTOKEN = CHAR ^ CTL ^ SEPARATORS\n\n\nclass noop:\n    def __await__(self) -> Generator[None, None, None]:\n        yield\n\n\njson_re = re.compile(r\"(?:application/|[\\w.-]+/[\\w.+-]+?\\+)json$\", re.IGNORECASE)\n\n\nclass BasicAuth(namedtuple(\"BasicAuth\", [\"login\", \"password\", \"encoding\"])):\n    \"\"\"Http basic authentication helper.\"\"\"\n\n    def __new__(\n        cls, login: str, password: str = \"\", encoding: str = \"latin1\"\n    ) -> \"BasicAuth\":\n        if login is None:\n            raise ValueError(\"None is not allowed as login value\")\n\n        if password is None:\n            raise ValueError(\"None is not allowed as password value\")\n\n        if \":\" in login:\n            raise ValueError('A \":\" is not allowed in login (RFC 1945#section-11.1)')\n\n        return super().__new__(cls, login, password, encoding)\n\n    @classmethod\n    def decode(cls, auth_header: str, encoding: str = \"latin1\") -> \"BasicAuth\":\n        \"\"\"Create a BasicAuth object from an Authorization HTTP header.\"\"\"\n        try:\n            auth_type, encoded_credentials = auth_header.split(\" \", 1)\n        except ValueError:\n            raise ValueError(\"Could not parse authorization header.\")\n\n        if auth_type.lower() != \"basic\":\n            raise ValueError(\"Unknown authorization method %s\" % auth_type)\n\n        try:\n            decoded = base64.b64decode(\n                encoded_credentials.encode(\"ascii\"), validate=True\n            ).decode(encoding)\n        except binascii.Error:\n            raise ValueError(\"Invalid base64 encoding.\")\n\n        try:\n            # RFC 2617 HTTP Authentication\n            # https://www.ietf.org/rfc/rfc2617.txt\n            # the colon must be present, but the username and password may be\n            # otherwise blank.\n            username, password = decoded.split(\":\", 1)\n        except ValueError:\n            raise ValueError(\"Invalid credentials.\")\n\n        return cls(username, password, encoding=encoding)\n\n    @classmethod\n    def from_url(cls, url: URL, *, encoding: str = \"latin1\") -> Optional[\"BasicAuth\"]:\n        \"\"\"Create BasicAuth from url.\"\"\"\n        if not isinstance(url, URL):\n            raise TypeError(\"url should be yarl.URL instance\")\n        if url.user is None:\n            return None\n        return cls(url.user, url.password or \"\", encoding=encoding)\n\n    def encode(self) -> str:\n        \"\"\"Encode credentials.\"\"\"\n        creds = (f\"{self.login}:{self.password}\").encode(self.encoding)\n        return \"Basic %s\" % base64.b64encode(creds).decode(self.encoding)\n\n\ndef strip_auth_from_url(url: URL) -> Tuple[URL, Optional[BasicAuth]]:\n    auth = BasicAuth.from_url(url)\n    if auth is None:\n        return url, None\n    else:\n        return url.with_user(None), auth\n\n\ndef netrc_from_env() -> Optional[netrc.netrc]:\n    \"\"\"Load netrc from file.\n\n    Attempt to load it from the path specified by the env-var\n    NETRC or in the default location in the user's home directory.\n\n    Returns None if it couldn't be found or fails to parse.\n    \"\"\"\n    netrc_env = os.environ.get(\"NETRC\")\n\n    if netrc_env is not None:\n        netrc_path = Path(netrc_env)\n    else:\n        try:\n            home_dir = Path.home()\n        except RuntimeError as e:  # pragma: no cover\n            # if pathlib can't resolve home, it may raise a RuntimeError\n            client_logger.debug(\n                \"Could not resolve home directory when \"\n                \"trying to look for .netrc file: %s\",\n                e,\n            )\n            return None\n\n        netrc_path = home_dir / (\n            \"_netrc\" if platform.system() == \"Windows\" else \".netrc\"\n        )\n\n    try:\n        return netrc.netrc(str(netrc_path))\n    except netrc.NetrcParseError as e:\n        client_logger.warning(\"Could not parse .netrc file: %s\", e)\n    except OSError as e:\n        netrc_exists = False\n        with contextlib.suppress(OSError):\n            netrc_exists = netrc_path.is_file()\n        # we couldn't read the file (doesn't exist, permissions, etc.)\n        if netrc_env or netrc_exists:\n            # only warn if the environment wanted us to load it,\n            # or it appears like the default file does actually exist\n            client_logger.warning(\"Could not read .netrc file: %s\", e)\n\n    return None\n\n\n@dataclasses.dataclass(frozen=True)\nclass ProxyInfo:\n    proxy: URL\n    proxy_auth: Optional[BasicAuth]\n\n\ndef basicauth_from_netrc(netrc_obj: Optional[netrc.netrc], host: str) -> BasicAuth:\n    \"\"\"\n    Return :py:class:`~aiohttp.BasicAuth` credentials for ``host`` from ``netrc_obj``.\n\n    :raises LookupError: if ``netrc_obj`` is :py:data:`None` or if no\n            entry is found for the ``host``.\n    \"\"\"\n    if netrc_obj is None:\n        raise LookupError(\"No .netrc file found\")\n    auth_from_netrc = netrc_obj.authenticators(host)\n\n    if auth_from_netrc is None:\n        raise LookupError(f\"No entry for {host!s} found in the `.netrc` file.\")\n    login, account, password = auth_from_netrc\n\n    # TODO(PY311): username = login or account\n    # Up to python 3.10, account could be None if not specified,\n    # and login will be empty string if not specified. From 3.11,\n    # login and account will be empty string if not specified.\n    username = login if (login or account is None) else account\n\n    # TODO(PY311): Remove this, as password will be empty string\n    # if not specified\n    if password is None:\n        password = \"\"\n\n    return BasicAuth(username, password)\n\n\ndef proxies_from_env() -> Dict[str, ProxyInfo]:\n    proxy_urls = {\n        k: URL(v)\n        for k, v in getproxies().items()\n        if k in (\"http\", \"https\", \"ws\", \"wss\")\n    }\n    netrc_obj = netrc_from_env()\n    stripped = {k: strip_auth_from_url(v) for k, v in proxy_urls.items()}\n    ret = {}\n    for proto, val in stripped.items():\n        proxy, auth = val\n        if proxy.scheme in (\"https\", \"wss\"):\n            client_logger.warning(\n                \"%s proxies %s are not supported, ignoring\", proxy.scheme.upper(), proxy\n            )\n            continue\n        if netrc_obj and auth is None:\n            if proxy.host is not None:\n                try:\n                    auth = basicauth_from_netrc(netrc_obj, proxy.host)\n                except LookupError:\n                    auth = None\n        ret[proto] = ProxyInfo(proxy, auth)\n    return ret\n\n\ndef get_env_proxy_for_url(url: URL) -> Tuple[URL, Optional[BasicAuth]]:\n    \"\"\"Get a permitted proxy for the given URL from the env.\"\"\"\n    if url.host is not None and proxy_bypass(url.host):\n        raise LookupError(f\"Proxying is disallowed for `{url.host!r}`\")\n\n    proxies_in_env = proxies_from_env()\n    try:\n        proxy_info = proxies_in_env[url.scheme]\n    except KeyError:\n        raise LookupError(f\"No proxies found for `{url!s}` in the env\")\n    else:\n        return proxy_info.proxy, proxy_info.proxy_auth\n\n\n@dataclasses.dataclass(frozen=True)\nclass MimeType:\n    type: str\n    subtype: str\n    suffix: str\n    parameters: \"MultiDictProxy[str]\"\n\n\n@functools.lru_cache(maxsize=56)\ndef parse_mimetype(mimetype: str) -> MimeType:\n    \"\"\"Parses a MIME type into its components.\n\n    mimetype is a MIME type string.\n\n    Returns a MimeType object.\n\n    Example:\n\n    >>> parse_mimetype('text/html; charset=utf-8')\n    MimeType(type='text', subtype='html', suffix='',\n             parameters={'charset': 'utf-8'})\n\n    \"\"\"\n    if not mimetype:\n        return MimeType(\n            type=\"\", subtype=\"\", suffix=\"\", parameters=MultiDictProxy(MultiDict())\n        )\n\n    parts = mimetype.split(\";\")\n    params: MultiDict[str] = MultiDict()\n    for item in parts[1:]:\n        if not item:\n            continue\n        key, _, value = item.partition(\"=\")\n        params.add(key.lower().strip(), value.strip(' \"'))\n\n    fulltype = parts[0].strip().lower()\n    if fulltype == \"*\":\n        fulltype = \"*/*\"\n\n    mtype, _, stype = fulltype.partition(\"/\")\n    stype, _, suffix = stype.partition(\"+\")\n\n    return MimeType(\n        type=mtype, subtype=stype, suffix=suffix, parameters=MultiDictProxy(params)\n    )\n\n\ndef guess_filename(obj: Any, default: Optional[str] = None) -> Optional[str]:\n    name = getattr(obj, \"name\", None)\n    if name and isinstance(name, str) and name[0] != \"<\" and name[-1] != \">\":\n        return Path(name).name\n    return default\n\n\nnot_qtext_re = re.compile(r\"[^\\041\\043-\\133\\135-\\176]\")\nQCONTENT = {chr(i) for i in range(0x20, 0x7F)} | {\"\\t\"}\n\n\ndef quoted_string(content: str) -> str:\n    \"\"\"Return 7-bit content as quoted-string.\n\n    Format content into a quoted-string as defined in RFC5322 for\n    Internet Message Format. Notice that this is not the 8-bit HTTP\n    format, but the 7-bit email format. Content must be in usascii or\n    a ValueError is raised.\n    \"\"\"\n    if not (QCONTENT > set(content)):\n        raise ValueError(f\"bad content for quoted-string {content!r}\")\n    return not_qtext_re.sub(lambda x: \"\\\\\" + x.group(0), content)\n\n\ndef content_disposition_header(\n    disptype: str, quote_fields: bool = True, _charset: str = \"utf-8\", **params: str\n) -> str:\n    \"\"\"Sets ``Content-Disposition`` header for MIME.\n\n    This is the MIME payload Content-Disposition header from RFC 2183\n    and RFC 7579 section 4.2, not the HTTP Content-Disposition from\n    RFC 6266.\n\n    disptype is a disposition type: inline, attachment, form-data.\n    Should be valid extension token (see RFC 2183)\n\n    quote_fields performs value quoting to 7-bit MIME headers\n    according to RFC 7578. Set to quote_fields to False if recipient\n    can take 8-bit file names and field values.\n\n    _charset specifies the charset to use when quote_fields is True.\n\n    params is a dict with disposition params.\n    \"\"\"\n    if not disptype or not (TOKEN > set(disptype)):\n        raise ValueError(\"bad content disposition type {!r}\" \"\".format(disptype))\n\n    value = disptype\n    if params:\n        lparams = []\n        for key, val in params.items():\n            if not key or not (TOKEN > set(key)):\n                raise ValueError(\n                    \"bad content disposition parameter\" \" {!r}={!r}\".format(key, val)\n                )\n            if quote_fields:\n                if key.lower() == \"filename\":\n                    qval = quote(val, \"\", encoding=_charset)\n                    lparams.append((key, '\"%s\"' % qval))\n                else:\n                    try:\n                        qval = quoted_string(val)\n                    except ValueError:\n                        qval = \"\".join(\n                            (_charset, \"''\", quote(val, \"\", encoding=_charset))\n                        )\n                        lparams.append((key + \"*\", qval))\n                    else:\n                        lparams.append((key, '\"%s\"' % qval))\n            else:\n                qval = val.replace(\"\\\\\", \"\\\\\\\\\").replace('\"', '\\\\\"')\n                lparams.append((key, '\"%s\"' % qval))\n        sparams = \"; \".join(\"=\".join(pair) for pair in lparams)\n        value = \"; \".join((value, sparams))\n    return value\n\n\ndef is_expected_content_type(\n    response_content_type: str, expected_content_type: str\n) -> bool:\n    \"\"\"Checks if received content type is processable as an expected one.\n\n    Both arguments should be given without parameters.\n    \"\"\"\n    if expected_content_type == \"application/json\":\n        return json_re.match(response_content_type) is not None\n    return expected_content_type in response_content_type\n\n\nclass _TSelf(Protocol, Generic[_T]):\n    _cache: Dict[str, _T]\n\n\nclass reify(Generic[_T]):\n    \"\"\"Use as a class method decorator.\n\n    It operates almost exactly like\n    the Python `@property` decorator, but it puts the result of the\n    method it decorates into the instance dict after the first call,\n    effectively replacing the function it decorates with an instance\n    variable.  It is, in Python parlance, a data descriptor.\n    \"\"\"\n\n    def __init__(self, wrapped: Callable[..., _T]) -> None:\n        self.wrapped = wrapped\n        self.__doc__ = wrapped.__doc__\n        self.name = wrapped.__name__\n\n    def __get__(self, inst: _TSelf[_T], owner: Optional[Type[Any]] = None) -> _T:\n        try:\n            try:\n                return inst._cache[self.name]\n            except KeyError:\n                val = self.wrapped(inst)\n                inst._cache[self.name] = val\n                return val\n        except AttributeError:\n            if inst is None:\n                return self\n            raise\n\n    def __set__(self, inst: _TSelf[_T], value: _T) -> None:\n        raise AttributeError(\"reified property is read-only\")\n\n\nreify_py = reify\n\ntry:\n    from ._helpers import reify as reify_c\n\n    if not NO_EXTENSIONS:\n        reify = reify_c  # type: ignore[misc,assignment]\nexcept ImportError:\n    pass\n\n_ipv4_pattern = (\n    r\"^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}\"\n    r\"(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$\"\n)\n_ipv6_pattern = (\n    r\"^(?:(?:(?:[A-F0-9]{1,4}:){6}|(?=(?:[A-F0-9]{0,4}:){0,6}\"\n    r\"(?:[0-9]{1,3}\\.){3}[0-9]{1,3}$)(([0-9A-F]{1,4}:){0,5}|:)\"\n    r\"((:[0-9A-F]{1,4}){1,5}:|:)|::(?:[A-F0-9]{1,4}:){5})\"\n    r\"(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])\\.){3}\"\n    r\"(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])|(?:[A-F0-9]{1,4}:){7}\"\n    r\"[A-F0-9]{1,4}|(?=(?:[A-F0-9]{0,4}:){0,7}[A-F0-9]{0,4}$)\"\n    r\"(([0-9A-F]{1,4}:){1,7}|:)((:[0-9A-F]{1,4}){1,7}|:)|(?:[A-F0-9]{1,4}:){7}\"\n    r\":|:(:[A-F0-9]{1,4}){7})$\"\n)\n_ipv4_regex = re.compile(_ipv4_pattern)\n_ipv6_regex = re.compile(_ipv6_pattern, flags=re.IGNORECASE)\n_ipv4_regexb = re.compile(_ipv4_pattern.encode(\"ascii\"))\n_ipv6_regexb = re.compile(_ipv6_pattern.encode(\"ascii\"), flags=re.IGNORECASE)\n\n\ndef _is_ip_address(\n    regex: Pattern[str], regexb: Pattern[bytes], host: Optional[Union[str, bytes]]\n) -> bool:\n    if host is None:\n        return False\n    if isinstance(host, str):\n        return bool(regex.match(host))\n    elif isinstance(host, (bytes, bytearray, memoryview)):\n        return bool(regexb.match(host))\n    else:\n        raise TypeError(f\"{host} [{type(host)}] is not a str or bytes\")\n\n\nis_ipv4_address = functools.partial(_is_ip_address, _ipv4_regex, _ipv4_regexb)\nis_ipv6_address = functools.partial(_is_ip_address, _ipv6_regex, _ipv6_regexb)\n\n\ndef is_ip_address(host: Optional[Union[str, bytes, bytearray, memoryview]]) -> bool:\n    return is_ipv4_address(host) or is_ipv6_address(host)\n\n\n_cached_current_datetime: Optional[int] = None\n_cached_formatted_datetime = \"\"\n\n\ndef rfc822_formatted_time() -> str:\n    global _cached_current_datetime\n    global _cached_formatted_datetime\n\n    now = int(time.time())\n    if now != _cached_current_datetime:\n        # Weekday and month names for HTTP date/time formatting;\n        # always English!\n        # Tuples are constants stored in codeobject!\n        _weekdayname = (\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")\n        _monthname = (\n            \"\",  # Dummy so we can use 1-based month numbers\n            \"Jan\",\n            \"Feb\",\n            \"Mar\",\n            \"Apr\",\n            \"May\",\n            \"Jun\",\n            \"Jul\",\n            \"Aug\",\n            \"Sep\",\n            \"Oct\",\n            \"Nov\",\n            \"Dec\",\n        )\n\n        year, month, day, hh, mm, ss, wd, *tail = time.gmtime(now)\n        _cached_formatted_datetime = \"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % (\n            _weekdayname[wd],\n            day,\n            _monthname[month],\n            year,\n            hh,\n            mm,\n            ss,\n        )\n        _cached_current_datetime = now\n    return _cached_formatted_datetime\n\n\ndef _weakref_handle(info: \"Tuple[weakref.ref[object], str]\") -> None:\n    ref, name = info\n    ob = ref()\n    if ob is not None:\n        with suppress(Exception):\n            getattr(ob, name)()\n\n\ndef weakref_handle(\n    ob: object,\n    name: str,\n    timeout: Optional[float],\n    loop: asyncio.AbstractEventLoop,\n    timeout_ceil_threshold: float = 5,\n) -> Optional[asyncio.TimerHandle]:\n    if timeout is not None and timeout > 0:\n        when = loop.time() + timeout\n        if timeout >= timeout_ceil_threshold:\n            when = ceil(when)\n\n        return loop.call_at(when, _weakref_handle, (weakref.ref(ob), name))\n    return None\n\n\ndef call_later(\n    cb: Callable[[], Any],\n    timeout: Optional[float],\n    loop: asyncio.AbstractEventLoop,\n    timeout_ceil_threshold: float = 5,\n) -> Optional[asyncio.TimerHandle]:\n    if timeout is not None and timeout > 0:\n        when = loop.time() + timeout\n        if timeout > timeout_ceil_threshold:\n            when = ceil(when)\n        return loop.call_at(when, cb)\n    return None\n\n\nclass TimeoutHandle:\n    \"\"\"Timeout handle\"\"\"\n\n    def __init__(\n        self,\n        loop: asyncio.AbstractEventLoop,\n        timeout: Optional[float],\n        ceil_threshold: float = 5,\n    ) -> None:\n        self._timeout = timeout\n        self._loop = loop\n        self._ceil_threshold = ceil_threshold\n        self._callbacks: List[\n            Tuple[Callable[..., None], Tuple[Any, ...], Dict[str, Any]]\n        ] = []\n\n    def register(\n        self, callback: Callable[..., None], *args: Any, **kwargs: Any\n    ) -> None:\n        self._callbacks.append((callback, args, kwargs))\n\n    def close(self) -> None:\n        self._callbacks.clear()\n\n    def start(self) -> Optional[asyncio.Handle]:\n        timeout = self._timeout\n        if timeout is not None and timeout > 0:\n            when = self._loop.time() + timeout\n            if timeout >= self._ceil_threshold:\n                when = ceil(when)\n            return self._loop.call_at(when, self.__call__)\n        else:\n            return None\n\n    def timer(self) -> \"BaseTimerContext\":\n        if self._timeout is not None and self._timeout > 0:\n            timer = TimerContext(self._loop)\n            self.register(timer.timeout)\n            return timer\n        else:\n            return TimerNoop()\n\n    def __call__(self) -> None:\n        for cb, args, kwargs in self._callbacks:\n            with suppress(Exception):\n                cb(*args, **kwargs)\n\n        self._callbacks.clear()\n\n\nclass BaseTimerContext(ContextManager[\"BaseTimerContext\"]):\n    def assert_timeout(self) -> None:\n        \"\"\"Raise TimeoutError if timeout has been exceeded.\"\"\"\n\n\nclass TimerNoop(BaseTimerContext):\n    def __enter__(self) -> BaseTimerContext:\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        return\n\n\nclass TimerContext(BaseTimerContext):\n    \"\"\"Low resolution timeout context manager\"\"\"\n\n    def __init__(self, loop: asyncio.AbstractEventLoop) -> None:\n        self._loop = loop\n        self._tasks: List[asyncio.Task[Any]] = []\n        self._cancelled = False\n\n    def assert_timeout(self) -> None:\n        \"\"\"Raise TimeoutError if timer has already been cancelled.\"\"\"\n        if self._cancelled:\n            raise asyncio.TimeoutError from None\n\n    def __enter__(self) -> BaseTimerContext:\n        task = asyncio.current_task(loop=self._loop)\n\n        if task is None:\n            raise RuntimeError(\n                \"Timeout context manager should be used \" \"inside a task\"\n            )\n\n        if self._cancelled:\n            raise asyncio.TimeoutError from None\n\n        self._tasks.append(task)\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> Optional[bool]:\n        if self._tasks:\n            self._tasks.pop()  # type: ignore[unused-awaitable]\n\n        if exc_type is asyncio.CancelledError and self._cancelled:\n            raise asyncio.TimeoutError from None\n        return None\n\n    def timeout(self) -> None:\n        if not self._cancelled:\n            for task in set(self._tasks):\n                task.cancel()\n\n            self._cancelled = True\n\n\ndef ceil_timeout(\n    delay: Optional[float], ceil_threshold: float = 5\n) -> async_timeout.Timeout:\n    if delay is None or delay <= 0:\n        return async_timeout.timeout(None)\n\n    loop = asyncio.get_running_loop()\n    now = loop.time()\n    when = now + delay\n    if delay > ceil_threshold:\n        when = ceil(when)\n    return async_timeout.timeout_at(when)\n\n\nclass HeadersMixin:\n    __slots__ = (\"_content_type\", \"_content_dict\", \"_stored_content_type\")\n\n    def __init__(self) -> None:\n        super().__init__()\n        self._content_type: Optional[str] = None\n        self._content_dict: Optional[Dict[str, str]] = None\n        self._stored_content_type: Union[str, _SENTINEL] = sentinel\n\n    def _parse_content_type(self, raw: str) -> None:\n        self._stored_content_type = raw\n        if raw is None:\n            # default value according to RFC 2616\n            self._content_type = \"application/octet-stream\"\n            self._content_dict = {}\n        else:\n            msg = HeaderParser().parsestr(\"Content-Type: \" + raw)\n            self._content_type = msg.get_content_type()\n            params = msg.get_params(())\n            self._content_dict = dict(params[1:])  # First element is content type again\n\n    @property\n    def content_type(self) -> str:\n        \"\"\"The value of content part for Content-Type HTTP header.\"\"\"\n        raw = self._headers.get(hdrs.CONTENT_TYPE)  # type: ignore[attr-defined]\n        if self._stored_content_type != raw:\n            self._parse_content_type(raw)\n        return self._content_type  # type: ignore[return-value]\n\n    @property\n    def charset(self) -> Optional[str]:\n        \"\"\"The value of charset part for Content-Type HTTP header.\"\"\"\n        raw = self._headers.get(hdrs.CONTENT_TYPE)  # type: ignore[attr-defined]\n        if self._stored_content_type != raw:\n            self._parse_content_type(raw)\n        return self._content_dict.get(\"charset\")  # type: ignore[union-attr]\n\n    @property\n    def content_length(self) -> Optional[int]:\n        \"\"\"The value of Content-Length HTTP header.\"\"\"\n        content_length = self._headers.get(  # type: ignore[attr-defined]\n            hdrs.CONTENT_LENGTH\n        )\n\n        if content_length is not None:\n            return int(content_length)\n        else:\n            return None\n\n\ndef set_result(fut: \"asyncio.Future[_T]\", result: _T) -> None:\n    if not fut.done():\n        fut.set_result(result)\n\n\n_EXC_SENTINEL = BaseException()\n\n\nclass ErrorableProtocol(Protocol):\n    def set_exception(\n        self,\n        exc: BaseException,\n        exc_cause: BaseException = ...,\n    ) -> None: ...  # pragma: no cover\n\n\ndef set_exception(\n    fut: \"asyncio.Future[_T] | ErrorableProtocol\",\n    exc: BaseException,\n    exc_cause: BaseException = _EXC_SENTINEL,\n) -> None:\n    \"\"\"Set future exception.\n\n    If the future is marked as complete, this function is a no-op.\n\n    :param exc_cause: An exception that is a direct cause of ``exc``.\n                      Only set if provided.\n    \"\"\"\n    if asyncio.isfuture(fut) and fut.done():\n        return\n\n    exc_is_sentinel = exc_cause is _EXC_SENTINEL\n    exc_causes_itself = exc is exc_cause\n    if not exc_is_sentinel and not exc_causes_itself:\n        exc.__cause__ = exc_cause\n\n    fut.set_exception(exc)\n\n\n@functools.total_ordering\nclass AppKey(Generic[_T]):\n    \"\"\"Keys for static typing support in Application.\"\"\"\n\n    __slots__ = (\"_name\", \"_t\", \"__orig_class__\")\n\n    # This may be set by Python when instantiating with a generic type. We need to\n    # support this, in order to support types that are not concrete classes,\n    # like Iterable, which can't be passed as the second parameter to __init__.\n    __orig_class__: Type[object]\n\n    def __init__(self, name: str, t: Optional[Type[_T]] = None):\n        # Prefix with module name to help deduplicate key names.\n        frame = inspect.currentframe()\n        while frame:\n            if frame.f_code.co_name == \"<module>\":\n                module: str = frame.f_globals[\"__name__\"]\n                break\n            frame = frame.f_back\n        else:\n            raise RuntimeError(\"Failed to get module name.\")\n\n        # https://github.com/python/mypy/issues/14209\n        self._name = module + \".\" + name  # type: ignore[possibly-undefined]\n        self._t = t\n\n    def __lt__(self, other: object) -> bool:\n        if isinstance(other, AppKey):\n            return self._name < other._name\n        return True  # Order AppKey above other types.\n\n    def __repr__(self) -> str:\n        t = self._t\n        if t is None:\n            with suppress(AttributeError):\n                # Set to type arg.\n                t = get_args(self.__orig_class__)[0]\n\n        if t is None:\n            t_repr = \"<<Unknown>>\"\n        elif isinstance(t, type):\n            if t.__module__ == \"builtins\":\n                t_repr = t.__qualname__\n            else:\n                t_repr = f\"{t.__module__}.{t.__qualname__}\"\n        else:\n            t_repr = repr(t)\n        return f\"<AppKey({self._name}, type={t_repr})>\"\n\n\n@final\nclass ChainMapProxy(Mapping[Union[str, AppKey[Any]], Any]):\n    __slots__ = (\"_maps\",)\n\n    def __init__(self, maps: Iterable[Mapping[Union[str, AppKey[Any]], Any]]) -> None:\n        self._maps = tuple(maps)\n\n    def __init_subclass__(cls) -> None:\n        raise TypeError(\n            \"Inheritance class {} from ChainMapProxy \"\n            \"is forbidden\".format(cls.__name__)\n        )\n\n    @overload  # type: ignore[override]\n    def __getitem__(self, key: AppKey[_T]) -> _T: ...\n\n    @overload\n    def __getitem__(self, key: str) -> Any: ...\n\n    def __getitem__(self, key: Union[str, AppKey[_T]]) -> Any:\n        for mapping in self._maps:\n            try:\n                return mapping[key]\n            except KeyError:\n                pass\n        raise KeyError(key)\n\n    @overload  # type: ignore[override]\n    def get(self, key: AppKey[_T], default: _S) -> Union[_T, _S]: ...\n\n    @overload\n    def get(self, key: AppKey[_T], default: None = ...) -> Optional[_T]: ...\n\n    @overload\n    def get(self, key: str, default: Any = ...) -> Any: ...\n\n    def get(self, key: Union[str, AppKey[_T]], default: Any = None) -> Any:\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def __len__(self) -> int:\n        # reuses stored hash values if possible\n        return len(set().union(*self._maps))\n\n    def __iter__(self) -> Iterator[Union[str, AppKey[Any]]]:\n        d: Dict[Union[str, AppKey[Any]], Any] = {}\n        for mapping in reversed(self._maps):\n            # reuses stored hash values if possible\n            d.update(mapping)\n        return iter(d)\n\n    def __contains__(self, key: object) -> bool:\n        return any(key in m for m in self._maps)\n\n    def __bool__(self) -> bool:\n        return any(self._maps)\n\n    def __repr__(self) -> str:\n        content = \", \".join(map(repr, self._maps))\n        return f\"ChainMapProxy({content})\"\n\n\nclass CookieMixin:\n    # The `_cookies` slots is not defined here because non-empty slots cannot\n    # be combined with an Exception base class, as is done in HTTPException.\n    # CookieMixin subclasses with slots should define the `_cookies`\n    # slot themselves.\n    __slots__ = ()\n\n    def __init__(self) -> None:\n        super().__init__()\n        # Mypy doesn't like that _cookies isn't in __slots__.\n        # See the comment on this class's __slots__ for why this is OK.\n        self._cookies = SimpleCookie()  # type: ignore[misc]\n\n    @property\n    def cookies(self) -> SimpleCookie:\n        return self._cookies\n\n    def set_cookie(\n        self,\n        name: str,\n        value: str,\n        *,\n        expires: Optional[str] = None,\n        domain: Optional[str] = None,\n        max_age: Optional[Union[int, str]] = None,\n        path: str = \"/\",\n        secure: Optional[bool] = None,\n        httponly: Optional[bool] = None,\n        version: Optional[str] = None,\n        samesite: Optional[str] = None,\n    ) -> None:\n        \"\"\"Set or update response cookie.\n\n        Sets new cookie or updates existent with new value.\n        Also updates only those params which are not None.\n        \"\"\"\n        old = self._cookies.get(name)\n        if old is not None and old.coded_value == \"\":\n            # deleted cookie\n            self._cookies.pop(name, None)\n\n        self._cookies[name] = value\n        c = self._cookies[name]\n\n        if expires is not None:\n            c[\"expires\"] = expires\n        elif c.get(\"expires\") == \"Thu, 01 Jan 1970 00:00:00 GMT\":\n            del c[\"expires\"]\n\n        if domain is not None:\n            c[\"domain\"] = domain\n\n        if max_age is not None:\n            c[\"max-age\"] = str(max_age)\n        elif \"max-age\" in c:\n            del c[\"max-age\"]\n\n        c[\"path\"] = path\n\n        if secure is not None:\n            c[\"secure\"] = secure\n        if httponly is not None:\n            c[\"httponly\"] = httponly\n        if version is not None:\n            c[\"version\"] = version\n        if samesite is not None:\n            c[\"samesite\"] = samesite\n\n        if DEBUG:\n            cookie_length = len(c.output(header=\"\")[1:])\n            if cookie_length > COOKIE_MAX_LENGTH:\n                warnings.warn(\n                    \"The size of is too large, it might get ignored by the client.\",\n                    UserWarning,\n                    stacklevel=2,\n                )\n\n    def del_cookie(\n        self, name: str, *, domain: Optional[str] = None, path: str = \"/\"\n    ) -> None:\n        \"\"\"Delete cookie.\n\n        Creates new empty expired cookie.\n        \"\"\"\n        # TODO: do we need domain/path here?\n        self._cookies.pop(name, None)\n        self.set_cookie(\n            name,\n            \"\",\n            max_age=0,\n            expires=\"Thu, 01 Jan 1970 00:00:00 GMT\",\n            domain=domain,\n            path=path,\n        )\n\n\ndef populate_with_cookies(headers: \"CIMultiDict[str]\", cookies: SimpleCookie) -> None:\n    for cookie in cookies.values():\n        value = cookie.output(header=\"\")[1:]\n        headers.add(hdrs.SET_COOKIE, value)\n\n\n# https://tools.ietf.org/html/rfc7232#section-2.3\n_ETAGC = r\"[!\\x23-\\x7E\\x80-\\xff]+\"\n_ETAGC_RE = re.compile(_ETAGC)\n_QUOTED_ETAG = rf'(W/)?\"({_ETAGC})\"'\nQUOTED_ETAG_RE = re.compile(_QUOTED_ETAG)\nLIST_QUOTED_ETAG_RE = re.compile(rf\"({_QUOTED_ETAG})(?:\\s*,\\s*|$)|(.)\")\n\nETAG_ANY = \"*\"\n\n\n@dataclasses.dataclass(frozen=True)\nclass ETag:\n    value: str\n    is_weak: bool = False\n\n\ndef validate_etag_value(value: str) -> None:\n    if value != ETAG_ANY and not _ETAGC_RE.fullmatch(value):\n        raise ValueError(\n            f\"Value {value!r} is not a valid etag. Maybe it contains '\\\"'?\"\n        )\n\n\ndef parse_http_date(date_str: Optional[str]) -> Optional[datetime.datetime]:\n    \"\"\"Process a date string, return a datetime object\"\"\"\n    if date_str is not None:\n        timetuple = parsedate(date_str)\n        if timetuple is not None:\n            with suppress(ValueError):\n                return datetime.datetime(*timetuple[:6], tzinfo=datetime.timezone.utc)\n    return None\n\n\ndef must_be_empty_body(method: str, code: int) -> bool:\n    \"\"\"Check if a request must return an empty body.\"\"\"\n    return (\n        status_code_must_be_empty_body(code)\n        or method_must_be_empty_body(method)\n        or (200 <= code < 300 and method.upper() == hdrs.METH_CONNECT)\n    )\n\n\ndef method_must_be_empty_body(method: str) -> bool:\n    \"\"\"Check if a method must return an empty body.\"\"\"\n    # https://datatracker.ietf.org/doc/html/rfc9112#section-6.3-2.1\n    # https://datatracker.ietf.org/doc/html/rfc9112#section-6.3-2.2\n    return method.upper() == hdrs.METH_HEAD\n\n\ndef status_code_must_be_empty_body(code: int) -> bool:\n    \"\"\"Check if a status code must return an empty body.\"\"\"\n    # https://datatracker.ietf.org/doc/html/rfc9112#section-6.3-2.1\n    return code in {204, 304} or 100 <= code < 200\n\n\ndef should_remove_content_length(method: str, code: int) -> bool:\n    \"\"\"Check if a Content-Length header should be removed.\n\n    This should always be a subset of must_be_empty_body\n    \"\"\"\n    # https://www.rfc-editor.org/rfc/rfc9110.html#section-8.6-8\n    # https://www.rfc-editor.org/rfc/rfc9110.html#section-15.4.5-4\n    return (\n        code in {204, 304}\n        or 100 <= code < 200\n        or (200 <= code < 300 and method.upper() == hdrs.METH_CONNECT)\n    )\n", "aiohttp/web_log.py": "import datetime\nimport functools\nimport logging\nimport os\nimport re\nimport time as time_mod\nfrom collections import namedtuple\nfrom typing import Any, Callable, Dict, Iterable, List, Tuple  # noqa\n\nfrom .abc import AbstractAccessLogger\nfrom .web_request import BaseRequest\nfrom .web_response import StreamResponse\n\nKeyMethod = namedtuple(\"KeyMethod\", \"key method\")\n\n\nclass AccessLogger(AbstractAccessLogger):\n    \"\"\"Helper object to log access.\n\n    Usage:\n        log = logging.getLogger(\"spam\")\n        log_format = \"%a %{User-Agent}i\"\n        access_logger = AccessLogger(log, log_format)\n        access_logger.log(request, response, time)\n\n    Format:\n        %%  The percent sign\n        %a  Remote IP-address (IP-address of proxy if using reverse proxy)\n        %t  Time when the request was started to process\n        %P  The process ID of the child that serviced the request\n        %r  First line of request\n        %s  Response status code\n        %b  Size of response in bytes, including HTTP headers\n        %T  Time taken to serve the request, in seconds\n        %Tf Time taken to serve the request, in seconds with floating fraction\n            in .06f format\n        %D  Time taken to serve the request, in microseconds\n        %{FOO}i  request.headers['FOO']\n        %{FOO}o  response.headers['FOO']\n        %{FOO}e  os.environ['FOO']\n\n    \"\"\"\n\n    LOG_FORMAT_MAP = {\n        \"a\": \"remote_address\",\n        \"t\": \"request_start_time\",\n        \"P\": \"process_id\",\n        \"r\": \"first_request_line\",\n        \"s\": \"response_status\",\n        \"b\": \"response_size\",\n        \"T\": \"request_time\",\n        \"Tf\": \"request_time_frac\",\n        \"D\": \"request_time_micro\",\n        \"i\": \"request_header\",\n        \"o\": \"response_header\",\n    }\n\n    LOG_FORMAT = '%a %t \"%r\" %s %b \"%{Referer}i\" \"%{User-Agent}i\"'\n    FORMAT_RE = re.compile(r\"%(\\{([A-Za-z0-9\\-_]+)\\}([ioe])|[atPrsbOD]|Tf?)\")\n    CLEANUP_RE = re.compile(r\"(%[^s])\")\n    _FORMAT_CACHE: Dict[str, Tuple[str, List[KeyMethod]]] = {}\n\n    def __init__(self, logger: logging.Logger, log_format: str = LOG_FORMAT) -> None:\n        \"\"\"Initialise the logger.\n\n        logger is a logger object to be used for logging.\n        log_format is a string with apache compatible log format description.\n\n        \"\"\"\n        super().__init__(logger, log_format=log_format)\n\n        _compiled_format = AccessLogger._FORMAT_CACHE.get(log_format)\n        if not _compiled_format:\n            _compiled_format = self.compile_format(log_format)\n            AccessLogger._FORMAT_CACHE[log_format] = _compiled_format\n\n        self._log_format, self._methods = _compiled_format\n\n    def compile_format(self, log_format: str) -> Tuple[str, List[KeyMethod]]:\n        \"\"\"Translate log_format into form usable by modulo formatting\n\n        All known atoms will be replaced with %s\n        Also methods for formatting of those atoms will be added to\n        _methods in appropriate order\n\n        For example we have log_format = \"%a %t\"\n        This format will be translated to \"%s %s\"\n        Also contents of _methods will be\n        [self._format_a, self._format_t]\n        These method will be called and results will be passed\n        to translated string format.\n\n        Each _format_* method receive 'args' which is list of arguments\n        given to self.log\n\n        Exceptions are _format_e, _format_i and _format_o methods which\n        also receive key name (by functools.partial)\n\n        \"\"\"\n        # list of (key, method) tuples, we don't use an OrderedDict as users\n        # can repeat the same key more than once\n        methods = list()\n\n        for atom in self.FORMAT_RE.findall(log_format):\n            if atom[1] == \"\":\n                format_key1 = self.LOG_FORMAT_MAP[atom[0]]\n                m = getattr(AccessLogger, \"_format_%s\" % atom[0])\n                key_method = KeyMethod(format_key1, m)\n            else:\n                format_key2 = (self.LOG_FORMAT_MAP[atom[2]], atom[1])\n                m = getattr(AccessLogger, \"_format_%s\" % atom[2])\n                key_method = KeyMethod(format_key2, functools.partial(m, atom[1]))\n\n            methods.append(key_method)\n\n        log_format = self.FORMAT_RE.sub(r\"%s\", log_format)\n        log_format = self.CLEANUP_RE.sub(r\"%\\1\", log_format)\n        return log_format, methods\n\n    @staticmethod\n    def _format_i(\n        key: str, request: BaseRequest, response: StreamResponse, time: float\n    ) -> str:\n        if request is None:\n            return \"(no headers)\"\n\n        # suboptimal, make istr(key) once\n        return request.headers.get(key, \"-\")\n\n    @staticmethod\n    def _format_o(\n        key: str, request: BaseRequest, response: StreamResponse, time: float\n    ) -> str:\n        # suboptimal, make istr(key) once\n        return response.headers.get(key, \"-\")\n\n    @staticmethod\n    def _format_a(request: BaseRequest, response: StreamResponse, time: float) -> str:\n        if request is None:\n            return \"-\"\n        ip = request.remote\n        return ip if ip is not None else \"-\"\n\n    @staticmethod\n    def _format_t(request: BaseRequest, response: StreamResponse, time: float) -> str:\n        tz = datetime.timezone(datetime.timedelta(seconds=-time_mod.timezone))\n        now = datetime.datetime.now(tz)\n        start_time = now - datetime.timedelta(seconds=time)\n        return start_time.strftime(\"[%d/%b/%Y:%H:%M:%S %z]\")\n\n    @staticmethod\n    def _format_P(request: BaseRequest, response: StreamResponse, time: float) -> str:\n        return \"<%s>\" % os.getpid()\n\n    @staticmethod\n    def _format_r(request: BaseRequest, response: StreamResponse, time: float) -> str:\n        if request is None:\n            return \"-\"\n        return \"{} {} HTTP/{}.{}\".format(\n            request.method,\n            request.path_qs,\n            request.version.major,\n            request.version.minor,\n        )\n\n    @staticmethod\n    def _format_s(request: BaseRequest, response: StreamResponse, time: float) -> int:\n        return response.status\n\n    @staticmethod\n    def _format_b(request: BaseRequest, response: StreamResponse, time: float) -> int:\n        return response.body_length\n\n    @staticmethod\n    def _format_T(request: BaseRequest, response: StreamResponse, time: float) -> str:\n        return str(round(time))\n\n    @staticmethod\n    def _format_Tf(request: BaseRequest, response: StreamResponse, time: float) -> str:\n        return \"%06f\" % time\n\n    @staticmethod\n    def _format_D(request: BaseRequest, response: StreamResponse, time: float) -> str:\n        return str(round(time * 1000000))\n\n    def _format_line(\n        self, request: BaseRequest, response: StreamResponse, time: float\n    ) -> Iterable[Tuple[str, Callable[[BaseRequest, StreamResponse, float], str]]]:\n        return [(key, method(request, response, time)) for key, method in self._methods]\n\n    def log(self, request: BaseRequest, response: StreamResponse, time: float) -> None:\n        if not self.logger.isEnabledFor(logging.INFO):\n            # Avoid formatting the log line if it will not be emitted.\n            return\n        try:\n            fmt_info = self._format_line(request, response, time)\n\n            values = list()\n            extra = dict()\n            for key, value in fmt_info:\n                values.append(value)\n\n                if key.__class__ is str:\n                    extra[key] = value\n                else:\n                    k1, k2 = key  # type: ignore[misc]\n                    dct = extra.get(k1, {})  # type: ignore[var-annotated,has-type]\n                    dct[k2] = value  # type: ignore[index,has-type]\n                    extra[k1] = dct  # type: ignore[has-type,assignment]\n\n            self.logger.info(self._log_format % tuple(values), extra=extra)\n        except Exception:\n            self.logger.exception(\"Error in logging\")\n", "aiohttp/http_parser.py": "import abc\nimport asyncio\nimport re\nimport string\nfrom contextlib import suppress\nfrom enum import IntEnum\nfrom typing import (\n    Any,\n    ClassVar,\n    Final,\n    Generic,\n    List,\n    Literal,\n    NamedTuple,\n    Optional,\n    Pattern,\n    Set,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n)\n\nfrom multidict import CIMultiDict, CIMultiDictProxy, istr\nfrom yarl import URL\n\nfrom . import hdrs\nfrom .base_protocol import BaseProtocol\nfrom .compression_utils import HAS_BROTLI, BrotliDecompressor, ZLibDecompressor\nfrom .helpers import (\n    _EXC_SENTINEL,\n    DEBUG,\n    NO_EXTENSIONS,\n    BaseTimerContext,\n    method_must_be_empty_body,\n    set_exception,\n    status_code_must_be_empty_body,\n)\nfrom .http_exceptions import (\n    BadHttpMessage,\n    BadStatusLine,\n    ContentEncodingError,\n    ContentLengthError,\n    InvalidHeader,\n    InvalidURLError,\n    LineTooLong,\n    TransferEncodingError,\n)\nfrom .http_writer import HttpVersion, HttpVersion10\nfrom .streams import EMPTY_PAYLOAD, StreamReader\nfrom .typedefs import RawHeaders\n\n__all__ = (\n    \"HeadersParser\",\n    \"HttpParser\",\n    \"HttpRequestParser\",\n    \"HttpResponseParser\",\n    \"RawRequestMessage\",\n    \"RawResponseMessage\",\n)\n\n_SEP = Literal[b\"\\r\\n\", b\"\\n\"]\n\nASCIISET: Final[Set[str]] = set(string.printable)\n\n# See https://www.rfc-editor.org/rfc/rfc9110.html#name-overview\n# and https://www.rfc-editor.org/rfc/rfc9110.html#name-tokens\n#\n#     method = token\n#     tchar = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\" / \"+\" / \"-\" / \".\" /\n#             \"^\" / \"_\" / \"`\" / \"|\" / \"~\" / DIGIT / ALPHA\n#     token = 1*tchar\n_TCHAR_SPECIALS: Final[str] = re.escape(\"!#$%&'*+-.^_`|~\")\nTOKENRE: Final[Pattern[str]] = re.compile(f\"[0-9A-Za-z{_TCHAR_SPECIALS}]+\")\nVERSRE: Final[Pattern[str]] = re.compile(r\"HTTP/(\\d)\\.(\\d)\", re.ASCII)\nDIGITS: Final[Pattern[str]] = re.compile(r\"\\d+\", re.ASCII)\nHEXDIGITS: Final[Pattern[bytes]] = re.compile(rb\"[0-9a-fA-F]+\")\n\n\nclass RawRequestMessage(NamedTuple):\n    method: str\n    path: str\n    version: HttpVersion\n    headers: CIMultiDictProxy[str]\n    raw_headers: RawHeaders\n    should_close: bool\n    compression: Optional[str]\n    upgrade: bool\n    chunked: bool\n    url: URL\n\n\nclass RawResponseMessage(NamedTuple):\n    version: HttpVersion\n    code: int\n    reason: str\n    headers: CIMultiDictProxy[str]\n    raw_headers: RawHeaders\n    should_close: bool\n    compression: Optional[str]\n    upgrade: bool\n    chunked: bool\n\n\n_MsgT = TypeVar(\"_MsgT\", RawRequestMessage, RawResponseMessage)\n\n\nclass ParseState(IntEnum):\n    PARSE_NONE = 0\n    PARSE_LENGTH = 1\n    PARSE_CHUNKED = 2\n    PARSE_UNTIL_EOF = 3\n\n\nclass ChunkState(IntEnum):\n    PARSE_CHUNKED_SIZE = 0\n    PARSE_CHUNKED_CHUNK = 1\n    PARSE_CHUNKED_CHUNK_EOF = 2\n    PARSE_MAYBE_TRAILERS = 3\n    PARSE_TRAILERS = 4\n\n\nclass HeadersParser:\n    def __init__(\n        self, max_line_size: int = 8190, max_field_size: int = 8190, lax: bool = False\n    ) -> None:\n        self.max_line_size = max_line_size\n        self.max_field_size = max_field_size\n        self._lax = lax\n\n    def parse_headers(\n        self, lines: List[bytes]\n    ) -> Tuple[\"CIMultiDictProxy[str]\", RawHeaders]:\n        headers: CIMultiDict[str] = CIMultiDict()\n        # note: \"raw\" does not mean inclusion of OWS before/after the field value\n        raw_headers = []\n\n        lines_idx = 1\n        line = lines[1]\n        line_count = len(lines)\n\n        while line:\n            # Parse initial header name : value pair.\n            try:\n                bname, bvalue = line.split(b\":\", 1)\n            except ValueError:\n                raise InvalidHeader(line) from None\n\n            if len(bname) == 0:\n                raise InvalidHeader(bname)\n\n            # https://www.rfc-editor.org/rfc/rfc9112.html#section-5.1-2\n            if {bname[0], bname[-1]} & {32, 9}:  # {\" \", \"\\t\"}\n                raise InvalidHeader(line)\n\n            bvalue = bvalue.lstrip(b\" \\t\")\n            if len(bname) > self.max_field_size:\n                raise LineTooLong(\n                    \"request header name {}\".format(\n                        bname.decode(\"utf8\", \"backslashreplace\")\n                    ),\n                    str(self.max_field_size),\n                    str(len(bname)),\n                )\n            name = bname.decode(\"utf-8\", \"surrogateescape\")\n            if not TOKENRE.fullmatch(name):\n                raise InvalidHeader(bname)\n\n            header_length = len(bvalue)\n\n            # next line\n            lines_idx += 1\n            line = lines[lines_idx]\n\n            # consume continuation lines\n            continuation = self._lax and line and line[0] in (32, 9)  # (' ', '\\t')\n\n            # Deprecated: https://www.rfc-editor.org/rfc/rfc9112.html#name-obsolete-line-folding\n            if continuation:\n                bvalue_lst = [bvalue]\n                while continuation:\n                    header_length += len(line)\n                    if header_length > self.max_field_size:\n                        raise LineTooLong(\n                            \"request header field {}\".format(\n                                bname.decode(\"utf8\", \"backslashreplace\")\n                            ),\n                            str(self.max_field_size),\n                            str(header_length),\n                        )\n                    bvalue_lst.append(line)\n\n                    # next line\n                    lines_idx += 1\n                    if lines_idx < line_count:\n                        line = lines[lines_idx]\n                        if line:\n                            continuation = line[0] in (32, 9)  # (' ', '\\t')\n                    else:\n                        line = b\"\"\n                        break\n                bvalue = b\"\".join(bvalue_lst)\n            else:\n                if header_length > self.max_field_size:\n                    raise LineTooLong(\n                        \"request header field {}\".format(\n                            bname.decode(\"utf8\", \"backslashreplace\")\n                        ),\n                        str(self.max_field_size),\n                        str(header_length),\n                    )\n\n            bvalue = bvalue.strip(b\" \\t\")\n            value = bvalue.decode(\"utf-8\", \"surrogateescape\")\n\n            # https://www.rfc-editor.org/rfc/rfc9110.html#section-5.5-5\n            if \"\\n\" in value or \"\\r\" in value or \"\\x00\" in value:\n                raise InvalidHeader(bvalue)\n\n            headers.add(name, value)\n            raw_headers.append((bname, bvalue))\n\n        return (CIMultiDictProxy(headers), tuple(raw_headers))\n\n\ndef _is_supported_upgrade(headers: CIMultiDictProxy[str]) -> bool:\n    \"\"\"Check if the upgrade header is supported.\"\"\"\n    return headers.get(hdrs.UPGRADE, \"\").lower() in {\"tcp\", \"websocket\"}\n\n\nclass HttpParser(abc.ABC, Generic[_MsgT]):\n    lax: ClassVar[bool] = False\n\n    def __init__(\n        self,\n        protocol: BaseProtocol,\n        loop: asyncio.AbstractEventLoop,\n        limit: int,\n        max_line_size: int = 8190,\n        max_field_size: int = 8190,\n        timer: Optional[BaseTimerContext] = None,\n        code: Optional[int] = None,\n        method: Optional[str] = None,\n        payload_exception: Optional[Type[BaseException]] = None,\n        response_with_body: bool = True,\n        read_until_eof: bool = False,\n        auto_decompress: bool = True,\n    ) -> None:\n        self.protocol = protocol\n        self.loop = loop\n        self.max_line_size = max_line_size\n        self.max_field_size = max_field_size\n        self.timer = timer\n        self.code = code\n        self.method = method\n        self.payload_exception = payload_exception\n        self.response_with_body = response_with_body\n        self.read_until_eof = read_until_eof\n\n        self._lines: List[bytes] = []\n        self._tail = b\"\"\n        self._upgraded = False\n        self._payload = None\n        self._payload_parser: Optional[HttpPayloadParser] = None\n        self._auto_decompress = auto_decompress\n        self._limit = limit\n        self._headers_parser = HeadersParser(max_line_size, max_field_size, self.lax)\n\n    @abc.abstractmethod\n    def parse_message(self, lines: List[bytes]) -> _MsgT:\n        pass\n\n    def feed_eof(self) -> Optional[_MsgT]:\n        if self._payload_parser is not None:\n            self._payload_parser.feed_eof()\n            self._payload_parser = None\n        else:\n            # try to extract partial message\n            if self._tail:\n                self._lines.append(self._tail)\n\n            if self._lines:\n                if self._lines[-1] != \"\\r\\n\":\n                    self._lines.append(b\"\")\n                with suppress(Exception):\n                    return self.parse_message(self._lines)\n        return None\n\n    def feed_data(\n        self,\n        data: bytes,\n        SEP: _SEP = b\"\\r\\n\",\n        EMPTY: bytes = b\"\",\n        CONTENT_LENGTH: istr = hdrs.CONTENT_LENGTH,\n        METH_CONNECT: str = hdrs.METH_CONNECT,\n        SEC_WEBSOCKET_KEY1: istr = hdrs.SEC_WEBSOCKET_KEY1,\n    ) -> Tuple[List[Tuple[_MsgT, StreamReader]], bool, bytes]:\n        messages = []\n\n        if self._tail:\n            data, self._tail = self._tail + data, b\"\"\n\n        data_len = len(data)\n        start_pos = 0\n        loop = self.loop\n\n        while start_pos < data_len:\n            # read HTTP message (request/response line + headers), \\r\\n\\r\\n\n            # and split by lines\n            if self._payload_parser is None and not self._upgraded:\n                pos = data.find(SEP, start_pos)\n                # consume \\r\\n\n                if pos == start_pos and not self._lines:\n                    start_pos = pos + len(SEP)\n                    continue\n\n                if pos >= start_pos:\n                    # line found\n                    line = data[start_pos:pos]\n                    if SEP == b\"\\n\":  # For lax response parsing\n                        line = line.rstrip(b\"\\r\")\n                    self._lines.append(line)\n                    start_pos = pos + len(SEP)\n\n                    # \\r\\n\\r\\n found\n                    if self._lines[-1] == EMPTY:\n                        try:\n                            msg: _MsgT = self.parse_message(self._lines)\n                        finally:\n                            self._lines.clear()\n\n                        def get_content_length() -> Optional[int]:\n                            # payload length\n                            length_hdr = msg.headers.get(CONTENT_LENGTH)\n                            if length_hdr is None:\n                                return None\n\n                            # Shouldn't allow +/- or other number formats.\n                            # https://www.rfc-editor.org/rfc/rfc9110#section-8.6-2\n                            # msg.headers is already stripped of leading/trailing wsp\n                            if not DIGITS.fullmatch(length_hdr):\n                                raise InvalidHeader(CONTENT_LENGTH)\n\n                            return int(length_hdr)\n\n                        length = get_content_length()\n                        # do not support old websocket spec\n                        if SEC_WEBSOCKET_KEY1 in msg.headers:\n                            raise InvalidHeader(SEC_WEBSOCKET_KEY1)\n\n                        self._upgraded = msg.upgrade and _is_supported_upgrade(\n                            msg.headers\n                        )\n\n                        method = getattr(msg, \"method\", self.method)\n                        # code is only present on responses\n                        code = getattr(msg, \"code\", 0)\n\n                        assert self.protocol is not None\n                        # calculate payload\n                        empty_body = status_code_must_be_empty_body(code) or bool(\n                            method and method_must_be_empty_body(method)\n                        )\n                        if not empty_body and (\n                            ((length is not None and length > 0) or msg.chunked)\n                            and not self._upgraded\n                        ):\n                            payload = StreamReader(\n                                self.protocol,\n                                timer=self.timer,\n                                loop=loop,\n                                limit=self._limit,\n                            )\n                            payload_parser = HttpPayloadParser(\n                                payload,\n                                length=length,\n                                chunked=msg.chunked,\n                                method=method,\n                                compression=msg.compression,\n                                code=self.code,\n                                response_with_body=self.response_with_body,\n                                auto_decompress=self._auto_decompress,\n                                lax=self.lax,\n                            )\n                            if not payload_parser.done:\n                                self._payload_parser = payload_parser\n                        elif method == METH_CONNECT:\n                            assert isinstance(msg, RawRequestMessage)\n                            payload = StreamReader(\n                                self.protocol,\n                                timer=self.timer,\n                                loop=loop,\n                                limit=self._limit,\n                            )\n                            self._upgraded = True\n                            self._payload_parser = HttpPayloadParser(\n                                payload,\n                                method=msg.method,\n                                compression=msg.compression,\n                                auto_decompress=self._auto_decompress,\n                                lax=self.lax,\n                            )\n                        elif not empty_body and length is None and self.read_until_eof:\n                            payload = StreamReader(\n                                self.protocol,\n                                timer=self.timer,\n                                loop=loop,\n                                limit=self._limit,\n                            )\n                            payload_parser = HttpPayloadParser(\n                                payload,\n                                length=length,\n                                chunked=msg.chunked,\n                                method=method,\n                                compression=msg.compression,\n                                code=self.code,\n                                response_with_body=self.response_with_body,\n                                auto_decompress=self._auto_decompress,\n                                lax=self.lax,\n                            )\n                            if not payload_parser.done:\n                                self._payload_parser = payload_parser\n                        else:\n                            payload = EMPTY_PAYLOAD\n\n                        messages.append((msg, payload))\n                else:\n                    self._tail = data[start_pos:]\n                    data = EMPTY\n                    break\n\n            # no parser, just store\n            elif self._payload_parser is None and self._upgraded:\n                assert not self._lines\n                break\n\n            # feed payload\n            elif data and start_pos < data_len:\n                assert not self._lines\n                assert self._payload_parser is not None\n                try:\n                    eof, data = self._payload_parser.feed_data(data[start_pos:], SEP)\n                except BaseException as underlying_exc:\n                    reraised_exc = underlying_exc\n                    if self.payload_exception is not None:\n                        reraised_exc = self.payload_exception(str(underlying_exc))\n\n                    set_exception(\n                        self._payload_parser.payload,\n                        reraised_exc,\n                        underlying_exc,\n                    )\n\n                    eof = True\n                    data = b\"\"\n\n                if eof:\n                    start_pos = 0\n                    data_len = len(data)\n                    self._payload_parser = None\n                    continue\n            else:\n                break\n\n        if data and start_pos < data_len:\n            data = data[start_pos:]\n        else:\n            data = EMPTY\n\n        return messages, self._upgraded, data\n\n    def parse_headers(\n        self, lines: List[bytes]\n    ) -> Tuple[\n        \"CIMultiDictProxy[str]\", RawHeaders, Optional[bool], Optional[str], bool, bool\n    ]:\n        \"\"\"Parses RFC 5322 headers from a stream.\n\n        Line continuations are supported. Returns list of header name\n        and value pairs. Header name is in upper case.\n        \"\"\"\n        headers, raw_headers = self._headers_parser.parse_headers(lines)\n        close_conn = None\n        encoding = None\n        upgrade = False\n        chunked = False\n\n        # https://www.rfc-editor.org/rfc/rfc9110.html#section-5.5-6\n        # https://www.rfc-editor.org/rfc/rfc9110.html#name-collected-abnf\n        singletons = (\n            hdrs.CONTENT_LENGTH,\n            hdrs.CONTENT_LOCATION,\n            hdrs.CONTENT_RANGE,\n            hdrs.CONTENT_TYPE,\n            hdrs.ETAG,\n            hdrs.HOST,\n            hdrs.MAX_FORWARDS,\n            hdrs.SERVER,\n            hdrs.TRANSFER_ENCODING,\n            hdrs.USER_AGENT,\n        )\n        bad_hdr = next((h for h in singletons if len(headers.getall(h, ())) > 1), None)\n        if bad_hdr is not None:\n            raise BadHttpMessage(f\"Duplicate '{bad_hdr}' header found.\")\n\n        # keep-alive\n        conn = headers.get(hdrs.CONNECTION)\n        if conn:\n            v = conn.lower()\n            if v == \"close\":\n                close_conn = True\n            elif v == \"keep-alive\":\n                close_conn = False\n            # https://www.rfc-editor.org/rfc/rfc9110.html#name-101-switching-protocols\n            elif v == \"upgrade\" and headers.get(hdrs.UPGRADE):\n                upgrade = True\n\n        # encoding\n        enc = headers.get(hdrs.CONTENT_ENCODING)\n        if enc:\n            enc = enc.lower()\n            if enc in (\"gzip\", \"deflate\", \"br\"):\n                encoding = enc\n\n        # chunking\n        te = headers.get(hdrs.TRANSFER_ENCODING)\n        if te is not None:\n            if \"chunked\" == te.lower():\n                chunked = True\n            else:\n                raise BadHttpMessage(\"Request has invalid `Transfer-Encoding`\")\n\n            if hdrs.CONTENT_LENGTH in headers:\n                raise BadHttpMessage(\n                    \"Transfer-Encoding can't be present with Content-Length\",\n                )\n\n        return (headers, raw_headers, close_conn, encoding, upgrade, chunked)\n\n    def set_upgraded(self, val: bool) -> None:\n        \"\"\"Set connection upgraded (to websocket) mode.\n\n        :param bool val: new state.\n        \"\"\"\n        self._upgraded = val\n\n\nclass HttpRequestParser(HttpParser[RawRequestMessage]):\n    \"\"\"Read request status line.\n\n    Exception .http_exceptions.BadStatusLine\n    could be raised in case of any errors in status line.\n    Returns RawRequestMessage.\n    \"\"\"\n\n    def parse_message(self, lines: List[bytes]) -> RawRequestMessage:\n        # request line\n        line = lines[0].decode(\"utf-8\", \"surrogateescape\")\n        try:\n            method, path, version = line.split(\" \", maxsplit=2)\n        except ValueError:\n            raise BadStatusLine(line) from None\n\n        if len(path) > self.max_line_size:\n            raise LineTooLong(\n                \"Status line is too long\", str(self.max_line_size), str(len(path))\n            )\n\n        # method\n        if not TOKENRE.fullmatch(method):\n            raise BadStatusLine(method)\n\n        # version\n        match = VERSRE.fullmatch(version)\n        if match is None:\n            raise BadStatusLine(line)\n        version_o = HttpVersion(int(match.group(1)), int(match.group(2)))\n\n        if method == \"CONNECT\":\n            # authority-form,\n            # https://datatracker.ietf.org/doc/html/rfc7230#section-5.3.3\n            url = URL.build(authority=path, encoded=True)\n        elif path.startswith(\"/\"):\n            # origin-form,\n            # https://datatracker.ietf.org/doc/html/rfc7230#section-5.3.1\n            path_part, _hash_separator, url_fragment = path.partition(\"#\")\n            path_part, _question_mark_separator, qs_part = path_part.partition(\"?\")\n\n            # NOTE: `yarl.URL.build()` is used to mimic what the Cython-based\n            # NOTE: parser does, otherwise it results into the same\n            # NOTE: HTTP Request-Line input producing different\n            # NOTE: `yarl.URL()` objects\n            url = URL.build(\n                path=path_part,\n                query_string=qs_part,\n                fragment=url_fragment,\n                encoded=True,\n            )\n        elif path == \"*\" and method == \"OPTIONS\":\n            # asterisk-form,\n            url = URL(path, encoded=True)\n        else:\n            # absolute-form for proxy maybe,\n            # https://datatracker.ietf.org/doc/html/rfc7230#section-5.3.2\n            url = URL(path, encoded=True)\n            if url.scheme == \"\":\n                # not absolute-form\n                raise InvalidURLError(\n                    path.encode(errors=\"surrogateescape\").decode(\"latin1\")\n                )\n\n        # read headers\n        (\n            headers,\n            raw_headers,\n            close,\n            compression,\n            upgrade,\n            chunked,\n        ) = self.parse_headers(lines)\n\n        if close is None:  # then the headers weren't set in the request\n            if version_o <= HttpVersion10:  # HTTP 1.0 must asks to not close\n                close = True\n            else:  # HTTP 1.1 must ask to close.\n                close = False\n\n        return RawRequestMessage(\n            method,\n            path,\n            version_o,\n            headers,\n            raw_headers,\n            close,\n            compression,\n            upgrade,\n            chunked,\n            url,\n        )\n\n\nclass HttpResponseParser(HttpParser[RawResponseMessage]):\n    \"\"\"Read response status line and headers.\n\n    BadStatusLine could be raised in case of any errors in status line.\n    Returns RawResponseMessage.\n    \"\"\"\n\n    # Lax mode should only be enabled on response parser.\n    lax = not DEBUG\n\n    def feed_data(\n        self,\n        data: bytes,\n        SEP: Optional[_SEP] = None,\n        *args: Any,\n        **kwargs: Any,\n    ) -> Tuple[List[Tuple[RawResponseMessage, StreamReader]], bool, bytes]:\n        if SEP is None:\n            SEP = b\"\\r\\n\" if DEBUG else b\"\\n\"\n        return super().feed_data(data, SEP, *args, **kwargs)\n\n    def parse_message(self, lines: List[bytes]) -> RawResponseMessage:\n        line = lines[0].decode(\"utf-8\", \"surrogateescape\")\n        try:\n            version, status = line.split(maxsplit=1)\n        except ValueError:\n            raise BadStatusLine(line) from None\n\n        try:\n            status, reason = status.split(maxsplit=1)\n        except ValueError:\n            status = status.strip()\n            reason = \"\"\n\n        if len(reason) > self.max_line_size:\n            raise LineTooLong(\n                \"Status line is too long\", str(self.max_line_size), str(len(reason))\n            )\n\n        # version\n        match = VERSRE.fullmatch(version)\n        if match is None:\n            raise BadStatusLine(line)\n        version_o = HttpVersion(int(match.group(1)), int(match.group(2)))\n\n        # The status code is a three-digit ASCII number, no padding\n        if len(status) != 3 or not DIGITS.fullmatch(status):\n            raise BadStatusLine(line)\n        status_i = int(status)\n\n        # read headers\n        (\n            headers,\n            raw_headers,\n            close,\n            compression,\n            upgrade,\n            chunked,\n        ) = self.parse_headers(lines)\n\n        if close is None:\n            if version_o <= HttpVersion10:\n                close = True\n            # https://www.rfc-editor.org/rfc/rfc9112.html#name-message-body-length\n            elif 100 <= status_i < 200 or status_i in {204, 304}:\n                close = False\n            elif hdrs.CONTENT_LENGTH in headers or hdrs.TRANSFER_ENCODING in headers:\n                close = False\n            else:\n                # https://www.rfc-editor.org/rfc/rfc9112.html#section-6.3-2.8\n                close = True\n\n        return RawResponseMessage(\n            version_o,\n            status_i,\n            reason.strip(),\n            headers,\n            raw_headers,\n            close,\n            compression,\n            upgrade,\n            chunked,\n        )\n\n\nclass HttpPayloadParser:\n    def __init__(\n        self,\n        payload: StreamReader,\n        length: Optional[int] = None,\n        chunked: bool = False,\n        compression: Optional[str] = None,\n        code: Optional[int] = None,\n        method: Optional[str] = None,\n        response_with_body: bool = True,\n        auto_decompress: bool = True,\n        lax: bool = False,\n    ) -> None:\n        self._length = 0\n        self._type = ParseState.PARSE_UNTIL_EOF\n        self._chunk = ChunkState.PARSE_CHUNKED_SIZE\n        self._chunk_size = 0\n        self._chunk_tail = b\"\"\n        self._auto_decompress = auto_decompress\n        self._lax = lax\n        self.done = False\n\n        # payload decompression wrapper\n        if response_with_body and compression and self._auto_decompress:\n            real_payload: Union[StreamReader, DeflateBuffer] = DeflateBuffer(\n                payload, compression\n            )\n        else:\n            real_payload = payload\n\n        # payload parser\n        if not response_with_body:\n            # don't parse payload if it's not expected to be received\n            self._type = ParseState.PARSE_NONE\n            real_payload.feed_eof()\n            self.done = True\n        elif chunked:\n            self._type = ParseState.PARSE_CHUNKED\n        elif length is not None:\n            self._type = ParseState.PARSE_LENGTH\n            self._length = length\n            if self._length == 0:\n                real_payload.feed_eof()\n                self.done = True\n\n        self.payload = real_payload\n\n    def feed_eof(self) -> None:\n        if self._type == ParseState.PARSE_UNTIL_EOF:\n            self.payload.feed_eof()\n        elif self._type == ParseState.PARSE_LENGTH:\n            raise ContentLengthError(\n                \"Not enough data for satisfy content length header.\"\n            )\n        elif self._type == ParseState.PARSE_CHUNKED:\n            raise TransferEncodingError(\n                \"Not enough data for satisfy transfer length header.\"\n            )\n\n    def feed_data(\n        self, chunk: bytes, SEP: _SEP = b\"\\r\\n\", CHUNK_EXT: bytes = b\";\"\n    ) -> Tuple[bool, bytes]:\n        # Read specified amount of bytes\n        if self._type == ParseState.PARSE_LENGTH:\n            required = self._length\n            self._length = max(required - len(chunk), 0)\n            self.payload.feed_data(chunk[:required])\n            if self._length == 0:\n                self.payload.feed_eof()\n                return True, chunk[required:]\n\n        # Chunked transfer encoding parser\n        elif self._type == ParseState.PARSE_CHUNKED:\n            if self._chunk_tail:\n                chunk = self._chunk_tail + chunk\n                self._chunk_tail = b\"\"\n\n            while chunk:\n                # read next chunk size\n                if self._chunk == ChunkState.PARSE_CHUNKED_SIZE:\n                    pos = chunk.find(SEP)\n                    if pos >= 0:\n                        i = chunk.find(CHUNK_EXT, 0, pos)\n                        if i >= 0:\n                            size_b = chunk[:i]  # strip chunk-extensions\n                        else:\n                            size_b = chunk[:pos]\n\n                        if self._lax:  # Allow whitespace in lax mode.\n                            size_b = size_b.strip()\n\n                        if not re.fullmatch(HEXDIGITS, size_b):\n                            exc = TransferEncodingError(\n                                chunk[:pos].decode(\"ascii\", \"surrogateescape\")\n                            )\n                            set_exception(self.payload, exc)\n                            raise exc\n                        size = int(bytes(size_b), 16)\n\n                        chunk = chunk[pos + len(SEP) :]\n                        if size == 0:  # eof marker\n                            self._chunk = ChunkState.PARSE_MAYBE_TRAILERS\n                            if self._lax and chunk.startswith(b\"\\r\"):\n                                chunk = chunk[1:]\n                        else:\n                            self._chunk = ChunkState.PARSE_CHUNKED_CHUNK\n                            self._chunk_size = size\n                            self.payload.begin_http_chunk_receiving()\n                    else:\n                        self._chunk_tail = chunk\n                        return False, b\"\"\n\n                # read chunk and feed buffer\n                if self._chunk == ChunkState.PARSE_CHUNKED_CHUNK:\n                    required = self._chunk_size\n                    self._chunk_size = max(required - len(chunk), 0)\n                    self.payload.feed_data(chunk[:required])\n\n                    if self._chunk_size:\n                        return False, b\"\"\n                    chunk = chunk[required:]\n                    if self._lax and chunk.startswith(b\"\\r\"):\n                        chunk = chunk[1:]\n                    self._chunk = ChunkState.PARSE_CHUNKED_CHUNK_EOF\n                    self.payload.end_http_chunk_receiving()\n\n                # toss the CRLF at the end of the chunk\n                if self._chunk == ChunkState.PARSE_CHUNKED_CHUNK_EOF:\n                    if chunk[: len(SEP)] == SEP:\n                        chunk = chunk[len(SEP) :]\n                        self._chunk = ChunkState.PARSE_CHUNKED_SIZE\n                    else:\n                        self._chunk_tail = chunk\n                        return False, b\"\"\n\n                # if stream does not contain trailer, after 0\\r\\n\n                # we should get another \\r\\n otherwise\n                # trailers needs to be skipped until \\r\\n\\r\\n\n                if self._chunk == ChunkState.PARSE_MAYBE_TRAILERS:\n                    head = chunk[: len(SEP)]\n                    if head == SEP:\n                        # end of stream\n                        self.payload.feed_eof()\n                        return True, chunk[len(SEP) :]\n                    # Both CR and LF, or only LF may not be received yet. It is\n                    # expected that CRLF or LF will be shown at the very first\n                    # byte next time, otherwise trailers should come. The last\n                    # CRLF which marks the end of response might not be\n                    # contained in the same TCP segment which delivered the\n                    # size indicator.\n                    if not head:\n                        return False, b\"\"\n                    if head == SEP[:1]:\n                        self._chunk_tail = head\n                        return False, b\"\"\n                    self._chunk = ChunkState.PARSE_TRAILERS\n\n                # read and discard trailer up to the CRLF terminator\n                if self._chunk == ChunkState.PARSE_TRAILERS:\n                    pos = chunk.find(SEP)\n                    if pos >= 0:\n                        chunk = chunk[pos + len(SEP) :]\n                        self._chunk = ChunkState.PARSE_MAYBE_TRAILERS\n                    else:\n                        self._chunk_tail = chunk\n                        return False, b\"\"\n\n        # Read all bytes until eof\n        elif self._type == ParseState.PARSE_UNTIL_EOF:\n            self.payload.feed_data(chunk)\n\n        return False, b\"\"\n\n\nclass DeflateBuffer:\n    \"\"\"DeflateStream decompress stream and feed data into specified stream.\"\"\"\n\n    def __init__(self, out: StreamReader, encoding: Optional[str]) -> None:\n        self.out = out\n        self.size = 0\n        self.encoding = encoding\n        self._started_decoding = False\n\n        self.decompressor: Union[BrotliDecompressor, ZLibDecompressor]\n        if encoding == \"br\":\n            if not HAS_BROTLI:  # pragma: no cover\n                raise ContentEncodingError(\n                    \"Can not decode content-encoding: brotli (br). \"\n                    \"Please install `Brotli`\"\n                )\n            self.decompressor = BrotliDecompressor()\n        else:\n            self.decompressor = ZLibDecompressor(encoding=encoding)\n\n    def set_exception(\n        self,\n        exc: BaseException,\n        exc_cause: BaseException = _EXC_SENTINEL,\n    ) -> None:\n        set_exception(self.out, exc, exc_cause)\n\n    def feed_data(self, chunk: bytes) -> None:\n        if not chunk:\n            return\n\n        self.size += len(chunk)\n\n        # RFC1950\n        # bits 0..3 = CM = 0b1000 = 8 = \"deflate\"\n        # bits 4..7 = CINFO = 1..7 = windows size.\n        if (\n            not self._started_decoding\n            and self.encoding == \"deflate\"\n            and chunk[0] & 0xF != 8\n        ):\n            # Change the decoder to decompress incorrectly compressed data\n            # Actually we should issue a warning about non-RFC-compliant data.\n            self.decompressor = ZLibDecompressor(\n                encoding=self.encoding, suppress_deflate_header=True\n            )\n\n        try:\n            chunk = self.decompressor.decompress_sync(chunk)\n        except Exception:\n            raise ContentEncodingError(\n                \"Can not decode content-encoding: %s\" % self.encoding\n            )\n\n        self._started_decoding = True\n\n        if chunk:\n            self.out.feed_data(chunk)\n\n    def feed_eof(self) -> None:\n        chunk = self.decompressor.flush()\n\n        if chunk or self.size > 0:\n            self.out.feed_data(chunk)\n            # decompressor is not brotli unless encoding is \"br\"\n            if self.encoding == \"deflate\" and not self.decompressor.eof:  # type: ignore[union-attr]\n                raise ContentEncodingError(\"deflate\")\n\n        self.out.feed_eof()\n\n    def begin_http_chunk_receiving(self) -> None:\n        self.out.begin_http_chunk_receiving()\n\n    def end_http_chunk_receiving(self) -> None:\n        self.out.end_http_chunk_receiving()\n\n\nHttpRequestParserPy = HttpRequestParser\nHttpResponseParserPy = HttpResponseParser\nRawRequestMessagePy = RawRequestMessage\nRawResponseMessagePy = RawResponseMessage\n\ntry:\n    if not NO_EXTENSIONS:\n        from ._http_parser import (  # type: ignore[import-not-found,no-redef]\n            HttpRequestParser,\n            HttpResponseParser,\n            RawRequestMessage,\n            RawResponseMessage,\n        )\n\n        HttpRequestParserC = HttpRequestParser\n        HttpResponseParserC = HttpResponseParser\n        RawRequestMessageC = RawRequestMessage\n        RawResponseMessageC = RawResponseMessage\nexcept ImportError:  # pragma: no cover\n    pass\n", "aiohttp/web_exceptions.py": "import warnings\nfrom http import HTTPStatus\nfrom typing import Any, Iterable, Optional, Set, Tuple\n\nfrom multidict import CIMultiDict\nfrom yarl import URL\n\nfrom . import hdrs\nfrom .helpers import CookieMixin\nfrom .typedefs import LooseHeaders, StrOrURL\n\n__all__ = (\n    \"HTTPException\",\n    \"HTTPError\",\n    \"HTTPRedirection\",\n    \"HTTPSuccessful\",\n    \"HTTPOk\",\n    \"HTTPCreated\",\n    \"HTTPAccepted\",\n    \"HTTPNonAuthoritativeInformation\",\n    \"HTTPNoContent\",\n    \"HTTPResetContent\",\n    \"HTTPPartialContent\",\n    \"HTTPMove\",\n    \"HTTPMultipleChoices\",\n    \"HTTPMovedPermanently\",\n    \"HTTPFound\",\n    \"HTTPSeeOther\",\n    \"HTTPNotModified\",\n    \"HTTPUseProxy\",\n    \"HTTPTemporaryRedirect\",\n    \"HTTPPermanentRedirect\",\n    \"HTTPClientError\",\n    \"HTTPBadRequest\",\n    \"HTTPUnauthorized\",\n    \"HTTPPaymentRequired\",\n    \"HTTPForbidden\",\n    \"HTTPNotFound\",\n    \"HTTPMethodNotAllowed\",\n    \"HTTPNotAcceptable\",\n    \"HTTPProxyAuthenticationRequired\",\n    \"HTTPRequestTimeout\",\n    \"HTTPConflict\",\n    \"HTTPGone\",\n    \"HTTPLengthRequired\",\n    \"HTTPPreconditionFailed\",\n    \"HTTPRequestEntityTooLarge\",\n    \"HTTPRequestURITooLong\",\n    \"HTTPUnsupportedMediaType\",\n    \"HTTPRequestRangeNotSatisfiable\",\n    \"HTTPExpectationFailed\",\n    \"HTTPMisdirectedRequest\",\n    \"HTTPUnprocessableEntity\",\n    \"HTTPFailedDependency\",\n    \"HTTPUpgradeRequired\",\n    \"HTTPPreconditionRequired\",\n    \"HTTPTooManyRequests\",\n    \"HTTPRequestHeaderFieldsTooLarge\",\n    \"HTTPUnavailableForLegalReasons\",\n    \"HTTPServerError\",\n    \"HTTPInternalServerError\",\n    \"HTTPNotImplemented\",\n    \"HTTPBadGateway\",\n    \"HTTPServiceUnavailable\",\n    \"HTTPGatewayTimeout\",\n    \"HTTPVersionNotSupported\",\n    \"HTTPVariantAlsoNegotiates\",\n    \"HTTPInsufficientStorage\",\n    \"HTTPNotExtended\",\n    \"HTTPNetworkAuthenticationRequired\",\n)\n\n\nclass NotAppKeyWarning(UserWarning):\n    \"\"\"Warning when not using AppKey in Application.\"\"\"\n\n\n############################################################\n# HTTP Exceptions\n############################################################\n\n\nclass HTTPException(CookieMixin, Exception):\n    # You should set in subclasses:\n    # status = 200\n\n    status_code = -1\n    empty_body = False\n    default_reason = \"\"  # Initialized at the end of the module\n\n    def __init__(\n        self,\n        *,\n        headers: Optional[LooseHeaders] = None,\n        reason: Optional[str] = None,\n        text: Optional[str] = None,\n        content_type: Optional[str] = None,\n    ) -> None:\n        super().__init__()\n        if reason is None:\n            reason = self.default_reason\n\n        if text is None:\n            if not self.empty_body:\n                text = f\"{self.status_code}: {reason}\"\n        else:\n            if self.empty_body:\n                warnings.warn(\n                    \"text argument is deprecated for HTTP status {} \"\n                    \"since 4.0 and scheduled for removal in 5.0 (#3462),\"\n                    \"the response should be provided without a body\".format(\n                        self.status_code\n                    ),\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n\n        if headers is not None:\n            real_headers = CIMultiDict(headers)\n        else:\n            real_headers = CIMultiDict()\n\n        if content_type is not None:\n            if not text:\n                warnings.warn(\n                    \"content_type without text is deprecated \"\n                    \"since 4.0 and scheduled for removal in 5.0 \"\n                    \"(#3462)\",\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n            real_headers[hdrs.CONTENT_TYPE] = content_type\n        elif hdrs.CONTENT_TYPE not in real_headers and text:\n            real_headers[hdrs.CONTENT_TYPE] = \"text/plain\"\n\n        self._reason = reason\n        self._text = text\n        self._headers = real_headers\n        self.args = ()\n\n    def __bool__(self) -> bool:\n        return True\n\n    @property\n    def status(self) -> int:\n        return self.status_code\n\n    @property\n    def reason(self) -> str:\n        return self._reason\n\n    @property\n    def text(self) -> Optional[str]:\n        return self._text\n\n    @property\n    def headers(self) -> \"CIMultiDict[str]\":\n        return self._headers\n\n    def __str__(self) -> str:\n        return self.reason\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__.__name__}: {self.reason}>\"\n\n    __reduce__ = object.__reduce__\n\n    def __getnewargs__(self) -> Tuple[Any, ...]:\n        return self.args\n\n\nclass HTTPError(HTTPException):\n    \"\"\"Base class for exceptions with status codes in the 400s and 500s.\"\"\"\n\n\nclass HTTPRedirection(HTTPException):\n    \"\"\"Base class for exceptions with status codes in the 300s.\"\"\"\n\n\nclass HTTPSuccessful(HTTPException):\n    \"\"\"Base class for exceptions with status codes in the 200s.\"\"\"\n\n\nclass HTTPOk(HTTPSuccessful):\n    status_code = 200\n\n\nclass HTTPCreated(HTTPSuccessful):\n    status_code = 201\n\n\nclass HTTPAccepted(HTTPSuccessful):\n    status_code = 202\n\n\nclass HTTPNonAuthoritativeInformation(HTTPSuccessful):\n    status_code = 203\n\n\nclass HTTPNoContent(HTTPSuccessful):\n    status_code = 204\n    empty_body = True\n\n\nclass HTTPResetContent(HTTPSuccessful):\n    status_code = 205\n    empty_body = True\n\n\nclass HTTPPartialContent(HTTPSuccessful):\n    status_code = 206\n\n\n############################################################\n# 3xx redirection\n############################################################\n\n\nclass HTTPMove(HTTPRedirection):\n    def __init__(\n        self,\n        location: StrOrURL,\n        *,\n        headers: Optional[LooseHeaders] = None,\n        reason: Optional[str] = None,\n        text: Optional[str] = None,\n        content_type: Optional[str] = None,\n    ) -> None:\n        if not location:\n            raise ValueError(\"HTTP redirects need a location to redirect to.\")\n        super().__init__(\n            headers=headers, reason=reason, text=text, content_type=content_type\n        )\n        self._location = URL(location)\n        self.headers[\"Location\"] = str(self.location)\n\n    @property\n    def location(self) -> URL:\n        return self._location\n\n\nclass HTTPMultipleChoices(HTTPMove):\n    status_code = 300\n\n\nclass HTTPMovedPermanently(HTTPMove):\n    status_code = 301\n\n\nclass HTTPFound(HTTPMove):\n    status_code = 302\n\n\n# This one is safe after a POST (the redirected location will be\n# retrieved with GET):\nclass HTTPSeeOther(HTTPMove):\n    status_code = 303\n\n\nclass HTTPNotModified(HTTPRedirection):\n    # FIXME: this should include a date or etag header\n    status_code = 304\n    empty_body = True\n\n\nclass HTTPUseProxy(HTTPMove):\n    # Not a move, but looks a little like one\n    status_code = 305\n\n\nclass HTTPTemporaryRedirect(HTTPMove):\n    status_code = 307\n\n\nclass HTTPPermanentRedirect(HTTPMove):\n    status_code = 308\n\n\n############################################################\n# 4xx client error\n############################################################\n\n\nclass HTTPClientError(HTTPError):\n    pass\n\n\nclass HTTPBadRequest(HTTPClientError):\n    status_code = 400\n\n\nclass HTTPUnauthorized(HTTPClientError):\n    status_code = 401\n\n\nclass HTTPPaymentRequired(HTTPClientError):\n    status_code = 402\n\n\nclass HTTPForbidden(HTTPClientError):\n    status_code = 403\n\n\nclass HTTPNotFound(HTTPClientError):\n    status_code = 404\n\n\nclass HTTPMethodNotAllowed(HTTPClientError):\n    status_code = 405\n\n    def __init__(\n        self,\n        method: str,\n        allowed_methods: Iterable[str],\n        *,\n        headers: Optional[LooseHeaders] = None,\n        reason: Optional[str] = None,\n        text: Optional[str] = None,\n        content_type: Optional[str] = None,\n    ) -> None:\n        allow = \",\".join(sorted(allowed_methods))\n        super().__init__(\n            headers=headers, reason=reason, text=text, content_type=content_type\n        )\n        self.headers[\"Allow\"] = allow\n        self._allowed: Set[str] = set(allowed_methods)\n        self._method = method\n\n    @property\n    def allowed_methods(self) -> Set[str]:\n        return self._allowed\n\n    @property\n    def method(self) -> str:\n        return self._method\n\n\nclass HTTPNotAcceptable(HTTPClientError):\n    status_code = 406\n\n\nclass HTTPProxyAuthenticationRequired(HTTPClientError):\n    status_code = 407\n\n\nclass HTTPRequestTimeout(HTTPClientError):\n    status_code = 408\n\n\nclass HTTPConflict(HTTPClientError):\n    status_code = 409\n\n\nclass HTTPGone(HTTPClientError):\n    status_code = 410\n\n\nclass HTTPLengthRequired(HTTPClientError):\n    status_code = 411\n\n\nclass HTTPPreconditionFailed(HTTPClientError):\n    status_code = 412\n\n\nclass HTTPRequestEntityTooLarge(HTTPClientError):\n    status_code = 413\n\n    def __init__(self, max_size: int, actual_size: int, **kwargs: Any) -> None:\n        kwargs.setdefault(\n            \"text\",\n            \"Maximum request body size {} exceeded, \"\n            \"actual body size {}\".format(max_size, actual_size),\n        )\n        super().__init__(**kwargs)\n\n\nclass HTTPRequestURITooLong(HTTPClientError):\n    status_code = 414\n\n\nclass HTTPUnsupportedMediaType(HTTPClientError):\n    status_code = 415\n\n\nclass HTTPRequestRangeNotSatisfiable(HTTPClientError):\n    status_code = 416\n\n\nclass HTTPExpectationFailed(HTTPClientError):\n    status_code = 417\n\n\nclass HTTPMisdirectedRequest(HTTPClientError):\n    status_code = 421\n\n\nclass HTTPUnprocessableEntity(HTTPClientError):\n    status_code = 422\n\n\nclass HTTPFailedDependency(HTTPClientError):\n    status_code = 424\n\n\nclass HTTPUpgradeRequired(HTTPClientError):\n    status_code = 426\n\n\nclass HTTPPreconditionRequired(HTTPClientError):\n    status_code = 428\n\n\nclass HTTPTooManyRequests(HTTPClientError):\n    status_code = 429\n\n\nclass HTTPRequestHeaderFieldsTooLarge(HTTPClientError):\n    status_code = 431\n\n\nclass HTTPUnavailableForLegalReasons(HTTPClientError):\n    status_code = 451\n\n    def __init__(\n        self,\n        link: Optional[StrOrURL],\n        *,\n        headers: Optional[LooseHeaders] = None,\n        reason: Optional[str] = None,\n        text: Optional[str] = None,\n        content_type: Optional[str] = None,\n    ) -> None:\n        super().__init__(\n            headers=headers, reason=reason, text=text, content_type=content_type\n        )\n        self._link = None\n        if link:\n            self._link = URL(link)\n            self.headers[\"Link\"] = f'<{str(self._link)}>; rel=\"blocked-by\"'\n\n    @property\n    def link(self) -> Optional[URL]:\n        return self._link\n\n\n############################################################\n# 5xx Server Error\n############################################################\n#  Response status codes beginning with the digit \"5\" indicate cases in\n#  which the server is aware that it has erred or is incapable of\n#  performing the request. Except when responding to a HEAD request, the\n#  server SHOULD include an entity containing an explanation of the error\n#  situation, and whether it is a temporary or permanent condition. User\n#  agents SHOULD display any included entity to the user. These response\n#  codes are applicable to any request method.\n\n\nclass HTTPServerError(HTTPError):\n    pass\n\n\nclass HTTPInternalServerError(HTTPServerError):\n    status_code = 500\n\n\nclass HTTPNotImplemented(HTTPServerError):\n    status_code = 501\n\n\nclass HTTPBadGateway(HTTPServerError):\n    status_code = 502\n\n\nclass HTTPServiceUnavailable(HTTPServerError):\n    status_code = 503\n\n\nclass HTTPGatewayTimeout(HTTPServerError):\n    status_code = 504\n\n\nclass HTTPVersionNotSupported(HTTPServerError):\n    status_code = 505\n\n\nclass HTTPVariantAlsoNegotiates(HTTPServerError):\n    status_code = 506\n\n\nclass HTTPInsufficientStorage(HTTPServerError):\n    status_code = 507\n\n\nclass HTTPNotExtended(HTTPServerError):\n    status_code = 510\n\n\nclass HTTPNetworkAuthenticationRequired(HTTPServerError):\n    status_code = 511\n\n\ndef _initialize_default_reason() -> None:\n    for obj in globals().values():\n        if isinstance(obj, type) and issubclass(obj, HTTPException):\n            if obj.status_code >= 0:\n                try:\n                    status = HTTPStatus(obj.status_code)\n                    obj.default_reason = status.phrase\n                except ValueError:\n                    pass\n\n\n_initialize_default_reason()\ndel _initialize_default_reason\n", "aiohttp/web_request.py": "import asyncio\nimport dataclasses\nimport datetime\nimport io\nimport re\nimport socket\nimport string\nimport tempfile\nimport types\nfrom http.cookies import SimpleCookie\nfrom types import MappingProxyType\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Dict,\n    Final,\n    Iterator,\n    Mapping,\n    MutableMapping,\n    Optional,\n    Pattern,\n    Set,\n    Tuple,\n    Union,\n    cast,\n)\nfrom urllib.parse import parse_qsl\n\nfrom multidict import CIMultiDict, CIMultiDictProxy, MultiDict, MultiDictProxy\nfrom yarl import URL\n\nfrom . import hdrs\nfrom .abc import AbstractStreamWriter\nfrom .helpers import (\n    _SENTINEL,\n    ETAG_ANY,\n    LIST_QUOTED_ETAG_RE,\n    ChainMapProxy,\n    ETag,\n    HeadersMixin,\n    is_expected_content_type,\n    parse_http_date,\n    reify,\n    sentinel,\n    set_exception,\n    set_result,\n)\nfrom .http_parser import RawRequestMessage\nfrom .http_writer import HttpVersion\nfrom .multipart import BodyPartReader, MultipartReader\nfrom .streams import EmptyStreamReader, StreamReader\nfrom .typedefs import (\n    DEFAULT_JSON_DECODER,\n    JSONDecoder,\n    LooseHeaders,\n    RawHeaders,\n    StrOrURL,\n)\nfrom .web_exceptions import (\n    HTTPBadRequest,\n    HTTPRequestEntityTooLarge,\n    HTTPUnsupportedMediaType,\n)\nfrom .web_response import StreamResponse\n\n__all__ = (\"BaseRequest\", \"FileField\", \"Request\")\n\n\nif TYPE_CHECKING:\n    from .web_app import Application\n    from .web_protocol import RequestHandler\n    from .web_urldispatcher import UrlMappingMatchInfo\n\n\n@dataclasses.dataclass(frozen=True)\nclass FileField:\n    name: str\n    filename: str\n    file: io.BufferedReader\n    content_type: str\n    headers: \"CIMultiDictProxy[str]\"\n\n\n_TCHAR: Final[str] = string.digits + string.ascii_letters + r\"!#$%&'*+.^_`|~-\"\n# '-' at the end to prevent interpretation as range in a char class\n\n_TOKEN: Final[str] = rf\"[{_TCHAR}]+\"\n\n_QDTEXT: Final[str] = r\"[{}]\".format(\n    r\"\".join(chr(c) for c in (0x09, 0x20, 0x21) + tuple(range(0x23, 0x7F)))\n)\n# qdtext includes 0x5C to escape 0x5D ('\\]')\n# qdtext excludes obs-text (because obsoleted, and encoding not specified)\n\n_QUOTED_PAIR: Final[str] = r\"\\\\[\\t !-~]\"\n\n_QUOTED_STRING: Final[str] = r'\"(?:{quoted_pair}|{qdtext})*\"'.format(\n    qdtext=_QDTEXT, quoted_pair=_QUOTED_PAIR\n)\n\n_FORWARDED_PAIR: Final[str] = (\n    r\"({token})=({token}|{quoted_string})(:\\d{{1,4}})?\".format(\n        token=_TOKEN, quoted_string=_QUOTED_STRING\n    )\n)\n\n_QUOTED_PAIR_REPLACE_RE: Final[Pattern[str]] = re.compile(r\"\\\\([\\t !-~])\")\n# same pattern as _QUOTED_PAIR but contains a capture group\n\n_FORWARDED_PAIR_RE: Final[Pattern[str]] = re.compile(_FORWARDED_PAIR)\n\n############################################################\n# HTTP Request\n############################################################\n\n\nclass BaseRequest(MutableMapping[str, Any], HeadersMixin):\n    POST_METHODS = {\n        hdrs.METH_PATCH,\n        hdrs.METH_POST,\n        hdrs.METH_PUT,\n        hdrs.METH_TRACE,\n        hdrs.METH_DELETE,\n    }\n\n    __slots__ = (\n        \"_message\",\n        \"_protocol\",\n        \"_payload_writer\",\n        \"_payload\",\n        \"_headers\",\n        \"_method\",\n        \"_version\",\n        \"_rel_url\",\n        \"_post\",\n        \"_read_bytes\",\n        \"_state\",\n        \"_cache\",\n        \"_task\",\n        \"_client_max_size\",\n        \"_loop\",\n        \"_transport_sslcontext\",\n        \"_transport_peername\",\n        \"_disconnection_waiters\",\n        \"__weakref__\",\n    )\n\n    def __init__(\n        self,\n        message: RawRequestMessage,\n        payload: StreamReader,\n        protocol: \"RequestHandler\",\n        payload_writer: AbstractStreamWriter,\n        task: \"asyncio.Task[None]\",\n        loop: asyncio.AbstractEventLoop,\n        *,\n        client_max_size: int = 1024**2,\n        state: Optional[Dict[str, Any]] = None,\n        scheme: Optional[str] = None,\n        host: Optional[str] = None,\n        remote: Optional[str] = None,\n    ) -> None:\n        super().__init__()\n        if state is None:\n            state = {}\n        self._message = message\n        self._protocol = protocol\n        self._payload_writer = payload_writer\n\n        self._payload = payload\n        self._headers = message.headers\n        self._method = message.method\n        self._version = message.version\n        self._cache: Dict[str, Any] = {}\n        url = message.url\n        if url.is_absolute():\n            # absolute URL is given,\n            # override auto-calculating url, host, and scheme\n            # all other properties should be good\n            self._cache[\"url\"] = url\n            self._cache[\"host\"] = url.host\n            self._cache[\"scheme\"] = url.scheme\n            self._rel_url = url.relative()\n        else:\n            self._rel_url = message.url\n        self._post: Optional[MultiDictProxy[Union[str, bytes, FileField]]] = None\n        self._read_bytes: Optional[bytes] = None\n\n        self._state = state\n        self._task = task\n        self._client_max_size = client_max_size\n        self._loop = loop\n        self._disconnection_waiters: Set[asyncio.Future[None]] = set()\n\n        transport = self._protocol.transport\n        assert transport is not None\n        self._transport_sslcontext = transport.get_extra_info(\"sslcontext\")\n        self._transport_peername = transport.get_extra_info(\"peername\")\n\n        if scheme is not None:\n            self._cache[\"scheme\"] = scheme\n        if host is not None:\n            self._cache[\"host\"] = host\n        if remote is not None:\n            self._cache[\"remote\"] = remote\n\n    def clone(\n        self,\n        *,\n        method: Union[str, _SENTINEL] = sentinel,\n        rel_url: Union[StrOrURL, _SENTINEL] = sentinel,\n        headers: Union[LooseHeaders, _SENTINEL] = sentinel,\n        scheme: Union[str, _SENTINEL] = sentinel,\n        host: Union[str, _SENTINEL] = sentinel,\n        remote: Union[str, _SENTINEL] = sentinel,\n        client_max_size: Union[int, _SENTINEL] = sentinel,\n    ) -> \"BaseRequest\":\n        \"\"\"Clone itself with replacement some attributes.\n\n        Creates and returns a new instance of Request object. If no parameters\n        are given, an exact copy is returned. If a parameter is not passed, it\n        will reuse the one from the current request object.\n        \"\"\"\n        if self._read_bytes:\n            raise RuntimeError(\"Cannot clone request \" \"after reading its content\")\n\n        dct: Dict[str, Any] = {}\n        if method is not sentinel:\n            dct[\"method\"] = method\n        if rel_url is not sentinel:\n            new_url: URL = URL(rel_url)\n            dct[\"url\"] = new_url\n            dct[\"path\"] = str(new_url)\n        if headers is not sentinel:\n            # a copy semantic\n            new_headers = CIMultiDictProxy(CIMultiDict(headers))\n            dct[\"headers\"] = new_headers\n            dct[\"raw_headers\"] = tuple(\n                (k.encode(\"utf-8\"), v.encode(\"utf-8\")) for k, v in new_headers.items()\n            )\n\n        message = self._message._replace(**dct)\n\n        kwargs: Dict[str, str] = {}\n        if scheme is not sentinel:\n            kwargs[\"scheme\"] = scheme\n        if host is not sentinel:\n            kwargs[\"host\"] = host\n        if remote is not sentinel:\n            kwargs[\"remote\"] = remote\n        if client_max_size is sentinel:\n            client_max_size = self._client_max_size\n\n        return self.__class__(\n            message,\n            self._payload,\n            self._protocol,\n            self._payload_writer,\n            self._task,\n            self._loop,\n            client_max_size=client_max_size,\n            state=self._state.copy(),\n            **kwargs,\n        )\n\n    @property\n    def task(self) -> \"asyncio.Task[None]\":\n        return self._task\n\n    @property\n    def protocol(self) -> \"RequestHandler\":\n        return self._protocol\n\n    @property\n    def transport(self) -> Optional[asyncio.Transport]:\n        if self._protocol is None:\n            return None\n        return self._protocol.transport\n\n    @property\n    def writer(self) -> AbstractStreamWriter:\n        return self._payload_writer\n\n    @property\n    def client_max_size(self) -> int:\n        return self._client_max_size\n\n    @reify\n    def rel_url(self) -> URL:\n        return self._rel_url\n\n    # MutableMapping API\n\n    def __getitem__(self, key: str) -> Any:\n        return self._state[key]\n\n    def __setitem__(self, key: str, value: Any) -> None:\n        self._state[key] = value\n\n    def __delitem__(self, key: str) -> None:\n        del self._state[key]\n\n    def __len__(self) -> int:\n        return len(self._state)\n\n    def __iter__(self) -> Iterator[str]:\n        return iter(self._state)\n\n    ########\n\n    @reify\n    def secure(self) -> bool:\n        \"\"\"A bool indicating if the request is handled with SSL.\"\"\"\n        return self.scheme == \"https\"\n\n    @reify\n    def forwarded(self) -> Tuple[Mapping[str, str], ...]:\n        \"\"\"A tuple containing all parsed Forwarded header(s).\n\n        Makes an effort to parse Forwarded headers as specified by RFC 7239:\n\n        - It adds one (immutable) dictionary per Forwarded 'field-value', ie\n          per proxy. The element corresponds to the data in the Forwarded\n          field-value added by the first proxy encountered by the client. Each\n          subsequent item corresponds to those added by later proxies.\n        - It checks that every value has valid syntax in general as specified\n          in section 4: either a 'token' or a 'quoted-string'.\n        - It un-escapes found escape sequences.\n        - It does NOT validate 'by' and 'for' contents as specified in section\n          6.\n        - It does NOT validate 'host' contents (Host ABNF).\n        - It does NOT validate 'proto' contents for valid URI scheme names.\n\n        Returns a tuple containing one or more immutable dicts\n        \"\"\"\n        elems = []\n        for field_value in self._message.headers.getall(hdrs.FORWARDED, ()):\n            length = len(field_value)\n            pos = 0\n            need_separator = False\n            elem: Dict[str, str] = {}\n            elems.append(types.MappingProxyType(elem))\n            while 0 <= pos < length:\n                match = _FORWARDED_PAIR_RE.match(field_value, pos)\n                if match is not None:  # got a valid forwarded-pair\n                    if need_separator:\n                        # bad syntax here, skip to next comma\n                        pos = field_value.find(\",\", pos)\n                    else:\n                        name, value, port = match.groups()\n                        if value[0] == '\"':\n                            # quoted string: remove quotes and unescape\n                            value = _QUOTED_PAIR_REPLACE_RE.sub(r\"\\1\", value[1:-1])\n                        if port:\n                            value += port\n                        elem[name.lower()] = value\n                        pos += len(match.group(0))\n                        need_separator = True\n                elif field_value[pos] == \",\":  # next forwarded-element\n                    need_separator = False\n                    elem = {}\n                    elems.append(types.MappingProxyType(elem))\n                    pos += 1\n                elif field_value[pos] == \";\":  # next forwarded-pair\n                    need_separator = False\n                    pos += 1\n                elif field_value[pos] in \" \\t\":\n                    # Allow whitespace even between forwarded-pairs, though\n                    # RFC 7239 doesn't. This simplifies code and is in line\n                    # with Postel's law.\n                    pos += 1\n                else:\n                    # bad syntax here, skip to next comma\n                    pos = field_value.find(\",\", pos)\n        return tuple(elems)\n\n    @reify\n    def scheme(self) -> str:\n        \"\"\"A string representing the scheme of the request.\n\n        Hostname is resolved in this order:\n\n        - overridden value by .clone(scheme=new_scheme) call.\n        - type of connection to peer: HTTPS if socket is SSL, HTTP otherwise.\n\n        'http' or 'https'.\n        \"\"\"\n        if self._transport_sslcontext:\n            return \"https\"\n        else:\n            return \"http\"\n\n    @reify\n    def method(self) -> str:\n        \"\"\"Read only property for getting HTTP method.\n\n        The value is upper-cased str like 'GET', 'POST', 'PUT' etc.\n        \"\"\"\n        return self._method\n\n    @reify\n    def version(self) -> HttpVersion:\n        \"\"\"Read only property for getting HTTP version of request.\n\n        Returns aiohttp.protocol.HttpVersion instance.\n        \"\"\"\n        return self._version\n\n    @reify\n    def host(self) -> str:\n        \"\"\"Hostname of the request.\n\n        Hostname is resolved in this order:\n\n        - overridden value by .clone(host=new_host) call.\n        - HOST HTTP header\n        - socket.getfqdn() value\n        \"\"\"\n        host = self._message.headers.get(hdrs.HOST)\n        if host is not None:\n            return host\n        return socket.getfqdn()\n\n    @reify\n    def remote(self) -> Optional[str]:\n        \"\"\"Remote IP of client initiated HTTP request.\n\n        The IP is resolved in this order:\n\n        - overridden value by .clone(remote=new_remote) call.\n        - peername of opened socket\n        \"\"\"\n        if self._transport_peername is None:\n            return None\n        if isinstance(self._transport_peername, (list, tuple)):\n            return str(self._transport_peername[0])\n        return str(self._transport_peername)\n\n    @reify\n    def url(self) -> URL:\n        url = URL.build(scheme=self.scheme, host=self.host)\n        return url.join(self._rel_url)\n\n    @reify\n    def path(self) -> str:\n        \"\"\"The URL including *PATH INFO* without the host or scheme.\n\n        E.g., ``/app/blog``\n        \"\"\"\n        return self._rel_url.path\n\n    @reify\n    def path_qs(self) -> str:\n        \"\"\"The URL including PATH_INFO and the query string.\n\n        E.g, /app/blog?id=10\n        \"\"\"\n        return str(self._rel_url)\n\n    @reify\n    def raw_path(self) -> str:\n        \"\"\"The URL including raw *PATH INFO* without the host or scheme.\n\n        Warning, the path is unquoted and may contains non valid URL characters\n\n        E.g., ``/my%2Fpath%7Cwith%21some%25strange%24characters``\n        \"\"\"\n        return self._message.path\n\n    @reify\n    def query(self) -> MultiDictProxy[str]:\n        \"\"\"A multidict with all the variables in the query string.\"\"\"\n        return MultiDictProxy(self._rel_url.query)\n\n    @reify\n    def query_string(self) -> str:\n        \"\"\"The query string in the URL.\n\n        E.g., id=10\n        \"\"\"\n        return self._rel_url.query_string\n\n    @reify\n    def headers(self) -> \"CIMultiDictProxy[str]\":\n        \"\"\"A case-insensitive multidict proxy with all headers.\"\"\"\n        return self._headers\n\n    @reify\n    def raw_headers(self) -> RawHeaders:\n        \"\"\"A sequence of pairs for all headers.\"\"\"\n        return self._message.raw_headers\n\n    @reify\n    def if_modified_since(self) -> Optional[datetime.datetime]:\n        \"\"\"The value of If-Modified-Since HTTP header, or None.\n\n        This header is represented as a `datetime` object.\n        \"\"\"\n        return parse_http_date(self.headers.get(hdrs.IF_MODIFIED_SINCE))\n\n    @reify\n    def if_unmodified_since(self) -> Optional[datetime.datetime]:\n        \"\"\"The value of If-Unmodified-Since HTTP header, or None.\n\n        This header is represented as a `datetime` object.\n        \"\"\"\n        return parse_http_date(self.headers.get(hdrs.IF_UNMODIFIED_SINCE))\n\n    @staticmethod\n    def _etag_values(etag_header: str) -> Iterator[ETag]:\n        \"\"\"Extract `ETag` objects from raw header.\"\"\"\n        if etag_header == ETAG_ANY:\n            yield ETag(\n                is_weak=False,\n                value=ETAG_ANY,\n            )\n        else:\n            for match in LIST_QUOTED_ETAG_RE.finditer(etag_header):\n                is_weak, value, garbage = match.group(2, 3, 4)\n                # Any symbol captured by 4th group means\n                # that the following sequence is invalid.\n                if garbage:\n                    break\n\n                yield ETag(\n                    is_weak=bool(is_weak),\n                    value=value,\n                )\n\n    @classmethod\n    def _if_match_or_none_impl(\n        cls, header_value: Optional[str]\n    ) -> Optional[Tuple[ETag, ...]]:\n        if not header_value:\n            return None\n\n        return tuple(cls._etag_values(header_value))\n\n    @reify\n    def if_match(self) -> Optional[Tuple[ETag, ...]]:\n        \"\"\"The value of If-Match HTTP header, or None.\n\n        This header is represented as a `tuple` of `ETag` objects.\n        \"\"\"\n        return self._if_match_or_none_impl(self.headers.get(hdrs.IF_MATCH))\n\n    @reify\n    def if_none_match(self) -> Optional[Tuple[ETag, ...]]:\n        \"\"\"The value of If-None-Match HTTP header, or None.\n\n        This header is represented as a `tuple` of `ETag` objects.\n        \"\"\"\n        return self._if_match_or_none_impl(self.headers.get(hdrs.IF_NONE_MATCH))\n\n    @reify\n    def if_range(self) -> Optional[datetime.datetime]:\n        \"\"\"The value of If-Range HTTP header, or None.\n\n        This header is represented as a `datetime` object.\n        \"\"\"\n        return parse_http_date(self.headers.get(hdrs.IF_RANGE))\n\n    @reify\n    def keep_alive(self) -> bool:\n        \"\"\"Is keepalive enabled by client?\"\"\"\n        return not self._message.should_close\n\n    @reify\n    def cookies(self) -> Mapping[str, str]:\n        \"\"\"Return request cookies.\n\n        A read-only dictionary-like object.\n        \"\"\"\n        raw = self.headers.get(hdrs.COOKIE, \"\")\n        parsed = SimpleCookie(raw)\n        return MappingProxyType({key: val.value for key, val in parsed.items()})\n\n    @reify\n    def http_range(self) -> slice:\n        \"\"\"The content of Range HTTP header.\n\n        Return a slice instance.\n\n        \"\"\"\n        rng = self._headers.get(hdrs.RANGE)\n        start, end = None, None\n        if rng is not None:\n            try:\n                pattern = r\"^bytes=(\\d*)-(\\d*)$\"\n                start, end = re.findall(pattern, rng)[0]\n            except IndexError:  # pattern was not found in header\n                raise ValueError(\"range not in acceptable format\")\n\n            end = int(end) if end else None\n            start = int(start) if start else None\n\n            if start is None and end is not None:\n                # end with no start is to return tail of content\n                start = -end\n                end = None\n\n            if start is not None and end is not None:\n                # end is inclusive in range header, exclusive for slice\n                end += 1\n\n                if start >= end:\n                    raise ValueError(\"start cannot be after end\")\n\n            if start is end is None:  # No valid range supplied\n                raise ValueError(\"No start or end of range specified\")\n\n        return slice(start, end, 1)\n\n    @reify\n    def content(self) -> StreamReader:\n        \"\"\"Return raw payload stream.\"\"\"\n        return self._payload\n\n    @property\n    def can_read_body(self) -> bool:\n        \"\"\"Return True if request's HTTP BODY can be read, False otherwise.\"\"\"\n        return not self._payload.at_eof()\n\n    @reify\n    def body_exists(self) -> bool:\n        \"\"\"Return True if request has HTTP BODY, False otherwise.\"\"\"\n        return type(self._payload) is not EmptyStreamReader\n\n    async def release(self) -> None:\n        \"\"\"Release request.\n\n        Eat unread part of HTTP BODY if present.\n        \"\"\"\n        while not self._payload.at_eof():\n            await self._payload.readany()\n\n    async def read(self) -> bytes:\n        \"\"\"Read request body if present.\n\n        Returns bytes object with full request content.\n        \"\"\"\n        if self._read_bytes is None:\n            body = bytearray()\n            while True:\n                chunk = await self._payload.readany()\n                body.extend(chunk)\n                if self._client_max_size:\n                    body_size = len(body)\n                    if body_size > self._client_max_size:\n                        raise HTTPRequestEntityTooLarge(\n                            max_size=self._client_max_size, actual_size=body_size\n                        )\n                if not chunk:\n                    break\n            self._read_bytes = bytes(body)\n        return self._read_bytes\n\n    async def text(self) -> str:\n        \"\"\"Return BODY as text using encoding from .charset.\"\"\"\n        bytes_body = await self.read()\n        encoding = self.charset or \"utf-8\"\n        try:\n            return bytes_body.decode(encoding)\n        except LookupError:\n            raise HTTPUnsupportedMediaType()\n\n    async def json(\n        self,\n        *,\n        loads: JSONDecoder = DEFAULT_JSON_DECODER,\n        content_type: Optional[str] = \"application/json\",\n    ) -> Any:\n        \"\"\"Return BODY as JSON.\"\"\"\n        body = await self.text()\n        if content_type:\n            if not is_expected_content_type(self.content_type, content_type):\n                raise HTTPBadRequest(\n                    text=(\n                        \"Attempt to decode JSON with \"\n                        \"unexpected mimetype: %s\" % self.content_type\n                    )\n                )\n\n        return loads(body)\n\n    async def multipart(self) -> MultipartReader:\n        \"\"\"Return async iterator to process BODY as multipart.\"\"\"\n        return MultipartReader(self._headers, self._payload)\n\n    async def post(self) -> \"MultiDictProxy[Union[str, bytes, FileField]]\":\n        \"\"\"Return POST parameters.\"\"\"\n        if self._post is not None:\n            return self._post\n        if self._method not in self.POST_METHODS:\n            self._post = MultiDictProxy(MultiDict())\n            return self._post\n\n        content_type = self.content_type\n        if content_type not in (\n            \"\",\n            \"application/x-www-form-urlencoded\",\n            \"multipart/form-data\",\n        ):\n            self._post = MultiDictProxy(MultiDict())\n            return self._post\n\n        out: MultiDict[Union[str, bytes, FileField]] = MultiDict()\n\n        if content_type == \"multipart/form-data\":\n            multipart = await self.multipart()\n            max_size = self._client_max_size\n\n            field = await multipart.next()\n            while field is not None:\n                size = 0\n                field_ct = field.headers.get(hdrs.CONTENT_TYPE)\n\n                if isinstance(field, BodyPartReader):\n                    assert field.name is not None\n\n                    # Note that according to RFC 7578, the Content-Type header\n                    # is optional, even for files, so we can't assume it's\n                    # present.\n                    # https://tools.ietf.org/html/rfc7578#section-4.4\n                    if field.filename:\n                        # store file in temp file\n                        tmp = await self._loop.run_in_executor(\n                            None, tempfile.TemporaryFile\n                        )\n                        chunk = await field.read_chunk(size=2**16)\n                        while chunk:\n                            chunk = field.decode(chunk)\n                            await self._loop.run_in_executor(None, tmp.write, chunk)\n                            size += len(chunk)\n                            if 0 < max_size < size:\n                                await self._loop.run_in_executor(None, tmp.close)\n                                raise HTTPRequestEntityTooLarge(\n                                    max_size=max_size, actual_size=size\n                                )\n                            chunk = await field.read_chunk(size=2**16)\n                        await self._loop.run_in_executor(None, tmp.seek, 0)\n\n                        if field_ct is None:\n                            field_ct = \"application/octet-stream\"\n\n                        ff = FileField(\n                            field.name,\n                            field.filename,\n                            cast(io.BufferedReader, tmp),\n                            field_ct,\n                            field.headers,\n                        )\n                        out.add(field.name, ff)\n                    else:\n                        # deal with ordinary data\n                        value = await field.read(decode=True)\n                        if field_ct is None or field_ct.startswith(\"text/\"):\n                            charset = field.get_charset(default=\"utf-8\")\n                            out.add(field.name, value.decode(charset))\n                        else:\n                            out.add(field.name, value)\n                        size += len(value)\n                        if 0 < max_size < size:\n                            raise HTTPRequestEntityTooLarge(\n                                max_size=max_size, actual_size=size\n                            )\n                else:\n                    raise ValueError(\n                        \"To decode nested multipart you need \" \"to use custom reader\",\n                    )\n\n                field = await multipart.next()\n        else:\n            data = await self.read()\n            if data:\n                charset = self.charset or \"utf-8\"\n                bytes_query = data.rstrip()\n                try:\n                    query = bytes_query.decode(charset)\n                except LookupError:\n                    raise HTTPUnsupportedMediaType()\n                out.extend(\n                    parse_qsl(qs=query, keep_blank_values=True, encoding=charset)\n                )\n\n        self._post = MultiDictProxy(out)\n        return self._post\n\n    def get_extra_info(self, name: str, default: Any = None) -> Any:\n        \"\"\"Extra info from protocol transport\"\"\"\n        protocol = self._protocol\n        if protocol is None:\n            return default\n\n        transport = protocol.transport\n        if transport is None:\n            return default\n\n        return transport.get_extra_info(name, default)\n\n    def __repr__(self) -> str:\n        ascii_encodable_path = self.path.encode(\"ascii\", \"backslashreplace\").decode(\n            \"ascii\"\n        )\n        return \"<{} {} {} >\".format(\n            self.__class__.__name__, self._method, ascii_encodable_path\n        )\n\n    def __eq__(self, other: object) -> bool:\n        return id(self) == id(other)\n\n    def __bool__(self) -> bool:\n        return True\n\n    async def _prepare_hook(self, response: StreamResponse) -> None:\n        return\n\n    def _cancel(self, exc: BaseException) -> None:\n        set_exception(self._payload, exc)\n        for fut in self._disconnection_waiters:\n            set_result(fut, None)\n\n    def _finish(self) -> None:\n        for fut in self._disconnection_waiters:\n            fut.cancel()\n\n        if self._post is None or self.content_type != \"multipart/form-data\":\n            return\n\n        # NOTE: Release file descriptors for the\n        # NOTE: `tempfile.Temporaryfile`-created `_io.BufferedRandom`\n        # NOTE: instances of files sent within multipart request body\n        # NOTE: via HTTP POST request.\n        for file_name, file_field_object in self._post.items():\n            if not isinstance(file_field_object, FileField):\n                continue\n\n            file_field_object.file.close()\n\n    async def wait_for_disconnection(self) -> None:\n        loop = asyncio.get_event_loop()\n        fut: asyncio.Future[None] = loop.create_future()\n        self._disconnection_waiters.add(fut)\n        try:\n            await fut\n        finally:\n            self._disconnection_waiters.remove(fut)\n\n\nclass Request(BaseRequest):\n    __slots__ = (\"_match_info\",)\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        super().__init__(*args, **kwargs)\n\n        # matchdict, route_name, handler\n        # or information about traversal lookup\n\n        # initialized after route resolving\n        self._match_info: Optional[UrlMappingMatchInfo] = None\n\n    def clone(\n        self,\n        *,\n        method: Union[str, _SENTINEL] = sentinel,\n        rel_url: Union[StrOrURL, _SENTINEL] = sentinel,\n        headers: Union[LooseHeaders, _SENTINEL] = sentinel,\n        scheme: Union[str, _SENTINEL] = sentinel,\n        host: Union[str, _SENTINEL] = sentinel,\n        remote: Union[str, _SENTINEL] = sentinel,\n        client_max_size: Union[int, _SENTINEL] = sentinel,\n    ) -> \"Request\":\n        ret = super().clone(\n            method=method,\n            rel_url=rel_url,\n            headers=headers,\n            scheme=scheme,\n            host=host,\n            remote=remote,\n            client_max_size=client_max_size,\n        )\n        new_ret = cast(Request, ret)\n        new_ret._match_info = self._match_info\n        return new_ret\n\n    @reify\n    def match_info(self) -> \"UrlMappingMatchInfo\":\n        \"\"\"Result of route resolving.\"\"\"\n        match_info = self._match_info\n        assert match_info is not None\n        return match_info\n\n    @property\n    def app(self) -> \"Application\":\n        \"\"\"Application instance.\"\"\"\n        match_info = self._match_info\n        assert match_info is not None\n        return match_info.current_app\n\n    @property\n    def config_dict(self) -> ChainMapProxy:\n        match_info = self._match_info\n        assert match_info is not None\n        lst = match_info.apps\n        app = self.app\n        idx = lst.index(app)\n        sublist = list(reversed(lst[: idx + 1]))\n        return ChainMapProxy(sublist)\n\n    async def _prepare_hook(self, response: StreamResponse) -> None:\n        match_info = self._match_info\n        if match_info is None:\n            return\n        for app in match_info._apps:\n            await app.on_response_prepare.send(self, response)\n", "aiohttp/http_websocket.py": "\"\"\"WebSocket protocol versions 13 and 8.\"\"\"\n\nimport asyncio\nimport functools\nimport json\nimport random\nimport re\nimport sys\nimport zlib\nfrom enum import IntEnum\nfrom struct import Struct\nfrom typing import (\n    Any,\n    Callable,\n    Final,\n    List,\n    NamedTuple,\n    Optional,\n    Pattern,\n    Set,\n    Tuple,\n    Union,\n    cast,\n)\n\nfrom .base_protocol import BaseProtocol\nfrom .compression_utils import ZLibCompressor, ZLibDecompressor\nfrom .helpers import NO_EXTENSIONS, set_exception\nfrom .streams import DataQueue\n\n__all__ = (\n    \"WS_CLOSED_MESSAGE\",\n    \"WS_CLOSING_MESSAGE\",\n    \"WS_KEY\",\n    \"WebSocketReader\",\n    \"WebSocketWriter\",\n    \"WSMessage\",\n    \"WebSocketError\",\n    \"WSMsgType\",\n    \"WSCloseCode\",\n)\n\n\nclass WSCloseCode(IntEnum):\n    OK = 1000\n    GOING_AWAY = 1001\n    PROTOCOL_ERROR = 1002\n    UNSUPPORTED_DATA = 1003\n    ABNORMAL_CLOSURE = 1006\n    INVALID_TEXT = 1007\n    POLICY_VIOLATION = 1008\n    MESSAGE_TOO_BIG = 1009\n    MANDATORY_EXTENSION = 1010\n    INTERNAL_ERROR = 1011\n    SERVICE_RESTART = 1012\n    TRY_AGAIN_LATER = 1013\n    BAD_GATEWAY = 1014\n\n\nALLOWED_CLOSE_CODES: Final[Set[int]] = {int(i) for i in WSCloseCode}\n\n# For websockets, keeping latency low is extremely important as implementations\n# generally expect to be able to send and receive messages quickly.  We use a\n# larger chunk size than the default to reduce the number of executor calls\n# since the executor is a significant source of latency and overhead when\n# the chunks are small. A size of 5KiB was chosen because it is also the\n# same value python-zlib-ng choose to use as the threshold to release the GIL.\n\nWEBSOCKET_MAX_SYNC_CHUNK_SIZE = 5 * 1024\n\n\nclass WSMsgType(IntEnum):\n    # websocket spec types\n    CONTINUATION = 0x0\n    TEXT = 0x1\n    BINARY = 0x2\n    PING = 0x9\n    PONG = 0xA\n    CLOSE = 0x8\n\n    # aiohttp specific types\n    CLOSING = 0x100\n    CLOSED = 0x101\n    ERROR = 0x102\n\n\nWS_KEY: Final[bytes] = b\"258EAFA5-E914-47DA-95CA-C5AB0DC85B11\"\n\n\nUNPACK_LEN2 = Struct(\"!H\").unpack_from\nUNPACK_LEN3 = Struct(\"!Q\").unpack_from\nUNPACK_CLOSE_CODE = Struct(\"!H\").unpack\nPACK_LEN1 = Struct(\"!BB\").pack\nPACK_LEN2 = Struct(\"!BBH\").pack\nPACK_LEN3 = Struct(\"!BBQ\").pack\nPACK_CLOSE_CODE = Struct(\"!H\").pack\nMSG_SIZE: Final[int] = 2**14\nDEFAULT_LIMIT: Final[int] = 2**16\n\n\nclass WSMessage(NamedTuple):\n    type: WSMsgType\n    # To type correctly, this would need some kind of tagged union for each type.\n    data: Any\n    extra: Optional[str]\n\n    def json(self, *, loads: Callable[[Any], Any] = json.loads) -> Any:\n        \"\"\"Return parsed JSON data.\n\n        .. versionadded:: 0.22\n        \"\"\"\n        return loads(self.data)\n\n\nWS_CLOSED_MESSAGE = WSMessage(WSMsgType.CLOSED, None, None)\nWS_CLOSING_MESSAGE = WSMessage(WSMsgType.CLOSING, None, None)\n\n\nclass WebSocketError(Exception):\n    \"\"\"WebSocket protocol parser error.\"\"\"\n\n    def __init__(self, code: int, message: str) -> None:\n        self.code = code\n        super().__init__(code, message)\n\n    def __str__(self) -> str:\n        return cast(str, self.args[1])\n\n\nclass WSHandshakeError(Exception):\n    \"\"\"WebSocket protocol handshake error.\"\"\"\n\n\nnative_byteorder: Final[str] = sys.byteorder\n\n\n# Used by _websocket_mask_python\n@functools.lru_cache\ndef _xor_table() -> List[bytes]:\n    return [bytes(a ^ b for a in range(256)) for b in range(256)]\n\n\ndef _websocket_mask_python(mask: bytes, data: bytearray) -> None:\n    \"\"\"Websocket masking function.\n\n    `mask` is a `bytes` object of length 4; `data` is a `bytearray`\n    object of any length. The contents of `data` are masked with `mask`,\n    as specified in section 5.3 of RFC 6455.\n\n    Note that this function mutates the `data` argument.\n\n    This pure-python implementation may be replaced by an optimized\n    version when available.\n\n    \"\"\"\n    assert isinstance(data, bytearray), data\n    assert len(mask) == 4, mask\n\n    if data:\n        _XOR_TABLE = _xor_table()\n        a, b, c, d = (_XOR_TABLE[n] for n in mask)\n        data[::4] = data[::4].translate(a)\n        data[1::4] = data[1::4].translate(b)\n        data[2::4] = data[2::4].translate(c)\n        data[3::4] = data[3::4].translate(d)\n\n\nif NO_EXTENSIONS:  # pragma: no cover\n    _websocket_mask = _websocket_mask_python\nelse:\n    try:\n        from ._websocket import _websocket_mask_cython  # type: ignore[import-not-found]\n\n        _websocket_mask = _websocket_mask_cython\n    except ImportError:  # pragma: no cover\n        _websocket_mask = _websocket_mask_python\n\n_WS_DEFLATE_TRAILING: Final[bytes] = bytes([0x00, 0x00, 0xFF, 0xFF])\n\n\n_WS_EXT_RE: Final[Pattern[str]] = re.compile(\n    r\"^(?:;\\s*(?:\"\n    r\"(server_no_context_takeover)|\"\n    r\"(client_no_context_takeover)|\"\n    r\"(server_max_window_bits(?:=(\\d+))?)|\"\n    r\"(client_max_window_bits(?:=(\\d+))?)))*$\"\n)\n\n_WS_EXT_RE_SPLIT: Final[Pattern[str]] = re.compile(r\"permessage-deflate([^,]+)?\")\n\n\ndef ws_ext_parse(extstr: Optional[str], isserver: bool = False) -> Tuple[int, bool]:\n    if not extstr:\n        return 0, False\n\n    compress = 0\n    notakeover = False\n    for ext in _WS_EXT_RE_SPLIT.finditer(extstr):\n        defext = ext.group(1)\n        # Return compress = 15 when get `permessage-deflate`\n        if not defext:\n            compress = 15\n            break\n        match = _WS_EXT_RE.match(defext)\n        if match:\n            compress = 15\n            if isserver:\n                # Server never fail to detect compress handshake.\n                # Server does not need to send max wbit to client\n                if match.group(4):\n                    compress = int(match.group(4))\n                    # Group3 must match if group4 matches\n                    # Compress wbit 8 does not support in zlib\n                    # If compress level not support,\n                    # CONTINUE to next extension\n                    if compress > 15 or compress < 9:\n                        compress = 0\n                        continue\n                if match.group(1):\n                    notakeover = True\n                # Ignore regex group 5 & 6 for client_max_window_bits\n                break\n            else:\n                if match.group(6):\n                    compress = int(match.group(6))\n                    # Group5 must match if group6 matches\n                    # Compress wbit 8 does not support in zlib\n                    # If compress level not support,\n                    # FAIL the parse progress\n                    if compress > 15 or compress < 9:\n                        raise WSHandshakeError(\"Invalid window size\")\n                if match.group(2):\n                    notakeover = True\n                # Ignore regex group 5 & 6 for client_max_window_bits\n                break\n        # Return Fail if client side and not match\n        elif not isserver:\n            raise WSHandshakeError(\"Extension for deflate not supported\" + ext.group(1))\n\n    return compress, notakeover\n\n\ndef ws_ext_gen(\n    compress: int = 15, isserver: bool = False, server_notakeover: bool = False\n) -> str:\n    # client_notakeover=False not used for server\n    # compress wbit 8 does not support in zlib\n    if compress < 9 or compress > 15:\n        raise ValueError(\n            \"Compress wbits must between 9 and 15, \" \"zlib does not support wbits=8\"\n        )\n    enabledext = [\"permessage-deflate\"]\n    if not isserver:\n        enabledext.append(\"client_max_window_bits\")\n\n    if compress < 15:\n        enabledext.append(\"server_max_window_bits=\" + str(compress))\n    if server_notakeover:\n        enabledext.append(\"server_no_context_takeover\")\n    # if client_notakeover:\n    #     enabledext.append('client_no_context_takeover')\n    return \"; \".join(enabledext)\n\n\nclass WSParserState(IntEnum):\n    READ_HEADER = 1\n    READ_PAYLOAD_LENGTH = 2\n    READ_PAYLOAD_MASK = 3\n    READ_PAYLOAD = 4\n\n\nclass WebSocketReader:\n    def __init__(\n        self, queue: DataQueue[WSMessage], max_msg_size: int, compress: bool = True\n    ) -> None:\n        self.queue = queue\n        self._max_msg_size = max_msg_size\n\n        self._exc: Optional[BaseException] = None\n        self._partial = bytearray()\n        self._state = WSParserState.READ_HEADER\n\n        self._opcode: Optional[int] = None\n        self._frame_fin = False\n        self._frame_opcode: Optional[int] = None\n        self._frame_payload = bytearray()\n\n        self._tail = b\"\"\n        self._has_mask = False\n        self._frame_mask: Optional[bytes] = None\n        self._payload_length = 0\n        self._payload_length_flag = 0\n        self._compressed: Optional[bool] = None\n        self._decompressobj: Optional[ZLibDecompressor] = None\n        self._compress = compress\n\n    def feed_eof(self) -> None:\n        self.queue.feed_eof()\n\n    def feed_data(self, data: bytes) -> Tuple[bool, bytes]:\n        if self._exc:\n            return True, data\n\n        try:\n            return self._feed_data(data)\n        except Exception as exc:\n            self._exc = exc\n            set_exception(self.queue, exc)\n            return True, b\"\"\n\n    def _feed_data(self, data: bytes) -> Tuple[bool, bytes]:\n        for fin, opcode, payload, compressed in self.parse_frame(data):\n            if compressed and not self._decompressobj:\n                self._decompressobj = ZLibDecompressor(suppress_deflate_header=True)\n            if opcode == WSMsgType.CLOSE:\n                if len(payload) >= 2:\n                    close_code = UNPACK_CLOSE_CODE(payload[:2])[0]\n                    if close_code < 3000 and close_code not in ALLOWED_CLOSE_CODES:\n                        raise WebSocketError(\n                            WSCloseCode.PROTOCOL_ERROR,\n                            f\"Invalid close code: {close_code}\",\n                        )\n                    try:\n                        close_message = payload[2:].decode(\"utf-8\")\n                    except UnicodeDecodeError as exc:\n                        raise WebSocketError(\n                            WSCloseCode.INVALID_TEXT, \"Invalid UTF-8 text message\"\n                        ) from exc\n                    msg = WSMessage(WSMsgType.CLOSE, close_code, close_message)\n                elif payload:\n                    raise WebSocketError(\n                        WSCloseCode.PROTOCOL_ERROR,\n                        f\"Invalid close frame: {fin} {opcode} {payload!r}\",\n                    )\n                else:\n                    msg = WSMessage(WSMsgType.CLOSE, 0, \"\")\n\n                self.queue.feed_data(msg)\n\n            elif opcode == WSMsgType.PING:\n                self.queue.feed_data(WSMessage(WSMsgType.PING, payload, \"\"))\n\n            elif opcode == WSMsgType.PONG:\n                self.queue.feed_data(WSMessage(WSMsgType.PONG, payload, \"\"))\n\n            elif (\n                opcode not in (WSMsgType.TEXT, WSMsgType.BINARY)\n                and self._opcode is None\n            ):\n                raise WebSocketError(\n                    WSCloseCode.PROTOCOL_ERROR, f\"Unexpected opcode={opcode!r}\"\n                )\n            else:\n                # load text/binary\n                if not fin:\n                    # got partial frame payload\n                    if opcode != WSMsgType.CONTINUATION:\n                        self._opcode = opcode\n                    self._partial.extend(payload)\n                    if self._max_msg_size and len(self._partial) >= self._max_msg_size:\n                        raise WebSocketError(\n                            WSCloseCode.MESSAGE_TOO_BIG,\n                            \"Message size {} exceeds limit {}\".format(\n                                len(self._partial), self._max_msg_size\n                            ),\n                        )\n                else:\n                    # previous frame was non finished\n                    # we should get continuation opcode\n                    if self._partial:\n                        if opcode != WSMsgType.CONTINUATION:\n                            raise WebSocketError(\n                                WSCloseCode.PROTOCOL_ERROR,\n                                \"The opcode in non-fin frame is expected \"\n                                \"to be zero, got {!r}\".format(opcode),\n                            )\n\n                    if opcode == WSMsgType.CONTINUATION:\n                        assert self._opcode is not None\n                        opcode = self._opcode\n                        self._opcode = None\n\n                    self._partial.extend(payload)\n                    if self._max_msg_size and len(self._partial) >= self._max_msg_size:\n                        raise WebSocketError(\n                            WSCloseCode.MESSAGE_TOO_BIG,\n                            \"Message size {} exceeds limit {}\".format(\n                                len(self._partial), self._max_msg_size\n                            ),\n                        )\n\n                    # Decompress process must to be done after all packets\n                    # received.\n                    if compressed:\n                        assert self._decompressobj is not None\n                        self._partial.extend(_WS_DEFLATE_TRAILING)\n                        payload_merged = self._decompressobj.decompress_sync(\n                            self._partial, self._max_msg_size\n                        )\n                        if self._decompressobj.unconsumed_tail:\n                            left = len(self._decompressobj.unconsumed_tail)\n                            raise WebSocketError(\n                                WSCloseCode.MESSAGE_TOO_BIG,\n                                \"Decompressed message size {} exceeds limit {}\".format(\n                                    self._max_msg_size + left, self._max_msg_size\n                                ),\n                            )\n                    else:\n                        payload_merged = bytes(self._partial)\n\n                    self._partial.clear()\n\n                    if opcode == WSMsgType.TEXT:\n                        try:\n                            text = payload_merged.decode(\"utf-8\")\n                            self.queue.feed_data(WSMessage(WSMsgType.TEXT, text, \"\"))\n                        except UnicodeDecodeError as exc:\n                            raise WebSocketError(\n                                WSCloseCode.INVALID_TEXT, \"Invalid UTF-8 text message\"\n                            ) from exc\n                    else:\n                        self.queue.feed_data(\n                            WSMessage(WSMsgType.BINARY, payload_merged, \"\"),\n                        )\n\n        return False, b\"\"\n\n    def parse_frame(\n        self, buf: bytes\n    ) -> List[Tuple[bool, Optional[int], bytearray, Optional[bool]]]:\n        \"\"\"Return the next frame from the socket.\"\"\"\n        frames = []\n        if self._tail:\n            buf, self._tail = self._tail + buf, b\"\"\n\n        start_pos = 0\n        buf_length = len(buf)\n\n        while True:\n            # read header\n            if self._state == WSParserState.READ_HEADER:\n                if buf_length - start_pos >= 2:\n                    data = buf[start_pos : start_pos + 2]\n                    start_pos += 2\n                    first_byte, second_byte = data\n\n                    fin = (first_byte >> 7) & 1\n                    rsv1 = (first_byte >> 6) & 1\n                    rsv2 = (first_byte >> 5) & 1\n                    rsv3 = (first_byte >> 4) & 1\n                    opcode = first_byte & 0xF\n\n                    # frame-fin = %x0 ; more frames of this message follow\n                    #           / %x1 ; final frame of this message\n                    # frame-rsv1 = %x0 ;\n                    #    1 bit, MUST be 0 unless negotiated otherwise\n                    # frame-rsv2 = %x0 ;\n                    #    1 bit, MUST be 0 unless negotiated otherwise\n                    # frame-rsv3 = %x0 ;\n                    #    1 bit, MUST be 0 unless negotiated otherwise\n                    #\n                    # Remove rsv1 from this test for deflate development\n                    if rsv2 or rsv3 or (rsv1 and not self._compress):\n                        raise WebSocketError(\n                            WSCloseCode.PROTOCOL_ERROR,\n                            \"Received frame with non-zero reserved bits\",\n                        )\n\n                    if opcode > 0x7 and fin == 0:\n                        raise WebSocketError(\n                            WSCloseCode.PROTOCOL_ERROR,\n                            \"Received fragmented control frame\",\n                        )\n\n                    has_mask = (second_byte >> 7) & 1\n                    length = second_byte & 0x7F\n\n                    # Control frames MUST have a payload\n                    # length of 125 bytes or less\n                    if opcode > 0x7 and length > 125:\n                        raise WebSocketError(\n                            WSCloseCode.PROTOCOL_ERROR,\n                            \"Control frame payload cannot be \" \"larger than 125 bytes\",\n                        )\n\n                    # Set compress status if last package is FIN\n                    # OR set compress status if this is first fragment\n                    # Raise error if not first fragment with rsv1 = 0x1\n                    if self._frame_fin or self._compressed is None:\n                        self._compressed = True if rsv1 else False\n                    elif rsv1:\n                        raise WebSocketError(\n                            WSCloseCode.PROTOCOL_ERROR,\n                            \"Received frame with non-zero reserved bits\",\n                        )\n\n                    self._frame_fin = bool(fin)\n                    self._frame_opcode = opcode\n                    self._has_mask = bool(has_mask)\n                    self._payload_length_flag = length\n                    self._state = WSParserState.READ_PAYLOAD_LENGTH\n                else:\n                    break\n\n            # read payload length\n            if self._state == WSParserState.READ_PAYLOAD_LENGTH:\n                length = self._payload_length_flag\n                if length == 126:\n                    if buf_length - start_pos >= 2:\n                        data = buf[start_pos : start_pos + 2]\n                        start_pos += 2\n                        length = UNPACK_LEN2(data)[0]\n                        self._payload_length = length\n                        self._state = (\n                            WSParserState.READ_PAYLOAD_MASK\n                            if self._has_mask\n                            else WSParserState.READ_PAYLOAD\n                        )\n                    else:\n                        break\n                elif length > 126:\n                    if buf_length - start_pos >= 8:\n                        data = buf[start_pos : start_pos + 8]\n                        start_pos += 8\n                        length = UNPACK_LEN3(data)[0]\n                        self._payload_length = length\n                        self._state = (\n                            WSParserState.READ_PAYLOAD_MASK\n                            if self._has_mask\n                            else WSParserState.READ_PAYLOAD\n                        )\n                    else:\n                        break\n                else:\n                    self._payload_length = length\n                    self._state = (\n                        WSParserState.READ_PAYLOAD_MASK\n                        if self._has_mask\n                        else WSParserState.READ_PAYLOAD\n                    )\n\n            # read payload mask\n            if self._state == WSParserState.READ_PAYLOAD_MASK:\n                if buf_length - start_pos >= 4:\n                    self._frame_mask = buf[start_pos : start_pos + 4]\n                    start_pos += 4\n                    self._state = WSParserState.READ_PAYLOAD\n                else:\n                    break\n\n            if self._state == WSParserState.READ_PAYLOAD:\n                length = self._payload_length\n                payload = self._frame_payload\n\n                chunk_len = buf_length - start_pos\n                if length >= chunk_len:\n                    self._payload_length = length - chunk_len\n                    payload.extend(buf[start_pos:])\n                    start_pos = buf_length\n                else:\n                    self._payload_length = 0\n                    payload.extend(buf[start_pos : start_pos + length])\n                    start_pos = start_pos + length\n\n                if self._payload_length == 0:\n                    if self._has_mask:\n                        assert self._frame_mask is not None\n                        _websocket_mask(self._frame_mask, payload)\n\n                    frames.append(\n                        (self._frame_fin, self._frame_opcode, payload, self._compressed)\n                    )\n\n                    self._frame_payload = bytearray()\n                    self._state = WSParserState.READ_HEADER\n                else:\n                    break\n\n        self._tail = buf[start_pos:]\n\n        return frames\n\n\nclass WebSocketWriter:\n    def __init__(\n        self,\n        protocol: BaseProtocol,\n        transport: asyncio.Transport,\n        *,\n        use_mask: bool = False,\n        limit: int = DEFAULT_LIMIT,\n        random: random.Random = random.Random(),\n        compress: int = 0,\n        notakeover: bool = False,\n    ) -> None:\n        self.protocol = protocol\n        self.transport = transport\n        self.use_mask = use_mask\n        self.randrange = random.randrange\n        self.compress = compress\n        self.notakeover = notakeover\n        self._closing = False\n        self._limit = limit\n        self._output_size = 0\n        self._compressobj: Any = None  # actually compressobj\n\n    async def _send_frame(\n        self, message: bytes, opcode: int, compress: Optional[int] = None\n    ) -> None:\n        \"\"\"Send a frame over the websocket with message as its payload.\"\"\"\n        if self._closing and not (opcode & WSMsgType.CLOSE):\n            raise ConnectionResetError(\"Cannot write to closing transport\")\n\n        rsv = 0\n\n        # Only compress larger packets (disabled)\n        # Does small packet needs to be compressed?\n        # if self.compress and opcode < 8 and len(message) > 124:\n        if (compress or self.compress) and opcode < 8:\n            if compress:\n                # Do not set self._compress if compressing is for this frame\n                compressobj = self._make_compress_obj(compress)\n            else:  # self.compress\n                if not self._compressobj:\n                    self._compressobj = self._make_compress_obj(self.compress)\n                compressobj = self._compressobj\n\n            message = await compressobj.compress(message)\n            # Its critical that we do not return control to the event\n            # loop until we have finished sending all the compressed\n            # data. Otherwise we could end up mixing compressed frames\n            # if there are multiple coroutines compressing data.\n            message += compressobj.flush(\n                zlib.Z_FULL_FLUSH if self.notakeover else zlib.Z_SYNC_FLUSH\n            )\n            if message.endswith(_WS_DEFLATE_TRAILING):\n                message = message[:-4]\n            rsv = rsv | 0x40\n\n        msg_length = len(message)\n\n        use_mask = self.use_mask\n        if use_mask:\n            mask_bit = 0x80\n        else:\n            mask_bit = 0\n\n        if msg_length < 126:\n            header = PACK_LEN1(0x80 | rsv | opcode, msg_length | mask_bit)\n        elif msg_length < (1 << 16):\n            header = PACK_LEN2(0x80 | rsv | opcode, 126 | mask_bit, msg_length)\n        else:\n            header = PACK_LEN3(0x80 | rsv | opcode, 127 | mask_bit, msg_length)\n        if use_mask:\n            mask_int = self.randrange(0, 0xFFFFFFFF)\n            mask = mask_int.to_bytes(4, \"big\")\n            message = bytearray(message)\n            _websocket_mask(mask, message)\n            self._write(header + mask + message)\n            self._output_size += len(header) + len(mask) + msg_length\n        else:\n            if msg_length > MSG_SIZE:\n                self._write(header)\n                self._write(message)\n            else:\n                self._write(header + message)\n\n            self._output_size += len(header) + msg_length\n\n        # It is safe to return control to the event loop when using compression\n        # after this point as we have already sent or buffered all the data.\n\n        if self._output_size > self._limit:\n            self._output_size = 0\n            await self.protocol._drain_helper()\n\n    def _make_compress_obj(self, compress: int) -> ZLibCompressor:\n        return ZLibCompressor(\n            level=zlib.Z_BEST_SPEED,\n            wbits=-compress,\n            max_sync_chunk_size=WEBSOCKET_MAX_SYNC_CHUNK_SIZE,\n        )\n\n    def _write(self, data: bytes) -> None:\n        if self.transport.is_closing():\n            raise ConnectionResetError(\"Cannot write to closing transport\")\n        self.transport.write(data)\n\n    async def pong(self, message: Union[bytes, str] = b\"\") -> None:\n        \"\"\"Send pong message.\"\"\"\n        if isinstance(message, str):\n            message = message.encode(\"utf-8\")\n        await self._send_frame(message, WSMsgType.PONG)\n\n    async def ping(self, message: Union[bytes, str] = b\"\") -> None:\n        \"\"\"Send ping message.\"\"\"\n        if isinstance(message, str):\n            message = message.encode(\"utf-8\")\n        await self._send_frame(message, WSMsgType.PING)\n\n    async def send(\n        self,\n        message: Union[str, bytes],\n        binary: bool = False,\n        compress: Optional[int] = None,\n    ) -> None:\n        \"\"\"Send a frame over the websocket with message as its payload.\"\"\"\n        if isinstance(message, str):\n            message = message.encode(\"utf-8\")\n        if binary:\n            await self._send_frame(message, WSMsgType.BINARY, compress)\n        else:\n            await self._send_frame(message, WSMsgType.TEXT, compress)\n\n    async def close(self, code: int = 1000, message: Union[bytes, str] = b\"\") -> None:\n        \"\"\"Close the websocket, sending the specified code and message.\"\"\"\n        if isinstance(message, str):\n            message = message.encode(\"utf-8\")\n        try:\n            await self._send_frame(\n                PACK_CLOSE_CODE(code) + message, opcode=WSMsgType.CLOSE\n            )\n        finally:\n            self._closing = True\n", "aiohttp/compression_utils.py": "import asyncio\nimport zlib\nfrom concurrent.futures import Executor\nfrom typing import Optional, cast\n\ntry:\n    try:\n        import brotlicffi as brotli\n    except ImportError:\n        import brotli\n\n    HAS_BROTLI = True\nexcept ImportError:  # pragma: no cover\n    HAS_BROTLI = False\n\nMAX_SYNC_CHUNK_SIZE = 1024\n\n\ndef encoding_to_mode(\n    encoding: Optional[str] = None,\n    suppress_deflate_header: bool = False,\n) -> int:\n    if encoding == \"gzip\":\n        return 16 + zlib.MAX_WBITS\n\n    return -zlib.MAX_WBITS if suppress_deflate_header else zlib.MAX_WBITS\n\n\nclass ZlibBaseHandler:\n    def __init__(\n        self,\n        mode: int,\n        executor: Optional[Executor] = None,\n        max_sync_chunk_size: Optional[int] = MAX_SYNC_CHUNK_SIZE,\n    ):\n        self._mode = mode\n        self._executor = executor\n        self._max_sync_chunk_size = max_sync_chunk_size\n\n\nclass ZLibCompressor(ZlibBaseHandler):\n    def __init__(\n        self,\n        encoding: Optional[str] = None,\n        suppress_deflate_header: bool = False,\n        level: Optional[int] = None,\n        wbits: Optional[int] = None,\n        strategy: int = zlib.Z_DEFAULT_STRATEGY,\n        executor: Optional[Executor] = None,\n        max_sync_chunk_size: Optional[int] = MAX_SYNC_CHUNK_SIZE,\n    ):\n        super().__init__(\n            mode=(\n                encoding_to_mode(encoding, suppress_deflate_header)\n                if wbits is None\n                else wbits\n            ),\n            executor=executor,\n            max_sync_chunk_size=max_sync_chunk_size,\n        )\n        if level is None:\n            self._compressor = zlib.compressobj(wbits=self._mode, strategy=strategy)\n        else:\n            self._compressor = zlib.compressobj(\n                wbits=self._mode, strategy=strategy, level=level\n            )\n        self._compress_lock = asyncio.Lock()\n\n    def compress_sync(self, data: bytes) -> bytes:\n        return self._compressor.compress(data)\n\n    async def compress(self, data: bytes) -> bytes:\n        async with self._compress_lock:\n            # To ensure the stream is consistent in the event\n            # there are multiple writers, we need to lock\n            # the compressor so that only one writer can\n            # compress at a time.\n            if (\n                self._max_sync_chunk_size is not None\n                and len(data) > self._max_sync_chunk_size\n            ):\n                return await asyncio.get_event_loop().run_in_executor(\n                    self._executor, self.compress_sync, data\n                )\n            return self.compress_sync(data)\n\n    def flush(self, mode: int = zlib.Z_FINISH) -> bytes:\n        return self._compressor.flush(mode)\n\n\nclass ZLibDecompressor(ZlibBaseHandler):\n    def __init__(\n        self,\n        encoding: Optional[str] = None,\n        suppress_deflate_header: bool = False,\n        executor: Optional[Executor] = None,\n        max_sync_chunk_size: Optional[int] = MAX_SYNC_CHUNK_SIZE,\n    ):\n        super().__init__(\n            mode=encoding_to_mode(encoding, suppress_deflate_header),\n            executor=executor,\n            max_sync_chunk_size=max_sync_chunk_size,\n        )\n        self._decompressor = zlib.decompressobj(wbits=self._mode)\n\n    def decompress_sync(self, data: bytes, max_length: int = 0) -> bytes:\n        return self._decompressor.decompress(data, max_length)\n\n    async def decompress(self, data: bytes, max_length: int = 0) -> bytes:\n        if (\n            self._max_sync_chunk_size is not None\n            and len(data) > self._max_sync_chunk_size\n        ):\n            return await asyncio.get_event_loop().run_in_executor(\n                self._executor, self.decompress_sync, data, max_length\n            )\n        return self.decompress_sync(data, max_length)\n\n    def flush(self, length: int = 0) -> bytes:\n        return (\n            self._decompressor.flush(length)\n            if length > 0\n            else self._decompressor.flush()\n        )\n\n    @property\n    def eof(self) -> bool:\n        return self._decompressor.eof\n\n    @property\n    def unconsumed_tail(self) -> bytes:\n        return self._decompressor.unconsumed_tail\n\n    @property\n    def unused_data(self) -> bytes:\n        return self._decompressor.unused_data\n\n\nclass BrotliDecompressor:\n    # Supports both 'brotlipy' and 'Brotli' packages\n    # since they share an import name. The top branches\n    # are for 'brotlipy' and bottom branches for 'Brotli'\n    def __init__(self) -> None:\n        if not HAS_BROTLI:\n            raise RuntimeError(\n                \"The brotli decompression is not available. \"\n                \"Please install `Brotli` module\"\n            )\n        self._obj = brotli.Decompressor()\n\n    def decompress_sync(self, data: bytes) -> bytes:\n        if hasattr(self._obj, \"decompress\"):\n            return cast(bytes, self._obj.decompress(data))\n        return cast(bytes, self._obj.process(data))\n\n    def flush(self) -> bytes:\n        if hasattr(self._obj, \"flush\"):\n            return cast(bytes, self._obj.flush())\n        return b\"\"\n", "aiohttp/tcp_helpers.py": "\"\"\"Helper methods to tune a TCP connection\"\"\"\n\nimport asyncio\nimport socket\nfrom contextlib import suppress\nfrom typing import Optional  # noqa\n\n__all__ = (\"tcp_keepalive\", \"tcp_nodelay\")\n\n\nif hasattr(socket, \"SO_KEEPALIVE\"):\n\n    def tcp_keepalive(transport: asyncio.Transport) -> None:\n        sock = transport.get_extra_info(\"socket\")\n        if sock is not None:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)\n\nelse:\n\n    def tcp_keepalive(transport: asyncio.Transport) -> None:  # pragma: no cover\n        pass\n\n\ndef tcp_nodelay(transport: asyncio.Transport, value: bool) -> None:\n    sock = transport.get_extra_info(\"socket\")\n\n    if sock is None:\n        return\n\n    if sock.family not in (socket.AF_INET, socket.AF_INET6):\n        return\n\n    value = bool(value)\n\n    # socket may be closed already, on windows OSError get raised\n    with suppress(OSError):\n        sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, value)\n", "aiohttp/client.py": "\"\"\"HTTP Client for asyncio.\"\"\"\n\nimport asyncio\nimport base64\nimport dataclasses\nimport hashlib\nimport json\nimport os\nimport sys\nimport traceback\nimport warnings\nfrom contextlib import suppress\nfrom types import SimpleNamespace, TracebackType\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Awaitable,\n    Callable,\n    Collection,\n    Coroutine,\n    Final,\n    FrozenSet,\n    Generator,\n    Generic,\n    Iterable,\n    List,\n    Mapping,\n    Optional,\n    Set,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    final,\n)\n\nfrom multidict import CIMultiDict, MultiDict, MultiDictProxy, istr\nfrom yarl import URL\n\nfrom . import hdrs, http, payload\nfrom .abc import AbstractCookieJar\nfrom .client_exceptions import (\n    ClientConnectionError,\n    ClientConnectorCertificateError,\n    ClientConnectorError,\n    ClientConnectorSSLError,\n    ClientError,\n    ClientHttpProxyError,\n    ClientOSError,\n    ClientPayloadError,\n    ClientProxyConnectionError,\n    ClientResponseError,\n    ClientSSLError,\n    ConnectionTimeoutError,\n    ContentTypeError,\n    InvalidURL,\n    InvalidUrlClientError,\n    InvalidUrlRedirectClientError,\n    NonHttpUrlClientError,\n    NonHttpUrlRedirectClientError,\n    RedirectClientError,\n    ServerConnectionError,\n    ServerDisconnectedError,\n    ServerFingerprintMismatch,\n    ServerTimeoutError,\n    SocketTimeoutError,\n    TooManyRedirects,\n    WSServerHandshakeError,\n)\nfrom .client_reqrep import (\n    SSL_ALLOWED_TYPES,\n    ClientRequest,\n    ClientResponse,\n    Fingerprint,\n    RequestInfo,\n)\nfrom .client_ws import (\n    DEFAULT_WS_CLIENT_TIMEOUT,\n    ClientWebSocketResponse,\n    ClientWSTimeout,\n)\nfrom .connector import BaseConnector, NamedPipeConnector, TCPConnector, UnixConnector\nfrom .cookiejar import CookieJar\nfrom .helpers import (\n    _SENTINEL,\n    BasicAuth,\n    TimeoutHandle,\n    ceil_timeout,\n    get_env_proxy_for_url,\n    method_must_be_empty_body,\n    sentinel,\n    strip_auth_from_url,\n)\nfrom .http import WS_KEY, HttpVersion, WebSocketReader, WebSocketWriter\nfrom .http_websocket import WSHandshakeError, WSMessage, ws_ext_gen, ws_ext_parse\nfrom .streams import FlowControlDataQueue\nfrom .tracing import Trace, TraceConfig\nfrom .typedefs import JSONEncoder, LooseCookies, LooseHeaders, StrOrURL\n\n__all__ = (\n    # client_exceptions\n    \"ClientConnectionError\",\n    \"ClientConnectorCertificateError\",\n    \"ClientConnectorError\",\n    \"ClientConnectorSSLError\",\n    \"ClientError\",\n    \"ClientHttpProxyError\",\n    \"ClientOSError\",\n    \"ClientPayloadError\",\n    \"ClientProxyConnectionError\",\n    \"ClientResponseError\",\n    \"ClientSSLError\",\n    \"ConnectionTimeoutError\",\n    \"ContentTypeError\",\n    \"InvalidURL\",\n    \"InvalidUrlClientError\",\n    \"RedirectClientError\",\n    \"NonHttpUrlClientError\",\n    \"InvalidUrlRedirectClientError\",\n    \"NonHttpUrlRedirectClientError\",\n    \"ServerConnectionError\",\n    \"ServerDisconnectedError\",\n    \"ServerFingerprintMismatch\",\n    \"ServerTimeoutError\",\n    \"SocketTimeoutError\",\n    \"TooManyRedirects\",\n    \"WSServerHandshakeError\",\n    # client_reqrep\n    \"ClientRequest\",\n    \"ClientResponse\",\n    \"Fingerprint\",\n    \"RequestInfo\",\n    # connector\n    \"BaseConnector\",\n    \"TCPConnector\",\n    \"UnixConnector\",\n    \"NamedPipeConnector\",\n    # client_ws\n    \"ClientWebSocketResponse\",\n    # client\n    \"ClientSession\",\n    \"ClientTimeout\",\n    \"request\",\n)\n\n\nif TYPE_CHECKING:\n    from ssl import SSLContext\nelse:\n    SSLContext = None\n\n\n@dataclasses.dataclass(frozen=True)\nclass ClientTimeout:\n    total: Optional[float] = None\n    connect: Optional[float] = None\n    sock_read: Optional[float] = None\n    sock_connect: Optional[float] = None\n    ceil_threshold: float = 5\n\n    # pool_queue_timeout: Optional[float] = None\n    # dns_resolution_timeout: Optional[float] = None\n    # socket_connect_timeout: Optional[float] = None\n    # connection_acquiring_timeout: Optional[float] = None\n    # new_connection_timeout: Optional[float] = None\n    # http_header_timeout: Optional[float] = None\n    # response_body_timeout: Optional[float] = None\n\n    # to create a timeout specific for a single request, either\n    # - create a completely new one to overwrite the default\n    # - or use https://docs.python.org/3/library/dataclasses.html#dataclasses.replace\n    # to overwrite the defaults\n\n\n# 5 Minute default read timeout\nDEFAULT_TIMEOUT: Final[ClientTimeout] = ClientTimeout(total=5 * 60)\n\n# https://www.rfc-editor.org/rfc/rfc9110#section-9.2.2\nIDEMPOTENT_METHODS = frozenset({\"GET\", \"HEAD\", \"OPTIONS\", \"TRACE\", \"PUT\", \"DELETE\"})\nHTTP_SCHEMA_SET = frozenset({\"http\", \"https\", \"\"})\n\n_RetType = TypeVar(\"_RetType\")\n_CharsetResolver = Callable[[ClientResponse, bytes], str]\n\n\n@final\nclass ClientSession:\n    \"\"\"First-class interface for making HTTP requests.\"\"\"\n\n    __slots__ = (\n        \"_base_url\",\n        \"_source_traceback\",\n        \"_connector\",\n        \"_loop\",\n        \"_cookie_jar\",\n        \"_connector_owner\",\n        \"_default_auth\",\n        \"_version\",\n        \"_json_serialize\",\n        \"_requote_redirect_url\",\n        \"_timeout\",\n        \"_raise_for_status\",\n        \"_auto_decompress\",\n        \"_trust_env\",\n        \"_default_headers\",\n        \"_skip_auto_headers\",\n        \"_request_class\",\n        \"_response_class\",\n        \"_ws_response_class\",\n        \"_trace_configs\",\n        \"_read_bufsize\",\n        \"_max_line_size\",\n        \"_max_field_size\",\n        \"_resolve_charset\",\n    )\n\n    def __init__(\n        self,\n        base_url: Optional[StrOrURL] = None,\n        *,\n        connector: Optional[BaseConnector] = None,\n        cookies: Optional[LooseCookies] = None,\n        headers: Optional[LooseHeaders] = None,\n        skip_auto_headers: Optional[Iterable[str]] = None,\n        auth: Optional[BasicAuth] = None,\n        json_serialize: JSONEncoder = json.dumps,\n        request_class: Type[ClientRequest] = ClientRequest,\n        response_class: Type[ClientResponse] = ClientResponse,\n        ws_response_class: Type[ClientWebSocketResponse] = ClientWebSocketResponse,\n        version: HttpVersion = http.HttpVersion11,\n        cookie_jar: Optional[AbstractCookieJar] = None,\n        connector_owner: bool = True,\n        raise_for_status: Union[\n            bool, Callable[[ClientResponse], Awaitable[None]]\n        ] = False,\n        timeout: Union[_SENTINEL, ClientTimeout, None] = sentinel,\n        auto_decompress: bool = True,\n        trust_env: bool = False,\n        requote_redirect_url: bool = True,\n        trace_configs: Optional[List[TraceConfig]] = None,\n        read_bufsize: int = 2**16,\n        max_line_size: int = 8190,\n        max_field_size: int = 8190,\n        fallback_charset_resolver: _CharsetResolver = lambda r, b: \"utf-8\",\n    ) -> None:\n        # We initialise _connector to None immediately, as it's referenced in __del__()\n        # and could cause issues if an exception occurs during initialisation.\n        self._connector: Optional[BaseConnector] = None\n        if base_url is None or isinstance(base_url, URL):\n            self._base_url: Optional[URL] = base_url\n        else:\n            self._base_url = URL(base_url)\n            assert (\n                self._base_url.origin() == self._base_url\n            ), \"Only absolute URLs without path part are supported\"\n\n        loop = asyncio.get_running_loop()\n\n        if timeout is sentinel or timeout is None:\n            timeout = DEFAULT_TIMEOUT\n        if not isinstance(timeout, ClientTimeout):\n            raise ValueError(\n                f\"timeout parameter cannot be of {type(timeout)} type, \"\n                \"please use 'timeout=ClientTimeout(...)'\",\n            )\n        self._timeout = timeout\n\n        if connector is None:\n            connector = TCPConnector()\n        # Initialize these three attrs before raising any exception,\n        # they are used in __del__\n        self._connector = connector\n        self._loop = loop\n        if loop.get_debug():\n            self._source_traceback: Optional[traceback.StackSummary] = (\n                traceback.extract_stack(sys._getframe(1))\n            )\n        else:\n            self._source_traceback = None\n\n        if connector._loop is not loop:\n            raise RuntimeError(\"Session and connector have to use same event loop\")\n\n        if cookie_jar is None:\n            cookie_jar = CookieJar()\n        self._cookie_jar = cookie_jar\n\n        if cookies is not None:\n            self._cookie_jar.update_cookies(cookies)\n\n        self._connector_owner = connector_owner\n        self._default_auth = auth\n        self._version = version\n        self._json_serialize = json_serialize\n        self._raise_for_status = raise_for_status\n        self._auto_decompress = auto_decompress\n        self._trust_env = trust_env\n        self._requote_redirect_url = requote_redirect_url\n        self._read_bufsize = read_bufsize\n        self._max_line_size = max_line_size\n        self._max_field_size = max_field_size\n\n        # Convert to list of tuples\n        if headers:\n            real_headers: CIMultiDict[str] = CIMultiDict(headers)\n        else:\n            real_headers = CIMultiDict()\n        self._default_headers: CIMultiDict[str] = real_headers\n        if skip_auto_headers is not None:\n            self._skip_auto_headers = frozenset(istr(i) for i in skip_auto_headers)\n        else:\n            self._skip_auto_headers = frozenset()\n\n        self._request_class = request_class\n        self._response_class = response_class\n        self._ws_response_class = ws_response_class\n\n        self._trace_configs = trace_configs or []\n        for trace_config in self._trace_configs:\n            trace_config.freeze()\n\n        self._resolve_charset = fallback_charset_resolver\n\n    def __init_subclass__(cls: Type[\"ClientSession\"]) -> None:\n        raise TypeError(\n            \"Inheritance class {} from ClientSession \"\n            \"is forbidden\".format(cls.__name__)\n        )\n\n    def __del__(self, _warnings: Any = warnings) -> None:\n        if not self.closed:\n            _warnings.warn(\n                f\"Unclosed client session {self!r}\",\n                ResourceWarning,\n                source=self,\n            )\n            context = {\"client_session\": self, \"message\": \"Unclosed client session\"}\n            if self._source_traceback is not None:\n                context[\"source_traceback\"] = self._source_traceback\n            self._loop.call_exception_handler(context)\n\n    def request(\n        self, method: str, url: StrOrURL, **kwargs: Any\n    ) -> \"_RequestContextManager\":\n        \"\"\"Perform HTTP request.\"\"\"\n        return _RequestContextManager(self._request(method, url, **kwargs))\n\n    def _build_url(self, str_or_url: StrOrURL) -> URL:\n        url = URL(str_or_url)\n        if self._base_url is None:\n            return url\n        else:\n            assert not url.is_absolute() and url.path.startswith(\"/\")\n            return self._base_url.join(url)\n\n    async def _request(\n        self,\n        method: str,\n        str_or_url: StrOrURL,\n        *,\n        params: Optional[Mapping[str, str]] = None,\n        data: Any = None,\n        json: Any = None,\n        cookies: Optional[LooseCookies] = None,\n        headers: Optional[LooseHeaders] = None,\n        skip_auto_headers: Optional[Iterable[str]] = None,\n        auth: Optional[BasicAuth] = None,\n        allow_redirects: bool = True,\n        max_redirects: int = 10,\n        compress: Optional[str] = None,\n        chunked: Optional[bool] = None,\n        expect100: bool = False,\n        raise_for_status: Union[\n            None, bool, Callable[[ClientResponse], Awaitable[None]]\n        ] = None,\n        read_until_eof: bool = True,\n        proxy: Optional[StrOrURL] = None,\n        proxy_auth: Optional[BasicAuth] = None,\n        timeout: Union[ClientTimeout, _SENTINEL, None] = sentinel,\n        ssl: Union[SSLContext, bool, Fingerprint] = True,\n        server_hostname: Optional[str] = None,\n        proxy_headers: Optional[LooseHeaders] = None,\n        trace_request_ctx: Optional[SimpleNamespace] = None,\n        read_bufsize: Optional[int] = None,\n        auto_decompress: Optional[bool] = None,\n        max_line_size: Optional[int] = None,\n        max_field_size: Optional[int] = None,\n    ) -> ClientResponse:\n        # NOTE: timeout clamps existing connect and read timeouts.  We cannot\n        # set the default to None because we need to detect if the user wants\n        # to use the existing timeouts by setting timeout to None.\n\n        if self.closed:\n            raise RuntimeError(\"Session is closed\")\n\n        if not isinstance(ssl, SSL_ALLOWED_TYPES):\n            raise TypeError(\n                \"ssl should be SSLContext, Fingerprint, or bool, \"\n                \"got {!r} instead.\".format(ssl)\n            )\n\n        if data is not None and json is not None:\n            raise ValueError(\n                \"data and json parameters can not be used at the same time\"\n            )\n        elif json is not None:\n            data = payload.JsonPayload(json, dumps=self._json_serialize)\n\n        redirects = 0\n        history = []\n        version = self._version\n        params = params or {}\n\n        # Merge with default headers and transform to CIMultiDict\n        headers = self._prepare_headers(headers)\n        proxy_headers = self._prepare_headers(proxy_headers)\n\n        try:\n            url = self._build_url(str_or_url)\n        except ValueError as e:\n            raise InvalidUrlClientError(str_or_url) from e\n\n        if url.scheme not in HTTP_SCHEMA_SET:\n            raise NonHttpUrlClientError(url)\n\n        skip_headers = set(self._skip_auto_headers)\n        if skip_auto_headers is not None:\n            for i in skip_auto_headers:\n                skip_headers.add(istr(i))\n\n        if proxy is not None:\n            try:\n                proxy = URL(proxy)\n            except ValueError as e:\n                raise InvalidURL(proxy) from e\n\n        if timeout is sentinel or timeout is None:\n            real_timeout: ClientTimeout = self._timeout\n        else:\n            real_timeout = timeout\n        # timeout is cumulative for all request operations\n        # (request, redirects, responses, data consuming)\n        tm = TimeoutHandle(\n            self._loop, real_timeout.total, ceil_threshold=real_timeout.ceil_threshold\n        )\n        handle = tm.start()\n\n        if read_bufsize is None:\n            read_bufsize = self._read_bufsize\n\n        if auto_decompress is None:\n            auto_decompress = self._auto_decompress\n\n        if max_line_size is None:\n            max_line_size = self._max_line_size\n\n        if max_field_size is None:\n            max_field_size = self._max_field_size\n\n        traces = [\n            Trace(\n                self,\n                trace_config,\n                trace_config.trace_config_ctx(trace_request_ctx=trace_request_ctx),\n            )\n            for trace_config in self._trace_configs\n        ]\n\n        for trace in traces:\n            await trace.send_request_start(method, url.update_query(params), headers)\n\n        timer = tm.timer()\n        try:\n            with timer:\n                # https://www.rfc-editor.org/rfc/rfc9112.html#name-retrying-requests\n                retry_persistent_connection = method in IDEMPOTENT_METHODS\n                while True:\n                    url, auth_from_url = strip_auth_from_url(url)\n                    if not url.raw_host:\n                        # NOTE: Bail early, otherwise, causes `InvalidURL` through\n                        # NOTE: `self._request_class()` below.\n                        err_exc_cls = (\n                            InvalidUrlRedirectClientError\n                            if redirects\n                            else InvalidUrlClientError\n                        )\n                        raise err_exc_cls(url)\n                    if auth and auth_from_url:\n                        raise ValueError(\n                            \"Cannot combine AUTH argument with \"\n                            \"credentials encoded in URL\"\n                        )\n\n                    if auth is None:\n                        auth = auth_from_url\n                    if auth is None:\n                        auth = self._default_auth\n                    # It would be confusing if we support explicit\n                    # Authorization header with auth argument\n                    if auth is not None and hdrs.AUTHORIZATION in headers:\n                        raise ValueError(\n                            \"Cannot combine AUTHORIZATION header \"\n                            \"with AUTH argument or credentials \"\n                            \"encoded in URL\"\n                        )\n\n                    all_cookies = self._cookie_jar.filter_cookies(url)\n\n                    if cookies is not None:\n                        tmp_cookie_jar = CookieJar()\n                        tmp_cookie_jar.update_cookies(cookies)\n                        req_cookies = tmp_cookie_jar.filter_cookies(url)\n                        if req_cookies:\n                            all_cookies.load(req_cookies)\n\n                    if proxy is not None:\n                        proxy = URL(proxy)\n                    elif self._trust_env:\n                        with suppress(LookupError):\n                            proxy, proxy_auth = get_env_proxy_for_url(url)\n\n                    req = self._request_class(\n                        method,\n                        url,\n                        params=params,\n                        headers=headers,\n                        skip_auto_headers=skip_headers,\n                        data=data,\n                        cookies=all_cookies,\n                        auth=auth,\n                        version=version,\n                        compress=compress,\n                        chunked=chunked,\n                        expect100=expect100,\n                        loop=self._loop,\n                        response_class=self._response_class,\n                        proxy=proxy,\n                        proxy_auth=proxy_auth,\n                        timer=timer,\n                        session=self,\n                        ssl=ssl,\n                        server_hostname=server_hostname,\n                        proxy_headers=proxy_headers,\n                        traces=traces,\n                        trust_env=self.trust_env,\n                    )\n\n                    # connection timeout\n                    try:\n                        async with ceil_timeout(\n                            real_timeout.connect,\n                            ceil_threshold=real_timeout.ceil_threshold,\n                        ):\n                            assert self._connector is not None\n                            conn = await self._connector.connect(\n                                req, traces=traces, timeout=real_timeout\n                            )\n                    except asyncio.TimeoutError as exc:\n                        raise ConnectionTimeoutError(\n                            f\"Connection timeout to host {url}\"\n                        ) from exc\n\n                    assert conn.transport is not None\n\n                    assert conn.protocol is not None\n                    conn.protocol.set_response_params(\n                        timer=timer,\n                        skip_payload=method_must_be_empty_body(method),\n                        read_until_eof=read_until_eof,\n                        auto_decompress=auto_decompress,\n                        read_timeout=real_timeout.sock_read,\n                        read_bufsize=read_bufsize,\n                        timeout_ceil_threshold=self._connector._timeout_ceil_threshold,\n                        max_line_size=max_line_size,\n                        max_field_size=max_field_size,\n                    )\n\n                    try:\n                        try:\n                            resp = await req.send(conn)\n                            try:\n                                await resp.start(conn)\n                            except BaseException:\n                                resp.close()\n                                raise\n                        except BaseException:\n                            conn.close()\n                            raise\n                    except (ClientOSError, ServerDisconnectedError):\n                        if retry_persistent_connection:\n                            retry_persistent_connection = False\n                            continue\n                        raise\n                    except ClientError:\n                        raise\n                    except OSError as exc:\n                        if exc.errno is None and isinstance(exc, asyncio.TimeoutError):\n                            raise\n                        raise ClientOSError(*exc.args) from exc\n\n                    self._cookie_jar.update_cookies(resp.cookies, resp.url)\n\n                    # redirects\n                    if resp.status in (301, 302, 303, 307, 308) and allow_redirects:\n                        for trace in traces:\n                            await trace.send_request_redirect(\n                                method, url.update_query(params), headers, resp\n                            )\n\n                        redirects += 1\n                        history.append(resp)\n                        if max_redirects and redirects >= max_redirects:\n                            resp.close()\n                            raise TooManyRedirects(\n                                history[0].request_info, tuple(history)\n                            )\n\n                        # For 301 and 302, mimic IE, now changed in RFC\n                        # https://github.com/kennethreitz/requests/pull/269\n                        if (resp.status == 303 and resp.method != hdrs.METH_HEAD) or (\n                            resp.status in (301, 302) and resp.method == hdrs.METH_POST\n                        ):\n                            method = hdrs.METH_GET\n                            data = None\n                            if headers.get(hdrs.CONTENT_LENGTH):\n                                headers.pop(hdrs.CONTENT_LENGTH)\n\n                        r_url = resp.headers.get(hdrs.LOCATION) or resp.headers.get(\n                            hdrs.URI\n                        )\n                        if r_url is None:\n                            # see github.com/aio-libs/aiohttp/issues/2022\n                            break\n                        else:\n                            # reading from correct redirection\n                            # response is forbidden\n                            resp.release()\n\n                        try:\n                            parsed_redirect_url = URL(\n                                r_url, encoded=not self._requote_redirect_url\n                            )\n                        except ValueError as e:\n                            raise InvalidUrlRedirectClientError(\n                                r_url,\n                                \"Server attempted redirecting to a location that does not look like a URL\",\n                            ) from e\n\n                        scheme = parsed_redirect_url.scheme\n                        if scheme not in HTTP_SCHEMA_SET:\n                            resp.close()\n                            raise NonHttpUrlRedirectClientError(r_url)\n                        elif not scheme:\n                            parsed_redirect_url = url.join(parsed_redirect_url)\n\n                        is_same_host_https_redirect = (\n                            url.host == parsed_redirect_url.host\n                            and parsed_redirect_url.scheme == \"https\"\n                            and url.scheme == \"http\"\n                        )\n\n                        try:\n                            redirect_origin = parsed_redirect_url.origin()\n                        except ValueError as origin_val_err:\n                            raise InvalidUrlRedirectClientError(\n                                parsed_redirect_url,\n                                \"Invalid redirect URL origin\",\n                            ) from origin_val_err\n\n                        if (\n                            url.origin() != redirect_origin\n                            and not is_same_host_https_redirect\n                        ):\n                            auth = None\n                            headers.pop(hdrs.AUTHORIZATION, None)\n\n                        url = parsed_redirect_url\n                        params = {}\n                        resp.release()\n                        continue\n\n                    break\n\n            # check response status\n            if raise_for_status is None:\n                raise_for_status = self._raise_for_status\n\n            if raise_for_status is None:\n                pass\n            elif callable(raise_for_status):\n                await raise_for_status(resp)\n            elif raise_for_status:\n                resp.raise_for_status()\n\n            # register connection\n            if handle is not None:\n                if resp.connection is not None:\n                    resp.connection.add_callback(handle.cancel)\n                else:\n                    handle.cancel()\n\n            resp._history = tuple(history)\n\n            for trace in traces:\n                await trace.send_request_end(\n                    method, url.update_query(params), headers, resp\n                )\n            return resp\n\n        except BaseException as e:\n            # cleanup timer\n            tm.close()\n            if handle:\n                handle.cancel()\n                handle = None\n\n            for trace in traces:\n                await trace.send_request_exception(\n                    method, url.update_query(params), headers, e\n                )\n            raise\n\n    def ws_connect(\n        self,\n        url: StrOrURL,\n        *,\n        method: str = hdrs.METH_GET,\n        protocols: Collection[str] = (),\n        timeout: Union[ClientWSTimeout, float, _SENTINEL, None] = sentinel,\n        receive_timeout: Optional[float] = None,\n        autoclose: bool = True,\n        autoping: bool = True,\n        heartbeat: Optional[float] = None,\n        auth: Optional[BasicAuth] = None,\n        origin: Optional[str] = None,\n        params: Optional[Mapping[str, str]] = None,\n        headers: Optional[LooseHeaders] = None,\n        proxy: Optional[StrOrURL] = None,\n        proxy_auth: Optional[BasicAuth] = None,\n        ssl: Union[SSLContext, bool, Fingerprint] = True,\n        server_hostname: Optional[str] = None,\n        proxy_headers: Optional[LooseHeaders] = None,\n        compress: int = 0,\n        max_msg_size: int = 4 * 1024 * 1024,\n    ) -> \"_WSRequestContextManager\":\n        \"\"\"Initiate websocket connection.\"\"\"\n        return _WSRequestContextManager(\n            self._ws_connect(\n                url,\n                method=method,\n                protocols=protocols,\n                timeout=timeout,\n                receive_timeout=receive_timeout,\n                autoclose=autoclose,\n                autoping=autoping,\n                heartbeat=heartbeat,\n                auth=auth,\n                origin=origin,\n                params=params,\n                headers=headers,\n                proxy=proxy,\n                proxy_auth=proxy_auth,\n                ssl=ssl,\n                server_hostname=server_hostname,\n                proxy_headers=proxy_headers,\n                compress=compress,\n                max_msg_size=max_msg_size,\n            )\n        )\n\n    async def _ws_connect(\n        self,\n        url: StrOrURL,\n        *,\n        method: str = hdrs.METH_GET,\n        protocols: Collection[str] = (),\n        timeout: Union[ClientWSTimeout, float, _SENTINEL, None] = sentinel,\n        receive_timeout: Optional[float] = None,\n        autoclose: bool = True,\n        autoping: bool = True,\n        heartbeat: Optional[float] = None,\n        auth: Optional[BasicAuth] = None,\n        origin: Optional[str] = None,\n        params: Optional[Mapping[str, str]] = None,\n        headers: Optional[LooseHeaders] = None,\n        proxy: Optional[StrOrURL] = None,\n        proxy_auth: Optional[BasicAuth] = None,\n        ssl: Union[SSLContext, bool, Fingerprint] = True,\n        server_hostname: Optional[str] = None,\n        proxy_headers: Optional[LooseHeaders] = None,\n        compress: int = 0,\n        max_msg_size: int = 4 * 1024 * 1024,\n    ) -> ClientWebSocketResponse:\n        if timeout is sentinel or timeout is None:\n            ws_timeout = DEFAULT_WS_CLIENT_TIMEOUT\n        else:\n            if isinstance(timeout, ClientWSTimeout):\n                ws_timeout = timeout\n            else:\n                warnings.warn(\n                    \"parameter 'timeout' of type 'float' \"\n                    \"is deprecated, please use \"\n                    \"'timeout=ClientWSTimeout(ws_close=...)'\",\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n                ws_timeout = ClientWSTimeout(ws_close=timeout)\n\n        if receive_timeout is not None:\n            warnings.warn(\n                \"float parameter 'receive_timeout' \"\n                \"is deprecated, please use parameter \"\n                \"'timeout=ClientWSTimeout(ws_receive=...)'\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            ws_timeout = dataclasses.replace(ws_timeout, ws_receive=receive_timeout)\n\n        if headers is None:\n            real_headers: CIMultiDict[str] = CIMultiDict()\n        else:\n            real_headers = CIMultiDict(headers)\n\n        default_headers = {\n            hdrs.UPGRADE: \"websocket\",\n            hdrs.CONNECTION: \"Upgrade\",\n            hdrs.SEC_WEBSOCKET_VERSION: \"13\",\n        }\n\n        for key, value in default_headers.items():\n            real_headers.setdefault(key, value)\n\n        sec_key = base64.b64encode(os.urandom(16))\n        real_headers[hdrs.SEC_WEBSOCKET_KEY] = sec_key.decode()\n\n        if protocols:\n            real_headers[hdrs.SEC_WEBSOCKET_PROTOCOL] = \",\".join(protocols)\n        if origin is not None:\n            real_headers[hdrs.ORIGIN] = origin\n        if compress:\n            extstr = ws_ext_gen(compress=compress)\n            real_headers[hdrs.SEC_WEBSOCKET_EXTENSIONS] = extstr\n\n        if not isinstance(ssl, SSL_ALLOWED_TYPES):\n            raise TypeError(\n                \"ssl should be SSLContext, Fingerprint, or bool, \"\n                \"got {!r} instead.\".format(ssl)\n            )\n\n        # send request\n        resp = await self.request(\n            method,\n            url,\n            params=params,\n            headers=real_headers,\n            read_until_eof=False,\n            auth=auth,\n            proxy=proxy,\n            proxy_auth=proxy_auth,\n            ssl=ssl,\n            server_hostname=server_hostname,\n            proxy_headers=proxy_headers,\n        )\n\n        try:\n            # check handshake\n            if resp.status != 101:\n                raise WSServerHandshakeError(\n                    resp.request_info,\n                    resp.history,\n                    message=\"Invalid response status\",\n                    status=resp.status,\n                    headers=resp.headers,\n                )\n\n            if resp.headers.get(hdrs.UPGRADE, \"\").lower() != \"websocket\":\n                raise WSServerHandshakeError(\n                    resp.request_info,\n                    resp.history,\n                    message=\"Invalid upgrade header\",\n                    status=resp.status,\n                    headers=resp.headers,\n                )\n\n            if resp.headers.get(hdrs.CONNECTION, \"\").lower() != \"upgrade\":\n                raise WSServerHandshakeError(\n                    resp.request_info,\n                    resp.history,\n                    message=\"Invalid connection header\",\n                    status=resp.status,\n                    headers=resp.headers,\n                )\n\n            # key calculation\n            r_key = resp.headers.get(hdrs.SEC_WEBSOCKET_ACCEPT, \"\")\n            match = base64.b64encode(hashlib.sha1(sec_key + WS_KEY).digest()).decode()\n            if r_key != match:\n                raise WSServerHandshakeError(\n                    resp.request_info,\n                    resp.history,\n                    message=\"Invalid challenge response\",\n                    status=resp.status,\n                    headers=resp.headers,\n                )\n\n            # websocket protocol\n            protocol = None\n            if protocols and hdrs.SEC_WEBSOCKET_PROTOCOL in resp.headers:\n                resp_protocols = [\n                    proto.strip()\n                    for proto in resp.headers[hdrs.SEC_WEBSOCKET_PROTOCOL].split(\",\")\n                ]\n\n                for proto in resp_protocols:\n                    if proto in protocols:\n                        protocol = proto\n                        break\n\n            # websocket compress\n            notakeover = False\n            if compress:\n                compress_hdrs = resp.headers.get(hdrs.SEC_WEBSOCKET_EXTENSIONS)\n                if compress_hdrs:\n                    try:\n                        compress, notakeover = ws_ext_parse(compress_hdrs)\n                    except WSHandshakeError as exc:\n                        raise WSServerHandshakeError(\n                            resp.request_info,\n                            resp.history,\n                            message=exc.args[0],\n                            status=resp.status,\n                            headers=resp.headers,\n                        ) from exc\n                else:\n                    compress = 0\n                    notakeover = False\n\n            conn = resp.connection\n            assert conn is not None\n            conn_proto = conn.protocol\n            assert conn_proto is not None\n            transport = conn.transport\n            assert transport is not None\n            reader: FlowControlDataQueue[WSMessage] = FlowControlDataQueue(\n                conn_proto, 2**16, loop=self._loop\n            )\n            conn_proto.set_parser(WebSocketReader(reader, max_msg_size), reader)\n            writer = WebSocketWriter(\n                conn_proto,\n                transport,\n                use_mask=True,\n                compress=compress,\n                notakeover=notakeover,\n            )\n        except BaseException:\n            resp.close()\n            raise\n        else:\n            return self._ws_response_class(\n                reader,\n                writer,\n                protocol,\n                resp,\n                ws_timeout,\n                autoclose,\n                autoping,\n                self._loop,\n                heartbeat=heartbeat,\n                compress=compress,\n                client_notakeover=notakeover,\n            )\n\n    def _prepare_headers(self, headers: Optional[LooseHeaders]) -> \"CIMultiDict[str]\":\n        \"\"\"Add default headers and transform it to CIMultiDict\"\"\"\n        # Convert headers to MultiDict\n        result = CIMultiDict(self._default_headers)\n        if headers:\n            if not isinstance(headers, (MultiDictProxy, MultiDict)):\n                headers = CIMultiDict(headers)\n            added_names: Set[str] = set()\n            for key, value in headers.items():\n                if key in added_names:\n                    result.add(key, value)\n                else:\n                    result[key] = value\n                    added_names.add(key)\n        return result\n\n    def get(\n        self, url: StrOrURL, *, allow_redirects: bool = True, **kwargs: Any\n    ) -> \"_RequestContextManager\":\n        \"\"\"Perform HTTP GET request.\"\"\"\n        return _RequestContextManager(\n            self._request(hdrs.METH_GET, url, allow_redirects=allow_redirects, **kwargs)\n        )\n\n    def options(\n        self, url: StrOrURL, *, allow_redirects: bool = True, **kwargs: Any\n    ) -> \"_RequestContextManager\":\n        \"\"\"Perform HTTP OPTIONS request.\"\"\"\n        return _RequestContextManager(\n            self._request(\n                hdrs.METH_OPTIONS, url, allow_redirects=allow_redirects, **kwargs\n            )\n        )\n\n    def head(\n        self, url: StrOrURL, *, allow_redirects: bool = False, **kwargs: Any\n    ) -> \"_RequestContextManager\":\n        \"\"\"Perform HTTP HEAD request.\"\"\"\n        return _RequestContextManager(\n            self._request(\n                hdrs.METH_HEAD, url, allow_redirects=allow_redirects, **kwargs\n            )\n        )\n\n    def post(\n        self, url: StrOrURL, *, data: Any = None, **kwargs: Any\n    ) -> \"_RequestContextManager\":\n        \"\"\"Perform HTTP POST request.\"\"\"\n        return _RequestContextManager(\n            self._request(hdrs.METH_POST, url, data=data, **kwargs)\n        )\n\n    def put(\n        self, url: StrOrURL, *, data: Any = None, **kwargs: Any\n    ) -> \"_RequestContextManager\":\n        \"\"\"Perform HTTP PUT request.\"\"\"\n        return _RequestContextManager(\n            self._request(hdrs.METH_PUT, url, data=data, **kwargs)\n        )\n\n    def patch(\n        self, url: StrOrURL, *, data: Any = None, **kwargs: Any\n    ) -> \"_RequestContextManager\":\n        \"\"\"Perform HTTP PATCH request.\"\"\"\n        return _RequestContextManager(\n            self._request(hdrs.METH_PATCH, url, data=data, **kwargs)\n        )\n\n    def delete(self, url: StrOrURL, **kwargs: Any) -> \"_RequestContextManager\":\n        \"\"\"Perform HTTP DELETE request.\"\"\"\n        return _RequestContextManager(self._request(hdrs.METH_DELETE, url, **kwargs))\n\n    async def close(self) -> None:\n        \"\"\"Close underlying connector.\n\n        Release all acquired resources.\n        \"\"\"\n        if not self.closed:\n            if self._connector is not None and self._connector_owner:\n                await self._connector.close()\n            self._connector = None\n\n    @property\n    def closed(self) -> bool:\n        \"\"\"Is client session closed.\n\n        A readonly property.\n        \"\"\"\n        return self._connector is None or self._connector.closed\n\n    @property\n    def connector(self) -> Optional[BaseConnector]:\n        \"\"\"Connector instance used for the session.\"\"\"\n        return self._connector\n\n    @property\n    def cookie_jar(self) -> AbstractCookieJar:\n        \"\"\"The session cookies.\"\"\"\n        return self._cookie_jar\n\n    @property\n    def version(self) -> Tuple[int, int]:\n        \"\"\"The session HTTP protocol version.\"\"\"\n        return self._version\n\n    @property\n    def requote_redirect_url(self) -> bool:\n        \"\"\"Do URL requoting on redirection handling.\"\"\"\n        return self._requote_redirect_url\n\n    @property\n    def timeout(self) -> ClientTimeout:\n        \"\"\"Timeout for the session.\"\"\"\n        return self._timeout\n\n    @property\n    def headers(self) -> \"CIMultiDict[str]\":\n        \"\"\"The default headers of the client session.\"\"\"\n        return self._default_headers\n\n    @property\n    def skip_auto_headers(self) -> FrozenSet[istr]:\n        \"\"\"Headers for which autogeneration should be skipped\"\"\"\n        return self._skip_auto_headers\n\n    @property\n    def auth(self) -> Optional[BasicAuth]:\n        \"\"\"An object that represents HTTP Basic Authorization\"\"\"\n        return self._default_auth\n\n    @property\n    def json_serialize(self) -> JSONEncoder:\n        \"\"\"Json serializer callable\"\"\"\n        return self._json_serialize\n\n    @property\n    def connector_owner(self) -> bool:\n        \"\"\"Should connector be closed on session closing\"\"\"\n        return self._connector_owner\n\n    @property\n    def raise_for_status(\n        self,\n    ) -> Union[bool, Callable[[ClientResponse], Awaitable[None]]]:\n        \"\"\"Should `ClientResponse.raise_for_status()` be called for each response.\"\"\"\n        return self._raise_for_status\n\n    @property\n    def auto_decompress(self) -> bool:\n        \"\"\"Should the body response be automatically decompressed.\"\"\"\n        return self._auto_decompress\n\n    @property\n    def trust_env(self) -> bool:\n        \"\"\"\n        Should proxies information from environment or netrc be trusted.\n\n        Information is from HTTP_PROXY / HTTPS_PROXY environment variables\n        or ~/.netrc file if present.\n        \"\"\"\n        return self._trust_env\n\n    @property\n    def trace_configs(self) -> List[TraceConfig]:\n        \"\"\"A list of TraceConfig instances used for client tracing\"\"\"\n        return self._trace_configs\n\n    def detach(self) -> None:\n        \"\"\"Detach connector from session without closing the former.\n\n        Session is switched to closed state anyway.\n        \"\"\"\n        self._connector = None\n\n    async def __aenter__(self) -> \"ClientSession\":\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        await self.close()\n\n\nclass _BaseRequestContextManager(Coroutine[Any, Any, _RetType], Generic[_RetType]):\n    __slots__ = (\"_coro\", \"_resp\")\n\n    def __init__(self, coro: Coroutine[\"asyncio.Future[Any]\", None, _RetType]) -> None:\n        self._coro = coro\n\n    def send(self, arg: None) -> \"asyncio.Future[Any]\":\n        return self._coro.send(arg)\n\n    def throw(self, *args: Any, **kwargs: Any) -> \"asyncio.Future[Any]\":\n        return self._coro.throw(*args, **kwargs)\n\n    def close(self) -> None:\n        return self._coro.close()\n\n    def __await__(self) -> Generator[Any, None, _RetType]:\n        ret = self._coro.__await__()\n        return ret\n\n    def __iter__(self) -> Generator[Any, None, _RetType]:\n        return self.__await__()\n\n    async def __aenter__(self) -> _RetType:\n        self._resp = await self._coro\n        return self._resp\n\n\nclass _RequestContextManager(_BaseRequestContextManager[ClientResponse]):\n    __slots__ = ()\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> None:\n        # We're basing behavior on the exception as it can be caused by\n        # user code unrelated to the status of the connection.  If you\n        # would like to close a connection you must do that\n        # explicitly.  Otherwise connection error handling should kick in\n        # and close/recycle the connection as required.\n        self._resp.release()\n        await self._resp.wait_for_close()\n\n\nclass _WSRequestContextManager(_BaseRequestContextManager[ClientWebSocketResponse]):\n    __slots__ = ()\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> None:\n        await self._resp.close()\n\n\nclass _SessionRequestContextManager:\n    __slots__ = (\"_coro\", \"_resp\", \"_session\")\n\n    def __init__(\n        self,\n        coro: Coroutine[\"asyncio.Future[Any]\", None, ClientResponse],\n        session: ClientSession,\n    ) -> None:\n        self._coro = coro\n        self._resp: Optional[ClientResponse] = None\n        self._session = session\n\n    async def __aenter__(self) -> ClientResponse:\n        try:\n            self._resp = await self._coro\n        except BaseException:\n            await self._session.close()\n            raise\n        else:\n            return self._resp\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> None:\n        assert self._resp is not None\n        self._resp.close()\n        await self._session.close()\n\n\ndef request(\n    method: str,\n    url: StrOrURL,\n    *,\n    params: Optional[Mapping[str, str]] = None,\n    data: Any = None,\n    json: Any = None,\n    headers: Optional[LooseHeaders] = None,\n    skip_auto_headers: Optional[Iterable[str]] = None,\n    auth: Optional[BasicAuth] = None,\n    allow_redirects: bool = True,\n    max_redirects: int = 10,\n    compress: Optional[str] = None,\n    chunked: Optional[bool] = None,\n    expect100: bool = False,\n    raise_for_status: Optional[bool] = None,\n    read_until_eof: bool = True,\n    proxy: Optional[StrOrURL] = None,\n    proxy_auth: Optional[BasicAuth] = None,\n    timeout: Union[ClientTimeout, _SENTINEL] = sentinel,\n    cookies: Optional[LooseCookies] = None,\n    version: HttpVersion = http.HttpVersion11,\n    connector: Optional[BaseConnector] = None,\n    read_bufsize: Optional[int] = None,\n    max_line_size: int = 8190,\n    max_field_size: int = 8190,\n) -> _SessionRequestContextManager:\n    \"\"\"Constructs and sends a request.\n\n    Returns response object.\n    method - HTTP method\n    url - request url\n    params - (optional) Dictionary or bytes to be sent in the query\n      string of the new request\n    data - (optional) Dictionary, bytes, or file-like object to\n      send in the body of the request\n    json - (optional) Any json compatible python object\n    headers - (optional) Dictionary of HTTP Headers to send with\n      the request\n    cookies - (optional) Dict object to send with the request\n    auth - (optional) BasicAuth named tuple represent HTTP Basic Auth\n    auth - aiohttp.helpers.BasicAuth\n    allow_redirects - (optional) If set to False, do not follow\n      redirects\n    version - Request HTTP version.\n    compress - Set to True if request has to be compressed\n       with deflate encoding.\n    chunked - Set to chunk size for chunked transfer encoding.\n    expect100 - Expect 100-continue response from server.\n    connector - BaseConnector sub-class instance to support\n       connection pooling.\n    read_until_eof - Read response until eof if response\n       does not have Content-Length header.\n    loop - Optional event loop.\n    timeout - Optional ClientTimeout settings structure, 5min\n       total timeout by default.\n    Usage::\n      >>> import aiohttp\n      >>> async with aiohttp.request('GET', 'http://python.org/') as resp:\n      ...    print(resp)\n      ...    data = await resp.read()\n      <ClientResponse(https://www.python.org/) [200 OK]>\n    \"\"\"\n    connector_owner = False\n    if connector is None:\n        connector_owner = True\n        connector = TCPConnector(force_close=True)\n\n    session = ClientSession(\n        cookies=cookies,\n        version=version,\n        timeout=timeout,\n        connector=connector,\n        connector_owner=connector_owner,\n    )\n\n    return _SessionRequestContextManager(\n        session._request(\n            method,\n            url,\n            params=params,\n            data=data,\n            json=json,\n            headers=headers,\n            skip_auto_headers=skip_auto_headers,\n            auth=auth,\n            allow_redirects=allow_redirects,\n            max_redirects=max_redirects,\n            compress=compress,\n            chunked=chunked,\n            expect100=expect100,\n            raise_for_status=raise_for_status,\n            read_until_eof=read_until_eof,\n            proxy=proxy,\n            proxy_auth=proxy_auth,\n            read_bufsize=read_bufsize,\n            max_line_size=max_line_size,\n            max_field_size=max_field_size,\n        ),\n        session,\n    )\n", "aiohttp/client_exceptions.py": "\"\"\"HTTP related errors.\"\"\"\n\nimport asyncio\nfrom typing import TYPE_CHECKING, Optional, Tuple, Union\n\nfrom .http_parser import RawResponseMessage\nfrom .typedefs import LooseHeaders, StrOrURL\n\ntry:\n    import ssl\n\n    SSLContext = ssl.SSLContext\nexcept ImportError:  # pragma: no cover\n    ssl = SSLContext = None  # type: ignore[assignment]\n\n\nif TYPE_CHECKING:\n    from .client_reqrep import ClientResponse, ConnectionKey, Fingerprint, RequestInfo\nelse:\n    RequestInfo = ClientResponse = ConnectionKey = None\n\n__all__ = (\n    \"ClientError\",\n    \"ClientConnectionError\",\n    \"ClientOSError\",\n    \"ClientConnectorError\",\n    \"ClientProxyConnectionError\",\n    \"ClientSSLError\",\n    \"ClientConnectorSSLError\",\n    \"ClientConnectorCertificateError\",\n    \"ConnectionTimeoutError\",\n    \"SocketTimeoutError\",\n    \"ServerConnectionError\",\n    \"ServerTimeoutError\",\n    \"ServerDisconnectedError\",\n    \"ServerFingerprintMismatch\",\n    \"ClientResponseError\",\n    \"ClientHttpProxyError\",\n    \"WSServerHandshakeError\",\n    \"ContentTypeError\",\n    \"ClientPayloadError\",\n    \"InvalidURL\",\n    \"InvalidUrlClientError\",\n    \"RedirectClientError\",\n    \"NonHttpUrlClientError\",\n    \"InvalidUrlRedirectClientError\",\n    \"NonHttpUrlRedirectClientError\",\n)\n\n\nclass ClientError(Exception):\n    \"\"\"Base class for client connection errors.\"\"\"\n\n\nclass ClientResponseError(ClientError):\n    \"\"\"Base class for exceptions that occur after getting a response.\n\n    request_info: An instance of RequestInfo.\n    history: A sequence of responses, if redirects occurred.\n    status: HTTP status code.\n    message: Error message.\n    headers: Response headers.\n    \"\"\"\n\n    def __init__(\n        self,\n        request_info: RequestInfo,\n        history: Tuple[ClientResponse, ...],\n        *,\n        status: Optional[int] = None,\n        message: str = \"\",\n        headers: Optional[LooseHeaders] = None,\n    ) -> None:\n        self.request_info = request_info\n        if status is not None:\n            self.status = status\n        else:\n            self.status = 0\n        self.message = message\n        self.headers = headers\n        self.history = history\n        self.args = (request_info, history)\n\n    def __str__(self) -> str:\n        return \"{}, message={!r}, url={!r}\".format(\n            self.status,\n            self.message,\n            self.request_info.real_url,\n        )\n\n    def __repr__(self) -> str:\n        args = f\"{self.request_info!r}, {self.history!r}\"\n        if self.status != 0:\n            args += f\", status={self.status!r}\"\n        if self.message != \"\":\n            args += f\", message={self.message!r}\"\n        if self.headers is not None:\n            args += f\", headers={self.headers!r}\"\n        return f\"{type(self).__name__}({args})\"\n\n\nclass ContentTypeError(ClientResponseError):\n    \"\"\"ContentType found is not valid.\"\"\"\n\n\nclass WSServerHandshakeError(ClientResponseError):\n    \"\"\"websocket server handshake error.\"\"\"\n\n\nclass ClientHttpProxyError(ClientResponseError):\n    \"\"\"HTTP proxy error.\n\n    Raised in :class:`aiohttp.connector.TCPConnector` if\n    proxy responds with status other than ``200 OK``\n    on ``CONNECT`` request.\n    \"\"\"\n\n\nclass TooManyRedirects(ClientResponseError):\n    \"\"\"Client was redirected too many times.\"\"\"\n\n\nclass ClientConnectionError(ClientError):\n    \"\"\"Base class for client socket errors.\"\"\"\n\n\nclass ClientOSError(ClientConnectionError, OSError):\n    \"\"\"OSError error.\"\"\"\n\n\nclass ClientConnectorError(ClientOSError):\n    \"\"\"Client connector error.\n\n    Raised in :class:`aiohttp.connector.TCPConnector` if\n        a connection can not be established.\n    \"\"\"\n\n    def __init__(self, connection_key: ConnectionKey, os_error: OSError) -> None:\n        self._conn_key = connection_key\n        self._os_error = os_error\n        super().__init__(os_error.errno, os_error.strerror)\n        self.args = (connection_key, os_error)\n\n    @property\n    def os_error(self) -> OSError:\n        return self._os_error\n\n    @property\n    def host(self) -> str:\n        return self._conn_key.host\n\n    @property\n    def port(self) -> Optional[int]:\n        return self._conn_key.port\n\n    @property\n    def ssl(self) -> Union[SSLContext, bool, \"Fingerprint\"]:\n        return self._conn_key.ssl\n\n    def __str__(self) -> str:\n        return \"Cannot connect to host {0.host}:{0.port} ssl:{1} [{2}]\".format(\n            self, \"default\" if self.ssl is True else self.ssl, self.strerror\n        )\n\n    # OSError.__reduce__ does too much black magick\n    __reduce__ = BaseException.__reduce__\n\n\nclass ClientProxyConnectionError(ClientConnectorError):\n    \"\"\"Proxy connection error.\n\n    Raised in :class:`aiohttp.connector.TCPConnector` if\n        connection to proxy can not be established.\n    \"\"\"\n\n\nclass UnixClientConnectorError(ClientConnectorError):\n    \"\"\"Unix connector error.\n\n    Raised in :py:class:`aiohttp.connector.UnixConnector`\n    if connection to unix socket can not be established.\n    \"\"\"\n\n    def __init__(\n        self, path: str, connection_key: ConnectionKey, os_error: OSError\n    ) -> None:\n        self._path = path\n        super().__init__(connection_key, os_error)\n\n    @property\n    def path(self) -> str:\n        return self._path\n\n    def __str__(self) -> str:\n        return \"Cannot connect to unix socket {0.path} ssl:{1} [{2}]\".format(\n            self, \"default\" if self.ssl is True else self.ssl, self.strerror\n        )\n\n\nclass ServerConnectionError(ClientConnectionError):\n    \"\"\"Server connection errors.\"\"\"\n\n\nclass ServerDisconnectedError(ServerConnectionError):\n    \"\"\"Server disconnected.\"\"\"\n\n    def __init__(self, message: Union[RawResponseMessage, str, None] = None) -> None:\n        if message is None:\n            message = \"Server disconnected\"\n\n        self.args = (message,)\n        self.message = message\n\n\nclass ServerTimeoutError(ServerConnectionError, asyncio.TimeoutError):\n    \"\"\"Server timeout error.\"\"\"\n\n\nclass ConnectionTimeoutError(ServerTimeoutError):\n    \"\"\"Connection timeout error.\"\"\"\n\n\nclass SocketTimeoutError(ServerTimeoutError):\n    \"\"\"Socket timeout error.\"\"\"\n\n\nclass ServerFingerprintMismatch(ServerConnectionError):\n    \"\"\"SSL certificate does not match expected fingerprint.\"\"\"\n\n    def __init__(self, expected: bytes, got: bytes, host: str, port: int) -> None:\n        self.expected = expected\n        self.got = got\n        self.host = host\n        self.port = port\n        self.args = (expected, got, host, port)\n\n    def __repr__(self) -> str:\n        return \"<{} expected={!r} got={!r} host={!r} port={!r}>\".format(\n            self.__class__.__name__, self.expected, self.got, self.host, self.port\n        )\n\n\nclass ClientPayloadError(ClientError):\n    \"\"\"Response payload error.\"\"\"\n\n\nclass InvalidURL(ClientError, ValueError):\n    \"\"\"Invalid URL.\n\n    URL used for fetching is malformed, e.g. it doesn't contains host\n    part.\n    \"\"\"\n\n    # Derive from ValueError for backward compatibility\n\n    def __init__(self, url: StrOrURL, description: Union[str, None] = None) -> None:\n        # The type of url is not yarl.URL because the exception can be raised\n        # on URL(url) call\n        self._url = url\n        self._description = description\n\n        if description:\n            super().__init__(url, description)\n        else:\n            super().__init__(url)\n\n    @property\n    def url(self) -> StrOrURL:\n        return self._url\n\n    @property\n    def description(self) -> \"str | None\":\n        return self._description\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__.__name__} {self}>\"\n\n    def __str__(self) -> str:\n        if self._description:\n            return f\"{self._url} - {self._description}\"\n        return str(self._url)\n\n\nclass InvalidUrlClientError(InvalidURL):\n    \"\"\"Invalid URL client error.\"\"\"\n\n\nclass RedirectClientError(ClientError):\n    \"\"\"Client redirect error.\"\"\"\n\n\nclass NonHttpUrlClientError(ClientError):\n    \"\"\"Non http URL client error.\"\"\"\n\n\nclass InvalidUrlRedirectClientError(InvalidUrlClientError, RedirectClientError):\n    \"\"\"Invalid URL redirect client error.\"\"\"\n\n\nclass NonHttpUrlRedirectClientError(NonHttpUrlClientError, RedirectClientError):\n    \"\"\"Non http URL redirect client error.\"\"\"\n\n\nclass ClientSSLError(ClientConnectorError):\n    \"\"\"Base error for ssl.*Errors.\"\"\"\n\n\nif ssl is not None:\n    cert_errors = (ssl.CertificateError,)\n    cert_errors_bases = (\n        ClientSSLError,\n        ssl.CertificateError,\n    )\n\n    ssl_errors = (ssl.SSLError,)\n    ssl_error_bases = (ClientSSLError, ssl.SSLError)\nelse:  # pragma: no cover\n    cert_errors = tuple()\n    cert_errors_bases = (\n        ClientSSLError,\n        ValueError,\n    )\n\n    ssl_errors = tuple()\n    ssl_error_bases = (ClientSSLError,)\n\n\nclass ClientConnectorSSLError(*ssl_error_bases):  # type: ignore[misc]\n    \"\"\"Response ssl error.\"\"\"\n\n\nclass ClientConnectorCertificateError(*cert_errors_bases):  # type: ignore[misc]\n    \"\"\"Response certificate error.\"\"\"\n\n    def __init__(\n        self, connection_key: ConnectionKey, certificate_error: Exception\n    ) -> None:\n        self._conn_key = connection_key\n        self._certificate_error = certificate_error\n        self.args = (connection_key, certificate_error)\n\n    @property\n    def certificate_error(self) -> Exception:\n        return self._certificate_error\n\n    @property\n    def host(self) -> str:\n        return self._conn_key.host\n\n    @property\n    def port(self) -> Optional[int]:\n        return self._conn_key.port\n\n    @property\n    def ssl(self) -> bool:\n        return self._conn_key.is_ssl\n\n    def __str__(self) -> str:\n        return (\n            \"Cannot connect to host {0.host}:{0.port} ssl:{0.ssl} \"\n            \"[{0.certificate_error.__class__.__name__}: \"\n            \"{0.certificate_error.args}]\".format(self)\n        )\n", "aiohttp/hdrs.py": "\"\"\"HTTP Headers constants.\"\"\"\n\n# After changing the file content call ./tools/gen.py\n# to regenerate the headers parser\nfrom typing import Final, Set\n\nfrom multidict import istr\n\nMETH_ANY: Final[str] = \"*\"\nMETH_CONNECT: Final[str] = \"CONNECT\"\nMETH_HEAD: Final[str] = \"HEAD\"\nMETH_GET: Final[str] = \"GET\"\nMETH_DELETE: Final[str] = \"DELETE\"\nMETH_OPTIONS: Final[str] = \"OPTIONS\"\nMETH_PATCH: Final[str] = \"PATCH\"\nMETH_POST: Final[str] = \"POST\"\nMETH_PUT: Final[str] = \"PUT\"\nMETH_TRACE: Final[str] = \"TRACE\"\n\nMETH_ALL: Final[Set[str]] = {\n    METH_CONNECT,\n    METH_HEAD,\n    METH_GET,\n    METH_DELETE,\n    METH_OPTIONS,\n    METH_PATCH,\n    METH_POST,\n    METH_PUT,\n    METH_TRACE,\n}\n\nACCEPT: Final[istr] = istr(\"Accept\")\nACCEPT_CHARSET: Final[istr] = istr(\"Accept-Charset\")\nACCEPT_ENCODING: Final[istr] = istr(\"Accept-Encoding\")\nACCEPT_LANGUAGE: Final[istr] = istr(\"Accept-Language\")\nACCEPT_RANGES: Final[istr] = istr(\"Accept-Ranges\")\nACCESS_CONTROL_MAX_AGE: Final[istr] = istr(\"Access-Control-Max-Age\")\nACCESS_CONTROL_ALLOW_CREDENTIALS: Final[istr] = istr(\"Access-Control-Allow-Credentials\")\nACCESS_CONTROL_ALLOW_HEADERS: Final[istr] = istr(\"Access-Control-Allow-Headers\")\nACCESS_CONTROL_ALLOW_METHODS: Final[istr] = istr(\"Access-Control-Allow-Methods\")\nACCESS_CONTROL_ALLOW_ORIGIN: Final[istr] = istr(\"Access-Control-Allow-Origin\")\nACCESS_CONTROL_EXPOSE_HEADERS: Final[istr] = istr(\"Access-Control-Expose-Headers\")\nACCESS_CONTROL_REQUEST_HEADERS: Final[istr] = istr(\"Access-Control-Request-Headers\")\nACCESS_CONTROL_REQUEST_METHOD: Final[istr] = istr(\"Access-Control-Request-Method\")\nAGE: Final[istr] = istr(\"Age\")\nALLOW: Final[istr] = istr(\"Allow\")\nAUTHORIZATION: Final[istr] = istr(\"Authorization\")\nCACHE_CONTROL: Final[istr] = istr(\"Cache-Control\")\nCONNECTION: Final[istr] = istr(\"Connection\")\nCONTENT_DISPOSITION: Final[istr] = istr(\"Content-Disposition\")\nCONTENT_ENCODING: Final[istr] = istr(\"Content-Encoding\")\nCONTENT_LANGUAGE: Final[istr] = istr(\"Content-Language\")\nCONTENT_LENGTH: Final[istr] = istr(\"Content-Length\")\nCONTENT_LOCATION: Final[istr] = istr(\"Content-Location\")\nCONTENT_MD5: Final[istr] = istr(\"Content-MD5\")\nCONTENT_RANGE: Final[istr] = istr(\"Content-Range\")\nCONTENT_TRANSFER_ENCODING: Final[istr] = istr(\"Content-Transfer-Encoding\")\nCONTENT_TYPE: Final[istr] = istr(\"Content-Type\")\nCOOKIE: Final[istr] = istr(\"Cookie\")\nDATE: Final[istr] = istr(\"Date\")\nDESTINATION: Final[istr] = istr(\"Destination\")\nDIGEST: Final[istr] = istr(\"Digest\")\nETAG: Final[istr] = istr(\"Etag\")\nEXPECT: Final[istr] = istr(\"Expect\")\nEXPIRES: Final[istr] = istr(\"Expires\")\nFORWARDED: Final[istr] = istr(\"Forwarded\")\nFROM: Final[istr] = istr(\"From\")\nHOST: Final[istr] = istr(\"Host\")\nIF_MATCH: Final[istr] = istr(\"If-Match\")\nIF_MODIFIED_SINCE: Final[istr] = istr(\"If-Modified-Since\")\nIF_NONE_MATCH: Final[istr] = istr(\"If-None-Match\")\nIF_RANGE: Final[istr] = istr(\"If-Range\")\nIF_UNMODIFIED_SINCE: Final[istr] = istr(\"If-Unmodified-Since\")\nKEEP_ALIVE: Final[istr] = istr(\"Keep-Alive\")\nLAST_EVENT_ID: Final[istr] = istr(\"Last-Event-ID\")\nLAST_MODIFIED: Final[istr] = istr(\"Last-Modified\")\nLINK: Final[istr] = istr(\"Link\")\nLOCATION: Final[istr] = istr(\"Location\")\nMAX_FORWARDS: Final[istr] = istr(\"Max-Forwards\")\nORIGIN: Final[istr] = istr(\"Origin\")\nPRAGMA: Final[istr] = istr(\"Pragma\")\nPROXY_AUTHENTICATE: Final[istr] = istr(\"Proxy-Authenticate\")\nPROXY_AUTHORIZATION: Final[istr] = istr(\"Proxy-Authorization\")\nRANGE: Final[istr] = istr(\"Range\")\nREFERER: Final[istr] = istr(\"Referer\")\nRETRY_AFTER: Final[istr] = istr(\"Retry-After\")\nSEC_WEBSOCKET_ACCEPT: Final[istr] = istr(\"Sec-WebSocket-Accept\")\nSEC_WEBSOCKET_VERSION: Final[istr] = istr(\"Sec-WebSocket-Version\")\nSEC_WEBSOCKET_PROTOCOL: Final[istr] = istr(\"Sec-WebSocket-Protocol\")\nSEC_WEBSOCKET_EXTENSIONS: Final[istr] = istr(\"Sec-WebSocket-Extensions\")\nSEC_WEBSOCKET_KEY: Final[istr] = istr(\"Sec-WebSocket-Key\")\nSEC_WEBSOCKET_KEY1: Final[istr] = istr(\"Sec-WebSocket-Key1\")\nSERVER: Final[istr] = istr(\"Server\")\nSET_COOKIE: Final[istr] = istr(\"Set-Cookie\")\nTE: Final[istr] = istr(\"TE\")\nTRAILER: Final[istr] = istr(\"Trailer\")\nTRANSFER_ENCODING: Final[istr] = istr(\"Transfer-Encoding\")\nUPGRADE: Final[istr] = istr(\"Upgrade\")\nURI: Final[istr] = istr(\"URI\")\nUSER_AGENT: Final[istr] = istr(\"User-Agent\")\nVARY: Final[istr] = istr(\"Vary\")\nVIA: Final[istr] = istr(\"Via\")\nWANT_DIGEST: Final[istr] = istr(\"Want-Digest\")\nWARNING: Final[istr] = istr(\"Warning\")\nWWW_AUTHENTICATE: Final[istr] = istr(\"WWW-Authenticate\")\nX_FORWARDED_FOR: Final[istr] = istr(\"X-Forwarded-For\")\nX_FORWARDED_HOST: Final[istr] = istr(\"X-Forwarded-Host\")\nX_FORWARDED_PROTO: Final[istr] = istr(\"X-Forwarded-Proto\")\n", "aiohttp/web_middlewares.py": "import re\nimport warnings\nfrom typing import TYPE_CHECKING, Tuple, Type, TypeVar\n\nfrom .typedefs import Handler, Middleware\nfrom .web_exceptions import HTTPMove, HTTPPermanentRedirect\nfrom .web_request import Request\nfrom .web_response import StreamResponse\nfrom .web_urldispatcher import SystemRoute\n\n__all__ = (\n    \"middleware\",\n    \"normalize_path_middleware\",\n)\n\nif TYPE_CHECKING:\n    from .web_app import Application\n\n_Func = TypeVar(\"_Func\")\n\n\nasync def _check_request_resolves(request: Request, path: str) -> Tuple[bool, Request]:\n    alt_request = request.clone(rel_url=path)\n\n    match_info = await request.app.router.resolve(alt_request)\n    alt_request._match_info = match_info\n\n    if match_info.http_exception is None:\n        return True, alt_request\n\n    return False, request\n\n\ndef middleware(f: _Func) -> _Func:\n    warnings.warn(\n        \"Middleware decorator is deprecated since 4.0 \"\n        \"and its behaviour is default, \"\n        \"you can simply remove this decorator.\",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    return f\n\n\ndef normalize_path_middleware(\n    *,\n    append_slash: bool = True,\n    remove_slash: bool = False,\n    merge_slashes: bool = True,\n    redirect_class: Type[HTTPMove] = HTTPPermanentRedirect,\n) -> Middleware:\n    \"\"\"Factory for producing a middleware that normalizes the path of a request.\n\n    Normalizing means:\n        - Add or remove a trailing slash to the path.\n        - Double slashes are replaced by one.\n\n    The middleware returns as soon as it finds a path that resolves\n    correctly. The order if both merge and append/remove are enabled is\n        1) merge slashes\n        2) append/remove slash\n        3) both merge slashes and append/remove slash.\n    If the path resolves with at least one of those conditions, it will\n    redirect to the new path.\n\n    Only one of `append_slash` and `remove_slash` can be enabled. If both\n    are `True` the factory will raise an assertion error\n\n    If `append_slash` is `True` the middleware will append a slash when\n    needed. If a resource is defined with trailing slash and the request\n    comes without it, it will append it automatically.\n\n    If `remove_slash` is `True`, `append_slash` must be `False`. When enabled\n    the middleware will remove trailing slashes and redirect if the resource\n    is defined\n\n    If merge_slashes is True, merge multiple consecutive slashes in the\n    path into one.\n    \"\"\"\n    correct_configuration = not (append_slash and remove_slash)\n    assert correct_configuration, \"Cannot both remove and append slash\"\n\n    async def impl(request: Request, handler: Handler) -> StreamResponse:\n        if isinstance(request.match_info.route, SystemRoute):\n            paths_to_check = []\n            if \"?\" in request.raw_path:\n                path, query = request.raw_path.split(\"?\", 1)\n                query = \"?\" + query\n            else:\n                query = \"\"\n                path = request.raw_path\n\n            if merge_slashes:\n                paths_to_check.append(re.sub(\"//+\", \"/\", path))\n            if append_slash and not request.path.endswith(\"/\"):\n                paths_to_check.append(path + \"/\")\n            if remove_slash and request.path.endswith(\"/\"):\n                paths_to_check.append(path[:-1])\n            if merge_slashes and append_slash:\n                paths_to_check.append(re.sub(\"//+\", \"/\", path + \"/\"))\n            if merge_slashes and remove_slash and path.endswith(\"/\"):\n                merged_slashes = re.sub(\"//+\", \"/\", path)\n                paths_to_check.append(merged_slashes[:-1])\n\n            for path in paths_to_check:\n                path = re.sub(\"^//+\", \"/\", path)  # SECURITY: GHSA-v6wp-4m6f-gcjg\n                resolves, request = await _check_request_resolves(request, path)\n                if resolves:\n                    raise redirect_class(request.raw_path + query)\n\n        return await handler(request)\n\n    return impl\n\n\ndef _fix_request_current_app(app: \"Application\") -> Middleware:\n    async def impl(request: Request, handler: Handler) -> StreamResponse:\n        with request.match_info.set_current_app(app):\n            return await handler(request)\n\n    return impl\n", "aiohttp/client_proto.py": "import asyncio\nfrom contextlib import suppress\nfrom typing import Any, Optional, Tuple\n\nfrom .base_protocol import BaseProtocol\nfrom .client_exceptions import (\n    ClientConnectionError,\n    ClientOSError,\n    ClientPayloadError,\n    ServerDisconnectedError,\n    SocketTimeoutError,\n)\nfrom .helpers import (\n    _EXC_SENTINEL,\n    BaseTimerContext,\n    set_exception,\n    set_result,\n    status_code_must_be_empty_body,\n)\nfrom .http import HttpResponseParser, RawResponseMessage, WebSocketReader\nfrom .http_exceptions import HttpProcessingError\nfrom .streams import EMPTY_PAYLOAD, DataQueue, StreamReader\n\n\nclass ResponseHandler(BaseProtocol, DataQueue[Tuple[RawResponseMessage, StreamReader]]):\n    \"\"\"Helper class to adapt between Protocol and StreamReader.\"\"\"\n\n    def __init__(self, loop: asyncio.AbstractEventLoop) -> None:\n        BaseProtocol.__init__(self, loop=loop)\n        DataQueue.__init__(self, loop)\n\n        self._should_close = False\n\n        self._payload: Optional[StreamReader] = None\n        self._skip_payload = False\n        self._payload_parser: Optional[WebSocketReader] = None\n\n        self._timer = None\n\n        self._tail = b\"\"\n        self._upgraded = False\n        self._parser: Optional[HttpResponseParser] = None\n\n        self._read_timeout: Optional[float] = None\n        self._read_timeout_handle: Optional[asyncio.TimerHandle] = None\n\n        self._timeout_ceil_threshold: Optional[float] = 5\n\n        self.closed: asyncio.Future[None] = self._loop.create_future()\n\n    @property\n    def upgraded(self) -> bool:\n        return self._upgraded\n\n    @property\n    def should_close(self) -> bool:\n        if self._payload is not None and not self._payload.is_eof():\n            return True\n\n        return (\n            self._should_close\n            or self._upgraded\n            or self.exception() is not None\n            or self._payload_parser is not None\n            or len(self) > 0\n            or bool(self._tail)\n        )\n\n    def force_close(self) -> None:\n        self._should_close = True\n\n    def close(self) -> None:\n        transport = self.transport\n        if transport is not None:\n            transport.close()\n            self.transport = None\n            self._payload = None\n            self._drop_timeout()\n\n    def is_connected(self) -> bool:\n        return self.transport is not None and not self.transport.is_closing()\n\n    def connection_lost(self, exc: Optional[BaseException]) -> None:\n        self._drop_timeout()\n\n        original_connection_error = exc\n        reraised_exc = original_connection_error\n\n        connection_closed_cleanly = original_connection_error is None\n\n        if connection_closed_cleanly:\n            set_result(self.closed, None)\n        else:\n            assert original_connection_error is not None\n            set_exception(\n                self.closed,\n                ClientConnectionError(\n                    f\"Connection lost: {original_connection_error !s}\",\n                ),\n                original_connection_error,\n            )\n\n        if self._payload_parser is not None:\n            with suppress(Exception):  # FIXME: log this somehow?\n                self._payload_parser.feed_eof()\n\n        uncompleted = None\n        if self._parser is not None:\n            try:\n                uncompleted = self._parser.feed_eof()\n            except Exception as underlying_exc:\n                if self._payload is not None:\n                    client_payload_exc_msg = (\n                        f\"Response payload is not completed: {underlying_exc !r}\"\n                    )\n                    if not connection_closed_cleanly:\n                        client_payload_exc_msg = (\n                            f\"{client_payload_exc_msg !s}. \"\n                            f\"{original_connection_error !r}\"\n                        )\n                    set_exception(\n                        self._payload,\n                        ClientPayloadError(client_payload_exc_msg),\n                        underlying_exc,\n                    )\n\n        if not self.is_eof():\n            if isinstance(original_connection_error, OSError):\n                reraised_exc = ClientOSError(*original_connection_error.args)\n            if connection_closed_cleanly:\n                reraised_exc = ServerDisconnectedError(uncompleted)\n            # assigns self._should_close to True as side effect,\n            # we do it anyway below\n            underlying_non_eof_exc = (\n                _EXC_SENTINEL\n                if connection_closed_cleanly\n                else original_connection_error\n            )\n            assert underlying_non_eof_exc is not None\n            assert reraised_exc is not None\n            self.set_exception(reraised_exc, underlying_non_eof_exc)\n\n        self._should_close = True\n        self._parser = None\n        self._payload = None\n        self._payload_parser = None\n        self._reading_paused = False\n\n        super().connection_lost(reraised_exc)\n\n    def eof_received(self) -> None:\n        # should call parser.feed_eof() most likely\n        self._drop_timeout()\n\n    def pause_reading(self) -> None:\n        super().pause_reading()\n        self._drop_timeout()\n\n    def resume_reading(self) -> None:\n        super().resume_reading()\n        self._reschedule_timeout()\n\n    def set_exception(\n        self,\n        exc: BaseException,\n        exc_cause: BaseException = _EXC_SENTINEL,\n    ) -> None:\n        self._should_close = True\n        self._drop_timeout()\n        super().set_exception(exc, exc_cause)\n\n    def set_parser(self, parser: Any, payload: Any) -> None:\n        # TODO: actual types are:\n        #   parser: WebSocketReader\n        #   payload: FlowControlDataQueue\n        # but they are not generi enough\n        # Need an ABC for both types\n        self._payload = payload\n        self._payload_parser = parser\n\n        self._drop_timeout()\n\n        if self._tail:\n            data, self._tail = self._tail, b\"\"\n            self.data_received(data)\n\n    def set_response_params(\n        self,\n        *,\n        timer: Optional[BaseTimerContext] = None,\n        skip_payload: bool = False,\n        read_until_eof: bool = False,\n        auto_decompress: bool = True,\n        read_timeout: Optional[float] = None,\n        read_bufsize: int = 2**16,\n        timeout_ceil_threshold: float = 5,\n        max_line_size: int = 8190,\n        max_field_size: int = 8190,\n    ) -> None:\n        self._skip_payload = skip_payload\n\n        self._read_timeout = read_timeout\n\n        self._timeout_ceil_threshold = timeout_ceil_threshold\n\n        self._parser = HttpResponseParser(\n            self,\n            self._loop,\n            read_bufsize,\n            timer=timer,\n            payload_exception=ClientPayloadError,\n            response_with_body=not skip_payload,\n            read_until_eof=read_until_eof,\n            auto_decompress=auto_decompress,\n            max_line_size=max_line_size,\n            max_field_size=max_field_size,\n        )\n\n        if self._tail:\n            data, self._tail = self._tail, b\"\"\n            self.data_received(data)\n\n    def _drop_timeout(self) -> None:\n        if self._read_timeout_handle is not None:\n            self._read_timeout_handle.cancel()\n            self._read_timeout_handle = None\n\n    def _reschedule_timeout(self) -> None:\n        timeout = self._read_timeout\n        if self._read_timeout_handle is not None:\n            self._read_timeout_handle.cancel()\n\n        if timeout:\n            self._read_timeout_handle = self._loop.call_later(\n                timeout, self._on_read_timeout\n            )\n        else:\n            self._read_timeout_handle = None\n\n    def start_timeout(self) -> None:\n        self._reschedule_timeout()\n\n    def _on_read_timeout(self) -> None:\n        exc = SocketTimeoutError(\"Timeout on reading data from socket\")\n        self.set_exception(exc)\n        if self._payload is not None:\n            set_exception(self._payload, exc)\n\n    def data_received(self, data: bytes) -> None:\n        self._reschedule_timeout()\n\n        if not data:\n            return\n\n        # custom payload parser\n        if self._payload_parser is not None:\n            eof, tail = self._payload_parser.feed_data(data)\n            if eof:\n                self._payload = None\n                self._payload_parser = None\n\n                if tail:\n                    self.data_received(tail)\n            return\n        else:\n            if self._upgraded or self._parser is None:\n                # i.e. websocket connection, websocket parser is not set yet\n                self._tail += data\n            else:\n                # parse http messages\n                try:\n                    messages, upgraded, tail = self._parser.feed_data(data)\n                except BaseException as underlying_exc:\n                    if self.transport is not None:\n                        # connection.release() could be called BEFORE\n                        # data_received(), the transport is already\n                        # closed in this case\n                        self.transport.close()\n                    # should_close is True after the call\n                    self.set_exception(HttpProcessingError(), underlying_exc)\n                    return\n\n                self._upgraded = upgraded\n\n                payload: Optional[StreamReader] = None\n                for message, payload in messages:\n                    if message.should_close:\n                        self._should_close = True\n\n                    self._payload = payload\n\n                    if self._skip_payload or status_code_must_be_empty_body(\n                        message.code\n                    ):\n                        self.feed_data((message, EMPTY_PAYLOAD))\n                    else:\n                        self.feed_data((message, payload))\n                if payload is not None:\n                    # new message(s) was processed\n                    # register timeout handler unsubscribing\n                    # either on end-of-stream or immediately for\n                    # EMPTY_PAYLOAD\n                    if payload is not EMPTY_PAYLOAD:\n                        payload.on_eof(self._drop_timeout)\n                    else:\n                        self._drop_timeout()\n\n                if tail:\n                    if upgraded:\n                        self.data_received(tail)\n                    else:\n                        self._tail = tail\n", "aiohttp/__init__.py": "__version__ = \"4.0.0a2.dev0\"\n\nfrom typing import TYPE_CHECKING, Tuple\n\nfrom . import hdrs\nfrom .client import (\n    BaseConnector,\n    ClientConnectionError,\n    ClientConnectorCertificateError,\n    ClientConnectorError,\n    ClientConnectorSSLError,\n    ClientError,\n    ClientHttpProxyError,\n    ClientOSError,\n    ClientPayloadError,\n    ClientProxyConnectionError,\n    ClientRequest,\n    ClientResponse,\n    ClientResponseError,\n    ClientSession,\n    ClientSSLError,\n    ClientTimeout,\n    ClientWebSocketResponse,\n    ConnectionTimeoutError,\n    ContentTypeError,\n    Fingerprint,\n    InvalidURL,\n    InvalidUrlClientError,\n    InvalidUrlRedirectClientError,\n    NamedPipeConnector,\n    NonHttpUrlClientError,\n    NonHttpUrlRedirectClientError,\n    RedirectClientError,\n    RequestInfo,\n    ServerConnectionError,\n    ServerDisconnectedError,\n    ServerFingerprintMismatch,\n    ServerTimeoutError,\n    SocketTimeoutError,\n    TCPConnector,\n    TooManyRedirects,\n    UnixConnector,\n    WSServerHandshakeError,\n    request,\n)\nfrom .cookiejar import CookieJar, DummyCookieJar\nfrom .formdata import FormData\nfrom .helpers import BasicAuth, ChainMapProxy, ETag\nfrom .http import (\n    HttpVersion,\n    HttpVersion10,\n    HttpVersion11,\n    WebSocketError,\n    WSCloseCode,\n    WSMessage,\n    WSMsgType,\n)\nfrom .multipart import (\n    BadContentDispositionHeader,\n    BadContentDispositionParam,\n    BodyPartReader,\n    MultipartReader,\n    MultipartWriter,\n    content_disposition_filename,\n    parse_content_disposition,\n)\nfrom .payload import (\n    PAYLOAD_REGISTRY,\n    AsyncIterablePayload,\n    BufferedReaderPayload,\n    BytesIOPayload,\n    BytesPayload,\n    IOBasePayload,\n    JsonPayload,\n    Payload,\n    StringIOPayload,\n    StringPayload,\n    TextIOPayload,\n    get_payload,\n    payload_type,\n)\nfrom .resolver import AsyncResolver, DefaultResolver, ThreadedResolver\nfrom .streams import (\n    EMPTY_PAYLOAD,\n    DataQueue,\n    EofStream,\n    FlowControlDataQueue,\n    StreamReader,\n)\nfrom .tracing import (\n    TraceConfig,\n    TraceConnectionCreateEndParams,\n    TraceConnectionCreateStartParams,\n    TraceConnectionQueuedEndParams,\n    TraceConnectionQueuedStartParams,\n    TraceConnectionReuseconnParams,\n    TraceDnsCacheHitParams,\n    TraceDnsCacheMissParams,\n    TraceDnsResolveHostEndParams,\n    TraceDnsResolveHostStartParams,\n    TraceRequestChunkSentParams,\n    TraceRequestEndParams,\n    TraceRequestExceptionParams,\n    TraceRequestRedirectParams,\n    TraceRequestStartParams,\n    TraceResponseChunkReceivedParams,\n)\n\nif TYPE_CHECKING:\n    # At runtime these are lazy-loaded at the bottom of the file.\n    from .worker import GunicornUVLoopWebWorker, GunicornWebWorker\n\n__all__: Tuple[str, ...] = (\n    \"hdrs\",\n    # client\n    \"BaseConnector\",\n    \"ClientConnectionError\",\n    \"ClientConnectorCertificateError\",\n    \"ClientConnectorError\",\n    \"ClientConnectorSSLError\",\n    \"ClientError\",\n    \"ClientHttpProxyError\",\n    \"ClientOSError\",\n    \"ClientPayloadError\",\n    \"ClientProxyConnectionError\",\n    \"ClientResponse\",\n    \"ClientRequest\",\n    \"ClientResponseError\",\n    \"ClientSSLError\",\n    \"ClientSession\",\n    \"ClientTimeout\",\n    \"ClientWebSocketResponse\",\n    \"ConnectionTimeoutError\",\n    \"ContentTypeError\",\n    \"Fingerprint\",\n    \"InvalidURL\",\n    \"InvalidUrlClientError\",\n    \"InvalidUrlRedirectClientError\",\n    \"NonHttpUrlClientError\",\n    \"NonHttpUrlRedirectClientError\",\n    \"RedirectClientError\",\n    \"RequestInfo\",\n    \"ServerConnectionError\",\n    \"ServerDisconnectedError\",\n    \"ServerFingerprintMismatch\",\n    \"ServerTimeoutError\",\n    \"SocketTimeoutError\",\n    \"TCPConnector\",\n    \"TooManyRedirects\",\n    \"UnixConnector\",\n    \"NamedPipeConnector\",\n    \"WSServerHandshakeError\",\n    \"request\",\n    # cookiejar\n    \"CookieJar\",\n    \"DummyCookieJar\",\n    # formdata\n    \"FormData\",\n    # helpers\n    \"BasicAuth\",\n    \"ChainMapProxy\",\n    \"ETag\",\n    # http\n    \"HttpVersion\",\n    \"HttpVersion10\",\n    \"HttpVersion11\",\n    \"WSMsgType\",\n    \"WSCloseCode\",\n    \"WSMessage\",\n    \"WebSocketError\",\n    # multipart\n    \"BadContentDispositionHeader\",\n    \"BadContentDispositionParam\",\n    \"BodyPartReader\",\n    \"MultipartReader\",\n    \"MultipartWriter\",\n    \"content_disposition_filename\",\n    \"parse_content_disposition\",\n    # payload\n    \"AsyncIterablePayload\",\n    \"BufferedReaderPayload\",\n    \"BytesIOPayload\",\n    \"BytesPayload\",\n    \"IOBasePayload\",\n    \"JsonPayload\",\n    \"PAYLOAD_REGISTRY\",\n    \"Payload\",\n    \"StringIOPayload\",\n    \"StringPayload\",\n    \"TextIOPayload\",\n    \"get_payload\",\n    \"payload_type\",\n    # resolver\n    \"AsyncResolver\",\n    \"DefaultResolver\",\n    \"ThreadedResolver\",\n    # streams\n    \"DataQueue\",\n    \"EMPTY_PAYLOAD\",\n    \"EofStream\",\n    \"FlowControlDataQueue\",\n    \"StreamReader\",\n    # tracing\n    \"TraceConfig\",\n    \"TraceConnectionCreateEndParams\",\n    \"TraceConnectionCreateStartParams\",\n    \"TraceConnectionQueuedEndParams\",\n    \"TraceConnectionQueuedStartParams\",\n    \"TraceConnectionReuseconnParams\",\n    \"TraceDnsCacheHitParams\",\n    \"TraceDnsCacheMissParams\",\n    \"TraceDnsResolveHostEndParams\",\n    \"TraceDnsResolveHostStartParams\",\n    \"TraceRequestChunkSentParams\",\n    \"TraceRequestEndParams\",\n    \"TraceRequestExceptionParams\",\n    \"TraceRequestRedirectParams\",\n    \"TraceRequestStartParams\",\n    \"TraceResponseChunkReceivedParams\",\n    # workers (imported lazily with __getattr__)\n    \"GunicornUVLoopWebWorker\",\n    \"GunicornWebWorker\",\n)\n\n\ndef __dir__() -> Tuple[str, ...]:\n    return __all__ + (\"__author__\", \"__doc__\")\n\n\ndef __getattr__(name: str) -> object:\n    global GunicornUVLoopWebWorker, GunicornWebWorker\n\n    # Importing gunicorn takes a long time (>100ms), so only import if actually needed.\n    if name in (\"GunicornUVLoopWebWorker\", \"GunicornWebWorker\"):\n        try:\n            from .worker import GunicornUVLoopWebWorker as guv, GunicornWebWorker as gw\n        except ImportError:\n            return None\n\n        GunicornUVLoopWebWorker = guv  # type: ignore[misc]\n        GunicornWebWorker = gw  # type: ignore[misc]\n        return guv if name == \"GunicornUVLoopWebWorker\" else gw\n\n    raise AttributeError(f\"module {__name__} has no attribute {name}\")\n", "aiohttp/cookiejar.py": "import calendar\nimport contextlib\nimport datetime\nimport itertools\nimport os  # noqa\nimport pathlib\nimport pickle\nimport re\nimport time\nimport warnings\nfrom collections import defaultdict\nfrom http.cookies import BaseCookie, Morsel, SimpleCookie\nfrom math import ceil\nfrom typing import (\n    DefaultDict,\n    Dict,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    Optional,\n    Set,\n    Tuple,\n    Union,\n    cast,\n)\n\nfrom yarl import URL\n\nfrom .abc import AbstractCookieJar, ClearCookiePredicate\nfrom .helpers import is_ip_address\nfrom .typedefs import LooseCookies, PathLike, StrOrURL\n\n__all__ = (\"CookieJar\", \"DummyCookieJar\")\n\n\nCookieItem = Union[str, \"Morsel[str]\"]\n\n\nclass CookieJar(AbstractCookieJar):\n    \"\"\"Implements cookie storage adhering to RFC 6265.\"\"\"\n\n    DATE_TOKENS_RE = re.compile(\n        r\"[\\x09\\x20-\\x2F\\x3B-\\x40\\x5B-\\x60\\x7B-\\x7E]*\"\n        r\"(?P<token>[\\x00-\\x08\\x0A-\\x1F\\d:a-zA-Z\\x7F-\\xFF]+)\"\n    )\n\n    DATE_HMS_TIME_RE = re.compile(r\"(\\d{1,2}):(\\d{1,2}):(\\d{1,2})\")\n\n    DATE_DAY_OF_MONTH_RE = re.compile(r\"(\\d{1,2})\")\n\n    DATE_MONTH_RE = re.compile(\n        \"(jan)|(feb)|(mar)|(apr)|(may)|(jun)|(jul)|\" \"(aug)|(sep)|(oct)|(nov)|(dec)\",\n        re.I,\n    )\n\n    DATE_YEAR_RE = re.compile(r\"(\\d{2,4})\")\n\n    # calendar.timegm() fails for timestamps after datetime.datetime.max\n    # Minus one as a loss of precision occurs when timestamp() is called.\n    MAX_TIME = (\n        int(datetime.datetime.max.replace(tzinfo=datetime.timezone.utc).timestamp()) - 1\n    )\n    try:\n        calendar.timegm(time.gmtime(MAX_TIME))\n    except (OSError, ValueError):\n        # Hit the maximum representable time on Windows\n        # https://learn.microsoft.com/en-us/cpp/c-runtime-library/reference/localtime-localtime32-localtime64\n        # Throws ValueError on PyPy 3.8 and 3.9, OSError elsewhere\n        MAX_TIME = calendar.timegm((3000, 12, 31, 23, 59, 59, -1, -1, -1))\n    except OverflowError:\n        # #4515: datetime.max may not be representable on 32-bit platforms\n        MAX_TIME = 2**31 - 1\n    # Avoid minuses in the future, 3x faster\n    SUB_MAX_TIME = MAX_TIME - 1\n\n    def __init__(\n        self,\n        *,\n        unsafe: bool = False,\n        quote_cookie: bool = True,\n        treat_as_secure_origin: Union[StrOrURL, List[StrOrURL], None] = None,\n    ) -> None:\n        self._cookies: DefaultDict[Tuple[str, str], SimpleCookie] = defaultdict(\n            SimpleCookie\n        )\n        self._host_only_cookies: Set[Tuple[str, str]] = set()\n        self._unsafe = unsafe\n        self._quote_cookie = quote_cookie\n        if treat_as_secure_origin is None:\n            treat_as_secure_origin = []\n        elif isinstance(treat_as_secure_origin, URL):\n            treat_as_secure_origin = [treat_as_secure_origin.origin()]\n        elif isinstance(treat_as_secure_origin, str):\n            treat_as_secure_origin = [URL(treat_as_secure_origin).origin()]\n        else:\n            treat_as_secure_origin = [\n                URL(url).origin() if isinstance(url, str) else url.origin()\n                for url in treat_as_secure_origin\n            ]\n        self._treat_as_secure_origin = treat_as_secure_origin\n        self._next_expiration: float = ceil(time.time())\n        self._expirations: Dict[Tuple[str, str, str], float] = {}\n\n    def save(self, file_path: PathLike) -> None:\n        file_path = pathlib.Path(file_path)\n        with file_path.open(mode=\"wb\") as f:\n            pickle.dump(self._cookies, f, pickle.HIGHEST_PROTOCOL)\n\n    def load(self, file_path: PathLike) -> None:\n        file_path = pathlib.Path(file_path)\n        with file_path.open(mode=\"rb\") as f:\n            self._cookies = pickle.load(f)\n\n    def clear(self, predicate: Optional[ClearCookiePredicate] = None) -> None:\n        if predicate is None:\n            self._next_expiration = ceil(time.time())\n            self._cookies.clear()\n            self._host_only_cookies.clear()\n            self._expirations.clear()\n            return\n\n        to_del = []\n        now = time.time()\n        for (domain, path), cookie in self._cookies.items():\n            for name, morsel in cookie.items():\n                key = (domain, path, name)\n                if (\n                    key in self._expirations and self._expirations[key] <= now\n                ) or predicate(morsel):\n                    to_del.append(key)\n\n        for domain, path, name in to_del:\n            self._host_only_cookies.discard((domain, name))\n            key = (domain, path, name)\n            if key in self._expirations:\n                del self._expirations[(domain, path, name)]\n            self._cookies[(domain, path)].pop(name, None)\n\n        self._next_expiration = (\n            min(*self._expirations.values(), self.SUB_MAX_TIME) + 1\n            if self._expirations\n            else self.MAX_TIME\n        )\n\n    def clear_domain(self, domain: str) -> None:\n        self.clear(lambda x: self._is_domain_match(domain, x[\"domain\"]))\n\n    def __iter__(self) -> \"Iterator[Morsel[str]]\":\n        self._do_expiration()\n        for val in self._cookies.values():\n            yield from val.values()\n\n    def __len__(self) -> int:\n        \"\"\"Return number of cookies.\n\n        This function does not iterate self to avoid unnecessary expiration\n        checks.\n        \"\"\"\n        return sum(len(cookie.values()) for cookie in self._cookies.values())\n\n    def _do_expiration(self) -> None:\n        self.clear(lambda x: False)\n\n    def _expire_cookie(self, when: float, domain: str, path: str, name: str) -> None:\n        self._next_expiration = min(self._next_expiration, when)\n        self._expirations[(domain, path, name)] = when\n\n    def update_cookies(self, cookies: LooseCookies, response_url: URL = URL()) -> None:\n        \"\"\"Update cookies.\"\"\"\n        hostname = response_url.raw_host\n\n        if not self._unsafe and is_ip_address(hostname):\n            # Don't accept cookies from IPs\n            return\n\n        if isinstance(cookies, Mapping):\n            cookies = cookies.items()\n\n        for name, cookie in cookies:\n            if not isinstance(cookie, Morsel):\n                tmp = SimpleCookie()\n                tmp[name] = cookie  # type: ignore[assignment]\n                cookie = tmp[name]\n\n            domain = cookie[\"domain\"]\n\n            # ignore domains with trailing dots\n            if domain.endswith(\".\"):\n                domain = \"\"\n                del cookie[\"domain\"]\n\n            if not domain and hostname is not None:\n                # Set the cookie's domain to the response hostname\n                # and set its host-only-flag\n                self._host_only_cookies.add((hostname, name))\n                domain = cookie[\"domain\"] = hostname\n\n            if domain.startswith(\".\"):\n                # Remove leading dot\n                domain = domain[1:]\n                cookie[\"domain\"] = domain\n\n            if hostname and not self._is_domain_match(domain, hostname):\n                # Setting cookies for different domains is not allowed\n                continue\n\n            path = cookie[\"path\"]\n            if not path or not path.startswith(\"/\"):\n                # Set the cookie's path to the response path\n                path = response_url.path\n                if not path.startswith(\"/\"):\n                    path = \"/\"\n                else:\n                    # Cut everything from the last slash to the end\n                    path = \"/\" + path[1 : path.rfind(\"/\")]\n                cookie[\"path\"] = path\n            path = path.rstrip(\"/\")\n\n            max_age = cookie[\"max-age\"]\n            if max_age:\n                try:\n                    delta_seconds = int(max_age)\n                    max_age_expiration = min(time.time() + delta_seconds, self.MAX_TIME)\n                    self._expire_cookie(max_age_expiration, domain, path, name)\n                except ValueError:\n                    cookie[\"max-age\"] = \"\"\n\n            else:\n                expires = cookie[\"expires\"]\n                if expires:\n                    expire_time = self._parse_date(expires)\n                    if expire_time:\n                        self._expire_cookie(expire_time, domain, path, name)\n                    else:\n                        cookie[\"expires\"] = \"\"\n\n            self._cookies[(domain, path)][name] = cookie\n\n        self._do_expiration()\n\n    def filter_cookies(self, request_url: URL = URL()) -> \"BaseCookie[str]\":\n        \"\"\"Returns this jar's cookies filtered by their attributes.\"\"\"\n        if not isinstance(request_url, URL):\n            warnings.warn(\n                \"The method accepts yarl.URL instances only, got {}\".format(\n                    type(request_url)\n                ),\n                DeprecationWarning,\n            )\n            request_url = URL(request_url)\n        filtered: Union[SimpleCookie, \"BaseCookie[str]\"] = (\n            SimpleCookie() if self._quote_cookie else BaseCookie()\n        )\n        if not self._cookies:\n            # Skip do_expiration() if there are no cookies.\n            return filtered\n        self._do_expiration()\n        if not self._cookies:\n            # Skip rest of function if no non-expired cookies.\n            return filtered\n        hostname = request_url.raw_host or \"\"\n\n        is_not_secure = request_url.scheme not in (\"https\", \"wss\")\n        if is_not_secure and self._treat_as_secure_origin:\n            request_origin = URL()\n            with contextlib.suppress(ValueError):\n                request_origin = request_url.origin()\n            is_not_secure = request_origin not in self._treat_as_secure_origin\n\n        # Send shared cookie\n        for c in self._cookies[(\"\", \"\")].values():\n            filtered[c.key] = c.value\n\n        if is_ip_address(hostname):\n            if not self._unsafe:\n                return filtered\n            domains: Iterable[str] = (hostname,)\n        else:\n            # Get all the subdomains that might match a cookie (e.g. \"foo.bar.com\", \"bar.com\", \"com\")\n            domains = itertools.accumulate(\n                reversed(hostname.split(\".\")), lambda x, y: f\"{y}.{x}\"\n            )\n        # Get all the path prefixes that might match a cookie (e.g. \"\", \"/foo\", \"/foo/bar\")\n        paths = itertools.accumulate(\n            request_url.path.split(\"/\"), lambda x, y: f\"{x}/{y}\"\n        )\n        # Create every combination of (domain, path) pairs.\n        pairs = itertools.product(domains, paths)\n\n        # Point 2: https://www.rfc-editor.org/rfc/rfc6265.html#section-5.4\n        cookies = itertools.chain.from_iterable(\n            self._cookies[p].values() for p in pairs\n        )\n        path_len = len(request_url.path)\n        for cookie in cookies:\n            name = cookie.key\n            domain = cookie[\"domain\"]\n\n            if (domain, name) in self._host_only_cookies:\n                if domain != hostname:\n                    continue\n\n            # Skip edge case when the cookie has a trailing slash but request doesn't.\n            if len(cookie[\"path\"]) > path_len:\n                continue\n\n            if is_not_secure and cookie[\"secure\"]:\n                continue\n\n            # It's critical we use the Morsel so the coded_value\n            # (based on cookie version) is preserved\n            mrsl_val = cast(\"Morsel[str]\", cookie.get(cookie.key, Morsel()))\n            mrsl_val.set(cookie.key, cookie.value, cookie.coded_value)\n            filtered[name] = mrsl_val\n\n        return filtered\n\n    @staticmethod\n    def _is_domain_match(domain: str, hostname: str) -> bool:\n        \"\"\"Implements domain matching adhering to RFC 6265.\"\"\"\n        if hostname == domain:\n            return True\n\n        if not hostname.endswith(domain):\n            return False\n\n        non_matching = hostname[: -len(domain)]\n\n        if not non_matching.endswith(\".\"):\n            return False\n\n        return not is_ip_address(hostname)\n\n    @classmethod\n    def _parse_date(cls, date_str: str) -> Optional[int]:\n        \"\"\"Implements date string parsing adhering to RFC 6265.\"\"\"\n        if not date_str:\n            return None\n\n        found_time = False\n        found_day = False\n        found_month = False\n        found_year = False\n\n        hour = minute = second = 0\n        day = 0\n        month = 0\n        year = 0\n\n        for token_match in cls.DATE_TOKENS_RE.finditer(date_str):\n            token = token_match.group(\"token\")\n\n            if not found_time:\n                time_match = cls.DATE_HMS_TIME_RE.match(token)\n                if time_match:\n                    found_time = True\n                    hour, minute, second = (int(s) for s in time_match.groups())\n                    continue\n\n            if not found_day:\n                day_match = cls.DATE_DAY_OF_MONTH_RE.match(token)\n                if day_match:\n                    found_day = True\n                    day = int(day_match.group())\n                    continue\n\n            if not found_month:\n                month_match = cls.DATE_MONTH_RE.match(token)\n                if month_match:\n                    found_month = True\n                    assert month_match.lastindex is not None\n                    month = month_match.lastindex\n                    continue\n\n            if not found_year:\n                year_match = cls.DATE_YEAR_RE.match(token)\n                if year_match:\n                    found_year = True\n                    year = int(year_match.group())\n\n        if 70 <= year <= 99:\n            year += 1900\n        elif 0 <= year <= 69:\n            year += 2000\n\n        if False in (found_day, found_month, found_year, found_time):\n            return None\n\n        if not 1 <= day <= 31:\n            return None\n\n        if year < 1601 or hour > 23 or minute > 59 or second > 59:\n            return None\n\n        return calendar.timegm((year, month, day, hour, minute, second, -1, -1, -1))\n\n\nclass DummyCookieJar(AbstractCookieJar):\n    \"\"\"Implements a dummy cookie storage.\n\n    It can be used with the ClientSession when no cookie processing is needed.\n\n    \"\"\"\n\n    def __iter__(self) -> \"Iterator[Morsel[str]]\":\n        while False:\n            yield None\n\n    def __len__(self) -> int:\n        return 0\n\n    def clear(self, predicate: Optional[ClearCookiePredicate] = None) -> None:\n        pass\n\n    def clear_domain(self, domain: str) -> None:\n        pass\n\n    def update_cookies(self, cookies: LooseCookies, response_url: URL = URL()) -> None:\n        pass\n\n    def filter_cookies(self, request_url: URL) -> \"BaseCookie[str]\":\n        return SimpleCookie()\n", "aiohttp/base_protocol.py": "import asyncio\nfrom typing import Optional, cast\n\nfrom .helpers import set_exception\nfrom .tcp_helpers import tcp_nodelay\n\n\nclass BaseProtocol(asyncio.Protocol):\n    __slots__ = (\n        \"_loop\",\n        \"_paused\",\n        \"_drain_waiter\",\n        \"_connection_lost\",\n        \"_reading_paused\",\n        \"transport\",\n    )\n\n    def __init__(self, loop: asyncio.AbstractEventLoop) -> None:\n        self._loop: asyncio.AbstractEventLoop = loop\n        self._paused = False\n        self._drain_waiter: Optional[asyncio.Future[None]] = None\n        self._reading_paused = False\n\n        self.transport: Optional[asyncio.Transport] = None\n\n    @property\n    def connected(self) -> bool:\n        \"\"\"Return True if the connection is open.\"\"\"\n        return self.transport is not None\n\n    def pause_writing(self) -> None:\n        assert not self._paused\n        self._paused = True\n\n    def resume_writing(self) -> None:\n        assert self._paused\n        self._paused = False\n\n        waiter = self._drain_waiter\n        if waiter is not None:\n            self._drain_waiter = None\n            if not waiter.done():\n                waiter.set_result(None)\n\n    def pause_reading(self) -> None:\n        if not self._reading_paused and self.transport is not None:\n            try:\n                self.transport.pause_reading()\n            except (AttributeError, NotImplementedError, RuntimeError):\n                pass\n            self._reading_paused = True\n\n    def resume_reading(self) -> None:\n        if self._reading_paused and self.transport is not None:\n            try:\n                self.transport.resume_reading()\n            except (AttributeError, NotImplementedError, RuntimeError):\n                pass\n            self._reading_paused = False\n\n    def connection_made(self, transport: asyncio.BaseTransport) -> None:\n        tr = cast(asyncio.Transport, transport)\n        tcp_nodelay(tr, True)\n        self.transport = tr\n\n    def connection_lost(self, exc: Optional[BaseException]) -> None:\n        # Wake up the writer if currently paused.\n        self.transport = None\n        if not self._paused:\n            return\n        waiter = self._drain_waiter\n        if waiter is None:\n            return\n        self._drain_waiter = None\n        if waiter.done():\n            return\n        if exc is None:\n            waiter.set_result(None)\n        else:\n            set_exception(\n                waiter,\n                ConnectionError(\"Connection lost\"),\n                exc,\n            )\n\n    async def _drain_helper(self) -> None:\n        if not self.connected:\n            raise ConnectionResetError(\"Connection lost\")\n        if not self._paused:\n            return\n        waiter = self._drain_waiter\n        if waiter is None:\n            waiter = self._loop.create_future()\n            self._drain_waiter = waiter\n        await asyncio.shield(waiter)\n", "aiohttp/web_runner.py": "import asyncio\nimport signal\nimport socket\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Awaitable, Callable, List, Optional, Set, Type\n\nfrom yarl import URL\n\nfrom .abc import AbstractAccessLogger, AbstractStreamWriter\nfrom .http_parser import RawRequestMessage\nfrom .streams import StreamReader\nfrom .typedefs import PathLike\nfrom .web_app import Application\nfrom .web_log import AccessLogger\nfrom .web_protocol import RequestHandler\nfrom .web_request import Request\nfrom .web_server import Server\n\ntry:\n    from ssl import SSLContext\nexcept ImportError:\n    SSLContext = object  # type: ignore[misc,assignment]\n\n\n__all__ = (\n    \"BaseSite\",\n    \"TCPSite\",\n    \"UnixSite\",\n    \"NamedPipeSite\",\n    \"SockSite\",\n    \"BaseRunner\",\n    \"AppRunner\",\n    \"ServerRunner\",\n    \"GracefulExit\",\n)\n\n\nclass GracefulExit(SystemExit):\n    code = 1\n\n\ndef _raise_graceful_exit() -> None:\n    raise GracefulExit()\n\n\nclass BaseSite(ABC):\n    __slots__ = (\"_runner\", \"_ssl_context\", \"_backlog\", \"_server\")\n\n    def __init__(\n        self,\n        runner: \"BaseRunner\",\n        *,\n        ssl_context: Optional[SSLContext] = None,\n        backlog: int = 128,\n    ) -> None:\n        if runner.server is None:\n            raise RuntimeError(\"Call runner.setup() before making a site\")\n        self._runner = runner\n        self._ssl_context = ssl_context\n        self._backlog = backlog\n        self._server: Optional[asyncio.AbstractServer] = None\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        pass  # pragma: no cover\n\n    @abstractmethod\n    async def start(self) -> None:\n        self._runner._reg_site(self)\n\n    async def stop(self) -> None:\n        self._runner._check_site(self)\n        if self._server is not None:  # Maybe not started yet\n            self._server.close()\n\n        self._runner._unreg_site(self)\n\n\nclass TCPSite(BaseSite):\n    __slots__ = (\"_host\", \"_port\", \"_reuse_address\", \"_reuse_port\")\n\n    def __init__(\n        self,\n        runner: \"BaseRunner\",\n        host: Optional[str] = None,\n        port: Optional[int] = None,\n        *,\n        ssl_context: Optional[SSLContext] = None,\n        backlog: int = 128,\n        reuse_address: Optional[bool] = None,\n        reuse_port: Optional[bool] = None,\n    ) -> None:\n        super().__init__(\n            runner,\n            ssl_context=ssl_context,\n            backlog=backlog,\n        )\n        self._host = host\n        if port is None:\n            port = 8443 if self._ssl_context else 8080\n        self._port = port\n        self._reuse_address = reuse_address\n        self._reuse_port = reuse_port\n\n    @property\n    def name(self) -> str:\n        scheme = \"https\" if self._ssl_context else \"http\"\n        host = \"0.0.0.0\" if self._host is None else self._host\n        return str(URL.build(scheme=scheme, host=host, port=self._port))\n\n    async def start(self) -> None:\n        await super().start()\n        loop = asyncio.get_event_loop()\n        server = self._runner.server\n        assert server is not None\n        self._server = await loop.create_server(\n            server,\n            self._host,\n            self._port,\n            ssl=self._ssl_context,\n            backlog=self._backlog,\n            reuse_address=self._reuse_address,\n            reuse_port=self._reuse_port,\n        )\n\n\nclass UnixSite(BaseSite):\n    __slots__ = (\"_path\",)\n\n    def __init__(\n        self,\n        runner: \"BaseRunner\",\n        path: PathLike,\n        *,\n        ssl_context: Optional[SSLContext] = None,\n        backlog: int = 128,\n    ) -> None:\n        super().__init__(\n            runner,\n            ssl_context=ssl_context,\n            backlog=backlog,\n        )\n        self._path = path\n\n    @property\n    def name(self) -> str:\n        scheme = \"https\" if self._ssl_context else \"http\"\n        return f\"{scheme}://unix:{self._path}:\"\n\n    async def start(self) -> None:\n        await super().start()\n        loop = asyncio.get_event_loop()\n        server = self._runner.server\n        assert server is not None\n        self._server = await loop.create_unix_server(\n            server,\n            self._path,\n            ssl=self._ssl_context,\n            backlog=self._backlog,\n        )\n\n\nclass NamedPipeSite(BaseSite):\n    __slots__ = (\"_path\",)\n\n    def __init__(self, runner: \"BaseRunner\", path: str) -> None:\n        loop = asyncio.get_event_loop()\n        if not isinstance(\n            loop, asyncio.ProactorEventLoop  # type: ignore[attr-defined]\n        ):\n            raise RuntimeError(\n                \"Named Pipes only available in proactor\" \"loop under windows\"\n            )\n        super().__init__(runner)\n        self._path = path\n\n    @property\n    def name(self) -> str:\n        return self._path\n\n    async def start(self) -> None:\n        await super().start()\n        loop = asyncio.get_event_loop()\n        server = self._runner.server\n        assert server is not None\n        _server = await loop.start_serving_pipe(  # type: ignore[attr-defined]\n            server, self._path\n        )\n        self._server = _server[0]\n\n\nclass SockSite(BaseSite):\n    __slots__ = (\"_sock\", \"_name\")\n\n    def __init__(\n        self,\n        runner: \"BaseRunner\",\n        sock: socket.socket,\n        *,\n        ssl_context: Optional[SSLContext] = None,\n        backlog: int = 128,\n    ) -> None:\n        super().__init__(\n            runner,\n            ssl_context=ssl_context,\n            backlog=backlog,\n        )\n        self._sock = sock\n        scheme = \"https\" if self._ssl_context else \"http\"\n        if hasattr(socket, \"AF_UNIX\") and sock.family == socket.AF_UNIX:\n            name = f\"{scheme}://unix:{sock.getsockname()}:\"\n        else:\n            host, port = sock.getsockname()[:2]\n            name = str(URL.build(scheme=scheme, host=host, port=port))\n        self._name = name\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    async def start(self) -> None:\n        await super().start()\n        loop = asyncio.get_event_loop()\n        server = self._runner.server\n        assert server is not None\n        self._server = await loop.create_server(\n            server, sock=self._sock, ssl=self._ssl_context, backlog=self._backlog\n        )\n\n\nclass BaseRunner(ABC):\n    __slots__ = (\n        \"shutdown_callback\",\n        \"_handle_signals\",\n        \"_kwargs\",\n        \"_server\",\n        \"_sites\",\n        \"_shutdown_timeout\",\n    )\n\n    def __init__(\n        self,\n        *,\n        handle_signals: bool = False,\n        shutdown_timeout: float = 60.0,\n        **kwargs: Any,\n    ) -> None:\n        self.shutdown_callback: Optional[Callable[[], Awaitable[None]]] = None\n        self._handle_signals = handle_signals\n        self._kwargs = kwargs\n        self._server: Optional[Server] = None\n        self._sites: List[BaseSite] = []\n        self._shutdown_timeout = shutdown_timeout\n\n    @property\n    def server(self) -> Optional[Server]:\n        return self._server\n\n    @property\n    def addresses(self) -> List[Any]:\n        ret: List[Any] = []\n        for site in self._sites:\n            server = site._server\n            if server is not None:\n                sockets = server.sockets  # type: ignore[attr-defined]\n                if sockets is not None:\n                    for sock in sockets:\n                        ret.append(sock.getsockname())\n        return ret\n\n    @property\n    def sites(self) -> Set[BaseSite]:\n        return set(self._sites)\n\n    async def setup(self) -> None:\n        loop = asyncio.get_event_loop()\n\n        if self._handle_signals:\n            try:\n                loop.add_signal_handler(signal.SIGINT, _raise_graceful_exit)\n                loop.add_signal_handler(signal.SIGTERM, _raise_graceful_exit)\n            except NotImplementedError:  # pragma: no cover\n                # add_signal_handler is not implemented on Windows\n                pass\n\n        self._server = await self._make_server()\n\n    @abstractmethod\n    async def shutdown(self) -> None:\n        \"\"\"Call any shutdown hooks to help server close gracefully.\"\"\"\n\n    async def cleanup(self) -> None:\n        # The loop over sites is intentional, an exception on gather()\n        # leaves self._sites in unpredictable state.\n        # The loop guarantees that a site is either deleted on success or\n        # still present on failure\n        for site in list(self._sites):\n            await site.stop()\n\n        if self._server:  # If setup succeeded\n            # Yield to event loop to ensure incoming requests prior to stopping the sites\n            # have all started to be handled before we proceed to close idle connections.\n            await asyncio.sleep(0)\n            self._server.pre_shutdown()\n            await self.shutdown()\n\n            if self.shutdown_callback:\n                await self.shutdown_callback()\n\n            await self._server.shutdown(self._shutdown_timeout)\n        await self._cleanup_server()\n\n        self._server = None\n        if self._handle_signals:\n            loop = asyncio.get_running_loop()\n            try:\n                loop.remove_signal_handler(signal.SIGINT)\n                loop.remove_signal_handler(signal.SIGTERM)\n            except NotImplementedError:  # pragma: no cover\n                # remove_signal_handler is not implemented on Windows\n                pass\n\n    @abstractmethod\n    async def _make_server(self) -> Server:\n        pass  # pragma: no cover\n\n    @abstractmethod\n    async def _cleanup_server(self) -> None:\n        pass  # pragma: no cover\n\n    def _reg_site(self, site: BaseSite) -> None:\n        if site in self._sites:\n            raise RuntimeError(f\"Site {site} is already registered in runner {self}\")\n        self._sites.append(site)\n\n    def _check_site(self, site: BaseSite) -> None:\n        if site not in self._sites:\n            raise RuntimeError(f\"Site {site} is not registered in runner {self}\")\n\n    def _unreg_site(self, site: BaseSite) -> None:\n        if site not in self._sites:\n            raise RuntimeError(f\"Site {site} is not registered in runner {self}\")\n        self._sites.remove(site)\n\n\nclass ServerRunner(BaseRunner):\n    \"\"\"Low-level web server runner\"\"\"\n\n    __slots__ = (\"_web_server\",)\n\n    def __init__(\n        self, web_server: Server, *, handle_signals: bool = False, **kwargs: Any\n    ) -> None:\n        super().__init__(handle_signals=handle_signals, **kwargs)\n        self._web_server = web_server\n\n    async def shutdown(self) -> None:\n        pass\n\n    async def _make_server(self) -> Server:\n        return self._web_server\n\n    async def _cleanup_server(self) -> None:\n        pass\n\n\nclass AppRunner(BaseRunner):\n    \"\"\"Web Application runner\"\"\"\n\n    __slots__ = (\"_app\",)\n\n    def __init__(\n        self,\n        app: Application,\n        *,\n        handle_signals: bool = False,\n        access_log_class: Type[AbstractAccessLogger] = AccessLogger,\n        **kwargs: Any,\n    ) -> None:\n        if not isinstance(app, Application):\n            raise TypeError(\n                \"The first argument should be web.Application \"\n                \"instance, got {!r}\".format(app)\n            )\n        kwargs[\"access_log_class\"] = access_log_class\n\n        if app._handler_args:\n            for k, v in app._handler_args.items():\n                kwargs[k] = v\n\n        if not issubclass(kwargs[\"access_log_class\"], AbstractAccessLogger):\n            raise TypeError(\n                \"access_log_class must be subclass of \"\n                \"aiohttp.abc.AbstractAccessLogger, got {}\".format(\n                    kwargs[\"access_log_class\"]\n                )\n            )\n\n        super().__init__(handle_signals=handle_signals, **kwargs)\n        self._app = app\n\n    @property\n    def app(self) -> Application:\n        return self._app\n\n    async def shutdown(self) -> None:\n        await self._app.shutdown()\n\n    async def _make_server(self) -> Server:\n        self._app.on_startup.freeze()\n        await self._app.startup()\n        self._app.freeze()\n\n        return Server(\n            self._app._handle,  # type: ignore[arg-type]\n            request_factory=self._make_request,\n            **self._kwargs,\n        )\n\n    def _make_request(\n        self,\n        message: RawRequestMessage,\n        payload: StreamReader,\n        protocol: RequestHandler,\n        writer: AbstractStreamWriter,\n        task: \"asyncio.Task[None]\",\n        _cls: Type[Request] = Request,\n    ) -> Request:\n        loop = asyncio.get_running_loop()\n        return _cls(\n            message,\n            payload,\n            protocol,\n            writer,\n            task,\n            loop,\n            client_max_size=self.app._client_max_size,\n        )\n\n    async def _cleanup_server(self) -> None:\n        await self._app.cleanup()\n", "aiohttp/web_routedef.py": "import abc\nimport dataclasses\nimport os  # noqa\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Dict,\n    Iterator,\n    List,\n    Optional,\n    Sequence,\n    Type,\n    Union,\n    overload,\n)\n\nfrom . import hdrs\nfrom .abc import AbstractView\nfrom .typedefs import Handler, PathLike\n\nif TYPE_CHECKING:\n    from .web_request import Request\n    from .web_response import StreamResponse\n    from .web_urldispatcher import AbstractRoute, UrlDispatcher\nelse:\n    Request = StreamResponse = UrlDispatcher = AbstractRoute = None\n\n\n__all__ = (\n    \"AbstractRouteDef\",\n    \"RouteDef\",\n    \"StaticDef\",\n    \"RouteTableDef\",\n    \"head\",\n    \"options\",\n    \"get\",\n    \"post\",\n    \"patch\",\n    \"put\",\n    \"delete\",\n    \"route\",\n    \"view\",\n    \"static\",\n)\n\n\nclass AbstractRouteDef(abc.ABC):\n    @abc.abstractmethod\n    def register(self, router: UrlDispatcher) -> List[AbstractRoute]:\n        pass  # pragma: no cover\n\n\n_HandlerType = Union[Type[AbstractView], Handler]\n\n\n@dataclasses.dataclass(frozen=True, repr=False)\nclass RouteDef(AbstractRouteDef):\n    method: str\n    path: str\n    handler: _HandlerType\n    kwargs: Dict[str, Any]\n\n    def __repr__(self) -> str:\n        info = []\n        for name, value in sorted(self.kwargs.items()):\n            info.append(f\", {name}={value!r}\")\n        return \"<RouteDef {method} {path} -> {handler.__name__!r}\" \"{info}>\".format(\n            method=self.method, path=self.path, handler=self.handler, info=\"\".join(info)\n        )\n\n    def register(self, router: UrlDispatcher) -> List[AbstractRoute]:\n        if self.method in hdrs.METH_ALL:\n            reg = getattr(router, \"add_\" + self.method.lower())\n            return [reg(self.path, self.handler, **self.kwargs)]\n        else:\n            return [\n                router.add_route(self.method, self.path, self.handler, **self.kwargs)\n            ]\n\n\n@dataclasses.dataclass(frozen=True, repr=False)\nclass StaticDef(AbstractRouteDef):\n    prefix: str\n    path: PathLike\n    kwargs: Dict[str, Any]\n\n    def __repr__(self) -> str:\n        info = []\n        for name, value in sorted(self.kwargs.items()):\n            info.append(f\", {name}={value!r}\")\n        return \"<StaticDef {prefix} -> {path}\" \"{info}>\".format(\n            prefix=self.prefix, path=self.path, info=\"\".join(info)\n        )\n\n    def register(self, router: UrlDispatcher) -> List[AbstractRoute]:\n        resource = router.add_static(self.prefix, self.path, **self.kwargs)\n        routes = resource.get_info().get(\"routes\", {})\n        return list(routes.values())\n\n\ndef route(method: str, path: str, handler: _HandlerType, **kwargs: Any) -> RouteDef:\n    return RouteDef(method, path, handler, kwargs)\n\n\ndef head(path: str, handler: _HandlerType, **kwargs: Any) -> RouteDef:\n    return route(hdrs.METH_HEAD, path, handler, **kwargs)\n\n\ndef options(path: str, handler: _HandlerType, **kwargs: Any) -> RouteDef:\n    return route(hdrs.METH_OPTIONS, path, handler, **kwargs)\n\n\ndef get(\n    path: str,\n    handler: _HandlerType,\n    *,\n    name: Optional[str] = None,\n    allow_head: bool = True,\n    **kwargs: Any,\n) -> RouteDef:\n    return route(\n        hdrs.METH_GET, path, handler, name=name, allow_head=allow_head, **kwargs\n    )\n\n\ndef post(path: str, handler: _HandlerType, **kwargs: Any) -> RouteDef:\n    return route(hdrs.METH_POST, path, handler, **kwargs)\n\n\ndef put(path: str, handler: _HandlerType, **kwargs: Any) -> RouteDef:\n    return route(hdrs.METH_PUT, path, handler, **kwargs)\n\n\ndef patch(path: str, handler: _HandlerType, **kwargs: Any) -> RouteDef:\n    return route(hdrs.METH_PATCH, path, handler, **kwargs)\n\n\ndef delete(path: str, handler: _HandlerType, **kwargs: Any) -> RouteDef:\n    return route(hdrs.METH_DELETE, path, handler, **kwargs)\n\n\ndef view(path: str, handler: Type[AbstractView], **kwargs: Any) -> RouteDef:\n    return route(hdrs.METH_ANY, path, handler, **kwargs)\n\n\ndef static(prefix: str, path: PathLike, **kwargs: Any) -> StaticDef:\n    return StaticDef(prefix, path, kwargs)\n\n\n_Deco = Callable[[_HandlerType], _HandlerType]\n\n\nclass RouteTableDef(Sequence[AbstractRouteDef]):\n    \"\"\"Route definition table\"\"\"\n\n    def __init__(self) -> None:\n        self._items: List[AbstractRouteDef] = []\n\n    def __repr__(self) -> str:\n        return f\"<RouteTableDef count={len(self._items)}>\"\n\n    @overload\n    def __getitem__(self, index: int) -> AbstractRouteDef: ...\n\n    @overload\n    def __getitem__(self, index: slice) -> List[AbstractRouteDef]: ...\n\n    def __getitem__(self, index):  # type: ignore[no-untyped-def]\n        return self._items[index]\n\n    def __iter__(self) -> Iterator[AbstractRouteDef]:\n        return iter(self._items)\n\n    def __len__(self) -> int:\n        return len(self._items)\n\n    def __contains__(self, item: object) -> bool:\n        return item in self._items\n\n    def route(self, method: str, path: str, **kwargs: Any) -> _Deco:\n        def inner(handler: _HandlerType) -> _HandlerType:\n            self._items.append(RouteDef(method, path, handler, kwargs))\n            return handler\n\n        return inner\n\n    def head(self, path: str, **kwargs: Any) -> _Deco:\n        return self.route(hdrs.METH_HEAD, path, **kwargs)\n\n    def get(self, path: str, **kwargs: Any) -> _Deco:\n        return self.route(hdrs.METH_GET, path, **kwargs)\n\n    def post(self, path: str, **kwargs: Any) -> _Deco:\n        return self.route(hdrs.METH_POST, path, **kwargs)\n\n    def put(self, path: str, **kwargs: Any) -> _Deco:\n        return self.route(hdrs.METH_PUT, path, **kwargs)\n\n    def patch(self, path: str, **kwargs: Any) -> _Deco:\n        return self.route(hdrs.METH_PATCH, path, **kwargs)\n\n    def delete(self, path: str, **kwargs: Any) -> _Deco:\n        return self.route(hdrs.METH_DELETE, path, **kwargs)\n\n    def options(self, path: str, **kwargs: Any) -> _Deco:\n        return self.route(hdrs.METH_OPTIONS, path, **kwargs)\n\n    def view(self, path: str, **kwargs: Any) -> _Deco:\n        return self.route(hdrs.METH_ANY, path, **kwargs)\n\n    def static(self, prefix: str, path: PathLike, **kwargs: Any) -> None:\n        self._items.append(StaticDef(prefix, path, kwargs))\n", "aiohttp/typedefs.py": "import json\nimport os\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Awaitable,\n    Callable,\n    Iterable,\n    Mapping,\n    Tuple,\n    Union,\n)\n\nfrom multidict import CIMultiDict, CIMultiDictProxy, MultiDict, MultiDictProxy, istr\nfrom yarl import URL\n\nDEFAULT_JSON_ENCODER = json.dumps\nDEFAULT_JSON_DECODER = json.loads\n\nif TYPE_CHECKING:\n    _CIMultiDict = CIMultiDict[str]\n    _CIMultiDictProxy = CIMultiDictProxy[str]\n    _MultiDict = MultiDict[str]\n    _MultiDictProxy = MultiDictProxy[str]\n    from http.cookies import BaseCookie, Morsel\n\n    from .web import Request, StreamResponse\nelse:\n    _CIMultiDict = CIMultiDict\n    _CIMultiDictProxy = CIMultiDictProxy\n    _MultiDict = MultiDict\n    _MultiDictProxy = MultiDictProxy\n\nByteish = Union[bytes, bytearray, memoryview]\nJSONEncoder = Callable[[Any], str]\nJSONDecoder = Callable[[str], Any]\nLooseHeaders = Union[Mapping[Union[str, istr], str], _CIMultiDict, _CIMultiDictProxy]\nRawHeaders = Tuple[Tuple[bytes, bytes], ...]\nStrOrURL = Union[str, URL]\n\nLooseCookiesMappings = Mapping[str, Union[str, \"BaseCookie[str]\", \"Morsel[Any]\"]]\nLooseCookiesIterables = Iterable[\n    Tuple[str, Union[str, \"BaseCookie[str]\", \"Morsel[Any]\"]]\n]\nLooseCookies = Union[\n    LooseCookiesMappings,\n    LooseCookiesIterables,\n    \"BaseCookie[str]\",\n]\n\nHandler = Callable[[\"Request\"], Awaitable[\"StreamResponse\"]]\nMiddleware = Callable[[\"Request\", Handler], Awaitable[\"StreamResponse\"]]\n\nPathLike = Union[str, \"os.PathLike[str]\"]\n", "aiohttp/test_utils.py": "\"\"\"Utilities shared by tests.\"\"\"\n\nimport asyncio\nimport contextlib\nimport gc\nimport inspect\nimport ipaddress\nimport os\nimport socket\nimport sys\nfrom abc import ABC, abstractmethod\nfrom types import TracebackType\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Iterator,\n    List,\n    Optional,\n    Type,\n    Union,\n    cast,\n)\nfrom unittest import IsolatedAsyncioTestCase, mock\n\nfrom aiosignal import Signal\nfrom multidict import CIMultiDict, CIMultiDictProxy\nfrom yarl import URL\n\nimport aiohttp\nfrom aiohttp.client import _RequestContextManager, _WSRequestContextManager\n\nfrom . import ClientSession, hdrs\nfrom .abc import AbstractCookieJar\nfrom .client_reqrep import ClientResponse\nfrom .client_ws import ClientWebSocketResponse\nfrom .helpers import _SENTINEL, sentinel\nfrom .http import HttpVersion, RawRequestMessage\nfrom .typedefs import StrOrURL\nfrom .web import (\n    Application,\n    AppRunner,\n    BaseRunner,\n    Request,\n    Server,\n    ServerRunner,\n    SockSite,\n    UrlMappingMatchInfo,\n)\nfrom .web_protocol import _RequestHandler\n\nif TYPE_CHECKING:\n    from ssl import SSLContext\nelse:\n    SSLContext = None\n\nREUSE_ADDRESS = os.name == \"posix\" and sys.platform != \"cygwin\"\n\n\ndef get_unused_port_socket(\n    host: str, family: socket.AddressFamily = socket.AF_INET\n) -> socket.socket:\n    return get_port_socket(host, 0, family)\n\n\ndef get_port_socket(\n    host: str, port: int, family: socket.AddressFamily = socket.AF_INET\n) -> socket.socket:\n    s = socket.socket(family, socket.SOCK_STREAM)\n    if REUSE_ADDRESS:\n        # Windows has different semantics for SO_REUSEADDR,\n        # so don't set it. Ref:\n        # https://docs.microsoft.com/en-us/windows/win32/winsock/using-so-reuseaddr-and-so-exclusiveaddruse\n        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    s.bind((host, port))\n    return s\n\n\ndef unused_port() -> int:\n    \"\"\"Return a port that is unused on the current host.\"\"\"\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.bind((\"127.0.0.1\", 0))\n        return cast(int, s.getsockname()[1])\n\n\nclass BaseTestServer(ABC):\n    __test__ = False\n\n    def __init__(\n        self,\n        *,\n        scheme: Union[str, _SENTINEL] = sentinel,\n        host: str = \"127.0.0.1\",\n        port: Optional[int] = None,\n        skip_url_asserts: bool = False,\n        socket_factory: Callable[\n            [str, int, socket.AddressFamily], socket.socket\n        ] = get_port_socket,\n        **kwargs: Any,\n    ) -> None:\n        self.runner: Optional[BaseRunner] = None\n        self._root: Optional[URL] = None\n        self.host = host\n        self.port = port\n        self._closed = False\n        self.scheme = scheme\n        self.skip_url_asserts = skip_url_asserts\n        self.socket_factory = socket_factory\n\n    async def start_server(self, **kwargs: Any) -> None:\n        if self.runner:\n            return\n        self._ssl = kwargs.pop(\"ssl\", None)\n        self.runner = await self._make_runner(handler_cancellation=True, **kwargs)\n        await self.runner.setup()\n        if not self.port:\n            self.port = 0\n        absolute_host = self.host\n        try:\n            version = ipaddress.ip_address(self.host).version\n        except ValueError:\n            version = 4\n        if version == 6:\n            absolute_host = f\"[{self.host}]\"\n        family = socket.AF_INET6 if version == 6 else socket.AF_INET\n        _sock = self.socket_factory(self.host, self.port, family)\n        self.host, self.port = _sock.getsockname()[:2]\n        site = SockSite(self.runner, sock=_sock, ssl_context=self._ssl)\n        await site.start()\n        server = site._server\n        assert server is not None\n        sockets = server.sockets  # type: ignore[attr-defined]\n        assert sockets is not None\n        self.port = sockets[0].getsockname()[1]\n        if self.scheme is sentinel:\n            if self._ssl:\n                scheme = \"https\"\n            else:\n                scheme = \"http\"\n            self.scheme = scheme\n        self._root = URL(f\"{self.scheme}://{absolute_host}:{self.port}\")\n\n    @abstractmethod  # pragma: no cover\n    async def _make_runner(self, **kwargs: Any) -> BaseRunner:\n        pass\n\n    def make_url(self, path: StrOrURL) -> URL:\n        assert self._root is not None\n        url = URL(path)\n        if not self.skip_url_asserts:\n            assert not url.is_absolute()\n            return self._root.join(url)\n        else:\n            return URL(str(self._root) + str(path))\n\n    @property\n    def started(self) -> bool:\n        return self.runner is not None\n\n    @property\n    def closed(self) -> bool:\n        return self._closed\n\n    @property\n    def handler(self) -> Server:\n        # for backward compatibility\n        # web.Server instance\n        runner = self.runner\n        assert runner is not None\n        assert runner.server is not None\n        return runner.server\n\n    async def close(self) -> None:\n        \"\"\"Close all fixtures created by the test client.\n\n        After that point, the TestClient is no longer usable.\n\n        This is an idempotent function: running close multiple times\n        will not have any additional effects.\n\n        close is also run when the object is garbage collected, and on\n        exit when used as a context manager.\n\n        \"\"\"\n        if self.started and not self.closed:\n            assert self.runner is not None\n            await self.runner.cleanup()\n            self._root = None\n            self.port = None\n            self._closed = True\n\n    async def __aenter__(self) -> \"BaseTestServer\":\n        await self.start_server()\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_value: Optional[BaseException],\n        traceback: Optional[TracebackType],\n    ) -> None:\n        await self.close()\n\n\nclass TestServer(BaseTestServer):\n    def __init__(\n        self,\n        app: Application,\n        *,\n        scheme: Union[str, _SENTINEL] = sentinel,\n        host: str = \"127.0.0.1\",\n        port: Optional[int] = None,\n        **kwargs: Any,\n    ):\n        self.app = app\n        super().__init__(scheme=scheme, host=host, port=port, **kwargs)\n\n    async def _make_runner(self, **kwargs: Any) -> BaseRunner:\n        return AppRunner(self.app, **kwargs)\n\n\nclass RawTestServer(BaseTestServer):\n    def __init__(\n        self,\n        handler: _RequestHandler,\n        *,\n        scheme: Union[str, _SENTINEL] = sentinel,\n        host: str = \"127.0.0.1\",\n        port: Optional[int] = None,\n        **kwargs: Any,\n    ) -> None:\n        self._handler = handler\n        super().__init__(scheme=scheme, host=host, port=port, **kwargs)\n\n    async def _make_runner(self, **kwargs: Any) -> ServerRunner:\n        srv = Server(self._handler, **kwargs)\n        return ServerRunner(srv, **kwargs)\n\n\nclass TestClient:\n    \"\"\"\n    A test client implementation.\n\n    To write functional tests for aiohttp based servers.\n\n    \"\"\"\n\n    __test__ = False\n\n    def __init__(\n        self,\n        server: BaseTestServer,\n        *,\n        cookie_jar: Optional[AbstractCookieJar] = None,\n        **kwargs: Any,\n    ) -> None:\n        if not isinstance(server, BaseTestServer):\n            raise TypeError(\n                \"server must be TestServer \" \"instance, found type: %r\" % type(server)\n            )\n        self._server = server\n        if cookie_jar is None:\n            cookie_jar = aiohttp.CookieJar(unsafe=True)\n        self._session = ClientSession(cookie_jar=cookie_jar, **kwargs)\n        self._closed = False\n        self._responses: List[ClientResponse] = []\n        self._websockets: List[ClientWebSocketResponse] = []\n\n    async def start_server(self) -> None:\n        await self._server.start_server()\n\n    @property\n    def scheme(self) -> Union[str, object]:\n        return self._server.scheme\n\n    @property\n    def host(self) -> str:\n        return self._server.host\n\n    @property\n    def port(self) -> Optional[int]:\n        return self._server.port\n\n    @property\n    def server(self) -> BaseTestServer:\n        return self._server\n\n    @property\n    def app(self) -> Optional[Application]:\n        return cast(Optional[Application], getattr(self._server, \"app\", None))\n\n    @property\n    def session(self) -> ClientSession:\n        \"\"\"An internal aiohttp.ClientSession.\n\n        Unlike the methods on the TestClient, client session requests\n        do not automatically include the host in the url queried, and\n        will require an absolute path to the resource.\n\n        \"\"\"\n        return self._session\n\n    def make_url(self, path: StrOrURL) -> URL:\n        return self._server.make_url(path)\n\n    async def _request(\n        self, method: str, path: StrOrURL, **kwargs: Any\n    ) -> ClientResponse:\n        resp = await self._session.request(method, self.make_url(path), **kwargs)\n        # save it to close later\n        self._responses.append(resp)\n        return resp\n\n    def request(\n        self, method: str, path: StrOrURL, **kwargs: Any\n    ) -> _RequestContextManager:\n        \"\"\"Routes a request to tested http server.\n\n        The interface is identical to aiohttp.ClientSession.request,\n        except the loop kwarg is overridden by the instance used by the\n        test server.\n\n        \"\"\"\n        return _RequestContextManager(self._request(method, path, **kwargs))\n\n    def get(self, path: StrOrURL, **kwargs: Any) -> _RequestContextManager:\n        \"\"\"Perform an HTTP GET request.\"\"\"\n        return _RequestContextManager(self._request(hdrs.METH_GET, path, **kwargs))\n\n    def post(self, path: StrOrURL, **kwargs: Any) -> _RequestContextManager:\n        \"\"\"Perform an HTTP POST request.\"\"\"\n        return _RequestContextManager(self._request(hdrs.METH_POST, path, **kwargs))\n\n    def options(self, path: StrOrURL, **kwargs: Any) -> _RequestContextManager:\n        \"\"\"Perform an HTTP OPTIONS request.\"\"\"\n        return _RequestContextManager(self._request(hdrs.METH_OPTIONS, path, **kwargs))\n\n    def head(self, path: StrOrURL, **kwargs: Any) -> _RequestContextManager:\n        \"\"\"Perform an HTTP HEAD request.\"\"\"\n        return _RequestContextManager(self._request(hdrs.METH_HEAD, path, **kwargs))\n\n    def put(self, path: StrOrURL, **kwargs: Any) -> _RequestContextManager:\n        \"\"\"Perform an HTTP PUT request.\"\"\"\n        return _RequestContextManager(self._request(hdrs.METH_PUT, path, **kwargs))\n\n    def patch(self, path: StrOrURL, **kwargs: Any) -> _RequestContextManager:\n        \"\"\"Perform an HTTP PATCH request.\"\"\"\n        return _RequestContextManager(self._request(hdrs.METH_PATCH, path, **kwargs))\n\n    def delete(self, path: StrOrURL, **kwargs: Any) -> _RequestContextManager:\n        \"\"\"Perform an HTTP PATCH request.\"\"\"\n        return _RequestContextManager(self._request(hdrs.METH_DELETE, path, **kwargs))\n\n    def ws_connect(self, path: StrOrURL, **kwargs: Any) -> _WSRequestContextManager:\n        \"\"\"Initiate websocket connection.\n\n        The api corresponds to aiohttp.ClientSession.ws_connect.\n\n        \"\"\"\n        return _WSRequestContextManager(self._ws_connect(path, **kwargs))\n\n    async def _ws_connect(\n        self, path: StrOrURL, **kwargs: Any\n    ) -> ClientWebSocketResponse:\n        ws = await self._session.ws_connect(self.make_url(path), **kwargs)\n        self._websockets.append(ws)\n        return ws\n\n    async def close(self) -> None:\n        \"\"\"Close all fixtures created by the test client.\n\n        After that point, the TestClient is no longer usable.\n\n        This is an idempotent function: running close multiple times\n        will not have any additional effects.\n\n        close is also run on exit when used as a(n) (asynchronous)\n        context manager.\n\n        \"\"\"\n        if not self._closed:\n            for resp in self._responses:\n                resp.close()\n            for ws in self._websockets:\n                await ws.close()\n            await self._session.close()\n            await self._server.close()\n            self._closed = True\n\n    async def __aenter__(self) -> \"TestClient\":\n        await self.start_server()\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> None:\n        await self.close()\n\n\nclass AioHTTPTestCase(IsolatedAsyncioTestCase, ABC):\n    \"\"\"A base class to allow for unittest web applications using aiohttp.\n\n    Provides the following:\n\n    * self.client (aiohttp.test_utils.TestClient): an aiohttp test client.\n    * self.app (aiohttp.web.Application): the application returned by\n        self.get_application()\n\n    Note that the TestClient's methods are asynchronous: you have to\n    execute function on the test client using asynchronous methods.\n    \"\"\"\n\n    @abstractmethod\n    async def get_application(self) -> Application:\n        \"\"\"Get application.\n\n        This method should be overridden to return the aiohttp.web.Application\n        object to test.\n        \"\"\"\n\n    async def asyncSetUp(self) -> None:\n        self.app = await self.get_application()\n        self.server = await self.get_server(self.app)\n        self.client = await self.get_client(self.server)\n\n        await self.client.start_server()\n\n    async def asyncTearDown(self) -> None:\n        await self.client.close()\n\n    async def get_server(self, app: Application) -> TestServer:\n        \"\"\"Return a TestServer instance.\"\"\"\n        return TestServer(app)\n\n    async def get_client(self, server: TestServer) -> TestClient:\n        \"\"\"Return a TestClient instance.\"\"\"\n        return TestClient(server)\n\n\n_LOOP_FACTORY = Callable[[], asyncio.AbstractEventLoop]\n\n\n@contextlib.contextmanager\ndef loop_context(\n    loop_factory: _LOOP_FACTORY = asyncio.new_event_loop, fast: bool = False\n) -> Iterator[asyncio.AbstractEventLoop]:\n    \"\"\"A contextmanager that creates an event_loop, for test purposes.\n\n    Handles the creation and cleanup of a test loop.\n    \"\"\"\n    loop = setup_test_loop(loop_factory)\n    yield loop\n    teardown_test_loop(loop, fast=fast)\n\n\ndef setup_test_loop(\n    loop_factory: _LOOP_FACTORY = asyncio.new_event_loop,\n) -> asyncio.AbstractEventLoop:\n    \"\"\"Create and return an asyncio.BaseEventLoop instance.\n\n    The caller should also call teardown_test_loop,\n    once they are done with the loop.\n    \"\"\"\n    loop = loop_factory()\n    asyncio.set_event_loop(loop)\n    return loop\n\n\ndef teardown_test_loop(loop: asyncio.AbstractEventLoop, fast: bool = False) -> None:\n    \"\"\"Teardown and cleanup an event_loop created by setup_test_loop.\"\"\"\n    closed = loop.is_closed()\n    if not closed:\n        loop.call_soon(loop.stop)\n        loop.run_forever()\n        loop.close()\n\n    if not fast:\n        gc.collect()\n\n    asyncio.set_event_loop(None)\n\n\ndef _create_app_mock() -> mock.MagicMock:\n    def get_dict(app: Any, key: str) -> Any:\n        return app.__app_dict[key]\n\n    def set_dict(app: Any, key: str, value: Any) -> None:\n        app.__app_dict[key] = value\n\n    app = mock.MagicMock(spec=Application)\n    app.__app_dict = {}\n    app.__getitem__ = get_dict\n    app.__setitem__ = set_dict\n\n    app.on_response_prepare = Signal(app)\n    app.on_response_prepare.freeze()\n    return app\n\n\ndef _create_transport(sslcontext: Optional[SSLContext] = None) -> mock.Mock:\n    transport = mock.Mock()\n\n    def get_extra_info(key: str) -> Optional[SSLContext]:\n        if key == \"sslcontext\":\n            return sslcontext\n        else:\n            return None\n\n    transport.get_extra_info.side_effect = get_extra_info\n    return transport\n\n\ndef make_mocked_request(\n    method: str,\n    path: str,\n    headers: Any = None,\n    *,\n    match_info: Any = sentinel,\n    version: HttpVersion = HttpVersion(1, 1),\n    closing: bool = False,\n    app: Any = None,\n    writer: Any = sentinel,\n    protocol: Any = sentinel,\n    transport: Any = sentinel,\n    payload: Any = sentinel,\n    sslcontext: Optional[SSLContext] = None,\n    client_max_size: int = 1024**2,\n    loop: Any = ...,\n) -> Request:\n    \"\"\"Creates mocked web.Request testing purposes.\n\n    Useful in unit tests, when spinning full web server is overkill or\n    specific conditions and errors are hard to trigger.\n    \"\"\"\n    task = mock.Mock()\n    if loop is ...:\n        # no loop passed, try to get the current one if\n        # its is running as we need a real loop to create\n        # executor jobs to be able to do testing\n        # with a real executor\n        try:\n            loop = asyncio.get_running_loop()\n        except RuntimeError:\n            loop = mock.Mock()\n            loop.create_future.return_value = ()\n\n    if version < HttpVersion(1, 1):\n        closing = True\n\n    if headers:\n        headers = CIMultiDictProxy(CIMultiDict(headers))\n        raw_hdrs = tuple(\n            (k.encode(\"utf-8\"), v.encode(\"utf-8\")) for k, v in headers.items()\n        )\n    else:\n        headers = CIMultiDictProxy(CIMultiDict())\n        raw_hdrs = ()\n\n    chunked = \"chunked\" in headers.get(hdrs.TRANSFER_ENCODING, \"\").lower()\n\n    message = RawRequestMessage(\n        method,\n        path,\n        version,\n        headers,\n        raw_hdrs,\n        closing,\n        None,\n        False,\n        chunked,\n        URL(path),\n    )\n    if app is None:\n        app = _create_app_mock()\n\n    if transport is sentinel:\n        transport = _create_transport(sslcontext)\n\n    if protocol is sentinel:\n        protocol = mock.Mock()\n        protocol.transport = transport\n\n    if writer is sentinel:\n        writer = mock.Mock()\n        writer.write_headers = make_mocked_coro(None)\n        writer.write = make_mocked_coro(None)\n        writer.write_eof = make_mocked_coro(None)\n        writer.drain = make_mocked_coro(None)\n        writer.transport = transport\n\n    protocol.transport = transport\n    protocol.writer = writer\n\n    if payload is sentinel:\n        payload = mock.Mock()\n\n    req = Request(\n        message, payload, protocol, writer, task, loop, client_max_size=client_max_size\n    )\n\n    match_info = UrlMappingMatchInfo(\n        {} if match_info is sentinel else match_info, mock.Mock()\n    )\n    match_info.add_app(app)\n    req._match_info = match_info\n\n    return req\n\n\ndef make_mocked_coro(\n    return_value: Any = sentinel, raise_exception: Any = sentinel\n) -> Any:\n    \"\"\"Creates a coroutine mock.\"\"\"\n\n    async def mock_coro(*args: Any, **kwargs: Any) -> Any:\n        if raise_exception is not sentinel:\n            raise raise_exception\n        if not inspect.isawaitable(return_value):\n            return return_value\n        await return_value\n\n    return mock.Mock(wraps=mock_coro)\n", "examples/web_srv_route_deco.py": "#!/usr/bin/env python3\n\"\"\"Example for aiohttp.web basic server with decorator definition for routes.\"\"\"\n\nimport textwrap\n\nfrom aiohttp import web\n\nroutes = web.RouteTableDef()\n\n\n@routes.get(\"/\")\nasync def intro(request: web.Request) -> web.StreamResponse:\n    txt = textwrap.dedent(\n        \"\"\"\\\n        Type {url}/hello/John  {url}/simple or {url}/change_body\n        in browser url bar\n    \"\"\"\n    ).format(url=\"127.0.0.1:8080\")\n    binary = txt.encode(\"utf8\")\n    resp = web.StreamResponse()\n    resp.content_length = len(binary)\n    resp.content_type = \"text/plain\"\n    await resp.prepare(request)\n    await resp.write(binary)\n    return resp\n\n\n@routes.get(\"/simple\")\nasync def simple(request: web.Request) -> web.StreamResponse:\n    return web.Response(text=\"Simple answer\")\n\n\n@routes.get(\"/change_body\")\nasync def change_body(request: web.Request) -> web.StreamResponse:\n    resp = web.Response()\n    resp.body = b\"Body changed\"\n    resp.content_type = \"text/plain\"\n    return resp\n\n\n@routes.get(\"/hello\")\nasync def hello(request: web.Request) -> web.StreamResponse:\n    resp = web.StreamResponse()\n    name = request.match_info.get(\"name\", \"Anonymous\")\n    answer = (\"Hello, \" + name).encode(\"utf8\")\n    resp.content_length = len(answer)\n    resp.content_type = \"text/plain\"\n    await resp.prepare(request)\n    await resp.write(answer)\n    await resp.write_eof()\n    return resp\n\n\ndef init() -> web.Application:\n    app = web.Application()\n    app.router.add_routes(routes)\n    return app\n\n\nweb.run_app(init())\n", "examples/lowlevel_srv.py": "import asyncio\n\nfrom aiohttp import web, web_request\n\n\nasync def handler(request: web_request.BaseRequest) -> web.StreamResponse:\n    return web.Response(text=\"OK\")\n\n\nasync def main(loop: asyncio.AbstractEventLoop) -> None:\n    server = web.Server(handler)\n    await loop.create_server(server, \"127.0.0.1\", 8080)\n    print(\"======= Serving on http://127.0.0.1:8080/ ======\")\n\n    # pause here for very long time by serving HTTP requests and\n    # waiting for keyboard interruption\n    await asyncio.sleep(100 * 3600)\n\n\nloop = asyncio.get_event_loop()\n\ntry:\n    loop.run_until_complete(main(loop))\nexcept KeyboardInterrupt:\n    pass\nloop.close()\n", "examples/static_files.py": "#!/usr/bin/env python3\nimport pathlib\n\nfrom aiohttp import web\n\napp = web.Application()\napp.router.add_static(\"/\", pathlib.Path(__file__).parent, show_index=True)\n\nweb.run_app(app)\n", "examples/server_simple.py": "# server_simple.py\nfrom aiohttp import web\n\n\nasync def handle(request: web.Request) -> web.StreamResponse:\n    name = request.match_info.get(\"name\", \"Anonymous\")\n    text = \"Hello, \" + name\n    return web.Response(text=text)\n\n\nasync def wshandle(request: web.Request) -> web.StreamResponse:\n    ws = web.WebSocketResponse()\n    await ws.prepare(request)\n\n    async for msg in ws:\n        if msg.type == web.WSMsgType.TEXT:\n            await ws.send_str(f\"Hello, {msg.data}\")\n        elif msg.type == web.WSMsgType.BINARY:\n            await ws.send_bytes(msg.data)\n        elif msg.type == web.WSMsgType.CLOSE:\n            break\n\n    return ws\n\n\napp = web.Application()\napp.add_routes(\n    [web.get(\"/\", handle), web.get(\"/echo\", wshandle), web.get(\"/{name}\", handle)]\n)\n\nweb.run_app(app)\n", "examples/web_rewrite_headers_middleware.py": "#!/usr/bin/env python3\n\"\"\"Example for rewriting response headers by middleware.\"\"\"\n\nfrom aiohttp import web\nfrom aiohttp.typedefs import Handler\n\n\nasync def handler(request: web.Request) -> web.StreamResponse:\n    return web.Response(text=\"Everything is fine\")\n\n\nasync def middleware(request: web.Request, handler: Handler) -> web.StreamResponse:\n    try:\n        response = await handler(request)\n    except web.HTTPException as exc:\n        raise exc\n    if not response.prepared:\n        response.headers[\"SERVER\"] = \"Secured Server Software\"\n    return response\n\n\ndef init() -> web.Application:\n    app = web.Application(middlewares=[middleware])\n    app.router.add_get(\"/\", handler)\n    return app\n\n\nweb.run_app(init())\n", "examples/web_ws.py": "#!/usr/bin/env python3\n\"\"\"Example for aiohttp.web websocket server.\"\"\"\n\n# The extra strict mypy settings are here to help test that `Application[AppKey()]`\n# syntax is working correctly. A regression will cause mypy to raise an error.\n# mypy: disallow-any-expr, disallow-any-unimported, disallow-subclassing-any\n\nimport os\nfrom typing import List, Union\n\nfrom aiohttp import web\n\nWS_FILE = os.path.join(os.path.dirname(__file__), \"websocket.html\")\nsockets = web.AppKey(\"sockets\", List[web.WebSocketResponse])\n\n\nasync def wshandler(request: web.Request) -> Union[web.WebSocketResponse, web.Response]:\n    resp = web.WebSocketResponse()\n    available = resp.can_prepare(request)\n    if not available:\n        with open(WS_FILE, \"rb\") as fp:\n            return web.Response(body=fp.read(), content_type=\"text/html\")\n\n    await resp.prepare(request)\n\n    await resp.send_str(\"Welcome!!!\")\n\n    try:\n        print(\"Someone joined.\")\n        for ws in request.app[sockets]:\n            await ws.send_str(\"Someone joined\")\n        request.app[sockets].append(resp)\n\n        async for msg in resp:  # type: ignore[misc]\n            if msg.type == web.WSMsgType.TEXT:  # type: ignore[misc]\n                for ws in request.app[sockets]:\n                    if ws is not resp:\n                        await ws.send_str(msg.data)  # type: ignore[misc]\n            else:\n                return resp\n        return resp\n\n    finally:\n        request.app[sockets].remove(resp)\n        print(\"Someone disconnected.\")\n        for ws in request.app[sockets]:\n            await ws.send_str(\"Someone disconnected.\")\n\n\nasync def on_shutdown(app: web.Application) -> None:\n    for ws in app[sockets]:\n        await ws.close()\n\n\ndef init() -> web.Application:\n    app = web.Application()\n    l: List[web.WebSocketResponse] = []\n    app[sockets] = l\n    app.router.add_get(\"/\", wshandler)\n    app.on_shutdown.append(on_shutdown)\n    return app\n\n\nweb.run_app(init())\n", "examples/background_tasks.py": "#!/usr/bin/env python3\n\"\"\"Example of aiohttp.web.Application.on_startup signal handler\"\"\"\nimport asyncio\nfrom typing import List\n\nimport aioredis\n\nfrom aiohttp import web\n\nredis_listener = web.AppKey(\"redis_listener\", asyncio.Task[None])\nwebsockets = web.AppKey(\"websockets\", List[web.WebSocketResponse])\n\n\nasync def websocket_handler(request: web.Request) -> web.StreamResponse:\n    ws = web.WebSocketResponse()\n    await ws.prepare(request)\n    request.app[websockets].append(ws)\n    try:\n        async for msg in ws:\n            print(msg)\n            await asyncio.sleep(1)\n    finally:\n        request.app[websockets].remove(ws)\n    return ws\n\n\nasync def on_shutdown(app: web.Application) -> None:\n    for ws in app[websockets]:\n        await ws.close(code=999, message=b\"Server shutdown\")\n\n\nasync def listen_to_redis(app: web.Application) -> None:\n    sub = await aioredis.Redis(host=\"localhost\", port=6379)\n    ch, *_ = await sub.subscribe(\"news\")\n    try:\n        async for msg in ch.iter(encoding=\"utf-8\"):\n            # Forward message to all connected websockets:\n            for ws in app[websockets]:\n                await ws.send_str(f\"{ch.name}: {msg}\")\n            print(f\"message in {ch.name}: {msg}\")\n    except asyncio.CancelledError:\n        pass\n    finally:\n        print(\"Cancel Redis listener: close connection...\")\n        await sub.unsubscribe(ch.name)\n        await sub.quit()\n        print(\"Redis connection closed.\")\n\n\nasync def start_background_tasks(app: web.Application) -> None:\n    app[redis_listener] = asyncio.create_task(listen_to_redis(app))\n\n\nasync def cleanup_background_tasks(app: web.Application) -> None:\n    print(\"cleanup background tasks...\")\n    app[redis_listener].cancel()\n    await app[redis_listener]\n\n\ndef init() -> web.Application:\n    app = web.Application()\n    l: List[web.WebSocketResponse] = []\n    app[websockets] = l\n    app.router.add_get(\"/news\", websocket_handler)\n    app.on_startup.append(start_background_tasks)\n    app.on_cleanup.append(cleanup_background_tasks)\n    app.on_shutdown.append(on_shutdown)\n    return app\n\n\nweb.run_app(init())\n", "examples/fake_server.py": "#!/usr/bin/env python3\nimport asyncio\nimport pathlib\nimport socket\nimport ssl\nfrom typing import Dict, List\n\nfrom aiohttp import ClientSession, TCPConnector, test_utils, web\nfrom aiohttp.abc import AbstractResolver, ResolveResult\nfrom aiohttp.resolver import DefaultResolver\n\n\nclass FakeResolver(AbstractResolver):\n    _LOCAL_HOST = {0: \"127.0.0.1\", socket.AF_INET: \"127.0.0.1\", socket.AF_INET6: \"::1\"}\n\n    def __init__(self, fakes: Dict[str, int]) -> None:\n        \"\"\"fakes -- dns -> port dict\"\"\"\n        self._fakes = fakes\n        self._resolver = DefaultResolver()\n\n    async def resolve(\n        self,\n        host: str,\n        port: int = 0,\n        family: socket.AddressFamily = socket.AF_INET,\n    ) -> List[ResolveResult]:\n        fake_port = self._fakes.get(host)\n        if fake_port is not None:\n            return [\n                {\n                    \"hostname\": host,\n                    \"host\": self._LOCAL_HOST[family],\n                    \"port\": fake_port,\n                    \"family\": family,\n                    \"proto\": 0,\n                    \"flags\": socket.AI_NUMERICHOST,\n                }\n            ]\n        else:\n            return await self._resolver.resolve(host, port, family)\n\n    async def close(self) -> None:\n        await self._resolver.close()\n\n\nclass FakeFacebook:\n    def __init__(self) -> None:\n        self.app = web.Application()\n        self.app.router.add_routes(\n            [\n                web.get(\"/v2.7/me\", self.on_me),\n                web.get(\"/v2.7/me/friends\", self.on_my_friends),\n            ]\n        )\n        self.runner = web.AppRunner(self.app)\n        here = pathlib.Path(__file__)\n        ssl_cert = here.parent / \"server.crt\"\n        ssl_key = here.parent / \"server.key\"\n        self.ssl_context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n        self.ssl_context.load_cert_chain(str(ssl_cert), str(ssl_key))\n\n    async def start(self) -> Dict[str, int]:\n        port = test_utils.unused_port()\n        await self.runner.setup()\n        site = web.TCPSite(self.runner, \"127.0.0.1\", port, ssl_context=self.ssl_context)\n        await site.start()\n        return {\"graph.facebook.com\": port}\n\n    async def stop(self) -> None:\n        await self.runner.cleanup()\n\n    async def on_me(self, request: web.Request) -> web.StreamResponse:\n        return web.json_response({\"name\": \"John Doe\", \"id\": \"12345678901234567\"})\n\n    async def on_my_friends(self, request: web.Request) -> web.StreamResponse:\n        return web.json_response(\n            {\n                \"data\": [\n                    {\"name\": \"Bill Doe\", \"id\": \"233242342342\"},\n                    {\"name\": \"Mary Doe\", \"id\": \"2342342343222\"},\n                    {\"name\": \"Alex Smith\", \"id\": \"234234234344\"},\n                ],\n                \"paging\": {\n                    \"cursors\": {\n                        \"before\": \"QVFIUjRtc2c5NEl0ajN\",\n                        \"after\": \"QVFIUlpFQWM0TmVuaDRad0dt\",\n                    },\n                    \"next\": (\n                        \"https://graph.facebook.com/v2.7/12345678901234567/\"\n                        \"friends?access_token=EAACEdEose0cB\"\n                    ),\n                },\n                \"summary\": {\"total_count\": 3},\n            }\n        )\n\n\nasync def main() -> None:\n    token = \"ER34gsSGGS34XCBKd7u\"\n\n    fake_facebook = FakeFacebook()\n    info = await fake_facebook.start()\n    resolver = FakeResolver(info)\n    connector = TCPConnector(resolver=resolver, ssl=False)\n\n    async with ClientSession(connector=connector) as session:\n        async with session.get(\n            \"https://graph.facebook.com/v2.7/me\", params={\"access_token\": token}\n        ) as resp:\n            print(await resp.json())\n\n        async with session.get(\n            \"https://graph.facebook.com/v2.7/me/friends\", params={\"access_token\": token}\n        ) as resp:\n            print(await resp.json())\n\n    await fake_facebook.stop()\n\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\n", "examples/web_srv.py": "#!/usr/bin/env python3\n\"\"\"Example for aiohttp.web basic server.\"\"\"\n\nimport textwrap\n\nfrom aiohttp import web\n\n\nasync def intro(request: web.Request) -> web.StreamResponse:\n    txt = textwrap.dedent(\n        \"\"\"\\\n        Type {url}/hello/John  {url}/simple or {url}/change_body\n        in browser url bar\n    \"\"\"\n    ).format(url=\"127.0.0.1:8080\")\n    binary = txt.encode(\"utf8\")\n    resp = web.StreamResponse()\n    resp.content_length = len(binary)\n    resp.content_type = \"text/plain\"\n    await resp.prepare(request)\n    await resp.write(binary)\n    return resp\n\n\nasync def simple(request: web.Request) -> web.StreamResponse:\n    return web.Response(text=\"Simple answer\")\n\n\nasync def change_body(request: web.Request) -> web.StreamResponse:\n    resp = web.Response()\n    resp.body = b\"Body changed\"\n    resp.content_type = \"text/plain\"\n    return resp\n\n\nasync def hello(request: web.Request) -> web.StreamResponse:\n    resp = web.StreamResponse()\n    name = request.match_info.get(\"name\", \"Anonymous\")\n    answer = (\"Hello, \" + name).encode(\"utf8\")\n    resp.content_length = len(answer)\n    resp.content_type = \"text/plain\"\n    await resp.prepare(request)\n    await resp.write(answer)\n    await resp.write_eof()\n    return resp\n\n\ndef init() -> web.Application:\n    app = web.Application()\n    app.router.add_get(\"/\", intro)\n    app.router.add_get(\"/simple\", simple)\n    app.router.add_get(\"/change_body\", change_body)\n    app.router.add_get(\"/hello/{name}\", hello)\n    app.router.add_get(\"/hello\", hello)\n    return app\n\n\nweb.run_app(init())\n", "examples/client_ws.py": "#!/usr/bin/env python3\n\"\"\"websocket cmd client for web_ws.py example.\"\"\"\n\nimport argparse\nimport asyncio\nimport sys\nfrom contextlib import suppress\n\nimport aiohttp\n\n\nasync def start_client(url: str) -> None:\n    name = input(\"Please enter your name: \")\n\n    async def dispatch(ws: aiohttp.ClientWebSocketResponse) -> None:\n        while True:\n            msg = await ws.receive()\n\n            if msg.type == aiohttp.WSMsgType.TEXT:\n                print(\"Text: \", msg.data.strip())\n            elif msg.type == aiohttp.WSMsgType.BINARY:\n                print(\"Binary: \", msg.data)\n            elif msg.type == aiohttp.WSMsgType.PING:\n                await ws.pong()\n            elif msg.type == aiohttp.WSMsgType.PONG:\n                print(\"Pong received\")\n            else:\n                if msg.type == aiohttp.WSMsgType.CLOSE:\n                    await ws.close()\n                elif msg.type == aiohttp.WSMsgType.ERROR:\n                    print(\"Error during receive %s\" % ws.exception())\n                elif msg.type == aiohttp.WSMsgType.CLOSED:\n                    pass\n\n                break\n\n    async with aiohttp.ClientSession() as session:\n        async with session.ws_connect(url, autoclose=False, autoping=False) as ws:\n            # send request\n            dispatch_task = asyncio.create_task(dispatch(ws))\n\n            # Exit with Ctrl+D\n            while line := await asyncio.to_thread(sys.stdin.readline):\n                await ws.send_str(name + \": \" + line)\n\n            dispatch_task.cancel()\n            with suppress(asyncio.CancelledError):\n                await dispatch_task\n\n\nARGS = argparse.ArgumentParser(\n    description=\"websocket console client for wssrv.py example.\"\n)\nARGS.add_argument(\n    \"--host\", action=\"store\", dest=\"host\", default=\"127.0.0.1\", help=\"Host name\"\n)\nARGS.add_argument(\n    \"--port\", action=\"store\", dest=\"port\", default=8080, type=int, help=\"Port number\"\n)\n\nif __name__ == \"__main__\":\n    args = ARGS.parse_args()\n    if \":\" in args.host:\n        args.host, port = args.host.split(\":\", 1)\n        args.port = int(port)\n\n    url = f\"http://{args.host}:{args.port}\"\n\n    asyncio.run(start_client(url))\n", "examples/web_srv_route_table.py": "#!/usr/bin/env python3\n\"\"\"Example for aiohttp.web basic server with table definition for routes.\"\"\"\n\nimport textwrap\n\nfrom aiohttp import web\n\n\nasync def intro(request: web.Request) -> web.StreamResponse:\n    txt = textwrap.dedent(\n        \"\"\"\\\n        Type {url}/hello/John  {url}/simple or {url}/change_body\n        in browser url bar\n    \"\"\"\n    ).format(url=\"127.0.0.1:8080\")\n    binary = txt.encode(\"utf8\")\n    resp = web.StreamResponse()\n    resp.content_length = len(binary)\n    resp.content_type = \"text/plain\"\n    await resp.prepare(request)\n    await resp.write(binary)\n    return resp\n\n\nasync def simple(request: web.Request) -> web.StreamResponse:\n    return web.Response(text=\"Simple answer\")\n\n\nasync def change_body(request: web.Request) -> web.StreamResponse:\n    resp = web.Response()\n    resp.body = b\"Body changed\"\n    resp.content_type = \"text/plain\"\n    return resp\n\n\nasync def hello(request: web.Request) -> web.StreamResponse:\n    resp = web.StreamResponse()\n    name = request.match_info.get(\"name\", \"Anonymous\")\n    answer = (\"Hello, \" + name).encode(\"utf8\")\n    resp.content_length = len(answer)\n    resp.content_type = \"text/plain\"\n    await resp.prepare(request)\n    await resp.write(answer)\n    await resp.write_eof()\n    return resp\n\n\ndef init() -> web.Application:\n    app = web.Application()\n    app.router.add_routes(\n        [\n            web.get(\"/\", intro),\n            web.get(\"/simple\", simple),\n            web.get(\"/change_body\", change_body),\n            web.get(\"/hello/{name}\", hello),\n            web.get(\"/hello\", hello),\n        ]\n    )\n    return app\n\n\nweb.run_app(init())\n", "examples/cli_app.py": "#!/usr/bin/env python3\n\"\"\"\nExample of serving an Application using the `aiohttp.web` CLI.\n\nServe this app using::\n\n    $ python -m aiohttp.web -H localhost -P 8080 --repeat 10 cli_app:init \\\n    > \"Hello World\"\n\nHere ``--repeat`` & ``\"Hello World\"`` are application specific command-line\narguments. `aiohttp.web` only parses & consumes the command-line arguments it\nneeds (i.e. ``-H``, ``-P`` & ``entry-func``) and passes on any additional\narguments to the `cli_app:init` function for processing.\n\"\"\"\n\nfrom argparse import ArgumentParser, Namespace\nfrom typing import Optional, Sequence\n\nfrom aiohttp import web\n\nargs_key = web.AppKey(\"args_key\", Namespace)\n\n\nasync def display_message(req: web.Request) -> web.StreamResponse:\n    args = req.app[args_key]\n    text = \"\\n\".join([args.message] * args.repeat)\n    return web.Response(text=text)\n\n\ndef init(argv: Optional[Sequence[str]]) -> web.Application:\n    arg_parser = ArgumentParser(\n        prog=\"aiohttp.web ...\", description=\"Application CLI\", add_help=False\n    )\n\n    # Positional argument\n    arg_parser.add_argument(\"message\", help=\"message to print\")\n\n    # Optional argument\n    arg_parser.add_argument(\n        \"--repeat\", help=\"number of times to repeat message\", type=int, default=\"1\"\n    )\n\n    # Avoid conflict with -h from `aiohttp.web` CLI parser\n    arg_parser.add_argument(\n        \"--app-help\", help=\"show this message and exit\", action=\"help\"\n    )\n\n    args = arg_parser.parse_args(argv)\n\n    app = web.Application()\n    app[args_key] = args\n    app.router.add_get(\"/\", display_message)\n\n    return app\n", "examples/client_auth.py": "#!/usr/bin/env python3\nimport asyncio\n\nimport aiohttp\n\n\nasync def fetch(session: aiohttp.ClientSession) -> None:\n    print(\"Query http://httpbin.org/basic-auth/andrew/password\")\n    async with session.get(\"http://httpbin.org/basic-auth/andrew/password\") as resp:\n        print(resp.status)\n        body = await resp.text()\n        print(body)\n\n\nasync def go() -> None:\n    async with aiohttp.ClientSession(\n        auth=aiohttp.BasicAuth(\"andrew\", \"password\")\n    ) as session:\n        await fetch(session)\n\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(go())\n", "examples/web_classview.py": "#!/usr/bin/env python3\n\"\"\"Example for aiohttp.web class based views.\"\"\"\n\nimport functools\nimport json\n\nfrom aiohttp import web\n\n\nclass MyView(web.View):\n    async def get(self) -> web.StreamResponse:\n        return web.json_response(\n            {\n                \"method\": self.request.method,\n                \"args\": dict(self.request.rel_url.query),\n                \"headers\": dict(self.request.headers),\n            },\n            dumps=functools.partial(json.dumps, indent=4),\n        )\n\n    async def post(self) -> web.StreamResponse:\n        data = await self.request.post()\n        return web.json_response(\n            {\n                \"method\": self.request.method,\n                \"data\": dict(data),\n                \"headers\": dict(self.request.headers),\n            },\n            dumps=functools.partial(json.dumps, indent=4),\n        )\n\n\nasync def index(request: web.Request) -> web.StreamResponse:\n    txt = \"\"\"\n      <html>\n        <head>\n          <title>Class based view example</title>\n        </head>\n        <body>\n          <h1>Class based view example</h1>\n          <ul>\n            <li><a href=\"/\">/</a> This page\n            <li><a href=\"/get\">/get</a> Returns GET data.\n            <li><a href=\"/post\">/post</a> Returns POST data.\n          </ul>\n        </body>\n      </html>\n    \"\"\"\n    return web.Response(text=txt, content_type=\"text/html\")\n\n\ndef init() -> web.Application:\n    app = web.Application()\n    app.router.add_get(\"/\", index)\n    app.router.add_get(\"/get\", MyView)\n    app.router.add_post(\"/post\", MyView)\n    return app\n\n\nweb.run_app(init())\n", "examples/curl.py": "#!/usr/bin/env python3\n\nimport argparse\nimport asyncio\nimport sys\n\nimport aiohttp\n\n\nasync def curl(url: str) -> None:\n    async with aiohttp.ClientSession() as session:\n        async with session.request(\"GET\", url) as response:\n            print(repr(response))\n            chunk = await response.content.read()\n            print(\"Downloaded: %s\" % len(chunk))\n\n\nif __name__ == \"__main__\":\n    ARGS = argparse.ArgumentParser(description=\"GET url example\")\n    ARGS.add_argument(\"url\", nargs=1, metavar=\"URL\", help=\"URL to download\")\n    ARGS.add_argument(\n        \"--iocp\",\n        default=False,\n        action=\"store_true\",\n        help=\"Use ProactorEventLoop on Windows\",\n    )\n    options = ARGS.parse_args()\n\n    if options.iocp and sys.platform == \"win32\":\n        from asyncio import events, windows_events\n\n        # https://github.com/python/mypy/issues/12286\n        el = windows_events.ProactorEventLoop()  # type: ignore[attr-defined]\n        events.set_event_loop(el)\n\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(curl(options.url[0]))\n", "examples/web_cookies.py": "#!/usr/bin/env python3\n\"\"\"Example for aiohttp.web basic server with cookies.\"\"\"\n\nfrom pprint import pformat\nfrom typing import NoReturn\n\nfrom aiohttp import web\n\ntmpl = \"\"\"\\\n<html>\n    <body>\n        <a href=\"/login\">Login</a><br/>\n        <a href=\"/logout\">Logout</a><br/>\n        <pre>{}</pre>\n    </body>\n</html>\"\"\"\n\n\nasync def root(request: web.Request) -> web.StreamResponse:\n    resp = web.Response(content_type=\"text/html\")\n    resp.text = tmpl.format(pformat(request.cookies))\n    return resp\n\n\nasync def login(request: web.Request) -> NoReturn:\n    exc = web.HTTPFound(location=\"/\")\n    exc.set_cookie(\"AUTH\", \"secret\")\n    raise exc\n\n\nasync def logout(request: web.Request) -> NoReturn:\n    exc = web.HTTPFound(location=\"/\")\n    exc.del_cookie(\"AUTH\")\n    raise exc\n\n\ndef init() -> web.Application:\n    app = web.Application()\n    app.router.add_get(\"/\", root)\n    app.router.add_get(\"/login\", login)\n    app.router.add_get(\"/logout\", logout)\n    return app\n\n\nweb.run_app(init())\n", "examples/client_json.py": "#!/usr/bin/env python3\nimport asyncio\n\nimport aiohttp\n\n\nasync def fetch(session: aiohttp.ClientSession) -> None:\n    print(\"Query http://httpbin.org/get\")\n    async with session.get(\"http://httpbin.org/get\") as resp:\n        print(resp.status)\n        data = await resp.json()\n        print(data)\n\n\nasync def go() -> None:\n    async with aiohttp.ClientSession() as session:\n        await fetch(session)\n\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(go())\nloop.close()\n"}