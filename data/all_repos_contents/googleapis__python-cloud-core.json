{"noxfile.py": "# Copyright 2016 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nimport os\nimport shutil\n\nimport nox\n\n\nBLACK_VERSION = \"black==23.7.0\"\nBLACK_PATHS = [\"docs\", \"google\", \"tests\", \"noxfile.py\", \"setup.py\"]\n\nDEFAULT_PYTHON_VERSION = \"3.8\"\nCURRENT_DIRECTORY = os.path.abspath(os.path.dirname(__file__))\n\n\n@nox.session(python=\"3.10\")\ndef lint(session):\n    \"\"\"Run linters.\n\n    Returns a failure if the linters find linting errors or sufficiently\n    serious code quality issues.\n    \"\"\"\n    session.install(\"flake8\", \"flake8-import-order\", BLACK_VERSION)\n    session.install(\".\")\n    session.run(\"flake8\", \"google\", \"tests\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef mypy(session):\n    \"\"\"Run type-checking.\"\"\"\n    session.install(\".\", \"mypy\")\n    # Exclude types-protobuf==4.24.0.20240106\n    # See https://github.com/python/typeshed/issues/11254\n    session.install(\n        \"types-setuptools\",\n        \"types-requests\",\n        \"types-mock\",\n        \"types-protobuf!=4.24.0.20240106\",\n    )\n    session.run(\"mypy\", \"-p\", \"google\", \"-p\", \"tests\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef blacken(session):\n    \"\"\"Run black.\n\n    Format code to uniform standard.\n    \"\"\"\n    session.install(BLACK_VERSION)\n    session.run(\"black\", *BLACK_PATHS)\n\n\ndef default(session):\n    \"\"\"Default unit test session.\n    This is intended to be run **without** an interpreter set, so\n    that the current ``python`` (on the ``PATH``) or the version of\n    Python corresponding to the ``nox`` binary the ``PATH`` can\n    run the tests.\n    \"\"\"\n    constraints_path = os.path.join(\n        CURRENT_DIRECTORY, \"testing\", \"constraints-{}.txt\".format(session.python)\n    )\n\n    # Install all test dependencies, then install local packages in-place.\n    session.install(\"pytest\", \"pytest-cov\", \"-c\", constraints_path)\n    session.install(\"-e\", \".[grpc]\", \"-c\", constraints_path)\n\n    # Run py.test against the unit tests.\n    session.run(\n        \"py.test\",\n        \"--quiet\",\n        \"--cov=google.cloud\",\n        \"--cov=tests.unit\",\n        \"--cov-append\",\n        \"--cov-config=.coveragerc\",\n        \"--cov-report=\",\n        \"--cov-fail-under=0\",\n        os.path.join(\"tests\", \"unit\"),\n        *session.posargs,\n    )\n\n\n@nox.session(python=[\"3.7\", \"3.8\", \"3.9\", \"3.10\", \"3.11\", \"3.12\"])\ndef unit(session):\n    \"\"\"Default unit test session.\"\"\"\n    default(session)\n\n\n@nox.session(python=\"3.10\")\ndef lint_setup_py(session):\n    \"\"\"Verify that setup.py is valid (including RST check).\"\"\"\n\n    session.install(\"docutils\", \"Pygments\")\n    session.run(\"python\", \"setup.py\", \"check\", \"--restructuredtext\", \"--strict\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef cover(session):\n    \"\"\"Run the final coverage report.\n\n    This outputs the coverage report aggregating coverage from the unit\n    test runs (not system test runs), and then erases coverage data.\n    \"\"\"\n    session.install(\"coverage\", \"pytest-cov\")\n    session.run(\"coverage\", \"report\", \"--show-missing\", \"--fail-under=100\")\n    session.run(\"coverage\", \"erase\")\n\n\n@nox.session(python=\"3.9\")\ndef docs(session):\n    \"\"\"Build the docs for this library.\"\"\"\n\n    session.install(\".\", \"grpcio >= 1.8.2\", \"grpcio-gcp >= 0.2.2\")\n    session.install(\"-e\", \".\")\n    session.install(\n        # We need to pin to specific versions of the `sphinxcontrib-*` packages\n        # which still support sphinx 4.x.\n        # See https://github.com/googleapis/sphinx-docfx-yaml/issues/344\n        # and https://github.com/googleapis/sphinx-docfx-yaml/issues/345.\n        \"sphinxcontrib-applehelp==1.0.4\",\n        \"sphinxcontrib-devhelp==1.0.2\",\n        \"sphinxcontrib-htmlhelp==2.0.1\",\n        \"sphinxcontrib-qthelp==1.0.3\",\n        \"sphinxcontrib-serializinghtml==1.1.5\",\n        \"sphinx==4.5.0\",\n        \"alabaster\",\n        \"recommonmark\",\n    )\n\n    shutil.rmtree(os.path.join(\"docs\", \"_build\"), ignore_errors=True)\n    session.run(\n        \"sphinx-build\",\n        \"-W\",  # warnings as errors\n        \"-T\",  # show full traceback on exception\n        \"-N\",  # no colors\n        \"-b\",\n        \"html\",\n        \"-d\",\n        os.path.join(\"docs\", \"_build\", \"doctrees\", \"\"),\n        os.path.join(\"docs\", \"\"),\n        os.path.join(\"docs\", \"_build\", \"html\", \"\"),\n    )\n\n\n@nox.session(python=\"3.10\")\ndef docfx(session):\n    \"\"\"Build the docfx yaml files for this library.\"\"\"\n\n    session.install(\"-e\", \".\")\n    session.install(\n        # We need to pin to specific versions of the `sphinxcontrib-*` packages\n        # which still support sphinx 4.x.\n        # See https://github.com/googleapis/sphinx-docfx-yaml/issues/344\n        # and https://github.com/googleapis/sphinx-docfx-yaml/issues/345.\n        \"sphinxcontrib-applehelp==1.0.4\",\n        \"sphinxcontrib-devhelp==1.0.2\",\n        \"sphinxcontrib-htmlhelp==2.0.1\",\n        \"sphinxcontrib-qthelp==1.0.3\",\n        \"sphinxcontrib-serializinghtml==1.1.5\",\n        \"gcp-sphinx-docfx-yaml\",\n        \"alabaster\",\n        \"recommonmark\",\n    )\n\n    shutil.rmtree(os.path.join(\"docs\", \"_build\"), ignore_errors=True)\n    session.run(\n        \"sphinx-build\",\n        \"-T\",  # show full traceback on exception\n        \"-N\",  # no colors\n        \"-D\",\n        (\n            \"extensions=sphinx.ext.autodoc,\"\n            \"sphinx.ext.autosummary,\"\n            \"docfx_yaml.extension,\"\n            \"sphinx.ext.intersphinx,\"\n            \"sphinx.ext.coverage,\"\n            \"sphinx.ext.napoleon,\"\n            \"sphinx.ext.todo,\"\n            \"sphinx.ext.viewcode,\"\n            \"recommonmark\"\n        ),\n        \"-b\",\n        \"html\",\n        \"-d\",\n        os.path.join(\"docs\", \"_build\", \"doctrees\", \"\"),\n        os.path.join(\"docs\", \"\"),\n        os.path.join(\"docs\", \"_build\", \"html\", \"\"),\n    )\n", "setup.py": "# Copyright 2018 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport io\nimport os\n\nimport setuptools\n\n\n# Package metadata.\n\nname = \"google-cloud-core\"\ndescription = \"Google Cloud API client core library\"\n# Should be one of:\n# 'Development Status :: 3 - Alpha'\n# 'Development Status :: 4 - Beta'\n# 'Development Status :: 5 - Production/Stable'\nrelease_status = \"Development Status :: 5 - Production/Stable\"\ndependencies = [\n    \"google-api-core >= 1.31.6, <3.0.0dev,!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0\",\n    \"google-auth >= 1.25.0, < 3.0dev\",\n    \"importlib-metadata > 1.0.0; python_version<'3.8'\",\n]\nextras = {\n    \"grpc\": [\n        \"grpcio >= 1.38.0, < 2.0dev\",\n        \"grpcio-status >= 1.38.0, < 2.0.dev0\",\n    ],\n}\n\n# Setup boilerplate below this line.\n\npackage_root = os.path.abspath(os.path.dirname(__file__))\n\nversion = {}\nwith open(os.path.join(package_root, \"google/cloud/version.py\")) as fp:\n    exec(fp.read(), version)\nversion = version[\"__version__\"]\n\nreadme_filename = os.path.join(package_root, \"README.rst\")\nwith io.open(readme_filename, encoding=\"utf-8\") as readme_file:\n    readme = readme_file.read()\n\n# Only include packages under the 'google' namespace. Do not include tests,\n# benchmarks, etc.\npackages = [\n    package\n    for package in setuptools.find_namespace_packages()\n    if package.startswith(\"google\")\n]\n\nsetuptools.setup(\n    name=name,\n    version=version,\n    description=description,\n    long_description=readme,\n    author=\"Google LLC\",\n    author_email=\"googleapis-packages@google.com\",\n    license=\"Apache 2.0\",\n    url=\"https://github.com/googleapis/python-cloud-core\",\n    classifiers=[\n        release_status,\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n        \"Operating System :: OS Independent\",\n        \"Topic :: Internet\",\n    ],\n    platforms=\"Posix; MacOS X; Windows\",\n    packages=packages,\n    install_requires=dependencies,\n    extras_require=extras,\n    python_requires=\">=3.7\",\n    include_package_data=True,\n    zip_safe=False,\n)\n", "owlbot.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"This script is used to synthesize generated parts of this library.\"\"\"\n\nimport synthtool as s\nfrom synthtool import gcp\nfrom synthtool.languages import python\n\ncommon = gcp.CommonTemplates()\n\n# ----------------------------------------------------------------------------\n# Add templated files\n# ----------------------------------------------------------------------------\ntemplated_files = common.py_library(\n    microgenerator=True,\n    cov_level=100,\n)\ns.move(\n    templated_files,\n    excludes=[\n        \"docs/multiprocessing.rst\",\n        \"noxfile.py\",\n        \".flake8\",\n        \".coveragerc\",\n        \"setup.cfg\",\n        \"README.rst\",\n    ],\n)\n\npython.configure_previous_major_version_branches()\n\ns.shell.run([\"nox\", \"-s\", \"blacken\"], hide_output=False)\n", "pylint.config.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"This module is used to configure gcp-devrel-py-tools run-pylint.\"\"\"\n\n# Library configuration\n\n# library_additions = {}\n# library_replacements = {}\n\n# Test configuration\n\n# test_additions = copy.deepcopy(library_additions)\n# test_replacements = copy.deepcopy(library_replacements)\n", "scripts/readme-gen/readme_gen.py": "#!/usr/bin/env python\n\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Generates READMEs using configuration defined in yaml.\"\"\"\n\nimport argparse\nimport io\nimport os\nimport subprocess\n\nimport jinja2\nimport yaml\n\n\njinja_env = jinja2.Environment(\n    trim_blocks=True,\n    loader=jinja2.FileSystemLoader(\n        os.path.abspath(os.path.join(os.path.dirname(__file__), \"templates\"))\n    ),\n    autoescape=True,\n)\n\nREADME_TMPL = jinja_env.get_template(\"README.tmpl.rst\")\n\n\ndef get_help(file):\n    return subprocess.check_output([\"python\", file, \"--help\"]).decode()\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"source\")\n    parser.add_argument(\"--destination\", default=\"README.rst\")\n\n    args = parser.parse_args()\n\n    source = os.path.abspath(args.source)\n    root = os.path.dirname(source)\n    destination = os.path.join(root, args.destination)\n\n    jinja_env.globals[\"get_help\"] = get_help\n\n    with io.open(source, \"r\") as f:\n        config = yaml.load(f)\n\n    # This allows get_help to execute in the right directory.\n    os.chdir(root)\n\n    output = README_TMPL.render(config)\n\n    with io.open(destination, \"w\") as f:\n        f.write(output)\n\n\nif __name__ == \"__main__\":\n    main()\n", "docs/conf.py": "# -*- coding: utf-8 -*-\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# google-cloud-core documentation build configuration file\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\nimport shlex\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\nsys.path.insert(0, os.path.abspath(\"..\"))\n\n# For plugins that can not read conf.py.\n# See also: https://github.com/docascode/sphinx-docfx-yaml/issues/85\nsys.path.insert(0, os.path.abspath(\".\"))\n\n__version__ = \"\"\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\nneeds_sphinx = \"1.5.5\"\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.autosummary\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.coverage\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.viewcode\",\n    \"recommonmark\",\n]\n\n# autodoc/autosummary flags\nautoclass_content = \"both\"\nautodoc_default_options = {\"members\": True}\nautosummary_generate = True\n\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = ['.rst', '.md']\nsource_suffix = [\".rst\", \".md\"]\n\n# The encoding of source files.\n# source_encoding = 'utf-8-sig'\n\n# The root toctree document.\nroot_doc = \"index\"\n\n# General information about the project.\nproject = \"google-cloud-core\"\ncopyright = \"2019, Google\"\nauthor = \"Google APIs\"\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The full version, including alpha/beta/rc tags.\nrelease = __version__\n# The short X.Y version.\nversion = \".\".join(release.split(\".\")[0:2])\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n# today = ''\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = '%B %d, %Y'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\n    \"_build\",\n    \"**/.nox/**/*\",\n    \"samples/AUTHORING_GUIDE.md\",\n    \"samples/CONTRIBUTING.md\",\n    \"samples/snippets/README.rst\",\n]\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n# default_role = None\n\n# If true, '()' will be appended to :func: etc. cross-reference text.\n# add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \"sphinx\"\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as \"system message\" paragraphs in the built documents.\n# keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \"alabaster\"\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\nhtml_theme_options = {\n    \"description\": \"Google Cloud Client Libraries for google-cloud-core\",\n    \"github_user\": \"googleapis\",\n    \"github_repo\": \"python-cloud-core\",\n    \"github_banner\": True,\n    \"font_family\": \"'Roboto', Georgia, sans\",\n    \"head_font_family\": \"'Roboto', Georgia, serif\",\n    \"code_font_family\": \"'Roboto Mono', 'Consolas', monospace\",\n}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n# html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n# html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n# html_extra_path = []\n\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n# html_last_updated_fmt = '%b %d, %Y'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n# html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n# html_show_sourcelink = True\n\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n# html_show_sphinx = True\n\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n# html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = ''\n\n# This is the file name suffix for HTML files (e.g. \".xhtml\").\n# html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'\n#   'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'\n# html_search_language = 'en'\n\n# A dictionary with options for the search language support, empty by default.\n# Now only 'ja' uses this config value\n# html_search_options = {'type': 'default'}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n# html_search_scorer = 'scorer.js'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \"google-cloud-core-doc\"\n\n# -- Options for warnings ------------------------------------------------------\n\n\nsuppress_warnings = [\n    # Temporarily suppress this to avoid \"more than one target found for\n    # cross-reference\" warning, which are intractable for us to avoid while in\n    # a mono-repo.\n    # See https://github.com/sphinx-doc/sphinx/blob\n    # /2a65ffeef5c107c19084fabdd706cdff3f52d93c/sphinx/domains/python.py#L843\n    \"ref.python\"\n]\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #'preamble': '',\n    # Latex figure (float) alignment\n    #'figure_align': 'htbp',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (\n        root_doc,\n        \"google-cloud-core.tex\",\n        \"google-cloud-core Documentation\",\n        author,\n        \"manual\",\n    )\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# If false, no module index is generated.\n# latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (\n        root_doc,\n        \"google-cloud-core\",\n        \"google-cloud-core Documentation\",\n        [author],\n        1,\n    )\n]\n\n# If true, show URL addresses after external links.\n# man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        root_doc,\n        \"google-cloud-core\",\n        \"google-cloud-core Documentation\",\n        author,\n        \"google-cloud-core\",\n        \"google-cloud-core Library\",\n        \"APIs\",\n    )\n]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n# texinfo_show_urls = 'footnote'\n\n# If true, do not generate a @detailmenu in the \"Top\" node's menu.\n# texinfo_no_detailmenu = False\n\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\n    \"python\": (\"https://python.readthedocs.org/en/latest/\", None),\n    \"google-auth\": (\"https://googleapis.dev/python/google-auth/latest/\", None),\n    \"google.api_core\": (\n        \"https://googleapis.dev/python/google-api-core/latest/\",\n        None,\n    ),\n    \"grpc\": (\"https://grpc.github.io/grpc/python/\", None),\n    \"proto-plus\": (\"https://proto-plus-python.readthedocs.io/en/latest/\", None),\n    \"protobuf\": (\"https://googleapis.dev/python/protobuf/latest/\", None),\n}\n\n\n# Napoleon settings\nnapoleon_google_docstring = True\nnapoleon_numpy_docstring = True\nnapoleon_include_private_with_doc = False\nnapoleon_include_special_with_doc = True\nnapoleon_use_admonition_for_examples = False\nnapoleon_use_admonition_for_notes = False\nnapoleon_use_admonition_for_references = False\nnapoleon_use_ivar = False\nnapoleon_use_param = True\nnapoleon_use_rtype = True\n", "tests/__init__.py": "", "tests/unit/test_obsolete.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom unittest import mock\nimport warnings\n\nfrom google.cloud import obsolete\n\n\ndef test_complain_noop():\n    with mock.patch.object(warnings, \"warn\", autospec=True) as warn:\n        obsolete.complain(\"bogus_package\")\n        assert warn.call_count == 0\n\n\ndef test_complain():\n    with mock.patch.object(warnings, \"warn\", autospec=True) as warn:\n        obsolete.complain(\"google-cloud-core\")\n        warn.assert_called_once_with(mock.ANY, DeprecationWarning)\n", "tests/unit/test__http.py": "# Copyright 2014 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport http.client\nimport json\nimport os\nimport unittest\nfrom unittest import mock\nimport warnings\n\nimport requests\n\n\nclass TestConnection(unittest.TestCase):\n    @staticmethod\n    def _get_target_class():\n        from google.cloud._http import Connection\n\n        return Connection\n\n    def _make_one(self, *args, **kw):\n        return self._get_target_class()(*args, **kw)\n\n    def test_constructor_defaults(self):\n        from google.api_core.client_info import ClientInfo\n\n        client = object()\n        conn = self._make_one(client)\n        self.assertIs(conn._client, client)\n        self.assertIsInstance(conn._client_info, ClientInfo)\n\n    def test_constructor_explicit(self):\n        client = object()\n        client_info = object()\n        conn = self._make_one(client, client_info=client_info)\n        self.assertIs(conn._client, client)\n\n    def test_user_agent_all_caps_getter_deprecated(self):\n        client = object()\n        conn = self._make_one(client)\n\n        with mock.patch.object(warnings, \"warn\", autospec=True) as warn:\n            self.assertEqual(conn.USER_AGENT, conn._client_info.to_user_agent())\n\n        warn.assert_called_once_with(mock.ANY, DeprecationWarning, stacklevel=2)\n\n    def test_user_agent_all_caps_setter_deprecated(self):\n        conn = self._make_one(object())\n        user_agent = \"testing\"\n\n        with mock.patch.object(warnings, \"warn\", autospec=True) as warn:\n            conn.USER_AGENT = user_agent\n\n        self.assertEqual(conn._client_info.user_agent, user_agent)\n        warn.assert_called_once_with(mock.ANY, DeprecationWarning, stacklevel=2)\n\n    def test_user_agent_getter(self):\n        conn = self._make_one(object())\n        self.assertEqual(conn.user_agent, conn._client_info.to_user_agent())\n\n    def test_user_agent_setter(self):\n        conn = self._make_one(object())\n        user_agent = \"testing\"\n        conn.user_agent = user_agent\n        self.assertEqual(conn._client_info.user_agent, user_agent)\n\n    def test_extra_headers_all_caps_getter_deprecated(self):\n        client = object()\n        conn = self._make_one(client)\n        expected = conn._extra_headers = {\"foo\": \"bar\"}\n\n        with mock.patch.object(warnings, \"warn\", autospec=True) as warn:\n            self.assertEqual(conn._EXTRA_HEADERS, expected)\n\n        warn.assert_called_once_with(mock.ANY, DeprecationWarning, stacklevel=2)\n\n    def test_extra_headers_all_caps_setter_deprecated(self):\n        conn = self._make_one(object())\n        extra_headers = {\"foo\": \"bar\"}\n\n        with mock.patch.object(warnings, \"warn\", autospec=True) as warn:\n            conn._EXTRA_HEADERS = extra_headers\n\n        self.assertEqual(conn._extra_headers, extra_headers)\n        warn.assert_called_once_with(mock.ANY, DeprecationWarning, stacklevel=2)\n\n    def test_extra_headers_getter_default(self):\n        conn = self._make_one(object())\n        expected = {}\n        self.assertEqual(conn.extra_headers, expected)\n\n    def test_extra_headers_getter_overridden(self):\n        conn = self._make_one(object())\n        expected = conn._extra_headers = {\"foo\": \"bar\"}\n        self.assertEqual(conn.extra_headers, expected)\n\n    def test_extra_headers_item_assignment(self):\n        conn = self._make_one(object())\n        expected = {\"foo\": \"bar\"}\n        conn.extra_headers[\"foo\"] = \"bar\"\n        self.assertEqual(conn._extra_headers, expected)\n\n    def test_extra_headers_setter(self):\n        conn = self._make_one(object())\n        expected = {\"foo\": \"bar\"}\n        conn.extra_headers = expected\n        self.assertEqual(conn._extra_headers, expected)\n\n    def test_credentials_property(self):\n        client = mock.Mock(spec=[\"_credentials\"])\n        conn = self._make_one(client)\n        self.assertIs(conn.credentials, client._credentials)\n\n    def test_http_property(self):\n        client = mock.Mock(spec=[\"_http\"])\n        conn = self._make_one(client)\n        self.assertIs(conn.http, client._http)\n\n\ndef make_response(status=http.client.OK, content=b\"\", headers={}):\n    response = requests.Response()\n    response.status_code = status\n    response._content = content\n    response.headers = headers\n    response.request = requests.Request()\n\n    # Work around requests 'charset_normalizer' idiocy.\n    # See https://github.com/googleapis/python-cloud-core/issues/117\n    response.encoding = \"utf-8\"\n\n    return response\n\n\ndef make_requests_session(responses):\n    session = mock.create_autospec(requests.Session, instance=True)\n    session.request.side_effect = responses\n    return session\n\n\nclass TestJSONConnection(unittest.TestCase):\n    JSON_HEADERS = {\"content-type\": \"application/json\"}\n    EMPTY_JSON_RESPONSE = make_response(content=b\"{}\", headers=JSON_HEADERS)\n\n    @staticmethod\n    def _get_default_timeout():\n        from google.cloud._http import _DEFAULT_TIMEOUT\n\n        return _DEFAULT_TIMEOUT\n\n    @staticmethod\n    def _get_target_class():\n        from google.cloud._http import JSONConnection\n\n        return JSONConnection\n\n    def _make_one(self, *args, **kw):\n        return self._get_target_class()(*args, **kw)\n\n    def _make_mock_one(self, *args, **kw):\n        class MockConnection(self._get_target_class()):\n            API_URL_TEMPLATE = \"{api_base_url}/mock/{api_version}{path}\"\n            API_BASE_URL = \"http://mock\"\n            API_BASE_MTLS_URL = \"https://mock.mtls\"\n            API_VERSION = \"vMOCK\"\n\n        return MockConnection(*args, **kw)\n\n    def test_class_defaults(self):\n        klass = self._get_target_class()\n        self.assertIsNone(klass.API_URL_TEMPLATE)\n        self.assertIsNone(klass.API_BASE_URL)\n        self.assertIsNone(klass.API_VERSION)\n\n    def test_constructor(self):\n        client = object()\n        conn = self._make_one(client)\n        self.assertIs(conn._client, client)\n\n    def test_build_api_url_no_extra_query_params(self):\n        client = object()\n        conn = self._make_mock_one(client)\n        # Intended to emulate self.mock_template\n        URI = \"/\".join(\n            [conn.API_BASE_URL, \"mock\", conn.API_VERSION, \"foo?prettyPrint=false\"]\n        )\n        self.assertEqual(conn.build_api_url(\"/foo\"), URI)\n\n    def test_build_api_url_w_pretty_print_query_params(self):\n        client = object()\n        conn = self._make_mock_one(client)\n        uri = conn.build_api_url(\"/foo\", {\"prettyPrint\": \"true\"})\n        URI = \"/\".join(\n            [conn.API_BASE_URL, \"mock\", conn.API_VERSION, \"foo?prettyPrint=true\"]\n        )\n        self.assertEqual(uri, URI)\n\n    def test_build_api_url_w_extra_query_params(self):\n        from urllib.parse import parse_qs\n        from urllib.parse import urlsplit\n\n        client = object()\n        conn = self._make_mock_one(client)\n        uri = conn.build_api_url(\"/foo\", {\"bar\": \"baz\", \"qux\": [\"quux\", \"corge\"]})\n\n        scheme, netloc, path, qs, _ = urlsplit(uri)\n        self.assertEqual(\"%s://%s\" % (scheme, netloc), conn.API_BASE_URL)\n        # Intended to emulate mock_template\n        PATH = \"/\".join([\"\", \"mock\", conn.API_VERSION, \"foo\"])\n        self.assertEqual(path, PATH)\n        parms = dict(parse_qs(qs))\n        self.assertEqual(parms[\"bar\"], [\"baz\"])\n        self.assertEqual(parms[\"qux\"], [\"quux\", \"corge\"])\n        self.assertEqual(parms[\"prettyPrint\"], [\"false\"])\n\n    def test_build_api_url_w_extra_query_params_tuples(self):\n        from urllib.parse import parse_qs\n        from urllib.parse import urlsplit\n\n        client = object()\n        conn = self._make_mock_one(client)\n        uri = conn.build_api_url(\n            \"/foo\", [(\"bar\", \"baz\"), (\"qux\", \"quux\"), (\"qux\", \"corge\")]\n        )\n\n        scheme, netloc, path, qs, _ = urlsplit(uri)\n        self.assertEqual(\"%s://%s\" % (scheme, netloc), conn.API_BASE_URL)\n        # Intended to emulate mock_template\n        PATH = \"/\".join([\"\", \"mock\", conn.API_VERSION, \"foo\"])\n        self.assertEqual(path, PATH)\n        parms = dict(parse_qs(qs))\n        self.assertEqual(parms[\"bar\"], [\"baz\"])\n        self.assertEqual(parms[\"qux\"], [\"quux\", \"corge\"])\n        self.assertEqual(parms[\"prettyPrint\"], [\"false\"])\n\n    def test_get_api_base_url_for_mtls_w_api_base_url(self):\n        client = object()\n        conn = self._make_mock_one(client)\n        uri = conn.get_api_base_url_for_mtls(api_base_url=\"http://foo\")\n        self.assertEqual(uri, \"http://foo\")\n\n    def test_get_api_base_url_for_mtls_env_always(self):\n        client = object()\n        conn = self._make_mock_one(client)\n        with mock.patch.dict(os.environ, {\"GOOGLE_API_USE_MTLS_ENDPOINT\": \"always\"}):\n            uri = conn.get_api_base_url_for_mtls()\n            self.assertEqual(uri, \"https://mock.mtls\")\n\n    def test_get_api_base_url_for_mtls_env_never(self):\n        client = object()\n        conn = self._make_mock_one(client)\n        with mock.patch.dict(os.environ, {\"GOOGLE_API_USE_MTLS_ENDPOINT\": \"never\"}):\n            uri = conn.get_api_base_url_for_mtls()\n            self.assertEqual(uri, \"http://mock\")\n\n    def test_get_api_base_url_for_mtls_env_auto(self):\n        client = mock.Mock()\n        client._http = mock.Mock()\n        client._http.is_mtls = False\n        conn = self._make_mock_one(client)\n\n        # ALLOW_AUTO_SWITCH_TO_MTLS_URL is False, so use regular endpoint.\n        with mock.patch.dict(os.environ, {\"GOOGLE_API_USE_MTLS_ENDPOINT\": \"auto\"}):\n            uri = conn.get_api_base_url_for_mtls()\n            self.assertEqual(uri, \"http://mock\")\n\n        # ALLOW_AUTO_SWITCH_TO_MTLS_URL is True, so now endpoint dependes\n        # on client._http.is_mtls\n        conn.ALLOW_AUTO_SWITCH_TO_MTLS_URL = True\n\n        with mock.patch.dict(os.environ, {\"GOOGLE_API_USE_MTLS_ENDPOINT\": \"auto\"}):\n            uri = conn.get_api_base_url_for_mtls()\n            self.assertEqual(uri, \"http://mock\")\n\n        client._http.is_mtls = True\n        with mock.patch.dict(os.environ, {\"GOOGLE_API_USE_MTLS_ENDPOINT\": \"auto\"}):\n            uri = conn.get_api_base_url_for_mtls()\n            self.assertEqual(uri, \"https://mock.mtls\")\n\n    def test__make_request_no_data_no_content_type_no_headers(self):\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session([make_response()])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_one(client)\n        url = \"http://example.com/test\"\n\n        response = conn._make_request(\"GET\", url)\n\n        self.assertEqual(response.status_code, http.client.OK)\n        self.assertEqual(response.content, b\"\")\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"User-Agent\": conn.user_agent,\n            CLIENT_INFO_HEADER: conn.user_agent,\n        }\n        session.request.assert_called_once_with(\n            method=\"GET\",\n            url=url,\n            headers=expected_headers,\n            data=None,\n            timeout=self._get_default_timeout(),\n        )\n\n    def test__make_request_w_data_no_extra_headers(self):\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session([make_response()])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_one(client)\n        url = \"http://example.com/test\"\n        data = b\"data\"\n\n        conn._make_request(\"GET\", url, data, \"application/json\")\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"Content-Type\": \"application/json\",\n            \"User-Agent\": conn.user_agent,\n            CLIENT_INFO_HEADER: conn.user_agent,\n        }\n        session.request.assert_called_once_with(\n            method=\"GET\",\n            url=url,\n            headers=expected_headers,\n            data=data,\n            timeout=self._get_default_timeout(),\n        )\n\n    def test__make_request_w_extra_headers(self):\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session([make_response()])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_one(client)\n\n        url = \"http://example.com/test\"\n        conn._make_request(\"GET\", url, headers={\"X-Foo\": \"foo\"})\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"X-Foo\": \"foo\",\n            \"User-Agent\": conn.user_agent,\n            CLIENT_INFO_HEADER: conn.user_agent,\n        }\n        session.request.assert_called_once_with(\n            method=\"GET\",\n            url=url,\n            headers=expected_headers,\n            data=None,\n            timeout=self._get_default_timeout(),\n        )\n\n    def test__make_request_w_timeout(self):\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session([make_response()])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_one(client)\n\n        url = \"http://example.com/test\"\n        conn._make_request(\"GET\", url, timeout=(5.5, 2.8))\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"User-Agent\": conn.user_agent,\n            CLIENT_INFO_HEADER: conn.user_agent,\n        }\n        session.request.assert_called_once_with(\n            method=\"GET\",\n            url=url,\n            headers=expected_headers,\n            data=None,\n            timeout=(5.5, 2.8),\n        )\n\n    def test_api_request_defaults(self):\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session(\n            [make_response(content=b\"{}\", headers=self.JSON_HEADERS)]\n        )\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n        path = \"/path/required\"\n\n        self.assertEqual(conn.api_request(\"GET\", path), {})\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"User-Agent\": conn.user_agent,\n            CLIENT_INFO_HEADER: conn.user_agent,\n        }\n        expected_url = \"{base}/mock/{version}{path}?prettyPrint=false\".format(\n            base=conn.API_BASE_URL, version=conn.API_VERSION, path=path\n        )\n        session.request.assert_called_once_with(\n            method=\"GET\",\n            url=expected_url,\n            headers=expected_headers,\n            data=None,\n            timeout=self._get_default_timeout(),\n        )\n\n    def test_api_request_w_non_json_response(self):\n        session = make_requests_session([make_response(content=b\"content\")])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n\n        with self.assertRaises(ValueError):\n            conn.api_request(\"GET\", \"/\")\n\n    def test_api_request_wo_json_expected(self):\n        session = make_requests_session([make_response(content=b\"content\")])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n\n        result = conn.api_request(\"GET\", \"/\", expect_json=False)\n\n        self.assertEqual(result, b\"content\")\n\n    def test_api_request_w_query_params(self):\n        from urllib.parse import parse_qs\n        from urllib.parse import urlsplit\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session([self.EMPTY_JSON_RESPONSE])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n\n        result = conn.api_request(\"GET\", \"/\", {\"foo\": \"bar\", \"baz\": [\"qux\", \"quux\"]})\n\n        self.assertEqual(result, {})\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"User-Agent\": conn.user_agent,\n            CLIENT_INFO_HEADER: conn.user_agent,\n        }\n        session.request.assert_called_once_with(\n            method=\"GET\",\n            url=mock.ANY,\n            headers=expected_headers,\n            data=None,\n            timeout=self._get_default_timeout(),\n        )\n\n        url = session.request.call_args[1][\"url\"]\n        scheme, netloc, path, qs, _ = urlsplit(url)\n        self.assertEqual(\"%s://%s\" % (scheme, netloc), conn.API_BASE_URL)\n        # Intended to emulate self.mock_template\n        PATH = \"/\".join([\"\", \"mock\", conn.API_VERSION, \"\"])\n        self.assertEqual(path, PATH)\n        parms = dict(parse_qs(qs))\n        self.assertEqual(parms[\"foo\"], [\"bar\"])\n        self.assertEqual(parms[\"baz\"], [\"qux\", \"quux\"])\n\n    def test_api_request_w_headers(self):\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session([self.EMPTY_JSON_RESPONSE])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n\n        result = conn.api_request(\"GET\", \"/\", headers={\"X-Foo\": \"bar\"})\n        self.assertEqual(result, {})\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"User-Agent\": conn.user_agent,\n            \"X-Foo\": \"bar\",\n            CLIENT_INFO_HEADER: conn.user_agent,\n        }\n        session.request.assert_called_once_with(\n            method=\"GET\",\n            url=mock.ANY,\n            headers=expected_headers,\n            data=None,\n            timeout=self._get_default_timeout(),\n        )\n\n    def test_api_request_w_extra_headers(self):\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session([self.EMPTY_JSON_RESPONSE])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n        conn.extra_headers = {\n            \"X-Baz\": \"dax-quux\",\n            \"X-Foo\": \"not-bar\",  # Collision with ``headers``.\n        }\n\n        result = conn.api_request(\"GET\", \"/\", headers={\"X-Foo\": \"bar\"})\n\n        self.assertEqual(result, {})\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"User-Agent\": conn.user_agent,\n            \"X-Foo\": \"not-bar\",  # The one passed-in is overridden.\n            \"X-Baz\": \"dax-quux\",\n            CLIENT_INFO_HEADER: conn.user_agent,\n        }\n        session.request.assert_called_once_with(\n            method=\"GET\",\n            url=mock.ANY,\n            headers=expected_headers,\n            data=None,\n            timeout=self._get_default_timeout(),\n        )\n\n    def test_api_request_w_data(self):\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session([self.EMPTY_JSON_RESPONSE])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n\n        data = {\"foo\": \"bar\"}\n        self.assertEqual(conn.api_request(\"POST\", \"/\", data=data), {})\n\n        expected_data = json.dumps(data)\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"Content-Type\": \"application/json\",\n            \"User-Agent\": conn.user_agent,\n            CLIENT_INFO_HEADER: conn.user_agent,\n        }\n\n        session.request.assert_called_once_with(\n            method=\"POST\",\n            url=mock.ANY,\n            headers=expected_headers,\n            data=expected_data,\n            timeout=self._get_default_timeout(),\n        )\n\n    def test_api_request_w_timeout(self):\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session(\n            [make_response(content=b\"{}\", headers=self.JSON_HEADERS)]\n        )\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n        path = \"/path/required\"\n\n        self.assertEqual(conn.api_request(\"GET\", path, timeout=(2.2, 3.3)), {})\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"User-Agent\": conn.user_agent,\n            CLIENT_INFO_HEADER: conn.user_agent,\n        }\n        expected_url = \"{base}/mock/{version}{path}?prettyPrint=false\".format(\n            base=conn.API_BASE_URL, version=conn.API_VERSION, path=path\n        )\n        session.request.assert_called_once_with(\n            method=\"GET\",\n            url=expected_url,\n            headers=expected_headers,\n            data=None,\n            timeout=(2.2, 3.3),\n        )\n\n    def test_api_request_w_extra_api_info(self):\n        from google.cloud._http import CLIENT_INFO_HEADER\n\n        session = make_requests_session([self.EMPTY_JSON_RESPONSE])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n\n        EXTRA_API_INFO = \"gccl-invocation-id/testing-id-123\"\n        result = conn.api_request(\"GET\", \"/\", extra_api_info=EXTRA_API_INFO)\n\n        self.assertEqual(result, {})\n\n        expected_headers = {\n            \"Accept-Encoding\": \"gzip\",\n            \"User-Agent\": conn.user_agent,\n            CLIENT_INFO_HEADER: f\"{conn.user_agent} {EXTRA_API_INFO}\",\n        }\n        session.request.assert_called_once_with(\n            method=\"GET\",\n            url=mock.ANY,\n            headers=expected_headers,\n            data=None,\n            timeout=self._get_default_timeout(),\n        )\n\n    def test_api_request_w_404(self):\n        from google.cloud import exceptions\n\n        session = make_requests_session([make_response(http.client.NOT_FOUND)])\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n\n        with self.assertRaises(exceptions.NotFound):\n            conn.api_request(\"GET\", \"/\")\n\n    def test_api_request_w_500(self):\n        from google.cloud import exceptions\n\n        session = make_requests_session(\n            [make_response(http.client.INTERNAL_SERVER_ERROR)]\n        )\n        client = mock.Mock(_http=session, spec=[\"_http\"])\n        conn = self._make_mock_one(client)\n\n        with self.assertRaises(exceptions.InternalServerError):\n            conn.api_request(\"GET\", \"/\")\n", "tests/unit/test_operation.py": "# Copyright 2016 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport unittest\n\n\nclass Test__compute_type_url(unittest.TestCase):\n    def _call_fut(self, klass, prefix=None):\n        from google.cloud.operation import _compute_type_url\n\n        if prefix is None:\n            return _compute_type_url(klass)\n        return _compute_type_url(klass, prefix)\n\n    def test_wo_prefix(self):\n        from google.protobuf.struct_pb2 import Struct\n        from google.cloud.operation import _GOOGLE_APIS_PREFIX\n\n        type_url = self._call_fut(Struct)\n\n        self.assertEqual(\n            type_url, \"%s/%s\" % (_GOOGLE_APIS_PREFIX, Struct.DESCRIPTOR.full_name)\n        )\n\n    def test_w_prefix(self):\n        from google.protobuf.struct_pb2 import Struct\n\n        PREFIX = \"test.google-cloud-python.com\"\n\n        type_url = self._call_fut(Struct, PREFIX)\n\n        self.assertEqual(type_url, \"%s/%s\" % (PREFIX, Struct.DESCRIPTOR.full_name))\n\n\nclass Test_register_type(unittest.TestCase):\n    def _call_fut(self, klass, type_url=None):\n        from google.cloud.operation import register_type\n\n        register_type(klass, type_url=type_url)\n\n    def test_explicit(self):\n        from google.cloud import operation as MUT\n        from google.cloud._testing import _Monkey\n\n        type_url = \"testing.google-cloud-python.com/testing\"\n        klass = object()\n        type_url_map = {}\n\n        with _Monkey(MUT, _TYPE_URL_MAP=type_url_map):\n            self._call_fut(klass, type_url)\n\n        self.assertEqual(type_url_map, {type_url: klass})\n\n    def test_default(self):\n        from google.protobuf.struct_pb2 import Struct\n        from google.cloud._testing import _Monkey\n        from google.cloud import operation as MUT\n\n        type_url_map = {}\n        with _Monkey(MUT, _TYPE_URL_MAP=type_url_map):\n            self._call_fut(Struct)\n\n        type_url = MUT._compute_type_url(Struct)\n        self.assertEqual(type_url_map, {type_url: Struct})\n\n    def test_w_same_class(self):\n        from google.cloud import operation as MUT\n        from google.cloud._testing import _Monkey\n\n        type_url = \"testing.google-cloud-python.com/testing\"\n        klass = object()\n        type_url_map = {type_url: klass}\n\n        with _Monkey(MUT, _TYPE_URL_MAP=type_url_map):\n            self._call_fut(klass, type_url)\n\n        self.assertEqual(type_url_map, {type_url: klass})\n\n    def test_w_conflict(self):\n        from google.cloud import operation as MUT\n        from google.cloud._testing import _Monkey\n\n        type_url = \"testing.google-cloud-python.com/testing\"\n        klass, other = object(), object()\n        type_url_map = {type_url: other}\n\n        with _Monkey(MUT, _TYPE_URL_MAP=type_url_map):\n            with self.assertRaises(ValueError):\n                self._call_fut(klass, type_url)\n\n        self.assertEqual(type_url_map, {type_url: other})\n\n\nclass TestOperation(unittest.TestCase):\n    OPERATION_NAME = \"operations/projects/foo/instances/bar/operations/123\"\n\n    @staticmethod\n    def _get_target_class():\n        from google.cloud.operation import Operation\n\n        return Operation\n\n    def _make_one(self, *args, **kw):\n        return self._get_target_class()(*args, **kw)\n\n    def test_ctor_defaults(self):\n        client = _Client()\n        operation = self._make_one(self.OPERATION_NAME, client)\n        self.assertEqual(operation.name, self.OPERATION_NAME)\n        self.assertIs(operation.client, client)\n        self.assertIsNone(operation.target)\n        self.assertIsNone(operation.response)\n        self.assertIsNone(operation.error)\n        self.assertIsNone(operation.metadata)\n        self.assertEqual(operation.caller_metadata, {})\n        self.assertTrue(operation._from_grpc)\n\n    def test_ctor_explicit(self):\n        client = _Client()\n        operation = self._make_one(self.OPERATION_NAME, client, foo=\"bar\")\n\n        self.assertEqual(operation.name, self.OPERATION_NAME)\n        self.assertIs(operation.client, client)\n        self.assertIsNone(operation.target)\n        self.assertIsNone(operation.response)\n        self.assertIsNone(operation.error)\n        self.assertIsNone(operation.metadata)\n        self.assertEqual(operation.caller_metadata, {\"foo\": \"bar\"})\n        self.assertTrue(operation._from_grpc)\n\n    def test_from_pb_wo_metadata_or_kw(self):\n        from google.longrunning import operations_pb2\n\n        client = _Client()\n        operation_pb = operations_pb2.Operation(name=self.OPERATION_NAME)\n        klass = self._get_target_class()\n\n        operation = klass.from_pb(operation_pb, client)\n\n        self.assertEqual(operation.name, self.OPERATION_NAME)\n        self.assertIs(operation.client, client)\n        self.assertIsNone(operation.metadata)\n        self.assertEqual(operation.caller_metadata, {})\n\n    def test_from_pb_w_unknown_metadata(self):\n        from google.longrunning import operations_pb2\n        from google.protobuf.any_pb2 import Any\n        from google.protobuf.json_format import ParseDict\n        from google.protobuf.struct_pb2 import Struct\n        from google.cloud._testing import _Monkey\n        from google.cloud import operation as MUT\n\n        type_url = \"type.googleapis.com/%s\" % (Struct.DESCRIPTOR.full_name,)\n        client = _Client()\n        meta = ParseDict({\"foo\": \"Bar\"}, Struct())\n        metadata_pb = Any(type_url=type_url, value=meta.SerializeToString())\n        operation_pb = operations_pb2.Operation(\n            name=self.OPERATION_NAME, metadata=metadata_pb\n        )\n        klass = self._get_target_class()\n\n        with _Monkey(MUT, _TYPE_URL_MAP={type_url: Struct}):\n            operation = klass.from_pb(operation_pb, client)\n\n        self.assertEqual(operation.name, self.OPERATION_NAME)\n        self.assertIs(operation.client, client)\n        self.assertEqual(operation.metadata, meta)\n        self.assertEqual(operation.caller_metadata, {})\n\n    def test_from_pb_w_metadata_and_kwargs(self):\n        from google.longrunning import operations_pb2\n        from google.protobuf.any_pb2 import Any\n        from google.protobuf.struct_pb2 import Struct\n        from google.protobuf.struct_pb2 import Value\n        from google.cloud import operation as MUT\n        from google.cloud._testing import _Monkey\n\n        type_url = \"type.googleapis.com/%s\" % (Struct.DESCRIPTOR.full_name,)\n        type_url_map = {type_url: Struct}\n\n        client = _Client()\n        meta = Struct(fields={\"foo\": Value(string_value=\"Bar\")})\n        metadata_pb = Any(type_url=type_url, value=meta.SerializeToString())\n        operation_pb = operations_pb2.Operation(\n            name=self.OPERATION_NAME, metadata=metadata_pb\n        )\n        klass = self._get_target_class()\n\n        with _Monkey(MUT, _TYPE_URL_MAP=type_url_map):\n            operation = klass.from_pb(operation_pb, client, baz=\"qux\")\n\n        self.assertEqual(operation.name, self.OPERATION_NAME)\n        self.assertIs(operation.client, client)\n        self.assertEqual(operation.metadata, meta)\n        self.assertEqual(operation.caller_metadata, {\"baz\": \"qux\"})\n\n    def test_from_dict(self):\n        from google.protobuf.struct_pb2 import Struct\n        from google.cloud._testing import _Monkey\n        from google.cloud import operation as MUT\n\n        type_url = \"type.googleapis.com/%s\" % (Struct.DESCRIPTOR.full_name,)\n        api_response = {\n            \"name\": self.OPERATION_NAME,\n            \"metadata\": {\"@type\": type_url, \"value\": {\"foo\": \"Bar\"}},\n        }\n\n        client = _Client()\n        klass = self._get_target_class()\n\n        with _Monkey(MUT, _TYPE_URL_MAP={type_url: Struct}):\n            operation = klass.from_dict(api_response, client)\n\n        self.assertEqual(operation.name, self.OPERATION_NAME)\n        self.assertIs(operation.client, client)\n        self.assertIsNone(operation.target)\n        self.assertIsNone(operation.response)\n        self.assertIsNone(operation.error)\n        self.assertIsInstance(operation.metadata, Struct)\n        self.assertEqual(len(operation.metadata.fields), 1)\n        self.assertEqual(operation.metadata.fields[\"foo\"].string_value, \"Bar\")\n        self.assertEqual(operation.caller_metadata, {})\n        self.assertFalse(operation._from_grpc)\n\n    def test_complete_property(self):\n        client = _Client()\n        operation = self._make_one(self.OPERATION_NAME, client)\n        self.assertFalse(operation.complete)\n        operation._complete = True\n        self.assertTrue(operation.complete)\n        with self.assertRaises(AttributeError):\n            operation.complete = False\n\n    def test_poll_already_complete(self):\n        client = _Client()\n        operation = self._make_one(self.OPERATION_NAME, client)\n        operation._complete = True\n\n        with self.assertRaises(ValueError):\n            operation.poll()\n\n    def test_poll_false(self):\n        from google.longrunning import operations_pb2\n\n        response_pb = operations_pb2.Operation(done=False)\n        client = _Client()\n        stub = client._operations_stub\n        stub._get_operation_response = response_pb\n        operation = self._make_one(self.OPERATION_NAME, client)\n\n        self.assertFalse(operation.poll())\n\n        request_pb = stub._get_operation_requested\n        self.assertIsInstance(request_pb, operations_pb2.GetOperationRequest)\n        self.assertEqual(request_pb.name, self.OPERATION_NAME)\n\n    def test_poll_true(self):\n        from google.longrunning import operations_pb2\n\n        response_pb = operations_pb2.Operation(done=True)\n        client = _Client()\n        stub = client._operations_stub\n        stub._get_operation_response = response_pb\n        operation = self._make_one(self.OPERATION_NAME, client)\n\n        self.assertTrue(operation.poll())\n\n        request_pb = stub._get_operation_requested\n        self.assertIsInstance(request_pb, operations_pb2.GetOperationRequest)\n        self.assertEqual(request_pb.name, self.OPERATION_NAME)\n\n    def test_poll_http(self):\n        from google.protobuf.struct_pb2 import Struct\n        from google.cloud._testing import _Monkey\n        from google.cloud import operation as MUT\n\n        type_url = \"type.googleapis.com/%s\" % (Struct.DESCRIPTOR.full_name,)\n        name = \"2302903294023\"\n        api_response = {\n            \"name\": name,\n            \"done\": True,\n            \"metadata\": {\"@type\": type_url, \"value\": {\"foo\": \"Bar\"}},\n        }\n        connection = _Connection(api_response)\n        client = _Client(connection)\n        operation = self._make_one(name, client)\n        operation._from_grpc = False\n\n        with _Monkey(MUT, _TYPE_URL_MAP={type_url: Struct}):\n            self.assertTrue(operation.poll())\n\n        expected_path = \"operations/%s\" % (name,)\n        self.assertEqual(\n            connection._requested, [{\"method\": \"GET\", \"path\": expected_path}]\n        )\n\n    def test__update_state_done(self):\n        from google.longrunning import operations_pb2\n\n        operation = self._make_one(None, None)\n        self.assertFalse(operation.complete)\n        operation_pb = operations_pb2.Operation(done=True)\n        operation._update_state(operation_pb)\n        self.assertTrue(operation.complete)\n\n    def test__update_state_metadata(self):\n        from google.longrunning import operations_pb2\n        from google.protobuf.any_pb2 import Any\n        from google.protobuf.struct_pb2 import Value\n        from google.cloud._testing import _Monkey\n        from google.cloud import operation as MUT\n\n        operation = self._make_one(None, None)\n        self.assertIsNone(operation.metadata)\n\n        val_pb = Value(number_value=1337)\n        type_url = \"type.googleapis.com/%s\" % (Value.DESCRIPTOR.full_name,)\n        val_any = Any(type_url=type_url, value=val_pb.SerializeToString())\n        operation_pb = operations_pb2.Operation(metadata=val_any)\n\n        with _Monkey(MUT, _TYPE_URL_MAP={type_url: Value}):\n            operation._update_state(operation_pb)\n\n        self.assertEqual(operation.metadata, val_pb)\n\n    def test__update_state_error(self):\n        from google.longrunning import operations_pb2\n        from google.rpc.status_pb2 import Status\n\n        operation = self._make_one(None, None)\n        self.assertIsNone(operation.error)\n        self.assertIsNone(operation.response)\n\n        error_pb = Status(code=1)\n        operation_pb = operations_pb2.Operation(error=error_pb)\n        operation._update_state(operation_pb)\n\n        self.assertEqual(operation.error, error_pb)\n        self.assertIsNone(operation.response)\n\n    def test__update_state_response(self):\n        from google.longrunning import operations_pb2\n        from google.protobuf.any_pb2 import Any\n        from google.protobuf.struct_pb2 import Value\n        from google.cloud._testing import _Monkey\n        from google.cloud import operation as MUT\n\n        operation = self._make_one(None, None)\n        self.assertIsNone(operation.error)\n        self.assertIsNone(operation.response)\n\n        response_pb = Value(string_value=\"totes a response\")\n        type_url = \"type.googleapis.com/%s\" % (Value.DESCRIPTOR.full_name,)\n        response_any = Any(type_url=type_url, value=response_pb.SerializeToString())\n        operation_pb = operations_pb2.Operation(response=response_any)\n\n        with _Monkey(MUT, _TYPE_URL_MAP={type_url: Value}):\n            operation._update_state(operation_pb)\n\n        self.assertIsNone(operation.error)\n        self.assertEqual(operation.response, response_pb)\n\n    def test__update_state_no_result(self):\n        from google.longrunning import operations_pb2\n\n        operation = self._make_one(None, None)\n        self.assertIsNone(operation.error)\n        self.assertIsNone(operation.response)\n\n        operation_pb = operations_pb2.Operation()\n        operation._update_state(operation_pb)\n\n        # Make sure nothing changed.\n        self.assertIsNone(operation.error)\n        self.assertIsNone(operation.response)\n\n\nclass _OperationsStub(object):\n    def GetOperation(self, request_pb):\n        self._get_operation_requested = request_pb\n        return self._get_operation_response\n\n\nclass _Connection(object):\n    def __init__(self, *responses):\n        self._responses = responses\n        self._requested = []\n\n    def api_request(self, **kw):\n        self._requested.append(kw)\n        response, self._responses = self._responses[0], self._responses[1:]\n        return response\n\n\nclass _Client(object):\n    def __init__(self, connection=None):\n        self._operations_stub = _OperationsStub()\n        self._connection = connection\n", "tests/unit/test_packaging.py": "# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport subprocess\nimport sys\n\n\ndef test_namespace_package_compat(tmp_path):\n    # The ``google`` namespace package should not be masked\n    # by the presence of ``google-cloud-core``.\n    google = tmp_path / \"google\"\n    google.mkdir()\n    google.joinpath(\"othermod.py\").write_text(\"\")\n    env = dict(os.environ, PYTHONPATH=str(tmp_path))\n    cmd = [sys.executable, \"-m\", \"google.othermod\"]\n    subprocess.check_call(cmd, env=env)\n\n    # The ``google.cloud`` namespace package should not be masked\n    # by the presence of ``google-cloud-core``.\n    google_cloud = tmp_path / \"google\" / \"cloud\"\n    google_cloud.mkdir()\n    google_cloud.joinpath(\"othermod.py\").write_text(\"\")\n    env = dict(os.environ, PYTHONPATH=str(tmp_path))\n    cmd = [sys.executable, \"-m\", \"google.cloud.othermod\"]\n    subprocess.check_call(cmd, env=env)\n", "tests/unit/test_client.py": "# Copyright 2015 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport io\nimport json\nimport unittest\nfrom unittest import mock\n\n\ndef _make_credentials():\n    import google.auth.credentials\n\n    return mock.Mock(spec=google.auth.credentials.CredentialsWithQuotaProject)\n\n\nclass Test_ClientFactoryMixin(unittest.TestCase):\n    @staticmethod\n    def _get_target_class():\n        from google.cloud.client import _ClientFactoryMixin\n\n        return _ClientFactoryMixin\n\n    def test_virtual(self):\n        klass = self._get_target_class()\n        self.assertFalse(\"__init__\" in klass.__dict__)\n\n\nclass TestClient(unittest.TestCase):\n    @staticmethod\n    def _get_target_class():\n        from google.cloud.client import Client\n\n        return Client\n\n    def _make_one(self, *args, **kw):\n        return self._get_target_class()(*args, **kw)\n\n    def test_unpickleable(self):\n        import pickle\n\n        credentials = _make_credentials()\n        HTTP = object()\n\n        client_obj = self._make_one(credentials=credentials, _http=HTTP)\n        with self.assertRaises(pickle.PicklingError):\n            pickle.dumps(client_obj)\n\n    def test_ctor_defaults(self):\n        credentials = _make_credentials()\n\n        patch = mock.patch(\"google.auth.default\", return_value=(credentials, None))\n        with patch as default:\n            client_obj = self._make_one()\n\n        self.assertIs(client_obj._credentials, credentials)\n        self.assertIsNone(client_obj._http_internal)\n        default.assert_called_once_with(scopes=None)\n\n    def test_ctor_explicit(self):\n        credentials = _make_credentials()\n        http = mock.sentinel.http\n        client_obj = self._make_one(credentials=credentials, _http=http)\n\n        self.assertIs(client_obj._credentials, credentials)\n        self.assertIs(client_obj._http_internal, http)\n\n    def test_ctor_client_options_w_conflicting_creds(self):\n        from google.api_core.exceptions import DuplicateCredentialArgs\n\n        credentials = _make_credentials()\n        client_options = {\"credentials_file\": \"/path/to/creds.json\"}\n        with self.assertRaises(DuplicateCredentialArgs):\n            self._make_one(credentials=credentials, client_options=client_options)\n\n    def test_ctor_bad_credentials(self):\n        credentials = mock.sentinel.credentials\n\n        with self.assertRaises(ValueError):\n            self._make_one(credentials=credentials)\n\n    def test_ctor_client_options_w_creds_file_scopes(self):\n        credentials = _make_credentials()\n        credentials_file = \"/path/to/creds.json\"\n        scopes = [\"SCOPE1\", \"SCOPE2\"]\n        client_options = {\"credentials_file\": credentials_file, \"scopes\": scopes}\n\n        patch = mock.patch(\n            \"google.auth.load_credentials_from_file\", return_value=(credentials, None)\n        )\n        with patch as load_credentials_from_file:\n            client_obj = self._make_one(client_options=client_options)\n\n        self.assertIs(client_obj._credentials, credentials)\n        self.assertIsNone(client_obj._http_internal)\n        load_credentials_from_file.assert_called_once_with(\n            credentials_file, scopes=scopes\n        )\n\n    def test_ctor_client_options_w_quota_project(self):\n        credentials = _make_credentials()\n        quota_project_id = \"quota-project-123\"\n        client_options = {\"quota_project_id\": quota_project_id}\n\n        client_obj = self._make_one(\n            credentials=credentials, client_options=client_options\n        )\n\n        self.assertIs(\n            client_obj._credentials, credentials.with_quota_project.return_value\n        )\n        credentials.with_quota_project.assert_called_once_with(quota_project_id)\n\n    def test_ctor__http_property_existing(self):\n        credentials = _make_credentials()\n        http = object()\n        client = self._make_one(credentials=credentials, _http=http)\n        self.assertIs(client._http_internal, http)\n        self.assertIs(client._http, http)\n\n    def test_ctor__http_property_new(self):\n        from google.cloud.client import _CREDENTIALS_REFRESH_TIMEOUT\n\n        credentials = _make_credentials()\n        mock_client_cert_source = mock.Mock()\n        client_options = {\"client_cert_source\": mock_client_cert_source}\n        client = self._make_one(credentials=credentials, client_options=client_options)\n        self.assertIsNone(client._http_internal)\n\n        with mock.patch(\n            \"google.auth.transport.requests.AuthorizedSession\"\n        ) as AuthorizedSession:\n            session = mock.Mock()\n            session.configure_mtls_channel = mock.Mock()\n            AuthorizedSession.return_value = session\n            self.assertIs(client._http, session)\n            # Check the mock.\n            AuthorizedSession.assert_called_once_with(\n                credentials, refresh_timeout=_CREDENTIALS_REFRESH_TIMEOUT\n            )\n            session.configure_mtls_channel.assert_called_once_with(\n                mock_client_cert_source\n            )\n            # Make sure the cached value is used on subsequent access.\n            self.assertIs(client._http_internal, session)\n            self.assertIs(client._http, session)\n            self.assertEqual(AuthorizedSession.call_count, 1)\n\n    def test_from_service_account_info(self):\n        klass = self._get_target_class()\n\n        info = {\"dummy\": \"value\", \"valid\": \"json\"}\n        constructor_patch = mock.patch(\n            \"google.oauth2.service_account.Credentials.from_service_account_info\",\n            return_value=_make_credentials(),\n        )\n\n        with constructor_patch as constructor:\n            client_obj = klass.from_service_account_info(info)\n\n        self.assertIs(client_obj._credentials, constructor.return_value)\n        self.assertIsNone(client_obj._http_internal)\n        constructor.assert_called_once_with(info)\n\n    def test_from_service_account_info_w_explicit_credentials(self):\n        KLASS = self._get_target_class()\n\n        info = {\"dummy\": \"value\", \"valid\": \"json\"}\n\n        with self.assertRaises(TypeError):\n            KLASS.from_service_account_info(info, credentials=mock.sentinel.credentials)\n\n    def test_from_service_account_json(self):\n        from google.cloud import _helpers\n\n        klass = self._get_target_class()\n\n        info = {\"dummy\": \"value\", \"valid\": \"json\"}\n        json_file = io.StringIO(_helpers._bytes_to_unicode(json.dumps(info)))\n\n        file_open_patch = mock.patch(\"io.open\", return_value=json_file)\n        constructor_patch = mock.patch(\n            \"google.oauth2.service_account.Credentials.\" \"from_service_account_info\",\n            return_value=_make_credentials(),\n        )\n\n        with file_open_patch as file_open:\n            with constructor_patch as constructor:\n                client_obj = klass.from_service_account_json(mock.sentinel.filename)\n\n        self.assertIs(client_obj._credentials, constructor.return_value)\n        self.assertIsNone(client_obj._http_internal)\n        # Check that mocks were called as expected.\n        file_open.assert_called_once_with(mock.sentinel.filename, \"r\", encoding=\"utf-8\")\n        constructor.assert_called_once_with(info)\n\n    def test_close_w__http_internal_none(self):\n        credentials = _make_credentials()\n        client_obj = self._make_one(credentials=credentials, _http=None)\n\n        client_obj.close()  # noraise\n\n    def test_close_w__http_internal_set(self):\n        credentials = _make_credentials()\n        http = mock.Mock(spec=[\"close\"])\n        client_obj = self._make_one(credentials=credentials, _http=http)\n\n        client_obj.close()\n\n        http.close.assert_called_once_with()\n\n\nclass Test_ClientProjectMixin(unittest.TestCase):\n    @staticmethod\n    def _get_target_class():\n        from google.cloud.client import _ClientProjectMixin\n\n        return _ClientProjectMixin\n\n    def _make_one(self, *args, **kw):\n        return self._get_target_class()(*args, **kw)\n\n    def test_ctor_defaults_wo_envvar(self):\n        environ = {}\n        patch_env = mock.patch(\"os.environ\", new=environ)\n        patch_default = mock.patch(\n            \"google.cloud.client._determine_default_project\",\n            return_value=None,\n        )\n        with patch_env:\n            with patch_default as patched:\n                with self.assertRaises(EnvironmentError):\n                    self._make_one()\n\n        patched.assert_called_once_with(None)\n\n    def test_ctor_defaults_w_envvar(self):\n        from google.auth.environment_vars import PROJECT\n\n        project = \"some-project-123\"\n        environ = {PROJECT: project}\n        patch_env = mock.patch(\"os.environ\", new=environ)\n        with patch_env:\n            client = self._make_one()\n\n        self.assertEqual(client.project, project)\n\n    def test_ctor_defaults_w_legacy_envvar(self):\n        from google.auth.environment_vars import LEGACY_PROJECT\n\n        project = \"some-project-123\"\n        environ = {LEGACY_PROJECT: project}\n        patch_env = mock.patch(\"os.environ\", new=environ)\n        with patch_env:\n            client = self._make_one()\n\n        self.assertEqual(client.project, project)\n\n    def test_ctor_w_explicit_project(self):\n        explicit_project = \"explicit-project-456\"\n        patch_default = mock.patch(\n            \"google.cloud.client._determine_default_project\",\n            return_value=None,\n        )\n        with patch_default as patched:\n            client = self._make_one(project=explicit_project)\n\n        self.assertEqual(client.project, explicit_project)\n\n        patched.assert_not_called()\n\n    def test_ctor_w_explicit_project_bytes(self):\n        explicit_project = b\"explicit-project-456\"\n        patch_default = mock.patch(\n            \"google.cloud.client._determine_default_project\",\n            return_value=None,\n        )\n        with patch_default as patched:\n            client = self._make_one(project=explicit_project)\n\n        self.assertEqual(client.project, explicit_project.decode(\"utf-8\"))\n\n        patched.assert_not_called()\n\n    def test_ctor_w_explicit_project_invalid(self):\n        explicit_project = object()\n        patch_default = mock.patch(\n            \"google.cloud.client._determine_default_project\",\n            return_value=None,\n        )\n        with patch_default as patched:\n            with self.assertRaises(ValueError):\n                self._make_one(project=explicit_project)\n\n        patched.assert_not_called()\n\n    @staticmethod\n    def _make_credentials(**kw):\n        from google.auth.credentials import Credentials\n\n        class _Credentials(Credentials):\n            def __init__(self, **kw):\n                self.__dict__.update(kw)\n\n            def refresh(self):  # pragma: NO COVER\n                pass\n\n        return _Credentials(**kw)\n\n    def test_ctor_w_explicit_credentials_wo_project(self):\n        default_project = \"default-project-123\"\n        credentials = self._make_credentials()\n        patch_default = mock.patch(\n            \"google.cloud.client._determine_default_project\",\n            return_value=default_project,\n        )\n        with patch_default as patched:\n            client = self._make_one(credentials=credentials)\n\n        self.assertEqual(client.project, default_project)\n\n        patched.assert_called_once_with(None)\n\n    def test_ctor_w_explicit_credentials_w_project(self):\n        project = \"credentials-project-456\"\n        credentials = self._make_credentials(project_id=project)\n        patch_default = mock.patch(\n            \"google.cloud.client._determine_default_project\",\n            return_value=None,\n        )\n        with patch_default as patched:\n            client = self._make_one(credentials=credentials)\n\n        self.assertEqual(client.project, project)\n\n        patched.assert_not_called()\n\n\nclass TestClientWithProject(unittest.TestCase):\n    @staticmethod\n    def _get_target_class():\n        from google.cloud.client import ClientWithProject\n\n        return ClientWithProject\n\n    def _make_one(self, *args, **kw):\n        return self._get_target_class()(*args, **kw)\n\n    def test_constructor_defaults(self):\n        credentials = _make_credentials()\n        patch1 = mock.patch(\"google.auth.default\", return_value=(credentials, None))\n\n        project = \"prahj-ekt\"\n        patch2 = mock.patch(\n            \"google.cloud.client._determine_default_project\", return_value=project\n        )\n\n        with patch1 as default:\n            with patch2 as _determine_default_project:\n                client_obj = self._make_one()\n\n        self.assertEqual(client_obj.project, project)\n        self.assertIs(client_obj._credentials, credentials)\n        self.assertIsNone(client_obj._http_internal)\n        default.assert_called_once_with(scopes=None)\n        _determine_default_project.assert_called_once_with(None)\n\n    def test_constructor_missing_project(self):\n        from google.cloud._testing import _Monkey\n        from google.cloud import client\n\n        FUNC_CALLS = []\n\n        def mock_determine_proj(project):\n            FUNC_CALLS.append((project, \"_determine_default_project\"))\n            return None\n\n        with _Monkey(client, _determine_default_project=mock_determine_proj):\n            self.assertRaises(EnvironmentError, self._make_one)\n\n        self.assertEqual(FUNC_CALLS, [(None, \"_determine_default_project\")])\n\n    def test_constructor_w_invalid_project(self):\n        CREDENTIALS = _make_credentials()\n        HTTP = object()\n        with self.assertRaises(ValueError):\n            self._make_one(project=object(), credentials=CREDENTIALS, _http=HTTP)\n\n    def _explicit_ctor_helper(self, project):\n        CREDENTIALS = _make_credentials()\n        HTTP = object()\n\n        client_obj = self._make_one(\n            project=project, credentials=CREDENTIALS, _http=HTTP\n        )\n\n        if isinstance(project, bytes):\n            self.assertEqual(client_obj.project, project.decode(\"utf-8\"))\n        else:\n            self.assertEqual(client_obj.project, project)\n        self.assertIs(client_obj._credentials, CREDENTIALS)\n        self.assertIs(client_obj._http_internal, HTTP)\n\n    def test_constructor_explicit_bytes(self):\n        PROJECT = b\"PROJECT\"\n        self._explicit_ctor_helper(PROJECT)\n\n    def test_constructor_explicit_text(self):\n        PROJECT = \"PROJECT\"\n        self._explicit_ctor_helper(PROJECT)\n\n    def _from_service_account_info_helper(self, project=None):\n        klass = self._get_target_class()\n\n        default_project = \"eye-d-of-project\"\n        info = {\"dummy\": \"value\", \"valid\": \"json\", \"project_id\": default_project}\n        kwargs = {}\n\n        if project is None:\n            expected_project = default_project\n        else:\n            expected_project = project\n            kwargs[\"project\"] = project\n\n        constructor_patch = mock.patch(\n            \"google.oauth2.service_account.Credentials.from_service_account_info\",\n            return_value=_make_credentials(),\n        )\n\n        with constructor_patch as constructor:\n            client_obj = klass.from_service_account_info(info, **kwargs)\n\n        self.assertIs(client_obj._credentials, constructor.return_value)\n        self.assertIsNone(client_obj._http_internal)\n        self.assertEqual(client_obj.project, expected_project)\n\n        constructor.assert_called_once_with(info)\n\n    def test_from_service_account_info(self):\n        self._from_service_account_info_helper()\n\n    def test_from_service_account_info_with_project(self):\n        self._from_service_account_info_helper(project=\"prah-jekt\")\n\n    def test_from_service_account_info_with_posarg(self):\n        class Derived(self._get_target_class()):\n            def __init__(self, required, **kwargs):\n                super(Derived, self).__init__(**kwargs)\n                self.required = required\n\n        project = \"eye-d-of-project\"\n        info = {\"dummy\": \"value\", \"valid\": \"json\", \"project_id\": project}\n\n        # Mock both the file opening and the credentials constructor.\n        constructor_patch = mock.patch(\n            \"google.oauth2.service_account.Credentials.from_service_account_info\",\n            return_value=_make_credentials(),\n        )\n\n        with constructor_patch as constructor:\n            client_obj = Derived.from_service_account_info(info, \"REQUIRED\")\n\n        self.assertIsInstance(client_obj, Derived)\n        self.assertIs(client_obj._credentials, constructor.return_value)\n        self.assertIsNone(client_obj._http_internal)\n        self.assertEqual(client_obj.project, project)\n        self.assertEqual(client_obj.required, \"REQUIRED\")\n\n        # Check that mocks were called as expected.\n        constructor.assert_called_once_with(info)\n\n    def _from_service_account_json_helper(self, project=None):\n        from google.cloud import _helpers\n\n        klass = self._get_target_class()\n\n        default_project = \"eye-d-of-project\"\n        info = {\"dummy\": \"value\", \"valid\": \"json\", \"project_id\": default_project}\n        if project is None:\n            expected_project = \"eye-d-of-project\"\n        else:\n            expected_project = project\n\n        # Mock both the file opening and the credentials constructor.\n        json_fi = io.StringIO(_helpers._bytes_to_unicode(json.dumps(info)))\n        file_open_patch = mock.patch(\"io.open\", return_value=json_fi)\n        constructor_patch = mock.patch(\n            \"google.oauth2.service_account.Credentials.\" \"from_service_account_info\",\n            return_value=_make_credentials(),\n        )\n\n        with file_open_patch as file_open:\n            with constructor_patch as constructor:\n                kwargs = {}\n                if project is not None:\n                    kwargs[\"project\"] = project\n                client_obj = klass.from_service_account_json(\n                    mock.sentinel.filename, **kwargs\n                )\n\n        self.assertIs(client_obj._credentials, constructor.return_value)\n        self.assertIsNone(client_obj._http_internal)\n        self.assertEqual(client_obj.project, expected_project)\n        # Check that mocks were called as expected.\n        file_open.assert_called_once_with(mock.sentinel.filename, \"r\", encoding=\"utf-8\")\n        constructor.assert_called_once_with(info)\n\n    def test_from_service_account_json(self):\n        self._from_service_account_json_helper()\n\n    def test_from_service_account_json_project_set(self):\n        self._from_service_account_json_helper(project=\"prah-jekt\")\n\n    def test_from_service_account_json_with_posarg(self):\n        from google.cloud import _helpers\n\n        class Derived(self._get_target_class()):\n            def __init__(self, required, **kwargs):\n                super(Derived, self).__init__(**kwargs)\n                self.required = required\n\n        project = \"eye-d-of-project\"\n        info = {\"dummy\": \"value\", \"valid\": \"json\", \"project_id\": project}\n\n        # Mock both the file opening and the credentials constructor.\n        json_fi = io.StringIO(_helpers._bytes_to_unicode(json.dumps(info)))\n        file_open_patch = mock.patch(\"io.open\", return_value=json_fi)\n        constructor_patch = mock.patch(\n            \"google.oauth2.service_account.Credentials.from_service_account_info\",\n            return_value=_make_credentials(),\n        )\n\n        with file_open_patch as file_open:\n            with constructor_patch as constructor:\n                client_obj = Derived.from_service_account_json(\n                    mock.sentinel.filename, \"REQUIRED\"\n                )\n\n        self.assertIsInstance(client_obj, Derived)\n        self.assertIs(client_obj._credentials, constructor.return_value)\n        self.assertIsNone(client_obj._http_internal)\n        self.assertEqual(client_obj.project, project)\n        self.assertEqual(client_obj.required, \"REQUIRED\")\n\n        # Check that mocks were called as expected.\n        file_open.assert_called_once_with(mock.sentinel.filename, \"r\", encoding=\"utf-8\")\n        constructor.assert_called_once_with(info)\n", "tests/unit/test__helpers.py": "# Copyright 2014 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport unittest\nfrom unittest import mock\n\n\nclass Test__LocalStack(unittest.TestCase):\n    @staticmethod\n    def _get_target_class():\n        from google.cloud._helpers import _LocalStack\n\n        return _LocalStack\n\n    def _make_one(self):\n        return self._get_target_class()()\n\n    def test_it(self):\n        batch1, batch2 = object(), object()\n        batches = self._make_one()\n        self.assertEqual(list(batches), [])\n        self.assertIsNone(batches.top)\n        batches.push(batch1)\n        self.assertIs(batches.top, batch1)\n        batches.push(batch2)\n        self.assertIs(batches.top, batch2)\n        popped = batches.pop()\n        self.assertIs(popped, batch2)\n        self.assertIs(batches.top, batch1)\n        self.assertEqual(list(batches), [batch1])\n        popped = batches.pop()\n        self.assertIsNone(batches.top)\n        self.assertEqual(list(batches), [])\n\n\nclass Test__ensure_tuple_or_list(unittest.TestCase):\n    def _call_fut(self, arg_name, tuple_or_list):\n        from google.cloud._helpers import _ensure_tuple_or_list\n\n        return _ensure_tuple_or_list(arg_name, tuple_or_list)\n\n    def test_valid_tuple(self):\n        valid_tuple_or_list = (\"a\", \"b\", \"c\", \"d\")\n        result = self._call_fut(\"ARGNAME\", valid_tuple_or_list)\n        self.assertEqual(result, [\"a\", \"b\", \"c\", \"d\"])\n\n    def test_valid_list(self):\n        valid_tuple_or_list = [\"a\", \"b\", \"c\", \"d\"]\n        result = self._call_fut(\"ARGNAME\", valid_tuple_or_list)\n        self.assertEqual(result, valid_tuple_or_list)\n\n    def test_invalid(self):\n        invalid_tuple_or_list = object()\n        with self.assertRaises(TypeError):\n            self._call_fut(\"ARGNAME\", invalid_tuple_or_list)\n\n    def test_invalid_iterable(self):\n        invalid_tuple_or_list = \"FOO\"\n        with self.assertRaises(TypeError):\n            self._call_fut(\"ARGNAME\", invalid_tuple_or_list)\n\n\nclass Test__determine_default_project(unittest.TestCase):\n    def _call_fut(self, project=None):\n        from google.cloud._helpers import _determine_default_project\n\n        return _determine_default_project(project=project)\n\n    def test_it(self):\n        with mock.patch(\"google.auth.default\", autospec=True) as default:\n            default.return_value = (mock.sentinel.credentials, mock.sentinel.project)\n            project = self._call_fut()\n\n        self.assertEqual(project, mock.sentinel.project)\n        default.assert_called_once_with()\n\n    def test_explicit(self):\n        with mock.patch(\"google.auth.default\", autospec=True) as default:\n            project = self._call_fut(mock.sentinel.project)\n\n        self.assertEqual(project, mock.sentinel.project)\n        self.assertFalse(default.called)\n\n\nclass Test__millis(unittest.TestCase):\n    def _call_fut(self, value):\n        from google.cloud._helpers import _millis\n\n        return _millis(value)\n\n    def test_one_second_from_epoch(self):\n        import datetime\n        from google.cloud._helpers import UTC\n\n        WHEN = datetime.datetime(1970, 1, 1, 0, 0, 1, tzinfo=UTC)\n        self.assertEqual(self._call_fut(WHEN), 1000)\n\n\nclass Test__microseconds_from_datetime(unittest.TestCase):\n    def _call_fut(self, value):\n        from google.cloud._helpers import _microseconds_from_datetime\n\n        return _microseconds_from_datetime(value)\n\n    def test_it(self):\n        import datetime\n\n        microseconds = 314159\n        timestamp = datetime.datetime(\n            1970, 1, 1, hour=0, minute=0, second=0, microsecond=microseconds\n        )\n        result = self._call_fut(timestamp)\n        self.assertEqual(result, microseconds)\n\n\nclass Test__millis_from_datetime(unittest.TestCase):\n    def _call_fut(self, value):\n        from google.cloud._helpers import _millis_from_datetime\n\n        return _millis_from_datetime(value)\n\n    def test_w_none(self):\n        self.assertIsNone(self._call_fut(None))\n\n    def test_w_utc_datetime(self):\n        import datetime\n        from google.cloud._helpers import UTC\n        from google.cloud._helpers import _microseconds_from_datetime\n\n        NOW = datetime.datetime.now().replace(tzinfo=UTC)\n        NOW_MICROS = _microseconds_from_datetime(NOW)\n        MILLIS = NOW_MICROS // 1000\n        result = self._call_fut(NOW)\n        self.assertIsInstance(result, int)\n        self.assertEqual(result, MILLIS)\n\n    def test_w_non_utc_datetime(self):\n        import datetime\n        from google.cloud._helpers import _microseconds_from_datetime\n\n        offset = datetime.timedelta(hours=-1)\n        zone = datetime.timezone(offset=offset, name=\"CET\")\n        NOW = datetime.datetime(2015, 7, 28, 16, 34, 47, tzinfo=zone)\n        NOW_MICROS = _microseconds_from_datetime(NOW)\n        MILLIS = NOW_MICROS // 1000\n        result = self._call_fut(NOW)\n        self.assertIsInstance(result, int)\n        self.assertEqual(result, MILLIS)\n\n    def test_w_naive_datetime(self):\n        import datetime\n        from google.cloud._helpers import UTC\n        from google.cloud._helpers import _microseconds_from_datetime\n\n        NOW = datetime.datetime.now(datetime.timezone.utc).replace(tzinfo=None)\n        UTC_NOW = NOW.replace(tzinfo=UTC)\n        UTC_NOW_MICROS = _microseconds_from_datetime(UTC_NOW)\n        MILLIS = UTC_NOW_MICROS // 1000\n        result = self._call_fut(NOW)\n        self.assertIsInstance(result, int)\n        self.assertEqual(result, MILLIS)\n\n\nclass Test__datetime_from_microseconds(unittest.TestCase):\n    def _call_fut(self, value):\n        from google.cloud._helpers import _datetime_from_microseconds\n\n        return _datetime_from_microseconds(value)\n\n    def test_it(self):\n        import datetime\n        from google.cloud._helpers import UTC\n        from google.cloud._helpers import _microseconds_from_datetime\n\n        NOW = datetime.datetime(2015, 7, 29, 17, 45, 21, 123456, tzinfo=UTC)\n        NOW_MICROS = _microseconds_from_datetime(NOW)\n        self.assertEqual(self._call_fut(NOW_MICROS), NOW)\n\n\nclass Test___date_from_iso8601_date(unittest.TestCase):\n    def _call_fut(self, value):\n        from google.cloud._helpers import _date_from_iso8601_date\n\n        return _date_from_iso8601_date(value)\n\n    def test_todays_date(self):\n        import datetime\n\n        TODAY = datetime.date.today()\n        self.assertEqual(self._call_fut(TODAY.strftime(\"%Y-%m-%d\")), TODAY)\n\n\nclass Test___time_from_iso8601_time_naive(unittest.TestCase):\n    def _call_fut(self, value):\n        from google.cloud._helpers import _time_from_iso8601_time_naive\n\n        return _time_from_iso8601_time_naive(value)\n\n    def test_todays_date(self):\n        import datetime\n\n        WHEN = datetime.time(12, 9, 42)\n        self.assertEqual(self._call_fut((\"12:09:42\")), WHEN)\n\n    def test_w_microseconds(self):\n        import datetime\n\n        WHEN = datetime.time(12, 9, 42, 123456)\n        self.assertEqual(self._call_fut((\"12:09:42.123456\")), WHEN)\n\n    def test_w_millis_fail(self):\n        with self.assertRaises(ValueError):\n            self._call_fut(\"12:09:42.123\")\n\n\nclass Test__rfc3339_to_datetime(unittest.TestCase):\n    def _call_fut(self, dt_str):\n        from google.cloud._helpers import _rfc3339_to_datetime\n\n        return _rfc3339_to_datetime(dt_str)\n\n    def test_w_bogus_zone(self):\n        year = 2009\n        month = 12\n        day = 17\n        hour = 12\n        minute = 44\n        seconds = 32\n        micros = 123456789\n\n        dt_str = \"%d-%02d-%02dT%02d:%02d:%02d.%06dBOGUS\" % (\n            year,\n            month,\n            day,\n            hour,\n            minute,\n            seconds,\n            micros,\n        )\n        with self.assertRaises(ValueError):\n            self._call_fut(dt_str)\n\n    def test_w_microseconds(self):\n        import datetime\n        from google.cloud._helpers import UTC\n\n        year = 2009\n        month = 12\n        day = 17\n        hour = 12\n        minute = 44\n        seconds = 32\n        micros = 123456\n\n        dt_str = \"%d-%02d-%02dT%02d:%02d:%02d.%06dZ\" % (\n            year,\n            month,\n            day,\n            hour,\n            minute,\n            seconds,\n            micros,\n        )\n        result = self._call_fut(dt_str)\n        expected_result = datetime.datetime(\n            year, month, day, hour, minute, seconds, micros, UTC\n        )\n        self.assertEqual(result, expected_result)\n\n    def test_w_naonseconds(self):\n        year = 2009\n        month = 12\n        day = 17\n        hour = 12\n        minute = 44\n        seconds = 32\n        nanos = 123456789\n\n        dt_str = \"%d-%02d-%02dT%02d:%02d:%02d.%09dZ\" % (\n            year,\n            month,\n            day,\n            hour,\n            minute,\n            seconds,\n            nanos,\n        )\n        with self.assertRaises(ValueError):\n            self._call_fut(dt_str)\n\n\nclass Test__rfc3339_nanos_to_datetime(unittest.TestCase):\n    def _call_fut(self, dt_str):\n        from google.cloud._helpers import _rfc3339_nanos_to_datetime\n\n        return _rfc3339_nanos_to_datetime(dt_str)\n\n    def test_w_bogus_zone(self):\n        year = 2009\n        month = 12\n        day = 17\n        hour = 12\n        minute = 44\n        seconds = 32\n        micros = 123456789\n\n        dt_str = \"%d-%02d-%02dT%02d:%02d:%02d.%06dBOGUS\" % (\n            year,\n            month,\n            day,\n            hour,\n            minute,\n            seconds,\n            micros,\n        )\n        with self.assertRaises(ValueError):\n            self._call_fut(dt_str)\n\n    def test_w_truncated_nanos(self):\n        import datetime\n        from google.cloud._helpers import UTC\n\n        year = 2009\n        month = 12\n        day = 17\n        hour = 12\n        minute = 44\n        seconds = 32\n        truncateds_and_micros = [\n            (\"12345678\", 123456),\n            (\"1234567\", 123456),\n            (\"123456\", 123456),\n            (\"12345\", 123450),\n            (\"1234\", 123400),\n            (\"123\", 123000),\n            (\"12\", 120000),\n            (\"1\", 100000),\n        ]\n\n        for truncated, micros in truncateds_and_micros:\n            dt_str = \"%d-%02d-%02dT%02d:%02d:%02d.%sZ\" % (\n                year,\n                month,\n                day,\n                hour,\n                minute,\n                seconds,\n                truncated,\n            )\n            result = self._call_fut(dt_str)\n            expected_result = datetime.datetime(\n                year, month, day, hour, minute, seconds, micros, UTC\n            )\n            self.assertEqual(result, expected_result)\n\n    def test_without_nanos(self):\n        import datetime\n        from google.cloud._helpers import UTC\n\n        year = 1988\n        month = 4\n        day = 29\n        hour = 12\n        minute = 12\n        seconds = 12\n\n        dt_str = \"%d-%02d-%02dT%02d:%02d:%02dZ\" % (\n            year,\n            month,\n            day,\n            hour,\n            minute,\n            seconds,\n        )\n        result = self._call_fut(dt_str)\n        expected_result = datetime.datetime(\n            year, month, day, hour, minute, seconds, 0, UTC\n        )\n        self.assertEqual(result, expected_result)\n\n    def test_w_naonseconds(self):\n        import datetime\n        from google.cloud._helpers import UTC\n\n        year = 2009\n        month = 12\n        day = 17\n        hour = 12\n        minute = 44\n        seconds = 32\n        nanos = 123456789\n        micros = nanos // 1000\n\n        dt_str = \"%d-%02d-%02dT%02d:%02d:%02d.%09dZ\" % (\n            year,\n            month,\n            day,\n            hour,\n            minute,\n            seconds,\n            nanos,\n        )\n        result = self._call_fut(dt_str)\n        expected_result = datetime.datetime(\n            year, month, day, hour, minute, seconds, micros, UTC\n        )\n        self.assertEqual(result, expected_result)\n\n\nclass Test__datetime_to_rfc3339(unittest.TestCase):\n    def _call_fut(self, *args, **kwargs):\n        from google.cloud._helpers import _datetime_to_rfc3339\n\n        return _datetime_to_rfc3339(*args, **kwargs)\n\n    @staticmethod\n    def _make_timezone(offset):\n        import datetime\n\n        return datetime.timezone(offset=offset, name=\"CET\")\n\n    def test_w_utc_datetime(self):\n        import datetime\n        from google.cloud._helpers import UTC\n\n        TIMESTAMP = datetime.datetime(2016, 4, 5, 13, 30, 0, tzinfo=UTC)\n        result = self._call_fut(TIMESTAMP, ignore_zone=False)\n        self.assertEqual(result, \"2016-04-05T13:30:00.000000Z\")\n\n    def test_w_non_utc_datetime(self):\n        import datetime\n\n        zone = self._make_timezone(offset=datetime.timedelta(hours=-1))\n        TIMESTAMP = datetime.datetime(2016, 4, 5, 13, 30, 0, tzinfo=zone)\n        result = self._call_fut(TIMESTAMP, ignore_zone=False)\n        self.assertEqual(result, \"2016-04-05T14:30:00.000000Z\")\n\n    def test_w_non_utc_datetime_and_ignore_zone(self):\n        import datetime\n\n        zone = self._make_timezone(offset=datetime.timedelta(hours=-1))\n        TIMESTAMP = datetime.datetime(2016, 4, 5, 13, 30, 0, tzinfo=zone)\n        result = self._call_fut(TIMESTAMP)\n        self.assertEqual(result, \"2016-04-05T13:30:00.000000Z\")\n\n    def test_w_naive_datetime(self):\n        import datetime\n\n        TIMESTAMP = datetime.datetime(2016, 4, 5, 13, 30, 0)\n        result = self._call_fut(TIMESTAMP)\n        self.assertEqual(result, \"2016-04-05T13:30:00.000000Z\")\n\n\nclass Test__to_bytes(unittest.TestCase):\n    def _call_fut(self, *args, **kwargs):\n        from google.cloud._helpers import _to_bytes\n\n        return _to_bytes(*args, **kwargs)\n\n    def test_with_bytes(self):\n        value = b\"bytes-val\"\n        self.assertEqual(self._call_fut(value), value)\n\n    def test_with_unicode(self):\n        value = \"string-val\"\n        encoded_value = b\"string-val\"\n        self.assertEqual(self._call_fut(value), encoded_value)\n\n    def test_unicode_non_ascii(self):\n        value = \"\\u2013\"  # Long hyphen\n        encoded_value = b\"\\xe2\\x80\\x93\"\n        self.assertRaises(UnicodeEncodeError, self._call_fut, value)\n        self.assertEqual(self._call_fut(value, encoding=\"utf-8\"), encoded_value)\n\n    def test_with_nonstring_type(self):\n        value = object()\n        self.assertRaises(TypeError, self._call_fut, value)\n\n\nclass Test__bytes_to_unicode(unittest.TestCase):\n    def _call_fut(self, *args, **kwargs):\n        from google.cloud._helpers import _bytes_to_unicode\n\n        return _bytes_to_unicode(*args, **kwargs)\n\n    def test_with_bytes(self):\n        value = b\"bytes-val\"\n        encoded_value = \"bytes-val\"\n        self.assertEqual(self._call_fut(value), encoded_value)\n\n    def test_with_unicode(self):\n        value = \"string-val\"\n        encoded_value = \"string-val\"\n        self.assertEqual(self._call_fut(value), encoded_value)\n\n    def test_with_nonstring_type(self):\n        value = object()\n        self.assertRaises(ValueError, self._call_fut, value)\n\n\nclass Test__pb_timestamp_to_datetime(unittest.TestCase):\n    def _call_fut(self, timestamp):\n        from google.cloud._helpers import _pb_timestamp_to_datetime\n\n        return _pb_timestamp_to_datetime(timestamp)\n\n    def test_it(self):\n        import datetime\n        from google.protobuf.timestamp_pb2 import Timestamp\n        from google.cloud._helpers import UTC\n\n        # Epoch is midnight on January 1, 1970 ...\n        dt_stamp = datetime.datetime(\n            1970,\n            month=1,\n            day=1,\n            hour=0,\n            minute=1,\n            second=1,\n            microsecond=1234,\n            tzinfo=UTC,\n        )\n        # ... so 1 minute and 1 second after is 61 seconds and 1234\n        # microseconds is 1234000 nanoseconds.\n        timestamp = Timestamp(seconds=61, nanos=1234000)\n        self.assertEqual(self._call_fut(timestamp), dt_stamp)\n\n\nclass Test__from_any_pb(unittest.TestCase):\n    def _call_fut(self, pb_type, any_pb):\n        from google.cloud._helpers import _from_any_pb\n\n        return _from_any_pb(pb_type, any_pb)\n\n    def test_success(self):\n        from google.protobuf import any_pb2\n        from google.type import date_pb2\n\n        in_message = date_pb2.Date(year=1990)\n        in_message_any = any_pb2.Any()\n        in_message_any.Pack(in_message)\n        out_message = self._call_fut(date_pb2.Date, in_message_any)\n        self.assertEqual(in_message, out_message)\n\n    def test_failure(\n        self,\n    ):\n        from google.protobuf import any_pb2\n        from google.type import date_pb2\n        from google.type import timeofday_pb2\n\n        in_message = any_pb2.Any()\n        in_message.Pack(date_pb2.Date(year=1990))\n\n        with self.assertRaises(TypeError):\n            self._call_fut(timeofday_pb2.TimeOfDay, in_message)\n\n\nclass Test__pb_timestamp_to_rfc3339(unittest.TestCase):\n    def _call_fut(self, timestamp):\n        from google.cloud._helpers import _pb_timestamp_to_rfc3339\n\n        return _pb_timestamp_to_rfc3339(timestamp)\n\n    def test_it(self):\n        from google.protobuf.timestamp_pb2 import Timestamp\n\n        # Epoch is midnight on January 1, 1970 ...\n        # ... so 1 minute and 1 second after is 61 seconds and 1234\n        # microseconds is 1234000 nanoseconds.\n        timestamp = Timestamp(seconds=61, nanos=1234000)\n        self.assertEqual(self._call_fut(timestamp), \"1970-01-01T00:01:01.001234Z\")\n\n\nclass Test__datetime_to_pb_timestamp(unittest.TestCase):\n    def _call_fut(self, when):\n        from google.cloud._helpers import _datetime_to_pb_timestamp\n\n        return _datetime_to_pb_timestamp(when)\n\n    def test_it(self):\n        import datetime\n        from google.protobuf.timestamp_pb2 import Timestamp\n        from google.cloud._helpers import UTC\n\n        # Epoch is midnight on January 1, 1970 ...\n        dt_stamp = datetime.datetime(\n            1970,\n            month=1,\n            day=1,\n            hour=0,\n            minute=1,\n            second=1,\n            microsecond=1234,\n            tzinfo=UTC,\n        )\n        # ... so 1 minute and 1 second after is 61 seconds and 1234\n        # microseconds is 1234000 nanoseconds.\n        timestamp = Timestamp(seconds=61, nanos=1234000)\n        self.assertEqual(self._call_fut(dt_stamp), timestamp)\n\n\nclass Test__timedelta_to_duration_pb(unittest.TestCase):\n    def _call_fut(self, *args, **kwargs):\n        from google.cloud._helpers import _timedelta_to_duration_pb\n\n        return _timedelta_to_duration_pb(*args, **kwargs)\n\n    def test_it(self):\n        import datetime\n        from google.protobuf import duration_pb2\n\n        seconds = microseconds = 1\n        timedelta_val = datetime.timedelta(seconds=seconds, microseconds=microseconds)\n        result = self._call_fut(timedelta_val)\n        self.assertIsInstance(result, duration_pb2.Duration)\n        self.assertEqual(result.seconds, seconds)\n        self.assertEqual(result.nanos, 1000 * microseconds)\n\n    def test_with_negative_microseconds(self):\n        import datetime\n        from google.protobuf import duration_pb2\n\n        seconds = 1\n        microseconds = -5\n        timedelta_val = datetime.timedelta(seconds=seconds, microseconds=microseconds)\n        result = self._call_fut(timedelta_val)\n        self.assertIsInstance(result, duration_pb2.Duration)\n        self.assertEqual(result.seconds, seconds - 1)\n        self.assertEqual(result.nanos, 10**9 + 1000 * microseconds)\n\n    def test_with_negative_seconds(self):\n        import datetime\n        from google.protobuf import duration_pb2\n\n        seconds = -1\n        microseconds = 5\n        timedelta_val = datetime.timedelta(seconds=seconds, microseconds=microseconds)\n        result = self._call_fut(timedelta_val)\n        self.assertIsInstance(result, duration_pb2.Duration)\n        self.assertEqual(result.seconds, seconds + 1)\n        self.assertEqual(result.nanos, -(10**9 - 1000 * microseconds))\n\n\nclass Test__duration_pb_to_timedelta(unittest.TestCase):\n    def _call_fut(self, *args, **kwargs):\n        from google.cloud._helpers import _duration_pb_to_timedelta\n\n        return _duration_pb_to_timedelta(*args, **kwargs)\n\n    def test_it(self):\n        import datetime\n        from google.protobuf import duration_pb2\n\n        seconds = microseconds = 1\n        duration_pb = duration_pb2.Duration(seconds=seconds, nanos=1000 * microseconds)\n        timedelta_val = datetime.timedelta(seconds=seconds, microseconds=microseconds)\n        result = self._call_fut(duration_pb)\n        self.assertIsInstance(result, datetime.timedelta)\n        self.assertEqual(result, timedelta_val)\n\n\nclass Test__name_from_project_path(unittest.TestCase):\n    PROJECT = \"PROJECT\"\n    THING_NAME = \"THING_NAME\"\n    TEMPLATE = r\"projects/(?P<project>\\w+)/things/(?P<name>\\w+)\"\n\n    def _call_fut(self, path, project, template):\n        from google.cloud._helpers import _name_from_project_path\n\n        return _name_from_project_path(path, project, template)\n\n    def test_w_invalid_path_length(self):\n        PATH = \"projects/foo\"\n        with self.assertRaises(ValueError):\n            self._call_fut(PATH, None, self.TEMPLATE)\n\n    def test_w_invalid_path_segments(self):\n        PATH = \"foo/%s/bar/%s\" % (self.PROJECT, self.THING_NAME)\n        with self.assertRaises(ValueError):\n            self._call_fut(PATH, self.PROJECT, self.TEMPLATE)\n\n    def test_w_mismatched_project(self):\n        PROJECT1 = \"PROJECT1\"\n        PROJECT2 = \"PROJECT2\"\n        PATH = \"projects/%s/things/%s\" % (PROJECT1, self.THING_NAME)\n        with self.assertRaises(ValueError):\n            self._call_fut(PATH, PROJECT2, self.TEMPLATE)\n\n    def test_w_valid_data_w_compiled_regex(self):\n        import re\n\n        template = re.compile(self.TEMPLATE)\n        PATH = \"projects/%s/things/%s\" % (self.PROJECT, self.THING_NAME)\n        name = self._call_fut(PATH, self.PROJECT, template)\n        self.assertEqual(name, self.THING_NAME)\n\n    def test_w_project_passed_as_none(self):\n        PROJECT1 = \"PROJECT1\"\n        PATH = \"projects/%s/things/%s\" % (PROJECT1, self.THING_NAME)\n        self._call_fut(PATH, None, self.TEMPLATE)\n        name = self._call_fut(PATH, None, self.TEMPLATE)\n        self.assertEqual(name, self.THING_NAME)\n\n\nclass Test_make_secure_channel(unittest.TestCase):\n    def _call_fut(self, *args, **kwargs):\n        from google.cloud._helpers import make_secure_channel\n\n        return make_secure_channel(*args, **kwargs)\n\n    def test_it(self):\n        import http.client\n\n        credentials = object()\n        host = \"HOST\"\n        user_agent = \"USER_AGENT\"\n\n        secure_authorized_channel_patch = mock.patch(\n            \"google.auth.transport.grpc.secure_authorized_channel\", autospec=True\n        )\n\n        with secure_authorized_channel_patch as secure_authorized_channel:\n            result = self._call_fut(credentials, user_agent, host)\n\n        self.assertIs(result, secure_authorized_channel.return_value)\n\n        expected_target = \"%s:%d\" % (host, http.client.HTTPS_PORT)\n        expected_options = ((\"grpc.primary_user_agent\", user_agent),)\n\n        secure_authorized_channel.assert_called_once_with(\n            credentials, mock.ANY, expected_target, options=expected_options\n        )\n\n    def test_extra_options(self):\n        import http.client\n\n        credentials = object()\n        host = \"HOST\"\n        user_agent = \"USER_AGENT\"\n        extra_options = ((\"some\", \"option\"),)\n\n        secure_authorized_channel_patch = mock.patch(\n            \"google.auth.transport.grpc.secure_authorized_channel\", autospec=True\n        )\n\n        with secure_authorized_channel_patch as secure_authorized_channel:\n            result = self._call_fut(credentials, user_agent, host, extra_options)\n\n        self.assertIs(result, secure_authorized_channel.return_value)\n\n        expected_target = \"%s:%d\" % (host, http.client.HTTPS_PORT)\n        expected_options = ((\"grpc.primary_user_agent\", user_agent), extra_options[0])\n\n        secure_authorized_channel.assert_called_once_with(\n            credentials, mock.ANY, expected_target, options=expected_options\n        )\n\n\nclass Test_make_secure_stub(unittest.TestCase):\n    def _call_fut(self, *args, **kwargs):\n        from google.cloud._helpers import make_secure_stub\n\n        return make_secure_stub(*args, **kwargs)\n\n    def test_it(self):\n        from google.cloud._testing import _Monkey\n        from google.cloud import _helpers as MUT\n\n        result = object()\n        channel_obj = object()\n        channels = []\n        channel_args = []\n\n        def stub_class(channel):\n            channels.append(channel)\n            return result\n\n        def mock_channel(*args, **kwargs):\n            channel_args.append(args)\n            channel_args.append(kwargs)\n            return channel_obj\n\n        credentials = object()\n        user_agent = \"you-sir-age-int\"\n        host = \"localhost\"\n        extra_options = {\"extra_options\": ()}\n        with _Monkey(MUT, make_secure_channel=mock_channel):\n            stub = self._call_fut(credentials, user_agent, stub_class, host)\n\n        self.assertIs(stub, result)\n        self.assertEqual(channels, [channel_obj])\n        self.assertEqual(channel_args, [(credentials, user_agent, host), extra_options])\n\n\nclass Test_make_insecure_stub(unittest.TestCase):\n    def _call_fut(self, *args, **kwargs):\n        from google.cloud._helpers import make_insecure_stub\n\n        return make_insecure_stub(*args, **kwargs)\n\n    def _helper(self, target, host, port=None):\n        from google.cloud._testing import _Monkey\n        from google.cloud import _helpers as MUT\n\n        mock_result = object()\n        stub_inputs = []\n        CHANNEL = object()\n\n        class _GRPCModule(object):\n            def insecure_channel(self, *args):\n                self.insecure_channel_args = args\n                return CHANNEL\n\n        grpc_mod = _GRPCModule()\n\n        def mock_stub_class(channel):\n            stub_inputs.append(channel)\n            return mock_result\n\n        with _Monkey(MUT, grpc=grpc_mod):\n            result = self._call_fut(mock_stub_class, host, port=port)\n\n        self.assertIs(result, mock_result)\n        self.assertEqual(stub_inputs, [CHANNEL])\n        self.assertEqual(grpc_mod.insecure_channel_args, (target,))\n\n    def test_with_port_argument(self):\n        host = \"HOST\"\n        port = 1025\n        target = \"%s:%d\" % (host, port)\n        self._helper(target, host, port=port)\n\n    def test_without_port_argument(self):\n        host = \"HOST:1114\"\n        self._helper(host, host)\n", "tests/unit/__init__.py": "# Copyright 2016 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "google/cloud/version.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n__version__ = \"2.4.1\"\n", "google/cloud/client/__init__.py": "# Copyright 2015 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Base classes for client used to interact with Google Cloud APIs.\"\"\"\n\nimport io\nimport json\nimport os\nfrom pickle import PicklingError\nfrom typing import Tuple\nfrom typing import Union\n\nimport google.api_core.client_options\nimport google.api_core.exceptions\nimport google.auth\nfrom google.auth import environment_vars\nimport google.auth.credentials\nimport google.auth.transport.requests\nfrom google.cloud._helpers import _determine_default_project\nfrom google.oauth2 import service_account\n\n\n_GOOGLE_AUTH_CREDENTIALS_HELP = (\n    \"This library only supports credentials from google-auth-library-python. \"\n    \"See https://google-auth.readthedocs.io/en/latest/ \"\n    \"for help on authentication with this library.\"\n)\n\n# Default timeout for auth requests.\n_CREDENTIALS_REFRESH_TIMEOUT = 300\n\n\nclass _ClientFactoryMixin(object):\n    \"\"\"Mixin to allow factories that create credentials.\n\n    .. note::\n\n        This class is virtual.\n    \"\"\"\n\n    _SET_PROJECT = False\n\n    @classmethod\n    def from_service_account_info(cls, info, *args, **kwargs):\n        \"\"\"Factory to retrieve JSON credentials while creating client.\n\n        :type info: dict\n        :param info:\n            The JSON object with a private key and other credentials\n            information (downloaded from the Google APIs console).\n\n        :type args: tuple\n        :param args: Remaining positional arguments to pass to constructor.\n\n        :param kwargs: Remaining keyword arguments to pass to constructor.\n\n        :rtype: :class:`_ClientFactoryMixin`\n        :returns: The client created with the retrieved JSON credentials.\n        :raises TypeError: if there is a conflict with the kwargs\n                 and the credentials created by the factory.\n        \"\"\"\n        if \"credentials\" in kwargs:\n            raise TypeError(\"credentials must not be in keyword arguments\")\n\n        credentials = service_account.Credentials.from_service_account_info(info)\n        if cls._SET_PROJECT:\n            if \"project\" not in kwargs:\n                kwargs[\"project\"] = info.get(\"project_id\")\n\n        kwargs[\"credentials\"] = credentials\n        return cls(*args, **kwargs)\n\n    @classmethod\n    def from_service_account_json(cls, json_credentials_path, *args, **kwargs):\n        \"\"\"Factory to retrieve JSON credentials while creating client.\n\n        :type json_credentials_path: str\n        :param json_credentials_path: The path to a private key file (this file\n                                      was given to you when you created the\n                                      service account). This file must contain\n                                      a JSON object with a private key and\n                                      other credentials information (downloaded\n                                      from the Google APIs console).\n\n        :type args: tuple\n        :param args: Remaining positional arguments to pass to constructor.\n\n        :param kwargs: Remaining keyword arguments to pass to constructor.\n\n        :rtype: :class:`_ClientFactoryMixin`\n        :returns: The client created with the retrieved JSON credentials.\n        :raises TypeError: if there is a conflict with the kwargs\n                 and the credentials created by the factory.\n        \"\"\"\n        with io.open(json_credentials_path, \"r\", encoding=\"utf-8\") as json_fi:\n            credentials_info = json.load(json_fi)\n\n        return cls.from_service_account_info(credentials_info, *args, **kwargs)\n\n\nclass Client(_ClientFactoryMixin):\n    \"\"\"Client to bundle configuration needed for API requests.\n\n    Stores ``credentials`` and an HTTP object so that subclasses\n    can pass them along to a connection class.\n\n    If no value is passed in for ``_http``, a :class:`requests.Session` object\n    will be created and authorized with the ``credentials``. If not, the\n    ``credentials`` and ``_http`` need not be related.\n\n    Callers and subclasses may seek to use the private key from\n    ``credentials`` to sign data.\n\n    Args:\n        credentials (google.auth.credentials.Credentials):\n            (Optional) The OAuth2 Credentials to use for this client. If not\n            passed (and if no ``_http`` object is passed), falls back to the\n            default inferred from the environment.\n        client_options (google.api_core.client_options.ClientOptions):\n            (Optional) Custom options for the client.\n        _http (requests.Session):\n            (Optional) HTTP object to make requests. Can be any object that\n            defines ``request()`` with the same interface as\n            :meth:`requests.Session.request`. If not passed, an ``_http``\n            object is created that is bound to the ``credentials`` for the\n            current object.\n            This parameter should be considered private, and could change in\n            the future.\n\n    Raises:\n        google.auth.exceptions.DefaultCredentialsError:\n            Raised if ``credentials`` is not specified and the library fails\n            to acquire default credentials.\n    \"\"\"\n\n    SCOPE: Union[Tuple[str, ...], None] = None\n    \"\"\"The scopes required for authenticating with a service.\n\n    Needs to be set by subclasses.\n    \"\"\"\n\n    def __init__(self, credentials=None, _http=None, client_options=None):\n        if isinstance(client_options, dict):\n            client_options = google.api_core.client_options.from_dict(client_options)\n        if client_options is None:\n            client_options = google.api_core.client_options.ClientOptions()\n\n        if credentials and client_options.credentials_file:\n            raise google.api_core.exceptions.DuplicateCredentialArgs(\n                \"'credentials' and 'client_options.credentials_file' are mutually exclusive.\"\n            )\n\n        if credentials and not isinstance(\n            credentials, google.auth.credentials.Credentials\n        ):\n            raise ValueError(_GOOGLE_AUTH_CREDENTIALS_HELP)\n\n        scopes = client_options.scopes or self.SCOPE\n\n        # if no http is provided, credentials must exist\n        if not _http and credentials is None:\n            if client_options.credentials_file:\n                credentials, _ = google.auth.load_credentials_from_file(\n                    client_options.credentials_file, scopes=scopes\n                )\n            else:\n                credentials, _ = google.auth.default(scopes=scopes)\n\n        self._credentials = google.auth.credentials.with_scopes_if_required(\n            credentials, scopes=scopes\n        )\n\n        if client_options.quota_project_id:\n            self._credentials = self._credentials.with_quota_project(\n                client_options.quota_project_id\n            )\n\n        self._http_internal = _http\n        self._client_cert_source = client_options.client_cert_source\n\n    def __getstate__(self):\n        \"\"\"Explicitly state that clients are not pickleable.\"\"\"\n        raise PicklingError(\n            \"\\n\".join(\n                [\n                    \"Pickling client objects is explicitly not supported.\",\n                    \"Clients have non-trivial state that is local and unpickleable.\",\n                ]\n            )\n        )\n\n    @property\n    def _http(self):\n        \"\"\"Getter for object used for HTTP transport.\n\n        :rtype: :class:`~requests.Session`\n        :returns: An HTTP object.\n        \"\"\"\n        if self._http_internal is None:\n            self._http_internal = google.auth.transport.requests.AuthorizedSession(\n                self._credentials,\n                refresh_timeout=_CREDENTIALS_REFRESH_TIMEOUT,\n            )\n            self._http_internal.configure_mtls_channel(self._client_cert_source)\n        return self._http_internal\n\n    def close(self):\n        \"\"\"Clean up transport, if set.\n\n        Suggested use:\n\n        .. code-block:: python\n\n           import contextlib\n\n           with contextlib.closing(client):  # closes on exit\n               do_something_with(client)\n        \"\"\"\n        if self._http_internal is not None:\n            self._http_internal.close()\n\n\nclass _ClientProjectMixin(object):\n    \"\"\"Mixin to allow setting the project on the client.\n\n    :type project: str\n    :param project:\n        (Optional) the project which the client acts on behalf of. If not\n        passed, falls back to the default inferred from the environment.\n\n    :type credentials: :class:`google.auth.credentials.Credentials`\n    :param credentials:\n        (Optional) credentials used to discover a project, if not passed.\n\n    :raises: :class:`EnvironmentError` if the project is neither passed in nor\n             set on the credentials or in the environment. :class:`ValueError`\n             if the project value is invalid.\n    \"\"\"\n\n    def __init__(self, project=None, credentials=None):\n        # This test duplicates the one from `google.auth.default`, but earlier,\n        # for backward compatibility:  we want the environment variable to\n        # override any project set on the credentials.  See:\n        # https://github.com/googleapis/python-cloud-core/issues/27\n        if project is None:\n            project = os.getenv(\n                environment_vars.PROJECT,\n                os.getenv(environment_vars.LEGACY_PROJECT),\n            )\n\n        # Project set on explicit credentials overrides discovery from\n        # SDK / GAE / GCE.\n        if project is None and credentials is not None:\n            project = getattr(credentials, \"project_id\", None)\n\n        if project is None:\n            project = self._determine_default(project)\n\n        if project is None:\n            raise EnvironmentError(\n                \"Project was not passed and could not be \"\n                \"determined from the environment.\"\n            )\n\n        if isinstance(project, bytes):\n            project = project.decode(\"utf-8\")\n\n        if not isinstance(project, str):\n            raise ValueError(\"Project must be a string.\")\n\n        self.project = project\n\n    @staticmethod\n    def _determine_default(project):\n        \"\"\"Helper:  use default project detection.\"\"\"\n        return _determine_default_project(project)\n\n\nclass ClientWithProject(Client, _ClientProjectMixin):\n    \"\"\"Client that also stores a project.\n\n    :type project: str\n    :param project: the project which the client acts on behalf of. If not\n                    passed falls back to the default inferred from the\n                    environment.\n\n    :type credentials: :class:`~google.auth.credentials.Credentials`\n    :param credentials: (Optional) The OAuth2 Credentials to use for this\n                        client. If not passed (and if no ``_http`` object is\n                        passed), falls back to the default inferred from the\n                        environment.\n\n    :type _http: :class:`~requests.Session`\n    :param _http: (Optional) HTTP object to make requests. Can be any object\n                  that defines ``request()`` with the same interface as\n                  :meth:`~requests.Session.request`. If not passed, an\n                  ``_http`` object is created that is bound to the\n                  ``credentials`` for the current object.\n                  This parameter should be considered private, and could\n                  change in the future.\n\n    :raises: :class:`ValueError` if the project is neither passed in nor\n             set in the environment.\n    \"\"\"\n\n    _SET_PROJECT = True  # Used by from_service_account_json()\n\n    def __init__(self, project=None, credentials=None, client_options=None, _http=None):\n        _ClientProjectMixin.__init__(self, project=project, credentials=credentials)\n        Client.__init__(\n            self, credentials=credentials, client_options=client_options, _http=_http\n        )\n", "google/cloud/exceptions/__init__.py": "# Copyright 2014 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# pylint: disable=invalid-name\n# pylint recognizies all of these aliases as constants and thinks they have\n# invalid names.\n\n\"\"\"Custom exceptions for :mod:`google.cloud` package.\"\"\"\n\n# Avoid the grpc and google.cloud.grpc collision.\nfrom __future__ import absolute_import\n\nfrom google.api_core import exceptions\n\ntry:\n    from grpc._channel import _Rendezvous\nexcept ImportError:  # pragma: NO COVER\n    _Rendezvous = None\n\nGrpcRendezvous = _Rendezvous\n\"\"\"Exception class raised by gRPC stable.\"\"\"\n\n# Aliases to moved classes.\nGoogleCloudError = exceptions.GoogleAPICallError\nRedirection = exceptions.Redirection\nMovedPermanently = exceptions.MovedPermanently\nNotModified = exceptions.NotModified\nTemporaryRedirect = exceptions.TemporaryRedirect\nResumeIncomplete = exceptions.ResumeIncomplete\nClientError = exceptions.ClientError\nBadRequest = exceptions.BadRequest\nUnauthorized = exceptions.Unauthorized\nForbidden = exceptions.Forbidden\nNotFound = exceptions.NotFound\nMethodNotAllowed = exceptions.MethodNotAllowed\nConflict = exceptions.Conflict\nLengthRequired = exceptions.LengthRequired\nPreconditionFailed = exceptions.PreconditionFailed\nRequestRangeNotSatisfiable = exceptions.RequestRangeNotSatisfiable\nTooManyRequests = exceptions.TooManyRequests\nServerError = exceptions.ServerError\nInternalServerError = exceptions.InternalServerError\nMethodNotImplemented = exceptions.MethodNotImplemented\nBadGateway = exceptions.BadGateway\nServiceUnavailable = exceptions.ServiceUnavailable\nGatewayTimeout = exceptions.GatewayTimeout\nfrom_http_status = exceptions.from_http_status\nfrom_http_response = exceptions.from_http_response\n", "google/cloud/operation/__init__.py": "# Copyright 2016 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Wrap long-running operations returned from Google Cloud APIs.\"\"\"\n\nfrom typing import Dict\n\nfrom google.longrunning import operations_pb2\nfrom google.protobuf import json_format\n\n\n_GOOGLE_APIS_PREFIX = \"type.googleapis.com\"\n\n_TYPE_URL_MAP: Dict[str, type] = {}\n\n\ndef _compute_type_url(klass, prefix=_GOOGLE_APIS_PREFIX):\n    \"\"\"Compute a type URL for a klass.\n\n    :type klass: type\n    :param klass: class to be used as a factory for the given type\n\n    :type prefix: str\n    :param prefix: URL prefix for the type\n\n    :rtype: str\n    :returns: the URL, prefixed as appropriate\n    \"\"\"\n    name = klass.DESCRIPTOR.full_name\n    return \"%s/%s\" % (prefix, name)\n\n\ndef register_type(klass, type_url=None):\n    \"\"\"Register a klass as the factory for a given type URL.\n\n    :type klass: :class:`type`\n    :param klass: class to be used as a factory for the given type\n\n    :type type_url: str\n    :param type_url: (Optional) URL naming the type. If not provided,\n                     infers the URL from the type descriptor.\n\n    :raises ValueError: if a registration already exists for the URL.\n    \"\"\"\n    if type_url is None:\n        type_url = _compute_type_url(klass)\n    if type_url in _TYPE_URL_MAP:\n        if _TYPE_URL_MAP[type_url] is not klass:\n            raise ValueError(\"Conflict: %s\" % (_TYPE_URL_MAP[type_url],))\n\n    _TYPE_URL_MAP[type_url] = klass\n\n\ndef _from_any(any_pb):\n    \"\"\"Convert an ``Any`` protobuf into the actual class.\n\n    Uses the type URL to do the conversion.\n\n    .. note::\n\n        This assumes that the type URL is already registered.\n\n    :type any_pb: :class:`google.protobuf.any_pb2.Any`\n    :param any_pb: An any object to be converted.\n\n    :rtype: object\n    :returns: The instance (of the correct type) stored in the any\n              instance.\n    \"\"\"\n    klass = _TYPE_URL_MAP[any_pb.type_url]\n    return klass.FromString(any_pb.value)\n\n\nclass Operation(object):\n    \"\"\"Representation of a Google API Long-Running Operation.\n\n    .. _protobuf: https://github.com/googleapis/googleapis/blob/\\\n                  050400df0fdb16f63b63e9dee53819044bffc857/\\\n                  google/longrunning/operations.proto#L80\n    .. _service: https://github.com/googleapis/googleapis/blob/\\\n                 050400df0fdb16f63b63e9dee53819044bffc857/\\\n                 google/longrunning/operations.proto#L38\n    .. _JSON: https://cloud.google.com/speech/reference/rest/\\\n              v1beta1/operations#Operation\n\n    This wraps an operation `protobuf`_ object and attempts to\n    interact with the long-running operations `service`_ (specific\n    to a given API). (Some services also offer a `JSON`_\n    API that maps the same underlying data type.)\n\n    :type name: str\n    :param name: The fully-qualified path naming the operation.\n\n    :type client: :class:`~google.cloud.client.Client`\n    :param client: The client used to poll for the status of the operation.\n                   If the operation was created via JSON/HTTP, the client\n                   must own a :class:`~google.cloud._http.Connection`\n                   to send polling requests. If created via protobuf, the\n                   client must have a gRPC stub in the ``_operations_stub``\n                   attribute.\n\n    :type caller_metadata: dict\n    :param caller_metadata: caller-assigned metadata about the operation\n    \"\"\"\n\n    target = None\n    \"\"\"Instance assocated with the operations:  callers may set.\"\"\"\n\n    response = None\n    \"\"\"Response returned from completed operation.\n\n    Only one of this and :attr:`error` can be populated.\n    \"\"\"\n\n    error = None\n    \"\"\"Error that resulted from a failed (complete) operation.\n\n    Only one of this and :attr:`response` can be populated.\n    \"\"\"\n\n    metadata = None\n    \"\"\"Metadata about the current operation (as a protobuf).\n\n    Code that uses operations must register the metadata types (via\n    :func:`register_type`) to ensure that the metadata fields can be\n    converted into the correct types.\n    \"\"\"\n\n    _from_grpc = True\n\n    def __init__(self, name, client, **caller_metadata):\n        self.name = name\n        self.client = client\n        self.caller_metadata = caller_metadata.copy()\n        self._complete = False\n\n    @classmethod\n    def from_pb(cls, operation_pb, client, **caller_metadata):\n        \"\"\"Factory:  construct an instance from a protobuf.\n\n        :type operation_pb:\n            :class:`~google.longrunning.operations_pb2.Operation`\n        :param operation_pb: Protobuf to be parsed.\n\n        :type client: object: must provide ``_operations_stub`` accessor.\n        :param client: The client used to poll for the status of the operation.\n\n        :type caller_metadata: dict\n        :param caller_metadata: caller-assigned metadata about the operation\n\n        :rtype: :class:`Operation`\n        :returns: new instance, with attributes based on the protobuf.\n        \"\"\"\n        result = cls(operation_pb.name, client, **caller_metadata)\n        result._update_state(operation_pb)\n        result._from_grpc = True\n        return result\n\n    @classmethod\n    def from_dict(cls, operation, client, **caller_metadata):\n        \"\"\"Factory: construct an instance from a dictionary.\n\n        :type operation: dict\n        :param operation: Operation as a JSON object.\n\n        :type client: :class:`~google.cloud.client.Client`\n        :param client: The client used to poll for the status of the operation.\n\n        :type caller_metadata: dict\n        :param caller_metadata: caller-assigned metadata about the operation\n\n        :rtype: :class:`Operation`\n        :returns: new instance, with attributes based on the protobuf.\n        \"\"\"\n        operation_pb = json_format.ParseDict(operation, operations_pb2.Operation())\n        result = cls(operation_pb.name, client, **caller_metadata)\n        result._update_state(operation_pb)\n        result._from_grpc = False\n        return result\n\n    @property\n    def complete(self):\n        \"\"\"Has the operation already completed?\n\n        :rtype: bool\n        :returns: True if already completed, else false.\n        \"\"\"\n        return self._complete\n\n    def _get_operation_rpc(self):\n        \"\"\"Polls the status of the current operation.\n\n        Uses gRPC request to check.\n\n        :rtype: :class:`~google.longrunning.operations_pb2.Operation`\n        :returns: The latest status of the current operation.\n        \"\"\"\n        request_pb = operations_pb2.GetOperationRequest(name=self.name)\n        return self.client._operations_stub.GetOperation(request_pb)\n\n    def _get_operation_http(self):\n        \"\"\"Checks the status of the current operation.\n\n        Uses HTTP request to check.\n\n        :rtype: :class:`~google.longrunning.operations_pb2.Operation`\n        :returns: The latest status of the current operation.\n        \"\"\"\n        path = \"operations/%s\" % (self.name,)\n        api_response = self.client._connection.api_request(method=\"GET\", path=path)\n        return json_format.ParseDict(api_response, operations_pb2.Operation())\n\n    def _get_operation(self):\n        \"\"\"Checks the status of the current operation.\n\n        :rtype: :class:`~google.longrunning.operations_pb2.Operation`\n        :returns: The latest status of the current operation.\n        \"\"\"\n        if self._from_grpc:\n            return self._get_operation_rpc()\n        else:\n            return self._get_operation_http()\n\n    def _update_state(self, operation_pb):\n        \"\"\"Update the state of the current object based on operation.\n\n        :type operation_pb:\n            :class:`~google.longrunning.operations_pb2.Operation`\n        :param operation_pb: Protobuf to be parsed.\n        \"\"\"\n        if operation_pb.done:\n            self._complete = True\n\n        if operation_pb.HasField(\"metadata\"):\n            self.metadata = _from_any(operation_pb.metadata)\n\n        result_type = operation_pb.WhichOneof(\"result\")\n        if result_type == \"error\":\n            self.error = operation_pb.error\n        elif result_type == \"response\":\n            self.response = _from_any(operation_pb.response)\n\n    def poll(self):\n        \"\"\"Check if the operation has finished.\n\n        :rtype: bool\n        :returns: A boolean indicating if the current operation has completed.\n        :raises ValueError: if the operation\n                 has already completed.\n        \"\"\"\n        if self.complete:\n            raise ValueError(\"The operation has completed.\")\n\n        operation_pb = self._get_operation()\n        self._update_state(operation_pb)\n\n        return self.complete\n", "google/cloud/obsolete/__init__.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for deprecated code and modules.\"\"\"\n\nimport sys\nimport warnings\n\n\nif sys.version_info < (3, 8):\n    import importlib_metadata as metadata\nelse:\n    import importlib.metadata as metadata\n\n\ndef complain(distribution_name):\n    \"\"\"Issue a warning if `distribution_name` is installed.\n\n    In a future release, this method will be updated to raise ImportError\n    rather than just send a warning.\n\n    Args:\n        distribution_name (str): The name of the obsolete distribution.\n    \"\"\"\n    try:\n        metadata.distribution(distribution_name)\n        warnings.warn(\n            \"The {pkg} distribution is now obsolete. \"\n            \"Please `pip uninstall {pkg}`. \"\n            \"In the future, this warning will become an ImportError.\".format(\n                pkg=distribution_name\n            ),\n            DeprecationWarning,\n        )\n    except metadata.PackageNotFoundError:\n        pass\n", "google/cloud/environment_vars/__init__.py": "# Copyright 2015 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Comprehensive list of environment variables used in google-cloud.\n\nThese enable many types of implicit behavior in both production\nand tests.\n\"\"\"\n\nGCD_DATASET = \"DATASTORE_DATASET\"\n\"\"\"Environment variable defining default dataset ID under GCD.\"\"\"\n\nGCD_HOST = \"DATASTORE_EMULATOR_HOST\"\n\"\"\"Environment variable defining host for GCD dataset server.\"\"\"\n\nPUBSUB_EMULATOR = \"PUBSUB_EMULATOR_HOST\"\n\"\"\"Environment variable defining host for Pub/Sub emulator.\"\"\"\n\nBIGTABLE_EMULATOR = \"BIGTABLE_EMULATOR_HOST\"\n\"\"\"Environment variable defining host for Bigtable emulator.\"\"\"\n\nDISABLE_GRPC = \"GOOGLE_CLOUD_DISABLE_GRPC\"\n\"\"\"Environment variable acting as flag to disable gRPC.\n\nTo be used for APIs where both an HTTP and gRPC implementation\nexist.\n\"\"\"\n", "google/cloud/_testing/__init__.py": "# Copyright 2014 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Shared testing utilities.\"\"\"\n\nfrom __future__ import absolute_import\n\n\nclass _Monkey(object):\n    \"\"\"Context-manager for replacing module names in the scope of a test.\"\"\"\n\n    def __init__(self, module, **kw):\n        self.module = module\n        if not kw:  # pragma: NO COVER\n            raise ValueError(\"_Monkey was used with nothing to monkey-patch\")\n        self.to_restore = {key: getattr(module, key) for key in kw}\n        for key, value in kw.items():\n            setattr(module, key, value)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        for key, value in self.to_restore.items():\n            setattr(self.module, key, value)\n\n\nclass _NamedTemporaryFile(object):\n    def __init__(self, suffix=\"\"):\n        import os\n        import tempfile\n\n        filehandle, self.name = tempfile.mkstemp(suffix=suffix)\n        os.close(filehandle)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        import os\n\n        os.remove(self.name)\n\n\ndef _tempdir_maker():\n    import contextlib\n    import shutil\n    import tempfile\n\n    @contextlib.contextmanager\n    def _tempdir_mgr():\n        temp_dir = tempfile.mkdtemp()\n        yield temp_dir\n        shutil.rmtree(temp_dir)\n\n    return _tempdir_mgr\n\n\n# pylint: disable=invalid-name\n# Retain _tempdir as a constant for backwards compatibility despite\n# being an invalid name.\n_tempdir = _tempdir_maker()\ndel _tempdir_maker\n# pylint: enable=invalid-name\n\n\nclass _GAXBaseAPI(object):\n    _random_gax_error = False\n\n    def __init__(self, **kw):\n        self.__dict__.update(kw)\n\n    @staticmethod\n    def _make_grpc_error(status_code, trailing=None):\n        from grpc._channel import _RPCState\n        from google.cloud.exceptions import GrpcRendezvous\n\n        details = \"Some error details.\"\n        exc_state = _RPCState((), None, trailing, status_code, details)\n        return GrpcRendezvous(exc_state, None, None, None)\n\n    def _make_grpc_not_found(self):\n        from grpc import StatusCode\n\n        return self._make_grpc_error(StatusCode.NOT_FOUND)\n\n    def _make_grpc_failed_precondition(self):\n        from grpc import StatusCode\n\n        return self._make_grpc_error(StatusCode.FAILED_PRECONDITION)\n\n    def _make_grpc_already_exists(self):\n        from grpc import StatusCode\n\n        return self._make_grpc_error(StatusCode.ALREADY_EXISTS)\n\n    def _make_grpc_deadline_exceeded(self):\n        from grpc import StatusCode\n\n        return self._make_grpc_error(StatusCode.DEADLINE_EXCEEDED)\n\n\nclass _GAXPageIterator(object):\n    def __init__(self, *pages, **kwargs):\n        self._pages = iter(pages)\n        self.page_token = kwargs.get(\"page_token\")\n\n    def __next__(self):\n        \"\"\"Iterate to the next page.\"\"\"\n        return next(self._pages)\n", "google/cloud/_http/__init__.py": "# Copyright 2014 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Shared implementation of connections to API servers.\"\"\"\n\nimport collections\nimport collections.abc\nimport json\nimport os\nimport platform\nfrom typing import Optional\nfrom urllib.parse import urlencode\nimport warnings\n\nfrom google.api_core.client_info import ClientInfo\nfrom google.cloud import exceptions\nfrom google.cloud import version\n\n\nAPI_BASE_URL = \"https://www.googleapis.com\"\n\"\"\"The base of the API call URL.\"\"\"\n\nDEFAULT_USER_AGENT = \"gcloud-python/{0}\".format(version.__version__)\n\"\"\"The user agent for google-cloud-python requests.\"\"\"\n\nCLIENT_INFO_HEADER = \"X-Goog-API-Client\"\nCLIENT_INFO_TEMPLATE = \"gl-python/\" + platform.python_version() + \" gccl/{}\"\n\n_USER_AGENT_ALL_CAPS_DEPRECATED = \"\"\"\\\nThe 'USER_AGENT' class-level attribute is deprecated.  Please use\n'user_agent' instead.\n\"\"\"\n\n_EXTRA_HEADERS_ALL_CAPS_DEPRECATED = \"\"\"\\\nThe '_EXTRA_HEADERS' class-level attribute is deprecated.  Please use\n'extra_headers' instead.\n\"\"\"\n\n_DEFAULT_TIMEOUT = 60  # in seconds\n\n\nclass Connection(object):\n    \"\"\"A generic connection to Google Cloud Platform.\n\n    :type client: :class:`~google.cloud.client.Client`\n    :param client: The client that owns the current connection.\n\n    :type client_info: :class:`~google.api_core.client_info.ClientInfo`\n    :param client_info: (Optional) instance used to generate user agent.\n    \"\"\"\n\n    _user_agent = DEFAULT_USER_AGENT\n\n    def __init__(self, client, client_info=None):\n        self._client = client\n\n        if client_info is None:\n            client_info = ClientInfo()\n\n        self._client_info = client_info\n        self._extra_headers = {}\n\n    @property\n    def USER_AGENT(self):\n        \"\"\"Deprecated:  get / set user agent sent by connection.\n\n        :rtype: str\n        :returns: user agent\n        \"\"\"\n        warnings.warn(_USER_AGENT_ALL_CAPS_DEPRECATED, DeprecationWarning, stacklevel=2)\n        return self.user_agent\n\n    @USER_AGENT.setter\n    def USER_AGENT(self, value):\n        warnings.warn(_USER_AGENT_ALL_CAPS_DEPRECATED, DeprecationWarning, stacklevel=2)\n        self.user_agent = value\n\n    @property\n    def user_agent(self):\n        \"\"\"Get / set user agent sent by connection.\n\n        :rtype: str\n        :returns: user agent\n        \"\"\"\n        return self._client_info.to_user_agent()\n\n    @user_agent.setter\n    def user_agent(self, value):\n        self._client_info.user_agent = value\n\n    @property\n    def _EXTRA_HEADERS(self):\n        \"\"\"Deprecated:  get / set extra headers sent by connection.\n\n        :rtype: dict\n        :returns: header keys / values\n        \"\"\"\n        warnings.warn(\n            _EXTRA_HEADERS_ALL_CAPS_DEPRECATED, DeprecationWarning, stacklevel=2\n        )\n        return self.extra_headers\n\n    @_EXTRA_HEADERS.setter\n    def _EXTRA_HEADERS(self, value):\n        warnings.warn(\n            _EXTRA_HEADERS_ALL_CAPS_DEPRECATED, DeprecationWarning, stacklevel=2\n        )\n        self.extra_headers = value\n\n    @property\n    def extra_headers(self):\n        \"\"\"Get / set extra headers sent by connection.\n\n        :rtype: dict\n        :returns: header keys / values\n        \"\"\"\n        return self._extra_headers\n\n    @extra_headers.setter\n    def extra_headers(self, value):\n        self._extra_headers = value\n\n    @property\n    def credentials(self):\n        \"\"\"Getter for current credentials.\n\n        :rtype: :class:`google.auth.credentials.Credentials` or\n                :class:`NoneType`\n        :returns: The credentials object associated with this connection.\n        \"\"\"\n        return self._client._credentials\n\n    @property\n    def http(self):\n        \"\"\"A getter for the HTTP transport used in talking to the API.\n\n        Returns:\n            google.auth.transport.requests.AuthorizedSession:\n                A :class:`requests.Session` instance.\n        \"\"\"\n        return self._client._http\n\n\nclass JSONConnection(Connection):\n    \"\"\"A connection to a Google JSON-based API.\n\n    These APIs are discovery based. For reference:\n\n        https://developers.google.com/discovery/\n\n    This defines :meth:`api_request` for making a generic JSON\n    API request and API requests are created elsewhere.\n\n    * :attr:`API_BASE_URL`\n    * :attr:`API_VERSION`\n    * :attr:`API_URL_TEMPLATE`\n\n    must be updated by subclasses.\n    \"\"\"\n\n    API_BASE_URL: Optional[str] = None\n    \"\"\"The base of the API call URL.\"\"\"\n\n    API_BASE_MTLS_URL: Optional[str] = None\n    \"\"\"The base of the API call URL for mutual TLS.\"\"\"\n\n    ALLOW_AUTO_SWITCH_TO_MTLS_URL = False\n    \"\"\"Indicates if auto switch to mTLS url is allowed.\"\"\"\n\n    API_VERSION: Optional[str] = None\n    \"\"\"The version of the API, used in building the API call's URL.\"\"\"\n\n    API_URL_TEMPLATE: Optional[str] = None\n    \"\"\"A template for the URL of a particular API call.\"\"\"\n\n    def get_api_base_url_for_mtls(self, api_base_url=None):\n        \"\"\"Return the api base url for mutual TLS.\n\n        Typically, you shouldn't need to use this method.\n\n        The logic is as follows:\n\n        If `api_base_url` is provided, just return this value; otherwise, the\n        return value depends `GOOGLE_API_USE_MTLS_ENDPOINT` environment variable\n        value.\n\n        If the environment variable value is \"always\", return `API_BASE_MTLS_URL`.\n        If the environment variable value is \"never\", return `API_BASE_URL`.\n        Otherwise, if `ALLOW_AUTO_SWITCH_TO_MTLS_URL` is True and the underlying\n        http is mTLS, then return `API_BASE_MTLS_URL`; otherwise return `API_BASE_URL`.\n\n        :type api_base_url: str\n        :param api_base_url: User provided api base url. It takes precedence over\n                             `API_BASE_URL` and `API_BASE_MTLS_URL`.\n\n        :rtype: str\n        :returns: The api base url used for mTLS.\n        \"\"\"\n        if api_base_url:\n            return api_base_url\n\n        env = os.getenv(\"GOOGLE_API_USE_MTLS_ENDPOINT\", \"auto\")\n        if env == \"always\":\n            url_to_use = self.API_BASE_MTLS_URL\n        elif env == \"never\":\n            url_to_use = self.API_BASE_URL\n        else:\n            if self.ALLOW_AUTO_SWITCH_TO_MTLS_URL:\n                url_to_use = (\n                    self.API_BASE_MTLS_URL if self.http.is_mtls else self.API_BASE_URL\n                )\n            else:\n                url_to_use = self.API_BASE_URL\n        return url_to_use\n\n    def build_api_url(\n        self, path, query_params=None, api_base_url=None, api_version=None\n    ):\n        \"\"\"Construct an API url given a few components, some optional.\n\n        Typically, you shouldn't need to use this method.\n\n        :type path: str\n        :param path: The path to the resource (ie, ``'/b/bucket-name'``).\n\n        :type query_params: dict or list\n        :param query_params: A dictionary of keys and values (or list of\n                             key-value pairs) to insert into the query\n                             string of the URL.\n\n        :type api_base_url: str\n        :param api_base_url: The base URL for the API endpoint.\n                             Typically you won't have to provide this.\n\n        :type api_version: str\n        :param api_version: The version of the API to call.\n                            Typically you shouldn't provide this and instead\n                            use the default for the library.\n\n        :rtype: str\n        :returns: The URL assembled from the pieces provided.\n        \"\"\"\n        url = self.API_URL_TEMPLATE.format(\n            api_base_url=self.get_api_base_url_for_mtls(api_base_url),\n            api_version=(api_version or self.API_VERSION),\n            path=path,\n        )\n\n        query_params = query_params or {}\n\n        if isinstance(query_params, collections.abc.Mapping):\n            query_params = query_params.copy()\n        else:\n            query_params_dict = collections.defaultdict(list)\n            for key, value in query_params:\n                query_params_dict[key].append(value)\n            query_params = query_params_dict\n\n        query_params.setdefault(\"prettyPrint\", \"false\")\n\n        url += \"?\" + urlencode(query_params, doseq=True)\n\n        return url\n\n    def _make_request(\n        self,\n        method,\n        url,\n        data=None,\n        content_type=None,\n        headers=None,\n        target_object=None,\n        timeout=_DEFAULT_TIMEOUT,\n        extra_api_info=None,\n    ):\n        \"\"\"A low level method to send a request to the API.\n\n        Typically, you shouldn't need to use this method.\n\n        :type method: str\n        :param method: The HTTP method to use in the request.\n\n        :type url: str\n        :param url: The URL to send the request to.\n\n        :type data: str\n        :param data: The data to send as the body of the request.\n\n        :type content_type: str\n        :param content_type: The proper MIME type of the data provided.\n\n        :type headers: dict\n        :param headers: (Optional) A dictionary of HTTP headers to send with\n                        the request. If passed, will be modified directly\n                        here with added headers.\n\n        :type target_object: object\n        :param target_object:\n            (Optional) Argument to be used by library callers.  This can allow\n            custom behavior, for example, to defer an HTTP request and complete\n            initialization of the object at a later time.\n\n        :type timeout: float or tuple\n        :param timeout: (optional) The amount of time, in seconds, to wait\n            for the server response.\n\n            Can also be passed as a tuple (connect_timeout, read_timeout).\n            See :meth:`requests.Session.request` documentation for details.\n\n        :type extra_api_info: string\n        :param extra_api_info: (optional) Extra api info to be appended to\n            the X-Goog-API-Client header\n\n        :rtype: :class:`requests.Response`\n        :returns: The HTTP response.\n        \"\"\"\n        headers = headers or {}\n        headers.update(self.extra_headers)\n        headers[\"Accept-Encoding\"] = \"gzip\"\n\n        if content_type:\n            headers[\"Content-Type\"] = content_type\n\n        if extra_api_info:\n            headers[CLIENT_INFO_HEADER] = f\"{self.user_agent} {extra_api_info}\"\n        else:\n            headers[CLIENT_INFO_HEADER] = self.user_agent\n        headers[\"User-Agent\"] = self.user_agent\n\n        return self._do_request(\n            method, url, headers, data, target_object, timeout=timeout\n        )\n\n    def _do_request(\n        self, method, url, headers, data, target_object, timeout=_DEFAULT_TIMEOUT\n    ):  # pylint: disable=unused-argument\n        \"\"\"Low-level helper:  perform the actual API request over HTTP.\n\n        Allows batch context managers to override and defer a request.\n\n        :type method: str\n        :param method: The HTTP method to use in the request.\n\n        :type url: str\n        :param url: The URL to send the request to.\n\n        :type headers: dict\n        :param headers: A dictionary of HTTP headers to send with the request.\n\n        :type data: str\n        :param data: The data to send as the body of the request.\n\n        :type target_object: object\n        :param target_object:\n            (Optional) Unused ``target_object`` here but may be used by a\n            superclass.\n\n        :type timeout: float or tuple\n        :param timeout: (optional) The amount of time, in seconds, to wait\n            for the server response.\n\n            Can also be passed as a tuple (connect_timeout, read_timeout).\n            See :meth:`requests.Session.request` documentation for details.\n\n        :rtype: :class:`requests.Response`\n        :returns: The HTTP response.\n        \"\"\"\n        return self.http.request(\n            url=url, method=method, headers=headers, data=data, timeout=timeout\n        )\n\n    def api_request(\n        self,\n        method,\n        path,\n        query_params=None,\n        data=None,\n        content_type=None,\n        headers=None,\n        api_base_url=None,\n        api_version=None,\n        expect_json=True,\n        _target_object=None,\n        timeout=_DEFAULT_TIMEOUT,\n        extra_api_info=None,\n    ):\n        \"\"\"Make a request over the HTTP transport to the API.\n\n        You shouldn't need to use this method, but if you plan to\n        interact with the API using these primitives, this is the\n        correct one to use.\n\n        :type method: str\n        :param method: The HTTP method name (ie, ``GET``, ``POST``, etc).\n                       Required.\n\n        :type path: str\n        :param path: The path to the resource (ie, ``'/b/bucket-name'``).\n                     Required.\n\n        :type query_params: dict or list\n        :param query_params: A dictionary of keys and values (or list of\n                             key-value pairs) to insert into the query\n                             string of the URL.\n\n        :type data: str\n        :param data: The data to send as the body of the request. Default is\n                     the empty string.\n\n        :type content_type: str\n        :param content_type: The proper MIME type of the data provided. Default\n                             is None.\n\n        :type headers: dict\n        :param headers: extra HTTP headers to be sent with the request.\n\n        :type api_base_url: str\n        :param api_base_url: The base URL for the API endpoint.\n                             Typically you won't have to provide this.\n                             Default is the standard API base URL.\n\n        :type api_version: str\n        :param api_version: The version of the API to call.  Typically\n                            you shouldn't provide this and instead use\n                            the default for the library.  Default is the\n                            latest API version supported by\n                            google-cloud-python.\n\n        :type expect_json: bool\n        :param expect_json: If True, this method will try to parse the\n                            response as JSON and raise an exception if\n                            that cannot be done.  Default is True.\n\n        :type _target_object: :class:`object`\n        :param _target_object:\n            (Optional) Protected argument to be used by library callers. This\n            can allow custom behavior, for example, to defer an HTTP request\n            and complete initialization of the object at a later time.\n\n        :type timeout: float or tuple\n        :param timeout: (optional) The amount of time, in seconds, to wait\n            for the server response.\n\n            Can also be passed as a tuple (connect_timeout, read_timeout).\n            See :meth:`requests.Session.request` documentation for details.\n\n        :type extra_api_info: string\n        :param extra_api_info: (optional) Extra api info to be appended to\n            the X-Goog-API-Client header\n\n        :raises ~google.cloud.exceptions.GoogleCloudError: if the response code\n            is not 200 OK.\n        :raises ValueError: if the response content type is not JSON.\n        :rtype: dict or str\n        :returns: The API response payload, either as a raw string or\n                  a dictionary if the response is valid JSON.\n        \"\"\"\n        url = self.build_api_url(\n            path=path,\n            query_params=query_params,\n            api_base_url=api_base_url,\n            api_version=api_version,\n        )\n\n        # Making the executive decision that any dictionary\n        # data will be sent properly as JSON.\n        if data and isinstance(data, dict):\n            data = json.dumps(data)\n            content_type = \"application/json\"\n\n        response = self._make_request(\n            method=method,\n            url=url,\n            data=data,\n            content_type=content_type,\n            headers=headers,\n            target_object=_target_object,\n            timeout=timeout,\n            extra_api_info=extra_api_info,\n        )\n\n        if not 200 <= response.status_code < 300:\n            raise exceptions.from_http_response(response)\n\n        if expect_json and response.content:\n            return response.json()\n        else:\n            return response.content\n", "google/cloud/_helpers/__init__.py": "# Copyright 2014 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Shared helpers for Google Cloud packages.\n\nThis module is not part of the public API surface.\n\"\"\"\n\nfrom __future__ import absolute_import\n\nimport calendar\nimport datetime\nimport http.client\nimport os\nimport re\nfrom threading import local as Local\nfrom typing import Union\n\nimport google.auth\nimport google.auth.transport.requests\nfrom google.protobuf import duration_pb2\nfrom google.protobuf import timestamp_pb2\n\ntry:\n    import grpc\n    import google.auth.transport.grpc\nexcept ImportError:  # pragma: NO COVER\n    grpc = None\n\n# `google.cloud._helpers._NOW` is deprecated\n_NOW = datetime.datetime.utcnow\nUTC = datetime.timezone.utc  # Singleton instance to be used throughout.\n_EPOCH = datetime.datetime(1970, 1, 1, tzinfo=datetime.timezone.utc)\n\n_RFC3339_MICROS = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n_RFC3339_NO_FRACTION = \"%Y-%m-%dT%H:%M:%S\"\n_TIMEONLY_W_MICROS = \"%H:%M:%S.%f\"\n_TIMEONLY_NO_FRACTION = \"%H:%M:%S\"\n# datetime.strptime cannot handle nanosecond precision:  parse w/ regex\n_RFC3339_NANOS = re.compile(\n    r\"\"\"\n    (?P<no_fraction>\n        \\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}  # YYYY-MM-DDTHH:MM:SS\n    )\n    (                                        # Optional decimal part\n     \\.                                      # decimal point\n     (?P<nanos>\\d{1,9})                      # nanoseconds, maybe truncated\n    )?\n    Z                                        # Zulu\n\"\"\",\n    re.VERBOSE,\n)\n# NOTE: Catching this ImportError is a workaround for GAE not supporting the\n#       \"pwd\" module which is imported lazily when \"expanduser\" is called.\n_USER_ROOT: Union[str, None]\ntry:\n    _USER_ROOT = os.path.expanduser(\"~\")\nexcept ImportError:  # pragma: NO COVER\n    _USER_ROOT = None\n_GCLOUD_CONFIG_FILE = os.path.join(\"gcloud\", \"configurations\", \"config_default\")\n_GCLOUD_CONFIG_SECTION = \"core\"\n_GCLOUD_CONFIG_KEY = \"project\"\n\n\nclass _LocalStack(Local):\n    \"\"\"Manage a thread-local LIFO stack of resources.\n\n    Intended for use in :class:`google.cloud.datastore.batch.Batch.__enter__`,\n    :class:`google.cloud.storage.batch.Batch.__enter__`, etc.\n    \"\"\"\n\n    def __init__(self):\n        super(_LocalStack, self).__init__()\n        self._stack = []\n\n    def __iter__(self):\n        \"\"\"Iterate the stack in LIFO order.\"\"\"\n        return iter(reversed(self._stack))\n\n    def push(self, resource):\n        \"\"\"Push a resource onto our stack.\"\"\"\n        self._stack.append(resource)\n\n    def pop(self):\n        \"\"\"Pop a resource from our stack.\n\n        :rtype: object\n        :returns: the top-most resource, after removing it.\n        :raises IndexError: if the stack is empty.\n        \"\"\"\n        return self._stack.pop()\n\n    @property\n    def top(self):\n        \"\"\"Get the top-most resource\n\n        :rtype: object\n        :returns: the top-most item, or None if the stack is empty.\n        \"\"\"\n        if self._stack:\n            return self._stack[-1]\n\n\ndef _ensure_tuple_or_list(arg_name, tuple_or_list):\n    \"\"\"Ensures an input is a tuple or list.\n\n    This effectively reduces the iterable types allowed to a very short\n    allowlist: list and tuple.\n\n    :type arg_name: str\n    :param arg_name: Name of argument to use in error message.\n\n    :type tuple_or_list: sequence of str\n    :param tuple_or_list: Sequence to be verified.\n\n    :rtype: list of str\n    :returns: The ``tuple_or_list`` passed in cast to a ``list``.\n    :raises TypeError: if the ``tuple_or_list`` is not a tuple or list.\n    \"\"\"\n    if not isinstance(tuple_or_list, (tuple, list)):\n        raise TypeError(\n            \"Expected %s to be a tuple or list. \"\n            \"Received %r\" % (arg_name, tuple_or_list)\n        )\n    return list(tuple_or_list)\n\n\ndef _determine_default_project(project=None):\n    \"\"\"Determine default project ID explicitly or implicitly as fall-back.\n\n    See :func:`google.auth.default` for details on how the default project\n    is determined.\n\n    :type project: str\n    :param project: Optional. The project name to use as default.\n\n    :rtype: str or ``NoneType``\n    :returns: Default project if it can be determined.\n    \"\"\"\n    if project is None:\n        _, project = google.auth.default()\n    return project\n\n\ndef _millis(when):\n    \"\"\"Convert a zone-aware datetime to integer milliseconds.\n\n    :type when: :class:`datetime.datetime`\n    :param when: the datetime to convert\n\n    :rtype: int\n    :returns: milliseconds since epoch for ``when``\n    \"\"\"\n    micros = _microseconds_from_datetime(when)\n    return micros // 1000\n\n\ndef _datetime_from_microseconds(value):\n    \"\"\"Convert timestamp to datetime, assuming UTC.\n\n    :type value: float\n    :param value: The timestamp to convert\n\n    :rtype: :class:`datetime.datetime`\n    :returns: The datetime object created from the value.\n    \"\"\"\n    return _EPOCH + datetime.timedelta(microseconds=value)\n\n\ndef _microseconds_from_datetime(value):\n    \"\"\"Convert non-none datetime to microseconds.\n\n    :type value: :class:`datetime.datetime`\n    :param value: The timestamp to convert.\n\n    :rtype: int\n    :returns: The timestamp, in microseconds.\n    \"\"\"\n    if not value.tzinfo:\n        value = value.replace(tzinfo=UTC)\n    # Regardless of what timezone is on the value, convert it to UTC.\n    value = value.astimezone(UTC)\n    # Convert the datetime to a microsecond timestamp.\n    return int(calendar.timegm(value.timetuple()) * 1e6) + value.microsecond\n\n\ndef _millis_from_datetime(value):\n    \"\"\"Convert non-none datetime to timestamp, assuming UTC.\n\n    :type value: :class:`datetime.datetime`\n    :param value: (Optional) the timestamp\n\n    :rtype: int, or ``NoneType``\n    :returns: the timestamp, in milliseconds, or None\n    \"\"\"\n    if value is not None:\n        return _millis(value)\n\n\ndef _date_from_iso8601_date(value):\n    \"\"\"Convert a ISO8601 date string to native datetime date\n\n    :type value: str\n    :param value: The date string to convert\n\n    :rtype: :class:`datetime.date`\n    :returns: A datetime date object created from the string\n\n    \"\"\"\n    return datetime.datetime.strptime(value, \"%Y-%m-%d\").date()\n\n\ndef _time_from_iso8601_time_naive(value):\n    \"\"\"Convert a zoneless ISO8601 time string to naive datetime time\n\n    :type value: str\n    :param value: The time string to convert\n\n    :rtype: :class:`datetime.time`\n    :returns: A datetime time object created from the string\n    :raises ValueError: if the value does not match a known format.\n    \"\"\"\n    if len(value) == 8:  # HH:MM:SS\n        fmt = _TIMEONLY_NO_FRACTION\n    elif len(value) == 15:  # HH:MM:SS.micros\n        fmt = _TIMEONLY_W_MICROS\n    else:\n        raise ValueError(\"Unknown time format: {}\".format(value))\n    return datetime.datetime.strptime(value, fmt).time()\n\n\ndef _rfc3339_to_datetime(dt_str):\n    \"\"\"Convert a microsecond-precision timestamp to a native datetime.\n\n    :type dt_str: str\n    :param dt_str: The string to convert.\n\n    :rtype: :class:`datetime.datetime`\n    :returns: The datetime object created from the string.\n    \"\"\"\n    return datetime.datetime.strptime(dt_str, _RFC3339_MICROS).replace(tzinfo=UTC)\n\n\ndef _rfc3339_nanos_to_datetime(dt_str):\n    \"\"\"Convert a nanosecond-precision timestamp to a native datetime.\n\n    .. note::\n\n       Python datetimes do not support nanosecond precision;  this function\n       therefore truncates such values to microseconds.\n\n    :type dt_str: str\n    :param dt_str: The string to convert.\n\n    :rtype: :class:`datetime.datetime`\n    :returns: The datetime object created from the string.\n    :raises ValueError: If the timestamp does not match the RFC 3339\n                        regular expression.\n    \"\"\"\n    with_nanos = _RFC3339_NANOS.match(dt_str)\n    if with_nanos is None:\n        raise ValueError(\n            \"Timestamp: %r, does not match pattern: %r\"\n            % (dt_str, _RFC3339_NANOS.pattern)\n        )\n    bare_seconds = datetime.datetime.strptime(\n        with_nanos.group(\"no_fraction\"), _RFC3339_NO_FRACTION\n    )\n    fraction = with_nanos.group(\"nanos\")\n    if fraction is None:\n        micros = 0\n    else:\n        scale = 9 - len(fraction)\n        nanos = int(fraction) * (10**scale)\n        micros = nanos // 1000\n    return bare_seconds.replace(microsecond=micros, tzinfo=UTC)\n\n\ndef _datetime_to_rfc3339(value, ignore_zone=True):\n    \"\"\"Convert a timestamp to a string.\n\n    :type value: :class:`datetime.datetime`\n    :param value: The datetime object to be converted to a string.\n\n    :type ignore_zone: bool\n    :param ignore_zone: If True, then the timezone (if any) of the datetime\n                        object is ignored.\n\n    :rtype: str\n    :returns: The string representing the datetime stamp.\n    \"\"\"\n    if not ignore_zone and value.tzinfo is not None:\n        # Convert to UTC and remove the time zone info.\n        value = value.replace(tzinfo=None) - value.utcoffset()\n\n    return value.strftime(_RFC3339_MICROS)\n\n\ndef _to_bytes(value, encoding=\"ascii\"):\n    \"\"\"Converts a string value to bytes, if necessary.\n\n    :type value: str / bytes or unicode\n    :param value: The string/bytes value to be converted.\n\n    :type encoding: str\n    :param encoding: The encoding to use to convert unicode to bytes. Defaults\n                     to \"ascii\", which will not allow any characters from\n                     ordinals larger than 127. Other useful values are\n                     \"latin-1\", which which will only allows byte ordinals\n                     (up to 255) and \"utf-8\", which will encode any unicode\n                     that needs to be.\n\n    :rtype: str / bytes\n    :returns: The original value converted to bytes (if unicode) or as passed\n              in if it started out as bytes.\n    :raises TypeError: if the value could not be converted to bytes.\n    \"\"\"\n    result = value.encode(encoding) if isinstance(value, str) else value\n    if isinstance(result, bytes):\n        return result\n    else:\n        raise TypeError(\"%r could not be converted to bytes\" % (value,))\n\n\ndef _bytes_to_unicode(value):\n    \"\"\"Converts bytes to a unicode value, if necessary.\n\n    :type value: bytes\n    :param value: bytes value to attempt string conversion on.\n\n    :rtype: str\n    :returns: The original value converted to unicode (if bytes) or as passed\n              in if it started out as unicode.\n\n    :raises ValueError: if the value could not be converted to unicode.\n    \"\"\"\n    result = value.decode(\"utf-8\") if isinstance(value, bytes) else value\n    if isinstance(result, str):\n        return result\n    else:\n        raise ValueError(\"%r could not be converted to unicode\" % (value,))\n\n\ndef _from_any_pb(pb_type, any_pb):\n    \"\"\"Converts an Any protobuf to the specified message type\n\n    Args:\n        pb_type (type): the type of the message that any_pb stores an instance\n            of.\n        any_pb (google.protobuf.any_pb2.Any): the object to be converted.\n\n    Returns:\n        pb_type: An instance of the pb_type message.\n\n    Raises:\n        TypeError: if the message could not be converted.\n    \"\"\"\n    msg = pb_type()\n    if not any_pb.Unpack(msg):\n        raise TypeError(\n            \"Could not convert {} to {}\".format(\n                any_pb.__class__.__name__, pb_type.__name__\n            )\n        )\n\n    return msg\n\n\ndef _pb_timestamp_to_datetime(timestamp_pb):\n    \"\"\"Convert a Timestamp protobuf to a datetime object.\n\n    :type timestamp_pb: :class:`google.protobuf.timestamp_pb2.Timestamp`\n    :param timestamp_pb: A Google returned timestamp protobuf.\n\n    :rtype: :class:`datetime.datetime`\n    :returns: A UTC datetime object converted from a protobuf timestamp.\n    \"\"\"\n    return _EPOCH + datetime.timedelta(\n        seconds=timestamp_pb.seconds, microseconds=(timestamp_pb.nanos / 1000.0)\n    )\n\n\ndef _pb_timestamp_to_rfc3339(timestamp_pb):\n    \"\"\"Convert a Timestamp protobuf to an RFC 3339 string.\n\n    :type timestamp_pb: :class:`google.protobuf.timestamp_pb2.Timestamp`\n    :param timestamp_pb: A Google returned timestamp protobuf.\n\n    :rtype: str\n    :returns: An RFC 3339 formatted timestamp string.\n    \"\"\"\n    timestamp = _pb_timestamp_to_datetime(timestamp_pb)\n    return _datetime_to_rfc3339(timestamp)\n\n\ndef _datetime_to_pb_timestamp(when):\n    \"\"\"Convert a datetime object to a Timestamp protobuf.\n\n    :type when: :class:`datetime.datetime`\n    :param when: the datetime to convert\n\n    :rtype: :class:`google.protobuf.timestamp_pb2.Timestamp`\n    :returns: A timestamp protobuf corresponding to the object.\n    \"\"\"\n    ms_value = _microseconds_from_datetime(when)\n    seconds, micros = divmod(ms_value, 10**6)\n    nanos = micros * 10**3\n    return timestamp_pb2.Timestamp(seconds=seconds, nanos=nanos)\n\n\ndef _timedelta_to_duration_pb(timedelta_val):\n    \"\"\"Convert a Python timedelta object to a duration protobuf.\n\n    .. note::\n\n        The Python timedelta has a granularity of microseconds while\n        the protobuf duration type has a duration of nanoseconds.\n\n    :type timedelta_val: :class:`datetime.timedelta`\n    :param timedelta_val: A timedelta object.\n\n    :rtype: :class:`google.protobuf.duration_pb2.Duration`\n    :returns: A duration object equivalent to the time delta.\n    \"\"\"\n    duration_pb = duration_pb2.Duration()\n    duration_pb.FromTimedelta(timedelta_val)\n    return duration_pb\n\n\ndef _duration_pb_to_timedelta(duration_pb):\n    \"\"\"Convert a duration protobuf to a Python timedelta object.\n\n    .. note::\n\n        The Python timedelta has a granularity of microseconds while\n        the protobuf duration type has a duration of nanoseconds.\n\n    :type duration_pb: :class:`google.protobuf.duration_pb2.Duration`\n    :param duration_pb: A protobuf duration object.\n\n    :rtype: :class:`datetime.timedelta`\n    :returns: The converted timedelta object.\n    \"\"\"\n    return datetime.timedelta(\n        seconds=duration_pb.seconds, microseconds=(duration_pb.nanos / 1000.0)\n    )\n\n\ndef _name_from_project_path(path, project, template):\n    \"\"\"Validate a URI path and get the leaf object's name.\n\n    :type path: str\n    :param path: URI path containing the name.\n\n    :type project: str\n    :param project: (Optional) The project associated with the request. It is\n                    included for validation purposes.  If passed as None,\n                    disables validation.\n\n    :type template: str\n    :param template: Template regex describing the expected form of the path.\n                     The regex must have two named groups, 'project' and\n                     'name'.\n\n    :rtype: str\n    :returns: Name parsed from ``path``.\n    :raises ValueError: if the ``path`` is ill-formed or if the project from\n                        the ``path`` does not agree with the ``project``\n                        passed in.\n    \"\"\"\n    if isinstance(template, str):\n        template = re.compile(template)\n\n    match = template.match(path)\n\n    if not match:\n        raise ValueError(\n            'path \"%s\" did not match expected pattern \"%s\"' % (path, template.pattern)\n        )\n\n    if project is not None:\n        found_project = match.group(\"project\")\n        if found_project != project:\n            raise ValueError(\n                \"Project from client (%s) should agree with \"\n                \"project from resource(%s).\" % (project, found_project)\n            )\n\n    return match.group(\"name\")\n\n\ndef make_secure_channel(credentials, user_agent, host, extra_options=()):\n    \"\"\"Makes a secure channel for an RPC service.\n\n    Uses / depends on gRPC.\n\n    :type credentials: :class:`google.auth.credentials.Credentials`\n    :param credentials: The OAuth2 Credentials to use for creating\n                        access tokens.\n\n    :type user_agent: str\n    :param user_agent: The user agent to be used with API requests.\n\n    :type host: str\n    :param host: The host for the service.\n\n    :type extra_options: tuple\n    :param extra_options: (Optional) Extra gRPC options used when creating the\n                          channel.\n\n    :rtype: :class:`grpc._channel.Channel`\n    :returns: gRPC secure channel with credentials attached.\n    \"\"\"\n    target = \"%s:%d\" % (host, http.client.HTTPS_PORT)\n    http_request = google.auth.transport.requests.Request()\n\n    user_agent_option = (\"grpc.primary_user_agent\", user_agent)\n    options = (user_agent_option,) + extra_options\n    return google.auth.transport.grpc.secure_authorized_channel(\n        credentials, http_request, target, options=options\n    )\n\n\ndef make_secure_stub(credentials, user_agent, stub_class, host, extra_options=()):\n    \"\"\"Makes a secure stub for an RPC service.\n\n    Uses / depends on gRPC.\n\n    :type credentials: :class:`google.auth.credentials.Credentials`\n    :param credentials: The OAuth2 Credentials to use for creating\n                        access tokens.\n\n    :type user_agent: str\n    :param user_agent: The user agent to be used with API requests.\n\n    :type stub_class: type\n    :param stub_class: A gRPC stub type for a given service.\n\n    :type host: str\n    :param host: The host for the service.\n\n    :type extra_options: tuple\n    :param extra_options: (Optional) Extra gRPC options passed when creating\n                          the channel.\n\n    :rtype: object, instance of ``stub_class``\n    :returns: The stub object used to make gRPC requests to a given API.\n    \"\"\"\n    channel = make_secure_channel(\n        credentials, user_agent, host, extra_options=extra_options\n    )\n    return stub_class(channel)\n\n\ndef make_insecure_stub(stub_class, host, port=None):\n    \"\"\"Makes an insecure stub for an RPC service.\n\n    Uses / depends on gRPC.\n\n    :type stub_class: type\n    :param stub_class: A gRPC stub type for a given service.\n\n    :type host: str\n    :param host: The host for the service. May also include the port\n                 if ``port`` is unspecified.\n\n    :type port: int\n    :param port: (Optional) The port for the service.\n\n    :rtype: object, instance of ``stub_class``\n    :returns: The stub object used to make gRPC requests to a given API.\n    \"\"\"\n    if port is None:\n        target = host\n    else:\n        # NOTE: This assumes port != http.client.HTTPS_PORT:\n        target = \"%s:%d\" % (host, port)\n    channel = grpc.insecure_channel(target)\n    return stub_class(channel)\n"}