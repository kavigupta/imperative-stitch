import json
from tests.abstraction_handling.from_rust_stitch_test import run_compression_for_testing

from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("meta-llama/Meta-Llama-3-8B")

with open("data/vlmaterial-set/human_200.json", "r") as f:
    code = json.load(f)


result = run_compression_for_testing(
    code,
    iterations=100,
    max_arity=4,
    silent=False,
    verbose_best=True,
    use_symvars=False,
)

result.no_choicevar_abstractions()

result.inline_abstractions(
    abstraction_names=[x.name for x in result.abstractions if x.dfa_choicevars]
)

cost_fn = lambda x: len(tokenizer.encode(x))

result = result.inline_multiline_calls()
result = result.remove_unhelpful_abstractions(is_pythonm=True, cost_fn=cost_fn)

print(sum(len(tokenizer.encode(x)) for x in code))
print(sum(len(tokenizer.encode(x)) for x in result.rewritten_python(is_pythonm=True)))


for i, abstr in enumerate(result.abstractions_python()):
    print("*" * 30 + " " + result.abstractions[i].name + " " + "*" * 30)
    print(abstr)

with open("out.py", "w") as f:
    f.write("# This file is auto-generated by create.py\n")
    for x in result.rewritten_python(is_pythonm=True):
        f.write("#" + "-" * 80 + "\n")
        f.write(x + "\n\n")
