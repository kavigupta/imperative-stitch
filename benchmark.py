import json
from tests.abstraction_handling.from_rust_stitch_test import run_compression_for_testing

from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("meta-llama/Meta-Llama-3-8B")

with open("data/vlmaterial-set/human_200.json", "r") as f:
    code = json.load(f)


result = run_compression_for_testing(
    code,
    iterations=100,
    max_arity=4,
    silent=False,
    verbose_best=True,
    is_pythonm=True,
    use_symvars=False,
)

cost_fn = lambda x: len(tokenizer.encode(x))

cost = sum(cost_fn(x) for x in code)

for abstr in result.abstractions:
    print("Trying", abstr.name)
    result2 = result.inline_abstractions(abstraction_names=[abstr.name])
    cost2 = sum(cost_fn(x) for x in result2.rewritten_python(is_pythonm=True))
    if cost2 < cost:
        print("Removed", abstr.name, "Saved", cost - cost2)
        result = result2
        cost = cost2

print(sum(len(tokenizer.encode(x)) for x in code))
print(sum(len(tokenizer.encode(x)) for x in result.rewritten_python(is_pythonm=True)))


for i, abstr in enumerate(result.abstractions_python()):
    print("*" * 30 + " " + result.abstractions[i].name + " " + "*" * 30)
    print(abstr)

with open("out.py", "w") as f:
    f.write("# This file is auto-generated by create.py\n")
    for x in result.rewritten_python(is_pythonm=True):
        f.write("#" + "-" * 80 + "\n")
        f.write(x + "\n\n")
